{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd \nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom collections import Counter\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\nsample=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\ntrain=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\ntest=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **1-DATA ANALYSIS.**\n<div id=\"intAnalysis\"></div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **A-Train dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are NaN values in the columns 'sex', 'age_approx', 'anatom_site_general_challenge'. We dont' need to handle this NaN values because we are going to classify the images using a convolutional neural network(hence, the only parameters we are going to need are image_name and target). That doesn't mean that we can't extract useful information from the rest of parameters, and we are going to do that in the next analysis. \n\nIf you wanted to do a classic machine learning model with sklearn you'll need to handle the NaN values. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.1. Distribution of the train dataset by sex.**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sexDataset=train.groupby('sex').size().reset_index(name='count')\n\nfig = go.Figure()\n\nfig= px.bar(sexDataset, x='sex', y='count',color='sex')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the train dataset by sex',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**A.2.Distribution of the train dataset by age.**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ageDataset=train.groupby('age_approx').size().reset_index(name='count')\n\nfig = go.Figure()\n\n\n\nfig= px.bar(ageDataset, x='age_approx', y='count',color='count')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the train dataset by age',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['age_approx'].skew()#Skewness involves the symmetry of the distribution. \n#Skewness is 0 in a normal distribution, so the farther away from 0, the more non-normal the distribution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, the age is normally distributed. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.3.Images by patient.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['patient_id'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the dataset train there are 2056 patients. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"patientsTrain = train.patient_id.value_counts()\n\nfig = go.Figure()\n# Use x instead of y argument for horizontal plot\nfig.add_trace(go.Box(x=patientsTrain,name=\"Images by patient in the train dataset\",marker_color='white'))\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The patient with the biggest number of images has 115 and the patient with the few number of images has 2. The median of images by patients is 12. The upper fence is 47. There are a few outliers. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.4.Most common areas where the images are made in the train dataset.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"anatomDataset=train.groupby('anatom_site_general_challenge').size().reset_index(name='count')\n\nfig= px.pie(anatomDataset, names='anatom_site_general_challenge', values='count',color='count')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the train dataset by anatomic areas',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most frequent anatomic areas are torso, lower extremity and upper extremity. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.5.Are tumors mostly benign or malignant in the train dataset?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BMDataset=train.groupby('benign_malignant').size().reset_index(name='count')\n\nfig= px.pie(BMDataset, names='benign_malignant', values='count',color='count')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the train dataset by benign or malignant',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a lot more of benign tumors in the train dataset, it's very imbalanced.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.6.Distribution of the dataset by benign and malignant and diagnosis.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BMDiagnosisDataset=train.groupby(['benign_malignant','diagnosis']).size().reset_index(name='count')\n\nfig= px.bar(BMDiagnosisDataset, y='diagnosis', x='count',color='benign_malignant')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by diagnosis',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The only diagnosis with a value 'malignant' associated is melanoma. The rest of the diagnosis are 'benign'.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.7.Distribution in the dataset by benign and malignant and sex.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BMSexDataset=train.groupby(['benign_malignant','sex']).size().reset_index(name='count')\n\nfig= px.bar(BMSexDataset, x='sex', y='count',color='benign_malignant')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by sex',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are slightly more cases of malignant in persons with male sex. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.8.Distribution in the dataset by benign and malignant and anatomic area.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nBMAnatomicDataset=train.groupby(['benign_malignant','anatom_site_general_challenge']).size().reset_index(name='count')\n\nfig= px.bar(BMAnatomicDataset, y='anatom_site_general_challenge', x='count',color='benign_malignant')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by anatomic site',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Melanomas in head/neck: 74\n\n* Melanomas in lower extremity: 124\n\n* Melanomas in oral/genital: 4\n\n* Melanomas in palms/soles: 5\n\n* Melanomas in torso: 257\n\n* Melanomas in upper extremity: 111","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.8.Distribution in the train dataset by benign and malignant and age.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BMAgeDataset=train.groupby(['benign_malignant','age_approx','sex']).size().reset_index(name='count')\n\nfig= px.bar(BMAgeDataset, x='age_approx', y='count',color='benign_malignant',hover_data=['sex'])\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by age',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are more malignant cases between 45 and 80 years old. According to various sources of information (Cancer Research UK, American Cancer Society), melanoma is more common in men, but before age 50/60 the rates are higher in women.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.9.Check if a target 0 is always associated with a value 'benign' in the benign_malignant column, and with a value 'melanoma' in the diagnosis column.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntargetDataset=train.groupby(['benign_malignant','target','diagnosis']).size().reset_index(name='count')\n\nfig = go.Figure()\n\nfig = px.bar(targetDataset, y=\"count\", x=\"target\", color='benign_malignant',height=500)\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by target',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A target '0' is always associated with benign. A target '1' is always associated with malignant. The target is very imbalanced.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig = px.bar(targetDataset, x=\"count\", y=\"diagnosis\", color='target',height=300)\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Diagnosis by target',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A diagnosis 'melanoma' is always associated with a target 1.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**A.10.Check if the column image_name has unique values for each row .**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"imagesNameTrain = train.image_name.value_counts()\n\nfig = go.Figure()\n# Use x instead of y argument for horizontal plot\nfig.add_trace(go.Box(x=imagesNameTrain,name=\"Has each image an unique image_name?\",marker_color='white'))\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes, the images names are unique. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This is the whole analysis of the train dataset. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **B-Test Dataset.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are NaN values in the column 'anatom_site_general_challenge'. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**B.1. Distribution of the test dataset by sex.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"testSexDataset=test.groupby('sex').size().reset_index(name='count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig = px.bar(testSexDataset,\n             x='sex',\n             y='count',\n             title='Distribution of the test dataset by sex',\n              color='sex',\n             barmode='stack')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the dataset test there are more males than females, when in the dataset train the quantity of both sexs was similar.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**B.2. Distribution of the test dataset by age.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"testAgeDataset=test.groupby('age_approx').size().reset_index(name='count')\nfig = go.Figure()\n\nfig = px.bar(testAgeDataset,\n             x='age_approx',\n             y='count',\n             title='Distribution of the test dataset by age',\n              color='age_approx',\n             barmode='stack')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['age_approx'].skew() #Skewness involves the symmetry of the distribution. \n#Skewness is 0 in a normal distribution, so the farther away from 0, the more non-normal the distribution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are more older patients in the test dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**B.3. Images by patient.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"patientsTest = test.patient_id.value_counts()\nfig = go.Figure()\n# Use x instead of y argument for horizontal plot\nfig.add_trace(go.Box(x=patientsTest,name=\"Images by patient in the test dataset\",marker_color='white'))\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The patient with the biggest number of images has 240 and the patient with the few number of images has 3. The median of images by patients is 10. The upper fence is 43. There are less outliers here than in the train dataset, but there is a huge one: the patient with 240 images. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**B.4.Most common areas where the images are made in the test dataset.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"testAnatomDataset=test.groupby('anatom_site_general_challenge').size().reset_index(name='count')\n\n\n\nfig= px.bar(testAnatomDataset, y='anatom_site_general_challenge', x='count',color='count')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the test dataset by anatomic areas',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution is similar to the one of the train dataset. There are a lot of rows with 'No anatomic site known'.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**B.5.Check if the column image_name has unique values for each row .**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"imagesNameTrain = test.image_name.value_counts()\n\nfig = go.Figure()\n# Use x instead of y argument for horizontal plot\nfig.add_trace(go.Box(x=imagesNameTrain,name=\"Has each image an unique image_name?\",marker_color='white'))\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes, the images names are unique.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **2-PREPROCESSING THE DATA.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As you can saw in the EDA before, the train dataset is very unbalaced, so this can lead to overfitting problems. There are many ways to deal with imbalanced data. There are these amazing papers which gives you some ways to solution this problem. \n\n* https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n* https://medium.com/analytics-vidhya/how-to-apply-data-augmentation-to-deal-with-unbalanced-datasets-in-20-lines-of-code-ada8521320c9\n* https://towardsdatascience.com/deep-learning-unbalanced-training-data-solve-it-like-this-6c528e9efea6\n* https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I'm going to fix the umbalanced data by doing oversampling using the RandomOverSampler algorithm, by using imbalanced-learn library. For more information about this library, check the link: https://imbalanced-learn.readthedocs.io/en/stable/index.html","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install -U imbalanced-learn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.drop('target',axis=1)\ny=train['target']\nprint('Original dataset shape %s' % Counter(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=42)\nX_res, y_res = ros.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mix X_res and y_res into train dataset again\nX_res['target']=y_res\ntrain_resampled=X_res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetDatasetResampled=train_resampled.groupby(['benign_malignant','target','diagnosis']).size().reset_index(name='count')\n\nfig = go.Figure()\n\nfig = px.bar(targetDatasetResampled, y=\"count\", x=\"target\", color='benign_malignant',height=500)\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by target',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3-BUILDING A CONVOLUTIONAL NEURAL NETWORK TO PREDICT THE IMAGES.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will use MobileNet. It's not the most efficient convolutional neural network but I wanted to obtain the predictions the quickest possible. If you want to check all the Keras' convolutional neural networks and their efficient, check the link: https://keras.io/api/applications/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras.applications import MobileNet as model\nfrom keras.layers import Dense, GlobalAveragePooling2D,Activation,Flatten\nfrom keras.models import Model\n\nbase_model = model(weights='imagenet',include_top=False)\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply transfer learning to the model\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x) # #we add dense layers so that the model can learn more complex functions and classify for better results\nx=Dense(1024,activation='relu')(x) \nx=Dense(512,activation='relu')(x)\n# and a logistic layer -- \npredictions = Dense(2, activation='softmax')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional layers\nfor layer in model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=train_resampled\ntest_data=test\n\ntrain_data['image_name'] = train_data['image_name'].apply(lambda x: x + '.jpg')\ntest_data['image_name'] = test_data['image_name'].apply(lambda x: x + '.jpg')\n\nX2_train, X2_val = train_test_split(train_data, test_size=0.2, random_state=42)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=360,rescale=1./255, horizontal_flip=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_generator=train_datagen.flow_from_dataframe(\n    dataframe=X2_train,\n    directory='../input/siim-isic-melanoma-classification/jpeg/train/',\n    x_col=\"image_name\",\n    y_col=\"target\",\n    class_mode=\"raw\",\n    batch_size=8,\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    \n    \n    )\n\nvalidation_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\nvalid_generator=validation_datagen.flow_from_dataframe(\n    dataframe=X2_val,\n    directory='../input/siim-isic-melanoma-classification/jpeg/train/',\n    x_col=\"image_name\",\n    y_col=\"target\",\n    class_mode=\"raw\", \n    batch_size=8,   \n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    \n    )\n\ntest_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntest_generator=test_datagen.flow_from_dataframe(  \n        dataframe=test_data,\n        directory = '../input/siim-isic-melanoma-classification/jpeg/test/',\n        x_col=\"image_name\",\n        batch_size=1,\n        class_mode=None,\n        shuffle=False,\n        target_size=(224, 224),\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\nmodel.fit_generator(generator=train_generator,\n                                    steps_per_epoch=train_generator.n//64,\n                                    validation_data=valid_generator,\n                                    validation_steps=valid_generator.n//64,\n                                    epochs=10,\n                                    \n                       )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4-MAKING THE PREDICTIONS.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.image as matimage\nimport cv2\n#predict a random image\npathImage=test_generator.filepaths[np.random.random_integers(low=0,high=test_generator.samples)]\nprint(pathImage)\nimg=matimage.imread(pathImage)\nplt.imshow(img)\n\nfrom PIL import Image\nimage=Image.open(pathImage)\nimage=image.convert('RGB')\nimage=image.resize((224,224))\nprobabilities=model.predict(np.expand_dims(image,axis=0))\nprint(probabilities[0][0])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataTestPathPredict='../input/siim-isic-melanoma-classification/jpeg/test/'\ndef make_predictions(image_name):\n    image=Image.open(str(dataTestPathPredict + image_name))\n    image=image.convert('RGB')\n    image=image.resize((224,224))\n    pre = model.predict(np.expand_dims(image,axis=0))\n    return pre[0][0]\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_predictions('ISIC_4809071.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['model_prediction'] = test_data['image_name'].apply(make_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.to_csv(\"saveData.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalpred=test_data['model_prediction']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['target']=finalpred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('FinalSubmission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}