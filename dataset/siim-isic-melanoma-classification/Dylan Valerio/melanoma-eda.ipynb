{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Forked!\nOriginal : https://www.kaggle.com/saife245/melanoma-detail-analysis-eda-ip-augmentation-model\n\nAnother great EDA kernel: https://www.kaggle.com/parulpandey/melanoma-classification-eda-starter\n\nFor this kernel, I'm also studying PyTorch.\nhttps://www.kaggle.com/zzy990106/pytorch-5-fold-efficientnet-baseline\n\nThere's also apparently a library for pre-trained models / architectures: for PyTorch Timm\n\nAutoAugment\nhttps://arxiv.org/abs/1805.09501\n\nPre-processed 224x224 images\nhttps://www.kaggle.com/arroqc/siic-isic-224x224-images","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"How to spot melanoma\n\nThe medical community has developed two ways to spot the early signs of melanoma, the most dangerous type of skin cancer. A person can use the ABCDE method and the ugly duckling method.\n\n    The ABCDE method:- Brown spots, marks, and moles are usually harmless. However, the first sign of melanoma can occur in what doctors call an atypical mole, or dysplastic nevi. To spot an atypical mole, check for the following:\n        A: Asymmetry. If the two halves of a mole do not match, this can be an early indication of melanoma.\n        B: Border. The edges of a harmless mole are even and smooth. If a mole has uneven edges, this can be an early sign of melanoma. The mole’s border may be scalloped or notched.\n        C: Color.Harmless moles are a single shade, usually of brown. Melanoma can cause differentiation in shade, from tan, brown, or black to red, blue, or white.\n        D: Diameter. Harmless moles tend to be smaller than dangerous ones, which are usually larger than a pencil’s eraser — around one-quarter of an inch, or 6 millimeters.\n        E: Evolving. If a mole starts to change, or evolve, this can be a warning. Changes may involve shape, color, or elevation from the skin. Or, a mole may start to bleed, itch, or crust. \n         \n![ABCDE](https://i.pinimg.com/originals/60/f6/d8/60f6d82a2edbc0c7e0e9df5308e654c3.jpg)\n\n\nMelanoma stage grouping...\n\n    Stage 0: This refers to melanoma in situ, which means melanoma cells are found only in the outer layer of skin or epidermis. This stage of melanoma is very unlikely to spread to other parts of the body.\n\n    Stage I: The primary melanoma is still only in the skin and is very thin. Stage I is divided into 2 subgroups, IA or IB, depending on the thickness of the melanoma and whether a pathologist sees ulceration under a microscope.\n\n    Stage II: Stage II melanoma is thicker than stage I melanoma, extending through the epidermis and further into the dermis, the dense inner layer of the skin. It has a higher chance of spreading. Stage II is divided into 3 subgroups—A, B, or C—depending on how thick the melanoma is and whether there is ulceration.\n    Stage III: This stage describes melanoma that has spread locally or through the lymphatic system to a regional lymph node located near where the cancer started or to a skin site on the way to a lymph node, called “in-transit metastasis, satellite metastasis, or microsatellite disease.” The lymphatic system is part of the immune system and drains fluid from body tissues through a series of tubes or vessels. Stage III is divided into 4 subgroups—A, B, C, or D—depending on the size and number of lymph nodes involved with melanoma, whether the primary tumor has satellite or in-transit lesions, and if it appears ulcerated under a microscope.\n    Stage IV: This stage describes melanoma that has spread through the bloodstream to other parts of the body, such as distant locations on the skin or soft tissue, distant lymph nodes, or other organs like the lung, liver, brain, bone, or gastrointestinal tract. Stage IV is further evaluated based on the location of distant metastasis:\n        M1a: The cancer has only spread to distant skin and/or soft tissue sites.\n        M1b: The cancer has spread to the lung.\n        M1c: The cancer has spread to any other location that does not involve the central nervous system.\n        M1d: The cancer has spread to the central nervous system, including the brain, spinal cord, and/or cerebrospinal fluid, or lining of the brain and/or spinal cord.\n\n![Stages Melanoma](https://images.agoramedia.com/everydayhealth/gcms/Melanoma-Stages-722x406.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## What am I predicting?\n* You are predicting a binary target for each image. \n* Your model should predict the probability (floating point) between 0.0 and 1.0 that the lesion in the image is malignant (the target). \n* In the training data, train.csv, the value 0 denotes benign, and 1 indicates malignant.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Imports","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport json\nimport math\nimport cv2\nimport PIL\nimport re\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\n#from sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nfrom tqdm import tqdm\n%matplotlib inline\n#from keras.preprocessing import image\nimport glob\nimport tensorflow.keras.applications.densenet as dense\nfrom kaggle_datasets import KaggleDatasets\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nimport missingno as msno\n\nfrom plotly.offline import iplot\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Few Word about dataset...\n\n### What should I expect the data format to be?\nThe images are provided in DICOM format. This can be accessed using commonly-available libraries like **pydicom**, and contains both image and metadata. It is a commonly used medical imaging data format.\n\nImages are also provided in **JPEG** and **TFRecord** format (in the jpeg and tfrecords directories, respectively). Images in TFRecord format have been resized to a uniform 1024x1024.\n\nMetadata is also provided outside of the DICOM format, in CSV files. See the Columns section for a description.\n\n## Columns...\n* **image_name** - unique identifier, points to filename of related DICOM image\n* **patient_id** - unique patient identifier\n* **sex** - the sex of the patient (when unknown, will be blank)\n* **age_approx** - approximate patient age at time of imaging\n* **anatom_site_general_challenge** - location of imaged site\n* **diagnosis** - detailed diagnosis information (train only)\n* **benign_malignant** - indicator of malignancy of imaged lesion\n* **target** - binarized version of the target variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\ntest = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')\n\nprint('Train: ', train.shape)\nprint(\"Test:\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(train, );","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Non-Image EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vc = train.groupby(\"benign_malignant\")[\"diagnosis\"].value_counts().unstack()[train[\"diagnosis\"].value_counts().sort_values().index]\ndisplay(vc)\nvc.iplot(kind='bar', yTitle='Percentage', \n          linecolor='black', \n          opacity=0.7,\n          theme='pearl',\n          bargap=0.5,\n          gridcolor='white',\n          barmode = 'stack',\n          title='Distribution of the Target column in the training set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc = train.groupby(\"benign_malignant\")[\"sex\"].value_counts(normalize=True).unstack()\nvc.iplot(kind='bar', yTitle='Percentage', \n          linecolor='black', \n          opacity=0.7,\n          theme='pearl',\n          bargap=0.5,\n          gridcolor='white',\n          barmode = 'stack',\n          title='Target vs Gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\n\nsns.distplot(train.loc[train['sex'] == 'female', 'age_approx'], label = 'Benign')\n\nsns.distplot(train.loc[train['sex'] == 'male', 'age_approx'], label = 'Malignant')\n\nscipy.stats.ttest_ind(train.loc[train['sex'] == 'female', 'age_approx'], train.loc[train['sex'] == 'male', 'age_approx'], nan_policy='omit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc = train.groupby(\"age_approx\")[\"benign_malignant\"].value_counts().unstack()\nvc.iplot(kind='bar', yTitle='Percentage', \n          linecolor='black', \n          opacity=0.7,\n          theme='pearl',\n          bargap=0.2,\n          gridcolor='white',\n          barmode = 'stack',\n          title='Age vs Gender')\nvc = train.groupby(\"age_approx\")[\"benign_malignant\"].value_counts(normalize=True).unstack()\nvc.iplot(kind='bar', yTitle='Percentage', \n          linecolor='black', \n          opacity=0.7,\n          theme='pearl',\n          bargap=0.2,\n          gridcolor='white',\n          barmode = 'stack',\n          title='Age vs Gender, normalized')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\n\nsns.distplot(train.loc[train['target'] == 0, 'age_approx'], label = 'Benign')\n\nsns.distplot(train.loc[train['target'] == 1, 'age_approx'], label = 'Malignant')\n\nscipy.stats.ttest_ind(train.loc[train['target'] == 0, 'age_approx'], train.loc[train['target'] == 1, 'age_approx'], nan_policy='omit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc = train[\"diagnosis\"].value_counts()[::-1]\nvc[vc.index != \"unknown\"].plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc = train.groupby(\"anatom_site_general_challenge\")[\"benign_malignant\"].value_counts().unstack()\nvc.iplot(kind='bar', yTitle='Percentage', \n          linecolor='black', \n          opacity=0.7,\n          theme='pearl',\n          bargap=0.2,\n          gridcolor='white',\n          barmode = 'stack',\n          title='Target vs Gender')\nvc = train.groupby(\"anatom_site_general_challenge\")[\"benign_malignant\"].value_counts(normalize=True).unstack()\nvc.iplot(kind='bar', yTitle='Percentage', \n          linecolor='black', \n          opacity=0.7,\n          theme='pearl',\n          bargap=0.2,\n          gridcolor='white',\n          barmode = 'stack',\n          title='Target vs Gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Seeing images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_training_curves(training, validation, title, subplot):\n  if subplot%10==1: # set up the subplots on the first call\n    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n    plt.tight_layout()\n  ax = plt.subplot(subplot)\n  ax.set_facecolor('#F8F8F8')\n  ax.plot(training)\n  ax.plot(validation)\n  ax.set_title('model '+ title)\n  ax.set_ylabel(title)\n  ax.set_xlabel('epoch')\n  ax.legend(['train', 'valid.'])\n\ndef grid_display(list_of_images, no_of_columns=2, figsize=(15,15), title = False):\n    num_images = len(list_of_images)\n    no_of_rows = int(num_images / no_of_columns)\n    fig, axes = plt.subplots(no_of_rows,no_of_columns, figsize=figsize)\n    if no_of_rows == 1:\n        list_axes = []\n        list_axes.append(axes)\n        axes = list_axes\n    \n    idx = 0\n    idy = 0\n    \n    for i, img in enumerate(list_of_images):\n        axes[idy][idx].imshow(img)\n        axes[idy][idx].axis('off')\n        if title:\n            axes[idy][idx].set_title(title[i])\n            \n        if idx < no_of_columns - 1:\n            idx+=1\n        else:\n            idx=0\n            idy+=1\n    fig.tight_layout()\n    return fig","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Benign, Moles, Nevuus","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[train['target'] == 0].sample(16)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\n#show_images(image_all, cols=1)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Melanoma","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[train['target'] == 1].sample(16)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Melanoma, torso","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[(train['anatom_site_general_challenge'] == 'torso') & (train['target'] == 1)].sample(16)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Melanoma, Lower extremities","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[(train['anatom_site_general_challenge'] == 'lower extremity') & (train[\"target\"] == 1)].sample(16)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Melanoma, Upper extremity.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[(train['anatom_site_general_challenge'] == 'upper extremity') & (train[\"target\"] == 1)].sample(16)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Melanoma, head/neck","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[(train['anatom_site_general_challenge'] == 'head/neck') & (train[\"target\"] == 1)].sample(16)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualiza the skin cancer at Palms/soles...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[(train['anatom_site_general_challenge'] == 'palms/soles') & (train[\"target\"] == 1)].sample(4)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Benign, seborrheic keratosis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[train['diagnosis'] == 'seborrheic keratosis'].sample(16)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Benign, Lentigo","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[train['diagnosis'] == 'lentigo NOS'].sample(16)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Benign, lichenoid keratosis...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[train['diagnosis'] == 'lichenoid keratosis'].sample(16)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(16))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Benign, Solar lentigo","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[train['diagnosis'] == 'solar lentigo'].sample(4)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = range(4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Atypical melanocytic proliferation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[train['diagnosis'] == 'atypical melanocytic proliferation'].sample(1)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n\nplt.imshow(img)\nplt.axis('off');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualiza the skin cancer cafe-au-lait macule...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = train[train['diagnosis'] == 'cafe-au-lait macule'].sample(1)['image_name']\nimage_all=[]\nfor image_id in image_list:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    image_all.append(img)\nplt.imshow(img)\nplt.axis('off');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Skin cancer At different Age Group...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"arr = [15.0,20.0,25.0,30.0,35.0,40.0,45.0,50.0,55.0,60.0,65.0,70.0,75.0,80.0,85.0,90.0]\nimage_all=[]\ntitles = ['At Age 15.0','At Age 20.0','At Age 25.0','At Age 30.0','At Age 35.0','At Age 40.0'\n          ,'At Age 45.0','At Age 50.0','At Age 55.0','At Age 60.0','At Age 65.0','At Age 70.0'\n          ,'At Age 75.0','At Age 80.0','At Age 85.0','At Age 90.0']\nfor i in arr:\n    image_list = train[(train['age_approx'] == i) & (train[\"target\"] == 1)].sample()['image_name']\n    for image_id in image_list:\n        image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n        img = np.array(Image.open(image_file))\n        image_all.append(img)\nfig = grid_display(image_all, 4, (15,15), title = titles)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Is there a difference in histograms?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"benign_images = train[train[\"target\"] == 0].sample(10)[\"image_name\"]\ncancer_images = train[train[\"target\"] == 1].sample(10)[\"image_name\"]\n\nbenign_image_arr = []\ncancer_image_arr = []\n\nfor image_id in benign_images:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    benign_image_arr.append(img)\n    \nfor image_id in cancer_images:\n    image_file = f'/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+image_id+'.jpg' \n    img = np.array(Image.open(image_file))\n    cancer_image_arr.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reds.mean()/255, greens.mean()/255, blues.mean()/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reds = np.hstack([v[:, :, 0].ravel() for v in benign_image_arr])\ngreens = np.hstack([v[:, :, 1].ravel() for v in benign_image_arr])\nblues = np.hstack([v[:, :, 2].ravel() for v in benign_image_arr])\n\nplt.figure(figsize=(15, 8))\n_ = plt.hist(reds, bins=256, color='red', alpha=0.5)\n_ = plt.hist(greens, bins=256, color='green', alpha=0.5)\n_ = plt.hist(blues, bins=256, color='blue', alpha=0.5)\n\n_ = plt.xlabel('Intensity Value')\n_ = plt.ylabel('Count')\n_ = plt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\n\nprint(\"R: {:.2f}, G: {:2f}, B: {:2f}\".format(reds.mean(), greens.mean(), blues.mean()))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reds = np.hstack([v[:, :, 0].ravel() for v in cancer_image_arr])\ngreens = np.hstack([v[:, :, 1].ravel() for v in cancer_image_arr])\nblues = np.hstack([v[:, :, 2].ravel() for v in cancer_image_arr])\n\nplt.figure(figsize=(15, 8))\n_ = plt.hist(reds, bins=256, color='red', alpha=0.5)\n_ = plt.hist(greens, bins=256, color='green', alpha=0.5)\n_ = plt.hist(blues, bins=256, color='blue', alpha=0.5)\n\n_ = plt.xlabel('Intensity Value')\n_ = plt.ylabel('Count')\n_ = plt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\n\nprint(\"R: {:.2f}, G: {:2f}, B: {:2f}\".format(reds.mean(), greens.mean(), blues.mean()))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Augmentations Showcase","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# img = Image.open(train_path + 'ISIC_2637011.jpg')\n\n# light = transforms.Compose([\n#     transforms.RandomErasing()\n#     ])\n\n\n# fig, axes = plt.subplots(1,2, figsize=(12, 6))\n# axes[0].imshow(img)\n# axes[1].imshow(transforms.RandomErasing()(np.array(img)))\n# # axes[1].imshow(Cutout(scale=(0.05, 0.007), value=(0, 0))(np.array(img)))\n\n# axes[0].axis('off')\n# axes[1].axis('off')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}