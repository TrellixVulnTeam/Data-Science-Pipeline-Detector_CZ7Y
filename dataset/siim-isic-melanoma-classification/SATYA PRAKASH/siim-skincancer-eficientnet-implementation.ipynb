{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_dir='/kaggle/input/siim-isic-melanoma-classification/train.csv'\ntest_dir='/kaggle/input/siim-isic-melanoma-classification/test.csv'\ntrain_dataframe=pd.read_csv(training_dir)\ntest_dataframe=pd.read_csv(test_dir)\ntrain_dataframe.head(7)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv(test_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#percentage of people not suffering from Melanoma are:\nprint('Non-Melonoma patients are :',(32542/(32542+584)*100))\nprint('Melonoma patients are : ',(584/(32542+584)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we saw above we have 33126 training_dataset and in which there is only 584 having label 1 or suffered from Melanoma. \nSo,here \"data imblance\" problem arises.\nonly 1.7% of people suffered from meloma in the given dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Format in which we need to submit the submission file.\nsubmission=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe['sex'].value_counts() \n#It shows,there is no gender biasness in this dataset,both are approximately equal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Mean of age is approx 49,and 75% of dataset lies under 60 ,\nand 1remaining upto 90 so there are not much more outliers in the dataset w.r.t age***"},{"metadata":{"trusted":true},"cell_type":"code","source":"#'anatom_site_general_challenge' is the location of cancer,so it is very important feature.\n\nlabels=train_dataframe['anatom_site_general_challenge'].value_counts()\nvalues=train_dataframe['anatom_site_general_challenge'].value_counts().values\n# i will try to plot it using graph,i think pie chart is good \nfig=labels.plot.pie(y=values,figsize=(10,10),autopct='%1.1f%%',startangle=15, shadow = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**If we look at the graph carefully,\nmore than 51% of data lies under \"torso\"\nit means half of the person having cancer on \"torso\"**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe.drop(train_dataframe.loc[train_dataframe['diagnosis']=='unknown'].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Another feature is diagnosis\n#I try to remove the \"unknown\" valued rows.\n\ndiag_index=train_dataframe['diagnosis'].value_counts()\ndiag_labels=train_dataframe['diagnosis'].value_counts().values\ndiag_index,diag_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diag_index.plot.pie(y=diag_labels,subplots=True,figsize=(7,5), startangle=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** 82% data are unknown  and 16% are navus**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=train_dataframe.drop(['image_name','patient_id','sex','age_approx','anatom_site_general_challenge','target'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if we will try to figure out that in which category of diagnosis ,most of the people are maligant or not maligant\npd.crosstab(df['diagnosis'].values,df['benign_malignant'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**benign cases are diagnosed as nevus\n**and those diagnosed as \"melanoma\" are maligant**"},{"metadata":{"trusted":true},"cell_type":"code","source":"benign_data=train_dataframe[train_dataframe['target']==0].sample(1500) #i have taken a small sample of benign_data\nmaligant_data=train_dataframe[train_dataframe['target']==1]\ntrain=pd.concat([benign_data,maligant_data])\ntrain=train.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\ntest_dir='/kaggle/input/siim-isic-melanoma-classification/jpeg/test/'\ndata=[]\nlabels=[]\nfor i in range(train.shape[0]):\n    data.append(train_dir+train['image_name'].iloc[i]+'.jpg')\n    labels.append(train['target'].iloc[i])\ndf=pd.DataFrame(data)\ndf.columns=['images']\ndf['target']=labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ../input/siim-isic-melanoma-classification/jpeg/train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data=[]\nfor i in range(test.shape[0]):\n    test_data.append(test_dir + test['image_name'].iloc[i]+'.jpg')\ndf_test=pd.DataFrame(test_data)\ndf_test.columns=['images']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val=train_test_split(df['images'],df['target'],test_size=0.2,random_state=42)\n\ntrain_gen = pd.DataFrame({'image_dir': x_train, 'target': y_train})\nval_gen = pd.DataFrame({'image_dir': x_val, 'target': y_val})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,horizontal_flip=True)\nval_datagen=ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_gen,\n    x_col='image_dir',\n    y_col='target',\n    target_size=(256, 256),\n    batch_size=8,\n    shuffle=True,\n    class_mode='raw')\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n    val_gen,\n    x_col='image_dir',\n    y_col='target',\n    target_size=(256, 256),\n    shuffle=False,\n    batch_size=8,\n    class_mode='raw')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen.shape,val_gen.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from keras.applications.vgg16 import VGG16\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras import layers\nfrom keras.metrics import AUC\nfrom keras.activations import sigmoid\nfrom keras.optimizers import SGD, Adam, Adamax\nfrom keras import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\nmodel=EfficientNetB0(weights='imagenet',include_top=False,drop_connect_rate=0.4,input_shape=(256, 256, 3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = layers.Flatten()(model.output)\noutput = layers.Dense(1, activation='sigmoid')(x)\nmodel = Model(model.input, output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install focal-loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom focal_loss import BinaryFocalLoss\nfrom keras.metrics import AUC\nopt = keras.optimizers.Adam(lr = 1e-5)\n# model.compile(loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'],optimizer=opt)\nmodel.compile(loss=BinaryFocalLoss(gamma=2), metrics=['AUC'],optimizer=opt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_epochs = 25\nbatch_size=8\nnb_train_steps = train_gen.shape[0]//batch_size\nnb_val_steps=val_gen.shape[0]//batch_size\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CallBacks Function\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\nearly_stop=EarlyStopping(monitor=\"val_loss\",\n                         patience=10,\n                         mode=\"auto\",)\nLearning_rate_reduction=ReduceLROnPlateau(monitor='val_loss',patience=2,verbose=1,factor=0.5,min_lr=0.001)\n\ncallbacks=[early_stop,Learning_rate_reduction]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist=model.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_steps,\n    epochs=nb_epochs,\n    validation_data=validation_generator,\n    callbacks=callbacks,\n    validation_steps=nb_val_steps)\n\n# history = model.fit_generator(train_generator,validation_data = validation_generator,epochs = 20, verbose = 1,callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import cv2\ntarget=[]\nfor path in df_test['images']:\n    img=cv2.imread(str(path))\n    img = cv2.resize(img, (256,256))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    img=np.reshape(img,(1,256,256,3))\n    prediction=model.predict(img)\n    target.append(prediction[0][0])\n\nsubmission['target']=target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = hist.history['auc']\nval_acc = hist.history['val_auc']\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='green', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='pink', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import pickle\nPkl_Filename = \"Pickle_RL_Model.pkl\"\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(model, file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}