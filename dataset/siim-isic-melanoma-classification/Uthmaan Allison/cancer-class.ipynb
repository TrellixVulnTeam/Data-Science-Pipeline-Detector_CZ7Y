{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:04.364205Z","iopub.execute_input":"2021-06-14T14:01:04.364792Z","iopub.status.idle":"2021-06-14T14:01:12.43718Z","shell.execute_reply.started":"2021-06-14T14:01:04.364726Z","shell.execute_reply":"2021-06-14T14:01:12.435315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q chart_studio","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:12.439293Z","iopub.execute_input":"2021-06-14T14:01:12.439586Z","iopub.status.idle":"2021-06-14T14:01:17.820268Z","shell.execute_reply.started":"2021-06-14T14:01:12.439554Z","shell.execute_reply":"2021-06-14T14:01:17.818903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import modules\n\nimport numpy as np \nimport pandas as pd \nimport math\nimport os\nimport glob\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport PIL\n\n# plotly\nimport plotly.express as px\nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\n\nfrom matplotlib.image import imread\nimport cv2\n\nfrom sklearn.model_selection import ( KFold, train_test_split, \n                                    cross_validate, cross_val_score, GridSearchCV )\nfrom sklearn.metrics import ( roc_curve, auc, precision_recall_curve, \n                             average_precision_score, ConfusionMatrixDisplay )\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom random import choices\nfrom functools import partial\nimport re\nfrom kaggle_datasets import KaggleDatasets\n\n# tensorflow\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import (Dense, Flatten, Dropout, LSTM, \n                                     Bidirectional, Lambda, Reshape,\n                                    GlobalAveragePooling2D) \nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras import optimizers\nfrom keras.utils.vis_utils import plot_model\n\nimport efficientnet.tfkeras as efn\n\n# Suppress warnings \nimport warnings\nwarnings.simplefilter(action='ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:17.822318Z","iopub.execute_input":"2021-06-14T14:01:17.822791Z","iopub.status.idle":"2021-06-14T14:01:17.846252Z","shell.execute_reply.started":"2021-06-14T14:01:17.822531Z","shell.execute_reply":"2021-06-14T14:01:17.845203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nsns.set(context=\"paper\", font=\"monospace\")\nsns.set(style=\"whitegrid\")\nplt.style.use('fivethirtyeight')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:17.847478Z","iopub.execute_input":"2021-06-14T14:01:17.847715Z","iopub.status.idle":"2021-06-14T14:01:17.874506Z","shell.execute_reply.started":"2021-06-14T14:01:17.847689Z","shell.execute_reply":"2021-06-14T14:01:17.873346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Data Loading and Exploration","metadata":{}},{"cell_type":"code","source":"# available files and folders \nprint(os.listdir(\"../input/siim-isic-melanoma-classification\"))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:17.875584Z","iopub.execute_input":"2021-06-14T14:01:17.875902Z","iopub.status.idle":"2021-06-14T14:01:17.89032Z","shell.execute_reply.started":"2021-06-14T14:01:17.875871Z","shell.execute_reply":"2021-06-14T14:01:17.889159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\n\ntest = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')\n\nprint('Training data shape: ', train.shape)\ntrain.head() ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:17.891698Z","iopub.execute_input":"2021-06-14T14:01:17.892099Z","iopub.status.idle":"2021-06-14T14:01:18.023518Z","shell.execute_reply.started":"2021-06-14T14:01:17.892049Z","shell.execute_reply":"2021-06-14T14:01:18.022536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and test data info\nprint('Train Set')\nprint(train.info())\nprint('-------------')\nprint('Test Set')\nprint(test.info())","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.02467Z","iopub.execute_input":"2021-06-14T14:01:18.024941Z","iopub.status.idle":"2021-06-14T14:01:18.059664Z","shell.execute_reply.started":"2021-06-14T14:01:18.024913Z","shell.execute_reply":"2021-06-14T14:01:18.058946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Explore melanoma target","metadata":{}},{"cell_type":"code","source":"train['benign_malignant'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.061578Z","iopub.execute_input":"2021-06-14T14:01:18.061958Z","iopub.status.idle":"2021-06-14T14:01:18.070198Z","shell.execute_reply.started":"2021-06-14T14:01:18.061929Z","shell.execute_reply":"2021-06-14T14:01:18.069569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['benign_malignant'].value_counts(normalize=True).iplot(kind='bar',\n                                                      yTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='red',\n                                                      theme='pearl',\n                                                      bargap=0.2,\n                                                      gridcolor='white',\n                                                      title='Melanoma Target Distribution')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.07155Z","iopub.execute_input":"2021-06-14T14:01:18.071997Z","iopub.status.idle":"2021-06-14T14:01:18.140427Z","shell.execute_reply.started":"2021-06-14T14:01:18.071967Z","shell.execute_reply":"2021-06-14T14:01:18.139572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Highly imbalanced target. There are significantly more benign images compared to malignant images in the train dataset.","metadata":{}},{"cell_type":"markdown","source":"#### Sex distribution","metadata":{}},{"cell_type":"code","source":"train['sex'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.141605Z","iopub.execute_input":"2021-06-14T14:01:18.142016Z","iopub.status.idle":"2021-06-14T14:01:18.151631Z","shell.execute_reply.started":"2021-06-14T14:01:18.141981Z","shell.execute_reply":"2021-06-14T14:01:18.150554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['sex'].value_counts(normalize=True).iplot(kind='bar',\n                                                yTitle='Percentage', \n                                                linecolor='black', \n                                                opacity=0.7,\n                                                color='green',\n                                                theme='pearl',\n                                                bargap=0.3,\n                                                gridcolor='white',\n                                                title='Sex Distribution')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.153266Z","iopub.execute_input":"2021-06-14T14:01:18.153953Z","iopub.status.idle":"2021-06-14T14:01:18.217258Z","shell.execute_reply.started":"2021-06-14T14:01:18.153907Z","shell.execute_reply":"2021-06-14T14:01:18.216287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Gender vs Target","metadata":{}},{"cell_type":"code","source":"z = train.groupby(['target','sex'])['benign_malignant'].count().to_frame().reset_index()\nz.style.background_gradient(cmap='Reds')  ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.218841Z","iopub.execute_input":"2021-06-14T14:01:18.219462Z","iopub.status.idle":"2021-06-14T14:01:18.246142Z","shell.execute_reply.started":"2021-06-14T14:01:18.219417Z","shell.execute_reply":"2021-06-14T14:01:18.244904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='target',y='benign_malignant', hue='sex',data=z,kind='bar')\nplt.ylabel('Count')\nplt.xlabel('benign:0 vs malignant:1');","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.247666Z","iopub.execute_input":"2021-06-14T14:01:18.248115Z","iopub.status.idle":"2021-06-14T14:01:18.591321Z","shell.execute_reply.started":"2021-06-14T14:01:18.248066Z","shell.execute_reply":"2021-06-14T14:01:18.590349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Location of imaged site","metadata":{}},{"cell_type":"code","source":"train['anatom_site_general_challenge'].value_counts(normalize=True).sort_values()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.592614Z","iopub.execute_input":"2021-06-14T14:01:18.59292Z","iopub.status.idle":"2021-06-14T14:01:18.603779Z","shell.execute_reply.started":"2021-06-14T14:01:18.592887Z","shell.execute_reply":"2021-06-14T14:01:18.602857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['anatom_site_general_challenge'].value_counts(normalize=True).sort_values().iplot(kind='barh',\n                                                      xTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='#FB8072',\n                                                      theme='pearl',\n                                                      bargap=0.2,\n                                                      gridcolor='white',\n                                                      title='Anatomical Site Distribution')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.604949Z","iopub.execute_input":"2021-06-14T14:01:18.605229Z","iopub.status.idle":"2021-06-14T14:01:18.670288Z","shell.execute_reply.started":"2021-06-14T14:01:18.6052Z","shell.execute_reply":"2021-06-14T14:01:18.669262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Age distribution of patients","metadata":{}},{"cell_type":"code","source":"train['age_approx'].iplot(kind='hist',bins=30,color='orange',xTitle='Age distribution',yTitle='Count')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:18.671637Z","iopub.execute_input":"2021-06-14T14:01:18.67195Z","iopub.status.idle":"2021-06-14T14:01:19.116575Z","shell.execute_reply.started":"2021-06-14T14:01:18.671916Z","shell.execute_reply":"2021-06-14T14:01:19.115252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Diagnosis Distribution","metadata":{}},{"cell_type":"code","source":"train['diagnosis'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:19.11818Z","iopub.execute_input":"2021-06-14T14:01:19.118578Z","iopub.status.idle":"2021-06-14T14:01:19.131577Z","shell.execute_reply.started":"2021-06-14T14:01:19.118537Z","shell.execute_reply":"2021-06-14T14:01:19.130633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['diagnosis'].value_counts(normalize=True).sort_values().iplot(kind='barh',\n                                                      xTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='blue',\n                                                      theme='pearl',\n                                                      bargap=0.2,\n                                                      gridcolor='white',\n                                                      title='Diagnosis Distribution')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:19.133133Z","iopub.execute_input":"2021-06-14T14:01:19.133648Z","iopub.status.idle":"2021-06-14T14:01:19.198166Z","shell.execute_reply.started":"2021-06-14T14:01:19.133605Z","shell.execute_reply":"2021-06-14T14:01:19.197156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualizing images","metadata":{}},{"cell_type":"code","source":"# Function for plotting samples\ndef plot_samples(samples):  \n    fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(32,16))\n    for i in range(len(samples)):\n        image = imread(samples[i])\n        ax = axes[i//5][i%5]\n        ax.imshow(image)\n        if i<10: # first 10 files\n            ax.set_title(\"Benign\", fontsize=20)\n        else:\n            ax.set_title(\"Malignant\", fontsize=20)\n        ax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:19.199461Z","iopub.execute_input":"2021-06-14T14:01:19.199782Z","iopub.status.idle":"2021-06-14T14:01:19.205967Z","shell.execute_reply.started":"2021-06-14T14:01:19.199729Z","shell.execute_reply":"2021-06-14T14:01:19.205034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample images\n\ndirname = '/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\nsample_img = []\n\n# get 10 benign image files \nbenign_ = train[train['benign_malignant'] == 'benign']['image_name'][:10]\n\n# get 10 malignant image files \nmalignant_ = train[train['benign_malignant'] == 'malignant']['image_name'][:10]\n\n# get benign filepaths\nfor i in benign_:\n    sample_img.append(dirname + i + '.jpg')\n\n# get malignant filepaths \nfor j in malignant_:\n    sample_img.append(dirname + j + '.jpg')\n\nplot_samples(sample_img)\nplt.suptitle('Melanoma Samples', fontsize=30)\n# plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:19.207073Z","iopub.execute_input":"2021-06-14T14:01:19.207317Z","iopub.status.idle":"2021-06-14T14:01:50.786839Z","shell.execute_reply.started":"2021-06-14T14:01:19.207292Z","shell.execute_reply":"2021-06-14T14:01:50.785446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Preparation and Augmentation","metadata":{}},{"cell_type":"markdown","source":"#### Connect to TPU","metadata":{}},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. \n    # On Kaggle this is always the case.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy() \n\nREPLICAS = strategy.num_replicas_in_sync\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:50.788082Z","iopub.execute_input":"2021-06-14T14:01:50.788344Z","iopub.status.idle":"2021-06-14T14:01:58.376181Z","shell.execute_reply.started":"2021-06-14T14:01:50.788317Z","shell.execute_reply":"2021-06-14T14:01:58.374955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Set parameters","metadata":{}},{"cell_type":"code","source":"SEED = 42\nFOLDS = 3\nEFF_NETS = 6 \nBATCH_SIZES = [bs * strategy.num_replicas_in_sync for bs in [32]*FOLDS] \nIMG_SIZES = [512]*FOLDS\nEPOCHS = 10 \nLR = 0.00004\nLABEL_SMOOTHING = 0.05\nTTA = 15 # test time augmentation","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:58.377916Z","iopub.execute_input":"2021-06-14T14:01:58.378459Z","iopub.status.idle":"2021-06-14T14:01:58.385578Z","shell.execute_reply.started":"2021-06-14T14:01:58.378401Z","shell.execute_reply":"2021-06-14T14:01:58.383881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seed to make sure the same random numbers are generated on multiple executions\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:58.390339Z","iopub.execute_input":"2021-06-14T14:01:58.390832Z","iopub.status.idle":"2021-06-14T14:01:58.400647Z","shell.execute_reply.started":"2021-06-14T14:01:58.390765Z","shell.execute_reply":"2021-06-14T14:01:58.399105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Get Dataset","metadata":{}},{"cell_type":"code","source":"# Get file paths for train, validation and test\n\nGCS_PATH = KaggleDatasets().get_gcs_path('512x512-melanoma-tfrecords-70k-images')\nGCS_PATH2 = KaggleDatasets().get_gcs_path('isic2019-512x512')\n\ntrain_filenames = tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\ntest_filenames = tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')\n\nprint(\"# TRAINING_FILENAMES\", len(train_filenames))\nprint(\"# TEST_FILENAMES\", len(test_filenames))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:58.402655Z","iopub.execute_input":"2021-06-14T14:01:58.403082Z","iopub.status.idle":"2021-06-14T14:01:59.166728Z","shell.execute_reply.started":"2021-06-14T14:01:58.403036Z","shell.execute_reply":"2021-06-14T14:01:59.165898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OLD_COMP_FILENAMES = tf.io.gfile.glob(GCS_PATH2 + '/*.tfrec')\nprint(\"# OLD_COMP_FILENAMES\", len(OLD_COMP_FILENAMES))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:59.167875Z","iopub.execute_input":"2021-06-14T14:01:59.168353Z","iopub.status.idle":"2021-06-14T14:01:59.257021Z","shell.execute_reply.started":"2021-06-14T14:01:59.168321Z","shell.execute_reply":"2021-06-14T14:01:59.256307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Image loading functions\nWe create some functions for loading TFRecords to get the images, target and image names\n\n* **decode_image**: to transform images to a tensor, normalize it, and reshape it into the correct shape for TPU\n* **read_tfrecord**: read the TFRecord, returns the image tensor, and based on the input arguments, return the label value, image name, or nothing (0)\n* **load_dataset**: reads data from the TFRecords. Here we can choose whether to shuffle the data or not. We will do that for the train, but not the validation and test dataset.\n* **count_data_items**: counts the number of images in a file\n* **data_augment**: performs data augmentation; techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data\n* **plot_transform**: plots some examples of augmented images","metadata":{}},{"cell_type":"code","source":"ROT_ = 180.0\nSHR_ = 2.0\nHZOOM_ = 8.0\nWZOOM_ = 8.0\nHSHIFT_ = 8.0\nWSHIFT_ = 8.0\n\ndef get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    shear    = math.pi * shear    / 180.\n\n    def get_3x3_mat(lst):\n        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n    \n    # ROTATION MATRIX\n    c1   = tf.math.cos(rotation)\n    s1   = tf.math.sin(rotation)\n    one  = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    \n    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n                                   -s1,  c1,   zero, \n                                   zero, zero, one])    \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)    \n    \n    shear_matrix = get_3x3_mat([one,  s2,   zero, \n                                zero, c2,   zero, \n                                zero, zero, one])        \n    # ZOOM MATRIX\n    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n                               zero,            one/width_zoom, zero, \n                               zero,            zero,           one])    \n    # SHIFT MATRIX\n    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n                                zero, one,  width_shift, \n                                zero, zero, one])\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), \n                 K.dot(zoom_matrix,     shift_matrix))\n\n\ndef transform(image, DIM=512):    \n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = ROT_ * tf.random.normal([1], dtype='float32')\n    shr = SHR_ * tf.random.normal([1], dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32') \n\n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n    z   = tf.ones([DIM*DIM], dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n    idx2 = K.cast(idx2, dtype='int32')\n    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n    d    = tf.gather_nd(image, tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM, DIM,3])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:59.257984Z","iopub.execute_input":"2021-06-14T14:01:59.25834Z","iopub.status.idle":"2021-06-14T14:01:59.273042Z","shell.execute_reply.started":"2021-06-14T14:01:59.258312Z","shell.execute_reply":"2021-06-14T14:01:59.271964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_image(image):\n    # decode a JPEG-encoded image to a uint8 tensor\n    image = tf.image.decode_jpeg(image, channels=3) \n    # cast tensor to float32 and normalize to [0, 1] range\n    image = tf.cast(image, tf.float32)/255.0 \n    # explicit size needed for TPU\n    image = tf.reshape(image, [*IMG_SIZES[0:2], 3]) \n    return image\n\ndef read_tfrecord(example, labeled, return_imgname=False):\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n    } if labeled else {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    # returns a dataset of (image, label) pairs if labeled=True\n    if labeled:\n        label = tf.cast(example['target'], tf.int32)\n        return image, label\n    idnum = example['image_name']\n    # returns a dataset of (image, image_name) pairs if return_imgname=True\n    if return_imgname:\n        return image, idnum\n    # else returns a dataset of (image, 0) pairs \n    return image, 0\n\ndef load_dataset(filenames, labeled=True, ordered=False, return_imgname=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    # automatically interleaves reads from multiple files\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n    # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.with_options(ignore_order) \n    dataset = dataset.map(partial(read_tfrecord, labeled=labeled, \n                                  return_imgname=return_imgname), num_parallel_calls=AUTO)\n    , or (image, id) pairs if labeled=False\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\ndef data_augment(image, label=None, seed=SEED):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement when \n    # loading dataset (below cell), this happens essentially for free on TPU. Data pipeline\n    # code is executed on the \"CPU\" part of the TPU while the TPU itself is \n    # computing gradients.\n    image = transform(image, IMG_SIZES[0])\n    #image = tf.image.rot90(image,k=np.random.randint(4)) # rotate\n    image = tf.image.random_flip_left_right(image, seed=seed) # flip horizontal\n    image = tf.image.random_flip_up_down(image, seed=seed) # flip vertical\n    image = tf.image.random_brightness(image, max_delta=0.2) # random brightness\n    image = tf.image.random_contrast(image, 0.8, 1.2) # random contrast\n    image = tf.image.random_saturation(image, 0.7, 1.3) # random saturation\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\n# plot augmented images sample\ndef plot_transform(num_images):\n    fig, ax = plt.subplots(nrows=3, ncols=num_images, figsize=(12,5))\n    x = (load_dataset(train_filenames, labeled=True)\n                     .shuffle(SEED)\n                     .batch(BATCH_SIZES[0],drop_remainder=True)                 \n                     .prefetch(AUTO)\n                     .unbatch().take(5))\n    images = []\n    imgs=[]\n    for r in range(3):\n        image,_ = iter(x).next()\n        images.append(image)\n        for i in range(0,num_images):\n            image = data_augment(image=images[r])\n            imgs.append(image)\n    for img in range(len(imgs)):          \n        ax[img//num_images][img%num_images].imshow(imgs[img])\n        ax[img//num_images][img%num_images].axis('off') ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:59.274282Z","iopub.execute_input":"2021-06-14T14:01:59.274533Z","iopub.status.idle":"2021-06-14T14:01:59.298235Z","shell.execute_reply.started":"2021-06-14T14:01:59.274507Z","shell.execute_reply":"2021-06-14T14:01:59.296889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for plotting images in grid\ndef show_dataset(thumb_size, cols, rows, ds):\n    mosaic = PIL.Image.new(mode='RGB', size=(thumb_size*cols + (cols-1), \n                                             thumb_size*rows + (rows-1)))\n   \n    for idx, data in enumerate(iter(ds)):\n        img, target_or_imgid = data\n        ix  = idx % cols\n        iy  = idx // cols\n        img = np.clip(img.numpy() * 255, 0, 255).astype(np.uint8)\n        img = PIL.Image.fromarray(img)\n        img = img.resize((thumb_size, thumb_size), resample=PIL.Image.BILINEAR)\n        mosaic.paste(img, (ix*thumb_size + ix, \n                           iy*thumb_size + iy))\n\n    display(mosaic)\n    \neg_ds = (load_dataset(train_filenames, labeled=True)\n                     .batch(BATCH_SIZES[0],drop_remainder=True)                 \n                     .prefetch(AUTO)\n                     .unbatch().take(10*6))  \n\nshow_dataset(64, 10, 6, eg_ds) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:01:59.299613Z","iopub.execute_input":"2021-06-14T14:01:59.299928Z","iopub.status.idle":"2021-06-14T14:02:01.469194Z","shell.execute_reply.started":"2021-06-14T14:01:59.299896Z","shell.execute_reply":"2021-06-14T14:02:01.466302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image augmentation examples. ","metadata":{}},{"cell_type":"code","source":"plot_transform(7) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:02:01.470977Z","iopub.execute_input":"2021-06-14T14:02:01.471482Z","iopub.status.idle":"2021-06-14T14:02:05.716081Z","shell.execute_reply.started":"2021-06-14T14:02:01.471431Z","shell.execute_reply":"2021-06-14T14:02:05.715046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of Train Files\", count_data_items(train_filenames))\nprint(\"Number of Test Files\", count_data_items(test_filenames)) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:02:05.717333Z","iopub.execute_input":"2021-06-14T14:02:05.717615Z","iopub.status.idle":"2021-06-14T14:02:05.723836Z","shell.execute_reply.started":"2021-06-14T14:02:05.717585Z","shell.execute_reply":"2021-06-14T14:02:05.72271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Transfer Learning EffNet (CNN)","metadata":{}},{"cell_type":"markdown","source":"#### Learning Rate Train Schedule\nThis is a common train schedule for transfer learning. The learning rate starts near zero, then increases to a maximum, then decays over time. ","metadata":{}},{"cell_type":"code","source":"def lrfn(epoch):\n    if epoch < lr_ramp_ep:\n        lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n\n    elif epoch < lr_ramp_ep + lr_sus_ep:\n        lr = lr_max\n\n    else:\n        lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n\n    return lr\n\ndef get_lr_callback(batch_size=8):\n    lr_start   = 0.000005\n    lr_max     = 0.000003 * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.3\n       \n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:02:05.725223Z","iopub.execute_input":"2021-06-14T14:02:05.725493Z","iopub.status.idle":"2021-06-14T14:02:05.738198Z","shell.execute_reply.started":"2021-06-14T14:02:05.725464Z","shell.execute_reply":"2021-06-14T14:02:05.736996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_start   = 0.000005\nlr_max     = 0.000003 * BATCH_SIZES[0]\nlr_min     = 0.000001\nlr_ramp_ep = 5\nlr_sus_ep  = 0\nlr_decay   = 0.3","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:02:05.739519Z","iopub.execute_input":"2021-06-14T14:02:05.739813Z","iopub.status.idle":"2021-06-14T14:02:05.752231Z","shell.execute_reply.started":"2021-06-14T14:02:05.739783Z","shell.execute_reply":"2021-06-14T14:02:05.751086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_training_curves(history, name, model_name):\n    '''\n    Plots the training process\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, figsize=(20,15))\n    fig.suptitle(model_name, size=20)\n    \n    # plot AUC\n    ax1.plot(np.arange(EPOCHS),history.history['auc'],'-o',\n             label='Train AUC',color='#ff7f0e')\n    ax1.plot(np.arange(EPOCHS),history.history['val_auc'],'-o',\n             label='Val AUC',color='#1f77b4')\n    x = np.argmax(history.history['val_auc']); y = np.max(history.history['val_auc'])\n    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n    ax1.scatter(x,y,s=200,color='#1f77b4')\n    ax1.text(x-0.03*xdist,y-0.05*ydist,'max auc\\n%.2f'%y,size=14)\n    ax1.set_ylabel('AUC',size=14); ax1.set_xlabel('Epoch',size=14)\n    ax1.set_title('AUC curve')\n    ax1.set_xticks(list(range(EPOCHS)))\n    ax1.set_xticklabels(list(range(1, EPOCHS+1)))\n    ax1.legend(loc=2)\n\n    #  plot loss\n    ax2.plot(np.arange(EPOCHS),history.history['loss'],'-o',\n              label='Train Loss',color='#2ca02c')\n    ax2.plot(np.arange(EPOCHS),history.history['val_loss'],'-o',\n              label='Val Loss',color='#d62728')\n    x = np.argmin(history.history['val_loss'] )\n    y = np.min(history.history['val_loss'] )\n    ydist = plt.ylim()[1] - plt.ylim()[0]\n    ax2.scatter(x,y,s=200,color='#d62728')\n    ax2.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n    ax2.set_ylabel('Loss',size=14); ax2.set_xlabel('Epoch',size=14)\n    ax2.set_title('Loss Curve')\n    ax2.set_xticks(list(range(EPOCHS)))\n    ax2.set_xticklabels(list(range(1, EPOCHS+1)))\n    ax2.legend(loc=3)\n    fig.savefig(name + '.png')\n    plt.show() \n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:16:06.980285Z","iopub.execute_input":"2021-06-14T15:16:06.980633Z","iopub.status.idle":"2021-06-14T15:16:06.993006Z","shell.execute_reply.started":"2021-06-14T15:16:06.980603Z","shell.execute_reply":"2021-06-14T15:16:06.991881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Get and load train, validation and test dataset","metadata":{}},{"cell_type":"markdown","source":"Split files to get train and validation filenames","metadata":{}},{"cell_type":"code","source":"files_train, files_valid = train_test_split(\n    train_filenames, test_size = 0.20, random_state = SEED)\n\n# add old comp data to valid set\nfiles_train += tf.io.gfile.glob(GCS_PATH2[0] + '/train*.tfrec')\n# shuffle training set\nnp.random.shuffle(files_train) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:02:05.769683Z","iopub.execute_input":"2021-06-14T14:02:05.770037Z","iopub.status.idle":"2021-06-14T14:02:05.789121Z","shell.execute_reply.started":"2021-06-14T14:02:05.770002Z","shell.execute_reply":"2021-06-14T14:02:05.787926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"# TRAINING_FILENAMES\", len(files_train))\nprint(\"# VALIDATION_FILENAMES\", len(files_valid))\n\nprint(\"# Train Files after Splitting\", count_data_items(files_train))\nprint(\"# Validation Files\", count_data_items(files_valid))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:02:05.790659Z","iopub.execute_input":"2021-06-14T14:02:05.790963Z","iopub.status.idle":"2021-06-14T14:02:05.807126Z","shell.execute_reply.started":"2021-06-14T14:02:05.790932Z","shell.execute_reply":"2021-06-14T14:02:05.805666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get test set filenames","metadata":{}},{"cell_type":"code","source":"files_test = np.sort(\n    np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec'))) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:02:05.808684Z","iopub.execute_input":"2021-06-14T14:02:05.809274Z","iopub.status.idle":"2021-06-14T14:02:05.886151Z","shell.execute_reply.started":"2021-06-14T14:02:05.809221Z","shell.execute_reply":"2021-06-14T14:02:05.885051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load train, validation and test dataset","metadata":{}},{"cell_type":"code","source":"train_dataset = (load_dataset(files_train, labeled=True)\n                     .repeat() # repeat to continue getting data for aug\n                     .map(data_augment, num_parallel_calls=AUTO) # data augmentation\n                     .shuffle(SEED)\n                     .batch(BATCH_SIZES[0],drop_remainder=True)\n                     # prefetch next batch while training (autotune prefetch buffer size)\n                     .prefetch(AUTO)) \n\nds_valid = (load_dataset(files_valid, labeled=True, ordered=True)                                        \n                     .cache()     \n                     .repeat()   # repeat for data aug during val\n                     .map(data_augment, num_parallel_calls=AUTO)  # data augmentation \n                     .batch(BATCH_SIZES[0]*4)  # X4 to speed up training\n                     .prefetch(AUTO))\n\nds_test = (load_dataset(files_test, labeled=False, ordered=True) # do not shuffle\n                     .repeat()                                   # repeat for TTA\n                     .map(data_augment, num_parallel_calls=AUTO) # data augmentation \n                     .batch(BATCH_SIZES[0]*4)\n                     .prefetch(AUTO))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:02:05.887831Z","iopub.execute_input":"2021-06-14T14:02:05.88826Z","iopub.status.idle":"2021-06-14T14:02:06.662206Z","shell.execute_reply.started":"2021-06-14T14:02:05.888219Z","shell.execute_reply":"2021-06-14T14:02:06.661314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train and Evaluate model","metadata":{}},{"cell_type":"code","source":"# initialize storage\npred_ = []; tar_ = []; val_ = []; names_ = []\n# initialize for prediction storage\npreds = np.zeros((count_data_items(test_filenames),1))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:02:39.317248Z","iopub.execute_input":"2021-06-14T14:02:39.317634Z","iopub.status.idle":"2021-06-14T14:02:39.321864Z","shell.execute_reply.started":"2021-06-14T14:02:39.317602Z","shell.execute_reply":"2021-06-14T14:02:39.321102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    \n# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\nVERBOSE = 2\n\nif tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    \nK.clear_session()\nwith strategy.scope():\n    model = tf.keras.Sequential([\n        efn.EfficientNetB6(input_shape=(IMG_SIZES[0],IMG_SIZES[0], 3),\n                           weights='imagenet',include_top=False),\n        GlobalAveragePooling2D(),\n        # add fully connected layer, with sigmoid activation since only 2 categories\n        Dense(1, activation='sigmoid') \n    ])\n    \n    model.compile(\n        optimizer='adam',\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing = LABEL_SMOOTHING),\n        metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n                 tf.keras.metrics.AUC(name='auc')])\n    print(model.summary())\n\n# for saving best model from the best epoch \nsv = tf.keras.callbacks.ModelCheckpoint(\n        'cnn_best.h5', monitor='val_loss', verbose=0, save_best_only=True,\n        save_weights_only=True, mode='min', save_freq='epoch')\n\nprint('#'*25)\nprint('#### Image Size %i with EfficientNet B%i and batch_size %i'%\n      (IMG_SIZES[0],EFF_NETS,BATCH_SIZES[0]))\n\n# TRAIN\nprint('Training...')         \nhistory = model.fit(\n    train_dataset, \n    epochs=EPOCHS, \n    callbacks=[sv,get_lr_callback(BATCH_SIZES[0])],     # lr schedule\n    steps_per_epoch=count_data_items(files_train) // BATCH_SIZES[0],\n    validation_data=load_dataset(files_valid, labeled=True)                                        \n                     .cache()\n                     .batch(BATCH_SIZES[0])\n                     .prefetch(AUTO),                         \n    verbose=VERBOSE) \n\n# LOAD BEST MODEL\nprint('Loading best model...')\nmodel.load_weights('cnn_best.h5')    ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:03:56.010924Z","iopub.execute_input":"2021-06-14T14:03:56.011332Z","iopub.status.idle":"2021-06-14T14:49:57.927906Z","shell.execute_reply.started":"2021-06-14T14:03:56.011296Z","shell.execute_reply":"2021-06-14T14:49:57.926874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict on Validation and test set using test time augmentation","metadata":{}},{"cell_type":"code","source":"print('Predicting Valid with TTA...')\n\nct_valid = count_data_items(files_valid)\nSTEPS = TTA * ct_valid/BATCH_SIZES[0]/4  # number of steps to go through all TTA images\n# slice to throw away images that pass the steps\npred = model.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n# store the average of each valid image \npred_.append(np.mean(pred.reshape((ct_valid,TTA),order='F'),axis=1)) \n\n# GET OOF TARGETS, FOLDS, AND NAMES\n# get targets \n# do not repeat=True here as we only want the target values \nds_valid = (load_dataset(files_valid, labeled=True, ordered=True) # do not shuffle\n                    .cache()\n                    .batch(BATCH_SIZES[0]*4)\n                    .prefetch(AUTO))\ntar_.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) ) \n# get names\nds = (load_dataset(files_valid, labeled=False, return_imgname=True, ordered=True)                                        \n            .cache()     \n            .batch(BATCH_SIZES[0]*4)                   \n            .prefetch(AUTO)) \nnames_.append(np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(\n    ds.unbatch())]))      \n\n# PREDICT TEST USING TTA\nprint('Predicting Test with TTA...')\nct_test = count_data_items(files_test)\nSTEPS = TTA * ct_test/BATCH_SIZES[0]/4 # number of steps to go through all TTA images\n# slice to throw away images that pass the steps\npred = model.predict(ds_test,steps=STEPS,verbose=VERBOSE)[:TTA*ct_test,] \n# store the average pred of each test image\npreds[:,0] += np.mean(pred.reshape((ct_test,TTA),order='F'),axis=1)\n\n# REPORT RESULTS\nauc_ = roc_auc_score(tar_[-1],pred_[-1])\nval_.append(np.max(history.history['val_auc']))\nprint('#### AUC without TTA = %.3f, with TTA = %.3f'%(val_[-1],auc_)) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T14:50:56.764091Z","iopub.execute_input":"2021-06-14T14:50:56.764488Z","iopub.status.idle":"2021-06-14T15:04:50.793167Z","shell.execute_reply.started":"2021-06-14T14:50:56.764454Z","shell.execute_reply":"2021-06-14T15:04:50.792053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot train history curve","metadata":{}},{"cell_type":"code","source":"display_training_curves(history, 'effnet_train', 'EfficientNet B6 Training Curve') ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:16:21.368347Z","iopub.execute_input":"2021-06-14T15:16:21.368713Z","iopub.status.idle":"2021-06-14T15:16:22.036799Z","shell.execute_reply.started":"2021-06-14T15:16:21.368676Z","shell.execute_reply":"2021-06-14T15:16:22.03604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAVE TO DISK\ndf = pd.DataFrame(dict(\n    image_name = names_[-1], target=tar_[-1], pred = pred_[-1]))\ndf.to_csv('effnet.csv',index=False) \ndf.head() ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:05:46.377501Z","iopub.execute_input":"2021-06-14T15:05:46.378081Z","iopub.status.idle":"2021-06-14T15:05:46.423643Z","shell.execute_reply.started":"2021-06-14T15:05:46.37803Z","shell.execute_reply":"2021-06-14T15:05:46.422554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ROC and PR curves","metadata":{}},{"cell_type":"code","source":"# AUROC\nfpr, tpr, _ = roc_curve(df.target, df.pred)\nroc_auc = auc(fpr, tpr)\n\n# AUPRC\nprecision, recall, thresholds = precision_recall_curve(df.target, df.pred)\naverage_precision = average_precision_score(df.target, df.pred)\n\n# PLOT\n# auroc\nfig = plt.figure(figsize=(18,6))\nax1 = fig.add_subplot(121)\n\nfig.suptitle('ROC and PRC Curves for EfficientNet B6', size=25)\n\nax1.plot([0, 1], [0, 1], linestyle='--', lw=4, color='r',\n        label='Chance', alpha=.8)\n\nax1.plot(fpr, tpr, color='b',\n        label=r'ROC (AUC = %0.2f)' % (roc_auc),\n        lw=4, alpha=.8)    \n    \nax1.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\nax1.set_title(\"Receiver Operating Characteristic Curve\", size=20)\nax1.set_xlabel('False Positive Rate',size=20); plt.xticks(size=15)\nax1.set_ylabel('True Positive Rate',size=20); plt.yticks(size=15)\nax1.legend(loc=\"lower right\",prop={\"size\":15})\n\n# auprc\nax2 = fig.add_subplot(122)\nax2.step(recall, precision, where='post', color='b',\n        label=r'AP (AP = %0.2f)' % (average_precision),\n        lw=4, alpha=.8)    \n    \nax2.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\nax2.set_title(\"Precision Recall Curve\", size=20)\nax2.set_xlabel('Recall',size=20); plt.xticks(size=15)\nax2.set_ylabel('Precision',size=20); plt.yticks(size=15)\nax2.legend(loc=\"lower left\",prop={\"size\":15})\nplt.savefig('effnet_roc.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:06:23.320852Z","iopub.execute_input":"2021-06-14T15:06:23.321398Z","iopub.status.idle":"2021-06-14T15:06:23.88361Z","shell.execute_reply.started":"2021-06-14T15:06:23.321349Z","shell.execute_reply":"2021-06-14T15:06:23.88261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper function to calculate the F1 Score\ndef calc_f1(prec, recall):\n    return 2*(prec*recall)/(prec+recall) if recall and prec else 0","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:07:47.096188Z","iopub.execute_input":"2021-06-14T15:07:47.096596Z","iopub.status.idle":"2021-06-14T15:07:47.1016Z","shell.execute_reply.started":"2021-06-14T15:07:47.096553Z","shell.execute_reply":"2021-06-14T15:07:47.100498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the f1 score for each threshold\nf1score = [calc_f1(precision[i], recall[i]) for i in range(len(thresholds))]\n\n# Get the highest f1score\nidx = np.argmax(f1score)\n\n# Get the highest precision, recall, threshold and f1score\nprecision = round(precision[idx], 4)\nrecall = round(recall[idx], 4)\nthreshold = round(thresholds[idx], 4)\nf1score = round(f1score[idx], 4)\n\nprint('Precision:', precision)\nprint('Recall:', recall)\nprint('Threshold:', threshold)\nprint('F1 Score:', f1score)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:07:53.398967Z","iopub.execute_input":"2021-06-14T15:07:53.399349Z","iopub.status.idle":"2021-06-14T15:07:53.42129Z","shell.execute_reply.started":"2021-06-14T15:07:53.399303Z","shell.execute_reply":"2021-06-14T15:07:53.420399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot a confusion matrix\nbinary_preds = [0 if x < threshold else 1 for x in df.pred]\ncm = confusion_matrix(df.target, binary_preds)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted label', size=10)\nplt.ylabel('True label', size=10)\nplt.title('EfficientNet B6 Confusion Matrix', size=15)\nplt.savefig('effnet_cm.png')\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:08:14.079649Z","iopub.execute_input":"2021-06-14T15:08:14.080252Z","iopub.status.idle":"2021-06-14T15:08:14.408659Z","shell.execute_reply.started":"2021-06-14T15:08:14.080196Z","shell.execute_reply":"2021-06-14T15:08:14.407925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Predict for an image","metadata":{}},{"cell_type":"code","source":"IMAGE_PATH = \"../input/siim-isic-melanoma-classification/jpeg/test/ISIC_0052060.jpg\"\nimg = tf.keras.preprocessing.image.load_img(IMAGE_PATH, \n                                            target_size=(IMG_SIZES[0], IMG_SIZES[0]))\nplt.imshow(img)\norigin_img = img","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:09:11.066674Z","iopub.execute_input":"2021-06-14T15:09:11.067444Z","iopub.status.idle":"2021-06-14T15:09:11.592819Z","shell.execute_reply.started":"2021-06-14T15:09:11.067382Z","shell.execute_reply":"2021-06-14T15:09:11.591587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the prediction for the image\nprediction = model.predict(np.expand_dims(img, axis=0))\nbinary_prediction = [0 if x < 0.5 else 1 for x in prediction]\nprint(\"Prediction: \" + (\"Benign\" if binary_prediction == 0 else \"Malignant\")) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:09:22.975756Z","iopub.execute_input":"2021-06-14T15:09:22.976293Z","iopub.status.idle":"2021-06-14T15:09:38.100197Z","shell.execute_reply.started":"2021-06-14T15:09:22.976245Z","shell.execute_reply":"2021-06-14T15:09:38.099113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. EffNet + BiLSTM (Hybrid)","metadata":{}},{"cell_type":"code","source":"def ReshapeLayer(x):\n    '''\n    Reshape CNN output\n    '''\n    shape = x.shape \n    # H,W * channel\n    reshape = Reshape((shape[1],1))(x)\n\n    return reshape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:18:38.468519Z","iopub.execute_input":"2021-06-14T15:18:38.468973Z","iopub.status.idle":"2021-06-14T15:18:38.475427Z","shell.execute_reply.started":"2021-06-14T15:18:38.468935Z","shell.execute_reply":"2021-06-14T15:18:38.473987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = (load_dataset(files_train, labeled=True)\n                     .repeat() # repeat to continue getting data for aug\n                     .map(data_augment, num_parallel_calls=AUTO) # data augmentation\n                     .shuffle(SEED)\n                     .batch(BATCH_SIZES[0],drop_remainder=True)\n                     # prefetch next batch while training (autotune prefetch buffer size)\n                     .prefetch(AUTO)) \n\nds_valid = (load_dataset(files_valid, labeled=True, ordered=True)                                        \n                     .cache()     \n                     .repeat()   # repeat for data aug during val\n                     .map(data_augment, num_parallel_calls=AUTO)  # data augmentation \n                     .batch(BATCH_SIZES[0]*4)  # X4 to speed up training\n                     .prefetch(AUTO))\n\nds_test = (load_dataset(files_test, labeled=False, ordered=True) # do not shuffle\n                     .repeat()                                   # repeat for TTA\n                     .map(data_augment, num_parallel_calls=AUTO) # data augmentation \n                     .batch(BATCH_SIZES[0]*4)\n                     .prefetch(AUTO))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:20:36.727184Z","iopub.execute_input":"2021-06-14T15:20:36.728438Z","iopub.status.idle":"2021-06-14T15:20:38.873136Z","shell.execute_reply.started":"2021-06-14T15:20:36.728367Z","shell.execute_reply":"2021-06-14T15:20:38.871739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Build, Train and Evaluate model  ","metadata":{}},{"cell_type":"code","source":"# initialize storage\npred_ = []; tar_ = []; val_ = []; names_ = []\n# initialize for prediction storage\npreds = np.zeros((count_data_items(test_filenames),1))  ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:20:45.909914Z","iopub.execute_input":"2021-06-14T15:20:45.910455Z","iopub.status.idle":"2021-06-14T15:20:45.918543Z","shell.execute_reply.started":"2021-06-14T15:20:45.910395Z","shell.execute_reply":"2021-06-14T15:20:45.916927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\nVERBOSE = 2\n\nif tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    \nK.clear_session()\nwith strategy.scope():\n    model = tf.keras.Sequential([\n        efn.EfficientNetB6(input_shape=(IMG_SIZES[0],IMG_SIZES[0], 3),\n                           weights='imagenet',include_top=False),\n        GlobalAveragePooling2D(),\n        # reshape layer\n        Lambda(ReshapeLayer),\n        # add BiLSTM layer\n        Bidirectional(LSTM(150, return_sequences=True, dropout=0.3)),\n        Bidirectional(LSTM(96, dropout=0.3)),\n        # dense layer\n        # Dense(8, activation='relu'),\n        # add fully connected layer, with sigmoid activation since only 2 categories\n        Dense(1, activation='sigmoid') \n    ])\n    \n    model.compile(\n        optimizer='adam',\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing = LABEL_SMOOTHING),\n        metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n                 tf.keras.metrics.AUC(name='auc')])\n    print(model.summary())\n\n# for saving best model from the best epoch \nsv = tf.keras.callbacks.ModelCheckpoint(\n        'bi_best.h5', monitor='val_loss', verbose=0, save_best_only=True,\n        save_weights_only=True, mode='min', save_freq='epoch')\n\nprint('#'*25)\nprint('#### Image Size %i with EfficientNet B%i + BiLSTM and batch_size %i'%\n      (IMG_SIZES[0],EFF_NETS,BATCH_SIZES[0]))\n\n# TRAIN\nprint('Training...')         \nhistory = model.fit(\n    train_dataset, \n    epochs=EPOCHS, \n    callbacks=[sv,get_lr_callback(BATCH_SIZES[0])],     # lr schedule\n    steps_per_epoch=count_data_items(files_train) // BATCH_SIZES[0],\n    validation_data=load_dataset(files_valid, labeled=True)                                        \n                     .cache()\n                     .batch(BATCH_SIZES[0])\n                     .prefetch(AUTO),                         \n    verbose=VERBOSE) \n\n# LOAD BEST MODEL\nprint('Loading best model...')\nmodel.load_weights('bi_best.h5') ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:50:46.189692Z","iopub.execute_input":"2021-06-14T15:50:46.190219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict valid and test dataset using test time augmentation (TTA). ","metadata":{}},{"cell_type":"code","source":"print('Predicting Valid with TTA...')\n\nct_valid = count_data_items(files_valid)\nSTEPS = TTA * ct_valid/BATCH_SIZES[0]/4  # number of steps to go through all TTA images\n# slice to throw away images that pass the steps\npred = model.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n# store the average of each valid image \npred_.append(np.mean(pred.reshape((ct_valid,TTA),order='F'),axis=1)) \n\n# GET OOF TARGETS, FOLDS, AND NAMES\n# get targets \n# do not repeat=True here as we only want the target values \nds_valid = (load_dataset(files_valid, labeled=True, ordered=True) # do not shuffle\n                    .cache()\n                    .batch(BATCH_SIZES[0]*4)\n                    .prefetch(AUTO))\ntar_.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) ) \n# get names\nds = (load_dataset(files_valid, labeled=False, return_imgname=True, ordered=True)                                        \n            .cache()     \n            .batch(BATCH_SIZES[0]*4)                   \n            .prefetch(AUTO)) \nnames_.append(np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(\n    ds.unbatch())]))      \n\n# PREDICT TEST USING TTA\nprint('Predicting Test with TTA...')\nct_test = count_data_items(files_test)\nSTEPS = TTA * ct_test/BATCH_SIZES[0]/4 # number of steps to go through all TTA images\n# slice to throw away images that pass the steps\npred = model.predict(ds_test,steps=STEPS,verbose=VERBOSE)[:TTA*ct_test,] \n# store the average pred of each test image\npreds[:,0] += np.mean(pred.reshape((ct_test,TTA),order='F'),axis=1)\n\n# REPORT RESULTS\nauc_ = roc_auc_score(tar_[-1],pred_[-1])\nval_.append(np.max(history.history['val_auc']))\nprint('#### AUC without TTA = %.3f, with TTA = %.3f'%(val_[-1],auc_)) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:19:26.48223Z","iopub.execute_input":"2021-06-14T12:19:26.482625Z","iopub.status.idle":"2021-06-14T12:25:02.131331Z","shell.execute_reply.started":"2021-06-14T12:19:26.482587Z","shell.execute_reply":"2021-06-14T12:25:02.130277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(history, 'bi_lstm_curve', 'EfficientNet B6 + BiLSTM Training Curve')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:25:58.748051Z","iopub.execute_input":"2021-06-14T12:25:58.748388Z","iopub.status.idle":"2021-06-14T12:25:59.47751Z","shell.execute_reply.started":"2021-06-14T12:25:58.748357Z","shell.execute_reply":"2021-06-14T12:25:59.476383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAVE TO DISK\ndf = pd.DataFrame(dict(\n    image_name = names_[-1], target=tar_[-1], pred = pred_[-1]))\ndf.to_csv('bilstm.csv',index=False) \ndf.head() ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:26:17.081166Z","iopub.execute_input":"2021-06-14T12:26:17.081638Z","iopub.status.idle":"2021-06-14T12:26:17.113106Z","shell.execute_reply.started":"2021-06-14T12:26:17.081603Z","shell.execute_reply":"2021-06-14T12:26:17.112212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ROC and PR Curves","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n\n# AUROC\nfpr, tpr, _ = roc_curve(df.target, df.pred)\nroc_auc = auc(fpr, tpr)\n\n# AUPRC\nprecision, recall, thresholds = precision_recall_curve(df.target, df.pred)\naverage_precision = average_precision_score(df.target, df.pred)\n\n# PLOT\n# auroc\nfig = plt.figure(figsize=(18,6))\nax1 = fig.add_subplot(121)\n\nfig.suptitle('ROC and PRC Curves for EfficientNet B6 + BiLSTM', size=25)\n\nax1.plot([0, 1], [0, 1], linestyle='--', lw=4, color='r',\n        label='Chance', alpha=.8)\n\nax1.plot(fpr, tpr, color='b',\n        label=r'ROC (AUC = %0.2f)' % (roc_auc),\n        lw=4, alpha=.8)    \n    \nax1.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\nax1.set_title(\"Receiver Operating Characteristic Curve\", size=20)\nax1.set_xlabel('False Positive Rate',size=20); plt.xticks(size=15)\nax1.set_ylabel('True Positive Rate',size=20); plt.yticks(size=15)\nax1.legend(loc=\"lower right\",prop={\"size\":15})\n\n# auprc\nax2 = fig.add_subplot(122)\nax2.step(recall, precision, where='post', color='b',\n        label=r'AP (AP = %0.2f)' % (average_precision),\n        lw=4, alpha=.8)    \n    \nax2.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\nax2.set_title(\"Precision Recall Curve\", size=20)\nax2.set_xlabel('Recall',size=20); plt.xticks(size=15)\nax2.set_ylabel('Precision',size=20); plt.yticks(size=15)\nax2.legend(loc=\"lower left\",prop={\"size\":15})\nplt.savefig('bilstm_roc.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:29:11.288911Z","iopub.execute_input":"2021-06-14T12:29:11.289499Z","iopub.status.idle":"2021-06-14T12:29:11.842072Z","shell.execute_reply.started":"2021-06-14T12:29:11.28946Z","shell.execute_reply":"2021-06-14T12:29:11.841194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper function to calculate the F1 Score\ndef calc_f1(prec, recall):\n    return 2*(prec*recall)/(prec+recall) if recall and prec else 0","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:29:31.488661Z","iopub.execute_input":"2021-06-14T12:29:31.48914Z","iopub.status.idle":"2021-06-14T12:29:31.493444Z","shell.execute_reply.started":"2021-06-14T12:29:31.489108Z","shell.execute_reply":"2021-06-14T12:29:31.492388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the f1 score for each threshold\nf1score = [calc_f1(precision[i], recall[i]) for i in range(len(thresholds))]\n\n# Get the highest f1score\nidx = np.argmax(f1score)\n\n# Get the highest precision, recall, threshold and f1score\nprecision = round(precision[idx], 4)\nrecall = round(recall[idx], 4)\nthreshold = round(thresholds[idx], 4)\nf1score = round(f1score[idx], 4)\n\nprint('Precision:', precision)\nprint('Recall:', recall)\nprint('Threshold:', threshold)\nprint('F1 Score:', f1score)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:29:41.155718Z","iopub.execute_input":"2021-06-14T12:29:41.156097Z","iopub.status.idle":"2021-06-14T12:29:41.170443Z","shell.execute_reply.started":"2021-06-14T12:29:41.156063Z","shell.execute_reply":"2021-06-14T12:29:41.169598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot a confusion matrix\nbinary_preds = [0 if x < threshold else 1 for x in df.pred]\ncm = confusion_matrix(df.target, binary_preds)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted label', size=10)\nplt.ylabel('True label', size=10)\nplt.title('EfficientNet B6 + BiLSTM Confusion Matrix', size=15)\nplt.savefig('bilstm_cm.png')\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T11:26:16.710042Z","iopub.execute_input":"2021-06-14T11:26:16.710469Z","iopub.status.idle":"2021-06-14T11:26:17.079411Z","shell.execute_reply.started":"2021-06-14T11:26:16.710429Z","shell.execute_reply":"2021-06-14T11:26:17.078082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Predict for an image","metadata":{}},{"cell_type":"code","source":"IMAGE_PATH = \"../input/siim-isic-melanoma-classification/jpeg/test/ISIC_0052060.jpg\"\nimg = tf.keras.preprocessing.image.load_img(IMAGE_PATH, \n                                            target_size=(IMG_SIZES[0], IMG_SIZES[0]))\nplt.imshow(img)\norigin_img = img ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T11:40:25.509901Z","iopub.execute_input":"2021-06-14T11:40:25.510261Z","iopub.status.idle":"2021-06-14T11:40:26.127633Z","shell.execute_reply.started":"2021-06-14T11:40:25.51023Z","shell.execute_reply":"2021-06-14T11:40:26.126588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the prediction for the image\nprediction = model.predict(np.expand_dims(img, axis=0))\nbinary_prediction = [0 if x < 0.5 else 1 for x in prediction]\nprint(\"Prediction: \" + (\"Benign\" if binary_prediction == 0 else \"Malignant\"))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T11:41:18.138087Z","iopub.execute_input":"2021-06-14T11:41:18.138592Z","iopub.status.idle":"2021-06-14T11:41:33.494405Z","shell.execute_reply.started":"2021-06-14T11:41:18.138555Z","shell.execute_reply":"2021-06-14T11:41:33.493746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}