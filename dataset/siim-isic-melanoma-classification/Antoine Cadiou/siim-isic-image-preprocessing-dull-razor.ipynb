{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Image preprocessing\n\n>>> Dataset TFRECORDS 256x256 with DULLRAZOR available here: [dataset](https://www.kaggle.com/antocad/melanoma-256x-dullrazor)\n\n* 1st step: remove hairs with Dull Razor filter (it works but need an improvement) ([ref](https://www.sciencedirect.com/science/article/abs/pii/S0010482597000206?via%3Dihub))\n* 2nd step: remove the noise with Median Filtering\n* 3rd step: Discovering filters, Applying Neuron Engineer's method    ([Notebook](https://www.kaggle.com/nxrprime/siim-d3-eda-augmentations-and-resnext))\n\n* Next step: Lesion segmentation","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os,cv2,re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"TFREC = '../input/melanoma-256x256'\n\nfiles_train = np.sort(np.array(tf.io.gfile.glob(TFREC + '/train*.tfrec')))\nfiles_test  = np.sort(np.array(tf.io.gfile.glob(TFREC + '/test*.tfrec')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ds = tf.data.TFRecordDataset(files_train).shuffle(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def read_tfrecord(example):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n        'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n    }           \n    example = tf.io.parse_single_example(example, tfrec_format)\n    return example['image'], example['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def image_decode(img):\n    img,label = read_tfrecord(img)\n    img = tf.image.decode_jpeg(img, channels=3)\n    return img,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def image_preprocessing(img):\n    \n    plt.imshow(img)\n    plt.show()\n    \n    #removing hairs\n    img = dullrazor(img)\n    #denoising\n    img = cv2.medianBlur(img, 3)\n    #filters\n    #CALL A FILTER METHOD HERE: BENGRAHAM for example\n \n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"def dullrazor(img, lowbound=15, showimgs=True, filterstruc=3, inpaintmat=3):\n    #grayscale\n    imgtmp1 = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n\n    #applying a blackhat\n    filterSize =(filterstruc, filterstruc)\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize) \n    imgtmp2 = cv2.morphologyEx(imgtmp1, cv2.MORPH_BLACKHAT, kernel)\n\n    #0=skin and 255=hair\n    ret, mask = cv2.threshold(imgtmp2, lowbound, 255, cv2.THRESH_BINARY)\n    \n    #inpainting\n    img_final = cv2.inpaint(img, mask, inpaintmat ,cv2.INPAINT_TELEA)\n    \n    if showimgs:\n        print(\"_____DULLRAZOR_____\")\n        plt.imshow(imgtmp1, cmap=\"gray\")\n        plt.show()\n        plt.imshow(imgtmp2, cmap='gray')\n        plt.show()\n        plt.imshow(mask, cmap='gray')\n        plt.show()\n        plt.imshow(img_final)\n        plt.show()\n        print(\"___________________\")\n\n    return img_final","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def view_images_bengraham(image):\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n        image = cv2.resize(image, (256, 256))\n        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 256/10) ,-4 ,128)\n        plt.imshow(image, cmap=plt.cm.bone)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def view_images_neuronengineer(image):\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (256, 256))\n        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 10) ,-4 ,128)\n        plt.imshow(image, cmap=plt.cm.bone)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n    \ndef circle_crop(img, sigmaX=10):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = crop_image_from_gray(img)    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n    return img \n\ndef view_images_crop(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (256, 256))\n    image= circle_crop(image)\n    plt.imshow(image, cmap=plt.cm.bone)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tmp = ds.take(1)\ntmp = tmp.map(lambda img: image_decode(img))\n\nfor img,label in tmp.as_numpy_iterator():\n    img = image_preprocessing(img)\n    view_images_bengraham(img)\n    view_images_neuronengineer(img)\n    view_images_crop(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (useless part)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def my_test(img):\n    def test_fn(img):\n        return image_preprocessing(img.numpy())\n    def call_test(img):\n        return tf.py_function(test_fn, [img], tf.uint8)\n    return call_test(img)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"ds = ds.map(lambda img: image_decode(img))\nds = ds.map(lambda img, label: (tf.py_function(my_test, [img], tf.uint8),label))","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}