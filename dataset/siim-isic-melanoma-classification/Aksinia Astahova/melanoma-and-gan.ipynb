{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GAN to assist in Melanoma Detection\n\n[melanoma competition](https://www.kaggle.com/c/siim-isic-melanoma-classification/data)\n","metadata":{}},{"cell_type":"code","source":"import glob\nimport os\nimport time\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nprint(tf.__version__)\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:13.171241Z","iopub.execute_input":"2022-05-01T15:54:13.171606Z","iopub.status.idle":"2022-05-01T15:54:17.764341Z","shell.execute_reply.started":"2022-05-01T15:54:13.171573Z","shell.execute_reply":"2022-05-01T15:54:17.763423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# asign some paths\ntrain_csv_path = '../input/siim-isic-melanoma-classification/train.csv'\ntest_csv_path = '../input/siim-isic-melanoma-classification/test.csv'\nimage_path = '../input/siim-isic-melanoma-classification/jpeg/train/'\n\n# read the csv data using pandas\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)\n\nprint(\"unique values in column 'target': {}\".format(list(train_df['target'].unique())))\ntarget_dis = list(train_df['target'].value_counts())\nbenign_per = target_dis[0]/sum(target_dis)\nprint(\"target count distribution: {}\".format(target_dis))\nprint(\"benign percentage: {:.2f}% vs malignant: {:.2f}%\".format(benign_per*100, (1-benign_per)*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:17.766088Z","iopub.execute_input":"2022-05-01T15:54:17.766467Z","iopub.status.idle":"2022-05-01T15:54:17.879014Z","shell.execute_reply.started":"2022-05-01T15:54:17.766429Z","shell.execute_reply":"2022-05-01T15:54:17.877777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect and initialize TPU (ignore if using GPU)\n# try:\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     print('Device:', tpu.master())\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     # set distribution strategy\n#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# except:\n#     strategy = tf.distribute.get_strategy()\n# print('Number of replicas:', strategy.num_replicas_in_sync)\n\n# # Use these params if using TPU\n# IMAGE_SIZE = [128, 128]  # used for reshaping\n# AUTOTUNE = tf.data.experimental.AUTOTUNE\n# GCS_PATH = KaggleDatasets().get_gcs_path('melanoma-128x128')  # store dataset to gcs buckets for the TPU to access in cloud\n# BATCH_SIZE = 16 * strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:17.880406Z","iopub.execute_input":"2022-05-01T15:54:17.880725Z","iopub.status.idle":"2022-05-01T15:54:17.885117Z","shell.execute_reply.started":"2022-05-01T15:54:17.88069Z","shell.execute_reply":"2022-05-01T15:54:17.884059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess Image","metadata":{}},{"cell_type":"code","source":"path_tfrec = '../input/melanoma-128x128/'\npath_jpg = '../input/jpeg-melanoma-128x128/train/'\nIMAGE_SIZE = [128, 128]\n\nmalignant = train_df[train_df[\"target\"] == 1]  # list of malignant images\n\ndef preprocess_X():  # load the images into memory\n    X = []\n    for img in malignant.image_name.values:\n        img_name = path_jpg + img + '.jpg'\n        i = tf.keras.preprocessing.image.load_img(img_name) #color_mode='grayscale')\n        i = tf.keras.preprocessing.image.img_to_array(i)\n        i = preprocess_input(i)  # preprocessing fits the pixel value from -127.5 to 127.5\n        X.append(i)\n    return np.array(X)  # convert to numpy array","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:17.886772Z","iopub.execute_input":"2022-05-01T15:54:17.887305Z","iopub.status.idle":"2022-05-01T15:54:17.913329Z","shell.execute_reply.started":"2022-05-01T15:54:17.887266Z","shell.execute_reply":"2022-05-01T15:54:17.912662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = preprocess_X()\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:17.9165Z","iopub.execute_input":"2022-05-01T15:54:17.916739Z","iopub.status.idle":"2022-05-01T15:54:23.786873Z","shell.execute_reply.started":"2022-05-01T15:54:17.916716Z","shell.execute_reply":"2022-05-01T15:54:23.785962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Display preprocessed image","metadata":{}},{"cell_type":"code","source":"def display_img(arr):\n    i = tf.keras.preprocessing.image.array_to_img(arr)\n    plt.imshow(i, cmap='gray')\n\nplt.figure(figsize=(7,7))\nfor i in range(9):\n    plt.subplot(3,3, i+1)\n    display_img(X[i])  ","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:23.789087Z","iopub.execute_input":"2022-05-01T15:54:23.789341Z","iopub.status.idle":"2022-05-01T15:54:24.87664Z","shell.execute_reply.started":"2022-05-01T15:54:23.789316Z","shell.execute_reply":"2022-05-01T15:54:24.875752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{}},{"cell_type":"code","source":"BUFFER_SIZE = 584\nBATCH_SIZE = 32  # from 128\nEPOCHS = 50  # from 50\nnoise_dim = 200  # from 100\nnum_examples_to_generate = 9\n\n# We will reuse this seed overtime (so it's easier to visualize progress in the animated GIF)\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Increase training data with Augmentations","metadata":{}},{"cell_type":"code","source":"def augmentation_pipeline(image):\n    image = tf.image.random_flip_left_right(image)\n#     image = tf.image.resize(image, IMAGE_RESIZE)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:26.956167Z","iopub.execute_input":"2022-05-01T15:54:26.95658Z","iopub.status.idle":"2022-05-01T15:54:26.966503Z","shell.execute_reply.started":"2022-05-01T15:54:26.956538Z","shell.execute_reply":"2022-05-01T15:54:26.96541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Simple dataset processing with batch and shuffle\ndef get_dataset():\n    ds = tf.data.Dataset.from_tensor_slices(X)\n#     ds = ds.map(augmentation_pipeline)\n    ds = ds.shuffle(BUFFER_SIZE)\n    ds = ds.batch(BATCH_SIZE)\n    return ds\n    \ntrain_dataset = get_dataset()\n# inspect a batch\nn_batch = 0\nfor i in train_dataset:\n    n_batch += 1\nprint(f\"num of batch: {n_batch}, shape of each batch: {i.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:26.971433Z","iopub.execute_input":"2022-05-01T15:54:26.973826Z","iopub.status.idle":"2022-05-01T15:54:27.488924Z","shell.execute_reply.started":"2022-05-01T15:54:26.973771Z","shell.execute_reply":"2022-05-01T15:54:27.487926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create Generator and Discriminator","metadata":{}},{"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential()   # dense unit is configured to match soon tobe reshaped layer\n    model.add(layers.Dense(32*32*256, use_bias=False, input_shape=(noise_dim,)))  # starts with 1D array, input is noise array of 100\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    # 32x32 bcz there's 2 conv2D. 128/2/2=32\n    model.add(layers.Reshape((32, 32, 256)))\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n\n    return model\n\n# create the generator\ngenerator = make_generator_model()\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:27.49354Z","iopub.execute_input":"2022-05-01T15:54:27.496027Z","iopub.status.idle":"2022-05-01T15:54:27.703607Z","shell.execute_reply.started":"2022-05-01T15:54:27.495977Z","shell.execute_reply":"2022-05-01T15:54:27.702187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Display an image generated from noise (G still not trained yet)","metadata":{}},{"cell_type":"code","source":"noise = tf.random.normal([1, noise_dim])  # outputs random values from normal dist. to a certain array shape\ngenerated_image = generator(noise, training=False)  # interesting, doesn't need .fit .predict or anything\n\nplt.imshow(generated_image[0, :, :, :]*255)#, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:27.704934Z","iopub.execute_input":"2022-05-01T15:54:27.705404Z","iopub.status.idle":"2022-05-01T15:54:30.170713Z","shell.execute_reply.started":"2022-05-01T15:54:27.705372Z","shell.execute_reply":"2022-05-01T15:54:30.169834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential()   # basic binary classification model\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[128, 128, 3]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model\n\n# create D\ndiscriminator = make_discriminator_model()\nprint(discriminator.summary())","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.172137Z","iopub.execute_input":"2022-05-01T15:54:30.172578Z","iopub.status.idle":"2022-05-01T15:54:30.23745Z","shell.execute_reply.started":"2022-05-01T15:54:30.172541Z","shell.execute_reply":"2022-05-01T15:54:30.236722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let the untrained D predict that generated image","metadata":{}},{"cell_type":"code","source":"decision = discriminator(generated_image)\nprint(decision)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.240654Z","iopub.execute_input":"2022-05-01T15:54:30.240924Z","iopub.status.idle":"2022-05-01T15:54:30.260362Z","shell.execute_reply.started":"2022-05-01T15:54:30.240897Z","shell.execute_reply":"2022-05-01T15:54:30.259576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Loss and Optimizer","metadata":{}},{"cell_type":"code","source":"# This method returns a helper function to compute cross entropy loss (prob between 0 and 1)\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.261468Z","iopub.execute_input":"2022-05-01T15:54:30.261796Z","iopub.status.idle":"2022-05-01T15:54:30.268182Z","shell.execute_reply.started":"2022-05-01T15:54:30.261769Z","shell.execute_reply":"2022-05-01T15:54:30.265754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discriminator Loss\nmeasures how well D distinguish real and fake images. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s.","metadata":{}},{"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    # ones_like creates array of ones with similar shape as the input array\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.269704Z","iopub.execute_input":"2022-05-01T15:54:30.270506Z","iopub.status.idle":"2022-05-01T15:54:30.278825Z","shell.execute_reply.started":"2022-05-01T15:54:30.270474Z","shell.execute_reply":"2022-05-01T15:54:30.278078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generator Loss\nMeasures how well G can trick D. If G is performing well, D will classify fake images as 1 (real)\nthe discriminator will classify the fake images as real (or 1). Here, we will compare the discriminators decisions on the generated images to an array of 1s. Here, we will compare the discriminators decisions on the generated images to an array of 1s.","metadata":{}},{"cell_type":"code","source":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.280693Z","iopub.execute_input":"2022-05-01T15:54:30.281186Z","iopub.status.idle":"2022-05-01T15:54:30.286785Z","shell.execute_reply.started":"2022-05-01T15:54:30.281149Z","shell.execute_reply":"2022-05-01T15:54:30.285805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optimizers","metadata":{}},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)  # but here they use the same Adam anyway\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.288461Z","iopub.execute_input":"2022-05-01T15:54:30.288911Z","iopub.status.idle":"2022-05-01T15:54:30.295698Z","shell.execute_reply.started":"2022-05-01T15:54:30.288874Z","shell.execute_reply":"2022-05-01T15:54:30.294794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create callbacks","metadata":{}},{"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.297405Z","iopub.execute_input":"2022-05-01T15:54:30.297792Z","iopub.status.idle":"2022-05-01T15:54:30.304781Z","shell.execute_reply.started":"2022-05-01T15:54:30.297753Z","shell.execute_reply":"2022-05-01T15:54:30.303703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining training loop\n\nThe training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fake images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator.","metadata":{}},{"cell_type":"code","source":"# Notice the use of `tf.function`\n# This annotation causes the function to be \"compiled\".\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.306127Z","iopub.execute_input":"2022-05-01T15:54:30.306506Z","iopub.status.idle":"2022-05-01T15:54:30.316976Z","shell.execute_reply.started":"2022-05-01T15:54:30.30647Z","shell.execute_reply":"2022-05-01T15:54:30.316274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n\n        for image_batch in dataset:\n            train_step(image_batch)\n\n        # Produce images for the GIF as we go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator,\n                                 epoch + 1,\n                                 seed)\n\n        # Save the model every 15 epochs\n        if (epoch + 1) % 15 == 0:\n            checkpoint.save(file_prefix = checkpoint_prefix)\n\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n        # Generate after the final epoch\n        display.clear_output(wait=True)\n        generate_and_save_images(generator, epochs, seed)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.318107Z","iopub.execute_input":"2022-05-01T15:54:30.318362Z","iopub.status.idle":"2022-05-01T15:54:30.329333Z","shell.execute_reply.started":"2022-05-01T15:54:30.318337Z","shell.execute_reply":"2022-05-01T15:54:30.328342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(model, epoch, test_input):\n    # Notice `training` is set to False.\n    # This is so all layers run in inference mode (batchnorm).\n    predictions = model(test_input, training=False)  # same as num_examples_to_generate\n    fig = plt.figure(figsize=(12,12))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(3, 3, i+1)\n        plt.imshow(predictions[i, :, :, :] * 127.5 + 127.5, cmap='gray')\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.330621Z","iopub.execute_input":"2022-05-01T15:54:30.331169Z","iopub.status.idle":"2022-05-01T15:54:30.339207Z","shell.execute_reply.started":"2022-05-01T15:54:30.331132Z","shell.execute_reply":"2022-05-01T15:54:30.338286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(train_dataset, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:54:30.340694Z","iopub.execute_input":"2022-05-01T15:54:30.341298Z","iopub.status.idle":"2022-05-01T15:56:31.895785Z","shell.execute_reply.started":"2022-05-01T15:54:30.341232Z","shell.execute_reply":"2022-05-01T15:56:31.89484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"benign = train_df[train_df[\"target\"] == 0]\nmalignant = train_df[train_df[\"target\"] == 1]\n\ndef show_img(target, n=20):\n    img_name = target.image_name.values\n    ex_img = np.random.choice(img_name, n)  # grab n number of images\n    plt.figure(figsize=(15,15))\n    for i in range(n):\n        plt.subplot(4, 5, i + 1)\n        img = plt.imread(image_path + ex_img[i]+'.jpg')\n        plt.imshow(img, cmap='gray')\n        plt.axis('off')\n    plt.tight_layout()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-05-01T15:56:31.897721Z","iopub.execute_input":"2022-05-01T15:56:31.898327Z","iopub.status.idle":"2022-05-01T15:56:31.912012Z","shell.execute_reply.started":"2022-05-01T15:56:31.898274Z","shell.execute_reply":"2022-05-01T15:56:31.911142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img(benign)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:56:31.913415Z","iopub.execute_input":"2022-05-01T15:56:31.913777Z","iopub.status.idle":"2022-05-01T15:56:53.078751Z","shell.execute_reply.started":"2022-05-01T15:56:31.91374Z","shell.execute_reply":"2022-05-01T15:56:53.07796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img(malignant)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T15:56:53.079999Z","iopub.execute_input":"2022-05-01T15:56:53.080461Z","iopub.status.idle":"2022-05-01T15:57:04.220676Z","shell.execute_reply.started":"2022-05-01T15:56:53.080422Z","shell.execute_reply":"2022-05-01T15:57:04.219026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}