{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport os\nimport math\nimport random\nimport re\nimport warnings\nfrom pathlib import Path\nfrom PIL import Image\nfrom typing import Optional, Tuple\nimport csv\nimport operator\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom scipy import spatial\nfrom sklearn.preprocessing import normalize\nfrom tqdm import tqdm\nfrom kaggle_datasets import KaggleDatasets","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:20.241032Z","iopub.execute_input":"2021-10-01T22:08:20.241358Z","iopub.status.idle":"2021-10-01T22:08:25.131125Z","shell.execute_reply.started":"2021-10-01T22:08:20.241267Z","shell.execute_reply":"2021-10-01T22:08:25.130237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:25.132488Z","iopub.execute_input":"2021-10-01T22:08:25.13284Z","iopub.status.idle":"2021-10-01T22:08:25.14177Z","shell.execute_reply.started":"2021-10-01T22:08:25.132804Z","shell.execute_reply":"2021-10-01T22:08:25.140733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:25.143848Z","iopub.execute_input":"2021-10-01T22:08:25.144206Z","iopub.status.idle":"2021-10-01T22:08:25.277432Z","shell.execute_reply.started":"2021-10-01T22:08:25.14417Z","shell.execute_reply":"2021-10-01T22:08:25.276189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Settings","metadata":{}},{"cell_type":"code","source":"DATADIR = Path(\"../input/landmark-recognition-2021\")\nTEST_IMAGE_DIR = DATADIR / \"test\"\nTRAIN_IMAGE_DIR = DATADIR / \"train\"\nTRAIN_LABELMAP_PATH = '../input/landmark-recognition-2021/train.csv'\n\nNUM_TO_RERANK = 10\n#TOP_K = 5  \nIMAGE_SIZE=420\nN_CHANNELS=3\n\nN_CLASSES = 81313\nTHRESHOLD = 0\nN_FOLDS=4\nTEST = False","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:25.279112Z","iopub.execute_input":"2021-10-01T22:08:25.27956Z","iopub.status.idle":"2021-10-01T22:08:25.286287Z","shell.execute_reply.started":"2021-10-01T22:08:25.279519Z","shell.execute_reply":"2021-10-01T22:08:25.285244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/landmark-recognition-2021/train.csv')\n\ndf_test = pd.read_csv('../input/landmark-recognition-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:25.287563Z","iopub.execute_input":"2021-10-01T22:08:25.287949Z","iopub.status.idle":"2021-10-01T22:08:26.800541Z","shell.execute_reply.started":"2021-10-01T22:08:25.287914Z","shell.execute_reply":"2021-10-01T22:08:26.799544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"import time\n\nfrom contextlib import contextmanager\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    print(f\"[{name}]\")\n    yield\n    print(f'[{name}] done in {time.time() - t0:.0f} s')","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.802096Z","iopub.execute_input":"2021-10-01T22:08:26.802493Z","iopub.status.idle":"2021-10-01T22:08:26.807582Z","shell.execute_reply.started":"2021-10-01T22:08:26.802452Z","shell.execute_reply":"2021-10-01T22:08:26.806716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n\nset_seed(1213)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.808917Z","iopub.execute_input":"2021-10-01T22:08:26.809522Z","iopub.status.idle":"2021-10-01T22:08:26.818393Z","shell.execute_reply.started":"2021-10-01T22:08:26.809482Z","shell.execute_reply":"2021-10-01T22:08:26.817474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    return strategy","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.822722Z","iopub.execute_input":"2021-10-01T22:08:26.823057Z","iopub.status.idle":"2021-10-01T22:08:26.830509Z","shell.execute_reply.started":"2021-10-01T22:08:26.823032Z","shell.execute_reply":"2021-10-01T22:08:26.829671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strategy = auto_select_accelerator()\nREPLICAS = strategy.num_replicas_in_sync\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.832399Z","iopub.execute_input":"2021-10-01T22:08:26.832793Z","iopub.status.idle":"2021-10-01T22:08:26.84505Z","shell.execute_reply.started":"2021-10-01T22:08:26.832757Z","shell.execute_reply":"2021-10-01T22:08:26.844304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class GeM(tf.keras.layers.Layer):\n    def __init__(self, pool_size, init_norm=3.0, normalize=False, **kwargs):\n        self.pool_size = pool_size\n        self.init_norm = init_norm\n        self.normalize = normalize\n\n        super(GeM, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'pool_size': self.pool_size,\n            'init_norm': self.init_norm,\n            'normalize': self.normalize,\n        })\n        return config\n\n    def build(self, input_shape):\n        feature_size = input_shape[-1]\n        self.p = self.add_weight(name='norms', shape=(feature_size,),\n                                 initializer=tf.keras.initializers.constant(self.init_norm),\n                                 trainable=True)\n        super(GeM, self).build(input_shape)\n\n    def call(self, inputs):\n        x = inputs\n        x = tf.math.maximum(x, 1e-6)\n        x = tf.pow(x, self.p)\n\n        x = tf.nn.avg_pool(x, self.pool_size, self.pool_size, 'VALID')\n        x = tf.pow(x, 1.0 / self.p)\n\n        if self.normalize:\n            x = tf.nn.l2_normalize(x, 1)\n        return x\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, input_shape[-1]])","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.8461Z","iopub.execute_input":"2021-10-01T22:08:26.846401Z","iopub.status.idle":"2021-10-01T22:08:26.857184Z","shell.execute_reply.started":"2021-10-01T22:08:26.846376Z","shell.execute_reply":"2021-10-01T22:08:26.854864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.858778Z","iopub.execute_input":"2021-10-01T22:08:26.859162Z","iopub.status.idle":"2021-10-01T22:08:26.874435Z","shell.execute_reply.started":"2021-10-01T22:08:26.859128Z","shell.execute_reply":"2021-10-01T22:08:26.873433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLDER_EFF_ORG0=\"../input/efficientnetv2-tfhub-weight-files/tfhub_models/efficientnetv2-m-21k-ft1k/classification\"\nFOLDER_EFF_ORG1=\"../input/efficientnetv2-tfhub-weight-files/tfhub_models/efficientnetv2-l-21k-ft1k/classification\"\ndef build_model(size=384, count=0,eff_org=FOLDER_EFF_ORG0):\n    inp = tf.keras.layers.Input(shape=(size, size, 3), name=\"inp1\")\n    label = tf.keras.layers.Input(shape=(), name=\"inp2\")\n    x=hub.KerasLayer(eff_org, trainable=True)(inp)\n    #x = getattr(efn, f\"EfficientNetB{efficientnet_size}\")(\n    #    weights=weights, include_top=False, input_shape=(size, size, 3))(inp)\n    #x = GeM(8)(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(1000, name=\"dense_before_arcface\", kernel_initializer=\"he_normal\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = ArcMarginProduct(\n        n_classes=N_CLASSES,\n        s=30,\n        m=0.5,\n        name=\"head/arc_margin\",\n        dtype=\"float32\"\n    )([x, label])\n    output = tf.keras.layers.Softmax(dtype=\"float32\")(x)\n    model = tf.keras.Model(inputs=[inp, label], outputs=[output])\n    opt = tf.optimizers.Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=opt,\n        loss=[tf.keras.losses.SparseCategoricalCrossentropy()],\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.875884Z","iopub.execute_input":"2021-10-01T22:08:26.876233Z","iopub.status.idle":"2021-10-01T22:08:26.887065Z","shell.execute_reply.started":"2021-10-01T22:08:26.876198Z","shell.execute_reply":"2021-10-01T22:08:26.886079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model_for_inference(weights_path: str,flg_eo=0):\n    with strategy.scope():\n        if flg_eo>0:\n            base_model = build_model(\n                size=IMAGE_SIZE,\n                count=0,\n                eff_org=FOLDER_EFF_ORG1)\n        else:\n            base_model = build_model(\n                size=IMAGE_SIZE,\n                count=0,\n                eff_org=FOLDER_EFF_ORG0)            \n        base_model.load_weights(weights_path)\n        model = tf.keras.Model(inputs=base_model.get_layer(\"inp1\").input,\n                               outputs=base_model.get_layer(\"dense_before_arcface\").output)\n        return model","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.888291Z","iopub.execute_input":"2021-10-01T22:08:26.888654Z","iopub.status.idle":"2021-10-01T22:08:26.897862Z","shell.execute_reply.started":"2021-10-01T22:08:26.888605Z","shell.execute_reply":"2021-10-01T22:08:26.897044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"def to_hex(image_id) -> str:\n    return '{0:0{1}x}'.format(image_id, 16)\n\n\ndef get_image_path(subset, image_id):\n    name = to_hex(image_id)\n    return os.path.join(DATASET_DIR, subset, name[0], name[1], name[2], '{}.jpg'.format(name))\n\n\ndef load_image_tensor(image_path):\n    tensor = tf.convert_to_tensor(np.array(Image.open(image_path).convert(\"RGB\")))\n    tensor = tf.image.resize(tensor, size=(IMAGE_SIZE, IMAGE_SIZE))\n    tensor = tf.expand_dims(tensor, axis=0)\n    return tf.cast(tensor, tf.float32) / 255.0\n\n\ndef create_batch(files):\n    images = []\n    for f in files:\n        images.append(load_image_tensor(f))\n    return tf.concat(images, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.899155Z","iopub.execute_input":"2021-10-01T22:08:26.899579Z","iopub.status.idle":"2021-10-01T22:08:26.908401Z","shell.execute_reply.started":"2021-10-01T22:08:26.899546Z","shell.execute_reply":"2021-10-01T22:08:26.907461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_global_features(image_root_dir):\n    n_models=N_FOLDS\n    image_paths = []\n    for root, dirs, files in os.walk(image_root_dir):\n        for file in files:\n            if file.endswith('.jpg'):\n                 image_paths.append(os.path.join(root, file))\n                    \n    if TEST:        \n        image_paths = image_paths[:1000]\n    \n    num_embeddings = len(image_paths)\n\n    ids = num_embeddings * [None]\n    ids = []\n    for path in image_paths:\n        ids.append(path.split('/')[-1][:-4])\n    \n    embeddings = np.zeros((n_models,num_embeddings, 1000))\n    image_paths = np.array(image_paths)\n    #chunk_size = 512\n    chunk_size = 128\n    models=[create_model_for_inference(f\"../input/glr21-my-model/M420_fold{n}.h5\",n%2) for n in range(n_models)]\n    n_chunks = len(image_paths) // chunk_size\n    if len(image_paths) % chunk_size != 0:\n        n_chunks += 1\n\n    for i in tqdm(range(n_chunks)):\n        #print(f\"Getting Embedding for fold{n} model.\")\n        files = image_paths[i * chunk_size:(i + 1) * chunk_size]\n        batch = create_batch(files)\n        for n in range(n_models):\n            #model = create_model_for_inference(f\"../input/glr21-my-model/fold{n}.h5\")\n            embedding_tensor = models[n].predict(batch)\n            embeddings[n,i * chunk_size:(i + 1) * chunk_size] = embedding_tensor\n        #del model\n        gc.collect()\n    tf.keras.backend.clear_session()\n    for n in range(n_models):\n        embeddings[n] = normalize(embeddings[n], axis=1)\n\n    return ids, embeddings\n","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.909601Z","iopub.execute_input":"2021-10-01T22:08:26.909967Z","iopub.status.idle":"2021-10-01T22:08:26.921132Z","shell.execute_reply.started":"2021-10-01T22:08:26.909932Z","shell.execute_reply":"2021-10-01T22:08:26.920116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_global_features_org(image_root_dir, n_models=4):\n    image_paths = []\n    for root, dirs, files in os.walk(image_root_dir):\n        for file in files:\n            if file.endswith('.jpg'):\n                 image_paths.append(os.path.join(root, file))\n                    \n    if TEST:        \n        image_paths = image_paths[:1000]\n    \n    num_embeddings = len(image_paths)\n\n    ids = num_embeddings * [None]\n    ids = []\n    for path in image_paths:\n        ids.append(path.split('/')[-1][:-4])\n    \n    embeddings = np.zeros((num_embeddings, 512))\n    image_paths = np.array(image_paths)\n    chunk_size = 512\n    models=[create_model_for_inference(f\"../input/glr21-my-model/fold{n}.h5\") for n in range(n_models)]\n    n_chunks = len(image_paths) // chunk_size\n    if len(image_paths) % chunk_size != 0:\n        n_chunks += 1\n\n    for i in tqdm(range(n_chunks)):\n        #print(f\"Getting Embedding for fold{n} model.\")\n        files = image_paths[i * chunk_size:(i + 1) * chunk_size]\n        batch = create_batch(files)\n        for n in range(n_models):\n            #model = create_model_for_inference(f\"../input/glr21-my-model/fold{n}.h5\")\n            embedding_tensor = models[n].predict(batch)\n            embeddings[i * chunk_size:(i + 1) * chunk_size] += embedding_tensor / n_models\n        #del model\n        gc.collect()\n    tf.keras.backend.clear_session()\n    embeddings = normalize(embeddings, axis=1)\n\n    return ids, embeddings\n","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.922608Z","iopub.execute_input":"2021-10-01T22:08:26.923062Z","iopub.status.idle":"2021-10-01T22:08:26.934401Z","shell.execute_reply.started":"2021-10-01T22:08:26.923027Z","shell.execute_reply":"2021-10-01T22:08:26.933507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef load_labelmap():   \n    with open(TRAIN_LABELMAP_PATH, mode='r') as csv_file:        \n        csv_reader = csv.DictReader(csv_file)\n        labelmap = {row['id']: row['landmark_id'] for row in csv_reader}\n    return labelmap\n\ndef get_aggregate_score(dict_map):\n    aggregate_scores = {}\n    for ids, label, score in dict_map:\n        if label not in aggregate_scores:\n            aggregate_scores[label] = score\n        else:\n            aggregate_scores[label] += score            \n    return aggregate_scores\n    \n    \ndef fill_prediction(ID):\n    if ID in prediction_dict:        \n        return str(prediction_dict[ID][0]) + ' ' + str(prediction_dict[ID][1])\n    else: \n        return ''\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.935755Z","iopub.execute_input":"2021-10-01T22:08:26.936106Z","iopub.status.idle":"2021-10-01T22:08:26.945312Z","shell.execute_reply.started":"2021-10-01T22:08:26.936072Z","shell.execute_reply":"2021-10-01T22:08:26.944479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"def get_predictions_org():\n    with timer(\"Getting Test Embeddings\"):\n        test_ids, test_embeddings = extract_global_features_org(str(TEST_IMAGE_DIR))\n\n    with timer(\"Getting Train Embeddings\"):\n        train_ids, train_embeddings = extract_global_features_org(str(TRAIN_IMAGE_DIR))\n\n    PredictionString_list = []\n    labelmap = load_labelmap()\n    train_ids_labels_and_scores = {}\n    test_ids_labels_and_scores = {}\n    with timer(\"Matching...\"):\n        for test_index in range(test_embeddings.shape[0]):\n            distances = spatial.distance.cdist(test_embeddings[np.newaxis, test_index, :], train_embeddings, 'cosine')[0]\n            partition = np.argpartition(distances, NUM_TO_RERANK)[:NUM_TO_RERANK]\n            nearest = sorted([(train_ids[p], distances[p]) for p in partition], key=lambda x: x[1])\n            df = pd.DataFrame(columns=['ids', 'distance', 'label'])\n            with timer(test_index):\n                \n                train_ids_labels_and_scores[test_ids[test_index]] = [\n                    (train_id, labelmap[train_id],1 - cosine_distance)\n                                    for train_id, cosine_distance in nearest\n                                ]\n    \n        for ids in train_ids_labels_and_scores:            \n            a = get_aggregate_score(train_ids_labels_and_scores[ids])            \n            test_ids_labels_and_scores[ids] =  max(a.items(), key=operator.itemgetter(1))\n    return test_ids_labels_and_scores #test_ids, PredictionString_list","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.946452Z","iopub.execute_input":"2021-10-01T22:08:26.946881Z","iopub.status.idle":"2021-10-01T22:08:26.95752Z","shell.execute_reply.started":"2021-10-01T22:08:26.946848Z","shell.execute_reply":"2021-10-01T22:08:26.956548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions():\n    n_models=N_FOLDS\n    with timer(\"Getting Test Embeddings\"):\n        test_ids, test_embeddings = extract_global_features(str(TEST_IMAGE_DIR))\n\n    with timer(\"Getting Train Embeddings\"):\n        train_ids, train_embeddings = extract_global_features(str(TRAIN_IMAGE_DIR))\n\n    PredictionString_list = []\n    labelmap = load_labelmap()\n    train_ids_labels_and_scores = {}\n    test_ids_labels_and_scores = {}\n    with timer(\"Matching...\"):\n        for test_index in range(test_embeddings.shape[1]):\n            distances=[]\n            for n in range(n_models):\n                if n==0:\n                    p_distances = spatial.distance.cdist(test_embeddings[n][np.newaxis, test_index, :], train_embeddings[n], 'cosine')[0]\n                    distances =p_distances/n_models\n                else:\n                    p_distances = spatial.distance.cdist(test_embeddings[n][np.newaxis, test_index, :], train_embeddings[n], 'cosine')[0]\n                    distances +=p_distances/n_models\n            partition = np.argpartition(distances, NUM_TO_RERANK)[:NUM_TO_RERANK]\n            nearest = sorted([(train_ids[p], distances[p]) for p in partition], key=lambda x: x[1])\n            df = pd.DataFrame(columns=['ids', 'distance', 'label'])\n            with timer(test_index):\n                train_ids_labels_and_scores[test_ids[test_index]] = [\n                    (train_id, labelmap[train_id],1 - cosine_distance)\n                                    for train_id, cosine_distance in nearest\n                ]\n    \n        for ids in train_ids_labels_and_scores:\n            a = get_aggregate_score(train_ids_labels_and_scores[ids])\n            test_ids_labels_and_scores[ids] =  max(a.items(), key=operator.itemgetter(1))\n    return test_ids_labels_and_scores #test_ids, PredictionString_list","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.958923Z","iopub.execute_input":"2021-10-01T22:08:26.959335Z","iopub.status.idle":"2021-10-01T22:08:26.971653Z","shell.execute_reply.started":"2021-10-01T22:08:26.959301Z","shell.execute_reply":"2021-10-01T22:08:26.970857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TEST:\n    num_pict = 1\nelse:\n    num_pict = 10345","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.972926Z","iopub.execute_input":"2021-10-01T22:08:26.973281Z","iopub.status.idle":"2021-10-01T22:08:26.982182Z","shell.execute_reply.started":"2021-10-01T22:08:26.973245Z","shell.execute_reply":"2021-10-01T22:08:26.981342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(df_test) == num_pict:\n    df_test[['id', 'landmarks']].to_csv('submission.csv', index = False)\n\nelse:\n    prediction_dict = get_predictions()\n    df_test['landmarks'] = df_test['id'].apply(fill_prediction)\n    df_test[['id', 'landmarks']].to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T22:08:26.983306Z","iopub.execute_input":"2021-10-01T22:08:26.983851Z","iopub.status.idle":"2021-10-01T22:22:26.879998Z","shell.execute_reply.started":"2021-10-01T22:08:26.983816Z","shell.execute_reply":"2021-10-01T22:22:26.879098Z"},"trusted":true},"execution_count":null,"outputs":[]}]}