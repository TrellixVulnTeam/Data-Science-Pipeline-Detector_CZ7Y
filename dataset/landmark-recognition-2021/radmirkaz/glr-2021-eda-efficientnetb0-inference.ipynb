{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nWelcome to the fourth Landmark Recognition competition! This year, we introduce a lot more diversity in the challenge’s test images in order to measure global landmark recognition performance in a fairer manner. And following last year’s success, we set this up as a code competition.\n\nHave you ever gone through your vacation photos and asked yourself: What is the name of this temple I visited in China? Who created this monument I saw in France? Landmark recognition can help! This technology can predict landmark labels directly from image pixels, to help people better understand and organize their photo collections. This competition challenges Kagglers to build models that recognize the correct landmark (if any) in a dataset of challenging test images.\n\n> Google Landmark Recognition is an image classification challenges like the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), which aims to recognize 1K general object categories. Landmark recognition is a little different from that: it contains a much larger number of classes (there are more than 81K classes in this challenge), and the number of training examples per class may not be very large. Landmark recognition is challenging in its own way.","metadata":{}},{"cell_type":"markdown","source":"# Info\n\nIn this competition, you are asked to take test images and recognize which landmarks (if any) are depicted in them. The training set is available in the train/ folder, with corresponding landmark labels in train.csv. The test set images are listed in the test/ folder. Each image has a unique id. Since there are a large number of images, each image is placed within three subfolders according to the first three characters of the image id (i.e. image abcdef.jpg is placed in a/b/c/abcdef.jpg).\n\n* This is a synchronous rerun code competition. The provided test set is a representative set of files to demonstrate the format of the private test set. When you submit your notebook, Kaggle will rerun your code on the private dataset. Additionally, this competition also has two unique characteristics:\n\n* To facilitate recognition-by-retrieval approaches, the private training set contains only a 100k subset of the total public training set. This 100k subset contains all of the training set images associated with the landmarks in the private test set. You may still attach the full training set as an external data set if you wish.\n\nSubmissions are given 12 hours to run, as compared to the site-wide session limit of 9 hours. While your commit must still finish in the 9 hour limit in order to be eligible to submit, the rerun may take the full 12 hours.\n\n* train.csv: This file contains, ids and targets\n - id: image id\n - landmark_id: target landmark id\n ","metadata":{}},{"cell_type":"code","source":"import os\n\n\nimport random\nimport seaborn as sns\nimport cv2\n\n# General packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\nimport IPython.display as ipd\nimport glob\nimport h5py\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom PIL import Image\nfrom tempfile import mktemp\n\n\nfrom bokeh.plotting import figure, output_notebook, show\nfrom math import pi\n\noutput_notebook()\n\n\nfrom IPython.display import Image, display\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:11.439092Z","iopub.execute_input":"2021-08-13T11:03:11.439512Z","iopub.status.idle":"2021-08-13T11:03:14.462991Z","shell.execute_reply.started":"2021-08-13T11:03:11.439424Z","shell.execute_reply":"2021-08-13T11:03:14.462114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input/landmark-recognition-2021/')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:14.464872Z","iopub.execute_input":"2021-08-13T11:03:14.465305Z","iopub.status.idle":"2021-08-13T11:03:14.473655Z","shell.execute_reply.started":"2021-08-13T11:03:14.465257Z","shell.execute_reply":"2021-08-13T11:03:14.472649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_DIR = '../input/landmark-recognition-2021'\n\nTRAIN_IMAGE_DIR = f'{DATASET_DIR}/train'\nTEST_IMAGE_DIR = f'{DATASET_DIR}/test'\ntrain = pd.read_csv(f'{DATASET_DIR}/train.csv')\nSUB = pd.read_csv(f'{DATASET_DIR}/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:14.475494Z","iopub.execute_input":"2021-08-13T11:03:14.476302Z","iopub.status.idle":"2021-08-13T11:03:16.109539Z","shell.execute_reply.started":"2021-08-13T11:03:14.476191Z","shell.execute_reply":"2021-08-13T11:03:16.108673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.head())\nprint(\"Shape of train_data :\", train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:16.111043Z","iopub.execute_input":"2021-08-13T11:03:16.111322Z","iopub.status.idle":"2021-08-13T11:03:16.136226Z","shell.execute_reply.started":"2021-08-13T11:03:16.111295Z","shell.execute_reply":"2021-08-13T11:03:16.134964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmark = train.landmark_id.value_counts()\nlandmark_df = pd.DataFrame({'landmark_id':landmark.index, 'frequency':landmark.values}).head(30)\n\nlandmark_df['landmark_id'] =   landmark_df.landmark_id.apply(lambda x: f'landmark_id_{x}')\n\nfig = px.bar(landmark_df, x=\"frequency\", y=\"landmark_id\",color='landmark_id',\n             hover_data=[\"landmark_id\", \"frequency\"],\n             height=1000,\n             title='Number of images per landmark_id (Top 30 landmark_ids)',\n             color_discrete_sequence=px.colors.sequential.RdBu)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:16.137678Z","iopub.execute_input":"2021-08-13T11:03:16.137961Z","iopub.status.idle":"2021-08-13T11:03:17.603758Z","shell.execute_reply.started":"2021-08-13T11:03:16.137931Z","shell.execute_reply":"2021-08-13T11:03:17.602598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmark.hist()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:17.605304Z","iopub.execute_input":"2021-08-13T11:03:17.605728Z","iopub.status.idle":"2021-08-13T11:03:17.856747Z","shell.execute_reply.started":"2021-08-13T11:03:17.605683Z","shell.execute_reply":"2021-08-13T11:03:17.855807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Landmark ID distribution\nplt.figure(figsize = (10, 8))\nplt.title('Landmark ID Distribuition')\nsns.distplot(train['landmark_id'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:17.857969Z","iopub.execute_input":"2021-08-13T11:03:17.858249Z","iopub.status.idle":"2021-08-13T11:03:26.22803Z","shell.execute_reply.started":"2021-08-13T11:03:17.858221Z","shell.execute_reply":"2021-08-13T11:03:26.22596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set()\nplt.title('Training set: number of images per class(line plot)')\nsns.set_color_codes(\"pastel\")\nlandmarks_fold = pd.DataFrame(train['landmark_id'].value_counts())\nlandmarks_fold.reset_index(inplace=True)\nlandmarks_fold.columns = ['landmark_id','count']\nax = landmarks_fold['count'].plot(logy=True, grid=True)\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=30)\nax.set(xlabel=\"Landmarks\", ylabel=\"Number of images\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:26.230484Z","iopub.execute_input":"2021-08-13T11:03:26.230798Z","iopub.status.idle":"2021-08-13T11:03:26.91296Z","shell.execute_reply.started":"2021-08-13T11:03:26.230768Z","shell.execute_reply":"2021-08-13T11:03:26.911909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize outliers, min/max or quantiles of the landmarks count\nsns.set()\nax = landmarks_fold.boxplot(column='count')\nax.set_yscale('log')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:26.914505Z","iopub.execute_input":"2021-08-13T11:03:26.914807Z","iopub.status.idle":"2021-08-13T11:03:27.41402Z","shell.execute_reply.started":"2021-08-13T11:03:26.914778Z","shell.execute_reply":"2021-08-13T11:03:27.41311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.landmark_id.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:27.415263Z","iopub.execute_input":"2021-08-13T11:03:27.415709Z","iopub.status.idle":"2021-08-13T11:03:27.457616Z","shell.execute_reply.started":"2021-08-13T11:03:27.415666Z","shell.execute_reply":"2021-08-13T11:03:27.456779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There are 81313 unique landmark_ids","metadata":{}},{"cell_type":"code","source":"landmark[:5]","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:27.458585Z","iopub.execute_input":"2021-08-13T11:03:27.458998Z","iopub.status.idle":"2021-08-13T11:03:27.46533Z","shell.execute_reply.started":"2021-08-13T11:03:27.458968Z","shell.execute_reply":"2021-08-13T11:03:27.464425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There is only one landmark which has more than 2300 images (landmark_id: 138982)","metadata":{}},{"cell_type":"code","source":"landmark.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:27.466604Z","iopub.execute_input":"2021-08-13T11:03:27.466998Z","iopub.status.idle":"2021-08-13T11:03:27.487099Z","shell.execute_reply.started":"2021-08-13T11:03:27.46697Z","shell.execute_reply":"2021-08-13T11:03:27.486176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Number of images per landmark_id ranges from 2 to 6272.\n- median is 9, mean is 19\n","metadata":{}},{"cell_type":"code","source":"landmark[landmark < 100].shape","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:27.488302Z","iopub.execute_input":"2021-08-13T11:03:27.48861Z","iopub.status.idle":"2021-08-13T11:03:27.496121Z","shell.execute_reply.started":"2021-08-13T11:03:27.48858Z","shell.execute_reply":"2021-08-13T11:03:27.494983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmark.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:27.497483Z","iopub.execute_input":"2021-08-13T11:03:27.497787Z","iopub.status.idle":"2021-08-13T11:03:27.508475Z","shell.execute_reply.started":"2021-08-13T11:03:27.497757Z","shell.execute_reply":"2021-08-13T11:03:27.507516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n- Out of 81313, there are 79298 (97.5%) landmark_ids with less than 100 images.","metadata":{}},{"cell_type":"code","source":"import PIL\nfrom PIL import Image, ImageDraw\n\n\ndef display_images(images, title=None): \n    \"\"\"\n    func for display images \n    Thank you @rohitsingh9990 for this fucntion\n    \"\"\"\n    f, ax = plt.subplots(5,5, figsize=(18,22))\n    if title:\n        f.suptitle(title, fontsize = 30)\n\n    for i, image_id in enumerate(images):\n        image_path = os.path.join(TRAIN_IMAGE_DIR, f'{image_id[0]}/{image_id[1]}/{image_id[2]}/{image_id}.jpg')\n        image = Image.open(image_path)\n        \n        ax[i//5, i%5].imshow(image) \n        image.close()       \n        ax[i//5, i%5].axis('off')\n\n        landmark_id = train[train.id==image_id.split('.')[0]].landmark_id.values[0]\n        ax[i//5, i%5].set_title(f\"ID: {image_id.split('.')[0]}\\nLandmark_id: {landmark_id}\", fontsize=\"12\")\n\n    plt.show() ","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-13T11:03:27.509704Z","iopub.execute_input":"2021-08-13T11:03:27.510091Z","iopub.status.idle":"2021-08-13T11:03:27.523026Z","shell.execute_reply.started":"2021-08-13T11:03:27.510062Z","shell.execute_reply":"2021-08-13T11:03:27.522163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing","metadata":{}},{"cell_type":"code","source":"samples = train.sample(25).id.values\ndisplay_images(samples, 'Random')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:27.52431Z","iopub.execute_input":"2021-08-13T11:03:27.524808Z","iopub.status.idle":"2021-08-13T11:03:37.836348Z","shell.execute_reply.started":"2021-08-13T11:03:27.524776Z","shell.execute_reply":"2021-08-13T11:03:37.835147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples = train[train.landmark_id == 138982].sample(25).id.values\ndisplay_images(samples, 'Top 1')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:37.837607Z","iopub.execute_input":"2021-08-13T11:03:37.837925Z","iopub.status.idle":"2021-08-13T11:03:48.269916Z","shell.execute_reply.started":"2021-08-13T11:03:37.837894Z","shell.execute_reply":"2021-08-13T11:03:48.268806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples = train[train.landmark_id == 126637].sample(25).id.values\ndisplay_images(samples, 'Top 2')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:48.27137Z","iopub.execute_input":"2021-08-13T11:03:48.271812Z","iopub.status.idle":"2021-08-13T11:03:58.614072Z","shell.execute_reply.started":"2021-08-13T11:03:48.271773Z","shell.execute_reply":"2021-08-13T11:03:58.613324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples = train[train.landmark_id == 20409].sample(25).id.values\ndisplay_images(samples, 'Top 3')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:03:58.615199Z","iopub.execute_input":"2021-08-13T11:03:58.615501Z","iopub.status.idle":"2021-08-13T11:04:08.701328Z","shell.execute_reply.started":"2021-08-13T11:03:58.615472Z","shell.execute_reply":"2021-08-13T11:04:08.700396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNetB0 inference","metadata":{}},{"cell_type":"code","source":"!pip install ../input/keras-efficientnet-whl/Keras_Applications-1.0.8-py3-none-any.whl\n!pip install ../input/keras-efficientnet-whl/efficientnet-1.1.1-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:10:11.372197Z","iopub.execute_input":"2021-08-13T11:10:11.372673Z","iopub.status.idle":"2021-08-13T11:10:26.81827Z","shell.execute_reply.started":"2021-08-13T11:10:11.372574Z","shell.execute_reply":"2021-08-13T11:10:26.817095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport efficientnet.keras as efn\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.preprocessing import image\nfrom random import shuffle\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport math","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:10:37.535502Z","iopub.execute_input":"2021-08-13T11:10:37.536042Z","iopub.status.idle":"2021-08-13T11:10:38.051256Z","shell.execute_reply.started":"2021-08-13T11:10:37.535995Z","shell.execute_reply":"2021-08-13T11:10:38.050273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, data, img_size, img_channel, batch_size):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.data = data\n        self.img_size = img_size\n        self.img_channel = img_channel\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(self.list_IDs))\n        \n    def __len__(self):\n        len_ = int(len(self.list_IDs)/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n            \n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, self.img_size, self.img_size, self.img_channel))\n        y = np.zeros((self.batch_size, 1), dtype=int)\n        for i, ID in enumerate(list_IDs_temp):\n            \n            image_id = self.data.loc[ID, 'id']\n            file = image_id+'.jpg'\n            subpath = '/'.join([char for char in image_id[0:3]]) \n            \n#             print(self.path+subpath+'/'+file)\n            img = cv2.imread(self.path+subpath+'/'+file)\n#             print(img)\n            img = img/255\n            img = cv2.resize(img, (self.img_size, self.img_size))\n            X[i, ] = img\n            if self.path.find('train')>=0:\n                y[i, ] = self.data.loc[ID, 'landmark_id']\n            else:\n                y[i, ] = 0\n        return X, y\n    \nimg_size = 256\nimg_channel = 3\n\nbatch_size = 1\nsub = pd.read_csv('../input/landmark-recognition-2021/sample_submission.csv')\nlist_IDs_test = list(sub.index)\n\ntest_generator = DataGenerator('../input/landmark-recognition-2021/'+'test/', list_IDs_test, sub, img_size, img_channel, batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:11:02.921551Z","iopub.execute_input":"2021-08-13T11:11:02.922069Z","iopub.status.idle":"2021-08-13T11:11:02.953425Z","shell.execute_reply.started":"2021-08-13T11:11:02.922037Z","shell.execute_reply":"2021-08-13T11:11:02.952372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model('../input/effnetb0trainedmodel/effnetB0.h5')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:11:12.479853Z","iopub.execute_input":"2021-08-13T11:11:12.480233Z","iopub.status.idle":"2021-08-13T11:11:17.369872Z","shell.execute_reply.started":"2021-08-13T11:11:12.480196Z","shell.execute_reply":"2021-08-13T11:11:17.368843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict_generator(test_generator)\npreds","metadata":{"execution":{"iopub.status.busy":"2021-08-13T11:15:33.215229Z","iopub.execute_input":"2021-08-13T11:15:33.21596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/landmark-recognition-2021/sample_submission.csv')\nfor i in range(len(sample_submission.index)):\n    category = np.argmax(preds[i])\n    score = preds[i][np.argmax(preds[i])].round(2)\n    sample_submission.loc[i, 'landmarks'] = str(category)+' '+str(score)\n    \nsample_submission.to_csv('submission.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['landmarks']","metadata":{},"execution_count":null,"outputs":[]}]}