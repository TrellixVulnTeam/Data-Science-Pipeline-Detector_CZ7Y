{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os \nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_hub as hub","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:48:59.827281Z","iopub.execute_input":"2021-08-16T18:48:59.827623Z","iopub.status.idle":"2021-08-16T18:48:59.834382Z","shell.execute_reply.started":"2021-08-16T18:48:59.827594Z","shell.execute_reply":"2021-08-16T18:48:59.83345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Location of training file for our training dataset\ntrain_file = \"../input/landmark-recognition-2021/train.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:50:21.441192Z","iopub.execute_input":"2021-08-16T18:50:21.441573Z","iopub.status.idle":"2021-08-16T18:50:21.445935Z","shell.execute_reply.started":"2021-08-16T18:50:21.441533Z","shell.execute_reply":"2021-08-16T18:50:21.4448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading file using pandas \"read_csv\" \ndata = pd.read_csv(train_file)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:50:23.000448Z","iopub.execute_input":"2021-08-16T18:50:23.000824Z","iopub.status.idle":"2021-08-16T18:50:24.542533Z","shell.execute_reply.started":"2021-08-16T18:50:23.00079Z","shell.execute_reply":"2021-08-16T18:50:24.54181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploring the dataset\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:50:25.330322Z","iopub.execute_input":"2021-08-16T18:50:25.330897Z","iopub.status.idle":"2021-08-16T18:50:25.355783Z","shell.execute_reply.started":"2021-08-16T18:50:25.330856Z","shell.execute_reply":"2021-08-16T18:50:25.355037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploring the target values and that is one the crucial task need to be taken care of\n\nprint(data[\"landmark_id\"].max(), data[\"landmark_id\"].min(), data[\"landmark_id\"].nunique())\n\n# seems like our data containes label inconsistent so we need a mapping dictiory for mapping our target values associated with \n#our input_image\n\nreverse_target_mapping = { i : value for i,value in enumerate(sorted(data[\"landmark_id\"].unique()))}\n\n# Here we are exchaning the keys and values in each other for mapping purpose\ntarget_mapping = {value : key for key,value in zip(reverse_target_mapping.keys(), reverse_target_mapping.values())}\n\ntarget_mapping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Colleting our input image file location using tf.io.gfile.glob, for more info look at official documentation\n\n\nfiles = tf.io.gfile.glob(\"../input/landmark-recognition-2021/train/*/*/*/*.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:50:39.491304Z","iopub.execute_input":"2021-08-16T18:50:39.491663Z","iopub.status.idle":"2021-08-16T18:52:09.395061Z","shell.execute_reply.started":"2021-08-16T18:50:39.491632Z","shell.execute_reply":"2021-08-16T18:52:09.394218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the files consistency with our input train file whether any value is missing or not\nlen(files)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:52:37.692526Z","iopub.execute_input":"2021-08-16T18:52:37.693133Z","iopub.status.idle":"2021-08-16T18:52:37.699147Z","shell.execute_reply.started":"2021-08-16T18:52:37.693098Z","shell.execute_reply":"2021-08-16T18:52:37.69801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sorting the value for concatnating our input image train file for processing\ndata.sort_values(inplace = True, by = \"id\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:52:39.529268Z","iopub.execute_input":"2021-08-16T18:52:39.529609Z","iopub.status.idle":"2021-08-16T18:52:43.910096Z","shell.execute_reply.started":"2021-08-16T18:52:39.529579Z","shell.execute_reply":"2021-08-16T18:52:43.908983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reseting the indices\n\ndata.reset_index(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:52:43.91168Z","iopub.execute_input":"2021-08-16T18:52:43.912127Z","iopub.status.idle":"2021-08-16T18:52:43.919654Z","shell.execute_reply.started":"2021-08-16T18:52:43.912086Z","shell.execute_reply":"2021-08-16T18:52:43.918636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# droping the previous indices column , this can be done using reset index = True, but i forgot\ndata.drop(columns = [\"index\"] , inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:52:44.631914Z","iopub.execute_input":"2021-08-16T18:52:44.632294Z","iopub.status.idle":"2021-08-16T18:52:44.76439Z","shell.execute_reply.started":"2021-08-16T18:52:44.632261Z","shell.execute_reply":"2021-08-16T18:52:44.763497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As we can see in the output , our landmark id contains inconsistent label values so we need to reverse map with\n# our target dictionary\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:52:49.601592Z","iopub.execute_input":"2021-08-16T18:52:49.601941Z","iopub.status.idle":"2021-08-16T18:52:49.612829Z","shell.execute_reply.started":"2021-08-16T18:52:49.601913Z","shell.execute_reply":"2021-08-16T18:52:49.611848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"landmark_id\"] = data[\"landmark_id\"].map(target_mapping)\n\n# we can double check for target mapping\nprint(target_mapping[107382])\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:52:52.051618Z","iopub.execute_input":"2021-08-16T18:52:52.052167Z","iopub.status.idle":"2021-08-16T18:52:52.191236Z","shell.execute_reply.started":"2021-08-16T18:52:52.05212Z","shell.execute_reply":"2021-08-16T18:52:52.190403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving processed this input_file into input directory\nos.makedirs(\"./precessed\")\ndata.to_csv(\"./precessed/training_file_processed.csv\")\n\nseries = pd.DataFrame(data = {\"true_label\" : target_mapping.keys(), \"mapped_label\" : target_mapping.values()})\n\nseries.to_csv(\"./precessed/label_mapping.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:55:45.207917Z","iopub.execute_input":"2021-08-16T18:55:45.208277Z","iopub.status.idle":"2021-08-16T18:55:55.763389Z","shell.execute_reply.started":"2021-08-16T18:55:45.208249Z","shell.execute_reply":"2021-08-16T18:55:55.762385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"input_file_loc\"] = sorted(files)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:52:59.212421Z","iopub.execute_input":"2021-08-16T18:52:59.212773Z","iopub.status.idle":"2021-08-16T18:52:59.854986Z","shell.execute_reply.started":"2021-08-16T18:52:59.212745Z","shell.execute_reply":"2021-08-16T18:52:59.853833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:14.847355Z","iopub.execute_input":"2021-08-16T18:56:14.847721Z","iopub.status.idle":"2021-08-16T18:56:14.858303Z","shell.execute_reply.started":"2021-08-16T18:56:14.847679Z","shell.execute_reply":"2021-08-16T18:56:14.857189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"id\"].loc[0], data[\"input_file_loc\"].loc[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:17.907518Z","iopub.execute_input":"2021-08-16T18:56:17.907866Z","iopub.status.idle":"2021-08-16T18:56:17.914393Z","shell.execute_reply.started":"2021-08-16T18:56:17.907837Z","shell.execute_reply":"2021-08-16T18:56:17.913415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Dataset Making","metadata":{}},{"cell_type":"code","source":"# Dataset making \n\n\nfile_dataset = tf.data.Dataset.from_tensor_slices(data[\"input_file_loc\"].values)\ntarget_dataset = tf.data.Dataset.from_tensor_slices(data[\"landmark_id\"].values)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:23.376376Z","iopub.execute_input":"2021-08-16T18:56:23.376864Z","iopub.status.idle":"2021-08-16T18:56:23.692321Z","shell.execute_reply.started":"2021-08-16T18:56:23.376833Z","shell.execute_reply":"2021-08-16T18:56:23.691496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnext(iter(file_dataset)), next(iter(target_dataset))","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:27.056561Z","iopub.execute_input":"2021-08-16T18:56:27.057061Z","iopub.status.idle":"2021-08-16T18:56:27.165952Z","shell.execute_reply.started":"2021-08-16T18:56:27.057031Z","shell.execute_reply":"2021-08-16T18:56:27.165018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Processing function","metadata":{}},{"cell_type":"code","source":"# Normalizing the images to [-1, 1]\ndef normalize(img):\n    img = (img / 127) - 1\n    return img\n\ndef prepare_dataset(image):\n    img = tf.io.read_file(image)\n    img = tf.image.decode_jpeg(img , channels = 3)\n    img = tf.image.resize(img, size = (299, 299))\n    \n    return img\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:29.256576Z","iopub.execute_input":"2021-08-16T18:56:29.256957Z","iopub.status.idle":"2021-08-16T18:56:29.262671Z","shell.execute_reply.started":"2021-08-16T18:56:29.256925Z","shell.execute_reply":"2021-08-16T18:56:29.261782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_dataset = file_dataset.map(prepare_dataset, num_parallel_calls = tf.data.AUTOTUNE)\nfile_dataset = file_dataset.map(normalize, num_parallel_calls = tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:31.254363Z","iopub.execute_input":"2021-08-16T18:56:31.254729Z","iopub.status.idle":"2021-08-16T18:56:31.409463Z","shell.execute_reply.started":"2021-08-16T18:56:31.254684Z","shell.execute_reply":"2021-08-16T18:56:31.408569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(file_dataset)), next(iter(target_dataset))","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:32.694341Z","iopub.execute_input":"2021-08-16T18:56:32.694676Z","iopub.status.idle":"2021-08-16T18:56:32.857243Z","shell.execute_reply.started":"2021-08-16T18:56:32.694648Z","shell.execute_reply":"2021-08-16T18:56:32.856314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_dataset = tf.data.Dataset.zip((file_dataset, target_dataset)).batch(32, drop_remainder = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:35.936313Z","iopub.execute_input":"2021-08-16T18:56:35.93681Z","iopub.status.idle":"2021-08-16T18:56:35.942506Z","shell.execute_reply.started":"2021-08-16T18:56:35.936778Z","shell.execute_reply":"2021-08-16T18:56:35.941785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Building\nnext(iter(final_dataset))[0].shape, next(iter(final_dataset))[1].shape","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:37.934442Z","iopub.execute_input":"2021-08-16T18:56:37.934795Z","iopub.status.idle":"2021-08-16T18:56:38.245015Z","shell.execute_reply.started":"2021-08-16T18:56:37.934767Z","shell.execute_reply":"2021-08-16T18:56:38.243928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model building","metadata":{}},{"cell_type":"code","source":"model = tf.keras.applications.MobileNetV3Large(include_top = True,weights = None ,input_shape = (299,299,3), classes = 81313)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:56:41.376979Z","iopub.execute_input":"2021-08-16T18:56:41.377345Z","iopub.status.idle":"2021-08-16T18:56:43.839949Z","shell.execute_reply.started":"2021-08-16T18:56:41.377312Z","shell.execute_reply":"2021-08-16T18:56:43.838834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Compilation","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(),\n              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n             metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:59:52.773544Z","iopub.execute_input":"2021-08-16T18:59:52.774333Z","iopub.status.idle":"2021-08-16T18:59:52.81094Z","shell.execute_reply.started":"2021-08-16T18:59:52.774295Z","shell.execute_reply":"2021-08-16T18:59:52.809857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Fitting and Evaluation","metadata":{}},{"cell_type":"code","source":"model.fit(final_dataset, epochs = 1, workers = 4, use_multiprocessing = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:59:56.165016Z","iopub.execute_input":"2021-08-16T18:59:56.165398Z","iopub.status.idle":"2021-08-16T19:06:10.655597Z","shell.execute_reply.started":"2021-08-16T18:59:56.165367Z","shell.execute_reply":"2021-08-16T19:06:10.653224Z"},"trusted":true},"execution_count":null,"outputs":[]}]}