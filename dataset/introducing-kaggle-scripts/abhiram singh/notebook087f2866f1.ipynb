{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"48da4007-cb75-c9b2-77a9-efd96ffefb4a"},"outputs":[],"source":"import tensorflow as tf\nimport numpy as np\nimport csv\nimport random\nimport pandas as pd\n\n# The competition datafiles are in the directory ../input\n# Read competition data files:\ntrain = pd.read_csv(\"../input/train.csv\")\ntest  = pd.read_csv(\"../input/test.csv\")\n\n# Write to the log:\nprint(\"Training set has {0[0]} rows and {0[1]} columns\".format(train.shape))\nprint(\"Test set has {0[0]} rows and {0[1]} columns\".format(test.shape))\n# Any files you write to the current directory get shown as outputs\n\n#my_data = np.genfromtxt('train.csv', delimiter=',')\n#my_data_test = np.genfromtxt('test.csv', delimiter=',')\n#row = len(my_data[:,1])\ntrain = np.array(train)\ntest = np.array(test)\ncol = len(train[1,:])\nprint (col)\nx_train = train[:,1:col]\nx_test = test\ny_train = train[:,0]\ny_train = y_train.astype(int)\n#print np.max(y_train)\n#print x_train.shape, y_train.shape\ny_train = np.eye(np.max(y_train) + 1)[y_train]\n#print x_train.shape, y_train.shape\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a62e23f-ccc9-ec35-1c0f-fb3a7dee7c83"},"outputs":[],"source":"sess = tf.InteractiveSession()\n\nx = tf.placeholder(tf.float32, shape=[None, 784])\ny_ = tf.placeholder(tf.float32, shape=[None, 10])\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n    strides=[1, 2, 2, 1], padding='SAME')\n\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\n\nx_image = tf.reshape(x, [-1,28,28,1])\n\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)\n\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\nh_pool2 = max_pool_2x2(h_conv2)\n\nW_fc1 = weight_variable([7 * 7 * 64, 1024])\nb_fc1 = bias_variable([1024])\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\nkeep_prob = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\nW_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\n\ny_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nsess.run(tf.initialize_all_variables())\nbatch_size = 10\ntrain_size = 40000\nx_train_test = x_train[train_size:41999,:]\ny_train_test = y_train[train_size:41999,:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df4ea771-4962-a175-50c4-4ffc1a75c4db"},"outputs":[],"source":"for i in range(1):\n#batch = mnist.train.next_batch(50)\n    for j in range(0,(train_size-1),batch_size):\n        x_batch = x_train[j:j+batch_size,:]\n        y_batch = y_train[j:j+batch_size,:]\n        if j%20000 == 0:\n            train_accuracy = accuracy.eval(feed_dict={\n                x:x_batch, y_: y_batch, keep_prob: 1.0})\n            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n        train_step.run(feed_dict={x: x_batch, y_: y_batch, keep_prob: 0.9})\n    c= list(zip(x_batch[0:train_size,:],y_batch[0:train_size,:]))\n    random.shuffle(c)\n    x_batch, y_batch = zip(*c)\n    x_batch = np.array(x_batch)\n    y_batch = np.array(y_batch)\nprint ('training done')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5699a30d-10fe-5bdb-9b93-0f8ed69f7a8f"},"outputs":[],"source":"print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n    x: x_train_test, y_: y_train_test, keep_prob: 1.0}))\nprint(\"train accuracy %g\"%accuracy.eval(feed_dict={\n    x: x_train[0:train_size,:], y_: y_train[0:train_size,:], keep_prob: 1.0}))\n#print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n#    x: x_train_test[4000:8000,:], y_: y_train_test[4000:8000,:], keep_prob: 1.0}))\n\ny_class = np.zeros(len(x_train[:,1]),dtype=np.int8)\nprint ('predicting new values')\nfor i in range(0,28000,4000):\n    y_pred = tf.argmax(y_conv,1)\n    y_class[i:i+4000] = sess.run(y_pred, feed_dict = \\\n        {x:x_test[i:i+4000, :],keep_prob:1.0})\n    print (i)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ac8311b-607d-04c4-07c8-20de269c83ad"},"outputs":[],"source":"print ('opening file for write')\n\nlabel = [\"ImageId,Label\"]\nwith open('../input/sample_submission.csv', 'wb') as csvfile:\n    spamwriter = csv.writer(csvfile, delimiter=' ')\n    spamwriter.writerow(label)\n    for i in xrange(1,28000+1):\n        values = [str(i)+','+str(y_class[i-1])]\n        spamwriter.writerow(values)\nprint ('file write complete')\n#------------things to add to code--------------\n#.validation check for differnt models\n#.randomize inputs"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}