{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Tabular Playground Series April 2021\n\n<img src=\"https://i.imgur.com/uHVJtv0.png\">\n\n<br><br>\n\n### Notebook Contents:\n\n<div id=\"toc_container\" style=\"background: #f9f9f9; border: 1px solid #aaa; display: table; font-size: 95%;\n                               margin-bottom: 1em; padding: 20px; width: auto;\">\n<p class=\"toc_title\" style=\"font-weight: 700; text-align: center\">Notebook Contents</p>\n<ul class=\"toc_list\">\n  <li><a href=\"#loading\">0. Imports, Data Loading and Preprocessing</a>\n  <li><a href=\"#optuna\">1. Optuna Hyperparameter Optimization</a>\n      <br>\n      <ul>\n    <li><a href=\"#optuna_objective\">1.0 Define Objective</a></li>\n    <li><a href=\"#optuna_study\">1.1 Start Optimization</a></li>\n    <li><a href=\"#optuna_plots\">1.2 Check Optimization Plots</a></li>\n  </ul>\n</li>\n<li><a href=\"#submission\">2. Submission</a></li>\n</ul>\n</div>\n\n##### Props\n\nProps to [corochann](https://www.kaggle.com/corochann/optuna-tutorial-for-hyperparameter-optimization), I believe this notebook is the best you can find about Optuna.\n\n\n##### Versioning\n\n17 For best score (0.79611)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"markdown","source":"<a id=\"loading\"></a>\n\n##### 0. Imports, Data Loading and Preprocessing","metadata":{}},{"cell_type":"code","source":"import torch\ndevice = 'gpu' if torch.cuda.is_available() else 'cpu'\nimport numpy as np\nimport pandas as pd\npd.options.display.max_columns = 100\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.preprocessing import QuantileTransformer, StandardScaler, PolynomialFeatures, LabelEncoder\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest\nimport warnings\nwarnings.filterwarnings('ignore')\nimport optuna\nimport tqdm\nimport gc\nimport os\nroot_path = '/kaggle/input/tabular-playground-series-apr-2021'","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(os.path.join(root_path, 'train.csv'))\ntest = pd.read_csv(os.path.join(root_path, 'test.csv'))\nsample_submission = pd.read_csv(os.path.join(root_path, 'sample_submission.csv'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.concat([train, test], axis = 0, ignore_index = True)\ntrain_len = len(train)\n\nlabel = LabelEncoder()\ncategorical_feature_columns = dataset.drop(['PassengerId', 'Survived'], 1).select_dtypes(exclude=['float64']).columns\n\nfor column in categorical_feature_columns:\n        label.fit(dataset[column])\n        dataset[column] = label.transform(dataset[column])\n\ncategorical_features = list(range(len(categorical_feature_columns)))\n\ntrain_preprocessed = dataset[:train_len]\ntest_preprocessed = dataset[train_len:]\n\nfeatures = train_preprocessed.drop(['PassengerId', 'Survived'], 1).columns.tolist()\n\nassert train_preprocessed.shape[1] == test_preprocessed.shape[1]\n\n#del train, test\ngc.collect()\ncat_indices = [features.index(i) for i in categorical_feature_columns]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"optuna\"></a>\n\n### Optuna\n\n\nCheck Version 2 for the actual Optimization.\n\nLook [here](https://optuna.readthedocs.io/en/stable/tutorial/) for reference about Optuna library. \n\nLook [here](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html) for a set of Lightgbm Classifier hyperparameters.\n\n\nSkip and go [here](#hyperparams) to find my best parameters.","metadata":{}},{"cell_type":"code","source":"#Set to False if you want to skip it\n\nOPTUNA_OPTIMIZATION = True\nN_SPLITS = 5 #Number of folds for validation\nN_TRIALS = 200 #Number of trials to find best hyperparameters\nTIME = 3600*3 #Time to run optimization (alternative to N_TRIALS)\nFOLD_RANDOM_SEED = 42","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"optuna_objective\"></a>\n<h6> Define Objective </h6>","metadata":{}},{"cell_type":"code","source":"def objective(trial, cv=StratifiedKFold(N_SPLITS, shuffle = True, random_state = FOLD_RANDOM_SEED)):\n    \n    \n    param_lgb = {\n        \"random_state\": 42,\n        \"metric\": \"auc\",\n        \"categorical_feature\": cat_indices,\n        \"verbosity\": -1,\n        \"n_estimators\": 2000,\n        \"learning_rate\": trial.suggest_categorical('learning_rate', [0.001, 0.005, 0.01, 0.05, 0.1]),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 1024),\n        'max_depth': trial.suggest_int('max_depth', -1, 32),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1E-16, 25),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1E-16, 25),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 1E-16, 1.0),\n        'subsample': trial.suggest_float('subsample ', 1E-16, 1.0),\n        'cat_smooth': trial.suggest_float('cat_smooth', 1.0, 50.0)  \n    }\n    \n    \n    val_aucs = []\n    aucs = []\n    accuracies = []\n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'auc', valid_name='valid_1') \n    \n    for kfold, (train_idx, val_idx) in tqdm.tqdm(enumerate(cv.split(train_preprocessed[features].values, \n                                                                    train_preprocessed['Survived'].values))):\n        \n        \n        X_train = train_preprocessed.loc[train_idx, features]\n        y_train = train_preprocessed.loc[train_idx, 'Survived']\n        \n        X_valid = train_preprocessed.loc[val_idx, features]\n        y_valid = train_preprocessed.loc[val_idx, 'Survived']\n        \n        d_train = lgb.Dataset(X_train, label=y_train)\n        d_valid = lgb.Dataset(X_valid, label=y_valid)\n        watchlist = [d_train, d_valid]\n        \n        model = lgb.train(param_lgb,\n                      train_set=d_train,\n                      num_boost_round=1500,\n                      valid_sets=watchlist,\n                      verbose_eval=0,\n                      early_stopping_rounds=100,\n                      callbacks=[pruning_callback])\n\n        preds = np.round(model.predict(X_valid)).astype(int)\n        #auc = roc_auc_score(y_valid, preds)\n        \n        accuracy = accuracy_score(y_valid, preds)\n        \n        #aucs.append(auc)\n        accuracies.append(accuracy)\n    \n    return np.average(accuracies)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"optuna_study\"></a>\n<h6> Start Optimization </h6>","metadata":{}},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    study = optuna.create_study(study_name = 'lgbm_parameter_opt', direction=\"maximize\",\n                                pruner=optuna.pruners.MedianPruner(n_warmup_steps=25))\n    \n    study.optimize(objective, n_trials=N_TRIALS) \n    \n    trial = study.best_trial\n    \n    print(\"  Value: {}\".format(trial.value))\n    \n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))\n    best_params = trial.params.items()\nelse:\n    trial = {\n            \"random_state\": 42,\n            \"metric\": \"auc\",\n            \"categorical_feature\": cat_indices,\n            \"verbosity\": -1,\n            \"n_estimators\": 20000,\n             'learning_rate': 0.05,\n             'num_leaves': 39,\n             'max_depth': 28,\n             'reg_alpha': 13.0124692806962,\n             'reg_lambda': 17.429087848443793,\n             'colsample_bytree': 0.6993443635848076,\n             'subsample': 0.7146065596315723,\n             'cat_smooth': 8.61671087256764}\n    best_params=trial","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"hyperparams\"></a>","metadata":{}},{"cell_type":"markdown","source":"best_params are: <br>\n>     {\"random_state\": 42,\n>      \"metric\": \"auc\",\n>      \"categorical_feature\": cat_indices,\n>      \"verbosity\": -1,\n>      \"n_estimators\": 20000,\n>      \"learning_rate\": 0.05,\n>      \"num_leaves\": 39,\n>      \"max_depth\": 28,\n>      \"reg_alpha\": 13.0124692806962,\n>      \"reg_lambda\": 17.429087848443793,\n>      \"colsample_bytree\": 0.6993443635848076,\n>      \"subsample\": 0.7146065596315723,\n>      \"cat_smooth\": 8.61671087256764}","metadata":{}},{"cell_type":"markdown","source":"<a id = \"optuna_plots\"></a>\n<h6> Check Optimization plots </h6>","metadata":{}},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_intermediate_values(study))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study, target_name = 'Average Validation AuC'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_slice(study, target_name = 'Average Validation AuC'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_parallel_coordinate(study, target_name = 'Average Validation AuC'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    display(study.trials_dataframe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"submission\"></a>\n\n### Submission","metadata":{}},{"cell_type":"code","source":"if OPTUNA_OPTIMIZATION:\n    final_model = LGBMClassifier(**trial.params)\nelse:\n    final_model = LGBMClassifier(**trial)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = []\n\nskf = StratifiedKFold(N_SPLITS, shuffle = True, random_state = FOLD_RANDOM_SEED)\naucs = []\naccuracies = []\n\nfor kfold, (train_idx, val_idx) in enumerate(skf.split(train_preprocessed[features].values, \n                                                      train_preprocessed['Survived'].values)):\n        \n        final_model.fit(train_preprocessed.loc[train_idx, features], \n                        train_preprocessed.loc[train_idx, 'Survived'])\n        print('Fitted {}'.format(type(final_model).__name__))\n        \n        val_true = train.loc[val_idx, 'Survived'].values\n        \n        preds = final_model.predict(train_preprocessed.loc[val_idx, features])\n        \n        auc = roc_auc_score(val_true, preds)\n        accuracy = accuracy_score(val_true, preds)\n        aucs.append(auc)\n        accuracies.append(accuracy)\n        print('Fold: {}\\t Validation AUC: {}\\n'.format(kfold, auc))\n        print('Fold: {}\\t Validation ACCURACY: {}\\n'.format(kfold, accuracy))\n        \n        test_preds.append(final_model.predict(test_preprocessed[features]))\n        \nprint(\"Best Parameters mean AUC: {}\".format(np.mean(aucs)))\nprint(\"Best Parameters mean ACCURACY: {}\".format(np.mean(accuracies)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = np.mean(test_preds, axis = 0)\nassert len(test_predictions) == len(test)\nsample_submission['Survived'] = np.round(test_predictions).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}