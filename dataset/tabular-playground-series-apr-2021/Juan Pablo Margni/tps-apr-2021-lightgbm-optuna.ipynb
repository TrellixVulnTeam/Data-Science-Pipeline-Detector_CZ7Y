{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h3>LightGBM parameter optimization with OPTUNA</h3>\n\nHyperparameter search notebook for: https://www.kaggle.com/jmargni/tps-apr-2021-lightgbm-cv\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nimport lightgbm as lgb\nimport optuna\nimport joblib","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:47:08.522995Z","start_time":"2021-04-05T17:47:07.290745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:23.287725Z","start_time":"2021-04-05T17:23:22.968601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encoder(c):\n    lc = LabelEncoder()\n    return lc.fit_transform(c)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:23.292876Z","start_time":"2021-04-05T17:23:23.289549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(df):\n    label_cols = ['Name', 'Ticket']\n    onehot_cols = ['Pclass', 'Sex', 'Cabin', 'Embarked', 'BucketAge']\n    numerical_cols = ['SibSp', 'Parch', 'SibSpParch', 'BucketFare', 'Survived']\n    age_map = df[['Age', 'Pclass']].dropna().groupby('Pclass').mean().to_dict()\n    df.Age = df.Age.fillna(df.Pclass.map(age_map['Age']))\n    df['BucketAge'] = df.Age//35\n    df['BucketFare'] = train_df.Fare//2\n    df['SibSpParch'] = df.SibSp + df.Parch\n    df.Cabin = df.Cabin.fillna('X').map(lambda x: x[0].strip())\n    df.Ticket = df.Ticket.fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n    df.Fare = df.Fare.fillna(df.Fare.mean())\n    df.Embarked = df.Embarked.fillna('X')\n    df.Name = df.Name.map(lambda x: x.split(',')[0])\n    onehot_encoded_df = pd.get_dummies(df[onehot_cols])\n    label_encoded_df = df[label_cols].apply(label_encoder)\n    numerical_df = df[numerical_cols]\n    return pd.concat([numerical_df, label_encoded_df, onehot_encoded_df], axis=1)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:23.324811Z","start_time":"2021-04-05T17:23:23.315004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df = preprocess(df = pd.concat([train_df, test_df]))","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:24.023694Z","start_time":"2021-04-05T17:23:23.477899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-split all data\nX = all_df[:train_df.shape[0]]\ny = X.pop('Survived')\nX_ = all_df[train_df.shape[0]:].drop(columns=['Survived'])","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:24.038044Z","start_time":"2021-04-05T17:23:24.025759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n    dtrain = lgb.Dataset(X_train, label=y_train)\n    dval = lgb.Dataset(X_test, label=y_test)\n \n    param = {\n        'objective': 'binary',\n        'boosting': 'gbdt',\n        'metric': 'auc',\n        'verbose': -1,\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 1),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 100, 2000, 50),\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n        'max_depth': trial.suggest_int('max_depth', 2, 10),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n#         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_bin': trial.suggest_int('max_bin', 10, 300, 10),\n    }\n    \n    folds = KFold(n_splits=5)\n    accuracies = []\n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n        print(\"Fold {}\".format(fold_))\n        X_train = X.iloc[trn_idx]\n        y_train = y[trn_idx]\n        X_test = X.iloc[val_idx]\n        y_test = y[val_idx]\n        \n        dtrain = lgb.Dataset(X_train, label=y_train)\n        dval = lgb.Dataset(X_test, label=y_test)\n    \n        gbm = lgb.train(param, dtrain, valid_sets=[dval], num_boost_round=10000, early_stopping_rounds=100, verbose_eval=-1)\n        preds = gbm.predict(X_test)\n        pred_labels = np.rint(preds)\n        accuracy = accuracy_score(y_test, pred_labels)\n        accuracies.append(accuracy)\n    return np.mean(accuracies)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:24.229199Z","start_time":"2021-04-05T17:23:24.220587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(n_trials=10):\n    try:  # try to load an already saved trials object, and increase the max\n        study = joblib.load(\"tabular_apr.optuna\")\n        print(\"Found saved Study! Loading...\")\n    except:  # create a new trials object and start searching\n        study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials)\n    \n    joblib.dump(study, \"tabular_apr.optuna\")","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:27:21.941018Z","start_time":"2021-04-05T17:27:21.936742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4>Study state is saved in each loop.</h4>\n<h4>Set <b>loops</b> and <b>trials_x_loop</b> for save study frequency and total number of trials.</h4>","metadata":{}},{"cell_type":"code","source":"loops = 4\ntrials_x_loop = 50\n\nfor i in range(loops):\n    main(trials_x_loop)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:29:44.202469Z","start_time":"2021-04-05T17:27:22.545362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = joblib.load(\"tabular_apr.optuna\")","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:47:13.183929Z","start_time":"2021-04-05T17:47:13.169594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_value, study.best_params ","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:47:14.751841Z","start_time":"2021-04-05T17:47:14.744562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_param_importances(study)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:50:39.973606Z","start_time":"2021-04-05T17:50:38.975655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:56:12.788243Z","start_time":"2021-04-05T17:56:12.7677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_parallel_coordinate(study)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:52:54.56609Z","start_time":"2021-04-05T17:52:54.519831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}