{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U optimal_pytorch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from optimal_pytorch.coin_betting.torch import Cocob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"help(Cocob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn import preprocessing\n\n\ndef preprocess(data, train=True):\n    if train:\n        X = data.drop(['Survived','PassengerId'], axis=1)\n        Y = data['Survived']\n    else:\n        X = data.drop(['PassengerId'], axis=1)\n    \n    X['Cabin'] = X['Cabin'].fillna('X').map(lambda x: x[0:5].strip())\n    imp = SimpleImputer(strategy=\"most_frequent\")\n    X = pd.DataFrame(imp.fit_transform(X), columns=X.columns)\n    enc = preprocessing.OrdinalEncoder()\n    cols = ['Sex','Cabin','Name','Ticket', 'Embarked']\n    X[cols] = enc.fit_transform(X[cols])\n    scaler = preprocessing.StandardScaler()\n    X = scaler.fit_transform(X)\n    if train:\n        return X, Y\n    else:\n        return X\n\n    \ndf = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\nx_train, y_train = preprocess(df)\ndf = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')\nx_test = preprocess(df, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom sklearn.model_selection import KFold\nfrom torch.optim import SGD\n\n\ndef log_loss(w, x):\n    wTx = torch.einsum('i,ki ->', w, x)\n    return torch.log(1 + torch.exp(wTx))\n\ndef predict(w, x):\n    wTx = torch.einsum('i,ji -> j', w, x)\n    out = 1. / (1. + torch.exp(-wTx))\n    out[out > .5] = 1.\n    out[out <= .5] = 0.\n    return out\n\n\nclass synthanic_data(Dataset):\n    \n    def __init__(self, x, y):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.x = torch.from_numpy(x)\n        self.y = torch.from_numpy(y)\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        features = self.x[idx]\n        labels = self.y[idx]\n        return {'x': features, 'y': labels}\n    \n    \n# Model\nclass LogisticRegression(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(LogisticRegression, self).__init__()\n        self.linear = nn.Linear(input_size, num_classes)\n    \n    def forward(self, x):\n        out = self.linear(x)\n        return out\n\n\n#define dataset\nsynthanic_torch = synthanic_data(np.array(x_train), np.array(y_train))\n\n# Configuration options\nk_folds = 5\nnum_epochs = 5\n# loss_function = nn.CrossEntropyLoss()\n\n# For fold results\nresults = {}\n\n# Set fixed random number seed\ntorch.manual_seed(42)\n\ndim = x_train.shape[1]\ncriterion = nn.CrossEntropyLoss()  \n\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=k_folds, shuffle=True)\n\n# Start print\nprint('--------------------------------')\n\n# K-fold Cross Validation model evaluation\nfor fold, (train_ids, test_ids) in enumerate(kfold.split(x_train)):\n\n    # Print\n    print(f'FOLD {fold}')\n    print('--------------------------------')\n\n    # Sample elements randomly from a given list of ids, no replacement.\n    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n\n    # Define data loaders for training and testing data in this fold\n    trainloader = torch.utils.data.DataLoader(\n                      synthanic_torch, batch_size=256, sampler=train_subsampler)\n    testloader = torch.utils.data.DataLoader(\n                      synthanic_torch, batch_size=10000, sampler=test_subsampler)\n\n    # Init the model and optimizer\n    model = LogisticRegression(dim, 2)\n    optimizer = Cocob(model.parameters())\n\n    # Run the training loop for defined number of epochs\n    for epoch in range(num_epochs):\n        print(f'Starting epoch {epoch+1}')\n        current_loss = 0.0\n        \n        # Iterate over the DataLoader for training data\n        for i, data in enumerate(trainloader, 0):\n            inputs, targets = data['x'].float(), data['y']\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            current_loss += loss.item()\n        \n        with torch.no_grad():\n            d = x_train.shape[0]\n            outputs = model(torch.tensor(x_train).float())\n            _, predicted = torch.max(outputs.data, 1)\n            correct = (predicted.numpy() == y_train).sum()\n\n        print(f\"Train loss after {epoch + 1} epochs {current_loss:.3f}\")\n        print(f\"Corrected classified {correct}\")\n        current_loss = 0.0\n\n    print('Training process has finished. Saving trained model.')\n    print('Starting testing')\n\n    # Saving the model\n    save_path = f'./model-fold-{fold}.pth'\n    torch.save(model, save_path)\n\n    # Evaluation for this fold\n    correct, total = 0, 0\n    with torch.no_grad():\n        for i, data in enumerate(testloader, 0):\n            inputs, targets = data['x'].float(), data['y']\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            correct += (predicted == targets).sum()\n            total += targets.shape[0]\n            \n    # Print accuracy\n    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n    print('--------------------------------')\n    results[fold] = 100.0 * (correct / total)\n\n# Print fold results\nprint(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\nprint('--------------------------------')\nsum = 0.0\nfor key, value in results.items():\n    print(f'Fold {key}: {value:.2f} %')\n    sum += value\n    print(f'Average: {sum/len(results.items()):.2f} %')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')\nwith torch.no_grad():\n    outputs = model(torch.tensor(x_test).float())\n    _, predicted = torch.max(outputs.data, 1)\n    # predicted = predict(model, torch.tensor(x_test).float())\nsample_submission['Survived'] = predicted.numpy().astype(int)\nsample_submission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}