{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ntest_data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')\nprint(train_data.shape)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initial Data Cleaning:\nLet's do the first things first. Drop passengerid from train and store the one from test; as that is needed for sample submission. The 'Survived' is the dependent target. In this competition, variables like age and cabin, not being present is also significant; so we will have to replace them tactfully to get some information out of them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ids = test_data['PassengerId'].tolist()\ntrain_survived = train_data['Survived']\ntrain_data = train_data.drop('Survived',axis = 1)\ntrain_data['split'] = 'train'\ntest_data['split'] = 'test'\ntotal_data = pd.concat([train_data,test_data[train_data.columns]],axis = 0,ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data['Age'] = total_data['Age'].fillna(-999)\ntotal_data['Cabin'] = total_data['Cabin'].fillna('UNK')\ntotal_data['Ticket'] = total_data['Ticket'].fillna('UNK')\ntotal_data['Embarked'] = total_data['Embarked'].fillna('UNK')\ntotal_data['Fare'] = total_data['Fare'].fillna(-999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data = total_data.drop('PassengerId',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.Pclass.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.Sex.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(total_data.Ticket.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,4):\n    total_data['Is_Pclass_'+str(i)] = total_data['Pclass'].apply(lambda x:(x==i)*1.0)\nfor i in ['male','female']:\n    total_data['Is_sex_'+i] = total_data['Sex'].apply(lambda x: (x==i)*1.0)\nfor i in ['S','C','Q']:\n    total_data['Is_class_'+i] = total_data['Embarked'].apply(lambda x:(x==i)*1.0)\ntotal_data['Is_ticket_unknown'] = total_data['Ticket'].apply(lambda x: (x=='UNK')*1.0)\ntotal_data['Passenger_class_unknown'] = total_data['Embarked'].apply(lambda x: (x=='UNK')*1.0)\ntotal_data['No_cabin'] = total_data['Cabin'].apply(lambda x: (x=='UNK')*1.0)\ntotal_data['ticket_only_digit'] = total_data['Ticket'].apply(lambda x: x.isdigit()*1.0)\ntotal_data['paris_bound'] = total_data['Ticket'].apply(lambda x: ('Paris' in x)*1.0)\ntotal_data['soton_bound'] = total_data['Ticket'].apply(lambda x: ('SOTON' in x)*1.0+('STON' in x)*1.0)\ntotal_data['PC_in_ticket'] = total_data['Ticket'].apply(lambda x: ('PC' in x)*1.0 +('P.C.' in x)*1.0)\ntotal_data['A_in_ticket'] = total_data['Ticket'].apply(lambda x: ('A' in x)*1.0)\ntotal_data['CA_in_ticket'] = total_data['Ticket'].apply(lambda x: ('CA' in x)*1.0)\ntotal_data['wc_in_ticket'] = total_data['Ticket'].apply(lambda x: ('W./C.' in x)*1.0)\ntotal_data['SC_in_ticket'] = total_data['Ticket'].apply(lambda x: ('SC' in x)*1.0)\n#total_data['PP_in_ticket'] = total_data['Ticket'].apply(lambda x: ('P.P.' in x)*1.0)\n#total_data['fcc_in_ticket'] = total_data['Ticket'].apply(lambda x: ('F.C.C.' in x)*1.0)\n#total_data['soc_in_ticket'] = total_data['Ticket'].apply(lambda x: ('S.O.C.' in x)*1.0)\ntotal_data['family_number'] = total_data['SibSp'] + total_data['Parch']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sex and the class interaction features are very important. So let's create them."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = 3\n((x<4) and (x>2)) *1.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cut_points = [-999,0,16,60,100]\nlabel_names = [\"Missing\",\"Child\",\"Adult\",\"Senior\"]\nfor i in range(len(label_names)):\n    total_data['Is_Age_'+label_names[i]] = total_data['Age'].apply(lambda x: ((x>=cut_points[i]) and (x<cut_points[i+1]))*1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data['Age'] = total_data['Age'].replace(-999,18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data['first_class_female'] = total_data['Is_Pclass_1']*total_data['Is_sex_female']\ntotal_data['first_class_child'] = total_data['Is_Pclass_1']*total_data['Is_Age_Child']\ntotal_data['second_class_child'] = total_data['Is_Pclass_2']*total_data['Is_Age_Child']\ntotal_data['second_class_female'] = total_data['Is_Pclass_1']*total_data['Is_sex_female']\ntotal_data['Third_class_adult'] = total_data['Is_Pclass_3']*(1-total_data['Is_Age_Child'])\ntotal_data['male_with_family'] = total_data['Is_sex_male']*total_data['family_number']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data['Embarked'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data = total_data.drop(['Pclass','Sex','Ticket','Embarked','Cabin'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(total_data['Name'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For me, It doesn't seem currently that the name feature has any valuable information. So we are going to drop it."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data = total_data.drop('Name',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(total_data[total_data['Age']!=-999]['Age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = total_data[total_data['split']=='train']\ntrain_data = train_data.drop('split',axis = 1)\ntest_data = total_data[total_data['split']=='test']\ntest_data = test_data.drop('split',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier as RFC\nfrom sklearn.metrics import classification_report as creport\nfrom sklearn.model_selection import train_test_split as tts\nfrom xgboost import XGBClassifier as XGBC\nfrom sklearn.svm import NuSVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test = tts(train_data,train_survived,test_size = 0.2,random_state = 8080)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RFC(n_estimators = 128,max_depth = 6,criterion = 'entropy',\n          min_samples_split = 5, max_features = 15,\n          #class_weight = 'balanced',#commenting out as this decreased accuracy.\n          oob_score = True,n_jobs = -1)\nrfc.fit(X_train,Y_train)\nY_pred_train = rfc.predict(X_train)\nY_pred_test = rfc.predict(X_test)\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))\nprint(\"the oob score is:\")\nprint(rfc.oob_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier as ETC\netc = ETC(n_estimators = 128,max_depth = 6,criterion = 'entropy',min_samples_split = 30,\n          #class_weight = 'balanced',#commenting out as this decreased accuracy.\n          bootstrap = True,\n          oob_score = True,n_jobs = -1)\netc.fit(X_train,Y_train)\nY_pred_train = etc.predict(X_train)\nY_pred_test = etc.predict(X_test)\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))\nprint(\"the oob score is:\")\nprint(etc.oob_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier as LGBC\nlgbc = LGBC()\nlgbc.fit(X_train,Y_train)\nY_pred_train = lgbc.predict(X_train)\nY_pred_test = lgbc.predict(X_test)\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = pd.DataFrame()\nfeature_importances['features'] = X_train.columns\nfeature_importances['feature_importance'] = rfc.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sort only important features and retrain random forest model."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important_columns = feature_importances[feature_importances['feature_importance']>0.001]['features'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n#commenting it out as for us random forest is the best model.\n#this is not a good model actually as this performed much worse: 0.78013.\n#probably this is caused by the fact that we reduced too many features.\nrfc = RFC(n_estimators = 128,max_depth = 10,\n          #criterion = 'entropy',\n          min_samples_split = 15,\n          #class_weight = 'balanced',#commenting out as this decreased accuracy.\n          oob_score = True,n_jobs = -1)\nrfc.fit(X_train[important_columns],Y_train)\nY_pred_train = rfc.predict(X_train[important_columns])\nY_pred_test = rfc.predict(X_test[important_columns])\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))\nprint(\"the oob score is:\")\nprint(rfc.oob_score_)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc = XGBC(n_estimators=900,\n            learning_rate = 0.1,\n            max_depth = 6,\n            reg_lambda = 100,\n            reg_alpha = 5,\n            scale_pos_weight = 1.33,\n            n_jobs = -1)\nxgbc.fit(X_train,Y_train)\nY_pred_train = xgbc.predict(X_train)\nY_pred_test = xgbc.predict(X_test)\nprint(\"for the train data:\")\nprint(creport(Y_train,Y_pred_train))\nprint(\"for the test data:\")\nprint(creport(Y_test,Y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv')\nprint(submission.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_prediction = rfc.predict(test_data)\nfirst_submission = pd.DataFrame()\nfirst_submission['PassengerId'] = test_ids\nfirst_submission['Survived'] = test_prediction\nfirst_submission.to_csv('third_randomforest_submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_prediction = lgbc.predict(test_data)\nfirst_submission = pd.DataFrame()\nfirst_submission['PassengerId'] = test_ids\nfirst_submission['Survived'] = test_prediction\nfirst_submission.to_csv('first_lgbm_submission.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}