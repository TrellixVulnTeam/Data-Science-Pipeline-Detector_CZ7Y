{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fname = '/kaggle/input/tabular-playground-series-apr-2021/train.csv'\ndf_train = pd.read_csv(train_fname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How many missing values are there?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many missing values\ndf_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pick a few columns to work with and fill the missing data.\nFor the numerical columns we can replace the NAs with the median values. For the categorical column, we can create a new category for the missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pick a few columns\ncol = [\n    'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Survived'\n]\ndf_clean = df_train[col]\n\n# Handle the missing data\ndf_clean['Fare'] = df_clean['Fare'].fillna(df_clean['Fare'].median())\ndf_clean['Age'] = df_clean['Age'].fillna(df_clean['Age'].median())\ndf_clean['Embarked'] = df_clean['Embarked'].fillna('NaN')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Double check that we now have no missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify no missing data\ndf_clean.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pandas has a nice `get_dummies` function that will create binary variables for categorical features. The `Pclass` column is a numerical column but is actually just a categorical feature, so we convert it to string before calling `get_dummies`."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make binary variable columns from the categorical columns\ndf_clean['Pclass'] = df_clean['Pclass'].astype(str)\ndft = pd.get_dummies(df_clean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In class, we talked a bit about training and validation accuracy. In general, we always want to evaluate the effectiveness of our models on data the model has never seen before. This means we should set aside some data before training our model to use as validation data. Scikit-learn has a nice `KFold` class that lets us split our data into training and test sets to do precisely this.\n\nWe will use look at how the `max_depth` parameter of the `DecisionTreeClassifier` affects the training/validation accuracies. We expect the training accuracy to increase as we increase `max_depth` since a higher depth means our model can fit the data better. We also expect the validation accuracy to increase up to a point before our model starts to overfit to our training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [c for c in dft.columns if c != 'Survived']\nx_train = dft[cols]\ny_train = dft['Survived']\n\nkf = KFold(n_splits=5, shuffle=True)\ntr_accs = []\nval_accs = []\n\n# max depth values to try\npvals = range(1, 20)\n\nmean_tr_accs = []\nmean_val_accs = []\nmodels = []\nfor pval in pvals:\n    tr_accs = []\n    val_accs = []\n    for train_index, test_index in kf.split(x_train):\n        x_tr, x_val = x_train.iloc[train_index], x_train.iloc[test_index]\n        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n\n        dt = DecisionTreeClassifier(max_depth=pval)\n        dt.fit(x_tr, y_tr)\n\n        yv_pred = dt.predict(x_val)\n        yt_pred = dt.predict(x_tr)\n        train_acc = accuracy_score(y_tr, yt_pred)\n        val_acc = accuracy_score(y_val, yv_pred)\n        tr_accs.append(train_acc)\n        val_accs.append(val_acc)\n    models.append(dt)\n\n    print('Depth: {:2d} | Train acc: {:.3f} | Val acc: {:.3f}'.format(\n            pval,\n            np.mean(tr_accs),\n            np.mean(val_accs)\n    ))\n    mean_tr_accs.append(np.mean(tr_accs))\n    mean_val_accs.append(np.mean(val_accs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot test/val accuracies\nplt.plot(pvals, mean_tr_accs, color='b', label='Train acc')\nplt.plot(pvals, mean_val_accs, color='r', label='Val acc')\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Max Depth')\nplt.title('Train vs Val acc over Max Depth settings')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that increasing our max depth for the Decision Tree classfier allows us to fit the data better. The validation accuracy peaks at max depth = 7 and decreases beyond that."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}