{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Loading in Initial Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inspecting training data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ndata.info()\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training data shows that we are missing a lot of values in Cabin, and some in age, Ticket, Fare and embarked. Within the dataset, lets see how balanced it is.","metadata":{}},{"cell_type":"code","source":"count = 0\n\nfor i in np.arange(0, data.shape[0], 1):\n    if data['Survived'][i] == 1:\n        count = count + 1\n    else:\n        pass\nprint('{} Passengers survived while {} did not!'.format(count, (data.shape[0]-count)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So there is ~43% passengers that survived while ~57% did not survive. Its a bit imbalanced but when we do the train test split lets see how it comes out. </br>\nFor train test split stratify will be set to the target value to ensure as equal proportion of separations as possible.\n# Splitting data\nPassengerId, Ticket and Cabin were dropped as they are not going to be relevant as we know from the original titanic dataset.","metadata":{}},{"cell_type":"code","source":"data_d = data.copy()\ndata_d = data_d.drop(['PassengerId', 'Ticket', 'Cabin'], axis=1)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data_d.iloc[:, 1:], data_d.iloc[:, 0],\n                                                   test_size = 0.20, shuffle = True, stratify=data_d.iloc[:, 0])\n\ndef index_reseter(variable):\n    variable = variable.reset_index()\n    variable = variable.drop('index', axis=1)\n    if variable.shape[1]==1:\n        #Changes variable back to array\n        return variable.squeeze()\n    else:\n        return variable\n\n#Reset index values and turn targets to array\nX_train = index_reseter(X_train)\nX_test = index_reseter(X_test)\ny_train = index_reseter(y_train)\ny_test = index_reseter(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor i in np.arange(0, y_train.shape[0], 1):\n    if y_train[i] == 1:\n        count = count + 1\n    else:\n        pass\n\nif (count/y_train.shape[0]*100) > 40 and (count/y_train.shape[0]*100) <= 60:\n    print('Training data has {}% survived labels'.format(count/y_train.shape[0]*100))\nelse:\n    print('Labels are far from balanced with {}% survived labels'.format(count/y_train.shape[0]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above code demonstrates that we maintained our proportions as equal as possible during splitting.\n# Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.compose import ColumnTransformer\nimport random\nfrom sklearn.neural_network import MLPClassifier as MLP\nfrom sklearn.metrics import accuracy_score\n\n#Setting up a function to transform name into intials\nclass NameSplitter(BaseEstimator, TransformerMixin):\n    \n    def __init__(self):\n        print('Initiate')\n        pass\n        \n    def fit(self, X, y=None):\n        print('Started')\n        return self\n    \n    def transform(self, X):\n            #Print shows custom transformer works\n            print('Transform')\n            X_new = X.copy()\n            X_new[['First_Name','Last_Name']] = X_new['Name'].str.split(\",\",expand=True)\n            X_new['Last_Name'] = X_new['Last_Name'].str.replace(' ', '')\n            X_new['First_Name'] = X_new['First_Name'].str[0]\n            X_new['Last_Name'] = X_new['Last_Name'].str[0]\n            X_new = X_new.drop('Name', axis=1)\n            print('Return new array')\n            return X_new\n        \n    def fit_transform(self, X, y=None):\n        print('Working')\n        return self.fit(X, y).transform(X)\n\n#Setting Name Splitter to Variable\nns = NameSplitter()\n\n#Setting up column transformer\nnumericals = list(X_train.select_dtypes(include=['int64', 'float64']).columns)\nn_t = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant')),\n    ('scaler', StandardScaler())])\n\ncategoricals = list(X_train.select_dtypes(include=['object', 'bool']).columns)\nc_t = Pipeline(steps=[\n    ('ns', NameSplitter()),\n    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n    ('scaler', OrdinalEncoder())])\n\ncolumn_trans = ColumnTransformer( \n               transformers=[\n                ('num', n_t, numericals),\n                ('cat', c_t, categoricals)])\n\n#MLP\nmlp = MLP(hidden_layer_sizes= (5,), solver='adam', activation='relu',\n          learning_rate_init=0.1, learning_rate='adaptive',\n          max_iter=1000, batch_size=7000, early_stopping=True)\n\n#Setting up sequential feature selector\n\nsfs = SFS(estimator=mlp,\n          k_features =(1,(X_train.shape[1]+1)), \n          scoring='f1', \n          floating=True,\n          forward=False,\n          cv=5)\n\n#Setting Pipeline\npipe = Pipeline(steps=[\n                ('col_t', column_trans),\n                ('sfs', sfs),\n                ('mlp', mlp)])\n\n\n\n#Modeling\nmodel = pipe.fit(X_train, y_train)\nprint('Done')\nprint('Predicting')\nprint('Score is {}%'.format(accuracy_score(y_test, model.predict(X_test))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')\ntest = test.drop(['PassengerId', 'Ticket', 'Cabin'], axis=1)\ntest.info()\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_pred = test\n# Saving the result\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv')\nsubmission['Survived'] = model.predict(X_pred)\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}