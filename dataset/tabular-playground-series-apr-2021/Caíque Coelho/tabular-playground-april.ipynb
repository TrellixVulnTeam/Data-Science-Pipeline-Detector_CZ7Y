{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.feature_engineering_new.ex2 import *\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.feature_selection import mutual_info_regression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_titanic_path = '../input/tabular-playground-series-apr-2021/train.csv'\n# my_data = pd.read_csv(data_titanic_path, index_col='PassengerId')\nmy_data = pd.read_csv(data_titanic_path)\nmy_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_data = my_data.drop('Name', axis=1)\nmy_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_titanic_path_test = '../input/tabular-playground-series-apr-2021/test.csv'\n# my_data = pd.read_csv(data_titanic_path, index_col='PassengerId')\nmy_test_data = pd.read_csv(data_titanic_path_test)\nmy_test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_test_data = my_test_data.drop('Name', axis=1)\nmy_test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_data.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_test_data.isnull().values.any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_cols = my_data[my_data.columns].select_dtypes(exclude=['int64','float64']).columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get number of unique entries in each column with categorical data\nobject_nunique = list(map(lambda col: my_data[col].nunique(), categorical_cols))\nd = dict(zip(categorical_cols, object_nunique))\n\n# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport plotly.figure_factory as ff\n\nprimary_bgcolor = \"#f4f0ea\"\n\nle = LabelEncoder()\nle_data = my_data.copy().drop(columns=['PassengerId'])\n\npure_cat_cols = my_data[my_data.columns].select_dtypes(exclude=['int64','float64']).columns\nfor col in pure_cat_cols:\n    le.fit(le_data[col])\n    le_data[col] = le.transform(le_data[col])\n    #my_test_data[col] = le.transform(my_test_data[col])\n\ncorrdata = le_data\n\n## correlation \ncorr = corrdata.corr().abs()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\ncorr1 = corr.mask(mask)\n\nfig = ff.create_annotated_heatmap(\n    z=corr1.to_numpy().round(2),\n    x=list(corr1.index.values),\n    y=list(corr1.columns.values),       \n    xgap=3, ygap=3,\n    zmin=0, zmax=1,\n    colorscale='blugrn',\n    colorbar_thickness=30,\n    colorbar_ticklen=3,\n)\n\nfig.update_layout(\n    title_text='<span style=\"font-size:32px; font-family:Times New Roman\">Features Correlation Matrix</span>', \n    font_family=\"Serif\",\n    titlefont={'size': 24},\n    width=800, height=700,\n    xaxis_showgrid=False,\n    yaxis_showgrid=False,\n    yaxis_autorange='reversed', \n    paper_bgcolor=primary_bgcolor,\n    plot_bgcolor=primary_bgcolor,\n    margin=dict(l=70, r=70, t=70, b=70, pad=1),\n)\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"important_features = [\"Sex\", \"Pclass\", \"Embarked\", \"Fare\", \"Cabin\", \"Survived\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns that will be one-hot encoded\nlow_cardinality_cols = [col for col in categorical_cols if my_data[col].nunique() < 10]\n\n# Columns that will be dropped from the dataset\nhigh_cardinality_cols = list(set(categorical_cols)-set(low_cardinality_cols))\n\nprint('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\nprint('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nhigh_cardinality_cols_to_drop = ['Cabin', 'Ticket']\nmy_data = my_data.drop(high_cardinality_cols_to_drop, axis=1)\nmy_test_data = my_test_data.drop(high_cardinality_cols_to_drop, axis=1)\nle_data = my_data.copy().drop(columns=['PassengerId'])\n\nfor col in low_cardinality_cols:\n    le.fit(le_data[col])\n    le_data[col] = le.transform(le_data[col])\n    #my_test_data[col] = le.transform(my_test_data[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport plotly.figure_factory as ff\n\nprimary_bgcolor = \"#f4f0ea\"\n\ncorrdata = le_data\n\n## correlation \ncorr = corrdata.corr().abs()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\ncorr1 = corr.mask(mask)\n\nfig = ff.create_annotated_heatmap(\n    z=corr1.to_numpy().round(2),\n    x=list(corr1.index.values),\n    y=list(corr1.columns.values),       \n    xgap=3, ygap=3,\n    zmin=0, zmax=1,\n    colorscale='blugrn',\n    colorbar_thickness=30,\n    colorbar_ticklen=3,\n)\n\nfig.update_layout(\n    title_text='<span style=\"font-size:32px; font-family:Times New Roman\">Features Correlation Matrix</span>', \n    font_family=\"Serif\",\n    titlefont={'size': 24},\n    width=800, height=700,\n    xaxis_showgrid=False,\n    yaxis_showgrid=False,\n    yaxis_autorange='reversed', \n    paper_bgcolor=primary_bgcolor,\n    plot_bgcolor=primary_bgcolor,\n    margin=dict(l=70, r=70, t=70, b=70, pad=1),\n)\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get Correlation\nprint(le_data[le_data.columns].corrwith(le_data.Survived))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_import_features = ['Sex', 'Embarked', 'Pclass', 'Fare']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le_data[new_import_features].isnull().values.any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le_data_important_features = le_data[new_import_features]\n\ndict_null = {}\nfor col in new_import_features:\n    dict_null[col] = le_data_important_features[col].isnull().sum()\ndict_null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_my_data = my_data[['Pclass', 'Sex', 'Fare', 'Embarked']]\nnew_my_test = my_test_data[['Pclass', 'Sex', 'Fare', 'Embarked']]\ny = my_data['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_my_data = new_my_data.fillna(method='bfill', axis=0)\nnew_my_test = new_my_test.fillna(method='bfill', axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_categorical_cols = new_my_data[new_my_data.columns].select_dtypes(exclude=['int64','float64']).columns\nnew_categorical_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_my_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_my_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_my_test[new_import_features].isnull().values.any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_my_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(new_my_data[low_cardinality_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(new_my_test[low_cardinality_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = new_my_data.index\nOH_cols_valid.index = new_my_test.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = new_my_data.drop(new_categorical_cols, axis=1)\nnum_X_valid = new_my_test.drop(new_categorical_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OH_cols_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#le_data_without_null = le_data[new_import_features].dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#le_data_without_null.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#my_test_data = my_test_data[new_import_features]\n\n#dict_null = {}\n#for col in new_import_features:\n#    dict_null[col] = my_test_data[col].isnull().sum()\n#dict_null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = le_data.drop('Survived', axis=1).fillna(method='bfill', axis=0).copy()\n\nmi_scores = make_mi_scores(X, y)\nmi_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores.head(20))\n# plot_mi_scores(mi_scores.tail(20))  # uncomment to see bottom 20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nmy_pipeline = Pipeline(steps=[\n                              ('model', RandomForestRegressor(n_estimators=50,\n                                                              random_state=0))\n                             ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(OH_X_train))\nprint(len(y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(my_pipeline, OH_X_train, y,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"MAE scores:\\n\", scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestRegressor(n_estimators=50, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OH_X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(OH_X_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(OH_X_train, y)\n\n# Fill in the line below: get test predictions\npreds_test = model.predict(OH_X_valid)\n\n# Save test predictions to file\noutput = pd.DataFrame({'PassengerId': my_test_data.PassengerId,\n                       'Survived': preds_test})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}