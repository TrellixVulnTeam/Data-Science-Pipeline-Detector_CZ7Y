{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(palette='cubehelix',context='notebook',\n       font='cambria',style='white')\nimport missingno as msn\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport shap\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, train_test_split, KFold, StratifiedKFold\nfrom sklearn.ensemble import StackingClassifier\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import plot_precision_recall_curve\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Load\n------","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv').set_index('PassengerId')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv').set_index('PassengerId')\n\ncombined = pd.concat([train,test])\nmsn.matrix(combined.drop('Survived', axis=1), figsize=(8,5), fontsize=12)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA & Data Pre-Processing\n--------","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=3, figsize=(12,4))\n\nsns.kdeplot(x=train.Survived, hue=train.Pclass, ax=axes[0], fill=True)\nsns.kdeplot(x=train.Survived, hue=train.Sex,ax=axes[1], fill=True)\nsns.kdeplot(x=train.Survived, hue=train.Embarked,ax=axes[2], fill=True)\nsns.despine()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Filling nans","metadata":{}},{"cell_type":"code","source":"def alt_age(df)->pd.Series:\n    \n    for sex in df.Sex.unique():\n        for pc in df.Pclass.unique():\n            df.loc[(df.Pclass == pc) & (df.Sex == sex),'Age']=\\\n            df.loc[(df.Pclass == pc) & (df.Sex == sex),'Age'].fillna(\n            df[(df.Pclass == pc) & (df.Sex == sex)].Age.median())\n            \n    return df\n\ncombined = alt_age(combined)\n\nfig, axes = plt.subplots(ncols=2, figsize=(11,4))\n\nsns.histplot(x=train.Age, ax=axes[0],legend='Train',\n             kde=True, bins=20, edgecolor='darkgreen')\nsns.histplot(x=test.Age,ax=axes[1], legend='Test',\n             kde=True, bins=20, edgecolor='darkgreen')\nsns.despine()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def alt_fare(df)->pd.Series:\n    \n    for sex in df.Sex.unique():\n        for pc in df.Pclass.unique():\n            df.loc[(df.Pclass == pc) & (df.Sex == sex),'Fare']=\\\n            df.loc[(df.Pclass == pc) & (df.Sex == sex),'Fare'].fillna(\n            df[(df.Pclass == pc) & (df.Sex == sex)].Fare.median())\n            \n    return df\n\ncombined=alt_fare(combined)\n\nfig, axes = plt.subplots(ncols=2, figsize=(11,4), sharey=True)\n\nsns.kdeplot(x=train.Fare, ax=axes[0],label='Train',\n            fill=True,edgecolor='darkgreen')\nsns.kdeplot(x=test.Fare,ax=axes[1], label='Test',\n            fill=True,edgecolor='darkgreen')\nsns.despine()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fam_size(df)->pd.Series:\n    return df.SibSp+df.Parch+1\n\ndef is_mother(series)->pd.Series:\n    mask = series > 0\n    return np.where(mask,1,0)\n\ndef is_alone(series)->pd.Series:\n    mask= series > 0\n    return np.where(mask,1,0)\n\ndef ticket(series)->pd.Series:\n    return [str(i).split()[0] if len(str(i).split())>1 else 'N' \n     for i in series]\n\ndef fill_cabin(series)->pd.Series:\n    series = series.fillna('N')\n    return series.apply(lambda x: x[0][0])\n\ncombined['Famsize'] = fam_size(combined)\ncombined['IsMother'] = is_mother(combined['Parch'])\ncombined['IsAlone'] = is_alone(combined['SibSp'])\ncombined['Ticket'] = ticket(combined['Ticket'])\n#combined['Embarked']=combined['Embarked'].fillna(np.random.choice(['S','C','Q']))\ncombined['Embarked']=combined['Embarked'].fillna('ffill')\ncombined['Cabin'] = fill_cabin(combined['Cabin'])\n\ncombined = combined.drop(['Name','SibSp','Parch'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Selection\n------","metadata":{}},{"cell_type":"markdown","source":"#### Label Encoding & MinMax Scaling","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\nhot_encoder = OneHotEncoder()\n\nfor col in combined.select_dtypes('object'):\n    if col == 'Cabin':\n        combined = combined.join(pd.get_dummies(combined[col]))\n    else:\n        combined[col] = encoder.fit_transform(combined[col])\n\nscaler = MinMaxScaler()\n\ncombined[['Fare','Age','Famsize','Ticket','Pclass','Embarked']] = scaler.fit_transform(\n    combined[['Fare','Age','Famsize','Ticket','Pclass','Embarked']])\n\ncombined = combined.drop('Cabin',axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a_train = combined[combined.index.isin(train.index)]\na_target = a_train.pop('Survived')\nb_test = combined[combined.index.isin(test.index)]\nb_target = b_test.pop('Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Defining KFold Parameters","metadata":{}},{"cell_type":"code","source":"n_folds = 10\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### DecisionTree Classifier","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"scores = {}\n\nmod = ('DecisionTreeClassifier',DecisionTreeClassifier(random_state=42,\n            max_depth=10,min_samples_split=818, min_samples_leaf=35))\n\nacc_mean,roc_auc_score_mean,f1_mean = [],[],[]\ny_pred = 0\n\nfor fold,(train_index, valid_index) in enumerate(kf.split(a_train,a_target)):\n\n    X_train, X_valid = a_train.iloc[train_index], a_train.iloc[valid_index]\n    y_train, y_valid = a_target.iloc[train_index], a_target.iloc[valid_index]\n\n    model = mod[1]\n    model.fit(X_train, y_train) \n\n    preds = model.predict(X_valid)\n\n    acc = accuracy_score(y_valid, preds)\n    roc = roc_auc_score(y_valid,preds)\n    f1 = f1_score(y_valid,preds)\n\n    acc_mean.append(acc),roc_auc_score_mean.append(roc), f1_mean.append(f1)\n\n    y_pred += model.predict_proba(b_test)[:,1]\n    \ny_pred /= n_folds\n\nscores['accuracy score'] = np.mean(acc_mean)\nscores['roc auc score'] = np.mean(roc_auc_score_mean)\nscores['f1 score'] = np.mean(f1_mean)\n\npd.DataFrame([scores], index=[mod[0]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### CatBoost Classifier","metadata":{}},{"cell_type":"code","source":"scores = {}\n\nmod = ('CatBoostClassifier',CatBoostClassifier(random_state=42, verbose=False))\n\nacc_mean,roc_auc_score_mean,f1_mean = [],[],[]\ny_pred = 0\n\nfor fold,(train_index, valid_index) in enumerate(kf.split(a_train,a_target)):\n\n    X_train, X_valid = a_train.iloc[train_index], a_train.iloc[valid_index]\n    y_train, y_valid = a_target.iloc[train_index], a_target.iloc[valid_index]\n\n    model = mod[1]\n    model.fit(X_train, y_train) \n\n    preds = model.predict(X_valid)\n\n    acc = accuracy_score(y_valid, preds)\n    roc = roc_auc_score(y_valid,preds)\n    f1 = f1_score(y_valid,preds)\n\n    acc_mean.append(acc),roc_auc_score_mean.append(roc), f1_mean.append(f1)\n\n    y_pred += model.predict_proba(b_test)[:,1]\n    \ny_pred /= n_folds\n\nscores['accuracy score'] = np.mean(acc_mean)\nscores['roc auc score'] = np.mean(roc_auc_score_mean)\nscores['f1 score'] = np.mean(f1_mean)\n\npd.DataFrame([scores], index=[mod[0]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"scores = {}\n\nmod = ('XGBoost Classifier',XGBClassifier(random_state=42,\n    cv=5,n_estimator=40,verbosity=0,n_jobs=-1,learning_rate=.1))\n\nacc_mean,roc_auc_score_mean,f1_mean = [],[],[]\ny_pred = 0\n\nfor fold,(train_index, valid_index) in enumerate(kf.split(a_train,a_target)):\n\n    X_train, X_valid = a_train.iloc[train_index], a_train.iloc[valid_index]\n    y_train, y_valid = a_target.iloc[train_index], a_target.iloc[valid_index]\n\n    model = mod[1]\n    model.fit(X_train, y_train) \n\n    preds = model.predict(X_valid)\n\n    acc = accuracy_score(y_valid, preds)\n    roc = roc_auc_score(y_valid,preds)\n    f1 = f1_score(y_valid,preds)\n\n    acc_mean.append(acc),roc_auc_score_mean.append(roc), f1_mean.append(f1)\n\n    y_pred += model.predict_proba(b_test)[:,1]\n    \ny_pred /= n_folds\n\nscores['accuracy score'] = np.mean(acc_mean)\nscores['roc auc score'] = np.mean(roc_auc_score_mean)\nscores['f1 score'] = np.mean(f1_mean)\n\npd.DataFrame([scores], index=[mod[0]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### LGBM Classifier","metadata":{}},{"cell_type":"code","source":"scores = {}\n\nmod = ('LGBM Classifier',LGBMClassifier(random_state=42))\n\nacc_mean,roc_auc_score_mean,f1_mean = [],[],[]\ny_pred = 0\n\nfor fold,(train_index, valid_index) in enumerate(kf.split(a_train,a_target)):\n\n    X_train, X_valid = a_train.iloc[train_index], a_train.iloc[valid_index]\n    y_train, y_valid = a_target.iloc[train_index], a_target.iloc[valid_index]\n\n    model = mod[1]\n    model.fit(X_train, y_train) \n\n    preds = model.predict(X_valid)\n\n    acc = accuracy_score(y_valid, preds)\n    roc = roc_auc_score(y_valid,preds)\n    f1 = f1_score(y_valid,preds)\n\n    acc_mean.append(acc),roc_auc_score_mean.append(roc), f1_mean.append(f1)\n\n    y_pred += model.predict_proba(b_test)[:,1]\n    \ny_pred /= n_folds\n\nscores['accuracy score'] = np.mean(acc_mean)\nscores['roc auc score'] = np.mean(roc_auc_score_mean)\nscores['f1 score'] = np.mean(f1_mean)\n\npd.DataFrame([scores], index=[mod[0]])","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$\\implies$ LGBMClassifier has the best score.","metadata":{}},{"cell_type":"code","source":"## final prediction\n\ny_pred = np.where(y_pred>.5,1,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\n------","metadata":{}},{"cell_type":"code","source":"## makes a submission\n\nsubmission = pd.DataFrame({\n    'PassengerId':b_test.index,'Survived': y_pred})\n\nsubmission.to_csv(\n    'submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}