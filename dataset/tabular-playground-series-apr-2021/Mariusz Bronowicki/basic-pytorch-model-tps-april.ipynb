{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is my first attempt to build model using Pytorch library, so for some of you this might be too basic, but we are here to learn so there you go. Many thanks to Akshaj Verma for a  which helped me understand parts of Pytorch model architecture. https://towardsdatascience.com/pytorch-tabular-binary-classification-a0368da5bb89\n","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2021/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2021/test.csv\")\nsample_df = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop(\"PassengerId\", axis=1, inplace=True)\ntest_df.drop(\"PassengerId\", axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cabin_feat(df):\n    df[\"Cabin\"] = df[\"Cabin\"].fillna(\"None\")\n    df[\"has_Cabin\"] = df[\"Cabin\"].apply(lambda x: 1 if x != \"None\" else 0)\n    df[\"Deck\"] = df[\"Cabin\"].apply(lambda x: x[0])\n    df.drop(\"Cabin\", axis=1, inplace=True)\n    \ncabin_feat(train_df)\ncabin_feat(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fill_nan(df, group_col, col):\n    \"\"\"\n    This function fill nan values in given column \n    based on groupby column.\n    \"\"\"\n    mask_dict = df.groupby(group_col).mean()[col].to_dict()\n    missing_mask = df[col].isna()\n    df.loc[missing_mask, col] = df.loc[missing_mask, group_col].map(mask_dict)\n    \nfill_nan(train_df, \"Pclass\", \"Age\")\nfill_nan(test_df, \"Pclass\", \"Age\")\nfill_nan(train_df, \"Deck\", \"Fare\")\nfill_nan(test_df, \"Deck\", \"Fare\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def age_feat(x):\n    if x <= 5:\n        return \"baby\"\n    elif 5 < x <= 16:\n        return \"teen\"\n    elif 16 < x <= 30:\n        return \"yound_adult\"\n    elif 30 < x <= 50:\n        return \"adult\"\n    else:\n        return \"elder\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"Fare\"] = train_df[\"Fare\"].apply(lambda x: np.log(x) if x != 0 else 0)\ntest_df[\"Fare\"] = test_df[\"Fare\"].apply(lambda x: np.log(x) if x != 0 else 0)\n\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(train_df[\"Embarked\"].mode()[0])\ntest_df[\"Embarked\"] = test_df[\"Embarked\"].fillna(test_df[\"Embarked\"].mode()[0])\n\ntrain_df[\"Ticket\"] = train_df[\"Ticket\"].fillna(\"NAN\")\ntest_df[\"Ticket\"] = test_df[\"Ticket\"].fillna(\"NAN\")\ntrain_df[\"Ticket\"] = train_df[\"Ticket\"].apply(lambda x: str(x)[:2])\ntest_df[\"Ticket\"] = test_df[\"Ticket\"].apply(lambda x: str(x)[:2])\n\ntrain_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"]\ntest_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"]\n\ntrain_df[\"Name_length\"] = train_df[\"Name\"].apply(lambda x: len(x.split(\",\")[0] + x.split(\",\")[1].strip()))\ntest_df[\"Name_length\"] = test_df[\"Name\"].apply(lambda x: len(x.split(\",\")[0] + x.split(\",\")[1].strip()))\ntrain_df[\"Last_name\"] = train_df[\"Name\"].apply(lambda x: x.split(\",\")[0])\ntrain_df[\"First_name\"] = train_df[\"Name\"].apply(lambda x: x.split(\",\")[1].strip())\ntest_df[\"Last_name\"] = test_df[\"Name\"].apply(lambda x: x.split(\",\")[0])\ntest_df[\"First_name\"] = test_df[\"Name\"].apply(lambda x: x.split(\",\")[1].strip())\ntrain_df.drop(\"Name\", axis=1, inplace=True)\ntest_df.drop(\"Name\", axis=1, inplace=True)\n\ntrain_df[\"age_range\"] = train_df[\"Age\"].apply(age_feat)\ntest_df[\"age_range\"] = test_df[\"Age\"].apply(age_feat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc_cols = [col for col in train_df.select_dtypes(\"object\").columns]\n\ndef label_encoder():\n    for col in enc_cols:\n        le = LabelEncoder()\n        le.fit(train_df[col].values.tolist() + test_df[col].values.tolist())\n        train_df.loc[:, col] = le.transform(train_df[col].values)\n        test_df.loc[:, col] = le.transform(test_df[col].values)\n\nlabel_encoder()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5)\ntrain_df[\"kfold\"] = -1\n\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\n\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(X=train_df, y=train_df[\"Survived\"])):\n    train_df.loc[valid_idx, \"kfold\"] = fold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class binaryClassification(nn.Module):\n    def __init__(self):\n        super(binaryClassification, self).__init__()\n        \n        \n        # Number of input features is 15\n        self.layer_1 = nn.Linear(15, 64)\n        self.layer_2 = nn.Linear(64, 64)\n        self.layer_out = nn.Linear(64, 1)\n        \n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.1)\n        self.batchnorm1 = nn.BatchNorm1d(64)\n        self.batchnorm2 = nn.BatchNorm1d(64)\n        \n    def forward(self, inputs):\n        x = self.relu(self.layer_1(inputs))\n        x = self.batchnorm1(x)\n        x = self.relu(self.layer_2(x))\n        x = self.batchnorm2(x)\n        x = self.dropout(x)\n        x = self.layer_out(x)\n        \n        return x\n\n\n\nclass trainData(Dataset):\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n    \n    def __len__(self):\n        return len(self.X_data)\n    \nclass testData(Dataset):\n    \n    def __init__(self, X_data):\n        self.X_data = X_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index]\n    \n    def __len__(self):\n        return len(self.X_data)\n    \n    \n    \ndef binary_acc(y_pred, yvalid):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n    \n    correct_results_sum = (y_pred_tag == yvalid).sum().float()\n    acc = correct_results_sum / yvalid.shape[0]\n    acc = torch.round(acc * 100)\n    return acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 25\nBATCH_SIZE = 64\nLEARNING_RATE = 0.001","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(5):\n    train = train_df[train_df.kfold != fold].reset_index(drop=True)\n    valid = train_df[train_df.kfold == fold].reset_index(drop=True)\n    \n    xtrain = train.drop([\"Survived\", \"kfold\"], axis=1).values\n    xvalid = valid.drop([\"Survived\", \"kfold\"], axis=1).values\n    ytrain = train.Survived.values\n    yvalid = valid.Survived.values\n    \n    sc = StandardScaler()\n    xtrain = sc.fit_transform(xtrain)\n    xvalid = sc.transform(xvalid)\n    test_scaled = sc.transform(test_df)\n    \n    train_data = trainData(torch.FloatTensor(xtrain),\n                           torch.FloatTensor(ytrain))\n    \n    valid_data = testData(torch.FloatTensor(xvalid))\n    \n    train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE,\n                              shuffle=True)\n    valid_loader = DataLoader(dataset=valid_data, batch_size=1)\n    \n    model = binaryClassification()\n    model.to(device)\n    \n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    \n    model.train()\n    for e in range(EPOCHS +1):\n        epoch_loss = 0\n        epoch_acc = 0\n        for X_batch, y_batch in train_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            \n            y_pred = model(X_batch)\n            \n            loss = criterion(y_pred, y_batch.unsqueeze(1))\n            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n            \n            loss.backward()\n            optimizer.step()\n            \n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n            \n        print(f'Epoch {e+0:03}: | Loss:{epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')","metadata":{"_kg_hide-output":true,"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_list = []\n\nmodel.eval()\nwith torch.no_grad():\n    for X_batch in valid_loader:\n        X_batch = X_batch.to(device)\n        y_valid_pred = model(X_batch)\n        y_valid_pred = torch.sigmoid(y_valid_pred)\n        y_pred_tag = torch.round(y_valid_pred)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\n\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(yvalid, y_pred_list))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is lots to improve here so if you have any suggestions or you see some mistakes, leave feedback, any constractive criticism is welcome.","metadata":{}}]}