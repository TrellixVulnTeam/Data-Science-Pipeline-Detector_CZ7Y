{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the train and test datasets\n\ntrain_data = pd.read_csv(\"../input/tabular-playground-series-apr-2021/train.csv\")\ntest_data = pd.read_csv(\"../input/tabular-playground-series-apr-2021/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix\n\ncorrelation = train_data.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(correlation, annot=True)     \nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to process the train dataset\n\ndef preprocess_inputs(df):\n    \n    # Creating a copy of the dataframe \n    \n    df = df.copy()\n    \n    # Dropping columns with excessive missing values and unnecessary columns for cardinality\n    \n    df = df.drop([\"Cabin\", \"Name\", \"Ticket\"], axis=1)\n    \n    # Filling the missing values in Age and Fare columns with Median\n    \n    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median()) \n    df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median()) \n    \n    # Binary encoding for Sex column\n    \n    df[\"Sex\"] = df[\"Sex\"].replace({\"male\":\"0\", \"female\":\"1\"})\n    \n    # One-hot encoding the Embarked column\n    \n    dummies = pd.get_dummies(df[\"Embarked\"], prefix=\"embark\")\n    df = pd.concat([df,dummies], axis=1)\n    df = df.drop(\"Embarked\", axis=1)\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = preprocess_inputs(train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to process the train dataset\n\ndef preprocess_inputs_test(df):\n    \n    # Creating a copy of the dataframe \n    \n    df = df.copy()\n    \n    # Dropping columns with excessive missing values and unnecessary columns for cardinality\n    \n    df = df.drop([\"Cabin\", \"Name\", \"Ticket\"], axis=1)\n    \n    # Filling the missing values in Age and Fare columns with Median\n    \n    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median()) \n    df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median()) \n    \n    # Binary encoding for Sex column\n    \n    df[\"Sex\"] = df[\"Sex\"].replace({\"male\":\"0\", \"female\":\"1\"})\n    \n    # One-hot encoding the Embarked column\n    \n    dummies = pd.get_dummies(df[\"Embarked\"], prefix=\"embark\")\n    df = pd.concat([df,dummies], axis=1)\n    df = df.drop(\"Embarked\", axis=1)\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = preprocess_inputs_test(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the training set into X_train and y_train\n\nX_train = train.drop([\"Survived\"], axis=1)\ny_train = train[\"Survived\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modelling and fitting the data \n\nmodel = RandomForestClassifier()\nmodel.fit(X_train,y_train)   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction on the test set\n\ny_preds = model.predict(test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the NumPy array of y_preds to Series\n\ny_preds = pd.Series(y_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a submission file\n\nsub_df = pd.read_csv(\"../input/tabular-playground-series-apr-2021/sample_submission.csv\")\nsubmission = pd.concat([sub_df[\"PassengerId\"], y_preds], axis=1)\nsubmission.columns = [\"PassengerId\", \"Survived\"]\nsubmission.to_csv(\"Submission_colab_rf.csv\", index=False) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter tuning - to be done\n\nrf_grid = {\"n_estimators\": np.arange(10, 500, 50),\n           \"max_depth\": [None, 3, 5, 10],\n           \"min_samples_split\": np.arange(2, 20, 2),\n           \"min_samples_leaf\": np.arange(1, 20, 2)}\n\nrs_rf = RandomizedSearchCV(RandomForestClassifier(),\n                           param_distributions=rf_grid,\n                           cv=5,\n                           n_iter=20,\n                           verbose=True)\n\nrs_rf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_rf.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds_tuned = rs_rf.predict(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds_tuned = pd.Series(y_preds_tuned) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a submission file after tuning\n\nsub_df = pd.read_csv(\"../input/tabular-playground-series-apr-2021/sample_submission.csv\")\nsubmission = pd.concat([sub_df[\"PassengerId\"], y_preds_tuned], axis=1)\nsubmission.columns = [\"PassengerId\", \"Survived\"]\nsubmission.to_csv(\"Submission_rf_tuned.csv\", index=False) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}