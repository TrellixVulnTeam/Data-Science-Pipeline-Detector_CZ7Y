{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom category_encoders import LeaveOneOutEncoder\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom scipy import stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\nimport optuna","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"base_dir = \"../input/tabular-playground-series-apr-2021\"\nX_full = pd.read_csv(os.path.join(base_dir, \"train.csv\"))\nX_test = pd.read_csv(os.path.join(base_dir, \"test.csv\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Specify target","metadata":{}},{"cell_type":"code","source":"target = \"Survived\"\ny_full = X_full.pop(target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Categorical and Numerical features","metadata":{}},{"cell_type":"code","source":"cat_features = [col for col in X_full.columns if X_full[col].dtype in [\"object\", \"int\"]]\nnum_features = [col for col in X_full.columns if X_full[col].dtype in [\"float\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check cardinality of categorical features","metadata":{}},{"cell_type":"code","source":"X_full[cat_features].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check NaN","metadata":{}},{"cell_type":"code","source":"X_full.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remove \"PassengerId\", \"Name\", \"Ticket\" features","metadata":{}},{"cell_type":"code","source":"X_full.drop(['PassengerId','Name', 'Ticket'], inplace=True, axis=1)\nX_test.drop(['Name', 'Ticket'], inplace=True, axis=1)\nPassengerId = X_test.pop('PassengerId')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# \"Cabin\": Extract the first letter and fill NaN","metadata":{}},{"cell_type":"code","source":"X_full['Cabin'] = X_full['Cabin'].str[0]\nX_full['Cabin'] = X_full['Cabin'].fillna('N')\nX_test['Cabin'] = X_test['Cabin'].str[0]\nX_test['Cabin'] = X_test['Cabin'].fillna('N')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Update categorical and numerical features","metadata":{}},{"cell_type":"code","source":"cat_features = [col for col in X_full.columns if X_full[col].dtype in [\"object\", \"int\"]]\nnum_features = [col for col in X_full.columns if X_full[col].dtype in [\"float\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# Imputation\nnum_imputer = SimpleImputer(strategy='mean')\nnum_imputer.fit(X_full[num_features])\nX_full[num_features] = num_imputer.transform(X_full[num_features])\nX_test[num_features] = num_imputer.transform(X_test[num_features])\n\ncat_imputer = SimpleImputer(strategy='most_frequent')\ncat_imputer.fit(X_full[cat_features])\nX_full[cat_features] = cat_imputer.transform(X_full[cat_features])\nX_test[cat_features] = cat_imputer.transform(X_test[cat_features])\n\n# LabelEncoder or LeaveOneOutEncoder cat_features\nfor feature in cat_features:\n    #le = LabelEncoder()\n    #le.fit(X_full[feature])\n    #X_full[feature] = le.transform(X_full[feature])\n    #X_test[feature] = le.transform(X_test[feature])\n    loo = LeaveOneOutEncoder()\n    loo.fit(X_full[feature], y_full)\n    X_full[feature] = loo.transform(X_full[feature])\n    X_test[feature] = loo.transform(X_test[feature])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make some EDA plots","metadata":{}},{"cell_type":"code","source":"eda_features = num_features + cat_features\nn = len(eda_features)\nnc = 3\nnr = int(n/nc+1)\n\nfig, axes = plt.subplots(nrows=nr, ncols=nc, figsize=(18,4*nr))\n\nfor count, feature in enumerate(eda_features):\n    ks_score = stats.ks_2samp(X_full[feature], X_test[feature])[0]\n    i, j = count//nc, count%nc\n    sns.kdeplot(X_full[feature], color='Blue', ax=axes[i, j])\n    sns.kdeplot(X_test[feature], color='Red', ax=axes[i, j])\n\n    axes[i, j].legend([\"Train\", \"Test\"], facecolor=\"White\")\n    axes[i, j].set_title(f\"{feature} ks stat : {np.round(ks_score,3)}\")\n\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Specify features to use","metadata":{}},{"cell_type":"code","source":"my_features = num_features + cat_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_full[my_features].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna hyperparameter optimization","metadata":{}},{"cell_type":"code","source":"def objective(trial, data=X_full[my_features], target=y_full):\n    seed = 2021\n    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n\n    for train_index, valid_index in split.split(X_full[my_features], y_full):\n        X_train = X_full[my_features].iloc[train_index]\n        y_train = y_full.iloc[train_index]\n        X_valid = X_full[my_features].iloc[valid_index]\n        y_valid = y_full.iloc[valid_index]\n\n\n    lgbm_params = {\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 11, 333),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth': trial.suggest_int('max_depth', 5, 30),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.005, 0.01, 0.02, 0.05, 0.1]),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.5),\n        'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n        'random_state': seed,\n        'boosting_type': 'gbdt',\n        'metric': 'binary_logloss',\n        #'device': 'gpu'\n    }\n    \n\n    model = LGBMClassifier(**lgbm_params)  \n    \n    model.fit(\n            X_train,\n            y_train,\n            early_stopping_rounds=100,\n            eval_set=[(X_valid, y_valid)],\n            verbose=False\n        )\n\n    y_valid_pred = model.predict(X_valid)\n    \n    acc_score = accuracy_score(y_valid, y_valid_pred)\n    \n    return acc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 20)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best value:', study.best_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fit model with Optuna best parameters","metadata":{}},{"cell_type":"code","source":"seed = 2021\nparamsLGBM = study.best_trial.params\nparamsLGBM['boosting_type'] = 'gbdt'\nparamsLGBM['metric'] = 'binary_logloss'\nparamsLGBM['random_state'] = seed\n\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\nfor train_index, valid_index in split.split(X_full[my_features], y_full):\n    X_train = X_full[my_features].iloc[train_index]\n    y_train = y_full.iloc[train_index]\n    X_valid = X_full[my_features].iloc[valid_index]\n    y_valid = y_full.iloc[valid_index]\n\n\nlgbm_clf = LGBMClassifier(**paramsLGBM)\n#lgbm_clf.fit(X_train[my_features], y_train, \n#             early_stopping_rounds=100, \n#             eval_set=[(X_valid, y_valid)], \n#             verbose=False)\n\n# no eval_set or early_stopping\nlgbm_clf.fit(X_full[my_features], y_full, verbose=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make predictions","metadata":{}},{"cell_type":"code","source":"test_preds = lgbm_clf.predict(X_test[my_features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save predictions to file","metadata":{}},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': PassengerId,\n                       target: test_preds})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}