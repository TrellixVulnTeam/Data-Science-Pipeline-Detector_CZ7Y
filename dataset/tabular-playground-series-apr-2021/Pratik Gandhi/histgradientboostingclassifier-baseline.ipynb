{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the data:\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')\nsubmsn = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling the missing values:\ntest['Age'].fillna((train['Age'].mean()), inplace=True)\ntrain['Age'].fillna((train['Age'].mean()), inplace=True)\ntest['Fare'].fillna((train['Fare'].mean()), inplace=True)\ntrain['Fare'].fillna((train['Fare'].mean()), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping some columns:\ntrain.drop(['Name','Ticket','Cabin'], axis=1, inplace=True)\ntest.drop(['Name','Ticket','Cabin'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Label Encoder:\nobj_cols = train.select_dtypes(include=['object']).columns.tolist()\nfor col in obj_cols:\n    le = LabelEncoder()\n    le.fit(train[col])\n    train[col] = le.transform(train[col])\n    test[col] = le.transform(test[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the columns and target:\ncols = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\ntarget = train.Survived.values\n\n# Fitting the model\nmodel = HistGradientBoostingClassifier()\nmodel.fit(train[cols], target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the score for train data:\nroc_auc_score(target, model.predict_proba(train[cols])[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the predictions for test data:\nsubmsn['Survived'] = model.predict(test[cols])\nsubmsn.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}