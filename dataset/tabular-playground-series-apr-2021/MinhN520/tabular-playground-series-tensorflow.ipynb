{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nsns.set_style('whitegrid')\nplt.style.use('fivethirtyeight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the data\ntrain = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the data\nprint(train.shape)\nprint()\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for NULL\ntrain.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill NaN with mean value\ntrain['Age'] = train['Age'].fillna(train['Age'].mean())\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill NaN with mean values\ntrain['Fare'] = train['Fare'].fillna(train['Fare'].mean())\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill NaN for Embarked column to the most frequent value in the column\ntrain['Embarked'] = train['Embarked'].fillna(train['Embarked'].value_counts().index[0])\ntrain.Embarked.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get first character of Cabin\ntrain['Cabin'] = train['Cabin'].str[0]\n\n# fill NaN to the most frequent value in the column\ntrain['Cabin'] = train['Cabin'].fillna(train['Cabin'].value_counts().index[0])\ntrain.Cabin.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# identify feature columns and label column\nX = train.copy().drop(columns=['PassengerId', 'Name', 'Ticket'])\ny = X.pop('Survived')\nX","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label encoding for categoricals\nfor colname in X.select_dtypes('object'):\n    X[colname], _ = X[colname].factorize()\n\n    \n# All discrete features should now have integer dtypes (double-check this before using MI!)\ndiscrete_features = X.dtypes == int","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate MI scores for our features\nfrom sklearn.feature_selection import mutual_info_regression\n\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X, y, discrete_features)\nmi_scores[::3]  # show a few features with their MI scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n\n\nplt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.copy().drop(columns=['PassengerId', 'Name', 'Ticket', 'Parch', 'Age', 'SibSp'])\ny = X.pop('Survived')\n\n# Label encoding for categoricals\nfor colname in X.select_dtypes('object'):\n    X[colname], _ = X[colname].factorize()\n\n    \nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX = scaler.fit_transform(X)\n\nrescaledX","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"survived_class = [1, 0]\n\nfeatures = ['Sex','Pclass', 'Fare', 'Embarked', 'Cabin']\nlabel = 'Survived'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\n# Split data 70%-30% into training set and test set\nx_train, x_test, y_train, y_test = train_test_split(rescaledX,\n                                                    y,\n                                                    test_size=0.30,\n                                                    random_state=42)\n\nprint ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set data types for float features\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\n# Set data types for f labels\ny_train = np.asarray(y_train).reshape((-1,1))\ny_test = np.asarray(y_test).reshape((-1,1))\n\nprint('Ready...')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow import keras\nfrom tensorflow.keras import models\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import utils\nfrom tensorflow.keras import optimizers\n\n# Set random seed for reproducability\ntensorflow.random.set_seed(0)\n\nprint(\"Libraries imported.\")\nprint('Keras version:',keras.__version__)\nprint('TensorFlow version:',tensorflow.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a classifier network\nhl = 10 # Number of hidden layer nodes\n\nmodel = Sequential()\nmodel.add(Dense(hl, input_dim=len(features), activation='relu'))\nmodel.add(Dense(hl, input_dim=hl, activation='relu'))\nmodel.add(Dense(1, input_dim=hl, activation='sigmoid'))\n\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyper-parameters for optimizer\nlearning_rate = 0.001\nopt = optimizers.Adam(lr=learning_rate)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\n# Train the model over 50 epochs using 10-observation batches and using the test holdout dataset for validation\nnum_epochs = 50\nhistory = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nepoch_nums = range(1,num_epochs+1)\ntraining_loss = history.history[\"loss\"]\nvalidation_loss = history.history[\"val_loss\"]\nplt.plot(epoch_nums, training_loss)\nplt.plot(epoch_nums, validation_loss)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['training', 'validation'], loc='upper right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_probabilities = model.predict(x_test)\npredictions = np.where(class_probabilities > 0.5, 1, 0) #np.argmax(class_probabilities, axis=1)\n\ntrue_labels = y_test #np.argmax(y_test, axis=1)\ncm = confusion_matrix(true_labels, predictions)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (np.arange(2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nclass_probabilities = model.predict(x_test)\npredictions = np.where(class_probabilities > 0.5, 1, 0)  # np.argmax(class_probabilities, axis=1)\ntrue_labels = y_test  # np.argmax(y_test, axis=1)\n\n# Plot the confusion matrix\ncm = confusion_matrix(true_labels, predictions)\nplt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\nplt.colorbar()\ntick_marks = np.arange(2)\nplt.xticks(tick_marks,  rotation=85)\nplt.yticks(tick_marks)\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill NaN with mean value\ntest['Age'] = test['Age'].fillna(test['Age'].mean())\n\n# fill NaN with mean values\ntest['Fare'] = test['Fare'].fillna(test['Fare'].mean())\n\n# fill NaN for Embarked column to the most frequent value in the column\ntest['Embarked'] = test['Embarked'].fillna(test['Embarked'].value_counts().index[0])\n\n# convert Sex (male/female) to 1 and 0\ntest['Sex'] = test.Sex.astype('category').cat.codes\n\n# convert Embarked (S,C,Q) to numbers (2,0,1) respectively\ntest['Embarked'] = test.Embarked.astype('category').cat.codes\n\n\n# get first character of Cabin\ntrain['Cabin'] = train['Cabin'].str[0]\n# fill NaN to the most frequent value in the column\ntrain['Cabin'] = train['Cabin'].fillna(train['Cabin'].value_counts().index[0])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label encoding for categoricals\nfor colname in test.select_dtypes('object'):\n    test[colname], _ = test[colname].factorize()\n    \ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_file = test.drop(columns=['PassengerId', 'Name', 'Ticket', 'Parch', 'Age', 'SibSp'], axis=1)\n\nrescaled_test = scaler.fit_transform(test_file)\nrescaled_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for null\ntest.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = model.predict(rescaled_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the probability to 0 and 1\nfinal_predictions = np.where(final_predictions > 0.5, 1, 0).reshape(-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_zeros = (final_predictions == 0).sum()\nnum_ones = (final_predictions == 1).sum()\nprint (num_zeros)\nprint (num_ones)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': final_predictions})\noutput.groupby('Survived').count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': final_predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}