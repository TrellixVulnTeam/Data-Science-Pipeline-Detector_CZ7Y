{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries and load data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.impute import SimpleImputer\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.utils import resample\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import VotingClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ntest_data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split train data in training - validation (80 - 20)\ntrain_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=111)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory analysis","metadata":{}},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# generate new cols\ntrain_data['Alone'] = 0\ntrain_data.loc[(train_data['SibSp']==0) & (train_data['Parch']==0), 'Alone'] = 1\n\ntrain_data['Woman_or_child'] = 0\ntrain_data.loc[(train_data['Sex']=='female') | (train_data['Age']<14), 'Woman_or_child'] = 1\n\ntrain_data['Family_size'] = train_data['Parch'] + train_data['SibSp']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform cabin column (replace nan with ' ' and remove the numbers)\ntrain_data['Cabin_letter'] = train_data['Cabin'].replace(np.nan, ' ').map(lambda x: x[0])\ntrain_data.drop('Cabin', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# group age: children 0-14, youth 14-25, adults 25-64, seniors 65-...\ndef categorize_age(age):\n    if age < 14:\n        return 0\n    elif age < 25:\n        return 1\n    elif age < 65:\n        return 2\n    else:\n        return 3\n\ntrain_data['Age_category'] = train_data['Age'].apply(lambda x: categorize_age(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# group fare: 0-10, 10-25, 25-40, 40-...\ndef categorize_fare(fare):\n    if fare < 10:\n        return 0\n    elif fare < 25:\n        return 1\n    elif fare < 40:\n        return 2\n    else:\n        return 3\n\ntrain_data['Fare_category'] = train_data['Fare'].apply(lambda x: categorize_fare(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# has or not a ticket\nmask = train_data['Ticket'].isna()\ntrain_data['Ticket'] = 1\ntrain_data.loc[mask, 'Ticket'] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create feature old person with family\ntrain_data['Old_with_family'] = 0\ntrain_data.loc[(train_data['Age_category']==3) & (train_data['Alone']==0), 'Old_with_family'] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data visualization","metadata":{}},{"cell_type":"code","source":"categorical_ordinal_cols = ['Pclass', \n                    'Sex', \n                    'SibSp', \n                    'Parch', \n                    'Cabin_letter', \n                    'Embarked', \n                    'Woman_or_child',\n                    'Fare_category',\n                    'Alone',\n                    'Age_category',\n                    'Ticket',\n                    'Old_with_family'\n#                     'Family_size'\n                   ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in categorical_ordinal_cols:\n    grouped = train_data.groupby(['Survived', col]).count().reset_index()\n    for row in grouped.index:  # get the probabilities\n        pos = grouped.loc[row, col]\n        grouped.loc[row, 'PassengerId'] /= train_data[col].value_counts().loc[pos]\n        \n    width = 0.35\n\n    fig, ax = plt.subplots()\n\n    ax.bar(x=np.arange(len(grouped[col].unique())) - width/2,\n            height=grouped[grouped['Survived']==0]['PassengerId'],\n            width=width,\n            label='No Survived')\n    ax.bar(x=np.arange(len(grouped[col].unique())) + width/2, \n            height=grouped[grouped['Survived']==1]['PassengerId'],\n            width=width,\n            label='Survived')\n\n    ax.set_xticks(np.arange(len(grouped[col].unique())))\n    ax.set_xticklabels(list(grouped[col].unique()))\n    ax.set_title(f'Survival % based on {col}')\n    ax.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- People in first class have a higher chance of survival.\n- Females have a higher chance of survival.\n- The number of siblings/spouses doesn't seem to have a big impact on the survival probability.\n- The number of parents/children seems to have a little impact.\n- The cabin type has an impact on the survival rate.\n- People embarked in C have a higher chance of survival.\n- Women and children have a higher chance of survival.\n- Fare category seems to have an impact on the classification.\n- Being alone or not doesn´t have much impact on the survival rate.\n- The age category doesn´t seem to have a big impact on the classification, as well as having ticket or not and being old with family onboard or not.\n","metadata":{}},{"cell_type":"code","source":"continue_cols = ['Age', 'Fare']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in continue_cols:\n    fig, ax = plt.subplots()\n    ax.hist(train_data[train_data['Survived']==0][col],\n            alpha=0.6,\n           label='No Survived')\n    ax.hist(train_data[train_data['Survived']==1][col],\n            alpha=0.6,\n           label='Survived')\n    ax.set_title(col)\n    ax.legend()\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- It seems that babies/children and people between 20 and 40 had a higher rate of non survival.\n- People that paid a higher fare seem to have a higher chance of survival.","metadata":{}},{"cell_type":"markdown","source":"# More preprocessing","metadata":{}},{"cell_type":"code","source":"# let's drop irrelevant columns\ntrain_data.drop(['PassengerId', 'Name'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split data and labels\nX_train = train_data.drop('Survived', axis=1)\ny_train = train_data['Survived']\n\nX_val = validation_data.drop('Survived', axis=1)\ny_val = validation_data['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace nan\nimp_most_freq = SimpleImputer(strategy='most_frequent')\n\ncols_most_freq = ['Embarked']\n\nX_train[cols_most_freq] = imp_most_freq.fit_transform(X_train[cols_most_freq])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode categorical values\nsex_enc = OrdinalEncoder()\ncabin_enc = OrdinalEncoder()\nembarked_enc = OrdinalEncoder()\n\nX_train['Sex'] = sex_enc.fit_transform(X_train[['Sex']])\nX_train['Cabin_letter'] = cabin_enc.fit_transform(X_train[['Cabin_letter']])\nX_train['Embarked'] = embarked_enc.fit_transform(X_train[['Embarked']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imputation with knn\nimputer = KNNImputer()\ncols = X_train.columns\nX_train = imputer.fit_transform(X_train)\nX_train = pd.DataFrame(X_train, columns=cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize\nscaler = MinMaxScaler()\n\ncols = X_train.columns\nX_train = scaler.fit_transform(X_train)\nX_train = pd.DataFrame(X_train, columns=cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look for outliers\niso = IsolationForest(contamination=0.05, random_state=111).fit(X_train)\n\noutliers = iso.predict(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove outliers\nmask = outliers != -1\nX_train, y_train = X_train[mask], y_train[mask]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# balance classes (downsampling)\ntrain_data = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\nsurvived = train_data[train_data['Survived']==1]\nno_survived = train_data[train_data['Survived']==0]\nno_survived_downsampled = resample(no_survived,\n                                   replace=False,\n                                   n_samples=len(survived),\n                                   random_state=111\n                                  )\n\ntrain_data = pd.concat([no_survived_downsampled, survived]).reset_index(drop=True)\n\nX_train = train_data.drop('Survived', axis=1)\ny_train = train_data['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_data(X, fit):\n    \n    # drop columns\n    X.drop(['PassengerId', 'Name'], axis=1, inplace=True)\n    # add cols\n    X['Alone'] = 0\n    X.loc[(X['SibSp']==0) & (X['Parch']==0), 'Alone'] = 1\n    X['Woman_or_child'] = 0\n    X.loc[(X['Sex']=='female') | (X['Age']<14), 'Woman_or_child'] = 1\n    X['Family_size'] = X['Parch'] + X['SibSp']\n    # tranform cabin data\n    X['Cabin_letter'] = X['Cabin'].replace(np.nan, ' ').map(lambda x: x[0])\n    X.drop('Cabin', axis=1, inplace=True)\n    # categorize age\n    X['Age_category'] = X['Age'].apply(lambda x: categorize_age(x))\n    # categorize fare\n    X['Fare_category'] = X['Fare'].apply(lambda x: categorize_fare(x))\n    # ticket transform\n    mask = X['Ticket'].isna()\n    X['Ticket'] = 1\n    X.loc[mask, 'Ticket'] = 0\n    # old with family\n    X['Old_with_family'] = 0\n    X.loc[(X['Age_category']==3) & (X['Alone']==0), 'Old_with_family'] = 1\n    # imputation most freq\n    imp_most_freq = SimpleImputer(strategy='most_frequent')\n    X[cols_most_freq] = imp_most_freq.fit_transform(X[cols_most_freq])\n    # encode categorical\n    if fit:\n        X['Sex'] = sex_enc.fit_transform(X[['Sex']])\n        X['Cabin_letter'] = cabin_enc.fit_transform(X[['Cabin_letter']])\n        X['Embarked'] = embarked_enc.fit_transform(X[['Embarked']])\n    else:\n        X['Sex'] = sex_enc.transform(X[['Sex']])\n        X['Cabin_letter'] = cabin_enc.transform(X[['Cabin_letter']])\n        X['Embarked'] = embarked_enc.transform(X[['Embarked']])\n    # imput knn\n    if fit:\n        X = imputer.fit_transform(X)\n    else:\n        X = imputer.transform(X)\n    # scaling\n    if fit:\n        X = scaler.fit_transform(X)\n    else:\n        X = scaler.transform(X)\n    X = pd.DataFrame(X, columns=cols)\n    \n    return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform validation data\nX_val = transform_data(X_val, fit=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature selection\nmodel = CatBoostClassifier(iterations=500,\n                            depth=6,\n                            verbose=False,\n                           random_state=111\n                           )\nmodel.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in zip(X_train.columns, model.feature_importances_):\n    print(i[0],':', i[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.drop(['SibSp', 'Parch', 'Ticket', 'Alone', 'Age_category', 'Fare_category', 'Old_with_family'], axis=1, inplace=True)\nX_val.drop(['SibSp', 'Parch', 'Ticket', 'Alone', 'Age_category', 'Fare_category', 'Old_with_family'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"# linear discriminant\nld_clf = LinearDiscriminantAnalysis()\nld_clf.fit(X_train, y_train)\n\nprint(\"TRAIN Accuracy linear discriminant:\", ld_clf.score(X_train, y_train))\nprint(\"VALIDATION Accuracy linear discriminant:\", ld_clf.score(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random forest\nmodel = RandomForestClassifier(n_jobs=-1, random_state=111)\nparams = {\n    'n_estimators': [300, 500, 700],\n    'max_depth': [5, 10, 15],\n    'min_samples_split': [32,64],\n    'min_samples_leaf': [10,15]\n}\nrf_clf = GridSearchCV(model, params, cv=3)\nrf_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best parameters:\", rf_clf.best_params_)\nprint(\"TRAIN Accuracy random forest:\", rf_clf.score(X_train, y_train))\nprint(\"VALIDATION Accuracy random forest:\", rf_clf.score(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# knn\nmodel = KNeighborsClassifier()\nparams = {\n    'n_neighbors': [11, 13, 15, 17]\n}\nknn_clf = GridSearchCV(model, params, cv=3)\nknn_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best parameters:\", knn_clf.best_params_)\nprint(\"TRAIN Accuracy KNN:\", knn_clf.score(X_train, y_train))\nprint(\"VALIDATION Accuracy KNN:\", knn_clf.score(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost\nmodel = xgb.XGBClassifier(use_label_encoder=False, verbosity=0, eta=0.1, seed=111)\nparams = {\n    'gamma': [0.5, 1, 3],\n    'max_depth': [3, 5],\n    'n_estimators': [150, 200, 300]\n}\nxgb_clf = GridSearchCV(model, params, cv=3)\nxgb_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best parameters:\", xgb_clf.best_params_)\nprint(\"TRAIN Accuracy XGBoost:\", xgb_clf.score(X_train, y_train))\nprint(\"VALIDATION Accuracy XGBoost:\", xgb_clf.score(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# neural network\nmodel = MLPClassifier(random_state=111)\nparams = {\n    'hidden_layer_sizes': [(32,32), (64,64)],\n    'learning_rate_init': [0.001, 0.01, 0.1]\n}\nmlp_clf = GridSearchCV(model, params, cv=3)\nmlp_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best parameters:\", mlp_clf.best_params_)\nprint(\"TRAIN Accuracy MLP:\", mlp_clf.score(X_train, y_train))\nprint(\"VALIDATION Accuracy MLP:\", mlp_clf.score(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# catboost\nmodel = CatBoostClassifier(verbose=False, random_state=111)\nparams = {\n    'iterations': [100, 200, 300],\n    'eta': [1, 0.1, 0.01],\n    'depth': [3, 4, 6]\n}\ncb_clf = GridSearchCV(model, params, cv=3)\ncb_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best parameters:\", cb_clf.best_params_)\nprint(\"TRAIN Accuracy CatBoost:\", cb_clf.score(X_train, y_train))\nprint(\"VALIDATION Accuracy CatBoost:\", cb_clf.score(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_clf2 = RandomForestClassifier(n_jobs=-1, random_state=111,\n                                 n_estimators=rf_clf.best_params_['n_estimators'],\n                                 max_depth=rf_clf.best_params_['max_depth'],\n                                 min_samples_split=rf_clf.best_params_['min_samples_split'],\n                                 min_samples_leaf=rf_clf.best_params_['min_samples_leaf']\n                                )\nxgb_clf2 = xgb.XGBClassifier(use_label_encoder=False, verbosity=0, eta=0.1, seed=111,\n                             n_estimators=xgb_clf.best_params_['n_estimators'],\n                             gamma=xgb_clf.best_params_['gamma'],\n                             max_depth=xgb_clf.best_params_['max_depth']\n                            )\nmlp_clf2 = MLPClassifier(random_state=111,\n                         hidden_layer_sizes=mlp_clf.best_params_['hidden_layer_sizes'],\n                         learning_rate_init=mlp_clf.best_params_['learning_rate_init']\n                        )\ncb_clf2 = CatBoostClassifier(verbose=False, random_state=111,\n                             iterations=cb_clf.best_params_['iterations'],\n                             eta=cb_clf.best_params_['eta'],\n                             depth=cb_clf.best_params_['depth']\n                            )\nensemble_clf = VotingClassifier(\n    estimators=[('rf',rf_clf2), ('xgb',xgb_clf2), ('mlp',mlp_clf2), ('cb', cb_clf2)],\n    voting='soft'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TRAIN Accuracy ensemble:\", ensemble_clf.score(X_train, y_train))\nprint(\"VALIDATION Accuracy ensemble:\", ensemble_clf.score(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training with all data","metadata":{}},{"cell_type":"code","source":"pas_id = test_data['PassengerId']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\n# split labels\nX_train = train_data.drop('Survived', axis=1)\ny_train = train_data['Survived']\n# transform data\nX_train = transform_data(X_train, fit=True)\ntest_data = transform_data(test_data, fit=False)\n# remove outliers\niso = IsolationForest(contamination=0.05, random_state=111).fit(X_train)\noutliers = iso.predict(X_train)\nmask = outliers != -1\nX_train, y_train = X_train[mask], y_train[mask]\n# downsampling\ntrain_data = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\nsurvived = train_data[train_data['Survived']==1]\nno_survived = train_data[train_data['Survived']==0]\nno_survived_downsampled = resample(no_survived,\n                                   replace=False,\n                                   n_samples=len(survived),\n                                   random_state=111\n                                  )\n\ntrain_data = pd.concat([no_survived_downsampled, survived]).reset_index(drop=True)\nX_train = train_data.drop('Survived', axis=1)\ny_train = train_data['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.drop(['SibSp', 'Parch', 'Ticket', 'Alone', 'Age_category', 'Fare_category', 'Old_with_family'], axis=1, inplace=True)\ntest_data.drop(['SibSp', 'Parch', 'Ticket', 'Alone', 'Age_category', 'Fare_category', 'Old_with_family'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_clf2 = RandomForestClassifier(n_jobs=-1, random_state=111,\n                                 n_estimators=rf_clf.best_params_['n_estimators'],\n                                 max_depth=rf_clf.best_params_['max_depth'],\n                                 min_samples_split=rf_clf.best_params_['min_samples_split'],\n                                 min_samples_leaf=rf_clf.best_params_['min_samples_leaf']\n                                )\nxgb_clf2 = xgb.XGBClassifier(use_label_encoder=False, verbosity=0, eta=0.1, seed=111,\n                             n_estimators=xgb_clf.best_params_['n_estimators'],\n                             gamma=xgb_clf.best_params_['gamma'],\n                             max_depth=xgb_clf.best_params_['max_depth']\n                            )\nmlp_clf2 = MLPClassifier(random_state=111,\n                         hidden_layer_sizes=mlp_clf.best_params_['hidden_layer_sizes'],\n                         learning_rate_init=mlp_clf.best_params_['learning_rate_init']\n                        )\ncb_clf2 = CatBoostClassifier(verbose=False, random_state=111,\n                             iterations=cb_clf.best_params_['iterations'],\n                             eta=cb_clf.best_params_['eta'],\n                             depth=cb_clf.best_params_['depth']\n                            )\nensemble_clf = VotingClassifier(\n    estimators=[('rf',rf_clf2), ('xgb',xgb_clf2), ('mlp',mlp_clf2), ('cb', cb_clf2)],\n    voting='soft'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = ensemble_clf.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_results = pd.DataFrame()\nfinal_results['PassengerId'] = pas_id\nfinal_results['Survived'] = pred\nfinal_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_results.to_csv('results.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}