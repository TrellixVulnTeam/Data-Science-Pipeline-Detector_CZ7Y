{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **April Tabular Playground Series - Your Baseline Model**\n\nIt is extremely important to start somewhere and identify it as your first standard of comparision against the progress you have. This notebook helps you make a baseline model , get a baseline score . Once you get the hold of this , do try and increase your score from here by either adding more features, trying more number of classification models, adding parameters to some of the already given models,etc , etc.\n\nShall we get started then ?\n\nAlright , in case you forgot , these are the variables in the dataset : \n### **Variable Notes**\n\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc√©s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","metadata":{}},{"cell_type":"markdown","source":"# **Importing Libraries**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import KNNImputer\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import StackingClassifier\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading the Data**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Deciding what to impute , drop and how ?**\n  \n  **ft : NaN Values**","metadata":{}},{"cell_type":"code","source":"for i in data.columns:\n    print(i,\":\",data[str(i)].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Alright so let's list out the columns holding Numerical Values :\n\n1. Age\n2. Fare\n\nThe remaining columns do not hold numerical values. \n\nLet's explore the distribution of the numerical values a bit before we replace their NaN values","metadata":{}},{"cell_type":"markdown","source":"# **Studying Distribution of Age and Fare**\n\n**What are we looking for ?**\n\nWe are looking for a possible metric for imputation. We will choose median if the data has a lot of large numerical values (as they tend to influence the central tendencies like mean and range but not median and IQR) and mean otherwise or neither and use some other tool.\n","metadata":{}},{"cell_type":"markdown","source":"## **Fare**","metadata":{}},{"cell_type":"code","source":"figure , axes = plt.subplots(ncols = 3 , figsize = (17,4) , dpi = 100)\n\nsns.boxplot(x = 'Fare' , data = data , color = 'red' , ax = axes[0])\nsns.distplot(x = data['Fare'] , ax = axes[1])\nsns.distplot(x = data['Fare'].apply(np.log) , ax = axes[2])\n\nfor i in range(3):\n    axes[i].set_ylabel('')\n    axes[i].set_xlabel('Fare')\n    axes[i].tick_params(axis='x', labelsize=10)\n    axes[i].tick_params(axis='y', labelsize=10)\n\naxes[0].set_title('Descriptive Statistics For Fare', fontsize=13)\naxes[1].set_title('Distribution (Fare)', fontsize=13)\naxes[2].set_title('Logarithmic Distribution (Fare)', fontsize=13)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the boxplot , we can see that anything above 100 looks like an outlier and that there are a lot of outliers. The suggested median seems to be somewhere between 0-100. \n\nThe Distribution Plot (right now we are assuming that we have a normal distribution) suggests that the data is left skewed. We could also deduce it from the boxplot as the data seems to be centered around values between 0-100 , and the rest is a tail of outliers. \n\nUpon taking a closer look using the function log , we can see that my assumption of thinking of fare as a normal distribution was wrong. We can clearly see three different peaks in the distribution (Logarithmic Distribution). This also matches with the the fact that our data has three classes and hence one can assume that these three peaks are a result of price distribution on those three classes.\n\nWill mean be an accurate way to go about it or median for that instance ?","metadata":{}},{"cell_type":"markdown","source":"## **Let's explore the fares of each classes!**\n\n**Assumption** : Distribution is multimodal only because of different classes.","metadata":{}},{"cell_type":"code","source":"firstclass = data[data['Pclass'] == 1]\nsecondclass = data[data['Pclass'] == 2]\nthirdclass = data[data['Pclass'] == 3]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **First Class Fare**","metadata":{}},{"cell_type":"code","source":"figure , axes = plt.subplots(ncols = 3 , figsize = (17,4) , dpi = 100)\n\nsns.boxplot(x = firstclass['Fare'] , color = 'red' , ax = axes[0])\nsns.distplot(x = firstclass['Fare'] , ax = axes[1])\nsns.distplot(x = firstclass['Fare'].apply(np.log) , ax = axes[2])\n\nfor i in range(3):\n    axes[i].set_ylabel('')\n    axes[i].set_xlabel('Fare')\n    axes[i].tick_params(axis='x', labelsize=10)\n    axes[i].tick_params(axis='y', labelsize=10)\n\naxes[0].set_title('Descriptive Statistics For First Class Fare', fontsize=13)\naxes[1].set_title('Distribution (Fare) For First Class Fare', fontsize=13)\naxes[2].set_title('Logarithmic Distribution (Fare) For First Class Fare', fontsize=13)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Second Class Fare**","metadata":{}},{"cell_type":"code","source":"figure , axes = plt.subplots(ncols = 3 , figsize = (17,4) , dpi = 100)\n\nsns.boxplot(x = secondclass['Fare'] , color = 'blue' , ax = axes[0])\nsns.distplot(x = secondclass['Fare'] , ax = axes[1])\nsns.distplot(x = secondclass['Fare'].apply(np.log) , ax = axes[2])\n\nfor i in range(3):\n    axes[i].set_ylabel('')\n    axes[i].set_xlabel('Fare')\n    axes[i].tick_params(axis='x', labelsize=10)\n    axes[i].tick_params(axis='y', labelsize=10)\n\naxes[0].set_title('Descriptive Statistics For Second Class Fare', fontsize=13)\naxes[1].set_title('Distribution (Fare) For Second Class Fare', fontsize=13)\naxes[2].set_title('Logarithmic Distribution (Fare) For Second Class Fare', fontsize=13)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Third Class Fare**","metadata":{}},{"cell_type":"code","source":"figure , axes = plt.subplots(ncols = 3 , figsize = (17,4) , dpi = 100)\n\nsns.boxplot(x = thirdclass['Fare'] , color = '#42e3bb' , ax = axes[0])\nsns.distplot(x = thirdclass['Fare'] , ax = axes[1])\nsns.distplot(x = thirdclass['Fare'].apply(np.log) , ax = axes[2])\n\nfor i in range(3):\n    axes[i].set_ylabel('')\n    axes[i].set_xlabel('Fare')\n    axes[i].tick_params(axis='x', labelsize=10)\n    axes[i].tick_params(axis='y', labelsize=10)\n\naxes[0].set_title('Descriptive Statistics For Third Class Fare', fontsize=13)\naxes[1].set_title('Distribution (Fare) For Third Class Fare', fontsize=13)\naxes[2].set_title('Logarithmic Distribution (Fare) For Third Class Fare', fontsize=13)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well we can see that my assumption was wrong once again. Seems like the ticket to the titanic did not have any fixed price for any class in particular.\n\nThis means we will have to scale the data and then proceed to impute it with its mean.","metadata":{}},{"cell_type":"code","source":"data['Fare'] = (data['Fare'] - data['Fare'].mean()) / data['Fare'].std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Age**","metadata":{}},{"cell_type":"code","source":"figure , axes = plt.subplots(ncols = 2 , figsize = (17,4) , dpi = 100)\n\nsns.boxplot(x = 'Age' , data = data , color = 'pink' , ax = axes[0])\nsns.distplot(x = data['Age'] , ax = axes[1])\n\nfor i in range(2):\n    axes[i].set_ylabel('')\n    axes[i].set_xlabel('Fare')\n    axes[i].tick_params(axis='x', labelsize=10)\n    axes[i].tick_params(axis='y', labelsize=10)\n\naxes[0].set_title('Descriptive Statistics For Fare', fontsize=13)\naxes[1].set_title('Distribution (Fare)', fontsize=13)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I think going for with the median for Age will do the job for us.","metadata":{}},{"cell_type":"code","source":"data['Age'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will also be imputing Embarked Values using the KNN Imputer.","metadata":{}},{"cell_type":"code","source":"data['Embarked'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embarked = {'S' : 0, 'C': 1, 'Q':2}\ndata['Embarked'] = data['Embarked'].map(embarked)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Imputing Values**","metadata":{}},{"cell_type":"code","source":"impute = KNNImputer()\ndata['Embarked']= pd.Series(impute.fit_transform(data['Embarked'].values.reshape(-1,1)).reshape(1,-1).flatten())\ndata['Age'] = data['Age'].replace(np.nan,data['Age'].median())\ndata['Fare'] = data['Fare'].replace(np.nan,data['Fare'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in data.columns:\n    print(i,\":\",data[str(i)].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Transformation and Correlations With Target Variable**\n\nFor now we are not using the variables ticket and cabin. You may use them in the future to increase the accuracy and draw more insights from the data.","metadata":{}},{"cell_type":"code","source":"sex = {'male':0,'female':1}\ndata['Sex'] = data['Sex'].map(sex)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = data.drop(columns = ['Name','Ticket','Cabin','Survived'],axis = 1)\ntest = data['Survived']","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.corrwith(test).plot.bar(figsize=(15,10),title=\"Correlation with response variable\",fontsize=15,rot=90, color = 'red', grid=True )","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So , from this we can see that variables SibSp, Parch , PassengerId have a very small correlation coefficient as compared to others. We will be dropping these variables.\n\n**P.S:**\n\nPlease remember correlation graphs are only capable for showing linear relationships. That means correlation will be high if the variables can be arranged in a straight line wrt to the target variable or else not (they are based on the Pearsonr Coefficient Formula).","metadata":{}},{"cell_type":"code","source":"train.drop(['PassengerId','SibSp','Parch'],axis=1,inplace=True)\ntrain.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's scale the data for Age as well so that all variables are in nearly, the same range.","metadata":{}},{"cell_type":"code","source":"train['Age'] = (train['Age'] - train['Age'].mean()) / train['Age'].std()\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **ML Models Implementation**\n\nWe will first split them and then fit the models. ","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr=LogisticRegression()\nlr.fit(x_train,y_train)\ny_pred=lr.predict(x_test)\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf.fit(x_train,y_train)\ny_pred=clf.predict(x_test)\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn=KNeighborsClassifier(n_neighbors=5)\nknn.fit(x_train,y_train)\ny_pred=knn.predict(x_test)\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest = RandomForestClassifier()\nrandom_forest.fit(x_train, y_train)\ny_pred = random_forest.predict(x_test)\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators = [('knn',KNeighborsClassifier()),('lr',LogisticRegression()),('dtr',DecisionTreeClassifier()),('rf',random_forest)]\nclf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\nclf.fit(x_train,y_train)\ny_pred=clf.predict(x_test)\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I think we can try Stacking Classifier and Logistic Regression on the test data.","metadata":{}},{"cell_type":"markdown","source":"# **Implementing it on Test Data**","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2021/test.csv\")\nfor i in test_data.columns:\n    print(i,\":\",test_data[str(i)].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())\ntest_data['Age'] = (test_data['Age'] - test_data['Age'].mean()) / test_data['Age'].std()\ntest_data['Fare'] = (test_data['Fare'] - test_data['Fare'].mean()) / test_data['Fare'].std()\ntest_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].mean())\ntest_data['Embarked'] = test_data['Embarked'].map(embarked)\ntest_data['Embarked']= pd.Series(impute.fit_transform(test_data['Embarked'].values.reshape(-1,1)).reshape(1,-1).flatten())\ntest_data['Sex'] = test_data['Sex'].map(sex)\npassengers = test_data['PassengerId']\ntest_data.drop(columns = ['PassengerId','Name','SibSp','Cabin','Ticket','Parch'], axis=1,inplace = True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans = lr.predict(test_data)\npd.DataFrame({'PassengerId' : passengers , 'Survived': ans}).to_csv(\"my_submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **That's all Folks!**\n\nLiked my work ? Give an upvote ! \nHave some suggestions ? Leave a comment and i'll get back to you ASAP.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}