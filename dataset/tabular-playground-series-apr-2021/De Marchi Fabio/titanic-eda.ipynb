{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Titanic EDA","metadata":{}},{"cell_type":"markdown","source":"The aim of this notebook is to visualize Titanic data in order to get some insights for the development of a predictive model.\n\nNotebook is divided in three parts:\n\n1- import of data\n\n2- Missing value imputation \n\n3- Data visualization","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\nprint(\"Data imported\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, after importing the data, let's take a look at train and test data types.","metadata":{}},{"cell_type":"code","source":"print(\"Train dtypes :\",train.dtypes)\nprint(\"Test dtypes :\", test.dtypes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Variables can be devided between categorical and numerical varibles.\nCategorical variables are:\n* Pclass\n* Sex\n* Embarked\n* Ticket\n* SibSp\n* Parch\n\nNumerical variables are:\n* Age\n* Fare\n\nTarget variable is Suvived: 1 if person suvived 0 if person not survived.\n","metadata":{}},{"cell_type":"markdown","source":"Before data visualization it's important to know how many null values there are both in training and testing dataset.","metadata":{}},{"cell_type":"code","source":"print(\"Percentages of null values in training data :\\n\", np.round(train.isnull().sum()/len(train),3)*100)\nprint(\"Percentages of null values in testing data :\\n\", np.round(test.isnull().sum()/len(test),3)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see some variables like Cabin have an high percentage of null values (67% for training dataset and 70.8% for testing dataset) wheras some other variables like Fare have a very low rate of null values. Having a variable with a high rate of null values doesn't mean that you have to drop it. Instead, you can map null values to another variable and still use it in the model. Null values in some cases can also be informative for the development of the model.\nSo let's take a look at some strategies to impute missing values.","metadata":{}},{"cell_type":"markdown","source":"## Dealing with missing values","metadata":{}},{"cell_type":"markdown","source":"#### Missing values in Cabin\n\nIn order not to drop the colum we can substitute missing value in cabin with  'W' and create a new categorical variable with the first digit of Cabin variable","metadata":{}},{"cell_type":"code","source":"df = [train , test]\n\nfor d in df:\n    d.loc[d['Cabin'].isnull(), 'Cabin'] = 'W'\n    d['Cabin_initial'] = d['Cabin'].apply(lambda x : x[0])\n    d.drop('Cabin', axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Missing values in Age and Embarked and Fare","metadata":{}},{"cell_type":"markdown","source":"We can use SimpleImputer to deal with missing values in Age, Fare and Embarked, for the first two the imputing strategy is 'mean' while for the latter strategy is 'most_common'. \nWe will then drop ticket column.","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\ndf = [train,test]\n\n# imputing missing values for age \nfor d in df:\n    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n    imp.fit(d[['Age']])\n    d['Age_imputed'] = np.round(imp.transform(d[['Age']]),2)\n    d.drop('Age', axis =1, inplace = True)\n    d.rename({'Age_imputed':'Age'}, axis = 1, inplace = True)\n\n# imputing missing values for Embarked\n\nfor d in df:\n    imp = SimpleImputer(missing_values= np.nan, strategy = 'most_frequent')\n    imp.fit(d[['Embarked']])\n    d['Embarked_imputed'] = imp.transform(d[['Embarked']])\n    d.drop('Embarked', axis =1, inplace = True)\n    d.rename({'Embarked_imputed':'Embarked'},axis =1, inplace = True)\n    \n# imputing missing values for Fare\n\nfor d in df:\n    imp = SimpleImputer(missing_values= np.nan, strategy = 'most_frequent')\n    imp.fit(d[['Fare']])\n    d['Fare_imputed'] = imp.transform(d[['Fare']])\n    d.drop('Fare', axis =1, inplace = True)\n    d.rename({'Fare_imputed':'Fare'},axis =1, inplace = True)\n    \n# drop ticket colum\n\nfor d in df:\n    d.drop('Ticket',axis =1, inplace = True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After imputation we can take a look at out training and test dataset to see if there are some other missing values.","metadata":{}},{"cell_type":"code","source":"print('Null values for training:', sum(train.isnull().sum()))\nprint('Null values for training:', sum(test.isnull().sum()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Everything seems ok after imputation so let's move on to data visualization!","metadata":{}},{"cell_type":"markdown","source":"## Visualizing data","metadata":{}},{"cell_type":"markdown","source":"First of all we can define a function to label data in the graphs. This function takes as input an axes a dataframe and plot data at a y_shift distance from the graph.","metadata":{}},{"cell_type":"code","source":"def autolabel(rects,df,ax, y_shift):\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(x = rect.get_x()+ rect.get_width()/2 , y = height+y_shift , s =f'{np.round(height/len(df)*100,2)}',horizontalalignment='center' )\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So let's first plot overall survival rate.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.countplot(x = 'Survived', data = train,ax =ax, palette ='pastel')\nax.set_title('Survival rate',fontsize = 15)\nsns.despine()\nplt.xticks([0,1],['Not survived', 'Survived'])\nax.set_ylabel('Passenger counts')\nax.set_xlabel('')\nrects = ax.patches\nautolabel(rects, train, ax,1500)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Survival rate is 57.23 %. This value however alone  does not provide enough information about data. We need to see how survival rate is related to others variables.","metadata":{}},{"cell_type":"markdown","source":"Before plotting let's map Pclass values to their respctive classes (First class, Second class an Third class) and Embarked to their repective ports of embarkation. ","metadata":{}},{"cell_type":"code","source":"train['Pclass'] = train['Pclass'].map({1: 'First class', 2: 'Second class',3:'Third class'})\ntrain['Embarked'] = train['Embarked'].map({'C' : 'Cherbourg', 'S' : 'Southampton', 'Q' : 'Queenstown'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A first insight could be obtained by plotting how the survival rate varies among class, port of embark and ticket. ","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize = (10,5))\na = sns.countplot(x = 'Pclass', data = train,ax =ax[0], palette ='pastel', hue ='Survived')\na.set_xlabel('')\nplt.setp( ax[0].xaxis.get_majorticklabels(), rotation=30 )\nautolabel(ax[0].patches, train, ax = ax[0], y_shift =100)\nb = sns.countplot(x = 'Embarked', data = train,ax =ax[1], palette ='pastel', hue ='Survived')\nb.set_xlabel('')\nautolabel(ax[1].patches, train, ax = ax[1], y_shift =100)\nplt.setp( ax[1].xaxis.get_majorticklabels(), rotation=30 )\nc = sns.countplot(x = 'Cabin_initial', data = train, ax = ax[2], palette = 'pastel', hue = 'Survived')\nplt.setp( ax[2].xaxis.get_majorticklabels(), rotation=30 )\nc.set_xlabel('')\nplt.suptitle('Number of survival for Class, Port of embark and Ticket', fontsize = 15)\nsns.despine()\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see First class and Second Class have a higher survival rate than Third class.\nThere is also a difference in the port of embark: people who embarked in Southampton and Cherbourg have a higher chance of survival than people embarked in Queenstown.\n\n\nAnother column that we can take into account is Sex: so let's take a look if survival rate changes as between male and female.","metadata":{}},{"cell_type":"code","source":"temp = np.round(train.groupby(['Sex'])['Survived'].sum()/len(train)*100,2)\nfig, ax  = plt.subplots(figsize = (6,4))\nsns.barplot(x = temp.index, y = temp, palette = 'Pastel2', ax = ax)\nsns.despine()\nplt.title('Survival rate for sex')\nplt.ylabel('Survival rate')\nprint(temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Woman have a higher rate of survive compared to men (about three times higher). So let's go deeper:\nare there any differences  between Class or port of embarking?","metadata":{}},{"cell_type":"code","source":"temp1 = train.groupby(['Embarked','Pclass','Sex'], as_index = False)['Survived'].sum()\ntemp2 = train.groupby(['Embarked','Pclass'],as_index = False)['Survived'].count()\ncombined = temp1.merge(temp2, how = 'left', left_on = ['Embarked','Pclass'],right_on = ['Embarked','Pclass'] )\ncombined['Survival_rate'] = np.round(combined['Survived_x']/combined['Survived_y']*100,2)\ncombined.drop(['Survived_x','Survived_y'],axis=1, inplace = True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.FacetGrid(combined, col = 'Pclass',row = 'Embarked',  margin_titles=True, height=2.5)\ng.map(sns.barplot, 'Sex','Survival_rate', palette = 'Pastel2', order = ['female','male'])\ng.set_axis_labels('','Survival rate')\ng.fig.subplots_adjust(wspace=.02, hspace=.02)\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see survival rate is higher for female. Southampton is the port of embark in which survival rate is lower both for female and male. Second class seems to have the higher chances of survival. Cherbourg is port of embark where survival rate if higher. Southampton has been the first port of embarkation, followed by  Cherbourg and  Queenstown). For the understanding of survival rate it's very important to study how different passenger where dislocated in the Titanic.","metadata":{}},{"cell_type":"markdown","source":"Let's now take into account another variable, Age and plot how survival change between different ages.","metadata":{}},{"cell_type":"code","source":"sns.displot(train ,x ='Age', hue ='Survived', kind ='kde', multiple = 'stack', col = 'Sex', row = 'Pclass', palette = 'Pastel1')\nplt.ylabel('Survival density')\nplt.suptitle('Survival density for Sex and port of Embark', y =1.009, fontsize = 15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Probably one thing that you can note is that first class has a higher average rate than second and third class. Let's take a look to se if this is correct.","metadata":{}},{"cell_type":"code","source":"np.round(train.groupby(['Pclass'])['Age'].mean(),1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yes, it's true, we can also split average Age between male and female.","metadata":{}},{"cell_type":"code","source":"np.round(train.groupby(['Pclass','Sex'], as_index = False)['Age'].mean(),1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's there a difference between survival rate and Fare?","metadata":{}},{"cell_type":"code","source":"sns.jointplot(data = train, x = 'Fare', y = 'Age', hue = 'Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Is there a significant difference between in the correlation between variables and Survived vs Not Survived? Let's take a look with a heatmap.","metadata":{}},{"cell_type":"code","source":"col_heatmap = [col for col in train.columns if col not in ('Survived','PassengerId')]\ntrain_survived = train[train['Survived'] ==1]\ntrain_not_survived = train[train['Survived'] ==0]\ncorr_surv = train_survived[col_heatmap].corr()\ncorr_notsurv = train_not_survived[col_heatmap].corr()\nmask = np.triu(np.ones_like(corr_surv,dtype=bool))\nfig,ax = plt.subplots(nrows = 1, ncols = 2,figsize = (10,6))\nsns.heatmap(corr_surv,mask= mask, ax = ax[0],annot = True)\nax[0].set_title('Correlation for Survived')\nsns.heatmap(corr_notsurv,mask= mask, ax = ax[1], annot = True)\nax[1].set_title('Correlation for not survived')\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For survived there seem to be a higher correlation between Age and Fare: that is most of the person who survived where int the first class where fare is higher and also the average age is higher.","metadata":{}},{"cell_type":"markdown","source":"Let's now take a look at Sibsp and Parch by creating a new variable by summing the two.","metadata":{}},{"cell_type":"code","source":"train['Sib+Parch'] = train['SibSp']+ train['Parch']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(train ,x ='Sib+Parch', hue ='Survived', kind = 'kde', col = 'Embarked', row = 'Pclass', palette = 'Pastel1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparison between training and testing dataset","metadata":{}},{"cell_type":"markdown","source":"Now we can compare training and testing dataset to see if there are some differences in the distribution of data which could effect the development of a machine learning model.","metadata":{}},{"cell_type":"markdown","source":"We can create a new dataframe by concatenating training and testing.","metadata":{}},{"cell_type":"code","source":"train.drop(['PassengerId','Survived','Name'],axis =1, inplace = True)\ntrain['Pclass'] = train['Pclass'].map({'First class':1, 'Second class':2, 'Third class':3})\ntest.drop(['PassengerId','Name'], axis = 1,inplace = True)\ntest['Sib+Parch'] = test['SibSp']+ test['Parch']\ntrain['Embarked'] =train['Embarked'].map({'Cherbourg':'C',  'Southampton':'S',  'Queenstown':'Q'})\ntest['data'] ='test'\ntrain['data'] = 'train'\ndf = pd.concat([train,test],axis = 0, ignore_index = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(nrows = 2, ncols = 3, figsize = (12,10))\nplt.suptitle('Distribution of data between train and test dataset', size = 20)\nsns.countplot(x = 'Sex', data = df,ax =ax[0][0], palette ='pastel', hue ='data')\nax[0][0].set_title('Male and female')\nsns.histplot(data=df, x=\"Age\", palette = 'Pastel1',hue = 'data', ax =ax[0][1])\nax[0][1].set_title('Age distribution')\nsns.countplot(data=df, x=\"Sib+Parch\", palette = 'Pastel1',hue = 'data', ax =ax[0][2])\nax[0][2].set_title('Sib+Parch')\nsns.countplot(data=df, x=\"Embarked\", palette = 'Pastel1',hue = 'data', ax =ax[1][0])\nax[1][0].set_title('Embarked')\nsns.countplot(data=df, x=\"Cabin_initial\", palette = 'Pastel1',hue = 'data',ax =ax[1][1])\nax[1][1].set_title('Cabin initial')\nsns.histplot(data=df, x=\"Fare\", palette = 'Pastel1',hue = 'data',multiple = 'dodge',bins = 5, ax =ax[1][2])\nax[1][2].set_title('Fare distribution')\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There seems to be a difference in Age distribution between training and testing: in the testing dataset there seems to be more concentration in the ages between 20 and 30. Male and Female distribution seems also slightly different.","metadata":{}},{"cell_type":"markdown","source":"Next steps: in another notebook I will develop a predictive model trying to exploit the intuitions about data distribution and relationship of features with the target variable gained in this notebook.","metadata":{}}]}