{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy             as np \nimport pandas            as pd \nimport matplotlib.pyplot as plt\nimport seaborn           as sns \n%matplotlib inline \n\nfrom sklearn.preprocessing   import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics         import roc_curve\nfrom sklearn.ensemble        import RandomForestClassifier\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ##### If you are in the intermmediate level & trying to hone your skills in algorithims such as Random forest & Logistic Regression this notebook is for you.\n* #####  I will be using Logistic Regression,Random forest at the first and then use ensembles to improvise the accuracy further.\n\n**Topics that we will cover in this notebook are:-**\n1. Data cleaning & Preprocessing by creating dummies, Scaling.\n2. Model building using Logistic Regression, Random Forest & Ensembles.\n3. Using RFE(Recursive feature elimination) for feature elimination.\n4. VIF (Variation inflation Factor) to detect multicolinearlity.\n5. Automatic Hyperparameter tunning using Sklearn.\n6. Model evalution using accuracy, F1 score, Recall,precision.","metadata":{}},{"cell_type":"markdown","source":"#### 1. DATA IMPORTING & ANALYZING","metadata":{}},{"cell_type":"code","source":"#Importing train & test data \ndf_train = pd.read_csv(r'../input/tabular-playground-series-apr-2021/train.csv')\ndf_test  = pd.read_csv(r'../input/tabular-playground-series-apr-2021/test.csv')\ntest_id  = pd.read_csv(r'../input/tabular-playground-series-apr-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analyzing the train & test dataset\nprint(df_train.info())\nprint(df_test.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. DATA CLEANING","metadata":{}},{"cell_type":"code","source":"#Analyzing the null values in train, test dataframe\nprint((df_train.isnull().sum()/len(df_train))*100)\nprint((df_test.isnull().sum()/len(df_test))*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#As we  can see in the column Cabin, more than 50% of the values are missing,we will delete the column \ndf_train.drop(columns='Cabin',axis=1,inplace=True)\ndf_test.drop(columns='Cabin',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#In some of the columns there are null values are less than 5% so we will delete these null values \ndf_train.dropna(axis=0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to impute the null values with most frequent values \ndef impute(df):\n    from sklearn.impute import SimpleImputer\n    my_imputer           = SimpleImputer(strategy='most_frequent')\n    imputed_data         = pd.DataFrame(my_imputer.fit_transform(df))\n    imputed_data.columns = df.columns\n    return imputed_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = impute(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the dataframe again for null values \nprint((df_train.isnull().sum()/len(df_train))*100)\nprint((df_test.isnull().sum()/len(df_test))*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. DATA PREPROCESSING ","metadata":{}},{"cell_type":"code","source":"#Checking the dataframe \ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting the categorical columns into numerical data \ndf_train['Sex'] = df_train['Sex'].apply(lambda x:1 if x=='male' else 0)\ndf_test['Sex']  = df_test['Sex'].apply(lambda x:1 if x=='male' else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analysing other categorical columns like 'EMBARKED'\ndf_train['Embarked'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting the 'EMBARKED' column into a dummy columns as it has more than 2 uniquie value \ntrain_dummy = pd.get_dummies(df_train['Embarked'],drop_first=True)\ntest_dummy  = pd.get_dummies(df_test['Embarked'],drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Merging the dummies with the main dataframe\ndf_train = pd.concat([df_train,train_dummy],axis=1)\ndf_test  = pd.concat([df_test,test_dummy],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dropping the main column 'Embarked'\ndf_train.drop(columns='Embarked',axis=1,inplace=True)\ndf_test.drop(columns='Embarked',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#As we can see name,passengerID,Ticket column can be dropped as they wont have any effect on survival\ndf_train.drop(columns=['PassengerId','Name','Ticket'],axis=1,inplace=True)\ndf_test.drop(columns=['PassengerId','Name','Ticket'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking if any outliers exits in the data \nsns.boxplot(df_train['Age']);\n#We can conclude that there is no outlier \n#Make a point we won't be analysing the test data for outliers as we have to consider it as hidden ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preprocessing the data using MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaling                = MinMaxScaler()\nscaling_col            = ['Age','Fare']\ndf_train[scaling_col]  = scaling.fit_transform(df_train[scaling_col])\ndf_test[scaling_col]   = scaling.transform(df_test[scaling_col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### If you are curious to know why we did ony tranform for test data set & fit_tranform to train.\nvisit the link below [https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe](http://)","metadata":{}},{"cell_type":"code","source":"#Checking the dataframe one last time\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4. EXPLORATORY DATA ANALYSIS ","metadata":{}},{"cell_type":"code","source":"#Checking the correlation between the features \nsns.heatmap(df_train.corr(),annot=True)\n#Features which are highly correlated with the target variables are \n#  ------>>> Sex,Pclass,S,Fare,Age","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking if the data is balanced or imbalanced\nsns.countplot(df_train['Survived']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(df_train['Survived'].value_counts(normalize=True))*100\n#The dataset is not balanced but we cannot deam it to the category of imbalance too","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5. MODEL BUILDING & Evaluation","metadata":{}},{"cell_type":"markdown","source":"#### 1. We are ready for the End game now, I will be using the below approach to build the best model.\n#### *     a. Building the best 'Logistic Regression model', submit pred & check accuracy.\n#### *     b. Building the best ' Random forest' model, submit pred & check accuracy.\n#### *     c. Finally, building a 'Ensemble' to check if we can maximize the accuarcy. ","metadata":{}},{"cell_type":"code","source":"#Function to check the VIF of the df\ndef vif_validation(X_train):\n    from statsmodels.stats.outliers_influence import variance_inflation_factor\n    # Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n    vif = pd.DataFrame()\n    vif['Features']  = X_train.columns\n    vif['VIF']       = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n    vif['VIF']       = round(vif['VIF'], 2)\n    vif              = vif.sort_values(by = \"VIF\", ascending = False)\n    return vif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to create a table with pred values for logistic regression \n#Function will return a dataframe with predicted values\ndef prediction(model_name,x_test,y_test,thres):\n    y_pred                        = model_name.predict(x_test)\n    y_pred_final                  = pd.DataFrame({'Prob':y_pred})\n    y_pred_final['Survived']      = y_test\n    y_pred_final['pred']          = y_pred_final['Prob'].apply(lambda x:1 if x>thres else 0)\n    return y_pred_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to create a table with pred values for logistic regression \n#Function will return a dataframe with predicted values\ndef test_prediction(model_name,x_test,thres):\n    y_pred                        = model_name.predict(x_test)\n    y_pred_final                  = pd.DataFrame({'Prob':y_pred})\n    y_pred_final['pred']          = y_pred_final['Prob'].apply(lambda x:1 if x>thres else 0)\n    return y_pred_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to test the logistic Regression model \ndef validating_lr(y_real,y_pred):\n    from sklearn.metrics import confusion_matrix, accuracy_score\n    print('Confusion Matrix')\n    confusion = confusion_matrix(y_pred,y_real)\n    print(confusion)\n    print('\\n')\n    print('Accuracy Score',(accuracy_score(y_pred,y_real)*100))\n    TP = confusion[1,1] # true positive \n    TN = confusion[0,0] # true negatives\n    FP = confusion[0,1] # false positives\n    FN = confusion[1,0] # false negatives\n    print('\\n')\n    print('Sensitivity:',(TP / float(TP+FN)*100))\n    print('\\n')\n    print('specificity:',(TN / float(TN+FP)*100))\n    print('\\n')\n    print('false postive rate - predicting 1 when its 0:',(FP/ float(TN+FP)*100))\n    print('\\n')\n    print('Positive predictive value:',(TP / float(TP+FP)*100))\n    print('\\n')\n    print('Negative predictive value:',(TN / float(TN+ FN)*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to get the probablities for all possible threshold\ndef optimum_threshold(y_pred):\n    numbers = [float(x)/10 for x in range(10)]\n    for i in numbers:\n        y_pred[i]= y_pred.Prob.map(lambda x: 1 if x > i else 0)\n    return y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ndef optimum_accuracy(df,op):\n    cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n    from sklearn.metrics import confusion_matrix\n\n    # TP = confusion[1,1] # true positive \n    # TN = confusion[0,0] # true negatives\n    # FP = confusion[0,1] # false positives\n    # FN = confusion[1,0] # false negatives\n\n    num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n    for i in num:\n        cm1              = confusion_matrix(df[op],df[i] )\n        total1           = sum(sum(cm1))\n        accuracy         = (cm1[0,0]+cm1[1,1])/total1\n        speci            = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n        sensi            = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n        cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n    return cutoff_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ndef Roc_plotting(df):\n    df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting the data into different parts \nX_train = df_train.drop(columns='Survived',axis=1).copy()\ny_train = df_train['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building a Logistic Regression model using Statsmodel\nimport statsmodels.api as sm\nlr    = sm.GLM(y_train,sm.add_constant(X_train),family=sm.families.Binomial())\nlr_1  = lr.fit()\nprint(lr_1.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analyzing if Multicolinearlity exits in the data \nvif_validation(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1. We have two situations here wherin we have column 'Pclass' with high VIF & low P-value.\n#### 2. Second column is 'Age' with high p-value & low VIF.\n#### 3. We will eliminate the column 'Pclass' as it has high VIF & also it is redundant as 'Fare' column is already present in the training dataset.","metadata":{}},{"cell_type":"code","source":"#Dropping the column 'Pclass' from the training data set \nX_train.drop(columns='Pclass',axis=1,inplace=True)\ndf_test.drop(columns='Pclass',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Rebuilding the model again with new_training dataframe \nlr    = sm.GLM(y_train,sm.add_constant(X_train),family=sm.families.Binomial())\nlr_2  = lr.fit()\nprint(lr_2.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analyzing if Multicolinearlity exits in the data \nvif_validation(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### * 1. As we can observe that the Multicolinearlity has been reduced significantly & the p-value of all the features is less & they all are sinificant.*","metadata":{}},{"cell_type":"code","source":"#Getting the prediction using train data & validating the model \ny_pred = prediction(lr_2,sm.add_constant(X_train),y_train,0.5)\ny_pred.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluting the model accuracy \nvalidating_lr(y_train,y_pred['pred'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting prediction for all the thresholds\ny_pred = optimum_threshold(y_pred)\ny_pred.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the ROC to analyse & choose the best threshold to maximize the accuracy\ncutoff_df = optimum_accuracy(y_pred,'Survived')\ncutoff_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analysing the ROC \nRoc_plotting(cutoff_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets try threhold value somewhere around 0.45-0.48\n#Getting the prediction using train data & validating the model \ny_pred = prediction(lr_2,sm.add_constant(X_train),y_train,0.5)\ny_pred.head()\n#Evaluting the model accuracy \nvalidating_lr(y_train,y_pred['pred'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_sm      = sm.add_constant(df_test)\ndf_test_sm.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[['Parch','SibSp']] = df_test[['Parch','SibSp']].astype('float64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Concatenanting the passgerID & Survival rate \ndf_test_sm      = sm.add_constant(df_test)\nlr_2_test_pred  = test_prediction(lr_2,df_test_sm,0.5)\nsubmission_file = pd.DataFrame({'PassengerID':test_id['PassengerId'],'Survived':lr_2_test_pred['pred']})\nsubmission_file.to_csv('submission_1.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* #### As of now lr_2 is the best model we are getting with 76% train_accuracy, Let's submit & check the test accuracy of around 79.38% I am not sure how this is possible but lets move on to build a Random forest model to further improve the accuracy","metadata":{}},{"cell_type":"code","source":"#Building a Decision Tree & then fitting it to the RandomForest model \nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(max_depth=5,min_samples_split=150,min_samples_leaf=150)\ndt.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the accuracy of the Decision Tree \nfrom sklearn.metrics import confusion_matrix, accuracy_score\ny_train_pred = dt.predict(X_train)\nprint(accuracy_score(y_train, y_train_pred))\nconfusion_matrix(y_train, y_train_pred)\n\n#We can observe that we are getting almost similar accuracy so we will do some hyperparameter tunning","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tunning the Hyperparameters \nfrom sklearn.model_selection import GridSearchCV\ndt = DecisionTreeClassifier(random_state=42)\n# Create the parameter grid based on the results of random search \nparams = {\n    'max_depth': [2, 3, 4, 5, 6, 8, 10],\n    'min_samples_leaf': [30,50,100,150,200,250,300],\n    'min_samples_split': [30,50,100,150,200,250,300],\n    'criterion': [\"gini\", \"entropy\"]\n}\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator=dt, \n                           param_grid=params, \n                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\ngrid_search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building a RandomForest model \nscore_df = pd.DataFrame(grid_search.cv_results_)\nscore_df.nlargest(5,\"mean_test_score\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training the DecisionTree with best hyperparameter to get maximum accuracy \ndt = DecisionTreeClassifier(max_depth=10,min_samples_split=250,min_samples_leaf=100,criterion='entropy',random_state=42)\ndt.fit(X_train, y_train)\ny_train_pred = dt.predict(X_train)\nprint(accuracy_score(y_train, y_train_pred))\nconfusion_matrix(y_train, y_train_pred)\n#Our accuracy has slightly increased","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Concatenanting the passgerID & Survival rate \ndt_test_pred    = dt.predict(df_test)\nsubmission_file = pd.DataFrame({'PassengerID':test_id['PassengerId'],'Survived':dt_test_pred})\nsubmission_file.to_csv('submission_2.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Th accuracy using the DecisionTree model is only 77.58% so lets try to build a RandomForest model","metadata":{}},{"cell_type":"code","source":"#Building a RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=30, max_depth=10, max_features=5, random_state=100, oob_score=True)\nrf.fit(X_train, y_train)\nrf.oob_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparameter tunning for RandomForest\nrf = RandomForestClassifier(random_state=42, n_jobs=-1)\nparams = {\n    'max_depth'        : [5,10,20],\n    'min_samples_leaf' : [50,100,150,200,250,300],\n    'min_samples_split': [100,150,200,250,300],\n    'n_estimators'     : [10, 25, 50, 100]\n}\ngrid_search = GridSearchCV(estimator=rf,\n                           param_grid=params,\n                           cv = 4,\n                           n_jobs=-1, verbose=1, scoring=\"accuracy\")\ngrid_search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting the best hyperparameters \ngrid_search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitting the model to new hyperparameters\nrf = RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=250,\n                       n_estimators=50, n_jobs=-1, random_state=42,oob_score=True)\nrf.fit(X_train, y_train)\nrf.oob_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the accuracy on the train dataset\ny_train_pred = rf.predict(X_train)\nprint(accuracy_score(y_train, y_train_pred))\nconfusion_matrix(y_train, y_train_pred)\n#We can clearly observe that there is a slight improvement in the overall accuracy of the model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the model accuracy on the test dataset \n#Concatenanting the passgerID & Survival rate \nrf_test_pred         = rf.predict(df_test)\nsubmission_file      = pd.DataFrame({'PassengerID':test_id['PassengerId'],'Survived':rf_test_pred})\nsubmission_file.to_csv('submission_3.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* #### Now, that we have used RandomForest as well and did not see any significant improvement in the model accuracy lets use Ensembles to predict the survival rate","metadata":{}},{"cell_type":"code","source":"#We will create an ensemble using Logistic Regression & RandomForest (Decision Tree)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree         import DecisionTreeClassifier\nfrom sklearn.ensemble     import StackingClassifier\nfrom sklearn.metrics      import r2_score,accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating the different models stack \nestimators = [\n    ('lr', LogisticRegression()),\n    ('dt', RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=250,\n                       n_estimators=50, n_jobs=-1, random_state=42,oob_score=True))\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Stacking the models together\nstack_reg = StackingClassifier(estimators=estimators)\nstack_reg.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing the accuracy of the model \ny_train_pred = stack_reg.predict(X_train)\naccuracy_score(y_train,y_train_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the model accuracy on the test dataset \n#Concatenanting the passgerID & Survival rate \nrf_test_pred         = stack_reg.predict(df_test)\nsubmission_file      = pd.DataFrame({'PassengerID':test_id['PassengerId'],'Survived':rf_test_pred})\nsubmission_file.to_csv('submission_4.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* #### Here we getting the test accuracy of 77.69.\n* #### We will also try knn for classifiying.","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nKnn = KNeighborsClassifier(4)\nKnn.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing the accuracy of the model \ny_train_pred = Knn.predict(X_train)\naccuracy_score(y_train,y_train_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the model accuracy on the test dataset \n#Concatenanting the passgerID & Survival rate \nrf_test_pred         = Knn.predict(df_test)\nsubmission_file      = pd.DataFrame({'PassengerID':test_id['PassengerId'],'Survived':rf_test_pred})\nsubmission_file.to_csv('submission_5.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1. Let's build an ensemble using LogisticRegression, KNN, RandomForest algorithm","metadata":{}},{"cell_type":"code","source":"#Creating the different models stack \nestimators = [\n    ('lr', LogisticRegression()),\n    ('dt', RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=250,\n                       n_estimators=50, n_jobs=-1, random_state=42,oob_score=True)),\n    ('Knn',KNeighborsClassifier(4))\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Stacking the models together\nstack_reg = StackingClassifier(estimators=estimators)\nstack_reg.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing the accuracy of the model \ny_train_pred = stack_reg.predict(X_train)\naccuracy_score(y_train,y_train_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the model accuracy on the test dataset \n#Concatenanting the passgerID & Survival rate \nrf_test_pred         = stack_reg.predict(df_test)\nsubmission_file      = pd.DataFrame({'PassengerID':test_id['PassengerId'],'Survived':rf_test_pred})\nsubmission_file.to_csv('submission_6.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}