{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport xgboost as xgb\n\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer, FunctionTransformer, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier, Lasso\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nfrom datetime import datetime\nimport pickle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Load datasets","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count missing value\nlist(zip(df_test.columns, df_train.drop('Survived', axis=1).isna().sum().values, df_test.isna().sum().values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Embarked'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_id = df_train['PassengerId']\ndf_test_id = df_test['PassengerId']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission(y_pred, file_name):\n    d = {'PassengerId': df_test_id, 'Survived': y_pred}\n    submission_file = pd.DataFrame(d)\n    submission_file.to_csv(file_name,  sep=',',  index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Separate features and label variable","metadata":{}},{"cell_type":"code","source":"X = df_train.drop('Survived', axis=1)\ny = df_train.Survived\n\nX_test = df_test.copy(deep=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot graphics","metadata":{}},{"cell_type":"code","source":"sns.pairplot(X.drop('PassengerId', axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Missing value","metadata":{}},{"cell_type":"code","source":"sns.heatmap(X.drop('PassengerId', axis=1).isna(), cbar=False, cmap='viridis', yticklabels='False')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Pearson Correlation Heatmap","metadata":{}},{"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n# Create the correlation matrix\ncorr = X.select_dtypes(include=numerics).astype(float).corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# plot graph\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(10,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\n\nsns.heatmap(corr, linewidths=0.1, vmax=1.0, mask=mask,\n            square=True, cmap=colormap, linecolor='white', annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split into train and validation","metadata":{}},{"cell_type":"code","source":"# Get validation data\nX_train, X_validation, y_train, y_validation = train_test_split(X, y,\n                                                                test_size=0.20, \n                                                                random_state=42)\n\nX_train.shape, X_validation.shape, X_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_validation.shape, y_validation.sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features engineering","metadata":{}},{"cell_type":"code","source":"def substrings_in_string(big_string, substrings):\n    for substring in substrings:\n        if big_string.startswith(substring):\n            return substring\n    return 'NA'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_all = [X_train, X_validation, X_test, X]\n\nmedian_age = X_train.loc[:,'Age'].median()\nmedian_fare = X_train.loc[:, 'Fare'].median()\ncabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'NA']\n# Specify the boundaries of the bins\nbins_age = [-np.inf, 20, 40, 60, 80, np.inf]\n# Bin labels\nlabels_age = ['Age_1', 'Age_2','Age_3', 'Age_4', 'Age_5']\n\npd.options.mode.chained_assignment = None  # default='warn'\nfor X_ in X_all:\n    # Imputing\n    # Imputing Age by median value\n    X_.loc[:,'Age'].fillna(median_age, inplace=True)\n\n    # Imputing Fare in test set by median value\n    X_.loc[:, 'Fare'].fillna(median_fare, inplace=True)\n\n    # Imputing Embarked and Cabin by 'NA' value\n    X_.loc[:, 'Embarked'].fillna('NA', inplace=True)\n    X_.loc[:, 'Cabin'].fillna('NA', inplace=True)\n    \n    \n    # Add new features\n    # Calculating FamilySize\n    X_.loc[:, 'FamilySize'] = X_['SibSp'] + X_['Parch']\n    \n    # Deck\n    # This is going be very similar, we have a ‘Cabin’ column not doing much, only 1st class passengers have cabins, \n    # the rest are ‘Unknown’. A cabin number looks like ‘C123’. The letter refers to the deck, \n    # and so we’re going to extract these just like the titles.\n    # Turning cabin number into Deck    \n    X_.loc[:, 'Deck'] = X_['Cabin'].map(lambda x: substrings_in_string(str(x), cabin_list))\n    \n    # Age*Class\n    # This is an interaction term, since age and class are both numbers we can just multiply them.\n    X_.loc[:, 'Age*Pclass'] = X_['Age'] * X_['Pclass']\n    \n    # Fare per Person\n    # Here we divide the fare by the number of family members traveling together, \n    X_.loc[:, 'FarePerPerson'] = X_['Fare'] / (X_['FamilySize'] + 1)\n    \n    # Specify Age\n    # Bin the continuous variable using these boundaries\n    X_.loc[:, 'Age_name'] = pd.cut(X_['Age'], bins=bins_age, labels=labels_age).astype('object')\n    \n     #\n    X_.loc[:, 'LastName_len'] = X_['Name'].str.split(', ').str[0].str.len()\n    X_.loc[:, 'FirstName_len'] = X_['Name'].str.split(', ').str[1].str.len()\n    \n    #\n    X_.loc[:, 'Family_size_group'] = X_['FamilySize'].map(lambda x: 'f_single' if x == 0\n                                                         else('f_usual' if 4 > x >= 1\n                                                             else('f_big' if 7 > x >= 4\n                                                                 else('f_large'))))\n    \n#     # Is alone\n#     X_['IsAlone'] = 0\n#     X_.loc[X_['FamilySize'] == 0, 'IsAlone'] = 1\n    \n    # Delete unuse columns\n    X_.drop(['PassengerId', 'Ticket', 'Cabin', 'Name'], axis=1, inplace=True)\n\npd.options.mode.chained_assignment = 'warn'   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imput_median_columns = ['Age', 'Fare']\nimput_median_indices = np.array([(column in imput_median_columns) for column in X_train.columns], dtype = bool)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head(4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Select columns for transformation","metadata":{}},{"cell_type":"code","source":"binary_data_columns = ['SibSp', 'Parch', 'FamilySize']\nbinary_data_indices = np.array([(column in binary_data_columns) for column in X_train.columns], dtype = bool)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(binary_data_columns)\nprint(binary_data_indices)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns for One-Hot-Encoder\ncategorical_data_columns = ['Pclass', 'Sex','Embarked', 'Deck',  'Age_name', 'Family_size_group'] \ncategorical_data_indices = np.array([(column in categorical_data_columns) for column in X_train.columns], dtype = bool)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(categorical_data_columns)\nprint(categorical_data_indices)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns for Standardization\nnumeric_data_columns = ['Age', 'LastName_len', 'FirstName_len']\nnumeric_data_indices = np.array([(column in numeric_data_columns) for column in X_train.columns], dtype = bool)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(numeric_data_columns)\nprint(numeric_data_indices)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply a power transform featurewise to make data more Gaussian-like\nnumeric_data_columns_log = ['Fare', 'Age*Pclass', 'FarePerPerson']\nnumeric_data_indices_log = np.array([(column in numeric_data_columns_log) for column in X_train.columns], dtype = bool)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(numeric_data_columns_log)\nprint(numeric_data_indices_log)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Models","metadata":{}},{"cell_type":"markdown","source":"##### Multiple feature extraction","metadata":{}},{"cell_type":"code","source":"combined_features = FeatureUnion(transformer_list = [\n            # binary\n            ('binary_variables_processing', FunctionTransformer(lambda data: data.iloc[:, binary_data_indices])), \n                    \n            # numeric\n            ('numeric_variables_processing', Pipeline(steps = [\n                ('selecting', FunctionTransformer(lambda data: data.iloc[:, numeric_data_indices])),\n                ('scaling', StandardScaler(with_mean=True))            \n                        ])),\n            # numeric_log\n            ('numeric_variables_log_processing', Pipeline(steps = [\n                ('selecting', FunctionTransformer(lambda data: data.iloc[:, numeric_data_indices_log])),\n                ('scaling', PowerTransformer(standardize=True))            \n                        ])),\n        \n            # categorical\n            ('categorical_variables_processing', Pipeline(steps = [\n                ('selecting', FunctionTransformer(lambda data: data.iloc[:, categorical_data_indices])),\n                ('hot_encoding', OneHotEncoder(handle_unknown = 'ignore'))            \n                        ])),\n        ],\n                                n_jobs = -1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### DecisionTreeModel","metadata":{}},{"cell_type":"code","source":"tree_class = DecisionTreeClassifier(random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator_tree = Pipeline(steps = [\n    ('feature_processing', combined_features),\n    ('classifier', tree_class)\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ngrid_param = {\n    'classifier__max_depth': np.arange(2, 5, dtype=int),\n    'classifier__min_samples_leaf':  np.arange(2, 5, dtype=int)\n}\n\ngsearch_tree = GridSearchCV(estimator = estimator_tree,\n                              param_grid = grid_param,\n                              scoring='accuracy',\n                              return_train_score=True,\n                              n_jobs=-1,\n                              verbose=2,\n                              cv=5)\n\ngsearch_tree.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gsearch_tree.best_params_, gsearch_tree.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation\ny_pred_train_tree = gsearch_tree.best_estimator_.predict(X_train)\ny_pred_val_tree = gsearch_tree.best_estimator_.predict(X_validation)\naccuracy_val = accuracy_score(y_validation, y_pred_val_tree)\nprint('accuracy_val: {}'.format(accuracy_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save submission file\ntime_now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\ny_pred_test_tree = gsearch_tree.best_estimator_.predict(X_test)\ncreate_submission(y_pred_test_tree, 'submissions/tree_gridSearch_submission_{}.csv'.format(time_now))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### XGB Classifier","metadata":{}},{"cell_type":"code","source":"xgb_class = xgb.XGBClassifier(objective='binary:logistic',\n                              eval_metric='logloss',\n                              use_label_encoder=False,\n                              nthread=-1,\n                              seed=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator_xgb = Pipeline(steps = [\n    ('feature_processing', combined_features),\n    ('classifier', xgb_class)\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ngrid_param = {\n    'classifier__learning_rate': [0.01, 0.1, 0.2, 0.5],\n    'classifier__n_estimators': range(80, 301, 20),\n    'classifier__max_depth': range(3,8),\n    'classifier__min_child_weight': range(2,6),\n    'classifier__learning_rate': np.arange(0.01, 0.505, 0.05),\n    'classifier__gamma': np.arange(0.1, 0.805, 0.1),\n    'classifier__subsample': np.arange(0.7, 1.0, 0.1),\n    'classifier__colsample_bytree': np.arange(0.6, 1.0, 0.1)\n}\n\nrsearch_xgb = RandomizedSearchCV(estimator=estimator_xgb,\n                                 n_iter=50,\n                                 param_distributions=grid_param,\n                                 scoring='accuracy',\n                                 return_train_score=True,\n                                 n_jobs=-1,\n                                 verbose=2,\n                                 random_state=42,\n                                 cv=4)\nrsearch_xgb.fit(X_train, y_train)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rsearch_xgb.best_params_, rsearch_xgb.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation\ny_pred_train_xgb = rsearch_xgb.best_estimator_.predict(X_train)\ny_pred_val_xgb = rsearch_xgb.best_estimator_.predict(X_validation)\naccuracy_val = accuracy_score(y_validation, y_pred_val_xgb)\nprint('accuracy_val: {}'.format(accuracy_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save submission file\ntime_now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\ny_pred_test_xgb = rsearch_xgb.best_estimator_.predict(X_test)\ncreate_submission(y_pred_test_xgb, 'submissions/xgb_randomSearch_submission_{}.csv'.format(time_now))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Logistic regression classifier","metadata":{}},{"cell_type":"code","source":"logreg = LogisticRegression(random_state=42,\n                            max_iter=200,\n                            n_jobs=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator_logreg = Pipeline(steps = [\n    ('feature_processing', combined_features),\n    ('classifier', logreg)\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ngrid_param = {\n    'classifier__C': np.logspace(-5, 8, 15)\n}\n\ngsearch_logreg = GridSearchCV(estimator = estimator_logreg,\n                              param_grid = grid_param,\n                              scoring='accuracy',\n                              return_train_score=True,\n                              n_jobs=-1,\n                              verbose=2,\n                              cv=5)\n\ngsearch_logreg.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gsearch_logreg.best_params_, gsearch_logreg.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation\ny_pred_train_lr = gsearch_logreg.best_estimator_.predict(X_train)\ny_pred_val_lr = gsearch_logreg.best_estimator_.predict(X_validation)\naccuracy_val = accuracy_score(y_validation, y_pred_val_lr)\nprint('accuracy_val: {}'.format(accuracy_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gsearch_logreg.cv_results_['params'][0], gsearch_logreg.cv_results_['mean_test_score'][0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save submission file\ntime_now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\ny_pred_test_lr = gsearch_logreg.best_estimator_.predict(X_test)\ncreate_submission(y_pred_test_lr, 'submissions/logreg_gs_submission_{}.csv'.format(time_now))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### SVM","metadata":{}},{"cell_type":"code","source":"svm = SGDClassifier(random_state=42,\n                    n_jobs=-1,\n                    early_stopping=True,\n                    validation_fraction=0.2,\n                    n_iter_no_change=10,\n                    verbose=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator_svm = Pipeline(steps = [\n    ('feature_processing', combined_features),\n    ('classifier', svm)\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ngrid_param = {\n    'classifier__alpha': np.logspace(-4, 1, 10),\n    'classifier__loss': ['hinge', 'modified_huber', 'squared_hinge', 'perceptron'] \n}\n\ngsearch_svm = GridSearchCV(estimator = estimator_svm,\n                           param_grid = grid_param,\n                           scoring='accuracy',\n                           return_train_score=True,\n                           n_jobs=-1,\n                           verbose=2,\n                           cv=4)\n\ngsearch_svm.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gsearch_svm.best_params_, gsearch_svm.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation\ny_pred_train_svm = gsearch_svm.best_estimator_.predict(X_train)\ny_pred_val_svm = gsearch_svm.best_estimator_.predict(X_validation)\naccuracy_val = accuracy_score(y_validation, y_pred_val_svm)\n\nprint('accuracy_val: {}'.format(accuracy_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save submission file\ntime_now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\ny_pred_test_svm = gsearch_svm.best_estimator_.predict(X_test)\ncreate_submission(y_pred_test_svm, 'submissions/svm_gs_submission_{}.csv'.format(time_now))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model to disk\npickle.dump(gsearch_svm.best_estimator_.named_steps['classifier'], \\\n            open('model/svm_grid_search_{}.sav'.format(time_now), 'wb'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot features importances from XGBoost","metadata":{}},{"cell_type":"code","source":"feature_important = rsearch_xgb.best_estimator_.named_steps['classifier'].get_booster().get_score(importance_type='weight')\nkeys = list(feature_important.keys())\nvalues = list(feature_important.values())\n\nprint(rsearch_xgb.best_estimator_.named_steps['classifier'].get_booster().feature_names)\n\nprint(X_train.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_imp = pd.Series(feature_important).sort_values(ascending=False)\nfeat_imp.plot(kind='bar', title='Feature Importances')\nplt.ylabel('Feature Importance Score')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble of classifiers","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Define the list classifiers\nclassifiers=[('dt', gsearch_tree.best_estimator_), \n             ('xgb', rsearch_xgb.best_estimator_), \n             ('lr', gsearch_logreg.best_estimator_), \n             ('svm', gsearch_svm.best_estimator_),]\n\n# Instantiate a VotingClassifier vc\nvc = VotingClassifier(estimators=classifiers, voting='hard', n_jobs=-1) \n\n# Fit vc to the training set\nvc.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation\ny_pred_train_vc = vc.predict(X_train)\ny_pred_val_vc = vc.predict(X_validation)\naccuracy_val = accuracy_score(y_validation, y_pred_val_vc)\n\nprint('accuracy_val: {}'.format(accuracy_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log info\nlogger.info('VotingClassifier')\nlogger.warning('accuracy_val: {}'.format(accuracy_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save submission file\ntime_now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\ny_pred_test_vc = vc.predict(X_test)\ncreate_submission(y_pred_test_vc, 'submissions/vc_submission_{}.csv'.format(time_now))","metadata":{},"execution_count":null,"outputs":[]}]}