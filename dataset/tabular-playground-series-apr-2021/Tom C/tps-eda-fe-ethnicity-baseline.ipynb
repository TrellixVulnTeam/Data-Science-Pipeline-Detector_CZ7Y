{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"background-color:#F8C1EE; font-family:newtimeroman; font-size:250%; text-align:center; border-radius: 15px 50px;\"><b>Tabular Playground Series April</b> <br><br> EDA üîç, Outliers, Correlations and Baseline üìà</p>\n\n# <p style=\"background-color:#F8C1EE; font-family:newtimeroman; font-size:100%; text-align:center; border-radius: 15px 50px;\">Please <u>upvote</u> if you find this notebook useful or interesting, I really appreciate the encouragement. Thanks!</p>","metadata":{}},{"cell_type":"code","source":"!pip install ethnicolr\n!pip install pandas","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%capture\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom scipy.stats import norm\nimport scipy.stats as st\n\ntry:\n    from collections import OrderedDict\nexcept ImportError:\n    from ordereddict import OrderedDict\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom ethnicolr import census_ln, pred_census_ln\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ndisplay(df_train.head())\ndf_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_train.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_FEATURES = ['Age', 'Fare']\n\ncat_FEATURES = ['Pclass', 'Sex']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning the Dataset\n\n","metadata":{}},{"cell_type":"markdown","source":"### Invalid Values","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above we can see that there are null values appearing. #TOOD: Tidy these up","metadata":{}},{"cell_type":"markdown","source":"# Outliers","metadata":{}},{"cell_type":"code","source":"def plot_outliers(df, feature, threshold=5):\n    mean, std = np.mean(df), np.std(df)\n    z_score = np.abs((df-mean) / std)\n    good = z_score < threshold\n\n    print(f\"Rejection {(~good).sum()} points\")\n    visual_scatter = np.random.normal(size=df.size)\n    plt.scatter(df[good], visual_scatter[good], s=2, label=\"Good\", color=\"#4CAF50\")\n    plt.scatter(df[~good], visual_scatter[~good], s=8, label=\"Bad\", color=\"#F44336\")\n    plt.legend(loc='upper right')\n    plt.title(feature)\n    plt.show();\n    \n    return good\n\ndef plot_lof_outliers(df, feature):\n    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.001, p=1)\n    good = lof.fit_predict(df) > 0.5 # change this value to set the threshold for outliers\n    print(f\"Rejection {(~good).sum()} points\")\n    \n    visual_scatter = np.random.normal(size=df.size)\n    plt.scatter(df[good], visual_scatter[good], s=2, label=\"Good\", color=\"#4CAF50\")\n    plt.scatter(df[~good], visual_scatter[~good], s=8, label=\"Bad\", color=\"#F44336\")\n    plt.legend(loc='upper right')\n    plt.title(feature)\n    plt.show();\n    \n    return good","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Target Outliers","metadata":{}},{"cell_type":"markdown","source":"### Feature Outliers","metadata":{}},{"cell_type":"code","source":"for feature in cont_FEATURES:\n    print(feature)\n    plot_outliers(df_train[feature], feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see in the above that there aren't any reasonable outliers picked out. It has marked the high Fare's as outliers but we can see from the graph that this isn't a reasonabe thing to do.","metadata":{}},{"cell_type":"code","source":"for feature in cont_FEATURES:\n    # There some reshaping done here for syntax sake\n    data = df_train[~df_train[feature].isna()][feature]\n    plot_lof_outliers(data.values.reshape(data.shape[0], -1), feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a few outliers here but because they seem to be mixed in with the group I am going to leave them in the dataset. I imagine the `Age` outliers are just due to some ages being `X.5`.","metadata":{}},{"cell_type":"markdown","source":"# Analysing Distributions","metadata":{}},{"cell_type":"markdown","source":"### Continuous Variables","metadata":{}},{"cell_type":"code","source":"for feature in cont_FEATURES:\n    sns.violinplot(x='Survived', y=feature, data=df_train, inner='quartile');\n    plt.title(feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see that there are subtle differences in the `Fare` paid and whether someone survived. This could therefore be a very useful feature.","metadata":{}},{"cell_type":"markdown","source":"### Categorical Variables","metadata":{}},{"cell_type":"code","source":"for feature in cat_FEATURES:\n    print(feature)\n    sns.histplot(df_train[feature].values)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This shows us that the classes are balanced enough that they won't cause any issues for our models.","metadata":{}},{"cell_type":"markdown","source":"# Empirical CDFs","metadata":{}},{"cell_type":"code","source":"def plot_cdf(df, feature):\n    ps = 100 * st.norm.cdf(np.linspace(-4, 4, 10)) # The last number in this tuple is the number of percentiles\n    x_p = np.percentile(df, ps)\n\n    xs = np.sort(df)\n    ys = np.linspace(0, 1, len(df))\n\n    plt.plot(xs, ys * 100, label=\"ECDF\")\n    plt.plot(x_p, ps, label=\"Percentiles\", marker=\".\", ms=10)\n    plt.legend()\n    plt.ylabel(\"Percentile\")\n    plt.title(feature)\n    plt.show();\n\nfor feature in cont_FEATURES:\n    plot_cdf(df_train[feature], feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see that there is a significant skew in the `Fare` variable where 80% of the fares are below 100.","metadata":{}},{"cell_type":"markdown","source":"# Correlation","metadata":{}},{"cell_type":"code","source":"# This plots a 16x16 matrix of correlations between all the features and the target\n# Note: I sometimes comment this out because it takes a few minutes to run and doesn't show any useful information.\n\n#pd.plotting.scatter_matrix(df_train, figsize=(10, 10));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10)) \nsns.heatmap(df_train.drop(columns=['PassengerId']).corr(), annot=True, cmap='viridis', fmt='0.2f', ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This heatmap shows us that there are some weak correlations between `Survived` and other variables. This could be useful to us, but also shows that there is now *silver bullet* feature that will completely solve our problems.","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Features to create:\n- Passenger nationality (from their name)\n- How good a deal did they get on their cabin?","metadata":{}},{"cell_type":"markdown","source":"### Categorical Features\n\nHere we are extracting the letter and number from their class since this likely gives us a good idea of where there cabin was on the boat.","metadata":{}},{"cell_type":"code","source":"def get_class_letter(text):\n    if str(text) != 'nan':\n        return text[0]\n\ndef get_class_number(text):\n    if str(text) != 'nan':\n        return int(text[1:])\n\ndf_train['class_letter'] = df_train['Cabin'].apply(get_class_letter)\ndf_train['class_number'] = df_train['Cabin'].apply(get_class_number)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['class_letter'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['class_number'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummies = pd.get_dummies(df_train['Embarked'])\nfor col in dummies.columns:\n    df_train['embarked_' + col] = dummies[col] \n    \ndummies = pd.get_dummies(df_train['class_letter'])\nfor col in dummies.columns:\n    df_train['class_letter_' + col] = dummies[col] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummies = pd.get_dummies(df_train['Sex'])\nfor col in dummies.columns:\n    df_train['sex_' + col] = dummies[col] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Passenger Ethnicity and Nationality","metadata":{}},{"cell_type":"code","source":"ethnicity_features = ['pctwhite', 'pctblack', 'pctapi', 'pctaian', 'pct2prace', 'pcthispanic']\n\ndf_train['last_name'] = df_train['Name'].apply(lambda x: x.split(',')[0])\ndf_train = census_ln(df_train, 'last_name')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace the (S) values in the ethnicity columns with a 0\ndf_train[ethnicity_features] = df_train[ethnicity_features].replace('(S)', 0).astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ethnicity_features:\n    sns.violinplot(x='Survived', y=feature, data=df_train, inner='quartile');\n    plt.title(feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above shows us that there was an equal distribution for Survived and Died but the comparison between these features will be interesting to observe in the model training.","metadata":{}},{"cell_type":"markdown","source":"### Continuous Features\n\nNow we want to normalise our continuous variables, since the values of `Fare` (e.g. 400) are obviously much larger than `Age` (e.g. 21).","metadata":{}},{"cell_type":"code","source":"for feature in ['Fare', 'Age', 'pctwhite', 'pctblack', 'pctapi', 'pctaian', 'pct2prace', 'pcthispanic']:\n    x = df_train[feature].values.reshape(-1, 1) #returns a numpy array\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    df_train[feature] = pd.DataFrame(x_scaled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline","metadata":{}},{"cell_type":"code","source":"print(df_train.columns)\ndf_train.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create out Train and Test Sets","metadata":{}},{"cell_type":"code","source":"model_FEATURES = ['Pclass', 'sex_female', 'sex_male', 'Age', 'SibSp', 'Parch', 'Fare', \n                  'embarked_C', 'embarked_Q', 'embarked_S',\n                  'class_number', 'class_letter_A', 'class_letter_B', 'class_letter_C',\n                  'class_letter_D', 'class_letter_E', 'class_letter_F', 'class_letter_G',\n                  'class_letter_T', 'pctwhite', 'pctblack', 'pctapi', 'pctaian', 'pct2prace', 'pcthispanic']\n\nX = df_train[model_FEATURES].fillna(0)\ntarget = df_train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression\nclf = LogisticRegression(random_state=0).fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Logistic Regression Score: {clf.score(X_test, y_test)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forrest\n\nRandom forrests are known for being the some of the best models for performing classification and so it is always good to experiment with these models.","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(max_depth=4, random_state=123)\nrf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Random Forest Score: {rf.score(X_test, y_test)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"markdown","source":"### Preprocess Test Set","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\n\ndf_test['class_letter'] = df_test['Cabin'].apply(get_class_letter)\ndf_test['class_number'] = df_test['Cabin'].apply(get_class_number)\n\ndummies = pd.get_dummies(df_test['Embarked'])\nfor col in dummies.columns:\n    df_test['embarked_' + col] = dummies[col] \n    \ndummies = pd.get_dummies(df_test['class_letter'])\nfor col in dummies.columns:\n    df_test['class_letter_' + col] = dummies[col] \n\ndummies = pd.get_dummies(df_test['Sex'])\nfor col in dummies.columns:\n    df_test['sex_' + col] = dummies[col] \n    \ndf_test['last_name'] = df_test['Name'].apply(lambda x: x.split(',')[0])\ndf_test = census_ln(df_test, 'last_name')    \ndf_test[ethnicity_features] = df_test[ethnicity_features].replace('(S)', 0).astype(float)\n\nfor feature in ['Fare', 'Age', 'pctwhite', 'pctblack', 'pctapi', 'pctaian', 'pct2prace', 'pcthispanic']:\n    x = df_test[feature].values.reshape(-1, 1) #returns a numpy array\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    df_test[feature] = pd.DataFrame(x_scaled)\n\nX = df_test[model_FEATURES].fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = rf.predict(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predictions = pd.DataFrame(data={'PassengerId': df_test['PassengerId'], 'Survived': predictions})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predictions.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predictions.to_csv('predictions.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}