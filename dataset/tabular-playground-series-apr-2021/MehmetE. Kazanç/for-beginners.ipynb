{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score,recall_score,confusion_matrix\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2021/train.csv\")\nprint(train.shape)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2021/test.csv\")\nprint(test.shape)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv\")\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_id = submission[['PassengerId']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check the null ratio at first. Then, handle the missing rows. ","metadata":{}},{"cell_type":"code","source":"# Find the missing values as a percentage in each column\ndef findMissingPercent(training):\n    percent_missing = training.isnull().sum() * 100 / len(training)\n    missing_value_df = pd.DataFrame({'column_name': training.columns,\n                                     'percent_missing': percent_missing})\n    missing_value_df.sort_values(by = 'percent_missing', ascending = False, inplace= True)\n    \n    return missing_value_df.reset_index(drop=True)\n\nmissing = findMissingPercent(train)\nmissing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_test = findMissingPercent(test)\nmissing_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Analysis","metadata":{}},{"cell_type":"markdown","source":"#F1 Cabin","metadata":{}},{"cell_type":"code","source":"print(\"The Number of Unique Elements : {}\".format(len(train['Cabin'].unique())))\npd.DataFrame(train['Cabin'].value_counts()).head()\n\n#There are a lot of distinct numbers so decided to use the first character by filling \"Other:XX\" class for null rows. \n# So that we will have less number of category. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill missing value as a new category\ntrain['Cabin'] = train['Cabin'].fillna(\"XX\")\n\n# make that column as string\ntrain['Cabin'] = train['Cabin'].astype(str)\n\n# extract the first digit\ntrain['Cabin_fd'] = train['Cabin'].apply(lambda x: (x[:1]))\n\n# take value counts\ntrain['Cabin_fd'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the same strategy for the test set. \ntest['Cabin'] = test['Cabin'].fillna(\"XX\")\n\n# make that column as string\ntest['Cabin'] = test['Cabin'].astype(str)\n\n# extract the first digit\ntest['Cabin_fd'] = test['Cabin'].apply(lambda x: (x[:1]))\n\n# take value counts\ntest['Cabin_fd'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#F2 Ticket","metadata":{}},{"cell_type":"code","source":"# I could not find any idea for the ticket no. I'll skip for now :) \nprint(\"The Number of Unique Elements : {}\".format(len(train['Ticket'].unique())))\npd.DataFrame(train['Ticket'].value_counts()).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#F3 Age","metadata":{}},{"cell_type":"code","source":"print(\"The Number of Unique Elements : {}\".format(len(train['Age'].unique())))\npd.DataFrame(train['Age'].value_counts()).head()\n\n# I will fill null rows in the Age column by looking at pcass and gender information. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate a reference for missing age value \nmissing_age = train.groupby(['Pclass', 'Sex']).agg({'Age':'mean'})\nmissing_age","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill based on the reference table. \ntrain['Age_filled'] = train.apply(\n    lambda row: missing_age['Age'][(row['Pclass'], row['Sex'])] if np.isnan(row['Age']) else row['Age'],\n    axis=1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the same method for test set. \ntest['Age_filled'] = test.apply(\n    lambda row: missing_age['Age'][(row['Pclass'], row['Sex'])] if np.isnan(row['Age']) else row['Age'],\n    axis=1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#F4 Embarked","metadata":{}},{"cell_type":"code","source":"print(\"The Number of Unique Elements : {}\".format(len(train['Embarked'].unique())))\npd.DataFrame(train['Embarked'].value_counts()).head()\n\n# There are small number of categories. I will fill the missing data with the most frequent element \"S\". \ntrain['Embarked']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill based on the reference table. \ntrain['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode().iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the same method for test set. \ntest['Embarked'] = test['Embarked'].fillna(train['Embarked'].mode().iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#F5 Fare ","metadata":{}},{"cell_type":"code","source":"# Plot the histogram \ntrain.hist(column='Fare', bins = 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate a reference for missing Fare value \nmissing_fare = train.groupby(['Pclass', 'Embarked']).agg({'Fare':'mean'})\nmissing_fare","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill based on the reference table. \ntrain['Fare_filled'] = train.apply(\n    lambda row: missing_fare['Fare'][(row['Pclass'], row['Embarked'])] if np.isnan(row['Fare']) else row['Fare'],\n    axis=1\n)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the same method for the test set. \ntest['Fare_filled'] = test.apply(\n    lambda row: missing_fare['Fare'][(row['Pclass'], row['Embarked'])] if np.isnan(row['Fare']) else row['Fare'],\n    axis=1\n)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Until now, we have completed the missing value problem. In the next section, we may add new features. I skipped this part for now. Firsty, I will create a baseline model. ","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Find the correlation between all features and target","metadata":{}},{"cell_type":"code","source":"train.corr(method ='pearson')\n# There is a correlation for Fare (positive) and Age (positive) and Pclass (negative)\n# We may use this information to generate new features. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# calculate the correlation matrix\ncorr = train.corr(method ='pearson')\n\n# plot the heatmap\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare the Training Data, Test and Validation Data","metadata":{}},{"cell_type":"code","source":"X = train[['Pclass','Sex','Age_filled','SibSp', 'Parch','Fare_filled', 'Cabin_fd','Embarked']]\ny = train[['Survived']]\nprint(\"Training Data Feature Shape {}\".format(X.shape))\nprint(\"Training Data Target Shape {}\".format(y.shape))\n\nsubmission = test[['Pclass','Sex','Age_filled','SibSp', 'Parch','Fare_filled', 'Cabin_fd','Embarked']]\n\nprint(\"Submission Data Shape {}\".format(submission.shape))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Deal With Categorical Features ","metadata":{}},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def applyOneHot(X,col):\n\n    # Apply one-hot encoding for the training data. \n    enc_dow = OneHotEncoder(handle_unknown='ignore')\n\n    enc_df_dow = pd.DataFrame(enc_dow.fit_transform(X[[col]]).toarray())\n    enc_df_dow.columns = enc_dow.get_feature_names([col])\n\n    print(\"Encoded Shape is {} for {} \\n\".format(enc_df_dow.shape, col))\n    \n    \n    # merge with main df bridge_df on key values\n    #X_ = X.join(enc_df)\n    X = pd.concat([X, enc_df_dow], axis = 1 )\n    \n    return enc_dow, X\n\n\none_sex, X = applyOneHot(X,'Sex')\ndel X['Sex']\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"one_cabin, X = applyOneHot(X,'Cabin_fd')\ndel X['Cabin_fd']\n\none_embark, X = applyOneHot(X,'Embarked')\ndel X['Embarked']\n\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply one-hot encoding for the test data. \n\ndef encodeTestSet(enc, df, col):\n    \n    enc_df_dow_test = pd.DataFrame(enc.transform(df[[col]]).toarray())\n    enc_df_dow_test.columns = enc.get_feature_names([col])\n    print(\"Encoded Shape is {} \\n\".format(enc_df_dow_test.shape))\n\n    # Merge with main df bridge_df on key values\n    df = pd.concat([df, enc_df_dow_test], axis = 1 )\n    return df \n\n# Encode Gender\nsubmission = encodeTestSet(one_sex, submission, 'Sex')\n\n# Encode Cabin\nsubmission = encodeTestSet(one_cabin, submission, 'Cabin_fd')\n\n# Encode Gender\nsubmission = encodeTestSet(one_embark, submission, 'Embarked')\n\ndel submission['Cabin_fd']\ndel submission['Embarked']\ndel submission['Sex']\n\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply test train and validation split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=121)\n\nprint(\"Training Ratio   : {}%\".format(X_train.shape[0]*100 /X.shape[0]))\nprint(\"Test Ratio       : {}%\".format(X_test.shape[0]*100 /X.shape[0] ))\n\n# We obtained %85-%15 distribution. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There is no imbalance between ones and zeros in both dataset. \nprint(y_test[y_test['Survived'] == 0].shape[0]*100 / y_test.shape[0])\nprint(y_train[y_train['Survived'] == 0].shape[0]*100 / y_train.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define a RF Model","metadata":{}},{"cell_type":"code","source":"# I will test the number of estimators and max_depth. \n# You can also use GridSearch or RandomSearch in this step. \n\nn_estimators = [50,100,500]\nmax_depth= [5,10,20]\n\nfinalScores = pd.DataFrame(columns = ['n_estimators','max_depth', 'mean_accuracy', 'std_accuracy'])\n\ndef performRF(finalScores, X_train=X_train, y_train=y_train, n_splits = 5):\n    # I will apply cross validation to get model performance from the training set. \n    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    \n    cnt = 1\n    \n    for i in n_estimators: \n        for j in max_depth: \n            \n            rf = RandomForestClassifier(\n                n_estimators=i,\n                max_depth=j\n            )\n\n            score = cross_val_score(rf, X_train, y_train, cv= kf, scoring=\"accuracy\")\n            #print(f'Scores for each fold are: {score}')\n            #print(\"----\")\n            #print(\"n_estimators : {} and max_depth : {}\".format(i,j))\n            #print(f'Average score: {\"{:.2f}\".format(score.mean())}')  \n            #print(\"----\")\n            \n            series_obj = pd.Series( [i,j,score.mean(),score.std()], \n                        index=finalScores.columns )\n            \n            # Add a series as a row to the dataframe  \n            finalScores = finalScores.append(series_obj,\n                                    ignore_index=True)\n            \n            print(\"No {} completed. (Out of {} )\".format(cnt, len(n_estimators)*len(max_depth)))\n\n            cnt = cnt + 1 \n            \n            \n    return finalScores\n\nfinalScores = performRF(finalScores, X_train=X_train, y_train=y_train, n_splits = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalScores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Perform Random Forest Model","metadata":{}},{"cell_type":"code","source":"# create an RF Model \nrf = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=10,\n    max_features= 10\n)\n\n# Fit the model \nrf.fit(X_train, y_train)\n\n\ny_pred = rf.predict(X_test)\ny_pred_tr = rf.predict(X_train)\n\n# save prediction probabilities \npreds = rf.predict_proba(X_test)[:,1]\n\n\nprint(\"Training Accuracy : {}\".format(accuracy_score(y_train,y_pred_tr)))\nprint(\"Test Accuracy : {}\".format(accuracy_score(y_test,y_pred)))\nprint(\"-- \")\nprint(\"Test Recall : {}\".format(recall_score(y_test,y_pred)))\nprint(\"Test Confusion Matrix : \\n {}\".format(confusion_matrix(y_test,y_pred)))\n\n\n# We obtained a low accuracy with RF. Let's optimize it with more model parameters. \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotROC(y_test, preds, name):\n    \n    # generate a no skill prediction (majority class)\n    ns_probs = [0 for _ in range(len(preds))]\n\n    # calculate scores\n    ns_auc = roc_auc_score(y_test, ns_probs)\n    lr_auc = roc_auc_score(y_test, preds)\n    \n    # summarize scores\n    print('Random Guess: ROC AUC={0:.2f}'.format(ns_auc)) \n    \n    print(name + ': ROC AUC={0:.2f}'.format(lr_auc))\n    # calculate roc curves\n    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n    lr_fpr, lr_tpr, _ = roc_curve(y_test, preds)\n    # plot the roc curve for the model\n    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Random Guess')\n    plt.plot(lr_fpr, lr_tpr, marker='.', label=name)\n    # axis labels\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    # show the grid\n    plt.grid(True)\n    # show the legend\n    plt.legend()\n    # show the plot\n    plt.show()\n    \nplotROC(y_test , preds, 'Random Forest')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Perform LightGBM","metadata":{}},{"cell_type":"code","source":"# I will test the number of estimators and max_depth. \n# You can also use GridSearch or RandomSearch in this step. \n\nnum_leaves = [200,500]\nmax_depth= [3,5,10]\n\n    \nfinalScores = pd.DataFrame(columns = ['num_leaves','max_depth', 'mean_accuracy', 'std_accuracy'])\n\ndef performLGBM(finalScores, X_train=X_train, y_train=y_train, n_splits = 5,\n                num_leaves=num_leaves,max_depth =max_depth ):\n    # I will apply cross validation to get model performance from the training set. \n    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    \n    cnt = 1\n    \n    for i in num_leaves: \n        for j in max_depth: \n            \n            lg = lgb.LGBMClassifier(\n                num_leaves=i,\n                max_depth=j\n            )\n\n\n            score = cross_val_score(lg, X_train, y_train, cv= kf, scoring=\"accuracy\")\n            #print(f'Scores for each fold are: {score}')\n            #print(\"----\")\n            #print(\"n_estimators : {} and max_depth : {}\".format(i,j))\n            #print(f'Average score: {\"{:.2f}\".format(score.mean())}')  \n            #print(\"----\")\n            \n            series_obj = pd.Series( [i,j,score.mean(),score.std()], \n                        index=finalScores.columns )\n            \n            # Add a series as a row to the dataframe  \n            finalScores = finalScores.append(series_obj,\n                                    ignore_index=True)\n            \n            print(\"No {} completed. (Out of {} )\".format(cnt, len(num_leaves)*len(max_depth)))\n\n            cnt = cnt + 1 \n            \n            \n    return finalScores\n\nfinalScores = performLGBM(finalScores, X_train=X_train, y_train=y_train, n_splits = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalScores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build the lightgbm model\nlgbm = lgb.LGBMClassifier(num_leaves=200,max_depth=3,learning_rate = 0.1, num_iterations = 1000)\nlgbm.fit(X_train, y_train)\n\n\ny_pred = lgbm.predict(X_test)\ny_pred_tr = lgbm.predict(X_train)\n\n# save prediction probabilities \npreds = lgbm.predict_proba(X_test)[:,1]\n\n\nprint(\"Training Accuracy : {}\".format(accuracy_score(y_train,y_pred_tr)))\nprint(\"Test Accuracy : {}\".format(accuracy_score(y_test,y_pred)))\nprint(\"-- \")\nprint(\"Test Recall : {}\".format(recall_score(y_test,y_pred)))\nprint(\"Test Confusion Matrix : \\n {}\".format(confusion_matrix(y_test,y_pred)))\nprint(\"--\\n\")\n\n# We obtained a low accuracy with LightGBM. Let's optimize it with more model parameters. \n\nplotROC(y_test , preds, 'LightGBM')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I obtained similar results via RF and LightGBM. I will use the LightGBM for test. ","metadata":{}},{"cell_type":"markdown","source":"Also, you can observe the most important features. This can help us to improve our model. ","metadata":{}},{"cell_type":"code","source":"#import warnings\n#warnings.simplefilter(action='ignore', category=FutureWarning)\n\ndef plotImp(model, X , num = 20):\n    feature_imp = pd.DataFrame({'Value':model.feature_importances_,'Feature':X.columns})\n    plt.figure(figsize=(40, 21))\n    sns.set(font_scale = 4)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n                                                        ascending=False)[0:num])\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    #plt.savefig('lgbm_importances-01.png')\n    plt.show()\n\n\nplotImp(lgbm, X_train , num = 30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\n#shap.initjs()\n\n# compute SHAP values\nexplainer = shap.Explainer(lgbm, X_train)\nshap_values = explainer(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize the effects of all the features\nshap.plots.beeswarm(shap_values , max_display = 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.plots.bar(shap_values , max_display = 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare Submission File","metadata":{}},{"cell_type":"code","source":"submission_test = lgbm.predict(submission) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_id['Survived'] = submission_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_id.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_id.to_csv(\"submission__.csv\", index = False, encoding = 'utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I used some part of my code from the below links.\n\n#ref : https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/","metadata":{}}]}