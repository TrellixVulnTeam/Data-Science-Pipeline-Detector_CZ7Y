{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.impute import *\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')\ny = train.Survived\n\nprint(np.sum(train.PassengerId == test.PassengerId))\n\ntrain.drop(['PassengerId', 'Survived', 'Name', 'Ticket'], axis=1, inplace=True)\ntest.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n\ntrain.head()","metadata":{"id":"ZD-30jy9oqlM","outputId":"6e77612a-4895-43bf-8099-bae71d6a9ad5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_column = 'Age'\ntrain[train[target_column].notnull()].info()","metadata":{"id":"6Qz8_sxg2n0U","outputId":"319adb7e-f258-4d16-dfd8-8f3f9af557b7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_to_fit = []\nfor key in train.keys():\n    if key == target_column: continue\n    if train[target_column].notnull().sum() == train[train[target_column].notnull()][key].notnull().sum():\n        columns_to_fit.append(key)\n\ncolumns_to_fit","metadata":{"id":"uIEaWF4jv2Im","outputId":"fd4cb467-694b-4ebc-92ce-69ce23752df1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_append, to_append = [], []\nfor column in columns_to_fit:\n    if train[column].dtype == np.float64:\n        not_append.append(column)\n    else:\n        to_append.append(column)\nprint(not_append)\nprint(to_append)","metadata":{"id":"2ED48hCOx1OH","outputId":"e3efdc5c-dc5a-4a43-f506-5b8b858352b3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import *\n\nonehotencoder = OneHotEncoder()\ncategorical = train[train[target_column].notnull()][to_append]\nX = onehotencoder.fit_transform(categorical).toarray()","metadata":{"id":"kDAdWX_pzgrn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"id":"ZoiaSetK3JQR","outputId":"09029cc5-7bba-4149-ca8d-e7690c0d3c2a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.concatenate((X, train[train[target_column].notnull()][not_append]), axis=1)","metadata":{"id":"6Gx7KG-E2uQX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.metrics import mean_squared_error, accuracy_score\n\nmodel = DecisionTreeRegressor()\n# model = LinearRegression()\nmodel.fit(X, train[train[target_column].notnull()][target_column])\nyp = model.predict(X)\n\nprint(mean_squared_error(yp, train[train[target_column].notnull()][target_column]))","metadata":{"id":"IKSf76Rs0Ez3","outputId":"be82c141-3aae-4d23-c3cf-8a6ba3b29de2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Xt = onehotencoder.transform(train[train[target_column].isnull()][to_append]).toarray()\n# Xt = np.concatenate((Xt, train[train[target_column].isnull()][not_append]), axis=1)\n\n# ypt = model.predict(Xt)\n\nXt = onehotencoder.transform(train[to_append]).toarray()\nXt = np.concatenate((Xt, train[not_append]), axis=1)\n\nypt = model.predict(Xt)","metadata":{"id":"jd-X1HLw1TQJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = train[target_column].isnull() * ypt","metadata":{"id":"qbbiTrxj6-xP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimputer = SimpleImputer(missing_values=np.nan, strategy = 'mean')\nimputer = imputer.fit(train[['Age']])\nimputed_mean = imputer.transform(train[['Age']])\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 3))\n\naxes[0].hist(imputed_mean, bins=50)\naxes[1].hist(train[\"Age\"], bins=50)\naxes[2].hist(train[target_column] + result, bins=50)\n\nfig.tight_layout()\n\n#Age clearly has three age distributions, putting the average or median in place of \n#nan may not be the best strategy\n#I'll separate into categories during training\n#What to put in place of NAN? \n#forms of imput missing values\n#We will use Regression on the other features","metadata":{"id":"bonC8Q9j_I_J","outputId":"b05bad8a-98ef-4539-b489-4c4268115012","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.fillna({target_column: 0}, inplace=True)\ntrain[target_column] = train[target_column] + result","metadata":{"id":"-J8Zy1wl7xnX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nfrom sklearn.preprocessing import *\n\n#Impute with regression from other features\ndef doMethodImpute(data, target_column, model=DecisionTreeRegressor):\n    class doMethodImputeIntern():\n        def __init__(self, target_column, not_append, to_append, onehotencoder, model):\n            self.target_column = target_column\n            self.not_append = not_append\n            self.to_append = to_append\n            self.onehotencoder = onehotencoder\n            self.model = model\n\n        def transform(self, new_data):\n            Xt = self.onehotencoder.transform(new_data[self.to_append]).toarray()\n            Xt = np.concatenate((Xt, new_data[self.not_append]), axis=1)\n            ypt = self.model.predict(Xt)\n\n            result = new_data[self.target_column].isnull() * ypt\n            new_data.fillna({self.target_column: 0}, inplace=True)\n            new_data[self.target_column] = new_data[self.target_column] + result\n            return self\n\n    columns_to_fit = []\n    for key in data.keys():\n        if key == target_column: continue\n        if data[target_column].notnull().sum() == data[data[target_column].notnull()][key].notnull().sum():\n            columns_to_fit.append(key)\n\n    not_append, to_append = [], []\n    for column in columns_to_fit:\n        if data[column].dtype == np.float64:\n            not_append.append(column)\n        else:\n            to_append.append(column)\n\n    onehotencoder = OneHotEncoder()\n    categorical = data[data[target_column].notnull()][to_append]\n    X = onehotencoder.fit_transform(categorical).toarray()\n    X = np.concatenate((X, data[data[target_column].notnull()][not_append]), axis=1)\n\n    model = model()\n    model.fit(X, data[data[target_column].notnull()][target_column])\n    yp = model.predict(X)\n\n    Xt = onehotencoder.transform(data[to_append]).toarray()\n    Xt = np.concatenate((Xt, data[not_append]), axis=1)\n    ypt = model.predict(Xt)\n\n    result = data[target_column].isnull() * ypt\n    data.fillna({target_column: 0}, inplace=True)\n    data[target_column] = data[target_column] + result\n    return doMethodImputeIntern(target_column, not_append, to_append, onehotencoder, model)","metadata":{"id":"XFiK-s0vAAFj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = doMethodImpute(train, 'Age')\nimputer.transform(test)","metadata":{"id":"96kkoOGcBumA","outputId":"0ad8bada-6997-420f-d9f2-3c750aae668d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"id":"6gH-KNERHMHW","outputId":"b7da4def-40bf-4929-a368-7c08996ebab7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"id":"EIBQuh9IHPB7","outputId":"2bc35da3-3421-44e7-8e2a-5c2dfb6cb178","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = doMethodImpute(train, 'Fare')\nimputer.transform(test)","metadata":{"id":"eKhlHKQoHVlz","outputId":"9ae0e1fd-c762-4ce1-b4cc-4813ddd4b738","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"id":"pMmlIm-d-gpr","outputId":"d317c104-f625-4991-f09b-e9c2ad123efe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train['Age'].interpolate(method='linear', inplace=False, limit_direction=\"both\")","metadata":{"id":"uBJJDbvF6EyA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Embarked'].hist()","metadata":{"id":"BhB6Y_c_I-Ny","outputId":"04fcb7fb-04b2-4616-f727-d241890be68a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.fillna({'Cabin': \"NE\"}, inplace=True)\ntest.fillna({'Cabin': \"NE\"}, inplace=True)\n\ntrain.fillna({'Embarked': \"NE\"}, inplace=True)\ntest.fillna({'Embarked': \"NE\"}, inplace=True)","metadata":{"id":"gt2SoK4NMdH2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data in [train, test]:\n    cabins_vec = []\n    for i in data['Cabin']:\n        if str(i) == 'NE':\n            cabins_vec.append(\"NE\")\n        else:\n            cabins_vec.append(i[0])\n    data['Cabin'] = pd.Series(cabins_vec)","metadata":{"id":"KSAHGo3zNXpL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data in [train, test]:\n    embk_vec = []\n    for i in data['Embarked']:\n        if str(i) == 'NE':\n            embk_vec.append(\"NE\")\n        else:\n            embk_vec.append(i)\n    data['Embarked'] = pd.Series(embk_vec)","metadata":{"id":"0ncoqh6UOJ1l","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Cabin'], train['Embarked']","metadata":{"id":"YrpuhOI3OEyi","outputId":"7ce10715-c165-49e9-d401-df77b98503da","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Cabin'].hist()","metadata":{"id":"S5mNAxK6PJVd","outputId":"b2780e68-05ef-4623-c979-5cbd59a4cc33","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Embarked'].hist()","metadata":{"id":"qsw6g7dDPXdF","outputId":"d1111af9-e893-4afb-e933-f32d2b6d19e1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"id":"FNv_tsNNP7sb","outputId":"a201788a-c5f6-42a8-84b0-d911edec0ff4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Other options for Impute\n# train.fillna({'Cabin': 0}, inplace=True)\n# test.fillna({'Cabin': 0}, inplace=True)\n\n# imputer = SimpleImputer(missing_values=np.nan, strategy = 'mean')\n# imputer = imputer.fit(train[['Age']])\n# train[['Age']] = imputer.transform(train[['Age']])\n# test[['Age']] = imputer.transform(test[['Age']])\n\n# #usando a mediana porque Fare varia muito, é skew\n# #log também ajuda a reduzir skewness\n# imputer = SimpleImputer(missing_values=np.nan, strategy = 'median')\n# imputer = imputer.fit(train[['Fare']])\n# train[['Fare']] = imputer.transform(train[['Fare']])\n# test[['Fare']] = imputer.transform(test[['Fare']])\n\n# train.fillna('notEval', inplace=True)\n# test.fillna('notEval', inplace=True)\n\n# train[[\"Fare\"]] = train[[\"Fare\"]].apply(pd.to_numeric)\n# test[[\"Fare\"]] = test[[\"Fare\"]].apply(pd.to_numeric)","metadata":{"id":"T2xnnZFlplfs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Age.hist()","metadata":{"id":"7THNSyv5Q0WC","outputId":"af283729-f9b2-4a94-8709-6baa4a837635","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import KBinsDiscretizer\n\n#DISCRETIZATION of Age and Fare\nenc = KBinsDiscretizer(n_bins=10, encode='onehot')\nenc = enc.fit(train['Age'].to_numpy().reshape(-1, 1))\nAge_discretized_train = enc.transform(train['Age'].to_numpy().reshape(-1, 1))\nAge_discretized_test = enc.transform(test['Age'].to_numpy().reshape(-1, 1))\n# print(Age_discretized_train)\n\n#Fare we are going to separate at intervals because there is high concentration in a region,\n#and log because Fare has an asymmetric distribution \nbefore_normalization_train_fare = train['Fare'].copy()\ntrain['Fare'] = np.log(train['Fare'])\ntest['Fare'] = np.log(test['Fare'])\nenc = KBinsDiscretizer(n_bins=20, encode='onehot')\nenc = enc.fit(train['Fare'].to_numpy().reshape(-1, 1))\nFare_discretized_train = enc.transform(train['Fare'].to_numpy().reshape(-1, 1))\nFare_discretized_test = enc.transform(test['Fare'].to_numpy().reshape(-1, 1))\n","metadata":{"id":"o_A4q4DcRFMn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\n\naxes[0].hist(before_normalization_train_fare, bins=50)\naxes[1].hist(train[\"Fare\"], bins=50)\nfig.tight_layout()\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import *\ncategorical_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked']\ncat = train[categorical_features]\ncat_t = test[categorical_features]\nonehotencoder = OneHotEncoder()\nX = onehotencoder.fit_transform(cat).toarray()\nXt =  onehotencoder.fit_transform(cat_t).toarray()","metadata":{"id":"PSLVe5PepA29","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.concatenate([X, Age_discretized_train.toarray(), Fare_discretized_train.toarray()], axis=1)\nXt = np.concatenate((Xt, Age_discretized_test.toarray(), Fare_discretized_test.toarray()), axis=1)","metadata":{"id":"_hGTTcPkVEeq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","metadata":{"id":"q_hd2PuFWtJ8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, accuracy_score\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\nyp = model.predict(X_train)\n\nprint(mean_squared_error(yp, y_train))\nbest_mse = 10000\nbest_i = 0\nfor i in range(2000):\n    yp1 = yp > i/1000\n    r = mean_squared_error(yp1, y_train)\n    if r < best_mse:\n        best_mse = r\n        best_i = i\n        # print(best_mse)\nprint(best_mse)\nprint(best_i)\nyp1 = yp > best_i/1000\nprint(accuracy_score(y_train, yp1))\nyp = model.predict(X_test)\n\nprint(mean_squared_error(yp, y_test))\nyp1 = yp > best_i/1000\nprint(mean_squared_error(yp1, y_test))\nprint(accuracy_score(y_test, yp1))","metadata":{"id":"avuULA0_pD4k","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import TheilSenRegressor, LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nfrom xgboost import XGBClassifier\nacc_train = []\nacc_test = []\n","metadata":{"id":"OpkkFrP6pH68","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = XGBClassifier(learning_rate=0.05 + 4*0.01)\nmodel = XGBClassifier(n_jobs=-1)\nmodel.fit(X, y)\n\nyp = model.predict(Xt)\n\nwith open('pred.csv', 'w') as out, open('/kaggle/input/tabular-playground-series-apr-2021/test.csv') as inp:\n    out.write('PassengerId,Survived\\n')\n    inp.readline()\n    for v in yp:\n        line = inp.readline().split(\",\")[0]\n        out.write(line + \",\" + str(int(v)) + \"\\n\")","metadata":{"id":"KtvDLjfIaCAj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import TheilSenRegressor, LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nfrom xgboost import XGBClassifier\nacc_train = []\nacc_test = []\n\n# model = XGBClassifier(learning_rate=0.5)\n\n\nmodel = XGBClassifier(base_score=0.1, gamma=1, min_child_weight=3, max_depth=5, n_jobs=-1)\nmodel.fit(X_train, y_train)\nyp = model.predict(X_train)\nacc_train = accuracy_score(yp, y_train)\n\nyp = model.predict(X_test)\nacc_test = accuracy_score(yp, y_test)\n\nprint(acc_train)\nprint(acc_test)\n","metadata":{"id":"rA3AcVVAbckd","trusted":true},"execution_count":null,"outputs":[]}]}