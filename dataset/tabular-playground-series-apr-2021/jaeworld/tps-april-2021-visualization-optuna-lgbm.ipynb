{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS April 2021 - Visualization + Optuna + LGBM ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom lightgbm import LGBMClassifier\nimport optuna\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nprimary_bgcolor = \"#f4f0ea\"\nprimary_palette = ['#ed4f37', '#40aff5']\nplt.rcParams['axes.facecolor'] = primary_bgcolor\nplt.rcParams['figure.dpi'] = 120","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. EDA & Visualization","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train shape: ', train.shape)\nprint('Test shape: ', test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features with null elements\n\nWhich feature has null elements? And how much?","metadata":{}},{"cell_type":"code","source":"null_count_df = train.isnull().sum().reset_index(name='count')\nnull_count_df['count'] = (null_count_df['count'] / train.shape[0]) * 100\nnull_count_df.sort_values(by='count', ascending=False, inplace=True)\nnull_count_df = null_count_df[null_count_df['count'] != 0]\n\nax = plt.figure(figsize=(5, 5))\nplt.title('Features with null elements')\nax = sns.barplot(x=null_count_df['index'], y=[100]*5, color='#e9f1f2')\nax = sns.barplot(data=null_count_df, x='index', y='count', palette='Set2')\n\nfor p in ax.patches:\n    val = '{:.2f}%'.format((p.get_height()))\n    ax.annotate(val, (p.get_x()+0.1, p.get_height()+1.8), va='center')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\"Cabin\" has the most null elements, having a null proportion of 67.87%.","metadata":{}},{"cell_type":"markdown","source":"### Number of people survived\n\nHow many people survived and didn't survive? Let's find out.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nsns.catplot(data=train, x='Survived', kind='count', palette=primary_palette)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Numerical / Categorial features distribution - who survived?\n\nTo find out what kind of passengers did or didn't survive, let's take a look at the distribution.\n","metadata":{}},{"cell_type":"code","source":"ft_cols = train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1).columns\nnum_cols = ['Age', 'Fare']\ncat_cols = train[ft_cols].drop(num_cols, axis=1).columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Numerical features","metadata":{}},{"cell_type":"code","source":"def kde_plot_num_cols(cols, train):\n    L = len(cols)\n    nrow = int(np.ceil(L/2))\n    ncol = 2\n    \n    plt.subplots(nrow, ncol, figsize=(24, 6))\n    plt.suptitle('Numerical features distribution')\n    i = 1\n    \n    for col in cols:\n        plt.subplot(nrow, ncol, i)\n        sns.kdeplot(data=train, x=col, shade=True, hue='Survived', palette=primary_palette)\n        i += 1\n        \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kde_plot_num_cols(num_cols, train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Categorial features","metadata":{}},{"cell_type":"code","source":"def count_plot_cat_cols(cols, train):\n    L = len(cols)\n    nrow = int(np.ceil(L/2))\n    ncol = 2\n    remove_last = (nrow*ncol) - L\n    \n    fig, ax = plt.subplots(nrow, ncol, figsize=(15, 15))\n    plt.suptitle('Categorial features distribution')\n    ax.flat[-remove_last].set_visible(False)\n    i = 1\n    \n    for col in cols:\n        plt.subplot(nrow, ncol, i)\n        sns.countplot(data=train, x=col, hue='Survived', alpha=0.7, palette=primary_palette)\n        plt.legend()\n        i += 1\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_plot_cat_cols(cat_cols, train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Modeling","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing\n\nFor categorial features, I will do some label encoding.","metadata":{}},{"cell_type":"code","source":"data_combined = pd.concat([train, test], axis=0)\n\ncat_cols = train.drop(['PassengerId', 'Survived'], axis=1).dtypes[train.dtypes != 'float64'].index.tolist()\n\nle = LabelEncoder()\n\nfor col in cat_cols:\n    le.fit(data_combined[col])\n    data_combined[col] = le.transform(data_combined[col])\n    \ntrain_df = data_combined[:len(train)]\ntest_df = data_combined[len(train):]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train size: ', train_df.shape)\nprint('Test size: ', test_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter tuning (Optuna)\n\nLet's find the optimal hyperparameter using Optuna in order to get the best score. ","metadata":{}},{"cell_type":"code","source":"X = train_df.drop('Survived', axis=1)\ny = train_df['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial, data=X, target=y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n    \n    params = {\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 11, 300),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth': trial.suggest_int('max_depth', 5, 20),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.01,0.02,0.05,0.005,0.1]),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.5),\n        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n        'random_state': 42,\n        'boosting_type': 'gbdt',\n    }\n    \n    model = LGBMClassifier(**params)\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=200, verbose=False)\n    pred = model.predict(X_test)\n    acc_score = accuracy_score(y_test, pred)\n    \n    return acc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\n\nbest_params = study.best_trial.params\nprint('Best model by Optuna: ', best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After a long iteration, I finally got the best parameters! Now let's move on to the prediction part.","metadata":{}},{"cell_type":"markdown","source":"## Prediction (LGBM)","metadata":{}},{"cell_type":"markdown","source":"Let's make predictions using the best parameter I've got from Optuna.\nI used LightGBM Classifier to make the prediction.","metadata":{}},{"cell_type":"code","source":"cols = [col for col in train_df.columns if col not in ['PassengerId', 'Survived']]\n\nkfold = StratifiedKFold(5, shuffle=True, random_state=0)\nscores = []\npreds = []\n\nfor fold, (train_index, test_index) in enumerate(kfold.split(train_df[cols], train_df['Survived']), 1):\n    train_f, test_f = train_df.iloc[train_index], train_df.iloc[test_index]\n    \n    X_train = train_f[cols]\n    X_test = test_f[cols]\n    y_train = train_f['Survived']\n    y_test = test_f['Survived']\n    lgbm_clf = LGBMClassifier(**best_params)\n    \n    lgbm_clf.fit(X_train, y_train)\n    pred = lgbm_clf.predict(X_test)\n    acc_score = accuracy_score(y_test, pred)\n    pred_test = lgbm_clf.predict(test_df[cols])\n    preds.append(pred_test)\n    scores.append(acc_score)\n    \n    print(f'Fold {fold}, Accuracy score: {acc_score:.5f}')\n    \nprint(f'Average accuracy score: {np.mean(scores)}')\n\npred = np.array(preds).mean(axis=0).round()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At last, I got my final prediction! It shows average accuracy score of 0.78431. ","metadata":{}},{"cell_type":"markdown","source":"## Make submission","metadata":{}},{"cell_type":"code","source":"sample_submission['Survived'] = np.rint(pred)\nsample_submission['Survived'] = sample_submission['Survived'].apply(int)\nsample_submission.to_csv('lgbm_submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}