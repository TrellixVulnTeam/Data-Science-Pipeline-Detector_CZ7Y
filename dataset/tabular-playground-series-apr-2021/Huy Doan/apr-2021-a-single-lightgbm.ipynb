{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nimport lightgbm as lgb\nimport optuna\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET = 'Survived'\ntrain_df = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\nsubmission = pd.read_csv('../input/81722/23_08_v5.csv')\ntest_df['Survived'] = submission['Survived']\nall_df = pd.concat([train_df, test_df.sample(frac = 0.4)]).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Age fillna with mean age for each class\nage_map = all_df[['Age', 'Pclass']].dropna().groupby('Pclass').mean().to_dict()\nall_df.Age = all_df.Age.fillna(all_df.Pclass.map(age_map['Age']))\n\n# Cabin, fillna with 'X' and take first letter\nall_df.Cabin = all_df.Cabin.fillna('X').map(lambda x: x[0].strip())\n\n# Ticket, fillna with 'X', split string and take first split \nall_df.Ticket = all_df.Ticket.fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\n# Fare, fillna with mean value\nfare_map = all_df[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\nall_df['Fare'] = all_df['Fare'].fillna(all_df['Pclass'].map(fare_map['Fare']))\nall_df['Fare'] = np.log1p(all_df['Fare'])\n\n# Embarked, fillna with 'X' value\nall_df.Embarked = all_df.Embarked.fillna('X')\n\n# Name, take only surnames\nall_df.Name = all_df.Name.map(lambda x: x.split(',')[0])\n#family\nall_df['FamilySize'] = all_df['SibSp'] + all_df['Parch'] + 1\nall_df['IsAlone'] = np.where(all_df['FamilySize']<=1,1,0)\n#cabin\n\nall_df['Cabin'] = all_df[\"Cabin\"].fillna('X').map(lambda x: x[0].strip())\nall_df['Has_Cabin'] = all_df[\"Cabin\"].apply(lambda x: 0 if (x != 'X') else 1)\ncabin_map = {'A' : 1,'B' : 2, 'C' : 3, 'D' : 4, 'E' : 5, 'F' : 6, 'G' : 7, 'T' : 1, 'X': 8}\nall_df['Cabin'] = all_df['Cabin'].str[0].fillna('X').replace(cabin_map)\n#Embarked\nall_df['Embarked'] = all_df['Embarked'].fillna(\"No\")\nconditions = [\n    (all_df['Embarked']==\"S\"),\n    (all_df['Embarked']==\"Q\"),\n    (all_df['Embarked']==\"C\"),\n    (all_df['Embarked']==\"No\")\n]\nchoices = [0, 1, 2, -1]\nall_df[\"Embarked\"] = np.select(conditions, choices)\nall_df['Embarked'] = all_df['Embarked'].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_cols = [ 'Ticket', 'Sex', 'IsAlone', 'Has_Cabin']\nonehot_cols = ['Cabin', 'Embarked']\nnumerical_cols = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass', 'FamilySize']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encoder(c):\n    le = LabelEncoder()\n    return le.fit_transform(c)\n\nscaler = StandardScaler()\n\nonehot_encoded_df = pd.get_dummies(all_df[onehot_cols])\nlabel_encoded_df = all_df[label_cols].apply(label_encoder)\nnumerical_df = pd.DataFrame(scaler.fit_transform(all_df[numerical_cols]), columns=numerical_cols)\ntarget_df = all_df[TARGET]\n\nall_df = pd.concat([label_encoded_df, numerical_df, onehot_encoded_df], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = all_df[:train_df.shape[0]]\ntarget = train.pop('Survived')\ntest = all_df[train_df.shape[0]:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_ft = train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial,data=all_df,target=target_df):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data[lgb_ft], target, test_size=0.15,random_state=42)\n    params = {\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 11, 333),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth': trial.suggest_int('max_depth', 5, 20),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.05, 0.005, 0.1]),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.5),\n        'n_estimators': trial.suggest_int('n_estimators', 2000, 8000),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 10, 100),\n        'cat_l2': trial.suggest_int('cat_l2', 1, 20),\n        'min_data_per_group': trial.suggest_int('min_data_per_group', 50, 200),\n        'cat_feature' : [0,1,2,3],\n        'n_jobs' : -1, \n        'random_state': 26,\n        'boosting_type': 'gbdt',\n        'metric': 'binary_logloss',\n        'objective' : 'binary',\n        'device': 'gpu'\n    }\n    model = LGBMClassifier(**params)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)], early_stopping_rounds=300, verbose=False)\n    \n    preds = model.predict(test_x)\n    \n    acc = accuracy_score(test_y , preds)\n    \n    return acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = study.best_trial.params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params['random_state'] = 26\nparams['device'] = 'gpu'\nparams['n_jobs'] = -1 \nparams['cat_feature'] = [0,1,2,3]\nparams['boosting_type'] =  'gbdt'\nparams['metric'] =  'binary_logloss'\nparams['objective'] = 'binary'\nparams","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NFOLDS = 2\nfolds = StratifiedKFold(n_splits=NFOLDS, random_state=26, shuffle=True)\nsplits = folds.split(all_df, target_df)\nlgb_train_preds = np.zeros(all_df.shape[0])\nlgb_test_preds = np.zeros(test.shape[0])\nfor fold, (train_index, test_index) in enumerate(splits):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    X_train, X_valid = all_df[lgb_ft].iloc[train_index], all_df[lgb_ft].iloc[test_index]\n    y_train, y_valid = target_df.iloc[train_index], target_df.iloc[test_index]\n    pre_model = LGBMClassifier(**params).fit(X_train, y_train, \n                                                  eval_set=[(X_valid, y_valid)],  \n                                                  early_stopping_rounds=300, verbose = 0)\n    params2 = params.copy()\n    params2['learning_rate'] = params['learning_rate']*0.1\n    model = LGBMClassifier(**params).fit(X_train, y_train, \n                                                  eval_set=[(X_valid, y_valid)],  \n                                                  early_stopping_rounds=300, verbose = 0,\n                                                  init_model = pre_model)\n    train_oof_preds = model.predict(X_valid)\n    test_oof_preds = model.predict(test[lgb_ft])\n    lgb_train_preds[test_index] = train_oof_preds\n    lgb_test_preds += test_oof_preds / NFOLDS\n    print(\": LGB - Accuracy Score = {}\".format(accuracy_score(y_valid, train_oof_preds)))\n\nprint(\"--> Overall metrics\")\nprint(\": LGB - Accuracy Score = {}\".format(accuracy_score(target_df, lgb_train_preds)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')\nsub['Survived'] = np.round(lgb_test_preds).astype(int)\nregr_table = sub.to_csv(\"25_04_v1.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}