{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import neural_network\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport missingno as msno\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas import Series, DataFrame\nimport lightgbm as lgb\n#import optuna.integration.lightgbm as lgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Import data","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.DataFrame(train)\ndf_test = pd.DataFrame(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Preprocessing","metadata":{}},{"cell_type":"code","source":"df_all = pd.concat([df_train.drop(columns='Survived'),df_test],ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Search for missing data\n\nmsno.matrix(df=df_all, figsize=(20,14), color=(0,.3,.3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Embarked2 = []\nfor i in range(len(df_all)):\n    if df_all[\"Embarked\"][i] == \"S\":\n        Embarked2.append(1)\n    elif df_all[\"Embarked\"][i] == \"C\":\n        Embarked2.append(2)\n    elif df_all[\"Embarked\"][i] == \"Q\":\n        Embarked2.append(3)\n    else:\n        Embarked2.append(4)\ndf_all = df_all.drop(columns=\"Embarked\")\ndf_all[\"Embarked\"] = Embarked2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all[\"FamilySize\"] = df_all[\"SibSp\"] + df_all[\"Parch\"] + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"FamilySize\"][i] == 1:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"isAlone\"] = ary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"FamilySize\"][i] == 2:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"isPair\"] = ary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"Embarked\"][i] == 1:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"English\"] = ary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"Embarked\"][i] == 2:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"French\"] = ary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add columns\nary = []\nfor i in range(len(df_all)):\n    if df_all[\"Embarked\"][i] == 3:\n        ary.append(1)\n    else:\n        ary.append(0)\ndf_all[\"Irish\"] = ary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# String label to categorical values\n\nfor i in range(df_all.shape[1]):\n    if df_all.iloc[:,i].dtypes == object:\n        lbl = LabelEncoder()\n        lbl.fit(list(df_all.iloc[:,i].values))\n        df_all.iloc[:,i] = lbl.transform(list(df_all.iloc[:,i].values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing data (Age, Fare) fill in median\nfor column in df_all.columns:\n    df_all[column] = df_all[column].fillna(df_all[column].median())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.merge(df_all.iloc[df_train.index[0]:df_train.index[-1]+1],df_train['Survived'],left_index=True,right_index=True)\ndf_test = df_all.iloc[df_train.index[-1]+1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Check the correlation for each item","metadata":{}},{"cell_type":"code","source":"df_train_corr = df_train.corr()\ndf_train_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.heatmap(df_train_corr, vmin=-1, vmax=1, center=0, square=False, annot=True, cmap='coolwarm');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Extract items with high correlation coefficient","metadata":{}},{"cell_type":"code","source":"predictor_cols = []\nfor i in df_train_corr:\n    if df_train_corr[i]['Survived'] > 0.01 or df_train_corr[i]['Survived'] < -0.01:\n        innerName = df_train_corr[i].name\n        if innerName != 'Survived':\n            predictor_cols.append(innerName)\npredictor_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Modeling","metadata":{}},{"cell_type":"code","source":"x = DataFrame(df_train[predictor_cols])\nt = DataFrame(df_train['Survived'])\n\nx = np.array(x)\nt = np.array(t)\nt = t.ravel()\n\nx = x.astype('float32')\nt = t.astype('int32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scaling\nfeatures = preprocessing.minmax_scale(x[:, :])\n\n# split data for train and test\nx_train, x_test, t_train, t_test = train_test_split(features, t.ravel(), test_size=0.2)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clf = neural_network.MLPClassifier(max_iter=200,\n#                                   hidden_layer_sizes=(100,),\n#                                   activation=\"relu\",\n#                                   solver=\"adam\",\n#                                   alpha=0.0001,\n#                                   tol=0.0001,\n#                                   verbose=True)\n#clf.fit(x_train, t_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LightGBM\nlgb_train = lgb.Dataset(x_train, t_train)\nlgb_test = lgb.Dataset(x_test, t_test)\nparams = {\n    'objective': 'binary',\n    \"metric\":\"binary_logloss\",\n    \"learning_rate\":0.01\n}\n\ngbm = lgb.train(\n    params,\n    train_set = lgb_train,\n    valid_sets = [lgb_train, lgb_test],\n    num_boost_round = 20000,\n    early_stopping_rounds = 100,\n    verbose_eval = 100\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict = clf.predict(x_test)\n#accuracy = accuracy_score(t_test, predict)\n#precision = precision_score(t_test, predict)\n#recall = recall_score(t_test, predict)\n#f1 = f1_score(t_test, predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Prediction","metadata":{}},{"cell_type":"code","source":"testData = DataFrame(df_test[predictor_cols])\ntestData = np.array(testData)\ntestData = testData.astype('float32')\n\n# scaling\ntestData = preprocessing.minmax_scale(testData[:, :])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#result = clf.predict(testData)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = gbm.predict(testData, num_iteration=gbm.best_iteration)\n\nresult = np.where(prediction < 0.51, 0, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Make submission file","metadata":{}},{"cell_type":"code","source":"outputArray = []\nPassengerId = 100000\nfor i in range(len(result)):\n    predict = result[i]\n    innerArray = [PassengerId, predict]\n    outputArray.append(innerArray)\n    PassengerId += 1\ndf = pd.DataFrame(outputArray, columns=['PassengerId', 'Survived'])\ndf.to_csv(path_or_buf='submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}