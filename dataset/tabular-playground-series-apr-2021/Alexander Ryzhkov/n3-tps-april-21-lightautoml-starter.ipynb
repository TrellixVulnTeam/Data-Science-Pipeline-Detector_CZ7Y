{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Please upvote if you find the notebook useful :)\n\n#### If you are new to LightAutoML, [here](https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/231090) is the explanation discussion topic\n\n#### In this notebook we try to incorporate features from [this notebook](https://www.kaggle.com/jmargni/tps-apr-2021-lightgbm-cv) to our LightAutoML solution to show how it can be done in real ML tasks.\n#### To make difference inside pseudolabelling process we also added Catboost algo with params from [this](https://www.kaggle.com/belov38/catboost-lb) notebook\n\n### The main idea of this kernel is pseudolabelling the test data (described in details [here](https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/231738)) and building model using our opensourced framework [LightAutoML](https://github.com/sberbank-ai-lab/LightAutoML).\n\n# Step 0.0. Install LightAutoML","metadata":{"papermill":{"duration":0.015469,"end_time":"2021-04-03T16:21:29.656074","exception":false,"start_time":"2021-04-03T16:21:29.640605","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pip install -U lightautoml","metadata":{"_kg_hide-output":true,"papermill":{"duration":22.772933,"end_time":"2021-04-03T16:21:52.443667","exception":false,"start_time":"2021-04-03T16:21:29.670734","status":"completed"},"tags":[],"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.1. Import necessary libraries ","metadata":{"papermill":{"duration":0.042647,"end_time":"2021-04-03T16:21:52.531114","exception":false,"start_time":"2021-04-03T16:21:52.488467","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%matplotlib inline\n\n# Standard python libraries\nimport os\nimport time\nimport re\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport matplotlib.pyplot as plt\n\n# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\nfrom lightautoml.utils.profiler import Profiler","metadata":{"papermill":{"duration":7.015224,"end_time":"2021-04-03T16:21:59.590712","exception":false,"start_time":"2021-04-03T16:21:52.575488","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.2. Parameters ","metadata":{"papermill":{"duration":0.042116,"end_time":"2021-04-03T16:21:59.675455","exception":false,"start_time":"2021-04-03T16:21:59.633339","status":"completed"},"tags":[]}},{"cell_type":"code","source":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 10 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 3*3600 # Time in seconds for automl run","metadata":{"papermill":{"duration":0.049379,"end_time":"2021-04-03T16:21:59.767542","exception":false,"start_time":"2021-04-03T16:21:59.718163","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.3. Fix torch number of threads and numpy seed ","metadata":{"papermill":{"duration":0.042043,"end_time":"2021-04-03T16:21:59.852048","exception":false,"start_time":"2021-04-03T16:21:59.810005","status":"completed"},"tags":[]}},{"cell_type":"code","source":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","metadata":{"papermill":{"duration":0.049551,"end_time":"2021-04-03T16:21:59.945","exception":false,"start_time":"2021-04-03T16:21:59.895449","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.4. Data load ","metadata":{"papermill":{"duration":0.042682,"end_time":"2021-04-03T16:22:00.030176","exception":false,"start_time":"2021-04-03T16:21:59.987494","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\n\ntrain_data = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntrain_data.head()","metadata":{"papermill":{"duration":0.35255,"end_time":"2021-04-03T16:22:00.42489","exception":false,"start_time":"2021-04-03T16:22:00.07234","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\ntest_data.head()","metadata":{"papermill":{"duration":0.348853,"end_time":"2021-04-03T16:22:00.81794","exception":false,"start_time":"2021-04-03T16:22:00.469087","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')\nsubmission.head()","metadata":{"papermill":{"duration":0.087514,"end_time":"2021-04-03T16:22:00.949025","exception":false,"start_time":"2021-04-03T16:22:00.861511","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we use our almost best submission\npseudo_label_test = pd.read_csv('../input/n3-tps-april-21-lightautoml-starter/LightAutoML_compose_version_25.csv')\npseudo_label_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['Survived'] = pseudo_label_test['Survived'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.5. Add new features\n\n#### Important note: below we can see new features creation from [this notebook](https://www.kaggle.com/jmargni/tps-apr-2021-lightgbm-cv) but I have deleted all NaNs filling if they don't use test data to do it","metadata":{"papermill":{"duration":0.04351,"end_time":"2021-04-03T16:22:01.036366","exception":false,"start_time":"2021-04-03T16:22:00.992856","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#ref.: https://www.kaggle.com/jmargni/tps-apr-2021-lightgbm-cv\n\ndef create_extra_features(data):\n    # Age fillna with mean age for each class\n    age_map = data[['Age', 'Pclass']].dropna().groupby('Pclass').mean().to_dict()\n    data.Age = data.Age.fillna(data.Pclass.map(age_map['Age']))\n\n    # Cabin, fillna with 'X' and take first letter\n    data.Cabin = data.Cabin.map(lambda x: str(x)[0].strip())\n\n    # Ticket, fillna with 'X', split string and take first split \n    data.Ticket = data.Ticket.map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\n    # Fare, fillna with mean value \n    # (THE ONLY FILLNA LEFT BECAUSE HERE WE USE TEST DATASET - LightAutoML can't do it in real life because of strict distinction between train and test stages)\n    data.Fare = data.Fare.fillna(data.Fare.mean())\n\n    # Embarked, fillna with 'X' value\n    #all_df.Embarked = all_df.Embarked.fillna('X')\n    \n    # Name, take only surnames\n    #data.Name = data.Name.map(lambda x: str(x).split(',')[0])\n       \n    # let's leave this features here to use after receiving plateau from pseudolabelling\n    \n    data['FirstName'] = data.Name.map(lambda x: str(x).split(',')[0])\n    data['Surname'] = data.Name.map(lambda x: str(x).split(',')[1])\n    \n    for col in ['Name', 'FirstName', 'Surname']:\n        data['Counter_' + col] = data[col].map(data.groupby(col)['PassengerId'].count().to_dict())\n        \n    data.drop(columns = ['Name', 'Surname'], inplace = True)\n\n    \n    return data\n","metadata":{"papermill":{"duration":4.017589,"end_time":"2021-04-03T16:22:05.098325","exception":false,"start_time":"2021-04-03T16:22:01.080736","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df = pd.concat([train_data, test_data]).reset_index(drop = True)\nall_df = create_extra_features(all_df)\ntrain_data, test_data = all_df[:len(train_data)], all_df[len(train_data):]\nprint(train_data.shape, test_data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ========= AutoML preset usage =========\n\n\n# Step 1. Create Task","metadata":{"papermill":{"duration":0.04484,"end_time":"2021-04-03T16:22:05.308526","exception":false,"start_time":"2021-04-03T16:22:05.263686","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\ndef acc_score(y_true, y_pred, **kwargs):\n    return accuracy_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\ndef roc_auc_metric(y_true, y_pred, sample_weight, **kwargs):\n    mask = (sample_weight > 1)\n    return roc_auc_score(y_true[mask], y_pred[mask])\n\ntask = Task('binary', metric = roc_auc_metric, greater_is_better=True)","metadata":{"papermill":{"duration":0.05691,"end_time":"2021-04-03T16:22:05.40975","exception":false,"start_time":"2021-04-03T16:22:05.35284","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2. Setup columns roles","metadata":{"papermill":{"duration":0.044199,"end_time":"2021-04-03T16:22:05.498676","exception":false,"start_time":"2021-04-03T16:22:05.454477","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Add weights for metric calculation only by true targets\nall_df['weight'] = [1.01] * len(train_data) + [0.99] * len(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nroles = {\n    'target': 'Survived',\n    'drop': ['PassengerId'],\n    'weights': 'weight' # To calculate metric only on real targets\n}","metadata":{"papermill":{"duration":0.053114,"end_time":"2021-04-03T16:22:05.596262","exception":false,"start_time":"2021-04-03T16:22:05.543148","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3. Train on full data (train + pseudolabeled by best submission test) using multistart with different seed and predict on test data\n\nAs we currently have a bug in TabularUtilizedAutoML with specific configs setup (it will be fixed in the next release), we will use simple for cycle by random states to do the job. ","metadata":{"papermill":{"duration":0.044438,"end_time":"2021-04-03T16:22:05.685429","exception":false,"start_time":"2021-04-03T16:22:05.640991","status":"completed"},"tags":[]}},{"cell_type":"code","source":"params = {\n    'metric': 'binary_logloss',\n    'n_estimators': 10000,\n    'objective': 'binary',\n    'learning_rate': 0.02,\n    'min_child_samples': 150,\n    'reg_alpha': 3e-5,\n    'reg_lambda': 9e-2,\n    'num_leaves': 20,\n    'max_depth': 16,\n    'colsample_bytree': 0.8,\n    'subsample': 0.8,\n    'subsample_freq': 2,\n    'max_bin': 240\n}\n\ncb_params = {\n    'max_depth':6,\n    'max_ctr_complexity': 5,\n    'num_trees': 50000,\n    'od_wait': 500,\n    'od_type':'Iter', \n    'learning_rate': 0.04,\n    'min_data_in_leaf': 3\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\ncnt_trained = 0\nresults = []\nfor it, rs in enumerate(range(2000, 2015)):\n    print('=' * 30)\n    print('START RANDOM_STATE = {}'.format(rs))\n    print('=' * 30)\n    \n    # Train AutoML\n    automl = TabularAutoML(task = task, \n                           timeout = TIMEOUT,\n                           cpu_limit = N_THREADS,\n                           general_params = {'use_algos': [['linear_l2', 'lgb', 'cb']]},\n                           selection_params = {'mode': 0},\n                           reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': rs},\n                           lgb_params = {'default_params': params, 'freeze_defaults': True},\n                           cb_params = {'default_params': cb_params, 'freeze_defaults': True})\n    \n    oof_pred = automl.fit_predict(all_df, roles = roles)\n    \n    # Predict on test\n    test_pred = automl.predict(test_data)\n    cnt_trained += 1\n    \n    # Save predictions\n    if it == 0:\n        oof_pred_full = oof_pred.data[:, 0].copy()\n        test_pred_full = test_pred.data[:, 0].copy()\n    else:\n        oof_pred_full += oof_pred.data[:, 0]\n        test_pred_full += test_pred.data[:, 0]\n    \n    # Check scores for current predict and aggregated one\n    acc_usual = acc_score(train_data['Survived'].values, oof_pred.data[:len(train_data), 0])\n    acc_full = acc_score(train_data['Survived'].values, oof_pred_full[:len(train_data)] / cnt_trained)\n    results.append((acc_usual, acc_full, acc_full - acc_usual))\n    \n    print('Check scores...')\n    print('OOF score: {}'.format(acc_usual))\n    print('OOF score full: {}'.format(acc_full))\n    print('Difference: {}'.format(acc_full - acc_usual))","metadata":{"_kg_hide-output":true,"papermill":{"duration":14087.307332,"end_time":"2021-04-03T20:16:53.037414","exception":false,"start_time":"2021-04-03T16:22:05.730082","status":"completed"},"tags":[],"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4. Graphic check for received results","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20, 10))\nplt.plot(range(1, cnt_trained + 1), [res[0] for res in results], color = 'b', linewidth = 2, label = 'Usual LightAutoML model accuracy')\nplt.plot(range(1, cnt_trained + 1), [res[1] for res in results], color = 'g', linewidth = 2, label = 'Accuracy for averaged LightAutoMLs')\nplt.grid()\nplt.legend()\nplt.title('LightAutoML accuracy vs. averaged LightAutoMLs composition accuracy')\nplt.xlabel('Iteration number')\nplt.ylabel('Accuracy score')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_acc = np.mean([res[0] for res in results])\nmean_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"differences = np.array([res[1] - mean_acc for res in results])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20, 10))\nplt.plot(range(1, cnt_trained + 1), differences, color = 'g', linewidth = 2, label = 'Difference')\nplt.plot(range(1, cnt_trained + 1), [np.mean(differences[0:i+1]) for i in range(len(differences))], 'b-.', linewidth = 2, label = 'Cumulative mean difference')\nplt.plot(range(1, cnt_trained + 1), [0.0 for res in results], 'r--', linewidth = 2, label = 'Zero line')\nplt.grid()\nplt.legend()\nplt.title('Difference between mean LightAutoML accuracy and averaged LightAutoMLs composition accuracy at each iteration')\nplt.xlabel('Iteration number')\nplt.ylabel('Accuracy score difference')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Everything ok, we are above zero line and cumulative mean difference in scores is growing :)","metadata":{}},{"cell_type":"markdown","source":"# Step 5. Prepare submission","metadata":{"papermill":{"duration":1.00707,"end_time":"2021-04-03T20:18:15.852725","exception":false,"start_time":"2021-04-03T20:18:14.845655","status":"completed"},"tags":[]}},{"cell_type":"code","source":"submission['Survived'] = ((test_pred_full / cnt_trained) > 0.5).astype(int)\nsubmission.to_csv('LightAutoML_compose_version_26.csv', index = False)","metadata":{"papermill":{"duration":1.092803,"end_time":"2021-04-03T20:18:17.928007","exception":false,"start_time":"2021-04-03T20:18:16.835204","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Survived'].mean()","metadata":{"papermill":{"duration":0.990399,"end_time":"2021-04-03T20:18:19.906244","exception":false,"start_time":"2021-04-03T20:18:18.915845","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}