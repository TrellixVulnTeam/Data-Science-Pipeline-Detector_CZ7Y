{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set() \n#import missingno\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\n        \ninput_path = Path('/kaggle/input/tabular-playground-series-apr-2021/')\n\n#from matplotlib import pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(input_path / 'train.csv', index_col='PassengerId')\ndisplay(train.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(input_path / 'test.csv', index_col='PassengerId')\ndisplay(test.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(input_path / 'sample_submission.csv', index_col='PassengerId')\ndisplay(submission.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Analysis","metadata":{}},{"cell_type":"code","source":"#Split numerical and categorical variables\ndf_num = train[['Age','SibSp', 'Parch', 'Fare']]\ndf_cat = train[['Survived', 'Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Numerical variables","metadata":{}},{"cell_type":"code","source":"#histograms of numberical variables\nfig, axes = plt.subplots(1, 4, figsize=(22,6))\nfig.suptitle('Distribution of numerical variables')\n\nsns.histplot(x = train['Age'],kde=True, ax=axes[0])\nsns.histplot(x = train['SibSp'],kde=True, ax=axes[1])\nsns.histplot(x = train['Parch'],kde=True, ax=axes[2])\nsns.histplot(x = train['Fare'],kde=True, ax=axes[3])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlations\nprint(df_num.corr())\nsns.heatmap(df_num.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Average values for survivors vs deceased\npd.pivot_table(train, index = 'Survived', values = df_num.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data = train, x = 'Age',kde=True, hue = 'Survived', col= 'Pclass')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data = train, x = 'Age',kde=True, hue = 'Survived', col= 'Sex')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Categorical variables","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(22,6))\nfig.suptitle('Distribution of categorical variables')\n#'Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked']]\nsns.barplot(x = 'Sex', y = 'Survived', data = train, ax=axes[0])\nsns.barplot(x = 'Pclass', y = 'Survived', data = train, ax=axes[1])\nsns.barplot(x = 'Embarked', y = 'Survived', data = train, ax=axes[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Embarked by class - greater proportion of 3rd class in Southampton, could be linked with lower surviaval rate\nsns.catplot(x='Pclass', col = 'Embarked', data = train, kind = 'count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"#Cabin letter, n = nan\ntrain['cabin_lett'] = train.Cabin.apply(lambda x: str(x)[0])\ntest['cabin_lett'] = test.Cabin.apply(lambda x: str(x)[0])\n#print(train.cabin_lett.value_counts())\npd.pivot_table(train, index = 'Survived', columns = 'cabin_lett', values = 'Ticket', aggfunc = 'count')\n\n#Cabin number\ntrain['cabin_num'] = train.Cabin.str.extract('(\\d+)',expand=True,)\ntrain.cabin_num = pd.to_numeric(train.cabin_num)\ntest['cabin_num'] = test.Cabin.str.extract('(\\d+)',expand=True,)\ntest.cabin_num = pd.to_numeric(test.cabin_num)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x = 'cabin_lett', y = 'Survived', data = train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#log fare\ntrain['log_Fare'] = np.log(train.Fare +1)\ntest['log_Fare'] = np.log(test.Fare +1)\nsns.displot(data = train, x = 'log_Fare',kde=True, hue = 'Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['family'] = train.SibSp + train.Parch\ntest['family'] = test.SibSp + test.Parch\n#train.head()\nsns.kdeplot(data = train, x = 'family',shade=True, hue = 'Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['log_Fam'] = np.log(train.family+1)\ntest['log_Fam'] = np.log(test.family+1)\nsns.kdeplot(data = train, x = 'log_Fam',shade=True, hue = 'Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sex and class\ntrain_Pclass_str = train.Pclass.apply(str)\ntrain['Who'] = train.Sex + train_Pclass_str\n\ntest_Pclass_str = test.Pclass.apply(str)\ntest['Who'] = test.Sex + test_Pclass_str","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Name split\ntrain[['last_name','first_name']] = train.Name.str.split(\", \",expand=True,)\ntest[['last_name','first_name']] = test.Name.str.split(\", \",expand=True,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ticket split\n\ntrain['ticket_num'] = train.Ticket.str.extract('(\\d+)',expand=True,)\ntrain.ticket_num = pd.to_numeric(train.ticket_num)\ntrain['log_ticket_num'] = np.log(train.ticket_num+1)\ntrain['ticket_lett'] = train.Ticket.replace('(\\d)', '', regex=True)\n\ntest['ticket_num'] = test.Ticket.str.extract('(\\d+)',expand=True,)\ntest.ticket_num = pd.to_numeric(test.ticket_num)\ntest['log_ticket_num'] = np.log(test.ticket_num+1)\ntest['ticket_lett'] = test.Ticket.replace('(\\d)', '', regex=True)\n\n#train.ticket_lett.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"#imputing null values\ntrain.Embarked = train.Embarked.fillna(value = 'N')\ntrain.Age = train.Age.fillna(train.Age.mean())\n#train.Fare = train.Fare.fillna(train.Fare.median())\ntrain.log_Fare = train.log_Fare.fillna(train.log_Fare.median())\n#train.Cabin = train.Cabin.fillna(0)\ntrain.Ticket = train.Ticket.fillna(0)\ntrain.ticket_lett = train.ticket_lett.fillna('')\ntrain.ticket_num = train.ticket_num.fillna(train.ticket_num.mean())\ntrain.cabin_num = train.cabin_num.fillna(train.cabin_num.mean())\ntrain.log_ticket_num = train.log_ticket_num.fillna(train.log_ticket_num.median())\n\ntest.Embarked = test.Embarked.fillna(value = 'N')\ntest.Age = test.Age.fillna(test.Age.mean())\n#test.Fare = test.Fare.fillna(test.Fare.median())\n#test.Cabin = test.Cabin.fillna(0)\ntest.Ticket = test.Ticket.fillna(0)\ntest.log_Fare = test.log_Fare.fillna(test.log_Fare.median())\ntest.ticket_lett = test.ticket_lett.fillna('')\ntest.ticket_num = test.ticket_num.fillna(test.ticket_num.mean())\ntest.log_ticket_num = test.log_ticket_num.fillna(test.log_ticket_num.median())\ntest.cabin_num = test.cabin_num.fillna(test.cabin_num.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.pop('Cabin')\ntrain.pop('Ticket')\ntrain.pop('Sex')\ntrain.pop('Fare')\ntrain.pop('Name')\ntrain.pop('log_ticket_num')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.pop('Cabin')\ntest.pop('Ticket')\ntest.pop('Fare')\ntest.pop('Sex')\ntest.pop('Name')\ntest.pop('log_ticket_num')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#label encoding catergoricals\nfor c in train.columns:\n    if train[c].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(train[c].values) + list(test[c].values))\n        train[c] = lbl.transform(train[c].values)\n        test[c] = lbl.transform(test[c].values)\n        \ndisplay(train.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Split data into train and validation**","metadata":{}},{"cell_type":"code","source":"target = train.pop('Survived')\nX_train, X_valid, y_train, y_valid = train_test_split(train, target, train_size=0.75, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model tuning","metadata":{}},{"cell_type":"code","source":"XGBoost","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import libaries, run a grid search to find best paramters for model\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nxgb_model = XGBClassifier(use_label_encoder=False,eval_metric = \"logloss\")\nparams_xgb = [\n    {'n_estimators':[10,100,250,500],\n     'max_depth':[2,4,6,8],\n     'learning_rate':[0.1,0.05,0.01],\n     'min_child_weight':[1,2,4,6,8]}]\n\ngrid_search = GridSearchCV(xgb_model, params_xgb, cv=5, scoring='accuracy', n_jobs=1)\ngrid_search.fit(train,target)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Base model 0.77925 {'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 250}\nThen start adding in new features from feauture engineering section to find if they improve model, and tune parameters again.","metadata":{}},{"cell_type":"code","source":"#gridsearch again but with narrower parameters\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nxgb_model = XGBClassifier(learning_rate=0.05,use_label_encoder=False,eval_metric = \"logloss\")\nparams_xgb = [\n    {'n_estimators':[200,225,250,275,300,325,350,375],\n     'max_depth':[3,4,5],\n     'min_child_weight':[7,8,9,10]}]\n\ngrid_search = GridSearchCV(xgb_model, params_xgb, cv=5, scoring='accuracy', n_jobs=1)\ngrid_search.fit(train,target)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LightGBM ","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nlgbm = LGBMClassifier(learning_rate=0.05, num_leaves=35, max_depth=7, n_estimators=160, feature_fraction=0.7, reg_alpha=0.6)\nparams_lgb = [\n    { 'reg_lambda': [0.5,0.6,0.7]}]\n    #reg_alpha = 0.2,\n    #reg_lambda = 0.4)}]\n\ngrid_search = GridSearchCV(lgbm, params_lgb, cv=5, scoring='accuracy', n_jobs=1)\ngrid_search.fit(train,target)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nclf_model = CatBoostClassifier(iterations =575, depth=6, learning_rate = 0.05, l2_leaf_reg=0.4, eval_metric = \"Logloss\")\nparams_clf = [\n    {'':[100,200,500]}]\n    # 'iterations':[10,100,250,500],\n     #'depth':[2,4,6,8]}]\n\ngrid_search = GridSearchCV(clf_model, params_clf, cv=5, scoring='accuracy', n_jobs=1)\ngrid_search.fit(train,target)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0.7844300000000001\n{0.05 learning rate, 'depth': 6, 'iterations': 500}","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nclf_model = CatBoostClassifier(learning_rate = 0.05, iterations=575,depth=6, l2_leaf_reg = 10, border_count = 32, eval_metric = \"Logloss\")\nparams_clf = [\n    {\n     'border_count':[32,5,10,20,50,100,200]}]\n     \n\ngrid_search = GridSearchCV(clf_model, params_clf, cv=5, scoring='accuracy', n_jobs=1)\ngrid_search.fit(train,target)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0.7845799999999999\n{'depth': 6, 'iterations': 575","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score\n\nclf = CatBoostClassifier(iterations =575, depth=6, learning_rate = 0.05, l2_leaf_reg=0.4, eval_metric = \"Logloss\")\nclf.fit(X_train, y_train,  \n        eval_set=(X_valid, y_valid), \n        verbose=False\n)\npredictions = clf.predict(X_valid)\nprint(predictions)\nprint(accuracy_score(predictions, y_valid))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model fitting","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom xgboost import plot_importance\nfrom sklearn.metrics import accuracy_score\n\nmodel = XGBClassifier(n_estimators=275,learning_rate=0.05,max_depth=4,min_child_weight=8,use_label_encoder=False,eval_metric = \"logloss\")\nmodel.fit(train,target)\npredictions = model.predict(test)\nprint(predictions)\n\nplot_importance(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = CatBoostClassifier(iterations =575, depth=6, learning_rate = 0.05, l2_leaf_reg=0.4, eval_metric = \"Logloss\")\nclf.fit(train,target)\npredictions = clf.predict(test)\nprint(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm = LGBMClassifier(learning_rate=0.05, num_leaves=35, max_depth=7, n_estimators=160, feature_fraction=0.7, reg_alpha=0.6)\nlgbm.fit(train,target)\npredictions = lgbm.predict(test)\nprint(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create submission file\nsub = pd.DataFrame({'PassengerId':test.index, 'Survived':predictions})\nsubmission = sub.set_index('PassengerId')\nsubmission.to_csv('cat-a.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are my final accuracy scores for my predictions made via my three models. \nXGBClassifier:      private score = 0.79520 (best score)\n                    public score  = 0.79724 \nCatBoostClassifier: private score = 0.79362 (top 43%)\n                    public score  = 0.79757\nLGBMClassifier:     private score = 0.79515\n                    public score  = 0.79700\n\nXGBClassifier outperformed the other two models with the private dataset with 79.520% accuracy. The CatBoostClassifier model performed the best in the public score, and was automatically used as the final submission for the Kaggle rankings, placing me in the top 43% of entrants.  ","metadata":{}}]}