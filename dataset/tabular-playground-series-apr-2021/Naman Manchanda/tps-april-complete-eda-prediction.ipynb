{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2 style=\"font-size:35px; background-color:orange; text-align:center; color:blue\">TPS April'21 </h2>","metadata":{}},{"cell_type":"markdown","source":"**The notebook consists of the following:-**\n1. Importing libraries\n2. Understanding Data\n3. Visualising Missing Data\n4. Exploratory Data Analysis\n   - Univariate Analysis\n   - Bivariate Analysis\n7. Data preprocessing\n8. Modeling and Prediction","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"font-size:35px; background-color:#8072fa; text-align:center; color:#fac472\">Importing libraries</h2>","metadata":{}},{"cell_type":"code","source":"# Data manipulation libraries\nimport numpy as np\nimport pandas as pd\nimport missingno as msno\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Avoid Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-size:35px; background-color:#8072fa; text-align:center; color:#fac472\">Understanding Data</h2>","metadata":{}},{"cell_type":"code","source":"print(train.shape)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.shape)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that there are missing values in both train and test data.","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"font-size:35px; background-color:#8072fa; text-align:center; color:#fac472\">Visualising Missing Data</h2>","metadata":{}},{"cell_type":"code","source":"msno.matrix(train, color = (.30, .20, .89), figsize=(8,8))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One more way to visualize using seaborn heatmap\nplt.figure(figsize=(10,10))\nsns.heatmap(train.isnull(), center=1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing data in train data\nmissing_percentages = (train[train.columns].isnull().sum() / train.shape[0]) * 100\nmissing_percentages","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing data in test data\nmissing_percentages_test = (test[test.columns].isnull().sum() / test.shape[0]) * 100\nmissing_percentages_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total missing data counts in train and test data\nmissing_values_count = train.isnull().sum()\nmissing_values_count_test = test.isnull().sum()\n\n# find the percentage of missing data in training data\ntotal_cells = np.product(train.shape)\ntotal_missing = missing_values_count.sum()\npercent_missing = (total_missing / total_cells)*100\nprint(\"The percentage of total missing data from the training dataset is :\", percent_missing, \"%\")\n\n# find the percentage of missing data in testing data\ntotal_cells_test = np.product(test.shape)\ntotal_missing_test = missing_values_count_test.sum()\npercent_missing_test = (total_missing_test / total_cells_test)*100\nprint(\"The percentage of total missing data from the testing dataset is :\", percent_missing_test, \"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The columns with missing values are*\n- Age\n- Ticket\n- Fare\n- Cabin\n- Embarked","metadata":{}},{"cell_type":"code","source":"train.describe().transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-size:35px; background-color:#8072fa; text-align:center; color:#fac472\">Exploratory Data Analysis</h2>","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train.columns:\n    print(\"The number of unique values in {} is {}\".format(i, len(train[i].unique())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The categorical features are*\n- Pclass\n- Sex\n- Embarked\n- Parch\n- SibSp\n\n*The continuous features are*\n- Age\n- Fare\n\n*The ones which will be dealt manually are*\n- Ticket\n- Cabin\n- Name","metadata":{}},{"cell_type":"code","source":"categorical_features = [\"Pclass\",\"Sex\",\"Embarked\",\"Parch\",\"SibSp\"]\ncontinuous_features = [\"Age\",\"Fare\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-size:35px; background-color:#8072fa; text-align:center; color:#fac472\">Univariate Analysis</h2>","metadata":{}},{"cell_type":"markdown","source":"> Understanding the target variable - Survived","metadata":{}},{"cell_type":"code","source":"# Checking the count & distribution of Survived\nfig = plt.figure(figsize=(15,8))\nplt.subplot(1,2,1)\nax = sns.countplot(x=\"Survived\",data=train)\nplt.subplot(1,2,2)\nsns.distplot(train.loc[: ,'Survived'], hist_kws={\"color\":\"r\"}, kde_kws={\"color\":\"b\", \"lw\":2})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The percentage of people who didn't survive :\",((train['Survived'] == 0).sum() / train.shape[0]) * 100)\nprint(\"The percentage of people who did survive :\",((train['Survived'] == 1).sum() / train.shape[0]) * 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Understanding the features","metadata":{}},{"cell_type":"markdown","source":"**Pclass**","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,8))\nplt.subplot(1,2,1)\nax = sns.countplot(x=\"Pclass\",data=train)\nplt.subplot(1,2,2)\nsns.distplot(train.loc[: ,\"Pclass\"], hist_kws={\"color\":\"r\"}, kde_kws={\"color\":\"b\", \"lw\":2})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The percentage of people in class 1 :\",((train['Pclass'] == 1).sum() / train.shape[0]) * 100)\nprint(\"The percentage of people in class 2 :\",((train['Pclass'] == 2).sum() / train.shape[0]) * 100)\nprint(\"The percentage of people in class 3 :\",((train['Pclass'] == 3).sum() / train.shape[0]) * 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Parch**","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,8))\nplt.subplot(1,2,1)\nax = sns.countplot(x=\"Parch\",data=train)\nplt.subplot(1,2,2)\nsns.distplot(train.loc[: ,\"Parch\"], hist_kws={\"color\":\"r\"}, kde_kws={\"color\":\"b\", \"lw\":2})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SibSp**","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,8))\nplt.subplot(1,2,1)\nax = sns.countplot(x=\"SibSp\",data=train)\nplt.subplot(1,2,2)\nsns.distplot(train.loc[: ,\"SibSp\"], hist_kws={\"color\":\"r\"}, kde_kws={\"color\":\"b\", \"lw\":2})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sex**","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(6,6))\nsns.set_palette([\"#8072fa\",\"orange\"])\nax = sns.countplot(x=\"Sex\",data=train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The percentage of people who are male :\",((train['Sex'] == \"male\").sum() / train.shape[0]) * 100)\nprint(\"The percentage of people who are female :\",((train['Sex'] == \"female\").sum() / train.shape[0]) * 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Embarked**","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(6,6))\nsns.set_palette([\"#8072fa\",\"orange\",\"Red\"])\nax = sns.countplot(x=\"Embarked\",data=train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The percentage of people embarked at S :\",((train['Embarked'] == \"S\").sum() / train.shape[0]) * 100)\nprint(\"The percentage of people embarked at C :\",((train['Embarked'] == \"C\").sum() / train.shape[0]) * 100)\nprint(\"The percentage of people embarked at Q :\",((train['Embarked'] == \"Q\").sum() / train.shape[0]) * 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,14))\nfor index,col in enumerate(continuous_features):\n    plt.subplot(4,1,index+1)\n    sns.boxplot(train.loc[:, col], color=\"#8072fa\",linewidth=2.5)\nfig.tight_layout(pad = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Fare has a lot of outliers.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,14))\nfor index,col in enumerate(continuous_features):\n    plt.subplot(4,1,index+1)\n    sns.distplot(train.loc[:, col], color=\"orange\", kde_kws={\"color\":\"r\", \"lw\":2})\nfig.tight_layout(pad = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-size:35px; background-color:#8072fa; text-align:center; color:#fac472\">Bivariate Analysis</h2>","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cr = train.corr(method='pearson')\nfig = px.imshow(cr)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(data_frame=train,\n                   x=\"Survived\",\n                   y=None,\n                   color='Sex',\n                   width=500,\n                   template=\"plotly_dark\",\n                  color_discrete_map={\"male\":\"#8072fa\",\"female\":\"orange\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly, more females survived than males.","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(data_frame=train,\n                   x=\"Embarked\",\n                   y=None,\n                   color='Survived',\n                   width=500,\n                   template=\"plotly_dark\",\n                  color_discrete_map={1:\"#8072fa\",0:\"orange\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the people who embarked at Southampton didn't survive. Most of the people who embarked at Cherbourg survived.","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(data_frame=train,\n                   x=\"Pclass\",\n                   y=None,\n                   color='Survived',\n                   width=500,\n                   template=\"plotly_dark\",\n                  color_discrete_map={0:\"#8072fa\",1:\"orange\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(data_frame=train,\n                   x=\"Parch\",\n                   y=None,\n                   color='Survived',\n                   width=500,\n                   template=\"plotly_dark\",\n                  color_discrete_map={1:\"#8072fa\",0:\"orange\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(data_frame=train,\n                   x=\"SibSp\",\n                   y=None,\n                   color='Survived',\n                   width=500,\n                   template=\"plotly_dark\",\n                  color_discrete_map={1:\"#8072fa\",0:\"orange\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-size:35px; background-color:#8072fa; text-align:center; color:#fac472\">Data Preprocessing</h2>","metadata":{}},{"cell_type":"markdown","source":"**Conclusions from the EDA**\n- There are NaNs value in\n    1. Age\n    2. Ticket\n    3. Fare\n    4. Cabin\n    5. Embarked\n- The people who survived and the people who didn't are almost equally distributed in train data.\n- There are a lot of outliers in Fare feature since the distribution curve of Fare is highly right-skewed.\n- The correlation graph doesn't show any significant correlation between features, so no dimensionality reduction can be performed. \n- Parch and SibSp represent the number of parents and siblings respectively. These can be added to form a feature of relatives.","metadata":{}},{"cell_type":"markdown","source":"> Handling missing data","metadata":{}},{"cell_type":"code","source":"train['Age'].fillna(train['Age'].mean(),inplace=True)\ntest['Age'].fillna(train['Age'].mean(),inplace=True)\n\ntrain['Fare'].fillna(train['Fare'].mean(),inplace=True)\ntest['Fare'].fillna(train['Fare'].mean(),inplace=True)\n\ntrain['Embarked'].fillna(train['Embarked'].mode()[0],inplace=True)\ntest['Embarked'].fillna(train['Embarked'].mode()[0],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ticket number,Cabin & Name number doesn't seem to influence Survival. ","metadata":{}},{"cell_type":"code","source":"train.drop(['Name','Ticket','Cabin','PassengerId'], axis=1, inplace=True)\ntest.drop(['Name','Ticket','Cabin','PassengerId'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Applying a log function to reduce the influence of outliers in Fare column. Since there are a large number of outliers, removing them will lead to loss of a large numberof points.","metadata":{}},{"cell_type":"code","source":"train['Fare'] = train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\ntest['Fare'] = test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8,6))\nsns.distplot(train.loc[:, 'Fare'],color='orange',kde_kws={\"color\":\"r\", \"lw\":2})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding Parch and SibSp into one feature","metadata":{}},{"cell_type":"code","source":"train[\"relatives\"] = train[\"Parch\"] + train[\"SibSp\"] + 1\ntest[\"relatives\"] = test[\"Parch\"] + test[\"SibSp\"] + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(data_frame=train,\n                   x=\"relatives\",\n                   y=None,\n                   color='Survived',\n                   width=500,\n                   template=\"plotly_dark\",\n                  color_discrete_map={1:\"#8072fa\",0:\"orange\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-size:35px; background-color:#8072fa; text-align:center; color:#fac472\">Modeling</h2>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import roc_auc_score, accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Label Encoding the categorical features","metadata":{}},{"cell_type":"code","source":"object_cols = ['Sex','Embarked']\nfor col in object_cols:\n    label_encoder = LabelEncoder()\n    label_encoder.fit(train[col])\n    train[col] = label_encoder.transform(train[col])\n    test[col] = label_encoder.transform(test[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','relatives']\ntarget = train['Survived'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Logistic Regression model","metadata":{}},{"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(train[features], target)\nprint(\"Logistic Regression ROC AUC score:\", roc_auc_score(target, lr.predict_proba(train[features])[:,1]))\nprint('Logistic Regression Accuracy score:', accuracy_score(target, lr.predict(train[features])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Decision Tree model","metadata":{}},{"cell_type":"code","source":"dt = DecisionTreeClassifier(random_state = 42)\ndt.fit(train[features], target)\nprint('Decision Tree ROC AUC score:', roc_auc_score(target, dt.predict_proba(train[features])[:,1]))\nprint('Decision Tree Accuracy score:', accuracy_score(target, dt.predict(train[features])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decision Tree is overfitting the data without tuning. So using Log Reg for final predictions.","metadata":{}},{"cell_type":"code","source":"sample_submission['Survived'] = lr.predict(test[features])\nsample_submission.to_csv('submission.csv',index=False)\nsample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If you like the notebook, consider giving an upvote.\nThese are my other notebooks:\n1. https://www.kaggle.com/namanmanchanda/cat-vs-dog-classifier-10-lines-of-code-fast-ai\n2. https://www.kaggle.com/namanmanchanda/star-wars-classifier\n3. https://www.kaggle.com/namanmanchanda/gradient-descent-101","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}