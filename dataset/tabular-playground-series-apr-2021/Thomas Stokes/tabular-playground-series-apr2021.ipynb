{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inspection","metadata":{}},{"cell_type":"code","source":"# Reading the training data\ntrain = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntrain.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since there is lots of data, we will just remove any rows with null values. I will also remove the Cabin and Ticket columns because only a third of the Cabin column was filled in and any relevant details from the Ticket should be embeded in the other variables.","metadata":{}},{"cell_type":"code","source":"train = train.drop(['Cabin', 'Ticket'], axis=1)\ntrain = train.dropna().reset_index(drop='index')\ntrain.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will change the Sex and embarked columns to numbers so they can evaluated in the heatmap below.","metadata":{}},{"cell_type":"code","source":"train.Embarked.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Sex'] = train['Sex'].apply(lambda x: 1 if x=='male' else 0)\ntrain['Embarked'] = train['Embarked'].apply(lambda x:-1 if x=='S' else 0 if x=='C' else 1)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(train.corr(), annot=True, linewidths=0.5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The variables that are most strongly correlated with survivability are Pclass (-0.29), Sex (-0.51), and Embarked(0.32)","metadata":{}},{"cell_type":"code","source":"train = train[['Survived', 'Pclass', 'Sex', 'Embarked']]\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Predictions","metadata":{}},{"cell_type":"markdown","source":"## Multilinear Regression","metadata":{}},{"cell_type":"code","source":"# SKlearn imports\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting up that data\ndata = train.drop(['Survived'], axis=1)\nlabels = train['Survived']\nx_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.3,random_state=42)\n# Model\nmodel = LinearRegression()\nmodel.fit(x_train, y_train)\n\nmse = mean_squared_error(y_test, model.predict(x_test)) \nrmse = np.sqrt(mse) \n# Results\nprint('Score:',model.score(x_test, y_test))\nprint('Model Intercept:',model.intercept_)\nprint('Model Coef:',model.coef_)\nprint('RMSE:',rmse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation\nThe multilinear model isn't very good. It is only able to correctly predict 30% of the results. This isn't too surprising, multilinear regression tends to be good for making predicitons with continuous variables. Our data is very discrete, hence we shall try other models.","metadata":{}},{"cell_type":"markdown","source":"## K-Nearest Neighbours","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import NearestCentroid\nfrom sklearn.neighbors import KNeighborsClassifier\n# Splitting up that data\ndata = train.drop(['Survived'], axis=1)\nlabels = train['Survived']\nx_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.4,random_state=42)\n# Model\nclf = KNeighborsClassifier(55) \nclf.fit(x_train, y_train)\n# Results\nknn_weight = clf.score(x_test, y_test)\nprint('Score:',clf.score(x_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation\nK-Nearest Neighbours was signficantly better than multilinear regression, correctly classifying 76% of the data.  ","metadata":{}},{"cell_type":"markdown","source":"## Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n# Splitting up that data\ndata = train.drop(['Survived'], axis=1)\nlabels = train['Survived']\nx_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.4,random_state=42)\n# Model\ngnb = GaussianNB()\ngnb.fit(x_train, y_train)\nnb_weight = gnb.score(x_test, y_test)\n# Results\nprint('Score:',gnb.score(x_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluating\nNaive Bayes is as good as KNN. Its score is only 0.6% lower, meaning both models would work just as well with predicting the test data.","metadata":{}},{"cell_type":"markdown","source":"## Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n# Splitting up that data\ndata = train.drop(['Survived'], axis=1)\nlabels = train['Survived']\nx_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.4,random_state=42)\n# Model\ndtc = DecisionTreeClassifier()\ndtc.fit(x_train, y_train)\ndt_weight = dtc.score(x_test, y_test)\n# Results\nprint('Score:',dtc.score(x_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation\nThe Decision tree scores 76% which is about the same as the other two classification algorithms.","metadata":{}},{"cell_type":"markdown","source":"## Neural Network\nNeural networks are only really worth trying if you have a large amount of data. Fortunately we have 96,000 data points to work with, which should be more than enough. Here's an example from the Keras documentation I will be using as a guide: https://keras.io/examples/structured_data/structured_data_classification_from_scratch/#introduction.","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras import layers\nfrom keras import Input\nfrom keras.models import Sequential\nfrom keras.layers import Dense","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building the model\nmodel = Sequential()\nmodel.add(Input(shape=(3,)))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(2, activation='relu'))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n            metrics=[\"accuracy\"])\nmodel.fit(x_train, y_train, epochs=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation\nNeural networks didn't perform as well as I thought they would. The model only trained on 2% of the data but I doubt training on more data would improve the model by much. ","metadata":{}},{"cell_type":"markdown","source":"## Conclusion\nThe best three models were KNN, Decision trees and Naive Bayes. I'll make my model a combination of these three.","metadata":{}},{"cell_type":"code","source":"\ndef eval(x_t, knn=clf, nb=gnb, dt=dtc):\n    weight_sum = knn_weight+nb_weight+dt_weight\n    knn_pred = knn.predict(x_t)\n    nb_pred = nb.predict(x_t)\n    dt_pred = dt.predict(x_t)\n    pred = []\n    for i in range(len(x_t)):\n        y = knn_pred[i]*knn_weight+nb_pred[i]*nb_weight+dt_pred[i]*dt_weight\n        y = y / weight_sum\n        if y > 0.5:\n            pred.append(1)\n        else:\n            pred.append(0)\n    return pred\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Data","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\ntest.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[['Pclass', 'Sex', 'Embarked']]\ntest['Sex'] = test['Sex'].apply(lambda x: 1 if x=='male' else 0)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 277 null values in the Embarked column. To fill these in I will make a new classifier that predicts where they embarked based on the other two variables","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import NearestCentroid\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n\ntcopy = test.copy()\ntcopy = tcopy.dropna().reset_index(drop='index')\n# Splitting up that data\ndata = tcopy.drop(['Embarked'], axis=1)\nlabels = tcopy['Embarked']\nx_train1, x_test1, y_train1, y_test1 = train_test_split(data, labels, test_size=0.4,random_state=42)\n# Model\nknn_ev = KNeighborsClassifier(55)\ngnb_ev = GaussianNB()\ndt_ev = DecisionTreeClassifier()\nknn_ev.fit(x_train1, y_train1)\ngnb_ev.fit(x_train1, y_train1)\ndt_ev.fit(x_train1, y_train1)\n# Results\nprint('Score:',knn_ev.score(x_test1, y_test1))\nprint('Score:',gnb_ev.score(x_test1, y_test1))\nprint('Score:',dt_ev.score(x_test1, y_test1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the models are as good as eachother.","metadata":{}},{"cell_type":"code","source":"test_na = test[test['Embarked'].isna() == True].reset_index(drop='index')\ntest_na.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_testna = test_na.drop(['Embarked'], axis=1)\nemb_na = knn_ev.predict(x_testna)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embarked = []\ntem = test['Embarked']\nj = 0\nfor i in range(len(test['Sex'])):\n    if tem[i] in ['S', 'C', 'Q']:\n        embarked.append(tem[i])\n    else:\n        embarked.append(emb_na[j])\n        j += 1\n\ntest['Embarked'] = embarked\ntest['Embarked'] = test['Embarked'].apply(lambda x:-1 if x=='S' else 0 if x=='C' else 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now all the null values have been filled in, its time to create the model","metadata":{}},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"code","source":"model_survived = eval(test)\nmodel_survived[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_results = pd.DataFrame({'PassengerId':np.arange(10**5,10**5+len(knn_survived),1), 'Survived':model_survived})\nmodel_results.to_csv('tpsapr21_pipe.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}