{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"___________\n# Summary\n#### The aim of this notebook is to make first submission and get a baseline score from where improvement can be made. For this I would just be filling the null values, correcting the datatypes which includes one-hot-encoding categorical columns. All this is required as ML models need data which are numerical and void of null values. \n#### There is no additional EDA/Feature Engineering/Model optimization etc as our aim is first submission.\n\n<a id='content-table'></a>\n## Table of Contents\n1. [Loading data](#load)\n2. [Combine Train and Test data](#tag2)\n3. [Filling missing values](#tag3)\n4. [Remove unncessary columns](#tag4)\n5. [Change datatypes if required](#tag5)\n6. [Splitting into train/test set](#tag6)\n7. [Training a simple model](#tag7)\n8. [Making predicitions on Test set](#tag8)\n9. [Making your first submission](#tag9)","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:53.769278Z","iopub.execute_input":"2021-07-09T23:54:53.769825Z","iopub.status.idle":"2021-07-09T23:54:53.783499Z","shell.execute_reply.started":"2021-07-09T23:54:53.769713Z","shell.execute_reply":"2021-07-09T23:54:53.782238Z"},"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='load'></a>\n## [Step - 1 : Loading data](#content-table)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv')\n\nprint(train.shape, test.shape, submission.shape)\nprint(train.columns)                             #printing the column names\nprint(set(train.columns)-set(test.columns))      #printing the target column","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:53.785331Z","iopub.execute_input":"2021-07-09T23:54:53.785756Z","iopub.status.idle":"2021-07-09T23:54:54.596532Z","shell.execute_reply.started":"2021-07-09T23:54:53.78568Z","shell.execute_reply":"2021-07-09T23:54:54.595218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Print first 5 rows","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:54.599662Z","iopub.execute_input":"2021-07-09T23:54:54.600375Z","iopub.status.idle":"2021-07-09T23:54:54.631139Z","shell.execute_reply.started":"2021-07-09T23:54:54.600276Z","shell.execute_reply":"2021-07-09T23:54:54.62984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check the %null values in  Train and Test data","metadata":{}},{"cell_type":"code","source":"_1 = train.isnull().sum()/len(train)*100\n_2 = test.isnull().sum()/len(train)*100\n\ndf = pd.concat([_1,_2], axis = 1)\ndf.columns = ['train', 'test']\ndf","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:54.633536Z","iopub.execute_input":"2021-07-09T23:54:54.633883Z","iopub.status.idle":"2021-07-09T23:54:54.75996Z","shell.execute_reply.started":"2021-07-09T23:54:54.633851Z","shell.execute_reply":"2021-07-09T23:54:54.758545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that columns that have null values are same in both the dataset and the % missing values is around the same","metadata":{}},{"cell_type":"markdown","source":"<a id='tag2'></a>\n## [Step - 2 : Combine Train and Test data](#content-table)","metadata":{}},{"cell_type":"code","source":"test['Survived'] = -1\nall_data = pd.concat([train, test])\nprint(all_data.head())\nall_data.tail()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:54.762023Z","iopub.execute_input":"2021-07-09T23:54:54.762614Z","iopub.status.idle":"2021-07-09T23:54:54.851003Z","shell.execute_reply.started":"2021-07-09T23:54:54.76255Z","shell.execute_reply":"2021-07-09T23:54:54.849703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag3'></a>\n## [Step - 3 : Filling missing values](#content-table)","metadata":{}},{"cell_type":"markdown","source":"### Fill 'Age' and 'Fare' value with their mean value","metadata":{}},{"cell_type":"code","source":"for col in ['Age', 'Fare']:\n    all_data[col] = all_data[col].fillna(all_data[col].mean())\n    print(all_data[col].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:54.852729Z","iopub.execute_input":"2021-07-09T23:54:54.853062Z","iopub.status.idle":"2021-07-09T23:54:54.866812Z","shell.execute_reply.started":"2021-07-09T23:54:54.853031Z","shell.execute_reply":"2021-07-09T23:54:54.86561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fill 'Embarked' and 'Ticket' values with their mode value","metadata":{}},{"cell_type":"code","source":"for col in ['Embarked', 'Ticket']:\n    all_data[col] = all_data[col].fillna(all_data[col].mode()[0]) \n    print(all_data[col].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:54.868416Z","iopub.execute_input":"2021-07-09T23:54:54.868757Z","iopub.status.idle":"2021-07-09T23:54:55.084114Z","shell.execute_reply.started":"2021-07-09T23:54:54.868727Z","shell.execute_reply":"2021-07-09T23:54:55.083149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filling Cabin values\nHere 67% values are missing. Hence I will fill it with 1 if value is present and 0 if missing value","metadata":{}},{"cell_type":"code","source":"col = 'Cabin'\nall_data[col] = all_data[col].notnull().astype(int)\nprint(all_data[col].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.085401Z","iopub.execute_input":"2021-07-09T23:54:55.085794Z","iopub.status.idle":"2021-07-09T23:54:55.111383Z","shell.execute_reply.started":"2021-07-09T23:54:55.08575Z","shell.execute_reply":"2021-07-09T23:54:55.110106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Verify there are no null values","metadata":{}},{"cell_type":"code","source":"all_data.isnull().sum()/len(train)*100","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.115517Z","iopub.execute_input":"2021-07-09T23:54:55.115875Z","iopub.status.idle":"2021-07-09T23:54:55.212062Z","shell.execute_reply.started":"2021-07-09T23:54:55.115839Z","shell.execute_reply":"2021-07-09T23:54:55.210896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag4'></a>\n## [Step - 4 : Remove unncessary columns](#content-table)\n\nWe will check %unique values in column","metadata":{}},{"cell_type":"code","source":"# Taking only categorical columns\ncols = [col for col in all_data.columns if all_data[col].dtype == 'object']\ncols\n\nfor col in cols:\n    print(f\"{col} : {all_data[col].nunique()/len(all_data)*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.214026Z","iopub.execute_input":"2021-07-09T23:54:55.214355Z","iopub.status.idle":"2021-07-09T23:54:55.438582Z","shell.execute_reply.started":"2021-07-09T23:54:55.214311Z","shell.execute_reply":"2021-07-09T23:54:55.437531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`'Name'` and `'Ticket'` columns have more than 87% & 66% unique values respectively. They don't give any information to the model just as is. EDA/Feature Engineering might give us some insight, but we are not doing that here.","metadata":{}},{"cell_type":"code","source":"all_data.drop(['Name', 'Ticket'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.43991Z","iopub.execute_input":"2021-07-09T23:54:55.440223Z","iopub.status.idle":"2021-07-09T23:54:55.498167Z","shell.execute_reply.started":"2021-07-09T23:54:55.440191Z","shell.execute_reply":"2021-07-09T23:54:55.497049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag5'></a>\n## [Step - 5 : Change datatypes if required](#content-table)","metadata":{}},{"cell_type":"markdown","source":"### Check column datatype with a sample datatype","metadata":{}},{"cell_type":"code","source":"df = pd.concat([all_data.iloc[0], all_data.dtypes], axis = 1)\ndf.columns = ['sample', 'dtype']\ndf","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.499568Z","iopub.execute_input":"2021-07-09T23:54:55.49991Z","iopub.status.idle":"2021-07-09T23:54:55.514795Z","shell.execute_reply.started":"2021-07-09T23:54:55.499877Z","shell.execute_reply":"2021-07-09T23:54:55.513636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see that the data type of sample matches with the datatype of the column. Hence no need to change column datatype","metadata":{}},{"cell_type":"markdown","source":"### One-hot-encode categorical columns","metadata":{}},{"cell_type":"code","source":"# Check which categorical columns are left\ncols = [col for col in all_data.columns if all_data[col].dtype == 'object']\ncols","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.516307Z","iopub.execute_input":"2021-07-09T23:54:55.516672Z","iopub.status.idle":"2021-07-09T23:54:55.529492Z","shell.execute_reply.started":"2021-07-09T23:54:55.51664Z","shell.execute_reply":"2021-07-09T23:54:55.52844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data = pd.get_dummies(all_data, drop_first = True)\nall_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.53106Z","iopub.execute_input":"2021-07-09T23:54:55.531505Z","iopub.status.idle":"2021-07-09T23:54:55.612072Z","shell.execute_reply.started":"2021-07-09T23:54:55.531467Z","shell.execute_reply":"2021-07-09T23:54:55.61109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now our data is ready to be fed into model. So we will split into train/validation/test set and train a basic model","metadata":{}},{"cell_type":"markdown","source":"<a id='tag6'></a>\n## [Step - 6 : Splitting into train/test set](#content-table)","metadata":{}},{"cell_type":"markdown","source":"### Split into train-test set","metadata":{}},{"cell_type":"code","source":"n_train = len(train)\ntrain_modified = all_data.iloc[:n_train].copy()   # This will create copy of the df. Done to avoid future warnings\ntest_modified = all_data.iloc[n_train:].copy()\n\nprint(len(train_modified), len(test_modified))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.613521Z","iopub.execute_input":"2021-07-09T23:54:55.613835Z","iopub.status.idle":"2021-07-09T23:54:55.623782Z","shell.execute_reply.started":"2021-07-09T23:54:55.613806Z","shell.execute_reply":"2021-07-09T23:54:55.622519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_modified.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.625316Z","iopub.execute_input":"2021-07-09T23:54:55.62568Z","iopub.status.idle":"2021-07-09T23:54:55.644872Z","shell.execute_reply.started":"2021-07-09T23:54:55.625645Z","shell.execute_reply":"2021-07-09T23:54:55.64364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing 'PassengerId' column\ntrain_modified.drop('PassengerId', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.646315Z","iopub.execute_input":"2021-07-09T23:54:55.646687Z","iopub.status.idle":"2021-07-09T23:54:55.662818Z","shell.execute_reply.started":"2021-07-09T23:54:55.646654Z","shell.execute_reply":"2021-07-09T23:54:55.661487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_modified.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.664616Z","iopub.execute_input":"2021-07-09T23:54:55.665081Z","iopub.status.idle":"2021-07-09T23:54:55.683519Z","shell.execute_reply.started":"2021-07-09T23:54:55.665034Z","shell.execute_reply":"2021-07-09T23:54:55.682357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove 'Survived' column from test data\ntest_modified.drop('Survived', axis = 1,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.685148Z","iopub.execute_input":"2021-07-09T23:54:55.685826Z","iopub.status.idle":"2021-07-09T23:54:55.700353Z","shell.execute_reply.started":"2021-07-09T23:54:55.685789Z","shell.execute_reply":"2021-07-09T23:54:55.699352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a train-test split on training data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train_modified.drop('Survived', axis = 1)\ny = train_modified['Survived'].copy()\n\nx_train, x_test, y_train, y_test = train_test_split(X, y.values, test_size = 0.25, random_state = 42)\n\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:55.701686Z","iopub.execute_input":"2021-07-09T23:54:55.701983Z","iopub.status.idle":"2021-07-09T23:54:56.042711Z","shell.execute_reply.started":"2021-07-09T23:54:55.701955Z","shell.execute_reply":"2021-07-09T23:54:56.04151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test","metadata":{"execution":{"iopub.status.busy":"2021-07-09T23:54:56.044612Z","iopub.execute_input":"2021-07-09T23:54:56.045083Z","iopub.status.idle":"2021-07-09T23:54:56.071208Z","shell.execute_reply.started":"2021-07-09T23:54:56.045035Z","shell.execute_reply":"2021-07-09T23:54:56.070096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag7'></a>\n## [Step - 7 : Training a simple model](#content-table)","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nclassifier = LogisticRegression(solver='liblinear', random_state = 42)\n\nclassifier.fit(x_train.values, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T00:29:00.11139Z","iopub.execute_input":"2021-07-10T00:29:00.111901Z","iopub.status.idle":"2021-07-10T00:29:00.560981Z","shell.execute_reply.started":"2021-07-10T00:29:00.111861Z","shell.execute_reply":"2021-07-10T00:29:00.559941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = classifier.predict(x_test.values)\naccuracy = (y_pred == y_test).astype(int).sum()/len(y_test)*100\nprint(f\"Model accuracy is : {accuracy: .3f} %\")","metadata":{"execution":{"iopub.status.busy":"2021-07-10T00:29:03.299122Z","iopub.execute_input":"2021-07-10T00:29:03.299583Z","iopub.status.idle":"2021-07-10T00:29:03.316987Z","shell.execute_reply.started":"2021-07-10T00:29:03.299547Z","shell.execute_reply":"2021-07-10T00:29:03.315574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"An accuracy of 76.612% is a good starting point. From here on we can improve","metadata":{}},{"cell_type":"markdown","source":"<a id='tag8'></a>\n## [Step - 8 : Making predicitions on Test set](#content-table)","metadata":{}},{"cell_type":"code","source":"# Saving 'PassengerId' of test data and deleting it\ntest_idx = test_modified['PassengerId'].copy()\n\ntest_modified.drop('PassengerId', axis = 1, inplace = True)\n\nprint(test_modified.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T00:06:12.44382Z","iopub.execute_input":"2021-07-10T00:06:12.444274Z","iopub.status.idle":"2021-07-10T00:06:12.4573Z","shell.execute_reply.started":"2021-07-10T00:06:12.444238Z","shell.execute_reply":"2021-07-10T00:06:12.455683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = classifier.predict(test_modified.values)\nsubmission.loc[:, 'Survived'] = y_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='tag9'></a>\n## [Step - 9 : Making your first submission](#content-table)","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)   # index = False is important ","metadata":{"execution":{"iopub.status.busy":"2021-07-10T00:19:47.882695Z","iopub.execute_input":"2021-07-10T00:19:47.883373Z","iopub.status.idle":"2021-07-10T00:19:48.077895Z","shell.execute_reply.started":"2021-07-10T00:19:47.8833Z","shell.execute_reply":"2021-07-10T00:19:48.076614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recheck if the file is in correct format\npd.read_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-10T00:20:05.45871Z","iopub.execute_input":"2021-07-10T00:20:05.459103Z","iopub.status.idle":"2021-07-10T00:20:05.493228Z","shell.execute_reply.started":"2021-07-10T00:20:05.459068Z","shell.execute_reply":"2021-07-10T00:20:05.492235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now you have made your first submssion. From here on you can do many things to improve your accuracy. You can do EDA to get better insights in your data. Furthur you can also do feature engineering, hyperparameter optimization, ensembling of models.**","metadata":{}},{"cell_type":"markdown","source":"_______________","metadata":{}}]}