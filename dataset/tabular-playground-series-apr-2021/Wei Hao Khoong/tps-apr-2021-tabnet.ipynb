{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Acknowledgements\n\n- built-upon Juan Pablo Margni's wonderful starter: https://www.kaggle.com/jmargni/tps-apr-2021-lightgbm-optuna","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install -q pytorch-tabnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nimport lightgbm as lgb\nimport optuna\nimport joblib\nfrom pytorch_tabnet.tab_model import TabNetClassifier","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:47:08.522995Z","start_time":"2021-04-05T17:47:07.290745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:23.287725Z","start_time":"2021-04-05T17:23:22.968601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encoder(c):\n    lc = LabelEncoder()\n    return lc.fit_transform(c)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:23.292876Z","start_time":"2021-04-05T17:23:23.289549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(df):\n    label_cols = ['Name', 'Ticket']\n    onehot_cols = ['Pclass', 'Sex', 'Cabin', 'Embarked']\n    numerical_cols = ['Age', 'SibSp', 'Parch', 'Fare', 'Survived']\n    age_map = df[['Age', 'Pclass']].dropna().groupby('Pclass').mean().to_dict()\n    df.Age = df.Age.fillna(df.Pclass.map(age_map['Age']))\n    df.Cabin = df.Cabin.fillna('X').map(lambda x: x[0].strip())\n    df.Ticket = df.Ticket.fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n    df.Fare = df.Fare.fillna(df.Fare.mean())\n    df.Embarked = df.Embarked.fillna('X')\n    df.Name = df.Name.map(lambda x: x.split(',')[0])\n    onehot_encoded_df = pd.get_dummies(df[onehot_cols])\n    label_encoded_df = df[label_cols].apply(label_encoder)\n    numerical_df = df[numerical_cols]\n    return pd.concat([numerical_df, label_encoded_df, onehot_encoded_df], axis=1)","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:23.324811Z","start_time":"2021-04-05T17:23:23.315004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df = preprocess(df = pd.concat([train_df, test_df]))","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:24.023694Z","start_time":"2021-04-05T17:23:23.477899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-split all data\nX = all_df[:train_df.shape[0]]\ny = X.pop('Survived')\nX_ = all_df[train_df.shape[0]:].drop(columns=['Survived'])","metadata":{"ExecuteTime":{"end_time":"2021-04-05T17:23:24.038044Z","start_time":"2021-04-05T17:23:24.025759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference with Best Params","metadata":{}},{"cell_type":"code","source":"folds = KFold(n_splits = 16)\noof = np.zeros(X.shape[0])\npredictions = np.zeros(X_.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BEST_PARAMS = {\n        'n_a': 16,\n        'n_d': 16,\n        'n_steps': 3,\n        'n_independent': 2,\n        'batch_size': 1024,\n        'virtual_batch_size': 128,\n        'seed': 42,\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    print(\"Fold {}\".format(fold_))\n    X_train = X.iloc[trn_idx].values\n    y_train = y[trn_idx]\n    X_test = X.iloc[val_idx].values\n    y_test = y[val_idx]\n    clf = TabNetClassifier(\n        n_a=BEST_PARAMS['n_a'],\n        n_d=BEST_PARAMS['n_d'],\n        n_steps=BEST_PARAMS['n_steps'],\n        n_independent=BEST_PARAMS['n_independent'],\n        seed=42,\n    )\n    clf.fit(\n        X_train=X_train, y_train=y_train,\n        eval_set=[(X_train, y_train), (X_test, y_test)],\n        eval_name=['train', 'valid'],\n        eval_metric=['accuracy'],\n        max_epochs=50,\n        patience=10, \n        batch_size=BEST_PARAMS['batch_size'],\n        virtual_batch_size=BEST_PARAMS['virtual_batch_size']\n    )\n    \n    predictions += clf.predict(X_.values) / folds.n_splits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binarizer = np.vectorize(lambda x: 1 if x >= .5 else 0)\nprediction_binarized = binarizer(predictions)\nsubmission = pd.concat([sample_submission,pd.DataFrame(prediction_binarized)], axis=1).drop(columns=['Survived'])\nsubmission.columns = ['PassengerId', 'Survived']\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}