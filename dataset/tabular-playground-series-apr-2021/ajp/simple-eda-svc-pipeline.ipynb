{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2021/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2021/test.csv\")\ntest['Survived'] = np.nan\ntest = test[train.columns]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Determine Preprocessing Steps\n\nTry out each step and determing a good pipeline.\n\nThen build the pipeline out of sklearn pipeline.\n\n### Inspect Data","metadata":{}},{"cell_type":"code","source":"print(train.isna().mean()*train.shape[0])\nprint(train.dtypes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Inspect Numerical Features","metadata":{}},{"cell_type":"code","source":"age_df = train[['Age', 'Survived', 'Sex', 'Pclass']].copy()\nage_df[\"Age_trunc\"] = (age_df[\"Age\"]//2)*2\nage_df['Sex'] = [1 if val==\"male\" else 0 if val==\"female\" else 2 for val in age_df['Sex']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nage_df[['Age_trunc', 'Sex', 'Survived']].groupby(['Age_trunc', 'Sex']).mean().reset_index().plot.scatter(x=\"Age_trunc\", \n                                                                                                         y=\"Survived\", \n                                                                                                         #c=\"Sex\", \n                                                                                                         alpha=0.5,\n                                                                                                         #cmap = plt.cm.Spectral,\n                                                                                                        )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_df[['Pclass', 'Sex', 'Survived']].groupby(['Pclass', 'Sex']).mean().plot.bar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age shows an unexpected trend, with teenager and the very old being most likely to survive. People between 16-40, and under 10 were the least likely to survive.","metadata":{}},{"cell_type":"markdown","source":"#### Inspect Categorical Features","metadata":{}},{"cell_type":"code","source":"train['Embarked'].value_counts(dropna=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split(\" \")) > 1 else 'X').value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['Parch']].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['SibSp']].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusions\n\nWe can see that the preprocessing needed is:\n\n* handling nans for: age, ticket, fare, cabin and embarked\n    * numerical columns (age, fare): impute, add nan indicator column\n    * string columns (ticket, cabin, embarked): create a new string for the nan indicator\n* encode categorical columns:\n    * transform and encode string columns: sex, ticket, cabin, embarked\n    * encode categories: SibSp, Parch (that have around 10 categ values each)\n    * name column will be ignored for now","metadata":{}},{"cell_type":"markdown","source":"## Build Sklearn pipeline for feature transformations","metadata":{}},{"cell_type":"code","source":"# indicate categ and numerical features\ncateg_feats = ['Sex', 'Pclass', 'SibSp', 'Parch', 'Cabin', 'Embarked', 'Ticket']\nnum_feats = ['Age', 'Fare']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import TransformerMixin, BaseEstimator\n\n# class to convert all categ columns to strings and transform strings\n# into category codes\nclass StrFunctionTransformer(TransformerMixin, BaseEstimator):\n    def __init__(self):\n        self.func_map = {\"Cabin\": self.transform_cabin,\n                         \"Ticket\": self.transform_ticket,\n                         \"Embarked\": self.transform_emb}\n\n    def transform(self, input_df, **transform_params):\n        df = input_df.copy()\n        for coln in df.columns:\n            if coln in self.func_map.keys():\n                new_col = self.func_map[coln](df)\n                df[coln] = new_col.astype(str)\n        return df\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n\n    def transform_cabin(self, df):\n        coln = \"Cabin\"\n        col = df.loc[:,coln]\n        new_col = col.fillna(\"Z0\").map(lambda x: x[0].strip())\n        return new_col\n\n    def transform_ticket(self, df):\n        coln = \"Ticket\"\n        col = df.loc[:,coln]\n        new_col = col.fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n        return new_col\n    \n    def transform_emb(self, df):\n        coln = \"Embarked\"\n        col = df.loc[:,coln]\n        new_col = col.fillna('NA')\n        return new_col\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test the string col transformer\ndft = StrFunctionTransformer()\ndft.fit_transform(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_union, make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.impute import SimpleImputer, MissingIndicator\nfrom sklearn.preprocessing import StandardScaler\nimport category_encoders as ce\n\n# construct pipelines for feature processing\nnum_pipe = make_union(MissingIndicator(), \n                       make_pipeline(SimpleImputer(strategy='median'), StandardScaler()))\nnum_trans = make_column_transformer((num_pipe, num_feats))\ncateg_trans = make_column_transformer((StrFunctionTransformer(), categ_feats))\n\n# encode categ feats\nencoder = ce.TargetEncoder(return_df=True) # encodes all string columns\ncateg_pipe = make_pipeline(categ_trans, encoder)\n\n# make union of categ and numerical features\nfeatures_union = make_union(categ_pipe, num_trans)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the piepline worked\nfeats = features_union.fit_transform(train, train['Survived'])\n\n# you can use the transformer to transform just one step\nfeatures_union.transformer_list[0][1].steps[0][1].transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check that it can transform the test df\nfeatures_union.transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inspect Correlations of New Features","metadata":{}},{"cell_type":"code","source":"# inspect correlation of new features\npd.DataFrame(feats).corrwith(train[\"Survived\"]).plot.bar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats_df = pd.DataFrame(feats)\nfeats_df[\"Survived\"] = train[\"Survived\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats_df.groupby('Survived').mean().T.plot.bar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusions\n\nSome features could be removed: 2, 7, 8","metadata":{}},{"cell_type":"markdown","source":"## Setup sklearn classifier","metadata":{}},{"cell_type":"code","source":"from imblearn.pipeline import make_pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import Normalizer, StandardScaler, OneHotEncoder\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier, VotingClassifier\nimport xgboost as xgb\n\nclass Classifier:\n    def __init__(self, num_feats, categ_feats):\n        # classifiers that could be tested\n#         XGB = xgb.XGBClassifier()\n#         ETC = ExtraTreesClassifier()\n#         RFC = RandomForestClassifier(n_estimators=1000, random_state=0)\n#         DTC = DecisionTreeClassifier()\n#         KNN = KNeighborsClassifier()\n#         BC = BaggingClassifier(base_estimator=LinearSVC(), n_estimators=100, random_state=0)\n#         CLASS = VotingClassifier(estimators=[('SVC', SVC),('RFC',RFC), ('KNN', KNN), ('BC', BC)])\n        SVC = LinearSVC(max_iter=2000, random_state = 0)\n        self.features_union = self.build_prepro_pipe(num_feats, categ_feats)\n        \n        self._pipeline = Pipeline(steps=[('preprocessor', self.features_union), ('classifier', SVC)])\n        \n    @staticmethod\n    def build_prepro_pipe(num_feats, categ_feats):\n        num_pipe = make_union(MissingIndicator(), \n                       make_pipeline(SimpleImputer(strategy='median'), StandardScaler()))\n        num_trans = make_column_transformer((num_pipe, num_feats))\n        categ_trans = make_column_transformer((StrFunctionTransformer(), categ_feats))\n\n        # encode categ feats\n        encoder = ce.TargetEncoder(return_df=True) # encodes all string columns\n        categ_pipe = make_pipeline(categ_trans, encoder)\n\n        # make union of categ and numerical features\n        features_union = make_union(categ_pipe, num_trans)\n        return features_union\n\n    def train(self, x, y):\n        self.classifier = self._pipeline\n        self.classifier.fit(x,y)\n        \n    def transform(self, x):\n        return self._pipeline.steps[0][1].transform(x)\n\n    def predict(self, x):\n        return self.classifier.predict(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Predict","metadata":{}},{"cell_type":"code","source":"clsi = Classifier(num_feats, categ_feats)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clsi.train(train, train[\"Survived\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = clsi.predict(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the transformed test can be seen from teh pipeline\nclsi.transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(preds.mean())\nprint(train[\"Survived\"].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Survived'] = preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.groupby('Survived').mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.loc[: , ['PassengerId', 'Survived']].to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}