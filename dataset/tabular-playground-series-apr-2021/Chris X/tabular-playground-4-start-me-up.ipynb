{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of Contents\n\n* [Target Exploration](#1)\n* [Numerical Features](#2)\n* [Categorical Features/Feature Engineering](#3)\n* [Test Set vs Train Set](#4)\n* [Target vs Features](#5)\n* [Build GBM Model](#6)\n* [Build Random Forest Model](#7)\n* [Predict on Test Set & Submission](#8)\n* [Explanations for GBM model](#9)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n# missing values visualization\nimport missingno as msno\n\n# machine learning tools\nimport h2o\nfrom h2o.estimators import H2OGeneralizedLinearEstimator, H2ORandomForestEstimator, H2OGradientBoostingEstimator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data + first glance\ndf_train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\ndf_sub = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')\n\n# first glance (training data)\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dimensions\nprint('Train Set:', df_train.shape)\nprint('Test Set :', df_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# structure\ndf_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We have quite a few missings here!","metadata":{}},{"cell_type":"code","source":"# show structure of missings\nmsno.matrix(df_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix missings in cabin feature by dummy imputation\ndf_train.Cabin = df_train.Cabin.fillna('0000')\ndf_test.Cabin = df_test.Cabin.fillna('0000')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='1'></a>\n# Target Exploration","metadata":{}},{"cell_type":"code","source":"# basic stats\nprint(df_train.Survived.value_counts())\ndf_train.Survived.value_counts().plot(kind='bar')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Nice, there is no balancing issue here.","metadata":{}},{"cell_type":"markdown","source":"<a id='2'></a>\n# Numerical Features","metadata":{}},{"cell_type":"code","source":"features_num = ['Age', 'SibSp', 'Parch', 'Fare']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic summary stats\ndf_train[features_num].describe(percentiles=[0.01,0.1,0.25,0.5,0.75,0.9,0.99])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distribution of numerical features\nfor f in features_num:\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,6), sharex=True)\n    ax1.hist(df_train[f], bins=30)\n    ax1.grid()\n    ax1.set_title(f)\n    # for boxplot we need to remove the NaNs first\n    feature_wo_nan = df_train[~np.isnan(df_train[f])][f]\n    ax2.boxplot(feature_wo_nan, vert=False)\n    ax2.grid()\n    ax2.set_title(f + '- boxplot')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlations","metadata":{}},{"cell_type":"code","source":"corr_pearson = df_train[features_num].corr(method='pearson')\ncorr_spearman = df_train[features_num].corr(method='spearman')\n\nplt.figure(figsize=(15,5))\nax1 = plt.subplot(1,2,1)\nsns.heatmap(corr_pearson, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation')\n\nax2 = plt.subplot(1,2,2, sharex=ax1)\nsns.heatmap(corr_spearman, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Spearman Correlation')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairwise scatter plot of numerical features\nt1 = time.time()\nsns.pairplot(df_train[features_num],\n             diag_kws = {'alpha': 1.0},\n             plot_kws = {'alpha': 0.1})\nplt.show()\nt2 = time.time()\nprint('Elapsed time:', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n# Categorical Features / Feature Engineering","metadata":{}},{"cell_type":"code","source":"features_cat = ['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# explicit conversions\ndf_train.Pclass = df_train.Pclass.astype('object')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summary stats\ndf_train[features_cat].describe(include='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Name, Ticket and Cabin have too many levels. We have to look at them separately...","metadata":{}},{"cell_type":"code","source":"features_cat_4plot = ['Pclass', 'Sex', 'Embarked']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distribution of categorical features\nfor f in features_cat_4plot:\n    plt.figure(figsize=(8,4))\n    df_train[f].value_counts().plot(kind='bar')\n    plt.title(f)\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_cat_too_many = ['Name', 'Ticket', 'Cabin']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show frequency counts for the features with many levels\nfor f in features_cat_too_many:\n    print('FEATURE', f, ':')\n    print(df_train[f].value_counts())\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's try some feature engineering","metadata":{}},{"cell_type":"code","source":"# prefix of cabin could be useful\ndf_train['CabinPrefix'] = df_train.Cabin.apply(lambda x : x[0])\ndf_test['CabinPrefix'] = df_test.Cabin.apply(lambda x : x[0])\n\ndf_train.CabinPrefix.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for test set as well\ndf_test.CabinPrefix.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['FirstName'] = df_train.Name.map(lambda x: x.split(', ')[1])\ndf_test['FirstName'] = df_test.Name.map(lambda x: x.split(', ')[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.FirstName.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.FirstName.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['LastName'] = df_train.Name.map(lambda x: x.split(',')[0])\ndf_test['LastName'] = df_test.Name.map(lambda x: x.split(',')[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.LastName.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.LastName.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'></a>\n# Test Set vs Train Set","metadata":{}},{"cell_type":"code","source":"# basic stats for numerical features for training\ndf_train[features_num].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# and the same for test set\ndf_test[features_num].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We observe quite some diffences between train and test set, e. g. lower age and higher SibSp in test set.","metadata":{}},{"cell_type":"markdown","source":"####  Let's explore the age feature a little bit more:","metadata":{}},{"cell_type":"code","source":"# compare age distributions\nplt.figure(figsize=(10,4))\nplt.hist(df_train.Age, bins=20, alpha=0.5, label='Train')\nplt.hist(df_test.Age, bins=20, alpha=0.5, label='Test')\nplt.title('Age - Train vs Test')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### => Age distribution is completely different. Especially, the test set includes much more individuals in the age range 20-30, those have a low survival probability as we will see later! Ceteris paribus we would therefore expect lower survival rates on the test set.","metadata":{}},{"cell_type":"code","source":"# compare gender distribution\nprint('Train Set:')\nprint(df_train.Sex.value_counts(normalize=True))\nprint()\nprint('Test Set:')\nprint(df_test.Sex.value_counts(normalize=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### => Significantly higher percentages of males in the test set (69.8% vs 56.1%). Males have a much lower probability of survival so we can again (as for feature age) expect to see a different survival situation between test and train set, especially because sex is the most important feature (see below).","metadata":{}},{"cell_type":"markdown","source":"#### Let's also check the **combined** effect of sex and age:","metadata":{}},{"cell_type":"code","source":"# let's first add a binned version of age\ndf_train['Age_bin10'] = pd.cut(df_train.Age, [0,10,20,30,40,50,60,70,80,90])\ndf_test['Age_bin10'] = pd.cut(df_test.Age, [0,10,20,30,40,50,60,70,80,90])\n\nplt.figure(figsize=(16,4))\nax1 = plt.subplot(1,2,1)\nfoo = df_train.Age_bin10.value_counts().sort_index()\nplt.bar(x=foo.index.astype(str), height=foo.values)\nplt.grid()\nplt.title('Age binned - Train Set')\n\nax2 = plt.subplot(1,2,2, sharex=ax1, sharey=ax1)\nfoo = df_test.Age_bin10.value_counts().sort_index()\nplt.bar(x=foo.index.astype(str), height=foo.values)\nplt.grid()\nplt.title('Age binned - Test Set')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calc cross tables Sex/Age[binned]\ntab_sex_age_train = pd.crosstab(df_train.Sex, df_train.Age_bin10)\ntab_sex_age_test = pd.crosstab(df_test.Sex, df_test.Age_bin10)\n\n# and visualize\nplt.figure(figsize=(14,7))\nax1 = plt.subplot(2,1,1)\nsns.heatmap(tab_sex_age_train, cmap='Blues', \n            annot=True, fmt='d',\n            vmin=0, vmax=30000,\n            linecolor='black',\n            linewidths=0.1)\nplt.title('Age/Sex - Train Set')\n\nax2 = plt.subplot(2,1,2)\nplt.subplots_adjust(hspace=0.35)\nsns.heatmap(tab_sex_age_test, cmap='Blues',\n            annot=True, fmt='d',\n            vmin=0, vmax=30000,\n            linecolor='black',\n            linewidths=0.1)\nplt.title('Age/Sex - Test Set')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Also the Pclass feature shows completely different distributions:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,4))\nax1 = plt.subplot(1,2,1)\nfoo = df_train.Pclass.value_counts().sort_index()\nplt.bar(x=foo.index.astype(str), height=foo.values)\nplt.grid()\nplt.title('Pclass - Train Set')\n\nax2 = plt.subplot(1,2,2, sharex=ax1, sharey=ax1)\nfoo = df_test.Pclass.value_counts().sort_index()\nplt.bar(x=foo.index.astype(str), height=foo.values)\nplt.grid()\nplt.title('Pclass - Test Set')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='5'></a>\n# Target vs Features","metadata":{}},{"cell_type":"markdown","source":"### Numerical Features","metadata":{}},{"cell_type":"code","source":"# plot target vs BINNED numerical features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in ['Age', 'Fare']:\n    # add binned version of each numerical feature first\n    new_var = f + '_bin'\n    df_train[new_var] = pd.qcut(df_train[f], 10)\n    # then create mosaic plot\n    plt.rcParams['figure.figsize'] = (16,6) # increase plot size for mosaics\n    mosaic(df_train, [new_var, 'Survived'], title='Target vs ' + f + ' [binned]')\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot target vs (discrete) numerical features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in ['SibSp', 'Parch']:\n    plt.rcParams['figure.figsize'] = (16,6) # increase plot size for mosaics\n    mosaic(df_train, [f, 'Survived'], title='Target vs ' + f)\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Features","metadata":{}},{"cell_type":"code","source":"# plot target vs features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in features_cat_4plot:\n    plt.rcParams['figure.figsize'] = (16,6) # increase plot size for mosaics\n    mosaic(df_train, [f, 'Survived'], title='Target vs ' + f)\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Strong impact of sex, we will later see that this is our most important feature.","metadata":{}},{"cell_type":"code","source":"# check our new cabin prefix feature as well\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nplt.rcParams['figure.figsize'] = (16,6) # increase plot size for mosaics\nmosaic(df_train, ['CabinPrefix', 'Survived'], title='Target vs CabinPrefix')\nplt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Ok, also the cabin prefix seems to make a measurable difference!","metadata":{}},{"cell_type":"markdown","source":"#### Let's check the names (most frequent only):","metadata":{}},{"cell_type":"code","source":"# plot target vs features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nplt.rcParams['figure.figsize'] = (16,6) # increase plot size for mosaics\n\nname_list = df_train.FirstName.value_counts()[0:15].index.tolist()\ndf_temp = df_train[df_train.FirstName.isin(name_list)]\nmosaic(df_temp, ['FirstName', 'Survived'], title='Target vs FirstName (Top 15)')\nplt.show()\n\nname_list = df_train.LastName.value_counts()[0:15].index.tolist()\ndf_temp = df_train[df_train.LastName.isin(name_list)]\nmosaic(df_temp, ['LastName', 'Survived'], title='Target vs LastName (Top 15)')\nplt.show()\n\n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='6'></a>\n# Build GBM Model","metadata":{}},{"cell_type":"code","source":"# select predictors\npredictors = features_num + features_cat_4plot\npredictors = predictors + ['Ticket', 'CabinPrefix', 'FirstName', 'LastName']\nprint('Number of predictors: ', len(predictors))\nprint(predictors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # Use maximum of 12 GB RAM and 4 cores","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# upload data frames in H2O environment\nt1 = time.time()\ntrain_hex = h2o.H2OFrame(df_train)\ntest_hex = h2o.H2OFrame(df_test)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))\n\n# force categorical target\ntrain_hex['Survived'] = train_hex['Survived'].asfactor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit Gradient Boosting model\nn_cv = 5\n\nfit_GBM = H2OGradientBoostingEstimator(ntrees=100,\n                                       max_depth=7,\n                                       min_rows=15,\n                                       learn_rate=0.1, # default: 0.1\n                                       sample_rate=0.8,\n                                       col_sample_rate=0.4,\n                                       nfolds=n_cv,\n                                       score_each_iteration=True,\n                                       stopping_metric='auc',\n                                       stopping_rounds=5,\n                                       stopping_tolerance=0.0001,\n                                       seed=999)\n# train model\nt1 = time.time()\nfit_GBM.train(x=predictors,\n              y='Survived',\n              training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show cross validation metrics\nfit_GBM.cross_validation_metrics_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show scoring history - training vs cross validations\nfor i in range(n_cv):\n    cv_model_temp = fit_GBM.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [AUC]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_auc, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_auc, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.ylabel('AUC')\n    plt.ylim(0.8,0.9)\n    plt.legend()\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# variable importance\nfit_GBM.varimp_plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# alternative variable importance using SHAP => see direction as well as severity of feature impact\nt1 = time.time()\nfit_GBM.shap_summary_plot(train_hex);\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check performance on training data / cross validations","metadata":{}},{"cell_type":"code","source":"# training performance\nperf_train = fit_GBM.model_performance(train=True)\nperf_train.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cross validation performance\nperf_cv = fit_GBM.model_performance(xval=True)\nperf_cv.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict on train set (extract probabilities only)\npred_train_GBM = fit_GBM.predict(train_hex)['p1']\npred_train_GBM = pred_train_GBM.as_data_frame().p1\n\n# plot train set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(pred_train_GBM, bins=100)\nplt.title('Predictions on Train Set - GBM')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calibration\nn_actual = sum(df_train.Survived)\nn_pred_GBM = sum(pred_train_GBM)\n\nprint('Actual Frequency    :', n_actual)\nprint('Predicted Frequency :', n_pred_GBM)\nprint('Calibration Ratio   :', n_pred_GBM / n_actual)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to 0/1\nbinary_threshold_GBM = 0.485945 # chose such that actual frequency is (approximately) met\npred_train_GBM_binary = np.where(pred_train_GBM > binary_threshold_GBM, 1, 0)\nprint('Actual Frequency      :', n_actual)\nprint('Calibrated Prediction :', sum(pred_train_GBM_binary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# confusion matrix at selected threshold\npd.crosstab(df_train.Survived, pred_train_GBM_binary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='7'></a>\n# Build Random Forest Model","metadata":{}},{"cell_type":"code","source":"# Random Forest model\nn_cv = 5\n\nfit_DRF = H2ORandomForestEstimator(nfolds=n_cv,\n                                  distribution='bernoulli',\n                                  ntrees=100,\n                                  mtries=-1, # automatic selection\n                                  max_depth=20,\n                                  score_each_iteration=True,\n                                  stopping_metric='auc',\n                                  stopping_rounds=5,\n                                  stopping_tolerance=0.0001,\n                                  seed=999)\n\n# train model\nt1 = time.time()\nfit_DRF.train(x=predictors,\n            y='Survived',\n            training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show cross validation metrics\nfit_DRF.cross_validation_metrics_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show scoring history - training vs cross validations\nfor i in range(n_cv):\n    cv_model_temp = fit_DRF.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [AUC]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_auc, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_auc, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.ylabel('AUC')\n    plt.ylim(0.7,0.9)\n    plt.legend()\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# variable importance\nfit_DRF.varimp_plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# alternative variable importance using SHAP => see direction as well as severity of feature impact\nt1 = time.time()\nfit_DRF.shap_summary_plot(train_hex);\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training performance\nperf_train = fit_DRF.model_performance(train=True)\nperf_train.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cross validation performance\nperf_cv = fit_DRF.model_performance(xval=True)\nperf_cv.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict on train set (extract probabilities only)\npred_train_DRF = fit_DRF.predict(train_hex)['p1']\npred_train_DRF = pred_train_DRF.as_data_frame().p1\n\n# plot train set predictions (probabilities)\nplt.figure(figsize=(6,4))\nplt.hist(pred_train_DRF, bins=100)\nplt.title('Predictions on Train Set - Random Forest')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calibration\nn_actual = sum(df_train.Survived)\nn_pred_DRF = sum(pred_train_DRF)\n\nprint('Actual Frequency    :', n_actual)\nprint('Predicted Frequency :', n_pred_DRF)\nprint('Calibration Ratio   :', n_pred_DRF / n_actual)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to 0/1\nbinary_threshold_DRF = 0.4709 # chose such that actual frequency is (approximately) met\npred_train_DRF_binary = np.where(pred_train_DRF > binary_threshold_DRF, 1, 0)\nprint('Actual Frequency      :', n_actual)\nprint('Calibrated Prediction :', sum(pred_train_DRF_binary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# confusion matrix at selected threshold\npd.crosstab(df_train.Survived, pred_train_DRF_binary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='8'></a>\n# Predict on Test Set & Submission","metadata":{}},{"cell_type":"markdown","source":"### GBM","metadata":{}},{"cell_type":"code","source":"# predict on test set (extract probabilities only)\npred_test_GBM = fit_GBM.predict(test_hex)['p1']\npred_test_GBM = pred_test_GBM.as_data_frame().p1\n\n# plot test set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(pred_test_GBM, bins=100)\nplt.title('Predictions on Test Set - GBM')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to binary again - aggregate probabilities first\npred_test_GBM_sum = pred_test_GBM.sum()\nprint('GBM - Sum of probs:', np.round(pred_test_GBM_sum,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we select threshold such that counts are approximately equal to sum of probs (expected frequency)\nbinary_threshold_GBM_test = 0.44319\npred_test_GBM_binary = np.where(pred_test_GBM > binary_threshold_GBM_test, 1, 0)\npd.Series(pred_test_GBM_binary).value_counts()\nprint('GBM - Number of Survived - Test Set (binary):', sum(pred_test_GBM_binary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GBM submission\ndf_sub_GBM = df_sub.copy()\ndf_sub_GBM.Survived = pred_test_GBM_binary\ndisplay(df_sub_GBM.head())\n# save to file\ndf_sub_GBM.to_csv('submission_GBM.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save probabilities as well\npred_test_GBM.to_csv('probs_GBM.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"# predict on test set (extract probabilities only)\npred_test_DRF = fit_DRF.predict(test_hex)['p1']\npred_test_DRF = pred_test_DRF.as_data_frame().p1\n\n# plot test set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(pred_test_DRF, bins=100)\nplt.title('Predictions on Test Set - Random Forest')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to binary again - aggregate probabilities first\npred_test_DRF_sum = pred_test_DRF.sum()\nprint('DRF - Sum of probs:', np.round(pred_test_DRF_sum,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we select threshold such that counts are approximately equal to sum of probs (expected frequency)\nbinary_threshold_DRF_test = 0.44357\npred_test_DRF_binary = np.where(pred_test_DRF > binary_threshold_DRF_test, 1, 0)\npd.Series(pred_test_DRF_binary).value_counts()\nprint('DRF - Number of Survived - Test Set (binary):', sum(pred_test_DRF_binary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DRF submission\ndf_sub_DRF = df_sub.copy()\ndf_sub_DRF.Survived = pred_test_DRF_binary\ndisplay(df_sub_DRF.head())\n# save to file\ndf_sub_DRF.to_csv('submission_DRF.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save probabilities as well\npred_test_DRF.to_csv('probs_DRF.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Blend","metadata":{}},{"cell_type":"code","source":"# combine predictions in one data frame\ndf_preds_train = pd.DataFrame({'GBM': pred_train_GBM.values, 'DRF': pred_train_DRF.values})\ndf_preds_test = pd.DataFrame({'GBM': pred_test_GBM.values, 'DRF': pred_test_DRF.values})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scatter plot of two prediction sets - TRAIN set\nsns.jointplot(data=df_preds_train, x='GBM', y='DRF',\n              joint_kws={'s' : 2},\n              alpha=0.25)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scatter plot of two prediction sets - TEST set\nsns.jointplot(data=df_preds_test, x='GBM', y='DRF',\n              joint_kws={'s' : 2},\n              alpha=0.25)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation (on test set)\ndf_preds_test.corr(method='pearson')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# blend two model results on probability level\nw_GBM = 0.8\nw_DRF = 1-w_GBM\ndf_preds_train['blend'] = w_GBM*df_preds_train.GBM + w_DRF*df_preds_train.DRF\ndf_preds_test['blend'] = w_GBM*df_preds_test.GBM + w_DRF*df_preds_test.DRF","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot test set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(df_preds_test.blend, bins=100)\nplt.title('Predictions on Test Set - Blend')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to 0/1\nprint('Actual Frequency:', n_actual)\n# recalc threshold (for training)\nbinary_threshold_BLEND = 0.488345 # chose such that actual frequency is (approximately) met\npred_train_BLEND_binary = np.where(df_preds_train.blend > binary_threshold_BLEND, 1, 0)\nprint('Number of Survived (binary):', sum(pred_train_BLEND_binary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# confusion matrix at selected threshold\npd.crosstab(df_train.Survived, pred_train_BLEND_binary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to binary again - aggregate probabilities first\npred_test_BLEND_sum = df_preds_test.blend.sum()\nprint('Blend - Sum of probs:', np.round(pred_test_BLEND_sum,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we select threshold such that counts are approximately equal to sum of probs (expected frequency)\nbinary_threshold_BLEND_test = 0.44189\npred_test_BLEND_binary = np.where(df_preds_test.blend > binary_threshold_BLEND_test, 1, 0)\npd.Series(pred_test_BLEND_binary).value_counts()\nprint('Blend - Number of Survived - Test Set (binary):', sum(pred_test_BLEND_binary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# blend submission\ndf_sub_BLEND = df_sub.copy()\ndf_sub_BLEND.Survived = pred_test_BLEND_binary\ndisplay(df_sub_BLEND.head())\n# save to file\ndf_sub_BLEND.to_csv('submission_BLEND.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='9'></a>\n# Explanations for GBM model","metadata":{}},{"cell_type":"markdown","source":"### Let's look a little bit behind the scenes of our GBM model predictions:","metadata":{}},{"cell_type":"code","source":"# pick an example (from training data)\nmy_row = 8\ntrain_hex[my_row,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what did we predict?\nprint('Prediction (binary):', pred_train_GBM_binary[my_row])\nprint('Prediction (prob.) :', pred_train_GBM[my_row])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# explain prediction by decomposing it into individual contributions\nfit_GBM.shap_explain_row_plot(row_index=my_row, frame=train_hex);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Interpretation: We have already seen that males had a much lower chance of survival and sex is also here the most important factor. On the positive side we have Parch=1 (# of parents / children aboard) and Pclass=1 (1st class ticket). Impact of name is negligible.","metadata":{}}]}