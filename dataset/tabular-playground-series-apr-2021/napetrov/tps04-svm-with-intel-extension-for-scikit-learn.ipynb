{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸš€ Optimizing Kaggle kernels using Intel(R) Extension for Scikit-learn\n\nFor classical machine learning algorithms, we often use the most popular Python library, scikit-learn. We use it to fit models and search for optimal parameters, butâ€¯scikit-learnâ€¯sometimes works for hours, if not days. Speeding up this process is something anyone who uses scikit-learn would be interested in.\n\nI want to show you how to get results faster without changing the code. To do this, we will use another Python library,â€¯[scikit-learn-intelex](https://github.com/intel/scikit-learn-intelex). It accelerates scikit-learn and does not require you changing the code written for scikit-learn.\n\nI will show you how to speed up your kernel **from 2h 26min to 6 minutes** without changes of your code! This is **25x** speedup\n\nThis kernel is based on [[TPS 2021-04] Support Vector Machines](https://www.kaggle.com/ekozyreff/tps-2021-04-support-vector-machines) and use same code with addition of scikit-learn-intelex\n\nSpeedup details:\n\n|Case                     | Original time  | Patched time   | Speedup       |Original accuracy | Patched accuracy |\n| :-----------------------| :------------: | :-------------:| :------------:|:----------------:| :---------------:|\n|SVM RBF Train            | 10min 2s       | 38.5 s         | x15.6         | 0.7614 - local   | 0.7614 - local   |\n|SVM RBF Predict          | 4min 51s       | 9.56 s         | x30.4         | 0.79062 - PL     | 0.79062 - PL     |\n|SVM RBF 10 folds         | 2h 26min 43s   | 5min 49s       | x25.2           | 0.79078 - PL     | 0.79066 - PL     |\n\nNote: actual run time depends on particular VM hardware provisioned for kernel - there are might be notisable fluctuation in time\n\nNote2: we observe slightly lower accuracy for folded case - will be investigating this\n","metadata":{}},{"cell_type":"markdown","source":"# Installing scikit-learn-intelex\n\nPackage also avaialble in conda  - please refer to details https://github.com/intel/scikit-learn-intelex","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn-intelex --progress-bar off >> /tmp/pip_sklearnex.log","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Enable Intel(R) Extension for Scikit-learn\nDo magic here - patching scikit-learn ","metadata":{}},{"cell_type":"code","source":"from sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Original code below\nOnly keep code relevant for final kfolds block","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv', index_col='PassengerId')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv', index_col='PassengerId')\nsubmission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv', index_col='PassengerId')\n\ntarget = train.pop('Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\ntest.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prepared = test.copy()\ntrain_prepared = train.copy()\n\ntest_prepared['Age'].fillna((train['Age'].median()), inplace=True)\ntrain_prepared['Age'].fillna((train['Age'].median()), inplace=True)\n\ntest_prepared['Fare'].fillna((train['Fare'].median()), inplace=True)\ntrain_prepared['Fare'].fillna((train['Fare'].median()), inplace=True)\n\ntest_prepared['Embarked'].fillna('S', inplace=True)\ntrain_prepared['Embarked'].fillna('S', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['Pclass', 'Sex', 'Embarked']:\n    le = LabelEncoder()\n    le.fit(train_prepared[col])\n    train_prepared[col] = le.transform(train_prepared[col])\n    test_prepared[col] = le.transform(test_prepared[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_prepared.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_prepared_scaled = train_prepared.copy()\ntest_prepared_scaled = test_prepared.copy()\n\nscaler = StandardScaler()\nscaler.fit(train_prepared)\ntrain_prepared_scaled = scaler.transform(train_prepared_scaled)\ntest_prepared_scaled = scaler.transform(test_prepared_scaled)\n\ntrain_prepared_scaled = pd.DataFrame(train_prepared_scaled, columns=train_prepared.columns)\ntest_prepared_scaled = pd.DataFrame(test_prepared_scaled, columns=train_prepared.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_prepared_scaled, target, test_size=0.1, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsvc_kernel_rbf = SVC(kernel='rbf', random_state=0, C=0.01)\nsvc_kernel_rbf.fit(X_train, y_train)\ny_pred = svc_kernel_rbf.predict(X_valid)\naccuracy_score(y_pred, y_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfinal_pred = svc_kernel_rbf.predict(test_prepared_scaled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing to original RBF case\n\nAchived same accuracy in local scoring - 0.7614\n\nAchived same accuracy in public leaderboard **0.79062**\n\nOriginal training time: 10min 2s\n\nOriginal predict time: 4min 51s\n\n","metadata":{}},{"cell_type":"code","source":"submission['Survived'] = np.round(final_pred).astype(int)\nsubmission.to_csv('svc_kernel_rbf.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nn_folds = 10\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=0)\ny_pred = np.zeros(test.shape[0])\n\nfor fold, (train_index, valid_index) in enumerate(kf.split(train_prepared_scaled, target)):\n    print(\"Running Fold {}\".format(fold + 1))\n    X_train, X_valid = pd.DataFrame(train_prepared_scaled.iloc[train_index]), pd.DataFrame(train_prepared_scaled.iloc[valid_index])\n    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n    svc_kernel_rbf = SVC(kernel='rbf', random_state=0, C=0.01)\n    svc_kernel_rbf.fit(X_train, y_train)\n    print(\"  Accuracy: {}\".format(accuracy_score(y_valid, svc_kernel_rbf.predict(X_valid))))\n    y_pred += svc_kernel_rbf.predict(test_prepared_scaled)\n\ny_pred /= n_folds\n\nprint(\"\")\nprint(\"Done!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Survived'] = np.round(y_pred).astype(int)\nsubmission.to_csv('svc_kernel_rbf_10_folds.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}