{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://faithmag.com/sites/default/files/styles/article_full/public/2018-09/titanic2.jpg?h=6521bd5e&itok=H8td6QVv\" alt=\"drawing\" height=\"600\" width=\"600\"/>\n\n# **Titanic dataset is one of the best known for those who start their journey with ML.**\n### In this notebook, I will show you an easy approach to obtain nearly 80%. This score may be easily improved by a couple of methods which I will mention at the end. The purpose of this work is not to find the best possible solution for this problem but a simple one that performs decently.\n\n## Please upvote my work if you find it helpful. Happy reading :)","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport sklearn as skl\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = '/kaggle/input/tabular-playground-series-apr-2021/'\ntrain_path = os.path.join(base_path, 'train.csv')\ntest_path = os.path.join(base_path, 'test.csv')\nsample_submission_path = os.path.join(base_path, 'sample_submission.csv')\n\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\nsample_submission = pd.read_csv(sample_submission_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train shape:', train.shape)\nprint('test shape:', test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### After initial data inspection it seems like Name, PassengerId columns won't be needed. Cabin and Ticket columns need to be transformed to bu useful.","metadata":{}},{"cell_type":"code","source":"cols_to_drop = ['Name', 'PassengerId']\n\ntrain.drop(cols_to_drop, axis=1, inplace=True)\n\n# keep ids for submission \ntest_indexes = test['PassengerId']\ntest.drop(cols_to_drop, axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_col = 'Survived'\n\ncategorical_cols = list(train.loc[:,train.dtypes == \"object\"].columns)\nnumerical_cols = list(train.loc[:,train.dtypes != \"object\"].columns)\n\nnumerical_cols.remove(target_col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Cabin.fillna('N', inplace=True)\ntest.Cabin.fillna('N', inplace=True)\n\ntrain.Cabin = train.Cabin.map(lambda x: x[0])\ntest.Cabin = test.Cabin.map(lambda x: x[0])\n\n\ntrain.Ticket = train.Ticket.fillna('N').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'N')\ntest.Ticket = test.Ticket.fillna('N').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'N')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's plot categorical and descrete values data with respect to Survived","metadata":{}},{"cell_type":"code","source":"axes = []\ncols = list(categorical_cols)\ncols.extend(['Pclass', 'SibSp', 'Parch'])\ncols.remove('Ticket')\nprint(cols)\nnum_of_cols = len(cols)\nfig = plt.figure(figsize=(12, 12 * num_of_cols))\n\nfor i in range(num_of_cols):    \n    plot = train[cols[i]].value_counts()\n  \n    ax = fig.add_subplot(num_of_cols, 1, i + 1)\n    axes.append(ax)\n    \n    sns.countplot(data=train, x=cols[i], hue=target_col, ax=ax)\n    ax.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As expected sex seems to have a big impact. Embarked, Cabin and Pclass also give some valueble insight. Looking into SibSp and Parth columns it is hard to evaluate because of not equaly distributed labels(~45% survived and ~55% not survived)\n### Now lets inspect numerical values with respect to the target value","metadata":{}},{"cell_type":"code","source":"def plot_face_grid(x):\n    g = sns.FacetGrid(train, col=target_col, height=6)\n    g.map(sns.kdeplot, x, shade=True).add_legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_face_grid('Age')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It seems like older people were more likely to survive compering to young adults","metadata":{}},{"cell_type":"code","source":"plot_face_grid('Fare')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As on the previous chart, data seems to be a bit skew to the right","metadata":{}},{"cell_type":"code","source":"# Apply Chi-Squared test on the next verison of the notebook","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now let's prepare data for the modeling\n### You may experiment with different strategies for SimpleImputer and with Scalers","metadata":{}},{"cell_type":"code","source":"def remove_target(data, target):\n    ret = data[target]\n    data.drop([target], axis=1, inplace=True)\n    return ret","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nclass ModifiedLabelEncoder(LabelEncoder):\n\n    def fit_transform(self, y, *args, **kwargs):\n        return super().fit_transform(y).reshape(-1, 1)\n\n    def transform(self, y, *args, **kwargs):\n        return super().transform(y).reshape(-1, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\n\ntrain_y = remove_target(train, target_col)\n\n\ncategorical_cols.remove('Ticket')\nlabel_cols = ['Ticket']\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('std_scaler', StandardScaler())\n    ])\n\ncat_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy='most_frequent')),#, fill_value='None')),\n        ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\nlab_pipeline = Pipeline([\n    ('label_encoder', ModifiedLabelEncoder())\n])\n\nfull_pipeline = ColumnTransformer([\n        ('num', num_pipeline, numerical_cols),\n        ('cat', cat_pipeline, categorical_cols),\n        ('lab', lab_pipeline, label_cols)\n    ])\n    \n\ntrain = full_pipeline.fit_transform(train, train_y)\ntest = full_pipeline.fit_transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modle selection","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom lightgbm.sklearn import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_validate\n\n\nfrom scipy.stats import uniform\nfrom random import randint\n\nnp.random.seed(123)\n\nmodels = [\n    (CatBoostClassifier(verbose=False), 'CatBoost'),\n    (AdaBoostClassifier(), 'AdaBoost'),\n    (RandomForestClassifier(), 'RandomForest'),\n    (GaussianNB(), 'NB'),\n    (ExtraTreesClassifier(), 'ExtraTreesClassifier'),\n    (LogisticRegression(max_iter=600), 'LogisticRegression'),\n    (KNeighborsClassifier(), 'KNeighbors'),\n    (XGBClassifier(use_label_encoder=False), 'XGB'),\n    (LGBMClassifier(), 'LGBM')\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n\ndef train_and_evaluate(model, x, y):\n    model, name = model\n    results = cross_validate(model, x, y)\n    results = results['test_score']\n    print(name)\n    print(results)\n    print('mean: ', results.mean())\n    print('std: ', results.std(), '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in models:\n    train_and_evaluate(model, train, train_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As we can see, catboost and LGBM performs the best. We will focus on finding best parameters for the second one. If you want to get better result you may increase n_iters to try bigger amount of combinations.","metadata":{}},{"cell_type":"code","source":"parameters = {\n    \"n_estimators\": list(range(20, 500)),\n    \"learning_rate\": uniform(0.001, 0.199),\n    \"max_depth\": [-1, 2, 4, 8, 16],\n    \"min_data_per_group\": list(range(2,1000)),\n    \"num_leaves\": list(range(2, 200)),\n    \"bagging_freq\": list(range(1, 8)),\n    \"max_bin\": list(range(2, 200)),\n    \"lambda_l1\": uniform(0.001, 0.199),\n    \"lambda_l2\": uniform(0.001, 0.199),\n    \"feature_fraction\" : [i/100 if i/100 < 1 else 1. for i in range(71,120)],\n    \"bagging_fraction\" : uniform(0.01, 0.99)\n    } \n\nmodel = LGBMClassifier(extra_trees=True, verbose=-1)\nrandomsearch = RandomizedSearchCV(model,\n                                  param_distributions=parameters,\n                                  n_iter=25,\n                                  cv=4,\n                                  random_state=1,\n                                  scoring='accuracy',\n                                  return_train_score=True,\n                                  refit='Accuracy',\n                                  )\n\nr = randomsearch.fit(train,train_y)\nscores = r.cv_results_\nbest = r.best_estimator_\n","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print all models tried with the parameters used and gained performace\nfor mean_score, params in sorted(list(zip(scores[\"mean_test_score\"], scores[\"params\"])), key = lambda x: x[0]):\n    print(mean_score, params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The best result I got has accuracy slightly above 78.2%. Fortunately, because of cross-validation, we did not overfit and it gives us almost 80% for the submission\n","metadata":{}},{"cell_type":"code","source":"result = best.predict(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(zip(test_indexes, result))\ndf.columns = ['PassengerId', 'Survived']\ndf.set_index('PassengerId', inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n\n### I hope you liked this notebook. If you have any suggestions, please share them in the comments.\n\n### List of the todo things to improve final accuracy:\n- Try pseudo labels. This works really well on this dataset. It may increase your final accuracy by > 1% (You first train the initial model to predict labels for the test set and later on you use a combined test and training set for training the final model) \n- Try Stacking. (Train many different models and use the probabilities returned by them as an input to the final decision model, read more here https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html.\n- Build the NN.\n- Experiment with feature engineering. ","metadata":{}}]}