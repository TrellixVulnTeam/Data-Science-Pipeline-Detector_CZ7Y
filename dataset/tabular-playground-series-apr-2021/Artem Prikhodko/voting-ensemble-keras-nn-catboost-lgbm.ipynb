{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nHello!\n\nIn this kernel you will find my approach to \"Tabular Playground Series - Apr 2021\" competition using neural network.","metadata":{}},{"cell_type":"markdown","source":"# Table of contents:\n\n1. Meeting our data\n\n2. Visualization and data analysis\n\n3. Data cleaning\n\n4. Feature engineering and encoding\n\n5. Creating and evaluating a model\n\n    5.1 Neural network\n\n    5.2 Other models\n\n    5.3 Voting ensemble","metadata":{}},{"cell_type":"markdown","source":"# 1. Meeting our data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv', index_col = 'PassengerId')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv', index_col = 'PassengerId')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.dtypes.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.select_dtypes(include = ['object']).describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop('Survived', axis = 1).select_dtypes(exclude = ['object']).describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = train.Survived.copy()\ntarget","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.isna().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.loc[target == 1].size / target.size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop('Survived', axis = 1).columns.equals(test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Visualization and data analysis","metadata":{}},{"cell_type":"code","source":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nsns.set_style('whitegrid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16, 6))\nsns.countplot(x = train.Survived, palette = 'Purples_r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_grid(data, fig_size, grid_size, plot_type, target = ''):\n    \"\"\"\n    Custom function for plotting grid of plots.\n    It takes: DataFrame of data, size of a grid, type of plots, string name of target variable;\n    And it outputs: grid of plots.\n    \"\"\"\n    fig = plt.figure(figsize = fig_size)\n    if plot_type == 'histplot':\n        for i, column_name in enumerate(data.select_dtypes(exclude = 'object').columns):\n            fig.add_subplot(grid_size[0], grid_size[1], i + 1)\n            plot = sns.histplot(data[column_name], kde = True, color = 'blueviolet', stat = 'count')\n    if plot_type == 'boxplot':\n        for i, column_name in enumerate(data.select_dtypes(exclude = 'object').columns):\n            fig.add_subplot(grid_size[0], grid_size[1], i + 1)\n            plot = sns.boxplot(x = data[column_name], color = 'blueviolet')\n    if plot_type == 'countplot':\n        target = data[target]\n        for i, column_name in enumerate(data.drop(target.name, axis = 1).columns):\n            fig.add_subplot(grid_size[0], grid_size[1], i + 1)\n            plot = sns.countplot(x = data[column_name], hue = target, palette = 'Purples_r')\n            plot.legend(loc = 'upper right', title = target.name)\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grid(train.drop('Survived', axis = 1), (16, 6), (2,3), 'histplot')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(train, index = 'Survived', values = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass'], aggfunc = 'mean')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grid(train.select_dtypes(exclude = 'object').drop(['Fare', 'Age'], axis = 1), (16, 6), (1, 3), 'countplot', 'Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"{pd.pivot_table(train, index = 'Survived', columns = 'Pclass', values = 'Name', aggfunc ='count')} \\n\\n\" +\n      f\"{pd.pivot_table(train, index = 'Survived', columns = 'SibSp', values = 'Name', aggfunc ='count')} \\n\\n\" +\n      f\"{pd.pivot_table(train, index = 'Survived', columns = 'Parch', values = 'Name', aggfunc ='count')}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16, 6))\nsns.heatmap(train.corr(), \n            annot = True,\n            fmt = '.2f',\n            square = True,\n            cmap = \"Purples_r\", \n            mask = np.triu(train.corr()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grid(train.drop('Survived', axis = 1), (16, 6), (2,3), 'boxplot')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grid(pd.concat([train.select_dtypes(include = 'object').drop(['Name', 'Ticket', 'Cabin'], axis = 1), target], axis = 1), (16, 6), (2,1), 'countplot', 'Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"{pd.pivot_table(train, index = 'Survived', columns = 'Sex', values = 'Name', aggfunc ='count')} \\n\\n\" +\n      f\"{pd.pivot_table(train, index = 'Survived', columns = 'Embarked', values = 'Name', aggfunc ='count')}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.select_dtypes(include = 'object').nunique().sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Data cleaning","metadata":{}},{"cell_type":"code","source":"train_test = pd.concat([train.drop('Survived', axis = 1), test], keys = ['train', 'test'], axis = 0)\nmissing_values = pd.concat([train_test.isna().sum(),\n                            (train_test.isna().sum() / train_test.shape[0]) * 100], axis = 1, \n                            keys = ['Values missing', 'Percent of missing'])\nmissing_values.loc[missing_values['Percent of missing'] > 0].sort_values(ascending = False, by = 'Percent of missing').style.background_gradient('Purples')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cleaning = train.drop('Survived', axis = 1).copy()\ntest_cleaning = test.copy()\n\ntrain_cleaning['Cabin'].fillna('none', inplace = True)\ntest_cleaning['Cabin'].fillna('none', inplace = True)\n\ntrain_cleaning['Ticket'].fillna('none', inplace = True)\ntest_cleaning['Ticket'].fillna('none', inplace = True)\n\ntrain_cleaning['Age'].fillna(train_cleaning['Age'].median(), inplace = True)\ntest_cleaning['Age'].fillna(train_cleaning['Age'].median(), inplace = True)\n\ntrain_cleaning['Embarked'] = train_cleaning.groupby('Pclass').Embarked.apply(lambda x: x.fillna(x.mode()[0]))\ntrain_cleaning['Fare'] = train_cleaning.groupby('Pclass').Fare.apply(lambda x: x.fillna(x.median()))\nfor i in train.Pclass.unique():\n    test_cleaning.loc[test.Pclass == i, 'Embarked'] = test_cleaning.loc[test.Pclass == i, 'Embarked'].fillna(train.loc[train.Pclass == i].Embarked.mode()[0])\n    test_cleaning.loc[test.Pclass == i, 'Fare'] = test_cleaning.loc[test.Pclass == i, 'Fare'].fillna(train.loc[train.Pclass == i].Fare.median())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cleaning.isnull().sum().max() + test_cleaning.isnull().sum().max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Feature engineering and encoding","metadata":{}},{"cell_type":"code","source":"train_test_cleaning = pd.concat([train_cleaning, test_cleaning], keys = ['train', 'test'], axis = 0)\ntrain_test_cleaning","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_cleaning['CabinLetter'] = train_test_cleaning.Cabin.str.split().apply(lambda x: x[-1][0].strip().lower() if x[0] != 'none' else np.nan)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_cleaning.xs('train').groupby('Pclass').CabinLetter.apply(lambda x: x.value_counts().index[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cleaning_new = train_test_cleaning.xs('train').copy()\ntest_cleaning_new = train_test_cleaning.xs('test').copy()\n\ntrain_cleaning_new['CabinLetter'] = train_cleaning_new.groupby('Pclass')['CabinLetter'].apply(lambda x: x.fillna(x.mode()[0]))\n\nfor i in train.Pclass.unique():\n    test_cleaning_new.loc[test_cleaning_new.Pclass == i, 'CabinLetter'] = test_cleaning_new.loc[test_cleaning_new.Pclass == i, 'CabinLetter'].fillna(train_cleaning_new.loc[train_cleaning_new.Pclass == i].CabinLetter.mode()[0])\n    \ntrain_test_cleaning = pd.concat([train_cleaning_new, test_cleaning_new], keys = ['train', 'test'], axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_cleaning['CabinNumbers'] = train_test_cleaning.Cabin.apply(lambda x: int(x[1:]) if x != 'none' else 0)\n\ntrain_test_cleaning['TicketNumbers'] = train_test_cleaning.Ticket.apply(lambda x: int(x) if x.isnumeric() else 0 if x == 'none' else int(x.split(' ')[-1]) if (x.split(' ')[-1]).isnumeric() else 0)\ntrain_test_cleaning['TicketLetters'] = train_test_cleaning.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.', '').replace('/', '').lower() \n                                                                        if len(x.split(' ')[:-1]) > 0 else 'none')\ntrain_test_cleaning['TicketIsNumeric'] = train_test_cleaning.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n\ntrain_test_cleaning['FamilySize'] = train_test_cleaning.SibSp + train_test_cleaning.Parch + 1\ntrain_test_cleaning['FamilySize'] = train_test_cleaning['FamilySize'].apply(lambda x: 'no family' if (x == 1)\n                                                                            else 'medium' if (x == 2 or x == 3)\n                                                                            else 'large')\n\n# train_test_cleaning['AgeGroup'] = train_test_cleaning['Age'].apply(lambda x: 'infant' if (x < 1) \n#                                                                    else 'child' if (x >= 1 and x <= 11)                                                                    \n#                                                                    else 'teen' if (x >= 12 and x <= 17)\n#                                                                    else 'adult' if (x >= 18 and x <= 64)\n#                                                                    else 'adult+')\n\n# train_test_cleaning['Surname'] = train_test_cleaning['Name'].apply(lambda x: x.split(',')[0].lower())\ntrain_test_cleaning['Embarked'] = train_test_cleaning['Embarked'].str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_cleaning","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cleaning_target_cleaned = pd.concat([train_test_cleaning.xs('train'), target], axis = 1)\ntrain_cleaning_target_cleaned","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"{pd.pivot_table(train_cleaning_target_cleaned, index = 'Survived', columns = 'CabinLetter', values = 'Name', aggfunc ='count')} \\n\\n\" +\n      f\"{pd.pivot_table(train_cleaning_target_cleaned, index = 'Survived', values = 'TicketNumbers', aggfunc = (lambda x: x.mode()[0]))} \\n\\n\" +\n      f\"{pd.pivot_table(train_cleaning_target_cleaned, index = 'Survived', columns = 'TicketIsNumeric', values = 'Name', aggfunc ='count')} \\n\\n\" +\n#       f\"{pd.pivot_table(train_cleaning_target_cleaned, index = 'Survived', columns = 'AgeGroup', values = 'Name', aggfunc ='count')} \\n\\n\" +\n      f\"{pd.pivot_table(train_cleaning_target_cleaned, index = 'Survived', columns = 'FamilySize', values = 'Name', aggfunc ='count')}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(train_cleaning_target_cleaned, index = 'Survived', columns = 'TicketLetters', values = 'Name', aggfunc = 'count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cleaning_target_cleaned.select_dtypes(include = 'object').nunique().sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grid(train_cleaning_target_cleaned.drop(['Survived', 'Pclass', 'TicketIsNumeric', 'SibSp', 'Parch'], axis = 1), (16, 6), (2, 3), 'histplot')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_grid(train_cleaning_target_cleaned.drop(['Name', 'Ticket', 'Cabin', 'Age', 'Fare', 'TicketNumbers', 'TicketLetters', 'CabinNumbers'],\n                                             axis = 1), (16, 6), (3, 3), 'countplot', 'Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'Age', 'Fare', 'TicketNumbers', 'CabinNumbers'\nfig, axs = plt.subplots(2, 2, figsize = (16, 6))\nsns.histplot(hue = train_cleaning_target_cleaned.Survived, x = train_cleaning_target_cleaned.Age, palette = {0 : 'black', 1 : 'purple'}, ax = axs[0][0])\naxs[0][0].set_title('Age distribution')\nsns.histplot(hue = train_cleaning_target_cleaned.Survived, x = train_cleaning_target_cleaned.Fare, palette = {0 : 'black', 1 : 'purple'}, ax = axs[0][1])\naxs[0][1].set_title('Fare distribution')\n\nsns.histplot(hue = train_cleaning_target_cleaned.Survived, x = train_cleaning_target_cleaned.TicketNumbers, palette = {0 : 'black', 1 : 'purple'}, ax = axs[1][0])\naxs[1][0].set_title('TicketNumbers distribution')\nsns.histplot(hue = train_cleaning_target_cleaned.Survived, x = train_cleaning_target_cleaned.CabinNumbers, palette = {0 : 'black', 1 : 'purple'}, ax = axs[1][1])\naxs[1][1].set_title('CabinNumbers distribution')\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,6))\nsns.heatmap(train_cleaning_target_cleaned.corr(),\n            annot = True,\n            fmt = '.2f',\n            square = True,\n            cmap = \"Purples_r\",\n            mask = np.triu(train_cleaning_target_cleaned.corr()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_drop = ['Name',\n           'Ticket',\n           'Cabin']\n\ntrain_test_cleaned = train_test_cleaning.drop(to_drop, axis = 1).copy()\ntrain_test_cleaned","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_cols = ['TicketLetters', 'Sex', 'Pclass', 'TicketIsNumeric', 'FamilySize']#'Surname', \nonehot_cols = ['CabinLetter', 'Embarked']\nnumerical_cols = ['Age', 'SibSp', 'Parch', 'Fare', 'TicketNumbers', 'CabinNumbers']#'Pclass'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# One-hot encoding\ntrain_test_onehot = pd.get_dummies(train_test_cleaned[onehot_cols])\nX_train_full_onehot, X_test_onehot = train_test_onehot.xs('train').reset_index(), train_test_onehot.xs('test').reset_index()\n\nX_train_full, X_test = train_test_cleaned.xs('train'), train_test_cleaned.xs('test')\n# Label encoding\nX_train_full_labeled = pd.DataFrame()\nX_test_labeled = pd.DataFrame()\nfor col in label_cols:\n    encoder = LabelEncoder()\n    encoder.fit(X_train_full[col])\n    \n    encoded_train = pd.Series(encoder.transform(X_train_full[col]), name = col)\n    X_train_full_labeled = pd.concat([X_train_full_labeled, encoded_train], axis = 1)\n    \n    encoded_test = pd.Series(encoder.transform(X_test[col]), name = col)\n    X_test_labeled = pd.concat([X_test_labeled, encoded_test], axis = 1)\n# Numerical features scaling\nscaler = StandardScaler()\nscaler.fit(X_train_full[numerical_cols])\nX_train_full_scaled = pd.DataFrame(scaler.transform(X_train_full[numerical_cols]), columns = numerical_cols)\nX_test_scaled = pd.DataFrame(scaler.transform(X_test[numerical_cols]), columns = numerical_cols)\n# Concatenating it all together\nX_train_full = pd.concat([X_train_full_onehot, \n                          X_train_full_labeled, \n                          X_train_full_scaled], axis = 1)\nX_train_full.set_index('PassengerId', inplace = True)\nX_test = pd.concat([X_test_onehot, \n                    X_test_labeled, \n                    X_test_scaled], axis = 1)\nX_test.set_index('PassengerId', inplace = True)\nX_train_full","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_full = target\ny_train_full","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Creating and evaluating a model","metadata":{}},{"cell_type":"markdown","source":"# 5.1 Neural network","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom sklearn.model_selection import train_test_split\n\ntf.random.set_seed(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    patience = 10,#100 80 40 20 10\n    min_delta = 0.001,\n    restore_best_weights = True,\n)\n\nk = 5\nhistory = pd.DataFrame(columns = ['ValAccuracy', 'TrainAccuracy', 'StoppedEpoch'], index = range(k))\n\nfor fold in range(k):\n    X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, stratify = y_train_full, train_size = 0.8)\n    \n    model = keras.Sequential([layers.BatchNormalization(input_shape = [X_train_full.shape[1]]),\n                              layers.Dense(units = 16, activation = 'relu'),\n                              layers.Dropout(rate = 0.1),\n                              \n                              layers.BatchNormalization(),\n                              layers.Dense(units = 16, activation = 'relu'),\n                              layers.Dropout(rate = 0.1),\n                              \n                              layers.BatchNormalization(),\n                              layers.Dense(units = 1, activation = 'sigmoid')])\n    \n    model.compile(optimizer = 'adam',\n                  loss = 'binary_crossentropy',\n                  metrics = ['binary_accuracy'])\n    \n    model.fit(X_train, y_train,\n              validation_data = (X_valid, y_valid),\n              batch_size = 512,\n              epochs = 1000,\n              callbacks = [early_stopping],\n              verbose = 0,)\n    \n    history.loc[fold, 'ValAccuracy'] = model.history.history['val_binary_accuracy']\n    history.loc[fold, 'TrainAccuracy'] = model.history.history['binary_accuracy']\n    history.loc[fold, 'StoppedEpoch'] = early_stopping.stopped_epoch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(k, figsize = (16, 32))\nfig.suptitle(f'Train and validation accuracy for {k}-fold validation\\n\\n', fontsize = 16)\nfor i in range(k):\n    sns.lineplot(data = history.loc[i, 'ValAccuracy'], ax = axs[i], color = 'red')\n    sns.lineplot(data = history.loc[i, 'TrainAccuracy'], ax = axs[i], color = 'blue')\n    axs[i].legend(['Validation', 'Train'])\n    axs[i].set_ylabel('Accuracy')\n    axs[i].set_xlabel('Epochs')\n    \nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.StoppedEpoch.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential([layers.BatchNormalization(input_shape = [X_train_full.shape[1]]),\n                              layers.Dense(units = 16, activation = 'relu'),\n                              layers.Dropout(rate = 0.1),\n                              \n                              layers.BatchNormalization(),\n                              layers.Dense(units = 16, activation = 'relu'),\n                              layers.Dropout(rate = 0.1),\n                              \n                              layers.BatchNormalization(),\n                              layers.Dense(units = 1, activation = 'sigmoid')])\n\nmodel.compile(optimizer = 'adam',\n              loss = 'binary_crossentropy',\n              metrics = ['binary_accuracy'])\n\nhistory = model.fit(X_train_full, y_train_full,\n                    batch_size = 512,\n                    epochs = 33,\n                    verbose = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train mean: {np.mean(history.history['binary_accuracy'])}\"+\"\\n\"+\n      f\"Train std: {np.std(history.history['binary_accuracy'])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_nn = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_nn[predictions_nn > 0.5] = 1\npredictions_nn[predictions_nn <= 0.5] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_nn[predictions_nn == 1].size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_nn[predictions_nn == 0].size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_nn.flatten().astype('int64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2 Other models","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_validate\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_estimators(X, y, estimators, labels, cv):\n    ''' \n    A function for testing multiple estimators.\n    It takes: full train data and target, list of estimators, \n              list of labels or names of estimators,\n              cross validation splitting strategy;\n    And it returns: a DataFrame of table with results of tests\n    '''\n    result_table = pd.DataFrame()\n\n    row_index = 0\n    for est, label in zip(estimators, labels):\n\n        est_name = label\n        result_table.loc[row_index, 'Model Name'] = est_name\n\n        cv_results = cross_validate(est,\n                                    X,\n                                    y,\n                                    cv = cv,\n                                    n_jobs = -1)\n\n        result_table.loc[row_index, 'Test accuracy'] = cv_results['test_score'].mean()\n        result_table.loc[row_index, 'Test Std'] = cv_results['test_score'].std()\n        result_table.loc[row_index, 'Fit Time'] = cv_results['fit_time'].mean()\n\n        row_index += 1\n\n    result_table.sort_values(by=['Test accuracy'], ascending = False, inplace = True)\n\n    return result_table","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking a sample to save some time.","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, stratify = y_train_full, train_size = 0.1)\ny_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression()\ndt = DecisionTreeClassifier(random_state = 1)\nrf = RandomForestClassifier()\n# xgb = XGBClassifier()\nlgbm = LGBMClassifier()\ncb = CatBoostClassifier(allow_writing_files = False, logging_level = 'Silent')\n\nestimators = [lr,\n              dt,\n              rf,\n              lgbm, \n              cb]\n#               xgb]\n\nlabels = ['LogRegression',\n          'DecisionTree',\n          'RandomForest',\n          'LGBM',\n          'CatBoost']\n#           'XGB']\n\nresults = test_estimators(X_train, y_train, estimators, labels, cv = 10)\nresults.style.background_gradient(cmap = 'Purples')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb.fit(X_train_full, y_train_full)\nlgbm.fit(X_train_full, y_train_full)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_cb = cb.predict(X_test)\npredictions_lgbm = lgbm.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.3 Voting ensemble","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['PassengerId'] = X_test.index\nsubmission['pr_nn'] = predictions_nn.flatten().astype('int64')\nsubmission['pr_cb'] = predictions_cb\nsubmission['pr_lgbm'] = predictions_lgbm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[[col for col in submission.columns if col.startswith('pr_')]].sum(axis = 1).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Survived'] = (submission[[col for col in submission.columns if col.startswith('pr_')]].sum(axis=1) >= 2).astype(int)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[['PassengerId', 'Survived']].to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}