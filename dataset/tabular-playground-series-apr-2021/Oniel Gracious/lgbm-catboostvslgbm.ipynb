{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **TITANIC EDA and Model**  - Public Leader Board 0.79385","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n#import torch\n#from torch import nn, optim\nimport seaborn as sns\nfrom pathlib import Path\nimport PIL\nimport json\nimport gc\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read the data","metadata":{}},{"cell_type":"code","source":"# Read data\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')\nsample_sub  = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv') \ntrain.shape,test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numcols = train._get_numeric_data().columns\ncatcols = list(set(train.columns) - set(numcols))\ntarget = 'Survived'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train.columns:\n    print(col, \" Missing Data Count: \",train[col].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age, Ticket, Fare, Cabin and Embarked features missing data need to be imputed. ","metadata":{}},{"cell_type":"code","source":"train['Survived'].value_counts().plot(kind = 'barh',color=\"gray\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of data in both classes of the target variables seems reasonable.","metadata":{}},{"cell_type":"code","source":"data = pd.concat([train,test])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape,test.shape, data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imputing Missing Data","metadata":{}},{"cell_type":"markdown","source":"### Age","metadata":{}},{"cell_type":"code","source":"plt.hist(data['Age'], edgecolor = 'w',color=\"gray\", bins = 25)\nplt.title('Age'); \nplt.xlabel('Age (years)'); \nplt.ylabel('Count',);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean of the data in test ad train sets\ntest['Age'].mean(),train['Age'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The mean age in the test data is lower then the test data. Lets examine the corelation of the Age with Survival.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10, 8))\nsns.kdeplot(train.loc[train['Survived'] == 0, 'Age'] , label = 'Survived == 0',color=\"gray\",)\nsns.kdeplot(train.loc[train['Survived'] == 1, 'Age'] , label = 'Survived == 1',color=\"red\",)\nplt.xlabel('Age (years)'); plt.ylabel('Survived Density'); \nplt.title('Distribution of Ages');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It appears that the 20 to 40 age group has differnt densities of survivors.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets look at the age of passengers in differnt classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Age'] = data.groupby(['Pclass','Sex'])['Age'].apply(lambda x: x.fillna(x.median())).reset_index()['Age']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets first bin the ages\ndata.loc[ data['Age'] <= 11, 'Age_bin'] = 0\ndata.loc[(data['Age'] > 11) & (data['Age'] <= 18), 'Age_bin'] = 1\ndata.loc[(data['Age'] > 18) & (data['Age'] <= 22), 'Age_bin'] = 2\ndata.loc[(data['Age'] > 22) & (data['Age'] <= 27), 'Age_bin'] = 3\ndata.loc[(data['Age'] > 27) & (data['Age'] <= 33), 'Age_bin'] = 4\ndata.loc[(data['Age'] > 33) & (data['Age'] <= 40), 'Age_bin'] = 5\ndata.loc[(data['Age'] > 40) & (data['Age'] <= 66), 'Age_bin'] = 6\ndata.loc[ data['Age'] > 66, 'Age_bin'] = 6\n\n# let's see how it's distributed \ndata['Age_bin'].value_counts().plot(color=\"gray\",kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"RANK\"] = data.groupby(\"Age\")['Age'].rank(method=\"first\", ascending=True)\ndata[\"RANK_avg\"] = data.groupby(\"Age\")['Age'].rank(method=\"average\", ascending=True)\ndata[\"RANK_max\"] = data.groupby(\"Age\")['Age'].rank(method=\"max\", ascending=True)\ndata[\"RANK_min\"] = data.groupby(\"Age\")['Age'].rank(method=\"min\", ascending=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['AgeBin2']=pd.cut(data['Age'],[-np.inf, 50, np.inf], right=False, labels = ['below 50', 'above 50']).astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"#data.drop(['Age_Sex_ratio'], axis = 1,inplace=True)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10, 8))\nsns.countplot(x='Pclass',hue='Age_bin',data=data,\n              palette=sns.color_palette(\"icefire\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Sex.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It will be preffered to impute the missing age data by the median of their Classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ticket","metadata":{}},{"cell_type":"code","source":"imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\ndata['Ticket'] = imputer.fit_transform(data['Ticket'].values.reshape(-1,1))[:,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Referenced https://www.kaggle.com/dwin183287/tps-april-2021-models-feature-enginering\n    \ndata['TicketCode'] = data['Ticket'].str.replace('[^\\w\\s]','')\ndata['TicketCode'] = data['TicketCode'].str.replace(' ','')\ndata['TicketCode'] = data['TicketCode'].fillna('NA')\n\ndata['TicketNumber'] = data['Ticket'].str.extract('(\\d+)')\ndata['TicketNumber'] = data['TicketNumber'].astype(float)\ndata['TicketNumber'] = data['TicketNumber'].fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Embarked","metadata":{}},{"cell_type":"code","source":"data['Embarked'].value_counts().sort_values().plot(kind = 'barh',color=\"gray\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Embarked'].fillna(data['Embarked'].mode()[0], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cabin","metadata":{}},{"cell_type":"code","source":"# sns.countplot(x='Survived',hue='Cabin',data=data,\n#               palette=sns.color_palette(\"icefire\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\ndata['Cabin'] = imputer.fit_transform(data['Cabin'].values.reshape(-1,1))[:,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Class","metadata":{}},{"cell_type":"code","source":"data['Pclass'].value_counts().sort_values().plot(kind = 'barh',color=\"gray\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='Survived',hue='Pclass',data=data,\n              palette=sns.color_palette(\"icefire\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fare","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 8))\nsns.kdeplot(train.loc[train['Survived'] == 0, 'Fare'] , label = 'Survived == 0',color=\"gray\",)\nsns.kdeplot(train.loc[train['Survived'] == 1, 'Fare'] , label = 'Survived == 1',color=\"red\",)\nplt.xlabel('Fare'); plt.ylabel('Survived Density'); \nplt.title('Distribution of Fare');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(missing_values=np.NaN, strategy='median')\ndata['Fare'] = imputer.fit_transform(data['Fare'].values.reshape(-1,1))[:,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train.columns:\n    print(col, \" Missing Data Count: \",data[col].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"data['FamilySize'] = data['SibSp'] + data['Parch'] + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Fare'] = data['Fare'].round()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lblFare = ['Low_fare','median_fare','Average_fare','high_fare']\ndata['Fare_bin'] = pd.cut(data['Fare'], bins=4,labels=lblFare).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Age_Class']= data['Age'] * data['Pclass']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Fare_Per_Person'] = data['Fare']/(data['FamilySize'])\ndata['Fare_Per_Person'] = data['Fare_Per_Person'].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def strDeck(strcabin):\n    deck_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n    res = list(filter(lambda x:  x in strcabin, deck_list))\n    return str(res[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\ndata['Deck']=data['Cabin'].map(lambda x: strDeck(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = data.loc[~data.Survived.isnull()]\ntest = data.loc[data.Survived.isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pair Plots","metadata":{}},{"cell_type":"code","source":"# g = sns.pairplot(data=train, hue='Survived', palette = 'seismic',\n#                  size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\n# g.set(xticklabels=[])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Corelation","metadata":{}},{"cell_type":"code","source":"sns.heatmap(train.corr(),annot=True, vmin=0.3, vmax=0.7,linewidths=0.3) \nfig=plt.gcf()\nfig.set_size_inches(25,12)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode Categorical Variables","metadata":{}},{"cell_type":"code","source":"encoder=ce.TargetEncoder(cols=['Age_bin','Sex','Deck','Embarked']) \n#Fit and Transform Train Data\n#encoder.fit_transform(data['class'],data['Marks'])\ndata[['Age_bin','Sex','Deck','Embarked']] = encoder.fit_transform(data[['Age_bin','Sex','Deck','Embarked']],data[target])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = data.loc[~data.Survived.isnull()]\ntest = data.loc[data.Survived.isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LABEL ENCODE\ndef encode_LE(col,train,test):\n    df_comb = pd.concat([train[col],test[col]],axis=0)\n    df_comb,_ = df_comb.factorize(sort=True)\n    \n    train[col] = df_comb[:len(train)].astype('int16')\n    test[col] = df_comb[len(train):].astype('int16')\n    del df_comb; \n    gc.collect()\n    print(col,', ',end='')\n\n    \n# FREQ ENCODE\ndef encode_FE(df1, df2, cols):\n    for col in cols:\n        df = pd.concat([df1[col],df2[col]])\n        col_dict = df.value_counts(dropna=True, normalize=True).to_dict()\n        col_dict[-1] = -1\n        colname = col+'_FE'\n        df1[colname] = df1[col].map(col_dict)\n        df1[colname] = df1[colname].astype('float32')\n        \n        df2[colname] = df2[col].map(col_dict)\n        df2[colname] = df2[colname].astype('float32')\n        print(colname,', ',end='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encode_FE(train,test,['Cabin','Ticket'])\nencode_LE('Sex',train,test)\nencode_LE('Deck',train,test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import category_encoders as ce\nencoder= ce.OrdinalEncoder(cols=['AgeBin2'],return_df=True,\n                           mapping=[{'col':'AgeBin2','mapping':{'below 50':1,'above 50':2}}])\ntrain = encoder.fit_transform(train)\ntest = encoder.fit_transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ncoder = ce.sum_coding.SumEncoder(cols=[\"Sex\",\"Age_bin\",\"Embarked\",\"Fare_bin\"],verbose=False,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = ncoder.fit_transform(train)\ntest = ncoder.fit_transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = pd.get_dummies(train, columns = [\"Sex\",\"Age_bin\",\"Embarked\",\"Fare_bin\"],\n#                              prefix=[\"Sex\",\"Age_bin\",\"Em_type\",\"Fare_type\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test = pd.get_dummies(test, columns = [\"Sex\",\"Age_bin\",\"Embarked\",\"Fare_bin\"],\n#                              prefix=[\"Sex\",\"Age_bin\",\"Em_type\",\"Fare_type\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Extra features - Reference - https://www.kaggle.com/subinium/how-to-use-pycaret-with-feature-engineering\ndef converter(x):\n    c, n = '', ''\n    x = str(x).replace('.', '').replace('/','').replace(' ', '')\n    for i in x:\n        if i.isnumeric():\n            n += i\n        else :\n            c += i \n    if n != '':\n        return c, int(n)\n    return c, np.nan\n    \ndef create_extra_features(data):\n    data['Ticket_type'] = data['Ticket'].map(lambda x: converter(x)[0])\n    #data['Ticket_number'] = data['Ticket'].map(lambda x: converter(x)[1])\n    \n    data['Cabin_type'] = data['Cabin'].map(lambda x: converter(x)[0])\n    data['Cabin_number'] = data['Cabin'].map(lambda x: converter(x)[1])\n    data['Name1'] = data['Name'].map(lambda x: x.split(', ')[0])    \n    data['Name2'] = data['Name'].map(lambda x: x.split(', ')[1])\n    data['isAlone'] = data['FamilySize'].apply(lambda x : 1 if x == 1 else 0)\n    \n    return data\n\ntrain = create_extra_features(train)\ntest = create_extra_features(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from category_encoders.cat_boost import CatBoostEncoder\n\nce = CatBoostEncoder()\n\ncolumn_name = ['Ticket_type', 'Cabin_type', 'Name1', 'Name2','TicketCode']\ntrain[column_name] = ce.fit_transform(train[column_name], train['Survived'])\ntest[column_name] = ce.transform(test[column_name])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train['TicketCode'] = ce.fit_transform(train['TicketCode'], train['Survived'])\n# test['TicketCode'] = ce.transform(test['TicketCode'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelling","metadata":{}},{"cell_type":"code","source":"usecols = list(train.columns.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"usecols.remove('PassengerId')\nusecols.remove('Name')\nusecols.remove('Cabin')\nusecols.remove('Ticket')\nusecols.remove('Survived')\nusecols.remove('intercept')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#usecols.remove('intercept')\nusecols.remove('Age_bin_0')\nusecols.remove( 'Age_bin_1')\nusecols.remove( 'Age_bin_2')\nusecols.remove( 'Age_bin_3')\nusecols.remove('Age_bin_4')\nusecols.remove('Age_bin_5')\n# usecols.remove('RANK')\n# usecols.remove('RANK_avg')\n# usecols.remove('RANK_max')\n# usecols.remove('RANK_min')\nusecols.remove('TicketCode')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(usecols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.model_selection import KFold,StratifiedKFold\n# kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\n# model = lgb.LGBMClassifier(objective='binary',\n#                             metric='auc')\n\n# param_grid = {\n#               'boosting' : [\"gbdt\"],\n#               'n_estimators' : [300,500],\n#               'learning_rate': [0.1,0.01],\n#               'max_depth': [4, 8],\n#               'num_leaves': [100,150],\n#               'feature_fraction': [0.3, 0.1,0.6], \n#               'bagging_fraction' : [0.65,0.25],\n#                'min_child_samples': [20,150],\n#               'reg_alpha' : [0.1,0.5],\n#               'reg_lambda' : [0.25,0.40],\n#               }\n\n# modelf = GridSearchCV(model,param_grid = param_grid, cv=kfold, \n#                       scoring=\"accuracy\", n_jobs= 4, verbose = 2)\n\n# modelf.fit(train[usecols],train[target])\n\n# # Best score\n# modelf.best_score_\n\n# # Best Estimator\n# modelf.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {}\nparams[\"objective\"] = \"binary\"\nparams[\"boosting\"] = \"gbdt\"\nparams['metric']= \"AUC\",\n\nparams[\"max_depth\"] = 45\nparams[\"min_data_in_leaf\"] = 1\nparams[\"min_child_samples\"] = 100\nparams[\"colsample_bytree\"] = 0.18\nparams[\"subsample\"] = 0.013\n\nparams[\"cat_l2\"] =  22\nparams[\"max_bin\"] =  33\nparams[\"min_data_per_group\"] =  90\n\nparams[\"reg_alpha\"] =  0.003\nparams[\"reg_lambda\"] = 8.97\nparams[\"learning_rate\"] = 0.002\nparams[\"bagging_fraction\"] = 0.65\nparams[\"feature_fraction\"] = 0.65\nparams[\"num_leaves\"] = 20   #50\nparams[\"n_estimators\"] = 1000\n#params[\"cat_smooth\"] = 60\nparams[\"nthread\"] =  4\nparams[\"verbosity\"] = -1\nparams['early_stopping_rounds'] = 500\nnum_rounds = 1000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\ncv_scores = []\npred_test_full = 0\nooflgb = np.zeros(train.shape[0])\npredictionslgb= np.zeros(test.shape[0])\n\nfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\ni=1\n\nfor dev_index, val_index in fold.split(train[usecols],train[target]):    \n\n    dev_X, val_X = train[usecols].loc[dev_index,:], train[usecols].loc[val_index,:]\n    dev_y, val_y = train[target][dev_index], train[target][val_index]\n    \n    lgtrain = lgb.Dataset(dev_X, label=dev_y)\n    lgtest = lgb.Dataset(val_X, label=val_y)\n    model = lgb.train(params, lgtrain, num_rounds,\n                          valid_sets=[lgtest], early_stopping_rounds=300, verbose_eval=50)\n    \n    pred_val  = model.predict(val_X, num_iteration=model.best_iteration)\n    pred_test = model.predict(test[usecols], num_iteration=model.best_iteration)\n      \n    ooflgb[val_index] = pred_val\n    predictionslgb += pred_test\n    \npredictionslgb /= 5.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\ndef get_best_thresholds(true, preds):\n    thresholds = [i/100 for i in range(100)]\n    best_thresholds = []\n    \n    f1_scores = [f1_score(true, (preds > thresh) * 1, average='micro') for thresh in thresholds]\n    best_thresh = thresholds[np.argmax(f1_scores)]\n    best_thresholds.append(best_thresh)\n    return best_thresholds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#['Pclass','Embarked','Cabin','Ticket',]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Pclass = train.Pclass.astype('category')\ntrain.Cabin = train.Cabin.astype('category')\ntrain.Ticket = train.Ticket.astype('category')\n\ntest.Pclass = test.Pclass.astype('category')\ntest.Cabin = test.Cabin.astype('category')\ntest.Ticket = test.Ticket.astype('category')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= train[usecols + ['Cabin']]\ny= train[target]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(usecols),len(X.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\nfrom catboost import CatBoostClassifier\n\n\ncategorical_features_indices = np.where(X.dtypes =='category')[0]\ncategorical_features_indices\noofcat = np.zeros(X.shape[0])\n\nerrcb=[]\ny_pred_totcb=[]\ny_pred_totcb = 0 \n\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\ni=1\nfor train_index, test_index in fold.split(X,y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    m=CatBoostClassifier(n_estimators=50000,random_state=2021,\n                         eval_metric='Accuracy',max_depth=6,min_data_in_leaf=3,\n                         max_ctr_complexity=5,\n                         learning_rate=0.04,\n                         l2_leaf_reg=10,cat_features=categorical_features_indices,\n                         od_wait=500,od_type='Iter',\n                         bagging_temperature=0.80,random_strength=100,\n                         use_best_model=True)\n    \n    m.fit(X_train,y_train,eval_set=[(X_test, y_test)], early_stopping_rounds=100,verbose=100)\n    \n    oofcat[test_index] = m.predict_proba(X_test)[:,-1]\n    #preds=m.predict(X_test)[:,-1]\n\n    p = m.predict_proba(test[usecols + ['Cabin']])[:,-1]\n    \n    y_pred_totcb += p\n\ny_pred_totcb = y_pred_totcb/5 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = (ooflgb + oofcat)/2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\nbest_thresholds = get_best_thresholds(train[target].values, ooflgb)\noof[:] = (oof[:] > best_thresholds) * 1\nf1_score(train[target], oof, average='micro')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred = y_pred_totcb * 0.80 + predictionslgb * 0.20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred = (ypred[:] > best_thresholds) * 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub[target] = ypred\nsample_sub.to_csv('submission_blendcatandlgb1.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred1 = (predictionslgb[:] > 0.50) * 1\nsample_sub[target] = ypred1\nsample_sub.to_csv('submission.csv',index=False) # 0.79385","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Please upvote if you find this helpful...","metadata":{}}]}