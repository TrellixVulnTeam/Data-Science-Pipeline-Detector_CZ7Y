{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![Titanic](https://www.encyclopedia-titanica.org/ezoimgfmt/titanica.org/images/titanic-intro-header-1.jpg?ezimgfmt=ng%3Awebp%2Fngcb30%2Frs%3Adevice%2Frscb30-2)","metadata":{}},{"cell_type":"markdown","source":"# TPS APRIL 2021: The Titanic","metadata":{}},{"cell_type":"markdown","source":"This competition uses the Titanic dataset and tries to predict the survival of the passengers.<br/>\nIt is one of the most popular Machine Learning problems and there are numerous notebook analyzing the dataset.\n\nThis notebook is a quick implementation of some effective algorithms and techniques in Machine Learning.","metadata":{}},{"cell_type":"markdown","source":"### Importing the libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom datetime import datetime\nfrom sklearn.preprocessing import  MinMaxScaler, StandardScaler, LabelEncoder\nfrom sklearn.model_selection import  cross_val_score, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score\nimport optuna\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom warnings import simplefilter\nsimplefilter('ignore')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing the dataset","metadata":{}},{"cell_type":"code","source":"train= pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest= pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\nsub=pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-procesing","metadata":{}},{"cell_type":"markdown","source":"Let's see the percentage of missing values.","metadata":{}},{"cell_type":"code","source":"print(train.isna().sum()/len(train)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Fare will be filled with the mean as less than 1% is missing.\n* Cabin, Embarked and Ticket will be filled with inexpressive values as they are categorical values and impossible to guess.\n* Age is an important feature, we see how to fill its missing values.","metadata":{}},{"cell_type":"code","source":"# f=plt.figure(figsize=(18,12))\n# ax1=f.add_subplot(2,3,1)\n# sns.boxplot(train['Sex'],train['Age'])\n\n# ax2=f.add_subplot(2,3,2)\n# sns.boxplot(train['Pclass'],train['Age'])\n\n# ax3=f.add_subplot(2,3,3)\n# sns.boxplot(train['Embarked'],train['Age'])\n\n# ax4=f.add_subplot(2,2,3)\n# sns.heatmap(train.corr(),annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age is going to be filled according to Pclass as it is the most important correlated attribute and offers 3 classe with distinctive age average, as the plots show.\n","metadata":{}},{"cell_type":"code","source":"def manip(train,training=False ):  \n    age_filling = train[['Age', 'Sex']].dropna().groupby('Sex').mean().to_dict()\n    train['Age'] = train.Age.fillna(train['Sex'].map(age_filling['Age']))   \n    train['Cabin'] = train['Cabin'].fillna('N').map(lambda x: x[0].strip())\n    train['Ticket'] = train['Ticket'].fillna('N').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n    train['Fare'] = train['Fare'].fillna(train['Fare'].mean())\n    train['Embarked'] = train['Embarked'].fillna('N')\n    train['Name'] = train['Name'].apply(lambda x: str.split(x, ',')[0])\n    le=LabelEncoder()\n    train['Name']=le.fit_transform(train['Name'])\n    train['Ticket']=le.fit_transform(train['Ticket'])\n    train.drop(columns=['PassengerId'],inplace=True)\n        \n    if training== False:    \n        train=pd.get_dummies(train[['Sex','Age','Pclass','SibSp','Parch','Embarked','Fare',\n                                    'Name','Ticket','Cabin']]) \n    \n    else:\n        train=pd.get_dummies(train[['Sex','Age','Pclass','SibSp','Parch','Embarked','Fare',\n                                    'Name','Ticket','Cabin','Survived']])\n        \n    train.dropna(inplace=True)\n\n    return train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We prepare the data for the machine learning step, we split and scale data.","metadata":{}},{"cell_type":"code","source":"train=manip(train, training=True)\ntest=manip(test,training=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=train['Survived']\n\nX_train=train.drop(columns='Survived')[:80000]\nX_test= train.drop(columns='Survived')[80000:]\ny_train=y[:80000]\ny_test=y[80000:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"Defining objective for Optuna hyperparameter tuning.","metadata":{}},{"cell_type":"code","source":"def objective_rf(trial):\n    n_estimators= trial.suggest_int('n_estimators',10,500)\n    max_depth=trial.suggest_int('max_depth',10,30)\n    random_state=trial.suggest_int('random_state',42,123)\n    \n    rf= RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,random_state=random_state)\n    return cross_val_score(rf, X_train, y_train, n_jobs=-1, cv=5).mean()\n\n    \ndef objective_lgb(trial):\n    n_estimators= trial.suggest_int('n_estimators',10,2000)\n    max_depth=trial.suggest_int('max_depth',10,30)\n    random_state=trial.suggest_int('random_state',42,123)\n    learning_rate= trial.suggest_loguniform('learning_rate', 0.001,10)\n    num_leaves=trial.suggest_int('num_leaves',40,100)\n    \n    lgb= LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth,random_state=random_state,learning_rate=learning_rate)\n    return cross_val_score(lgb, X_train, y_train, n_jobs=-1, cv=5).mean()\n\n    \ndef objective_log(trial):\n    C= trial.suggest_loguniform('C',0.1,10)\n    l1_ratio=trial.suggest_loguniform('l1_ratio',0.1,2)\n    random_state=trial.suggest_int('random_state',42,123)\n\n    log= LogisticRegression(l1_ratio=l1_ratio, C=C,random_state=random_state)\n    return cross_val_score(log, X_train, y_train, n_jobs=-1, cv=5).mean()\n\n\ndef objective_cat(trial):\n    learning_rate= trial.suggest_loguniform('learning_rate',0.001,0.5)\n    iterations=trial.suggest_int('iterations',100,600)\n    depth=trial.suggest_int('depth',5,13)\n    \n    cat= CatBoostClassifier(learning_rate=learning_rate, iterations=iterations,depth=depth,\n                            loss_function='Logloss',eval_metric='AUC',bootstrap_type='Bayesian')\n    return cross_val_score(cat, X_train, y_train, n_jobs=-1, cv=3).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We do the trials according to the computation power of the algorithms.","metadata":{}},{"cell_type":"code","source":"study_rf = optuna.create_study(direction='maximize')\nstudy_rf.optimize(objective_rf, n_trials=6)\n\nstudy_log = optuna.create_study(direction='maximize')\nstudy_log.optimize(objective_log, n_trials=10)\n\nstudy_lgb = optuna.create_study(direction='maximize')\nstudy_lgb.optimize(objective_lgb, n_trials=10)\n\nstudy_cat = optuna.create_study(direction='maximize')\nstudy_cat.optimize(objective_cat, n_trials=6)","metadata":{"scrolled":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fetching the best parameters.","metadata":{}},{"cell_type":"code","source":"rf_params=study_rf.best_trial.params\nprint ('best rf param:',rf_params )\n\nlog_params=study_log.best_trial.params\nprint ('\\nbest log param:', log_params)\n\nlgb_params=study_lgb.best_trial.params\nprint ('\\nbest lgb param:', lgb_params)\n\ncat_params=study_cat.best_trial.params\nprint ('\\nbest cat param:',cat_params )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Training the models","metadata":{}},{"cell_type":"code","source":"log=LogisticRegression(**log_params)\nlog.fit(X_train,y_train)\n\nlgb= LGBMClassifier(**lgb_params)\nlgb.fit(X_train,y_train,early_stopping_rounds=200, verbose=0, eval_set=[(X_train,y_train),(X_test,y_test)] )\n\nrf = RandomForestClassifier(**rf_params)\nrf.fit(X_train,y_train)\n\ncat=CatBoostClassifier(**cat_params)\ncat.fit(X_train,y_train, silent=True)\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Printing the accuracy score","metadata":{}},{"cell_type":"markdown","source":"## Pseudo labeling and retraining with folds","metadata":{}},{"cell_type":"code","source":"train= pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\n\ntest_f= pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\n\ndata=pd.concat([train,test_f])\ntest_f=manip(test_f,training=False)\n\ndata=manip(data,training=True)\n\nX=data.drop(columns='Survived')[:80000]\ny=data['Survived'][:80000]\n\nX_test=data.drop(columns='Survived')[80000:]\ny_test=data['Survived'][80000:] \n\ntest=data.drop(columns='Survived')[:80000]\n\n\n\ny_all = pd.DataFrame() #where all predicted data of every step will be kept\nthresh = [] \nacc_thresh = []\nbest_cat_acc=0.75\n\nkfold = StratifiedKFold(n_splits=15, shuffle=True, random_state=420)\nfor i, (train_i, val_i) in enumerate(kfold.split(X, y)):\n    print(\"\\n FOLD\",i)\n    X_train = X.iloc[train_i]\n    y_train = y.iloc[train_i]\n    X_val = X.iloc[val_i]\n    y_val = y.iloc[val_i]\n\n    clf = CatBoostClassifier(**cat_params)\n    clf_fit = clf.fit(X_train,y_train,eval_set=[(X_train, y_train), (X_val, y_val)],silent=True)\n\n\n    if clf.score(X_test,y_test)>best_cat_acc:\n        best_cat_acc=clf.score(X_test,y_test)\n        best_cat=clf\n\n    y_proba = clf_fit.predict_proba(X_val)[:,1]\n    acc = accuracy_score(y_val, np.where(y_proba>0.5, 1, 0))            \n\n\n    threshs = np.arange(0, 1.0, 0.01)\n    acc_scores = []\n\n    for thresh in threshs:\n        acc_scores.append(accuracy_score(y_val, [1 if m>thresh else 0 for m in y_proba]))\n\n    accs = np.array(acc_scores)\n    max_acc = accs.max() \n    max_acc_threshold =  threshs[accs.argmax()] \n    thresh = thresh + [max_acc_threshold]\n\n    acc = accuracy_score(y_val,np.where(y_proba>max_acc_threshold,1,0)) \n    acc_thresh = acc_thresh + [acc]\n    print(\"Accuracy:\",acc)\n\n    ypred_fold = pd.DataFrame({'fold'+str(i): np.where(best_cat.predict_proba(test_f)[:,1]>threshs[accs.argmax()],1,0)})        \n    y_all = pd.concat([y_all, ypred_fold], axis=1)\n\nypred=np.where(y_all.sum(axis=1)/len(y_all.columns)>0.5,1,0)\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_f['Survived']=ypred\ntrain=manip(train,training=True)\ndata=pd.concat([train,test_f]).reset_index(drop=True)\n\ntest_f= pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\n\ntest_f=manip(test_f,training=False)\n\nX=data.drop(columns='Survived')[:150000]\ny=data['Survived'][:150000]\n\nX_test=data.drop(columns='Survived')[150000:]\ny_test=data['Survived'][150000:] \n\ntest=data.drop(columns='Survived')[:150000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_all = pd.DataFrame() #where all predicted data of every step will be kept\nthresh = [] \nacc_thresh = []\nbest_lgb_acc=0.75\n\nkfold = StratifiedKFold(n_splits=15, shuffle=True, random_state=420)\nfor i, (train_i, val_i) in enumerate(kfold.split(X, y)):\n    print(\"\\n FOLD\",i)\n    X_train = X.iloc[train_i]\n    y_train = y.iloc[train_i]\n    X_val = X.iloc[val_i]\n    y_val = y.iloc[val_i]\n\n    clf = LGBMClassifier(**lgb_params)\n    clf_fit = clf.fit(X_train,y_train,eval_set=[(X_train, y_train), (X_val, y_val)],verbose=0,early_stopping_rounds=200)\n\n\n    if clf.score(X_test,y_test)>best_lgb_acc:\n        best_lgb_acc=clf.score(X_test,y_test)\n        best_lgb=clf\n\n    y_proba = clf_fit.predict_proba(X_val)[:,1]\n    acc = accuracy_score(y_val, np.where(y_proba>0.5, 1, 0))            \n\n\n    threshs = np.arange(0.0, 1.0, 0.01)\n    acc_scores = []\n\n    for thresh in threshs:\n        acc_scores.append(accuracy_score(y_val, [1 if m>thresh else 0 for m in y_proba]))\n\n    accs = np.array(acc_scores)\n    max_acc = accs.max() \n    max_acc_threshold =  threshs[accs.argmax()] \n    thresh = thresh + [max_acc_threshold]\n\n    acc = accuracy_score(y_val,np.where(y_proba>max_acc_threshold,1,0)) \n    acc_thresh = acc_thresh + [acc]\n    print(\"Accuracy:\",acc)\n\n    ypred_fold = pd.DataFrame({'fold'+str(i): np.where(best_lgb.predict_proba(test_f)[:,1]>threshs[accs.argmax()],1,0)})        \n    y_all = pd.concat([y_all, ypred_fold], axis=1)\n\nypred=np.where(y_all.sum(axis=1)/len(y_all.columns)>0.5,1,0)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_f['Survived']=ypred\ndata=pd.concat([train,test_f]).reset_index(drop=True)\n\ntest_f= pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\n\ntest_f=manip(test_f,training=False)\n\nX=data.drop(columns='Survived')[:150000]\ny=data['Survived'][:150000]\n\nX_test=data.drop(columns='Survived')[150000:]\ny_test=data['Survived'][150000:] \n\ntest=data.drop(columns='Survived')[:150000]\n\n\n\ny_all = pd.DataFrame() #where all predicted data of every step will be kept\nthresh = [] \nacc_thresh = []\nbest_cat_acc=0.75\n\nkfold = StratifiedKFold(n_splits=30, shuffle=True, random_state=420)\nfor i, (train_i, val_i) in enumerate(kfold.split(X, y)):\n    print(\"\\n FOLD\",i)\n    X_train = X.iloc[train_i]\n    y_train = y.iloc[train_i]\n    X_val = X.iloc[val_i]\n    y_val = y.iloc[val_i]\n\n    clf = CatBoostClassifier(**cat_params)\n    clf_fit = clf.fit(X_train,y_train,eval_set=[(X_train, y_train), (X_val, y_val)],silent=True)\n\n\n    if clf.score(X_test,y_test)>best_cat_acc:\n        best_cat_acc=clf.score(X_test,y_test)\n        best_cat=clf\n\n    y_proba = clf_fit.predict_proba(X_val)[:,1]\n    acc = accuracy_score(y_val, np.where(y_proba>0.5, 1, 0))            \n\n\n    threshs = np.arange(0, 1.0, 0.01)\n    acc_scores = []\n\n    for thresh in threshs:\n        acc_scores.append(accuracy_score(y_val, [1 if m>thresh else 0 for m in y_proba]))\n\n    accs = np.array(acc_scores)\n    max_acc = accs.max() \n    max_acc_threshold =  threshs[accs.argmax()] \n    thresh = thresh + [max_acc_threshold]\n\n    acc = accuracy_score(y_val,np.where(y_proba>max_acc_threshold,1,0)) \n    acc_thresh = acc_thresh + [acc]\n    print(\"Accuracy:\",acc)\n\n    ypred_fold = pd.DataFrame({'fold'+str(i): np.where(best_cat.predict_proba(test_f)[:,1]>threshs[accs.argmax()],1,0)})        \n    y_all = pd.concat([y_all, ypred_fold], axis=1)\n\nypred=np.where(y_all.sum(axis=1)/len(y_all.columns)>0.5,1,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Voting\nvote=VotingClassifier([('random forest',rf),('LightGBM',lgb),('Catboost',cat),('LogisticRegression',log),\n                       ('Kfold Cat',best_cat),('Kfold LightGBM',best_lgb)],\n                      voting='hard',n_jobs=-1,weights=[2,3,2,1,3,5])\nvote.fit(X_train,y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using the previous models to build a vote model","metadata":{}},{"cell_type":"code","source":"print('Random Forest:',rf.score(X_test,y_test),\n    '\\nLogistic Regression:',log.score(X_test,y_test),\n    '\\nLightGBM:',lgb.score(X_test,y_test),\n    '\\nCatBoost:',cat.score(X_test,y_test),\n    '\\nVote:',vote.score(X_test, y_test),\n    '\\nKfold cat:',best_cat.score(X_test, y_test),\n    '\\nKfold LGBM:',best_lgb.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submitting predictions","metadata":{}},{"cell_type":"code","source":"#for submission\ntest= pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\ntest=manip(test,training=False)\n\nsub['Survived']=vote.predict(test)\nsub['Survived']=sub['Survived'].astype(int)\nsub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['Survived']=ypred\nsub['Survived']=sub['Survived'].astype(int)\nsub.to_csv('submission2.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}