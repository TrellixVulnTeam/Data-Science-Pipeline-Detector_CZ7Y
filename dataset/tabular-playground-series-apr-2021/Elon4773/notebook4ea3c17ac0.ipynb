{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport itertools\nimport gc,os,sys\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom mlxtend.classifier import StackingCVClassifier\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 300)\npd.set_option('display.max_colwidth', 30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_SEED = 2021\nPROBAS = True\nFOLDS = 5\nN_ESTIMATORS = 1000\n\nTARGET = 'Survived'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\nsubmission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')\n\npseudo_labels = pd.read_csv('../input/pseudo-label/pseudo_label.csv')\ntest_df[TARGET] = pseudo_labels[TARGET]\n\ntemp = pd.concat([train_df, test_df]).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp['Age'] = temp['Age'].fillna(temp['Age'].median())\n\ntemp[\"Age_bucket\"] = pd.cut(temp['Age'], 9,\n                            labels = [\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"70-79\", \"80-89\"])\n\ntemp['Embarked'] = temp['Embarked'].fillna('N')\n\ntemp['CabinNotAlloted'] = temp.Cabin.isna().astype(int)\n\ntemp['Cabin'] = temp.Cabin.str[:1]\ntemp['Cabin'].fillna('X')\n\ntemp['TicketType'] = temp.Ticket.fillna('XX')\ntemp['TicketType'] = temp.TicketType.map(lambda x: str(x).split()[0] if len(str(x).split()) > 1 else 'XX')\ntemp['TicketType'] = temp['TicketType'].str.lower()\n\nimport re\ntemp['TicketType'] = temp.TicketType.map(lambda x: re.sub(\"[^\\w\\s]+\",\"\",x))\n\ntemp['TT_bucket'] = temp.TicketType.map(lambda x:0 if x == 'pc' else 3 if x in ['stono', 'stono2', 'sotono2', 'stonoq', 'aq3', 'a', 'a5', 'sotonoq', 'fa', 'ca'] \\\n                                          else 2 if x in ['fcc', 'scow', 'caston', 'wc', 'c', 'wep', 'swpp', 'ppp', 'scah', 'soc', 'sopp'] else 1)\n\nFareByClass = pd.crosstab(index = temp.Pclass, columns = 'MedianFare', values = np.log(1+temp.Fare), aggfunc = 'median').to_dict()['MedianFare']\nFareByClass\n\ntemp['LnFare'] = np.log(1+temp['Fare'])\n\ntemp['LnFare'].fillna(temp.Pclass.map(FareByClass), inplace = True)\n\ntemp['FamilySize'] = temp['SibSp'] + temp['Parch'] + 1\n\ndef family_size(x):\n    if x == 1:\n        return \"alone\"\n    else:\n        return \"notalone\"\n    \ntemp['Group'] = temp['FamilySize'].apply(family_size)\nprint(temp['Group'].value_counts())    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_cols = ['Sex','CabinNotAlloted', 'TT_bucket', 'Cabin','Group']\nonehot_cols = ['Age_bucket','Embarked']\nnumerical_cols = ['LnFare','Age','Pclass']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encoder(c):\n    le = LabelEncoder()\n    return le.fit_transform(c.astype(str))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onehot_encoded_df = pd.get_dummies(temp[onehot_cols])\nlabel_encoded_df = temp[label_cols].apply(label_encoder)\nnumerical_df = pd.DataFrame(temp[numerical_cols], columns=numerical_cols)\ntarget_df = temp['Survived']\n\nall_df = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_parameters = {\n  'metric' : 'binary_logloss',\n  'n_estimators' : N_ESTIMATORS,\n  'objective' : 'binary',\n  'random_state' : RANDOM_SEED,\n  'learning_rate' : 0.01,  \n  'colsample_bytree': 0.6283725788215941,\n  'max_bin': int(round(15.826197551963968)),\n  'max_depth': int(round(39.32209311790955)),\n  'min_child_weight': 44.95339851660889,\n  'min_split_gain': 0.04358718365142237,\n  'num_leaves': int(round(24.715504910160405)),\n  'reg_alpha': 0.4127198530404361,\n  'reg_lambda': 0.0006949333245371281,\n  'subsample': 0.7192205961769677,\n  'subsample_freq': int(round(13.984681107001574))}\n\ncat_parameters =  {\n  'bootstrap_type' : 'Poisson',\n  'loss_function' : 'Logloss',\n  'eval_metric' : 'Logloss',\n  'random_seed' : RANDOM_SEED,\n  'task_type': 'GPU',\n  'learning_rate' : 0.01,\n  'n_estimators' : N_ESTIMATORS, \n  'bagging_temperature': 534.445170361156,\n  'border_count': int(round(230.32755580650806)),\n  'depth': int(round(5.969930611242375)),\n  'learning_rate': 0.01966964700090523,\n  'min_data_in_leaf': 2.208728103621775}\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl1 = CatBoostClassifier(**cat_parameters, verbose = None, logging_level = 'Silent')\ncl2 = LGBMClassifier(**lgbm_parameters)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlr = LogisticRegression()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scl = StackingCVClassifier(classifiers= [cl1, cl2], #[cl1, cl2, cl3, cl4, cl5, cl6, cl7, cl8]\n                            meta_classifier = mlr, # use meta-classifier\n                            use_probas = PROBAS,   # use_probas = True/False\n                            random_state = RANDOM_SEED)\n\nNUM_CLAS = 4 # classifiers (l1) + stacked (meta-classifier)\n\nclassifiers = {\"CatBoost\": cl1,\n               \"LGBM\": cl2,\n               \"Stacked\": scl}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = all_df.drop([TARGET], axis = 1)\ny = all_df[TARGET]\n\nprint (f'X:{X.shape} y: {y.shape} \\n')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = RANDOM_SEED)\nprint (f'X_train:{X_train.shape} y_train: {y_train.shape}')\nprint (f'X_test:{X_test.shape} y_test: {y_test.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = all_df[len(train_df):].drop([TARGET], axis = 1)\nprint (f'test:{test.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train classifiers","metadata":{}},{"cell_type":"code","source":"print(\">>>> Training started <<<<\")\nfor key in classifiers:\n    classifier = classifiers[key]\n    scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=FOLDS, scoring='accuracy')\n    print(\"[%s] = accuracy: %0.2f\" % (key, scores.mean()))\n    classifier.fit(X_train, y_train)\n    \n    classifiers[key] = classifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict and validate (AUC)","metadata":{}},{"cell_type":"code","source":"preds = pd.DataFrame()\n\nfor key in classifiers:\n    y_pred = classifiers[key].predict_proba(X_test)[:,1]\n    preds[f\"{key}\"] = y_pred\n    auc = metrics.roc_auc_score(y_test, y_pred)\n    print(f\"{key} --> AUC: {auc:.3f}\")\n    \npreds[TARGET] = pd.DataFrame(y_test).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = classifiers['Stacked'].predict_proba(test)[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = pd.Series(test_preds).sort_values(ascending = False).head(34911).values[-1]\nprint(f\"Current threshold is: {threshold}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['submit_1'] = (test_preds > threshold).astype(int)\nsubmission['submit_1'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['submit_2'] = pd.read_csv(\"../input/for-score/dae.csv\")[TARGET]\nsubmission['submit_3'] = pseudo_labels[TARGET]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis = 1).value_counts()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[TARGET] = (submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis=1) >= 2).astype(int)\nsubmission[TARGET].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[['PassengerId', TARGET]].to_csv(\"submission.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}