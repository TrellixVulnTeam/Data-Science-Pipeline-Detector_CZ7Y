{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Cleaning & Model\nData Set: Tabular Playground April 2021","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split # train set dividing\nfrom sklearn.inspection import permutation_importance # to see the feature weights in the model\nfrom sklearn.ensemble import RandomForestClassifier # Model\nfrom sklearn.preprocessing import StandardScaler # transforming data\nfrom sklearn.neural_network import MLPClassifier # Model\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import data set\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert non-numerycal data & null data","metadata":{}},{"cell_type":"code","source":"train.info() # To see nulls & data type","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations:\n* Sex can be boolean.\n* Embarked can be converted in range (1,4).\n* Age have almost 4000 null values.\n* Ticket have almost 5000 null values.\n* Cabin is the feature with the most null values.\n* Cabin, Name, Ticket and Embarked are non-numerycal values.\n\n### Implications:\n(Some of the following implications are been taken based in this [EDA](https://www.kaggle.com/betancourt/tabularplayground-april-eda))\n* Transform Cabin, Name and Ticket features.\n* Convert features Sex and Embarked with pd.map({}).\n* Since Pclass are correlated to Age feature, null values in Age will be filled with the average of its respective value in Pclass.\n* Since Pclass are correlated to Fare feature, null values in Fare will be filled with the average of its respective value in Pclass.\n* Delete the Name & Ticket Columns","metadata":{}},{"cell_type":"code","source":"# Convert in numerycal Sex and Embarked\n# Train Set\ntrain['Sex'] = train['Sex'].map({'male':1, 'female':0})\ntrain['Embarked'] = train['Embarked'].map({'S':1, 'C':2, 'Q':3})\n\n# Test Set\ntest['Sex'] = test['Sex'].map({'male':1, 'female':0})\ntest['Embarked'] = test['Embarked'].map({'S':1, 'C':2, 'Q':3})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill null values in Age feature\n# Train Set\nAge_mean_vs_class = train.groupby(['Pclass'], as_index = False)['Age'].mean()\nAge_mean_vs_class\n\ntrain_P1 = train[(train['Pclass'] == 1)]\ntrain_P1['Age'] = train_P1['Age'].fillna(Age_mean_vs_class.iloc[0][1])\n\ntrain_P2 = train[(train['Pclass'] == 2)]\ntrain_P2['Age'] = train_P2['Age'].fillna(Age_mean_vs_class.iloc[1][1])\n\ntrain_P3 = train[(train['Pclass'] == 3)]\ntrain_P3['Age'] = train_P3['Age'].fillna(Age_mean_vs_class.iloc[2][1])\n\ntrain = pd.concat([train_P1, train_P2, train_P3])\ntrain.isnull().any()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Set\nAge_mean_vs_class = test.groupby(['Pclass'], as_index = False)['Age'].mean()\nAge_mean_vs_class\n\ntest_P1 = test[(test['Pclass'] == 1)]\ntest_P1['Age'] = test_P1['Age'].fillna(Age_mean_vs_class.iloc[0][1])\n\ntest_P2 = test[(test['Pclass'] == 2)]\ntest_P2['Age'] = test_P2['Age'].fillna(Age_mean_vs_class.iloc[1][1])\n\ntest_P3 = test[(test['Pclass'] == 3)]\ntest_P3['Age'] = test_P3['Age'].fillna(Age_mean_vs_class.iloc[2][1])\n\ntest = pd.concat([test_P1, test_P2, test_P3])\ntest.isnull().any()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill null values in Cabin\n# Train Set\ntrain['Cabin'].fillna('N', inplace = True)\ntrain['Cabin'] = train['Cabin'].apply(lambda x: x[0])\ntrain['Cabin'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill null values in Cabin\n# Test Set\ntest['Cabin'].fillna('N', inplace = True)\ntest['Cabin'] = test['Cabin'].apply(lambda x: x[0])\ntest['Cabin'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a dictionary to replace the values\ndict_replace = {\n    'N':0,\n    'C':1,\n    'B':2,\n    'A':3,\n    'D':4,\n    'E':5,\n    'F':6,\n    'G':7,\n    'T':9\n}\n\n# Train Set\ntrain['Cabin'] = train['Cabin'].map(dict_replace)\n\n#train['Cabin'] = StandardScaler().fit_transform(train['Cabin'].values.reshape(-1, 1))\ntrain['Cabin'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Set\ntest['Cabin'] = test['Cabin'].map(dict_replace)\n\n#test['Cabin'] = StandardScaler().fit_transform(test['Cabin'].values.reshape(-1, 1))\ntest['Cabin'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, Embarked feature","metadata":{}},{"cell_type":"code","source":"# Fill null values in Embarked feature\n# Train Set\ntrain['Embarked'].fillna(0, inplace = True)\n# Transform the data to set it around zero\n#train['Embarked'] = StandardScaler().fit_transform(train['Embarked'].values.reshape(-1,1))\ntrain['Embarked'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Set\ntest['Embarked'].fillna(0, inplace = True)\n# Transform the data to set it around zero\n#test['Embarked'] = StandardScaler().fit_transform(test['Embarked'].values.reshape(-1,1))\ntest['Embarked'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will fill te NaN values in Fare feature with the mean value\n# Train Set\nFare_mean_vs_class = train.groupby(['Pclass'], as_index = False)['Fare'].mean()\n\ntrain_P1 = train[(train['Pclass'] == 1)]\ntrain_P1['Fare'] = train_P1['Fare'].fillna(Fare_mean_vs_class.iloc[0][1])\n\ntrain_P2 = train[(train['Pclass'] == 2)]\ntrain_P2['Fare'] = train_P2['Fare'].fillna(Fare_mean_vs_class.iloc[1][1])\n\ntrain_P3 = train[(train['Pclass'] == 3)]\ntrain_P3['Fare'] = train_P3['Fare'].fillna(Fare_mean_vs_class.iloc[2][1])\n\ntrain = pd.concat([train_P1, train_P2, train_P3])\ntrain.isnull().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Set\nFare_mean_vs_class = test.groupby(['Pclass'], as_index = False)['Fare'].mean()\n\ntest_P1 = test[(test['Pclass'] == 1)]\ntest_P1['Fare'] = test_P1['Fare'].fillna(Fare_mean_vs_class.iloc[0][1])\n\ntest_P2 = test[(test['Pclass'] == 2)]\ntest_P2['Fare'] = test_P2['Fare'].fillna(Fare_mean_vs_class.iloc[1][1])\n\ntest_P3 = test[(test['Pclass'] == 3)]\ntest_P3['Fare'] = test_P3['Fare'].fillna(Fare_mean_vs_class.iloc[2][1])\n\ntest = pd.concat([test_P1, test_P2, test_P3])\ntest.isnull().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the Name and Ticket columns\n# Train Set\ntrain = train.drop(['Ticket', 'Name'], axis = 1)\ntrain.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Set\ntest = test.drop(['Ticket', 'Name'], axis = 1)\ntest.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adding new features","metadata":{}},{"cell_type":"markdown","source":"The following lines (as well as much of this Notebook) are taken or based from this [Notebook](https://www.kaggle.com/marcogdepinto/feature-engineering-eda-data-cleaning-tutorial).","metadata":{}},{"cell_type":"code","source":"# Train Set\n\ndef process_family_train():\n    \n    # introducing a new feature : the size of families (including the passenger)\n    train['FamilySize'] = train['Parch'] + train['SibSp'] + 1\n    \n    # introducing other features based on the family size\n    train['Singleton'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    train['SmallFamily'] = train['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n    train['LargeFamily'] = train['FamilySize'].map(lambda s: 1 if 5 <= s else 0)\n    \n    return train\ntrain = process_family_train()\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_family_train():\n    \n    # introducing a new feature : the size of families (including the passenger)\n    test['FamilySize'] = test['Parch'] + test['SibSp'] + 1\n    \n    # introducing other features based on the family size\n    test['Singleton'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    test['SmallFamily'] = test['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n    test['LargeFamily'] = test['FamilySize'].map(lambda s: 1 if 5 <= s else 0)\n    \n    return test\ntest = process_family_train()\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Age*Class']=train['Age']*train['Pclass']\ntest['Age*Class']=test['Age']*test['Pclass']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Singleton*Pclass']=train['Singleton']*train['Pclass']\ntest['Singleton*Pclass']=test['Singleton']*test['Pclass']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['SmallFamily*Pclass']=train['SmallFamily']*train['Pclass']\ntest['SmallFamily*Pclass']=test['SmallFamily']*test['Pclass']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['MaleSingle'] = (train['Singleton'] == 1) & (train['Sex'] == 1)\ntest['MaleSingle'] = (test['Singleton'] == 1) & (test['Sex'] == 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Sex*Pclass'] = train['Sex']*train['Pclass']\ntest['Sex*Pclass'] = test['Sex']*test['Pclass']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Sex*Singleton'] = train['Sex']*train['Singleton']\ntest['Sex*Singleton'] = test['Sex']*test['Singleton']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model & Submission","metadata":{}},{"cell_type":"code","source":"# Make the train & test sets\nX = train.drop(['Survived', 'PassengerId'], axis =1)\nY = train['Survived']\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(X_train.values.reshape(-1,1))\nscaler.fit(X_test.values.reshape(-1,1))\n\nscaler.fit(test.values.reshape(-1,1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"# Choose the RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators = 100, random_state=5)\nmodel.fit(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.score(X_test, Y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MLP Classifier","metadata":{}},{"cell_type":"code","source":"model_b = MLPClassifier(max_iter=1000, hidden_layer_sizes=(100, 55), alpha=0.0001, solver='adam', random_state=1)\nmodel_b.fit(X, Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_b.score(X_test, Y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make submission\n\npredicts = model_b.predict(test.drop(['PassengerId'], axis = 1))\n\nmy_submission = pd.DataFrame({'PassengerId': test['PassengerId'].values, 'Survived': predicts})\nmy_submission.to_csv('submissionv.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}