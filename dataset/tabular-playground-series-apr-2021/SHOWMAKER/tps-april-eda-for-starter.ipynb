{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Table of Contents\n**1. Dataset Check**\n**2. EDA**\n**3. Pclass (include sequence and category)**\n**4. Sex**\n**5. Both Sex and Pclass**\n**6. Age**\n**7. Pclass, Sex, Age**\n**8. Embarked**\n**9. Family - SibSp + Parch**\n**10. Fare**\n**11. Cabin**\n**12. Ticket**"},{"metadata":{},"cell_type":"markdown","source":"## Import Data "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn')\nsns.set(font_scale=2.5)  #it is that i am gona use font_size 2.5 \n\nimport missingno as msno  #show the nerd data in the dataframe \n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Dataset Check"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check Null data\n1)Check train data first "},{"metadata":{"trusted":true},"cell_type":"code","source":"#First we chect train and test files null data -> Null data have to be fill in!!!\nfor col in df_train.columns:\n    wsg = 'column: {:>10}₩t Percent of NaN value: {:.2f}%'.format(col, 100*(df_train[col].isnull().sum()/df_train[col].shape[0]))\n    print(wsg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can check that **'Age'**, **'Ticket'**, **'Fare'**, **'Cabin'**, **'Embarked**' have the null data"},{"metadata":{},"cell_type":"markdown","source":"Next check out the test data "},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df_test.columns:\n    wsg = 'column: {:>10}₩t Percent of NaN value: {:.2f}%'.format(col, 100*(df_test[col].isnull().sum()/df_test[col].shape[0]))\n    print(wsg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can check that **'Age'**, **'Ticket'**, **'Fare'**, **'Cabin'**, **'Embarked**' have the null data.\n* Both test and train data have the same columns null data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can check there is 250 null data in the train data \ndf_train[col].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To find the percentage of the null data   divide it with the total dataframe\ndf_train[col].isnull().sum() / df_train[col].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#.iloc[] = index location. it brings the index that we need (distribution)\n#the blank below the graph is the null\nmsno.matrix(df=df_train.iloc[:, :],figsize=(8,8),color=(0.8,0.5,0.2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Other way to find null data - using bar (percentage)\nmsno.bar(df=df_train.iloc[:, :],figsize=(8,8),color=(0.8,0.5,0.2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Conclusion:\nWe found out that there is the null data in our data.Next Step we will gona find out the target label. We have to find out what kind of distribution they have, which we are targeting.\n\nThe method of evaluating the model depends on how valancefully the target label has or does not have a balance. Also, the way to make a model changes.So we have to check what kind of distribution we have.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize=(18,8))  \n\n#explode = make a distance between the picture\n#autopct = make a percentage \n#  ax[0], ax[1] = So which part you gona put in between 0 and 1\n\ndf_train['Survived'].value_counts().plot.pie(explode=[0,0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\nax[0].set_title('Pie plot - Survived')\nax[0].set_ylabel('') #ylabel = blank\nsns.countplot('Survived', data=df_train, ax=ax[1])  #Count the Survived in the file df_train\nax[1].set_title('Count plot - Survived')\nplt.show()\n\n#The result show that this data is balanced ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_train['Survived'].value_counts() = Series, every series have a plot\ndf_train['Survived'].value_counts().plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. EDA\nIt's about finding correlations between features. By doing this, we can gain a strong insight into which feature should be used. We need to create the ability to interpret pictures"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can find out that there is a 12 features. \ndf_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Pclass (include sequence and category)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[['Pclass','Survived']].groupby(['Pclass'], as_index=True).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[['Pclass','Survived']].groupby(['Pclass']).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df_train['Pclass'],df_train['Survived'], margins=True).style.background_gradient(cmap='cool')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#What's the survival rate for each class?\n#We have to as_index=False not as_index=True. Because if we make a plot we can only get one graph if we use =True\n\ndf_train[['Pclass','Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_position = 1.02\nf, ax = plt.subplots(1,2,figsize=(18,8))\ndf_train['Pclass'].value_counts().plot.bar(color=['#CD7F32', '#FFDF00', '#D3D3D3'], ax=ax[0])\nax[0].set_title('Number of passengers By Pclass', y=y_position)\nax[0].set_ylabel('Count')\nsns.countplot('Pclass', hue='Survived', data = df_train, ax=ax[1])\nax[1].set_title('Pclass:Survived vs Dead', y = y_position)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion:\nThe higher the class, the higher the probability of survival.\n\nTherefore, if you use 'class data' to make a model through this, it will have a better input."},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Sex"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize=(18,8))\ndf_train[['Sex','Survived']].groupby(['Sex'],as_index=True).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex', hue= 'Survived', data = df_train, ax=ax[1])\nax[1].set_title('Sex: Survived vs Dead')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df_train['Sex'], df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion:\nLike Pclass, Sex is an important feature for predictive models."},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Both Sex and Pclass\n* Now, let's see how survival changes with respect to two things: Sex and Pclass.\n* With Seaborn's factorplot, you can easily draw a graph of three dimensions."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot('Pclass', 'Survived', hue='Sex', data=df_train, size=6, aspect=1.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* You can see that female is more likely to live in all classes than male.\n* Also, the higher the class regardless of male or female, the higher the probability of living.\n* The graph above is column instead of hue, which makes it look like below."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Other way to show in different plot\nsns.factorplot(x='Sex', y='Survived', col='Pclass',data=df_train, satureation=.5,size=9, aspect=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4 Age "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('oldest passenger : {:.1f} Years'.format(df_train['Age'].max()))\nprint('youngest passenger : {:.1f} Years'.format(df_train['Age'].min()))\nprint('passenger average age : {:.1f} Years'.format(df_train['Age'].mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let me draw a histogram of the Age of Survival.\nfig, ax = plt.subplots(1,1,figsize=(9,5))\nsns.kdeplot(df_train[df_train['Survived']==1]['Age'],ax=ax)\nsns.kdeplot(df_train[df_train['Survived']==0]['Age'],ax=ax)\nplt.legend(['Survived == 1', 'Survived == 0'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting! Different with the titanic! The age 40-60 got the highest survival rate!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Age distribution withing classes, by using hist plot we can see easily \nplt.figure(figsize=(18,16))\ndf_train['Age'][df_train['Pclass']==1].plot(kind='hist')\ndf_train['Age'][df_train['Pclass']==2].plot(kind='hist')\ndf_train['Age'][df_train['Pclass']==3].plot(kind='hist')\n\nplt.xlabel('Age')\nplt.title('Age Distribution within classes')\nplt.legend(['1st Class', '2nd Class', '3rd Class'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The higher the class, the greater the proportion of older people\n* I'm going to see what the survival rate is as the age changes.\n* As we expand our age range, let's see what the survival rate is."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(9,5))\nsns.kdeplot(df_train[(df_train['Survived']==0)&(df_train['Pclass']==1)]['Age'],ax=ax)\nsns.kdeplot(df_train[(df_train['Survived']==1)&(df_train['Pclass']==1)]['Age'],ax=ax)\nplt.legend(['Survived == 0', 'Survived == 1'])\nplt.title('1st Class')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(9,5))\nsns.kdeplot(df_train[(df_train['Survived']==0)&(df_train['Pclass']==2)]['Age'],ax=ax)\nsns.kdeplot(df_train[(df_train['Survived']==1)&(df_train['Pclass']==2)]['Age'],ax=ax)\nplt.legend(['Survived == 0', 'Survived == 1'])\nplt.title('2st Class')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(9,5))\nsns.kdeplot(df_train[(df_train['Survived']==0)&(df_train['Pclass']==3)]['Age'],ax=ax)\nsns.kdeplot(df_train[(df_train['Survived']==1)&(df_train['Pclass']==3)]['Age'],ax=ax)\nplt.legend(['Survived == 0', 'Survived == 1'])\nplt.title('3rd Class')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only the **1st Class** age distribution between 40-60 got higher survival rate contrast with 2nd and 3rd class.\n\nLet's check out the **survival rate** also!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"cummulate_survival_ratio = []\n#Survival of age by showing the trend.\n\nfor i in range(1, 80):\n    cummulate_survival_ratio.append(df_train[df_train['Age'] < i]['Survived'].sum() / len(df_train[df_train['Age'] < i]['Survived']))\n\nplt.figure(figsize=(7, 7))\nplt.plot(cummulate_survival_ratio)\nplt.title('Survival rate change depending on range of Age', y=1.02)\nplt.ylabel('Survival rate')\nplt.xlabel('Range of Age(0~x)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As you can see, the younger you are,and as the age get older the higher your survival rate is.\n* We confirmed that this age can be used as an important feature."},{"metadata":{},"cell_type":"markdown","source":"### 2.5 Pclass,Sex,Age\n* I'd like to see all of the Sex, Pclass, Age, Survived. The easy way to draw this is seaborn's violinplot.\n* The x-axis represents the case that we want to see separately, and the y-axis represents the distribution (Age) that we want to see.\n* I'll draw it."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize=(18,8))\nsns.violinplot('Pclass','Age', hue='Survived', data=df_train, scale='count', split=True, ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0,110,10))\n\nsns.violinplot('Sex','Age', hue='Survived', data=df_train, scale='count',split=True, ax=ax[1])\nax[1].set_title('sex and Age vs Survived')\nax[1].set_yticks(range(0,110,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The figure on the left is a graph of how the distribution of Age varies by Pclass, and whether it survives or not.\n* The figure on the right is the same, a graph that shows how the distribution of survival differs.\n* We can't find out the correlation between Age and survival rate. It is different with the titanic's dataset \n* In the picture on the right, you can clearly see that women have survived a lot.\n* You can see that they took care of women and children first."},{"metadata":{},"cell_type":"markdown","source":"### 2.6 Embarked \n* Embarked represents the port on board.\n* Similar to what we've done above, we'll look at the survival rate according to where we're on board."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=True).mean().sort_values(by='Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,1,figsize=(7,7))\ndf_train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As you can see, there is a difference, the survival rate is a bit different. But C is the highest. C is twice much survival rate than S\n* I don't know how much impact it will have on the model, but I'll still use it.\n* In fact, once we've created a model, we can see how important the features we've used have played. We will look at this later after we make the model.\n* Let's split into different features and take a look."},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(2, 2, figsize=(20,15))\n\nsns.countplot('Embarked', data=df_train, ax=ax[0,0])\nax[0,0].set_title('(1) No. Of Passengers Boarded')\n\nsns.countplot('Embarked', hue='Sex', data=df_train, ax=ax[0,1])\nax[0,1].set_title('(2) Male-Female Split for Embarked')\n\nsns.countplot('Embarked', hue='Survived', data=df_train, ax=ax[1,0])\nax[1,0].set_title('(3) Embarked vs Survived')\n\nsns.countplot('Embarked', hue='Pclass', data=df_train, ax=ax[1,1])\nax[1,1].set_title('(4) Embarked vs Pclass')\n\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Figure (1) - Overall, S has the largest number of people on board.\n* Figure (2) - C and Q have more proportions of women, and S has more men.\n* Figure (3) - If the survival probability is S, you can see that it is very low. (I saw it on the previous graph.). But in the C, you can see that the survival rate is very high(I think because there is more women proportions rate)\n* Figure (4) - According to the class split, the reason why C has a high probability of survival is because many people in the 1st class ride it. S has a low probability of survival because there are many 3rd classes."},{"metadata":{},"cell_type":"markdown","source":"### 2.7 Family -SibSp + Parch\nIf you combine SibSp and Parch, it will be Family. Let's combine them into Family."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can combine data because it is combined with number \ndf_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 #we have to add 1 because we have include oneself\ndf_test['FamilySize'] = df_test['SibSp'] + df_train['Parch'] + 1 #we have to add 1 because we have include oneself","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Maximum size of Family:', df_train['FamilySize'].max())\nprint('Minimum size of Family:', df_train['FamilySize'].min())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at the relationship between Family Size and survival."},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(1, 3, figsize=(40,10))\nsns.countplot('FamilySize', data=df_train, ax=ax[0])\nax[0].set_title('(1) No. Of Passengers Boarded', y=1.02)\n\nsns.countplot('FamilySize', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('(2) Survived countplot depending on FamilySize',  y=1.02)\n\ndf_train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax[2])\nax[2].set_title('(3) Survived rate depending on FamilySize',  y=1.02)\n\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Figure (1) - You can see that the family size is from 1 to 18. It's mostly one person, followed by two, three, and four people.\n* Figure (2), (3) - Only the family size2 survived more. We can think there is less correlation between family size and the survival rate. The probability of survival is random without any relationship."},{"metadata":{},"cell_type":"markdown","source":"### 2.8 Fare\nFare is a boarding fee and a constant feature. I'll draw a histogram."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(8,8))\ng = sns.distplot(df_train['Fare'], color='b',label='skewness : {:.2f}'.format(df_train['Fare'].skew(), ax=ax))\ng = g.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As you can see, the distribution is very asymmetrical (high sense). If you put it in the model like this, the model may learn it wrong. If you are too sensitive to a few outlier, you can have bad results in real predictions.\n* To reduce the impact of outlier, we will log on Fare.\n* Here we will use the useful function of Pandas. If you want to apply a common action (function) to a particular column of dataFrame, you can apply it very easily by using the map, or apply below.\n* What we want now is to log all the data in the Fare columns, and if you put a function that applies a simple log into the map using Python's simple lambda function, it's applied to the Fare columns data as an argument. It's a very useful feature, so make sure you understand it!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace the nanvalue in the testset with the average value.\ndf_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean() \n\ndf_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\ndf_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.9 Cabin\n* This feature has a so much **null data**, so it is not easy to obtain important information that will affect survival.\n* Therefore, we will not include it in the model we are trying to build."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.10 Ticket\n* This feature also has too many a **null-data**, so it is not easy to obtain important information that will affect survival.\n* Therefore, we will not include it in the model we are trying to build."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ticket'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As you can see, ticket numbers vary widely. What characteristics can we draw from this and link it to survival?\n* You should come up with your own ideas! This is the starting point for a full-fledged Caglace. ^^\n* This is a tutorial, so I'll skip the ticket first. After finishing the tutorial, it's good to get information out of the ticket to improve the performance of your model!"},{"metadata":{},"cell_type":"markdown","source":"# The End!!\n\n## If this notebook helped you in any way or you liked it, please upvote and/or leave a comment!! :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}