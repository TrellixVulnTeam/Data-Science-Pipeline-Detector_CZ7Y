{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\ntrain = pd.read_csv(\"../input/tabular-playground-series-apr-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-apr-2021/test.csv\")\nsample = pd.read_csv(\"../input/tabular-playground-series-apr-2021/sample_submission.csv\")\nprint(train.shape, test.shape)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MissingValue","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.style.use(\"seaborn-white\")\nimport seaborn as sns\n\ndummy = train.isnull().sum() / train.shape[0]\nsns.barplot(x = dummy.index, y = dummy.values)\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy = test.isnull().sum() / test.shape[0]\nsns.barplot(x = dummy.index, y = dummy.values)\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(train, test):\n    dummy = train[\"Age\"].median()\n    train[\"Age\"].fillna(dummy, inplace = True)\n    test[\"Age\"].fillna(dummy, inplace = True)\n    \n    dummy = train[\"Fare\"].median()\n    train[\"Fare\"].fillna(dummy, inplace = True)\n    test[\"Fare\"].fillna(dummy, inplace = True)\n    \n    dummy = train[\"Embarked\"].mode()[0]\n    train[\"Embarked\"].fillna(dummy, inplace = True)\n    test[\"Embarked\"].fillna(dummy, inplace = True)\n    return train, test\n\ntrain, test = preprocess(train, test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Name","metadata":{}},{"cell_type":"code","source":"train[\"Name\"].values[:100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom wordcloud import WordCloud\n\ndef name_cloud(df):\n    word_text = []\n    for i in range(df.shape[0]):\n        word_text.append(re.sub(\",\", \"\", df[\"Name\"].values[i]))\n    word_text = \" \".join(word_text)\n    wordcloud = WordCloud(width = 800, height = 800, collocations = False).generate(word_text)\n    plt.figure(figsize = (8, 8))\n    plt.imshow(wordcloud)\n    plt.show()\nname_cloud(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name_cloud(train.loc[train[\"Survived\"] == 0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name_cloud(train.loc[train[\"Survived\"] == 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"first\"] = train[\"Name\"].apply(lambda x: x.split(\", \")[0])\ntrain[\"family\"] = train[\"Name\"].apply(lambda x: x.split(\", \")[1])\ntest[\"first\"] = test[\"Name\"].apply(lambda x: x.split(\", \")[0])\ntest[\"family\"] = test[\"Name\"].apply(lambda x: x.split(\", \")[1])\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ticket","metadata":{}},{"cell_type":"code","source":"def clean(text):\n    text = text.upper()\n    text = re.sub(\" \", \"\", text)\n    text = re.sub(r\"\\.\", \"\", text)\n    text = re.sub(r\"\\/\", \"\", text)\n    text = re.sub(r\"\\\\\", \"\", text)\n    return text\n\ntrain[\"Ticket\"] = train[\"Ticket\"].astype(str)\ntest[\"Ticket\"] = test[\"Ticket\"].astype(str)\ntrain[\"cleaned_ticket\"] = train[\"Ticket\"].apply(clean)\ntest[\"cleaned_ticket\"] = test[\"Ticket\"].apply(clean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"nan_ticket\"] = (train[\"cleaned_ticket\"] == \"NAN\").astype(int)\ntest[\"nan_ticket\"] = (test[\"cleaned_ticket\"] == \"NAN\").astype(int)\ntrain[\"ticket_feat\"] = train[\"cleaned_ticket\"].apply(lambda x: re.sub(\"[0-9]*\", \"\", x))\ntest[\"ticket_feat\"] = test[\"cleaned_ticket\"].apply(lambda x: re.sub(\"[0-9]*\", \"\", x))\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ticket_cloud(df):\n    word_text = []\n    for i in range(df.shape[0]):\n        text = re.sub(\"[0-9]*\", \"\", df[\"cleaned_ticket\"].values[i])\n        if text != \"\":\n            word_text.append(text)\n    word_text = \" \".join(word_text)\n    wordcloud = WordCloud(width = 800, height = 800, collocations = False).generate(word_text)\n    plt.figure(figsize = (8, 8), facecolor = None)\n    plt.imshow(wordcloud)\n    plt.show()\n    \nticket_cloud(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticket_cloud(train.loc[train[\"Survived\"] == 0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticket_cloud(train.loc[train[\"Survived\"] == 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cabin","metadata":{}},{"cell_type":"code","source":"train[\"Cabin\"].fillna(\"NAN\", inplace = True)\ntest[\"Cabin\"].fillna(\"NAN\", inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_cabin_feat(cabin):\n    if cabin == \"NAN\":\n        return \"N\"\n    else:\n        return cabin[0]\ntrain[\"cabin_feat\"] = train[\"Cabin\"].apply(create_cabin_feat)\ntest[\"cabin_feat\"] = test[\"Cabin\"].apply(create_cabin_feat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train[\"cabin_feat\"].unique())\nprint(test[\"cabin_feat\"].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = train[\"cabin_feat\"], hue = train[\"Survived\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PreProcess","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(n_splits = 5)\nfold_dict = {}\nfor fold, (train_idx, valid_idx) in enumerate(kfold.split(train, train[\"Survived\"])):\n    fold_dict[fold] = (train_idx, valid_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlbl = LabelEncoder()\nfor col in [\"Sex\", \"Embarked\", \"ticket_feat\", \"cabin_feat\"]:\n    lbl.fit(pd.concat([train, test])[col])\n    train[col] = lbl.transform(train[col])\n    test[col] = lbl.transform(test[col])\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in [\"first\", \"family\"]:\n    tmp = train[col].value_counts().to_dict()\n    train[col] = train[col].map(tmp)\n    test[col] = test[col].map(tmp).fillna(0)\n    \ntrain[\"family_size\"] = train[\"SibSp\"] + train[\"Parch\"]\ntest[\"family_size\"] = test[\"SibSp\"] + test[\"Parch\"]\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"use_cols = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"first\", \"family\", \"nan_ticket\", \"ticket_feat\", \"cabin_feat\", \"family_size\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nparams = {\n    \"objective\" : \"binary\",\n    \"metric\" : \"auc\",\n    \"verbosity\" : -1,\n    'num_leaves': 76,\n    'lambda_l1': 0.00018,\n    'lambda_l2': 0.0010,\n    'feature_fraction': 0.65,\n    'bagging_fraction': 0.56,\n    'min_child_samples': 29\n}\n\ndef training(params):\n    OOF = np.zeros(train.shape[0])\n    models = []\n    for fold in range(5):\n        train_idx = fold_dict[fold][0]\n        valid_idx = fold_dict[fold][1]\n        X_train = train.loc[train_idx, use_cols]\n        X_valid = train.loc[valid_idx, use_cols]\n        y_train = train.loc[train_idx, \"Survived\"]\n        y_valid = train.loc[valid_idx, \"Survived\"]\n        train_set = lgb.Dataset(X_train, y_train)\n        valid_set = lgb.Dataset(X_valid, y_valid)\n        model = lgb.train(\n            params = params, train_set = train_set, valid_sets = [train_set, valid_set],\n            num_boost_round = 100, early_stopping_rounds = 10, verbose_eval = 20\n        )\n        OOF[valid_idx] = model.predict(X_valid)\n        models.append(model)\n    return OOF, models\nOOF, models = training(params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nacc = accuracy_score(y_true = train[\"Survived\"], y_pred = np.where(OOF > 0.5, 1, 0))\nprint(acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\n\ndef objective(trial):\n    tune_params = {\n        \"objectve\" : \"binary\",\n        \"metric\" : \"auc\",\n        \"verbosity\" : -1,\n        \"num_leaves\" : trial.suggest_int(\"num_leaves\", 2, 256),\n        \"lambda_l1\" : trial.suggest_loguniform(\"lambda_l1\", 1e-6, 1),\n        \"lambda_l2\" : trial.suggest_loguniform(\"lambda_l2\", 1e-6, 1),\n        \"feature_fraction\" : trial.suggest_uniform(\"feature_fraction\", 0.5, 1.0),\n        \"bagging_fraction\" : trial.suggest_uniform(\"bagging_fraction\", 0.5, 1.0),\n        \"min_child_samples\" : trial.suggest_int(\"min_child_samples\", 5, 100)\n    }\n    OOF, _ = training(tune_params)\n    acc = accuracy_score(y_true = train[\"Survived\"], y_pred = np.where(OOF > 0.5, 1, 0))\n    return acc\n\nTUNING = False\nif TUNING:\n    study = optuna.create_study(direction = \"maximize\")\n    study.optimize(objective, n_trials = 10)\n    print(\"=\" * 100)\n    print(study.best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"preds = []\nfor model in models:\n    preds.append(model.predict(test[use_cols]))\npreds = np.mean(preds, axis = 0)\ntest[\"Survived\"] = np.where(preds > 0.5, 1, 0)\ntest[[\"PassengerId\", \"Survived\"]].to_csv(\"submission.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nshap.initjs()\nexplainer = shap.TreeExplainer(model = models[0])\nshap_values = explainer.shap_values(X = train[use_cols])\nshap.summary_plot(shap_values, train[use_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}