{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:160%; text-align:center\">Tabular Playground Series April</p>\n1. [Exploratory Data Analysis üìä](https://www.kaggle.com/zhaodianwen/tps-april-1-eda/)","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis üßê","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##loading data\ntrain = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### To compare train&test data at first glance:","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Join train and test datasets in order to obtain the same number of features during categorical conversion\ntrain_indexs = train.index\ntest_indexs = test.index\n\ndf = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\ndf = df.drop('PassengerId', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### To get the information of train&test data:","metadata":{}},{"cell_type":"code","source":"def simple_eda(df):\n    \n    \"\"\"\n    This function helps us with simple data analysis.\n    We may explore the common information about the dataset, missing values, features distribution and duplicated rows\n    \"\"\"\n    \n    # applying info() method\n    print('---')\n    print('Common Information')\n    print('---')\n    print(df.info())\n    \n    # missing values\n    print('---')\n    if df.isna().sum().sum() == 0:\n        print('There are no missing values')\n    else:\n        print('Detected')\n        display(df.isna().sum())\n    \n    \n    # applying describe() method for categorical features\n    print('---')\n    print('Categorical Columns')\n    print('Total {}'.format(len(df.select_dtypes(include='object').columns)))\n    print('---')\n    display(df.describe(include = 'object'))\n    \n    # same describe() but for continious features\n    print('---')\n    print('Continuous Columns')\n    print('Total {}'.format(len(df.select_dtypes(include=['int', 'float']).columns)))\n    print('---')\n    display(df.describe())\n    \n    #checking for duplicated rows\n    if df.duplicated().sum() == 0:\n        print('---')\n        print('There are no duplicates')\n        print('---')\n    else:\n        print('---')\n        print('Duplicates found')\n        print('---')\n        display(df[df.duplicated()])\n    \n    print('End of the report')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simple_eda(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### To have a look at the distribution of the target:","metadata":{}},{"cell_type":"code","source":"df['Survived'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(16, 6))\nsns.distplot(train['Survived'], ax=ax[0])\nsns.countplot(train['Survived'], ax=ax[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### To have a look at numerical and categorical data separately:","metadata":{}},{"cell_type":"code","source":"## Collecting all the features. \nfeature_cols = train.drop(['PassengerId', 'Survived'], axis=1).columns\n\n## Getting all the data that are not of \"object\" type. \nnumerical_columns = train[feature_cols].select_dtypes(include=['int64','float64']).columns\ncategorical_columns = train[feature_cols].select_dtypes(exclude=['int64','float64']).columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_rows, num_cols = 3,2\nf, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(12, 12))\nf.suptitle('Distribution of Features', fontsize=16)\n\nfor index, column in enumerate(df[numerical_columns].columns):\n    i,j = (index // num_cols, index % num_cols)\n    g = sns.kdeplot(train[column], color=\"m\", shade=True, label=\"%.2f\"%(train[column].skew()), ax=axes[i,j])\n    g = g.legend(loc=\"best\")\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = df[numerical_columns].corr().abs()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\nfig, ax = plt.subplots(figsize=(14, 14))\n\n# plot heatmap\nsns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap='coolwarm',\n            cbar_kws={\"shrink\": .8}, vmin=0, vmax=1)\n# yticks\nplt.yticks(rotation=0)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:120%; text-align:center\">Categorical Variables</p>","metadata":{}},{"cell_type":"code","source":"categorical_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ProfileReport on train&test data","metadata":{}},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\n\nProfileReportTrain = ProfileReport(train, title='Profile Report on Train data',html={'style':{'full_width':True}}) \nProfileReportTest = ProfileReport(test, title='Profile Report on Test data',html={'style':{'full_width':True}}) \nProfileReportDF = ProfileReport(df, title='Profile Report on df',html={'style':{'full_width':True}}) ","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ProfileReportDF","metadata":{},"execution_count":null,"outputs":[]}]}