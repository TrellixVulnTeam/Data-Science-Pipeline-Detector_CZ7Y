{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Utils\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, make_scorer, accuracy_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom kmodes.kmodes import KModes\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform as sp_uniform\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.metrics.pairwise import pairwise_kernels\nfrom sklearn.metrics.pairwise  import cosine_similarity\nfrom sklearn.metrics.pairwise import chi2_kernel\nfrom catboost import CatBoostClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"train= pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/train.csv', sep=',')\nsub_sample = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/sample_submission.csv', sep=',')\ntest= pd.read_csv('/kaggle/input/tabular-playground-series-apr-2021/test.csv', sep=',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features Extraction","metadata":{}},{"cell_type":"code","source":"train = train.set_index('PassengerId')\n\n#df with train + test data\ndfg = pd.concat([train, test], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.Age","metadata":{}},{"cell_type":"code","source":"train['Age'] = train['Age'].replace(np.nan, dfg['Age'].median())\ntrain['Age'] = round(train['Age'],0)\n\nbins = ['Y1', 'Y2', 'Y3', 'Y4', 'M1', 'M2', 'E']\ntrain['Age_Bin'] = pd.cut(x=train['Age'],\n                            bins=[0, 5 , 10, 15, 20, 30, 50,1000],\n                            labels=bins,right=False)\ntrain['Age_Bin'] = train['Age_Bin'].astype('str')\ntrain['Age_Bin'] = train['Age_Bin']+train['Sex']\ndf_Age_bin = pd.get_dummies(train['Age_Bin'], prefix='Age_bin')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.Fare","metadata":{}},{"cell_type":"code","source":"dfg['Age_Bin'] = pd.cut(x=dfg['Age'],\n                            bins=[0, 5 , 10, 15, 20, 30, 50,1000],\n                            labels=bins,right=False)\ndfg.groupby(by=['Sex','Pclass'])['Fare'].median()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[(train['Fare'].isna()) & (train['Pclass']==1) & (train['Sex']=='female'), 'Fare']=85.40\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==2) & (train['Sex']=='female'), 'Fare']=24.75\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==3) & (train['Sex']=='female'), 'Fare']=12.54\n\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==1) & (train['Sex']=='male'), 'Fare']=64.51\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==2) & (train['Sex']=='male'), 'Fare']=14.23\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==3) & (train['Sex']=='male'), 'Fare']=11.02","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fare bins\nbins2 = ['L1', 'L2', 'L3', 'L4']\ntrain['Fare_Bin'] = pd.cut(x=train['Fare'],\n                            bins=[0,11, 30 , 60, 10000],\n                            labels=bins2,right=False)\ntrain['Fare_Bin'] = train['Fare_Bin'].astype('str')\ndf_Fare_bin = pd.get_dummies(train['Fare_Bin'], prefix='Fare_bin')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.Cabin","metadata":{}},{"cell_type":"code","source":"dfg['Cabin'] =dfg['Cabin'].str[0]\ntrain['Cabin'] =train['Cabin'].str[0]\ntrain['Cabin'] = train['Cabin'].fillna('Z')\ntrain.loc[(train['Cabin']=='T'), 'Cabin']='Z'\ndf_cabin = pd.get_dummies(train['Cabin'], prefix='Cabin')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.Embarked ","metadata":{}},{"cell_type":"code","source":"#Used the most frequent caracter\ntrain['Embarked'] = train['Embarked'].fillna('S')\ndf_embarked = pd.get_dummies(train['Embarked'], prefix='Embark')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.Ticket ","metadata":{}},{"cell_type":"code","source":"train['Ticket'] = train['Ticket'].str.replace('[^a-zA-Z]', '').str[:1]\ntrain['Ticket'] = train['Ticket'].str.strip()\ntrain['Ticket'] = train['Ticket'].fillna('ZZ')\ntrain.loc[train['Ticket']=='', 'Ticket']='ZZ'\ntrain.loc[train['Ticket']=='L', 'Ticket']='ZZ'\ndf_tiket = pd.get_dummies(train['Ticket'], prefix='ticket')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.Name ","metadata":{}},{"cell_type":"code","source":"df_name = pd.concat([train['Name'], test['Name']], axis=0)\ndf_name = pd.DataFrame(df_name, columns=['Name'])\n\ndf_name['FirstName'] = df_name['Name'].apply(lambda x:x.split(', ')[0])\ndf_name['SecondName'] = df_name['Name'].str.split(', ', 1, expand=True)[1]\n\nle = LabelEncoder()\nle1 = LabelEncoder()\ndf_name['FirstName'] = le.fit_transform(df_name['FirstName'])\ndf_name['SecondName'] = le1.fit_transform(df_name['SecondName'])\n\ntrain['FirstName'] = train['Name'].apply(lambda x:x.split(', ')[0])\ntrain['SecondName'] = train['Name'].str.split(', ', 1, expand=True)[1]\n\ntrain['FirstName'] = le.transform(train['FirstName'])\ntrain['SecondName'] = le1.transform(train['SecondName'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.Sex ","metadata":{}},{"cell_type":"code","source":"train['Sex'] = train['Sex'].apply(lambda x: 1 if x=='female' else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 8.Pclass ","metadata":{}},{"cell_type":"code","source":"train['Pclass'] = train['Pclass'].astype('str')\ndf_pclass = pd.get_dummies(train['Pclass'], prefix='class')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 9.Family Size ","metadata":{}},{"cell_type":"markdown","source":"Get the Fatures related to Family size. An idea taken from: https://medium.datadriveninvestor.com/start-with-kaggle-a-comprehensive-guide-to-solve-the-titanic-challenge-8ac5815b0473","metadata":{}},{"cell_type":"code","source":"# introducing a new feature : the size of families (including the passenger)\ntrain['FamilySize'] = train['Parch'] + train['SibSp'] + 1\n\n# introducing other features based on the family size\ntrain['Singleton'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFamily'] = train['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntrain['LargeFamily'] = train['FamilySize'].map(lambda s: 1 if 5 <= s else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA Features importance","metadata":{}},{"cell_type":"code","source":"df = pd.concat([train['Fare'], train['Age'],train['SibSp'],train['Parch'],train['FamilySize'], train['Singleton'], train['SmallFamily'], train['LargeFamily'],train['Sex'], df_cabin,df_tiket, df_pclass, df_embarked ,train['FirstName'],train['SecondName'],df_Age_bin,df_Fare_bin,train['Survived']], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.heatmap(data=df.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns='Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding 3 Kmeans Features","metadata":{}},{"cell_type":"code","source":"km = KMeans(n_clusters=3, random_state=22, n_init=20)\ndf_km = km.fit_predict(df)\ndf_km = pd.DataFrame(df_km, index=df.index)\ndf_km = df_km.astype('str')\ndf_km = pd.get_dummies(df_km)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df, df_km], axis=1)\ndf_target = train['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=200, max_features='sqrt')\nclf = clf.fit(df, df_target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = pd.DataFrame()\nfeatures['feature'] = df.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(25, 25))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cb = pd.concat([train['Fare'],train['SibSp'],train['Parch'], train['Age'],train['FamilySize'], train['Singleton'], train['SmallFamily'], train['LargeFamily'], train['Sex'], train['Cabin'],train['Ticket'], train['Pclass'], train['Embarked'] ,train['FirstName'], train['SecondName'],train['Age_Bin'],train['Fare_Bin'], df_km], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optuna with Catboost","metadata":{}},{"cell_type":"code","source":"#Category Columns\ncat_cols = ['FamilySize', 'Singleton', 'SmallFamily', 'LargeFamily',\n       'Sex', 'Cabin', 'Ticket', 'Pclass', 'Embarked', 'FirstName', 'SecondName',\n       '0_0', '0_1', '0_2', 'Age_Bin', 'Fare_Bin']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cb.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial , data = df_cb , target = df_target):\n    train_x , test_x , train_y , test_y = train_test_split(data , target , \\\n            test_size = 0.028059109276941666 , random_state = 2)\n\n    params = {'iterations':10000,\n              'depth': trial.suggest_int(\"depth\", 4, 70),\n              'l2_leaf_reg': trial.suggest_float(\"l2_leaf_reg\", 0.0001, 25, log=True),\n              'bagging_temperature': trial.suggest_float(\"bagging_temperature\", 0, 100),\n              'auto_class_weights':trial.suggest_categorical('auto_class_weights', [None,'Balanced','SqrtBalanced']),\n              'grow_policy': 'Lossguide',\n              'loss_function':'Logloss',\n              'bootstrap_type':trial.suggest_categorical(\"bootstrap_type\", ['Poisson']),\n              'use_best_model':True,\n              'task_type':'GPU', \n              'cat_features':cat_cols,\n              'eval_metric': 'Logloss',\n              'learning_rate': trial.suggest_uniform('learning_rate' , 1e-5 , 1.0),\n              #'max_bin': trial.suggest_int('max_bin', 5, 500),\n              'verbose':False,\n              'border_count':trial.suggest_int('max_bin', 5, 600),\n              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 600),\n              'subsample': trial.suggest_uniform('subsample' , 1e-5 , 1.0)\n             }\n    model = CatBoostClassifier(**params)\n    model.fit(train_x , train_y , eval_set = [(test_x , test_y)] , early_stopping_rounds = 2000 , \\\n             verbose = False)\n    preds = model.predict(test_x)\n    acc = accuracy_score(test_y , preds)\n    return acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize' , study_name = 'cb')\nstudy.optimize(objective , n_trials = 1)\nprint('numbers of the finished trials:' , len(study.trials))\nprint('the best params:' , study.best_trial.params)\nprint('the best value:' , study.best_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the best value: 0.7822523164647185\nparams={'depth': 38, 'l2_leaf_reg': 0.0010021036002324036, 'bagging_temperature': 54.72815390606476, 'auto_class_weights': None, 'bootstrap_type': 'Poisson', 'learning_rate': 0.0863109888471924, 'max_bin': 192, 'min_data_in_leaf': 338, 'subsample': 0.5399710139554038}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.set_index('PassengerId')\n\n#Age\ntest['Age'] = test['Age'].replace(np.nan, dfg['Age'].median())\ntest['Age_Bin'] = pd.cut(x=test['Age'],\n                            bins=[0, 5 , 10, 15, 20, 30, 50,1000],\n                            labels=bins,right=False)\ntest['Age_Bin'] = test['Age_Bin'].astype('str')\ntest['Age_Bin'] = test['Age_Bin']+test['Sex']\ndft_Age_bin = pd.get_dummies(test['Age_Bin'], prefix='Age_bin')\n\n\n#Fare\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==1) & (test['Sex']=='female'), 'Fare']=85.40\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==2) & (test['Sex']=='female'), 'Fare']=24.75\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==3) & (test['Sex']=='female'), 'Fare']=12.54\n\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==1) & (test['Sex']=='male'), 'Fare']=64.51\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==2) & (test['Sex']=='male'), 'Fare']=14.23\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==3) & (test['Sex']=='male'), 'Fare']=11.02\n\ntest['Fare_Bin'] = pd.cut(x=test['Fare'],\n                            bins=[0,11, 30 , 60, 10000],\n                            labels=bins2,right=False)\n\ntest['Fare_Bin'] = test['Fare_Bin'].astype('str')\ndft_Fare_bin = pd.get_dummies(test['Fare_Bin'], prefix='Fare_bin')\n\n\n#Cabin\ntest['Cabin'] =test['Cabin'].str[0]\ntest['Cabin'] = test['Cabin'].fillna('Z')\ntest.loc[(test['Cabin']=='T'), 'Cabin']='Z'\ndft_cabin = pd.get_dummies(test['Cabin'], prefix='Cabin')\n\n#Embarked\ntest['Embarked'] = test['Embarked'].fillna('S')\ndft_embarked = pd.get_dummies(test['Embarked'], prefix='Embark')\n\n#Ticket\ntest['Ticket'] = test['Ticket'].str.replace('[^a-zA-Z]', '').str[:1]\ntest['Ticket'] = test['Ticket'].str.strip()\ntest['Ticket'] = test['Ticket'].fillna('ZZ')\ntest.loc[test['Ticket']=='', 'Ticket']='ZZ'\ntest.loc[test['Ticket']=='L', 'Ticket']='ZZ'\ndft_tiket = pd.get_dummies(test['Ticket'], prefix='ticket')\n\n#Name\ntest['FirstName'] = test['Name'].apply(lambda x:x.split(', ')[0])\ntest['SecondName'] = test['Name'].str.split(', ', 1, expand=True)[1]\n\ntest['FirstName'] = le.transform(test['FirstName'])\ntest['SecondName'] = le1.transform(test['SecondName'])\n\n#Sex\ntest['Sex'] = test['Sex'].apply(lambda x: 1 if x=='female' else 0)\n\n#Pclass\ntest['Pclass'] = test['Pclass'].astype('str')\ndft_pclass = pd.get_dummies(test['Pclass'], prefix='class')\n\n#Family Size\ntest['FamilySize'] = test['Parch'] + test['SibSp'] + 1\n\ntest['Singleton'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFamily'] = test['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntest['LargeFamily'] = test['FamilySize'].map(lambda s: 1 if 5 <= s else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft = pd.concat([test['Fare'],test['SibSp'],test['Parch'], test['Age'],test['FamilySize'], test['Singleton'], test['SmallFamily'], test['LargeFamily'], test['Sex'],dft_cabin,dft_tiket, dft_pclass, dft_embarked, test['FirstName'],test['SecondName'], dft_Age_bin, dft_Fare_bin], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft_km = km.predict(dft)\ndft_km = pd.DataFrame(dft_km, index=dft.index)\ndft_km = dft_km.astype('str')\ndft_km = pd.get_dummies(dft_km)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft = pd.concat([dft, dft_km], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft_cb = pd.concat([test['Fare'], test['SibSp'], test['Parch'],test['Age'],test['FamilySize'], test['Singleton'], test['SmallFamily'], test['LargeFamily'], test['Sex'], test['Cabin'],test['Ticket'], test['Pclass'], test['Embarked'] ,test['FirstName'],test['SecondName'],test['Age_Bin'],test['Fare_Bin'], dft_km], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_cb = {\n    'bootstrap_type': 'Poisson',\n    'loss_function': 'Logloss',\n    'eval_metric': 'Logloss',\n    'random_seed': 22,\n    'task_type': 'GPU',\n    'grow_policy': 'Lossguide',\n    'depth': 38,\n    'bagging_temperature': 54.72815390606476,\n    'auto_class_weights': None,\n    'cat_features': cat_cols,\n    'learning_rate': 0.0863109888471924,\n    'iterations':10000,\n    'max_bin': 192,\n    'min_data_in_leaf': 338,\n    'subsample': 0.5399710139554038,\n    'l2_leaf_reg': 0.0010021036002324036,\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds3 = np.zeros(dft_cb.shape[0])\noof_preds3 = np.zeros(df_cb.shape[0])\nkf = StratifiedKFold(n_splits = 10 , random_state = 22 , shuffle = True)\nroc3 = []\nn = 0\nfor trn_idx , val_idx in kf.split(df_cb , df_target):\n    train_x = df_cb.iloc[trn_idx]\n    train_y = df_target.iloc[trn_idx]\n    val_x = df_cb.iloc[val_idx]\n    val_y = df_target.iloc[val_idx]\n    \n    model3 = CatBoostClassifier(**params_cb)\n    model3.fit(train_x , train_y , eval_set = [(val_x , val_y)], early_stopping_rounds = 3000 , verbose = False)\n    preds3 += model3.predict_proba(dft_cb)[:,1]/kf.n_splits\n    oof_preds3 += model3.predict_proba(df_cb)[:,1]/kf.n_splits\n    roc3.append(accuracy_score(val_y , model3.predict(val_x)))\n    fpr, tpr, thresholds = roc_curve(val_y , model3.predict_proba(val_x)[:,1])\n    gmeans = np.sqrt(tpr * (1-fpr))\n    ix = np.argmax(gmeans)\n    print(n+1 , roc3[n], 'Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n    n+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Looking for the Best Threshold","metadata":{}},{"cell_type":"code","source":"thresholds = np.arange(0, 1, 0.001)\n# apply threshold to positive probabilities to create labels\n\ndef to_labels(pos_probs, threshold):\n    return (pos_probs >= threshold).astype('int')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [accuracy_score(df_target, to_labels(oof_preds3, t)) for t in thresholds]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ix = np.argmax(scores)\nprint('Threshold=%.3f, accuracy_Score=%.5f' % (thresholds[ix], scores[ix]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_sample['Survived'] = preds3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#simple threshold\nsub_sample['Survived'] = sub_sample['Survived'].apply(lambda x: 1 if x>thresholds[ix] else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pseudo-Labels with the same model","metadata":{}},{"cell_type":"code","source":"y = pd.concat([df_target, sub_sample['Survived']], axis=0)\nX = pd.concat([df_cb, dft_cb], axis=0)\nprint(X.shape,y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds3 = np.zeros(dft_cb.shape[0])\noof_preds3 = np.zeros(X.shape[0])\nkf = StratifiedKFold(n_splits = 10 , random_state = 22 , shuffle = True)\nroc3 = []\nn = 0\nfor trn_idx , val_idx in kf.split(X , y):\n    train_x = X.iloc[trn_idx]\n    train_y = y.iloc[trn_idx]\n    val_x = X.iloc[val_idx]\n    val_y = y.iloc[val_idx]\n    \n    model3 = CatBoostClassifier(**params_cb)\n    model3.fit(train_x , train_y , eval_set = [(val_x , val_y)], early_stopping_rounds = 3000 , verbose = False)\n    preds3 += model3.predict_proba(dft_cb)[:,1]/kf.n_splits\n    oof_preds3 += model3.predict_proba(X)[:,1]/kf.n_splits\n    roc3.append(accuracy_score(val_y , model3.predict(val_x)))\n    fpr, tpr, thresholds = roc_curve(val_y , model3.predict_proba(val_x)[:,1])\n    gmeans = np.sqrt(tpr * (1-fpr))\n    ix = np.argmax(gmeans)\n    print(n+1 , roc3[n], 'Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n    n+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Final Threshold\nscores = [accuracy_score(y, to_labels(oof_preds3, t)) for t in thresholds]\nix = np.argmax(scores)\nprint('Threshold=%.3f, accuracy_Score=%.5f' % (thresholds[ix], scores[ix]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_sample['Survived'] = preds3\nsub_sample['Survived'] = sub_sample['Survived'].apply(lambda x: 1 if x>thresholds[ix] else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_sample.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}