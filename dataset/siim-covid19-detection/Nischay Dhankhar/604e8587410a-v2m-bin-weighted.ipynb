{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:40:33.898803Z","iopub.execute_input":"2021-08-08T05:40:33.899225Z","iopub.status.idle":"2021-08-08T05:40:34.616239Z","shell.execute_reply.started":"2021-08-08T05:40:33.899137Z","shell.execute_reply":"2021-08-08T05:40:34.615309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dependencies","metadata":{}},{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y\n\n!pip install --no-deps -U ../input/pytorch-image-models/\n!pip install --no-deps -U ../input/effdet-latestvinbigdata-wbf-fused/omegaconf-2.0.6-py3-none-any.whl\n!pip install --no-deps -U ../input/effdet-latestvinbigdata-wbf-fused/pycocotools-2.0.2/\n!pip install --no-deps -U ../input/efficientdetpytorch/\n!pip install --no-deps -U ../input/ensemble-boxes-104/ensemble_boxes-1.0.4\n!pip install /kaggle/input/mishcuda/mish-cuda/\n\n!pip install '/kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmcv_full-1_3_8-cu110-torch1_7_0/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps\n\n!cp -r /kaggle/input/mmdetectionv2140/mmdetection-2.14.0 /kaggle/working/\n!mv /kaggle/working/mmdetection-2.14.0 /kaggle/working/mmdetection\n!pip install -e '/kaggle/working/mmdetection/'","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-08T05:40:35.167853Z","iopub.execute_input":"2021-08-08T05:40:35.168217Z","iopub.status.idle":"2021-08-08T05:47:57.024313Z","shell.execute_reply.started":"2021-08-08T05:40:35.168183Z","shell.execute_reply":"2021-08-08T05:47:57.023304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports and Env Setup","metadata":{}},{"cell_type":"code","source":"import sys, warnings, pandas\npandas.reset_option(\"all\")\nwarnings.filterwarnings('ignore')\nsys.path.append('../input/siimfisabiorsna-covid19-checkpoints/pytorch-toolbelt/pytorch-toolbelt-develop/')\nsys.path.append('../input/ttach-pytorch/')\nsys.path.append('../input/siim-code/classification_code/')\nsys.path.append('./mmdetection/')","metadata":{"_uuid":"d1fc7a93-68da-40df-8857-8a08a29393d2","_cell_guid":"192a4c33-e3e0-404b-952f-f60dadff511d","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-08T05:48:00.427481Z","iopub.execute_input":"2021-08-08T05:48:00.427856Z","iopub.status.idle":"2021-08-08T05:48:00.461235Z","shell.execute_reply.started":"2021-08-08T05:48:00.427824Z","shell.execute_reply":"2021-08-08T05:48:00.460252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc, json, cv2\n\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\nfrom tqdm.auto import tqdm\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import get_dicom_files\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport ttach as tta\nfrom timm.models import load_checkpoint\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom src.defaults import get_cfg\nfrom src.models import build_model, create_backbone\nfrom heng_inference_binary_multiaux_final import Net,\\\n     BenchPredictHengBinary","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:01.656782Z","iopub.execute_input":"2021-08-08T05:48:01.657105Z","iopub.status.idle":"2021-08-08T05:48:05.870765Z","shell.execute_reply.started":"2021-08-08T05:48:01.657075Z","shell.execute_reply":"2021-08-08T05:48:05.869648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nif df.shape[0] == 2477:\n    fast_sub = True\nelse:\n    fast_sub = False\nprint(fast_sub)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:05.872549Z","iopub.execute_input":"2021-08-08T05:48:05.872867Z","iopub.status.idle":"2021-08-08T05:48:05.892214Z","shell.execute_reply.started":"2021-08-08T05:48:05.872839Z","shell.execute_reply":"2021-08-08T05:48:05.891479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepaths = get_dicom_files(\"/kaggle/input/siim-covid19-detection/test/\", recurse=True)\nif fast_sub:\n    filepaths = filepaths[:5]\ntest_df = pd.DataFrame({'filepath': filepaths.map(lambda x: str(x))})\ntest_df['image_id'] = test_df.filepath.map(lambda x: str(x).split('/')[-1].replace('.dcm', '') + '_image')\ntest_df['study_id'] = test_df.filepath.map(lambda x: str(x).split('/')[-3].replace('.dcm', '') + '_study')\ndisplay_df(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:07.085844Z","iopub.execute_input":"2021-08-08T05:48:07.086166Z","iopub.status.idle":"2021-08-08T05:48:11.536083Z","shell.execute_reply.started":"2021-08-08T05:48:07.086137Z","shell.execute_reply":"2021-08-08T05:48:11.535321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label2name   = {0: 'atypical', 1: 'indeterminate', 2: 'negative', 3: 'typical'}\nclass_labels = ['0', '1', '2', '3']\n\nIMG_SIZE  = 1024\nTEST_PATH = '/kaggle/tmp/test/'\nos.makedirs(TEST_PATH, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:11.537471Z","iopub.execute_input":"2021-08-08T05:48:11.537798Z","iopub.status.idle":"2021-08-08T05:48:11.542488Z","shell.execute_reply.started":"2021-08-08T05:48:11.537764Z","shell.execute_reply":"2021-08-08T05:48:11.541669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Serialization of Test Images","metadata":{}},{"cell_type":"code","source":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    if voi_lut: \n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else: \n        data = dicom.pixel_array\n        \n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8) \n    return data\n\ndef resize(array, size, keep_ratio=True, resample=Image.LANCZOS):\n    im = Image.fromarray(array)\n    if keep_ratio: \n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    return im\n\ndef resize_and_save(file_path):\n    base_dir = TEST_PATH\n    xray = read_xray(file_path)\n    img  = resize(xray, IMG_SIZE, keep_ratio=True)\n    filename = file_path.split('/')[-1].split('.')[0]\n    img.save(os.path.join(base_dir, f'{filename}.png'))\n    return filename.replace('dcm','') + '_image', xray.shape[0], xray.shape[1]\n\ndef serialize(paths):\n    info = []\n    dim0 = []\n    dim1 = []\n    iterator = tqdm(paths, total=len(paths), dynamic_ncols=True )\n    for idx , p in enumerate(iterator): \n        i, d0, d1 = resize_and_save(p)\n        info.append(i)  \n        dim0.append(d0)\n        dim1.append(d1)\n    return info, dim0, dim1","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:14.661457Z","iopub.execute_input":"2021-08-08T05:48:14.661781Z","iopub.status.idle":"2021-08-08T05:48:14.673788Z","shell.execute_reply.started":"2021-08-08T05:48:14.661752Z","shell.execute_reply":"2021-08-08T05:48:14.67257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepaths = test_df.filepath.iloc[:test_df.shape[0]]\n(info, dim0, dim1) = serialize(filepaths)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:15.268094Z","iopub.execute_input":"2021-08-08T05:48:15.268483Z","iopub.status.idle":"2021-08-08T05:48:19.718348Z","shell.execute_reply.started":"2021-08-08T05:48:15.268452Z","shell.execute_reply":"2021-08-08T05:48:19.717345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'image_id': list(info)})\ndf['image_path'] = TEST_PATH + df.image_id.map(lambda x: x.replace('_image','')) + '.png'\ndf['dim0'] = list(dim0)\ndf['dim1'] = list(dim1)\n\ntest_df = pd.merge(test_df, df, on='image_id', how='left')\ntest_df.drop(columns=['filepath'], inplace=True)\ndisplay_df(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:21.086445Z","iopub.execute_input":"2021-08-08T05:48:21.088865Z","iopub.status.idle":"2021-08-08T05:48:21.121023Z","shell.execute_reply.started":"2021-08-08T05:48:21.08882Z","shell.execute_reply":"2021-08-08T05:48:21.120247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df = test_df.drop(columns=[\"study_id\"], inplace=False)\nstudy_df = test_df.drop(columns=[\"image_id\"], inplace=False)\ntest_df.loc[:, class_labels] = 0\ndisplay_df(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:22.276948Z","iopub.execute_input":"2021-08-08T05:48:22.277281Z","iopub.status.idle":"2021-08-08T05:48:22.292384Z","shell.execute_reply.started":"2021-08-08T05:48:22.277237Z","shell.execute_reply":"2021-08-08T05:48:22.29126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Study Level Predictions","metadata":{}},{"cell_type":"code","source":"class LoadImages(Dataset):\n    def __init__(self, df, transform):\n        self.file_names = L(list(df.image_path.iloc[:test_df.shape[0]]))\n        self.transform  = transform\n\n    def __len__(self): \n        return len(self.file_names)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        assert os.path.exists(file_name)\n        image = cv2.imread(file_name)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = self.transform(image=image)['image']\n        return image\n    \ndef pre_processing(sz, *args, **kwargs):\n    return albu.Compose([\n        albu.Resize(sz, sz), \n        albu.ToFloat(p=1.0, max_value=255.0), \n        ToTensorV2(p=1.0)\n    ])\n\ndef get_tta_transforms(): \n    return tta.Compose([tta.HorizontalFlip()])\n\n\nclass BenchPredict(nn.Module):\n    def __init__(self, model):\n        super(BenchPredict, self).__init__()\n        self.model = model\n    \n    def forward(self, input):\n        logits = self.model(input)['output']\n        return F.softmax(logits)\n\n\n@torch.no_grad()\ndef get_preds(model, test_loader):\n    batch_probs = []\n    for i, (images) in enumerate(tqdm(test_loader, dynamic_ncols=True, leave=False)):\n        images = images.cuda()\n        y_preds= model(images)\n        batch_probs.append(y_preds)\n        del y_preds, images\n        gc.collect()\n        torch.cuda.empty_cache()\n    return torch.cat(batch_probs).data.cpu().numpy()\n\n@delegates(load_checkpoint)\ndef make_model(cfg, state, **kwargs):\n    model = build_model(cfg)\n    load_checkpoint(model, state, **kwargs)\n    bench = BenchPredict(model=model)\n    bench.cuda()\n    bench.eval()\n    return bench\n\ndef get_PredictionString(row, df, thr=0.0):\n    string = ''\n    for idx in list(df.columns[1:]):\n        conf =  row[idx]\n        if conf>thr:\n            string += f'{idx} {conf:.6f} 0 0 1 1 '\n    string = string.strip()\n    return string","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:23.892116Z","iopub.execute_input":"2021-08-08T05:48:23.892476Z","iopub.status.idle":"2021-08-08T05:48:23.906634Z","shell.execute_reply.started":"2021-08-08T05:48:23.892445Z","shell.execute_reply":"2021-08-08T05:48:23.905445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Study : Mix Model Predictions","metadata":{}},{"cell_type":"code","source":"used_models = [\n    '../input/studymodelsbest/001cf4cc-8939v2l_noisy_Fine/fold1/model_best.pth.tar',\n    '../input/studymodelsbest/001cf4cc-8939v2l_noisy_Fine/fold3/model_best.pth.tar',\n    '../input/studymodelsbest/001cf4cc-8939v2l_noisy_Fine/fold4/model_best.pth.tar',\n    '../input/studymodelsbest/001cf4cc-8939v2m_noisy640/fold0/model_best.pth.tar',\n    '../input/studymodelsbest/7f8543b6-6957eb5_Noisy/fold2/model_best.pth.tar',\n    \n    '../input/studymodelsbest/7f8543b6-6957eb7_noisy640_Fine/fold3/model_best.pth.tar',\n    \n    '../input/study-models-best-part2/6957eb7_noisy640_Fine/fold2/model_best.pth.tar',\n    '../input/study-models-best-part2/8939v2l_640_rotate/fold1/model_best.pth.tar',\n    '../input/study-models-best-part2/8939v2l_noisy512_50_hard/fold3/model_best.pth.tar',\n    '../input/study-models-best-part2/8939v2l_noisy_512_rotate_Fine/fold4/model_best.pth.tar',\n    '../input/study-models-best-part2/8939v2m_1024_noisy/fold0/model_best.pth.tar',\n]\n    \nconfigs = [    \n    '../input/studymodelsbest/001cf4cc-8939v2l_noisy_Fine/fold1/config.yaml',\n    '../input/studymodelsbest/001cf4cc-8939v2l_noisy_Fine/fold3/config.yaml',\n    '../input/studymodelsbest/001cf4cc-8939v2l_noisy_Fine/fold4/config.yaml',\n    '../input/studymodelsbest/001cf4cc-8939v2m_noisy640/fold0/config.yaml',\n    '../input/studymodelsbest/7f8543b6-6957eb5_Noisy/fold2/config.yaml',\n    \n    '../input/studymodelsbest/7f8543b6-6957eb7_noisy640_Fine/fold3/config.yaml',\n    \n    '../input/study-models-best-part2/6957eb7_noisy640_Fine/fold2/config.yaml',\n    '../input/study-models-best-part2/8939v2l_640_rotate/fold1/config.yaml',\n    '../input/study-models-best-part2/8939v2l_noisy512_50_hard/fold3/config.yaml',\n    '../input/study-models-best-part2/8939v2l_noisy_512_rotate_Fine/fold4/config.yaml',\n    '../input/study-models-best-part2/8939v2m_1024_noisy/fold0/config.yaml'\n]\n\npreds = []\n\nfor c, chkpt in tqdm(zip(configs, used_models), total=len(used_models), dynamic_ncols=True):\n    CFG = get_cfg()\n    CFG.merge_from_file(c)\n    CFG.MODEL.BACKBONE.PRETRAINED = False\n\n    transform = pre_processing(sz=CFG.INPUT.INPUT_SIZE)\n    dset = LoadImages(test_df, transform=transform)\n    dl = DataLoader(dset, batch_size=16)\n    \n    model = make_model(CFG, chkpt)\n    ttas = get_tta_transforms()\n    model = tta.ClassificationTTAWrapper(model, ttas) \n    \n    predict = get_preds(model, dl)\n    preds.append(predict)\n    \n    del model, dl,dset, predict\n    gc.collect(); torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:48:25.945173Z","iopub.execute_input":"2021-08-08T05:48:25.945503Z","iopub.status.idle":"2021-08-08T05:52:40.969054Z","shell.execute_reply.started":"2021-08-08T05:48:25.945473Z","shell.execute_reply":"2021-08-08T05:52:40.968242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## v2m Predictions","metadata":{}},{"cell_type":"code","source":"used_models = [\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold0-8f5d9473-4fda.pth.tar',\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold1-8f5d9473-4fda.pth.tar',\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold2-8f5d9473-4fda.pth.tar',\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold3-8f5d9473-4fda.pth.tar',\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold4-8f5d9473-4fda.pth.tar',\n\n]\n    \nconfigs = [\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/config.yml',\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/config.yml',\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/config.yml',\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/config.yml',\n    '../input/siimfisabiorsna-covid19-checkpoints/8f5d9473-4fda/config.yml'\n]\n\nv2m_preds = []\n\nfor c, chkpt in tqdm(zip(configs, used_models), total=len(used_models), dynamic_ncols=True):\n    CFG = get_cfg()\n    CFG.merge_from_file(c)\n    CFG.MODEL.BACKBONE.PRETRAINED = False\n\n    transform = pre_processing(sz=CFG.INPUT.INPUT_SIZE)\n    dset = LoadImages(test_df, transform=transform)\n    dl = DataLoader(dset, batch_size=16)\n    \n    model = make_model(CFG, chkpt)\n    model = tta.ClassificationTTAWrapper(model, get_tta_transforms()) \n    \n    predict = get_preds(model, dl)\n    v2m_preds.append(predict)\n    \n    del model, dl,dset, predict\n    torch.cuda.empty_cache(); gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:53:05.705151Z","iopub.execute_input":"2021-08-08T05:53:05.705553Z","iopub.status.idle":"2021-08-08T05:53:38.707768Z","shell.execute_reply.started":"2021-08-08T05:53:05.705519Z","shell.execute_reply":"2021-08-08T05:53:38.706901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Binary Predictions","metadata":{}},{"cell_type":"code","source":"@delegates(load_checkpoint)\ndef load_binary_model(state, **kwargs):\n    model = Net()\n    load_checkpoint(model, state, **kwargs)\n    bench = BenchPredictHengBinary(binary_model=model)\n    bench.cuda()\n    bench.eval()\n    return bench","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:56:21.612396Z","iopub.execute_input":"2021-08-08T05:56:21.612779Z","iopub.status.idle":"2021-08-08T05:56:21.618239Z","shell.execute_reply.started":"2021-08-08T05:56:21.61275Z","shell.execute_reply":"2021-08-08T05:56:21.617405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"used_models = [\n    '../input/covid-binary-models/eb6ns_512_binary_multimask_noisy_new/eb6ns_512_binary_multimask_noisy_fold0_1374.pth',\n    '../input/covid-binary-models/eb6ns_512_binary_multimask_noisy_new/eb6ns_512_binary_multimask_noisy_fold1_1408_ext.pth',\n    '../input/covid-binary-models/eb6ns_512_binary_multimask_noisy_new/eb6ns_512_binary_multimask_noisy_fold2_1376_ext.pth',\n    '../input/covid-binary-models/eb6ns_512_binary_multimask_noisy_new/eb6ns_512_binary_multimask_noisy_fold3_1377_ext.pth',\n    '../input/covid-binary-models/eb6ns_512_binary_multimask_noisy_new/eb6ns_512_binary_multimask_noisy_fold4_1343.pth',\n]\n\nbinary_preds = []\n\nfor chkpt in tqdm(used_models, total=len(used_models), dynamic_ncols=True):\n\n    transform = pre_processing(sz=512)\n    dset = LoadImages(test_df, transform=transform)\n    dl   = DataLoader(dset, batch_size=16)\n\n    ttas  = get_tta_transforms() \n    \n    model = load_binary_model(chkpt)\n    model = tta.ClassificationTTAWrapper(model, ttas) \n    \n    predict = get_preds(model, dl)\n    binary_preds.append(predict)\n    \n    del model, dl, dset, predict\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:56:22.893175Z","iopub.execute_input":"2021-08-08T05:56:22.893565Z","iopub.status.idle":"2021-08-08T05:56:40.988751Z","shell.execute_reply.started":"2021-08-08T05:56:22.893532Z","shell.execute_reply":"2021-08-08T05:56:40.987778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process Study Predictions","metadata":{}},{"cell_type":"code","source":"final_mix_preds_study = np.mean(preds, axis=0)\nfinal_v2m_preds_study = np.mean(v2m_preds, axis=0)\nstudy_final_preds = 0.85*final_mix_preds_study + 0.15*final_v2m_preds_study\n\ntest_df.loc[:test_df.shape[0], class_labels] = study_final_preds\nstudy_df = test_df.groupby(['study_id'])[class_labels].mean().reset_index()\nstudy_df.rename(columns={'study_id': 'id'}, inplace=True)\nstudy_df.columns = ['id',\"atypical\", \"indeterminate\", \"negative\", \"typical\"]\n\nstudy_df['PredictionString'] = study_df.apply(partial(get_PredictionString, df=study_df), axis=1)\nstudy_df.to_csv('./study_df.csv', index=False)\ndisplay_df(study_df.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T05:57:52.089092Z","iopub.execute_input":"2021-08-08T05:57:52.089471Z","iopub.status.idle":"2021-08-08T05:57:52.422591Z","shell.execute_reply.started":"2021-08-08T05:57:52.089439Z","shell.execute_reply":"2021-08-08T05:57:52.421786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process Binary Predictions","metadata":{}},{"cell_type":"code","source":"# Mean of 5 fold binary model predictions\nbinary_predictions = np.mean(binary_preds, axis=0)\n# Store binary predictions\ntest_df.loc[:test_df.shape[0], 'none'] = binary_predictions\n# Prepare a dataframe with only none predictions\nbin_df = test_df[[\"study_id\", \"image_id\", \"none\"]]\n# Sort values to ensure same indices\nbin_df = bin_df.sort_values(by='image_id', ascending=True)\nbin_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:04:45.880904Z","iopub.execute_input":"2021-08-08T06:04:45.881254Z","iopub.status.idle":"2021-08-08T06:04:45.897193Z","shell.execute_reply.started":"2021-08-08T06:04:45.881223Z","shell.execute_reply":"2021-08-08T06:04:45.895869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean of 5 fold v2m predictions\nclass_labels = [\"atypical\", \"indeterminate\", \"negative\", \"typical\"]\npreds2 = np.mean(v2m_preds, axis=0)\ntest_df.loc[:test_df.shape[0], class_labels] = preds2\n# Store v2m predictions\nv2m_df = test_df[[\"study_id\", \"image_id\", \"negative\"]]\n# Prepare a dataframe with only none predictions\nv2m_df = v2m_df.rename(columns=dict(negative='none'), inplace=False)\n# Sort values to ensure same indices\nv2m_df = v2m_df.sort_values(by='image_id', ascending=True)\nv2m_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:04:35.477039Z","iopub.execute_input":"2021-08-08T06:04:35.477401Z","iopub.status.idle":"2021-08-08T06:04:35.496161Z","shell.execute_reply.started":"2021-08-08T06:04:35.477367Z","shell.execute_reply":"2021-08-08T06:04:35.495153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binary_submission = v2m_df.copy()\nbinary_submission['none'] = 0.6*v2m_df['none'].values + 0.4*bin_df['none'].values\n\nbinary_submission = binary_submission.reset_index(inplace=False, drop=True)\nbinary_submission.to_csv('./binary_submission.csv', index=False)\ndisplay_df(binary_submission.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:05:44.821162Z","iopub.execute_input":"2021-08-08T06:05:44.821504Z","iopub.status.idle":"2021-08-08T06:05:44.840018Z","shell.execute_reply.started":"2021-08-08T06:05:44.821475Z","shell.execute_reply":"2021-08-08T06:05:44.839234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Level Predictions (Detection Models)","metadata":{}},{"cell_type":"code","source":"def format_prediction_string(boxes, scores, labels):\n    \"generate a single prediction string given boxes, scores and labels\"\n    pred_strings = []\n    if len(boxes) > 0 :\n        for j in zip(labels, scores, boxes):\n            pred_strings.append(\"opacity {0:.4f} {1} {2} {3} {4}\".format(j[1], j[2][0], j[2][1], j[2][2], j[2][3]))\n    else:\n        pred_strings.append(\"none 1 0 0 1 1\")\n    return \" \".join(pred_strings)\n\n\ndef write_submission(test_images_ids, result_boxes, result_scores, result_labels, score_thr):\n    \"write submissions in pandas dataframe format\"\n    results = []\n    \n    for i, image in enumerate(test_images_ids):\n        image_id   = test_images_ids[i]\n        cur_boxes  = np.array(result_boxes[i])\n        cur_scores = np.array(result_scores[i])\n        cur_labels = np.array(result_labels[i])\n\n        score_filter = cur_scores >= score_thr\n        cur_boxes    = cur_boxes[score_filter]\n        cur_scores   = cur_scores[score_filter]\n        cur_labels   = cur_labels[score_filter]\n        \n        result = {'image_id': image_id, 'PredictionString': format_prediction_string(cur_boxes, cur_scores, cur_labels)}\n        results.append(result)\n    \n    return pd.DataFrame(results, columns=['image_id', 'PredictionString'])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:06:01.696893Z","iopub.execute_input":"2021-08-08T06:06:01.697235Z","iopub.status.idle":"2021-08-08T06:06:01.706411Z","shell.execute_reply.started":"2021-08-08T06:06:01.697204Z","shell.execute_reply":"2021-08-08T06:06:01.705517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## + Efficientnet Models\n- D3 (pseudo + ema) (896)\n- D5 (ema) (512)","metadata":{}},{"cell_type":"code","source":"from ensemble_boxes import *\nfrom effdet import unwrap_bench\nfrom effdet import create_model as create_det\nfrom effdet.config import get_efficientdet_config","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:06:02.595904Z","iopub.execute_input":"2021-08-08T06:06:02.596253Z","iopub.status.idle":"2021-08-08T06:06:03.453454Z","shell.execute_reply.started":"2021-08-08T06:06:02.596219Z","shell.execute_reply":"2021-08-08T06:06:03.452594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LoadDetectionDatset(Dataset):\n    \"\"\"Object Detection Dataset\"\"\"\n    def __init__(self, image_paths, augmentations, img_size):\n        self.image_paths = image_paths\n        self.augmentations = augmentations\n        self.img_size = img_size\n        \n    def __len__(self): \n        return len(self.image_paths)\n    \n    def __getitem__(self, index: int):\n        image_path = self.image_paths[index]\n        image = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n        image = self.augmentations(image=image)['image']\n        \n        image_id = str(image_path).split(os.path.sep)[-1].split('.')[0] + '_image'\n        ann = dict(img_idx=index, img_size=self.img_size)\n        return image, ann, image_id","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:06:18.77799Z","iopub.execute_input":"2021-08-08T06:06:18.778406Z","iopub.status.idle":"2021-08-08T06:06:18.786884Z","shell.execute_reply.started":"2021-08-08T06:06:18.778371Z","shell.execute_reply":"2021-08-08T06:06:18.78576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()        \ndef make_predictions(dl, net, score_threshold=0.001):\n    predictions = {}\n    \n    for batch in tqdm(dl, dynamic_ncols=True, smoothing=0):\n        image, ann, image_id = batch\n        images = torch.stack(image).cuda().float()\n        \n        target = {}\n        target['img_scale'] = torch.tensor([1]*images.shape[0]).float().cuda()\n        target['img_size']  = torch.tensor([a['img_size'] for a in ann]).cuda().float()\n\n        with torch.no_grad():\n            det = net(images, img_info=target)\n            for i in range(images.shape[0]):\n                boxes  = det[i].detach().cpu().numpy()[:,:4]    \n                scores = det[i].detach().cpu().numpy()[:,4]\n                indexes= np.where(scores > score_threshold)[0]\n                boxes  = boxes[indexes]\n                predictions[image_id[i]] = ({'boxes': boxes[indexes], 'scores': scores[indexes]})\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:06:20.135245Z","iopub.execute_input":"2021-08-08T06:06:20.13564Z","iopub.status.idle":"2021-08-08T06:06:20.147728Z","shell.execute_reply.started":"2021-08-08T06:06:20.135607Z","shell.execute_reply":"2021-08-08T06:06:20.146226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@delegates(weighted_boxes_fusion)\ndef merge_boxes_from_models(all_models_boxes, all_models_scores, all_models_labels,n_images, **kwargs):\n    n_variants = len(all_models_boxes)\n    assert len(all_models_scores) == n_variants\n    assert len(all_models_labels) == n_variants\n    \n    print(len(all_models_boxes), len(all_models_scores), len(all_models_labels))\n\n    result_boxes  = []\n    result_scores = []\n    result_labels = []\n    \n    for ii in tqdm(range(n_images), dynamic_ncols=True, smoothing=0):\n        pred_boxes  = []\n        pred_scores = []\n        pred_labels = []\n        max_value = 10000\n        \n        for vi in range(n_variants):\n            cur_pred_boxes  = np.array(all_models_boxes[vi][ii],  copy=False)\n            cur_pred_scores = np.array(all_models_scores[vi][ii], copy=False)\n            cur_pred_labels = np.array(all_models_labels[vi][ii], copy=False)\n            \n            cur_pred_boxes  = cur_pred_boxes / max_value\n\n            pred_boxes.append(cur_pred_boxes)\n            pred_scores.append(cur_pred_scores)\n            pred_labels.append(cur_pred_labels)\n\n        pred_boxes, pred_scores, pred_labels = weighted_boxes_fusion(\n            pred_boxes, pred_scores, pred_labels, **kwargs)\n        \n        pred_boxes = np.round(pred_boxes * max_value).astype(int)\n\n        assert len(pred_boxes) == len(pred_scores)\n        assert len(pred_boxes) == len(pred_scores)\n        assert len(pred_boxes) == len(pred_labels)\n        \n        result_boxes.append(pred_boxes)\n        result_scores.append(pred_scores)\n        result_labels.append(pred_labels)\n    \n    return result_boxes, result_scores, result_labels","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:06:21.094554Z","iopub.execute_input":"2021-08-08T06:06:21.094892Z","iopub.status.idle":"2021-08-08T06:06:21.107065Z","shell.execute_reply.started":"2021-08-08T06:06:21.094864Z","shell.execute_reply":"2021-08-08T06:06:21.106019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagenames = image_df.image_path.values.tolist()\nimage_ids  = L(imagenames).map(lambda x: x.split(os.path.sep)[-1].split('.')[0] + '_image')\n\ndef collate_fn(batch): return tuple(zip(*batch))\n\nstates1 = [\n    '../input/psuedo-models-covid/d3_896_stage1_psuedo_ema/model_best_d3_896_stage1_psuedo_fold0_5811.pth.tar',\n    '../input/psuedo-models-covid/d3_896_stage1_psuedo_ema/model_best_d3_896_stage1_psuedo_fold1_5814.pth.tar',\n    '../input/psuedo-models-covid/d3_896_stage1_psuedo_ema/model_best_d3_896_stage1_psuedo_fold2_6012.pth.tar',\n    '../input/psuedo-models-covid/d3_896_stage1_psuedo_ema/model_best_d3_896_stage1_psuedo_fold3_5738.pth.tar',\n    '../input/psuedo-models-covid/d3_896_stage1_psuedo_ema/model_best_d3_896_stage1_psuedo_fold4_6182.pth.tar',\n]\n    \nMODEL = 'tf_efficientdet_d3_ap'\nbase_conf = get_efficientdet_config(MODEL)\nSZ = 896\nprint(\"Image dims:\", SZ)\n    \ntest_transforms = pre_processing(SZ)\n\nds = LoadDetectionDatset(imagenames, test_transforms, img_size=[SZ, SZ])\ndl = DataLoader(ds, batch_size=12, num_workers=2, collate_fn=collate_fn)\n\n\npredictions = []\nfor i in tqdm(states1, dynamic_ncols=True):\n    bench = create_det(\n        model_name=MODEL, bench_task='predict', \n        num_classes=1, bench_labeler=True,\n        soft_nms=False, pretrained_backbone=False, \n        image_size = [SZ,SZ])\n    \n    load_checkpoint(unwrap_bench(bench), i, use_ema=True)\n    bench.cuda()\n    bench.eval() \n    \n    preds = make_predictions(dl, bench)\n    predictions.append(preds)\n    \n    del bench, preds\n    gc.collect()\n    torch.cuda.empty_cache()\n    \ndel ds, dl\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:06:22.713174Z","iopub.execute_input":"2021-08-08T06:06:22.713599Z","iopub.status.idle":"2021-08-08T06:06:52.357676Z","shell.execute_reply.started":"2021-08-08T06:06:22.713555Z","shell.execute_reply":"2021-08-08T06:06:52.356446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_folds_boxes  = []\nall_folds_scores = []\nall_folds_labels = []\n\nfor prediction in tqdm(predictions, smoothing=0, dynamic_ncols=True,):\n    pred_boxes = []; pred_scores = []; pred_labels = []\n\n    for image_index in image_ids:\n        pred_boxes.append(prediction[image_index]['boxes'].tolist()) \n        pred_scores.append(prediction[image_index]['scores'].tolist())\n        pred_labels.append(np.ones(prediction[image_index]['scores'].shape[0]).tolist())\n    pred_boxes, pred_scores, pred_labels = np.array(pred_boxes), np.array(pred_scores), np.array(pred_labels)\n\n    for i, image in enumerate(image_ids):\n        image_id = image_ids[i]\n        image_height, image_width = image_df.loc[image_df.image_id == image_id, ['dim0', 'dim1']].values[0]\n\n        if len(pred_boxes[i]) > 0:\n            xscale = image_width / SZ\n            yscale = image_height / SZ\n            pred_boxes[i][:, [0, 2]] = (pred_boxes[i][:, [0, 2]] * xscale).astype(int)\n            pred_boxes[i][:, [1, 3]] = (pred_boxes[i][:, [1, 3]] * yscale).astype(int)\n\n    all_folds_boxes.append(pred_boxes)\n    all_folds_scores.append(pred_scores)\n    all_folds_labels.append(pred_labels)\n    \n    \nresult_boxes, result_scores, result_labels = merge_boxes_from_models(\n    all_folds_boxes, all_folds_scores, all_folds_labels, \n    n_images=len(image_ids), weights=None, iou_thr=0.60, conf_type='avg')\n\nd3_preds = write_submission(image_ids, result_boxes, result_scores, result_labels, score_thr=0.0001)\nd3_preds.to_csv('efdet2_sub1.csv',index=False)\nd3_preds.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:06:56.645025Z","iopub.execute_input":"2021-08-08T06:06:56.645403Z","iopub.status.idle":"2021-08-08T06:06:58.383392Z","shell.execute_reply.started":"2021-08-08T06:06:56.645365Z","shell.execute_reply":"2021-08-08T06:06:58.382364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagenames = image_df.image_path.values.tolist()\nimage_ids  = L(imagenames).map(lambda x: x.split(os.path.sep)[-1].split('.')[0] + '_image')\n\ndef collate_fn(batch): return tuple(zip(*batch))\n\nstates1 = [\n    '../input/covid-models-new/d5_stage1/model_best_d5_fold0_5698.pth.tar',\n    '../input/covid-models-new/model_best_d5_fold1_5654_stage2.pth.tar',\n    '../input/covid-models-new/model_best_d5_fold2_6040_stage2.pth.tar',\n    '../input/covid-models-new/d5_stage1/model_best_d5_fold3_5577.pth.tar',\n    '../input/covid-models-new/d5_stage1/model_best_d5_fold4_6100.pth.tar'\n]\n    \nMODEL = 'tf_efficientdet_d5_ap'\nbase_conf = get_efficientdet_config(MODEL)\nSZ = 512\nprint(\"Image dims:\", SZ)\n    \ntest_transforms = pre_processing(SZ, norm=None)\n\nds = LoadDetectionDatset(imagenames, test_transforms, img_size=[SZ, SZ])\ndl = DataLoader(ds, batch_size=6, collate_fn=collate_fn)\n\npredictions = []\nfor i in tqdm(states1, dynamic_ncols=True):\n    bench = create_det(\n        model_name=MODEL, bench_task='predict', \n        num_classes=1, bench_labeler=True,\n        soft_nms=False, pretrained_backbone=False, \n        image_size = [SZ,SZ])\n    \n    load_checkpoint(unwrap_bench(bench), i, use_ema=True)\n    bench.cuda()\n    bench.eval() \n    \n    preds = make_predictions(dl, bench)\n    predictions.append(preds)\n    \n    del bench, preds\n    gc.collect()\n    torch.cuda.empty_cache()\n    \ndel ds, dl\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:07:07.46199Z","iopub.execute_input":"2021-08-08T06:07:07.46234Z","iopub.status.idle":"2021-08-08T06:07:46.481953Z","shell.execute_reply.started":"2021-08-08T06:07:07.462305Z","shell.execute_reply":"2021-08-08T06:07:46.480713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_folds_boxes  = []\nall_folds_scores = []\nall_folds_labels = []\n\nfor prediction in tqdm(predictions, smoothing=0, dynamic_ncols=True,):\n    pred_boxes = []; pred_scores = []; pred_labels = []\n\n    for image_index in image_ids:\n        pred_boxes.append(prediction[image_index]['boxes'].tolist()) \n        pred_scores.append(prediction[image_index]['scores'].tolist())\n        pred_labels.append(np.ones(prediction[image_index]['scores'].shape[0]).tolist())\n    pred_boxes, pred_scores, pred_labels = np.array(pred_boxes), np.array(pred_scores), np.array(pred_labels)\n\n    for i, image in enumerate(image_ids):\n        image_id = image_ids[i]\n        image_height, image_width = image_df.loc[image_df.image_id == image_id, ['dim0', 'dim1']].values[0]\n\n        if len(pred_boxes[i]) > 0:\n            xscale = image_width / SZ\n            yscale = image_height / SZ\n            pred_boxes[i][:, [0, 2]] = (pred_boxes[i][:, [0, 2]] * xscale).astype(int)\n            pred_boxes[i][:, [1, 3]] = (pred_boxes[i][:, [1, 3]] * yscale).astype(int)\n\n    all_folds_boxes.append(pred_boxes)\n    all_folds_scores.append(pred_scores)\n    all_folds_labels.append(pred_labels)\n    \n    \nresult_boxes, result_scores, result_labels = merge_boxes_from_models(\n    all_folds_boxes, all_folds_scores, all_folds_labels, \n    n_images=len(image_ids), weights=None, iou_thr=0.60, conf_type='avg')\n\nd5_preds = write_submission(image_ids, result_boxes, result_scores, result_labels, score_thr=0.0001)\nd5_preds.to_csv('efdet2_sub2.csv',index=False)\nd5_preds.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:07:46.483793Z","iopub.execute_input":"2021-08-08T06:07:46.484245Z","iopub.status.idle":"2021-08-08T06:07:47.736098Z","shell.execute_reply.started":"2021-08-08T06:07:46.4842Z","shell.execute_reply":"2021-08-08T06:07:47.734813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## + Yolov5 Models\n- yolov5l6_640_psuedo\n- yolov5x_640_psuedo","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/simmyolov5/')\n\nSUB_DIR_1 = '/kaggle/tmp/sub/'\nSUB_DIR_2 = '/kaggle/tmp/sub2/'\n\nos.makedirs(SUB_DIR_1, exist_ok=True)\nos.makedirs(SUB_DIR_2, exist_ok=True)\nos.makedirs('/kaggle/working/subm', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:07:52.610689Z","iopub.execute_input":"2021-08-08T06:07:52.611026Z","iopub.status.idle":"2021-08-08T06:07:52.618001Z","shell.execute_reply.started":"2021-08-08T06:07:52.610996Z","shell.execute_reply":"2021-08-08T06:07:52.617027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def txt2pandas(Idxs, fold,num,sub):\n    image_ids = []\n    PredictionStrings = []\n    \n    for Idx in tqdm(Idxs, dynamic_ncols=True):\n        H,W = image_df.loc[image_df.image_id == Idx, ['dim0', 'dim1']].values[0]\n        Idx = Idx.split('_')[0]\n        txt_label = os.path.join(sub, f'fold{fold}/labels/{Idx}.txt')\n        bboxes = []\n    \n        if os.path.isfile(txt_label):\n            in1 = open(txt_label, 'r')\n            lines = in1.readlines()\n            in1.close()\n\n            for line in lines:\n                arr = line.strip().split(' ')\n                class_id = 'opacity'\n                x = float(arr[1])\n                y = float(arr[2])\n                w = float(arr[3])\n                h = float(arr[4])\n                x1 = x - (w / 2)  \n                x2 = x + (w / 2)    \n                y1 = y - (h / 2)\n                y2 = y + (h / 2)\n                conf = arr[5]\n\n                x1 = int(round(x1 * W))\n                y1 = int(round(y1 * H))\n                x2 = int(round(x2 * W))\n                y2 = int(round(y2 * H))\n\n                bboxes.append(f\"{class_id} {conf} {x1} {y1} {x2} {y2}\")\n        else:\n            print(txt_label)\n            class_id = 'none'\n            conf = 1.0\n            [x1, y1, x2, y2] = [0, 0, 1, 1]\n            bboxes.append(f\"{class_id} {conf} {x1} {y1} {x2} {y2}\")\n\n        image_ids.append(Idx)\n        PredictionStrings.append(' '.join(bboxes))\n    \n    detections = pd.DataFrame()    \n    detections['image_id'] = image_ids\n    detections['image_id'] = detections['image_id'].map(lambda x: x + '_image')\n    detections['PredictionString'] = PredictionStrings\n    detections.to_csv(f'/kaggle/working/subm/yolo_fold{fold}{num}.csv', index=False)\n    print(f'Dataframe saved to /kaggle/working/subm/yolo_fold{fold}{num}.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:07:53.761415Z","iopub.execute_input":"2021-08-08T06:07:53.761746Z","iopub.status.idle":"2021-08-08T06:07:53.77467Z","shell.execute_reply.started":"2021-08-08T06:07:53.761715Z","shell.execute_reply":"2021-08-08T06:07:53.77355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5l6_640_psuedo/yolov5l6_640_fold0.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold0\n\n!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5l6_640_psuedo/yolov5l6_640_fold1.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold1\n\n!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5l6_640_psuedo/yolov5l6_640_fold2.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold2\n\n!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5l6_640_psuedo/yolov5l6_640_fold3.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold3\n\n!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5l6_640_psuedo/yolov5l6_640_fold4.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold4\n\n\nIdxs = image_df.image_id.values.tolist()\nfor i in range(0, 5):  txt2pandas(Idxs, i,0,SUB_DIR_1)\n!rm -r {SUB_DIR_1}","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-08T06:07:57.211777Z","iopub.execute_input":"2021-08-08T06:07:57.212109Z","iopub.status.idle":"2021-08-08T06:08:54.639975Z","shell.execute_reply.started":"2021-08-08T06:07:57.212075Z","shell.execute_reply":"2021-08-08T06:08:54.638939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5x_640_psuedo/yolov5x_640_fold0.pt  \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold0\n\n!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5x_640_psuedo/yolov5x_640_fold1.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold1\n\n!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5x_640_psuedo/yolov5x_640_fold2.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold2\n\n!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5x_640_psuedo/yolov5x_640_fold3.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold3\n\n!python /kaggle/input/simmyolov5/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ../input/psuedo-models-covid/yolov5x_640_psuedo/yolov5x_640_fold4.pt  \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold4\n\nfor i in range(0, 5): txt2pandas(Idxs, i,1, SUB_DIR_2)  \n    \n!rm -r {SUB_DIR_2}","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-08T06:08:54.643958Z","iopub.execute_input":"2021-08-08T06:08:54.644289Z","iopub.status.idle":"2021-08-08T06:09:42.954291Z","shell.execute_reply.started":"2021-08-08T06:08:54.644244Z","shell.execute_reply":"2021-08-08T06:09:42.953127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@delegates(weighted_boxes_fusion)\ndef run_wbf(subm_list, out_path=None, **kwargs):\n    max_value = 10000\n    preds   = []\n    checker = None\n    \n    for path in subm_list:\n        s = pd.read_csv(path)\n        s.sort_values('image_id', inplace=True)\n        s.reset_index(drop=True, inplace=True)\n        ids = s['image_id']\n        if checker:\n            if tuple(ids) != checker:\n                print(set(checker) - set(ids))\n                print('Different IDS!', len(tuple(ids)), path)\n                exit()\n        else:\n            checker = tuple(ids)\n        preds.append(s['PredictionString'].values)\n\n    if out_path is None:\n        out_path = '/kaggle/working/' + 'ensemble_iou_{}.csv'.format(iou_same)\n    \n    out = open(out_path, 'w')\n    \n    out.write('image_id,PredictionString\\n')\n    \n    for j, id in enumerate(tqdm(list(checker))):\n        \n        boxes_list = []\n        scores_list = []\n        labels_list = []\n        empty = True\n        for i in range(len(preds)):\n            boxes = []\n            scores = []\n            labels = []\n            p1 = preds[i][j]\n            if str(p1) != 'nan':\n                arr = p1.strip().split(' ')\n                for k in range(0, len(arr), 6):\n                    cls = 1 if arr[k] == 'opacity' else 0\n                    prob = float(arr[k + 1])\n                    x1 = float(arr[k + 2]) / max_value\n                    y1 = float(arr[k + 3]) / max_value\n                    x2 = float(arr[k + 4]) / max_value\n                    y2 = float(arr[k + 5]) / max_value\n                    boxes.append([x1, y1, x2, y2])\n                    scores.append(prob)\n                    labels.append(cls)\n\n            boxes_list.append(boxes)\n            scores_list.append(scores)\n            labels_list.append(labels)\n\n        boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, **kwargs)\n\n        if len(boxes) == 0:\n            out.write('{},none 1 0 0 1 1\\n'.format(id, ))\n        else:\n            final_str = ''\n            for i in range(len(boxes)):\n                cls = int(labels[i])\n                prob = scores[i]\n                x1 = int(boxes[i][0] * max_value)\n                y1 = int(boxes[i][1] * max_value)\n                x2 = int(boxes[i][2] * max_value)\n                y2 = int(boxes[i][3] * max_value)\n                if cls == 0:\n                    final_str += '{} {} {} {} {} {} '.format('none', prob, 0, 0, 1, 1)\n                else:\n                    final_str += '{} {} {} {} {} {} '.format('opacity', prob, x1, y1, x2, y2)\n            out.write('{},{}\\n'.format(id, final_str.strip()))\n\n    out.close()\n    print(f\"Results ---> {out_path}\")\n    return out_path","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:10:13.396007Z","iopub.execute_input":"2021-08-08T06:10:13.39637Z","iopub.status.idle":"2021-08-08T06:10:13.419575Z","shell.execute_reply.started":"2021-08-08T06:10:13.396337Z","shell.execute_reply":"2021-08-08T06:10:13.418335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm_list1 = [\n    '/kaggle/working/subm/yolo_fold00.csv',\n    '/kaggle/working/subm/yolo_fold10.csv',\n    '/kaggle/working/subm/yolo_fold20.csv',\n    '/kaggle/working/subm/yolo_fold30.csv',\n    '/kaggle/working/subm/yolo_fold40.csv'\n]\n\nsubm_list2 = [\n    '/kaggle/working/subm/yolo_fold01.csv',\n    '/kaggle/working/subm/yolo_fold11.csv',\n    '/kaggle/working/subm/yolo_fold21.csv',\n    '/kaggle/working/subm/yolo_fold31.csv',\n    '/kaggle/working/subm/yolo_fold41.csv'\n]\n\n\nrun_wbf(subm_list1, out_path='/kaggle/working/yolo_v5_sub1.csv',  iou_thr=0.60)\nrun_wbf(subm_list2, out_path='/kaggle/working/yolo_v5_sub2.csv',  iou_thr=0.60)\n\nyolo_sub1 = pd.read_csv('/kaggle/working/yolo_v5_sub1.csv' )\nyolo_sub2 = pd.read_csv('/kaggle/working/yolo_v5_sub2.csv' )","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:10:14.839075Z","iopub.execute_input":"2021-08-08T06:10:14.839476Z","iopub.status.idle":"2021-08-08T06:10:16.042793Z","shell.execute_reply.started":"2021-08-08T06:10:14.839441Z","shell.execute_reply":"2021-08-08T06:10:16.041814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## + MMdetection (retinanet_x101_64x4d_fpn)","metadata":{}},{"cell_type":"code","source":"import mmdet\nimport mmcv\n\nfrom mmcv import Config\nfrom mmcv.runner import load_checkpoint\nfrom mmdet.apis import set_random_seed, inference_detector, \\\n     init_detector, show_result_pyplot, single_gpu_test\nfrom mmdet.datasets import build_dataset, build_dataloader\nfrom mmdet.models import build_detector","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:10:17.199457Z","iopub.execute_input":"2021-08-08T06:10:17.199787Z","iopub.status.idle":"2021-08-08T06:10:36.21939Z","shell.execute_reply.started":"2021-08-08T06:10:17.199755Z","shell.execute_reply":"2021-08-08T06:10:36.218357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_cfg_path = \"../input/detsiim/retinanet_x101_64x4d_fpn_without_empty/fold0/retinanet_x101_64x4d_fpn_siim_fold0.py\"\ncfg = Config.fromfile(baseline_cfg_path)\n\nWEIGHTS_FILES = [\n    \"../input/detsiim/retinanet_x101_64x4d_fpn_without_empty/fold0/best_bbox_mAP_50_epoch_12.pth\",\n    \"../input/detsiim/retinanet_x101_64x4d_fpn_without_empty/fold1/best_bbox_mAP_50_epoch_8.pth\",\n    \"../input/detsiim/retinanet_x101_64x4d_fpn_without_empty/fold2/best_bbox_mAP_50_epoch_10.pth\",\n    \"../input/detsiim/retinanet_x101_64x4d_fpn_without_empty/fold3/best_bbox_mAP_50_epoch_14.pth\",\n    \"../input/detsiim/retinanet_x101_64x4d_fpn_without_empty/fold4/best_bbox_mAP_50_epoch_7.pth\",\n]\n\nassert [os.path.isfile(w) for w in WEIGHTS_FILES]","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:10:36.224225Z","iopub.execute_input":"2021-08-08T06:10:36.226454Z","iopub.status.idle":"2021-08-08T06:10:36.267608Z","shell.execute_reply.started":"2021-08-08T06:10:36.226395Z","shell.execute_reply":"2021-08-08T06:10:36.266622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_threshold = cfg.model.test_cfg.score_thr\n\ndef format_pred(boxes: np.ndarray, scores: np.ndarray, labels: np.ndarray) -> str:\n    pred_strings = []\n    for label, score, bbox in zip(labels, scores, boxes):\n        xmin, ymin, xmax, ymax = bbox.astype(np.int64)\n        pred_strings.append(f\"opacity {score:.16f} {xmin} {ymin} {xmax} {ymax}\")\n    return \" \".join(pred_strings)\n\nfor i, weights in enumerate(tqdm(WEIGHTS_FILES,  dynamic_ncols=True)):\n    results = []\n    model = init_detector(cfg, weights, device='cuda:0')\n    model.eval()\n\n    with torch.no_grad():\n        for index, row in tqdm(image_df.iterrows(), total=image_df.shape[0], dynamic_ncols=True):\n            original_H, original_W = (int(row.dim0), int(row.dim1))\n            predictions = inference_detector(model, row.image_path)\n            boxes, scores, labels = (list(), list(), list())\n\n            for k, cls_result in enumerate(predictions):\n                if cls_result.size != 0:\n                    if len(labels) == 0:\n                        boxes  = np.array(cls_result[:, :4])\n                        scores = np.array(cls_result[:, 4])\n                        labels = np.array([k]*len(cls_result[:, 4]))\n                    else:    \n                        boxes  = np.concatenate((boxes, np.array(cls_result[:, :4])))\n                        scores = np.concatenate((scores, np.array(cls_result[:, 4])))\n                        labels = np.concatenate((labels, [k]*len(cls_result[:, 4])))\n                    \n            indexes = np.where(scores > score_threshold)\n            boxes   = boxes[indexes]\n            scores  = scores[indexes]\n            labels  = labels[indexes]\n            \n            IMAGE_DIMS = cv2.imread(row.image_path).shape[:2]\n\n            if len(labels) != 0:\n                h_ratio = original_H/IMAGE_DIMS[0]\n                w_ratio = original_W/IMAGE_DIMS[1]\n                boxes[:, [0, 2]] *= w_ratio\n                boxes[:, [1, 3]] *= h_ratio\n                result = {\"image_id\": row.image_id, \"PredictionString\": format_pred(boxes, scores, labels)}\n                results.append(result)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n    detection_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n    detection_df.to_csv(f'retinanet_x101_64x4d_fpn_fold_{i}.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:10:36.272626Z","iopub.execute_input":"2021-08-08T06:10:36.274813Z","iopub.status.idle":"2021-08-08T06:11:27.253952Z","shell.execute_reply.started":"2021-08-08T06:10:36.274765Z","shell.execute_reply":"2021-08-08T06:11:27.252946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retina_subs = [\n    '/kaggle/working/retinanet_x101_64x4d_fpn_fold_0.csv',\n    '/kaggle/working/retinanet_x101_64x4d_fpn_fold_1.csv',\n    '/kaggle/working/retinanet_x101_64x4d_fpn_fold_2.csv',\n    '/kaggle/working/retinanet_x101_64x4d_fpn_fold_3.csv',\n    '/kaggle/working/retinanet_x101_64x4d_fpn_fold_4.csv',\n]\n\n\nrun_wbf(retina_subs, out_path='/kaggle/working/retinanet_x101_64x4d_fpn_sub.csv',  iou_thr=0.60)\nretinanet_sub = pd.read_csv('/kaggle/working/retinanet_x101_64x4d_fpn_sub.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:11:30.490964Z","iopub.execute_input":"2021-08-08T06:11:30.49133Z","iopub.status.idle":"2021-08-08T06:11:30.801037Z","shell.execute_reply.started":"2021-08-08T06:11:30.491289Z","shell.execute_reply":"2021-08-08T06:11:30.797175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merge all Image Level (Detection) Predictions","metadata":{}},{"cell_type":"code","source":"@delegates(weighted_boxes_fusion)\ndef merge_boxes_from_models(test_files, test_filenames, **kwargs):\n    n_images   = len(test_filenames)\n    n_variants = len(test_files)\n\n    result_boxes = []\n    result_scores = []\n    result_labels = []\n    for ii in tqdm(range(n_images), dynamic_ncols=True):\n        image_id = test_filenames[ii]\n        pred_variants = pred_locations[image_id]\n        assert len(pred_variants) == n_variants\n\n        pred_boxes = []\n        pred_scores = []\n        pred_labels = []\n        max_value = 10000\n        for vi in range(n_variants):\n            if len(pred_variants[vi]) > 0:\n                cur_pred_labels, cur_pred_scores, cur_pred_boxes = list(zip(*pred_variants[vi]))\n            else:\n                cur_pred_labels = []\n                cur_pred_scores = []\n                cur_pred_boxes = []\n            cur_pred_boxes = np.array(cur_pred_boxes, copy=False)\n            cur_pred_scores = np.array(cur_pred_scores, copy=False)\n            cur_pred_labels = np.array(cur_pred_labels, copy=False)\n\n            # WBF expects the coordinates in 0-1 range.\n            cur_pred_boxes = cur_pred_boxes / max_value\n\n            pred_boxes.append(cur_pred_boxes)\n            pred_scores.append(cur_pred_scores)\n            pred_labels.append(cur_pred_labels)\n\n        pred_boxes, pred_scores, pred_labels = weighted_boxes_fusion(pred_boxes, pred_scores, pred_labels, **kwargs)\n        pred_boxes = np.round(pred_boxes * max_value).astype(int)\n\n        assert len(pred_boxes) == len(pred_scores)\n        assert len(pred_boxes) == len(pred_scores)\n        assert len(pred_boxes) == len(pred_labels)\n        result_boxes.append(pred_boxes)\n        result_scores.append(pred_scores)\n        result_labels.append(pred_labels)\n\n    return result_boxes, result_scores, result_labels","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:11:32.575644Z","iopub.execute_input":"2021-08-08T06:11:32.575972Z","iopub.status.idle":"2021-08-08T06:11:32.58708Z","shell.execute_reply.started":"2021-08-08T06:11:32.575941Z","shell.execute_reply":"2021-08-08T06:11:32.586072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_files = [\n    './efdet2_sub1.csv', \n    './efdet2_sub2.csv',  \n    './yolo_v5_sub1.csv', \n    './yolo_v5_sub2.csv', \n    './retinanet_x101_64x4d_fpn_sub.csv'\n]\n\nprint('# models', len(test_files))\nprint(test_files)\n\npred_locations = {}\n\nfor model_index in range(len(test_files)):\n    # load table\n    with open(test_files[model_index], mode='r') as infile:\n        # open reader\n        reader = csv.reader(infile)\n        # skip header\n        next(reader, None)\n        # loop through rows\n        for rows in reader:\n            # retrieve information\n            filename = rows[0]\n            # print(rows[0])\n            parts = rows[1].split()\n            # print(parts)\n            assert len(parts) % 6 == 0\n            locations = []\n            for ind in range(len(parts) // 6):\n                #label = int(parts[ind * 6])\n                label = parts[ind * 6]\n                label = 1 if label == 'opacity' else 0\n                score = float(parts[ind * 6 + 1])\n                location = int(float(parts[ind * 6 + 2])), int(float(parts[ind * 6 + 3])), \\\n                           int(float(parts[ind * 6 + 4])), int(float(parts[ind * 6 + 5]))\n                if score > 0 and label < 14:\n                    locations.append((label, score, location))\n            if filename in pred_locations:\n                pred_locations[filename].append(locations)\n            else:\n                pred_locations[filename] = [locations]\n                \n                \ntest_filenames = [*pred_locations]\ntest_filenames.sort()\n\nresult_boxes, result_scores, result_labels = merge_boxes_from_models(\n    test_files, test_filenames, weights=[0.22,0.23,0.25,0.2,0.1], \n    iou_thr=0.625, conf_type='avg', allows_overflow=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:11:36.703235Z","iopub.execute_input":"2021-08-08T06:11:36.703627Z","iopub.status.idle":"2021-08-08T06:11:38.867671Z","shell.execute_reply.started":"2021-08-08T06:11:36.703595Z","shell.execute_reply":"2021-08-08T06:11:38.866781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission for opactity only","metadata":{}},{"cell_type":"code","source":"image_df = write_submission(test_filenames, result_boxes, result_scores, result_labels, 0)\nimage_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:11:40.769596Z","iopub.execute_input":"2021-08-08T06:11:40.769941Z","iopub.status.idle":"2021-08-08T06:11:40.79377Z","shell.execute_reply.started":"2021-08-08T06:11:40.76991Z","shell.execute_reply":"2021-08-08T06:11:40.792954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add Binary None Predictions to Image Level (Opacity) Predictions","metadata":{}},{"cell_type":"code","source":"image_preds_df = pd.merge(image_df, binary_submission, on='image_id')\nimage_preds_df = image_preds_df.drop(columns=['study_id'])\nimage_preds_df.columns = ['id', 'PredictionString', 'none']\nimage_preds_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:13:28.409813Z","iopub.execute_input":"2021-08-08T06:13:28.410162Z","iopub.status.idle":"2021-08-08T06:13:28.427836Z","shell.execute_reply.started":"2021-08-08T06:13:28.410129Z","shell.execute_reply":"2021-08-08T06:13:28.426934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(range(0,image_preds_df.shape[0])):\n    if image_preds_df.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n        image_preds_df.loc[i,'PredictionString']='none 1 0 0 1 1'\n        continue\n    \n    image_split = image_preds_df.loc[i,'PredictionString'].split()\n    binary_none = image_preds_df.loc[i,'none']\n    image_df_list = []\n    preds_for_none = 0\n    final_image = []\n    \n    for j in range(int(len(image_split) / 6)):\n        if j==0:\n            preds_for_none = 1 - ((float(image_split[6 * j + 1])**0.20)*(1-binary_none)**0.80)\n        else:\n            preds_for_none = preds_for_none\n\n        image_df_list.append([\n            'opacity',\n            (float(image_split[6 * j + 1])**0.80)*(1-binary_none)**0.20,\n            image_split[6 * j + 2],\n            image_split[6 * j + 3],\n            image_split[6 * j + 4],\n            image_split[6 * j + 5]\n        ])\n    image_df_list = sorted(image_df_list, key = lambda x: x[1], reverse=True)\n    for k in range(len(image_df_list)):\n        image_df_list[k][1] = str(image_df_list[k][1])\n        final_image.extend(image_df_list[k])\n\n    image_preds_df.loc[i,'PredictionString'] = ' '.join(final_image)\n\n    image_preds_df.loc[i,'PredictionString'] = image_preds_df.loc[i,'PredictionString'] + ' none ' + \\\n    str(preds_for_none) + ' 0 0 1 1'\n    image_preds_df.loc[i,'none'] = preds_for_none","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:15:10.905944Z","iopub.execute_input":"2021-08-08T06:15:10.906472Z","iopub.status.idle":"2021-08-08T06:15:11.037183Z","shell.execute_reply.started":"2021-08-08T06:15:10.906423Z","shell.execute_reply":"2021-08-08T06:15:11.036169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df = image_preds_df[['id','PredictionString']].copy()\nimage_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:15:14.964139Z","iopub.execute_input":"2021-08-08T06:15:14.96454Z","iopub.status.idle":"2021-08-08T06:15:14.97753Z","shell.execute_reply.started":"2021-08-08T06:15:14.964506Z","shell.execute_reply":"2021-08-08T06:15:14.976402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Final Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.concat([study_df[['id','PredictionString']],image_df],axis=0)\nsubmission = submission[['id','PredictionString']]\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:15:42.266028Z","iopub.execute_input":"2021-08-08T06:15:42.266377Z","iopub.status.idle":"2021-08-08T06:15:42.282487Z","shell.execute_reply.started":"2021-08-08T06:15:42.266345Z","shell.execute_reply":"2021-08-08T06:15:42.281505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.tail()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:15:44.642868Z","iopub.execute_input":"2021-08-08T06:15:44.643215Z","iopub.status.idle":"2021-08-08T06:15:44.657085Z","shell.execute_reply.started":"2021-08-08T06:15:44.643183Z","shell.execute_reply":"2021-08-08T06:15:44.656235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r /kaggle/working/\n!rm -r /kaggle/tmp/","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:16:32.502669Z","iopub.execute_input":"2021-08-08T06:16:32.503017Z","iopub.status.idle":"2021-08-08T06:16:32.947692Z","shell.execute_reply.started":"2021-08-08T06:16:32.502987Z","shell.execute_reply":"2021-08-08T06:16:32.946557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T06:16:34.120166Z","iopub.execute_input":"2021-08-08T06:16:34.120552Z","iopub.status.idle":"2021-08-08T06:16:34.134323Z","shell.execute_reply.started":"2021-08-08T06:16:34.120515Z","shell.execute_reply":"2021-08-08T06:16:34.133439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}