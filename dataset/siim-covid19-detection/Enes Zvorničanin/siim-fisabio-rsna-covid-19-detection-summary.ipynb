{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import HTML\nimport glob\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport math\nimport ast\nimport cv2\n\ndef css_styling():\n    styles = open(\"../input/titlestyle/style2.css\", \"r\").read()\n    return HTML(styles)\ncss_styling()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-10T19:02:02.263683Z","iopub.execute_input":"2021-08-10T19:02:02.264086Z","iopub.status.idle":"2021-08-10T19:02:02.788835Z","shell.execute_reply.started":"2021-08-10T19:02:02.263995Z","shell.execute_reply":"2021-08-10T19:02:02.78793Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"heading\">\n   <h1><span style=\"color: white\">Intro</span></h1>\n</div>\n<div class=\"content\">\n\n<u>üìî Public notebooks - 546+</u><br>\n\n<u>ü•á Gold medals - 26+</u><br>\n\n<u>ü•à Silver medals - 40+</u><br>\n\n<u>ü•â Bronze medals - 94+</u><br>\n    \n1Ô∏è place solution - <a href=\"https://www.kaggle.com/c/siim-covid19-detection/discussion/263658\">https://www.kaggle.com/c/siim-covid19-detection/discussion/263658</a><br>\n    \n2Ô∏è place solution - <a href=\"https://www.kaggle.com/c/siim-covid19-detection/discussion/263674\">https://www.kaggle.com/c/siim-covid19-detection/discussion/263674</a><br>\n    \n3Ô∏è place solution - <a href=\"https://www.kaggle.com/c/siim-covid19-detection/discussion/263654\">https://www.kaggle.com/c/siim-covid19-detection/discussion/263654</a><br>\n\n\nWordcloud made of notebook titles:\n<img src=\"https://i.imgur.com/S3I8ap4.png\" alt=\"img1\"/>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style = \"font-family: Arial;font-size:1.6em;color: #0a6121;background: #ace6bc;padding:5px;border-style: solid;border-color:#0a6121;\">\n<b>Summa summarum: EfficientNet, YOLOv5 and dicom files</b> \n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"heading\">\n   <h1><span style=\"color: white\">Goal</span></h1>\n</div>\n<div class='content'>\n    <h3><b>üò∑ Categorize chest radiographs as negative for pneumonia, typical, indeterminate, or atypical for COVID-19. If some abnormalities are found, provide the bounding boxes.</b> </h3>\n    <h3><b>üò∑ Image can have positive value for only one label but multiple bounding boxes. This competition is both object detection and classification</b></h3>\n</div>","metadata":{}},{"cell_type":"code","source":"train_study = pd.read_csv(\"../input/siim-covid19-detection/train_study_level.csv\")\ntrain_image = pd.read_csv(\"../input/siim-covid19-detection/train_image_level.csv\")\ntrain_study.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:40:58.484828Z","iopub.execute_input":"2021-08-10T14:40:58.48559Z","iopub.status.idle":"2021-08-10T14:40:58.584477Z","shell.execute_reply.started":"2021-08-10T14:40:58.485531Z","shell.execute_reply":"2021-08-10T14:40:58.583175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T14:41:01.969937Z","iopub.execute_input":"2021-08-10T14:41:01.970378Z","iopub.status.idle":"2021-08-10T14:41:01.987441Z","shell.execute_reply.started":"2021-08-10T14:41:01.97034Z","shell.execute_reply":"2021-08-10T14:41:01.985449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fix_inverted_radiograms(data, img):\n    '''Fixes inverted radiograms - with PhotometricInterpretation == \"MONOCHROME1\"\n    data: the .dcm dataset\n    img: the .dcm pixel_array'''\n    \n    if data.PhotometricInterpretation == \"MONOCHROME1\":\n        img = np.amax(img) - img\n    \n    img = img - np.min(img)\n    img = img / np.max(img)\n    img = (img * 255).astype(np.uint8)\n    \n    return img\n\ndef get_image_metadata(study_id, df):\n    '''Returns the label and bounding boxes (if any)\n    for a speciffic study id.'''\n    \n    data = df[df[\"study_id\"] == study_id]\n    \n    if data[\"Negative for Pneumonia\"].values == 1:\n        label = \"negative_for_pneumonia\"\n    elif data[\"Typical Appearance\"].values == 1:\n        label = \"typical\"\n    elif data[\"Indeterminate Appearance\"].values == 1:\n        label = \"indeterminate\"\n    else:\n        label = \"atypical\"\n        \n    bbox = list(data[\"boxes\"].values)\n    \n    return label, bbox\n\ndef return_coords(box):\n    '''Returns coordinates from a bbox'''\n    # Get the list of dictionaries\n    box = ast.literal_eval(box)[0]\n    # Get the exact x and y coordinates\n    x1, y1, x2, y2 = box[\"x\"], box[\"y\"], box[\"x\"] + box[\"width\"], box[\"y\"] + box[\"height\"]\n    # Save coordinates\n    return (int(x1), int(y1), int(x2), int(y2))\n\ndef show_dcm_info(study_ids, df):\n    '''Show .dcm images along with description.'''\n    \n    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(21,10))\n\n    # Get .dcm paths\n    dcm_paths = [glob.glob(f\"../input/siim-covid19-detection/train/{study_id}/*/*\")[0]\n                 for study_id in study_ids]\n    datasets = [pydicom.dcmread(path) for path in dcm_paths]\n    images = [apply_voi_lut(dataset.pixel_array, dataset) for dataset in datasets]\n\n    # Loop through the information\n    for study_id, data, img, i in zip(study_ids, datasets, images, range(2*3)):\n        # Fix inverted images\n        img = fix_inverted_radiograms(data, img)\n\n        # Below function available in functions section ;)\n        label, bbox = get_image_metadata(study_id, df)\n        \n        # Check for bounding box and add if it's the case\n        try: \n            # For no bbox, the list is [nan]\n            no_box = math.isnan(bbox[0])\n            pass\n        except TypeError:\n            # Retrieve the bounding box\n            all_coords = []\n            for box in bbox:\n                all_coords.append(return_coords(box))\n\n            for (x1, y1, x2, y2) in all_coords:\n                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 80, 255), 15)\n                cv2.putText(img, label, (x1, y1-14), \n                            cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 0), 4)\n                \n        # Plot the image\n        x = i // 3\n        y = i % 3\n        \n        axes[x, y].imshow(img, cmap=\"binary\")\n        axes[x, y].set_title(f\"Label: {label} \\n Sex: {data.PatientSex} | Body Part: {data.BodyPartExamined}\", \n                  fontsize=14, weight='bold')\n        axes[x, y].axis('off')\n        \ntrain_study[\"study_id\"] = train_study[\"id\"].apply(lambda x: x.split(\"_\")[0])\ntrain = pd.merge(train_image, train_study, \n                 left_on=\"StudyInstanceUID\", right_on=\"study_id\")\n\ntrain.drop([\"id_x\", \"StudyInstanceUID\", \"id_y\"], axis=1, inplace=True)\n\nshow_dcm_info(study_ids=[\"72044bb44d41\", \"f807cd855d31\", \"b949689a9ef1\",\n                         \"612ea5194007\", \"082cafb03942\", \"d3e83031ebea\"], \n              df=train)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T13:26:53.664465Z","iopub.execute_input":"2021-08-10T13:26:53.66494Z","iopub.status.idle":"2021-08-10T13:27:05.070797Z","shell.execute_reply.started":"2021-08-10T13:26:53.664907Z","shell.execute_reply":"2021-08-10T13:27:05.069704Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dicom file example, it contains additional meta data\npydicom.dcmread('../input/siim-covid19-detection/train/72044bb44d41/c39be19d56ba/7452ddd5b44b.dcm')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T15:03:39.754393Z","iopub.execute_input":"2021-08-10T15:03:39.754905Z","iopub.status.idle":"2021-08-10T15:03:39.804654Z","shell.execute_reply.started":"2021-08-10T15:03:39.754857Z","shell.execute_reply":"2021-08-10T15:03:39.803445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"heading\">\n   <h1><span style=\"color: white\">Data preparation</span></h1>\n</div>\n<div class='content'>\n    \n<b>DICOM stands for Digital Imaging and Communications in Medicine</b>. It is a standard, internationally accepted format to view, store, retrieve and share medical images. This file consists of a header and image data sets packed into a single file. Notebook for preparing dicom files with extracting of meta data can be found here <a href=\"https://www.kaggle.com/andradaolteanu/siim-covid-19-box-detect-dcm-metadata\">https://www.kaggle.com/andradaolteanu/siim-covid-19-box-detect-dcm-metadata</a><br><br>\n    \n<b>Data augmentation</b> is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. Some methods such as random contrast, random crop, RGB shift and others are presented here <a href=\"https://www.kaggle.com/ruchi798/siim-covid-19-detection-eda-data-augmentation\">https://www.kaggle.com/ruchi798/siim-covid-19-detection-eda-data-augmentation</a><br><br>\n    \nImage preprocessing with ploting boxes <a href=\"https://www.kaggle.com/yujiariyasu/catch-up-on-positive-samples-plot-submission-csv\">https://www.kaggle.com/yujiariyasu/catch-up-on-positive-samples-plot-submission-csv</a><br><br>\n    \n    \nVery informative notebook with several <b>image transformation techniques including histogram equalization, CLAHE, noise reduction</b> <a href=\"https://www.kaggle.com/yujiariyasu/catch-up-on-positive-samples-plot-submission-csv\">https://www.kaggle.com/yujiariyasu/catch-up-on-positive-samples-plot-submission-csv</a><br><br>\n\nGreat notebook with lung <b>segmentation</b> and a list of other processing notebooks <a href=\"https://www.kaggle.com/davidbroberts/lung-segmentation-without-cnn\">https://www.kaggle.com/davidbroberts/lung-segmentation-without-cnn</a><br><br>\n    \n<b>Data augumentation using albumentations package</b> <a href=\"https://www.kaggle.com/boltcoder/siim-covid19-simple-data-augmentation-techniques\">https://www.kaggle.com/boltcoder/siim-covid19-simple-data-augmentation-techniques</a><br><br>\n    \n\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"heading\">\n   <h1><span style=\"color: white\">Models</span></h1>\n</div>\n<div class='content'>\n    \n<b>YOLO</b> an acronym for 'You only look once', is an object detection algorithm that divides images into a grid system. Each cell in the grid is responsible for detecting objects within itself. This model enables real-time object detection with convolutional neural networks. How to prepare data and run YOLOv5 is explained here <a href=\"https://www.kaggle.com/ayuraj/train-covid-19-detection-using-yolov5\">https://www.kaggle.com/ayuraj/train-covid-19-detection-using-yolov5</a><br><br>\n    \nConvert dicom to png and use <b>Efficientnet with Keras</b> for classification and YOLOv5 for detection <a href=\"https://www.kaggle.com/h053473666/siim-cov19-efnb7-yolov5-infer\">https://www.kaggle.com/h053473666/siim-cov19-efnb7-yolov5-infer</a><br><br>\n    \n<b>MMDetection</b> is an open-source toolbox based on PyTorch for Object Detection and Segmentation tasks. The toolbox supports over 50+ baselines. One of the models, CascadeRCNN is presented here <a href=\"https://www.kaggle.com/sreevishnudamodaran/siim-mmdetection-cascadercnn-weight-bias\">https://www.kaggle.com/sreevishnudamodaran/siim-mmdetection-cascadercnn-weight-bias</a><br><br>\n    \n<b>FasterRCNN</b> using PyTorch <a href=\"https://www.kaggle.com/piantic/train-siim-covid-19-detection-fasterrcnn\">https://www.kaggle.com/piantic/train-siim-covid-19-detection-fasterrcnn</a><br><br>\n    \nTraining several <b>EfficientNet models using TensorFlow</b> <a href=\"https://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-keras-study-train-tpu-cv0-805\">https://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-keras-study-train-tpu-cv0-805</a><br><br>\n    \n<b>EfficientNet using PyTorch and timm</b> <a href=\"https://www.kaggle.com/heyytanay/siim-pytorch-classification-only-training-effnets\">https://www.kaggle.com/heyytanay/siim-pytorch-classification-only-training-effnets</a><br><br>\n    \n<b>YOLOv5</b> object detection training with easy to follow explanation <a href=\"https://www.kaggle.com/ammarnassanalhajali/covid-19-detection-yolov5-3classes-training\">https://www.kaggle.com/ammarnassanalhajali/covid-19-detection-yolov5-3classes-training</a><br><br>\n    \n    \n<b>Vision Transformer with Grad-CAM algorithm</b> used to interpret prediction of the model <a href=\"https://www.kaggle.com/basu369victor/covid19-detection-with-vit-and-heatmap\">https://www.kaggle.com/basu369victor/covid19-detection-with-vit-and-heatmap</a> and one more notebook with Grad-CAM <a href=\"https://www.kaggle.com/sinamhd9/where-s-your-model-looking-at-grad-cam\">https://www.kaggle.com/sinamhd9/where-s-your-model-looking-at-grad-cam</a>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<!-- <div class=\"heading\">\n   <h1><span style=\"color: white\">Transformers</span></h1>\n</div>\n<div class='content'>\n</div> -->","metadata":{}},{"cell_type":"markdown","source":"<div class=\"heading\">\n   <h1><span style=\"color: white\">Other useful notebooks</span></h1>\n</div>\n<div class='content'>\nLoad 3D CT scans using dicom files and work with them <a href=\"https://www.kaggle.com/allunia/pulmonary-dicom-preprocessing\">https://www.kaggle.com/allunia/pulmonary-dicom-preprocessing</a>\n    \nConvert dicom to jpg <a href=\"https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px\">https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px</a>\n</div>","metadata":{}}]}