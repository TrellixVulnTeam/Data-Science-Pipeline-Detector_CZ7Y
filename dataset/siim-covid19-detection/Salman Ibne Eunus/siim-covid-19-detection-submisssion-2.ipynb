{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:17:50.974151Z","iopub.execute_input":"2021-06-19T15:17:50.974546Z","iopub.status.idle":"2021-06-19T15:18:54.817495Z","shell.execute_reply.started":"2021-06-19T15:17:50.974513Z","shell.execute_reply":"2021-06-19T15:18:54.816058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle')\n! pip install -e /kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle -q","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-19T15:18:54.823353Z","iopub.execute_input":"2021-06-19T15:18:54.823705Z","iopub.status.idle":"2021-06-19T15:19:26.693746Z","shell.execute_reply.started":"2021-06-19T15:18:54.823669Z","shell.execute_reply":"2021-06-19T15:19:26.692307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Packages","metadata":{}},{"cell_type":"code","source":"import os\nfrom glob import glob\nimport shutil\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport efficientnet.tfkeras as efn\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-19T15:19:26.698582Z","iopub.execute_input":"2021-06-19T15:19:26.698974Z","iopub.status.idle":"2021-06-19T15:19:26.708249Z","shell.execute_reply.started":"2021-06-19T15:19:26.69894Z","shell.execute_reply":"2021-06-19T15:19:26.706762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"debug=False\nIMG_SIZES = [[512, 512]]\nDIM=IMG_SIZES[0]\nTTA = 3\ndim = DIM[0]\naspect_ratio = False\nclass_labels = ['0', '1', '2', '3']\n\nsat  = (0.7, 1.3)\ncont = (0.8, 1.2)\nbri  =  0.1\nROT_    = 0.0\nSHR_    = 2.0\nHZOOM_  = 8.0\nWZOOM_  = 8.0\nHSHIFT_ = 8.0\nWSHIFT_ = 8.0","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:19:26.709996Z","iopub.execute_input":"2021-06-19T15:19:26.710445Z","iopub.status.idle":"2021-06-19T15:19:26.725691Z","shell.execute_reply.started":"2021-06-19T15:19:26.710397Z","shell.execute_reply":"2021-06-19T15:19:26.724491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Commit or Not","metadata":{}},{"cell_type":"code","source":"filepaths = glob('/kaggle/input/siim-covid19-detection/test/**/*dcm',recursive=True)\ntest_df = pd.DataFrame({'filepath':filepaths,})\ntest_df['image_id'] = test_df.filepath.map(lambda x: x.split('/')[-1].replace('.dcm', '')+'_image')\ntest_df['study_id'] = test_df.filepath.map(lambda x: x.split('/')[-3].replace('.dcm', '')+'_study')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:19:26.732106Z","iopub.execute_input":"2021-06-19T15:19:26.732691Z","iopub.status.idle":"2021-06-19T15:19:30.233833Z","shell.execute_reply.started":"2021-06-19T15:19:26.732654Z","shell.execute_reply":"2021-06-19T15:19:30.23282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('/kaggle/working/test', exist_ok = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:19:30.238151Z","iopub.execute_input":"2021-06-19T15:19:30.238507Z","iopub.status.idle":"2021-06-19T15:19:30.244287Z","shell.execute_reply.started":"2021-06-19T15:19:30.238475Z","shell.execute_reply":"2021-06-19T15:19:30.242972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# credit @raddar\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\ndef resize_and_save(file_path):\n    split = 'train' if 'train' in file_path else 'test'\n    base_dir = f'/kaggle/working/{split}'\n    img = read_xray(file_path)\n    h, w = img.shape[:2]  # orig hw\n    if aspect_ratio:\n        r = dim / max(h, w)  # resize image to img_size\n        interp = cv2.INTER_AREA if r < 1 else cv2.INTER_LINEAR\n        if r != 1:  # always resize down, only resize up if training with augmentation\n            img = cv2.resize(img, (int(w * r), int(h * r)), interpolation=interp)\n    else:\n        img = cv2.resize(img, (dim, dim), cv2.INTER_AREA)\n    filename = file_path.split('/')[-1].split('.')[0]\n    cv2.imwrite(os.path.join(base_dir, f'{filename}.jpg'), img)\n    return filename.replace('dcm','')+'_image',w, h\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:19:30.2467Z","iopub.execute_input":"2021-06-19T15:19:30.247534Z","iopub.status.idle":"2021-06-19T15:19:30.278925Z","shell.execute_reply.started":"2021-06-19T15:19:30.247487Z","shell.execute_reply":"2021-06-19T15:19:30.27705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepaths = test_df.filepath.iloc[:100 if debug else test_df.shape[0]]\ninfo = []\nfor filepath in tqdm(filepaths):\n    info.append(resize_and_save(filepath))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:19:30.28092Z","iopub.execute_input":"2021-06-19T15:19:30.281527Z","iopub.status.idle":"2021-06-19T15:26:37.129921Z","shell.execute_reply.started":"2021-06-19T15:19:30.281477Z","shell.execute_reply":"2021-06-19T15:26:37.128486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id, width, height = list(zip(*info))\ndf = pd.DataFrame({'image_id':image_id,\n                   'width':width,\n                   'height':height})\ndf['image_path'] = '/kaggle/working/test/'+df.image_id.map(lambda x: x.replace('_image',''))+'.jpg'\ntest_df = pd.merge(test_df, df, on = 'image_id', how = 'left')\ntest_df.loc[:,class_labels] = 0\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:26:37.131927Z","iopub.execute_input":"2021-06-19T15:26:37.132761Z","iopub.status.idle":"2021-06-19T15:26:37.180954Z","shell.execute_reply.started":"2021-06-19T15:26:37.132708Z","shell.execute_reply":"2021-06-19T15:26:37.179617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nimport math\ndef get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    shear    = math.pi * shear    / 180.\n\n    def get_3x3_mat(lst):\n        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n    \n    # ROTATION MATRIX\n    c1   = tf.math.cos(rotation)\n    s1   = tf.math.sin(rotation)\n    one  = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    \n    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n                                   -s1,  c1,   zero, \n                                   zero, zero, one])    \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)    \n    \n    shear_matrix = get_3x3_mat([one,  s2,   zero, \n                                zero, c2,   zero, \n                                zero, zero, one])        \n    # ZOOM MATRIX\n    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n                               zero,            one/width_zoom, zero, \n                               zero,            zero,           one])    \n    # SHIFT MATRIX\n    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n                                zero, one,  width_shift, \n                                zero, zero, one])\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), \n                 K.dot(zoom_matrix,     shift_matrix))\n\n\ndef transform(image, DIM=IMG_SIZES[0]):    \n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    \n    # fixed for non-square image thanks to Chris Deotte\n    \n    if DIM[0]!=DIM[1]:\n        pad = (DIM[0]-DIM[1])//2\n        image = tf.pad(image, [[0, 0], [pad, pad+1],[0, 0]])\n        \n    NEW_DIM = DIM[0]\n    \n    XDIM = NEW_DIM%2 #fix for size 331\n    \n    rot = ROT_ * tf.random.normal([1], dtype='float32')\n    shr = SHR_ * tf.random.normal([1], dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32') \n\n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x   = tf.repeat(tf.range(NEW_DIM//2, -NEW_DIM//2,-1), NEW_DIM)\n    y   = tf.tile(tf.range(-NEW_DIM//2, NEW_DIM//2), [NEW_DIM])\n    z   = tf.ones([NEW_DIM*NEW_DIM], dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n    idx2 = K.cast(idx2, dtype='int32')\n    idx2 = K.clip(idx2, -NEW_DIM//2+XDIM+1, NEW_DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack([NEW_DIM//2-idx2[0,], NEW_DIM//2-1+idx2[1,]])\n    d    = tf.gather_nd(image, tf.transpose(idx3))\n    \n    if DIM[0]!=DIM[1]:\n        image = tf.reshape(d,[NEW_DIM, NEW_DIM,3])\n        image = image[:, pad:DIM[1]+pad,:]\n    image = tf.reshape(image, [*DIM, 3])\n        \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:26:37.18332Z","iopub.execute_input":"2021-06-19T15:26:37.183819Z","iopub.status.idle":"2021-06-19T15:26:37.218144Z","shell.execute_reply.started":"2021-06-19T15:26:37.183771Z","shell.execute_reply":"2021-06-19T15:26:37.216419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy\n\n\ndef build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32)\n        img = tf.image.resize(img, target_size, method='area')\n#         img = tf.image.resize(img, target_size)\n        img = img/255.0\n\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), label\n    \n    return decode_with_labels if with_labels else decode\n\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = transform(img, DIM = DIM)\n        img = tf.image.random_flip_left_right(img)\n#         img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, sat[0], sat[1])\n        img = tf.image.random_contrast(img, cont[0], cont[1])\n        img = tf.image.random_brightness(img, bri)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\n\ndef build_dataset(paths, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO)\n    \n    return dset","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-19T15:26:37.220459Z","iopub.execute_input":"2021-06-19T15:26:37.220984Z","iopub.status.idle":"2021-06-19T15:26:37.251369Z","shell.execute_reply.started":"2021-06-19T15:26:37.220935Z","shell.execute_reply":"2021-06-19T15:26:37.249893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 32","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:26:37.253108Z","iopub.execute_input":"2021-06-19T15:26:37.254096Z","iopub.status.idle":"2021-06-19T15:26:37.269917Z","shell.execute_reply.started":"2021-06-19T15:26:37.254043Z","shell.execute_reply":"2021-06-19T15:26:37.26885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"# IMSIZE = (256, 384, 512, 640, 768, 1024)\n\ntest_paths = test_df.image_path.iloc[:100 if debug else test_df.shape[0]]\n# Get the multi-labels\n# label_cols = sub_df.columns[1:]\ntest_decoder = build_decoder(with_labels=False, target_size=DIM)\ndtest = build_dataset(\n    test_paths, bsize=BATCH_SIZE, repeat=True, \n    shuffle=False, augment=True, cache=False,\n    decode_fn=test_decoder\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:26:37.272905Z","iopub.execute_input":"2021-06-19T15:26:37.273255Z","iopub.status.idle":"2021-06-19T15:26:38.027404Z","shell.execute_reply.started":"2021-06-19T15:26:37.273224Z","shell.execute_reply":"2021-06-19T15:26:38.026255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load model and submit","metadata":{}},{"cell_type":"code","source":"EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n\ndef build_model(dim=IMG_SIZES[0], ef=0):\n    inp = tf.keras.layers.Input(shape=(*dim,3))\n    base = EFNS[ef](input_shape=(*dim,3),weights='imagenet',include_top=False)\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n    x = tf.keras.layers.Dense(4,activation='softmax')(x)\n    model = tf.keras.Model(inputs=inp,outputs=x)\n#     opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n#     loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01) \n# #     acc = tf.keras.metrics.CategoricalAccuracy()\n# #     f1  = tfa.metrics.F1Score(num_classes=4,average='macro',threshold=None)\n#     model.compile(optimizer=opt,loss=loss,metrics=['AUC', acc, f1])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:26:38.029989Z","iopub.execute_input":"2021-06-19T15:26:38.030473Z","iopub.status.idle":"2021-06-19T15:26:38.042165Z","shell.execute_reply.started":"2021-06-19T15:26:38.030423Z","shell.execute_reply":"2021-06-19T15:26:38.040517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dir = '/kaggle/input/siim-covid-19-study-level-train-tpu'\nmodel_paths = sorted(glob(os.path.join(base_dir, '*h5')))# preds = np.zeros((count_data_items(files_test),1))\npreds=[]\nmodel = build_model(dim=IMG_SIZES[0], ef=7)\nfor fold, model_path in enumerate(tqdm(model_paths)):\n    print(f'Fold: {fold+1}')\n    with strategy.scope():\n        print('Loading Model...')\n        #model = tf.keras.models.load_model(model_path, compile=False)\n        model.load_weights(model_path)\n    print('Predicting...')\n    pred = model.predict(dtest, steps = TTA*len(test_paths)/BATCH_SIZE, verbose=1)[:TTA*len(test_paths),:]\n    pred = np.mean(pred.reshape(TTA, len(test_paths), -1), axis=0)\n    preds.append(pred)\npreds = np.mean(preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:26:38.044482Z","iopub.execute_input":"2021-06-19T15:26:38.045135Z","iopub.status.idle":"2021-06-19T15:37:40.029886Z","shell.execute_reply.started":"2021-06-19T15:26:38.04509Z","shell.execute_reply":"2021-06-19T15:37:40.028562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process Prediction","metadata":{}},{"cell_type":"code","source":"name2label = { \n    'negative': 0,\n    'indeterminate': 1,\n    'atypical': 2,\n    'typical': 3}\nlabel2name  = {v:k for k, v in name2label.items()}","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:37:40.0316Z","iopub.execute_input":"2021-06-19T15:37:40.032008Z","iopub.status.idle":"2021-06-19T15:37:40.039096Z","shell.execute_reply.started":"2021-06-19T15:37:40.031965Z","shell.execute_reply":"2021-06-19T15:37:40.037274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.loc[:99 if debug else test_df.shape[0],class_labels] = preds\nstudy_df = test_df.groupby(['study_id'])[class_labels].mean().reset_index()\nstudy_df.rename(columns={'study_id':'id'}, inplace=True)\nstudy_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:37:40.04171Z","iopub.execute_input":"2021-06-19T15:37:40.042439Z","iopub.status.idle":"2021-06-19T15:37:40.079138Z","shell.execute_reply.started":"2021-06-19T15:37:40.04235Z","shell.execute_reply":"2021-06-19T15:37:40.077617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_PredictionString(row, thr=0):\n    string = ''\n    for idx in range(4):\n        conf =  row[str(idx)]\n        if conf>thr:\n            string+=f'{label2name[idx]} {conf:0.2f} 0 0 1 1 '\n    string = string.strip()\n    return string","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:37:40.081202Z","iopub.execute_input":"2021-06-19T15:37:40.081714Z","iopub.status.idle":"2021-06-19T15:37:40.08924Z","shell.execute_reply.started":"2021-06-19T15:37:40.081667Z","shell.execute_reply":"2021-06-19T15:37:40.087982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_df['PredictionString'] = study_df.progress_apply(get_PredictionString, axis=1)\nstudy_df = study_df.drop(class_labels, axis=1)\nstudy_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:37:40.091593Z","iopub.execute_input":"2021-06-19T15:37:40.092245Z","iopub.status.idle":"2021-06-19T15:37:40.2126Z","shell.execute_reply.started":"2021-06-19T15:37:40.092199Z","shell.execute_reply":"2021-06-19T15:37:40.210861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df = pd.DataFrame({'id':test_df.image_id.tolist(),\n                         'PredictionString':[\"none 1 0 0 1 1\"]*len(test_df.image_id.tolist())})\nimage_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:37:40.215116Z","iopub.execute_input":"2021-06-19T15:37:40.2156Z","iopub.status.idle":"2021-06-19T15:37:40.235582Z","shell.execute_reply.started":"2021-06-19T15:37:40.215553Z","shell.execute_reply":"2021-06-19T15:37:40.233955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.concat([study_df, image_df])\nsub_df.to_csv('/kaggle/working/submission.csv',index=False)\nprint(sub_df.shape)\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:37:40.23796Z","iopub.execute_input":"2021-06-19T15:37:40.238479Z","iopub.status.idle":"2021-06-19T15:37:40.268798Z","shell.execute_reply.started":"2021-06-19T15:37:40.238419Z","shell.execute_reply":"2021-06-19T15:37:40.267444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('/kaggle/working/test')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:37:40.270872Z","iopub.execute_input":"2021-06-19T15:37:40.271307Z","iopub.status.idle":"2021-06-19T15:37:40.333344Z","shell.execute_reply.started":"2021-06-19T15:37:40.271261Z","shell.execute_reply":"2021-06-19T15:37:40.332447Z"},"trusted":true},"execution_count":null,"outputs":[]}]}