{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-30T11:32:57.764069Z","iopub.execute_input":"2021-09-30T11:32:57.764475Z","iopub.status.idle":"2021-09-30T11:32:57.775375Z","shell.execute_reply.started":"2021-09-30T11:32:57.764392Z","shell.execute_reply":"2021-09-30T11:32:57.773961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compteur = 0\nfor dirname, _, filenames in os.walk('/kaggle/input/siim-covid19-detection/train'):\n    for filename in filenames:\n      compteur += 1\ncompteur","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:32:57.798822Z","iopub.execute_input":"2021-09-30T11:32:57.799198Z","iopub.status.idle":"2021-09-30T11:33:30.109267Z","shell.execute_reply.started":"2021-09-30T11:32:57.799165Z","shell.execute_reply":"2021-09-30T11:33:30.108276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"liste = []\nfor dirname, _, filenames in os.walk('/kaggle/input/siim-covid19-detection/test'):\n    for filename in filenames:\n        liste.append(os.path.join(dirname, filename))\nlen(liste)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:30.110728Z","iopub.execute_input":"2021-09-30T11:33:30.111343Z","iopub.status.idle":"2021-09-30T11:33:40.395223Z","shell.execute_reply.started":"2021-09-30T11:33:30.111297Z","shell.execute_reply":"2021-09-30T11:33:40.394038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"liste[:10]","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:40.397445Z","iopub.execute_input":"2021-09-30T11:33:40.397896Z","iopub.status.idle":"2021-09-30T11:33:40.404316Z","shell.execute_reply.started":"2021-09-30T11:33:40.397832Z","shell.execute_reply":"2021-09-30T11:33:40.403286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compteur = 0\nfor dirname in os.walk('/kaggle/input/siim-covid19-detection/test'):\n    compteur += 1\ncompteur","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:40.405987Z","iopub.execute_input":"2021-09-30T11:33:40.406277Z","iopub.status.idle":"2021-09-30T11:33:41.551232Z","shell.execute_reply.started":"2021-09-30T11:33:40.406247Z","shell.execute_reply":"2021-09-30T11:33:41.550065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\ndf_box = pd.read_csv('/kaggle/input/siim-covid19-detection/train_image_level.csv')\ndf_classif = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv')\ndf_classif['id'] = df_classif['id'].apply(lambda x: f'{x[:12]}')\ndf_classif.rename(columns = {'id':'StudyInstanceUID'}, inplace = True)\ndata = pd.merge(df_box, df_classif, on='StudyInstanceUID')\ndata['id'] = data['id'].apply(lambda x: x.split('_')[0])\n\ndata[ data['Negative for Pneumonia'] == 1 ] # pas de bbox dans ces cas là","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:41.55262Z","iopub.execute_input":"2021-09-30T11:33:41.553048Z","iopub.status.idle":"2021-09-30T11:33:41.705777Z","shell.execute_reply.started":"2021-09-30T11:33:41.553015Z","shell.execute_reply":"2021-09-30T11:33:41.704665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df) # TOUT LE DOSSIER TEST: 1263 études (1263 dossiers dans le dossier test) + toutes les images qu'ils contiennent = 2475","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:41.707031Z","iopub.execute_input":"2021-09-30T11:33:41.70733Z","iopub.status.idle":"2021-09-30T11:33:41.712775Z","shell.execute_reply.started":"2021-09-30T11:33:41.707301Z","shell.execute_reply":"2021-09-30T11:33:41.711878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:41.713735Z","iopub.execute_input":"2021-09-30T11:33:41.714024Z","iopub.status.idle":"2021-09-30T11:33:41.731653Z","shell.execute_reply.started":"2021-09-30T11:33:41.713997Z","shell.execute_reply":"2021-09-30T11:33:41.730769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\n# Trouver tous les chemins vers les fichiers qui finissent par .jpg\nliste = glob.glob('/kaggle/input/siim-covid19-detection/train/*/*/*.dcm')\nliste[:10]\n\ndf2 = pd.DataFrame(liste, columns = ['URL'])\ndf2['id'] = df2['URL'].apply(lambda x : os.path.split(x)[-1])\ndf2['id'] = df2['id'].apply(lambda x : x.split('.')[0])\ndata['id'] = data['id'].apply(lambda x : x.split('_')[0])\nFinalDf = pd.merge(data, df2, on='id')\nFinalDf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:41.734005Z","iopub.execute_input":"2021-09-30T11:33:41.734277Z","iopub.status.idle":"2021-09-30T11:33:47.14788Z","shell.execute_reply.started":"2021-09-30T11:33:41.73425Z","shell.execute_reply":"2021-09-30T11:33:47.146656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\ndef read_box(box):\n    try:\n        return json.loads(box.replace('\\'', '\\\"'))\n    except AttributeError:\n        return []\n    \nFinalDf['bbox_nbr'] = FinalDf['boxes'].apply(lambda x : len(read_box(x)) ).astype(int)\nFinalDf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:47.149616Z","iopub.execute_input":"2021-09-30T11:33:47.14993Z","iopub.status.idle":"2021-09-30T11:33:47.20866Z","shell.execute_reply.started":"2021-09-30T11:33:47.1499Z","shell.execute_reply":"2021-09-30T11:33:47.207937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(6, 3))\nsns.barplot(x = FinalDf['bbox_nbr'].value_counts().index, y = FinalDf['bbox_nbr'].value_counts().values, palette=\"husl\")\nplt.ylabel('Image number')\nplt.xlabel('Bbox number')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:47.209797Z","iopub.execute_input":"2021-09-30T11:33:47.210342Z","iopub.status.idle":"2021-09-30T11:33:48.245524Z","shell.execute_reply.started":"2021-09-30T11:33:47.210308Z","shell.execute_reply":"2021-09-30T11:33:48.244405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Etant donné que les radios avec 3 ou 4 bbox sont largement minoritaire nous allons considérer uniquement celles avec 0, 1 ou 2 bbox dans un premier temps","metadata":{}},{"cell_type":"code","source":"FinalDf_0bbox = FinalDf[ FinalDf['bbox_nbr'] == 0 ]\nFinalDf_0bbox = FinalDf_0bbox.reset_index()\nFinalDf_0bbox = FinalDf_0bbox.drop(['index'], axis=1)\n\nFinalDf_1bbox = FinalDf[ FinalDf['bbox_nbr'] == 1 ]\nFinalDf_1bbox = FinalDf_1bbox.reset_index()\nFinalDf_1bbox = FinalDf_1bbox.drop(['index'], axis=1)\n\nFinalDf_2bbox = FinalDf[ FinalDf['bbox_nbr'] == 2 ]\nFinalDf_2bbox = FinalDf_2bbox.reset_index()\nFinalDf_2bbox = FinalDf_2bbox.drop(['index'], axis=1)\n\n# FinalDf_3bbox = FinalDf[ FinalDf['bbox_nbr'] == 3] on va pas considérer ceux-là dans un 1er temps\nFinalDf_2bbox.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:48.247249Z","iopub.execute_input":"2021-09-30T11:33:48.247681Z","iopub.status.idle":"2021-09-30T11:33:48.279494Z","shell.execute_reply.started":"2021-09-30T11:33:48.247635Z","shell.execute_reply":"2021-09-30T11:33:48.278351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# coordonnées bounding box 1\nFinalDf_1bbox['x1 bb1'] = FinalDf_1bbox['label'].apply(lambda x : x.split(' ')[2]).astype(float)\nFinalDf_1bbox['y1 bb1'] = FinalDf_1bbox['label'].apply(lambda x : x.split(' ')[3]).astype(float)\nFinalDf_1bbox['x2 bb1'] = FinalDf_1bbox['label'].apply(lambda x : x.split(' ')[4]).astype(float)\nFinalDf_1bbox['y2 bb1'] = FinalDf_1bbox['label'].apply(lambda x : x.split(' ')[5]).astype(float)\n\nFinalDf_1bbox['xmoy bb1'] = (FinalDf_1bbox['x1 bb1'] + FinalDf_1bbox['x2 bb1']) /2\nFinalDf_1bbox['ymoy bb1'] = (FinalDf_1bbox['y1 bb1'] + FinalDf_1bbox['y2 bb1']) /2\nFinalDf_1bbox['w bb1'] = FinalDf_1bbox['x2 bb1'] - FinalDf_1bbox['x1 bb1']\nFinalDf_1bbox['h bb1'] = FinalDf_1bbox['y2 bb1'] - FinalDf_1bbox['y1 bb1']\n\nFinalDf_1bbox.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:48.281124Z","iopub.execute_input":"2021-09-30T11:33:48.281581Z","iopub.status.idle":"2021-09-30T11:33:48.319949Z","shell.execute_reply.started":"2021-09-30T11:33:48.281538Z","shell.execute_reply":"2021-09-30T11:33:48.318853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# coordonnées bounding box 1\nFinalDf_2bbox['x1 bb1'] = FinalDf_2bbox['label'].apply(lambda x : x.split(' ')[2]).astype(float)\nFinalDf_2bbox['y1 bb1'] = FinalDf_2bbox['label'].apply(lambda x : x.split(' ')[3]).astype(float)\nFinalDf_2bbox['x2 bb1'] = FinalDf_2bbox['label'].apply(lambda x : x.split(' ')[4]).astype(float)\nFinalDf_2bbox['y2 bb1'] = FinalDf_2bbox['label'].apply(lambda x : x.split(' ')[5]).astype(float)\n\nFinalDf_2bbox['xmoy bb1'] = (FinalDf_2bbox['x1 bb1'] + FinalDf_2bbox['x2 bb1']) /2\nFinalDf_2bbox['ymoy bb1'] = (FinalDf_2bbox['y1 bb1'] + FinalDf_2bbox['y2 bb1']) /2\nFinalDf_2bbox['w bb1'] = FinalDf_2bbox['x2 bb1'] - FinalDf_2bbox['x1 bb1']\nFinalDf_2bbox['h bb1'] = FinalDf_2bbox['y2 bb1'] - FinalDf_2bbox['y1 bb1']\n\n# coordonnées bounding box 2\nFinalDf_2bbox['x1 bb2'] = FinalDf_2bbox['label'].apply(lambda x : x.split(' ')[8]).astype(float)\nFinalDf_2bbox['y1 bb2'] = FinalDf_2bbox['label'].apply(lambda x : x.split(' ')[9]).astype(float)\nFinalDf_2bbox['x2 bb2'] = FinalDf_2bbox['label'].apply(lambda x : x.split(' ')[10]).astype(float)\nFinalDf_2bbox['y2 bb2'] = FinalDf_2bbox['label'].apply(lambda x : x.split(' ')[11]).astype(float)\n\nFinalDf_2bbox['xmoy bb2'] = (FinalDf_2bbox['x1 bb2'] + FinalDf_2bbox['x2 bb2']) /2\nFinalDf_2bbox['ymoy bb2'] = (FinalDf_2bbox['y1 bb2'] + FinalDf_2bbox['y2 bb2']) /2\nFinalDf_2bbox['w bb2'] = FinalDf_2bbox['x2 bb2'] - FinalDf_2bbox['x1 bb2']\nFinalDf_2bbox['h bb2'] = FinalDf_2bbox['y2 bb2'] - FinalDf_2bbox['y1 bb2']\n\nFinalDf_2bbox.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:48.321048Z","iopub.execute_input":"2021-09-30T11:33:48.321353Z","iopub.status.idle":"2021-09-30T11:33:48.404442Z","shell.execute_reply.started":"2021-09-30T11:33:48.321325Z","shell.execute_reply":"2021-09-30T11:33:48.403159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_intermediaire = pd.concat([FinalDf_0bbox, FinalDf_1bbox], axis=0)\ndata = pd.concat([df_intermediaire, FinalDf_2bbox], axis=0)\n\ndico = {'Negative for Pneumonia': 'Negative',\n        'Typical Appearance': 'Typical',\n        'Indeterminate Appearance': 'Ind',\n        'Atypical Appearance': 'Atypical'}\ndata = data.rename(dico, axis = 1) \ndata.tail()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:48.405712Z","iopub.execute_input":"2021-09-30T11:33:48.406033Z","iopub.status.idle":"2021-09-30T11:33:48.451688Z","shell.execute_reply.started":"2021-09-30T11:33:48.406005Z","shell.execute_reply":"2021-09-30T11:33:48.450727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FinalDf = data.fillna(0)\nFinalDf = FinalDf .reset_index()\ncols_to_drop = ['boxes', 'label', 'StudyInstanceUID']\nFinalDf = FinalDf.drop(cols_to_drop, axis=1)\nFinalDf.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:48.45268Z","iopub.execute_input":"2021-09-30T11:33:48.452972Z","iopub.status.idle":"2021-09-30T11:33:48.486865Z","shell.execute_reply.started":"2021-09-30T11:33:48.452945Z","shell.execute_reply":"2021-09-30T11:33:48.485779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(FinalDf) # 6334 images moins celles qui ont 3 ou 4 bbox","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:48.488373Z","iopub.execute_input":"2021-09-30T11:33:48.488781Z","iopub.status.idle":"2021-09-30T11:33:48.494626Z","shell.execute_reply.started":"2021-09-30T11:33:48.488737Z","shell.execute_reply":"2021-09-30T11:33:48.493959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FinalDf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:48.495687Z","iopub.execute_input":"2021-09-30T11:33:48.496062Z","iopub.status.idle":"2021-09-30T11:33:48.541807Z","shell.execute_reply.started":"2021-09-30T11:33:48.496031Z","shell.execute_reply":"2021-09-30T11:33:48.540896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow-io","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:33:48.543056Z","iopub.execute_input":"2021-09-30T11:33:48.543358Z","iopub.status.idle":"2021-09-30T11:35:22.373016Z","shell.execute_reply.started":"2021-09-30T11:33:48.543328Z","shell.execute_reply":"2021-09-30T11:35:22.37211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_io as tfio\n\ndef load_image(pathname):\n    image_bytes = tf.io.read_file(pathname)\n    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n    return image\n\nim = load_image(FinalDf['URL'][0]) \n\nplt.figure(figsize=(5, 5))\nplt.imshow(np.squeeze(im.numpy()), cmap='gray');","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:22.374543Z","iopub.execute_input":"2021-09-30T11:35:22.37498Z","iopub.status.idle":"2021-09-30T11:35:26.734197Z","shell.execute_reply.started":"2021-09-30T11:35:22.374932Z","shell.execute_reply":"2021-09-30T11:35:26.733104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Tensorflow version \" + tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:26.735567Z","iopub.execute_input":"2021-09-30T11:35:26.735897Z","iopub.status.idle":"2021-09-30T11:35:26.741099Z","shell.execute_reply.started":"2021-09-30T11:35:26.735856Z","shell.execute_reply":"2021-09-30T11:35:26.739943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_two_bounding_box(im, bbox1, bbox2, color='r'):\n    # Signification de bbox\n    x11, y11, x21, y21 = bbox1\n    x12, y12, x22, y22 = bbox2\n\n    # Afficher l'image\n    plt.figure(figsize=(5, 5))\n    plt.imshow(np.squeeze(im.numpy()), cmap='gray')\n    \n    # Afficher les bounding box\n    plt.plot([x11,x21,x21,x11,x11],[y11,y11,y21,y21,y11],\"r\")\n    plt.plot([x12,x22,x22,x12,x12],[y12,y12,y22,y22,y12],\"r\")\n\nidx = 3 # \n# Array de l'image\nim = load_image(FinalDf_2bbox.URL[idx]) \n# Coordonnées de la bounding box\nbbox1 = FinalDf_2bbox[['x1 bb1', 'y1 bb1', 'x2 bb1', 'y2 bb1']].values[idx]\nbbox2 = FinalDf_2bbox[['x1 bb2', 'y1 bb2', 'x2 bb2', 'y2 bb2']].values[idx]\n# Afficher l'image ainsi que la bounding box\nshow_two_bounding_box(im, bbox1, bbox2)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:26.742642Z","iopub.execute_input":"2021-09-30T11:35:26.743098Z","iopub.status.idle":"2021-09-30T11:35:28.709163Z","shell.execute_reply.started":"2021-09-30T11:35:26.74306Z","shell.execute_reply":"2021-09-30T11:35:28.708066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 2045 # len(FinalDf_0bbox) = 2040 donc pour cet indice on est dans une entrée qui a une seule bbox\n# Array de l'image\nim = load_image(FinalDf.URL[idx]) \n# Coordonnées de la bounding box\nbbox1 = FinalDf[['x1 bb1', 'y1 bb1', 'x2 bb1', 'y2 bb1']].values[idx]\nbbox2 = FinalDf[['x1 bb2', 'y1 bb2', 'x2 bb2', 'y2 bb2']].values[idx]\n# Afficher l'image ainsi que la bounding box\nshow_two_bounding_box(im, bbox1, bbox2)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:28.71046Z","iopub.execute_input":"2021-09-30T11:35:28.710761Z","iopub.status.idle":"2021-09-30T11:35:33.001405Z","shell.execute_reply.started":"2021-09-30T11:35:28.710732Z","shell.execute_reply":"2021-09-30T11:35:33.000318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 7 # 0 bbox pour les 1eres entrées\n# Array de l'image\nim = load_image(FinalDf.URL[idx]) \n# Coordonnées de la bounding box\nbbox1 = FinalDf[['x1 bb1', 'y1 bb1', 'x2 bb1', 'y2 bb1']].values[idx]\nbbox2 = FinalDf[['x1 bb2', 'y1 bb2', 'x2 bb2', 'y2 bb2']].values[idx]\n# Afficher l'image ainsi que la bounding box\nshow_two_bounding_box(im, bbox1, bbox2)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:33.00592Z","iopub.execute_input":"2021-09-30T11:35:33.006247Z","iopub.status.idle":"2021-09-30T11:35:35.538875Z","shell.execute_reply.started":"2021-09-30T11:35:33.006216Z","shell.execute_reply":"2021-09-30T11:35:35.537902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_resize_image(pathname, resize=(256,256)):\n    image_bytes = tf.io.read_file(pathname)\n    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n    image = tf.image.resize(im, resize)\n    return image.numpy() # enlever le .numpy() si c'est mieux de garder un tensor\n\nim = load_resize_image(FinalDf['URL'][0]) \nim = im.reshape(im.shape[1], im.shape[2]) # shape = 256x256\n# For grayscale images, the pixel value is typically an 8-bit data value (with a range of 0 to 255) \n# or a 16-bit data value (with a range of 0 to 65535)\nnp.max(im) # -> max pixel value  (si jamais on veut normaliser) ","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:35.542463Z","iopub.execute_input":"2021-09-30T11:35:35.543067Z","iopub.status.idle":"2021-09-30T11:35:36.340542Z","shell.execute_reply.started":"2021-09-30T11:35:35.543018Z","shell.execute_reply":"2021-09-30T11:35:36.33934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_path, X_test_path, y_train, y_test = train_test_split(FinalDf.URL.values, \n                                             FinalDf[['x1 bb1', 'y1 bb1', 'x2 bb1', 'y2 bb1', \n                                                      'Negative', 'Typical', 'Ind', 'Atypical',\n                                                      'x1 bb2', 'y1 bb2', 'x2 bb2', 'y2 bb2']].values, \n                                                       train_size=0.9, random_state=1234)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:36.342159Z","iopub.execute_input":"2021-09-30T11:35:36.342594Z","iopub.status.idle":"2021-09-30T11:35:36.545199Z","shell.execute_reply.started":"2021-09-30T11:35:36.342547Z","shell.execute_reply":"2021-09-30T11:35:36.544308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[10] # 2 bbox ","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:36.546302Z","iopub.execute_input":"2021-09-30T11:35:36.546578Z","iopub.status.idle":"2021-09-30T11:35:36.552855Z","shell.execute_reply.started":"2021-09-30T11:35:36.546552Z","shell.execute_reply":"2021-09-30T11:35:36.551879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[10][8:12]","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:36.554126Z","iopub.execute_input":"2021-09-30T11:35:36.554472Z","iopub.status.idle":"2021-09-30T11:35:36.565877Z","shell.execute_reply.started":"2021-09-30T11:35:36.554442Z","shell.execute_reply":"2021-09-30T11:35:36.564494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepath = X_train_path[10]\nim = load_image(filepath) \nbbox1 = y_train[10][0:4]\nbbox2 = y_train[10][8:12]\nshow_two_bounding_box(im, bbox1, bbox2)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:36.567444Z","iopub.execute_input":"2021-09-30T11:35:36.567887Z","iopub.status.idle":"2021-09-30T11:35:39.303475Z","shell.execute_reply.started":"2021-09-30T11:35:36.567827Z","shell.execute_reply":"2021-09-30T11:35:39.302442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image_convert_target(pathname, pouet):\n\n    image_bytes = tf.io.read_file(pathname)\n    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n    img_shape = image.numpy().shape \n    resize = (224,224)\n    image = tf.image.resize(image, resize)\n    image = tf.image.grayscale_to_rgb(image)\n\n    # on initialise une matrice de zero de dimension 8x8 x5\n    output_shape = (7, 7)\n    y_target = np.zeros([output_shape[0], output_shape[1], 9])\n    \n    lx = 1/output_shape[1] # lx = 1/8eme\n    ly = 1/output_shape[0] # ly = 1/8eme\n    \n    # on modifie dans la matrice les 5 valeurs del'array correspondant à la case contenant le centre de la bbox\n    for x1, y1, x2, y2, a, b, c, d in [pouet[:8]]:\n\n        # normalisation entre 0 et 1:\n        x1 = x1/img_shape[2]\n        y1 = y1/img_shape[1]\n        x2 = x2/img_shape[2]\n        y2 = y2/img_shape[1]\n        \n        x = (x1+x2)/2 # x milieu bbox\n        y = (y1+y2)/2 # y milieu bbox\n        w = x2 - x1\n        h = y2 - y1\n        \n        idx_x = int(x//lx) # numéro case abcisse\n        idx_y = int(y//ly) # numéro case ordonnée\n\n        y_target[idx_y, idx_x, 0] = 1                      # p true object case\n        y_target[idx_y, idx_x, 1] = 2*(x/lx - (idx_x+0.5)) # x\n        y_target[idx_y, idx_x, 2] = 2*(y/ly - (idx_y+0.5)) # y\n        y_target[idx_y, idx_x, 3] = w                      # w\n        y_target[idx_y, idx_x, 4] = h                      # h\n        y_target[idx_y, idx_x, 5] = a                      # Neg for Pneumo (0ou1)\n        y_target[idx_y, idx_x, 6] = b                      # Typical (0ou1)\n        y_target[idx_y, idx_x, 7] = c                      # Ind (0ou1)\n        y_target[idx_y, idx_x, 8] = d                      # Atypical (0ou1)\n        \n    for a, b, c, d, x1, y1, x2, y2 in [pouet[4:]]:\n\n        x1 = x1/img_shape[2]\n        y1 = y1/img_shape[1]\n        x2 = x2/img_shape[2]\n        y2 = y2/img_shape[1]\n        \n        x = (x1+x2)/2\n        y = (y1+y2)/2\n        w = x2 - x1\n        h = y2 - y1\n        \n        idx_x = int(x//lx) # numéro case abcisse\n        idx_y = int(y//ly) # numéro case ordonnée\n        \n        y_target[idx_y, idx_x, 0] = 1                      # p true object case\n        y_target[idx_y, idx_x, 1] = 2*(x/lx - (idx_x+0.5)) # x    \n        y_target[idx_y, idx_x, 2] = 2*(y/ly - (idx_y+0.5)) # y\n        y_target[idx_y, idx_x, 3] = w                      # w\n        y_target[idx_y, idx_x, 4] = h                      # h\n        y_target[idx_y, idx_x, 5] = a                      # Neg for Pneumo (0ou1)\n        y_target[idx_y, idx_x, 6] = b                      # Typical (0ou1)\n        y_target[idx_y, idx_x, 7] = c                      # Ind (0ou1)\n        y_target[idx_y, idx_x, 8] = d                      # Atypical (0ou1)\n        \n    return image.numpy().reshape([224, 224, 3])/np.max(image.numpy().reshape([224, 224, 3]))*255, y_target.reshape([-1, 9]) # tuple dont la 1ere valeur est l'array de \n                                                                           # l'image et la 2nde est une grille qui aura les 9 valeurs\n                                                                           # target de bbox dans les 2 cases concernées\n\n\nload_image_convert_target(X_train_path[10], y_train[10])[1]\n# en partant du principe que la classe est la même pour les 2 bbox","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:39.304826Z","iopub.execute_input":"2021-09-30T11:35:39.305157Z","iopub.status.idle":"2021-09-30T11:35:40.454285Z","shell.execute_reply.started":"2021-09-30T11:35:39.305125Z","shell.execute_reply":"2021-09-30T11:35:40.453439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"max pixel value image10: \", np.max(load_image_convert_target(X_train_path[10], y_train[10])[0]))\nload_image_convert_target(X_train_path[10], y_train[10])[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:40.455375Z","iopub.execute_input":"2021-09-30T11:35:40.45582Z","iopub.status.idle":"2021-09-30T11:35:42.653032Z","shell.execute_reply.started":"2021-09-30T11:35:40.45579Z","shell.execute_reply":"2021-09-30T11:35:42.652008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(load_image_convert_target(X_train_path[10], y_train[10])[1][:,0].shape)\nload_image_convert_target(X_train_path[10], y_train[10])[1][:,0] # grille de 64 cases avec 1 quand le centre de la bbox s'y trouve","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:42.65433Z","iopub.execute_input":"2021-09-30T11:35:42.65463Z","iopub.status.idle":"2021-09-30T11:35:44.868625Z","shell.execute_reply.started":"2021-09-30T11:35:42.654601Z","shell.execute_reply":"2021-09-30T11:35:44.867466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_two_bounding_box(pathname, cible, color='r'):\n\n    im = load_image(pathname)\n    img_shape = np.squeeze(im.numpy()).shape\n    resize = (224,224)\n    im = tf.image.resize(im, resize)\n\n    x11, y11, x21, y21 = cible[:4][0], cible[:4][1], cible[:4][2], cible[:4][3]\n    x12, y12, x22, y22 = cible[8:][0], cible[8:][1], cible[8:][2], cible[8:][3]\n    \n    x11 = x11/img_shape[1] * 224\n    y11 = y11/img_shape[0] * 224\n    x21 = x21/img_shape[1] * 224\n    y21 = y21/img_shape[0] * 224\n    \n    x12 = x12/img_shape[1] * 224\n    y12 = y12/img_shape[0] * 224\n    x22 = x22/img_shape[1] * 224\n    y22 = y22/img_shape[0] * 224\n\n    plt.imshow(np.squeeze(im.numpy()))\n    plt.plot([x11,x21,x21,x11,x11],[y11,y11,y21,y21,y11],\"r\")\n    plt.plot([x12,x22,x22,x12,x12],[y12,y12,y22,y22,y12],\"r\")\n\noutput_shape = (7,7)\nplt.figure(figsize=(12,5))\nplt.subplot(121)\nshow_two_bounding_box(X_train_path[10], y_train[10])\nplt.subplot(122)\nplt.imshow(load_image_convert_target(X_train_path[10], y_train[10])[1][:,0].reshape(output_shape))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:44.870267Z","iopub.execute_input":"2021-09-30T11:35:44.870593Z","iopub.status.idle":"2021-09-30T11:35:47.441446Z","shell.execute_reply.started":"2021-09-30T11:35:44.870561Z","shell.execute_reply":"2021-09-30T11:35:47.440162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip uninstall tensorflow -y\n# !pip install tensorflow-gpu\n# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n# from tensorflow.python.client import device_lib \n# print(device_lib.list_local_devices())\n# !nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:47.442749Z","iopub.execute_input":"2021-09-30T11:35:47.443108Z","iopub.status.idle":"2021-09-30T11:35:47.446741Z","shell.execute_reply.started":"2021-09-30T11:35:47.443074Z","shell.execute_reply":"2021-09-30T11:35:47.446006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, LeakyReLU, Dropout, Reshape, BatchNormalization\nfrom tensorflow.keras import Sequential\n\nnb_class = 4\n\n# Backbone\nefficientNet = EfficientNetB0(include_top=False, input_shape=(224,224,3)) \n\n# Freeze the blackbone\nfor layer in efficientNet.layers:\n    layer.trainable = False\n\n# Définition de la partie encoder\nmodel = Sequential()\n# Feature extration part\nmodel.add(efficientNet) \nmodel.add(Reshape([-1, 1280]))\n# Regression Part\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5 + nb_class))\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:47.448147Z","iopub.execute_input":"2021-09-30T11:35:47.448456Z","iopub.status.idle":"2021-09-30T11:35:50.693508Z","shell.execute_reply.started":"2021-09-30T11:35:47.448426Z","shell.execute_reply":"2021-09-30T11:35:50.692416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:50.694984Z","iopub.execute_input":"2021-09-30T11:35:50.695401Z","iopub.status.idle":"2021-09-30T11:35:50.705049Z","shell.execute_reply.started":"2021-09-30T11:35:50.695355Z","shell.execute_reply":"2021-09-30T11:35:50.703663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = dataset_train.shuffle(100000).map(lambda x, y : tf.py_function(load_image_convert_target, [x, y], [tf.float32, tf.float32]), num_parallel_calls=-1).batch(32)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:50.706456Z","iopub.execute_input":"2021-09-30T11:35:50.706865Z","iopub.status.idle":"2021-09-30T11:35:51.020975Z","shell.execute_reply.started":"2021-09-30T11:35:50.70681Z","shell.execute_reply":"2021-09-30T11:35:51.019816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_t, y_t = next(iter(dataset_train))\nX_t[0].numpy().shape","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:35:51.022382Z","iopub.execute_input":"2021-09-30T11:35:51.022682Z","iopub.status.idle":"2021-09-30T11:36:09.079575Z","shell.execute_reply.started":"2021-09-30T11:35:51.022655Z","shell.execute_reply":"2021-09-30T11:36:09.078476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_t.numpy().shape","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:09.080865Z","iopub.execute_input":"2021-09-30T11:36:09.081179Z","iopub.status.idle":"2021-09-30T11:36:09.092291Z","shell.execute_reply.started":"2021-09-30T11:36:09.081149Z","shell.execute_reply":"2021-09-30T11:36:09.091081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_raw = model.predict(X_t)\ny_pred_raw.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:09.093824Z","iopub.execute_input":"2021-09-30T11:36:09.094139Z","iopub.status.idle":"2021-09-30T11:36:12.209861Z","shell.execute_reply.started":"2021-09-30T11:36:09.094111Z","shell.execute_reply":"2021-09-30T11:36:12.208881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_netout(y_pred_raw):\n    \n    y_pred_conf = tf.sigmoid(y_pred_raw[...,0:1]) # outputs sigmoïde [0,1] et notre p_true doit valoir 0 ou 1 \n    y_pred_xy = (tf.nn.tanh(y_pred_raw[...,1:3])) # pour avoir des valeurs comprises entre -1 et 1 avec tanh --> rappel: chaque case de la grille devient un nouveau repère dont l'origine est centrée: le max des abcisses et des ordonnées est 1 et le min -1\n    y_pred_wh = (tf.sigmoid(y_pred_raw[...,3:5])) # parce que la largeur et la hauteur de la bbox peuvent valoir 0 au min et 1 au max\n    y_pred_class = tf.nn.softmax(y_pred_raw[..., 5:])  # pour avoir des probas comprises entre 0 et 1 pour chacune des 4 classes VERIFIER!!\n\n    return tf.concat([y_pred_conf, y_pred_xy, y_pred_wh, y_pred_class], -1)\n\ny_pred = transform_netout(y_pred_raw)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:12.211411Z","iopub.execute_input":"2021-09-30T11:36:12.212093Z","iopub.status.idle":"2021-09-30T11:36:12.228327Z","shell.execute_reply.started":"2021-09-30T11:36:12.212047Z","shell.execute_reply":"2021-09-30T11:36:12.227055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (X_b, y_b) in dataset_train.take(count=2):\n    print('Shape of the batch X :', X_b.numpy().shape)\n    print('Target elements of the batch :', y_b.numpy().shape, '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:12.229946Z","iopub.execute_input":"2021-09-30T11:36:12.230911Z","iopub.status.idle":"2021-09-30T11:36:41.668358Z","shell.execute_reply.started":"2021-09-30T11:36:12.230835Z","shell.execute_reply":"2021-09-30T11:36:41.667245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def class_loss(y_true, y_pred):\n    y_true_conf = y_true[:,:,0]\n    y_true_class = y_true[:,:,5:] # on est déjà en one hot \n    y_pred_class = y_pred[:,:,5:]\n    # Calcul de la fonction de perte\n    class_loss = tf.reduce_sum(y_true_conf*tf.reduce_sum(tf.square(y_true_class - y_pred_class), axis=-1), axis=-1)\n    # mettre une softmax plutôt?\n    return class_loss # vaudra zéro pour toutes les cases sans bbox. zéro s'il yen a une et que la pred est correcte et 1 sinon (-1 au carré)\n\nclass_loss(y_t, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:41.669954Z","iopub.execute_input":"2021-09-30T11:36:41.670278Z","iopub.status.idle":"2021-09-30T11:36:41.681556Z","shell.execute_reply.started":"2021-09-30T11:36:41.670247Z","shell.execute_reply":"2021-09-30T11:36:41.680637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def coord_loss(y_true, y_pred):\n    y_true_conf = y_true[...,0]\n    y_true = y_true[...,1:5]\n    y_pred= y_pred[...,1:5]\n    return tf.reduce_sum(tf.reduce_sum(tf.square(y_true- y_pred),axis=-1)*y_true_conf, axis=-1)\n\ncoord_loss(y_t, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:41.683052Z","iopub.execute_input":"2021-09-30T11:36:41.683738Z","iopub.status.idle":"2021-09-30T11:36:41.695934Z","shell.execute_reply.started":"2021-09-30T11:36:41.683682Z","shell.execute_reply":"2021-09-30T11:36:41.694954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lambda_noobj = 0.5\ndef object_loss(y_true, y_pred):\n    # x and y loss for real object\n    y_true_p = y_true[...,0]\n    y_pred_p = y_pred[...,0]\n    return tf.reduce_sum((lambda_noobj + (1-lambda_noobj)*y_true_p)*tf.square(y_true_p - y_pred_p), axis=-1)\n\n# Object loss for the prediction X_t\nobject_loss(y_t, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:41.697747Z","iopub.execute_input":"2021-09-30T11:36:41.698621Z","iopub.status.idle":"2021-09-30T11:36:41.710461Z","shell.execute_reply.started":"2021-09-30T11:36:41.698573Z","shell.execute_reply":"2021-09-30T11:36:41.709552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lambda_coord = 5\nlambda_object = 1\n# lamda_class = ?\n\ndef global_loss(y_true, y_pred):\n    # Convert input\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    y_pred = transform_netout(y_pred)\n    loss_class = class_loss(y_true, y_pred)\n    loss_coordinate = coord_loss(y_true, y_pred)\n    loss_object = object_loss(y_true, y_pred)\n    return lambda_object*loss_object + lambda_coord*loss_coordinate + loss_class #ajouter lambda class\n\n# Global loss for the prediction X_t\nglobal_loss(y_t, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:41.71214Z","iopub.execute_input":"2021-09-30T11:36:41.712785Z","iopub.status.idle":"2021-09-30T11:36:41.729196Z","shell.execute_reply.started":"2021-09-30T11:36:41.712735Z","shell.execute_reply":"2021-09-30T11:36:41.727932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_save_path = '/kaggle/input/modeltest1/model_test1_12epochs.joblib'\n#weights_path = '/kaggle/input/modeltest1/Auto_save_model_correctedNormalize_14_epochs.h5'","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:41.73078Z","iopub.execute_input":"2021-09-30T11:36:41.731232Z","iopub.status.idle":"2021-09-30T11:36:41.735252Z","shell.execute_reply.started":"2021-09-30T11:36:41.731188Z","shell.execute_reply":"2021-09-30T11:36:41.734236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import callbacks\n\nautosave_path = \"Auto_save_model.h5\"\n\ncheckpoint = callbacks.ModelCheckpoint(autosave_path, \n                                       monitor = 'loss',\n                                       save_best_only = True,\n                                       save_weights_only = True,\n                                       mode = 'min',\n                                       save_freq = 'epoch')\n\n\n# Callback to reduce automatically the learning rate.\nlr_plateau = callbacks.ReduceLROnPlateau(monitor = 'loss',\n                                         patience=5,\n                                         factor=0.1,\n                                         verbose=2,\n                                         mode='min')\n\n\nmodel.compile(optimizer=Adam(1e-3), loss = global_loss)\n#model.load_weights(weights_path)\nepochs = 10\n# history = model.fit(dataset_train, epochs = epochs, callbacks = [lr_plateau, checkpoint])","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:41.736963Z","iopub.execute_input":"2021-09-30T11:36:41.737631Z","iopub.status.idle":"2021-09-30T11:36:41.763655Z","shell.execute_reply.started":"2021-09-30T11:36:41.737586Z","shell.execute_reply":"2021-09-30T11:36:41.762911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize=(12,10))\n#plt.plot(history.history['loss'])\n#plt.title(\"Loss evolution test model 1\")\n#plt.ylabel('loss')\n#plt.xlabel('epoch')\n#plt.savefig(\"loss_evol_8ep.png\");","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:41.764928Z","iopub.execute_input":"2021-09-30T11:36:41.765558Z","iopub.status.idle":"2021-09-30T11:36:41.769766Z","shell.execute_reply.started":"2021-09-30T11:36:41.765513Z","shell.execute_reply":"2021-09-30T11:36:41.768612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_save_path = \"model\" + str(epochs) + \".joblib\"\n# model.save( model_save_path)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:41.771464Z","iopub.execute_input":"2021-09-30T11:36:41.771951Z","iopub.status.idle":"2021-09-30T11:36:41.782106Z","shell.execute_reply.started":"2021-09-30T11:36:41.77183Z","shell.execute_reply":"2021-09-30T11:36:41.780945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_10ep_path = \"../input/10epochstrain/model10.joblib\"\nmodel_trained_10 = tf.keras.models.load_model(model_10ep_path, custom_objects = {\"global_loss\":global_loss})\nweights_path = \"../input/10epochstrain/Auto_save_model.h5\"\nmodel_trained_10.load_weights(weights_path)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:36:41.783657Z","iopub.execute_input":"2021-09-30T11:36:41.784273Z","iopub.status.idle":"2021-09-30T11:37:00.381881Z","shell.execute_reply.started":"2021-09-30T11:36:41.784238Z","shell.execute_reply":"2021-09-30T11:37:00.380748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_prediction(y_pred, threshold=0.8, grid=(7, 7)):\n    ### Return the coordinates of the x, y, w and h in out_image unity\n    if type(y_pred) == np.ndarray:\n        pred = y_pred.reshape((grid[0], grid[1], 9))\n    else:\n        pred = y_pred.numpy().reshape((grid[0], grid[1], 9))\n    idx_y, idx_x = np.where(pred[..., 0] > threshold)\n    lx = 1 / grid[0]\n    ly = 1 / grid[1]\n    \n    x = (pred[idx_y, idx_x, 1] /2 + (idx_x + 0.5) )* lx # 2*(x/lx - (idx_x+0.5))à l'envers\n    y = (pred[idx_y, idx_x, 2] /2 + (idx_y + 0.5) )* ly\n    w = pred[idx_y, idx_x, 3]\n    h = pred[idx_y, idx_x, 4]\n    x,y,w,h = x*224,y*224,w*224,h*224\n\n    c = np.argmax(pred[idx_x, idx_y, 5:], axis=1)\n    return x - (w / 2), y - (h / 2), x + (w / 2),  y + (h / 2), c","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:00.383637Z","iopub.execute_input":"2021-09-30T11:37:00.384096Z","iopub.status.idle":"2021-09-30T11:37:00.395243Z","shell.execute_reply.started":"2021-09-30T11:37:00.384049Z","shell.execute_reply":"2021-09-30T11:37:00.394055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_two_bboxFROMpred(im, coord_pred, color='r'):\n    x1, y1, x2, y2 = coord_pred[:4]\n    plt.imshow(im/255)\n    plt.plot([x1,x2,x2,x1,x1],[y1,y1,y2,y2,y1],color)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:00.396828Z","iopub.execute_input":"2021-09-30T11:37:00.397297Z","iopub.status.idle":"2021-09-30T11:37:00.414154Z","shell.execute_reply.started":"2021-09-30T11:37:00.397251Z","shell.execute_reply":"2021-09-30T11:37:00.413156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AFFICHAGE DES PREDICTIONS FAITES AVANT L'ENTRAINEMENT DU MODELE","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 8))\n\nplt.subplot(1, 3, 1)\nplt.title('All TRUE bboxes for the batch of 32 img ')\nfor i in range(32):\n    show_two_bboxFROMpred(X_t[i], process_prediction(y_t[i]))\n \nplt.subplot(1, 3, 2)\nplt.title('All pred - seuil 0.8 ')\nfor i in range(32):\n    show_two_bboxFROMpred(X_t[i], process_prediction(y_pred[i]))\n    \nplt.subplot(1, 3, 3)\nplt.title('All pred - seuil 0.5 ')\nfor i in range(32):\n    show_two_bboxFROMpred(X_t[i], process_prediction(y_pred[i], threshold=0.5))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:01.643677Z","iopub.execute_input":"2021-09-30T11:37:01.644135Z","iopub.status.idle":"2021-09-30T11:37:03.492673Z","shell.execute_reply.started":"2021-09-30T11:37:01.644088Z","shell.execute_reply":"2021-09-30T11:37:03.49168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"APRES 10 EPOCHS","metadata":{}},{"cell_type":"code","source":"y_t_pred_raw_10ep = model_trained_10.predict(X_t)\ny_t_pred_10ep = transform_netout(y_t_pred_raw_10ep)\n\nplt.figure(figsize=(10, 8))\n\nplt.subplot(1, 3, 1)\nplt.title('All TRUE bboxes for the batch of 32 img ')\nfor i in range(32):\n    show_two_bboxFROMpred(X_t[i], process_prediction(y_t[i]))\n \nplt.subplot(1, 3, 2)\nplt.title('All pred - seuil 0.8 ')\nfor i in range(32):\n    show_two_bboxFROMpred(X_t[i], process_prediction(y_t_pred_10ep[i]))\n    \nplt.subplot(1, 3, 3)\nplt.title('All pred - seuil 0.5 ')\nfor i in range(32):\n    show_two_bboxFROMpred(X_t[i], process_prediction(y_t_pred_10ep[i], threshold=0.5))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:03.494156Z","iopub.execute_input":"2021-09-30T11:37:03.49468Z","iopub.status.idle":"2021-09-30T11:37:08.679424Z","shell.execute_reply.started":"2021-09-30T11:37:03.494632Z","shell.execute_reply":"2021-09-30T11:37:08.678212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(12):\n plt.figure(figsize=(10, 8))\n\n plt.subplot(1, 3, 1)\n plt.title('img '+ str(i) +' TRUE')\n show_two_bboxFROMpred(X_t[i], process_prediction(y_t[i]), color='blue') \n\n plt.subplot(1, 3, 2)\n plt.title('img '+ str(i) + ' PRED - seuil 0.8 ')\n show_two_bboxFROMpred(X_t[i], process_prediction(y_t_pred_10ep[i]))\n\n plt.subplot(1, 3, 3)\n plt.title('img '+ str(i) + ' PRED - seuil 0.5 ')\n show_two_bboxFROMpred(X_t[i], process_prediction(y_t_pred_10ep[i], threshold=0.5))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:21:24.239286Z","iopub.execute_input":"2021-09-30T15:21:24.239639Z","iopub.status.idle":"2021-09-30T15:21:31.379589Z","shell.execute_reply.started":"2021-09-30T15:21:24.23961Z","shell.execute_reply":"2021-09-30T15:21:31.378611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef load_Data( data, targets ):\n    img_list=[]\n    label_list=[]\n    for i in tqdm(range(len(data))):\n        img_list.append( load_image_convert_target(data[i], targets[i])[0] )\n        label_list.append( load_image_convert_target(data[i], targets[i])[1] )\n        if i%500==0:\n            print(i)\n    return np.array(img_list), np.array(label_list)\n \n\ndataset_test = load_Data( X_train_path[:100], y_train[:100] ) \n\nX_train = dataset_test[0]\ny_t_train = dataset_test[1]\n# y_pred_train = model.predict(X_train)\ny_pred_10ep = model_trained_10.predict(X_train)\ny_train_pred_10ep = transform_netout(y_pred_10ep)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:37:08.680834Z","iopub.execute_input":"2021-09-30T11:37:08.681192Z","iopub.status.idle":"2021-09-30T11:41:47.09431Z","shell.execute_reply.started":"2021-09-30T11:37:08.681161Z","shell.execute_reply":"2021-09-30T11:41:47.093291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_two_bounding_boxV1(pathname, target, color='r'):\n    \n    image_bytes = tf.io.read_file(pathname)\n    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n    # Signification de bbox\n    x11, y11, x21, y21 = target[:4]\n    x12, y12, x22, y22 = target[8:]\n\n    # Afficher l'image\n    #plt.figure(figsize=(5, 5))\n    plt.imshow(np.squeeze(image.numpy()), cmap='gray')\n    \n    # Afficher les bounding box\n    plt.plot([x11,x21,x21,x11,x11],[y11,y11,y21,y21,y11], color)\n    plt.plot([x12,x22,x22,x12,x12],[y12,y12,y22,y22,y12], color)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:41:47.095621Z","iopub.execute_input":"2021-09-30T11:41:47.09615Z","iopub.status.idle":"2021-09-30T11:41:47.103006Z","shell.execute_reply.started":"2021-09-30T11:41:47.096115Z","shell.execute_reply":"2021-09-30T11:41:47.102153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"VERIFICATION QU'APRES LE REDIMENSIONNEMENT ET LA CONVERSION/DECONVERSION DES COORDONNEES EN GRILLES LES BBOX SONT BIEN AU MEME ENDROIT SUR L'IMAGE","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 6))\nfor i in range(5):\n\n  plt.subplot(2, 5, i+1)\n  plt.title('img '+ str(i+3) +' initial DIM')\n  show_two_bounding_boxV1(X_train_path[i+3], y_train[i+3], color='b')\n\n  plt.subplot(2, 5, 6+i)\n  plt.title('img '+ str(i+3) +' REDIM')\n  show_two_bboxFROMpred(X_train[i+3], process_prediction(y_t_train[i+3]))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:41:47.104256Z","iopub.execute_input":"2021-09-30T11:41:47.104724Z","iopub.status.idle":"2021-09-30T11:41:56.032029Z","shell.execute_reply.started":"2021-09-30T11:41:47.104692Z","shell.execute_reply":"2021-09-30T11:41:56.031026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_trueANDpred(im, cible, true_cible):\n    plt.imshow(im/255)\n    \n    x1, y1, x2, y2 = cible[:4]\n    plt.plot([x1,x2,x2,x1,x1],[y1,y1,y2,y2,y1],\"r\")\n    \n    x1, y1, x2, y2 = true_cible[:4]\n    plt.plot([x1,x2,x2,x1,x1],[y1,y1,y2,y2,y1],\"b\")","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:41:56.033346Z","iopub.execute_input":"2021-09-30T11:41:56.033651Z","iopub.status.idle":"2021-09-30T11:41:56.039796Z","shell.execute_reply.started":"2021-09-30T11:41:56.03362Z","shell.execute_reply":"2021-09-30T11:41:56.038868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AFFICHAGE DES PREDICITONS APRES 15 EPOCHS D'ENTRAINEMENT","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 50))\nfor i in range(100):\n  plt.subplot(20, 5, i+1)\n  show_trueANDpred(X_train[i], process_prediction(y_train_pred_10ep[i], threshold=0.5), process_prediction(y_t_train[i]))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:41:56.041278Z","iopub.execute_input":"2021-09-30T11:41:56.0419Z","iopub.status.idle":"2021-09-30T11:42:07.808011Z","shell.execute_reply.started":"2021-09-30T11:41:56.041822Z","shell.execute_reply":"2021-09-30T11:42:07.806745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 50))\nfor i in range(100):\n  plt.subplot(20, 5, i+1)\n  show_trueANDpred(X_train[i], process_prediction(y_train_pred_10ep[i], threshold=0.75), process_prediction(y_t_train[i]))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:42:07.809912Z","iopub.execute_input":"2021-09-30T11:42:07.810313Z","iopub.status.idle":"2021-09-30T11:42:19.694345Z","shell.execute_reply.started":"2021-09-30T11:42:07.810276Z","shell.execute_reply":"2021-09-30T11:42:19.69304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le modèle n'est pas encore assez entraîné pour prédire des bbox avec une probabilité robuste il a \"vu\" une grande majorité de cases vides donc il a tendance à prédire qu'il n'y a pas d'objet.","metadata":{}},{"cell_type":"code","source":"epochs = 5\nhistory = model_trained_10.fit(dataset_train, epochs = epochs, callbacks = [lr_plateau, checkpoint])","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:55.961642Z","iopub.execute_input":"2021-09-30T11:49:55.962038Z","iopub.status.idle":"2021-09-30T15:16:55.534133Z","shell.execute_reply.started":"2021-09-30T11:49:55.962002Z","shell.execute_reply":"2021-09-30T15:16:55.533233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_save_path = \"model_15ep.joblib\"\nmodel_trained_10.save( model_save_path)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:17:17.419999Z","iopub.execute_input":"2021-09-30T15:17:17.420405Z","iopub.status.idle":"2021-09-30T15:18:02.288148Z","shell.execute_reply.started":"2021-09-30T15:17:17.420374Z","shell.execute_reply":"2021-09-30T15:18:02.287037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(VA ARRETER LE SCRIPT)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.128055Z","iopub.status.idle":"2021-09-30T11:49:33.128765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_yolo_grid(g):\n    c_x = tf.cast(tf.reshape(tf.tile(tf.range(g), [g]), (1, g, g)), 'float32')\n    c_y = tf.transpose(c_x, (0,2,1))\n    return tf.stack([tf.reshape(c_x, (-1, g*g)), tf.reshape(c_y, (-1, g*g))] , -1)\n\nc_grid = generate_yolo_grid(output_shape[0])\n","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.130118Z","iopub.status.idle":"2021-09-30T11:49:33.130775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def proccess_xy(y_true_raw): # y_true shape 64 par 9\n    y_true_xy = ((y_true_raw[..., 1:3]+1)/2 + c_grid)/output_shape[0]\n    y_true_wh = y_true_raw[..., 3:5]\n    y_true_conf = y_true_raw[..., :1]\n    y_true_class = y_true_raw[..., 5:]\n    return tf.concat([y_true_conf, y_true_xy, y_true_wh, y_true_class], -1) \n# 64 par 9 on a juste changé la 2e et la 3e valeur","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.131905Z","iopub.status.idle":"2021-09-30T11:49:33.132534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_bboxes(y, threshold=0.8):\n    y_xy = tf.cast(y, tf.float32)\n    y_xy = tf.expand_dims(y_xy, axis=0) # 1 x 64 x 9\n    y_xy = proccess_xy(y_xy)[0] # = proccess_xy(y_xy) mais comme on a rajoute une dimension c'est pour que ce soit bien 64x9\n    #return y_xy\n    bboxes =  sorted(y_xy.numpy(), key=lambda x: x[0], reverse=True)\n    bboxes = np.array(bboxes)\n    result = bboxes[bboxes[...,0]>threshold]\n    if len(result)== 0:\n        return np.zeros((1, 9))\n        # return bboxes[[0]]\n    return result    ","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.133788Z","iopub.status.idle":"2021-09-30T11:49:33.13455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_save_path = output_path + \"model_test1_10epochs\" + \".joblib\"\nmodel.save( model_save_path)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.142969Z","iopub.status.idle":"2021-09-30T11:49:33.14361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! ls '/kaggle/input/notebookfc4bf591d7/model_test1_10epochs.joblib'","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.144941Z","iopub.status.idle":"2021-09-30T11:49:33.145579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = tf.keras.models.load_model(model_save_path, custom_objects = {\"global_loss\":global_loss})","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.146924Z","iopub.status.idle":"2021-09-30T11:49:33.147557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.load_weights(autosave_path)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.148717Z","iopub.status.idle":"2021-09-30T11:49:33.156397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history2 = model.fit(dataset_train, epochs = 3, workers=-1,  callbacks = [lr_plateau, checkpoint])","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.15779Z","iopub.status.idle":"2021-09-30T11:49:33.158405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image_augmentation_convert_target(pathname, cible): \n    \n    image_bytes = tf.io.read_file(pathname)\n    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n    img_shape = image.numpy().shape \n    resize = (256,256)\n    image = tf.image.resize(image, resize)\n        \n    ############################### bbox1 \n    x1 = cible[0]/img_shape[2]\n    y1 = cible[1]/img_shape[1]\n    x2 = cible[2]/img_shape[2]\n    y2 = cible[3]/img_shape[1]\n    \n    # Find the max translation to keep the object in the image\n    tx_max_bbox1 = 256 * (1 - x1)           # abscisse max de l'image shiftee\n    tx_min_bbox1 = -256 * (1 - x2)          # abscisse min du shift de l'image shiftee\n    ty_max_bbox1 = 256*tf.nn.relu( 1 - y1 ) # ordonne max de l'image shiftee\n    ty_min_bbox1 = -256*tf.nn.relu(1 - y2)  # ordonne min de l'image\n    \n    ############################### bbox2\n    x1 = cible[8]/img_shape[2]\n    y1 = cible[9]/img_shape[1]\n    x2 = cible[10]/img_shape[2]\n    y2 = cible[11]/img_shape[1]\n    \n    # Find the max translation to keep the object in the image\n    tx_max_bbox2 = 256 * (1 - x1)           # abscisse max de l'image shiftee\n    tx_min_bbox2 = -256 * (1 - x2)          # abscisse min du shift de l'image shiftee\n    ty_max_bbox2 = 256*tf.nn.relu( 1 - y1 ) # ordonne max de l'image shiftee\n    ty_min_bbox2 = -256*tf.nn.relu(1 - y2)  # ordonne min de l'image\n      \n    ################### SHIFT FINAL image\n    tx = np.random( (np.min(tx_min_bbox1, tx_min_bbox2)), (np.min(tx_max_bbox1, tx_max_bbox2)) ) # horizontal translation\n    ty = np.random( (np.min(ty_min_bbox1, ty_min_bbox2)), (np.min(ty_max_bbox1, ty_max_bbox2)) ) # vertical translation\n    \n    # New coord calcul\n    cible[0] += tx/256\n    cible[1] += ty/256\n    cible[2] += tx/256\n    cible[3] += ty/256\n    cible[8] += tx/256\n    cible[9] += ty/256\n    cible[10] += tx/256\n    cible[11] += ty/256\n    \n    im = tf.keras.preprocessing.image.apply_affine_transform(\n    image.numpy().reshape([256, 256]), theta=0, tx = ty, ty = tx, shear=0, zx=1, zy=1, row_axis=0, col_axis=1,\n    channel_axis=2, fill_mode='nearest', cval=0.0, order=1)\n    \n    return image, convert_target(pathname, cible)[1]\n","metadata":{"execution":{"iopub.status.busy":"2021-09-30T11:49:33.15987Z","iopub.status.idle":"2021-09-30T11:49:33.160417Z"},"trusted":true},"execution_count":null,"outputs":[]}]}