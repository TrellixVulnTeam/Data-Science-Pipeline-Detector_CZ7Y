{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport shutil\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom glob import glob\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n#customize iPython writefile so we can write variables\nfrom IPython.core.magic import register_line_cell_magic\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))\n        \nimport torch\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:20:58.346171Z","iopub.execute_input":"2021-07-21T05:20:58.346519Z","iopub.status.idle":"2021-07-21T05:21:05.585323Z","shell.execute_reply.started":"2021-07-21T05:20:58.346487Z","shell.execute_reply":"2021-07-21T05:21:05.584323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:21:08.046342Z","iopub.execute_input":"2021-07-21T05:21:08.046702Z","iopub.status.idle":"2021-07-21T05:22:19.868215Z","shell.execute_reply.started":"2021-07-21T05:21:08.046673Z","shell.execute_reply":"2021-07-21T05:22:19.867282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fast_df = False\nIMG_SIZE = 600","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:22:19.869997Z","iopub.execute_input":"2021-07-21T05:22:19.870364Z","iopub.status.idle":"2021-07-21T05:22:19.877279Z","shell.execute_reply.started":"2021-07-21T05:22:19.870325Z","shell.execute_reply":"2021-07-21T05:22:19.876538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:22:19.880237Z","iopub.execute_input":"2021-07-21T05:22:19.880478Z","iopub.status.idle":"2021-07-21T05:22:20.139934Z","shell.execute_reply.started":"2021-07-21T05:22:19.880455Z","shell.execute_reply":"2021-07-21T05:22:20.139117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:22:20.141356Z","iopub.execute_input":"2021-07-21T05:22:20.141676Z","iopub.status.idle":"2021-07-21T05:22:20.14929Z","shell.execute_reply.started":"2021-07-21T05:22:20.141642Z","shell.execute_reply":"2021-07-21T05:22:20.148524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split = 'test'\nimage_id = []\ndim0 = []\ndim1 = []\nsplits = []\nsave_dir = f'/kaggle/tmp/{split}/image/'\nos.makedirs(save_dir, exist_ok=True)\n\nfor dirname, _, filenames in tqdm(os.walk(f'/kaggle/input/siim-covid19-detection/{split}')):\n    for file in filenames:\n        # set keep_ratio=True to have original aspect ratio\n        xray = read_xray(os.path.join(dirname, file))\n        im = resize(xray, size=IMG_SIZE)  \n        im.save(os.path.join(save_dir, file.replace('.dcm', '_image.jpeg')))\n        image_id.append(file.replace('.dcm', ''))\n        dim0.append(xray.shape[0])\n        dim1.append(xray.shape[1])\n        splits.append(split)\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:24:15.022677Z","iopub.execute_input":"2021-07-21T05:24:15.023094Z","iopub.status.idle":"2021-07-21T05:32:26.833155Z","shell.execute_reply.started":"2021-07-21T05:24:15.023057Z","shell.execute_reply":"2021-07-21T05:32:26.832042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = \"/kaggle/input/k/ajinkyadeshpande39/yolo-notebook/tmp/yolov5/artifacts/run_1qerm3x5_model:v24/last.pt\"\n# MODEL_PATH = \"/kaggle/input/yolov5-150-epochs-covid-localization/best.pt\"\n# MODEL_PATH = \"/kaggle/input/yolo-notebook/tmp/yolov5/artifacts/run_2yubez04_model:v29/best.pt\"\nTEST_PATH = '/kaggle/tmp/test/image'","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:32:26.834884Z","iopub.execute_input":"2021-07-21T05:32:26.835335Z","iopub.status.idle":"2021-07-21T05:32:26.83992Z","shell.execute_reply.started":"2021-07-21T05:32:26.835291Z","shell.execute_reply":"2021-07-21T05:32:26.838838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from numba import cuda\n# import torch\n# cuda.select_device(0)\n# cuda.close()\n# cuda.select_device(0)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:04:10.543345Z","iopub.execute_input":"2021-07-21T04:04:10.54374Z","iopub.status.idle":"2021-07-21T04:04:11.468567Z","shell.execute_reply.started":"2021-07-21T04:04:10.543681Z","shell.execute_reply":"2021-07-21T04:04:11.467668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/input/k/ajinkyadeshpande39/yolo-notebook/tmp/yolov5","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:32:26.842396Z","iopub.execute_input":"2021-07-21T05:32:26.842962Z","iopub.status.idle":"2021-07-21T05:32:26.856774Z","shell.execute_reply.started":"2021-07-21T05:32:26.842921Z","shell.execute_reply":"2021-07-21T05:32:26.855816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"all the detection will be stored in '/kaggle/tmp/detect'","metadata":{}},{"cell_type":"code","source":"!python detect.py --weights {MODEL_PATH} \\\n                  --source {TEST_PATH} \\\n                  --img {512} \\\n                  --conf 0.3 \\\n                  --iou 0.4\\\n                  --save-txt \\\n                  --save-conf \\\n                  --project \"/kaggle/tmp/detect\"","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:32:26.858805Z","iopub.execute_input":"2021-07-21T05:32:26.859556Z","iopub.status.idle":"2021-07-21T05:33:42.815729Z","shell.execute_reply.started":"2021-07-21T05:32:26.85952Z","shell.execute_reply":"2021-07-21T05:33:42.814824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model =  tf.keras.models.load_model(\"/kaggle/input/efficientnetb7/weights/my_model.h5\") \n#83%","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model =  tf.keras.models.load_model(\"/kaggle/input/efficientnetweights/weights/my_model.h5\") \n#75%","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model =  tf.keras.models.load_model(\"/kaggle/input/efnetb7-layers-increased-more-trainable-layers/weights/my_model.h5\")\n#65%","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:41:49.40045Z","iopub.execute_input":"2021-07-23T09:41:49.400861Z","iopub.status.idle":"2021-07-23T09:41:49.405322Z","shell.execute_reply.started":"2021-07-23T09:41:49.400778Z","shell.execute_reply":"2021-07-23T09:41:49.404136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name2label = { \n    'negative': 2,\n    'indeterminate': 1,\n    'atypical': 0,\n    'typical': 3}\nlabel2name  = {v:k for k, v in name2label.items()}","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:33:58.789143Z","iopub.execute_input":"2021-07-21T05:33:58.789476Z","iopub.status.idle":"2021-07-21T05:33:58.794248Z","shell.execute_reply.started":"2021-07-21T05:33:58.789442Z","shell.execute_reply":"2021-07-21T05:33:58.79346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepaths = glob('/kaggle/input/siim-covid19-detection/test/**/*dcm',recursive=True)\ntest_df = pd.DataFrame({'filepath':filepaths,})\ntest_df['image_id'] = test_df.filepath.map(lambda x: x.split('/')[-1].replace('.dcm', '')+'_image')\ntest_df['study_id'] = test_df.filepath.map(lambda x: x.split('/')[-3].replace('.dcm', '')+'_study')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:33:58.795652Z","iopub.execute_input":"2021-07-21T05:33:58.796218Z","iopub.status.idle":"2021-07-21T05:34:01.795787Z","shell.execute_reply.started":"2021-07-21T05:33:58.796183Z","shell.execute_reply":"2021-07-21T05:34:01.795053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"path_modified\"] = test_df.filepath.map(lambda x: \"/kaggle/tmp/test/image/\" +\n                                                x.split('/')[-1].replace('.dcm', '')+\"_image.jpeg\")","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:34:01.79814Z","iopub.execute_input":"2021-07-21T05:34:01.798491Z","iopub.status.idle":"2021-07-21T05:34:01.804575Z","shell.execute_reply.started":"2021-07-21T05:34:01.798455Z","shell.execute_reply":"2021-07-21T05:34:01.803537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:34:01.806358Z","iopub.execute_input":"2021-07-21T05:34:01.807161Z","iopub.status.idle":"2021-07-21T05:34:01.825247Z","shell.execute_reply.started":"2021-07-21T05:34:01.80705Z","shell.execute_reply":"2021-07-21T05:34:01.824434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PRED_PATH = '/kaggle/tmp/detect/exp/labels'\n!ls {PRED_PATH}","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:34:01.826446Z","iopub.execute_input":"2021-07-21T05:34:01.826802Z","iopub.status.idle":"2021-07-21T05:34:02.66262Z","shell.execute_reply.started":"2021-07-21T05:34:01.826755Z","shell.execute_reply":"2021-07-21T05:34:02.661558Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_files = os.listdir(PRED_PATH)\nprint('Number of test images predicted as opaque: ', len(prediction_files))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:34:02.66627Z","iopub.execute_input":"2021-07-21T05:34:02.666549Z","iopub.status.idle":"2021-07-21T05:34:02.676842Z","shell.execute_reply.started":"2021-07-21T05:34:02.666522Z","shell.execute_reply":"2021-07-21T05:34:02.675918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The submisison requires xmin, ymin, xmax, ymax format. \n# YOLOv5 returns x_center, y_center, width, height\ndef correct_bbox_format(bboxes):\n    correct_bboxes = []\n    for b in bboxes:\n        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n\n        xmin = xc - int(np.round(w/2))\n        xmax = xc + int(np.round(w/2))\n        ymin = yc - int(np.round(h/2))\n        ymax = yc + int(np.round(h/2))\n        \n        correct_bboxes.append([xmin, xmax, ymin, ymax])\n        \n    return correct_bboxes\n\n# Read the txt file generated by YOLOv5 during inference and extract \n# confidence and bounding box coordinates.\ndef get_conf_bboxes(file_path):\n    confidence = []\n    bboxes = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            preds = line.strip('\\n').split(' ')\n            preds = list(map(float, preds))\n            confidence.append(preds[-1])\n            bboxes.append(preds[1:-1])\n    return confidence, bboxes","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:34:02.678762Z","iopub.execute_input":"2021-07-21T05:34:02.679144Z","iopub.status.idle":"2021-07-21T05:34:02.695284Z","shell.execute_reply.started":"2021-07-21T05:34:02.679107Z","shell.execute_reply":"2021-07-21T05:34:02.694283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the submisison file\nsub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\nsub_df","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:34:02.696929Z","iopub.execute_input":"2021-07-21T05:34:02.697313Z","iopub.status.idle":"2021-07-21T05:34:02.729597Z","shell.execute_reply.started":"2021-07-21T05:34:02.697275Z","shell.execute_reply":"2021-07-21T05:34:02.728867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction loop for submission\npredictions = []\n# iterating through submission.csv.\nfor i in tqdm(range(len(sub_df))):\n    row = sub_df.loc[i]\n    id_name = row.id.split('_')[0]\n    id_level = row.id.split('_')[-1]\n    # passing all images under this id through Efficientneb7 model if id_level is 'study' \n    if id_level == 'study':\n        # one study can contain more than one images. multiple images can have same predictions. appending all predictions \n        # in set and submitting only distinct predictions. \n        temp = set()\n        ans =\"\"\n        for i in test_df.loc[test_df[\"study_id\"]==row.id][\"path_modified\"] :\n            # dcm to jpeg\n            img = tf.io.read_file(i)\n            img = tf.image.decode_jpeg(img, channels=1)\n            img = tf.reshape(img,(1,IMG_SIZE,IMG_SIZE,1))\n            # output predictions\n            op = Model(img)\n            label = label2name[op.numpy().argmax()]+\" 1 0 0 1 1\" \n            temp.add(label)\n        for i in temp:\n            ans = ans +i+\" \"\n            \n        predictions.append(ans.strip())\n\n    elif id_level == 'image':\n        # we can do image-level classification here.\n        # also we can rely on the object detector's classification head.\n        # for this example submisison we will use YOLO's classification head. \n        # since we already ran the inference we know which test images belong to opacity.\n        if f'{id_name}_{id_level}.txt' in prediction_files:\n            # opacity label\n            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}/{id_name}_{id_level}.txt')\n            bboxes = correct_bbox_format(bboxes)\n            pred_string = ''\n            for j, conf in enumerate(confidence):\n                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n            predictions.append(pred_string[:-1]) \n        else:\n            predictions.append(\"none 1 0 0 1 1\")","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:34:02.732448Z","iopub.execute_input":"2021-07-21T05:34:02.732741Z","iopub.status.idle":"2021-07-21T05:39:14.623583Z","shell.execute_reply.started":"2021-07-21T05:34:02.732711Z","shell.execute_reply":"2021-07-21T05:39:14.622411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['PredictionString'] = predictions\nsub_df.to_csv('/kaggle/working/submission.csv', index=False)\nsub_df","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:39:14.625114Z","iopub.execute_input":"2021-07-21T05:39:14.625403Z","iopub.status.idle":"2021-07-21T05:39:14.895591Z","shell.execute_reply.started":"2021-07-21T05:39:14.625375Z","shell.execute_reply":"2021-07-21T05:39:14.894779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:14:54.805171Z","iopub.execute_input":"2021-07-21T04:14:54.805523Z","iopub.status.idle":"2021-07-21T04:14:54.858906Z","shell.execute_reply.started":"2021-07-21T04:14:54.805489Z","shell.execute_reply":"2021-07-21T04:14:54.857922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}