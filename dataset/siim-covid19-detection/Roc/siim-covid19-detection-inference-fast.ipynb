{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\nif pd.read_csv('../input/siim-covid19-detection/sample_submission.csv').shape[0] != 2477:\n    \n    !bash ../input/preprocessing/setup.sh\n    import os\n    import cv2\n\n    from PIL import Image\n    from tqdm.auto import tqdm\n\n    import numpy as np\n    import pandas as pd\n    import pydicom\n    from pydicom.pixel_data_handlers.util import apply_voi_lut\n\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from torch.utils.data import Dataset,DataLoader,ConcatDataset\n    import albumentations as A\n    from albumentations.pytorch import ToTensorV2\n\n    from sklearn.metrics import average_precision_score\n    from glob import glob\n    import shutil\n    import matplotlib.pyplot as plt\n    from sklearn.model_selection import GroupKFold\n    import seaborn as sns\n    import pandas as pd\n    import numpy as np\n    import gc\n\n    from PIL import Image\n    from tqdm.auto import tqdm\n\n    # pytorch lighting\n    import pytorch_lightning as pl\n    import pickle\n    import warnings \n    import sys\n    sys.path.append('../input/timm210703/pytorch-image-models-master-210703')\n    import timm\n\n    import torch.nn.functional as F\n\n    import torch\n    import torch.nn as nn\n\n    warnings.filterwarnings('ignore')\n    !python ../input/preprocessing/preprocess.py --img_size 640 --output_dir /kaggle/temp/\n\n    def compute_oof_map(df):\n        negative_map = average_precision_score(df['Negative for Pneumonia'], df['negative'])\n        typical_map = average_precision_score(df['Typical Appearance'], df['typical'])\n        indeterminate_map = average_precision_score(df['Indeterminate Appearance'], df['indeterminate'])\n        atypical_map = average_precision_score(df['Atypical Appearance'], df['atypical'])\n        map = (negative_map + typical_map + indeterminate_map + atypical_map) / 6\n\n        return map\n\n    def memory_cleanup():\n        \"\"\"\n        Cleans up GPU memory\n        https://github.com/huggingface/transformers/issues/1742\n        \"\"\"\n        print('Cleaning GPU....')\n        for obj in gc.get_objects():\n            if torch.is_tensor(obj):\n                del obj\n\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    root_dir1 = '../input/siim-covid19-pred-oofs/siim-covid19-pred-oofs/'\n    model_0_path = f'{root_dir1}tf_efficientnet_b5_ns/'\n    model_1_path = f'{root_dir1}tf_efficientnet_b7_ns/'\n    model_2_path = f'{root_dir1}tf_efficientnetv2_m/'\n    model_3_path = f'{root_dir1}swin_base_patch4_window12_384/'\n    model_4_path = f'../input/effnet-b5-models-test-2477-pseudo/tf_efficientnet_b5_ns/'\n#     model_1_path = f'../input/effnet-b5-models-v3/tf_efficientnet_b5_ns/'\n#     model_2_path = f'../input/effnet-b7-models-v3/tf_efficientnet_b7_ns/'\n#     model_3_path = f'../input/effnetv2-m-models-v3/tf_efficientnetv2_m/'\n#     model_4_path = f'../input/swim-trans-models-v3/'\n\n    models_states = [\n        [\n            f'{model_0_path}/fold_0/oof_preds_tta_flip.csv',\n            f'{model_0_path}/fold_1/oof_preds_tta_flip.csv',\n            f'{model_0_path}/fold_2/oof_preds_tta_flip.csv',\n            f'{model_0_path}/fold_3/oof_preds_tta_flip.csv',\n            f'{model_0_path}/fold_4/oof_preds_tta_flip.csv',\n        ],\n        [\n            f'{model_1_path}/fold_0/oof_preds_tta_flip.csv',\n            f'{model_1_path}/fold_1/oof_preds_tta_flip.csv',\n            f'{model_1_path}/fold_2/oof_preds_tta_flip.csv',\n            f'{model_1_path}/fold_3/oof_preds_tta_flip.csv',\n            f'{model_1_path}/fold_4/oof_preds_tta_flip.csv',\n        ],\n        [\n            f'{model_2_path}/fold_0/oof_preds_tta_flip.csv',\n            f'{model_2_path}/fold_1/oof_preds_tta_flip.csv',\n            f'{model_2_path}/fold_2/oof_preds_tta_flip.csv',\n            f'{model_2_path}/fold_3/oof_preds_tta_flip.csv',\n            f'{model_2_path}/fold_4/oof_preds_tta_flip.csv',\n        ],\n        [\n            f'{model_3_path}/fold_0/oof_preds_tta_flip.csv',\n            f'{model_3_path}/fold_1/oof_preds_tta_flip.csv',\n            f'{model_3_path}/fold_2/oof_preds_tta_flip.csv',\n            f'{model_3_path}/fold_3/oof_preds_tta_flip.csv',\n            f'{model_3_path}/fold_4/oof_preds_tta_flip.csv',\n        ],\n        [\n            f'{model_4_path}/fold_0/oof_preds_tta_flip.csv',\n            f'{model_4_path}/fold_1/oof_preds_tta_flip.csv',\n            f'{model_4_path}/fold_2/oof_preds_tta_flip.csv',\n            f'{model_4_path}/fold_3/oof_preds_tta_flip.csv',\n            f'{model_4_path}/fold_4/oof_preds_tta_flip.csv',\n        ],\n    ]\n\n    study_folds_csv_path = '../input/train-study-folds/train_study_folds_washen_v2.csv'\n    study_folds = pd.read_csv(study_folds_csv_path)\n\n    study_folds = study_folds[['image','None','Opacity','fold']]\n    study_folds.columns = ['image','None','Opacity','fold_n']\n\n    z = [['Atypical Appearance','atypical'],\n        ['Negative for Pneumonia','negative'],\n        ['Indeterminate Appearance','indeterminate'],\n        ['Typical Appearance','typical'],\n        ['None','negative']\n        ]\n\n    ww = []\n    tt = []\n    final_score = []\n    for jj in z:\n        t,p = jj[0], jj[1]\n        oof_zoo = []\n        for index, states in enumerate(models_states):\n            oof = []\n            for fold,state in enumerate(states):\n                none_df = study_folds[study_folds.fold_n == fold]\n                df = pd.read_csv(state)\n                if index == 4:\n                    df.columns = df.columns.str.replace('None', 'None_bimcv_p')\n                    df.columns = df.columns.str.replace('Opacity', 'Opacity_bimcv_p')\n                df = pd.merge(df, none_df, on = 'image', how = 'left')\n\n\n                oof.append(df.loc[:,['study_id',t,p, 'fold']])\n            oof_zoo.append(pd.concat(oof).reset_index())\n\n        x = np.zeros(( len(oof_zoo[0]),len(oof_zoo) ))\n        for k in range(len(oof_zoo)):\n            x[:,k] = oof_zoo[k][p].values\n\n        TRUE = oof_zoo[0][t].values\n        all = []\n        for k in range(x.shape[1]):\n            auc = average_precision_score(oof_zoo[0][t],x[:,k])\n            all.append(auc)\n            print('Model %i has OOF AUC = %.4f'%(k,auc))\n\n        m = [np.argmax(all)]; w = []\n        old = np.max(all); \n\n        RES = 100; \n        PATIENCE = 30; \n        TOL = 0.0000003\n        DUPLICATES = True\n\n        print('Ensemble AUC = %.4f by beginning with model %i'%(old,m[0]))\n        print()\n\n        for kk in range(len(oof_zoo)):\n\n            # BUILD CURRENT ENSEMBLE\n            md = x[:,m[0]]\n            for i,k in enumerate(m[1:]):\n                md = w[i]*x[:,k] + (1-w[i])*md\n\n            # FIND MODEL TO ADD\n            mx = 0; mx_k = 0; mx_w = 0\n            print('Searching for best model to add... ')\n\n            # TRY ADDING EACH MODEL\n            for k in range(x.shape[1]):\n                print(k,', ',end='')\n                if not DUPLICATES and (k in m): continue\n\n                # EVALUATE ADDING MODEL K WITH WEIGHTS W\n                bst_j = 0; bst = 0; ct = 0\n                for j in range(RES):\n                    tmp = j/RES*x[:,k] + (1-j/RES)*md\n                    auc =  average_precision_score(TRUE,tmp**0.5)\n                    if auc>bst:\n                        bst = auc\n                        bst_j = j/RES\n                    else: ct += 1\n                    if ct>PATIENCE: continue\n                if bst>mx:\n                    mx = bst\n                    mx_k = k\n                    mx_w = bst_j\n\n            # STOP IF INCREASE IS LESS THAN TOL\n            inc = mx-old\n            if inc<=TOL: \n                print(); print('No increase. Stopping.')\n                continue\n\n            # DISPLAY RESULTS\n            print(); #print(kk,mx,mx_k,mx_w,'%.5f'%inc)\n            print('Ensemble AUC = %.4f after adding model %i with weight %.3f. Increase of %.4f'%(mx,mx_k,mx_w,inc))\n            print()\n\n            old = mx; m.append(mx_k); w.append(mx_w)\n        print('We are using models',m)\n        ww.append(w)\n        tt.append(m)\n        print('with weights',w)\n        print('and achieve ensemble AUC = %.4f'%old)\n        final_score.append(old)\n        md = x[:,m[0]]\n        for i,k in enumerate(m[1:]):\n            md = w[i]*x[:,k] + (1-w[i])*md\n        df = oof_zoo[0].copy()\n        df[p] = md\n    #     df.to_csv(f'ensemble_oof_{p}.csv',index=False)\n\n    print(f'Total mAP: {sum(final_score)/6}')\n\n    study2images_d = pickle.load(open('/kaggle/temp/study2images_d.pickle', 'rb'))\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n    image2shape_d = pd.read_pickle('/kaggle/temp/image2shape_d.pickle')\n    image_df = sub_df.copy()\n\n    class Config:\n        data_dir = '../input/siim-covid19-detection/'\n        test_csv_path = data_dir + 'sample_submission.csv'\n\n        num_classes = 4\n        model_name = 'tf_efficientnet_b5_ns'\n    #     model_name = 'tf_efficientnet_b7_ns'\n    #     model_name = 'tf_efficientnetv2_m'\n        image_size = 512            ### input size in training\n\n    #     model_name = 'swin_base_patch4_window12_384'\n    #     image_size = 384            ### input size in training\n        batch_size = 32\n        num_workers = 4\n\n        device = 'cuda'             ### set gpu or cpu mode\n        debug = False              ### debug flag for checking your modify code\n\n    CFG = Config\n\n    test_df = pd.read_csv(CFG.test_csv_path)\n    study_len = test_df[test_df.id.str.contains('study')].index\n    test_df = test_df[test_df.id.str.contains('image')]\n\n    test_df['negative'] = 0\n    test_df['typical'] = 0\n    test_df['indeterminate'] = 0\n    test_df['atypical'] = 0\n\n    label_cols = test_df.columns[2:]\n\n    def to_tensor(x, **kwargs):\n        if x.ndim==2 : \n            x = np.expand_dims(x,2)\n        x = np.transpose(x,(2,0,1)).astype('float32') / 255.\n\n        x = torch.from_numpy(x)\n        return x\n\n    def get_preprocessing():\n        \"\"\"Construct preprocessing transform\n\n        Args:\n            preprocessing_fn (callbale): data normalization function \n                (can be specific for each pretrained neural network)\n        Return:\n            transform: albumentations.Compose\n\n        \"\"\"\n\n        _transform = [\n    #         A.Lambda(image=preprocessing_fn),\n            A.Lambda(image=to_tensor, mask=to_tensor),\n        ]\n        return A.Compose(_transform)\n\n\n    def get_val_transforms(CFG):\n        return A.Compose([\n                A.Resize(CFG.image_size, CFG.image_size),\n    #             A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n    #             ToTensorV2(),\n            ],p=1.0)\n\n    class SIIMTestDataset(Dataset):\n        def __init__(self, df, transforms=None, preprocessing=None):\n            super().__init__()\n            self.df = df\n            self.transforms = transforms\n            self.preprocessing = preprocessing\n            self.length = len(df)\n\n        def __len__(self):\n            return self.length\n\n        def __getitem__(self, index):\n            d = self.df.iloc[index]\n            split = d.id.split('_')[-1]\n            image_path =  '/kaggle/temp/test/%s.png' % (d.id[:-6])\n            image = cv2.imread(image_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            if image is None:\n                raise FileNotFoundError(image_path)\n\n            # apply augmentations\n            if self.transforms:\n                image = self.transforms(image=image)['image']\n            else:\n                image = torch.from_numpy(image)\n\n            # apply preprocessing\n            if self.preprocessing:\n                sample = self.preprocessing(image=image)\n                image = sample['image']\n\n            return image\n\n\n    def gem(x, p=3, eps=1e-6):\n        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n\n    class GeM(nn.Module):\n        def __init__(self, p=3, eps=1e-6):\n            super(GeM, self).__init__()\n            self.p = nn.Parameter(torch.ones(1) * p)\n            self.eps = eps\n        def forward(self, x):\n            return gem(x, p=self.p, eps=self.eps)[:,:,0,0]\n        def __repr__(self):\n            return (\n                self.__class__.__name__\n                + f\"(p={self.p.data.tolist()[0]:.4f}, eps={str(self.eps)})\"\n            )\n\n    class SIIMMaskNet(nn.Module):\n        def __init__(self, model_name, num_classes, pretrained=False):\n            super(SIIMMaskNet,self).__init__()\n            self.model_name = model_name\n            self.model = timm.create_model(model_name, pretrained=pretrained)\n\n            ### effnet\n            if model_name == 'tf_efficientnet_b5_ns' or model_name == 'tf_efficientnet_b7_ns':\n    #             self.model.global_pool = GeM()\n                num_features = self.model.classifier.in_features  \n                self.model.classifier = nn.Linear(num_features, num_classes)\n\n            if model_name == 'tf_efficientnetv2_m':   \n                num_features = self.model.classifier.in_features  \n                self.model.classifier = nn.Linear(num_features, num_classes)\n\n            if model_name == 'swin_base_patch4_window12_384':\n                num_features = self.model.head.in_features  \n                self.model.head = nn.Linear(num_features, num_classes) \n\n\n            hidden_dims = 128\n            ## for effnet \n            if model_name == 'tf_efficientnet_b5_ns' or model_name == 'tf_efficientnetv2_m':\n                self.mask = nn.Sequential(\n                    nn.Conv2d(176, hidden_dims, kernel_size=3, padding=1), \n                    nn.BatchNorm2d(hidden_dims),\n                    nn.ReLU(inplace=True),\n                    nn.Conv2d(hidden_dims, hidden_dims, kernel_size=3, padding=1),\n                    nn.BatchNorm2d(hidden_dims),\n                    nn.ReLU(inplace=True),\n                    nn.Conv2d(hidden_dims, 1, kernel_size=1, padding=0),\n                )\n\n            if model_name == 'tf_efficientnet_b7_ns':\n                self.mask = nn.Sequential(\n                    nn.Conv2d(224, hidden_dims, kernel_size=3, padding=1), \n                    nn.BatchNorm2d(hidden_dims),\n                    nn.ReLU(inplace=True),\n                    nn.Conv2d(hidden_dims, hidden_dims, kernel_size=3, padding=1),\n                    nn.BatchNorm2d(hidden_dims),\n                    nn.ReLU(inplace=True),\n                    nn.Conv2d(hidden_dims, 1, kernel_size=1, padding=0),\n                )    \n\n            ### for transformer\n            if model_name == 'swin_base_patch4_window12_384':\n                self.mask = nn.Sequential(\n                    nn.Conv2d(512, hidden_dims, kernel_size=3, padding=1), ### swin\n                    nn.BatchNorm2d(hidden_dims),\n                    nn.ReLU(inplace=True),\n                    nn.Conv2d(hidden_dims, hidden_dims, kernel_size=3, padding=1),\n                    nn.BatchNorm2d(hidden_dims),\n                    nn.ReLU(inplace=True),\n                    nn.Conv2d(hidden_dims, 1, kernel_size=1, padding=0),\n                )\n\n\n        def forward(self, x):\n            if self.model_name == 'tf_efficientnet_b5_ns' or self.model_name == 'tf_efficientnet_b7_ns' or self.model_name == 'tf_efficientnetv2_m':\n                x = self.model.act1(self.model.bn1(self.model.conv_stem(x)))\n                x = self.model.blocks[0](x)\n                x = self.model.blocks[1](x)\n                x = self.model.blocks[2](x)\n                x = self.model.blocks[3](x)\n                x = self.model.blocks[4](x)\n\n                ####----\n                mask = self.mask(x)\n                ####----\n\n                x = self.model.blocks[5](x)\n                x = self.model.blocks[6](x)\n                conv5 = self.model.act2(self.model.bn2(self.model.conv_head(x)))\n\n                feat = self.model.global_pool(conv5).view(conv5.size(0), -1)\n                logits = self.model.classifier(feat)\n\n            if self.model_name == 'swin_base_patch4_window12_384':\n                x = self.model.patch_embed(x)\n                if self.model.absolute_pos_embed is not None:\n                    x = x + self.model.absolute_pos_embed\n                x = self.model.pos_drop(x)\n                x = self.model.layers[0](x)\n                x = self.model.layers[1](x)\n\n    #             x = self.model.layers[2](x)\n                for blk in self.model.layers[2].blocks:\n                    if not torch.jit.is_scripting() and self.model.layers[2].use_checkpoint:\n                        x = checkpoint.checkpoint(blk, x)\n                    else:\n                        x = blk(x)\n\n                ####----\n                # B L C to B C L\n                x_mask = x.transpose(1, 2)\n                # B C L to B C H W\n                x_mask = x_mask.reshape(x_mask.size(0),x_mask.size(1), 24, 24) # 24 = 384 / 16\n                mask = self.mask(x_mask)\n                ####----\n\n                if self.model.layers[2].downsample is not None:\n                    x = self.model.layers[2].downsample(x)\n\n                x = self.model.layers[3](x)\n                conv5 = x\n                x = self.model.norm(x)  # B L C\n                x = self.model.avgpool(x.transpose(1, 2))  # B C 1\n                feat = torch.flatten(x, 1)\n                logits = self.model.head(feat)\n\n            return logits, mask\n\n    class SIIMPLModel(pl.LightningModule):\n        def __init__(self):\n            super(SIIMPLModel,self).__init__()\n            self.model = SIIMMaskNet(CFG.model_name, CFG.num_classes, pretrained=False)\n\n        def forward(self, x):\n            return self.model(x)\n\n    def do_predict(model, test_loader, tta=['']):\n        print(f'tta is {tta}')\n        test_probability = []\n        test_num = 0\n        tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n        for t, (image) in tk0:\n            batch_size = image.size(0)\n            image = image.to(device)\n            #<todo> TTA\n            model.eval()\n            with torch.no_grad():\n                probability = []\n                logit, mask = model(image)\n                probability.append(F.softmax(logit,-1))\n\n                if 'flip' in tta:\n                    logit, mask = model(torch.flip(image,dims=(3,)))\n                    probability.append(F.softmax(logit,-1))\n\n                if 'scale' in tta:\n                    # size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None):\n                    logit, mask = model(F.interpolate(image, scale_factor=1.25, mode='bilinear', align_corners=False))\n                    probability.append(F.softmax(logit,-1))\n\n                #--------------\n                probability = torch.stack(probability,0).mean(0)\n\n            test_num += batch_size\n            test_probability.append(probability.data.cpu().numpy())\n        assert(test_num == len(test_loader.dataset))\n\n        probability = np.concatenate(test_probability)\n        return probability\n\n    # ====================================================\n    # Helper functions\n    # ====================================================\n    def inference(model, states, test_loader, device, ttas):\n        probs = 0\n        for (state,tta) in zip(states,ttas):\n            model = model.load_from_checkpoint(state)\n            model.to(device)\n            probability = do_predict(model, test_loader, tta)\n            probs += probability**0.5\n        probs = probs/len(states) \n        return probs\n\n    # ====================================================\n    # inference\n    # ====================================================\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    SUB_CSV = []\n\n    ### load test dataloader\n    CFG.image_size = 512\n    test_dataset_512 = SIIMTestDataset(test_df, transforms=get_val_transforms(CFG), preprocessing=get_preprocessing())\n    test_loader_512 = DataLoader(test_dataset_512, CFG.batch_size, num_workers=CFG.num_workers, shuffle=False) \n\n    CFG.image_size = 384\n    test_dataset_384 = SIIMTestDataset(test_df, transforms=get_val_transforms(CFG), preprocessing=get_preprocessing())\n    test_loader_384 = DataLoader(test_dataset_384, CFG.batch_size, num_workers=CFG.num_workers, shuffle=False) \n    memory_cleanup()\n    \n    \n    #### b5 v1\n    CFG.model_name = 'tf_efficientnet_b5_ns'\n    CFG.image_size = 512\n\n    ### init pl model\n    pl_model = SIIMPLModel()\n\n    ### load test dataloader\n    if CFG.image_size == 512:\n        test_loader = test_loader_512\n    else:\n        test_loader = test_loader_384\n\n    model_path = '../input/efficientnetb5models/tf_efficientnet_b5_ns/'\n\n    states = [\n        f'{model_path}/fold0_best_mAP.ckpt',\n        f'{model_path}/fold1_best_mAP.ckpt',\n        f'{model_path}/fold2_best_mAP.ckpt',\n        f'{model_path}/fold3_best_mAP.ckpt',\n        f'{model_path}/fold4_best_mAP.ckpt',\n    ]\n\n    fold_ttas = [\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ]\n    predictions = inference(pl_model, states, test_loader, device, fold_ttas)\n\n    pred_df = test_df.copy()\n    pred_df[label_cols] = predictions\n    print(pred_df.head())\n    SUB_CSV.append(pred_df)\n    # SUB_CSV\n    memory_cleanup()\n    \n    #### b7 v1\n    CFG.model_name = 'tf_efficientnet_b7_ns'\n    CFG.image_size = 512\n\n    ### init pl model\n    pl_model = SIIMPLModel()\n\n    ### load test dataloader\n    if CFG.image_size == 512:\n        test_loader = test_loader_512\n    else:\n        test_loader = test_loader_384\n\n    model_path = '../input/efficientnetb7models/tf_efficientnet_b7_ns/'\n\n    states = [\n        f'{model_path}/fold0_best_mAP.ckpt',\n        f'{model_path}/fold1_best_mAP.ckpt',\n        f'{model_path}/fold2_best_mAP.ckpt',\n        f'{model_path}/fold3_best_mAP.ckpt',\n        f'{model_path}/fold4_best_mAP.ckpt',\n    ]\n\n    fold_ttas = [\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ]\n    predictions = inference(pl_model, states, test_loader, device, fold_ttas)\n\n    pred_df = test_df.copy()\n    pred_df[label_cols] = predictions\n    print(pred_df.head())\n    SUB_CSV.append(pred_df)\n    # SUB_CSV\n    memory_cleanup()\n\n    #### v2m v1\n    CFG.model_name = 'tf_efficientnetv2_m'\n    CFG.image_size = 512\n    ### init pl model\n    pl_model = SIIMPLModel()\n\n    ### load test dataloader\n    if CFG.image_size == 512:\n        test_loader = test_loader_512\n    else:\n        test_loader = test_loader_384\n\n    model_path = '../input/efficientnetv2mmodels/tf_efficientnetv2_m/'\n\n    states = [\n        f'{model_path}/fold0_best_mAP.ckpt',\n        f'{model_path}/fold1_best_mAP.ckpt',\n        f'{model_path}/fold2_best_mAP.ckpt',\n        f'{model_path}/fold3_best_mAP.ckpt',\n        f'{model_path}/fold4_best_mAP.ckpt',\n    ]\n\n    fold_ttas = [\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ]\n    predictions = inference(pl_model, states, test_loader, device, fold_ttas)\n\n    pred_df = test_df.copy()\n    pred_df[label_cols] = predictions\n    print(pred_df.head())\n    SUB_CSV.append(pred_df)\n    # SUB_CSV\n    memory_cleanup()\n\n    #### swim-trans v1\n    CFG.model_name = 'swin_base_patch4_window12_384'\n    CFG.image_size = 384\n    ### init pl model\n    pl_model = SIIMPLModel()\n\n    ### load test dataloader\n    if CFG.image_size == 512:\n        test_loader = test_loader_512\n    else:\n        test_loader = test_loader_384\n\n    model_path = '../input/swimtrans384models/swin_base_patch4_window12_384/'\n\n    states = [\n        f'{model_path}/fold0_best_mAP.ckpt',\n        f'{model_path}/fold1_best_mAP.ckpt',\n        f'{model_path}/fold2_best_mAP.ckpt',\n        f'{model_path}/fold3_best_mAP.ckpt',\n        f'{model_path}/fold4_best_mAP.ckpt',\n    ]\n\n    fold_ttas = [\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ]\n    predictions = inference(pl_model, states, test_loader, device, fold_ttas)\n\n    pred_df = test_df.copy()\n    pred_df[label_cols] = predictions\n    print(pred_df.head())\n    SUB_CSV.append(pred_df)\n    # SUB_CSV\n    memory_cleanup()\n    \n    \n     #### b5 test pseudo\n    CFG.model_name = 'tf_efficientnet_b5_ns'\n    CFG.image_size = 512\n\n    ### init pl model\n    pl_model = SIIMPLModel()\n\n    ### load test dataloader\n    if CFG.image_size == 512:\n        test_loader = test_loader_512\n    else:\n        test_loader = test_loader_384\n\n    model_path = '../input/effnet-b5-models-test-2477-pseudo/tf_efficientnet_b5_ns/'\n\n    states = [\n        f'{model_path}/fold0_best_mAP.ckpt',\n        f'{model_path}/fold1_best_mAP.ckpt',\n        f'{model_path}/fold2_best_mAP.ckpt',\n        f'{model_path}/fold3_best_mAP.ckpt',\n        f'{model_path}/fold4_best_mAP.ckpt',\n    ]\n\n    fold_ttas = [\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ['flip'],\n        ]\n    predictions = inference(pl_model, states, test_loader, device, fold_ttas)\n\n    pred_df = test_df.copy()\n    pred_df[label_cols] = predictions\n    print(pred_df.head())\n    SUB_CSV.append(pred_df)\n    # SUB_CSV\n    memory_cleanup()\n\n    test_df = SUB_CSV[0].copy()\n    for ix,jj in enumerate(z):\n        t,p = jj[0], jj[1]\n        y = np.zeros(( len(SUB_CSV[0]),len(SUB_CSV) ))\n        for k in range(len(SUB_CSV)):\n            y[:,k] = SUB_CSV[k][p].values\n\n        md2 = y[:,tt[ix][0]]\n        for i,k in enumerate(tt[ix][1:]):\n            md2 = ww[ix][i]*y[:,k] + (1-ww[ix][i])*md2\n        test_df[p] = md2**0.5\n\n    index = sub_df.index\n    sub_df[label_cols] = 0.0\n    for i,j in tqdm(study2images_d.items()):\n        x = []\n        for k in j:\n            temp = test_df[test_df['id'] == (k+'_image')]\n            x.append(np.mean(temp[label_cols].values, axis = 0))\n        condition = sub_df[\"id\"] == i+'_study'\n        ndices = index[condition]\n        sub_df.loc[ndices,label_cols] = np.mean(np.array(x), axis = 0)\n\n    pd.concat([sub_df,test_df], axis = 0).to_csv('pred_study.csv', index = False)\n\n    for i in range(max(study_len)+1):\n        x = sub_df.iloc[i,:].values\n        sub_df.loc[i,'PredictionString'] = f'negative {x[2]} 0 0 1 1 typical {x[3]} 0 0 1 1 indeterminate {x[4]} 0 0 1 1 atypical {x[5]} 0 0 1 1'\n\n    sub_df = sub_df[['id', 'PredictionString']]\n\n    sub_df.to_csv('submission_study.csv', index = False)\n\n    %cd ../input/siimyolov5develop/yolov5-develop/\n\n    test_dir = f'/kaggle/temp/test'\n    image_size = 384\n    conf_thres = 0.0001\n    iou_thres = 0.5\n    infer_fold = [0,1,2,3,4]\n\n#     models_dir = '/kaggle/input/yolov5384foldsmodels/yolov5-models'\n    models_dir = '/kaggle/input/yolotrs384pseudo/yolotrs-384-test-pseudo'\n\n\n    shutil.copytree('/kaggle/input/siimyolov5develop/yolov5-develop', '/kaggle/working/yolov5-develop')\n    os.chdir('/kaggle/working/yolov5-develop')\n\n    from glob import glob\n\n    def yolo2voc(image_height, image_width, bboxes):\n        \"\"\"\n        yolo => [xmid, ymid, w, h] (normalized)\n        voc  => [x1, y1, x2, y1]\n\n        \"\"\" \n        bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n        bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n        bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n\n        bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n        bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n        return bboxes\n\n\n    for fold in infer_fold:\n        weight_path = f'{models_dir}/fold{fold}_best.pt'\n        save_name = f'exp-siim-yolotrs-384-1cls-fold{fold}'\n#         weight_0_path = f'{models_dir}/yolotrs-384/fold{fold}_best.pt'\n#         weight_1_path = f'{models_dir}/yolotrl-384/fold{fold}_best.pt'\n#         weight_2_path = f'{models_dir}/yolov5x-384/fold{fold}_best.pt'\n#         save_name = f'exp-siim-ensemble3-384-1cls-fold{fold}'\n        !python detect.py --weights $weight_path\\\n                          --source $test_dir\\\n                          --img {image_size} \\\n                          --conf {conf_thres} \\\n                          --iou-thres {iou_thres} \\\n                          --save-txt \\\n                          --save-conf \\\n                          --augment \\\n                          --name $save_name\n\n        PRED_PATH = f'runs/detect/{save_name}/labels'\n        prediction_files = os.listdir(PRED_PATH)\n        print('Number of test images predicted as opaque: ', len(prediction_files))\n\n\n        memory_cleanup()\n        PRED_PATH = f'runs/detect/{save_name}/labels'\n\n        image_ids = []\n        PredictionStrings = []\n        for file_path in tqdm(glob(f'{PRED_PATH}/*.txt')):\n            image_id = file_path.split('/')[-1].split('.')[0]\n            h, w = image2shape_d[image_id]\n            f = open(file_path, 'r')\n            data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n            data = data[:, [0, 5, 1, 2, 3, 4]]\n            bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n\n            for idx in range(len(bboxes)):\n                bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n            image_ids.append(image_id+'_image')\n            PredictionStrings.append(' '.join(bboxes))\n\n        pred_df = pd.DataFrame({'id':image_ids,\n                                'PredictionString':PredictionStrings})\n\n    #     print(pred_df.head())\n        temp_image_df = sub_df.copy()\n        temp_image_df = temp_image_df.drop(['PredictionString'], axis=1)\n        sub_df = pd.merge(temp_image_df, pred_df, on = 'id', how = 'left').fillna(\"none 1 0 0 1 1\")\n        sub_df = sub_df[['id', 'PredictionString']]\n        for i in range(sub_df.shape[0]):\n            if sub_df.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n                continue\n            sub_df_split = sub_df.loc[i,'PredictionString'].split()\n            sub_df_list = []\n            for j in range(int(len(sub_df_split) / 6)):\n                sub_df_list.append('opacity')\n                sub_df_list.append(sub_df_split[6 * j + 1])\n                sub_df_list.append(sub_df_split[6 * j + 2])\n                sub_df_list.append(sub_df_split[6 * j + 3])\n                sub_df_list.append(sub_df_split[6 * j + 4])\n                sub_df_list.append(sub_df_split[6 * j + 5])\n            sub_df.loc[i,'PredictionString'] = ' '.join(sub_df_list)\n        #### Paths to 5-fold yolotrs csv\n        sub_df.to_csv(f'/kaggle/working/ensemble3_image_fold{fold}.csv',index=False)\n\n    sample_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\n    ## load study part\n    study_pred_df = pd.read_csv('/kaggle/working/pred_study.csv')\n    study_image_df = study_pred_df[sample_df.shape[0]:]\n    study_part_df = study_pred_df[:len(study_len)]\n    study_df = pd.concat([study_part_df,study_image_df], axis = 0).reset_index(drop=True) ### this 2477 images predict results about study part\n    study_df.columns = ['id','PredictionString_study','negative','typical','indeterminate','atypical']\n    ### merge study\n    sample_df = pd.merge(sample_df,study_df,on='id',how='left')\n#     sample_df\n\n    ### load image part with fold 1\n    image_df = pd.read_csv('/kaggle/working/ensemble3_image_fold1.csv')\n    image_df.columns = ['id','PredictionString_image']\n    ### merge image part\n    sample_df = pd.merge(sample_df,image_df,on='id',how='left')\n    \n    for i in range(len(sample_df)):\n        if i < len(study_len):\n            negative = sample_df.loc[i,'negative']\n            typical = sample_df.loc[i,'typical']\n            indeterminate = sample_df.loc[i,'indeterminate']\n            atypical = sample_df.loc[i,'atypical']\n            sample_df.loc[i,'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\n        else:\n            negative = sample_df.loc[i,'negative']\n            if 'none' in sample_df.loc[i,'PredictionString_image']:\n                sample_df.loc[i,'PredictionString'] = f'none {negative} 0 0 1 1'\n            else:\n                image_preds = sample_df.loc[i,'PredictionString_image']\n                sample_df.loc[i,'PredictionString'] = f'none {negative} 0 0 1 1 {image_preds}'\n\n    sample_df = sample_df[['id','PredictionString']].reset_index(drop=True)\n    #### path for study part\n    sample_df.to_csv('/kaggle/working/study_2477_images.csv', index = False)\n\n    %cd /kaggle/working\n    !mkdir -p /kaggle/temp/hung/image-level\n    !cp -ar /kaggle/input/image-level-submission-code-siim/* /kaggle/temp/hung/image-level\n    !mkdir -p /kaggle/temp/hung/post-process\n    !cp -ar /kaggle/input/post-processing-submission-code-siim/* /kaggle/temp/hung/post-process\n\n    # %%capture cell_print\n    %cd /kaggle/temp/hung/image-level\n    !python run.py -checkpoints \\\n    /kaggle/input/yolov5-checkpoints-siim/best.pt \\\n    /kaggle/input/yolov5-checkpoints-siim/best1.pt \\\n    /kaggle/input/yolov5-checkpoints-siim/best2.pt \\\n    /kaggle/input/yolov5-checkpoints-siim/best3.pt \\\n    /kaggle/input/yolov5-checkpoints-siim/best4.pt \\\n    -image-dir /kaggle/temp/test \\\n    -save-dir /kaggle/working/image_sub \\\n    -img2shape /kaggle/temp/image2shape_d.pickle \\\n    --image-size 640 \\\n    --batch 256 \\\n    --conf 0.0001\n    # %%capture cell_print\n    %cd /kaggle/temp/hung/image-level\n    !python run.py -checkpoints \\\n    /kaggle/input/hung-yolo/best_fold_0.pt \\\n    /kaggle/input/hung-yolo/best_fold_1.pt \\\n    /kaggle/input/hung-yolo/best_fold_2.pt \\\n    /kaggle/input/hung-yolo/best_fold_3.pt \\\n    /kaggle/input/hung-yolo/best_fold_4.pt \\\n    -image-dir /kaggle/temp/test \\\n    -save-dir /kaggle/working/image_sub \\\n    -img2shape /kaggle/temp/image2shape_d.pickle \\\n    --image-size 512 \\\n    --batch 256 \\\n    --conf 0.0001\n\n    %cd /kaggle/temp/hung/post-process\n    !python run.py \\\n    -study-csv \\\n    /kaggle/working/study_2477_images.csv \\\n    -image-csv \\\n    /kaggle/working/image_sub/best.csv \\\n    /kaggle/working/image_sub/best1.csv \\\n    /kaggle/working/image_sub/best2.csv \\\n    /kaggle/working/image_sub/best3.csv \\\n    /kaggle/working/image_sub/best4.csv \\\n    /kaggle/working/image_sub/best_fold_0.csv \\\n    /kaggle/working/image_sub/best_fold_1.csv \\\n    /kaggle/working/image_sub/best_fold_2.csv \\\n    /kaggle/working/image_sub/best_fold_3.csv \\\n    /kaggle/working/image_sub/best_fold_4.csv \\\n    /kaggle/working/ensemble3_image_fold0.csv \\\n    /kaggle/working/ensemble3_image_fold1.csv \\\n    /kaggle/working/ensemble3_image_fold2.csv \\\n    /kaggle/working/ensemble3_image_fold3.csv \\\n    /kaggle/working/ensemble3_image_fold4.csv \\\n    -sw 1 \\\n    -iw 2 2 2 2 2 \\\n    3 3 3 3 3 \\\n    2 2 2 2 2 \\\n    -std2img /kaggle/temp/study2images_d.pickle \\\n    -img2shape /kaggle/temp/image2shape_d.pickle \\\n    --iou 0.6 \\\n    --conf 0.0001\n\n    !rm -rf /kaggle/working/yolov5-develop\n    !ls -l /kaggle/working\nelse:\n    pd.read_csv('../input/siim-covid19-detection/sample_submission.csv').to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T02:32:41.909639Z","iopub.execute_input":"2021-08-09T02:32:41.910023Z","iopub.status.idle":"2021-08-09T02:32:44.066738Z","shell.execute_reply.started":"2021-08-09T02:32:41.909941Z","shell.execute_reply":"2021-08-09T02:32:44.065871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}