{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style = \"text-align :center; color:white; background-image:url(https://cdn.pixabay.com/photo/2014/06/16/23/40/blue-370128__340.png)\"> About Competition </h1>","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"border-style: outset;border-color: red;text-align: center;\">SIIM-FISABIO-RSNA COVID-19 YOLO-v5 Training</h2>\n\n<img src=\"https://content.presspage.com/uploads/2110/gettyimages-1214942330.jpg\" height=\"500\" width=\"500\" style=\"display: block;margin-left: auto;margin-right: auto;\"> \n\n<h2 style=\"text-align: center;border-style: double;text-align: center;border-color: red; \">About SIIM</h2>\n<img src=\"https://siim.org/resource/resmgr/SIIM_logo-600x315.png\" width=\"200\" style=\"display: block;margin-left: auto;margin-right: auto;\">\n<p> <b>Society for Imaging Informatics in Medicine</b> (<a href=\"https://siim.org/\">SIIM</a>) is the leading healthcare professional organization for those interested in the current and future use of informatics in medical imaging. The society's mission is to advance medical imaging informatics across the enterprise through education, research, and innovation in a multi-disciplinary community.</p>\n\n<h3 style = \"text-align :center; color:red; background-color: yellow; \">This is my first competition on Object Detection. Kindly comment if there are any mistakes ðŸ™‚</h3>\n\n<a href = \"https://wandb.ai/shanmukh/siim_covid19_yolov5/reports/SIIM-COVID19-Image-Level-Predictions--Vmlldzo3MzI3MjQ\" style=\"font-weight:'bold'; color:blue; font-family:monospace; text-align: center;\"><h3>See Weights & Biases Dashboard here</h3></a> \n\n<img src=\"https://camo.githubusercontent.com/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\" style= \"display: block;margin-left: auto; margin-right: auto;\" height=\"100\" width=\"300\">\n\n<a href = \"https://www.kaggle.com/shanmukh05/siim-covid19-dataset-256px-jpg\" style=\"font-weight:'bold'; color:blue; font-family:monospace; \"><h3>My Dataset</h3></a>\n\n<a href = \"https://www.kaggle.com/shanmukh05/siim-covid-19-data-preparation-for-detectron2\" style=\"font-weight:'bold'; color:blue; font-family:monospace; \"><h3>My Data Preparation Notebook</h3></a> \n\n<a href = \"https://www.kaggle.com/shanmukh05/siim-covid-19-data-visualization\" style=\"font-weight:'bold'; color:blue; font-family:monospace; \"><h3>My Data Visualization Notebook</h3></a> \n\n<a href = \"https://www.kaggle.com/shanmukh05/siim-covid-19-detection-detectron2-training\" style=\"font-weight:'bold'; color:blue; font-family:monospace; \"><h3>My Training Notebook (Detectron2)</h3></a> \nTo be updated\n\n<h3 style = \"text-align :center; color:red; background-color: yellow; \">I am moving from one folder to other frequently in cells, so make sure that you understand the folder structure properly.</h3>\n\n## Complete Folder structure after running the whole notebook \n- kaggle\n  - working (output data)\n     - train_results\n       - .jpg\n       - .png\n  - input (input data)\n    - siim-covid19-detection\n    - siim-covid19-dataset-256px-jpg\n  - siim_covid19\n    - dataset\n      - images\n        - train\n          - **abc.jpg**\n        - valid\n      - labels\n        - train\n          - **abc.txt**\n        - valid\n    - yolov5\n      - runs\n        - train\n          - yolov5_training (**given as argument while training**)\n        - detect\n          - yolov5_testing (**given as argument while testing**)\n             - .jpg (**Test images**)\n             - labels\n               - .txt (**Test labels**)","metadata":{}},{"cell_type":"markdown","source":"<h1 style = \"text-align :center; color:white; background-image:url(https://cdn.pixabay.com/photo/2014/06/16/23/40/blue-370128__340.png)\"> Installing Requirements </h1>","metadata":{}},{"cell_type":"code","source":"#creating new directory\n%cd ../\n!mkdir siim_covid19\n# Reason for creating & moving into this directory can be seen in above folder structure\n%cd siim_covid19  \n\n!git clone https://github.com/ultralytics/yolov5  # clone repo\n%cd yolov5\n!pip install -r requirements.txt\n# moving back to working directory\n%cd ../ ","metadata":{"scrolled":true,"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:24:06.61589Z","iopub.execute_input":"2021-06-17T06:24:06.616238Z","iopub.status.idle":"2021-06-17T06:24:13.726555Z","shell.execute_reply.started":"2021-06-17T06:24:06.616208Z","shell.execute_reply":"2021-06-17T06:24:13.725598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##------------------\n#Not saving logs into W&B\n##------------------\n# Access WANDB account\n#!pip install -q --upgrade wandb\n#import wandb\n#wandb.login()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:24:13.728349Z","iopub.execute_input":"2021-06-17T06:24:13.728723Z","iopub.status.idle":"2021-06-17T06:24:13.734436Z","shell.execute_reply.started":"2021-06-17T06:24:13.728682Z","shell.execute_reply":"2021-06-17T06:24:13.733662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"text-align :center; color:white; background-image:url(https://cdn.pixabay.com/photo/2014/06/16/23/40/blue-370128__340.png)\"> What is YOLO v5 </h1>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://user-images.githubusercontent.com/26833433/98699617-a1595a00-2377-11eb-8145-fc674eb9b1a7.jpg\" style= \"display: block; margin-left: auto; margin-right: auto;\" height=\"300\" width=\"300\">\n\n**YOLO (You Only Look Once)** is a clever convolutional neural network (CNN) for doing object detection in real-time. The algorithm applies a single neural network to the full image, and then divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities.\n\n<h2 style = \"text-align :center; font-family:verdana; color:red; background-image: url(https://hookagency.com/wp-content/uploads/2015/11/miracle-grow-light-green-gradient.jpg); \">Wanna Learn More ?</h2>\n\n<a style = \"text-align :center; font-family:verdana; color:blue; font-size:15px\" href = \"https://github.com/ultralytics/yolov5\"> Github Repository </a>\n\n<a style = \"text-align :center; font-family:verdana; color:blue; font-size:15px\" href = \"https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\">How to Train on custom Data </a>\n\n<a style = \"text-align :center; font-family:verdana; color:blue; font-size:15px\" href = \"https://ultralytics.com/yolov5\">\nOfficial Ultralytics page </a>\n\n<a style = \"text-align :center; font-family:verdana; color:blue; font-size:15px\" href = \"https://www.coursera.org/learn/convolutional-neural-networks\"> Introductory lectures by Andrew NG on YOLO (week 3 of the course) in Coursera</a>","metadata":{}},{"cell_type":"markdown","source":"<h1 style = \"text-align :center; color:white; background-image:url(https://cdn.pixabay.com/photo/2014/06/16/23/40/blue-370128__340.png)\"> Importing Dependencies </h1>","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport tensorflow as tf\nimport yaml\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport ast\n\nimport matplotlib.pyplot as plt\nimport cv2\nimport PIL\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:24:13.736686Z","iopub.execute_input":"2021-06-17T06:24:13.737126Z","iopub.status.idle":"2021-06-17T06:24:13.749205Z","shell.execute_reply.started":"2021-06-17T06:24:13.73708Z","shell.execute_reply":"2021-06-17T06:24:13.748355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"../input/siim-covid19-dataset-256px-jpg/512px/train/train/\"\nHEIGHT,WIDTH = 512,512\nCHANNELS = 3\nBATCH_SIZE = 16\nEPOCHS  = 40\nSEED  =2021","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:24:13.750868Z","iopub.execute_input":"2021-06-17T06:24:13.75123Z","iopub.status.idle":"2021-06-17T06:24:13.759021Z","shell.execute_reply.started":"2021-06-17T06:24:13.751193Z","shell.execute_reply":"2021-06-17T06:24:13.758244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"text-align :center; color:white; background-image:url(https://cdn.pixabay.com/photo/2014/06/16/23/40/blue-370128__340.png)\"> Data Preprocessing </h1>","metadata":{}},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:black; background-image: url(https://i.pinimg.com/originals/dd/f9/97/ddf997d65d8b92a3d7e085d6bf1cc484.jpg); \">CSV file</h2>","metadata":{}},{"cell_type":"code","source":"# Get image path from image_id\ndef get_path(image_id):\n    path = tf.io.gfile.glob(TRAIN_PATH + f\"*{image_id}.jpg\")[0]\n    return path\n\nimage_dict = {\n    \"opacity\" : 1,\n    \"none\" : 0\n}\ndf = pd.read_csv(\"../input/siim-covid19-dataset-256px-jpg/train.csv\")\n\ndf[\"image_label\"] = df[\"image_label\"].map(lambda x : x.split(\" \")[0])\ndf[\"image_label_id\"] = df[\"image_label\"].map(lambda x  : image_dict[x])\ndf[\"filepath\"] = df[\"ImageInstanceUID\"].map(get_path)\ndf.head(3)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:24:13.760389Z","iopub.execute_input":"2021-06-17T06:24:13.760756Z","iopub.status.idle":"2021-06-17T06:25:15.103207Z","shell.execute_reply.started":"2021-06-17T06:24:13.760721Z","shell.execute_reply":"2021-06-17T06:25:15.102408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:black; background-image: url(https://i.pinimg.com/originals/dd/f9/97/ddf997d65d8b92a3d7e085d6bf1cc484.jpg); \">Splitting Data</h2>","metadata":{}},{"cell_type":"code","source":"train_df,val_df = train_test_split(df,\n                                    test_size=0.2,\n                                    random_state = SEED,\n                                    stratify = df.image_label.values\n                                    )\n\ntrain_df.loc[:,\"data\"] = \"train\"\nval_df.loc[:,\"data\"] = \"val\"\ndf = pd.concat([train_df, val_df]).reset_index(drop=True)","metadata":{"_kg_hide-output":true,"scrolled":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:25:15.10449Z","iopub.execute_input":"2021-06-17T06:25:15.104847Z","iopub.status.idle":"2021-06-17T06:25:15.135043Z","shell.execute_reply.started":"2021-06-17T06:25:15.104794Z","shell.execute_reply":"2021-06-17T06:25:15.134211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:black; background-image: url(https://i.pinimg.com/originals/dd/f9/97/ddf997d65d8b92a3d7e085d6bf1cc484.jpg); \"> Preparing folder structure</h2>","metadata":{}},{"cell_type":"code","source":"os.makedirs('../siim_covid19/dataset/images/train', exist_ok=True)\nos.makedirs('../siim_covid19/dataset/images/val', exist_ok=True)\n\nos.makedirs('../siim_covid19/dataset/labels/train', exist_ok=True)\nos.makedirs('../siim_covid19/dataset/labels/val', exist_ok=True)\nprint(\"Created folder structure\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:25:15.136406Z","iopub.execute_input":"2021-06-17T06:25:15.136792Z","iopub.status.idle":"2021-06-17T06:25:15.146187Z","shell.execute_reply.started":"2021-06-17T06:25:15.136755Z","shell.execute_reply":"2021-06-17T06:25:15.145217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = \"../siim_covid19/dataset/images\"\nfor i in df.values:\n    data = i[10]\n    img_name = i[9].split(\"/\")[-1]\n    shutil.copyfile(i[9],f\"{IMAGE_PATH}/{data}/{img_name}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:25:15.148579Z","iopub.execute_input":"2021-06-17T06:25:15.14954Z","iopub.status.idle":"2021-06-17T06:25:29.807971Z","shell.execute_reply.started":"2021-06-17T06:25:15.149507Z","shell.execute_reply":"2021-06-17T06:25:29.807099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:black; background-image: url(https://i.pinimg.com/originals/dd/f9/97/ddf997d65d8b92a3d7e085d6bf1cc484.jpg); \"> Creating YAML file </h2>","metadata":{}},{"cell_type":"code","source":"# REF :  https://www.kaggle.com/ayuraj/train-covid-19-detection-using-yolov5\n\nyaml_dict = dict(\n    train = \"../dataset/images/train\",\n    val = \"../dataset/images/val\",\n    nc = 2,\n    names = [\"none\",\"opacity\"]\n)\n\nwith open(\"../siim_covid19/yolov5/data/data.yaml\", \"w\") as f:\n    yaml.dump(yaml_dict,f,default_flow_style=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:25:29.810102Z","iopub.execute_input":"2021-06-17T06:25:29.8105Z","iopub.status.idle":"2021-06-17T06:25:29.819759Z","shell.execute_reply.started":"2021-06-17T06:25:29.810458Z","shell.execute_reply":"2021-06-17T06:25:29.818402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:black; background-image: url(https://i.pinimg.com/originals/dd/f9/97/ddf997d65d8b92a3d7e085d6bf1cc484.jpg); \"> Preprocessing Bounding Boxes </h2>\n\n- One row per object\n- Each row is class `x_center` `y_center` `width` `height` format.\n- Box coordinates must be in normalized `xywh` format (from 0 - 1). If your boxes are in pixels, divide `x_center` and `width` by `image width`, and `y_center` and `height` by `image height`.\n- Class numbers are zero-indexed (start from 0).","metadata":{}},{"cell_type":"code","source":"df[\"boxes\"] = df[\"boxes\"].map(lambda x : ast.literal_eval(x))\n\ndef preprocess_bbox(row):\n    factor_x = 1/row[5]\n    factor_y = 1/row[4]\n    bboxes = []\n    \n    if row[7] == \"opacity\":\n        for box in row[6]:\n            x = box[\"x\"]*factor_x\n            y = box[\"y\"]*factor_y\n            w = box[\"width\"]*factor_x\n            h = box[\"height\"]*factor_y\n            xc = x + w/2\n            yc = y + h/2\n        \n            bboxes.append([xc,yc,w,h])\n    return bboxes","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:25:29.822473Z","iopub.execute_input":"2021-06-17T06:25:29.822862Z","iopub.status.idle":"2021-06-17T06:25:30.215713Z","shell.execute_reply.started":"2021-06-17T06:25:29.822808Z","shell.execute_reply":"2021-06-17T06:25:30.214848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare txt files\nLABEL_PATH = \"../siim_covid19/dataset/labels\"\nfor row in df.values:\n    filename = row[9].split(\"/\")[-1][:-4]\n    filepath = f\"{LABEL_PATH}/{row[10]}/{filename}.txt\"\n    \n    if row[7] == \"opacity\":\n        bbox = preprocess_bbox(row)\n        with open(filepath, \"w\") as f:\n            for box in bbox:\n                box = [1] + box\n                box = [str(i) for i in box]\n                box = ' '.join(box)\n                f.write(box)\n                f.write('\\n')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:25:30.217074Z","iopub.execute_input":"2021-06-17T06:25:30.217427Z","iopub.status.idle":"2021-06-17T06:25:30.506987Z","shell.execute_reply.started":"2021-06-17T06:25:30.217391Z","shell.execute_reply":"2021-06-17T06:25:30.506056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"text-align :center; color:white; background-image:url(https://cdn.pixabay.com/photo/2014/06/16/23/40/blue-370128__340.png)\"> Training </h1>","metadata":{}},{"cell_type":"code","source":"%cd yolov5/\n!wandb off\n!python train.py --img {HEIGHT} \\\n                 --batch {BATCH_SIZE} \\\n                 --epochs {EPOCHS} \\\n                 --data data.yaml \\\n                 --weights yolov5s.pt \\\n                 --save_period 1\\\n                 --name yolov5_training","metadata":{"scrolled":true,"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T06:25:30.508328Z","iopub.execute_input":"2021-06-17T06:25:30.508677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training Completed\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ../../\ntrain_ls = tf.io.gfile.glob(\"./siim_covid19/yolov5/runs/train/yolov5_training/*.*g\")\n\nos.makedirs(\"./working/train_results\", exist_ok=True)\nfor filepath in train_ls:\n    name = filepath.split(\"/\")[-1]\n    shutil.copyfile(filepath,\"./working/train_results/\"+name)\n\nshutil.copyfile(\"./siim_covid19/yolov5/runs/train/yolov5_training/weights/best.pt\",\"./working/best_yolov5.pt\")\nprint(\"Training curves moved to output directory\")","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"text-align :center; color:white; background-image:url(https://cdn.pixabay.com/photo/2014/06/16/23/40/blue-370128__340.png)\"> Inference </h1>","metadata":{}},{"cell_type":"code","source":"TEST_PATH = \"/kaggle/input/siim-covid19-dataset-256px-jpg/224px/test/test\"\nBEST_MODEL_PATH  =\"./runs/train/yolov5_training/weights/best.pt\"","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ./siim_covid19/yolov5\n!python detect.py --weights {BEST_MODEL_PATH} \\\n                  --source {TEST_PATH} \\\n                  --img {HEIGHT} \\\n                  --conf 0.3 \\\n                  --iou-thres 0.5 \\\n                  --max-det 3 \\\n                  --save-txt \\\n                  --save-conf \\\n                  --name yolov5_testing","metadata":{"scrolled":true,"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Predictions Completed\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:black; background-image: url(https://i.pinimg.com/originals/dd/f9/97/ddf997d65d8b92a3d7e085d6bf1cc484.jpg); \"> Format of txt file of output </h2>\n\n- `label_id` `x_center` `y_center` `width` `height`","metadata":{}},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:red; background-image: url(https://hookagency.com/wp-content/uploads/2015/11/miracle-grow-light-green-gradient.jpg); \">Sample Prediction</h2>","metadata":{}},{"cell_type":"code","source":"PREDICTIONS_PATH = \"runs/detect/yolov5_testing/labels/\"\nPRED_FILES = os.listdir(PREDICTIONS_PATH)\n\nprint(\"Sample prediction (in txt file) : \\n\")\n\nwith open(PREDICTIONS_PATH + PRED_FILES[0], \"r\") as f:\n    ls = f.read().strip(\"\\n\").split(\" \")\n    print(f\"LABEL : {ls[0]} \\nX_CENTER : {ls[1]} \\nY_CENTER : {ls[2]} \\nWIDTH : {ls[3]} \\nHEIGHT : {ls[4]} \\nCONFIDENCE : {ls[5]}\")\nprint(\"Number of Prediction file originally present : \",len(PRED_FILES))   ","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:red; background-image: url(https://hookagency.com/wp-content/uploads/2015/11/miracle-grow-light-green-gradient.jpg); \">Creating txt files for \"none\" class</h2>","metadata":{}},{"cell_type":"code","source":"IMAGE_FILES = tf.io.gfile.glob(\"runs/detect/yolov5_testing/*.jpg\")\nACTUAL_FILES = []\nfor path in IMAGE_FILES:\n    ls = path.split(\"/\")\n    name = ls[-1].split(\".\")[0] + \".txt\"\n    ACTUAL_FILES.append(PREDICTIONS_PATH + name)\n    \nfor filepath in ACTUAL_FILES:\n    if not os.path.exists(filepath):\n        with open(filepath,\"w\") as f:\n            f.write(\"0 0 0 1 1 1\")\n            f.close()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:red; background-image: url(https://hookagency.com/wp-content/uploads/2015/11/miracle-grow-light-green-gradient.jpg); \">Preprocessing functions</h2>","metadata":{}},{"cell_type":"code","source":"##------------------------------------------\n#getting string of predictions from txt file\n##------------------------------------------\ndef get_string(filepath,out= \"bbox\"):\n    probs = []\n    bboxes = []\n    labels = []\n    with open(filepath, \"r\") as f:\n        for line in f:\n            ls = line.strip(\"\\n\").split(\" \")\n            ls = list(map(float, ls))\n            labels.append(ls[0])\n            bboxes.append(ls[1:-1])\n            probs.append(ls[-1]) \n    if out == \"bbox\":\n        return bboxes\n    elif out == \"label\":\n        return labels\n    else:\n        return probs\n\n##------------------------------------------\n#Scaling-up bounding box co-ordinates\n##------------------------------------------\ndef scale_bbox(row):\n    scale_x = row[5]\n    scale_y = row[6]\n    scale_bboxes = []\n    for box in row[1]:\n        if row[2][0] != 0.0:\n            xc,yc = box[0]*scale_x,box[1]*scale_y\n            w,h = box[2]*scale_x,box[3]*scale_y\n            xmin,ymin = int(xc - w/2),int(yc - h/2)\n            xmax,ymax = int(xc + w/2),int(yc + h/2)\n            scale_bboxes.append([xmin,ymin,xmax,ymax])\n        else:\n            return [[0,0,1,1]]\n    return scale_bboxes","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:red; background-image: url(https://hookagency.com/wp-content/uploads/2015/11/miracle-grow-light-green-gradient.jpg); \">Preprocessing prediction csv file</h2>","metadata":{}},{"cell_type":"code","source":"pred_df = pd.DataFrame.from_dict({\"filepath\" : ACTUAL_FILES})\npred_df[\"bboxes\"] = pred_df[\"filepath\"].map(lambda x: get_string(x,out=\"bbox\"))\npred_df[\"label\"] = pred_df[\"filepath\"].map(lambda x: get_string(x,out=\"label\"))\npred_df[\"confidence\"] = pred_df[\"filepath\"].map(lambda x: get_string(x,out=\"conf\"))\n\npred_df[\"ImageInstanceUID\"] = pred_df[\"filepath\"].map(lambda x : x.split(\"/\")[-1].split(\"_\")[-1][:-4])\n\n#%cd ../\nmeta_df = pd.read_csv(\"/kaggle/input/siim-covid19-dataset-256px-jpg/meta_test.csv\")\npred_df = pred_df.merge(meta_df, on = \"ImageInstanceUID\")\n\nbox_ls = []\nfor i,row in enumerate(pred_df.values):\n    box_ls.append(scale_bbox(row))\n    \npred_df[\"scale_bboxes\"] = box_ls\n    \npred_df.head(3)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style = \"text-align :center; font-family:verdana; color:red; background-image: url(https://hookagency.com/wp-content/uploads/2015/11/miracle-grow-light-green-gradient.jpg); \">Final Study Level Predictions</h2>","metadata":{}},{"cell_type":"code","source":"%cd ../../../\nimage_dict = {\n    0. : \"none\",\n    1. : \"opacity\"\n}\n\ndef get_string(row):\n    string = \"\"\n    if row[2][0] == 0.:\n        string += \"none 1 0 0 1 1\"\n        return string\n    for i in range(len(row[2])):\n        string += \"opacity \"\n        string += str(row[3][i])\n        string += \" \"\n        bbox = map(str,row[7][i])\n        tmp = \" \".join(bbox)\n        string += tmp\n        string += \" \"\n    return string\n        \nstrings = []\nfor row in pred_df.values:\n    strings.append(get_string(row))\n    \n    \ntest_df = pd.DataFrame.from_dict({\"Id\" : pred_df[\"ImageInstanceUID\"]})\ntest_df[\"Id\"] = test_df['Id'].map(lambda x : x+\"_image\")\ntest_df[\"PredictionString\"] = strings\ntest_df.to_csv(\"kaggle/working/study_level_pred.csv\",index = False)\ntest_df.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src=\"https://t4.ftcdn.net/jpg/03/54/26/09/360_F_354260981_mvf4Yt39tO1iAWkXeFcPayv0OkTw6p4j.jpg\" style= \"display: block;margin-left: auto; margin-right: auto;\" height=\"100\" width=\"300\">\n\n<h1 style = \"text-align :center; color:white; background-image: url(https://cdn.pixabay.com/photo/2014/06/16/23/40/blue-370128__340.png); \">Do upvote if you found this notebook usefulðŸ™‚</h1>","metadata":{}}]}