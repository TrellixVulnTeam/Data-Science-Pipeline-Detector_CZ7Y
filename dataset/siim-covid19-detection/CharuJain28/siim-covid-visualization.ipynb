{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!apt-get -qq update && apt-get -qq install -y  libgdcm-tools python-gdcm\n!conda install -y -q -c conda-forge opencv gdcm pydicom apache-beam -y","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-05T10:29:47.143089Z","iopub.execute_input":"2021-08-05T10:29:47.143454Z","iopub.status.idle":"2021-08-05T10:32:30.741755Z","shell.execute_reply.started":"2021-08-05T10:29:47.143391Z","shell.execute_reply":"2021-08-05T10:32:30.740679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport apache_beam\nimport pydicom\nimport gdcm\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport os\nimport sys\nimport csv\nimport pickle\nimport random\nfrom datetime import datetime\nprint('Libraries Imported!')\nimport matplotlib.pyplot as plt\nimport PIL\nimport numpy as np\nimport os\nimport six.moves.urllib as urllib\nimport sys\nimport tarfile\nimport tensorflow as tf\nimport zipfile\nimport pandas as pd\nfrom collections import defaultdict\nfrom io import StringIO\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nfrom skimage import exposure\nfrom skimage.transform import resize\n\nnp.set_printoptions(threshold=sys.maxsize)\nprint('Settings Set!')\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:46:09.770235Z","iopub.execute_input":"2021-08-05T10:46:09.770857Z","iopub.status.idle":"2021-08-05T10:46:12.566897Z","shell.execute_reply.started":"2021-08-05T10:46:09.770753Z","shell.execute_reply":"2021-08-05T10:46:12.565807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 9\ndef showDataset(data, num):    \n    plt.figure(figsize=(15,15))\n    for num, x in enumerate(data):\n        plt.subplot(rows,6,num+1)\n        plt.xlabel(x[1])\n        plt.imshow(x[0], cmap=\"gray\")  \n\n    \ndef list_dicoms_in_folder(folder):\n    '''Lists the full path to all the DICOM files in a given folder.'''\n    my_list = []\n    i = 0 \n    for dirname, _, filenames in os.walk(folder):\n        for filename in filenames:\n            if filename[-4:]=='.dcm':\n                my_list.append([os.path.join(dirname, filename),filename.split('.')[0]])\n                i = i +1\n        if i ==50:\n            break\n    return my_list\n","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:46:14.94183Z","iopub.execute_input":"2021-08-05T10:46:14.94226Z","iopub.status.idle":"2021-08-05T10:46:14.94923Z","shell.execute_reply.started":"2021-08-05T10:46:14.942214Z","shell.execute_reply":"2021-08-05T10:46:14.948512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change this to True if you want to do something with all the data\n# For testing purposes, you can just use the small list of files defined in the next cell\nTRAIN_FOLDER = '/kaggle/input/siim-covid19-detection/train'\nTEST_FOLDER = '/kaggle/input/siim-covid19-detection/test'\nVERBOSE = False\n\nif True:\n    Train_Data = list_dicoms_in_folder(TRAIN_FOLDER)\n    Test_Data = list_dicoms_in_folder(TEST_FOLDER)\n    \ntrain_images=[]\ntest_images=[]\n\nfor element,name in Train_Data:\n    ds = pydicom.dcmread(element)\n    train_images.append([ds.pixel_array,name])\n\nshowDataset(train_images, 48)    \n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:46:17.997908Z","iopub.execute_input":"2021-08-05T10:46:17.998524Z","iopub.status.idle":"2021-08-05T10:46:44.449589Z","shell.execute_reply.started":"2021-08-05T10:46:17.998469Z","shell.execute_reply":"2021-08-05T10:46:44.44854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for element,name in Test_Data:\n    ds = pydicom.dcmread(element)\n    test_images.append([ds.pixel_array,name])\n\nshowDataset(test_images, 48)    \n","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:35:39.392224Z","iopub.execute_input":"2021-08-05T10:35:39.392765Z","iopub.status.idle":"2021-08-05T10:36:23.014043Z","shell.execute_reply.started":"2021-08-05T10:35:39.392726Z","shell.execute_reply":"2021-08-05T10:36:23.013266Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reading training dataset and writing to annotation.txt\nSaving dcm images to jpg\n","metadata":{}},{"cell_type":"code","source":"os.mkdir('train')","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:46:55.530219Z","iopub.execute_input":"2021-08-05T10:46:55.530823Z","iopub.status.idle":"2021-08-05T10:46:55.842694Z","shell.execute_reply.started":"2021-08-05T10:46:55.530764Z","shell.execute_reply":"2021-08-05T10:46:55.840994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualising training set","metadata":{}},{"cell_type":"code","source":"import ast\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport csv\ni = 0\ndf = pd.read_csv('/kaggle/input/siim-covid19-detection/train_image_level.csv')  \ndf2 = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv')  \n\n# create annotation.txt and append values\nf = open(\"annotation.txt\",\"a+\")\nf.truncate(0)\n\nres = [(row,img) for index,row in df.iterrows() \n        for img,name in train_images if name in row['id']]\n\nf= open(\"annotation.txt\",\"a+\")\nf.truncate(0)\n\n# Iterate over image csv rows\nfor r,img in (res):\n    if str(r['boxes'])!='nan':\n        \n        grp = [c for index,c in df2.iterrows() if r['StudyInstanceUID'] in c['id']]\n       \n        if grp[0]['Negative for Pneumonia'] ==1:\n             classification = '0'\n        elif grp[0]['Typical Appearance'] ==1:\n             classification = '1'\n        elif grp[0]['Indeterminate Appearance'] ==1:\n             classification = '2'\n        elif grp[0]['Atypical Appearance'] ==1:\n             classification = '3'\n      \n        result= (np.maximum(img,0) / img.max()) * 255.0\n        \n        cv.imwrite(os.path.join('/kaggle/working/train/', r['id'][:-6]+'.jpg'), result)\n        # Read jpeg image\n        jpg_img = cv.imread(os.path.join('/kaggle/working/train/', r['id'][:-6]+'.jpg'))\n        \n        plt.figure(figsize=(5,5))\n        plt.xlabel(r['id'][:-6] + ':'+ classification)\n        f.write(str(r['id'][:-6])+\".jpg \")\n        for b in ast.literal_eval(r['boxes']):\n            x1= b['x']\n            y1 = b['y']\n            w1 = b['width'] + b['x']\n            h1= b['height'] + b['y']\n            \n            cv.rectangle(jpg_img, (int(x1), int(y1)), (int(w1), int(h1)), (255, 0, 0), 10)\n        \n            \n            f.write(str(int(x1))+\" \")\n            f.write(str(int(y1))+\" \")\n            f.write(str(int(w1))+\" \")\n            f.write(str(int(h1))+\" \")\n            f.write(str(classification)+\" \")\n            plt.imshow(jpg_img)  \n        \n        f.write(\"\\n\")\nf.close()         ","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:36:32.551898Z","iopub.execute_input":"2021-08-05T10:36:32.552251Z","iopub.status.idle":"2021-08-05T10:38:22.823552Z","shell.execute_reply.started":"2021-08-05T10:36:32.552221Z","shell.execute_reply":"2021-08-05T10:38:22.822683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"YOLO_TYPE                   = \"yolov3\" \nTRAIN_LOAD_IMAGES_TO_RAM = True\nTRAIN_ANNOT_PATH            = \"/kaggle/working/annotation.txt\"\nTEST_ANNOT_PATH             = \"/kaggle/working/annotation.txt\"\nTRAIN_BATCH_SIZE            = 4\nTRAIN_INPUT_SIZE            = 416\nTEST_BATCH_SIZE             = 4\nTEST_INPUT_SIZE             = 416\nTRAIN_IMAGES= '/kaggle/working/train'\nTEST_IMAGES= '/kaggle/working/test'\nYOLO_STRIDES                = [8, 16, 32]\nTRAIN_CLASSES               = ['0','1','2','3']\nYOLO_ANCHOR_PER_SCALE       = 3\nYOLO_MAX_BBOX_PER_SCALE     = 100\n\nYOLO_STRIDES                = [8, 16, 32]\nYOLO_IOU_LOSS_THRESH        = 0.5\nYOLO_INPUT_SIZE             = 416\nif YOLO_TYPE                == \"yolov3\":\n    YOLO_ANCHORS            = [[[10,  13], [16,   30], [33,   23]],\n                               [[30,  61], [62,   45], [59,  119]],\n                               [[116, 90], [156, 198], [373, 326]]]\nYOLO_V3_WEIGHTS             = \"/kaggle/input/yolov3-weights\"\nTRAIN_LOGDIR                = \"/kaggle/working/log\"\nTRAIN_CHECKPOINTS_FOLDER    = \"/kaggle/working/checkpoints\"\nYOLO_COCO_CLASSES           = ['0','1','4','7','3','6','10','2','5','8','9']\nTRAIN_CLASSES               = ['0','1','2','3']\nTRAIN_MODEL_NAME            = f\"{YOLO_TYPE}_custom\"\nTRAIN_LOAD_IMAGES_TO_RAM    = True # With True faster training, but need more RAM\nTRAIN_BATCH_SIZE            = 4\nTRAIN_INPUT_SIZE            = 416\nTRAIN_DATA_AUG              = True\nTRAIN_TRANSFER              = True\nTRAIN_FROM_CHECKPOINT       = False # \"checkpoints/yolov3_custom\"\nTRAIN_LR_INIT               = 0.005\nTRAIN_LR_END                = 0.009\nTRAIN_WARMUP_EPOCHS         = 2\nTRAIN_EPOCHS                = 500","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:38:51.019598Z","iopub.execute_input":"2021-08-05T10:38:51.020079Z","iopub.status.idle":"2021-08-05T10:38:51.029137Z","shell.execute_reply.started":"2021-08-05T10:38:51.020047Z","shell.execute_reply":"2021-08-05T10:38:51.028431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nos.mkdir('./log')\nos.mkdir('./checkpoints')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:38:54.95493Z","iopub.execute_input":"2021-08-05T10:38:54.95546Z","iopub.status.idle":"2021-08-05T10:38:54.959945Z","shell.execute_reply.started":"2021-08-05T10:38:54.955403Z","shell.execute_reply":"2021-08-05T10:38:54.958902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def showDatasetWithBB(img,bboxes,typeOfimage):    \n    plt.figure(figsize=(5,5))\n    color = (0, 255, 0)\n    \n    for x in bboxes:\n        cv.putText(img, 'gt bbox', (x[0], x[1]), cv.FONT_HERSHEY_DUPLEX, 0.7, color, 4)\n        cv.rectangle(img, (x[0], x[1]), (x[0]+x[2],  x[1]+x[3]), color, 7)\n        cv.circle(img, (int((x[0]+ x[2])/2), int((x[1]+ x[3])/2)), 3, color, -1)\n        print(\"Type\",typeOfimage,\"BBbox: \",x)\n        \n        plt.imshow(img)\n        plt.show()\n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:38:57.678791Z","iopub.execute_input":"2021-08-05T10:38:57.67912Z","iopub.status.idle":"2021-08-05T10:38:57.68661Z","shell.execute_reply.started":"2021-08-05T10:38:57.679092Z","shell.execute_reply":"2021-08-05T10:38:57.685617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_preprocess(image, target_size, gt_boxes=None):\n    ih, iw    = target_size\n    h,  w, _  = image.shape\n\n    scale = min(iw/w, ih/h)\n    nw, nh  = int(scale * w), int(scale * h)\n    image_resized = cv.resize(image, (nw, nh))\n\n    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n    image_paded = image_paded / 255.\n    \n    showDatasetWithBB(image,gt_boxes,\"ground truth boxes\")\n    \n    if gt_boxes is None:\n        return image_paded\n    else:\n        gt_boxes[:, [2, 3]] = np.multiply(gt_boxes[:, [2, 3]] , scale) + dw\n        gt_boxes[:, [0, 1]] = np.multiply(gt_boxes[:, [0, 1]] , scale) + dh\n\n    showDatasetWithBB(image_paded,gt_boxes,\"preprocessed ground truth boxes\")\n    return image_paded, gt_boxes\n","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:39:02.44281Z","iopub.execute_input":"2021-08-05T10:39:02.443173Z","iopub.status.idle":"2021-08-05T10:39:02.451398Z","shell.execute_reply.started":"2021-08-05T10:39:02.443142Z","shell.execute_reply":"2021-08-05T10:39:02.450272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(object):\n    # Dataset preprocess implementation\n    def __init__(self, dataset_type, TEST_INPUT_SIZE=TEST_INPUT_SIZE):\n        \n        self.annot_path  = TRAIN_ANNOT_PATH if dataset_type == 'train' else TEST_ANNOT_PATH\n        self.input_sizes = TRAIN_INPUT_SIZE if dataset_type == 'train' else TEST_INPUT_SIZE\n        self.batch_size  = TRAIN_BATCH_SIZE if dataset_type == 'train' else TEST_BATCH_SIZE\n        self.train_input_sizes = TRAIN_INPUT_SIZE\n        self.image_path    = TRAIN_IMAGES   if dataset_type == 'train' else TEST_IMAGES\n        self.batch_count = 0\n        self.strides = np.array(YOLO_STRIDES)\n        self.anchors = (np.array(YOLO_ANCHORS).T/self.strides).T\n        self.anchor_per_scale = YOLO_ANCHOR_PER_SCALE\n        self.max_bbox_per_scale = YOLO_MAX_BBOX_PER_SCALE\n        self.classes = (TRAIN_CLASSES)\n        self.num_classes = len(self.classes)\n        \n        self.annotations = self.load_annotations(dataset_type)\n        self.num_samples = len(self.annotations)\n        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size))\n        \n    def __iter__(self):\n        return self\n    \n    def __len__(self):\n        return self.num_batchs\n\n    def __next__(self):\n        self.train_input_size = random.choice([self.train_input_sizes])\n        self.train_output_sizes = self.train_input_size // self.strides\n\n        batch_image = np.zeros((self.batch_size, self.train_input_size, self.train_input_size, 3), dtype=np.float32)\n\n        batch_label_sbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0],\n                                      self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n        batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1],\n                                      self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n        batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[2], self.train_output_sizes[2],\n                                      self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n\n        batch_sbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n        batch_mbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n        batch_lbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n\n        exceptions = False\n        num = 0\n        if self.batch_count < self.num_batchs:\n            while num < self.batch_size:\n                index = self.batch_count * self.batch_size + num\n                if index >= self.num_samples: index -= self.num_samples\n                annotation = self.annotations[index]\n                image, bboxes = self.parse_annotation(annotation)\n                \n                try:\n                    label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes)\n                except IndexError:\n                    exceptions = True\n                    continue\n            \n                batch_image[num, :, :, :] = image\n                batch_label_sbbox[num, :, :, :, :] = label_sbbox\n                batch_label_mbbox[num, :, :, :, :] = label_mbbox\n                batch_label_lbbox[num, :, :, :, :] = label_lbbox\n                batch_sbboxes[num, :, :] = sbboxes\n                batch_mbboxes[num, :, :] = mbboxes\n                batch_lbboxes[num, :, :] = lbboxes\n                num += 1\n            self.batch_count += 1\n            batch_smaller_target = batch_label_sbbox, batch_sbboxes\n            batch_medium_target  = batch_label_mbbox, batch_mbboxes\n            batch_larger_target  = batch_label_lbbox, batch_lbboxes\n            \n            return batch_image, (batch_smaller_target, batch_medium_target, batch_larger_target)\n        else:\n            self.batch_count = 0\n            np.random.shuffle(self.annotations)\n            raise StopIteration\n            \n    def load_annotations(self, dataset_type):\n        final_annotations = []\n        with open(self.annot_path, 'r') as f:\n            txt = f.readlines()\n            annotations = [line.strip() for line in txt if len(line.strip().split()[1:]) != 0]\n           # print(annotations)\n            \n        np.random.shuffle(annotations)\n       \n        for annotation in annotations:\n            # fully parse annotations\n            line = annotation.split(\" \")\n            #print(line)\n            image_path, index = \"\", 1\n            for i, one_line in enumerate(line):\n                if not one_line.replace(\",\",\"\").isnumeric():\n                    if image_path != \"\": image_path += \" \"\n                    image_path += one_line\n                else:\n                    index = i\n                    break\n            \n            if not os.path.exists(os.path.join(self.image_path,image_path)):\n                continue\n            if TRAIN_LOAD_IMAGES_TO_RAM:\n                image = cv.imread(os.path.join(self.image_path,image_path))\n            else:\n                image = ''\n                \n            final_annotations.append([os.path.join(self.image_path,image_path), line[1:], image])\n            \n        return final_annotations\n\n       \n    def parse_annotation(self, annotation, mAP = 'False'):\n        if True:\n            image_path = annotation[0]\n            image = cv.imread(image_path)\n        else:\n            image_path = os.path.join(TRAIN_IMAGES,annotation[0])\n            image = cv.imread(image_path)\n        \n        i = 0\n        box=[]\n        bboxes=[]\n       # print(annotation[1])\n        for box_ind in annotation[1]:\n            box.append(int(box_ind))\n            i = i + 1 \n            if i%5==0:\n                bboxes.append(box)\n                box= []\n        \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if mAP == True: \n            return image, bboxes\n        \n     \n        image, bboxes = image_preprocess(np.copy(image), [self.input_sizes, self.input_sizes], np.copy(bboxes))\n        \n        return image, bboxes\n\n    def preprocess_true_boxes(self, bboxes):\n        label = [np.zeros((self.train_output_sizes[i], self.train_output_sizes[i], self.anchor_per_scale,\n                           5 + self.num_classes)) for i in range(3)]\n        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4)) for _ in range(3)]\n        bbox_count = np.zeros((3,))\n        \n        for bbox in bboxes:\n            bbox_coor = bbox[:4]\n            bbox_class_ind = bbox[4]\n\n            onehot = np.zeros(self.num_classes, dtype=np.float)\n            onehot[bbox_class_ind] = 1.0\n            uniform_distribution = np.full(self.num_classes, 1.0 / self.num_classes)\n            deta = 0.01\n            smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n\n            bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / self.strides[:, np.newaxis]\n\n            iou = []\n            exist_positive = False\n            for i in range(3):\n                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n                anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n                anchors_xywh[:, 2:4] = self.anchors[i]\n\n                iou_scale = bbox_iou(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n                iou.append(iou_scale)\n                iou_mask = iou_scale > 0.3\n\n                if np.any(iou_mask):\n                    xind, yind = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32)\n\n                    label[i][yind, xind, iou_mask, :] = 0\n                    label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n                    label[i][yind, xind, iou_mask, 4:5] = 1.0\n                    label[i][yind, xind, iou_mask, 5:] = smooth_onehot\n\n                    bbox_ind = int(bbox_count[i] % self.max_bbox_per_scale)\n                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n                    bbox_count[i] += 1\n\n                    exist_positive = True\n\n            if not exist_positive:\n                best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n                best_detect = int(best_anchor_ind / self.anchor_per_scale)\n                best_anchor = int(best_anchor_ind % self.anchor_per_scale)\n                xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n\n                label[best_detect][yind, xind, best_anchor, :] = 0\n                label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n                label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n                label[best_detect][yind, xind, best_anchor, 5:] = smooth_onehot\n\n                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n                bbox_count[best_detect] += 1\n        label_sbbox, label_mbbox, label_lbbox = label\n        sbboxes, mbboxes, lbboxes = bboxes_xywh\n        return label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n\n\n    def random_horizontal_flip(self, image, bboxes):\n      \n        return image, bboxes\n\n    def random_crop(self, image, bboxes):\n        \n        return image, bboxes\n\n    def random_translate(self, image, bboxes):\n       \n        return image, bboxes\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:39:05.347402Z","iopub.execute_input":"2021-08-05T10:39:05.347863Z","iopub.status.idle":"2021-08-05T10:39:05.38472Z","shell.execute_reply.started":"2021-08-05T10:39:05.347829Z","shell.execute_reply":"2021-08-05T10:39:05.383811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nimport random\n#from tensorflow.keras.utils import plot_model\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:39:18.373606Z","iopub.execute_input":"2021-08-05T10:39:18.373934Z","iopub.status.idle":"2021-08-05T10:39:18.394296Z","shell.execute_reply.started":"2021-08-05T10:39:18.373906Z","shell.execute_reply":"2021-08-05T10:39:18.393532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if YOLO_TYPE == \"yolov4\":\n    Darknet_weights = YOLO_V4_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V4_WEIGHTS\nif YOLO_TYPE == \"yolov3\":\n    Darknet_weights =  YOLO_V3_WEIGHTS\n\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nprint(f'GPUs {gpus}')\nif len(gpus) > 0:\n    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError: pass\n\nif os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\nwriter = tf.summary.create_file_writer(TRAIN_LOGDIR)\n    \ntrainset = Dataset('train')\ntestset = Dataset('test')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:39:21.474006Z","iopub.execute_input":"2021-08-05T10:39:21.476027Z","iopub.status.idle":"2021-08-05T10:39:25.374289Z","shell.execute_reply.started":"2021-08-05T10:39:21.47599Z","shell.execute_reply":"2021-08-05T10:39:25.37323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = [(img,name) for img,name in train_images]\n\nfor image,name in res:\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = image_preprocess(np.copy(image), [TEST_INPUT_SIZE, TEST_INPUT_SIZE])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-05T10:41:58.182937Z","iopub.execute_input":"2021-08-05T10:41:58.183315Z","iopub.status.idle":"2021-08-05T10:41:58.535826Z","shell.execute_reply.started":"2021-08-05T10:41:58.183277Z","shell.execute_reply":"2021-08-05T10:41:58.534305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = [(img,name) for img,name in test_images]\n\nfor img,name in res:\n    result= (np.maximum(img,0) / img.max()) * 255.0\n    \n    cv.imwrite(os.path.join('/kaggle/working/test/'+name+'.jpg'), result)\n    # Read jpeg image\n    jpg_img = cv.imread('/kaggle/working/test/'+name+'.jpg')\n    plt.figure(figsize=(5,5))\n    plt.xlabel(name)\n    plt.imshow(result,cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:54:34.929495Z","iopub.execute_input":"2021-08-05T08:54:34.929847Z","iopub.status.idle":"2021-08-05T08:54:46.217666Z","shell.execute_reply.started":"2021-08-05T08:54:34.929813Z","shell.execute_reply":"2021-08-05T08:54:46.216623Z"},"trusted":true},"execution_count":null,"outputs":[]}]}