{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 制作测试集","metadata":{}},{"cell_type":"markdown","source":"这部分参照了：https://www.kaggle.com/laxmikantnishad/covid-19-2-para","metadata":{}},{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-07T13:10:42.471506Z","iopub.execute_input":"2021-06-07T13:10:42.472047Z","iopub.status.idle":"2021-06-07T13:11:54.05858Z","shell.execute_reply.started":"2021-06-07T13:10:42.471944Z","shell.execute_reply":"2021-06-07T13:11:54.057588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-07T13:11:54.060635Z","iopub.execute_input":"2021-06-07T13:11:54.060992Z","iopub.status.idle":"2021-06-07T13:11:54.072189Z","shell.execute_reply.started":"2021-06-07T13:11:54.060955Z","shell.execute_reply":"2021-06-07T13:11:54.071337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"（1）dcm to .png","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n        ","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:11:54.075827Z","iopub.execute_input":"2021-06-07T13:11:54.076079Z","iopub.status.idle":"2021-06-07T13:11:54.336594Z","shell.execute_reply.started":"2021-06-07T13:11:54.076056Z","shell.execute_reply":"2021-06-07T13:11:54.335758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:11:54.338552Z","iopub.execute_input":"2021-06-07T13:11:54.338952Z","iopub.status.idle":"2021-06-07T13:11:54.345192Z","shell.execute_reply.started":"2021-06-07T13:11:54.338902Z","shell.execute_reply":"2021-06-07T13:11:54.344071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"（2）开始划分数据集","metadata":{}},{"cell_type":"code","source":"split = 'test'\nsave_dir = f'./{split}/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'./{split}/study/'\nos.makedirs(save_dir, exist_ok=True)\n\nfor dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n    for file in filenames:\n        # set keep_ratio=True to have original aspect ratio\n        xray = read_xray(os.path.join(dirname, file))\n        im = resize(xray, size=512)  \n        study = dirname.split('/')[-2] + '_study.png'\n        #study = dirname.split('/')[-2] + '_study'\n        im.save(os.path.join(save_dir, study))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:11:54.346772Z","iopub.execute_input":"2021-06-07T13:11:54.347395Z","iopub.status.idle":"2021-06-07T13:21:23.33473Z","shell.execute_reply.started":"2021-06-07T13:11:54.347352Z","shell.execute_reply":"2021-06-07T13:21:23.333873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#调试时用于删除残留数据\n#!rm -r ./test/study/","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:23.336035Z","iopub.execute_input":"2021-06-07T13:21:23.336518Z","iopub.status.idle":"2021-06-07T13:21:23.34015Z","shell.execute_reply.started":"2021-06-07T13:21:23.33648Z","shell.execute_reply":"2021-06-07T13:21:23.339334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 创造验证集与测试集","metadata":{}},{"cell_type":"code","source":"import sys; \n\npackage_paths = [\n    '../input/pytorch-image-models/pytorch-image-models-master', #导入pytorch模型\n    '../input/image-fmix/FMix-master'                            #FMix是一种数据增强方法（最近比较火的一种）\n]\n\nfor pth in package_paths:\n    sys.path.append(pth)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:23.341315Z","iopub.execute_input":"2021-06-07T13:21:23.341797Z","iopub.status.idle":"2021-06-07T13:21:23.355679Z","shell.execute_reply.started":"2021-06-07T13:21:23.34176Z","shell.execute_reply":"2021-06-07T13:21:23.35493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimport cv2\nfrom skimage import io\nimport torch\nfrom torch import nn\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport torchvision\nfrom torchvision import transforms\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\n\nimport timm\nimport sklearn\nimport warnings\nimport joblib\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn import metrics\nimport warnings\nimport cv2\nimport pydicom\nfrom scipy.ndimage.interpolation import zoom\n\nfrom fmix import sample_mask, make_low_freq_image, binarise_mask\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:23.356965Z","iopub.execute_input":"2021-06-07T13:21:23.357513Z","iopub.status.idle":"2021-06-07T13:21:26.645695Z","shell.execute_reply.started":"2021-06-07T13:21:23.357477Z","shell.execute_reply":"2021-06-07T13:21:26.644889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 将训练csv读入\nCOMPETITION_NAME = \"siimcovid19-512-img-png-600-study-png\"\nload_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\ndf = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:26.649451Z","iopub.execute_input":"2021-06-07T13:21:26.649717Z","iopub.status.idle":"2021-06-07T13:21:26.69771Z","shell.execute_reply.started":"2021-06-07T13:21:26.649691Z","shell.execute_reply":"2021-06-07T13:21:26.696942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 为操作方便修改表头 inplace参数决定是否修改原df\ndf.rename(columns={'Negative for Pneumonia':'0','Typical Appearance':'1',\"Indeterminate Appearance\":'2',\n                   \"Atypical Appearance\":\"3\"}, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:26.699322Z","iopub.execute_input":"2021-06-07T13:21:26.699703Z","iopub.status.idle":"2021-06-07T13:21:26.713738Z","shell.execute_reply.started":"2021-06-07T13:21:26.699667Z","shell.execute_reply":"2021-06-07T13:21:26.712533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 解码one-hot\nlabels = []\ndef get_label(row):\n    for c in df.columns:\n        if row[c]==1:\n            labels.append(int(c))\ndf.apply(get_label, axis=1)\nprint(\"label modified\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:26.715295Z","iopub.execute_input":"2021-06-07T13:21:26.71585Z","iopub.status.idle":"2021-06-07T13:21:26.91203Z","shell.execute_reply.started":"2021-06-07T13:21:26.715811Z","shell.execute_reply":"2021-06-07T13:21:26.911103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 合并两份DataFrame,注意axis = 1参数\nlabels = {'label':labels}\nstudy_label = pd.DataFrame(labels)\ntrain_study = pd.concat([df, study_label], axis = 1)\n#print(train_study)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:26.913366Z","iopub.execute_input":"2021-06-07T13:21:26.913954Z","iopub.status.idle":"2021-06-07T13:21:26.924294Z","shell.execute_reply.started":"2021-06-07T13:21:26.913912Z","shell.execute_reply":"2021-06-07T13:21:26.923356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_study ['0'];del train_study ['1'];del train_study ['2'];del train_study ['3']\ntrain_study","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:26.925712Z","iopub.execute_input":"2021-06-07T13:21:26.926041Z","iopub.status.idle":"2021-06-07T13:21:26.941786Z","shell.execute_reply.started":"2021-06-07T13:21:26.926015Z","shell.execute_reply":"2021-06-07T13:21:26.940628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3 模型的基本参数","metadata":{}},{"cell_type":"code","source":"CFG = {\n    'fold_num': 5,\n    'seed': 719,\n    'model_arch': 'tf_efficientnet_b4_ns',\n    'img_size': 512,\n    'epochs': 10,\n    'train_bs': 32,\n    'valid_bs': 32,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'tta': 3,\n    'used_epochs': [53,55,56,59],\n    'weights': [1,1,1,1]\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:26.943614Z","iopub.execute_input":"2021-06-07T13:21:26.944204Z","iopub.status.idle":"2021-06-07T13:21:26.951455Z","shell.execute_reply.started":"2021-06-07T13:21:26.944162Z","shell.execute_reply":"2021-06-07T13:21:26.950247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \ndef get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    #print(im_rgb)\n    return im_rgb\n\n#img = get_img('../input/siim-covid19-detection/test/00188a671292/3eb5a506ccf3/3dcdfc352a06.dcm')\n#plt.imshow(img)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:26.953061Z","iopub.execute_input":"2021-06-07T13:21:26.953823Z","iopub.status.idle":"2021-06-07T13:21:26.961722Z","shell.execute_reply.started":"2021-06-07T13:21:26.95378Z","shell.execute_reply":"2021-06-07T13:21:26.960796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(\n        self, df, data_root, transforms=None, output_label=True\n    ):\n        \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.output_label = output_label\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.df.iloc[index]['label']\n        \n        tempstr = self.df.iloc[index]['id'][-3:]\n        if tempstr == 'png':\n            path = \"{}/{}\".format(self.data_root, self.df.iloc[index]['id'])\n        else:\n            path = \"{}/{}\".format(self.data_root, self.df.iloc[index]['id'])+'.png'\n        \n        img  = get_img(path)\n        \n        if self.transforms:\n            img = self.transforms(image=img)['image']\n            \n        # do label smoothing\n        if self.output_label == True:\n            return img, target\n        else:\n            return img","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:26.9633Z","iopub.execute_input":"2021-06-07T13:21:26.963741Z","iopub.status.idle":"2021-06-07T13:21:26.975506Z","shell.execute_reply.started":"2021-06-07T13:21:26.9637Z","shell.execute_reply":"2021-06-07T13:21:26.974398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_train_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n  \n        \ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\ndef get_inference_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:26.977141Z","iopub.execute_input":"2021-06-07T13:21:26.977539Z","iopub.status.idle":"2021-06-07T13:21:27.616269Z","shell.execute_reply.started":"2021-06-07T13:21:26.977496Z","shell.execute_reply":"2021-06-07T13:21:27.615211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CassvaImgClassifier(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:27.617586Z","iopub.execute_input":"2021-06-07T13:21:27.618823Z","iopub.status.idle":"2021-06-07T13:21:27.631761Z","shell.execute_reply.started":"2021-06-07T13:21:27.618781Z","shell.execute_reply":"2021-06-07T13:21:27.630586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_one_epoch(model, data_loader, device):\n    model.eval()\n\n    image_preds_all = []\n    \n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs) in pbar:\n        imgs = imgs.to(device).float()\n        \n        image_preds = model(imgs)   #output = model(input)\n        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n        \n    \n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:21:27.633506Z","iopub.execute_input":"2021-06-07T13:21:27.63508Z","iopub.status.idle":"2021-06-07T13:21:27.650499Z","shell.execute_reply.started":"2021-06-07T13:21:27.63499Z","shell.execute_reply":"2021-06-07T13:21:27.649343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4 主循环","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n     # for training only, need nightly build pytorch\n\n    seed_everything(CFG['seed'])\n    \n    folds = StratifiedKFold(n_splits=CFG['fold_num']).split(np.arange(train_study.shape[0]), train_study.label.values)\n    \n    for fold, (trn_idx, val_idx) in enumerate(folds):\n        # we'll train fold 0 first\n        if fold > 0:\n            break \n\n        print('Inference fold {} started'.format(fold))\n\n        valid_ = train_study.loc[val_idx,:].reset_index(drop=True)\n        #print('valid_',valid_)\n        valid_ds = CassavaDataset(valid_, '../input/siimcovid19-512-img-png-600-study-png/study/', transforms=get_inference_transforms(), output_label=False)\n        \n        test = pd.DataFrame()\n        test['id'] = list(os.listdir('./test/study/'))\n        #print('test',test)\n        test_ds = CassavaDataset(test, './test/study/', transforms=get_inference_transforms(), output_label=False)\n        #print('test_ds',test)\n\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=False,\n        )\n        \n        tst_loader = torch.utils.data.DataLoader(\n            test_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=False,\n        )\n\n        device = torch.device(CFG['device'])\n        model = CassvaImgClassifier(CFG['model_arch'], train_study.label.nunique()).to(device)\n        \n        val_preds = []\n        tst_preds = []\n        \n        #for epoch in range(CFG['epochs']-3):\n        for i, epoch in enumerate(CFG['used_epochs']):    \n            model.load_state_dict(torch.load('../input/pytorch-studyclass-baseline/{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch)))\n            \n            with torch.no_grad():\n                for _ in range(CFG['tta']):\n                    val_preds += [CFG['weights'][i]/sum(CFG['weights'])/CFG['tta']*inference_one_epoch(model, val_loader, device)]\n                    tst_preds += [CFG['weights'][i]/sum(CFG['weights'])/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n\n        val_preds = np.mean(val_preds, axis=0) \n        tst_preds = np.mean(tst_preds, axis=0) \n        \n        print('fold {} validation loss = {:.5f}'.format(fold, log_loss(valid_.label.values, val_preds)))\n        print('fold {} validation accuracy = {:.5f}'.format(fold, (valid_.label.values==np.argmax(val_preds, axis=1)).mean()))\n        \n        del model\n        torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T13:23:17.963334Z","iopub.execute_input":"2021-06-07T13:23:17.96382Z","iopub.status.idle":"2021-06-07T13:33:37.251355Z","shell.execute_reply.started":"2021-06-07T13:23:17.963779Z","shell.execute_reply":"2021-06-07T13:33:37.250258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5 创造submission.csv","metadata":{}},{"cell_type":"code","source":"def CreateSub(testid, tst_preds):\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n    for i in range(len(test)):\n        for j in range(len(test)):\n            a = test.loc[i,'id'].split('.')[0]\n            b = sub_df.loc[j,'id']\n            if a==b:\n                negative, typical, indeterminate, atypical = str(tst_preds[i][0]),str(tst_preds[i][1]),str(tst_preds[i][2]),str(tst_preds[i][3]),\n                sub_df.loc[j,'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\n    return sub_df","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:13:25.914735Z","iopub.execute_input":"2021-06-07T14:13:25.915169Z","iopub.status.idle":"2021-06-07T14:13:25.923127Z","shell.execute_reply.started":"2021-06-07T14:13:25.915123Z","shell.execute_reply":"2021-06-07T14:13:25.922111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sumfile = CreateSub(test, tst_preds)\nsumfile.to_csv('./submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:16:14.485443Z","iopub.execute_input":"2021-06-07T14:16:14.485789Z","iopub.status.idle":"2021-06-07T14:16:45.963576Z","shell.execute_reply.started":"2021-06-07T14:16:14.485756Z","shell.execute_reply":"2021-06-07T14:16:45.962742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#删除残留数据\n!rm -r ./test/study/","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:16:49.691401Z","iopub.execute_input":"2021-06-07T14:16:49.691748Z","iopub.status.idle":"2021-06-07T14:16:50.556931Z","shell.execute_reply.started":"2021-06-07T14:16:49.69172Z","shell.execute_reply":"2021-06-07T14:16:50.555755Z"},"trusted":true},"execution_count":null,"outputs":[]}]}