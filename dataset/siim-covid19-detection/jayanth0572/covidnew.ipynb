{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-19T04:11:55.381787Z","iopub.execute_input":"2021-06-19T04:11:55.382184Z","iopub.status.idle":"2021-06-19T04:11:55.386818Z","shell.execute_reply.started":"2021-06-19T04:11:55.382131Z","shell.execute_reply":"2021-06-19T04:11:55.385636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q\n!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q\n!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q\n!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q\n!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q\n!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q\n\n!conda install 'libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install 'libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install 'gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install 'conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install 'certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install 'openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nfrom PIL import Image\nimport pandas as pd\ntrain = pd.read_csv('/kaggle/input/siim-covid19-detection/train_image_level.csv')\ntrain_study = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv')\ntrain_study['StudyInstanceUID'] = train_study['id'].apply(lambda x: x.replace('_study', ''))\ndel train_study['id']\ntrain = train.merge(train_study, on='StudyInstanceUID')\nclass_names = ['Negative for Pneumonia','Typical Appearance', 'Indeterminate Appearance','Atypical Appearance']\nclassMap={0:[1, 0, 0, 0],\n         1:[0, 1, 0, 0],\n         2:[0, 0, 1, 0],\n         3:[0, 0, 0, 1]}\n\ndef findClass(value):\n    value=value.tolist()\n    for key,val in classMap.items():\n        if value==val:\n            return key\ntrain[\"class\"] =[findClass(li) for li in train[class_names].values]\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:21:33.488709Z","iopub.execute_input":"2021-06-19T07:21:33.489009Z","iopub.status.idle":"2021-06-19T07:21:33.587556Z","shell.execute_reply.started":"2021-06-19T07:21:33.488978Z","shell.execute_reply":"2021-06-19T07:21:33.586449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgPath_df=pd.DataFrame(columns=['id','path'])\nfor dirname, _, filenames in os.walk('/kaggle/input/siim-covid19-detection/train'):\n    for filename in filenames:\n        imgPath=os.path.join(dirname, filename)\n        imgPath_df=imgPath_df.append({'id':filename.replace('.dcm','_image'),'path':imgPath},ignore_index=True)\n\n\ntrain = train.merge(imgPath_df, on='id')\ntrain.to_csv('/kaggle/working/train.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:21:33.589381Z","iopub.execute_input":"2021-06-19T07:21:33.58979Z","iopub.status.idle":"2021-06-19T07:22:07.268559Z","shell.execute_reply.started":"2021-06-19T07:21:33.589747Z","shell.execute_reply":"2021-06-19T07:22:07.267656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:17:27.322445Z","iopub.execute_input":"2021-06-19T07:17:27.322771Z","iopub.status.idle":"2021-06-19T07:17:27.345717Z","shell.execute_reply.started":"2021-06-19T07:17:27.322739Z","shell.execute_reply":"2021-06-19T07:17:27.344981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://www.kaggle.com/jayanth0572/inference-studyclass-baseline/edit","metadata":{}},{"cell_type":"code","source":"\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport numpy as np\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:22:07.270086Z","iopub.execute_input":"2021-06-19T07:22:07.270667Z","iopub.status.idle":"2021-06-19T07:22:07.472697Z","shell.execute_reply.started":"2021-06-19T07:22:07.270629Z","shell.execute_reply":"2021-06-19T07:22:07.471613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:22:07.476873Z","iopub.execute_input":"2021-06-19T07:22:07.477219Z","iopub.status.idle":"2021-06-19T07:22:07.486576Z","shell.execute_reply.started":"2021-06-19T07:22:07.477184Z","shell.execute_reply":"2021-06-19T07:22:07.485645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import Tensor\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms, models\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nfrom torch.nn import Linear\nfrom torch.nn import ReLU\nfrom torch.nn import Softmax\nfrom torch.nn import Module\nfrom torch.optim import SGD\nfrom torch.nn import CrossEntropyLoss\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom numpy import asarray\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, annotations_file, transform=None, target_transform=None):\n        \n        self.img_labels=pd.read_csv(annotations_file)[:1000]\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path =self.img_labels.iloc[idx,9]\n        image=read_xray(img_path)\n        image=resize(image, 416)\n        image=asarray(image)\n        image = torch.from_numpy(image).long()\n        image=np.stack((image,)*3, axis=0)\n        label = self.img_labels.iloc[idx, 8]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        \n        return image, label\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:22:07.490926Z","iopub.execute_input":"2021-06-19T07:22:07.492843Z","iopub.status.idle":"2021-06-19T07:22:08.780917Z","shell.execute_reply.started":"2021-06-19T07:22:07.492803Z","shell.execute_reply":"2021-06-19T07:22:08.780074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n\nhttps://towardsdatascience.com/how-to-train-an-image-classifier-in-pytorch-and-use-it-to-perform-basic-inference-on-single-images-99465a1e9bf5","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() \n                                  else \"cpu\")\nmodel = models.resnet50(pretrained=False)\nfor param in model.parameters():\n    param.requires_grad = True\n    \nmodel.fc = nn.Sequential(nn.Linear(2048, 512),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(512, 4),\n                                 nn.Softmax(dim=1))\n\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:22:08.782898Z","iopub.execute_input":"2021-06-19T07:22:08.783154Z","iopub.status.idle":"2021-06-19T07:22:13.736814Z","shell.execute_reply.started":"2021-06-19T07:22:08.783128Z","shell.execute_reply":"2021-06-19T07:22:13.735997Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\ndef train_model(train_dl, model):\n    # define the optimization\n    criterion =nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n    # enumerate epochs\n    for epoch in range(5):\n        # enumerate mini batches\n        for inputs, labels in train_dl:\n            inputs, labels = inputs.to(device), labels.to(device)\n            # clear the gradients\n            optimizer.zero_grad()\n            # compute the model output\n            logps = model.forward(inputs.float())\n            # calculate loss\n            loss = criterion(logps, labels.long())\n            # credit assignment\n            loss.backward()\n            # update model weights\n            optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:26:41.620772Z","iopub.execute_input":"2021-06-19T07:26:41.62113Z","iopub.status.idle":"2021-06-19T07:26:41.627944Z","shell.execute_reply.started":"2021-06-19T07:26:41.621099Z","shell.execute_reply":"2021-06-19T07:26:41.626766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dataset = CustomImageDataset(annotations_file='/kaggle/working/train.csv')\ntrain_dataloader = DataLoader(image_dataset, batch_size=10, shuffle=True)\ntrain_model(train_dataloader,model)\ntorch.save(model, 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:26:46.534946Z","iopub.execute_input":"2021-06-19T07:26:46.535272Z","iopub.status.idle":"2021-06-19T07:55:06.460578Z","shell.execute_reply.started":"2021-06-19T07:26:46.535242Z","shell.execute_reply":"2021-06-19T07:55:06.456516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ncol=['id','PredictionString']\ntest_transforms = transforms.Compose([transforms.ToTensor(),\n                                     ])\nprediction=pd.DataFrame(columns = col) \nfor dirname, _, filenames in os.walk('/kaggle/input/siim-covid19-detection/test'):\n    for filename in filenames:\n        img_path= os.path.join(dirname, filename)\n        id_=img_path.split('/')[5]+\"_study\"\n        image=read_xray(img_path)\n        image=resize(image, 416)\n        image=asarray(image)\n        image = torch.from_numpy(image).long()\n        image=np.stack((image,)*3, axis=0)\n        image_tensor = test_transforms(image).float()\n        image_tensor = image_tensor.unsqueeze_(0)\n        #inputs = Variable(image_tensor)\n        inputs = image_tensor.to(device)\n        inputs=torch.transpose(inputs, 1, 2)\n        output = model(inputs)\n        predProb = output.detach().cpu().numpy()[0]\n        PredictionString=f'negative {format(predProb[0],\".8f\")} 0 0 1 1 typical {format(predProb[1],\".5f\")} 0 0 1 1 indeterminate {format(predProb[2],\".5f\")} 0 0 1 1 atypical {format(predProb[3],\".5f\")} 0 0 1 1' \n        #print(PredictionString)\n        prediction=prediction.append({\"id\":id_,\"PredictionString\":PredictionString},ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T08:28:19.622639Z","iopub.execute_input":"2021-06-19T08:28:19.622984Z","iopub.status.idle":"2021-06-19T08:35:59.767372Z","shell.execute_reply.started":"2021-06-19T08:28:19.622954Z","shell.execute_reply":"2021-06-19T08:35:59.765406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CreateSub(test):\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n    for i in range(len(sub_df)):\n        #print(test[test['id']==sub_df.loc[i,'id']])\n        #negative, typical, indeterminate, atypical = str(tst_preds[i][0]),str(tst_preds[i][1]),str(tst_preds[i][2]),str(tst_preds[i][3]),\n        try:\n            sub_df.loc[i,'PredictionString'] =test[test['id']==sub_df.loc[i,'id']].iloc[0,1]# test[test['id']==sub_df.loc[i,'id']][0][1]#f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\n        except:\n            continue\n    return sub_df","metadata":{"execution":{"iopub.status.busy":"2021-06-19T08:47:03.211143Z","iopub.execute_input":"2021-06-19T08:47:03.211454Z","iopub.status.idle":"2021-06-19T08:47:03.216287Z","shell.execute_reply.started":"2021-06-19T08:47:03.211425Z","shell.execute_reply":"2021-06-19T08:47:03.215498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sumfile = CreateSub(prediction)\nsumfile.to_csv('./submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T08:47:07.438472Z","iopub.execute_input":"2021-06-19T08:47:07.438817Z","iopub.status.idle":"2021-06-19T08:47:09.157512Z","shell.execute_reply.started":"2021-06-19T08:47:07.438787Z","shell.execute_reply":"2021-06-19T08:47:09.156684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}