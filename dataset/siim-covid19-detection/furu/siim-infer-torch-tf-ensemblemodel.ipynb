{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Pytorch Tensorflow ensemble model\n\n#### studylevel : effnetv2m(torch) + effnetv2l(tf)\n#### 2class: effnetv2m+b3(torch) + effnetb5(tf)\n#### imagelevel : yolov5(3model) + effdet + resdet (wbf ensemble)\n\n### only publish inference notebook \n\n## reference\n\n### thanks to https://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-l-cascadercnn-mmdetection-infer\n### thanks to https://www.kaggle.com/micheomaano/siim-cov19-efnb7-yolov5-infer\n### thanks to https://www.kaggle.com/h053473666/siim-cov19-efnb7-yolov5-infer\n### thanks to https://www.kaggle.com/shangweichen/siim-efnb7-train-pytorch-xla-tpu\n\n\n## my public notebook \n\n### [step1 get_imageinformation](https://www.kaggle.com/kunihikofurugori/siim-step1-get-imginfo).\n\n### [step2 make_dataframe](https://www.kaggle.com/kunihikofurugori/step2-make-dataframe/edit/run/69201903).\n\n### [step3-1 renew-imglev_ds](https://www.kaggle.com/kunihikofurugori/siim-step3-1-renew-imglev-ds)\n\n### [step3-2 renew-studylev_ds](https://www.kaggle.com/kunihikofurugori/siim-step3-1-renew-studylev-ds)\n\n","metadata":{}},{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:44:39.527504Z","iopub.execute_input":"2021-08-04T22:44:39.527858Z","iopub.status.idle":"2021-08-04T22:45:50.360376Z","shell.execute_reply.started":"2021-08-04T22:44:39.527781Z","shell.execute_reply":"2021-08-04T22:45:50.359458Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport cv2\nimport sys\nsys.path.append(\"/kaggle/usr/lib/siim_infer_helper_func/\")\nfrom siim_infer_helper_func import *","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-04T22:45:50.363846Z","iopub.execute_input":"2021-08-04T22:45:50.364129Z","iopub.status.idle":"2021-08-04T22:45:55.202718Z","shell.execute_reply.started":"2021-08-04T22:45:50.364101Z","shell.execute_reply":"2021-08-04T22:45:55.2018Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\nif df.shape[0] == 2477:\n    tp1 = \"/kaggle/input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm\"\n    tp2 = \"/kaggle/input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm\"\n    fast_sub = True\n    fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n                         ['65761e66de9f_image', 'none 1 0 0 1 1'], \n                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n                       columns=['id', 'PredictionString'])\nelse:\n    fast_sub = False","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-04T22:45:55.204458Z","iopub.execute_input":"2021-08-04T22:45:55.204783Z","iopub.status.idle":"2021-08-04T22:45:55.223826Z","shell.execute_reply.started":"2021-08-04T22:45:55.204748Z","shell.execute_reply":"2021-08-04T22:45:55.222928Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_size = (768,768)\nimage_size = (640,640)\n\nsplit = 'test'\nsave_dir = f'/kaggle/tmp/{split}/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'/kaggle/tmp/{split}/study/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray(tp1)\n    im = resize(xray, size1=study_size[0],size2=study_size[1])  \n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    assert(tp1.split(\"/\")[-3] == '00086460a852')\n    xray = read_xray(tp2)\n    im = resize(xray, size1=study_size[0],size2=study_size[1])  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    assert(tp2.split(\"/\")[-3] == '000c9c05fd14')\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size1=study_size[0], size2=study_size[1])  \n            study = dirname.split('/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-04T22:45:55.225598Z","iopub.execute_input":"2021-08-04T22:45:55.22606Z","iopub.status.idle":"2021-08-04T22:45:56.960313Z","shell.execute_reply.started":"2021-08-04T22:45:55.226018Z","shell.execute_reply":"2021-08-04T22:45:56.959449Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id = []\ndim0 = []\ndim1 = []\nsplits = []\nsave_dir = f'/kaggle/tmp/{split}/image/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray(tp1)\n    im = cv2.resize(xray,image_size,interpolation = cv2.INTER_AREA)\n    cv2.imwrite(os.path.join(save_dir,'65761e66de9f_image.png'),im)\n    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\n    xray = read_xray(tp2)\n    im = cv2.resize(xray,image_size,interpolation = cv2.INTER_AREA)\n    cv2.imwrite(os.path.join(save_dir, '51759b5579bc_image.png'),im)\n    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\nelse:\n    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = cv2.resize(xray,image_size,interpolation = cv2.INTER_AREA)\n            cv2.imwrite(os.path.join(save_dir, file.replace('.dcm', '_image.png')),im)\n            image_id.append(file.replace('.dcm', ''))\n            dim0.append(xray.shape[0])\n            dim1.append(xray.shape[1])\n            splits.append(split)\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-04T22:45:56.961671Z","iopub.execute_input":"2021-08-04T22:45:56.962033Z","iopub.status.idle":"2021-08-04T22:45:57.200204Z","shell.execute_reply.started":"2021-08-04T22:45:56.961996Z","shell.execute_reply":"2021-08-04T22:45:57.199309Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# study level and 2-class","metadata":{}},{"cell_type":"markdown","source":"## model and weight paths","metadata":{}},{"cell_type":"code","source":"study_tf_mpaths = [\n    \"/kaggle/input/bestmodeldataset/fold0v2l_0.831.h5\",\n    \"/kaggle/input/bestmodeldataset/fold0v2l_0.831.h5\",\n    \"/kaggle/input/bestmodeldataset/fold0_v2l_0.828.h5\",\n    \"/kaggle/input/bestmodeldataset/fold1_v2l_0.828.h5\"\n]\n\nbinaryclass_tf_mpaths = [\n    \"/kaggle/input/2class-tf/model0.h5\",\n    \"/kaggle/input/2class-tf/model1.h5\",\n    \"/kaggle/input/2class-tf/model2.h5\",\n    \"/kaggle/input/2class-tf/model3.h5\",\n    \"/kaggle/input/2class-tf/model4.h5\",\n]\n\nweightpath = [\n              \"../input/covid19-effneteffdet/blackout_effv2m_image600/pretrained_model_0_0.848.bin\",\n              \"../input/covid19-effneteffdet/blackout_effv2m_image600/pretrained_model_2_0.841.bin\",           \n             ]\n\nmodelpath = [\n             \"tf_efficientnetv2_m\",\n             \"tf_efficientnetv2_m\",\n            ]\n\nnonewpath = [\"../input/covid19-effneteffdet/none_effv2m_image600/model_0_0.903.bin\",\n             \"../input/covid19-effneteffdet/effv2mnone_image640model/pretrained_model_1_0.925_imagesize640.bin\",\n             \"../input/covid19-effneteffdet/none_effv2m_image600/model_2_0.925.bin\",\n             \"../input/covid19-effneteffdet/effv2mnone_image640model/pretrained_model_3_0.908_imagesize640.bin\",\n             \"../input/covid19-effneteffdet/effv2mnone_image640model/pretrained_model_4_0.901_centralcrop640to600.bin\"]\n\nnonemodelpath = [\"tf_efficientnetv2_m\",\n                 \"tf_efficientnetv2_m\",\n                 \"tf_efficientnetv2_m\",\n                 \"tf_efficientnetv2_m\",\n                 \"tf_efficientnetv2_m\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:45:57.203399Z","iopub.execute_input":"2021-08-04T22:45:57.203672Z","iopub.status.idle":"2021-08-04T22:45:57.211438Z","shell.execute_reply.started":"2021-08-04T22:45:57.203646Z","shell.execute_reply":"2021-08-04T22:45:57.210598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tensorflow","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as tfhub\n\nMODEL_ARCH = 'efficientnetv2-l-21k-ft1k'\n# Get the TensorFlow Hub model URL\nhub_type = 'feature_vector' # ['classification', 'feature_vector']\nMODEL_ARCH_PATH = f'/kaggle/input/efficientnetv2-tfhub-weight-files/tfhub_models/{MODEL_ARCH}/{hub_type}'\n\n# Custom wrapper class to load the right pretrained weights explicitly from the local directory\nclass KerasLayerWrapper(tfhub.KerasLayer):\n    def __init__(self, handle, **kwargs):\n        handle = tfhub.KerasLayer(tfhub.load(MODEL_ARCH_PATH))\n        super().__init__(handle, **kwargs)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:45:57.212858Z","iopub.execute_input":"2021-08-04T22:45:57.213198Z","iopub.status.idle":"2021-08-04T22:45:57.371811Z","shell.execute_reply.started":"2021-08-04T22:45:57.213163Z","shell.execute_reply":"2021-08-04T22:45:57.370951Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nif fast_sub:\n    df = fast_df.copy()\nelse:\n    df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\n\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:45:57.3749Z","iopub.execute_input":"2021-08-04T22:45:57.375315Z","iopub.status.idle":"2021-08-04T22:45:57.397039Z","shell.execute_reply.started":"2021-08-04T22:45:57.375272Z","shell.execute_reply":"2021-08-04T22:45:57.396203Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prepare tensorflow module\n\n!pip install /kaggle/input/kerasapplications -q\n!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps\n\nimport os\n\nimport efficientnet.tfkeras as efn\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:45:57.399195Z","iopub.execute_input":"2021-08-04T22:45:57.399564Z","iopub.status.idle":"2021-08-04T22:46:49.970539Z","shell.execute_reply.started":"2021-08-04T22:45:57.399526Z","shell.execute_reply":"2021-08-04T22:46:49.96968Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nsub_df = sub_df[:study_len]\ntest_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'\n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 16\nIMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 768)\n\nlabel_cols = sub_df.columns[2:]\n\ntest_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[8], IMSIZE[8]), ext='png')\ndtest = build_dataset(\n    test_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder\n)\n\nwith strategy.scope():\n    \n    models = []\n    for mpath in study_tf_mpaths:\n        model = tf.keras.models.load_model(mpath,custom_objects={'KerasLayer': KerasLayerWrapper})\n        models.append(model)\n        del model\n\nsub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)\nsub_df_tf = sub_df.copy()\ndel models","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:46:49.97366Z","iopub.execute_input":"2021-08-04T22:46:49.973935Z","iopub.status.idle":"2021-08-04T22:48:24.601827Z","shell.execute_reply.started":"2021-08-04T22:46:49.973908Z","shell.execute_reply":"2021-08-04T22:48:24.600976Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nsub_df = sub_df[study_len:]\ntest_paths = f'/kaggle/tmp/{split}/image/' + sub_df['id'] +'.png'\nsub_df['none'] = 0\n\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 16\nIMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)\n\nlabel_cols = sub_df.columns[2]\n\ntest_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[8], IMSIZE[8]), ext='png')\ndtest = build_dataset(\n    test_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder\n)\n\nwith strategy.scope():\n    \n    models = []\n    for mpath in binaryclass_tf_mpaths:\n        model = tf.keras.models.load_model(mpath)\n        models.append(model)\n        del model\n\nsub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)\ndf_2class_tf = sub_df.copy().reset_index(drop=True)\ndel models","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:48:24.624394Z","iopub.execute_input":"2021-08-04T22:48:24.624762Z","iopub.status.idle":"2021-08-04T22:50:30.89141Z","shell.execute_reply.started":"2021-08-04T22:48:24.624724Z","shell.execute_reply":"2021-08-04T22:50:30.890574Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numba import cuda \ndevice = cuda.get_current_device()\ndevice.reset()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:30.90463Z","iopub.execute_input":"2021-08-04T22:50:30.905436Z","iopub.status.idle":"2021-08-04T22:50:31.93412Z","shell.execute_reply.started":"2021-08-04T22:50:30.905397Z","shell.execute_reply":"2021-08-04T22:50:31.933248Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport torch\nimport torch.nn as nn\n\nimport sys\nsys.path.insert(0, \"../input/timm-pytorch-image-models/pytorch-image-models-master/\")\nimport timm\n\ndevice = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:31.935617Z","iopub.execute_input":"2021-08-04T22:50:31.935964Z","iopub.status.idle":"2021-08-04T22:50:34.911786Z","shell.execute_reply.started":"2021-08-04T22:50:31.935922Z","shell.execute_reply":"2021-08-04T22:50:34.910818Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch studylevel","metadata":{}},{"cell_type":"code","source":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nsub_df = sub_df[:study_len]\ntest_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'\n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\nlabel_cols = sub_df.columns[2:]\nsub_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:34.914993Z","iopub.execute_input":"2021-08-04T22:50:34.915257Z","iopub.status.idle":"2021-08-04T22:50:34.936707Z","shell.execute_reply.started":"2021-08-04T22:50:34.915227Z","shell.execute_reply":"2021-08-04T22:50:34.935931Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_valid_transforms():\n    return A.Compose(\n        [\n            A.Resize(height=600, width=600, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\nDATA_ROOT_PATH = '/kaggle/tmp/test/study'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, path, transforms=None):\n        super().__init__()\n        self.df = df\n        self.path = path\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        path = self.path[index]\n        image_id = self.df.id[index]\n        image = cv2.imread(path,cv2.IMREAD_COLOR)\n        #print(image.std())\n        if image.std() < 20.0:\n            histimage = A.Equalize(p=1.0)(image=image)['image']\n        else:\n            histimage = image\n        histimage = ToTensorV2(p=1.0)(image=histimage)[\"image\"]\n        image = image.astype(np.float32)\n        image /= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        \n        assert(image.shape == (3,600,600))\n        return sample['image'], histimage, image_id#, dim0, dim1\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:34.938036Z","iopub.execute_input":"2021-08-04T22:50:34.938381Z","iopub.status.idle":"2021-08-04T22:50:34.948271Z","shell.execute_reply.started":"2021-08-04T22:50:34.938347Z","shell.execute_reply":"2021-08-04T22:50:34.947263Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetRetriever(\n    df=sub_df,\n    path = test_paths,\n    transforms=get_valid_transforms()\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:34.949784Z","iopub.execute_input":"2021-08-04T22:50:34.950178Z","iopub.status.idle":"2021-08-04T22:50:34.96051Z","shell.execute_reply.started":"2021-08-04T22:50:34.950142Z","shell.execute_reply":"2021-08-04T22:50:34.959642Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EfficientNetModel(nn.Module):\n    \"\"\"\n    Model Class for EfficientNet Model\n    \"\"\"\n    def __init__(self, model_name, num_classes=4, pretrained=True):\n        super(EfficientNetModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, num_classes)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nmodels = []\nmmodels = []\n\nfor wpath,mpath in zip(weightpath,modelpath):\n    print(wpath,mpath)\n    model = EfficientNetModel(mpath,pretrained=False).to(device)\n    model.load_state_dict(torch.load(wpath))\n    model.eval()\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:34.961757Z","iopub.execute_input":"2021-08-04T22:50:34.962243Z","iopub.status.idle":"2021-08-04T22:50:46.993122Z","shell.execute_reply.started":"2021-08-04T22:50:34.962208Z","shell.execute_reply":"2021-08-04T22:50:46.992195Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids = []\noutputs = np.empty((0,4))\n\nwith torch.no_grad():\n    for image, histimage, image_id, in data_loader:\n        image = image.cuda().float()\n        histimage = histimage.cuda().float()\n        for i,model in enumerate(models):\n            if i==0: \n                output = model(image).softmax(dim=1)\n            else:\n                output += model(image).softmax(dim=1)\n    \n        output = output/len(models)\n        \n        outputs = np.append(outputs,output.cpu().detach().numpy(),axis=0)\n        image_ids = np.append(image_ids,image_id)\nprint(outputs.shape)\nprint(image_ids.shape)\nsub_df.id = image_ids\nsub_df[label_cols] = outputs\nsub_df_torch = sub_df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:46.99451Z","iopub.execute_input":"2021-08-04T22:50:46.994846Z","iopub.status.idle":"2021-08-04T22:50:48.221357Z","shell.execute_reply.started":"2021-08-04T22:50:46.994809Z","shell.execute_reply":"2021-08-04T22:50:48.22006Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(sub_df_torch,sub_df_tf)\nsub_df[label_cols] = (sub_df_tf[label_cols] + sub_df_torch[label_cols])/2\ndisplay(sub_df)\ndf_study = sub_df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:48.254327Z","iopub.execute_input":"2021-08-04T22:50:48.25472Z","iopub.status.idle":"2021-08-04T22:50:48.289944Z","shell.execute_reply.started":"2021-08-04T22:50:48.254682Z","shell.execute_reply":"2021-08-04T22:50:48.288824Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(study_len):\n    negative = df_study.loc[i,'negative']\n    typical = df_study.loc[i,'typical']\n    indeterminate = df_study.loc[i,'indeterminate']\n    atypical = df_study.loc[i,'atypical']\n    df_study.loc[i, 'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\ndf_study = df_study[[\"id\",\"PredictionString\"]]\ndisplay(df_study)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:48.362556Z","iopub.execute_input":"2021-08-04T22:50:48.363033Z","iopub.status.idle":"2021-08-04T22:50:48.384672Z","shell.execute_reply.started":"2021-08-04T22:50:48.362998Z","shell.execute_reply":"2021-08-04T22:50:48.383923Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\ndel models","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:48.385845Z","iopub.execute_input":"2021-08-04T22:50:48.38633Z","iopub.status.idle":"2021-08-04T22:50:48.397896Z","shell.execute_reply.started":"2021-08-04T22:50:48.386294Z","shell.execute_reply":"2021-08-04T22:50:48.396857Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch 2-class","metadata":{}},{"cell_type":"code","source":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nsub_df = sub_df[study_len:].reset_index(drop=True)\ntest_paths = f'/kaggle/tmp/{split}/image/' + sub_df['id'] +'.png'\nsub_df['none'] = 0\nlabel_cols = sub_df.columns[2]\nsub_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:48.401445Z","iopub.execute_input":"2021-08-04T22:50:48.402053Z","iopub.status.idle":"2021-08-04T22:50:48.425102Z","shell.execute_reply.started":"2021-08-04T22:50:48.402018Z","shell.execute_reply":"2021-08-04T22:50:48.422626Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_valid_transforms():\n    return A.Compose(\n        [\n            #A.Resize(height=600, width=600, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\nDATA_ROOT_PATH = '/kaggle/tmp/test/study'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, path, transforms=None):\n        super().__init__()\n        self.df = df\n        self.path = path\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        path = self.path[index]\n        image_id = self.df.id[index]\n        image = cv2.imread(path,cv2.IMREAD_COLOR)\n        image = image.astype(np.float32)\n        image /= 255.0\n        cimage = A.CenterCrop(height=600,width=600,p=1.0)(image=image)[\"image\"]\n        rimage = cv2.resize(image,(600,600))\n        image = ToTensorV2(p=1.0)(image=image)[\"image\"]\n        cimage = ToTensorV2(p=1.0)(image=cimage)[\"image\"]\n        rimage = ToTensorV2(p=1.0)(image=rimage)[\"image\"]\n        \n        #assert(image.shape == (3,600,600))\n        return image, cimage, rimage, image_id\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:48.427786Z","iopub.execute_input":"2021-08-04T22:50:48.429132Z","iopub.status.idle":"2021-08-04T22:50:48.444666Z","shell.execute_reply.started":"2021-08-04T22:50:48.429081Z","shell.execute_reply":"2021-08-04T22:50:48.443439Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nonemodels = []\nfor wpath,mpath in zip(nonewpath,nonemodelpath):\n    model = EfficientNetModel(mpath,pretrained=False,num_classes=1).to(device)\n    model.load_state_dict(torch.load(wpath))\n    model.eval()\n    nonemodels.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:50:48.44638Z","iopub.execute_input":"2021-08-04T22:50:48.44709Z","iopub.status.idle":"2021-08-04T22:51:06.850829Z","shell.execute_reply.started":"2021-08-04T22:50:48.447054Z","shell.execute_reply":"2021-08-04T22:51:06.850003Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetRetriever(\n    df=sub_df,\n    path = test_paths,\n    transforms=get_valid_transforms()\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:06.85357Z","iopub.execute_input":"2021-08-04T22:51:06.853941Z","iopub.status.idle":"2021-08-04T22:51:06.858765Z","shell.execute_reply.started":"2021-08-04T22:51:06.853904Z","shell.execute_reply":"2021-08-04T22:51:06.85762Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids = []\nnoneout = []\n\n#outputs = []\nwith torch.no_grad():\n    for image,cimage,rimage, image_id, in data_loader:\n        image = image.cuda().float()\n        cimage = cimage.cuda().float()\n        rimage = rimage.cuda().float()\n        output0 = nonemodels[0](rimage).sigmoid() \n        output1 = nonemodels[1](image).sigmoid() \n        output2 = nonemodels[2](rimage).sigmoid() \n        output3 = nonemodels[3](image).sigmoid()\n        output4 = nonemodels[4](cimage).sigmoid()\n\n        outputn = (output0+output1+output2+output3+output4)/5\n        noneout = np.append(noneout,outputn.cpu().detach().numpy())\n        image_ids = np.append(image_ids,image_id)\nprint(noneout.shape)\nprint(image_ids.shape)\nsub_df[label_cols] = noneout\ndf_2class_torch = sub_df.reset_index(drop=True).copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:06.860053Z","iopub.execute_input":"2021-08-04T22:51:06.860416Z","iopub.status.idle":"2021-08-04T22:51:07.639781Z","shell.execute_reply.started":"2021-08-04T22:51:06.860379Z","shell.execute_reply":"2021-08-04T22:51:07.638755Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_2class_tf,df_2class_torch)\nsub_df[label_cols] = (df_2class_tf[label_cols] + df_2class_torch[label_cols])/2.0\ndisplay(sub_df)\ndf_2class = sub_df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:07.657528Z","iopub.execute_input":"2021-08-04T22:51:07.658076Z","iopub.status.idle":"2021-08-04T22:51:07.675273Z","shell.execute_reply.started":"2021-08-04T22:51:07.658029Z","shell.execute_reply":"2021-08-04T22:51:07.674033Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\ndel nonemodels","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:07.705027Z","iopub.execute_input":"2021-08-04T22:51:07.705507Z","iopub.status.idle":"2021-08-04T22:51:07.745369Z","shell.execute_reply.started":"2021-08-04T22:51:07.705463Z","shell.execute_reply":"2021-08-04T22:51:07.744389Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# image classification end \n\n# image level start","metadata":{}},{"cell_type":"markdown","source":"## image level path list","metadata":{}},{"cell_type":"code","source":"weights_dir = ['/kaggle/input/yolo-bestresult/best_fold0.pt',\n               '/kaggle/input/yolo-bestresult/best_fold1.pt',\n               '/kaggle/input/yolo-bestresult/best_fold2.pt',\n              ]\n\npaths = [\n         \n         \"/kaggle/input/covid19-effneteffdet/d3_image640/fold4-d3_0.660.bin\",\n         \"/kaggle/input/covid19-effneteffdet/fold0-cspresdext50pan_0.650.bin\",\n        ]\n\nmodel_names = [\n    \"tf_efficientdet_d3\",\n    \"cspresdext50pan\",\n]\n\ndet_weights = [1,1]\nweight_detyolo = [1,1]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:07.752313Z","iopub.execute_input":"2021-08-04T22:51:07.752656Z","iopub.status.idle":"2021-08-04T22:51:07.758176Z","shell.execute_reply.started":"2021-08-04T22:51:07.752625Z","shell.execute_reply":"2021-08-04T22:51:07.756951Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# yolo","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport torch\n\n\ndim = 640 #1024, 256, 'original'\ntest_dir = f'/kaggle/tmp/{split}/image'\n\n\nshutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\nos.chdir('/kaggle/working/yolov5') # install dependencies\n","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:07.760032Z","iopub.execute_input":"2021-08-04T22:51:07.760756Z","iopub.status.idle":"2021-08-04T22:51:08.311188Z","shell.execute_reply.started":"2021-08-04T22:51:07.760701Z","shell.execute_reply":"2021-08-04T22:51:08.310308Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py \\\n--weights {weights_dir[0]} {weights_dir[1]} {weights_dir[2]} \\\n--img 640\\\n--conf 0.001\\\n--iou 0.5\\\n--source $test_dir\\\n--name infer_fold \\\n--save-txt --save-conf --exist-ok\n\nlabelpaths = glob(\"runs/detect/infer_fold/labels/*\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:08.312504Z","iopub.execute_input":"2021-08-04T22:51:08.312836Z","iopub.status.idle":"2021-08-04T22:51:26.663119Z","shell.execute_reply.started":"2021-08-04T22:51:08.3128Z","shell.execute_reply":"2021-08-04T22:51:26.662155Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta = meta[meta['split'] == 'test']\nif fast_sub:\n    test_df = fast_df.copy()\nelse:\n    test_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\ntest_df = df[study_len:].reset_index(drop=True) \nmeta['image_id'] = meta['image_id'] + '_image'\nmeta.columns = ['id', 'dim0', 'dim1', 'split']\ntest_df = pd.merge(test_df, meta, on = 'id', how = 'left')\n\ntest_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:26.664748Z","iopub.execute_input":"2021-08-04T22:51:26.665121Z","iopub.status.idle":"2021-08-04T22:51:26.694558Z","shell.execute_reply.started":"2021-08-04T22:51:26.66508Z","shell.execute_reply":"2021-08-04T22:51:26.693701Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predbox_ens = []\nimage_ids = []\nscore = []\nbox = []\nfor file_path in tqdm(labelpaths):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    data = np.concatenate([data[:, :2], yolo2a(data[:, 2:])],axis=1)\n    \n    if fast_sub:\n        predbox_ens.append(norm2hw(h, w, data[:,2:]))\n    \n    \n    image_ids.append(image_id)\n    score.append(data[:,1])\n    box.append(data[:,2:])\n\npred_df_yolo = pd.DataFrame({'id':image_ids,'score':score,'label':1,'box':box})","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:26.696018Z","iopub.execute_input":"2021-08-04T22:51:26.696371Z","iopub.status.idle":"2021-08-04T22:51:26.754495Z","shell.execute_reply.started":"2021-08-04T22:51:26.696336Z","shell.execute_reply":"2021-08-04T22:51:26.753548Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df_yolo","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:26.755797Z","iopub.execute_input":"2021-08-04T22:51:26.756177Z","iopub.status.idle":"2021-08-04T22:51:26.784252Z","shell.execute_reply.started":"2021-08-04T22:51:26.756124Z","shell.execute_reply":"2021-08-04T22:51:26.783352Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fast_sub:\n    box_plot(tp1,predbox_ens[0])\n    box_plot(tp2,predbox_ens[1])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:26.785423Z","iopub.execute_input":"2021-08-04T22:51:26.785761Z","iopub.status.idle":"2021-08-04T22:51:28.52945Z","shell.execute_reply.started":"2021-08-04T22:51:26.785727Z","shell.execute_reply":"2021-08-04T22:51:28.528599Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# effdet","metadata":{}},{"cell_type":"code","source":"!pip install --no-deps '/kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl'\n!pip install \"/kaggle/input/effdet-latestvinbigdata-wbf-fused/omegaconf-2.0.6-py3-none-any.whl\"","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:51:28.530762Z","iopub.execute_input":"2021-08-04T22:51:28.531292Z","iopub.status.idle":"2021-08-04T22:52:17.309245Z","shell.execute_reply.started":"2021-08-04T22:51:28.53125Z","shell.execute_reply":"2021-08-04T22:52:17.30827Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.insert(0, \"/kaggle/input/effdet-latestvinbigdata-wbf-fused/efficientdet-pytorch/\")\nsys.path.insert(0, \"/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master/\")\nsys.path.insert(0, \"/kaggle/input/weightedboxesfusion\")\n\nimport torch\nimport os\n\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom effdet import get_efficientdet_config, EfficientDet, DetBenchPredict\nfrom effdet.efficientdet import HeadNet\nfrom glob import glob\nimport gc\nfrom ensemble_boxes import *","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:17.312773Z","iopub.execute_input":"2021-08-04T22:52:17.313069Z","iopub.status.idle":"2021-08-04T22:52:17.890636Z","shell.execute_reply.started":"2021-08-04T22:52:17.313039Z","shell.execute_reply":"2021-08-04T22:52:17.889686Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#meta = meta[meta['split'] == 'test']\nif fast_sub:\n    test_df = fast_df.copy()\nelse:\n    test_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\ntest_df = df[study_len:].reset_index(drop=True) \n#meta['image_id'] = meta['image_id'] + '_image'\n#meta.columns = ['id', 'dim0', 'dim1', 'split']\ntest_df = pd.merge(test_df, meta, on = 'id', how = 'left')\n\ntest_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:17.892017Z","iopub.execute_input":"2021-08-04T22:52:17.892505Z","iopub.status.idle":"2021-08-04T22:52:17.918997Z","shell.execute_reply.started":"2021-08-04T22:52:17.892463Z","shell.execute_reply":"2021-08-04T22:52:17.918018Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_valid_transforms():\n    return A.Compose(\n        [\n            #A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\nDATA_ROOT_PATH = '/kaggle/tmp/test/image'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, transforms=None):\n        super().__init__()\n        self.df = df\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_id = self.df.id.values[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}.png',cv2.IMREAD_COLOR)\n        dim0 = self.df.dim0.values[index]\n        dim1 = self.df.dim1.values[index]\n        image = image.astype(np.float32)\n        image /= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        \n        return sample['image'], image_id, dim0, dim1\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:17.920464Z","iopub.execute_input":"2021-08-04T22:52:17.920826Z","iopub.status.idle":"2021-08-04T22:52:17.930522Z","shell.execute_reply.started":"2021-08-04T22:52:17.92079Z","shell.execute_reply":"2021-08-04T22:52:17.929182Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetRetriever(\n    df=test_df,\n    transforms=get_valid_transforms()\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:17.932159Z","iopub.execute_input":"2021-08-04T22:52:17.932761Z","iopub.status.idle":"2021-08-04T22:52:17.94298Z","shell.execute_reply.started":"2021-08-04T22:52:17.932721Z","shell.execute_reply":"2021-08-04T22:52:17.942118Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_net(checkpoint_path,model_name):\n    config = get_efficientdet_config(model_name)\n    config.image_size = [640,640]\n    config.norm_kwargs=dict(eps=.001, momentum=.01)\n    net = EfficientDet(config, pretrained_backbone=False)\n    net.reset_head(num_classes=1)\n    net.class_net = HeadNet(config, num_outputs=config.num_classes)\n\n    checkpoint = torch.load(checkpoint_path)\n    net.load_state_dict(checkpoint['model_state_dict'])\n    del checkpoint\n    gc.collect()\n\n    evalnet = DetBenchPredict(net)\n    evalnet.eval();\n    return evalnet.cuda()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:17.944335Z","iopub.execute_input":"2021-08-04T22:52:17.944737Z","iopub.status.idle":"2021-08-04T22:52:17.953403Z","shell.execute_reply.started":"2021-08-04T22:52:17.944701Z","shell.execute_reply":"2021-08-04T22:52:17.952546Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nets = []\nfor path, mname in zip(paths,model_names):\n    print(path)\n    model = load_net(path,mname)\n    nets.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:17.954744Z","iopub.execute_input":"2021-08-04T22:52:17.955174Z","iopub.status.idle":"2021-08-04T22:52:25.55147Z","shell.execute_reply.started":"2021-08-04T22:52:17.955139Z","shell.execute_reply":"2021-08-04T22:52:25.550581Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_predictions(images, nets, score_threshold=0.001):\n    images = images.cuda().float()\n    predictions = []\n    dets = []\n    with torch.no_grad():\n        for model in nets:\n            dets.append(model(images))\n        for i in range(images.shape[0]):\n            boxes = [det[i].detach().cpu().numpy()[:,[1,0,3,2]]/640.0 for det in dets]\n            scores = [det[i].detach().cpu().numpy()[:,4] for det in dets]\n            label = [det[i].detach().cpu().numpy()[:,5] for det in dets]            \n            boxes, scores, label  = weighted_boxes_fusion(boxes,\n                                                          scores,\n                                                          label,\n                                                          weights=det_weights,\n                                                          iou_thr=0.6,\n                                                          conf_type='avg',\n                                                          skip_box_thr=0.01)\n            \n            indexes = np.where(scores > score_threshold)[0]\n            boxes = boxes[indexes]\n            scores = scores[indexes]\n            label = label[indexes]\n            predictions.append({\n                'boxes': boxes,\n                'scores': scores,\n                'label': label\n            })\n    return predictions\n\ndef format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"opacity {0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n    return \" \".join(pred_strings)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:25.552881Z","iopub.execute_input":"2021-08-04T22:52:25.553223Z","iopub.status.idle":"2021-08-04T22:52:25.566875Z","shell.execute_reply.started":"2021-08-04T22:52:25.553186Z","shell.execute_reply":"2021-08-04T22:52:25.566019Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nboxess = []\nfor j,(images, image_ids, dim0, dim1) in enumerate(data_loader):\n    predictions = make_predictions(images, nets)\n    for i,prediction in enumerate(predictions):\n        boxes = prediction['boxes']\n        scores = prediction['scores']\n        label = prediction['label']\n        image_id = image_ids[i]\n        \n        index = pred_df_yolo[pred_df_yolo.id==image_id].index\n        yolorow = pred_df_yolo.iloc[index]\n        boxes_y = yolorow.box.values[0]\n        scores_y = yolorow.score.values[0]\n        labels_y = label\n        ens_box = [boxes,boxes_y]\n        ens_score = [scores,scores_y]\n        ens_label = [label,labels_y]\n        \n        \n        \n        boxes, scores, label  = weighted_boxes_fusion(ens_box,\n                                                      ens_score,\n                                                      ens_label,\n                                                      weights=weight_detyolo,\n                                                      iou_thr=0.6,\n                                                      conf_type='avg',\n                                                      skip_box_thr=0.01)\n        \n        boxes[:,0], boxes[:,2] = boxes[:,0]*dim1[i].item(), boxes[:,2]*dim1[i].item()\n        boxes[:,1], boxes[:,3] = boxes[:,1]*dim0[i].item(), boxes[:,3]*dim0[i].item()  \n        boxes = boxes.astype(np.int32)\n        if fast_sub:\n            boxess.append(boxes)\n        result = {\n            'id': image_id,\n            'PredictionString': format_prediction_string(boxes, scores)\n        }\n        results.append(result)\npred_df = pd.DataFrame(results, columns=['id', 'PredictionString'])\npred_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:25.567951Z","iopub.execute_input":"2021-08-04T22:52:25.568307Z","iopub.status.idle":"2021-08-04T22:52:27.701238Z","shell.execute_reply.started":"2021-08-04T22:52:25.568272Z","shell.execute_reply":"2021-08-04T22:52:27.700374Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df['none'] = df_2class['none'] \npred_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:27.702787Z","iopub.execute_input":"2021-08-04T22:52:27.703159Z","iopub.status.idle":"2021-08-04T22:52:27.71505Z","shell.execute_reply.started":"2021-08-04T22:52:27.703119Z","shell.execute_reply":"2021-08-04T22:52:27.713821Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(sub_df.shape[0]):\n    if pred_df.loc[i,'none']< 0.95:\n        pred_df.loc[i,'PredictionString'] = pred_df.loc[i,'PredictionString'] + ' none ' + str(pred_df.loc[i,'none']) + ' 0 0 1 1'\n    else:\n        pred_df.loc[i,'PredictionString'] = 'none 1 0 0 1 1'\npred_df = pred_df[['id', 'PredictionString']]   \npred_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:27.716684Z","iopub.execute_input":"2021-08-04T22:52:27.717106Z","iopub.status.idle":"2021-08-04T22:52:27.735176Z","shell.execute_reply.started":"2021-08-04T22:52:27.717067Z","shell.execute_reply":"2021-08-04T22:52:27.734276Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fast_sub:\n    box_plot(tp1,boxess[0])\n    box_plot(tp2,boxess[1])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:27.736547Z","iopub.execute_input":"2021-08-04T22:52:27.737003Z","iopub.status.idle":"2021-08-04T22:52:29.489915Z","shell.execute_reply.started":"2021-08-04T22:52:27.736962Z","shell.execute_reply":"2021-08-04T22:52:29.488919Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_study = df_study.append(pred_df).reset_index(drop=True)\ndf_study = df_study[['id','PredictionString']]\ndf_study.to_csv('/kaggle/working/submission.csv',index = False)\ndf_study","metadata":{"execution":{"iopub.status.busy":"2021-08-04T22:52:29.502591Z","iopub.execute_input":"2021-08-04T22:52:29.50296Z","iopub.status.idle":"2021-08-04T22:52:29.521533Z","shell.execute_reply.started":"2021-08-04T22:52:29.502923Z","shell.execute_reply":"2021-08-04T22:52:29.520721Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}