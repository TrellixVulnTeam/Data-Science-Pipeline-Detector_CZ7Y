{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-09T14:40:03.681924Z","iopub.execute_input":"2021-08-09T14:40:03.682399Z","iopub.status.idle":"2021-08-09T14:41:11.857738Z","shell.execute_reply.started":"2021-08-09T14:40:03.682259Z","shell.execute_reply":"2021-08-09T14:41:11.856837Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nfrom PIL import Image\nimport numpy as np \nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport cv2\nimport sys\nsys.path.append(\"/kaggle/usr/lib/siim_infer_helper_func/\")\nfrom siim_infer_helper_func import *","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:41:11.861036Z","iopub.execute_input":"2021-08-09T14:41:11.861298Z","iopub.status.idle":"2021-08-09T14:41:18.472464Z","shell.execute_reply.started":"2021-08-09T14:41:11.861272Z","shell.execute_reply":"2021-08-09T14:41:18.471464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\nif df.shape[0] == 2477:\n    tp1 = \"/kaggle/input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm\"\n    tp2 = \"/kaggle/input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm\"\n    fast_sub = True\n    fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n                         ['65761e66de9f_image', 'none 1 0 0 1 1'], \n                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n                       columns=['id', 'PredictionString'])\nelse:\n    fast_sub = False\n#fast_sub = False","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:41:18.474704Z","iopub.execute_input":"2021-08-09T14:41:18.475092Z","iopub.status.idle":"2021-08-09T14:41:18.496769Z","shell.execute_reply.started":"2021-08-09T14:41:18.475052Z","shell.execute_reply":"2021-08-09T14:41:18.495902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import numpy as np\n#import pydicom\n#from pydicom.pixel_data_handlers.util import apply_voi_lut\n\nstudy_size = (768,768)\nimage_size = (640,640)\n\nsplit = 'test'\nsave_dir = f'/kaggle/tmp/{split}/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'/kaggle/tmp/{split}/study/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray(tp1)\n    im = resize(xray, size1=study_size[0],size2=study_size[1])  \n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    assert(tp1.split(\"/\")[-3] == '00086460a852')\n    xray = read_xray(tp2)\n    im = resize(xray, size1=study_size[0],size2=study_size[1])  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    assert(tp2.split(\"/\")[-3] == '000c9c05fd14')\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size1=study_size[0], size2=study_size[1])  \n            study = dirname.split('/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:41:18.498399Z","iopub.execute_input":"2021-08-09T14:41:18.498762Z","iopub.status.idle":"2021-08-09T14:41:19.830051Z","shell.execute_reply.started":"2021-08-09T14:41:18.498726Z","shell.execute_reply":"2021-08-09T14:41:19.829191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id = []\ndim0 = []\ndim1 = []\nsplits = []\nsave_dir = f'/kaggle/tmp/{split}/image/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray(tp1)\n    im = cv2.resize(xray,image_size,interpolation = cv2.INTER_AREA)\n    cv2.imwrite(os.path.join(save_dir,'65761e66de9f_image.png'),im)\n    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\n    xray = read_xray(tp2)\n    im = cv2.resize(xray,image_size,interpolation = cv2.INTER_AREA)\n    cv2.imwrite(os.path.join(save_dir, '51759b5579bc_image.png'),im)\n    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\nelse:\n    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = cv2.resize(xray,image_size,interpolation = cv2.INTER_AREA)\n            cv2.imwrite(os.path.join(save_dir, file.replace('.dcm', '_image.png')),im)\n            image_id.append(file.replace('.dcm', ''))\n            dim0.append(xray.shape[0])\n            dim1.append(xray.shape[1])\n            splits.append(split)\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:41:19.831573Z","iopub.execute_input":"2021-08-09T14:41:19.83194Z","iopub.status.idle":"2021-08-09T14:41:20.068436Z","shell.execute_reply.started":"2021-08-09T14:41:19.831893Z","shell.execute_reply":"2021-08-09T14:41:20.065487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# study level and 2-class","metadata":{}},{"cell_type":"markdown","source":"## make submit dataframe","metadata":{}},{"cell_type":"code","source":"if fast_sub:\n    df = fast_df.copy()\nelse:\n    df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\n\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:41:20.072607Z","iopub.execute_input":"2021-08-09T14:41:20.072955Z","iopub.status.idle":"2021-08-09T14:41:20.097815Z","shell.execute_reply.started":"2021-08-09T14:41:20.07292Z","shell.execute_reply":"2021-08-09T14:41:20.096679Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## study level","metadata":{}},{"cell_type":"code","source":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nsub_df = sub_df[:study_len]\nstudy_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'\n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\ndfstudy_tf = sub_df.copy()\ndfstudy_torch = sub_df.copy()\ndfstudy = sub_df.copy()\nstudy_label_cols = sub_df.columns[2:]\n\nif fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nsub_df = sub_df[study_len:].reset_index(drop=True)\nimage_paths = f'/kaggle/tmp/{split}/image/' + sub_df['id'] +'.png'\nsub_df['none'] = 0\n\ndf_2class_tf = sub_df.copy()\ndf_2class_touch = sub_df.copy()\ndf_2class = sub_df.copy()\n\n\nclass2_label_cols = sub_df.columns[2]","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:41:20.099135Z","iopub.execute_input":"2021-08-09T14:41:20.099514Z","iopub.status.idle":"2021-08-09T14:41:20.156851Z","shell.execute_reply.started":"2021-08-09T14:41:20.099478Z","shell.execute_reply":"2021-08-09T14:41:20.156105Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model and weight paths","metadata":{}},{"cell_type":"code","source":"study_tf_mpaths = [\n    \"/kaggle/input/bestmodeldataset/fold0_v2l_0.828.h5\",\n    \"/kaggle/input/bestmodeldataset/fold1_v2l_0.828.h5\",\n]\n\nbinaryclass_tf_mpaths = [\n    \"/kaggle/input/2classtfv2m/model0.h5\",\n    \"/kaggle/input/2classtfv2m/model1.h5\",\n    \"/kaggle/input/2classtfv2m/model3.h5\",\n    \"/kaggle/input/2classtfv2m/model4.h5\",\n]\n\n\nbinaryclass_tf_mpaths_b5 =[\n    \"/kaggle/input/2class-tf/model0.h5\",\n    \"/kaggle/input/2class-tf/model1.h5\",\n    \"/kaggle/input/2class-tf/model3.h5\",\n]\n\nmaskwpath = [\"../input/covid19-effneteffdet/auxlossv2m_weight/pretrained_model_0_0.834.bin\",\n             \"../input/covid19-effneteffdet/auxlossv2m_weight/pretrained_model_2_0.854.bin\",\n             \"../input/covid19-effneteffdet/auxlossv2m_weight/pretrained_model_3_0.832.bin\",\n             \"../input/covid19-effneteffdet/auxlossv2m_weight/pretrained_model_4_0.849.bin\",\n            ]\n\nbcemaskpath = [\n      \"../input/covid19-effneteffdet/auxlossv2m_bcemodel/fold0_0.837.bin\",\n      \"../input/covid19-effneteffdet/auxlossv2m_bcemodel/fold2_0.857.bin\",\n      \"../input/covid19-effneteffdet/auxlossv2m_bcemodel/fold3_0.851.bin\",\n      \"../input/covid19-effneteffdet/auxlossv2m_bcemodel/fold4_0.855.bin\",\n             ]\n\n\nnonewpath = [\"../input/covid19-effneteffdet/2class_v2m/fold0_0.924.bin\",\n             \"../input/covid19-effneteffdet/2class_v2m/fold3_0.921.bin\",\n             \"../input/covid19-effneteffdet/2class_v2m/fold4_0.923.bin\",\n             \"../input/covid19-effneteffdet/cutmix_fold0_0.934.bin\",\n             \"../input/covid19-effneteffdet/cutmix_fold1_0.931.bin\",\n             \"../input/covid19-effneteffdet/cutmix_fold4_0.932.bin\",\n            ]\n","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:41:20.157919Z","iopub.execute_input":"2021-08-09T14:41:20.158212Z","iopub.status.idle":"2021-08-09T14:41:20.166071Z","shell.execute_reply.started":"2021-08-09T14:41:20.158187Z","shell.execute_reply":"2021-08-09T14:41:20.165178Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tensorflow","metadata":{}},{"cell_type":"code","source":"#prepare tensorflow module\n\n!pip install /kaggle/input/kerasapplications -q\n!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps\n\nimport os\n\nimport efficientnet.tfkeras as efn\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:41:20.169746Z","iopub.execute_input":"2021-08-09T14:41:20.170001Z","iopub.status.idle":"2021-08-09T14:42:12.499602Z","shell.execute_reply.started":"2021-08-09T14:41:20.169978Z","shell.execute_reply":"2021-08-09T14:42:12.498656Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 16\ntest_decoder0 = build_decoder(with_labels=False, target_size=(690, 690), ext='png')\ntest_decoder1 = build_decoder(with_labels=False, target_size=(710, 710), ext='png')\ndtest1 = build_dataset(\n    study_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder0\n)\n\ndtest2 = build_dataset(\n    study_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder1\n)\n\n\n\nwith strategy.scope():\n    \n    models = []\n    for mpath in study_tf_mpaths:\n        model = tf.keras.models.load_model(mpath,custom_objects={'KerasLayer': KerasLayerWrapperv2l})\n        models.append(model)\n        del model\n\ntmp1 = sum([model.predict(dtest1, verbose=1) for model in models]) / len(models)\ntmp2 = sum([model.predict(dtest2, verbose=1) for model in models]) / len(models)\n\ndfstudy_tf[study_label_cols] = (tmp1 + tmp2)/2","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:42:12.50165Z","iopub.execute_input":"2021-08-09T14:42:12.501915Z","iopub.status.idle":"2021-08-09T14:44:03.615133Z","shell.execute_reply.started":"2021-08-09T14:42:12.501887Z","shell.execute_reply":"2021-08-09T14:44:03.614281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_decoder = build_decoder(with_labels=False, target_size=(660,660), ext='png')\ndtest = build_dataset(\n    image_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder\n)\n\nwith strategy.scope():\n    \n    models = []\n    models2 = []\n    for mpath in binaryclass_tf_mpaths:\n        \n        model = tf.keras.models.load_model(mpath,custom_objects={'KerasLayer': KerasLayerWrapperv2m})\n        models.append(model)\n        del model\n    \n    for mpath in binaryclass_tf_mpaths_b5:\n        model = tf.keras.models.load_model(mpath)\n        models2.append(model)\n        del model\n        \n                \ntmp1 = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)\n\ndel models\n\ntest_decoder = build_decoder(with_labels=False, target_size=(512,512), ext='png')\ndtest = build_dataset(\n    image_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder\n)\n\ntmp2 = sum([model.predict(dtest, verbose=1) for model in models2]) / len(models2)\ndel models2\n\ndf_2class_tf[class2_label_cols] = (tmp1+tmp2)/2\ndf_2class_tf = df_2class_tf.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:44:41.627932Z","iopub.execute_input":"2021-08-09T14:44:41.628252Z","iopub.status.idle":"2021-08-09T14:48:03.34003Z","shell.execute_reply.started":"2021-08-09T14:44:41.628221Z","shell.execute_reply":"2021-08-09T14:48:03.339172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numba import cuda \ndevice = cuda.get_current_device()\ndevice.reset()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:48:07.194077Z","iopub.execute_input":"2021-08-09T14:48:07.194432Z","iopub.status.idle":"2021-08-09T14:48:08.653807Z","shell.execute_reply.started":"2021-08-09T14:48:07.194399Z","shell.execute_reply":"2021-08-09T14:48:08.652858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport torch\nimport torch.nn as nn\n\nimport sys\nsys.path.insert(0, \"../input/timm-pytorch-image-models/pytorch-image-models-master/\")\nimport timm\n\ndevice = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:48:10.922097Z","iopub.execute_input":"2021-08-09T14:48:10.922457Z","iopub.status.idle":"2021-08-09T14:48:11.512468Z","shell.execute_reply.started":"2021-08-09T14:48:10.922426Z","shell.execute_reply":"2021-08-09T14:48:11.511614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch studylevel","metadata":{}},{"cell_type":"code","source":"def get_valid_transforms(size):\n    return A.Compose(\n        [\n            A.Resize(height=size, width=size, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\ndef augtransform(size):\n    return A.Compose(\n        [\n            A.RandomSizedCrop(min_max_height=[740,768],\n                         height=740,\n                         width=740,\n                         p=0.5),\n            A.CLAHE(clip_limit=(1,1.5),p=0.5),\n            A.RandomBrightnessContrast(\n                    brightness_limit=0.05, \n                    contrast_limit=0.05,\n                    p=0.5),\n            A.HorizontalFlip(p=0.25),\n            A.VerticalFlip(p=0.25),\n            A.Rotate(limit=5,p=0.25),\n            A.Resize(height=size, width=size, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\nDATA_ROOT_PATH = '/kaggle/tmp/test/study'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, path):\n        super().__init__()\n        self.df = df\n        self.path = path\n\n    def __getitem__(self, index: int):\n        path = self.path[index]\n        image_id = self.df.id[index]\n        image = cv2.imread(path,cv2.IMREAD_COLOR)        \n        \n        image0 = get_valid_transforms(512)(image=image)[\"image\"]\n        image1 = augtransform(506)(image=image)[\"image\"]\n        image2 = augtransform(520)(image=image)[\"image\"]\n        image3 = augtransform(510)(image=image)[\"image\"]\n\n        image0 = image0/255.0\n        image1 = image1/255.0\n        image2 = image2/255.0\n        image3 = image3/255.0\n        \n        return image0,image1,image2,image3,image_id\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:48:11.761404Z","iopub.execute_input":"2021-08-09T14:48:11.761719Z","iopub.status.idle":"2021-08-09T14:48:11.775294Z","shell.execute_reply.started":"2021-08-09T14:48:11.76169Z","shell.execute_reply":"2021-08-09T14:48:11.773547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetRetriever(\n    df= dfstudy_torch,\n    path = study_paths,\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True,\n    drop_last=False,\n)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:48:11.912402Z","iopub.execute_input":"2021-08-09T14:48:11.91265Z","iopub.status.idle":"2021-08-09T14:48:11.91843Z","shell.execute_reply.started":"2021-08-09T14:48:11.912626Z","shell.execute_reply":"2021-08-09T14:48:11.91628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mmodels = []\nbcemodels = []\n\nfor wpath in maskwpath:\n    print(wpath)\n    model = Net().to(device)\n    model.load_state_dict(torch.load(wpath))\n    model.eval()\n    mmodels.append(model)\n    del model\n\nfor bcepath in bcemaskpath:\n    bcemodel = Net().to(device)\n    bcemodel.load_state_dict(torch.load(bcepath))\n    bcemodel.eval()\n    bcemodels.append(bcemodel)\n    del bcemodel","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:48:12.074819Z","iopub.execute_input":"2021-08-09T14:48:12.075165Z","iopub.status.idle":"2021-08-09T14:48:47.483893Z","shell.execute_reply.started":"2021-08-09T14:48:12.075131Z","shell.execute_reply":"2021-08-09T14:48:47.482898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids = []\noutputs = np.empty((0,4))\n\nwith torch.no_grad():\n    for image0,image1,image2,image3, image_id, in data_loader:\n        image0 = image0.cuda().float()\n        image1 = image1.cuda().float()\n        image2 = image2.cuda().float()\n        image3 = image3.cuda().float()\n        for i,mmodel in enumerate(mmodels):\n            if i==0: \n                mout = (\n                        bcemodels[0](image0)[0].sigmoid() +\n                        bcemodels[1](image1)[0].sigmoid() +\n                        bcemodels[2](image2)[0].sigmoid() +\n                        bcemodels[3](image3)[0].sigmoid())/4\n            else:\n                mout +=(mmodel(image0)[0].softmax(dim=1) +\n                        mmodel(image1)[0].softmax(dim=1) +\n                        mmodel(image2)[0].softmax(dim=1) +\n                        mmodel(image3)[0].softmax(dim=1))/4\n    \n        mout = mout/len(mmodels)\n        \n        outputs = np.append(outputs,mout.cpu().detach().numpy(),axis=0)\n        image_ids = np.append(image_ids,image_id)\nprint(outputs.shape)\nprint(image_ids.shape)\ndfstudy_torch.id = image_ids\ndfstudy_torch[study_label_cols] = outputs\n\ndel bcemodels\ndel mmodels","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:49:25.064981Z","iopub.execute_input":"2021-08-09T14:49:25.065501Z","iopub.status.idle":"2021-08-09T14:49:26.933827Z","shell.execute_reply.started":"2021-08-09T14:49:25.065456Z","shell.execute_reply":"2021-08-09T14:49:26.932822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfstudy[study_label_cols] = (dfstudy_tf[study_label_cols] + dfstudy_torch[study_label_cols])/2\ndisplay(dfstudy_torch,dfstudy_tf)\ndisplay(dfstudy)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:49:31.748392Z","iopub.execute_input":"2021-08-09T14:49:31.748731Z","iopub.status.idle":"2021-08-09T14:49:31.791607Z","shell.execute_reply.started":"2021-08-09T14:49:31.748701Z","shell.execute_reply":"2021-08-09T14:49:31.790829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(study_len):\n    negative = dfstudy.loc[i,'negative']\n    typical = dfstudy.loc[i,'typical']\n    indeterminate = dfstudy.loc[i,'indeterminate']\n    atypical = dfstudy.loc[i,'atypical']\n    dfstudy.loc[i, 'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\ndf_study = dfstudy[[\"id\",\"PredictionString\"]]\ndisplay(df_study)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:49:46.091707Z","iopub.execute_input":"2021-08-09T14:49:46.092039Z","iopub.status.idle":"2021-08-09T14:49:46.104754Z","shell.execute_reply.started":"2021-08-09T14:49:46.092009Z","shell.execute_reply":"2021-08-09T14:49:46.103748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch 2-class","metadata":{}},{"cell_type":"code","source":"def get_valid_transforms(size):\n    return A.Compose(\n        [\n            A.Resize(height=size, width=size, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\ndef augtransform(size):\n    return A.Compose(\n        [\n            A.RandomSizedCrop(min_max_height=[610,640],\n                         height=600,\n                         width=600,\n                         p=0.5),\n            A.CLAHE(clip_limit=(1,1.5),p=0.5),\n            A.RandomBrightnessContrast(\n                    brightness_limit=0.05, \n                    contrast_limit=0.05,\n                    p=0.5),\n            A.HorizontalFlip(p=0.25),\n            A.VerticalFlip(p=0.25),\n            A.Rotate(limit=5,p=0.25),\n            A.Resize(height=size, width=size, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, path):\n        super().__init__()\n        self.df = df\n        self.path = path\n\n    def __getitem__(self, index: int):\n        path = self.path[index]\n        image_id = self.df.id[index]\n        image = cv2.imread(path,cv2.IMREAD_COLOR)        \n        \n        image0 = get_valid_transforms(512)(image=image)[\"image\"]\n        image1 = augtransform(506)(image=image)[\"image\"]\n        image2 = augtransform(520)(image=image)[\"image\"]\n        image3 = augtransform(510)(image=image)[\"image\"]\n\n        image0 = image0/255.0\n        image1 = image1/255.0\n        image2 = image2/255.0\n        image3 = image3/255.0\n        \n        return image0,image1,image2,image3,image_id\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:49:50.088454Z","iopub.execute_input":"2021-08-09T14:49:50.088841Z","iopub.status.idle":"2021-08-09T14:49:50.100524Z","shell.execute_reply.started":"2021-08-09T14:49:50.088798Z","shell.execute_reply":"2021-08-09T14:49:50.09952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from timm.models.efficientnet import *\nclass Net2class(nn.Module):\n    def __init__(self):\n        super(Net2class, self).__init__()\n\n        e = tf_efficientnetv2_m_in21k(pretrained=False, drop_rate=0.3, drop_path_rate=0.2,in_chans=3)\n        self.b0 = nn.Sequential(\n            e.conv_stem,\n            e.bn1,\n            e.act1,\n        )\n        self.b1 = e.blocks[0]\n        self.b2 = e.blocks[1]\n        self.b3 = e.blocks[2]\n        self.b4 = e.blocks[3]\n        self.b5 = e.blocks[4]\n        self.b6 = e.blocks[5]\n        self.b7 = e.blocks[6]\n        self.gp = e.global_pool\n        self.b8 = nn.Sequential(\n            e.conv_head, #384, 1536\n            e.bn2,\n            e.act2,\n        )\n\n        self.logit = nn.Linear(1280,1)\n        self.mask = nn.Sequential(\n            nn.Conv2d(176, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n        )\n\n\n    # @torch.cuda.amp.autocast()\n    def forward(self, image):\n        batch_size = len(image)\n        x = image\n\n        x = self.b0(x) \n        x = self.b1(x) \n        x = self.b2(x) \n        x = self.b3(x) \n        x = self.b4(x) \n        x = self.b5(x) \n        #------------\n        mask = self.mask(x)\n        #-------------\n        x = self.b6(x) \n        x = self.b7(x) \n        x = self.b8(x) \n        x = self.gp(x)\n        x = F.dropout(x, 0.1, training=True)\n        logit = self.logit(x)\n        return logit, mask","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:49:52.610481Z","iopub.execute_input":"2021-08-09T14:49:52.610818Z","iopub.status.idle":"2021-08-09T14:49:52.625425Z","shell.execute_reply.started":"2021-08-09T14:49:52.610788Z","shell.execute_reply":"2021-08-09T14:49:52.62317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nonemodels = []\nfor wpath in nonewpath:\n    print(wpath)\n    model = Net2class().to(device)\n    model.load_state_dict(torch.load(wpath))\n    model.eval()\n    nonemodels.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:49:58.437218Z","iopub.execute_input":"2021-08-09T14:49:58.43761Z","iopub.status.idle":"2021-08-09T14:50:22.962024Z","shell.execute_reply.started":"2021-08-09T14:49:58.437577Z","shell.execute_reply":"2021-08-09T14:50:22.960949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetRetriever(\n    df=df_2class_touch,\n    path = image_paths,\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=2,\n    drop_last=False,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:50:25.816154Z","iopub.execute_input":"2021-08-09T14:50:25.816519Z","iopub.status.idle":"2021-08-09T14:50:25.823379Z","shell.execute_reply.started":"2021-08-09T14:50:25.816485Z","shell.execute_reply":"2021-08-09T14:50:25.822421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids = []\nnoneout = []\n\nwith torch.no_grad():\n    for image0,image1,image2,image3, image_id, in data_loader:\n        image0 = image0.cuda().float()\n        image1 = image1.cuda().float()\n        image2 = image2.cuda().float()\n        image3 = image3.cuda().float()\n        for i,nmodel in enumerate(nonemodels):\n            if i==0: \n                nout = (nmodel(image0)[0].sigmoid() +\n                        nmodel(image1)[0].sigmoid() +\n                        nmodel(image2)[0].sigmoid() +\n                        nmodel(image3)[0].sigmoid())/4\n            else:\n                nout += (nmodel(image0)[0].sigmoid() +\n                        nmodel(image1)[0].sigmoid() +\n                        nmodel(image2)[0].sigmoid() +\n                        nmodel(image3)[0].sigmoid())/4\n\n\n        nout = nout/len(nonemodels)\n        noneout = np.append(noneout,nout.cpu().detach().numpy())\n        image_ids = np.append(image_ids,image_id)\nprint(noneout.shape)\nprint(image_ids.shape)\ndf_2class_touch[class2_label_cols] = noneout\ndf_2class_touch = df_2class_touch.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:50:26.205151Z","iopub.execute_input":"2021-08-09T14:50:26.20551Z","iopub.status.idle":"2021-08-09T14:50:28.489346Z","shell.execute_reply.started":"2021-08-09T14:50:26.205476Z","shell.execute_reply":"2021-08-09T14:50:28.488422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2class[class2_label_cols] = (df_2class_tf[class2_label_cols] + df_2class_touch[class2_label_cols])/2\ndisplay(df_2class_tf,df_2class_touch)\ndf_2class","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:50:28.703234Z","iopub.execute_input":"2021-08-09T14:50:28.703575Z","iopub.status.idle":"2021-08-09T14:50:28.727302Z","shell.execute_reply.started":"2021-08-09T14:50:28.703546Z","shell.execute_reply":"2021-08-09T14:50:28.726551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\ndel nonemodels","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:50:35.92673Z","iopub.execute_input":"2021-08-09T14:50:35.927051Z","iopub.status.idle":"2021-08-09T14:50:35.952563Z","shell.execute_reply.started":"2021-08-09T14:50:35.927022Z","shell.execute_reply":"2021-08-09T14:50:35.951695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# image classification end \n\n# image level start","metadata":{}},{"cell_type":"markdown","source":"## image level path list","metadata":{}},{"cell_type":"code","source":"weights_dir = ['/kaggle/input/yolo-bestresult/best_fold0.pt',\n               '/kaggle/input/yolo-bestresult/best_fold1.pt',\n               '/kaggle/input/yolo-bestresult/best_fold2.pt',\n               '/kaggle/input/yolo-bestresult/best_fold3.pt',\n               '/kaggle/input/yolo-bestresult/best_fold4.pt',]\n\npaths = [\"/kaggle/input/covid19-effneteffdet/d3_image640/fold1-d3_0.630.bin\",\n         \"/kaggle/input/covid19-effneteffdet/d3_image640/fold4-d3_0.660.bin\",\n         \"/kaggle/input/covid19-effneteffdet/fold0-cspresdext50pan_0.650.bin\",\n         \"/kaggle/input/covid19-effneteffdet/fold3-cspresdext50pan_0.634.bin\",\n         \"/kaggle/input/covid19-effneteffdet/fold4_cspresdext50pan-0.672.bin\",\n        ]\n\nmodel_names = [\n    \"tf_efficientdet_d3\",\n    \"tf_efficientdet_d3\",\n    \"cspresdext50pan\",\n    \"cspresdext50pan\",\n    \"cspresdext50pan\",\n]\n\ndet_weights = [1,1,1,1,1,1]\nweight_detyolo = [1,2]\n\nmeta = meta[meta['split'] == 'test']\nif fast_sub:\n    test_df = fast_df.copy()\nelse:\n    test_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\ntest_df = df[study_len:].reset_index(drop=True) \nmeta['image_id'] = meta['image_id'] + '_image'\nmeta.columns = ['id', 'dim0', 'dim1', 'split']\ntest_df = pd.merge(test_df, meta, on = 'id', how = 'left')\n\ntest_df","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.137929Z","iopub.status.idle":"2021-08-09T14:44:04.138544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# yolo","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport torch\n\n\ndim = 640 #1024, 256, 'original'\ntest_dir = f'/kaggle/tmp/{split}/image'\n\n\nshutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\nos.chdir('/kaggle/working/yolov5') # install dependencies\n\n!python detect.py \\\n--weights {weights_dir[0]} {weights_dir[1]} {weights_dir[2]} {weights_dir[3]} {weights_dir[4]} \\\n--img 640\\\n--conf 0.001\\\n--iou 0.5\\\n--source $test_dir\\\n--name infer_fold \\\n--save-txt --save-conf --exist-ok --augment\n\nlabelpaths = glob(\"runs/detect/infer_fold/labels/*\")\n\npredbox_ens = []\nimage_ids = []\nscore = []\nbox = []\nfor file_path in tqdm(labelpaths):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    data = np.concatenate([data[:, :2], yolo2a(data[:, 2:])],axis=1)\n    \n    if fast_sub:\n        predbox_ens.append(norm2hw(h, w, data[:,2:]))\n    \n    \n    image_ids.append(image_id)\n    score.append(data[:,1])\n    box.append(data[:,2:])\n\npred_df_yolo = pd.DataFrame({'id':image_ids,'score':score,'label':1,'box':box})\n\nif fast_sub:\n    display(pred_df_yolo)\n    box_plot(tp1,predbox_ens[0])\n    box_plot(tp2,predbox_ens[1])","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.139681Z","iopub.status.idle":"2021-08-09T14:44:04.140295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# effdet","metadata":{}},{"cell_type":"code","source":"!pip install --no-deps '/kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl'\n!pip install \"/kaggle/input/effdet-latestvinbigdata-wbf-fused/omegaconf-2.0.6-py3-none-any.whl\"\nimport sys\nsys.path.insert(0, \"/kaggle/input/effdet-latestvinbigdata-wbf-fused/efficientdet-pytorch/\")\nsys.path.insert(0, \"/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master/\")\nsys.path.insert(0, \"/kaggle/input/weightedboxesfusion\")","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.141547Z","iopub.status.idle":"2021-08-09T14:44:04.142176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport os\n\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom effdet import get_efficientdet_config, EfficientDet, DetBenchPredict\nfrom effdet.efficientdet import HeadNet\nfrom glob import glob\nimport gc\nfrom ensemble_boxes import *\n\ndef get_valid_transforms():\n    return A.Compose(\n        [\n            #A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\nDATA_ROOT_PATH = '/kaggle/tmp/test/image'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, transforms=None):\n        super().__init__()\n        self.df = df\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_id = self.df.id.values[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}.png',cv2.IMREAD_COLOR)\n        dim0 = self.df.dim0.values[index]\n        dim1 = self.df.dim1.values[index]\n        image = image.astype(np.float32)\n        image /= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        \n        return sample['image'], image_id, dim0, dim1\n\n    def __len__(self) -> int:\n        return self.df.shape[0]\n    \ndataset = DatasetRetriever(\n    df=test_df,\n    transforms=get_valid_transforms()\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n)\n\ndef load_net(checkpoint_path,model_name):\n    config = get_efficientdet_config(model_name)\n    config.image_size = [640,640]\n    config.norm_kwargs=dict(eps=.001, momentum=.01)\n    net = EfficientDet(config, pretrained_backbone=False)\n    net.reset_head(num_classes=1)\n    net.class_net = HeadNet(config, num_outputs=config.num_classes)\n\n    checkpoint = torch.load(checkpoint_path)\n    net.load_state_dict(checkpoint['model_state_dict'])\n    del checkpoint\n    gc.collect()\n    evalnet = DetBenchPredict(net)\n    evalnet.eval();\n    return evalnet.cuda()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.143488Z","iopub.status.idle":"2021-08-09T14:44:04.144121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nets = []\nfor path, mname in zip(paths,model_names):\n    print(path)\n    model = load_net(path,mname)\n    nets.append(model)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.145418Z","iopub.status.idle":"2021-08-09T14:44:04.14602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_predictions(images, nets, score_threshold=0.001):\n    images = images.cuda().float()\n    predictions = []\n    dets = []\n    with torch.no_grad():\n        for model in nets:\n            dets.append(model(images))\n        for i in range(images.shape[0]):\n            boxes = [det[i].detach().cpu().numpy()[:,[1,0,3,2]]/640.0 for det in dets]\n            scores = [det[i].detach().cpu().numpy()[:,4] for det in dets]\n            label = [det[i].detach().cpu().numpy()[:,5] for det in dets]\n            \n            boxes, scores, label  = weighted_boxes_fusion(boxes,\n                                                          scores,\n                                                          label,\n                                                          weights=det_weights,\n                                                          iou_thr=0.6,\n                                                          conf_type='avg',\n                                                          skip_box_thr=0.001)\n            \n            indexes = np.where(scores > score_threshold)[0]\n            boxes = boxes[indexes]\n            scores = scores[indexes]\n            label = label[indexes]\n            predictions.append({\n                'boxes': boxes,\n                'scores': scores,\n                'label': label\n            })\n    return predictions","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.147156Z","iopub.status.idle":"2021-08-09T14:44:04.147796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nboxess = []\nfor j,(images, image_ids, dim0, dim1) in enumerate(data_loader):\n    #print(images.shape)\n    predictions = make_predictions(images, nets)\n    for i,prediction in enumerate(predictions):\n        boxes = prediction['boxes']\n        scores = prediction['scores']\n        label = prediction['label']\n        image_id = image_ids[i]\n        \n        index = pred_df_yolo[pred_df_yolo.id==image_id].index\n        yolorow = pred_df_yolo.iloc[index]\n        boxes_y = yolorow.box.values[0]\n        scores_y = yolorow.score.values[0]\n        labels_y = label\n        ens_box = [boxes,boxes_y]\n        ens_score = [scores,scores_y]\n        ens_label = [label,labels_y]\n        \n        \n        \n        boxes, scores, label  = weighted_boxes_fusion(ens_box,\n                                                      ens_score,\n                                                      ens_label,\n                                                      weights=weight_detyolo,\n                                                      iou_thr=0.6,\n                                                      conf_type='avg',\n                                                      skip_box_thr=0.001)\n        \n        boxes[:,0], boxes[:,2] = boxes[:,0]*dim1[i].item(), boxes[:,2]*dim1[i].item()\n        boxes[:,1], boxes[:,3] = boxes[:,1]*dim0[i].item(), boxes[:,3]*dim0[i].item()  \n        boxes = boxes.astype(np.int32)\n        if fast_sub:\n            boxess.append(boxes)\n        result = {\n            'id': image_id,\n            'PredictionString': format_prediction_string(boxes, scores)\n        }\n        results.append(result)\npred_df = pd.DataFrame(results, columns=['id', 'PredictionString'])\npred_df","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.148944Z","iopub.status.idle":"2021-08-09T14:44:04.149636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df['none'] = df_2class['none'] \npred_df","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.1507Z","iopub.status.idle":"2021-08-09T14:44:04.151333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(sub_df.shape[0]):\n    if pred_df.loc[i,'PredictionString'] != 'none 1 0 0 1 1':\n        pred_df.loc[i,'PredictionString'] = pred_df.loc[i,'PredictionString'] + ' none ' + str(pred_df.loc[i,'none']) + ' 0 0 1 1'\npred_df = pred_df[['id', 'PredictionString']]   \npred_df","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.152615Z","iopub.status.idle":"2021-08-09T14:44:04.153228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fast_sub:\n    box_plot(tp1,boxess[0])\n    box_plot(tp2,boxess[1])","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.154437Z","iopub.status.idle":"2021-08-09T14:44:04.155029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.156188Z","iopub.status.idle":"2021-08-09T14:44:04.156809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_study = df[:study_len]\ndf_study = df_study.append(pred_df).reset_index(drop=True)\ndf_study = df_study[['id','PredictionString']]\ndf_study","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.158088Z","iopub.status.idle":"2021-08-09T14:44:04.158661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_study.to_csv('/kaggle/working/submission.csv',index = False) \ndf_study","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-09T14:44:04.159717Z","iopub.status.idle":"2021-08-09T14:44:04.160349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]}]}