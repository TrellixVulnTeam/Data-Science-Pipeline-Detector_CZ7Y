{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\nfrom glob import glob\nimport shutil\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport json\nimport math\nfrom albumentations import Compose\nimport albumentations as A\nfrom PIL import Image\nimport os\nimport warnings\nfrom multiprocessing import Pool\n\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-11T09:06:28.444004Z","iopub.execute_input":"2021-07-11T09:06:28.444443Z","iopub.status.idle":"2021-07-11T09:06:34.351919Z","shell.execute_reply.started":"2021-07-11T09:06:28.444365Z","shell.execute_reply":"2021-07-11T09:06:34.350956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG = {\n    \"model\": 'tf_efficientnet_b4_ns',\n    #\"img_size\": 512,\n    # \"img_size\": 256,\n    \"img_size\": 224,\n    \"epochs\": 5,\n    # 'lr': 1e-5,\n    'lr': .001,\n    \"n_class\": 4,\n    \"batch_size\": 8,\n    \"num_workers\": 4,\n    'device': 'cuda:0'\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-11T09:06:40.761794Z","iopub.execute_input":"2021-07-11T09:06:40.762241Z","iopub.status.idle":"2021-07-11T09:06:40.76839Z","shell.execute_reply.started":"2021-07-11T09:06:40.762168Z","shell.execute_reply":"2021-07-11T09:06:40.766641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\n\nimg_add = '../input/siim-covid19-resized-to-512px-png/train/001398f4ff4f.png'\nimg = cv2.imread(img_add, cv2.IMREAD_COLOR)\n\n# cv2.imshow('image',img)\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nim = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\nrow_sums = np.sum(im, axis=1)\ncol_sums = np.sum(im, axis=0)\nrows = np.where(row_sums > img.shape[1] * 0.03)[0]\ncols = np.where(col_sums > img.shape[0] * 0.03)[0]\nmin_row, min_col = np.min(rows), np.min(cols)\nmax_row, max_col = np.max(rows), np.max(cols)\nprint(max_row)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T09:48:40.939587Z","iopub.execute_input":"2021-07-11T09:48:40.939955Z","iopub.status.idle":"2021-07-11T09:48:40.965226Z","shell.execute_reply.started":"2021-07-11T09:48:40.939926Z","shell.execute_reply":"2021-07-11T09:48:40.964052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trim1(im):\n    \n    percentage = 0.03\n\n    img = np.array(im)\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    im = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n    row_sums = np.sum(im, axis=1)\n    col_sums = np.sum(im, axis=0)\n    rows = np.where(row_sums > img.shape[1] * percentage)[0]\n    cols = np.where(col_sums > img.shape[0] * percentage)[0]\n    min_row, min_col = np.min(rows), np.min(cols)\n    max_row, max_col = np.max(rows), np.max(cols)\n    im_crop = img[min_row : max_row + 1, min_col : max_col + 1]\n    return Image.fromarray(im_crop)\n\ndef resize_maintain_aspect(image, desired_size):\n    \n    \n    old_size = image.size  # old_size[0] is in (width, height) format\n    ratio = float(desired_size) / max(old_size)\n    new_size = tuple([int(x * ratio) for x in old_size])\n    im = image.resize(new_size, Image.ANTIALIAS)\n    new_im = Image.new(\"RGB\", (desired_size, desired_size))\n    new_im.paste(im, ((desired_size - new_size[0]) // 2, (desired_size - new_size[1]) // 2))\n    return new_im\n\ndef save_single(args):\n    img_file, input_path_folder, output_path_folder, output_size = args\n    image_original = Image.open(os.path.join(input_path_folder, img_file))\n    image = trim1(image_original)\n    image = resize_maintain_aspect(image, desired_size=output_size[0])\n    image.save(os.path.join(output_path_folder + img_file))\n    \n\ndef fast_image_resize(input_path_folder, output_path_folder, output_size=None):\n\n    if not output_size:\n        warnings.warn(\"Need to specify output_size! For example: output_size=100\")\n        exit()\n\n    if not os.path.exists(output_path_folder):\n        os.makedirs(output_path_folder)\n\n    jobs = [\n        (file, input_path_folder, output_path_folder, output_size)\n        for file in os.listdir(input_path_folder)\n    ]\n\n    with Pool() as p:\n        list(tqdm(p.imap_unordered(save_single, jobs), total=len(jobs)))\n\n\n# if __name__ == \"__main__\":\n# fast_image_resize(\"../train/images/\", \"../train/images_resized_150/\", output_size=(150, 150))\n# fast_image_resize(\"../test/images/\", \"../test/images_resized_150/\", output_size=(150, 150))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T09:09:11.447022Z","iopub.execute_input":"2021-07-11T09:09:11.447389Z","iopub.status.idle":"2021-07-11T09:09:11.462662Z","shell.execute_reply.started":"2021-07-11T09:09:11.447357Z","shell.execute_reply":"2021-07-11T09:09:11.461514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = \"../input/siim-covid19-detection/train\"\ntrain_image_level = pd.read_csv(\"../input/siim-covid19-detection/train_image_level.csv\")\ntrain_study_level = pd.read_csv(\"../input/siim-covid19-detection/train_study_level.csv\")\ndef trim(x):\n   return x[:-6]\n\ntrain_study_level['id'] = train_study_level['id'].apply(trim)\ntrain_study_level['StudyInstanceUID'] = train_study_level['id']\n\ntrain_data = train_image_level.merge(train_study_level, on='StudyInstanceUID', how='inner')\ndel train_data['id_y']\ntrain_data['id_x'] = train_data['id_x'].apply(trim)\ntrain_data = train_data.rename(columns={'id_x':\"image_id\"})\nmeta = pd.read_csv(\"../input/siim-covid19-resized-to-512px-png/meta.csv\")\ntrain_data = train_data.merge(meta, on='image_id', how='inner')\n\n# train_data = pd.read_csv(\"../input/trained-data-an-scaled-v3csv/train_data_an_scaled_v3.csv\")\n\n\n\n#train_data\n# boxes_split=train_data.boxes.str.split(expand=True)\n# train_data = train_data.join(boxes_split)\n# train_data.to_csv('train_data_an.csv')\n\ntrain_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T02:47:09.673771Z","iopub.execute_input":"2021-07-11T02:47:09.674175Z","iopub.status.idle":"2021-07-11T02:47:09.78709Z","shell.execute_reply.started":"2021-07-11T02:47:09.67414Z","shell.execute_reply":"2021-07-11T02:47:09.786321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_data['split']\ndel train_data['boxes']\ndel train_data['label']\n\n# train_data = train_data.drop(columns = [\"split\", \"boxes\", \"label\"])\n\ntrain_data['image_path'] = '../input/siim-covid19-resized-to-512px-png/train/'+train_data['image_id']+'.png'\ntrain_data[\"class_id\"] = 0*train_data[\"Negative for Pneumonia\"] + 1*train_data[\"Typical Appearance\"] + 2*train_data[\"Indeterminate Appearance\"] + 3*train_data[\"Atypical Appearance\"]\ntrain_data = train_data.drop(columns=[\"Negative for Pneumonia\", \"Typical Appearance\", \"Indeterminate Appearance\", \"Atypical Appearance\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T02:47:09.788651Z","iopub.execute_input":"2021-07-11T02:47:09.788976Z","iopub.status.idle":"2021-07-11T02:47:09.814462Z","shell.execute_reply.started":"2021-07-11T02:47:09.788941Z","shell.execute_reply":"2021-07-11T02:47:09.813767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = [\n    \"negative\",\n    \"typical\",\n    \"indeterminate\",\n    \"atypical\"\n]\n\n# train, test = train_test_split(train_data, test_size=0.5, random_state=42)\ntrain, val = train_test_split(train_data, test_size=0.3, random_state=42)\ntrain = train.reset_index()\nval = val.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T02:47:09.817295Z","iopub.execute_input":"2021-07-11T02:47:09.817551Z","iopub.status.idle":"2021-07-11T02:47:09.827521Z","shell.execute_reply.started":"2021-07-11T02:47:09.817523Z","shell.execute_reply":"2021-07-11T02:47:09.826616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T02:47:09.830346Z","iopub.execute_input":"2021-07-11T02:47:09.830596Z","iopub.status.idle":"2021-07-11T02:47:09.840328Z","shell.execute_reply.started":"2021-07-11T02:47:09.830572Z","shell.execute_reply":"2021-07-11T02:47:09.839588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, df, output_label=True, transform=None):\n        super().__init__()\n        self.df = df\n        self.image_paths = df['image_path']\n        self.output_label = output_label\n        if output_label:\n            self.labels = df['class_id']\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        if self.output_label:\n            label = self.labels[index]\n        img_path = self.df.loc[index]['image_path']\n        image = mpimg.imread(img_path)\n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n        image = np.array([image, image, image])\n        if self.output_label:\n            return image, label\n        else:\n            return image\n        \ntrain_transforms = Compose([\n    A.Transpose(p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(p=0.5),\n    # A.Resize(width = 256, height = 256),\n    # A.Normalize( ),\n    #        mean=[0.3199, 0.2240, 0.1609],\n    #        std=[0.3020, 0.2183, 0.1741],\n    #        max_pixel_value=255.0,\n    #    ),\n    A.Resize(width = 224, height = 224),\n    A.Normalize( \n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n        ),\n    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n    A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n], p=1.)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T02:47:09.841515Z","iopub.execute_input":"2021-07-11T02:47:09.8421Z","iopub.status.idle":"2021-07-11T02:47:09.854596Z","shell.execute_reply.started":"2021-07-11T02:47:09.842063Z","shell.execute_reply":"2021-07-11T02:47:09.853692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = ImageDataset(train, train_transforms)\nvalid_ds = ImageDataset(val)\n\ntrain_ds\ntrain_loader = torch.utils.data.DataLoader(\n    train_ds,\n    batch_size=CFG['batch_size'],\n    pin_memory=False,\n    drop_last=False,\n    shuffle=True,        \n    num_workers=CFG['num_workers'],\n)\nval_loader = torch.utils.data.DataLoader(\n    valid_ds, \n    batch_size=CFG['batch_size'],\n    pin_memory=False,\n    shuffle=False,\n    num_workers=CFG['num_workers'],        \n)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T02:47:09.857173Z","iopub.execute_input":"2021-07-11T02:47:09.857536Z","iopub.status.idle":"2021-07-11T02:47:09.866097Z","shell.execute_reply.started":"2021-07-11T02:47:09.857484Z","shell.execute_reply":"2021-07-11T02:47:09.865274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CovidClassifier(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-11T02:47:09.8676Z","iopub.execute_input":"2021-07-11T02:47:09.867973Z","iopub.status.idle":"2021-07-11T02:47:09.875102Z","shell.execute_reply.started":"2021-07-11T02:47:09.867937Z","shell.execute_reply":"2021-07-11T02:47:09.874184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, loss_fn, optimizer, scheduler, loader, device):\n    model.train()\n    \n    pbar = tqdm(enumerate(loader), total=len(loader))\n    for step, (imgs, image_labels) in pbar:\n        imgs = imgs.to(device)\n        image_labels = image_labels.to(device)\n        image_preds = model(imgs)\n        loss = loss_fn(image_preds, image_labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n#         scheduler.step()\n        \ndef validate_epoch(model, loss_fn, loader, device):\n    model.eval()\n    test_loss, correct = 0, 0\n    size = len(loader.dataset)\n    pbar = tqdm(enumerate(loader), total=len(loader))\n    with torch.no_grad():\n        for step, (imgs, image_labels) in pbar:\n            imgs = imgs.to(device)\n            image_labels = image_labels.to(device)\n            image_preds = model(imgs)\n            loss = loss_fn(image_preds, image_labels)\n            test_loss+=loss.item()\n            correct+=(image_preds.argmax(1) == image_labels).type(torch.float).sum().item()\n    test_loss /= size\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{"execution":{"iopub.status.busy":"2021-07-11T02:47:09.8764Z","iopub.execute_input":"2021-07-11T02:47:09.87676Z","iopub.status.idle":"2021-07-11T02:47:09.886881Z","shell.execute_reply.started":"2021-07-11T02:47:09.876725Z","shell.execute_reply":"2021-07-11T02:47:09.885911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(CFG['device'])\nmodel = CovidClassifier(CFG[\"model\"], CFG[\"n_class\"]).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader)/2)\nloss_fn = nn.CrossEntropyLoss().to(device)\nfor epoch in range(CFG[\"epochs\"]):\n    train_epoch(model, loss_fn, optimizer, scheduler, train_loader, device)\n    validate_epoch(model, loss_fn, val_loader, device)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T02:47:09.888163Z","iopub.execute_input":"2021-07-11T02:47:09.888581Z","iopub.status.idle":"2021-07-11T03:09:26.118159Z","shell.execute_reply.started":"2021-07-11T02:47:09.888548Z","shell.execute_reply":"2021-07-11T03:09:26.117209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model1\")","metadata":{"execution":{"iopub.status.busy":"2021-07-11T03:10:17.046343Z","iopub.execute_input":"2021-07-11T03:10:17.046691Z","iopub.status.idle":"2021-07-11T03:10:17.267766Z","shell.execute_reply.started":"2021-07-11T03:10:17.046659Z","shell.execute_reply":"2021-07-11T03:10:17.266862Z"},"trusted":true},"execution_count":null,"outputs":[]}]}