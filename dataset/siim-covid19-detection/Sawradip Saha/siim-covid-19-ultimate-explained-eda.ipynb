{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style='color:red;font-weight:500;'>SIIM-FISABIO-RSNA COVID-19 Detection: An Extended EDA </h1>\n\nIn this competition, we are provided with <span style='color:blue;font-weight:500;'>DICOM images </span> of chest X-ray radiographs, and we are asked to identify and localize COVID-19 abnormalities. This is important because typical diagnosis of COVID-19 requires molecular testing (polymerase chain reaction) requires several hours, while chest radiographs can be obtained in minutes, but it is hard to distinguish between COVID-19 pneumonia and other other viral and bacterial pneumonias. Therefore, in this competition, be hope to develop AI that that eventually help radiologists diagnose the millions of COVID-19 patients more confidently and quickly.\n\nI'll provide a quick and simple EDA to help you get started with this very interesting competition!\n","metadata":{}},{"cell_type":"markdown","source":"<span style='color:green;font-size:20px;font-weight:500;'>This Notebook is forked from anoder EDA notebook. But in this one , I am going to explain all the fact about this competition that confused me from beginning. </span>","metadata":{}},{"cell_type":"markdown","source":"<span style='color:crimson;font-size:20px;font-weight:500;'><b> First thing before Getting Started : </b> The data might look huge, but there is only a small number of images. We will determine the exact number of images in later part of the notebook. The huge size is mainly due to `DICOM` format. If we extract only the images in PNG format, even in high quality the dataset comes down to 3-4 GB only.  </span> ","metadata":{}},{"cell_type":"markdown","source":"<span style='color:blue;font-size:15px;font-weight:500;'>Some kind Kagglers have converted the dataset to JPG or PNG format. Though I will show in this notebook how to convert from `.dcm` to .`.jpg'/'.png`, but the converted datasets will also be linked. </span> ","metadata":{}},{"cell_type":"markdown","source":"\n<span style='color:blue;font-size:18px;font-weight:500;'>DICOM : </span> `It is the standard format for the communication and management of medical imaging information and related data.`\n\n","metadata":{}},{"cell_type":"code","source":"! conda install -c conda-forge gdcm -y","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-26T14:42:12.294114Z","iopub.execute_input":"2021-05-26T14:42:12.294478Z","iopub.status.idle":"2021-05-26T14:42:40.063643Z","shell.execute_reply.started":"2021-05-26T14:42:12.294448Z","shell.execute_reply":"2021-05-26T14:42:40.062475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# import os\n# import pydicom\n# import glob\n# from tqdm.notebook import tqdm\n# from pydicom.pixel_data_handlers.util import apply_voi_lut\n# import matplotlib.pyplot as plt\n# from skimage import exposure\n# import cv2\n# import warnings\n# from fastai.vision.all import *\n# from fastai.medical.imaging import *\n# warnings.filterwarnings('ignore')\n\nimport os\nimport pydicom\nimport glob\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:30:49.52182Z","iopub.execute_input":"2021-05-26T14:30:49.522198Z","iopub.status.idle":"2021-05-26T14:30:49.527139Z","shell.execute_reply.started":"2021-05-26T14:30:49.522166Z","shell.execute_reply":"2021-05-26T14:30:49.525979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style='color:green;'>A look at the provided data </h1>","metadata":{}},{"cell_type":"code","source":"dataset_path = '../input/siim-covid19-detection/'\n\nfor path in glob.glob(dataset_path  + '*'):\n    print(path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T14:16:20.150583Z","iopub.execute_input":"2021-05-26T14:16:20.151133Z","iopub.status.idle":"2021-05-26T14:16:20.159318Z","shell.execute_reply.started":"2021-05-26T14:16:20.151082Z","shell.execute_reply":"2021-05-26T14:16:20.158059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style='color:blue;font-size:18px;font-weight:500;'> We can see that we have:</span>\n\n* `train_study_level.csv` - the train study-level metadata, with one row for each study, including correct labels.\n* `train_image_level.csv` - the train image-level metadata, with one row for each image, including both correct labels and any bounding boxes in a dictionary format. Some images in both test and train have multiple bounding boxes.\n* `sample_submission.csv` - a sample submission file containing all image- and study-level IDs.\n* `train` folder - comprises 6,334 chest scans in DICOM format, stored in paths with the form `study`/`series`/`image`\n* `test` folder - The hidden test dataset is of roughly the same scale as the training dataset.\n","metadata":{}},{"cell_type":"markdown","source":"<span style='color:crimson;font-size:18px;font-weight:500;'> Train folder analysis: </span>\n\n\n`We see that there are some folders in train folder. Each of them have atleast one subfolder in them, and each of the subfolders have at least one dcm file, ","metadata":{}},{"cell_type":"code","source":"train_images = '../input/siim-covid19-detection/train/'\n\nn_folders = len(glob.glob(train_images  + '*'))\nn_subfolders = len(glob.glob(train_images  + '*/*'))\nn_images = len(glob.glob(train_images  + '*/*/*.dcm'))\n\nprint(f'There are {n_subfolders} subfolders in {n_folders} folders.')\nprint(f'There are altogether {n_images} images.')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:16:27.968213Z","iopub.execute_input":"2021-05-26T14:16:27.96857Z","iopub.status.idle":"2021-05-26T14:16:46.335666Z","shell.execute_reply.started":"2021-05-26T14:16:27.96854Z","shell.execute_reply":"2021-05-26T14:16:46.334521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`So , some folders have more than one subfolders and some subfolders have more than one image.`","metadata":{}},{"cell_type":"code","source":"folders = glob.glob(train_images  + '*')\n\nsubfolder_dict = {}\n\nfor folder in folders:\n    n = len(glob.glob(folder + '/*'))\n    if n in subfolder_dict.keys():\n        subfolder_dict[n] += 1\n    else:\n        subfolder_dict[n] = 1\n        \nfor k, v in subfolder_dict.items():\n    print(f'There is {v} subfolders with {k} images.')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:17:59.313568Z","iopub.execute_input":"2021-05-26T14:17:59.313898Z","iopub.status.idle":"2021-05-26T14:18:01.673102Z","shell.execute_reply.started":"2021-05-26T14:17:59.313869Z","shell.execute_reply":"2021-05-26T14:18:01.672073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subfolders = glob.glob(train_images  + '*/*')\n\nimage_dict = {}\n\nfor subfolder in subfolders:\n    n = len(glob.glob(subfolder + '/*'))\n    if (n!=1):\n        print (subfolder.split('/')[-1])\n        for image in glob.glob(subfolder + '/*'):\n            print ('-->' + image.split('/')[-1])\n\n    if n in image_dict.keys():\n        image_dict[n] += 1\n    else:\n        image_dict[n] = 1\n        \nfor k, v in image_dict.items():\n    print(f'There is {v} subfolders with {k} images.')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:18:21.691954Z","iopub.execute_input":"2021-05-26T14:18:21.69229Z","iopub.status.idle":"2021-05-26T14:18:25.77755Z","shell.execute_reply.started":"2021-05-26T14:18:21.692262Z","shell.execute_reply":"2021-05-26T14:18:25.776398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style='color:crimson;font-size:18px;font-weight:500;'> Major thing to remember is: </span>\n`There are 6331 subfolders in 6054 folders.\nThere are altogether 6334 images. Lets keep those numbers around.`","metadata":{}},{"cell_type":"markdown","source":"<span style='color:green;font-size:18px;font-weight:500;'>What is Study Level? What is Image Level? </span> <br><br> `Wait for a sec...We will get the answer  just after analyzing the CSV files.`\n\n","metadata":{}},{"cell_type":"markdown","source":"<span style='color:red;font-size:18px;font-weight:500;'>train_study_level.csv :</span>","metadata":{}},{"cell_type":"code","source":"train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')\n\ntrain_study_df","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:19:40.783008Z","iopub.execute_input":"2021-05-26T14:19:40.783389Z","iopub.status.idle":"2021-05-26T14:19:40.830373Z","shell.execute_reply.started":"2021-05-26T14:19:40.78336Z","shell.execute_reply":"2021-05-26T14:19:40.829429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we have `6054` rows in this. All the rows are classified in following classes:\n* `Negative for Pneumonia`\n* `Typical Appearance`\n* `Intermediate Appearance`\n* `Atypical Appearance`\n\n <b>So the `Study Level`  looks something like a classification task</b>. We will check later, if this is single label classification or multilabel. \n\nDo you remeber those numbers ?? <br> \nYes, The `train_study_level.csv` targets these folder number.<b> Each Folder refers to a study.</b>\n\n<span style='color:blue;font-size:16px;font-weight:500;'>Now, Checking frequency of classes...</span>\n","metadata":{}},{"cell_type":"code","source":"study_classes = train_study_df.drop(columns = ['id']).columns.tolist()\nplt.figure(figsize = (10,5))\nplt.bar([1,2,3,4], train_study_df[study_classes].values.sum(axis=0))\nplt.xticks([1,2,3,4],study_classes)\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:19:42.800227Z","iopub.execute_input":"2021-05-26T14:19:42.800568Z","iopub.status.idle":"2021-05-26T14:19:42.966348Z","shell.execute_reply.started":"2021-05-26T14:19:42.80054Z","shell.execute_reply":"2021-05-26T14:19:42.965097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This seems okay. Because, naturally number of `Typycal Appearance` will be highest, because that is the general case. Then there should be number of `Negative for Pneumonia` , which would be less than the normal case, as those X-rays are for pataints, not random people.There will be a moderate number of cases that the doctors will fail to identify. Those are `Indeteminate Appearence`. And the lowest number willbe of wired `Atypical Cases`.\n\n<span style='color:blue;font-size:16px;font-weight:500;'>Lets check if any row has multiples labels</span>","metadata":{}},{"cell_type":"code","source":"train_study_df[study_classes].sum(axis = 1).value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:20:35.954513Z","iopub.execute_input":"2021-05-26T14:20:35.954861Z","iopub.status.idle":"2021-05-26T14:20:35.966242Z","shell.execute_reply.started":"2021-05-26T14:20:35.954832Z","shell.execute_reply":"2021-05-26T14:20:35.965327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that each row has sum 1 after summing them along the row. So, `each of the 6054 studies have only one label each.`","metadata":{}},{"cell_type":"markdown","source":"<span style='color:red;font-size:18px;font-weight:500;'>train_image_level.csv :</span>","metadata":{}},{"cell_type":"code","source":"train_image_df = pd.read_csv(dataset_path +'/train_image_level.csv')\n\ntrain_image_df","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:25:51.817019Z","iopub.execute_input":"2021-05-26T14:25:51.817372Z","iopub.status.idle":"2021-05-26T14:25:51.860957Z","shell.execute_reply.started":"2021-05-26T14:25:51.817343Z","shell.execute_reply":"2021-05-26T14:25:51.859846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Firstly, Bboxex are goven here. That means it has something to do with localizing some portion of image. <b>This is an `Objet Detection Task`</b><br>\nDo you recognize the row number?? <br>\nYap! That is the total image number.\n\n<b>Thus `Image Level` means nothing but prediction for each image.</b>\n\nWe have our bounding box labels provided in the `label` column. The format is as follows:\n\n`[class ID] [confidence score] [bounding box]`\n\n* class ID - either `opacity` or `none`\n* confidence score - confidence from your neural network model. If none, the confidence is `1`.\n* bounding box - typical `xmin ymin xmax ymax` format. If class ID is none, the bounding box is `1 0 0 1 1`.\n\nThe bounding boxes are also provided in easily readable dictionary format in column `boxes`, and the study that each image is a part of is provided in`StudyInstanceUID`.\n\n<span style='color:blue;font-size:16px;font-weight:500;'>Now we will create a new column, splitting the label to more understandable list format.</span>","metadata":{}},{"cell_type":"code","source":"train_image_df['split_label'] = train_image_df.label.apply(lambda x: [x.split()[offs:offs+6] for offs in range(0, len(x.split()), 6)])\n\ntrain_image_df['split_label']","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:40:20.273978Z","iopub.execute_input":"2021-05-26T14:40:20.274327Z","iopub.status.idle":"2021-05-26T14:40:20.41669Z","shell.execute_reply.started":"2021-05-26T14:40:20.274296Z","shell.execute_reply":"2021-05-26T14:40:20.415832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay, If the label is None, there is inly one detection. But if not `None` , there might be a number of detections.\n\n<span style='color:blue;font-size:16px;font-weight:500;'>Now I will create one more column to estimate how many bounding boxes are there for each image.</span>\n","metadata":{}},{"cell_type":"code","source":"train_image_df['label_len'] = train_image_df['split_label'].apply(lambda x: 0 if (x[0][0] == 'none') else len(x))\ntrain_image_df['label_len'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:40:25.28519Z","iopub.execute_input":"2021-05-26T14:40:25.285541Z","iopub.status.idle":"2021-05-26T14:40:25.302426Z","shell.execute_reply.started":"2021-05-26T14:40:25.285512Z","shell.execute_reply":"2021-05-26T14:40:25.301335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, It looks like , there is 2040 images with no detection. 3113 images with 2 detections (understadibly in two lobes of lung).\n\n<span style='color:blue;font-size:16px;font-weight:500;'>Let's quick look at the distribution of opacity vs none:</span>","metadata":{}},{"cell_type":"code","source":"classes_freq = []\nfor i in range(len(train_image_df)):\n    for j in train_image_df.iloc[i].split_label: classes_freq.append(j[0])\nplt.hist(classes_freq)\nplt.ylabel('Frequency')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:40:27.23376Z","iopub.execute_input":"2021-05-26T14:40:27.234198Z","iopub.status.idle":"2021-05-26T14:40:28.366273Z","shell.execute_reply.started":"2021-05-26T14:40:27.234162Z","shell.execute_reply":"2021-05-26T14:40:28.365201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n","metadata":{}},{"cell_type":"code","source":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = pydicom.pixel_data_handlers.util.apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n        \n    \ndef plot_img(img, size=(7, 7), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n    \ndef plot_imgs(imgs, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', img_size=(500,500)):\n    rows = len(imgs)//cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:41:10.314552Z","iopub.execute_input":"2021-05-26T14:41:10.314914Z","iopub.status.idle":"2021-05-26T14:41:10.326609Z","shell.execute_reply.started":"2021-05-26T14:41:10.314877Z","shell.execute_reply":"2021-05-26T14:41:10.325395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs = []\nimage_ids = train_image_df['id'].values\n\n# map label_id to specify color\nthickness = 10\nscale = 5\n\n\nfor i in range(8):\n    image_id = random.choice(image_ids)\n    image_path = glob.glob(f\"../input/siim-covid19-detection/train/*/*/{image_id.split('_')[0]}.dcm\")[0]\n    print(image_path)\n    img = dicom2array(path=image_path)\n    img = cv2.resize(img, None, fx=1/scale, fy=1/scale)\n    img = np.stack([img, img, img], axis=-1)\n    print(train_image_df.loc[train_image_df['id'] == image_id])\n#     for i in train_image_df.loc[train_image_df['id'] == image_id].split_label.values[0]:\n#         if i[0] == 'opacity':\n#             img = cv2.rectangle(img,\n#                                 (int(float(i[2])/scale), int(float(i[3])/scale)),\n#                                 (int(float(i[4])/scale), int(float(i[5])/scale)),\n#                                 [255,0,0], thickness)\n    \n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:41:12.054883Z","iopub.execute_input":"2021-05-26T14:41:12.055461Z","iopub.status.idle":"2021-05-26T14:41:35.923962Z","shell.execute_reply.started":"2021-05-26T14:41:12.055421Z","shell.execute_reply":"2021-05-26T14:41:35.921141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_areas = []\nfor i in range(len(train_image_df)):\n    for j in train_image_df.iloc[i].split_label:\n        bbox_areas.append((float(j[4])-float(j[2]))*(float(j[5])*float(j[3])))\nplt.hist(bbox_areas)\nplt.ylabel('Frequency')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:22:54.291839Z","iopub.execute_input":"2021-05-26T14:22:54.292243Z","iopub.status.idle":"2021-05-26T14:22:55.452545Z","shell.execute_reply.started":"2021-05-26T14:22:54.29221Z","shell.execute_reply":"2021-05-26T14:22:55.45149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style='color:crimson;font-size:20px;font-weight:500;'><b> If you like the EDA approach or the notebook, a lot more thing will be added. Thank you. </b>  </span> ","metadata":{}},{"cell_type":"markdown","source":"That's it for now!\n\n**Please upvote if you found this helpful!**","metadata":{}}]}