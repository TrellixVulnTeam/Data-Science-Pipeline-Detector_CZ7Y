{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-25T03:02:49.855784Z","iopub.execute_input":"2021-08-25T03:02:49.856122Z","iopub.status.idle":"2021-08-25T03:03:36.032474Z","shell.execute_reply.started":"2021-08-25T03:02:49.856092Z","shell.execute_reply":"2021-08-25T03:03:36.031489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/segmentation-model-pt/segmentation_models_pytorch-0.2.0-py3-none-any.whl --no-index --no-deps","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:03:36.036082Z","iopub.execute_input":"2021-08-25T03:03:36.036362Z","iopub.status.idle":"2021-08-25T03:03:37.84826Z","shell.execute_reply.started":"2021-08-25T03:03:36.036333Z","shell.execute_reply":"2021-08-25T03:03:37.847267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/segmentation-model-pt/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:03:37.851943Z","iopub.execute_input":"2021-08-25T03:03:37.852213Z","iopub.status.idle":"2021-08-25T03:04:05.193465Z","shell.execute_reply.started":"2021-08-25T03:03:37.852184Z","shell.execute_reply":"2021-08-25T03:04:05.192468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/segmentation-model-pt/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3/","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:04:05.195455Z","iopub.execute_input":"2021-08-25T03:04:05.19583Z","iopub.status.idle":"2021-08-25T03:04:32.191831Z","shell.execute_reply.started":"2021-08-25T03:04:05.19579Z","shell.execute_reply":"2021-08-25T03:04:32.190553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/timm-pytorch-image-models/pytorch-image-models-master/","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:04:32.196762Z","iopub.execute_input":"2021-08-25T03:04:32.199073Z","iopub.status.idle":"2021-08-25T03:05:00.079996Z","shell.execute_reply.started":"2021-08-25T03:04:32.199023Z","shell.execute_reply":"2021-08-25T03:05:00.079011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:05:00.081585Z","iopub.execute_input":"2021-08-25T03:05:00.081945Z","iopub.status.idle":"2021-08-25T03:05:00.086009Z","shell.execute_reply.started":"2021-08-25T03:05:00.081906Z","shell.execute_reply":"2021-08-25T03:05:00.085186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nfrom torch import nn\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-25T03:05:00.087387Z","iopub.execute_input":"2021-08-25T03:05:00.088095Z","iopub.status.idle":"2021-08-25T03:05:00.100683Z","shell.execute_reply.started":"2021-08-25T03:05:00.088054Z","shell.execute_reply":"2021-08-25T03:05:00.099758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIM = (512,512,3)\nBATCH_SIZE = 4\n\nCANDIDATES = [\n    {\n        'model_path':'../input/siimstudyclfmodels/v303/v303/Fold0_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.733_ValidAcc0.000_ValidAUC0.796_ValidmAP0.366_Ep11.pth'\n    },\n    {\n        'model_path':'../input/siimstudyclfmodels/v303/v303/Fold1_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.722_ValidAcc0.000_ValidAUC0.799_ValidmAP0.362_Ep03.pth'\n    },\n    {\n        'model_path':'../input/siimstudyclfmodels/v303/v303/Fold2_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.695_ValidAcc0.000_ValidAUC0.825_ValidmAP0.382_Ep16.pth'\n    },\n    {\n        'model_path':'../input/siimstudyclfmodels/v303/v303/Fold3_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.687_ValidAcc0.000_ValidAUC0.821_ValidmAP0.380_Ep18.pth'\n    },\n    {\n        'model_path':'../input/siimstudyclfmodels/v303/v303/Fold4_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.718_ValidAcc0.000_ValidAUC0.822_ValidmAP0.401_Ep10.pth'\n    },\n    \n]\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:05:00.105886Z","iopub.execute_input":"2021-08-25T03:05:00.106205Z","iopub.status.idle":"2021-08-25T03:05:00.113793Z","shell.execute_reply.started":"2021-08-25T03:05:00.106179Z","shell.execute_reply":"2021-08-25T03:05:00.112967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nfast_sub = False\n\n# if df.shape[0] == 2477:\n#     fast_sub = True\n#     fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n#                          ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n#                          ['65761e66de9f_image', 'none 1 0 0 1 1'], \n#                          ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n#                        columns=['id', 'PredictionString'])\n# else:\n#     fast_sub = False\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:05:00.115946Z","iopub.execute_input":"2021-08-25T03:05:00.116385Z","iopub.status.idle":"2021-08-25T03:05:00.131045Z","shell.execute_reply.started":"2021-08-25T03:05:00.116347Z","shell.execute_reply":"2021-08-25T03:05:00.130275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# .dcm to .png","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:05:00.132131Z","iopub.execute_input":"2021-08-25T03:05:00.132451Z","iopub.status.idle":"2021-08-25T03:05:00.140375Z","shell.execute_reply.started":"2021-08-25T03:05:00.132425Z","shell.execute_reply":"2021-08-25T03:05:00.137465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:05:00.141739Z","iopub.execute_input":"2021-08-25T03:05:00.142115Z","iopub.status.idle":"2021-08-25T03:05:00.152954Z","shell.execute_reply.started":"2021-08-25T03:05:00.142078Z","shell.execute_reply":"2021-08-25T03:05:00.152148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split = 'test'\nsave_dir = f'/kaggle/tmp/{split}/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'/kaggle/tmp/{split}/study/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('../input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')\n    im = resize(xray, size=600)  \n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    xray = read_xray('../input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')\n    im = resize(xray, size=600)  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=600)  \n            study = dirname.split('/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:05:00.154193Z","iopub.execute_input":"2021-08-25T03:05:00.154522Z","iopub.status.idle":"2021-08-25T03:05:00.57497Z","shell.execute_reply.started":"2021-08-25T03:05:00.154485Z","shell.execute_reply":"2021-08-25T03:05:00.574062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# study predict","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nif fast_sub:\n    df = fast_df.copy()\nelse:\n    df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\n\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:07:53.374052Z","iopub.execute_input":"2021-08-25T03:07:53.374408Z","iopub.status.idle":"2021-08-25T03:07:53.384565Z","shell.execute_reply.started":"2021-08-25T03:07:53.374379Z","shell.execute_reply":"2021-08-25T03:07:53.383755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['id_last_str']","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:07:53.628546Z","iopub.execute_input":"2021-08-25T03:07:53.628888Z","iopub.status.idle":"2021-08-25T03:07:53.638333Z","shell.execute_reply.started":"2021-08-25T03:07:53.628858Z","shell.execute_reply":"2021-08-25T03:07:53.637522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_len","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:07:53.756559Z","iopub.execute_input":"2021-08-25T03:07:53.75686Z","iopub.status.idle":"2021-08-25T03:07:53.76439Z","shell.execute_reply.started":"2021-08-25T03:07:53.756835Z","shell.execute_reply":"2021-08-25T03:07:53.763683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)\n\n#load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\nif fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\nsub_df = sub_df[:study_len]\ntest_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'\n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\n\nlabel_cols = sub_df.columns[2:]\n\nsub_df['test_path'] = test_paths","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:33.148471Z","iopub.execute_input":"2021-08-25T03:08:33.148875Z","iopub.status.idle":"2021-08-25T03:08:33.159143Z","shell.execute_reply.started":"2021-08-25T03:08:33.148841Z","shell.execute_reply":"2021-08-25T03:08:33.15778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Optional, List\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import autocast\n\nfrom segmentation_models_pytorch.encoders import get_encoder\nfrom segmentation_models_pytorch.unet.decoder import UnetDecoder\nfrom segmentation_models_pytorch.unetplusplus.decoder import UnetPlusPlusDecoder\nfrom segmentation_models_pytorch.deeplabv3.decoder import DeepLabV3PlusDecoder\nfrom segmentation_models_pytorch.fpn.decoder import FPNDecoder\nfrom segmentation_models_pytorch.linknet.decoder import LinknetDecoder\nfrom segmentation_models_pytorch.base import SegmentationHead\nfrom segmentation_models_pytorch.base import initialization as init\n\nclass PretrainModel(nn.Module):\n    def __init__(\n        self,\n        encoder_name: str = \"timm-efficientnet-b7\",\n        encoder_weights: Optional[str] = None,\n        classes: int = 4,\n        in_features: int = 2560, \n        pretrained_path=None, \n        pretrained_num_classes=None,\n    ):\n        super(PretrainModel, self).__init__()\n        self.in_features = in_features\n        if pretrained_path is None:\n            self.encoder = get_encoder(\n                encoder_name,\n                in_channels=3,\n                depth=5,\n                weights=encoder_weights,\n            )\n            if 'timm-efficientnet' in encoder_name:\n                self.hidden_layer = nn.Sequential(*list(self.encoder.children())[-4:])\n                del self.encoder.global_pool\n                del self.encoder.act2\n                del self.encoder.bn2\n                del self.encoder.conv_head\n            elif 'timm-seresnet' in encoder_name or 'timm-resnet' in encoder_name:\n                self.hidden_layer = nn.AdaptiveAvgPool2d(output_size=1)\n        else:\n            print('Load pretrain: {}'.format(pretrained_path))\n            model = PretrainModel(\n                encoder_name=encoder_name,\n                encoder_weights=encoder_weights,\n                classes=pretrained_num_classes,\n                in_features=in_features, \n                pretrained_path=None, \n                pretrained_num_classes=None)\n            model.load_state_dict(torch.load(pretrained_path, map_location='cpu'))\n            self.encoder = model.encoder\n            self.hidden_layer = model.hidden_layer\n            del model\n\n        self.fc = nn.Linear(in_features, 1024, bias=True)\n        self.cls_head = nn.Linear(1024, classes, bias=True)\n\n        init.initialize_head(self.fc)\n        init.initialize_head(self.cls_head)\n\n    @autocast(enabled=True)\n    def forward(self, x):\n        x = self.encoder(x)[-1]\n        x = self.hidden_layer(x)\n        x = x.view(-1, self.in_features)\n        x = self.fc(x)\n        x = F.relu(x)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.cls_head(x)\n        return x\n\nclass SiimCovidAuxModel(nn.Module):\n    def __init__(\n        self,\n        encoder_name: str = \"timm-efficientnet-b7\",\n        encoder_weights: Optional[str] = None,\n        decoder_use_batchnorm: bool = True,\n        decoder_channels: List[int] = (256, 128, 64, 32, 16),\n        decoder_attention_type: Optional[str] = None,\n        decoder: Optional[str] = 'unet',\n        classes: int = 4,\n        in_features: int = 2560,\n        encoder_pretrained_path=None, \n        encoder_pretrained_num_classes=None,\n        model_pretrained_path=None, \n        model_pretrained_num_classes=None,\n        test_mode=False,\n    ):\n        super(SiimCovidAuxModel, self).__init__()\n        self.in_features = in_features\n        self.test_mode = test_mode\n\n        if model_pretrained_path is None:\n            if encoder_pretrained_path is None:\n                model = PretrainModel(\n                            encoder_name=encoder_name,\n                            encoder_weights=encoder_weights,\n                            classes=classes,\n                            in_features=in_features, \n                            pretrained_path=None, \n                            pretrained_num_classes=None)\n            else:\n                print('load pretrain', encoder_pretrained_path)\n                model = PretrainModel(\n                            encoder_name=encoder_name,\n                            encoder_weights=encoder_weights,\n                            classes=encoder_pretrained_num_classes,\n                            in_features=in_features, \n                            pretrained_path=None, \n                            pretrained_num_classes=None)\n                model.load_state_dict(torch.load(encoder_pretrained_path, map_location='cpu'))\n            self.encoder = model.encoder\n            self.hidden_layer = model.hidden_layer\n            del model\n            self.fc = nn.Linear(in_features, 1024, bias=True)\n            self.cls_head = nn.Linear(1024, classes, bias=True)\n\n            if decoder == 'unet':\n                self.decoder = UnetDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    decoder_channels=decoder_channels,\n                    n_blocks=5,\n                    use_batchnorm=decoder_use_batchnorm,\n                    center=True if encoder_name.startswith(\"vgg\") else False,\n                    attention_type=decoder_attention_type,\n                )\n            elif decoder == 'unetplusplus':\n                self.decoder = UnetPlusPlusDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    decoder_channels=decoder_channels,\n                    n_blocks=5,\n                    use_batchnorm=decoder_use_batchnorm,\n                    center=True if encoder_name.startswith(\"vgg\") else False,\n                    attention_type=decoder_attention_type,\n                )\n            elif decoder == 'fpn':\n                self.decoder = FPNDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    encoder_depth=5,\n                    pyramid_channels=256,\n                    segmentation_channels=128,\n                    dropout=0.2,\n                    merge_policy=\"add\",\n                )\n            elif decoder == 'linknet':\n                self.decoder = LinknetDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    n_blocks=5,\n                    prefinal_channels=32,\n                    use_batchnorm=decoder_use_batchnorm,\n                )\n            elif decoder == 'deeplabv3plus':\n                decoder_atrous_rates = [12, 24, 36]\n                encoder_output_stride = 16\n                self.encoder.make_dilated(\n                    stage_list=[5],\n                    dilation_list=[2]\n                )\n                self.decoder = DeepLabV3PlusDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    out_channels=decoder_channels,\n                    atrous_rates=decoder_atrous_rates,\n                    output_stride=encoder_output_stride,\n                )\n            else:\n                raise ValueError('Decoder error!!!')\n\n            if decoder == 'unet' or decoder == 'unetplusplus':\n                self.segmentation_head = SegmentationHead(\n                    in_channels=decoder_channels[-1],\n                    out_channels=1,\n                    activation='sigmoid',\n                    kernel_size=3,\n                )\n            elif decoder == 'deeplabv3plus':\n                self.segmentation_head = SegmentationHead(\n                    in_channels=self.decoder.out_channels,\n                    out_channels=1,\n                    activation='sigmoid',\n                    kernel_size=1,\n                    upsampling=4,\n                )\n            elif decoder == 'fpn':\n                self.segmentation_head = SegmentationHead(\n                    in_channels=self.decoder.out_channels,\n                    out_channels=1,\n                    activation='sigmoid',\n                    kernel_size=1,\n                    upsampling=4,\n                )\n            elif decoder == 'linknet':\n                self.segmentation_head = SegmentationHead(\n                    in_channels=32, \n                    out_channels=1, \n                    activation='sigmoid',\n                    kernel_size=1\n                )\n            else:\n                raise ValueError('Decoder error!!!')\n\n            init.initialize_head(self.fc)\n            init.initialize_head(self.cls_head)\n            init.initialize_decoder(self.decoder)\n            init.initialize_head(self.segmentation_head)\n        else:\n            print('Load pretrain: {}'.format(model_pretrained_path))\n            model = SiimCovidAuxModel(\n                encoder_name=encoder_name,\n                encoder_weights=None,\n                decoder=decoder,\n                classes=model_pretrained_num_classes,\n                in_features=in_features,\n                decoder_channels=decoder_channels,\n                encoder_pretrained_path=None,\n                encoder_pretrained_num_classes=None,\n                model_pretrained_path=None, \n                model_pretrained_num_classes=None,\n                test_mode=False,\n            )\n            model.load_state_dict(torch.load(model_pretrained_path, map_location='cpu'))\n\n            self.encoder = model.encoder\n            self.hidden_layer = model.hidden_layer\n            self.decoder = model.decoder\n            self.segmentation_head = model.segmentation_head\n            self.fc = nn.Linear(in_features, 1024, bias=True)\n            self.cls_head = nn.Linear(1024, classes, bias=True)\n            del model\n            init.initialize_head(self.fc)\n            init.initialize_head(self.cls_head)\n    \n    @autocast(enabled=True)\n    def forward(self, x):\n        if self.test_mode:\n            features = self.encoder(x)\n            xcls = self.hidden_layer(features[-1])\n            xcls = xcls.view(-1, self.in_features)\n            xcls = self.fc(xcls)\n            xcls = F.relu(xcls)\n            xcls = F.dropout(xcls, p=0.5, training=self.training)\n            xcls = self.cls_head(xcls)\n            return xcls\n        else:\n            features = self.encoder(x)\n            xseg = self.decoder(*features)\n            xseg = self.segmentation_head(xseg)\n\n            xcls = self.hidden_layer(features[-1])\n            xcls = xcls.view(-1, self.in_features)\n            xcls = self.fc(xcls)\n            xcls = F.relu(xcls)\n            xcls = F.dropout(xcls, p=0.5, training=self.training)\n            xcls = self.cls_head(xcls)\n\n            return xseg, xcls\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:33.357Z","iopub.execute_input":"2021-08-25T03:08:33.357283Z","iopub.status.idle":"2021-08-25T03:08:33.395878Z","shell.execute_reply.started":"2021-08-25T03:08:33.357256Z","shell.execute_reply":"2021-08-25T03:08:33.394941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ClfTestDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, csv, transforms=None):\n        self.csv = csv.reset_index()\n        self.augmentations = transforms\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        image = cv2.imread(row.test_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']\n        \n        if('clf_label_idx' in self.csv.columns):\n            return torch.tensor(image), torch.tensor(row.clf_label_idx)\n        \n        return image\n    \n\ndef get_test_transforms(candidate):\n    dim = candidate.get('dim', DIM)\n    print(dim)\n    return A.Compose(\n        [\n            A.Resize(dim[0],dim[1],always_apply=True),\n            A.Normalize(),\n            ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:33.510656Z","iopub.execute_input":"2021-08-25T03:08:33.510932Z","iopub.status.idle":"2021-08-25T03:08:33.518728Z","shell.execute_reply.started":"2021-08-25T03:08:33.510906Z","shell.execute_reply":"2021-08-25T03:08:33.517757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm \n\ndef clf_predict_fn(dataloader, model, device):\n    model.eval()\n    tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n    batch_preds=[]\n    \n    for i, inps in tk0:\n        inps = inps.to(device)\n        with torch.cuda.amp.autocast(enabled=True):\n            logits = model(inps)\n            if(torch.isnan(logits.sum())):\n                print(torch.isnan(logits.sum(axis=1)).sum())\n            sum_check_nan = logits.sum(axis=1)\n            logits[torch.isnan(sum_check_nan), :] = 0.25\n            \n        probs = nn.functional.softmax(logits, dim=-1)\n        batch_preds.append(probs.detach().cpu().numpy())\n        \n        del inps, logits, probs, sum_check_nan\n        torch.cuda.empty_cache()\n        \n    return np.concatenate(batch_preds)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:33.811748Z","iopub.execute_input":"2021-08-25T03:08:33.812017Z","iopub.status.idle":"2021-08-25T03:08:33.819621Z","shell.execute_reply.started":"2021-08-25T03:08:33.811992Z","shell.execute_reply":"2021-08-25T03:08:33.818422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = dict()\ncfg['encoder_name'] = 'timm-efficientnet-b7'\ncfg['encoder_weight'] = None\ncfg['decoder'] = 'unetplusplus'\ncfg['in_features'] = 2560\ncfg['decoder_channels'] = [256, 128, 64, 32, 16]\ncfg['encoder_pretrained_path'] = None\ncfg['model_pretrained_num_classes'] = 4","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:34.092926Z","iopub.execute_input":"2021-08-25T03:08:34.093473Z","iopub.status.idle":"2021-08-25T03:08:34.106084Z","shell.execute_reply.started":"2021-08-25T03:08:34.093433Z","shell.execute_reply":"2021-08-25T03:08:34.105043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for candidate in CANDIDATES:\n    cfg['model_pretrained_path'] = candidate.get('model_path')\n    model = SiimCovidAuxModel(\n    encoder_name=cfg['encoder_name'],\n    encoder_weights=cfg['encoder_weight'],\n    decoder=cfg['decoder'],\n    classes=4,\n    in_features=cfg['in_features'],\n    decoder_channels=cfg['decoder_channels'],\n    encoder_pretrained_path=None ,\n    encoder_pretrained_num_classes=None,\n    model_pretrained_path=None, \n    model_pretrained_num_classes=cfg['model_pretrained_num_classes'],\n    test_mode=True)\n    \n    model.load_state_dict(torch.load(cfg['model_pretrained_path'], map_location='cpu'))\n    model.to('cuda:0')\n    print()\n    \n    batch_size = candidate.get('batch_size', BATCH_SIZE)\n    test_dataset = ClfTestDataset(sub_df, get_test_transforms(candidate))\n    test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n    \n    sub_df[label_cols] += clf_predict_fn(test_dataloader, model, torch.device('cuda:0'))\n    \n    del model\n    torch.cuda.empty_cache()\n    \nsub_df[label_cols] /= len(CANDIDATES)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:34.452623Z","iopub.execute_input":"2021-08-25T03:08:34.453072Z","iopub.status.idle":"2021-08-25T03:08:45.77951Z","shell.execute_reply.started":"2021-08-25T03:08:34.453018Z","shell.execute_reply":"2021-08-25T03:08:45.778644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:45.780996Z","iopub.execute_input":"2021-08-25T03:08:45.781481Z","iopub.status.idle":"2021-08-25T03:08:45.786609Z","shell.execute_reply.started":"2021-08-25T03:08:45.78144Z","shell.execute_reply":"2021-08-25T03:08:45.78578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.columns = ['id', 'PredictionString1', 'negative', 'typical', 'indeterminate', 'atypical', 'test_path']\ndf = pd.merge(df, sub_df, on = 'id', how = 'left')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:45.788176Z","iopub.execute_input":"2021-08-25T03:08:45.788684Z","iopub.status.idle":"2021-08-25T03:08:45.801198Z","shell.execute_reply.started":"2021-08-25T03:08:45.788625Z","shell.execute_reply":"2021-08-25T03:08:45.800271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# study string","metadata":{}},{"cell_type":"code","source":"for i in range(study_len):\n    negative = df.loc[i,'negative']\n    typical = df.loc[i,'typical']\n    indeterminate = df.loc[i,'indeterminate']\n    atypical = df.loc[i,'atypical']\n    df.loc[i, 'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:06.665543Z","iopub.execute_input":"2021-08-25T03:08:06.666116Z","iopub.status.idle":"2021-08-25T03:08:06.673069Z","shell.execute_reply.started":"2021-08-25T03:08:06.666078Z","shell.execute_reply":"2021-08-25T03:08:06.672064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_study = df[['id', 'PredictionString']]\n\n# df.to_csv('submission.csv',index=False)\n# df","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:06.674535Z","iopub.execute_input":"2021-08-25T03:08:06.674913Z","iopub.status.idle":"2021-08-25T03:08:06.682459Z","shell.execute_reply.started":"2021-08-25T03:08:06.674876Z","shell.execute_reply":"2021-08-25T03:08:06.681613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = df_study.fillna('')\ndef remove_prediction_on_image_level(row):\n    if(row['id'].endswith('_image')):\n        row['PredictionString'] = ''\n    return row\nsub_df = sub_df.apply(remove_prediction_on_image_level, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:06.683833Z","iopub.execute_input":"2021-08-25T03:08:06.684355Z","iopub.status.idle":"2021-08-25T03:08:06.694062Z","shell.execute_reply.started":"2021-08-25T03:08:06.684317Z","shell.execute_reply":"2021-08-25T03:08:06.693253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.iloc[0].PredictionString","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:06.695371Z","iopub.execute_input":"2021-08-25T03:08:06.695766Z","iopub.status.idle":"2021-08-25T03:08:06.70237Z","shell.execute_reply.started":"2021-08-25T03:08:06.69573Z","shell.execute_reply":"2021-08-25T03:08:06.701257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'negative 0.01657867431640625 0 0 1 1 typical 0.76240234375 0 0 1 1 indeterminate 0.13795166015625 0 0 1 1 atypical 0.083038330078125 0 0 1 1'","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:06.705019Z","iopub.execute_input":"2021-08-25T03:08:06.705437Z","iopub.status.idle":"2021-08-25T03:08:06.709691Z","shell.execute_reply.started":"2021-08-25T03:08:06.705399Z","shell.execute_reply":"2021-08-25T03:08:06.708631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.iloc[1].PredictionString","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:06.711455Z","iopub.execute_input":"2021-08-25T03:08:06.712019Z","iopub.status.idle":"2021-08-25T03:08:06.722732Z","shell.execute_reply.started":"2021-08-25T03:08:06.711981Z","shell.execute_reply":"2021-08-25T03:08:06.721744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'negative 0.277313232421875 0 0 1 1 typical 0.082476806640625 0 0 1 1 indeterminate 0.1296875 0 0 1 1 atypical 0.510546875 0 0 1 1'","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:06.724089Z","iopub.execute_input":"2021-08-25T03:08:06.724477Z","iopub.status.idle":"2021-08-25T03:08:06.731207Z","shell.execute_reply.started":"2021-08-25T03:08:06.724441Z","shell.execute_reply":"2021-08-25T03:08:06.730358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T03:08:06.732642Z","iopub.execute_input":"2021-08-25T03:08:06.733314Z","iopub.status.idle":"2021-08-25T03:08:06.743605Z","shell.execute_reply.started":"2021-08-25T03:08:06.733275Z","shell.execute_reply":"2021-08-25T03:08:06.742783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}