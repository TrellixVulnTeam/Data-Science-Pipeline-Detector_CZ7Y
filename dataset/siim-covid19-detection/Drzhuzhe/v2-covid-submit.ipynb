{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Approach and Refferences\n\n> efficientnetb3a and efficientnetbv2m with aux loss for study + yolov5m and yolov5x for image \n\n## Refferences\n\n1. henhttps://www.kaggle.com/c/siim-covid19-detection/discussion/246586gk's aux loss https://www.kaggle.com/c/siim-covid19-detection/discussion/240233\n2. alien's 2 class tricks https://www.kaggle.com/c/siim-covid19-detection/discussion/246586\n3. darian's duplicate analysis https://www.kaggle.com/c/siim-covid19-detection/discussion/240878\n\n## Training notebook\n\n1. drop duplicate and create mask https://www.kaggle.com/drzhuzhe/siiim-covid-stratified-k-fold-and-create-mask\n\n2. training study level https://www.kaggle.com/drzhuzhe/covid19-classify \n\n    efficientnetb3a 1e-3 10 ep + 1e-4 5ep CV map*0.66 score (3.76 + 3.92 + 3.85 + 3.7 + 3.6)/5 avg 3.766\n    \n    efficientnetv2m ReduceLROnPlateau CV map*0.66 score (3.92 + 3.92 + 3.81 + 3.85 + 3.74)\n\n3. training yolov5m https://www.kaggle.com/drzhuzhe/covid19-det?scriptVersionId=67605495 \n    \n    yolom only 10 epoch  CV map score (0.4947 + 0.5103 + 0.4848 +0.4692 +0.5198)/5 avg 0.49575 \n    \n    yolox 30 epoch CV map score (0.525 + 0.525 + 0.488 + 0.488+ 0.481)\n    \n\n4. ~2 class https://www.kaggle.com/drzhuzhe/siim-covid19-efnb7-train-fold0-5-2class  yolov5m 15 epoch (0.869 + 0.860 + 0.882 + 0.878 + 0.876)/5 avg 0.872~ Only use 'negative' probility as 'none'\n","metadata":{}},{"cell_type":"code","source":"with_ensemble = True\nwith_study = True\nwith_image = True\nwith_2class = True","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:09:53.416013Z","iopub.execute_input":"2021-08-07T08:09:53.416252Z","iopub.status.idle":"2021-08-07T08:09:53.420957Z","shell.execute_reply.started":"2021-08-07T08:09:53.416229Z","shell.execute_reply":"2021-08-07T08:09:53.420109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda install '../input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -y --offline\n!conda install '../input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -y --offline","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:09:53.423379Z","iopub.execute_input":"2021-08-07T08:09:53.42399Z","iopub.status.idle":"2021-08-07T08:10:25.082567Z","shell.execute_reply.started":"2021-08-07T08:09:53.423955Z","shell.execute_reply":"2021-08-07T08:10:25.081642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\n\nimport cv2\nimport sys\nimport math\n\nfrom timeit import default_timer as timer\nfrom datetime import datetime\nfrom numba import cuda\n\n# read dicom\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom PIL import Image\nimport csv","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:10:25.085691Z","iopub.execute_input":"2021-08-07T08:10:25.085968Z","iopub.status.idle":"2021-08-07T08:10:26.933729Z","shell.execute_reply.started":"2021-08-07T08:10:25.085938Z","shell.execute_reply":"2021-08-07T08:10:26.932898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preporcess","metadata":{}},{"cell_type":"code","source":"_SIZE_ = 512 \n_Type_ = \"png\"","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:10:26.935428Z","iopub.execute_input":"2021-08-07T08:10:26.935758Z","iopub.status.idle":"2021-08-07T08:10:26.942523Z","shell.execute_reply.started":"2021-08-07T08:10:26.935731Z","shell.execute_reply":"2021-08-07T08:10:26.941772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:10:26.943708Z","iopub.execute_input":"2021-08-07T08:10:26.944028Z","iopub.status.idle":"2021-08-07T08:10:26.955111Z","shell.execute_reply.started":"2021-08-07T08:10:26.943998Z","shell.execute_reply":"2021-08-07T08:10:26.954306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id = []\ndim0 = []\ndim1 = []\nsplits = []\nstudy = []\n\n    \n#for split in ['test', 'train']:\nfor split in ['test']:\n    save_dir = f'/kaggle/tmp/{split}/'\n    \n    os.makedirs(save_dir, exist_ok=True)\n    \n    for study_id in tqdm(os.listdir(f'../input/siim-covid19-detection/{split}')):\n        for dirname, _, filenames in os.walk(f'../input/siim-covid19-detection/{split}/{study_id}'):\n            for file in filenames:\n                # set keep_ratio=True to have original aspect ratio\n                xray = read_xray(os.path.join(dirname, file))\n\n                im = resize(xray, size=_SIZE_)\n                _name = file.replace('dcm', _Type_)\n                im.save(os.path.join(save_dir, _name))\n\n                _img_id = file.replace('.dcm', '')\n                image_id.append(_img_id)\n\n                _w = xray.shape[0]\n                _h = xray.shape[1]\n                dim0.append(_w)\n                dim1.append(_h)\n                splits.append(split)\n                study.append(study_id)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:20:52.318316Z","iopub.execute_input":"2021-08-07T08:20:52.318646Z","iopub.status.idle":"2021-08-07T08:21:11.678401Z","shell.execute_reply.started":"2021-08-07T08:20:52.318605Z","shell.execute_reply":"2021-08-07T08:21:11.676586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_df = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits, 'study': study})\nmeta_df.to_csv('/kaggle/tmp/meta.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:19:37.863722Z","iopub.execute_input":"2021-08-07T08:19:37.864056Z","iopub.status.idle":"2021-08-07T08:19:37.877614Z","shell.execute_reply.started":"2021-08-07T08:19:37.864027Z","shell.execute_reply":"2021-08-07T08:19:37.876888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:48.918238Z","iopub.execute_input":"2021-08-07T08:21:48.918596Z","iopub.status.idle":"2021-08-07T08:21:48.923451Z","shell.execute_reply.started":"2021-08-07T08:21:48.918563Z","shell.execute_reply":"2021-08-07T08:21:48.92231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_det_model_path = \"/kaggle/input/collect-submit-model/det/\"\n\n\n_classify_model1_path = \"/kaggle/input/covidmodels/Archive/classify-ep12/\"\n\n_classify_model2_path = \"/kaggle/input/covidmodels/\"\n\n#_test_files_path = \"/kaggle/input/covid19512/test/\"\n#_data_dir = \"/kaggle/input/covid19512/\"\n\n_test_files_path = \"/kaggle/tmp/test/\"\n_data_dir = \"/kaggle/tmp/\"\n\nmeta_df = pd.read_csv(_data_dir + \"meta.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:48.927774Z","iopub.execute_input":"2021-08-07T08:21:48.928203Z","iopub.status.idle":"2021-08-07T08:21:48.944087Z","shell.execute_reply.started":"2021-08-07T08:21:48.928164Z","shell.execute_reply":"2021-08-07T08:21:48.943229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 512","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:48.945887Z","iopub.execute_input":"2021-08-07T08:21:48.946243Z","iopub.status.idle":"2021-08-07T08:21:48.950348Z","shell.execute_reply.started":"2021-08-07T08:21:48.94621Z","shell.execute_reply":"2021-08-07T08:21:48.949248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clssification","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.nn.parallel.data_parallel import data_parallel\n\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import *\n\nimport collections\nfrom collections import defaultdict\n\nimport timm\nfrom timm.models.efficientnet import *\n\nimport torch.cuda.amp as amp","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:48.952681Z","iopub.execute_input":"2021-08-07T08:21:48.953086Z","iopub.status.idle":"2021-08-07T08:21:52.674174Z","shell.execute_reply.started":"2021-08-07T08:21:48.953054Z","shell.execute_reply":"2021-08-07T08:21:52.673175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = _data_dir\nimage_size = IMG_SIZE\n\nstudy_name_to_predict_string = {\n    'Negative for Pneumonia'  :'negative',\n    'Typical Appearance'      :'typical',\n    'Indeterminate Appearance':'indeterminate',\n    'Atypical Appearance'     :'atypical',\n}\n\nstudy_name_to_label = {\n    'Negative for Pneumonia'  :0,\n    'Typical Appearance'      :1,\n    'Indeterminate Appearance':2,\n    'Atypical Appearance'     :3,\n}\nstudy_label_to_name = { v:k for k,v in study_name_to_label.items()}\nnum_study_label = len(study_name_to_label)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.675995Z","iopub.execute_input":"2021-08-07T08:21:52.676341Z","iopub.status.idle":"2021-08-07T08:21:52.681973Z","shell.execute_reply.started":"2021-08-07T08:21:52.676302Z","shell.execute_reply":"2021-08-07T08:21:52.680787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_fold(mode='train-0'):\n    if 'test' in mode:\n        df_meta  = pd.read_csv(data_dir+'meta.csv')\n        df_valid = df_meta[df_meta['split']=='test'].copy()\n\n        for l in study_name_to_label.keys():\n            df_valid.loc[:,l]=0\n        df_valid = df_valid.reset_index(drop=True)\n        return df_valid","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.683254Z","iopub.execute_input":"2021-08-07T08:21:52.683842Z","iopub.status.idle":"2021-08-07T08:21:52.695698Z","shell.execute_reply.started":"2021-08-07T08:21:52.683787Z","shell.execute_reply":"2021-08-07T08:21:52.694874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiimDataset(Dataset):\n    def __init__(self, df, augment=None):\n        super().__init__()\n        self.df = df\n        self.augment = augment\n        self.length = len(df)\n\n    def __str__(self):\n        string  = ''\n        string += '\\tlen = %d\\n'%len(self)\n        string += '\\tdf  = %s\\n'%str(self.df.shape)\n\n        string += '\\tlabel distribution\\n'\n        for i in range(num_study_label):\n            n = self.df[study_label_to_name[i]].sum()\n            string += '\\t\\t %d %26s: %5d (%0.4f)\\n'%(i, study_label_to_name[i], n, n/len(self.df) )\n        return string\n\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, index):\n        d = self.df.iloc[index]\n\n        image_file = data_dir + '/test/%s.png' % (d.image_id)\n        image = cv2.imread(image_file,cv2.IMREAD_GRAYSCALE)\n        onehot = d[study_name_to_label.keys()].values\n\n        mask = np.zeros_like(image)\n\n\n        r = {\n            'index' : index,\n            'd' : d,\n            'image' : image,\n            'mask' : mask,\n            'onehot' : onehot,\n        }\n        if self.augment is not None: r = self.augment(r)\n        return r\n\ndef null_collate(batch):\n    collate = defaultdict(list)\n\n    for r in batch:\n        for k, v in r.items():\n            collate[k].append(v)\n\n    # ---\n    batch_size = len(batch)\n    onehot = np.ascontiguousarray(np.stack(collate['onehot'])).astype(np.float32)\n    collate['onehot'] = torch.from_numpy(onehot)\n\n    image = np.stack(collate['image'])\n    image = image.reshape(batch_size, 1, image_size,image_size).repeat(3,1)\n    image = np.ascontiguousarray(image)\n    image = image.astype(np.float32) / 255\n    collate['image'] = torch.from_numpy(image)\n\n\n    mask = np.stack(collate['mask'])\n    mask = mask.reshape(batch_size, 1, image_size,image_size)\n    mask = np.ascontiguousarray(mask)\n    mask = mask.astype(np.float32) / 255\n    collate['mask'] = torch.from_numpy(mask)\n\n    return collate","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.697449Z","iopub.execute_input":"2021-08-07T08:21:52.699035Z","iopub.status.idle":"2021-08-07T08:21:52.715569Z","shell.execute_reply.started":"2021-08-07T08:21:52.699005Z","shell.execute_reply":"2021-08-07T08:21:52.714608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        e = efficientnet_b3a(pretrained=False, drop_rate=0.3, drop_path_rate=0.2)\n        self.b0 = nn.Sequential(\n            e.conv_stem,\n            e.bn1,\n            e.act1,\n        )\n        self.b1 = e.blocks[0]\n        self.b2 = e.blocks[1]\n        self.b3 = e.blocks[2]\n        self.b4 = e.blocks[3]\n        self.b5 = e.blocks[4]\n        self.b6 = e.blocks[5]\n        self.b7 = e.blocks[6]\n        self.b8 = nn.Sequential(\n            e.conv_head, #384, 1536\n            e.bn2,\n            e.act2,\n        )\n\n        self.logit = nn.Linear(1536,num_study_label)\n        self.mask = nn.Sequential(\n            nn.Conv2d(136, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n        )\n\n\n    # @torch.cuda.amp.autocast()\n    def forward(self, image):\n        batch_size = len(image)\n        x = 2*image-1     # ; print('input ',   x.shape)\n\n        x = self.b0(x) #; print (x.shape)  # torch.Size([2, 40, 256, 256])\n        x = self.b1(x) #; print (x.shape)  # torch.Size([2, 24, 256, 256])\n        x = self.b2(x) #; print (x.shape)  # torch.Size([2, 32, 128, 128])\n        x = self.b3(x) #; print (x.shape)  # torch.Size([2, 48, 64, 64])\n        x = self.b4(x) #; print (x.shape)  # torch.Size([2, 96, 32, 32])\n        x = self.b5(x) #; print (x.shape)  # torch.Size([2, 136, 32, 32])\n        #------------\n        mask = self.mask(x)\n        #-------------\n        x = self.b6(x) #; print (x.shape)  # torch.Size([2, 232, 16, 16])\n        x = self.b7(x) #; print (x.shape)  # torch.Size([2, 384, 16, 16])\n        x = self.b8(x) #; print (x.shape)  # torch.Size([2, 1536, 16, 16])\n        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n        #x = F.dropout(x, 0.5, training=self.training)\n        logit = self.logit(x)\n        return logit, mask","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.717266Z","iopub.execute_input":"2021-08-07T08:21:52.717903Z","iopub.status.idle":"2021-08-07T08:21:52.733188Z","shell.execute_reply.started":"2021-08-07T08:21:52.717811Z","shell.execute_reply":"2021-08-07T08:21:52.732376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NetV2(nn.Module):\n    def __init__(self):\n        super(NetV2, self).__init__()\n\n        #e = efficientnet_b3a(pretrained=True, drop_rate=0.3, drop_path_rate=0.2)\n        #e = efficientnetv2_rw_m(pretrained=True, drop_rate=0.5, drop_path_rate=0.2)\n        #e = tf_efficientnetv2_m_in21ft1k(pretrained=True, drop_rate=0.3, drop_path_rate=0.2)\n        e = tf_efficientnetv2_m(pretrained=False, drop_path_rate=0.4)\n        \n        self.b0 = nn.Sequential(\n            e.conv_stem,\n            e.bn1,\n            e.act1,\n        )\n        self.b1 = e.blocks[0]\n        self.b2 = e.blocks[1]\n        self.b3 = e.blocks[2]\n        self.b4 = e.blocks[3]\n        self.b5 = e.blocks[4]\n        self.b6 = e.blocks[5]\n        self.b7 = e.blocks[6]\n        self.b8 = nn.Sequential(\n            e.conv_head, #384, 1536\n            e.bn2,\n            e.act2,\n        )\n\n        self.logit = nn.Linear(1280,num_study_label)\n        self.mask = nn.Sequential(\n            nn.Conv2d(176, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n\n            #nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            #nn.BatchNorm2d(128),\n            #nn.ReLU(inplace=True),\n\n            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n        )\n\n\n    # @torch.cuda.amp.autocast()\n    def forward(self, image):\n        batch_size = len(image)\n        x = 2*image-1     # ; print('input ',   x.shape)\n        \"\"\"\n        rw_m\n        torch.Size([2, 32, 256, 256])\n        torch.Size([2, 32, 256, 256])\n        torch.Size([2, 56, 128, 128])\n        torch.Size([2, 80, 64, 64])\n        torch.Size([2, 152, 32, 32])\n        torch.Size([2, 192, 32, 32])\n        torch.Size([2, 328, 16, 16])\n        torch.Size([2, 2152, 16, 16])\n        \"\"\"\n        x = self.b0(x) ; #print (x.shape)  # torch.Size([2, 32, 256, 256])\n        x = self.b1(x) ; #print (x.shape)  # torch.Size([2, 32, 256, 256])\n        x = self.b2(x) ; #print (x.shape)  # torch.Size([2, 56, 128, 128])\n        x = self.b3(x) ; #print (x.shape)  # torch.Size([2, 80, 64, 64])\n        x = self.b4(x) ; #print (x.shape)  # torch.Size([2, 152, 32, 32])\n        x = self.b5(x) ; #print (x.shape)  # torch.Size([2, 192, 32, 32])\n\n        #------------\n        mask = self.mask(x)\n        #-------------\n\n        x = self.b6(x) ; #print (x.shape)  # torch.Size([2, 328, 16, 16])\n        \n        x = self.b7(x) ; #print (x.shape)  # torch.Size([2, 512, 16, 16])\n        \n        x = self.b8(x) ; #print (x.shape)  # torch.Size([2, 2152, 16, 16])\n        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n        x = F.dropout(x, 0.5, training=self.training)\n\n        logit = self.logit(x)\n        return logit, mask","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.736617Z","iopub.execute_input":"2021-08-07T08:21:52.736958Z","iopub.status.idle":"2021-08-07T08:21:52.751022Z","shell.execute_reply.started":"2021-08-07T08:21:52.736926Z","shell.execute_reply":"2021-08-07T08:21:52.750277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def probability_to_df_study(df_valid, probability):\n    df_study = pd.DataFrame()\n    df_image = df_valid.copy()\n    df_study.loc[:,'id'] = df_valid.study + '_study'\n    for i in range(num_study_label):\n        df_study.loc[:,study_name_to_predict_string[study_label_to_name[i]]]=probability[:,i]\n        df_image.loc[:,study_name_to_predict_string[study_label_to_name[i]]]=probability[:,i]\n    \n    \n    df_study = df_study.groupby('id', as_index=False).mean()\n    df_study.loc[:, 'PredictionString'] = \\\n           'negative '      + df_study.negative.apply(lambda x: '%0.6f'%x)      + ' 0 0 1 1' \\\n        + ' typical '       + df_study.typical.apply(lambda x: '%0.6f'%x)       + ' 0 0 1 1' \\\n        + ' indeterminate ' + df_study.indeterminate.apply(lambda x: '%0.6f'%x) + ' 0 0 1 1' \\\n        + ' atypical '      + df_study.atypical.apply(lambda x: '%0.6f'%x)      + ' 0 0 1 1'\n\n    df_study = df_study[['id','PredictionString']]\n    return df_study, df_image","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.753006Z","iopub.execute_input":"2021-08-07T08:21:52.753392Z","iopub.status.idle":"2021-08-07T08:21:52.762094Z","shell.execute_reply.started":"2021-08-07T08:21:52.753359Z","shell.execute_reply":"2021-08-07T08:21:52.7611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_predict(net, valid_loader, tta=['flip','scale']): #flip\n\n    valid_probability = []\n    valid_num = 0\n\n    start_timer = timer()\n    for t, batch in enumerate(valid_loader):\n        batch_size = len(batch['index'])\n        image  = batch['image'].cuda()\n        onehot = batch['onehot']\n        label  = onehot.argmax(-1)\n\n        #<todo> TTA\n        net.eval()\n        with torch.no_grad():\n            probability = []\n            logit, mask = net(image)\n            probability.append(F.softmax(logit,-1))\n\n            if 'flip' in tta:\n                logit, mask = net(torch.flip(image,dims=(3,)))\n                probability.append(F.softmax(logit,-1))\n\n            if 'scale' in tta:\n                # size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None):\n                logit, mask = net(F.interpolate(image, scale_factor=1.33, mode='bilinear', align_corners=False))\n                probability.append(F.softmax(logit,-1))\n\n            #--------------\n            probability = torch.stack(probability,0).mean(0)\n\n        valid_num += batch_size\n        valid_probability.append(probability.data.cpu().numpy())\n        print('\\r %8d / %d  %s' % (valid_num, len(valid_loader.dataset), time_to_str(timer() - start_timer, 'sec')),\n              end='', flush=True)\n\n    assert(valid_num == len(valid_loader.dataset))\n    print('')\n\n    probability = np.concatenate(valid_probability)\n    return probability","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.763401Z","iopub.execute_input":"2021-08-07T08:21:52.763826Z","iopub.status.idle":"2021-08-07T08:21:52.775269Z","shell.execute_reply.started":"2021-08-07T08:21:52.763778Z","shell.execute_reply":"2021-08-07T08:21:52.774249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Logger(object):\n    def __init__(self):\n        self.terminal = sys.stdout  #stdout\n        self.file = None\n\n    def open(self, file, mode=None):\n        if mode is None: mode ='w'\n        self.file = open(file, mode)\n\n    def write(self, message, is_terminal=1, is_file=1 ):\n        if '\\r' in message: is_file=0\n\n        if is_terminal == 1:\n            self.terminal.write(message)\n            self.terminal.flush()\n            #time.sleep(1)\n\n        if is_file == 1:\n            self.file.write(message)\n            self.file.flush()\n\n    def flush(self):\n        # this flush method is needed for python 3 compatibility.\n        # this handles the flush command by doing nothing.\n        # you might want to specify some extra behavior here.\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.777379Z","iopub.execute_input":"2021-08-07T08:21:52.778001Z","iopub.status.idle":"2021-08-07T08:21:52.78593Z","shell.execute_reply.started":"2021-08-07T08:21:52.777965Z","shell.execute_reply":"2021-08-07T08:21:52.785131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def time_to_str(t, mode='min'):\n    if mode=='min':\n        t  = int(t)/60\n        hr = t//60\n        min = t%60\n        return '%2d hr %02d min'%(hr,min)\n\n    elif mode=='sec':\n        t   = int(t)\n        min = t//60\n        sec = t%60\n        return '%2d min %02d sec'%(min,sec)\n\n    else:\n        raise NotImplementedError","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.787246Z","iopub.execute_input":"2021-08-07T08:21:52.787631Z","iopub.status.idle":"2021-08-07T08:21:52.797313Z","shell.execute_reply.started":"2021-08-07T08:21:52.787596Z","shell.execute_reply":"2021-08-07T08:21:52.796548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"netList = [Net, NetV2]\n\nif with_ensemble:\n    VersionList = [0 , 1]\nelse:\n    VersionList = [0]\n\ndef run_submit():\n    for fold in [0 ,1 ,2, 3, 4]:\n        out_dir = './study_predict/'\n        \n        initial_checkpoint_v1 = \\\n                _classify_model1_path + 'f' + str(fold) + '.pth'\n\n        # v2\n        initial_checkpoint_v2 = _classify_model2_path + 'effv2-m-f' + str(fold) + '.pth'\n           \n        initial_checkpoint = [initial_checkpoint_v1, initial_checkpoint_v2]  \n        \n        \n        for ver in VersionList:\n            \n\n            ## setup  ----------------------------------------\n            #mode = 'local'\n            mode = 'remote'\n\n            submit_dir = out_dir + 'v' + str(ver)+ '/%s-fold%d'%(mode, fold)\n            os.makedirs(submit_dir, exist_ok=True)\n        \n        \n\n            log = Logger()\n            log.open(out_dir + 'log.submit.txt', mode='a')\n            log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n            #log.write('\\t%s\\n' % COMMON_STRING)\n            log.write('\\n')\n\n            #\n            ## dataset ------------------------------------\n\n            df_valid = make_fold('test')\n\n            valid_dataset = SiimDataset(df_valid)\n            valid_loader  = DataLoader(\n                valid_dataset,\n                sampler = SequentialSampler(valid_dataset),\n                batch_size  = 32,#128, #\n                drop_last   = False,\n                num_workers = 8,\n                pin_memory  = True,\n                collate_fn  = null_collate,\n            )\n            log.write('mode : %s\\n'%(mode))\n            log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n\n            ## net -------------------------------------       \n            if 1:\n                #V2\n                net = netList[ver]().cuda()\n                net.load_state_dict(torch.load(initial_checkpoint[ver])['state_dict'], strict=True)\n\n                #---\n                start_timer = timer()\n                probability = do_predict(net, valid_loader)\n                log.write('time %s \\n' % time_to_str(timer() - start_timer, 'min'))\n                log.write('probability %s \\n' % str(probability.shape))\n\n                np.save(submit_dir+ '/probability.npy',probability)\n                df_valid.to_csv(submit_dir + '/df_valid.csv', index=False)\n\n            else:\n                probability = np.load(submit_dir + '/probability.npy')\n\n            #----\n            df_study, df_image = probability_to_df_study(df_valid, probability)\n\n            #df_image = probability_to_df_image(df_valid, None, None)\n            #df_submit = pd.concat([df_study,df_image])\n            df_submit = pd.concat([df_study])\n            df_submit.to_csv(submit_dir + '/submit.csv', index=False)\n\n            log.write('submit_dir : %s\\n' % (submit_dir))\n            log.write('initial_checkpoint : %s\\n' % (initial_checkpoint))\n            log.write('df_submit : %s\\n' % str(df_submit.shape))\n            log.write('%s\\n' % str(df_submit))\n            log.write('\\n')\n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:21:52.798657Z","iopub.execute_input":"2021-08-07T08:21:52.799065Z","iopub.status.idle":"2021-08-07T08:21:52.815944Z","shell.execute_reply.started":"2021-08-07T08:21:52.799028Z","shell.execute_reply":"2021-08-07T08:21:52.81497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDENTIFIER   = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\nif with_study:\n    run_submit()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-07T08:21:52.817733Z","iopub.execute_input":"2021-08-07T08:21:52.818069Z","iopub.status.idle":"2021-08-07T08:25:43.57119Z","shell.execute_reply.started":"2021-08-07T08:21:52.818041Z","shell.execute_reply":"2021-08-07T08:25:43.570289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_valid = make_fold('test')\n#df_valid","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:43.5727Z","iopub.execute_input":"2021-08-07T08:25:43.572976Z","iopub.status.idle":"2021-08-07T08:25:43.579977Z","shell.execute_reply.started":"2021-08-07T08:25:43.572946Z","shell.execute_reply":"2021-08-07T08:25:43.579106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_remote_ensemble():\n    out_dir = './study_predict/'\n    log = Logger()\n    log.open(out_dir + 'log.submit.txt', mode='a')\n    log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n    #log.write('\\t%s\\n' % COMMON_STRING)\n    log.write('\\n')\n\n\n    submit_dir=[\n        out_dir+'v0/remote-fold0',\n        out_dir+'v0/remote-fold1',\n        out_dir+'v0/remote-fold2',\n        out_dir+'v0/remote-fold3',\n        out_dir+'v0/remote-fold4'    \n    ]\n    \n    if with_ensemble:\n         submit_dir += [\n            out_dir+'v1/remote-fold0',\n            out_dir+'v1/remote-fold1',\n            out_dir+'v1/remote-fold2',\n            out_dir+'v1/remote-fold3',\n            out_dir+'v1/remote-fold4'\n         ] \n\n    probability=0\n    for d in submit_dir:\n        p = np.load(d + '/probability.npy')\n        probability += p**0.5\n    probability = probability/len(submit_dir)\n\n\n    #----\n    df_valid = pd.read_csv(submit_dir[0] + '/df_valid.csv')\n\n    df_study, df_image  = probability_to_df_study(df_valid, probability)\n    #df_image  = probability_to_df_image(df_valid, None, None)\n    #df_submit = pd.concat([df_study, df_image])\n    df_submit = pd.concat([df_study])\n    \n    #df_submit.to_csv(out_dir + '/effb3-full-512-mask-submit-ensemble1.csv', index=False)\n\n    log.write('submit_dir : %s\\n' % (submit_dir))\n    log.write('df_submit : %s\\n' % str(df_submit.shape))\n    log.write('%s\\n' % str(df_submit))\n    log.write('\\n')\n    \n    return df_submit, df_image","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:43.581232Z","iopub.execute_input":"2021-08-07T08:25:43.581737Z","iopub.status.idle":"2021-08-07T08:25:43.591949Z","shell.execute_reply.started":"2021-08-07T08:25:43.581695Z","shell.execute_reply":"2021-08-07T08:25:43.590926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDENTIFIER   = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\nif with_study:\n    predict_study, df_image = run_remote_ensemble()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:43.593332Z","iopub.execute_input":"2021-08-07T08:25:43.593689Z","iopub.status.idle":"2021-08-07T08:25:43.642808Z","shell.execute_reply.started":"2021-08-07T08:25:43.593653Z","shell.execute_reply":"2021-08-07T08:25:43.641925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda.select_device(0)\ncuda.close()\ncuda.select_device(0)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:43.644112Z","iopub.execute_input":"2021-08-07T08:25:43.644576Z","iopub.status.idle":"2021-08-07T08:25:44.703088Z","shell.execute_reply.started":"2021-08-07T08:25:43.64454Z","shell.execute_reply":"2021-08-07T08:25:44.702257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:44.704398Z","iopub.execute_input":"2021-08-07T08:25:44.704729Z","iopub.status.idle":"2021-08-07T08:25:44.719495Z","shell.execute_reply.started":"2021-08-07T08:25:44.704692Z","shell.execute_reply":"2021-08-07T08:25:44.71878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2class = meta_df.loc[meta_df.split == \"test\"].copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:44.720602Z","iopub.execute_input":"2021-08-07T08:25:44.720925Z","iopub.status.idle":"2021-08-07T08:25:44.72943Z","shell.execute_reply.started":"2021-08-07T08:25:44.720899Z","shell.execute_reply":"2021-08-07T08:25:44.728496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_paths = f'/kaggle/input/covid19512/test/' + df_2class['image_id'] +'.png'","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:44.730809Z","iopub.execute_input":"2021-08-07T08:25:44.731189Z","iopub.status.idle":"2021-08-07T08:25:44.735414Z","shell.execute_reply.started":"2021-08-07T08:25:44.731144Z","shell.execute_reply":"2021-08-07T08:25:44.7345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2class['none'] = 0","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:44.74001Z","iopub.execute_input":"2021-08-07T08:25:44.740341Z","iopub.status.idle":"2021-08-07T08:25:44.746477Z","shell.execute_reply.started":"2021-08-07T08:25:44.740304Z","shell.execute_reply":"2021-08-07T08:25:44.745712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#label_cols = df_2class.columns[5]\n#label_cols","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:44.748285Z","iopub.execute_input":"2021-08-07T08:25:44.748632Z","iopub.status.idle":"2021-08-07T08:25:44.755589Z","shell.execute_reply.started":"2021-08-07T08:25:44.748597Z","shell.execute_reply":"2021-08-07T08:25:44.754792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if with_2class:\n    df_2class['none'] = df_image['negative'].values\n    df_2class.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:44.756999Z","iopub.execute_input":"2021-08-07T08:25:44.757346Z","iopub.status.idle":"2021-08-07T08:25:44.765985Z","shell.execute_reply.started":"2021-08-07T08:25:44.757311Z","shell.execute_reply":"2021-08-07T08:25:44.765148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detect","metadata":{}},{"cell_type":"code","source":"shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\nos.chdir('/kaggle/working/yolov5')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:44.767148Z","iopub.execute_input":"2021-08-07T08:25:44.767557Z","iopub.status.idle":"2021-08-07T08:25:45.457984Z","shell.execute_reply.started":"2021-08-07T08:25:44.767522Z","shell.execute_reply":"2021-08-07T08:25:45.457119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = _det_model_path + \"yolom-f0.pt\" + \" \" + _det_model_path + \"yolom-f1.pt\" + \" \" + _det_model_path + \"yolom-f2.pt\" + \" \" + _det_model_path + \"yolom-f3.pt\" + \" \" + _det_model_path + \"yolom-f4.pt\"\n_yolox_path = \"/kaggle/input/covidmodels/yolox-v0/\"\n\n#MODEL_PATH = _yolox_path + \"f0.pt\" + \" \" + _yolox_path + \"f1.pt\" + \" \" + _yolox_path + \"f2.pt\" + \" \" + _yolox_path + \"f3.pt\" + \" \" + _yolox_path + \"f4.pt\"\n\nif with_ensemble:\n    MODEL_PATH += \" \" + _yolox_path + \"f0.pt\" + \" \" + _yolox_path + \"f1.pt\" + \" \" + _yolox_path + \"f2.pt\" + \" \" + _yolox_path + \"f3.pt\" + \" \" + _yolox_path + \"f4.pt\"","metadata":{"execution":{"iopub.status.busy":"2021-08-09T04:00:12.562057Z","iopub.execute_input":"2021-08-09T04:00:12.562801Z","iopub.status.idle":"2021-08-09T04:00:12.586552Z","shell.execute_reply.started":"2021-08-09T04:00:12.562684Z","shell.execute_reply":"2021-08-09T04:00:12.585526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if with_image:\n    if with_ensemble:\n        !python detect.py --weights {MODEL_PATH} \\\n                          --source {_test_files_path} \\\n                          --img {IMG_SIZE} \\\n                          --conf 0.0001 \\\n                          --iou-thres 0.5 \\\n                          --save-txt \\\n                          --save-conf \\\n                          --augment\n    else:\n        !python detect.py --weights {MODEL_PATH} \\\n                          --source {_test_files_path} \\\n                          --img {IMG_SIZE} \\\n                          --conf 0.001 \\\n                          --iou-thres 0.5 \\\n                          --save-txt \\\n                          --save-conf ","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:25:45.468617Z","iopub.execute_input":"2021-08-07T08:25:45.469182Z","iopub.status.idle":"2021-08-07T08:29:43.864376Z","shell.execute_reply.started":"2021-08-07T08:25:45.469135Z","shell.execute_reply":"2021-08-07T08:29:43.863421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if with_image:\n    def yolo2voc(image_height, image_width, bboxes):\n\n        bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n        bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n        bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n\n        bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n        bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n        return bboxes\n\n\n    image_ids = []\n    PredictionStrings = []\n\n    #for file_path in tqdm(glob('runs/detect/exp/labels/*.txt')):\n    for dir_path, _, filenames in os.walk(_test_files_path):\n            print(len(filenames))\n    for file in filenames:\n        file_path = 'runs/detect/exp/labels/' + file.replace(\".png\", '.txt')\n        image_id = file_path.split('/')[-1].split('.')[0]\n        w, h = meta_df.loc[meta_df.image_id == image_id,['dim1', 'dim0']].values[0]\n        if not os.path.exists(file_path):\n            bboxes = \"none 1 0 0 1 1\"\n        else:\n            f = open(file_path, 'r')\n            data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n            data = data[:, [0, 5, 1, 2, 3, 4]]\n            bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n            for idx in range(len(bboxes)):\n                bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n            bboxes = ' '.join(bboxes)\n        image_id += \"_image\"\n        image_ids.append(image_id)\n        PredictionStrings.append(bboxes)\n\n    predict_image = pd.DataFrame({'id':image_ids,\n                            'PredictionString':PredictionStrings})","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:29:43.867785Z","iopub.execute_input":"2021-08-07T08:29:43.868069Z","iopub.status.idle":"2021-08-07T08:29:46.47108Z","shell.execute_reply.started":"2021-08-07T08:29:43.86804Z","shell.execute_reply":"2021-08-07T08:29:46.470077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"if with_image:\n    for i in range(predict_image.shape[0]):\n        if predict_image.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n            continue\n        sub_df_split = predict_image.loc[i,'PredictionString'].split()\n        sub_df_list = []\n        for j in range(int(len(sub_df_split) / 6)):\n            sub_df_list.append('opacity')\n            sub_df_list.append(sub_df_split[6 * j + 1])\n            sub_df_list.append(sub_df_split[6 * j + 2])\n            sub_df_list.append(sub_df_split[6 * j + 3])\n            sub_df_list.append(sub_df_split[6 * j + 4])\n            sub_df_list.append(sub_df_split[6 * j + 5])\n        predict_image.loc[i,'PredictionString'] = ' '.join(sub_df_list)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:29:46.472493Z","iopub.execute_input":"2021-08-07T08:29:46.472956Z","iopub.status.idle":"2021-08-07T08:29:46.905871Z","shell.execute_reply.started":"2021-08-07T08:29:46.472908Z","shell.execute_reply":"2021-08-07T08:29:46.904842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if with_image and with_2class:\n    for i in range(predict_image.shape[0]):\n        if predict_image.loc[i,'PredictionString'] != 'none 1 0 0 1 1':\n            _none = str(df_2class.loc[df_2class.image_id + \"_image\" == predict_image.iloc[i].id]['none'].item())\n            predict_image.loc[i,'PredictionString'] = predict_image.loc[i,'PredictionString'] + ' none ' + _none + ' 0 0 1 1'","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:29:46.907515Z","iopub.execute_input":"2021-08-07T08:29:46.907936Z","iopub.status.idle":"2021-08-07T08:29:49.077997Z","shell.execute_reply.started":"2021-08-07T08:29:46.907894Z","shell.execute_reply":"2021-08-07T08:29:49.07705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if with_study:\n    for index, row in predict_study.iterrows():\n        submit_df.loc[submit_df.id == row.id, \"PredictionString\"] = row.PredictionString\n\nif with_image:\n    for index, row in predict_image.iterrows():\n        submit_df.loc[submit_df.id == row.id, \"PredictionString\"] = row.PredictionString","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:29:49.079329Z","iopub.execute_input":"2021-08-07T08:29:49.079695Z","iopub.status.idle":"2021-08-07T08:29:51.446849Z","shell.execute_reply.started":"2021-08-07T08:29:49.079657Z","shell.execute_reply":"2021-08-07T08:29:51.445918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df.to_csv('/kaggle/working/submission.csv',index = False)  ","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:29:51.448226Z","iopub.execute_input":"2021-08-07T08:29:51.448585Z","iopub.status.idle":"2021-08-07T08:29:51.53013Z","shell.execute_reply.started":"2021-08-07T08:29:51.448551Z","shell.execute_reply":"2021-08-07T08:29:51.529402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nsample = submit_df.iloc[-1]\nprint(sample.id, sample.PredictionString)\n\n_study = meta_df.loc[meta_df.image_id + \"_image\" == sample.id].study.item()\nprint(_study)\n_study_item = submit_df.loc[submit_df.id == _study + \"_study\"]\n_study_item\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:29:51.531329Z","iopub.execute_input":"2021-08-07T08:29:51.531625Z","iopub.status.idle":"2021-08-07T08:29:51.538266Z","shell.execute_reply.started":"2021-08-07T08:29:51.531597Z","shell.execute_reply":"2021-08-07T08:29:51.537253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if with_image:\n    shutil.rmtree('/kaggle/working/yolov5')\nif with_study:\n    shutil.rmtree('/kaggle/working/study_predict')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:29:51.539459Z","iopub.execute_input":"2021-08-07T08:29:51.540153Z","iopub.status.idle":"2021-08-07T08:29:51.668381Z","shell.execute_reply.started":"2021-08-07T08:29:51.540116Z","shell.execute_reply":"2021-08-07T08:29:51.66744Z"},"trusted":true},"execution_count":null,"outputs":[]}]}