{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# from __future__ import absolute_import\n# from __future__ import division\n# from __future__ import print_function\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# import tensorflow as tf\n# import os\n# import matplotlib.pyplot as plt\n# from tensorflow import keras \n# from keras.utils import to_categorical\n# import matplotlib.pyplot as plt\n# import sys\n# import cv2 as cv\n# from sklearn import model_selection\n# from tqdm import tqdm\n# import git \n# import pydicom\n# from keras import metrics\n# from tensorflow.keras.applications.xception import preprocess_input\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# tf.keras.backend.set_floatx('float16')\n# models = tf.keras.models\n# layers = tf.keras.layers\n# utils = tf.keras.utils\n# losses = tf.keras.losses\n# optimizers = tf.keras.optimizers \n# metrics = tf.keras.metrics\n# preprocessing_image = tf.keras.preprocessing.image\n# applications = tf.keras.applications\n\n# base_model = applications.Xception(include_top=True,\n#                                    weights = None,\n#                                    input_shape=(299,299,3),\n#                                    pooling='avg',\n#                                    classes = 4)\n\n# def L2M_regularizer(x):\n#     return (0.03 * tf.math.reduce_mean(x)) + (0.07*tf.reduce_sum(tf.square(x)))\n\n# #regularizer = tf.keras.regularizers.l2(l2=0.01)\n\n\n# for layer in base_model.layers:\n#     if (hasattr(layer,'activations'))==True:\n#          layer.activation = swish\n\n# for layer in base_model.layers:\n#     for attr in ['kernel_regularizer']:\n#         if hasattr(layer, attr):\n#             setattr(layer, attr, L2M_regularizer)\n#     for attr in ['bias_regularizer']:\n#         if hasattr(layer,attr):\n#             setattr(layer, attr, L2M_regularizer)\n#     for attr in ['activity_regularizer']:\n#         if hasattr(layer,attr):\n#             setattr(layer, attr, L2M_regularizer)\n\n# opt = keras.optimizers.Adam(learning_rate=2e-4, epsilon = 1e-7, amsgrad=True, clipnorm = 1)\n# met= ['categorical_accuracy']\n# l = keras.losses.CategoricalCrossentropy()\n# base_model.compile(loss = l, optimizer=opt, metrics = met)\n\n# base_model.summary()\n\n# BASE_DIR = \"/kaggle/input/notebook7e3db3ba5c/COVID_data/images\"\n\n# datagen = ImageDataGenerator(\n#     preprocessing_function = preprocess_input,\n#     validation_split = 0.1)\n\n# train_datagen = datagen.flow_from_directory(\n#     BASE_DIR,\n#     target_size = (299,299),\n#     subset = 'training'\n#     )\n# val_datagen = datagen.flow_from_directory(\n#     BASE_DIR,\n#     target_size = (299,299),\n#     subset = 'validation'\n#     )\n\n# history = base_model.fit(\n#     train_datagen,\n#     steps_per_epoch = 100,\n#     epochs=10,\n#     validation_data=val_datagen,\n#     validation_steps = 20)\n\n# base_model.save('/kaggle/working/')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-18T02:02:11.647721Z","iopub.execute_input":"2021-07-18T02:02:11.648038Z","iopub.status.idle":"2021-07-18T02:17:58.744534Z","shell.execute_reply.started":"2021-07-18T02:02:11.64801Z","shell.execute_reply":"2021-07-18T02:17:58.741272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-17T21:34:26.597709Z","iopub.execute_input":"2021-07-17T21:34:26.598058Z","iopub.status.idle":"2021-07-17T21:34:26.602692Z","shell.execute_reply.started":"2021-07-17T21:34:26.598028Z","shell.execute_reply":"2021-07-17T21:34:26.601447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pydicom\nfrom pydicom import dcmread\nimport pandas as pd\nimport numpy as np\n#import pylibjpeg\nfrom PIL import Image, ImageFont, ImageDraw, ImageEnhance\n#import gdcm\nimport vtk\nfrom vtk.util import numpy_support\nfrom vtk.util.numpy_support import vtk_to_numpy\nimport numpy\nimport cv2 as cv\nfrom matplotlib import pyplot as plt\n\nreader = vtk.vtkDICOMImageReader()\nOUTPUT_PATH = '/kaggle/working/'\nos.mkdir(os.path.join(OUTPUT_PATH, 'COVID_data'))\nos.mkdir(os.path.join(OUTPUT_PATH, 'COVID_data/images'))\nos.mkdir(os.path.join(OUTPUT_PATH, 'COVID_data/images/Negative for Pneumonia'))\nos.mkdir(os.path.join(OUTPUT_PATH, 'COVID_data/images/Typical Appearance'))\nos.mkdir(os.path.join(OUTPUT_PATH, 'COVID_data/images/Indeterminate Appearance'))\nos.mkdir(os.path.join(OUTPUT_PATH, 'COVID_data/images/Atypical Appearance'))\n\ndef process_data(f_name, img_array, o_class):\n    cv.imwrite(os.path.join('/kaggle/working/COVID_data/', f\"images/{o_class}/{f_name}.png\"), img_array)\n    return\n\ndef get_img(path):\n    reader.SetFileName(path)\n    reader.Update()\n    im = reader.GetOutput()\n    nx, ny, nz= im.GetDimensions()\n    pointData = im.GetPointData()\n    arrayData = pointData.GetAbstractArray(0)\n    ArrayDicom = np.rot90(vtk_to_numpy(arrayData).reshape((nx, ny, nz), order = 'F'))\n    cl1 = cv.convertScaleAbs(ArrayDicom, alpha=(255.0/65535.0))\n    cl1 = cv.resize(cl1, (299, 299))\n#     cl1 = cv.GaussianBlur(cl1,(5,5),0)\n#     cl1 = cv.Laplacian(cl1,cv.CV_16S, 3)\n#     kernel = np.array([[0.0, -1.0, 0.0], [-1.0, 5.0, -1.0],[0.0, -1.0, 0.0]]) high pass filter\n#     kernel = kernel/(np.sum(kernel) if np.sum(kernel)!=0 else 1)\n#     cl1= cv.filter2D(cl1,-1,kernel)\n#     cl1 = cv.convertScaleAbs(cl1)\n    table = np.array([((i / 255.0) ** (1/3)) * 255 #gamma correction\n        for i in np.arange(0, 256)]).astype(\"uint8\")\n    cl1 = cv.LUT(cl1, table)\n    clahe = cv.createCLAHE(clipLimit=255.0, tileGridSize=(3,3))\n    cl1 = clahe.apply(cl1)\n    cl1 = cv.merge([cl1,cl1,cl1])\n    cl1 = ~cl1\n    #hist_full = cv.calcHist([cl1],[0],None,[256],[0,256])\n    plt.imshow(cl1)\n    #plt.xlim([0,256])\n    plt.show()\n    return cl1\n    \n\nclassifier_metadata = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv')\nfor dirname, _, filenames in os.walk('/kaggle/input/siim-covid19-detection/train/'):\n    for filename in filenames:\n        study = [x for x in os.path.join(dirname, filename).split('/')]\n        study = study[5]+'_study'\n        row = classifier_metadata[classifier_metadata['id'] == study]\n        if row['Negative for Pneumonia'].item() == 1: \n            study = 'Negative for Pneumonia'\n        elif row['Typical Appearance'].item() == 1: \n            study = 'Typical Appearance'\n        elif row['Indeterminate Appearance'].item() == 1: \n            study = 'Indeterminate Appearance'\n        elif row['Atypical Appearance'].item() == 1: \n            study = 'Atypical Appearance'\n        process_data(filename, get_img(os.path.join(dirname, filename)), study)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T03:19:30.454244Z","iopub.execute_input":"2021-07-18T03:19:30.454604Z","iopub.status.idle":"2021-07-18T03:20:10.313029Z","shell.execute_reply.started":"2021-07-18T03:19:30.454554Z","shell.execute_reply":"2021-07-18T03:20:10.310266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}