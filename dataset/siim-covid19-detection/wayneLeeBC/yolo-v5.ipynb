{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd ../\n!mkdir tmp\n%cd tmp","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T11:41:57.92828Z","iopub.execute_input":"2022-05-04T11:41:57.928927Z","iopub.status.idle":"2022-05-04T11:41:58.731564Z","shell.execute_reply.started":"2022-05-04T11:41:57.928823Z","shell.execute_reply":"2022-05-04T11:41:58.730294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download YOLOv5\n!git clone https://github.com/ultralytics/yolov5 # clone repo\n%cd yolov5\n# Install dependencies requirements.txt 是用來表達你具體的環境是如何。\n%pip install -qr requirements.txt  # install dependencies\n\n%cd ../\n#pytorch\nimport torch\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:41:58.733855Z","iopub.execute_input":"2022-05-04T11:41:58.734313Z","iopub.status.idle":"2022-05-04T11:42:17.663816Z","shell.execute_reply.started":"2022-05-04T11:41:58.734266Z","shell.execute_reply":"2022-05-04T11:42:17.662491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Install W&B \n!pip install -q --upgrade wandb\n# Login 登入wandb\nimport wandb\n!wandb login 2475fd7c9b2de3f6cc173a97474a8ab98233627c\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:17.665525Z","iopub.execute_input":"2022-05-04T11:42:17.666593Z","iopub.status.idle":"2022-05-04T11:42:17.675959Z","shell.execute_reply.started":"2022-05-04T11:42:17.666536Z","shell.execute_reply":"2022-05-04T11:42:17.674838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Necessary/extra dependencies. \nimport os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n#customize iPython writefile so we can write variables自定義 iPython 寫入文件，以便我們可以寫入變量\nfrom IPython.core.magic import register_line_cell_magic\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:17.680466Z","iopub.execute_input":"2022-05-04T11:42:17.681202Z","iopub.status.idle":"2022-05-04T11:42:19.11124Z","shell.execute_reply.started":"2022-05-04T11:42:17.681154Z","shell.execute_reply":"2022-05-04T11:42:19.110437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparameters超參數\nTRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'\n#圖片大小\nIMG_SIZE = 256\n#每批資料量\nBATCH_SIZE = 16\n#迭代次數(全部資料過train算1)\nEPOCHS = 10","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:19.112382Z","iopub.execute_input":"2022-05-04T11:42:19.112779Z","iopub.status.idle":"2022-05-04T11:42:19.117428Z","shell.execute_reply.started":"2022-05-04T11:42:19.112726Z","shell.execute_reply":"2022-05-04T11:42:19.116178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Everything is done from /kaggle directory.\n%cd ../\n\n# Load image level csv file載入檔案\ndf = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')\n\n# Modify values in the id column分割ID列的ID與image\ndf['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)#axis是column\n# Add absolute path新增一列path\ndf['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)\n# Get image level labels新增一列image_level\ndf['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)#[0]取分割的第一個\n#顯示前五個資料\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:19.118599Z","iopub.execute_input":"2022-05-04T11:42:19.119821Z","iopub.status.idle":"2022-05-04T11:42:19.574495Z","shell.execute_reply.started":"2022-05-04T11:42:19.119779Z","shell.execute_reply":"2022-05-04T11:42:19.573378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load meta.csv file 載入meta.csv\n# Original dimensions are required to scale the bounding box coordinates appropriately.\nmeta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')\ntrain_meta_df = meta_df.loc[meta_df.split == 'train']#提出有train標籤的資料\ntrain_meta_df = train_meta_df.drop('split', axis=1)#刪除整個column的split\ntrain_meta_df.columns = ['id', 'dim0', 'dim1']#把頭三行改成'id', 'dim0', 'dim1'\n\ntrain_meta_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:19.57597Z","iopub.execute_input":"2022-05-04T11:42:19.576204Z","iopub.status.idle":"2022-05-04T11:42:19.621369Z","shell.execute_reply.started":"2022-05-04T11:42:19.576175Z","shell.execute_reply":"2022-05-04T11:42:19.620165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge both the dataframes組合兩個檔案成一個檔案\ndf = df.merge(train_meta_df, on='id',how=\"left\")#依照id組合(df第一個datafile，train_meta_df第二個datafile)，left:資料庫LEFT OUTER JOIN\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:19.622997Z","iopub.execute_input":"2022-05-04T11:42:19.624489Z","iopub.status.idle":"2022-05-04T11:42:19.65769Z","shell.execute_reply.started":"2022-05-04T11:42:19.624431Z","shell.execute_reply":"2022-05-04T11:42:19.656778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create train and validation split建立與拆分訓練和驗證集\ntrain_df, valid_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df.image_level.values)#stratify依照檔案分成設定比例\n\ntrain_df.loc[:, 'split'] = 'train'#多設一行標籤為train(loc:用index的標籤來取出資料)\nvalid_df.loc[:, 'split'] = 'valid'#多設一行標籤為valid\n\ndf = pd.concat([train_df, valid_df]).reset_index(drop=True)#組合兩個表 reset index=頭疼\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:19.659011Z","iopub.execute_input":"2022-05-04T11:42:19.659351Z","iopub.status.idle":"2022-05-04T11:42:19.709113Z","shell.execute_reply.started":"2022-05-04T11:42:19.659307Z","shell.execute_reply":"2022-05-04T11:42:19.707644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#顯示train和test個數\nprint(f'Size of dataset: {len(df)}, training images: {len(train_df)}. validation images: {len(valid_df)}')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:19.713605Z","iopub.execute_input":"2022-05-04T11:42:19.714319Z","iopub.status.idle":"2022-05-04T11:42:19.720319Z","shell.execute_reply.started":"2022-05-04T11:42:19.714273Z","shell.execute_reply":"2022-05-04T11:42:19.719057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('tmp/covid/images/train', exist_ok=True)#在images底下建立train和valid資料夾\nos.makedirs('tmp/covid/images/valid', exist_ok=True)\n\nos.makedirs('tmp/covid/labels/train', exist_ok=True)#在labels底下建立train和valid資料夾\nos.makedirs('tmp/covid/labels/valid', exist_ok=True)\n\n! ls tmp/covid/images","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:19.72235Z","iopub.execute_input":"2022-05-04T11:42:19.722962Z","iopub.status.idle":"2022-05-04T11:42:20.500306Z","shell.execute_reply.started":"2022-05-04T11:42:19.722891Z","shell.execute_reply":"2022-05-04T11:42:20.499319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Move the images to relevant split folder.把圖像依照剛剛合併的excel檔標籤train or valid分類到兩個資料夾下\nfor i in tqdm(range(len(df))):\n    row = df.loc[i]\n    if row.split == 'train':\n        copyfile(row.path, f'tmp/covid/images/train/{row.id}.jpg')\n    else:\n        copyfile(row.path, f'tmp/covid/images/valid/{row.id}.jpg')\ndf.head()\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:20.502107Z","iopub.execute_input":"2022-05-04T11:42:20.502481Z","iopub.status.idle":"2022-05-04T11:42:20.509921Z","shell.execute_reply.started":"2022-05-04T11:42:20.502436Z","shell.execute_reply":"2022-05-04T11:42:20.509242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create .yaml file建立.yaml檔\nimport yaml\n#dict是key and value\ndata_yaml = dict(\n    train = '../covid/images/train',\n    val = '../covid/images/valid',\n    nc = 2,#兩個類別\n    names = ['none', 'opacity']#類別分別叫none，opacity\n)\n\n# Note that I am creating the file in the yolov5/data/ directory.建立\"tmp/yolov5/data/data.yaml\"\n# 打開檔案w是覆寫\nwith open('tmp/yolov5/data/data.yaml', 'w') as outfile:\n    #dump轉成str寫入json檔\n    yaml.dump(data_yaml, outfile, default_flow_style=True)\n    \n#cat 輸出檔案內容\n%cat tmp/yolov5/data/data.yaml","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:20.510909Z","iopub.execute_input":"2022-05-04T11:42:20.511139Z","iopub.status.idle":"2022-05-04T11:42:21.307484Z","shell.execute_reply.started":"2022-05-04T11:42:20.511111Z","shell.execute_reply":"2022-05-04T11:42:21.306525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the raw bounding box by parsing the row value of the label column.從excel得到bbox值\n# Ref: https://www.kaggle.com/yujiariyasu/plot-3positive-classes\ndef get_bbox(row):\n    bboxes = []\n    bbox = []\n    #用enumerate取的i是list的索引值，這個for只取label裡的opacity(none)和1\n    for i, l in enumerate(row.label.split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            #contunue跳過本次的for迴圈\n            continue\n        #把x y w h放入bbox\n        bbox.append(float(l))\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []  \n            \n    return bboxes\n\n# Scale the bounding boxes according to the size of the resized image.設置bbox在256size下的新值\ndef scale_bbox(row, bboxes):\n    # Get scaling factor IMG_SIZE=256\n    scale_x = IMG_SIZE/row.dim1\n    scale_y = IMG_SIZE/row.dim0\n    \n    scaled_bboxes = []\n    for bbox in bboxes:\n        x = int(np.round(bbox[0]*scale_x, 4))\n        y = int(np.round(bbox[1]*scale_y, 4))\n        x1 = int(np.round(bbox[2]*(scale_x), 4))\n        y1= int(np.round(bbox[3]*scale_y, 4))\n        \n        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n        \n    return scaled_bboxes\n\n# Convert the bounding boxes in YOLO format.bbox轉成yolo格式\ndef get_yolo_format_bbox(img_w, img_h, bboxes):\n    yolo_boxes = []\n    for bbox in bboxes:\n        w = bbox[2] - bbox[0] # xmax - xmin\n        h = bbox[3] - bbox[1] # ymax - ymin\n        xc = bbox[0] + int(np.round(w/2)) # xmin + width/2\n        yc = bbox[1] + int(np.round(h/2)) # ymin + height/2\n        \n        yolo_boxes.append([xc/img_w, yc/img_h, w/img_w, h/img_h]) # x_center y_center width height\n    return yolo_boxes","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:21.310274Z","iopub.execute_input":"2022-05-04T11:42:21.311011Z","iopub.status.idle":"2022-05-04T11:42:21.326551Z","shell.execute_reply.started":"2022-05-04T11:42:21.310957Z","shell.execute_reply":"2022-05-04T11:42:21.325324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#test\nrow = df.loc[0]\nimg_id = row.id\nsplit = row.split\nlabel = row.image_level\nprint(\"img_id:\"+img_id,\"split:\"+split,\"label:\"+label)\nif label=='opacity':\n    # Get bboxes\n    bboxes = get_bbox(row)\n    # Scale bounding boxes\n    scale_bboxes = scale_bbox(row, bboxes)\n    # Format for YOLOv5\n    yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n\n''' \n'''\n# Prepare the txt files for bounding box準備bbox的txt檔\nfor i in tqdm(range(len(df))):#tqdm進度條\n    row = df.loc[i]\n    # Get image id\n    img_id = row.id\n    # Get split\n    split = row.split\n    # Get image-level label(opacity or none)\n    label = row.image_level\n    \n    if row.split=='train':\n        file_name = f'tmp/covid/labels/train/{row.id}.txt'\n    else:\n        file_name = f'tmp/covid/labels/valid/{row.id}.txt'\n        \n    \n    if label=='opacity':\n        # Get bboxes\n        bboxes = get_bbox(row)\n        # Scale bounding boxes\n        scale_bboxes = scale_bbox(row, bboxes)\n        # Format for YOLOv5\n        yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n        \n        with open(file_name, 'w') as f:\n            for bbox in yolo_bboxes:\n                bbox = [1]+bbox\n                bbox = [str(i) for i in bbox]\n                bbox = ' '.join(bbox)\n                f.write(bbox)\n                f.write('\\n')\n   '''","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:21.327816Z","iopub.execute_input":"2022-05-04T11:42:21.328732Z","iopub.status.idle":"2022-05-04T11:42:21.348873Z","shell.execute_reply.started":"2022-05-04T11:42:21.328683Z","shell.execute_reply":"2022-05-04T11:42:21.347591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd tmp/yolov5/","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:21.351101Z","iopub.execute_input":"2022-05-04T11:42:21.351831Z","iopub.status.idle":"2022-05-04T11:42:21.36688Z","shell.execute_reply.started":"2022-05-04T11:42:21.351777Z","shell.execute_reply":"2022-05-04T11:42:21.365404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n--img {IMG_SIZE} \\ # 輸入圖片大小\n--batch {BATCH_SIZE} \\ # 每批訓練數量\n--epochs {EPOCHS} \\ # 歷遍資料次數\n--data data.yaml \\ # 設定檔\n--weights yolov5s.pt \\ # 模組名稱\n--save_period 1\\ # 多久間隔後存檔\n--project kaggle-siim-covid # W&B project name\n\n\n!python train.py --img {IMG_SIZE} \\\n                 --batch {BATCH_SIZE} \\\n                 --epochs {EPOCHS} \\\n                 --data data.yaml \\\n                 --weights yolov5s.pt \\\n                 --project kaggle-siim-covid\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:21.369483Z","iopub.execute_input":"2022-05-04T11:42:21.370174Z","iopub.status.idle":"2022-05-04T11:42:21.388978Z","shell.execute_reply.started":"2022-05-04T11:42:21.370088Z","shell.execute_reply":"2022-05-04T11:42:21.387979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_PATH = '/kaggle/input/siim-covid19-resized-to-256px-jpg/test/'\nMODEL_PATH = '/kaggle/working/yolov5/kaggle-siim-covid/exp/weights/best.pt'","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:21.39072Z","iopub.execute_input":"2022-05-04T11:42:21.391252Z","iopub.status.idle":"2022-05-04T11:42:21.399352Z","shell.execute_reply.started":"2022-05-04T11:42:21.391206Z","shell.execute_reply":"2022-05-04T11:42:21.398659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"os.makedirs('/kaggle/working/yolov5/kaggle-siim-covid/exp/weights', exist_ok=True)\nimport shutil\nsrc=r\"/kaggle/input/mymodule/best.pt\"\ndes=r'/kaggle/working/yolov5/kaggle-siim-covid/exp/weights/best.pt'\nshutil.copy(src,des)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:21.400627Z","iopub.execute_input":"2022-05-04T11:42:21.401403Z","iopub.status.idle":"2022-05-04T11:42:21.887887Z","shell.execute_reply.started":"2022-05-04T11:42:21.40137Z","shell.execute_reply":"2022-05-04T11:42:21.886819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n--weights {MODEL_PATH} \\ # 模型路徑\n--source {TEST_PATH} \\ # 測試集的絕對路徑\n--img {IMG_SIZE} \\ # 圖片大小\n--conf 0.281 \\ # Confidence值的最低值 (預設0.25)\n--iou-thres 0.5 \\ # IOU最低值 (預設0.45)\n--max-det 3 \\ # 每張圖的檢測次數 (預設1000次) \n--save-txt \\ # 把bbox的座標存成txt檔\n--save-conf # 保存每個預測bbox的confidence值\n'''\n!python detect.py --weights {MODEL_PATH} \\\n                  --source {TEST_PATH} \\\n                  --img {IMG_SIZE} \\\n                  --conf 0.281 \\\n                  --iou-thres 0.5 \\\n                  --max-det 3 \\\n                  --save-txt \\\n                  --save-conf\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:42:21.889463Z","iopub.execute_input":"2022-05-04T11:42:21.889766Z","iopub.status.idle":"2022-05-04T11:43:56.71237Z","shell.execute_reply.started":"2022-05-04T11:42:21.889717Z","shell.execute_reply":"2022-05-04T11:43:56.711169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#bbox的座標的txt檔位置\nPRED_PATH = 'runs/detect/exp/labels'\n!ls {PRED_PATH}\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:44:40.14605Z","iopub.execute_input":"2022-05-04T11:44:40.146402Z","iopub.status.idle":"2022-05-04T11:44:40.910723Z","shell.execute_reply.started":"2022-05-04T11:44:40.146369Z","shell.execute_reply":"2022-05-04T11:44:40.909041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Visualize predicted coordinates.\n%cat runs/detect/exp/labels/ba91d37ee459.txt\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:44:52.65506Z","iopub.execute_input":"2022-05-04T11:44:52.655375Z","iopub.status.idle":"2022-05-04T11:44:53.412939Z","shell.execute_reply.started":"2022-05-04T11:44:52.655345Z","shell.execute_reply":"2022-05-04T11:44:53.41184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#列出txt檔裡的檔案(裡面全都是不透明的預測)\nprediction_files = os.listdir(PRED_PATH)\nprint('Number of test images predicted as opaque: ', len(prediction_files))\n\n\n\n#最後不透明度數量有774張\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:44:54.53312Z","iopub.execute_input":"2022-05-04T11:44:54.53408Z","iopub.status.idle":"2022-05-04T11:44:54.540468Z","shell.execute_reply.started":"2022-05-04T11:44:54.534017Z","shell.execute_reply":"2022-05-04T11:44:54.539817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The submisison requires xmin, ymin, xmax, ymax format. \n# YOLOv5 returns x_center, y_center, width, height\ndef correct_bbox_format(bboxes):\n    correct_bboxes = []\n    for b in bboxes:\n        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n\n        xmin = xc - int(np.round(w/2))\n        xmax = xc + int(np.round(w/2))\n        ymin = yc - int(np.round(h/2))\n        ymax = yc + int(np.round(h/2))\n        \n        correct_bboxes.append([xmin, xmax, ymin, ymax])\n        \n    return correct_bboxes\n\n# Read the txt file generated by YOLOv5 during inference and extract \n# confidence and bounding box coordinates.\ndef get_conf_bboxes(file_path):\n    confidence = []\n    bboxes = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            preds = line.strip('\\n').split(' ')\n            preds = list(map(float, preds))\n            confidence.append(preds[-1])\n            bboxes.append(preds[1:-1])\n    return confidence, bboxes","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:45:00.29315Z","iopub.execute_input":"2022-05-04T11:45:00.293747Z","iopub.status.idle":"2022-05-04T11:45:00.303743Z","shell.execute_reply.started":"2022-05-04T11:45:00.293707Z","shell.execute_reply":"2022-05-04T11:45:00.303086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the submisison file\nsub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\nsub_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:45:01.579937Z","iopub.execute_input":"2022-05-04T11:45:01.580663Z","iopub.status.idle":"2022-05-04T11:45:01.610777Z","shell.execute_reply.started":"2022-05-04T11:45:01.580595Z","shell.execute_reply":"2022-05-04T11:45:01.609467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction loop for submission\npredictions = []\n\nfor i in tqdm(range(len(sub_df))):\n    row = sub_df.loc[i]\n    id_name = row.id.split('_')[0]\n    id_level = row.id.split('_')[-1]\n    \n    if id_level == 'study':\n        # do study-level classification\n        predictions.append(\"Negative 1 0 0 1 1\") # dummy prediction\n        \n    elif id_level == 'image':\n        # we can do image-level classification here.\n        # also we can rely on the object detector's classification head.\n        # for this example submisison we will use YOLO's classification head. \n        # since we already ran the inference we know which test images belong to opacity.\n        if f'{id_name}.txt' in prediction_files:\n            # opacity label\n            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}/{id_name}.txt')\n            bboxes = correct_bbox_format(bboxes)\n            pred_string = ''\n            for j, conf in enumerate(confidence):\n                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n            predictions.append(pred_string[:-1]) \n        else:\n            predictions.append(\"None 1 0 0 1 1\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:45:03.297326Z","iopub.execute_input":"2022-05-04T11:45:03.297813Z","iopub.status.idle":"2022-05-04T11:45:03.783052Z","shell.execute_reply.started":"2022-05-04T11:45:03.297747Z","shell.execute_reply":"2022-05-04T11:45:03.781931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['PredictionString'] = predictions\nsub_df.to_csv('submission.csv', index=False)\nfile=f'submission.csv'\ndestination=f'/kaggle/working'\nshutil.copy(file,destination)\nsub_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:45:06.324532Z","iopub.execute_input":"2022-05-04T11:45:06.324914Z","iopub.status.idle":"2022-05-04T11:45:06.353155Z","shell.execute_reply.started":"2022-05-04T11:45:06.324874Z","shell.execute_reply":"2022-05-04T11:45:06.352052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The submisison requires xmin, ymin, xmax, ymax format. \n# YOLOv5 returns x_center, y_center, width, height\ndef correct_bbox_format(bboxes):\n    correct_bboxes = []\n    for b in bboxes:\n        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n\n        xmin = xc - int(np.round(w/2))\n        xmax = xc + int(np.round(w/2))\n        ymin = yc - int(np.round(h/2))\n        ymax = yc + int(np.round(h/2))\n        \n        correct_bboxes.append([xmin, xmax, ymin, ymax])\n        \n    return correct_bboxes\n\n# Read the txt file generated by YOLOv5 during inference and extract \n# confidence and bounding box coordinates.\ndef get_conf_bboxes(file_path):\n    confidence = []\n    bboxes = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            preds = line.strip('\\n').split(' ')\n            preds = list(map(float, preds))\n            confidence.append(preds[-1])\n            bboxes.append(preds[1:-1])\n    return confidence, bboxes","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:45:07.834655Z","iopub.execute_input":"2022-05-04T11:45:07.835007Z","iopub.status.idle":"2022-05-04T11:45:07.847297Z","shell.execute_reply.started":"2022-05-04T11:45:07.834973Z","shell.execute_reply":"2022-05-04T11:45:07.846119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the submisison file\nsub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\nsub_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:45:10.104408Z","iopub.execute_input":"2022-05-04T11:45:10.104727Z","iopub.status.idle":"2022-05-04T11:45:10.121181Z","shell.execute_reply.started":"2022-05-04T11:45:10.104692Z","shell.execute_reply":"2022-05-04T11:45:10.120338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction loop for submission\npredictions = []\n\nfor i in tqdm(range(len(sub_df))):\n    row = sub_df.loc[i]\n    id_name = row.id.split('_')[0]\n    id_level = row.id.split('_')[-1]\n    \n    if id_level == 'study':\n        # do study-level classification\n        predictions.append(\"Negative 1 0 0 1 1\") # dummy prediction\n        \n    elif id_level == 'image':\n        # we can do image-level classification here.\n        # also we can rely on the object detector's classification head.\n        # for this example submisison we will use YOLO's classification head. \n        # since we already ran the inference we know which test images belong to opacity.\n        if f'{id_name}.txt' in prediction_files:\n            # opacity label\n            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}/{id_name}.txt')\n            bboxes = correct_bbox_format(bboxes)\n            pred_string = ''\n            for j, conf in enumerate(confidence):\n                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n            predictions.append(pred_string[:-1]) \n        else:\n            predictions.append(\"None 1 0 0 1 1\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:45:11.531439Z","iopub.execute_input":"2022-05-04T11:45:11.532278Z","iopub.status.idle":"2022-05-04T11:45:12.003038Z","shell.execute_reply.started":"2022-05-04T11:45:11.53224Z","shell.execute_reply":"2022-05-04T11:45:12.001876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['PredictionString'] = predictions\nsub_df.to_csv('submission.csv', index=False)\nsub_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T11:45:14.135534Z","iopub.execute_input":"2022-05-04T11:45:14.136195Z","iopub.status.idle":"2022-05-04T11:45:14.160738Z","shell.execute_reply.started":"2022-05-04T11:45:14.136158Z","shell.execute_reply":"2022-05-04T11:45:14.159776Z"},"trusted":true},"execution_count":null,"outputs":[]}]}