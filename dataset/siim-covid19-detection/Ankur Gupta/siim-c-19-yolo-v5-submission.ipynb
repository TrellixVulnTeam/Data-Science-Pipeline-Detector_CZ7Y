{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:04:09.276966Z","iopub.execute_input":"2021-08-10T06:04:09.277352Z","iopub.status.idle":"2021-08-10T06:04:56.613015Z","shell.execute_reply.started":"2021-08-10T06:04:09.277311Z","shell.execute_reply":"2021-08-10T06:04:56.612053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Necessary/extra dependencies. \nimport os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n#! conda install -c conda-forge gdcm -y\n#! conda install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg\n#! conda install pillow\n#customize iPython writefile so we can write variables\nfrom IPython.core.magic import register_line_cell_magic\n\n\nimport pylab\n#import pillow\n#import gdcm\n#pydicom\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom fastai.imports import *\n#from fastai.medical.imaging import *\nfrom PIL import Image\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))\n        \nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-10T06:04:56.614718Z","iopub.execute_input":"2021-08-10T06:04:56.615068Z","iopub.status.idle":"2021-08-10T06:04:57.093714Z","shell.execute_reply.started":"2021-08-10T06:04:56.615028Z","shell.execute_reply":"2021-08-10T06:04:57.092841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:04:57.09555Z","iopub.execute_input":"2021-08-10T06:04:57.09587Z","iopub.status.idle":"2021-08-10T06:04:57.539479Z","shell.execute_reply.started":"2021-08-10T06:04:57.095842Z","shell.execute_reply":"2021-08-10T06:04:57.538583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read Files","metadata":{}},{"cell_type":"code","source":"# Read the submisison file\nsub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\nprint(len(sub_df))\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:04:57.54112Z","iopub.execute_input":"2021-08-10T06:04:57.541491Z","iopub.status.idle":"2021-08-10T06:04:57.56358Z","shell.execute_reply.started":"2021-08-10T06:04:57.541453Z","shell.execute_reply":"2021-08-10T06:04:57.562634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_df = sub_df.loc[sub_df.id.str.contains('_study')]\nlen(study_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:04:57.564944Z","iopub.execute_input":"2021-08-10T06:04:57.565328Z","iopub.status.idle":"2021-08-10T06:04:57.575413Z","shell.execute_reply.started":"2021-08-10T06:04:57.565292Z","shell.execute_reply":"2021-08-10T06:04:57.574508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_df = sub_df.loc[sub_df.id.str.contains('_study')]\nlen(study_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:04:57.576914Z","iopub.execute_input":"2021-08-10T06:04:57.577335Z","iopub.status.idle":"2021-08-10T06:04:57.586699Z","shell.execute_reply.started":"2021-08-10T06:04:57.5773Z","shell.execute_reply":"2021-08-10T06:04:57.58564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df = sub_df.loc[sub_df.id.str.contains('_image')]\nlen(image_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:04:57.588183Z","iopub.execute_input":"2021-08-10T06:04:57.588693Z","iopub.status.idle":"2021-08-10T06:04:57.596912Z","shell.execute_reply.started":"2021-08-10T06:04:57.588647Z","shell.execute_reply":"2021-08-10T06:04:57.595854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\ndef resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:04:57.60064Z","iopub.execute_input":"2021-08-10T06:04:57.601187Z","iopub.status.idle":"2021-08-10T06:04:57.60949Z","shell.execute_reply.started":"2021-08-10T06:04:57.60115Z","shell.execute_reply":"2021-08-10T06:04:57.608357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nIMG_SIZE = 256\nTEST_PATH = f'/kaggle/tmp/test/'\n\ndef prepare_test_images():\n    image_id = []\n    dim0 = []\n    dim1 = []\n\n    os.makedirs(TEST_PATH, exist_ok=True)\n\n    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/test')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize_xray(xray, size=IMG_SIZE)  \n            im.save(os.path.join(TEST_PATH, file.replace('dcm', 'png')))\n\n            image_id.append(file.replace('.dcm', ''))\n            dim0.append(xray.shape[0])\n            dim1.append(xray.shape[1])\n            \n    return image_id, dim0, dim1","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:04:57.611829Z","iopub.execute_input":"2021-08-10T06:04:57.612229Z","iopub.status.idle":"2021-08-10T06:04:57.620938Z","shell.execute_reply.started":"2021-08-10T06:04:57.612195Z","shell.execute_reply":"2021-08-10T06:04:57.620019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids, dim0, dim1 = prepare_test_images()\nprint(f'Number of test images: {len(os.listdir(TEST_PATH))}')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:04:57.622548Z","iopub.execute_input":"2021-08-10T06:04:57.622993Z","iopub.status.idle":"2021-08-10T06:11:50.254579Z","shell.execute_reply.started":"2021-08-10T06:04:57.622957Z","shell.execute_reply":"2021-08-10T06:11:50.251887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls '../input/yolo-model-train-weight/weights'","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:11:50.255888Z","iopub.execute_input":"2021-08-10T06:11:50.256233Z","iopub.status.idle":"2021-08-10T06:11:50.997693Z","shell.execute_reply.started":"2021-08-10T06:11:50.256196Z","shell.execute_reply":"2021-08-10T06:11:50.996796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_dir = '../input/yolo-model-train-weight/weights/best.pt'","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:11:51.000798Z","iopub.execute_input":"2021-08-10T06:11:51.001067Z","iopub.status.idle":"2021-08-10T06:11:51.005306Z","shell.execute_reply.started":"2021-08-10T06:11:51.001036Z","shell.execute_reply":"2021-08-10T06:11:51.004232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Run Detection","metadata":{}},{"cell_type":"markdown","source":"# Meta Files","metadata":{}},{"cell_type":"code","source":"# meta_df=pd.read_csv('/kaggle/input/siim-covid19-resized-to-256px-jpg/meta.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:11:51.00693Z","iopub.execute_input":"2021-08-10T06:11:51.007745Z","iopub.status.idle":"2021-08-10T06:11:51.012938Z","shell.execute_reply.started":"2021-08-10T06:11:51.007707Z","shell.execute_reply":"2021-08-10T06:11:51.012161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_df = pd.DataFrame.from_dict({'image_id': image_ids, 'dim0': dim0, 'dim1': dim1})\n\n# Associate image-level id with study-level ids.\n# Note that a study-level might have more than one image-level ids.\nfor study_dir in os.listdir('../input/siim-covid19-detection/test'):\n    for series in os.listdir(f'../input/siim-covid19-detection/test/{study_dir}'):\n        for image in os.listdir(f'../input/siim-covid19-detection/test/{study_dir}/{series}/'):\n            image_id = image[:-4]\n            meta_df.loc[meta_df['image_id'] == image_id, 'study_id'] = study_dir\n        \nmeta_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:11:51.014433Z","iopub.execute_input":"2021-08-10T06:11:51.014846Z","iopub.status.idle":"2021-08-10T06:11:53.66835Z","shell.execute_reply.started":"2021-08-10T06:11:51.014807Z","shell.execute_reply":"2021-08-10T06:11:53.667568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#meta_df_test=meta_df.loc[meta_df['split']=='test']\nmeta_df_test=meta_df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:11:53.669593Z","iopub.execute_input":"2021-08-10T06:11:53.669946Z","iopub.status.idle":"2021-08-10T06:11:53.675972Z","shell.execute_reply.started":"2021-08-10T06:11:53.66991Z","shell.execute_reply":"2021-08-10T06:11:53.675167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del meta_df_test['split']","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:11:53.677149Z","iopub.execute_input":"2021-08-10T06:11:53.677512Z","iopub.status.idle":"2021-08-10T06:11:53.68559Z","shell.execute_reply.started":"2021-08-10T06:11:53.677475Z","shell.execute_reply":"2021-08-10T06:11:53.684505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create Meta file for Test  dataset","metadata":{}},{"cell_type":"code","source":"meta_df_test","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:11:53.686827Z","iopub.execute_input":"2021-08-10T06:11:53.687172Z","iopub.status.idle":"2021-08-10T06:11:53.706046Z","shell.execute_reply.started":"2021-08-10T06:11:53.687135Z","shell.execute_reply":"2021-08-10T06:11:53.705309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image Detection","metadata":{}},{"cell_type":"code","source":"# YOLO_MODEL_PATH = '../input/yolo-models/yolov5s-e-100-img-512.pt'\n#YOLO_MODEL_PATHS = 'kaggle-siim-covid19/exp/weights/best.pt'\n# TEST_PATH = '/kaggle/input/siim-covid19-resized-to-256px-jpg/test/'\nTEST_PATH = f'/kaggle/tmp/test/'\n!python ../input/yolo-v5/detect.py --weights {weights_dir} \\\n                  --source {TEST_PATH} \\\n                  --img {IMG_SIZE} \\\n                  --conf 0.28 \\\n                  --iou-thres 0.5 \\\n                  --max-det 3 \\\n                  --save-txt \\\n                  --save-conf \\\n                  --exist-ok","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:11:53.707275Z","iopub.execute_input":"2021-08-10T06:11:53.707644Z","iopub.status.idle":"2021-08-10T06:12:49.139447Z","shell.execute_reply.started":"2021-08-10T06:11:53.707599Z","shell.execute_reply":"2021-08-10T06:12:49.138498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('runs/detect/')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:49.14293Z","iopub.execute_input":"2021-08-10T06:12:49.143236Z","iopub.status.idle":"2021-08-10T06:12:49.152236Z","shell.execute_reply.started":"2021-08-10T06:12:49.143203Z","shell.execute_reply":"2021-08-10T06:12:49.150979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs/detect/exp/*')\nfor _ in range(3):\n    row = 4\n    col = 3\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img= cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:49.154026Z","iopub.execute_input":"2021-08-10T06:12:49.154509Z","iopub.status.idle":"2021-08-10T06:12:52.811312Z","shell.execute_reply.started":"2021-08-10T06:12:49.154469Z","shell.execute_reply":"2021-08-10T06:12:52.810296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PRED_PATH ='runs/detect/exp/labels'\nprediction_files = os.listdir(PRED_PATH)\nprint(f'Number of opacity predicted by YOLOv5: {len(prediction_files)}')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:52.812941Z","iopub.execute_input":"2021-08-10T06:12:52.813365Z","iopub.status.idle":"2021-08-10T06:12:52.820108Z","shell.execute_reply.started":"2021-08-10T06:12:52.813324Z","shell.execute_reply":"2021-08-10T06:12:52.819043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport gc\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:52.821593Z","iopub.execute_input":"2021-08-10T06:12:52.822011Z","iopub.status.idle":"2021-08-10T06:12:57.055306Z","shell.execute_reply.started":"2021-08-10T06:12:52.821966Z","shell.execute_reply":"2021-08-10T06:12:57.054332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\nCONFIG = dict (\n    seed = 42,\n    num_labels = 4,\n    num_folds = 5,\n    img_width = 256,\n    img_height = 256,\n    batch_size = 8,\n    architecture = \"CNN\",\n    infra = \"GCP\",\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:57.059734Z","iopub.execute_input":"2021-08-10T06:12:57.060037Z","iopub.status.idle":"2021-08-10T06:12:57.065532Z","shell.execute_reply.started":"2021-08-10T06:12:57.060006Z","shell.execute_reply":"2021-08-10T06:12:57.064523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TEST_PATH = '/kaggle/input/siim-covid19-resized-to-256px-jpg/test/'","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:57.067626Z","iopub.execute_input":"2021-08-10T06:12:57.068306Z","iopub.status.idle":"2021-08-10T06:12:57.07565Z","shell.execute_reply.started":"2021-08-10T06:12:57.068246Z","shell.execute_reply":"2021-08-10T06:12:57.074617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df['path'] = image_df.apply(lambda row: TEST_PATH+row.id.split('_')[0]+'.png', axis=1)\nimage_df = image_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:57.077116Z","iopub.execute_input":"2021-08-10T06:12:57.07762Z","iopub.status.idle":"2021-08-10T06:12:57.11035Z","shell.execute_reply.started":"2021-08-10T06:12:57.077582Z","shell.execute_reply":"2021-08-10T06:12:57.108985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:57.111473Z","iopub.execute_input":"2021-08-10T06:12:57.11179Z","iopub.status.idle":"2021-08-10T06:12:57.123835Z","shell.execute_reply.started":"2021-08-10T06:12:57.111757Z","shell.execute_reply":"2021-08-10T06:12:57.122784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_df = sub_df.loc[sub_df.id.str.contains('_study')]\nlen(study_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:57.12544Z","iopub.execute_input":"2021-08-10T06:12:57.125822Z","iopub.status.idle":"2021-08-10T06:12:57.137048Z","shell.execute_reply.started":"2021-08-10T06:12:57.125787Z","shell.execute_reply":"2021-08-10T06:12:57.136055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks to https://www.kaggle.com/ayuraj/submission-covid19/data","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef decode_image(image):\n    # convert the compressed string to a 3D uint8 tensor\n    image = tf.image.decode_png(image, channels=3)\n    # Normalize image\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\n@tf.function\ndef load_image(df_dict):\n    # Load image\n    image = tf.io.read_file(df_dict['path'])\n    image = decode_image(image)\n    \n    # Resize image\n    image = tf.image.resize(image, (CONFIG['img_height'], CONFIG['img_width']))\n    \n    return image\n\ntestloader = tf.data.Dataset.from_tensor_slices(dict(image_df))\n\ntestloader = (\n    testloader\n    .shuffle(1024)\n    .map(load_image, num_parallel_calls=AUTOTUNE)\n    .batch(CONFIG['batch_size'])\n    .prefetch(AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:12:57.139627Z","iopub.execute_input":"2021-08-10T06:12:57.14018Z","iopub.status.idle":"2021-08-10T06:13:00.828217Z","shell.execute_reply.started":"2021-08-10T06:12:57.140143Z","shell.execute_reply":"2021-08-10T06:13:00.827326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Model\nSTUDY_MODEL_PATHS = '/kaggle/input/studylevelmodel/SIIM-Study-Level-model/'\nstudy_models = os.listdir(STUDY_MODEL_PATHS)\nstudy_models","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:13:00.829666Z","iopub.execute_input":"2021-08-10T06:13:00.830013Z","iopub.status.idle":"2021-08-10T06:13:00.847849Z","shell.execute_reply.started":"2021-08-10T06:13:00.829977Z","shell.execute_reply":"2021-08-10T06:13:00.846808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model for Study _pred","metadata":{}},{"cell_type":"code","source":"# ! pip install -q efficientnet\n\n\n!pip install ../input/keras-efficientnet-whl/Keras_Applications-1.0.8-py3-none-any.whl\n!pip install ../input/keras-efficientnet-whl/efficientnet-1.1.1-py3-none-any.whl\nfrom efficientnet.tfkeras import EfficientNetB5","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:13:00.849309Z","iopub.execute_input":"2021-08-10T06:13:00.849881Z","iopub.status.idle":"2021-08-10T06:13:55.453398Z","shell.execute_reply.started":"2021-08-10T06:13:00.849839Z","shell.execute_reply":"2021-08-10T06:13:55.452356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor model in study_models:\n    # Load model\n    tf.keras.backend.clear_session()\n    model = tf.keras.models.load_model(STUDY_MODEL_PATHS+model)\n    # Prediction\n    tmp = []\n    for img_batch in tqdm(testloader):\n        preds = model.predict(img_batch)\n        tmp.extend(preds)\n        \n    predictions.append(tmp)\n    \n    del model\n    _ = gc.collect()\n    \npredictions = np.mean(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:13:55.454969Z","iopub.execute_input":"2021-08-10T06:13:55.455446Z","iopub.status.idle":"2021-08-10T06:16:33.178913Z","shell.execute_reply.started":"2021-08-10T06:13:55.455397Z","shell.execute_reply":"2021-08-10T06:16:33.177967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = ['0', '1', '2', '3']\nimage_df.loc[:, class_labels] = predictions\nimage_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:33.182741Z","iopub.execute_input":"2021-08-10T06:16:33.183032Z","iopub.status.idle":"2021-08-10T06:16:33.206492Z","shell.execute_reply.started":"2021-08-10T06:16:33.183003Z","shell.execute_reply":"2021-08-10T06:16:33.205566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_to_id = { \n    'negative': 0,\n    'typical': 1,\n    'indeterminate': 2,\n    'atypical': 3}\nid_to_class  = {v:k for k, v in class_to_id.items()}\n\ndef get_study_prediction_string(preds, threshold=0):\n    string = ''\n    for idx in range(4):\n        conf =  preds[idx]\n        if conf>threshold:\n            string+=f'{id_to_class[idx]} {conf:0.2f} 0 0 1 1 '\n    string = string.strip()\n    return string","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:33.207801Z","iopub.execute_input":"2021-08-10T06:16:33.208539Z","iopub.status.idle":"2021-08-10T06:16:33.215774Z","shell.execute_reply.started":"2021-08-10T06:16:33.208496Z","shell.execute_reply":"2021-08-10T06:16:33.214876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:33.217172Z","iopub.execute_input":"2021-08-10T06:16:33.217605Z","iopub.status.idle":"2021-08-10T06:16:33.237167Z","shell.execute_reply.started":"2021-08-10T06:16:33.217568Z","shell.execute_reply":"2021-08-10T06:16:33.236058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:33.238885Z","iopub.execute_input":"2021-08-10T06:16:33.239361Z","iopub.status.idle":"2021-08-10T06:16:33.25174Z","shell.execute_reply.started":"2021-08-10T06:16:33.239317Z","shell.execute_reply":"2021-08-10T06:16:33.250766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_ids = []\npred_strings = []\n\nfor study_id, df in meta_df_test.groupby('study_id'):\n    # accumulate preds for diff images belonging to same study_id\n    tmp_pred = []\n    \n    df = df.reset_index(drop=True)\n    for image_id in df.image_id.values:\n        preds = image_df.loc[image_df.id == image_id+'_image'].values[0]\n        tmp_pred.append(preds[3:])\n    \n    preds = np.mean(tmp_pred, axis=0)\n    pred_string = get_study_prediction_string(preds)\n    pred_strings.append(pred_string)\n    \n    study_ids.append(f'{study_id}_study')\n    \nstudy_df = pd.DataFrame.from_dict({'id': study_ids, 'PredictionString': pred_strings})\nstudy_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:33.25349Z","iopub.execute_input":"2021-08-10T06:16:33.253972Z","iopub.status.idle":"2021-08-10T06:16:34.388107Z","shell.execute_reply.started":"2021-08-10T06:16:33.253936Z","shell.execute_reply":"2021-08-10T06:16:34.387293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The submisison requires xmin, ymin, xmax, ymax format. \n# YOLOv5 returns x_center, y_center, width, height\ndef correct_bbox_format(bboxes):\n    correct_bboxes = []\n    for b in bboxes:\n        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n\n        xmin = xc - int(np.round(w/2))\n        ymin = yc - int(np.round(h/2))\n        xmax = xc + int(np.round(w/2))\n        ymax = yc + int(np.round(h/2))\n        \n        correct_bboxes.append([xmin, ymin, xmax, ymax])\n        \n    return correct_bboxes\n\ndef scale_bboxes_to_original(row, bboxes):\n    # Get scaling factor\n    scale_x = IMG_SIZE/row.dim1\n    scale_y = IMG_SIZE/row.dim0\n    \n    scaled_bboxes = []\n    for bbox in bboxes:\n        xmin, ymin, xmax, ymax = bbox\n        \n        xmin = int(np.round(xmin/scale_x))\n        ymin = int(np.round(ymin/scale_y))\n        xmax = int(np.round(xmax/scale_x))\n        ymax = int(np.round(ymax/scale_y))\n        \n        scaled_bboxes.append([xmin, ymin, xmax, ymax])\n        \n    return scaled_bboxes\n\n# Read the txt file generated by YOLOv5 during inference and extract \n# confidence and bounding box coordinates.\ndef get_conf_bboxes(file_path):\n    confidence = []\n    bboxes = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            preds = line.strip('\\n').split(' ')\n            preds = list(map(float, preds))\n            confidence.append(preds[-1])\n            bboxes.append(preds[1:-1])\n    return confidence, bboxes","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:34.389521Z","iopub.execute_input":"2021-08-10T06:16:34.389862Z","iopub.status.idle":"2021-08-10T06:16:34.400812Z","shell.execute_reply.started":"2021-08-10T06:16:34.389824Z","shell.execute_reply":"2021-08-10T06:16:34.399843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_pred_strings = []\nfor i in tqdm(range(len(image_df))):\n    row = meta_df_test.loc[i]\n    id_name = row.image_id\n    \n    if f'{id_name}.txt' in prediction_files:\n        # opacity label\n        confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}/{id_name}.txt')\n        bboxes = correct_bbox_format(bboxes)\n        ori_bboxes = scale_bboxes_to_original(row, bboxes)\n        \n        pred_string = ''\n        for j, conf in enumerate(confidence):\n            pred_string += f'opacity {conf} ' + ' '.join(map(str, ori_bboxes[j])) + ' '\n        image_pred_strings.append(pred_string[:-1]) \n    else:\n        image_pred_strings.append(\"none 1 0 0 1 1\")","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:34.40206Z","iopub.execute_input":"2021-08-10T06:16:34.402456Z","iopub.status.idle":"2021-08-10T06:16:34.782518Z","shell.execute_reply.started":"2021-08-10T06:16:34.402418Z","shell.execute_reply":"2021-08-10T06:16:34.781538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission File","metadata":{}},{"cell_type":"code","source":"meta_df_test['PredictionString'] = image_pred_strings\nimage_df = meta_df_test[['image_id', 'PredictionString']]\nimage_df.insert(0, 'id', image_df.apply(lambda row: row.image_id+'_image', axis=1))\nimage_df = image_df.drop('image_id', axis=1)\nimage_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:34.783961Z","iopub.execute_input":"2021-08-10T06:16:34.784331Z","iopub.status.idle":"2021-08-10T06:16:34.818445Z","shell.execute_reply.started":"2021-08-10T06:16:34.784291Z","shell.execute_reply":"2021-08-10T06:16:34.817511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"remove unused files","metadata":{}},{"cell_type":"code","source":"!rm -rf runs","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:34.819686Z","iopub.execute_input":"2021-08-10T06:16:34.820031Z","iopub.status.idle":"2021-08-10T06:16:35.716392Z","shell.execute_reply.started":"2021-08-10T06:16:34.819995Z","shell.execute_reply":"2021-08-10T06:16:35.715318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.concat([study_df, image_df])\nsub_df.to_csv('/kaggle/working/submission.csv', index=False)\nsub_df","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:16:35.717909Z","iopub.execute_input":"2021-08-10T06:16:35.718261Z","iopub.status.idle":"2021-08-10T06:16:35.749762Z","shell.execute_reply.started":"2021-08-10T06:16:35.718214Z","shell.execute_reply":"2021-08-10T06:16:35.748789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}