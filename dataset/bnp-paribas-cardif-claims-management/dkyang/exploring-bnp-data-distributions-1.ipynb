{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Exploring BNP Data Distributions\n\nHopefully this will run on Kaggle servers.  You should see a lot of plots (I can only see one right now, before pressing view HTML output).  \nIf it doesn't I guess you'll have to run the code on your own machine. "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Read the Data\ntrain = pd.read_csv(\"../input/train.csv\")\ntrain = train.drop(['ID'],axis=1)\ntest = pd.read_csv(\"../input/test.csv\")\ntest = test.drop(['ID'],axis=1)\ntarget = train.target\nfeatureNames = train.columns.values"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Function to convert to hexavigesimal base\ndef az_to_int(az,nanVal=None):\n    if az==az:  #catch NaN\n        hv = 0\n        for i in range(len(az)):\n            hv += (ord(az[i].lower())-ord('a')+1)*26**(len(az)-1-i)\n        return hv\n    else:\n        if nanVal is not None:\n            return nanVal\n        else:\n            return az"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Prepare the data: combine, process, split\ntest['target'] = -999\nall_data = train.append(test)\n\n# convert v22 to hexavigesimal\nall_data.v22 = all_data.v22.apply(az_to_int)\n\nfor c in all_data.columns.values:\n    if all_data[c].dtype=='object':\n        all_data[c], tmpItter = all_data[c].factorize()\n\n# replace all NA's with -1\nall_data.fillna(-1, inplace=True)\n\n# split the data\ntrain = all_data[all_data['target']>-999]\ntest = all_data[all_data['target']==-999]\ntest = test.drop(['target'],axis=1)"},{"cell_type":"markdown","metadata":{},"source":"## Plot Descriptions\n\n### Histogram Plots on the the left:\n* Blue:  All of the train data (normalized)\n* Red:  Train Data where the target variable is one (again normalized)\n* Na's are -1, so the first column is usually large\n\n### CDF Plots on the right:\n* Blue and red as before\n* Black line is the difference in the CDF's (x10 + 0.5 for visualization)\n\n### A few interesting insights:\n* It's easy to see why v50 is such a powerful predictor\n* Somewhat counterintuitive, most of the features have more NA's when the target is true.  This is indicated both by the first red bar on the left being higher than the blue and by the cdf difference line being negative at the start.  Perhaps it's the presence of certain information, not the lack of it, that prevents fast-track processing.\n* With v22 coded in hexavigesimal, there is some large scale structure in the pdf, and possibly some structure in the CDF difference plot"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"plt.rcParams['figure.max_open_warning']=300\nnbins=20\nfor c in  featureNames:\n    if train[c].dtype != 'object' and c != 'target':\n        if c=='v22':\n            hbins = 100\n        else:\n            hbins = nbins\n        fig=plt.figure(figsize=(14,4))\n        ax1 = fig.add_subplot(1,2,1) \n        \n        dataset1 = train[c][~np.isnan(train[c])]\n        dataset2 = train[c][~np.isnan(train[c]) & train.target]\n        \n        # left plot\n        hd = ax1.hist((dataset1, dataset2), bins=hbins, histtype='bar',normed=True,\n                        color=[\"blue\", \"red\"],label=['all','target=1'])\n        ax1.set_xlabel('Feature: '+c)\n        ax1.set_xlim((-1,max(train[c])))\n        \n        binwidth = hd[1][1]-hd[1][0]\n        midpts = (hd[1][:-1]+hd[1][1:])/2\n        cdf_all= np.cumsum(hd[0][0])*binwidth\n        cdf_ones = np.cumsum(hd[0][1])*binwidth\n\n        # right plot\n        ax2 = fig.add_subplot(1,2,2) \n        ax2.set_ylim((0,1))\n        ax2.set_xlim((0,nbins))\n        ax2.plot(midpts,cdf_all,color='b')\n        ax2.plot(midpts,cdf_ones,color='r')\n        ax2.plot(midpts,0.5+10*(cdf_all-cdf_ones),color='k')\n        ax2.grid()\n        ax2.set_xlim((-1,max(train[c])))\n        ax2.set_xlabel('cdfs plus cdf_diff*10+0.5')\n        ax2.axhline(0.5,color='gray',linestyle='--')"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}