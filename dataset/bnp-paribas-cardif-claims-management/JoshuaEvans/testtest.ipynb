{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#FUNCTIONS\n#--is_number\n#--calc_entropy\n#--calc_gain\n#---------------------------------------------------------------------------------------------\ndef is_number(s):\n\ttry:\n\t\treturn float(s)\n\texcept ValueError:\n\t\treturn False\n\n# Entropy(TotalSet) = - (Class_Yes/NumberInTotal)*Log2(Class_Yest/NumberInTotal) - (Class_No/NumberInTotal)*Log2(Class_No/NumberInTotal))\ndef calc_entropy(NumberInTotal,NumberTrueInTotal):\t\n\ttotal = float(NumberInTotal)\n\ttotalTrue = float(NumberTrueInTotal)\n\ttotalFalse = total - totalTrue\n\n\tif total != 0:\n\t\ttF_div_t = totalFalse / total\n\n\t\tif totalTrue != 0:\n\t\t\ttT_div_t = totalTrue / total\n\t\telse:\n\t\t\ttT_div_t = 0\n\telse:\n\t\ttF_div_t = 0\n\t\ttT_div_t = 0\n\n\tif tT_div_t != 0:\n\t\tentropyTrue = -tT_div_t * np.log2(tT_div_t)\n\telse:\n\t\tentropyTrue = 0\n\t\n\tif tF_div_t != 0:\n\t\tentropyFalse = -tF_div_t * np.log2(tF_div_t)\n\telse:\n\t\tentropyFalse = 0\n\n\t#entropy\n\treturn  entropyTrue + entropyFalse\n\n# Gain = Entropy(TotalSet) - Sum ( ( NumberInSubset / NumberInTotal) ) * Entropy(Subset)\ndef calc_gain(EntropyOfTotalSet,NumberInTotal, ArrayOf_NumberInSubset,ArrayOf_NumberTrueInSubset):\n\tsumOfSubsetsEntropy = 0\n\tsubsetIndex = 0\n\tnumberOfSubsets = len(ArrayOf_NumberInSubset)\n\twhile subsetIndex < numberOfSubsets:\n\t\tsumOfSubsetsEntropy += (ArrayOf_NumberInSubset[subsetIndex]/float(NumberInTotal)) * calc_entropy( ArrayOf_NumberInSubset[subsetIndex],ArrayOf_NumberTrueInSubset[subsetIndex])\n\t \tsubsetIndex += 1\n\treturn EntropyOfTotalSet - sumOfSubsetsEntropy #gain\n#---------------------------------------------------------------------------------------------\n\n#CLASSES\n#---Node\n#---Tree\n#******************************************************************\nclass Node:\n\tdef __init__(self,typeOfNode,nodeId):\n\t\t#types are 'branching' and 'value'\n\t\t#values can include \n\t\t\t# a numerical percentage chance of membership\n\t\t\t# membership value of 1 or 0 (extremely confident)\n\t\t\t# failure\n\t\t#branching nodes lead to other nodes\n\t\tself._typeOfNode = typeOfNode\n\t\tself._ID = nodeId\n\t\tif typeOfNode == 'Branching':\n\t\t\tself._paths = []\n\n\tdef setBranchType(self,branchType):\n\t\tself._branchType = branchType\n\n\tdef setFeatureIndex(self,featureIndex):\n\t\tself._featureIndex = featureIndex\n\n\tdef setValue(self,value):\n\t\tself._value = value\n\n\tdef setAddress(self,address): # this is the nodes 'address' in the previous branch nodeIs' _paths list\n\t\tself._address = address\n\n\tdef setSplitValue(self,splitValue):\n\t\tself._splitValue = splitValue\n\n\tdef setGroupWithHighestOdds(self,groupWithHighestOdds):\n\t\tself._groupWithHighestOdds = groupWithHighestOdds\n\n\tdef getBranchType(self):\n\t\treturn self._branchType\n\tdef getFeatureIndex(self):\n\t\treturn self._featureIndex\n\tdef getId(self):\n\t\treturn self._ID\n\tdef getType(self):\n\t\treturn self._typeOfNode\n\tdef getValue(self):\n\t\treturn self._value\n\tdef getAddress(self):\n\t\treturn self._address\n\tdef getSplitValue(self):\n\t\treturn self._splitValue\n\tdef getGroupWithHighestOdds(self):\n\t\treturn self._groupWithHighestOdds\n\n\t# arg 'branch' is nodeID the node branches to\n\tdef addBranch(self,branch):\n\t\tself._paths.append(branch)\t\n\tdef getPaths(self):\n\t\treturn self._paths\n\nclass Tree:\n\tdef __init__(self,featuresList,membershipData,featureData):\n\t\tself._nodes = {}\n\t\tself._nodeCount = 0\n\t\t\n\t\tnumberTrue = 0\n\t\tnumberFalse = 0\n\t\tunknownValue = 0\n\t\tfor memberData in membershipData:\n\t\t \tif memberData == '1':\n\t\t \t\tnumberTrue += 1\n\t\t \telif memberData == '0':\n\t\t \t\tnumberFalse += 1\n\t\t \telse:\n\t\t \t\tunknownValue += 1\n\n\t\toverAllOddsOfMembership = numberTrue / float(numberTrue+numberFalse)\n\n\t\tself._rootNode = self.CreateNode(featuresList,membershipData,featureData,overAllOddsOfMembership)\n\n\tdef CreateNode(self,featuresList,membershipData,featureData,overAllOddsOfMembership):\n\t\t#*If all cases are true, create true node\n\t\t#**Get number of true false for current data\n\t\tprint 'node creating'\n\t\tnumberTrue = 0\n\t\tnumberFalse = 0\n\t\tunknownValue = 0\n\t\tfor memberData in membershipData:\n\t\t \tif memberData == '1':\n\t\t \t\tnumberTrue += 1\n\t\t \telif memberData == '0':\n\t\t \t\tnumberFalse += 1\n\t\t \telse:\n\t\t \t\tunknownValue += 1\n\n\t\t#*If no data, create failure node\n\t\tif len(featureData) == 0:\n\t\t\tnode = Node('value',str(self._nodeCount))\n\t\t\tself._nodeCount += 1\n\t\t\tprint numberTrue\n\t\t\tprint numberFalse\n\t\t\tnode.setValue(overAllOddsOfMembership)\n\t\t\t\n\t\t\tself._nodes[node.getId()] = node\n\t\t\t##print 'FAILURE node'\n\t\t\t#raw_input()\n\t\t\treturn node\n\t\t\n\n\t\tif numberFalse == 0 and numberTrue > 0:\n\t\t \tnode = Node('value',str(self._nodeCount))\n\t\t\tself._nodeCount += 1\n\t\t \tnode.setValue(1.0)\n\t\t\tself._nodes[node.getId()] = node\n\t\t\t##print 'true node'\n\t\t\t#raw_input()\n\t\t\treturn node\n\n\n\t\t #*If all cases are false, create false node\n\t\tif numberTrue == 0 and numberFalse > 0:\n\t\t \tnode = Node('value',str(self._nodeCount))\n\t\t\tself._nodeCount += 1\n\t\t \tnode.setValue(0.0)\n\t\t \tself._nodes[node.getId()] = node\n\t\t\t##print 'false node'\n\t\t\t#raw_input()\n\t\t\treturn node\n\n\t\t\n\t\t#*If no features, create percentage node true from remaining data !WILL BE CALCULATION ERRORS!\n\t\tif len(featuresList) == 0:\n\t\t\tnode = Node('value',str(self._nodeCount))\n\t\t\tself._nodeCount += 1\n\t\t\tnode.setValue(float(numberTrue)/(numberTrue+numberFalse))\n\t\t\tself._nodes[node.getId()] = node\n\t\t\t##print 'percentage node'\n\t\t\t#raw_input()\n\t\t\treturn node\n\n#---------------------------------------------------------------------------------------------------------------------\n\t\t#*The tree grows\n\t\t#** Create this node, and add to node dictionary\n\t\tnode = Node('Branching',str(self._nodeCount))\n\t\tnode.setValue('Branching')\n\t\tself._nodeCount += 1\n\t\tself._nodes[node.getId()] = node\n\t\t\n\t\t#**Calculate entropy for current data\n\t\ttotalNumber  = numberTrue+numberFalse                # total number of data\n\t\ttotalEntropy = calc_entropy(totalNumber,numberTrue)  # entropy for total data\n\t\t\n\t\t#**Find feature with highest gain\n\t\tcurrentFeatureIndex = 0                        # list iterator\n\t\tmaxFeatureGain = 0                             # hold highest feature gain found\n\t\tnumberOfFeatures = len(featureData)\t\t\t\t\t\t # number of features, 131 this case\n\t\twhile(currentFeatureIndex < len(featureData)): # loop through features\n\t\t\trowOfFeatureValues = featureData[currentFeatureIndex] # place current row of \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#  features into variable\n\t\t\t#***Skip past entries that are empty until non empty cell is found\n\t\t\tcheckTypeIndex = 0\n\t\t\twhile rowOfFeatureValues[checkTypeIndex] == '' and checkTypeIndex < len(rowOfFeatureValues)-1:\n\t\t\t\tcheckTypeIndex+=1\n\n\t\t\t#***Determine data type of feature (number or category) and calculate gain\n\t\t\tif is_number(rowOfFeatureValues[checkTypeIndex]):        # if 'number'\n\t\t\t\tsortedValues = list(rowOfFeatureValues)                # sort values and remove missing data\n\t\t\t\tsortedValues.sort()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t       # -\n\t\t\t\tsortedValues = filter(lambda a: a != '', sortedValues) # -\n\n\t\t\t\t#***find highest gain from splitting list at each value in sortedValues\n\t\t\t\tsortedValueIndex = 0\n\t\t\t\tlengthSortedValues = len(sortedValues)\n\t\t\t\tgainList = []\n\t\t\t\tsortingValueList = []\n\t\t\t\tfloatRowTotalsList = []\n\t\t\t\tfloatRowTrueTotals = []\n\t\t\t\twhile(sortedValueIndex < len(sortedValues)):\n\t\t\t\t\toverNumberTrue = overNumberFalse = 0\n\t\t\t\t\tunderNumberTrue = underNumberFalse = 0\n\t\t\t\t\temptyQuotesNumberTrue = emptyQuotesNumberFalse = 0\n\t\t\t\t\t# split data into three groups: \n\t\t\t\t\t#  1. > current sorting value\n\t\t\t\t\t#  2. <= current sorting value \n\t\t\t\t\t#  3. empty quotes (missing data)\n\t\t\t\t\t# get number and true ('1') and false ('0') for each group \n\n\t\t\t\t\tcurrentSortingValue = sortedValues[sortedValueIndex]\n\t\t\t\t\tdataItemIndex = 0\n\t\t\t\t\tlengthDataItems = len(membershipData)\n\t\t\t\t\twhile(dataItemIndex < len(membershipData)):\n\t\t\t\t\t\tdataItem = rowOfFeatureValues[dataItemIndex] \n\t\t\t\t\t\tif dataItem != '':\n\t\t\t\t\t\t\tif dataItem > currentSortingValue:\n\t\t\t\t\t\t\t\tif membershipData[dataItemIndex] == '1':\n\t\t\t\t\t\t\t\t\toverNumberTrue += 1\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\toverNumberFalse += 1\n\t\t\t\t\t\t\telse: # lower than or equal to currentSortingValue\n\t\t\t\t\t\t\t\tif membershipData[dataItemIndex] == '1':\n\t\t\t\t\t\t\t\t\tunderNumberTrue += 1\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tunderNumberFalse += 1\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tif membershipData[dataItemIndex] == '1':\n\t\t\t\t\t\t\t\temptyQuotesNumberTrue += 1\n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\temptyQuotesNumberFalse += 1\n\t\t\t\t\t\tdataItemIndex += 1\n\n\t\t\t\t\t#calculate gain at current splitting value\n\t\t\t\t\trowTotals = [overNumberTrue+overNumberFalse, underNumberTrue+underNumberFalse, emptyQuotesNumberTrue+emptyQuotesNumberFalse]\n\t\t\t\t\trowTrueTotals = [overNumberTrue, underNumberTrue, emptyQuotesNumberTrue]\n\t\t\t\t\t\n\t\t\t\t\tgain = calc_gain(totalEntropy, totalNumber, rowTotals, rowTrueTotals)\n\n\t\t\t\t\tgainList.append(gain)\n\t\t\t\t\tsortingValueList.append(currentSortingValue)\n\t\t\t\t\tfloatRowTotalsList.append(rowTotals)\n\t\t\t\t\tfloatRowTrueTotals.append(rowTrueTotals)\n\t\t\t\t\tsortedValueIndex+=1\n\t\t\t\t\n\t\t\t\t# If this is current highest gain replace previous feature data with this data\n\t\t\t\tif len(gainList) > 0 and max(gainList) > maxFeatureGain:\n\t\t\t\t\tmaxFeatureGain = max(gainList)\n\t\t\t\t\tmaxFeatureGainIndex = gainList.index(maxFeatureGain)\n\n\t\t\t\t\tmaxGainSortingValue       = float(sortingValueList[maxFeatureGainIndex])\n\t\t\t\t\tmaxGainRowTotals     = floatRowTotalsList[maxFeatureGainIndex]\n\t\t\t\t\tmaxGainRowTrueTotals =  floatRowTrueTotals[maxFeatureGainIndex]\n\t\t\t\t\tmaxGainFeatureIndex =  currentFeatureIndex \n\t\t\t\t\n\t\t\t\t#plt.plot(gainList)\n\t\t\t\t#plt.suptitle(featuresList[currentFeatureIndex])\n\t\t\t\t#plt.show()\n\n\t\t\telse: #----------------------------------------------# category\n\t\t\t\trowOfFeatureValues = featureData[currentFeatureIndex]\n\n\t\t\t\tvalueDict = {} # total totalTrue totalFalse\n\t\t\t\tcurrentFeatureIndexValueLine = 0\n\t\t\t\tlengthRowOfFeatureValues = len(membershipData)\n\t\t\t\twhile( currentFeatureIndexValueLine < len(membershipData)):\n\t\t\t\t\tline = rowOfFeatureValues[currentFeatureIndexValueLine]\n\t\t\t\t\tif valueDict.has_key(line) == False:\n\t\t\t\t\t\tvalueDict[line] = [1,0,0]\n\t\t\t\t\t\tif membershipData[currentFeatureIndexValueLine] == '1':\n\t\t\t\t\t\t\tvalueDict[line][1] = 1\n\t\t\t\t\t\t\tvalueDict[line][2] = 0\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tvalueDict[line][1] = 0\n\t\t\t\t\t\t\tvalueDict[line][2] = 1\n\t\t\t\t\telse:\n\t\t\t\t\t\tvalueDict[line][0] += 1\n\t\t\t\t\t\tif membershipData[currentFeatureIndexValueLine] == '1':\n\t\t\t\t\t\t\tvalueDict[line][1] += 1\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tvalueDict[line][2] += 1\n\t\t\t\t\t\n\t\t\t\t\tcurrentFeatureIndexValueLine+=1\n\t\t\t\t#calculate Gain for valueDict\n\t\t\t\t'''\n\t\t\t\t#\n\t\t\t\t#\n\t\t\t\t# Probem in here--------------------------------------------------------------\n\t\t\t\t#\n\t\t\t\t# remove the data for valueDict from training data\n\t\t\t\t#\n\t\t\t\t#\n\t\t\t\tif(len(valueDict)) > 5 :\n\t\t\t\t\t#print valueDict\n\t\t\t\t\tgain = .00001\n\n\t\t\t\t\t#print '!!!!!!!!!!!'\n\t\t\t\t\t#print currentFeatureIndex\n\t\t\t\t\t#print len(featuresList)\n\t\t\t\t\tdel featuresList[currentFeatureIndex]\n\t\t\t\t\t#print len(featuresList)\n\t\t\t\t\t\n\t\t\t\t\t#print np.shape(featureData)\n\t\t\t\t\t#print featureData[0][21]\n\t\t\t\t\t#print featureData[0][22]\n\n\t\t\t\t\tfeatureData = np.delete(featureData,currentFeatureIndex,1)\n\t\t\t\t\t#print np.shape(featureData)\n\t\t\t\t\t#print featureData[0][21]\n\t\t\t\t\traw_input('HERE')\n\t\t\t\t\t# remove data from featuresList,membershipData,featureData\n\t\t\t\telse:\n\t\t\t\t'''\n\t\t\t\t#\n\t\t\t\t#\n\t\t\t\t# -----------------------------------------------------------------------------\n\t\t\t\t#\n\t\t\t\t#\n\n\t\t\t\t#---------------------------------------------\n\t\t\t\t#if(len(valueDict)) > 10:\n\t\t\t\t#\t#print currentFeatureIndex\n\n\t\t\t\trowTotals = []\n\t\t\t\trowTrueTotals = []\n\t\t\t\t\t\n\t\t\t\tfor entry in valueDict:\n\t\t\t\t\ttempEntry = valueDict[entry]\n\t\t\t\t\trowTotals.append(tempEntry[0])\n\t\t\t\t\trowTrueTotals.append(tempEntry[1])\n\t\t\t\tgain = calc_gain(totalEntropy, totalNumber, rowTotals, rowTrueTotals)\n\t\t\t\t\n\t\t\t\tif gain > maxFeatureGain:\n\t\t\t\t\tmaxFeatureGain = gain\n\n\t\t\t\t\tmaxGainSortingValue       = 'char'\n\t\t\t\t\tmaxGainRowTotals     = rowTotals\n\t\t\t\t\tmaxGainRowTrueTotals =  rowTrueTotals\n\t\t\t\t\tmaxGainFeatureIndex =  currentFeatureIndex \n\t\t\t\t\tmaxGainValueDict = valueDict\n\n\t\t\tcurrentFeatureIndex+=1\n\t\t\n\n\t\t#**For the feature with highest gain\n\t\t#  sort pieces of data into groups from feature _note:treat quotes as a group in both cases\n\t\t#  if categorical sort into categories from feature\n\t\n\t\thighestGainFeatureData = featuresList[maxGainFeatureIndex] # label of feature with highest gain\n\n\t\tif maxGainSortingValue == 'char':\n\t\t\t##print maxGainValueDict  \n\t\t\t##print '************'\n\t\t\t##print maxGainValueDict\n\n\t\t\thighestOdds = 0\t\t\t\n\t\t\tgroupWithHighestOdds = ''\n\t\t\tfor group in maxGainValueDict:\n\t\t\t\t# calculate group that has highest odds of data being examined belonging to it\n\t\t\t\t#  this is testing data that has a categorical value that was not seen during tree construction \n\t\t\t\tgroupOdds = float( maxGainValueDict[group][1] ) / maxGainValueDict[group][0]\n\t\t\t\t\n\t\t\t\tif groupOdds > highestOdds:\n\t\t\t\t\thighestOdds = groupOdds\n\t\t\t\t\tgroupWithHighestOdds = group\n\n\t\t\t\tgroupFeaturesList = []\n\t\t\t\tgroupMembershipData = []\n\t\t\t\tgroupFeatureData = []\n\n\t\t\t\t# get list of feature labels and place into groupFeaturesList, omit feature label of feature with highest gain\n\t\t\t\tgroupFeaturesList = list(featuresList)\n\t\t\t\tdel groupFeaturesList[maxGainFeatureIndex]\n\n\n\t\t\t\t# get group membership data\n\t\t\t\tlengthMembershipData = len(membershipData)\n\t\t\t\tdataIndex = 0\n\t\t\t\twhile dataIndex < lengthMembershipData:\n\t\t\t\t\tif group == featureData[maxGainFeatureIndex][dataIndex]:\n\t\t\t\t\t\tgroupMembershipData.append(membershipData[dataIndex])\n\t\t\t\t\tdataIndex+=1\n\n\t\t\t\t# get group feature data\n\t\t\t\tlengthFeatureData = np.shape(featureData)[1]\n\t\t\t\tdataIndex = 0\n\t\t\t\twhile dataIndex < lengthFeatureData:\t\t\t\t\t\n\t\t\t\t\tif group == featureData[maxGainFeatureIndex][dataIndex]:\n\t\t\t\t\t\t#group FeatureData\n\t\t\t\t\t\tindividualData = []\n\t\t\t\t\t\ttempIndex = 0\n\t\t\t\t\t\twhile tempIndex <  int(np.shape(featureData)[0]):\n\t\t\t\t\t\t\tindividualData.append(featureData[tempIndex][dataIndex])\n\t\t\t\t\t\t\ttempIndex+=1\t\t\t\t\t\t\n\t\t\t\t\t\tgroupFeatureData.append(individualData)\n \n\t\t\t\t\tdataIndex+=1\n\t\t\t\tgroupFeatureData = np.transpose(groupFeatureData)\n\t\t\t\t# remove features used to calculate this gain from feature data set\n\t\t\t\tgroupFeatureData = np.delete(groupFeatureData,maxGainFeatureIndex,0)  \n#------>#!!!Pass the groupFeatureData groupFeaturesList groupMembershipData to recursive function here\n\t\t\t\ttempNode = self.CreateNode(groupFeaturesList,groupMembershipData,groupFeatureData,overAllOddsOfMembership)\n\t\t\t\ttempNode.setAddress(group)\n\t\t\t\tnode.addBranch(tempNode.getId())\n\t\t\tnode.setFeatureIndex(maxGainFeatureIndex)\n\t\t\tnode.setBranchType('category')\n\t\t\tnode.setGroupWithHighestOdds(groupWithHighestOdds)\n\t\t#if numerical sort by splitting value that gives highest gain\n\t\telse:\n\t\t\tunderGroupFeatureData = []\n\t\t\tunderGroupMembershipData = []\n\t\t\toverGroupFeatureData = []\n\t\t\toverGroupMembershipData = []\n\t\t\temptyGroupFeatureData = []\n\t\t\temptyGroupMembershipData = []\n\t\t\tgroupFeaturesList = []\n\n\t\t\t# get list of feature labels and place into groupFeaturesList, omit feature label of feature with highest gain\n\t\t\tgroupFeaturesList = list(featuresList)\n\t\t\tdel groupFeaturesList[maxGainFeatureIndex]\n\n\t\t\t#groupFeatureData,groupMembershipData\n\t\t\tlengthFeatureData = len(featureData[maxGainFeatureIndex])\n\t\t\tdataIndex = 0\n\t\t\twhile dataIndex < lengthFeatureData:\n\t\t\t\tif featureData[maxGainFeatureIndex][dataIndex] == '':\n\t\t\t\t\tindividualData = []\n\t\t\t\t\ttempIndex = 0\n\t\t\t\t\twhile tempIndex < len(featureData):\n\t\t\t\t\t\tif tempIndex !=  (int(highestGainFeatureData[1:])-1):\n\t\t\t\t\t\t\tindividualData.append(featureData[tempIndex][dataIndex])\n\t\t\t\t\t\ttempIndex+=1 \n\t\t\t\t\temptyGroupFeatureData.append(individualData)\n\t\t\t\t\temptyGroupMembershipData.append(membershipData[dataIndex])\n\t\t\t\t\n\t\t\t\telse:\n\t\t\t\t\tcurrentComparingValue = float(featureData[maxGainFeatureIndex][dataIndex])\n\t\t\t\t\tif currentComparingValue <= maxGainSortingValue:\n\t\t\t\t\t\t#group FeatureData\n\t\t\t\t\t\tindividualData = []\n\t\t\t\t\t\ttempIndex = 0\n\t\t\t\t\t\twhile tempIndex < len(featureData):\n\t\t\t\t\t\t\tif tempIndex !=  (int(highestGainFeatureData[1:])-1):\n\t\t\t\t\t\t\t\tindividualData.append(featureData[tempIndex][dataIndex])\n\t\t\t\t\t\t\ttempIndex+=1 \n\t\t\t\t\t\tunderGroupFeatureData.append(individualData)\n\t\t\t\t\t\tunderGroupMembershipData.append(membershipData[dataIndex])\n\n\t\t\t\t\telif currentComparingValue > maxGainSortingValue:\n\t\t\t\t\t\t#group FeatureData\n\t\t\t\t\t\tindividualData = []\n\t\t\t\t\t\ttempIndex = 0\n\t\t\t\t\t\twhile tempIndex < len(featureData):\n\t\t\t\t\t\t\tif tempIndex !=  (int(highestGainFeatureData[1:])-1):\n\t\t\t\t\t\t\t\tindividualData.append(featureData[tempIndex][dataIndex])\n\t\t\t\t\t\t\ttempIndex+=1 \n\t\t\t\t\t\toverGroupFeatureData.append(individualData)\n\t\t\t\t\t\toverGroupMembershipData.append(membershipData[dataIndex])\n\t\t\t\tdataIndex+=1\n\n\t\t\tnode.setBranchType('float')\n\t\t\tnode.setFeatureIndex(maxGainFeatureIndex)\n\t\t\tnode.setSplitValue(maxGainSortingValue)\n\n \t\t\ttempNode = self.CreateNode(groupFeaturesList,underGroupMembershipData,np.transpose(underGroupFeatureData),overAllOddsOfMembership)\n \t\t\ttempNode.setAddress('under')\n\t\t\t##print self._nodeCount\n\t\t\tnode.addBranch(tempNode.getId())\n\n \t\t\ttempNode = self.CreateNode(groupFeaturesList,overGroupMembershipData,np.transpose(overGroupFeatureData),overAllOddsOfMembership)\n \t\t\ttempNode.setAddress('over') \n\t\t\t##print self._nodeCount\n\t\t\tnode.addBranch(tempNode.getId())\n\n \t\t\ttempNode = self.CreateNode(groupFeaturesList,emptyGroupMembershipData,np.transpose(emptyGroupFeatureData),overAllOddsOfMembership)\n \t\t\ttempNode.setAddress('empty')\n \t\t\t##print self._nodeCount\n\t\t\tnode.addBranch(tempNode.getId())\n\n\t\treturn node\n\n\tdef Test(self,testData,testIds):\n\t\t'''\n\t\t#print self._nodes['0'].getType()\t\t\n\t\t#print self._nodes['0'].getBranchType()\n\t\t#print self._nodes['0'].getFeatureIndex()\n\t\t'''\n\t\tresultsStr = ''\n\t\tcountForIdRetrieval = 0\n\t\tfor line in testData:\n\t\t\tcurrentNodeId = '0'\n\t\t\tcurrentNode = self._nodes[currentNodeId] # root node\n\t\t\twhile currentNode.getValue() == 'Branching':\n\t\t\t\tbranchType = currentNode.getBranchType()\n\t\t\t\t#print branchType\n\t\t\t\tfeatureIndex = currentNode.getFeatureIndex()\n\t\t\t\t\n\t\t\t\tif branchType == 'category':\n\t\t\t\t\t#print currentNode.getPaths()\n\t\t\t\t\tdataNotSeenInGroups = True\n\t\t\t\t\tfor path in currentNode.getPaths():\n\t\t\t\t\t\t#print path\n\t\t\t\t\t\t#print self._nodes[path].getAddress()\n\t\t\t\t\t\t#print featureIndex\n\t\t\t\t\t\t#print line[featureIndex]\n\t\t\t\t\t\t#raw_input('-------')\n\t\t\t\t\t\t\n\t\t\t\t\t\tif currentNode.getGroupWithHighestOdds() == self._nodes[path].getAddress():\n\t\t\t\t\t\t\thighestOddsPath = path\n\n\t\t\t\t\t\tif line[featureIndex] == self._nodes[path].getAddress():\n\t\t\t\t\t\t\tcurrentNode = self._nodes[path]\n\t\t\t\t\t\t\tline = np.delete(line,featureIndex,0)\n\t\t\t\t\t\t\tdataNotSeenInGroups = False\n\t\t\t\t\t\t\t#print path\n\t\t\t\t\t\t\t#print '****************'\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\tif dataNotSeenInGroups == True:\n\t\t\t\t\t\t#print currentNode.getGroupWithHighestOdds() \n\t\t\t\t\t\tcurrentNode = self._nodes[highestOddsPath]\n\t\t\t\t\t\tline = np.delete(line,featureIndex,0)\n\t\t\t\telif branchType == 'float':\n\t\t\t\t\tsplitValue =  currentNode.getSplitValue()\n\t\t\t\t\t#print splitValue\n\t\t\t\t\t#print featureIndex\n\t\t\t\t\t#print line[featureIndex]\n\n\t\t\t\t\tif line[featureIndex] == '': # empty quotes\n\t\t\t\t\t\t#print 'empty'\n\t\t\t\t\t\tfor path in currentNode.getPaths():\n\t\t\t\t\t\t\tif self._nodes[path].getAddress() == 'empty':\n\t\t\t\t\t\t\t\tcurrentNode = self._nodes[path]\n\t\t\t\t\telse: # not empty quotes\n\t\t\t\t\t\tif float(line[featureIndex]) <= splitValue: # under\n\t\t\t\t\t\t\t#print 'under'\n\t\t\t\t\t\t\tfor path in currentNode.getPaths():\n\t\t\t\t\t\t\t\tif self._nodes[path].getAddress() == 'under':\n\t\t\t\t\t\t\t\t\tcurrentNode = self._nodes[path]\n\t\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\telse :  # over\n\t\t\t\t\t\t\t#print 'over'\n\t\t\t\t\t\t\tfor path in currentNode.getPaths():\n\t\t\t\t\t\t\t\tif self._nodes[path].getAddress() == 'over':\n\t\t\t\t\t\t\t\t\tcurrentNode = self._nodes[path]\n\t\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t#print featureIndex\n\t\t\t\t\t\tline = np.delete(line,featureIndex,0)\n\t\t\t\t\t#raw_input('-------------')\t\n\t\t\t\telse: # error\n\t\t\t\t\t#print 'Error: class:Tree -> function:Test -> branchType unrecognized'\n\t\t\t\t\tquit()\n\t\t\t#print 'predicted value'\n\t\t\t#print currentNode.getValue()\n\t\t\t#print type(currentNode.getValue())\n\t\t\tresultsStr += str(testIds[countForIdRetrieval])+','+str(currentNode.getValue())+'\\n'\n\t\t\tcountForIdRetrieval += 1\n\t\t\t#raw_input()\n\n\t\treturn resultsStr\t\n\t\t\n\tdef PrintTree(self,nodeId,depth):\n\t\tif self._nodes.has_key(nodeId):\n\t\t\tif self._nodes[nodeId].getType() == 'Branching':\n\t\t\t\tpaths =  self._nodes[nodeId].getPaths()\n\t\t\t\t#print paths\n\t\t\t\t#print '-'*10\n\t\t\t\tfor path in paths:\n\t\t\t\t\t#print str(depth)+' '+path+'---->path'\n\t\t\t\t\tself.PrintTree(path,depth+1)\n\t\t\t\treturn\n\t\t\telse:\n\t\t\t\t#print str(depth)+' '+str(self._nodes[nodeId].getValue())\n\t\t\t\treturn\n\t\telse:\n\t\t\treturn\n\t\t\n\n\t\t\n#******************************************************************\n\n\n\nif __name__ == '__main__':\n\tf = open('train.csv','r')\n\tfileData = f.read().split('\\n')[:-1]                          # read file data into a list, remove last line\n\tfileData = fileData[: -( len(fileData)-len(fileData)/10 ) ] # grab subsection of full data from file\n\t##print len(fileData)\n\tf.close()\n\t\n\t# Break fileData list members into lists themselves\n\t# place in list named data\n\tdata = []\n\tfor line in fileData:\n\t\tline = line.split(',')\n\t\tdel line[23]\n\t\tdel line[52]\n\t\tdel line[55]\n\t\tdel line[77]\n\t\tdel line[109]\n\t\tdel line[109]\n\t\tdel line[120]\n\t\t#quit()\n\t\tdata.append(line)\n\t\t\n\n#---------------IN PROGRESS\n\t#data= data[:-2]\n\t#splitData = np.split(np.array(data),112/14.0,0)\n#--------------------------\n\n\t#featuresList   -> Label (feature name) for each column of data \n\t#membershipData -> Classification (target answer) for individual data\n\t#dataT          -> Transposed member data, each line is list of members data for a single feature\n\tfeaturesList = data[0][2:] # omit 'ID' and 'Target'\n\n\tdata = data[1:]            # omit feature list from data\n\n\tdataT = np.transpose(data) \n\tmembershipData =  dataT[1] \n\tdataT = dataT[2:] \t\t\t\t #omit id and target from member data\n\n\t# Create Tree\n\n\tprint 'beginning training'\n\ttree = Tree(featuresList,membershipData,dataT)\n\n\tf = open('test.csv')\n\ttestFileData = f.read().split('\\n')[:-1]\n\tf.close()\n\ttestData = []\n\tfor line in testFileData:\n\t\tline = line.split(',')\n\t\tdel line[22]\n\t\tdel line[51]\n\t\tdel line[54]\n\t\tdel line[76]\n\t\tdel line[108]\n\t\tdel line[108]\n\t\tdel line[119]\n\t\ttestData.append(line)\n \n\t#-------------------------------------------\n\ttestFeaturesList = testData[0][:1] # omit ID\n\n\ttestData = testData[1:]            # omit feature list ftom test data\n\ttestDataT = np.transpose(testData)\n\ttestIds = testDataT[0]\n\ttestDataTT = np.transpose(testDataT[1:])\n\n\tprint 'beginning test...'\n\tresults = tree.Test(testDataTT,testIds)\n\tprint 'writing results to file.'\n\tf = open('decisionTreeResults.csv','w')\n\tfileStr = 'ID,PredictedProb\\n'+results\n\tf.write(fileStr)\n\tf.close()\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}