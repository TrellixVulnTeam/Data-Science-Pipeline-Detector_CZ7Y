{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import the datasets\ntrain = pd.read_csv('../input/bnp-paribas-cardif-claims-management/train.csv.zip')\ntest = pd.read_csv('../input/bnp-paribas-cardif-claims-management/test.csv.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Features and Observations\nprint('Training Set : %d observations & %d features'%(train.shape[0],train.shape[1]))\nprint('Test Set : %d observations & %d features'%(test.shape[0],test.shape[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fill Missing Categorical Values with most frequent occuring\ntrain = train.fillna(train.mode().iloc[0])\ntest = test.fillna(test.mode().iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fill Missing numeric value with mean of respective column\ntrain = train.fillna(value=train.mean())\ntest = test.fillna(value=train.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_var = [key for key in dict(train.dtypes)\n             if dict(train.dtypes)[key] in ['object'] ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain['v3'] = le.fit_transform(train['v3'])\ntrain['v22'] = le.fit_transform(train['v22'])\ntrain['v24'] = le.fit_transform(train['v24'])\ntrain['v30'] = le.fit_transform(train['v30'])\ntrain['v31'] = le.fit_transform(train['v31'])\ntrain['v47'] = le.fit_transform(train['v47'])\ntrain['v52'] = le.fit_transform(train['v52'])\ntrain['v56'] = le.fit_transform(train['v56'])\ntrain['v66'] = le.fit_transform(train['v66'])\ntrain['v71'] = le.fit_transform(train['v71'])\ntrain['v74'] = le.fit_transform(train['v74'])\ntrain['v75'] = le.fit_transform(train['v75'])\ntrain['v79'] = le.fit_transform(train['v79'])\ntrain['v91'] = le.fit_transform(train['v91'])\ntrain['v107'] = le.fit_transform(train['v107'])\ntrain['v110'] = le.fit_transform(train['v110'])\ntrain['v112'] = le.fit_transform(train['v112'])\ntrain['v113'] = le.fit_transform(train['v113'])\ntrain['v125'] = le.fit_transform(train['v125'])\n\ntest['v3'] = le.fit_transform(test['v3'])\ntest['v22'] = le.fit_transform(test['v22'])\ntest['v24'] = le.fit_transform(test['v24'])\ntest['v30'] = le.fit_transform(test['v30'])\ntest['v31'] = le.fit_transform(test['v31'])\ntest['v47'] = le.fit_transform(test['v47'])\ntest['v52'] = le.fit_transform(test['v52'])\ntest['v56'] = le.fit_transform(test['v56'])\ntest['v66'] = le.fit_transform(test['v66'])\ntest['v71'] = le.fit_transform(test['v71'])\ntest['v74'] = le.fit_transform(test['v74'])\ntest['v75'] = le.fit_transform(test['v75'])\ntest['v79'] = le.fit_transform(test['v79'])\ntest['v91'] = le.fit_transform(test['v91'])\ntest['v107'] = le.fit_transform(test['v107'])\ntest['v110'] = le.fit_transform(test['v110'])\ntest['v112'] = le.fit_transform(test['v112'])\ntest['v113'] = le.fit_transform(test['v113'])\ntest['v125'] = le.fit_transform(test['v125'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalize skewed features\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\n\nnumeric_feats = train.dtypes[train.dtypes != 'object'].index\nskewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\ntrain[skewed_feats] = np.log1p(train[skewed_feats])\ntest[skewed_feats] = np.log1p(test[skewed_feats])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation Matrix\ncolormap = plt.cm.viridis\ncor = train.corr()\ncor = cor.drop(['ID'],axis=1).drop(['ID'],axis=0)\n#plt.figure(figsize=(12,12))\n#sns.heatmap(cor,vmax=0.8,cmap=colormap,annot=True,fmt='.2f',square=True,annot_kws={'size':10},linecolor='white',linewidths=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#47 features have coeff >= 0.00\nk = 47 #number of variables for heatmap\ncols = cor.nlargest(k, 'target')['target'].index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1.25)\nplt.figure(figsize=(25,25))\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values, linecolor='white')\nplt.show()\n\nprint('Features with Maximum Correlation with target:\\n',cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Next, pair plot some important features\nimp_feats = cols[:10]\nsns.pairplot(train[imp_feats],height=2.5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing outliers as seen from the pairplot\nctr_removed = 0 \nfor i in range(len(train)):\n    if train['v50'][i] > 3 or train['v50'][i] < 0:\n        train = train.drop(index = i, axis = 0)\n        ctr_removed += 1\n        i += 1\n    if train['v10'][i] > 2.20 or train['v10'][i] < 0:\n        train = train.drop(index = i, axis = 0)\n        ctr_removed += 1\n        i += 1\n    if train['v14'][i] > 18.5 or train['v14'][i] < 5:\n        train = train.drop(index = i, axis = 0)\n        ctr_removed += 1\n        i += 1\n    if train['v34'][i] > 15 or train['v34'][i] < 0.5:\n        train = train.drop(index = i, axis = 0)\n        ctr_removed += 1\n        i += 1\n    if train['v114'][i] < 3:\n        train = train.drop(index = i, axis = 0)\n        ctr_removed += 1\n        i += 1\n    if train['v14'][i] < 4:\n        train = train.drop(index = i, axis = 0)\n        ctr_removed += 1\n        i += 1\n    if train['v21'][i] > 18 or train['v21'][i] < 0.5:\n        train = train.drop(index = i, axis = 0)\n        ctr_removed += 1  \n        i += 1\nprint('Total samples removed : ',ctr_removed)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train\nX = X.drop(labels = ['target','ID'],axis = 1)\ny = train['target']\nX_submit = test.drop(labels = ['ID'],axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)\nX_submit = sc.transform(X_submit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Important features after removal after outliers\nimp_feats = cols[:10]\nsns.pairplot(train[imp_feats],height=2.5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Take a further look at v50\n#train['v50'] = np.log1p(train['v50'] )\nfacet = sns.FacetGrid(train, hue='target',size=5,aspect=3,palette='seismic')\nfacet.map(plt.hist,'v50',bins=30,alpha=0.5)\nfacet.set(xlim=(0,train.v10.max()+10))\nfacet.add_legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctr_0, ctr_1 = 0, 0\nfor i in range(len(y)):\n    if np.array(y)[i] == 0:\n        ctr_0 += 1\n    else:\n        ctr_1 += 1\n\nprint('Count of target = 1 : ', ctr_1)\nprint('Count of target = 0 : ', ctr_0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.85, shuffle = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import skew\nfrom scipy.stats import mode\nfrom scipy.optimize import minimize\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,GradientBoostingClassifier, VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Modelling**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nxgb1 = xgb.XGBClassifier()\nparameters = {'learning_rate': [0.01],\n              'booster' : ['gbtree'],\n              'n_estimators': [8000,9000,10000],\n              'min_child_weight': [0],\n              #'max_depth': [0,8,16,24],\n              'max_delta_step': [0],\n              'gamma': [0],\n              'scale_pos_weight' : [ctr_0/ctr_1],\n              'random_state' : [0],\n              'tree_method' : ['gpu_hist'],\n              'n_jobs' : [4]}\n\nxgb_grid = GridSearchCV(xgb1,\n                        parameters,\n                        cv = 2,\n                        verbose=True,\n                        n_jobs=4)\n\nxgb_grid.fit(X,y)\n\nprint(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the model\nclf = xgb.XGBClassifier(learning_rate = 0.01,\n                        scale_pos_weight = ctr_0/ctr_1,\n                        n_estimators = 10000, \n                        tree_method = \"gpu_hist\",\n                        booster = \"gbtree\", \n                        n_jobs = -1)\nclf.fit(X,y)\ny_pred_xgb = clf.predict_proba(X_submit)[:,1]\n#print(clf.feature_importances_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier as etc\nfrom sklearn.model_selection import GridSearchCV\netc_clf = ExtraTreesClassifier(random_state = 0)\nparameters = {'n_estimators' : [1200],\n              'criterion' : ['entropy'],\n              'max_depth' : [30],\n              'min_samples_split' : [2],\n              'min_samples_leaf' : [2],\n              'random_state' : [0]}\n\netc_grid = GridSearchCV(etc_clf,parameters,cv = 3,verbose=True,n_jobs=-1)\n\netc_grid.fit(X,np.array(y))\n\nprint(etc_grid.best_score_)\nprint(etc_grid.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"etc = ExtraTreesClassifier(n_estimators = 1000,\n                           criterion = 'entropy',\n                           max_features = 50, \n                           max_depth = 35, \n                           min_samples_split = 4,\n                           min_samples_leaf = 2,\n                           n_jobs = -1)\netc.fit(X,y)\ny_pred_etc = etc.predict_proba(X_submit)[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import catboost as cat\nmodel_cat = cat.CatBoostClassifier(loss_function = 'Logloss',\n                                   eval_metric = 'Logloss',\n                                   learning_rate = 0.03,\n                                   iterations = 3000,\n                                   l2_leaf_reg = 3,\n                                   random_seed = 432013,\n                                   subsample = 0.66,\n                                   od_type = 'Iter',\n                                   rsm = 0.2,\n                                   depth = 6,\n                                   border_count = 128)\nmodel_cat.fit(X,y)\ny_pred_cat = model_cat.predict_proba(X_submit)[:,1]","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_9 = y_pred_xgb*0.1 + y_pred_etc*0.2 + y_pred_cat*0.7\ny_pred_10 = y_pred_xgb*0.2 + y_pred_etc*0.3 + y_pred_cat*0.5\ny_pred_11 = y_pred_xgb*0.2 + y_pred_etc*0.2 + y_pred_cat*0.6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_9 = y_pred_etc*0.5 + y_pred_cat*0.5\ny_pred_10 = y_pred_etc*0.3 + y_pred_cat*0.7\ny_pred_11 = y_pred_etc*0.7 + y_pred_cat*0.3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['PredictedProb'] = y_pred_9\nX_submission = test[['ID','PredictedProb']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_submission.to_csv('Submission_etc_cat_0.5_0.5.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['PredictedProb'] = y_pred_10\nX_submission = test[['ID','PredictedProb']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_submission.to_csv('Submission_etc_cat_0.3_0.7.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['PredictedProb'] = y_pred_11\nX_submission = test[['ID','PredictedProb']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_submission.to_csv('Submission_etc_cat_0.7_0.3.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}