{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\nimport csv\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print('Load data...')\ntrain = pd.read_csv(\"../input/train.csv\")\ntarget = train['target']\ntrain = train.drop(['ID','target'],axis=1)\ntest = pd.read_csv(\"../input/test.csv\")\nids = test['ID'].values\ntest = test.drop(['ID'],axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print('Clearing...')\nfor (train_name, train_series), (test_name, test_series) in zip(train.iteritems(),test.iteritems()):\n    if train_series.dtype == 'O':\n        #for objects: factorize\n        train[train_name], tmp_indexer = pd.factorize(train[train_name])\n        test[test_name] = tmp_indexer.get_indexer(test[test_name])\n        #but now we have -1 values (NaN)\n    else:\n        #for int or float: fill NaN\n        tmp_len = len(train[train_series.isnull()])\n        if tmp_len>0:\n            train.loc[train_series.isnull(), train_name] = 0 #train_series.mean()\n        #and Test\n        tmp_len = len(test[test_series.isnull()])\n        if tmp_len>0:\n            test.loc[test_series.isnull(), test_name] = 0 #train_series.mean()  #TODO"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"xgtrain = xgb.DMatrix(train.values, target.values)\nxgtest = xgb.DMatrix(test.values)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"xgboost_params = { \n   \"objective\": \"binary:logistic\",\n   \"booster\": \"gbtree\",\n   \"eta\": 0.017483,\n   \"min_child_weight\": 4.436,\n   \"subsample\": 0.812,\n   \"colsample_bytree\": 0.844,\n   \"max_depth\": 5,\n   \"gamma\":0.00036354432647887241\n}\n\nclf = xgb.train(xgboost_params\n                , xgtrain\n                , num_boost_round=500\n                , verbose_eval=True\n                , maximize=False)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_preds = clf.predict(xgtrain, ntree_limit=clf.best_iteration)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"a = np.transpose(np.vstack([target, train_preds]))\na\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"predictions_file = open(\"result.csv\", \"w\")\nopen_file_object = csv.writer(predictions_file)\n#open_file_object.writerow([\"ID\", \"PredictedProb\"])\n#open_file_object.writerows(zip(ids, test_preds))\nopen_file_object.writerows(a)\npredictions_file.close()"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}