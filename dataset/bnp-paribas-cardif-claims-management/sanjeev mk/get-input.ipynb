{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n# coding: utf-8\n\n# In[108]:\n\nimport pandas as pd\nfrom sklearn.feature_extraction import DictVectorizer\nimport numpy as np\n\n# In[187]:\n\ndf = pd.read_csv('../input/train.csv')\ntdf = pd.read_csv('../input/test.csv')\n\n# In[191]:\n\ncatdf = df.select_dtypes(['object'])\ntcatdf = tdf.select_dtypes(['object'])\ncatdf.fillna(\"NA\",inplace=True)\ntcatdf.fillna(\"NA\",inplace=True)\n\nv22df = catdf.loc[:,['v22']]\ntv22df = tcatdf.loc[:,['v22']]\nv22df.fillna(\"NA\",inplace=True)\ntv22df.fillna(\"NA\",inplace=True)\ndel catdf['v22']\ndel tcatdf['v22']\n\n# In[195]:\n\nvec = DictVectorizer()\nvectorized_catdf = vec.fit_transform(catdf.to_dict('records')).toarray()\ntvectorized_catdf = vec.transform(tcatdf.to_dict('records')).toarray()\n\n# In[197]:\n\nnumtrainrows = v22df['v22'].shape[0]\nnumtestrows = tv22df['v22'].shape[0]\n\ntotalv22 = pd.concat([v22df,tv22df])\nx = pd.Categorical(totalv22['v22'])\n\n# In[198]:\n\nv22columncodes = x.codes\nv22column = v22columncodes[:numtrainrows]\ntv22column = v22columncodes[numtrainrows:]\n# In[199]:\n\nv22column = np.matrix(v22column).T\ntv22column = np.matrix(tv22column).T\n\n# In[200]:\n\nvectorized_catdf = np.hstack((vectorized_catdf,v22column))\ntvectorized_catdf = np.hstack((tvectorized_catdf,tv22column))\n\n# In[202]:\n\ndf_withoutid_target = df.drop(['ID'],axis=1)\ntdf_withoutid_target = tdf.drop(['ID'],axis=1)\n\n\n# In[205]:\n\ncategorical_columns = df.select_dtypes(['object']).columns\ndf_without_categ_also = df_withoutid_target.drop(categorical_columns,axis=1)\ntdf_without_categ_also = tdf_withoutid_target.drop(categorical_columns,axis=1)\n\ndf_without_categ_also.fillna(df.mean(axis=0),inplace=True)\ntdf_without_categ_also.fillna(df.mean(axis=0),inplace=True)\n# In[209]:\n\nnoncat_columns = df_without_categ_also.as_matrix()\ntnoncat_columns = tdf_without_categ_also.as_matrix()\nprint(noncat_columns.shape,vectorized_catdf.shape,tnoncat_columns.shape,tvectorized_catdf.shape)\nfinal_data_matrix = np.hstack((noncat_columns,vectorized_catdf))\ntfinal_data_matrix = np.hstack((tnoncat_columns,tvectorized_catdf))\nheader = range(final_data_matrix.shape[1])\ntheader = range(tfinal_data_matrix.shape[1])\n\nindex = range(final_data_matrix.shape[0])\ntindex = range(tfinal_data_matrix.shape[0])\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df = pd.DataFrame(final_data_matrix,index=index,columns=header)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"testdf = pd.DataFrame(tfinal_data_matrix,index=tindex,columns=theader)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"testdfforid =pd.read_csv(\"../input/test.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"labeldf = df.loc[:,[0]]\niddf = testdfforid.loc[:,['ID']]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df.drop([0],axis=1,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"trainx = df.as_matrix()\ntrainy = labeldf.as_matrix()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"testx = testdf.as_matrix()\ntestids = iddf.as_matrix()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def testandsubmit(clf,test):\n    predictions = clf.predict_proba(test)\n    predictions = [p[1] for p in predictions]\n    f = open('../working/submission.csv','wb')\n    f.write(\"ID,PredictedProb\\n\")\n    for i in range(len(predictions)):\n        f.write(str(testids[i][0])+\",\"+str(predictions[i]) + \"\\n\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport math\nfrom sklearn.cross_validation import train_test_split"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\n\ndef main():\n    global processedtrainx,processedtrainy,trainx,trainy,testx\n    pca = PCA(n_components=15)\n    scaler = StandardScaler()\n    print(trainx.shape,testx.shape)\n    processedtrainx = scaler.fit_transform(trainx)\n    #processedtrainx = pca.fit_transform(processedtrainx)\n    #print(pca.explained_variance_ratio_)\n    processedtrainy = trainy\n   \n    testx = scaler.transform(testx)\n    #testx = pca.transform(testx)\n    \n    X_train, X_test, y_train, y_test = train_test_split(processedtrainx, processedtrainy, test_size=0.1, random_state=0)\n    clf = RandomForestClassifier(n_estimators=80,max_features=60,max_depth=40,criterion='entropy',class_weight='balanced_subsample')\n    clf.fit(X_train,y_train)\n    probabs = clf.predict_proba(X_train)\n    probabs = [p[1] for p in probabs]\n    print(log_loss(y_train, np.array(probabs)  ))\n    validatepredict = clf.predict_proba(X_test)\n    validatepredict = [p[1] for p in validatepredict]\n    print(log_loss( y_test,validatepredict))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"main()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}