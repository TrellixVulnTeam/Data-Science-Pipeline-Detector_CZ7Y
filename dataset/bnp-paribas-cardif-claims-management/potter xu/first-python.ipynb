{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train=pd.read_csv(\"../input/train.csv\")\ntest=pd.read_csv(\"../input/test.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.shape,test.shape"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import log_loss\nimport xgboost as xgb\nfrom sklearn.naive_bayes import BernoulliNB\n\n\ndef Binarize(columnName, df, features=None):\n    df[columnName] = df[columnName].astype(str)\n    if(features is None):\n        features = np.unique(df[columnName].values)\n    print(features)\n    for x in features:\n        df[columnName+'_' + x] = df[columnName].map(lambda y:\n                                                    1 if y == x else 0)\n    df.drop(columnName, inplace=True, axis=1)\n    return df, features\n\n\ndef MungeData(train, test):\n\n    todrop = ['v22', 'v112', 'v125', 'v74', 'v1', 'v110', 'v47']\n    print(todrop)\n\n    train.drop(todrop,\n               axis=1, inplace=True)\n    test.drop(todrop,\n              axis=1, inplace=True)\n\n    features = train.columns[2:]\n    for col in features:\n        if((train[col].dtype == 'object')):\n            print(col)\n            train, binfeatures = Binarize(col, train)\n            test, _ = Binarize(col, test, binfeatures)\n            nb = BernoulliNB()\n            nb.fit(train[col+'_'+binfeatures].values, train.target.values)\n            train[col] = \\\n                nb.predict_proba(train[col+'_'+binfeatures].values)[:, 1]\n            test[col] = \\\n                nb.predict_proba(test[col+'_'+binfeatures].values)[:, 1]\n            train.drop(col+'_'+binfeatures, inplace=True, axis=1)\n            test.drop(col+'_'+binfeatures, inplace=True, axis=1)\n\n    features = train.columns[2:]\n    train[features] = train[features].astype(float)\n    test[features] = test[features].astype(float)\n    train.fillna(-1, inplace=True)\n    test.fillna(-1, inplace=True)\n    return train, test\n\n\ndef Mother(train, test):\n    features = train.columns[2:]\n    num_rounds = 100\n    params = {}\n    params[\"objective\"] = \"binary:logistic\"\n    params[\"eta\"] = 0.01\n    params[\"min_child_weight\"] = 3\n    params[\"subsample\"] = 0.8\n    params[\"colsample_bytree\"] = 0.7\n    params[\"silent\"] = 1\n    params[\"max_depth\"] = 10\n    params[\"eval_metric\"] = \"logloss\"\n\n    trainpredictions = pd.DataFrame({'ID': train.ID.values,\n                                     'target': train.target.values})\n    testpredictions = pd.DataFrame({'ID': test.ID.values})\n\n    dvisibletrain = xgb.DMatrix((train[features].values),\n                                train.target.values,\n                                silent=True)\n\n    dblindtrain = xgb.DMatrix((train[features].values),\n                              train.target.values,\n                              silent=True)\n    dblindtest = xgb.DMatrix((test[features].values),\n                             silent=True)\n\n    watchlist = [(dblindtrain, 'eval'), (dvisibletrain, 'train')]\n    gbm = xgb.train(params, dvisibletrain, num_rounds,\n                    evals=watchlist, early_stopping_rounds=50,\n                    verbose_eval=True)\n\n    predictions1 = gbm.predict(dblindtrain)\n    score = log_loss(train.target.values,\n                     predictions1)\n\n    trainpredictions['PredictedProb'] = predictions1\n    predictions2 = gbm.predict(dblindtest)\n    testpredictions['PredictedProb'] = predictions2\n    return score, trainpredictions, testpredictions\n\n\nif __name__ == \"__main__\":\n    print('Start')\n    print('Importing Data')\n    train = pd.read_csv('../input/train.csv')\n    test = pd.read_csv('../input/test.csv')\n    print(train[train.target == 0].shape[0])\n    print(train[train.target == 1].shape[0])\n    print('Munge Data')\n    train, test = MungeData(train, test)\n    print('Start Train')\n    score, secondtrain, secondtest = Mother(train, test)\n    print('Start Output')\n    secondtrain.to_csv('2ndnbxgbtrain.csv', index=False)\n    secondtest.to_csv('2ndnbxgbtest.csv', index=False)\n    print('Primary Score', score)\n    print('Finish')"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}