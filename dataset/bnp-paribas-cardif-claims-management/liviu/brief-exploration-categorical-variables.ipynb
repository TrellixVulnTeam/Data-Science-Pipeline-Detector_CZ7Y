{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Disclaimer: I'm a Kaggle beginner, and this may not necessarily be a good way to treat categorical variables.\n# If you have any suggestions or corrections, please let me know.\n\n%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom IPython import embed\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 7"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"target = train['target']\ntrain.drop('target', axis=1, inplace=True)"},{"cell_type":"markdown","metadata":{},"source":"## Non null columns"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(train.columns[np.where(train.isnull().any().values == False)])"},{"cell_type":"markdown","metadata":{},"source":"These are the columns with no null values, which seems to make a very small part of the dataset, so imputation will be required for algorithms that don't handle null values automatically.\n\n## Non numeric columns"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"non_numeric_columns = list(set(train.columns) - set(train.select_dtypes(include=[np.number]).columns))\nprint(non_numeric_columns)"},{"cell_type":"markdown","metadata":{},"source":"The columns above are the ones whose values are not numeric (probably strings), so they must be encoded in some sorts of numeric form.\n\n## Count of non numeric values for each feature"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"D = {}\nfor column in non_numeric_columns:\n    col = getattr(train, column)\n    D[column] = len(col.value_counts())\n\nplt.bar(range(len(D)), D.values(), align='center')\nplt.xticks(range(len(D)), D.keys())\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"## What's that spike?\n\nIt's actually obvious from the graph if it's big enough, but I'll just leave this here."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(max(D.keys(), key=lambda key: D[key]))"},{"cell_type":"markdown","metadata":{},"source":"## What's v22?"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.v22[target == 1].value_counts()[:50].plot()\ntrain.v22[target == 0].value_counts()[:50].plot()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"target.value_counts()"},{"cell_type":"markdown","metadata":{},"source":"They seem quite correlated to be honest, and the discrepancy can be explained by the class difference in `target`. I'll just discard this value\n\nWhile posting this, I realised that a better way is to encode all variables and actually compute relationships with Pearson's correlation or mutual information (for nonlinear relationships). Moreso, the graphs are not very good indicators, as the xticks are the ones used for the second plot, and they might differ for the two. Luckily, I don't think it mattered too much in this example."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.drop('v22', axis=1, inplace=True)\ntest.drop('v22', axis=1, inplace=True)\n\ndel D['v22']"},{"cell_type":"markdown","metadata":{},"source":"## Check the new non numeric variables"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"plt.bar(range(len(D)), D.values(), align='center')\nplt.xticks(range(len(D)), D.keys())\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"## Examine v56"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.v56[target == 1].value_counts()[:100].plot()\ntrain.v56[target == 0].value_counts()[:100].plot()"},{"cell_type":"markdown","metadata":{},"source":"This may be silly, but it looks like only the first jump is significantly different between the 2, so I will use one-hot encoding only for the 2 most common variables for each case."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def get_common_values(df, var, number):\n    return (set(df[var][target == 1].value_counts().keys()[:number]) |\n                   set(df[var][target == 0].value_counts().keys()[:number]))\n\ncommon_v56 = get_common_values(train, 'v56', 2)\nprint(common_v56)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def encode_value(df, val, col):\n    positives = df[df[col] == val][col].index\n    df[\"{}_{}\".format(col, val)] = [1 if i in positives else 0 for i in range(len(df))]\n    return df"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"for value in common_v56:\n    train = encode_value(train, value, \"v56\")\n    test = encode_value(test, value, \"v56\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.drop('v56', axis=1, inplace=True)\ntest.drop('v56', axis=1, inplace=True)\n\ndel D['v56']"},{"cell_type":"markdown","metadata":{},"source":"## One more categorical variable"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"plt.bar(range(len(D)), D.values(), align='center')\nplt.xticks(range(len(D)), D.keys())\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"## v125"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.v125[target == 1].value_counts()[:100].plot()\ntrain.v125[target == 0].value_counts()[:100].plot()"},{"cell_type":"markdown","metadata":{},"source":"This one looks a lot less correlated in my opinion, especially for top values.\n\n## Zooming in small a section\n\nJust \"zooming\" in a bit to see if there's a trend among lower values that can't be observed due to the scale."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.v125[target == 1].value_counts()[50:70].plot()\ntrain.v125[target == 0].value_counts()[50:70].plot()"},{"cell_type":"markdown","metadata":{},"source":"For this one, I will encode the first 10 most common variables from each class."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"common_v125 = get_common_values(train, 'v125', 10)\nprint(common_v125)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"for value in common_v125:\n    train = encode_value(train, value, \"v125\")\n    test = encode_value(test, value, \"v125\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(train.shape)\nprint(test.shape)"},{"cell_type":"markdown","metadata":{},"source":"## Conclusion\n\nThis may not be the best way, or even a good way to do it, but it's the path I happened to take for this exploration. The other variables have fewer categories, and I might just one-hot all of them or look into different methods. If anyone has any corrections or advice, I'd appreciate if you let me know, as I'm doing this primarly to learn."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}