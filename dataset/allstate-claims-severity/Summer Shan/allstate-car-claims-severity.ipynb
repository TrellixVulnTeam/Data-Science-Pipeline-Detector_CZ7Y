{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Objective**\n\n\nThe purpose of this project is to create machine learning models that could accurately predict the severity of auto claims from independent numerical and categorical variables. The dataset is provided by Allstate Insurance, a P&C insurance company that is specialized in auto insurance in North America. Extreme Gradient Boosting (XGBoost) is used to create 1000 cycles of modeling with new models add into every round of cycle. Lastly, mean absolute error is used to evaluate how well the models able to predict the severity of auto claims."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport sklearn\nimport xgboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load train and test data from the Kaggle competition input links\n# Use 'describe' to check: number of unique values in categorical variables\n#                          and summary statistics for numerical variables\npath = '/kaggle/input/allstate-claims-severity/train.csv'\npath_test = '/kaggle/input/allstate-claims-severity/test.csv'\ncar_data = pd.read_csv(path, index_col=['id'])\ncar_data_test = pd.read_csv(path_test, index_col=['id'])\n\ncar_data.head()\ncar_data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# --------Method 1----------\n# Used XGBoost (extreme gradient boosting) to iterativelly adding model\n# into existing modeles to improve the mean absolute squares\n# Split the data into train and validations sets by using train_test_split\nX = car_data.drop(columns = ['loss']).select_dtypes(exclude=['object'])\ny = car_data['loss']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 0)\ncar_model = XGBRegressor(n_estimators=1000, learning_rate=0.01)\ncar_model.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_valid, y_valid)], \n             verbose=False)\nclaims_predict = car_model.predict(X_valid)\nmean_absolute_error(claims_predict, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the entire train set to train the model\ncar_model_full = XGBRegressor(n_estimators=1000, learning_rate=0.05)\ncar_model_full.fit(X, y, \n             early_stopping_rounds=5, \n             eval_set=[(X_valid, y_valid)], \n             verbose=False)\ntest_preds = car_model_full.predict(car_data_test.select_dtypes(exclude=['object']))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# --------Method 2----------\n# Label categorical data to fit the mode\n# Find categorical variables that have less than 10 unique values\nX = car_data.drop(columns = ['loss'])\ny = car_data['loss']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 0)\n\nobject_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\nlow_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\nhigh_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\n\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_valid = X_valid.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Used XGBoost (extreme gradient boosting) to iterativelly adding model\n# into existing modeles to improve the mean absolute squares\ncar_model_2 = XGBRegressor(n_estimators=1000, learning_rate=0.01)\ncar_model_2.fit(OH_X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(OH_X_valid, y_valid)], \n             verbose=False)\nclaims_predict = car_model_2.predict(OH_X_valid)\nmean_absolute_error(claims_predict, y_valid)\n## mae = 1208","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the entire train set to train the second model \nOH_cols_full = pd.DataFrame(OH_encoder.fit_transform(X[low_cardinality_cols]))\nOH_cols_test = pd.DataFrame(OH_encoder.transform(car_data_test[low_cardinality_cols]))\n\nOH_cols_full.index = X.index\nOH_cols_test.index = car_data_test.index\n\nnum_X = X.drop(object_cols, axis=1)\nnum_X_test = car_data_test.drop(object_cols, axis=1)\n\nOH_X_full = pd.concat([num_X, OH_cols_full], axis=1)\nOH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n\ncar_model_full_2 = XGBRegressor(n_estimators=1000, learning_rate=0.05)\ncar_model_full_2.fit(OH_X_full, y, verbose=False)\ntest_preds = car_model_full_2.predict(OH_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output the csv prediction file and submit to Kaggle Leaderboard\noutput = pd.DataFrame({'id': car_data_test.index,\n                      'loss': test_preds})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}