{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/allstate-claims-severity/train.csv')\ntest = pd.read_csv('/kaggle/input/allstate-claims-severity/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/allstate-claims-severity/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train data dimensions: \", train.shape)\nprint(\"Test data dimensions: \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of missing values\",train.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking skewness and kurtosis to see if normally distributed continuous features\n#### The acceptable values are between -1.5 to +1.5"},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features = train.iloc[:,-15:-1]\ncont_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cont_features.skew())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cont_features.kurtosis())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysis of loss feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(13,9))\nsns.boxplot(train[\"loss\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13,9))\nsns.distplot(train[\"loss\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Loss is highly skewed to the right because there are many outliers in the data as we can see from box plot. So we can use log function to see if we can get a normal distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13,9))\nsns.boxplot(np.log1p(train[\"loss\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13,9))\nsns.distplot(np.log1p(train[\"loss\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now we have normal distribution by applying logarithm on loss function and we can train model using the same target feature without removing outliers."},{"metadata":{},"cell_type":"markdown","source":"### Convert categorical string values to numeric values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()\nfor i in train:\n    if 'cat' in i:\n        train[i] = enc.fit_transform(train[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop([\"id\",\"loss\"],axis=1)\nY = train[\"loss\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation and prediction\n ### XGBoost Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nmodel = XGBRegressor(n_estimators=1000)\nmodel.fit(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_predict = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nprint(\"r2 score is \", r2_score(Y_predict,Y_test))\nprint(\"MAE is \",mean_absolute_error(Y_predict,Y_test))\nprint(\"MSE score is \", mean_squared_error(Y_predict,Y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TEST DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = test['id']\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of missing values\",train.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = LabelEncoder()\nfor i in test:\n    if 'cat' in i:\n        test[i] = enc.fit_transform(test[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop([\"id\"],axis= 1)\ntest = sc.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(test_id)\nsubmission['prediction'] = prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('Submission_ACS.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}