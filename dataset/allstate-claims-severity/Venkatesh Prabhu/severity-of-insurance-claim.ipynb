{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Setting things up\n\nImport the necessary libraries."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/allstate-claims-severity/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the file names\nfiles = os.listdir(PATH)\nfiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the csv files as Pandas DataFrame and store it separate variables \nvariables = [x.replace('.csv', '') for x in files]\n\nfor v, f in zip(variables, files):\n    exec(\"%s=pd.read_csv(PATH+f)\" % v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping Id column from train and test sets\ntr, ts = train.drop(['id'], 1), test.drop(['id'], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overview of Train set\ntr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overview of Test set\nts.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\n\nLet us explore out data a bit. The more you understand the easier it gets while trying to fit a model on top of it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking shape\nprint(f'Shape of Train: {tr.shape}')\nprint(f'Shape of Test: {ts.shape}')\n\n# Inference: \n# There are 131 columns in train and 130 in test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for missing values\nprint(f'No.of missing values in Train: {tr.isnull().sum().sum()}')\nprint(f'No.of missing values in Test: {ts.isnull().sum().sum()}')\n\n# Inference: \n# There are no missing values in the dataset.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for different dtypes\npd.DataFrame({'Train': tr.dtypes.value_counts(), 'Test': ts.dtypes.value_counts()})\n\n# Inference: \n# There are no problems with the datatypes between train and test sets.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Understanding the categorical variables\ncategories = tr.describe(include='object')\ncategories\n\n# Inference: \n# We understand the no.of distinct values in each categorical columns and the most frequent one","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Understanding the continuous variables\nfig, axes = plt.subplots(4, 4, figsize=(24, 15))\n\nfor col, ax in zip(tr.select_dtypes(['float64']).columns, axes.flat):\n    sns.kdeplot(tr[col], shade=True, ax=ax)\n    ax.set_title(col)\nplt.show()\n\n# Inference: \n# We are having multi-modal distributions in some columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for skewness in the data\nplt.figure(figsize=(20,5))\nsns.barplot(tr.select_dtypes(['float64']).columns, tr.skew())\n\n# Inference:\n# No major skewness identified other than loss column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Understanding the correlation.\nplt.figure(figsize=(20, 10))\nsns.heatmap(tr.corr(), annot=True)\n\n# Inference: \n# There are certain independent variables correlated to other independent variables. These only adds bias to the model so we can remove them.\n# No feature is highly correlated with the target","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tranformation\n\nWe need to handle the skewness in our target. We can do that by taking log."},{"metadata":{"trusted":true},"cell_type":"code","source":"tr['loss'] = np.log1p(tr['loss'])\nsns.kdeplot(tr['loss'], shade=True)\n\n# Note:\n# We use np.log1p returns all positive log distribution rather than np.log which returns negative values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation\n\nThere is one more step before creating the model. We need to handle the categorical values in the dataset. We can use pd.get_dummies() function for that. Also we will be splitting the dataset into train, validation and test sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Shuffling the train set\n# tr = tr.sample(random_state=SEED, frac=1)\n\n# # Note: \n# # This shuffles the data. \n# # Shuffling is necessary so that after splitting the data into train, validation and test sets our model gets diverse amount of data to be trained on.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering categories having low percent of data distribution\n# Length of the dataframe / (No.of unique values * Frequency)\n\ndist_percent = np.divide(len(tr), np.multiply(categories.loc['unique'].values, categories.loc['freq'].values))\npercentages = pd.DataFrame({'column': categories.columns, 'percent': dist_percent})\ncat_cols = list(percentages[percentages['percent'] > 0.1]['column'].values)\n\nprint(f\"Filtered categories: {len(cat_cols)}\")\n\n# Note:\n# I am experimenting this technique and let us see if this works","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering continuous variables with correlation greater than 0.75\ncorr = tr.drop('loss', 1).corr().abs()\nupper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\nto_drop_num = [column for column in upper.columns if any(upper[column] > 0.6)]\nnum_cols = list(set(tr.drop('loss', 1).select_dtypes(['float64'])) - set(to_drop_num))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select only the filtered categories and continuous variables\nfinal_tr = tr[cat_cols + num_cols + ['loss']]\nfinal_ts = ts[cat_cols + num_cols]\nfinal_tr.shape, final_ts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prearing features and target before encoding\nfeatures = final_tr.drop('loss', 1)\ntarget = final_tr['loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encode train data\nfeatures = pd.get_dummies(features, columns=features.select_dtypes('object').columns)\nfeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encode test data\npayload = pd.get_dummies(final_ts, columns=final_ts.select_dtypes('object').columns)\npayload.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handling missing columns in train and test sets\nfeatures, payload = features.align(payload, join='outer', axis=1, fill_value=0)\nfeatures.shape, payload.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = features.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Scaling\n# from sklearn.preprocessing import StandardScaler\n\n# sc = StandardScaler()\n# features = sc.fit_transform(features)\n# payload = sc.transform(payload)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"SIZE = 0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx, x_test, y, y_test = train_test_split(features, target, random_state=SEED, test_size=SIZE)\nx_train, x_val, y_train, y_val = train_test_split(x, y, random_state=SEED, test_size=SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling\n\nWe will create a base model to understand the feature importances."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.metrics import mean_absolute_error, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"eval_set  = [(x_val,y_val)]\nmodel = CatBoostRegressor(random_state=SEED, \n                          n_estimators=6000,\n                          max_depth=3, \n                          learning_rate=0.1, \n                          loss_function='MAE', \n                          eval_metric='MAE', \n                          reg_lambda=3, \n                          verbose=100)\n%time model.fit(x_train, y_train, eval_set=eval_set, early_stopping_rounds=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = model.predict(x_train)\ny_val_pred = model.predict(x_val)\ny_test_pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"MAE Train: {mean_absolute_error(np.expm1(y_train_pred), np.expm1(y_train))}\")\nprint(f\"MAE Val: {mean_absolute_error(np.expm1(y_val_pred), np.expm1(y_val))}\")\nprint(f\"MAE Test: {mean_absolute_error(np.expm1(y_test_pred), np.expm1(y_test))}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importances = pd.DataFrame({'Feature': cols, 'Importance': np.round(model.feature_importances_, 4)}).sort_values('Importance', ascending=False)\n# importances[importances['Importance'] > 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scoring\n\nWe can now apply the model to the test set (payload in our case) to get the outcomes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scoring\npredictions = np.round(np.expm1(model.predict(payload)), 2)\n\nsubmission = pd.DataFrame({'id': test['id'], 'loss': pd.Series(predictions)})\nsubmission.to_csv('submission.csv', index=False)\n\n# Note:\n# We need to take the inverse for our predictions as it is the result of np.log1p(). We can do that using np.expm1() function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}