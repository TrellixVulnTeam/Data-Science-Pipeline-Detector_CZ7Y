{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"53e4ddd2-cf7d-e4ec-7a84-4f6fbc33c8c6"},"source":"**Just a starter code with Xgboost**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f884cd51-7170-9a57-1220-ef93c1e462b7"},"outputs":[],"source":"#Importing necessary libraries\nimport numpy as np\n\nimport pandas as pd\npd.set_option('display.width', 500)\npd.set_option('display.max_columns', 100)\npd.set_option('display.notebook_repr_html', True)\n\nimport xgboost as xgb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5cd142a8-1b36-6c15-e704-ee3945f93d44"},"outputs":[],"source":"# Reading and Formatting data\ntrainData = pd.read_csv('../input/train.csv')\ntestData = pd.read_csv('../input/test.csv')\nprint ((trainData.shape, testData.shape))\ny = trainData['loss']\ntrainData.drop('loss', axis =1, inplace = True)\nprint (trainData.shape)\n# Log makes the distribution more gaussian. From the discussion forums, shift of 200\n# seems to be giving the best results\ny = np.log(y.add(200)) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7010f2e7-2c74-2fb0-7fad-db0dd1ae79bb"},"outputs":[],"source":"trainData = trainData.append(testData)\nprint (trainData.shape)\ntrainData.head()\ntrainData.drop('id', axis=1, inplace = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"77a68edf-e5da-e92d-b41d-2da07803d000"},"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder\nlabCatEncode = LabelEncoder()\ntrainData.ix[:,0:116] = trainData.ix[:,0:116].apply(labCatEncode.fit_transform)\ntrain = trainData.iloc[:188318]\ntest = trainData.iloc[188318:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf8b8522-0770-e65c-cf67-d1e9a57d4f86"},"outputs":[],"source":"# Params for xgboost : Shamelessly copied from the user Tilii's kernel\nparams = {}\nparams['booster'] = 'gbtree'\nparams['objective'] = \"reg:linear\"\nparams['eval_metric'] = 'mae'\nparams['eta'] = 0.1\nparams['gamma'] = 0.5290\nparams['min_child_weight'] = 4.2922\nparams['colsample_bytree'] = 0.3085\nparams['subsample'] = 0.9930\nparams['max_depth'] = 7\nparams['max_delta_step'] = 0\nparams['silent'] = 1\nparams['random_state'] = 1001"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c7f1c80-d05e-1d42-dbe3-92d3068757b7"},"outputs":[],"source":"from sklearn.cross_validation import train_test_split\nXtrain,Xval,ytrain,yval = train_test_split(train.values, y.values, test_size  = 0.3)\ndTrain = xgb.DMatrix(Xtrain, label=ytrain)\ndVal = xgb.DMatrix(Xval, label=yval)\ndTest = xgb.DMatrix(test.values)\nwatchlist = [(dTrain, 'train'), (dVal, 'eval')]\nclf = xgb.train(params,dTrain,1000,watchlist,early_stopping_rounds=300)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32a7cfe5-fdb6-7693-218b-ce25df583111"},"outputs":[],"source":"Pred = pd.DataFrame()\nPred['id'] = testData['id']\nPred['loss'] = np.exp(clf.predict(dTest))\nPred['loss']  = Pred['loss'].add(-200)\nPred.to_csv('XGB_Starter.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}