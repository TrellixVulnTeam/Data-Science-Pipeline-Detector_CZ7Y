{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Allstate Claim Severity and Faron's Stacking Starter"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"This is a copy of Farons stacking starter code  https://www.kaggle.com/mmueller/stacking-starter as a notebock with some further print statements added to show what's going on"},{"metadata":{"_uuid":"647c7e812ef12a54e3588d5dd530f1f3afa914c7"},"cell_type":"markdown","source":"Task: Regression\n\nFirst level models: extra tree (et), random forest (rf) and XGBOOST (xg, gradient boosting)\n\nSecond level: XGBOOST\n"},{"metadata":{},"cell_type":"markdown","source":"### 0. Read and transform data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# read data, print data shape (feature set)\n\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.cross_validation import KFold\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nID = 'id'\nTARGET = 'loss'\nNFOLDS = 4\nSEED = 0\nNROWS = None\nDATA_DIR = \"../input\"\n\nTRAIN_FILE = \"{0}/train.csv\".format(DATA_DIR)\nTEST_FILE = \"{0}/test.csv\".format(DATA_DIR)\nSUBMISSION_FILE = \"{0}/sample_submission.csv\".format(DATA_DIR)\n\ntrain = pd.read_csv(TRAIN_FILE, nrows=NROWS)\ntest = pd.read_csv(TEST_FILE, nrows=NROWS)\n\ny_train = train[TARGET].ravel()\n\ntrain.drop([ID, TARGET], axis=1, inplace=True)\ntest.drop([ID], axis=1, inplace=True)\n\nprint(\"{},{}\".format(train.shape, test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3f3e03c7b63d02e60fcdd959aecfe51c86382f7"},"cell_type":"code","source":"# transform categories in numbers\n\nntrain = train.shape[0]\nntest = test.shape[0]\ntrain_test = pd.concat((train, test)).reset_index(drop=True)\n\nfeatures = train.columns\n\ncats = [feat for feat in features if 'cat' in feat]\nfor feat in cats:\n    train_test[feat] = pd.factorize(train_test[feat], sort=True)[0]\n\nprint(train_test.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30cd1e5bb9b0a8a62425ff62739b9c75ca7c1e2b"},"cell_type":"markdown","source":"### 1. First level models"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"081a58d548fa09a47d992fd9065c9e3aa0a582b8"},"cell_type":"code","source":"# define folds and wrapper functions, out-of-fold (oof)\n\nx_train = np.array(train_test.iloc[:ntrain,:])\nx_test = np.array(train_test.iloc[ntrain:,:])\n\nkf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n\n\nclass SklearnWrapper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf = clf(**params)\n\n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n\n    def predict(self, x):\n        return self.clf.predict(x)\n\n\nclass XgbWrapper(object):\n    def __init__(self, seed=0, params=None):\n        self.param = params\n        self.param['seed'] = seed\n        self.nrounds = params.pop('nrounds', 250)\n\n    def train(self, x_train, y_train):\n        dtrain = xgb.DMatrix(x_train, label=y_train)\n        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n\n    def predict(self, x):\n        return self.gbdt.predict(xgb.DMatrix(x))\n    \ndef get_oof(clf):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_te)\n        oof_test_skf[i, :] = clf.predict(x_test)\n\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"57cb905cbc3bd4227aa2164c3a9376614cdb4ed5"},"cell_type":"code","source":"# set hyper-parameters for extra tree (et), random forest (rf) and gradient boosting tool XGBOOST (xg)\n\net_params = {\n    'n_jobs': 16,\n    'n_estimators': 100,\n    'max_features': 0.5,\n    'max_depth': 12,\n    'min_samples_leaf': 2,\n}\n\nrf_params = {\n    'n_jobs': 16,\n    'n_estimators': 100,\n    'max_features': 0.2,\n    'max_depth': 8,\n    'min_samples_leaf': 2,\n}\n\nxgb_params = {\n    'seed': 0,\n    'colsample_bytree': 0.7,\n    'silent': 1,\n    'subsample': 0.7,\n    'learning_rate': 0.075,\n    'objective': 'reg:linear',\n    'max_depth': 7,\n    'num_parallel_tree': 1,\n    'min_child_weight': 1,\n    'eval_metric': 'mae',\n    'nrounds': 350\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"074a4c9abbeef628f7ca6640ecf5e6adc081a72e","collapsed":true},"cell_type":"code","source":"# train 1. level models:\n\nxg = XgbWrapper(seed=SEED, params=xgb_params)\net = SklearnWrapper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\nrf = SklearnWrapper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n\nxg_oof_train, xg_oof_test = get_oof(xg)\net_oof_train, et_oof_test = get_oof(et)\nrf_oof_train, rf_oof_test = get_oof(rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### First level results:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"XG-CV: {}\".format(mean_absolute_error(y_train, xg_oof_train)))\nprint(\"ET-CV: {}\".format(mean_absolute_error(y_train, et_oof_train)))\nprint(\"RF-CV: {}\".format(mean_absolute_error(y_train, rf_oof_train)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39326530dee330830cb36e66a7065dc37c5b143f"},"cell_type":"markdown","source":"### 2. Stacking"},{"metadata":{"trusted":true,"_uuid":"70297eb8e72dc55245089b77709ed90d7db72138"},"cell_type":"code","source":"#  generate new data set (based on first level predictions)\n\nx_train = np.concatenate((xg_oof_train, et_oof_train, rf_oof_train), axis=1)\nx_test = np.concatenate((xg_oof_test, et_oof_test, rf_oof_test), axis=1)\n\nprint(\"{},{}\".format(x_train.shape, x_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36deaa4742b7dbe5c436b541aba3931f14ec9fd2"},"cell_type":"code","source":"# show first level predicitions\nx_train_df = pd.DataFrame(x_train)\nx_train_df.head(10) # xg - et - rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"397632e15c08a4807cee51ebfbc4c93103d9fea0"},"cell_type":"code","source":"# set 2. level hyper-parameters\n\ndtrain = xgb.DMatrix(x_train, label=y_train)\ndtest = xgb.DMatrix(x_test)\n\nxgb_params = {\n    'seed': 0,\n    'colsample_bytree': 0.8,\n    'silent': 1,\n    'subsample': 0.6,\n    'learning_rate': 0.01,\n    'objective': 'reg:linear',\n    'max_depth': 4,\n    'num_parallel_tree': 1,\n    'min_child_weight': 1,\n    'eval_metric': 'mae',\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9d40a4aebe07ddd6d6e3c44d7235e08482aa0122"},"cell_type":"code","source":"# cross validation, print result\n\nres = xgb.cv(xgb_params, dtrain, num_boost_round=500, nfold=4, seed=SEED, stratified=False,\n             early_stopping_rounds=25, verbose_eval=10, show_stdv=True)\n\nbest_nrounds = res.shape[0] - 1\ncv_mean = res.iloc[-1, 0]\ncv_std = res.iloc[-1, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Second level result (stacking):"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### A much lower loss!"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6b39206229f07580ad17f4831ba781556debb744"},"cell_type":"code","source":"# train up to best round and write submission file\n\ngbdt = xgb.train(xgb_params, dtrain, best_nrounds)\n\nsubmission = pd.read_csv(SUBMISSION_FILE)\nsubmission.iloc[:, 1] = gbdt.predict(dtest)\nsubmission.to_csv('xgstacker_starter_logLoss.csv', index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}