{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"a281007a-5d64-7d67-fdd4-50e2f7b713ae"},"source":"All state"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7444e4f-3ec6-9d55-ea69-b6ec0363a9f6"},"outputs":[],"source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas\ndataset = pandas.read_csv(\"../input/train.csv\") \ndataset_test = pandas.read_csv(\"../input/test.csv\")\nID = dataset_test['id']\n\ndataset_test.drop('id',axis=1,inplace=True)\npandas.set_option('display.max_rows', None)\npandas.set_option('display.max_columns', None)\n\nprint(dataset.head(5))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f716aa9b-09d6-4ade-ae81-d2dfb6abf29d"},"outputs":[],"source":"import seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nlabels = []\nvalues = []\nfor col in dataset_test.columns:\n    labels.append(col)\n    values.append(dataset[col].isnull().sum())\n    print(col, values[-1])\nind = np.arange(len(labels))\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,50))\nrects = ax.barh(ind, np.array(values), color='y')\nax.set_yticks(ind+((width)/2.))\nax.set_yticklabels(labels, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\n#autolabel(rects)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc8783c5-69db-4d61-a7b1-cfab7ac7b64f"},"outputs":[],"source":"dataset.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8f7b65a-4988-0257-4ec1-2305475ca48f"},"outputs":[],"source":"dataset = dataset.iloc[:,1:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"081db0da-4249-0e90-2269-3ee49ce93e27"},"outputs":[],"source":"#cont data\ndata=dataset.iloc[:,116:] \nsize = 15\ndata_corr = data.corr()\n\n# Set the threshold to select only highly correlated attributes\nthreshold = 0.5\n\n# List of pairs along with correlation above threshold\ncorr_list = []\n\n#Search for the highly correlated pairs\nfor i in range(0,size): #for 'size' features\n    for j in range(i+1,size): #avoid repetition\n        if (data_corr.iloc[i,j] >= threshold and data_corr.iloc[i,j] < 1) or (data_corr.iloc[i,j] < 0 and data_corr.iloc[i,j] <= -threshold):\n            corr_list.append([data_corr.iloc[i,j],i,j]) #store correlation and columns index\n\n#Sort to show higher ones first            \ns_corr_list = sorted(corr_list,key=lambda x: -abs(x[0]))\n\n#Print correlations and column names\nfor v,i,j in s_corr_list:\n    print (\"%s and %s = %.2f\" % (data.columns[i],data.columns[j],v))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a3f1548-ac0e-69eb-e78d-a256385ec1e8"},"outputs":[],"source":"import scipy.stats as scs\nfrom sklearn.preprocessing import LabelEncoder as LE\n\ndef categories(series):\n    return range(int(series.min()), int(series.max()) + 1)\n\n\ndef chi_square_of_df_cols(df, col1, col2):\n    df_col1, df_col2 = df[col1], df[col2]\n    le1 = LE()\n    df_col1 = le1.fit_transform(df_col1)\n    df_col2 = le1.fit_transform(df_col2)\n\n    result = [[sum((df_col1 == cat1) & (df_col2 == cat2))\n               for cat2 in categories(df_col2)]\n              for cat1 in categories(df_col1)]\n\n    return scs.chi2_contingency(result)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6fd50243-d362-55cd-1142-4aeb23b89d96"},"outputs":[],"source":"#colsCat = dataset.columns[:116]\n#corr_list2 = []\n#for i in range(0,116): #for 'size' features\n#    for j in range(i+1,116): #avoid repetition\n#        ch = chi_square_of_df_cols(dataset,colsCat[i],colsCat[j])[0]\n#        print(\"Correlation between \" + colsCat[i] + \" \" + colsCat[j] +\" \" + str(ch))\n#        corr_list2.append([ch,i,j]) #store correlation and columns index\n\n#Sort to show higher ones first            \n#s_corr_list2 = sorted(corr_list2,key=lambda x: -abs(x[0]))\n\n#Print correlations and column names\n#for v,i,j in s_corr_list2:\n    #print (\"%s and %s = %.2f\" % (data.columns[i],data.columns[j],v))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f7859f0-b626-fe0e-cf2e-aa40ac2d0db7"},"outputs":[],"source":"y = dataset.loss\ndataset.drop([\"loss\"], axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"176501d1-91f8-a2ab-4dcb-fc223b99c9ff"},"outputs":[],"source":"dataset.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c9a533b-5d43-5ab9-e8be-9ef7b34eb24d"},"outputs":[],"source":"shapeTrain = dataset.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37451e03-2f42-0f43-53da-4a68e2663e01"},"outputs":[],"source":"data = dataset.append(dataset_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"327a697e-1a1a-0c44-6069-32e302535499"},"outputs":[],"source":"catCols = data.columns[:116]\nWasteCat = []\nfor col in catCols:\n    if data[col].value_counts()[0] > 310000:\n        print(col)\n        WasteCat.append(col)\nprint(len(WasteCat))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07c18358-3dc0-ef7c-2636-320ffad484c0"},"outputs":[],"source":"print(data.shape[0]*0.99)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dbf783ee-7de3-ee7a-5da5-edf7d333d5b3"},"outputs":[],"source":"#data.drop(WasteCat,axis=1,inplace=True)\ndata.drop([\"cont1\",\"cont11\"], axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f17f813a-a38c-3458-fef1-1fd33de8cd26"},"outputs":[],"source":"data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2066ae7c-43dd-31e9-9a61-f9a2fefdb918"},"outputs":[],"source":"catCols = data.columns[:116]\nfor col in catCols:\n    print(col)\n    data[col] = LE().fit_transform(data[col])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f3430429-42a7-f1a8-11b7-f5fa881fdcd9"},"outputs":[],"source":"data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4f41a16-f862-3239-cb1a-7c1c4f7c9908"},"outputs":[],"source":"y = np.log1p(y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f4d3091-66b1-5b87-c48a-d6d6f2d49850"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a0fa9d5-14e5-ae20-9b9d-e43221a2c55f"},"outputs":[],"source":"Xtrain = data.iloc[:shapeTrain[0],:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd831365-ab8b-44b0-1426-1b496fb3af83"},"outputs":[],"source":"from sklearn.ensemble import GradientBoostingRegressor as GBR, RandomForestRegressor as RFG\nfrom xgboost import XGBRegressor as XGBR\nmodel3 = XGBR(n_estimators=1000,nthread=4,min_child_weight=1.75)\n#model = RFG(n_estimators=40,n_jobs=16)\n#model2 = GBR(n_estimators=150)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"02b0a857-305a-218c-9082-ab7c5a557bac"},"outputs":[],"source":"from sklearn.cross_validation import train_test_split as tts\nX_train,X_test,y_train,y_test = tts(Xtrain,y,test_size=0.2,random_state = 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c200b65b-f26c-1bb8-e520-0f065ca3505b"},"outputs":[],"source":"#model2.fit(X_train,y_train)\n#print(\"Gradient Fitted\")\n#model.fit(X_train,y_train)\n#print(\"Random Fitted\")\nmodel3.fit(X_train,y_train)\nprint(\"XGB fitted\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"961c2996-b293-09db-0947-c496f2ed9d13"},"outputs":[],"source":"\nfrom sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse\nXtest = data.iloc[shapeTrain[0]:,:]\n#y_test = np.expm1(y_test)\n#y_train = np.expm1(y_train)\n#predTestRandom = model.predict(X_test)\n#predTestGrad = model2.predict(X_test)\npredTestXGB = model3.predict(X_test)\n#predTrainRandom = model.predict(X_train)\n#predTrainGrad = model2.predict(X_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b48f006-e53d-c1d3-3ae3-6ac18b183cf2"},"outputs":[],"source":"#predTest =  (predTestRandom*0.43 + 0.57*predTestGrad)\n#predTest = (np.expm1(predTest))\n#predTrain = (predTrainRandom*0.5 + predTrainGrad*0.5)\n#predTrain = (np.expm1(predTrain))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"87707cfb-c58e-7792-be2f-c2cd2cea2dee"},"outputs":[],"source":"#print(mae(y_test,pred))\n#print(mae(y_test,predTest))\n#print(mae(y_train,predTrain))\n#print(predTestRandom[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cff83b71-7d32-ef99-3dc1-d75229cee3aa"},"outputs":[],"source":"\n#model3.fit(X_train,y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3a530cd5-2f3f-7d43-cc05-07f4347ee981"},"outputs":[],"source":"y_test = np.expm1(y_test)\n#y_train = np.expm1(y_train)\n#predTrainXGB= model3.predict(X_train)\n#predTestXGB = model3.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5376f86d-e25b-0ebb-ef76-21d9bfed41e3"},"outputs":[],"source":"\n\nfor j in range(101):\n    print(\"j = \" +str(j) )\n    for i in range(j):\n        predTest =  ((predTestRandom)*(j-i)/100 + i*predTestGrad/100 + (100-j)*predTestXGB/100)\n        predTest = (np.expm1(predTest))\n        #predTrain = (predTrainRandom*0.23 + predTrainGrad*0.07 + predTrainXGB*0.7)\n        #predTrain = (np.expm1(predTrain))\n        print(\"i = \" + str(i))\n        print(mae(y_test,predTest))\n#print(mae(y_train,predTrain))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb3e38b6-eb77-6c3c-8e79-41eb34bcf2ef"},"outputs":[],"source":"#print(mae(y_test,predTest))\n#print(mae(y_train,predTrain))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4846d465-e972-5659-8ddf-a803864f5644"},"outputs":[],"source":"predAns = ((model.predict(Xtest))*(j-i)/100  + (100-j)*model3.predict(Xtest)/100)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"276b532a-f2d1-0b88-6d82-fd25a461ea7b"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad2a210a-c9c4-062a-63b9-d0187e57e47c"},"outputs":[],"source":"predAns = np.expm1(predAns)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cba1785c-9986-6cce-dc33-a97e09f6efe5"},"outputs":[],"source":"output = pandas.DataFrame({\"id\":ID,\"loss\":predAns})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c4eedd2-eaf5-4466-7c7d-d624f2023914"},"outputs":[],"source":"output.to_csv(\"output.csv\",index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac48b541-6f55-1972-73b0-7ac3184cd6fa"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}