{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport torch.nn as nn\nfrom torch import optim \nimport torch\nimport torch.utils.data as Data\nfrom sklearn.ensemble import AdaBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/allstate-claims-severity/train.csv\")\nprint(train_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = train_df[\"loss\"]\nfeatures = train_df.drop(\"loss\", axis = 1)\nprint(loss.shape)\nprint(features.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check for Skewness in the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Look at cont variables\nfeatures.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Only one variable is over 1 skewness which is pretty good. Feature Data does not need skewness\ncont_skewness_dict = dict()\nfor columns in features.columns:\n    if columns[:4] == \"cont\":\n        column_skewness = eval('features[\"{}\"].skew()'.format(columns))\n        cont_skewness_dict[columns] = column_skewness\nprint(cont_skewness_dict)\nfor value in cont_skewness_dict:\n    if cont_skewness_dict[value] > 1 or cont_skewness_dict[value] < -1:\n        print(\"Data skewness over at one at\", str(value))\n        break\n\n#Loss needs to be logged\nprint(loss.skew())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets remove outliers in loss\naverage_loss = np.mean((loss))\nmaximum_loss = np.max((loss))\nprint(\"Average_loss {}\".format(average_loss))\nprint(\"Maximum_loss {}\".format(maximum_loss))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_train = pd.get_dummies(features)\nloss_train = np.log(loss)\n\nX_train, X_test, y_train, y_test = train_test_split(features_train, loss_train, test_size = 0.33)\n\n#Lets run a baseline model\nlinear_regression = LinearRegression()\nlinear_regression.fit(X_train, y_train)\nbase_predictions = linear_regression.predict(X_test)\n\n\nprint(\"Mean squared error {}\".format(mean_squared_error(np.exp(y_test), np.exp(base_predictions))))\nprint(\"Mean absolute error {}\".format(mean_absolute_error(np.exp(y_test), np.exp(base_predictions))))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = np.log(loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Here we are going to use PCA or Principal Component Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets get the columns for cont variables and category variables \nskimmed_features = features.drop(\"id\", axis = 1)\ncategory_features = skimmed_features.iloc[:, :116]\ncont_features = skimmed_features.iloc[:, 116:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(category_features.shape)\nprint(cont_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = 9)\ncont_reduced = pca.fit_transform(cont_features)\nprint(cont_reduced.shape)\n\ncont_explained = 0\nfor value in pca.explained_variance_ratio_:\n    cont_explained += value\ncont_explained\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sparse_category_features = pd.get_dummies(category_features)\nsparse_category_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = 150)\ncat_reduced = pca.fit_transform(sparse_category_features)\nprint(cat_reduced.shape)\n\ncat_explained = 0\nfor value in pca.explained_variance_ratio_:\n    cat_explained += value\ncat_explained","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we are going to combine the data into one dataframe.\nreduced_feature = np.hstack((cat_reduced,cont_reduced))\nprint(\"Reduced PCA Dataset: {}\".format(reduced_feature.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we are going to try to run some supervised Models on the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(reduced_feature))\nprint(\"Did not use fit_transform with PCA\")\nprint(type(loss_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(reduced_feature, loss_train, test_size = 0.33)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_scores(pred, y_true):\n    print(\"The Means absolute error: {}\".format(mean_absolute_error(np.exp(y_true), np.exp(pred))))\n    print(\"The Mean Squared error: {}\".format(mean_squared_error(np.exp(y_true), np.exp(pred))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(X_train))\nprint(type(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets run a polynomial regression\n\n# polynomial_object = PolynomialFeatures(2)\n# poly_data = polynomial_object.fit_transform(X_train)\n\n# linear_regression = LinearRegression()\n# linear_regression.fit(X_train, y_train)\n# polynomial_pred = linear_regression.predict(X_test)\n\n# find_scores(polynomial_pred, y_test)\n#Uncomment to use Polynomial Regression. Note: Takes a lot of RAM. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Regressor Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets run a Decision Tree Regressor except now we will use GridSearchCV to validate the best model\nparameters = {\"max_depth\": [5, 10]}\ntree_scoring = make_scorer(mean_squared_error)\ntree_regressor = DecisionTreeRegressor()\ngrid = GridSearchCV(tree_regressor, parameters, scoring = tree_scoring)\ngrid_fit = grid.fit(X_train, y_train)\nbest_tree = grid_fit.best_estimator_\nprint(\"Best estimator: {}\".format(best_tree))\n\nbest_tree_fit = best_tree.fit(X_train, y_train)\ntree_predictions = best_tree_fit.predict(X_test)\n\nfind_scores(tree_predictions, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Model (Bagging Model)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters = {\"n_estimators\": [5, 10]}\n# random_forest = RandomForestRegressor(max_depth = 5)\n# grid = GridSearchCV(random_forest, parameters, scoring = absolute_scoring)\n# grid_fit = grid.fit(X_train, y_train)\n# best_forest = grid_fit.best_estimator_\n# print(\"Best random Forest{}\".format(best_forest))\n# print(\"The run time{}\".format(grid_fit.refit_time_))\n\n# best_forest_fit = best_forest.fit(X_train, y_train)\n# forest_predictions = best_forest_fit.predict(X_test)\n\nrandom_forest = RandomForestRegressor(n_estimators = 10, max_depth = 5)\nrandom_forest_fit = random_forest.fit(X_train, y_train)\nforest_predictions = random_forest_fit.predict(X_test)\n\nfind_scores(forest_predictions, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lasso Model (Regularized Linear Regression)"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\"alpha\": [0.5, 1, 2, 5]}\nabsolute_scoring = make_scorer(mean_absolute_error)\nlasso_model = Lasso()\ngrid = GridSearchCV(lasso_model, parameters, scoring = absolute_scoring)\ngrid_fit = grid.fit(X_train, y_train)\nbest_lasso = grid_fit.best_estimator_\nprint(\"Best Lasso Model L1 Regularization: {}\".format(best_lasso))\nprint(\"The run time: {}\".format(grid_fit.refit_time_))\n\nbest_lasso_fit = best_lasso.fit(X_train, y_train)\nlasso_predictions = best_lasso_fit.predict(X_test)\n\nfind_scores(lasso_predictions, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AdaBoostRegressor Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_boost = AdaBoostRegressor(n_estimators = 10, learning_rate = 0.5)\nada_boost_fit = ada_boost.fit(X_train, y_train)\nada_boost_predictions = ada_boost.predict(X_test)\n\nfind_scores(ada_boost_predictions, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Neural Network Pytorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.fc1 = nn.Linear(159, 30)\n        self.fc2 = nn.Linear(30, 1)\n        \n        self.tanh = nn.Tanh()\n        \n        \n    def forward(self, x):\n        \n        #x shape (1, 159)\n        x = self.tanh(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net()\noptimizer = optim.Adam(net.parameters(), lr = 0.01)\ncriterion = nn.MSELoss()\nfor epoch in range(151):\n    \n    epoch_loss = 0\n    \n    optimizer.zero_grad()\n    X_train = torch.FloatTensor(X_train)\n    y_train = (torch.FloatTensor(y_train)).view(-1, 1)\n    output = net(X_train)\n    loss = criterion(output, y_train)\n    loss.backward()\n    optimizer.step()\n    epoch_loss += loss.item()\n    \n    if epoch % 10 == 0:\n        \n        print(\"Epoch: {}\".format(epoch))\n        print(\"Loss: {:.3f}\".format(np.exp(epoch_loss)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = torch.FloatTensor(X_test)\ny_test = (torch.Tensor(y_test.values)).view(-1, 1)\ntest_output = net(X_test)\nloss = criterion(test_output, y_test)\nprint(\"Loss: {}\".format(torch.exp(loss)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net(X_test[0:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How would you batch data\n\npandas series --> numpy_array --> torch tensor\n\n``` for (batch_i), images, labels in enumerate(loader): ```"},{"metadata":{"trusted":true},"cell_type":"code","source":"torch_dataset = Data.TensorDataset(X_train, y_train)\n\nloader = Data.DataLoader(\n    dataset=torch_dataset, \n    batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iterator = iter(loader)\ndata, label = iterator.next()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(label)\nprint(label.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}