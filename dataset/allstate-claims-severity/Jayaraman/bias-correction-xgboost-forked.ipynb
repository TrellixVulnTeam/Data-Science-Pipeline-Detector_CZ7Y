{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45c5e39b-f88f-2e6a-bc1d-5295092e5f99"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"95725cb0-2fe5-a1d4-391c-76e7d6d9d5f1"},"outputs":[],"source":"from datetime import datetime\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cross_validation import KFold\nfrom sklearn.metrics import mean_absolute_error\nfrom scipy.stats import skew, boxcox\nfrom math import exp, log\nimport xgboost as xgb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45afe9cd-a1d4-fd19-61e7-005cc4b9171c"},"outputs":[],"source":"def timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n        print(' Time taken: %i minutes and %s seconds.' %\n              (tmin, round(tsec, 2)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1f0a888-a632-b7ab-7635-9ea3c7649b84"},"outputs":[],"source":"def scale_data(X, scaler=None):\n    if not scaler:\n        scaler = StandardScaler()\n        scaler.fit(X)\n    X = scaler.transform(X)\n    return X, scaler"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06340266-8423-82c8-8b7d-e1079819f542"},"outputs":[],"source":"\nDATA_TRAIN_PATH = '../input/train.csv'\nDATA_TEST_PATH = '../input/test.csv'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03c2fa98-be49-7bac-23a7-b158b1de6258"},"outputs":[],"source":"def load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n    train_loader = pd.read_csv(path_train, dtype={'id': np.int32})\n    train = train_loader.drop(['id', 'loss'], axis=1)\n    test_loader = pd.read_csv(path_test, dtype={'id': np.int32})\n    test = test_loader.drop(['id'], axis=1)\n    ntrain = train.shape[0]\n    ntest = test.shape[0]\n    train_test = pd.concat((train, test)).reset_index(drop=True)\n    numeric_feats = train_test.dtypes[train_test.dtypes != \"object\"].index\n\n    # compute skew and do Box-Cox transformation\n    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n    print(\"\\nSkew in numeric features:\")\n    print(skewed_feats)\n    # transform features with skew > 0.25 (this can be varied to find optimal value)\n    skewed_feats = skewed_feats[skewed_feats > 0.25]\n    skewed_feats = skewed_feats.index\n    for feats in skewed_feats:\n        train_test[feats] = train_test[feats] + 1\n        train_test[feats], lam = boxcox(train_test[feats])\n    features = train.columns\n    cats = [feat for feat in features if 'cat' in feat]\n    # factorize categorical features\n    for feat in cats:\n        train_test[feat] = pd.factorize(train_test[feat], sort=True)[0]\n    x_train = train_test.iloc[:ntrain, :]\n    x_test = train_test.iloc[ntrain:, :]\n    train_test_scaled, scaler = scale_data(train_test)\n    train, _ = scale_data(x_train, scaler)\n    test, _ = scale_data(x_test, scaler)\n\n    train_labels = np.log(np.array(train_loader['loss']))\n    train_ids = train_loader['id'].values.astype(np.int32)\n    test_ids = test_loader['id'].values.astype(np.int32)\n\n    return train, train_labels, test, train_ids, test_ids"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd0f4fb3-87a7-595b-3d15-28f98a86818b"},"outputs":[],"source":"# enter the number of folds from xgb.cv\nfolds = 4\ncv_sum = 0\nearly_stopping = 25\nfpred = []\nxgb_rounds = []\n\nparams = {}\nparams['booster'] = 'gbtree'\nparams['objective'] = \"reg:linear\"\nparams['eval_metric'] = 'mae'\nparams['eta'] = 0.1\nparams['gamma'] = 0. 35\nparams['min_child_weight'] = 4.2922\nparams['colsample_bytree'] = 0.32\nparams['subsample'] = 0.9930\nparams['max_depth'] = 7\nparams['max_delta_step'] = 0\nparams['silent'] = 1\nparams['random_state'] = 1001"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d370e25-0f5a-cad1-2d42-970ea2de5e18"},"outputs":[],"source":"start_time = timer(None)\n\n# Load data set and target values\ntrain, target, test, _, ids = load_data()\nd_train_full = xgb.DMatrix(train, label=target)\nd_test = xgb.DMatrix(test)\nkf = KFold(train.shape[0], n_folds=folds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54920198-0082-7d56-ef5a-1ac2c7595787"},"outputs":[],"source":"\nfor i, (train_index, test_index) in enumerate(kf):\n    \n    print('\\n Fold %d\\n' % (i + 1))\n    X_train, X_val = train[train_index], train[test_index]\n    y_train, y_val = target[train_index], target[test_index]\n    \n    d_train = xgb.DMatrix(X_train, label=y_train)\n    d_valid = xgb.DMatrix(X_val, label=y_val)\n    watchlist = [(d_train, 'train'), (d_valid, 'eval')]\n    \n    clf = xgb.train(params,d_train,100000,watchlist,early_stopping_rounds=early_stopping)\n    \n    ####################################\n    #  Evaluate Model and Predict\n    ####################################\n\n    xgb_rounds.append(clf.best_iteration)\n    scores_val = clf.predict(d_valid, ntree_limit=clf.best_ntree_limit)\n    cv_score = mean_absolute_error(np.exp(y_val), np.exp(scores_val))\n    print(' eval-MAE: %.6f' % cv_score)\n    y_pred = np.exp(clf.predict(d_test, ntree_limit=clf.best_ntree_limit))\n    \n    ####################################\n    #  Add Predictions and Average Them\n    ####################################\n\n    if i > 0:\n        fpred = pred + y_pred\n    else:\n        fpred = y_pred\n    pred = fpred\n    cv_sum = cv_sum + cv_score\n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49482bbe-3001-0acc-96c1-2c84f5a3cdee"},"outputs":[],"source":"mpred = pred / folds\nscore = cv_sum / folds\nprint('\\n Average eval-MAE: %.6f' % score)\nn_rounds = int(np.mean(xgb_rounds))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30fbe903-b586-b412-d0f8-ed84f0e8160d"},"outputs":[],"source":"print('\\n Training full dataset for %d rounds ...' % n_rounds)\nwatchlist = [(d_train_full, 'train')]\nclf_full = xgb.train(\n    params, d_train_full,\n    n_rounds,\n    watchlist,\n    verbose_eval=False,)\ny_pred_full = np.exp(clf_full.predict(d_test))\ntimer(start_time)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a7d76d3-4d9a-76d7-158a-680c237bd22e"},"outputs":[],"source":"n_fixed = 376\nnfixed = int(n_fixed * (1 + (1. / folds)))\nprint('\\n Training full dataset for %d fixed rounds ...\\n' % nfixed)\n\n\n\nclf_fixed = xgb.train(\n    params, d_train_full,\n    nfixed,\n    watchlist,\n    verbose_eval=False,)\ny_pred_fixed = np.exp(clf_fixed.predict(d_test))\ntimer(start_time)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2493d811-2b75-f75a-5881-77efbd799410"},"outputs":[],"source":"print(\"#\\n Writing results\")\nresult = pd.DataFrame(mpred, columns=['loss'])\nresult[\"id\"] = ids\nresult = result.set_index(\"id\")\nprint(\"\\n %d-fold average prediction:\\n\" % folds)\nprint(result.head())\nresult_full = pd.DataFrame(y_pred_full, columns=['loss'])\nresult_full[\"id\"] = ids\nresult_full = result_full.set_index(\"id\")\nprint(\"\\n Full dataset prediction:\\n\")\nprint(result_full.head())\n\nresult_fixed = pd.DataFrame(y_pred_fixed, columns=['loss'])\nresult_fixed[\"id\"] = ids\nresult_fixed = result_fixed.set_index(\"id\")\nprint(\"\\n Full datset (at CV #iterations) prediction:\\n\")\nprint(result_fixed.head())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b262709d-ba18-1880-9447-843087a2bda1"},"outputs":[],"source":"now = datetime.now()\nscore = str(round((cv_sum / folds), 6))\nsub_file = 'submission_5fold-average-xgb_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\nprint(\"\\n Writing submission: %s\" % sub_file)\nresult.to_csv(sub_file, index=True, index_label='id')\n\n# trained on full data \nsub_file = 'submission_full-average-xgb_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\nprint(\"\\n Writing submission: %s\" % sub_file)\nresult_full.to_csv(sub_file, index=True, index_label='id')\n\n#trained on full cv\nsub_file = 'submission_full-CV-xgb_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\nprint(\"\\n Writing submission: %s\" % sub_file)\nresult_fixed.to_csv(sub_file, index=True, index_label='id')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34cfc6ea-2a1e-f415-fc66-9e56e6bf1d94"},"outputs":[],"source":"fusion=(result_fixed+result_full+result)/3"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7303e4f-3cb2-7ec3-5a2c-d7e863fc5166"},"outputs":[],"source":"meanSub=\"meanSub.csv\"\nprint(\"\\n Writing submission: %s\" % meanSub)\nfusion.to_csv(meanSub, index=True, index_label='id')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6702190-9432-6b97-3b5a-7066fcb6e035"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}