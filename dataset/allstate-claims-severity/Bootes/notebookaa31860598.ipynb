{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"9a94ad4e-a822-2efb-c872-e798735f8190"},"source":"If you don't know where to go, start at the beginning. What are we looking at here? "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e5c1b65-33f2-8238-e43d-ae5c65f7bbff"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nsample=pd.read_csv('../input/sample_submission.csv')\ntest=pd.read_csv('../input/test.csv')\ntrain=pd.read_csv('../input/train.csv')\n\n#If you check this out in Linux (e.g. head train.csv), you see the extent of the data:\nprint(train.head(5)) #116 Categorical Values, and 14 continuous ones.\n\t"},{"cell_type":"markdown","metadata":{"_cell_guid":"5b9cb548-a2a8-7fcf-f48b-387a53163b60"},"source":"train=pd.read_csv('../input/train.csv')\nnature. What can we do when we know nothing? Like the early taxonomists, we can start sorting! Categorical values appear to be mainly 'A' and 'B', with a few categorical columns containing various other characters."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75643af3-30a7-8b9a-6ad8-6d134ac5fed5"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb #Run the classifier\n\n\nprint('This article was very helpful: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/')\nprint('As well as: https://www.kaggle.com/guyko81/allstate-claims-severity/just-an-easy-solution')\n\ntest=pd.read_csv('../input/test.csv')\ntrain=pd.read_csv('../input/train.csv')\nfeatures = [x for x in train.columns if x not in ['id','loss']]\ncat_features = [x for x in train.select_dtypes(include=['object']).columns if x not in ['id','loss']]\n\nfor c in range(len(cat_features)):\n\ttrain[cat_features[c]] = train[cat_features[c]].astype('category').cat.codes\n    \ntrain['ln_loss'] = np.log(train['loss']) #Take LN of loss column\ntrainX=pd.DataFrame(train[features])\ntrainY=pd.DataFrame(train['ln_loss'])\nxgdmat = xgb.DMatrix(trainX, trainY) #Put these in DMTATRIX\n\nparams = {'eta': 0.01, 'seed':0, 'subsample': 0.5, 'colsample_bytree': 0.5, \n             'objective': 'reg:linear', 'max_depth':6, 'min_child_weight':3} \nprint('Training')\nnum_rounds = 1000\nbst = xgb.train(params, xgdmat, num_boost_round = num_rounds)\nprint('Done Training')\n\nprint('Testing')\ny_pred=[]\nfor c in range(len(cat_features)):\n    test[cat_features[c]] = test[cat_features[c]].astype('category').cat.codes\t\ntestDM=xgb.DMatrix(test[features])\ny_pred+=list(bst.predict(testDM))\nprint('Done Testing')\n\nprint('Preparing to Submit')\ny_pred=np.exp(y_pred)#Convert back to normal values\nsubmission = pd.DataFrame({\n        \"id\": test[\"id\"],\n        \"loss\": y_pred    })\nsubmission.to_csv('XGB_OUT.csv', index=False)\t#Including more min_splits and min_leaf helps out a little\nprint(\"Submission Saved\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49d8e248-b830-1486-87c9-2cdd61e80f72"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import SGDRegressor as SDG\n\nprint('This code works poorly and gives huge swings in loss')\ntest=pd.read_csv('../input/test.csv')\ntrain=pd.read_csv('../input/train.csv')\nprint('Categories from : https://www.kaggle.com/guyko81/allstate-claims-severity/just-an-easy-solution')\nfeatures = [x for x in train.columns if x not in ['id','loss']]\ncat_features = [x for x in train.select_dtypes(include=['object']).columns if x not in ['id','loss']]\nnum_features = [x for x in train.select_dtypes(exclude=['object']).columns if x not in ['id','loss']]\t\t\ntest,train='',''\t\n\nchunksize=20000\nprint('Training')\ntrain=pd.read_csv('../input/train.csv',iterator=True,chunksize=chunksize)#Load in the file again\nfor chunk in train:\n\tconts=[x for x in chunk if 'cont' in x]#Only continuous values\n\tfor c in range(len(cat_features)):\n\t\tchunk[cat_features[c]] = chunk[cat_features[c]].astype('category').cat.codes\t\n\ttrainX=pd.DataFrame(chunk[features])\n\ttrainY=pd.DataFrame(chunk['loss'])\n\talg = SDG(warm_start=True)\n\talg.fit(trainX[features],trainY['loss'])\n\t\t\nprint('Done Training')\ntrain,trainX,trainY='','',''\n\nprint('Testing')\n#Iterate through?\ntest=pd.read_csv('../input/test.csv',iterator=True,chunksize=chunksize)\ny_pred=[]\nfor chunk in test:\n\tfor c in range(len(cat_features)):\n\t\tchunk[cat_features[c]] = chunk[cat_features[c]].astype('category').cat.codes\t\n\ttestX=pd.DataFrame(chunk[features]).astype(float)\n\ty_pred += list(alg.predict(testX))\nprint('Done Testing')\n\ntest=''\ntest=pd.read_csv('../input/test.csv')\nsubmission = pd.DataFrame({\n        \"id\": test[\"id\"],\n        \"loss\": y_pred    })\n#submission.to_csv('SGD_OUT.csv', index=False)\t#Including more min_splits and min_leaf helps out a little\nprint(\"Submission Saved\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e2c22ad-0eee-2ee7-f800-4f3f637705e0"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import SGDRegressor as SDG\n\nprint('Maybe transform this to  log_loss as guyko81 does. Also, remove the iterators.')\ntest=pd.read_csv('../input/test.csv')\ntrain=pd.read_csv('../input/train.csv')\nprint('Categories from : https://www.kaggle.com/guyko81/allstate-claims-severity/just-an-easy-solution')\nfeatures = [x for x in train.columns if x not in ['id','loss']]\ncat_features = [x for x in train.select_dtypes(include=['object']).columns if x not in ['id','loss']]\nnum_features = [x for x in train.select_dtypes(exclude=['object']).columns if x not in ['id','loss']]\t\t\ntest,train='',''\t\n\nprint('Training')\ntrain=pd.read_csv('../input/train.csv')#Load in the file again\n\n\nfor c in range(len(cat_features)):\n\ttrain[cat_features[c]] = train[cat_features[c]].astype('category').cat.codes\ntrain['ln_loss'] = np.log(train['loss']) \ntrainX=pd.DataFrame(train[features])\ntrainY=pd.DataFrame(train['ln_loss'])\nalg = SDG()\nalg.fit(trainX[features],trainY['ln_loss'])\n\t\t\nprint('Done Training')\ntrain,trainX,trainY='','',''\n\nprint('Testing')\n#Iterate through?\ntest=pd.read_csv('../input/test.csv')\ny_pred=[]\nfor c in range(len(cat_features)):\n    test[cat_features[c]] = test[cat_features[c]].astype('category').cat.codes\t\ntestX=pd.DataFrame(test[features])\ny_pred += list(alg.predict(testX))\nprint('Done Testing')\n\nprint('Preparing to Submit')\ny_pred=np.exp(y_pred)#Convert back to normal values\nsubmission = pd.DataFrame({\n        \"id\": test[\"id\"],\n        \"loss\": y_pred    })\nsubmission.to_csv('SGD_OUT2.csv', index=False)\t#Including more min_splits and min_leaf helps out a little\nprint(\"Submission Saved\")"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}