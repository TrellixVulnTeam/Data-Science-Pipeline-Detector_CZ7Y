{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n            \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/allstate-claims-severity/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/allstate-claims-severity/test.csv\")\nsubmission=pd.read_csv(\"/kaggle/input/allstate-claims-severity/sample_submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import FactorAnalysis\nfa= FactorAnalysis(n_components=15, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contFeatureslist=[]\nfor colName,x in train_df.iloc[1,:].iteritems():\n    if(not str(x).isalpha()):\n        contFeatureslist.append(colName)\ncontFeatureslist.remove(\"id\")\ncontFeatureslist.remove(\"loss\")\nimport matplotlib.pyplot as plt\n\n\nnewdf=train_df[contFeatureslist]\nnewdf.columns\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n%matplotlib inline\nprint(contFeatureslist)\nplt.figure(figsize=(23,9))\nsns.boxplot(x=contFeatureslist,data=newdf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlationMatrix = train_df[contFeatureslist].corr().abs()\nplt.subplots(figsize=(13, 9))\nsns.heatmap(correlationMatrix,annot=True)\n\n# Mask unimportant features\nsns.heatmap(correlationMatrix, mask=correlationMatrix < 1, cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(np.log1p(train_df[\"loss\"]))\ntrain_df[\"loss\"]=np.log1p(train_df[\"loss\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catFeatureslist = []\nfor colName,x in train_df.iloc[1,:].iteritems():\n    if(str(x).isalpha()):\n        catFeatureslist.append(colName)\nfrom sklearn.preprocessing import LabelEncoder\nfor cf1 in catFeatureslist:\n    le = LabelEncoder()\n    le.fit(train_df[cf1].unique())\n    train_df[cf1] = le.transform(train_df[cf1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_df.columns))\nsum(train_df[catFeatureslist].apply(pd.Series.nunique) > 2)\nprint(len(train_df.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filterG5_10 = list((train_df[catFeatureslist].apply(pd.Series.nunique) > 5) & \n                (train_df[catFeatureslist].apply(pd.Series.nunique) < 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catFeaturesG5_10List = [i for (i, v) in zip(catFeatureslist, filterG5_10) if v]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlationMatrix = train_df[catFeatureslist].corr().abs()\ncrrm=correlationMatrix[correlationMatrix>0.9]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catFeatureslist = []\nfor colName,x in test_df.iloc[1,:].iteritems():\n    if(str(x).isalpha()):\n        catFeatureslist.append(colName)\nfrom sklearn.preprocessing import LabelEncoder\nfor cf1 in catFeatureslist:\n    le = LabelEncoder()\n    le.fit(test_df[cf1].unique())\n    test_df[cf1] = le.transform(test_df[cf1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat2=train_df.drop(\"cat2\",axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ytrain=train_df[\"loss\"]\ntrain_df=train_df.drop(\"loss\",axis=1)\nXtrain=train_df\nXtest=test_df\ncat_features=list(np.where(all_data.dtypes==np.object)[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nall_data=pd.concat((train_df, test_df))\nall_data.shape\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import cross_val_score\nmodel_xgb=XGBRegressor(tree_method='gpu_hist', seed=18, objective='reg:linear', n_jobs=-1, verbosity=0,\n                       colsample_bylevel=0.764115402027029, colsample_bynode=0.29243734009596956, \n                       colsample_bytree= 0.7095719673041723, gamma= 4.127534050725986, learning_rate= 0.02387231810322894, \n                       max_depth=14, min_child_weight=135, n_estimators=828,reg_alpha=0.3170105723222332, \n                       reg_lambda= 0.3660379465131937, subsample=0.611471430211575)\nmodel_xgb\n\nmodel_LGB=LGBMRegressor(objective='regression_l1', random_state=18, subsample_freq=1,\n                        colsample_bytree=0.3261853512759363, min_child_samples=221, n_estimators=2151, num_leaves= 45, \n                        reg_alpha=0.9113713668943361, reg_lambda=0.8220990333713991, subsample=0.49969995651550947, \n                        max_bin=202, learning_rate=0.02959820893211799) #,device='gpu')\nmodel_LGB\n\n\n# model_Cat=CatBoostRegressor(loss_function='MAE', random_seed=18, task_type='GPU', cat_features=cat_features, verbose=False,\n#                             iterations=2681, learning_rate=0.2127106032536721, depth=7, l2_leaf_reg=5.266150673910493, \n#                             random_strength=7.3001140226199315, bagging_temperature=0.26098669708900213)\n# model_Cat\n\n\n# model_Cat.fit(Xtrain, Ytrain)\nmodel_LGB.fit(Xtrain, Ytrain)\nmodel_xgb.fit(Xtrain, Ytrain)\n\nlgb_predictions=model_LGB.predict(Xtest)\n# cat_predictions=model_Cat.predict(Xtest)\nxgb_predictions=model_xgb.predict(Xtest)\n\npredictions=(lgb_predictions  + xgb_predictions)/2\n\npredictions=np.exp(predictions)-1\nsubmission['loss']=predictions\nsubmission.to_csv('Result.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}