{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e57450b-4a35-939f-260d-ba6154463295"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\ndirectory = '../input/'\ntrain = pd.read_csv(directory + 'train.csv')\ntest = pd.read_csv(directory + 'test.csv')\nnumeric_feats = [x for x in train.columns[1:-1] if 'cont' in x]\ncategorical_feats = [x for x in train.columns[1:-1] if 'cat' in x]\ncatwithdummies =pd.get_dummies(train)\nprint(catwithdummies)\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab3b5d64-e015-b550-1468-66d3f8d598bb"},"outputs":[],"source":"print(catwithdummies.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dcd53c6b-a52c-fb97-04be-99d7a63f83e5"},"outputs":[],"source":"index = list(train.index)\nprint(index[0:10])\nnp.random.shuffle(index)\nprint(index[0:10])\ntrain = train.iloc[index]\n'train = train.iloc[np.random.permutation(len(train))]'\n\n## set test loss to NaN\ntest['loss'] = np.nan\n\n## response and IDs\ny = np.log(train['loss'].values+200)\nid_train = train['id'].values\nid_test = test['id'].values\n\n## stack train test\nntrain = train.shape[0]\ntr_te = pd.concat((train, test), axis = 0)\n\n## Preprocessing and transforming to sparse data\nsparse_data = []\n\nf_cat = [f for f in tr_te.columns if 'cat' in f]\nfor f in f_cat:\n    dummy = pd.get_dummies(tr_te[f].astype('category'))\n    tmp = csr_matrix(dummy)\n    sparse_data.append(tmp)\n\nf_num = [f for f in tr_te.columns if 'cont' in f]\nscaler = StandardScaler()\ntmp = csr_matrix(scaler.fit_transform(tr_te[f_num]))\nsparse_data.append(tmp)\n\ndel(tr_te, train, test)\n\n## sparse train and test data\nxtr_te = hstack(sparse_data, format = 'csr')\nxtrain = xtr_te[:ntrain, :]\nxtest = xtr_te[ntrain:, :]\n\nprint('Dim train', xtrain.shape)\nprint('Dim test', xtest.shape)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}