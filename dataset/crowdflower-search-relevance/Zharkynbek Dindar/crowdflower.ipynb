{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nimport scipy\nimport nltk\nfrom scipy.sparse import coo_matrix, hstack\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import pairwise\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib\nimport matplotlib.patches as mpatches","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import LeaveOneOut\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import cohen_kappa_score\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom Levenshtein import distance\n\nloo = LeaveOneOut()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = pd.read_csv('C:/Users/Dindar/crowdflower/tables1/train.csv')\ntest = pd.read_csv('C:/Users/Dindar/crowdflower/tables1/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = train[train['query'] == 'bridal shower decorations']\ndf['product_description'].fillna('0', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"stop_words = set(stopwords.words('english')) \ndf['query'] = df['query'].str.lower()\ndf['product_title'] = df['product_title'].str.lower()\ndf['product_description'] = df['product_description'].str.lower()\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\ndf['query'] = df['query'].apply(lemmatize_text)\ndf['product_title'] = df['product_title'].apply(lemmatize_text)\ndf['product_description'] = df['product_description'].apply(lemmatize_text)\ndef listToString(s):  \n    str1 = \"\"  \n    for ele in s:  \n        str1 = str1 + ' ' + ele      \n    return str1[1:]\ndf['query'] = df['query'].apply(listToString)\ndf['product_title'] = df['product_title'].apply(listToString)\ndf['product_description'] = df['product_description'].apply(listToString)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# word2vec","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import gensim\n\nword2vec_path = \"G:/Downloads/GoogleNews-vectors-negative300.bin.gz\"\nword2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"type(word2vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n    if len(tokens_list)<1:\n        return np.zeros(k)\n    if generate_missing:\n        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n    else:\n        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n    length = len(vectorized)\n    summed = np.sum(vectorized, axis=0)\n    averaged = np.divide(summed, length)\n    return averaged\n\ndef get_word2vec_embeddings(vectors, clean_questions,col, generate_missing=False):\n    embeddings = clean_questions[col].apply(lambda x: get_average_word2vec(x, vectors, \n                                                                                generate_missing=generate_missing))\n    return list(embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df['product_title'] = df['product_title'].str.split()\ndf['product_description'] = df['product_description'].str.split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"embeddings = get_word2vec_embeddings(word2vec, df,'product_description')\nembeddings1 = get_word2vec_embeddings(word2vec, df,'product_title')\nembeddings = np.asarray(embeddings)\nembeddings1 = np.asarray(embeddings1)\nembeddings = pd.DataFrame(embeddings)\nembeddings1 = pd.DataFrame(embeddings1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"embeddings['target'] = list(df['median_relevance'])\nembeddings1['target1'] = list(df['median_relevance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"a = pairwise.cosine_similarity(embeddings)\na = pd.DataFrame(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"meann = []\nmaxx = []\nminn = []\nfor i in a.index:\n    iii = a.iloc[i].sort_values(ascending=False)[:6].index\n    meann.append(embeddings.iloc[iii]['target'].mean())\n    maxx.append(embeddings.iloc[iii]['target'].max())\n    minn.append(embeddings.iloc[iii]['target'].min())\nembeddings['mean_6_cos_word2vec'] = meann\nembeddings['max_6_cos_word2vec'] = maxx\nembeddings['min_6_cos_word2vec'] = minn\n\none = []\ntwo = []\nthree = []\nfour = []\nfor i in range(43):\n    one.append(0)\n    two.append(0)\n    three.append(0)\n    four.append(0)\nfor i in a.index:\n    iii = a.iloc[i].sort_values()[:6].index\n    for j in embeddings.iloc[iii]['target']:\n        if j == 1:\n            one[i] = one[i] + 1\n        elif j == 2:\n            two[i] = two[i] + 1\n        elif j == 3:\n            three[i] = three[i] + 1\n        elif j == 4:\n            four[i] = four[i] + 1\nembeddings['one_6_cos_word2vec'] = one\nembeddings['two_6_cos_word2vec'] = two\nembeddings['three_6_cos_word2vec'] = three\nembeddings['four_6_cos_word2vec'] = four","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"a = pairwise.cosine_similarity(embeddings1)\na = pd.DataFrame(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"meann = []\nmaxx = []\nminn = []\nfor i in a.index:\n    iii = a.iloc[i].sort_values(ascending=False)[:3].index\n    meann.append(embeddings1.iloc[iii]['target1'].mean())\n    maxx.append(embeddings1.iloc[iii]['target1'].max())\n    minn.append(embeddings1.iloc[iii]['target1'].min())\nembeddings1['mean_3_cos_word2vec_title'] = meann\nembeddings1['max_3_cos_word2vec_title'] = maxx\nembeddings1['min_3_cos_word2vec_title'] = minn","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"one = []\ntwo = []\nthree = []\nfour = []\nfor i in range(43):\n    one.append(0)\n    two.append(0)\n    three.append(0)\n    four.append(0)\nfor i in a.index:\n    iii = a.iloc[i].sort_values()[:3].index\n    for j in embeddings1.iloc[iii]['target1']:\n        if j == 1:\n            one[i] = one[i] + 1\n        elif j == 2:\n            two[i] = two[i] + 1\n        elif j == 3:\n            three[i] = three[i] + 1\n        elif j == 4:\n            four[i] = four[i] + 1\nembeddings1['one_3_cos_word2vec_title'] = one\nembeddings1['two_3_cos_word2vec_title'] = two\nembeddings1['three_3_cos_word2vec_title'] = three\nembeddings1['four_3_cos_word2vec_title'] = four","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"embeddings.shape, embeddings1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"embeddings1.drop('target1',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.concat([embeddings, embeddings1], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vectorizer = TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 7))\nvectorizer1 = TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 7))\nvectorizer2 = TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vectorizer3 = TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 4), analyzer='char')\nX3 = vectorizer3.fit_transform(df['product_description'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X1 = vectorizer1.fit_transform(df['product_title'])\nX2 = vectorizer2.fit_transform(df['product_description'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"f1 = vectorizer1.get_feature_names()\nf2 = vectorizer2.get_feature_names()\nf3 = vectorizer3.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tr = hstack([X1,X2,X3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = df['median_relevance']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tr","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.DataFrame(tr.A)\ndata['target'] = list(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"svd = TruncatedSVD(n_components=4, random_state=42)\nX_reduced1 = svd.fit_transform(tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_reduced1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.DataFrame(X_reduced1)\ndata['target'] = list(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# cosine_similarity","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"a = pairwise.cosine_similarity(data.drop('target', axis=1).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"a = pd.DataFrame(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"meann = []\nmaxx = []\nminn = []\nfor i in a.index:\n    iii = a.iloc[i].sort_values(ascending=False)[:4].index\n    meann.append(data.iloc[iii]['target'].mean())\n    maxx.append(data.iloc[iii]['target'].max())\n    minn.append(data.iloc[iii]['target'].min())\ndata['mean_4_cos'] = meann\ndata['max_4_cos'] = maxx\ndata['min_4_cos'] = minn","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"one = []\ntwo = []\nthree = []\nfour = []\nfor i in range(43):\n    one.append(0)\n    two.append(0)\n    three.append(0)\n    four.append(0)\nfor i in a.index:\n    iii = a.iloc[i].sort_values()[:4].index\n    for j in data.iloc[iii]['target']:\n        if j == 1:\n            one[i] = one[i] + 1\n        elif j == 2:\n            two[i] = two[i] + 1\n        elif j == 3:\n            three[i] = three[i] + 1\n        elif j == 4:\n            four[i] = four[i] + 1\ndata['one_4_cos'] = one\ndata['two_4_cos'] = two\ndata['three_4_cos'] = three\ndata['four_4_cos'] = four","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Levenshtein","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.set_index(pd.Index(list(range(43))), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"a = []\nfor i in df.index:\n    b = []\n    for j in df.index:\n        b.append(distance(df.iloc[i]['product_description'], df.iloc[j]['product_description']))\n    a.append(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"a = np.asarray(a)\na = pd.DataFrame(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"meann = []\nmaxx = []\nminn = []\nb = []\nfor i in a.index:\n    iii = a.iloc[i].sort_values()[:4].index\n\n    b.append(np.mean(a.iloc[i].iloc[iii]))\n    meann.append(data.iloc[iii]['target'].mean())\n    maxx.append(data.iloc[iii]['target'].max())\n    minn.append(data.iloc[iii]['target'].min())\ndata['mean_4_lev'] = meann\ndata['max_4_lev'] = maxx\ndata['min_4_lev'] = minn\ndata['mean_dis_lev_4'] = b","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"one = []\ntwo = []\nthree = []\nfour = []\nfor i in range(43):\n    one.append(0)\n    two.append(0)\n    three.append(0)\n    four.append(0)\nfor i in a.index:\n    iii = a.iloc[i].sort_values()[:4].index\n    for j in data.iloc[iii]['target']:\n        if j == 1:\n            one[i] = one[i] + 1\n        elif j == 2:\n            two[i] = two[i] + 1\n        elif j == 3:\n            three[i] = three[i] + 1\n        elif j == 4:\n            four[i] = four[i] + 1\ndata['one_4_lev'] = one\ndata['two_4_lev'] = two\ndata['three_4_lev'] = three\ndata['four_4_lev'] = four","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"a = []\nfor i in df.index:\n    b = []\n    for j in df.index:\n        b.append(distance(df.iloc[i]['product_title'], df.iloc[j]['product_title']))\n    a.append(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"a = np.asarray(a)\na = pd.DataFrame(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"meann = []\nmaxx = []\nminn = []\nb = []\nfor i in a.index:\n    iii = a.iloc[i].sort_values()[:4].index\n    b.append(np.mean(a.iloc[i].iloc[iii]))\n    meann.append(data.iloc[iii]['target'].mean())\n    maxx.append(data.iloc[iii]['target'].max())\n    minn.append(data.iloc[iii]['target'].min())\ndata['mean_4_lev_title'] = meann\ndata['max_4_lev_title'] = maxx\ndata['min_4_lev_title'] = minn\ndata['mean_dis_lev_4_title'] = b","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"one = []\ntwo = []\nthree = []\nfour = []\nfor i in range(43):\n    one.append(0)\n    two.append(0)\n    three.append(0)\n    four.append(0)\nfor i in a.index:\n    iii = a.iloc[i].sort_values()[:4].index\n    for j in data.iloc[iii]['target']:\n        if j == 1:\n            one[i] = one[i] + 1\n        elif j == 2:\n            two[i] = two[i] + 1\n        elif j == 3:\n            three[i] = three[i] + 1\n        elif j == 4:\n            four[i] = four[i] + 1\ndata['one_4_lev_title'] = one\ndata['two_4_lev_title'] = two\ndata['three_4_lev_title'] = three\ndata['four_4_lev_title'] = four","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# jaccard_similarity","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from distance import jaccard","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"a = []\nfor i in df.index:\n    b = []\n    for j in df.index:\n        b.append(jaccard(df.iloc[i]['product_title'], df.iloc[j]['product_title']))\n    a.append(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"a = np.asarray(a)\na = pd.DataFrame(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"meann = []\nmaxx = []\nminn = []\nb = []\nfor i in a.index:\n    iii = a.iloc[i].sort_values()[:4].index\n    b.append(np.mean(a.iloc[i].iloc[iii]))\n    meann.append(data.iloc[iii]['target'].mean())\n    maxx.append(data.iloc[iii]['target'].max())\n    minn.append(data.iloc[iii]['target'].min())\ndata['mean_4_jar_title'] = meann\ndata['max_4_jar_title'] = maxx\ndata['min_4_jar_title'] = minn\ndata['mean_dis_jar_4_title'] = b","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"one = []\ntwo = []\nthree = []\nfour = []\nfor i in range(43):\n    one.append(0)\n    two.append(0)\n    three.append(0)\n    four.append(0)\nfor i in a.index:\n    iii = a.iloc[i].sort_values()[:4].index\n    for j in data.iloc[iii]['target']:\n        if j == 1:\n            one[i] = one[i] + 1\n        elif j == 2:\n            two[i] = two[i] + 1\n        elif j == 3:\n            three[i] = three[i] + 1\n        elif j == 4:\n            four[i] = four[i] + 1\ndata['one_4_jar_title'] = one\ndata['two_4_jar_title'] = two\ndata['three_4_jar_title'] = three\ndata['four_4_jar_title'] = four","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# model","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X = data.drop(['target','min_4_lev_title','max_4_lev_title'],axis=1)\ny = data['target']\nweight = 1 / (1 + df['relevance_variance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ny_ts = []\ny_pr = []\nfor train_index, test_index in loo.split(X):\n    X_train, X_test = X.values[train_index], X.values[test_index]\n    y_train, y_test = y.values[train_index], y.values[test_index]\n    w = weight.values[train_index]\n    xgb = XGBClassifier()\n    xgb.fit(X_train, y_train, sample_weight=w)\n    y_preds = xgb.predict(X_test)\n    y_ts.append(y_test)\n    y_pr.append(y_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# word2vec(avg) title(3), description(6,5) + sample weight, cos","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# word2vec(avg) title(3), description(6,5) + sample weight, cos","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# word2vec(avg) title(3), description(6) + sample weight, cos","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# desc char 1,4, compon = 5, iter = жок\n                                                  # lev 4 descr, title\n                                                  # data.drop(['target',3,4,'one_4_lev_title','one_4_lev','mean_4_lev']\n                                                  # lev adding count features one, two, three, four","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 5, iter = жок\n                                                  # lev 4 descr, title\n                                                  # data.drop(['target',3,4,'one_4_lev_title', 'one_4_lev']\n                                                  # lev adding count features one, two, three, four","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 5, iter = жок\n                                                  # lev 4 descr, title\n                                                  # data.drop(['target']\n                                                  # lev adding count features one, two, three, four","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 5, iter = жок\n                                                  # lev 4 descr, title\n                                                  # data.drop(['target']\n                                                  # lev adding count features one, two, three, four ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 5, iter = жок\n                                                  # lev 4 + cos 4\n                                                  # data.drop(['target',3,4]\n                                                  # lev adding count features one, two, three, four ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 5, iter = жок\n                                                  # lev 4 + cos 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 5\n                                                  # lev 4 + cos 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 10\n                                                  # lev 4 + cos 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 10\n                                                  # lev 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 10\n                                                  # lev 4 + cos 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 10\n                                                  # lev 3 + cos 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cohen_kappa_score(y_ts, y_pr ,weights='quadratic')# des char 1,4, compon = 10\n                                                  # lev 3 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"feature_imp = dict(zip(list(X.columns), list(xgb.feature_importances_)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sorted_x = sorted(feature_imp.items(), key=lambda x: x[1], reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost import plot_importance\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"xgb = XGBClassifier()\nxgb.fit(X, y, sample_weight=weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_features(xgb, (14,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_ts, y_pr), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}