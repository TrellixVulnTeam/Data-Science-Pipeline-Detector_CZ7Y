{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch, torchvision, glob, os\nimport pandas as pd\nimport pytorch_lightning as  pl\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nfrom os import  path","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T05:47:50.030998Z","iopub.execute_input":"2022-05-04T05:47:50.031388Z","iopub.status.idle":"2022-05-04T05:47:58.659898Z","shell.execute_reply.started":"2022-05-04T05:47:50.031289Z","shell.execute_reply":"2022-05-04T05:47:58.658775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_paths(dir_,jpg=True):\n    if jpg:\n        paths=glob.glob(dir_+'/'+dir_.split('/')[-1]+'/*.jpg')\n    else:\n        paths=glob.glob(dir_+'/'+dir_.split('/')[-1]+'/*.png')\n    return paths\n\ndef read_img(path):\n    img=torchvision.io.read_image(path)\n    return img\n\ndef get_mask_path(path):\n    path_=path.split('/')\n    path_[-2],path_[-3]='instance_masks','instance_masks'\n    temp_last=path_[-1].split('.')\n    temp_last[-1]='png'\n    path_[-1]='.'.join(temp_last)\n    return '/'.join(path_)\n\n\ndef get_img_path(path):\n    path_=path.split('/')\n    path_[-2],path_[-3]='train','train'\n    temp_last=path_[-1].split('.')\n    temp_last[-1]='jpg'\n    path_[-1]='.'.join(temp_last)\n    return '/'.join(path_)\n\ndef plot_images(img_paths,r=8,c=8,figsize=(20,20)):\n    \n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    \n    for n, ax in enumerate(axs):\n        \n        img=read_img(img_paths[n])\n        ax.imshow(torchvision.transforms.functional.to_pil_image(img))\n        ax.axis('off')\n        \n    plt.tight_layout()\n    plt.show()\n\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:47:58.661824Z","iopub.execute_input":"2022-05-04T05:47:58.662236Z","iopub.status.idle":"2022-05-04T05:47:58.681803Z","shell.execute_reply.started":"2022-05-04T05:47:58.662192Z","shell.execute_reply":"2022-05-04T05:47:58.680657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# here check path exists","metadata":{}},{"cell_type":"code","source":"def plot_overlays(img_paths,mask_paths,r=8,c=8,figsize=(20,20)):\n    \n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    \n    for n, ax in enumerate(axs):\n        if path_exits_condition:\n            img=read_img(get_img_path(mask_paths[n]))\n            mask=read_img(mask_paths[n])\n            mask=torch.tensor(mask,dtype=bool)\n            img=torchvision.utils.draw_segmentation_masks(img,mask,0.3)\n\n            ax.imshow(torchvision.transforms.functional.to_pil_image(img))\n            ax.axis('off')\n        \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T06:37:00.466459Z","iopub.execute_input":"2022-05-04T06:37:00.466732Z","iopub.status.idle":"2022-05-04T06:37:00.474913Z","shell.execute_reply.started":"2022-05-04T06:37:00.466705Z","shell.execute_reply":"2022-05-04T06:37:00.4738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_json(path):\n    with open(path) as json_data:\n        d = json.loads(json_data.read())\n    return d\n\ndef create_detection_map(annotations):\n    \"\"\"Creates a dict mapping IDs to detections.\"\"\"\n\n    ann_map = {}\n    for image in annotations['images']:\n        ann_map[image['file'].split('/')[-1].rstrip('.jpg')] = image['detections']\n    return ann_map\n\n\ndef image_name_to_id(name):\n    return name.rstrip('.jpg')\n\nBOX_ANNOTATION_FILE='../input/iwildcam2022-fgvc9/metadata/metadata/iwildcam2022_mdv4_detections.json'\nannotations = read_json(BOX_ANNOTATION_FILE)\ndetection_map = create_detection_map(annotations)\nimage_ids = list(detection_map.keys())","metadata":{"execution":{"iopub.status.busy":"2022-05-04T06:20:58.575585Z","iopub.execute_input":"2022-05-04T06:20:58.576102Z","iopub.status.idle":"2022-05-04T06:21:03.738227Z","shell.execute_reply.started":"2022-05-04T06:20:58.576043Z","shell.execute_reply":"2022-05-04T06:21:03.737327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    \n    train_dir_='../input/iwildcam2022-fgvc9/train'\n    train_paths=get_paths(train_dir_)\n    print(len(train_paths))\n    \n    mask_dir_='../input/iwildcam2022-fgvc9/instance_masks'\n    mask_paths=get_paths(mask_dir_,jpg=False)\n    \n    test_dir_='../input/iwildcam2022-fgvc9/test'\n    test_paths=get_paths(test_dir_)\n    \n    plot_images(train_paths)\n    plot_images(mask_paths)\n    \n#     plot_overlays(train_paths,mask_paths)\n    \n    \n    \n    \nmain()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:47:58.683442Z","iopub.execute_input":"2022-05-04T05:47:58.683721Z","iopub.status.idle":"2022-05-04T05:49:13.716008Z","shell.execute_reply.started":"2022-05-04T05:47:58.68368Z","shell.execute_reply":"2022-05-04T05:49:13.715051Z"},"trusted":true},"execution_count":null,"outputs":[]}]}