{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"Notebook that can be used to compare various ELO prediction setups, to find a setup that's optimized to your liking. Set your desired inputs in the \"User Defined Values\" section. General rule of thumb for compute time is about 1000 scenarios per hour.\n\nAll predictions are made using ELO ratings as of the end of the regular season. \n\nHappy to hear any and all ideas to make it better. Enjoy!\n\nResources:\n- https://en.wikipedia.org/wiki/Elo_rating_system\n- https://fivethirtyeight.com/features/how-we-calculate-nba-elo-ratings/\n- https://github.com/fivethirtyeight/nfl-elo-game/blob/master/forecast.py"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# User Defined Values"},{"metadata":{"trusted":true,"_uuid":"dc9a31b1cd760be654144af9f8b4521e669fda1c"},"cell_type":"code","source":"ratings_initialization = 1500 # where to start Elo ratings\nk_series = [10, 20] # how much importance to give to recent games - higher value assigns more importance\nhome_adv_series = [100, 200] # value of home court advantage\nrevert_series = [0.4, 0.6] # how much mean reversion to allow after seasons - note if revert_option = 'None', still need to have at least one value here\nrevert_option = ['None', 'NCAA'] # options for mean reversion - 'None' or 'NCAA'. NCAA reverts to ratings_initialization\nfirst_season = [2000, 2010] # what season to start ELO calculation in\nkeep_seasons = [2014, 2015, 2016, 2017, 2018] # which seasons to keep end of season ELOs, for prediction and analysis","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b10fbba18234fa65d314d7bfec6b3b09b1cf595"},"cell_type":"markdown","source":"# Import Packages"},{"metadata":{"trusted":true,"_uuid":"04a029afbcac89676adf39682c5a69364ab34df3"},"cell_type":"code","source":"# for data manipulation\nimport pandas as pd\nimport numpy as np \n\n# for tracking simulation time\nimport time\n\n# for individual log loss function evaluation\nimport math\n\n# for vector log loss metric evaluation\nimport sklearn\nfrom sklearn import metrics\n\n# for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5719af43f01dd626ec80c01d7be51b53ad93fc3"},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"trusted":true,"_uuid":"900466d99ca67f7e9661a83bb51787e10c9c2f44"},"cell_type":"code","source":"regular_season = pd.read_csv(\"../input/wdatafiles/WRegularSeasonCompactResults.csv\")\ntourney = pd.read_csv(\"../input/wdatafiles/WNCAATourneyCompactResults.csv\")\nteams = pd.read_csv(\"../input/wdatafiles/WTeams.csv\")\nseeds = pd.read_csv(\"../input/wdatafiles/WNCAATourneySeeds.csv\")\npredictions = pd.read_csv(\"../input/WSampleSubmissionStage1.csv\")\nresults = pd.read_csv(\"../input/wdatafiles/WNCAATourneyCompactResults.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ecbb5baf1baca8c8e524a3814298ad8fa5973c2"},"cell_type":"markdown","source":"# Data Prep for Simulations"},{"metadata":{"trusted":true,"_uuid":"bc680aaba03df564681ac5f19e03a4cdb0fd6fe9"},"cell_type":"code","source":"# Create tourney data indicator in regular season and tourney data\nregular_season['Tourney_Ind'] = 'N'\ntourney['Tourney_Ind'] = 'Y'\n# Append tourney data to regular season data\ngames = regular_season.append(tourney)\n\n# Columns to help identify teams, store Elo ratings\ngames['Team1ID'] = games.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID']]))), axis=1)\ngames['Team2ID'] = games.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['LTeamID']]))), axis=1)\ngames['Team1Elo'] = ratings_initialization\ngames['Team2Elo'] = ratings_initialization\ngames['margin'] = games['WScore'] - games['LScore']\n#games['elo'] = None\n\n# Create dictionary to store Elo ratings, for quick iteration\ndf_Team1 = pd.DataFrame({'Team': games['Team1ID'], 'Elo': games['Team1Elo']})\ndf_Team2 = pd.DataFrame({'Team': games['Team2ID'], 'Elo': games['Team2Elo']})\ndf_Team = df_Team1.append(df_Team2)\ndf_Team = df_Team.drop_duplicates(['Team'])\ndf_Team['Season'] = df_Team['Team'].map(lambda x: x.split('_')[0]).astype(int)\ndf_Team['Team'] = df_Team['Team'].map(lambda x: x.split('_')[1]).astype(int)\nelo_dict = dict(zip(df_Team['Team'], df_Team['Elo']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f713a7d5578c5ffe6ea7c21bb32c43e82f18e2fa"},"cell_type":"markdown","source":"# Functions to Calculate Elo Ratings and Find End of Regular Season Elo Ratings"},{"metadata":{"trusted":true,"_uuid":"ead36ffa0e56de2ba9297f57bc5cf8e943def6af"},"cell_type":"code","source":"def elo_dataframe(df, team_id):\n   # Creates dataframe ready to take in Elo simulations \n    d = games.copy()\n    d = d.loc[(d['WTeamID'] == team_id) | (d['LTeamID'] == team_id), :].reset_index(drop=True)\n    d.drop_duplicates(['Season'], keep='last', inplace=True)\n    out = pd.DataFrame({\n        'team_id': team_id,\n        'season': d['Season'],\n    })\n    return(out)\n\ndef elo_update(w_elo, l_elo, margin, k):\n    ''' Calculates updated Elo rankings after taking in game results '''\n    \n    elo_diff = w_elo - l_elo\n    pred = (1. / (10. ** (-(w_elo - l_elo) / 400.) + 1.))\n    mult = math.log(abs(margin)+1)*(2.2/((w_elo-l_elo)*0.001+2.2))\n    update = k * mult * (1 - pred)\n    \n    return(pred, update)\n\ndef calculate_elo(in_df, out_df, scenario_dict, k, home_adv, revert, option):\n    ''' Iterates through all games in the dataframe, calculating Elo ratings at each point in time '''\n    preds = []\n    elo_df = pd.DataFrame(columns=['team_id', 'season', 'elo'])\n    elo_df['team_id'] = elo_df['team_id'].astype(int)\n    elo_df['season'] = elo_df['season'].astype(int)\n    scenario_dict = {x:ratings_initialization for x, y in scenario_dict.items()}\n                    \n    for i in range(in_df.shape[0]):\n            # Get key data from current row\n            w = in_df.at[i, 'WTeamID']\n            l = in_df.at[i, 'LTeamID']\n            margin = in_df.at[i, 'margin']\n            wloc = in_df.at[i, 'WLoc']\n            # Does either team get a home-court advantage?\n            w_ad, l_ad, = 0., 0.\n            if wloc == \"H\":\n                w_ad += home_adv\n            elif wloc == \"A\":\n                l_ad += home_adv\n            # Get elo updates as a result of the game\n            pred, update = elo_update(scenario_dict[w] + w_ad,\n                                      scenario_dict[l] + l_ad, \n                                      margin,\n                                      k)\n            scenario_dict[w] += update\n            scenario_dict[l] -= update\n            preds.append(pred)\n            # If game is last of the regular season for a given scenario, stores the elo in the elo_df dataframe, to be included in the output\n            if ((i+1 in range(in_df.shape[0])) and (in_df.at[i+1, 'Tourney_Ind'] == 'Y') and (in_df.at[i, 'Tourney_Ind'] == 'N')) or (i == in_df.shape[0]):\n                elo = pd.DataFrame.from_dict(scenario_dict, orient='index', columns=['elo']).reset_index().rename(columns={'index':'team_id'})\n                elo['season']= in_df.at[i, 'Season']\n                elo_df = elo_df.append(elo, sort=True)\n               # print(elo_df.shape)\n            # If a new season is started, account for some mean reversion \n            if (i+1 in range(in_df.shape[0])) and (in_df.at[i, 'Season'] < in_df.at[i+1, 'Season']):\n                if option == 'NCAA':\n                    scenario_dict = {x:((revert*ratings_initialization) + ((1-revert)*y)) for x, y in scenario_dict.items()}\n                else:\n                    scenario_dict = scenario_dict\n                               \n    out_df = out_df.merge(elo_df, how='inner', on=['team_id', 'season'])   \n    return(out_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18d4ea653923b8e8e4544c2469814368d20ddc6b"},"cell_type":"markdown","source":"# Run Simulations"},{"metadata":{"trusted":true,"_uuid":"91b5d3d2b7b365009fba241b3661b6eae8fccfad"},"cell_type":"code","source":"start = time.time()\n\n#Set up dataframes to hold Elo ratings - only setup to keep results that we can test on (2014-2018 tournaments)\ngames = games.sort_values(by=['Season', 'DayNum'], ascending=True).reset_index(drop=True)\nseasons_keep = games[games['Season'].isin(keep_seasons)]\nteam_ids = set(seasons_keep['WTeamID']).union(set(seasons_keep['LTeamID']))\nelo_list = [elo_dataframe(games, i) for i in team_ids]\nseason_elos = pd.concat(elo_list)\nscenario_elos = season_elos\n\nfor season in first_season:\n    # Set games dataframe to only include seasons you want to iterate over\n    games_indexed = games[games['Season'] >= season]\n    # Make sure games index is in order, otherwise functions won't work\n    games_indexed = games_indexed.sort_values(by=['Season', 'DayNum'], ascending=True).reset_index(drop=True)\n    \n    #Run through scenarios\n    for k in k_series:\n        for home_adv in home_adv_series:\n            for revert in revert_series:\n                for option in revert_option:\n            # Calculate Elo ratings\n                    scenario = calculate_elo(in_df = games_indexed, out_df=scenario_elos, scenario_dict=elo_dict, k=k, home_adv=home_adv, revert=revert, option=option).rename({\n                        'elo':'elo_'+str(season)+'_'+str(k)+'_'+str(home_adv)+'_'+str(revert)+'_'+str(option)}, axis='columns')\n                    season_elos =season_elos.merge(scenario, how='inner', on=['team_id', 'season'])\n        \nprint(\"Completed in\", time.time() - start, \"seconds\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f944c5d2baa7443a91470bb282e54103ca958ff"},"cell_type":"markdown","source":"# Data Prep for Predictions"},{"metadata":{"trusted":true,"_uuid":"1a61267a59d310fbe3c49cedceffaad0d2a0f53c"},"cell_type":"code","source":"# Data prep\npredictions['Season'] = predictions['ID'].map(lambda x: x.split('_')[0]).astype(int)\npredictions['Team1'] = predictions['ID'].map(lambda x: x.split('_')[1]).astype(int)\npredictions['Team2'] = predictions['ID'].map(lambda x: x.split('_')[2]).astype(int)\n\nelos1 = season_elos.rename(columns={'team_id':'Team1', 'season': 'Season'})\nelos2 = season_elos.rename(columns={'team_id':'Team2', 'season': 'Season'})\n\npredictions = pd.merge(left=predictions, right=elos1, how='left', on=['Team1', 'Season'])\npredictions = pd.merge(left=predictions, right=elos2, how='left', on=['Team2', 'Season'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8443df415e1ee8e918703e09d66149ddb4d14cc5"},"cell_type":"markdown","source":"# Function for Prediction"},{"metadata":{"trusted":true,"_uuid":"b293e2e5394b0cd51c39dc234c55f2ab136662c6"},"cell_type":"code","source":"# Prediction function\ndef elo_pred(elo1, elo2):\n    pred = 1. / (10. ** (-(np.subtract(elo1, elo2)) / 400.) + 1.)\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3723ba6f1be4f0f64a726e4aee3079cabe46ef3c"},"cell_type":"markdown","source":"# Create Predictions"},{"metadata":{"trusted":true,"_uuid":"738d697487c91ae581b6d5ecee57422b2c7e5acb"},"cell_type":"code","source":"# Create predictions\nfor season in first_season:\n    for k in k_series:\n        for home_adv in home_adv_series:\n            for revert in revert_series:\n                for option in revert_option:\n        # Calculate Elo ratings\n                     predictions['pred_'+str(season)+'_'+str(k)+'_'+str(home_adv)+'_'+str(revert)+'_'+str(option)]= elo_pred(predictions['elo_'+str(season)+'_'+str(k)+'_'+str(home_adv)+'_'+str(revert)+'_'+str(option)+'_x'],\n                             predictions['elo_'+str(season)+'_'+str(k)+'_'+str(home_adv)+'_'+str(revert)+'_'+str(option)+'_y'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5622a45ff63462a240eb2d3dfc52a52fa74480df"},"cell_type":"markdown","source":"# Bring in Actual Results"},{"metadata":{"trusted":true,"_uuid":"3565e4aba29fafbb4900581130d8a542a229a3b6"},"cell_type":"code","source":"# Load in actual results\nresults = results.loc[results['DayNum'] > 135] \nresults['Team1'] = results[['WTeamID','LTeamID']].min(axis=1)\nresults['Team2'] = results[['WTeamID','LTeamID']].max(axis=1)\npredictions = pd.merge(predictions, results, how='inner', on=['Season','Team1','Team2'])\npredictions['result'] = (predictions['WTeamID'] == predictions['Team1']).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a80b3da03764dec53b4dd13f38b17304cb5db07c"},"cell_type":"markdown","source":"# Calculate Log Loss for Each Scenario"},{"metadata":{"trusted":true,"_uuid":"4cf5f760255bc4187f3147e75d483908164c6c26"},"cell_type":"code","source":"# Total log loss for each iteration of ELO\nlogloss=pd.DataFrame(columns=['name', 'log_loss'])\nname = []\ncalc = []\n\nfor season in first_season:\n    for k in k_series:\n        for home_adv in home_adv_series:\n            for revert in revert_series:\n                for option in revert_option:\n        # Calculate Elo ratings\n                    name_i = str(season)+\"_\"+str(k)+\"_\"+str(home_adv)+\"_\"+str(revert)+\"_\"+str(option)\n                    calc_i = sklearn.metrics.log_loss(predictions['result'], predictions['pred_'+str(season)+\"_\"+str(k)+'_'+str(home_adv)+'_'+str(revert)+'_'+str(option)], eps=1e-15) \n                    \n                    name.append(name_i)\n                    calc.append(calc_i)\n\nlogloss['name'] = name\nlogloss['log_loss'] = calc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c39c6f15f50fd16923152453d8d43bdf3784f9f4"},"cell_type":"markdown","source":"# Analysis"},{"metadata":{"_uuid":"fa943da8af4ac52f88710622877ccd0db53b5fea"},"cell_type":"markdown","source":"# Top 10 Log Loss Results for 2014-2018"},{"metadata":{"trusted":true,"_uuid":"3c3833175534bbefa2b4a68de7ac7df86de358ab"},"cell_type":"code","source":"# Let's only keep top 20 results, for comparison\nlogloss = logloss.sort_values(by='log_loss', ascending=True, axis=0)\nlogloss_top10 = logloss[:9]\nlogloss_top10","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9de00afbc0b8481a576d49c9ac214c078a2f4a8b"},"cell_type":"markdown","source":"# Season by Season Log Loss for Top 10 Scenarios"},{"metadata":{"trusted":true,"_uuid":"02ff570e8ddefbecbbbee5b3767c553780d46779"},"cell_type":"code","source":"# Calculate season by season results for scenarios with top 10 total log loss\nlogloss_season=pd.DataFrame(columns=['name', 'season', 'log_loss']) \nname = []\nseason = []\ncalc = []\n\nfor s in predictions['Season'].unique():\n    data = predictions[predictions['Season']==s]\n    for scenario in logloss_top10['name'].unique(): \n        # Calculate Elo ratings\n                    name_i = scenario\n                    season_i = s\n                    calc_i = sklearn.metrics.log_loss(data['result'], data['pred_'+str(scenario)],eps=1e-15) \n                    \n                    name.append(name_i)\n                    season.append(season_i)\n                    calc.append(calc_i)\n\nlogloss_season['name'] = name\nlogloss_season['season'] = season\nlogloss_season['log_loss'] = calc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"420f4aeafc4671bf9cb66960537d7800aef5354e"},"cell_type":"code","source":"# Visualize season by season results of predictions\nsns.lineplot(x=logloss_season['season'], y=logloss_season['log_loss'], hue=logloss_season['name'], legend=False) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d13ed7599996abd7155d2dd15ef32ae07ea88ae9"},"cell_type":"markdown","source":"# Analysis on End of Season ELO Rankings and Biggest Prediction Misses "},{"metadata":{"trusted":true,"_uuid":"d1aaa71fd640fe228d96ab007bdb54b545a4d9e6"},"cell_type":"code","source":"# Pick a scenario to further analyze\nscenario = '2000_20_100_0.6_None'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21168903f3c478872f607a006950f8629dcc362e"},"cell_type":"code","source":"analysis = predictions[['ID', 'Season', 'Team1', 'Team2', 'elo_'+scenario+'_x',\n                       'elo_'+scenario+'_y', 'pred_'+scenario, 'result', 'WScore', 'LScore']]\nanalysis = analysis.rename(columns={'elo_'+scenario+'_x':'elo1','elo_'+scenario+'_y': 'elo2',\n                                   'pred_'+scenario:'pred'})\n#Bring in team names\nanalysis = analysis.merge(teams[['TeamID', 'TeamName']],left_on=['Team1'], right_on=['TeamID'], how='left').rename(columns={'TeamName':'TeamName1'})\nanalysis = analysis.merge(teams[['TeamID', 'TeamName']],left_on=['Team2'], right_on=['TeamID'], how='left').rename(columns={'TeamName':'TeamName2'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c1df85cd91274ea673029a1fec541299db77f89"},"cell_type":"code","source":"# Calculate log loss for individual games to see where biggest errors are\n\ndef logloss(true_label, predicted, eps=1e-15):\n  p = np.clip(predicted, eps, 1 - eps)\n  if true_label == 1:\n    return -math.log(p)\n  else:\n    return -math.log(1 - p)\n\nanalysis['logloss']=0\nanalysis['logloss']=analysis['logloss'].astype(float)\nfor i in range(len(analysis.index)):\n    analysis['logloss'][i] = logloss(analysis['result'][i], analysis['pred'][i], eps=1e-15) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e94a7a6c53a5296412de2d5e0007bbe0c7ca9a5"},"cell_type":"code","source":"#Create dataframe for rankings analysis\nrankings = analysis[['Season', 'TeamName1', 'elo1']].drop_duplicates()\nrankings2 = analysis[['Season', 'TeamName2', 'elo2']].drop_duplicates().rename(columns={'TeamName2':'TeamName1', 'elo2':'elo1'})\nrankings = rankings.append(rankings2, sort=True).drop_duplicates()\n\n#Create dataframe for evaluating biggest misses\nmisses = analysis[['Season', 'TeamName1', 'TeamName2', 'elo1', 'elo2', 'pred', 'WScore', 'LScore', 'logloss']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c04022c523359c775408c632268003b6c93ae36a"},"cell_type":"code","source":"#2018 rankings\nrankings[rankings['Season']==2018].sort_values('elo1', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d149785eb25f2b615e7b65ba782a1eda0df1d064"},"cell_type":"code","source":"#2018 biggest misses\nmisses[misses['Season']==2018].sort_values('logloss', ascending=False).head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}