{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import log_loss\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, GaussianNoise\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nfrom math import ceil\n\nimport gc\ngc.enable()\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/womens-machine-learning-competition-2019/stage2wdatafiles\"))\nprint(os.listdir(\"../input/season-stats\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ae2998735bb0f2b3de9d3ba1dd7e71db97ff18c"},"cell_type":"markdown","source":"**Load data**\n\nSeeds are used to express the overall strength of the team.\n\nRecent data was collected to express the current position of the team."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"recent = pd.read_csv(\"../input/season-stats/RecentStatsSince1998.csv\", index_col=0)\nseeds = pd.read_csv('../input/womens-machine-learning-competition-2019/stage2wdatafiles/WNCAATourneySeeds.csv')\ntourney_dresults = pd.read_csv('../input/womens-machine-learning-competition-2019/stage2wdatafiles/WNCAATourneyCompactResults.csv')\n\nsub = pd.read_csv('../input/womens-machine-learning-competition-2019/WSampleSubmissionStage2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b4989ebb48efa85d5b66b944db9786fc9b469e2"},"cell_type":"code","source":"recent.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc2a75e964624985e76d33530574fd88d0aa7d0f"},"cell_type":"markdown","source":"Convert the seeds into numbers."},{"metadata":{"trusted":true,"_uuid":"79403118a2a2944b29c84c742ce4e5272b760905"},"cell_type":"code","source":"seeds[\"Seed\"] = seeds[\"Seed\"].replace(\"\\D\", \"\", regex=True).astype(\"int8\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0817287ddd9b70f89c59aee022dbcea09c2b27c0"},"cell_type":"markdown","source":"**Preprocess the recent data**\n\nThis includes filtering for teams that actually played in a given season, calculating the total scores (and scores against) of the individual teams in post-2009 seasons from the individual points scored.\n\nAdditionally, scaling and imputing of missing values in pre-2010 is done (imputed with 0.5)\n\nLastly, seeds are added to the stats."},{"metadata":{"trusted":true,"_uuid":"7da3025ba28523a154e507ffb2bd882a8dbcafb8","scrolled":false},"cell_type":"code","source":"recent = recent.loc[recent[\"Games\"] != 0]\n\nrecent.loc[recent[\"Season\"] > 2009,\"Score\"] = 2*recent.loc[recent[\"Season\"] > 2009,\"FGM\"] + recent.loc[recent[\"Season\"] > 2009,\"FGM3\"] + recent.loc[recent[\"Season\"] > 2009,\"FTM\"]\nrecent.loc[recent[\"Season\"] > 2009,\"Score_A\"] = 2*recent.loc[recent[\"Season\"] > 2009,\"FGM_A\"] + recent.loc[recent[\"Season\"] > 2009,\"FGM3_A\"] + recent.loc[recent[\"Season\"] > 2009,\"FTM_A\"]    \n    \nrecent[\"ScoreDf\"] = recent[\"Score\"] - recent[\"Score_A\"]\nrecent[\"TODf\"] = recent[\"TO\"] - recent[\"Stl\"]\nrecent[[\"Wins\", \"Score\", \"Score_A\", \"ScoreDf\", \"FGM\", \"FGA\", \"FGM3\", \"FTM\", \"FTA\", \"OR\", \"DR\", \"Ast\", \"TO\", \"Stl\", \"Blk\", \"PF\", \"FGM_A\", \"FGA_A\", \"FGM3_A\", \"FTM_A\", \"FTA_A\", \"OR_A\", \"DR_A\", \"Ast_A\", \"TO_A\", \"Stl_A\", \"Blk_A\", \"PF_A\"]] = recent[[\"Wins\", \"Score\", \"Score_A\", \"ScoreDf\", \"FGM\", \"FGA\", \"FGM3\", \"FTM\", \"FTA\", \"OR\", \"DR\", \"Ast\", \"TO\", \"Stl\", \"Blk\", \"PF\", \"FGM_A\", \"FGA_A\", \"FGM3_A\", \"FTM_A\", \"FTA_A\", \"OR_A\", \"DR_A\", \"Ast_A\", \"TO_A\", \"Stl_A\", \"Blk_A\", \"PF_A\"]].values/np.reshape(recent[\"Games\"].values, [-1,1])\nrecent.columns = [\"Recent\"+x if (x not in [\"TeamID\", \"Season\"]) else x for x in recent.columns ]\n\nstsc = MinMaxScaler()\nrecent[[x for x in recent.columns if x not in [\"TeamID\", \"Season\"]]] = stsc.fit_transform(recent[[x for x in recent.columns if x not in [\"TeamID\", \"Season\"]]])\n\nnulls = [x for x in recent.columns if x not in [\"TeamID\", \"Season\", \"RecentGames\", \"RecentScore\"]]\nfor x in nulls:\n    recent.loc[(recent[\"Season\"].isin(range(1998,2010)) & recent[\"RecentGames\"]>0) & np.isnan(recent[x]), x] = 0.5\n\ndt = seeds.merge(recent, on=[\"TeamID\", \"Season\"])\n\ndt.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30f7890be4f249014331723ddd2d4b83a0643aa5"},"cell_type":"markdown","source":"**Preprocess tournament results**\n\nThe teams are identified, and each game is supplemented with the information about the teams playing it."},{"metadata":{"trusted":true,"_uuid":"e5ff79da1b66e5f5766947a62eabcc2abba46988"},"cell_type":"code","source":"tourney_dresults[\"ID\"] = tourney_dresults.apply(lambda r: '_'.join(map(str, [r['Season'], min(r['WTeamID'], r[\"LTeamID\"]), max(r[\"WTeamID\"],r[\"LTeamID\"])])), axis=1)\ntourney_dresults[\"mTeam\"] = tourney_dresults.apply(lambda r: min(r['WTeamID'], r[\"LTeamID\"]), axis=1)\ntourney_dresults[\"Pred\"] = 0\n\ntourney_dresults.loc[tourney_dresults[\"mTeam\"]==tourney_dresults[\"WTeamID\"],\"Pred\"] = 1\ntourney_dresults.drop([\"mTeam\"],1, inplace=True)\n\ntourney_dresults['WLoc'] = 3\ntourney_dresults['Season'] = tourney_dresults['ID'].map(lambda x: x.split('_')[0])\ntourney_dresults['Season'] = tourney_dresults['Season'].astype(int)\ntourney_dresults['Team1'] = tourney_dresults['ID'].map(lambda x: x.split('_')[1])\ntourney_dresults['Team2'] = tourney_dresults['ID'].map(lambda x: x.split('_')[2])\n\ntourney_dresults['IDTeams'] = tourney_dresults.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\ntourney_dresults['IDTeam1'] = tourney_dresults.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\ntourney_dresults['IDTeam2'] = tourney_dresults.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n\ntourney_dresults = tourney_dresults[[\"ID\", \"Pred\", \"Season\", \"Team1\", \"Team2\"]]\n\ntourney_dresults[[\"Team1\", \"Team2\", \"Season\"]] = tourney_dresults[[\"Team1\", \"Team2\", \"Season\"]].astype(\"int16\")\n\ntourney_dresults = tourney_dresults.merge(dt, left_on=[\"Team1\", \"Season\"], right_on=[\"TeamID\", \"Season\"])\ntourney_dresults = tourney_dresults.merge(dt, left_on=[\"Team2\", \"Season\"], right_on=[\"TeamID\", \"Season\"])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f44715f5b96346909368171a29ad49f3b836ffa"},"cell_type":"markdown","source":"**Count differences of  strengths**\n\nRecent strength is expressed as the ratio of each statistics for each of the teams. To avoid division by zero, small quantity is added "},{"metadata":{"trusted":true,"_uuid":"b7fcc77d63cf889c17741a7aef5f66b5cf0bbf67"},"cell_type":"code","source":"cols = [\"Seed\", \"RecentTODf\", 'RecentGames', 'RecentWins', \"RecentScore\", \"RecentScore_A\", \"RecentScoreDf\", 'RecentFGM', 'RecentFGA', 'RecentFGM3',\n                          'RecentFTM', 'RecentFTA', 'RecentOR', 'RecentDR', 'RecentAst',\n                          'RecentTO', 'RecentStl', 'RecentBlk', 'RecentPF',\n                         \"RecentFGM_A\", \"RecentFGA_A\", \"RecentFGM3_A\", \"RecentFTM_A\",\n                          \"RecentFTA_A\", \"RecentOR_A\", \"RecentDR_A\",\n                          \"RecentAst_A\", \"RecentTO_A\", \"RecentStl_A\", \"RecentBlk_A\", \"RecentPF_A\"]\n\ndiff = [\"Dif\"+x for x in cols]\n\ndifs = pd.DataFrame((tourney_dresults[[x+\"_x\" for x in cols]].values+0.1)/(0.1+\n                    tourney_dresults[[x+\"_y\" for x in cols]].values), columns=diff)\n\ntourney_dresults = pd.concat([tourney_dresults, difs], 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ee6ca83b026f54726c42c76fc16fe5ddb4f20fc"},"cell_type":"markdown","source":"**Prepare the submission data**\n\nThe processing is identical to that of tournament games."},{"metadata":{"trusted":true,"_uuid":"3368847a815c3f07000c69e221285661be90a3e0"},"cell_type":"code","source":"sub = pd.read_csv('../input/womens-machine-learning-competition-2019/WSampleSubmissionStage2.csv')\n\nsub['WLoc'] = 3\nsub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\nsub['Season'] = sub['Season'].astype(int)\nsub['Team1'] = sub['ID'].map(lambda x: x.split('_')[1])\nsub['Team2'] = sub['ID'].map(lambda x: x.split('_')[2])\n\nsub['IDTeams'] = sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\nsub['IDTeam1'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\nsub['IDTeam2'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n\nsub = sub[[\"ID\", \"Pred\", \"Season\", \"Team1\", \"Team2\"]]\n\nsub[[\"Team1\", \"Team2\", \"Season\"]] = sub[[\"Team1\", \"Team2\", \"Season\"]].astype(\"int16\")\nsub = sub.merge(dt, left_on=[\"Team1\", \"Season\"], right_on=[\"TeamID\", \"Season\"])\nsub = sub.merge(dt, left_on=[\"Team2\", \"Season\"], right_on=[\"TeamID\", \"Season\"])\n\ndifs = pd.DataFrame((0.1+sub[[x+\"_x\" for x in cols]].values)/(0.1+\n                    sub[[x+\"_y\" for x in cols]].values), columns=diff)\n\nsub = pd.concat([sub, difs], 1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a307fe48ce0c1a9e9654fb48dcf919ed8322d1fd"},"cell_type":"markdown","source":"**Explore data**"},{"metadata":{"trusted":true,"_uuid":"249dd4fc390478040da2d0f7236cffbca807375b"},"cell_type":"code","source":"tourney_dresults.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0456ffe74708755d90e6e59f2b77ea71f4b919a"},"cell_type":"code","source":"import seaborn as sns\n\nsns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"DifRecentScore\"])\nplt.show()\nsns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"DifRecentScore_A\"])\nplt.show()\nsns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"DifRecentScoreDf\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c759272a55773ac02742d99cc56c5d32fe68de9c"},"cell_type":"code","source":"sns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"DifRecentScoreDf\"])\nplt.show()\nsns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"RecentScoreDf_x\"])\nplt.show()\nsns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"RecentScoreDf_y\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3eaf928f26343094fb78a839d43339548c6e70dd"},"cell_type":"code","source":"sns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"DifRecentWins\"])\nplt.show()\nsns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"RecentWins_x\"])\nplt.show()\nsns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"RecentWins_y\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"359f962ae398f66d792bd22194598af4c6ec2474"},"cell_type":"code","source":"sns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"DifSeed\"])\nplt.show()\nsns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"Seed_x\"])\nplt.show()\nsns.boxplot(tourney_dresults[\"Pred\"], tourney_dresults[\"Seed_y\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42fd2bb22902c2c2eaccf6354dec6a39647e5d60"},"cell_type":"markdown","source":"**Prepare training/validation/test data**\n\nEither use all columns or only those for which data is available throughout the history"},{"metadata":{"trusted":true,"_uuid":"db32bc489c6a61399c14d1cfdc450aed05cbd51d"},"cell_type":"code","source":"dat = \"both\"\nrs = 1999\n\ntr_val_test = [0.8,0.1,0.1]\nstandardize = True\n\nensemble = 15\nepochs = 1500\npatience = 50\nalpha_factor = 0.4\n\ncol = [x for x in tourney_dresults.columns if x not in [\"ID\", \"Season\", \"Pred\", \"Games\", \"Team1\", \"Team2\", \"TeamID_x\", \"TeamID_y\", \"RecentGames\", \"DifRecentGames\",\"DifGames\"]]    \n    \nminicol = [\"Seed_x\", \"Seed_y\", \"DifRecentWins\", \"DifSeed\", \"RecentScoreDf_x\",\n          \"RecentScoreDf_y\", \"DifRecentScoreDf\"]\n\nif dat == \"mini\":\n    train = tourney_dresults.copy()\n    train.drop([x for x in train.columns if x not in minicol], 1, inplace=True)\n    y_train = tourney_dresults[\"Pred\"].ravel()\n\nelif dat == \"maxi\":\n    train = tourney_dresults.copy()\n    train.drop([x for x in train.columns if x not in col], 1, inplace=True)\n    y_train = tourney_dresults[\"Pred\"].ravel()\n    \nelse:\n    train_min = tourney_dresults.copy()\n    train_min.drop([x for x in train_min.columns if x not in minicol], 1, inplace=True)\n    y_train_min = tourney_dresults[\"Pred\"].ravel()   \n\n    train_max = tourney_dresults.loc[tourney_dresults[\"Season\"]>2009].copy()\n    train_max.drop([x for x in train_max.columns if x not in col], 1, inplace=True)\n    y_train_max = tourney_dresults.loc[tourney_dresults[\"Season\"]>2009, \"Pred\"].ravel()    \n\nif dat in [\"mini\", \"maxi\"]:    \n    train, test, y_train, y_test = train_test_split(train, y_train, test_size=tr_val_test[2], random_state=rs\n                                               )\n    sets = []\n    for x in range(ensemble):\n        train, val, y_train, y_val = train_test_split(train, y_train, test_size=tr_val_test[1]/(tr_val_test[0]+tr_val_test[1]), random_state=rs+x+1)\n        sets.append([train, val, y_train, y_val])\n\n    test_s = sub.copy()\n    if dat == \"mini\":\n        test_s.drop([x for x in test_s.columns if x not in minicol], 1, inplace=True)\n    else:\n        test_s.drop([x for x in test_s.columns if x not in col], 1, inplace=True)\n    \n    stsc = MinMaxScaler()\n    if dat == \"mini\":\n        stsc.fit(tourney_dresults[minicol].values.astype(\"float64\"))\n    else:\n        stsc.fit(tourney_dresults[col].values.astype(\"float64\"))\n\n    if standardize == True:\n        test = stsc.transform(test)\n        for x in range(ensemble):\n            t,v,y_t,y_v = sets[x]\n            t = stsc.transform(t)\n            v = stsc.transform(v)\n            sets[x] = [t,v,y_t,y_v]\n        test_s = stsc.transform(test_s)  \n    \n    else:\n        test = test.values\n        for x in range(ensemble):\n            t,v,y_t,y_v = sets[x]\n            t = t.values\n            v = v.values\n            sets[x] = [t,v,y_t,y_v]\n        test_s = test_s.values\n\nelse:    \n    train_min, test_min, y_train_min, y_test_min = train_test_split(train_min, y_train_min, test_size=tr_val_test[2], random_state=rs\n                                               )\n    sets_min = []\n    for x in range(ensemble):\n        train_min, val_min, y_train_min, y_val_min = train_test_split(train_min, y_train_min, test_size=tr_val_test[1]/(tr_val_test[0]+tr_val_test[1]), random_state=rs+x+1                                               )\n        sets_min.append([train_min, val_min, y_train_min, y_val_min])\n\n    test_s_min = sub.copy()\n    test_s_min.drop([x for x in test_s_min.columns if x not in minicol], 1, inplace=True)\n\n    stsc = MinMaxScaler()\n    stsc.fit(tourney_dresults[minicol].values.astype(\"float64\"))\n\n    if standardize == True:\n        test_min = stsc.transform(test_min)\n        for x in range(ensemble):\n            t,v,y_t,y_v = sets_min[x]\n            t = stsc.transform(t)\n            v = stsc.transform(v)\n            sets_min[x] = [t,v,y_t,y_v]\n        test_s_min = stsc.transform(test_s_min)  \n    \n    else:\n        test_min = test_min.values\n        for x in range(ensemble):\n            t,v,y_t,y_v = sets_min[x]\n            t = t.values\n            v = v.values\n            sets_min[x] = [t,v,y_t,y_v]\n        test_s_min = test_s_min.values\n\n    train_max, test_max, y_train_max, y_test_max = train_test_split(train_max, y_train_max, test_size=tr_val_test[2], random_state=rs\n                                               )\n    sets_max = []\n    for x in range(ensemble):\n        train_max, val_max, y_train_max, y_val_max = train_test_split(train_max, y_train_max, test_size=tr_val_test[1]/(tr_val_test[0]+tr_val_test[1]), random_state=rs+x+1                                               )\n        sets_max.append([train_max, val_max, y_train_max, y_val_max])\n\n    test_s_max = sub.copy()\n    test_s_max.drop([x for x in test_s_max.columns if x not in col], 1, inplace=True)\n\n    stsc = MinMaxScaler()\n    stsc.fit(tourney_dresults[col].values.astype(\"float64\"))\n\n    if standardize == True:\n        test_max = stsc.transform(test_max)\n        for x in range(ensemble):\n            t,v,y_t,y_v = sets_max[x]\n            t = stsc.transform(t)\n            v = stsc.transform(v)\n            sets_max[x] = [t,v,y_t,y_v]\n        test_s_max = stsc.transform(test_s_max)  \n    \n    else:\n        test_max = test_max.values\n        for x in range(ensemble):\n            t,v,y_t,y_v = sets_max[x]\n            t = t.values\n            v = v.values\n            sets_max[x] = [t,v,y_t,y_v]\n        test_s_max = test_s_max.values        \n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e53ec7da325b5d501768c1370585afc626a61d0"},"cell_type":"markdown","source":"**Modelling**\n\nCreate models, fit them"},{"metadata":{"trusted":true,"_uuid":"0e90d4e5f8e2f9007eb83b57fbd9dad1dc66aee9"},"cell_type":"code","source":"if dat in [\"mini\", \"maxi\"]:\n    models = []\n    histories = []\n    pred = np.zeros([len(test),1], dtype=\"float64\")\n    for x in range(ensemble):\n        print(\"Fitting model %i\" % x)\n        train, val, y_train, y_val = sets[x]\n        param = {'num_leaves':31, 'num_trees':1000, 'objective':'binary'}\n        num_round = 10\n        model = lgb.train(param, [train, y_train], num_round, valid_sets=[val, y_val], early_stopping_rounds=50)\n\n        #history = model.fit(train, y_train, validation_data=[val, y_val], callbacks=[EarlyStopping(min_delta=0.0001, patience=300,restore_best_weights=True)], batch_size=len(y_train), epochs=2000, verbose=0)    \n        models.append(model)\n        #histories.append(history)\n        pred += model.predict(test)\n        \nelse:        \n    models_min = []\n    histories_min = []\n    pred_min = np.zeros([len(test_min),1], dtype=\"float64\")\n    print(\"Fitting MINI\")\n    for x in range(ensemble):\n        train, val, y_train, y_val = sets_min[x]\n        param = {'num_leaves':31, 'num_trees':1000, 'objective':'binary', \"colsample_bytree\":0.3}\n        num_round = 10\n        model = lgb.LGBMClassifier(max_depth=-1,\n                               n_estimators=50000,\n                               learning_rate=0.01,\n                               colsample_bytree=0.1,\n                               objective='binary', \n                               n_jobs=-1)        \n        model.fit(train, y_train, eval_set=[(val, y_val)],verbose=0, early_stopping_rounds=500)\n        models_min.append(model)\n        histories_min.append(log_loss(y_val, np.reshape(model.predict_proba(val)[:,-1], [-1,1])))\n        \n        #print(model.predict_proba(test_min)[:,-1])\n        pred_min += np.reshape(model.predict_proba(test_min)[:,-1], [-1,1])\n        \n        try:\n            print(\"\\t%i/%i: %.4f\" % (x+1, ensemble, histories_min[-1]))  \n        except:\n            pass\n    models_max = []\n    histories_max = []\n    pred_max = np.zeros([len(test_max),1], dtype=\"float64\")\n    print(\"Fitting MAXI\")\n    for x in range(ensemble):\n        train, val, y_train, y_val = sets_max[x]\n        param = {'num_leaves':31, 'num_trees':1000, 'objective':'binary', \"colsample_bytree\":0.3}\n        num_round = 10\n        model = lgb.LGBMClassifier(max_depth=-1,\n                               n_estimators=50000,\n                               learning_rate=0.01,\n                               colsample_bytree=0.1,\n                               objective='binary', \n                               n_jobs=-1)        \n        history = model.fit(train, y_train, eval_set=[(val, y_val)], verbose=0, early_stopping_rounds=1000)        \n        models_max.append(model)\n        histories_max.append(log_loss(y_val, np.reshape(model.predict_proba(val)[:,-1], [-1,1])))\n        pred_max +=  np.reshape(model.predict_proba(test_max)[:,-1], [-1,1])\n        try:\n            print(\"\\t%i/%i: %.4f\" % (x+1, ensemble, histories_max[-1]))   \n        except:\n            pass","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"259d48aa30540abdaeed75de8d76f11d2d8e59e8"},"cell_type":"markdown","source":"**Evaluate the model**\n\nUse three levels of evaluation:\n1. Loss over test data\n2. Loss over validation data as developing throughout the training\n3. By-model loss over validation data as developing throughout the training\n"},{"metadata":{"trusted":true,"_uuid":"021aa974504a2e982b44d20e75507f54ba2b986a"},"cell_type":"code","source":"def pad(c, dim):\n    c = c + [min(c)]*(dim-len(c))\n    return(c)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf27e098fdbb4d31ca71ceec3e144fc60bc835e1","trusted":true},"cell_type":"markdown","source":"def pad(c, dim):\n    c = c + [min(c)]*(dim-len(c))\n    return(c)\n\nif dat in [\"mini\", \"maxi\"]:\n    pred = pred/ensemble\n    print(\"Log loss: %f\" % log_loss(y_test, pred))\n\n    losses = np.zeros([epochs,1])\n    for x in range(ensemble):\n        hst = histories[x]\n        hst = np.reshape(pad(hst.history[\"val_loss\"], epochs), [-1,1])\n        losses += hst\n    \n    losses /= ensemble\n\n    plt.plot(losses)\n    plt.title('Average loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.show()\n\n    for x in range(ensemble):\n        hst = histories[x]    \n        plt.plot(hst.history['val_loss'])\n\n    plt.title('Individual losses')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(range(ensemble), loc='upper left')\n    plt.show()\n    \nelse:\n    print(\"Log loss MIN: %f\" % log_loss(y_test_min, pred_min/ensemble))    \n    print(\"Log loss MAX: %f\" % log_loss(y_test_max, pred_max/ensemble))\n\n    #pred = (pred_max+pred_min)/(2*ensemble)\n    #print(\"Log loss BLEND: %f\" % log_loss(y_test, pred))    \n    \n    losses_min = np.zeros([epochs,1])\n    for x in range(ensemble):\n        hst = histories_min[x]\n        hst = np.reshape(pad(hst.history[\"val_loss\"], epochs), [-1,1])\n        losses_min += hst\n    \n    losses_min /= ensemble\n\n    plt.plot(losses_min)\n    \n    losses_max = np.zeros([epochs,1])\n    for x in range(ensemble):\n        hst = histories_max[x]\n        hst = np.reshape(pad(hst.history[\"val_loss\"], epochs), [-1,1])\n        losses_max += hst\n    \n    losses_max /= ensemble\n\n    plt.plot(losses_max)    \n    \n    plt.title('Average loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend([\"MINI\", \"MAXI\"], loc='upper left')    \n    plt.show()\n\n    for x in range(ensemble):\n        hst = histories_min[x]    \n        plt.plot(hst.history['val_loss'])\n\n    plt.title('Individual losses MIN')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(range(ensemble), loc='upper left')\n    plt.show() \n    \n    for x in range(ensemble):\n        hst = histories_max[x]    \n        plt.plot(hst.history['val_loss'])\n\n    plt.title('Individual losses MAX')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(range(ensemble), loc='upper left')\n    plt.show()       "},{"metadata":{"_uuid":"890ec85c33607e6366fd78aff497bdf404f447d6"},"cell_type":"markdown","source":"**Breed**"},{"metadata":{"trusted":true,"_uuid":"af545c288a4af4b991af4da975054321aa74453e"},"cell_type":"code","source":"alphas = []\nhists = []\n\nhmin = histories_min\nhmax = histories_max\nbests = [x for x in hmin+hmax]\nfor x in range(ceil(ensemble*alpha_factor)):\n    #print(bests)\n    best = np.argmin(bests)\n    #print(best)\n    #print(bests[best])\n    if best < ensemble:\n        alphas.append([\"min\",models_min[best]])\n        hists.append(hmin[best])\n        bests[best] = 20\n    else:\n        alphas.append([\"max\",models_max[best-ensemble]])\n        hists.append(hmax[best-ensemble])        \n        bests[best] = 20     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b02ef83e343cd44acf2eaeb2fbb4d0150a24ce0"},"cell_type":"code","source":"nalphas = []\nnhists = []\n\nhmin = [log_loss(y_test_min, x[1].predict_proba(test_min)[:,-1]) for x in alphas if x[0]==\"min\"]\nhmax = [log_loss(y_test_max, x[1].predict_proba(test_max)[:,-1]) for x in alphas if x[0]==\"max\"]\nalphas = [x for x in alphas if x[0]==\"min\"]+[x for x in alphas if x[0]==\"max\"]\n\nbests = hmin+hmax\nfor x in range(ceil(len(bests)*alpha_factor)):\n    best = np.argmin(bests)\n    if alphas[best][0] == \"min\":\n        nalphas.append(alphas[best])\n        nhists.append(bests[best])\n        bests[best] = 20\n    else:\n        nalphas.append(alphas[best])\n        nhists.append(bests[best])            \n        bests[best] = 20\n        \n\nloss = sum(nhists)/len(nhists)\n\nprint(\"Optimized LOSS: %.3f\" % loss)\nprint(nhists)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b29e76431bcf546f3150ede0f1ef8c5a4401601b"},"cell_type":"markdown","source":"**Prepare the submission**"},{"metadata":{"trusted":true,"_uuid":"017549fe6ccf4ad9eed2e7a206790fb9fe80a1a9"},"cell_type":"code","source":"if dat in [\"mini\", \"maxi\"]:\n    pred = np.zeros([len(test_s),1])\n    for x in range(ensemble):\n        pred += models[x].predict_proba(test_s)[:,-1]\nelse:\n    pred = np.zeros([len(test_s_min),1])\n    for x in range(len(alphas)):\n        if alphas[x][0] == \"min\":\n            pred += np.reshape(alphas[x][1].predict_proba(test_s_min)[:,-1], [-1,1])\n        else:\n            pred += np.reshape(alphas[x][1].predict_proba(test_s_max)[:,-1], [-1,1])\nsubm = pd.DataFrame(np.zeros([len(sub), 2]), columns=[\"ID\", \"Pred\"]) \nsubm[\"Pred\"] = pred/len(alphas)\nsubm = subm[[\"ID\", \"Pred\"]]\nsubm[\"ID\"] = sub[\"ID\"].astype(\"str\")\nsubm.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}