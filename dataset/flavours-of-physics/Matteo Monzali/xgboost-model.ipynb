{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Load datasets\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport pandas as pd\n\ntrain = pd.read_csv('../input/flavours-of-physics/training.csv.zip')\ncheck_agreement = pd.read_csv('../input/flavours-of-physics/check_agreement.csv.zip')\ncheck_correlation = pd.read_csv('../input/flavours-of-physics/check_correlation.csv.zip')    \ntest = pd.read_csv('../input/flavours-of-physics/test.csv.zip')\n\n#Import libraries for timing and XGBoost\n\nimport time\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import external library evaluation.py for KS and CvM tests","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile evaluation.py\n\nimport numpy\nfrom sklearn.metrics import roc_curve, auc\n\n\ndef __rolling_window(data, window_size):\n    \"\"\"\n    Rolling window: take window with definite size through the array\n\n    :param data: array-like\n    :param window_size: size\n    :return: the sequence of windows\n\n    Example: data = array(1, 2, 3, 4, 5, 6), window_size = 4\n        Then this function return array(array(1, 2, 3, 4), array(2, 3, 4, 5), array(3, 4, 5, 6))\n    \"\"\"\n    shape = data.shape[:-1] + (data.shape[-1] - window_size + 1, window_size)\n    strides = data.strides + (data.strides[-1],)\n    return numpy.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n\n\ndef __cvm(subindices, total_events):\n    \"\"\"\n    Compute Cramer-von Mises metric.\n    Compared two distributions, where first is subset of second one.\n    Assuming that second is ordered by ascending\n\n    :param subindices: indices of events which will be associated with the first distribution\n    :param total_events: count of events in the second distribution\n    :return: cvm metric\n    \"\"\"\n    target_distribution = numpy.arange(1, total_events + 1, dtype='float') / total_events\n    subarray_distribution = numpy.cumsum(numpy.bincount(subindices, minlength=total_events), dtype='float')\n    subarray_distribution /= 1.0 * subarray_distribution[-1]\n    return numpy.mean((target_distribution - subarray_distribution) ** 2)\n\n\ndef compute_cvm(predictions, masses, n_neighbours=200, step=50):\n    \"\"\"\n    Computing Cramer-von Mises (cvm) metric on background events: take average of cvms calculated for each mass bin.\n    In each mass bin global prediction's cdf is compared to prediction's cdf in mass bin.\n\n    :param predictions: array-like, predictions\n    :param masses: array-like, in case of Kaggle tau23mu this is reconstructed mass\n    :param n_neighbours: count of neighbours for event to define mass bin\n    :param step: step through sorted mass-array to define next center of bin\n    :return: average cvm value\n    \"\"\"\n    predictions = numpy.array(predictions)\n    masses = numpy.array(masses)\n    assert len(predictions) == len(masses)\n\n    # First, reorder by masses\n    predictions = predictions[numpy.argsort(masses)]\n\n    # Second, replace probabilities with order of probability among other events\n    predictions = numpy.argsort(numpy.argsort(predictions, kind='mergesort'), kind='mergesort')\n\n    # Now, each window forms a group, and we can compute contribution of each group to CvM\n    cvms = []\n    for window in __rolling_window(predictions, window_size=n_neighbours)[::step]:\n        cvms.append(__cvm(subindices=window, total_events=len(predictions)))\n    return numpy.mean(cvms)\n\n\ndef __roc_curve_splitted(data_zero, data_one, sample_weights_zero, sample_weights_one):\n    \"\"\"\n    Compute roc curve\n\n    :param data_zero: 0-labeled data\n    :param data_one:  1-labeled data\n    :param sample_weights_zero: weights for 0-labeled data\n    :param sample_weights_one:  weights for 1-labeled data\n    :return: roc curve\n    \"\"\"\n    labels = [0] * len(data_zero) + [1] * len(data_one)\n    weights = numpy.concatenate([sample_weights_zero, sample_weights_one])\n    data_all = numpy.concatenate([data_zero, data_one])\n    fpr, tpr, _ = roc_curve(labels, data_all, sample_weight=weights)\n    return fpr, tpr\n\n\ndef compute_ks(data_prediction, mc_prediction, weights_data, weights_mc):\n    \"\"\"\n    Compute Kolmogorov-Smirnov (ks) distance between real data predictions cdf and Monte Carlo one.\n\n    :param data_prediction: array-like, real data predictions\n    :param mc_prediction: array-like, Monte Carlo data predictions\n    :param weights_data: array-like, real data weights\n    :param weights_mc: array-like, Monte Carlo weights\n    :return: ks value\n    \"\"\"\n    assert len(data_prediction) == len(weights_data), 'Data length and weight one must be the same'\n    assert len(mc_prediction) == len(weights_mc), 'Data length and weight one must be the same'\n\n    data_prediction, mc_prediction = numpy.array(data_prediction), numpy.array(mc_prediction)\n    weights_data, weights_mc = numpy.array(weights_data), numpy.array(weights_mc)\n\n    assert numpy.all(data_prediction >= 0.) and numpy.all(data_prediction <= 1.), 'Data predictions are out of range [0, 1]'\n    assert numpy.all(mc_prediction >= 0.) and numpy.all(mc_prediction <= 1.), 'MC predictions are out of range [0, 1]'\n\n    weights_data /= numpy.sum(weights_data)\n    weights_mc /= numpy.sum(weights_mc)\n\n    fpr, tpr = __roc_curve_splitted(data_prediction, mc_prediction, weights_data, weights_mc)\n\n    Dnm = numpy.max(numpy.abs(fpr - tpr))\n    return Dnm\n\n\ndef roc_auc_truncated(labels, predictions, tpr_thresholds=(0.2, 0.4, 0.6, 0.8),\n                      roc_weights=(4, 3, 2, 1, 0)):\n    \"\"\"\n    Compute weighted area under ROC curve.\n\n    :param labels: array-like, true labels\n    :param predictions: array-like, predictions\n    :param tpr_thresholds: array-like, true positive rate thresholds delimiting the ROC segments\n    :param roc_weights: array-like, weights for true positive rate segments\n    :return: weighted AUC\n    \"\"\"\n    assert numpy.all(predictions >= 0.) and numpy.all(predictions <= 1.), 'Data predictions are out of range [0, 1]'\n    assert len(tpr_thresholds) + 1 == len(roc_weights), 'Incompatible lengths of thresholds and weights'\n    fpr, tpr, _ = roc_curve(labels, predictions)\n    area = 0.\n    tpr_thresholds = [0.] + list(tpr_thresholds) + [1.]\n    for index in range(1, len(tpr_thresholds)):\n        tpr_cut = numpy.minimum(tpr, tpr_thresholds[index])\n        tpr_previous = numpy.minimum(tpr, tpr_thresholds[index - 1])\n        area += roc_weights[index - 1] * (auc(fpr, tpr_cut, reorder=True) - auc(fpr, tpr_previous, reorder=True))\n    tpr_thresholds = numpy.array(tpr_thresholds)\n    # roc auc normalization to be 1 for an ideal classifier\n    area /= numpy.sum((tpr_thresholds[1:] - tpr_thresholds[:-1]) * numpy.array(roc_weights))\n    return area","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import evaluation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data preselection\n\ntrain_pre = train.drop(train[train.min_ANNmuon <= 0.4].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create features and labels tables\n\ntrain_features = train_pre.drop(['min_ANNmuon', 'mass', 'production', 'signal', 'id', 'SPDhits'], axis = 1)\ntrain_labels = train_pre['signal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ntrain_features.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create model and fit to data\n\nt0 = time.perf_counter()\n\nparams = {\"objective\": \"binary:logistic\",\n          \"eta\": 0.4,\n          \"max_depth\": 6,\n          \"min_child_weight\": 3,\n          \"subsample\": 0.5,\n          \"colsample_bytree\": 0.7,\n          \"seed\": 2}\nn_trees = 300\nmodel = xgb.train(params, xgb.DMatrix(train_features, train_labels), n_trees)\n\nt1 = time.perf_counter() - t0\nprint('Timing: ', t1, ' s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create datasets for agreement and correlation check\n\ncheck_agreement_features = check_agreement.drop(['signal', 'id', 'weight', 'SPDhits'], axis = 1)\ncheck_agreement_labels = check_agreement['signal']\ncheck_agreement_weigths = check_agreement['weight']\n\ncheck_correlation_features = check_correlation.drop(['id', 'mass', 'SPDhits'], axis = 1)\ncheck_correlation_labels = check_correlation['mass']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predictions on agreement and correlation datasets\n\nagreement_probs = model.predict(xgb.DMatrix(check_agreement_features)).reshape(-1,)\ncorrelation_probs = model.predict(xgb.DMatrix(check_correlation_features)).reshape(-1,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate KS score, it has to be less than 0.09\n\nks = evaluation.compute_ks(\nagreement_probs[check_agreement['signal'].values == 0],\nagreement_probs[check_agreement['signal'].values == 1],\ncheck_agreement[check_agreement['signal'] == 0]['weight'].values,\ncheck_agreement[check_agreement['signal'] == 1]['weight'].values)\nprint ('KS metric', ks, ks < 0.09)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate CvM score, it has to be less than 0.002\n\ncvm = evaluation.compute_cvm(correlation_probs, check_correlation['mass'])\nprint ('CvM metric', cvm, cvm < 0.002)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#If the two tests have been passed import test dataset, create the feature table and \n#make predictions on test dataset and export them as .csv file\n#Not every run gives True conditions both for cvm and ks\n\nif cvm < 0.002 and ks < 0.09 :\n\n    test_features = test.drop(['id', 'SPDhits'], axis = 1)\n    test_probs = model.predict(xgb.DMatrix(test_features)).reshape(-1,)\n    submission = pd.DataFrame({\"id\": test[\"id\"], \"prediction\": test_probs})\n    submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot ROC curve\n\nimport sklearn.metrics as metrics\n# calculate the fpr and tpr for all thresholds of the classification\npreds = model.predict(xgb.DMatrix(check_agreement_features))\n#preds = probs[:,0]\n\nfpr, tpr, threshold = metrics.roc_curve(check_agreement_labels, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\nimport matplotlib.pyplot as plt\nplt.style.use('default')\nplt.title('ROC curve')\nplt.plot(tpr, 1-fpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [1, 0],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.xlabel('Signal efficiency (TPR)')\nplt.ylabel('Background rejection (1-FPR)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create signal/background tables for histograms + predictions\n\ntest_1 = train_pre.loc[train_pre['signal'] == 1]\ntest_0 = train_pre.loc[train_pre['signal'] == 0]\ntest_1 = test_1.drop(['min_ANNmuon', 'mass', 'production', 'signal', 'id', 'SPDhits'], axis = 1)\ntest_0 = test_0.drop(['min_ANNmuon', 'mass', 'production', 'signal', 'id', 'SPDhits'], axis = 1)\n\ntest_1_probs = model.predict(xgb.DMatrix(test_1)).reshape(-1,)\ntest_0_probs = model.predict(xgb.DMatrix(test_0)).reshape(-1,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Histograms for signal and background\n\nplt.yscale('symlog')\nplt.ylim(10,3_0000)\nplt.hist(test_1_probs, bins = 15)\nplt.hist(test_0_probs, bins = 15, histtype='step')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph = train.drop(['min_ANNmuon', 'mass', 'production', 'id', 'SPDhits'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Histograms for signal and background variables\n\nplt.yscale('symlog')\nplt.ylim(10,3_0000)\nfor column in test_1.columns:\n    plt.hist(test_1[column], bins = 15, label=('Signal '+ column))\n    plt.hist(test_0[column], bins = 15, histtype='step', label=('Background '+ column))\n    plt.legend(loc=\"upper left\")\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}