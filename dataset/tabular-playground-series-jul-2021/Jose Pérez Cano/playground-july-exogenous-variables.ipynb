{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabular Playground\n## Data loading and preprocessing\n\nFollowing the same steps as the other notebook I will standardize the data.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntrain = pd.read_csv('../input/tabular-playground-series-jul-2021/train.csv', \n                    parse_dates=[\"date_time\"])\ntrain = train.set_index('date_time')\ntarget = train[['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']]\ntrain = train.drop(['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides'], axis=1)\ntest = pd.read_csv('../input/tabular-playground-series-jul-2021/test.csv',\n                  parse_dates=[\"date_time\"])\ntest = test.set_index('date_time')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-03T15:10:17.887965Z","iopub.execute_input":"2021-07-03T15:10:17.888375Z","iopub.status.idle":"2021-07-03T15:10:17.937016Z","shell.execute_reply.started":"2021-07-03T15:10:17.888342Z","shell.execute_reply":"2021-07-03T15:10:17.935574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:10:18.844024Z","iopub.execute_input":"2021-07-03T15:10:18.844573Z","iopub.status.idle":"2021-07-03T15:10:18.85221Z","shell.execute_reply.started":"2021-07-03T15:10:18.844526Z","shell.execute_reply":"2021-07-03T15:10:18.851452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import PowerTransformer\n\npt = PowerTransformer(method='box-cox')\nX_train_sc = pd.DataFrame(data = pt.fit_transform(X_train), columns=X_train.columns, \n                          index=X_train.index)\nX_val_sc = pd.DataFrame(data = pt.transform(X_val), columns=X_val.columns, \n                          index=X_val.index)\n\nfig = X_train_sc.hist(figsize=(100, 100), bins=30)\n[x.title.set_size(80) for x in fig.ravel()]\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:10:19.284169Z","iopub.execute_input":"2021-07-03T15:10:19.284592Z","iopub.status.idle":"2021-07-03T15:10:23.534112Z","shell.execute_reply.started":"2021-07-03T15:10:19.28456Z","shell.execute_reply":"2021-07-03T15:10:23.532968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model selection\n\nAs always we will try linear models as baseline, then random forest, xgboost, ligthboost, catboost and finally and ensemble.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\n\ndef score_model(model, tr, y_train, val, y_val, fitted=False):\n    preds = [[],[],[]]\n    for i in range(3):\n        if not fitted:\n            model.fit(tr, y_train.iloc[:,i])\n        preds[i] = model.predict(val)\n    return mean_squared_log_error(y_val, np.array(preds).T)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:10:23.53636Z","iopub.execute_input":"2021-07-03T15:10:23.537067Z","iopub.status.idle":"2021-07-03T15:10:23.544939Z","shell.execute_reply.started":"2021-07-03T15:10:23.537018Z","shell.execute_reply":"2021-07-03T15:10:23.543713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linear model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import GammaRegressor\n\nmodel = GammaRegressor()\nprint('Baseline error (scaled):',\n      \"{0:.4f}\".format(score_model(model, X_train_sc, y_train, X_val_sc, y_val)),\n      '\\nWithout scaling:',\n      \"{0:.4f}\".format(score_model(model, X_train, y_train, X_val, y_val)))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:10:23.546875Z","iopub.execute_input":"2021-07-03T15:10:23.54723Z","iopub.status.idle":"2021-07-03T15:10:23.673883Z","shell.execute_reply.started":"2021-07-03T15:10:23.547201Z","shell.execute_reply":"2021-07-03T15:10:23.671021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nprint('Random Forest (scaled):',\n      \"{0:.4f}\".format(score_model(model, X_train_sc, y_train, X_val_sc, y_val)),\n      '\\nWithout scaling:',\n      \"{0:.4f}\".format(score_model(model, X_train, y_train, X_val, y_val)))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:40:42.595685Z","iopub.execute_input":"2021-07-03T14:40:42.596061Z","iopub.status.idle":"2021-07-03T14:41:03.074453Z","shell.execute_reply.started":"2021-07-03T14:40:42.596028Z","shell.execute_reply":"2021-07-03T14:41:03.073335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nmodel = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0, objective='reg:gamma')\nprint('XGBoost (scaled):',\n      \"{0:.4f}\".format(score_model(model, X_train_sc, y_train, X_val_sc, y_val)),\n      '\\nWithout scaling:',\n      \"{0:.4f}\".format(score_model(model, X_train, y_train, X_val, y_val)))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:41:03.077052Z","iopub.execute_input":"2021-07-03T14:41:03.077493Z","iopub.status.idle":"2021-07-03T14:41:06.506502Z","shell.execute_reply.started":"2021-07-03T14:41:03.077449Z","shell.execute_reply":"2021-07-03T14:41:06.505468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightGBM","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\n\nmodel = LGBMRegressor(n_estimators=500, learning_rate=0.01, random_state=0, objective='gamma')\nprint('LightGBM (scaled):',\n      \"{0:.4f}\".format(score_model(model, X_train_sc, y_train, X_val_sc, y_val)),\n      '\\nWithout scaling:',\n      \"{0:.4f}\".format(score_model(model, X_train, y_train, X_val, y_val)))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:44:25.21722Z","iopub.execute_input":"2021-07-03T14:44:25.218022Z","iopub.status.idle":"2021-07-03T14:44:29.481867Z","shell.execute_reply.started":"2021-07-03T14:44:25.217978Z","shell.execute_reply":"2021-07-03T14:44:29.481071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CatBoost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\nmodel = CatBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=0, verbose=0,\n                          objective='Tweedie:variance_power=1.5') # Gamma regression\nprint('CatBoost (scaled):',\n      \"{0:.4f}\".format(score_model(model, X_train_sc, y_train, X_val_sc, y_val)),\n      '\\nWithout scaling:',\n      \"{0:.4f}\".format(score_model(model, X_train, y_train, X_val, y_val)))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:50:20.898276Z","iopub.execute_input":"2021-07-03T14:50:20.898762Z","iopub.status.idle":"2021-07-03T14:50:23.331539Z","shell.execute_reply.started":"2021-07-03T14:50:20.89873Z","shell.execute_reply":"2021-07-03T14:50:23.330641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble","metadata":{}},{"cell_type":"code","source":"from random import sample\n\nsampling = np.array(sample(list(X_train.index),len(X_train))).reshape((4,-1))\n  \nX_train0 = X_train[X_train.index.isin(sampling[0])]\ny_train0 = y_train[y_train.index.isin(sampling[0])]\n\nX_train1 = X_train[X_train.index.isin(sampling[1])]\ny_train1 = y_train[y_train.index.isin(sampling[1])]\n\nX_train2 = X_train[X_train.index.isin(sampling[2])]\ny_train2 = y_train[y_train.index.isin(sampling[2])]\n\nX_train3 = X_train[X_train.index.isin(sampling[3])]\ny_train3 = y_train[y_train.index.isin(sampling[3])]\n\npreds = [[],[],[]]\nfor i in range(3):\n    model0 = CatBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=0, verbose=0,\n                              objective='Tweedie:variance_power=1.5') \n    model0.fit(X_train0, y_train0.iloc[:,i])\n\n    model1 = RandomForestRegressor(n_estimators=100, random_state=0)\n    model1.fit(X_train1, y_train1.iloc[:,i])\n\n    model2 = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0, objective='reg:gamma')\n    model2.fit(X_train2, y_train2.iloc[:,i])\n\n    model3 = LGBMRegressor(n_estimators=500, learning_rate=0.01, random_state=0, objective='gamma')\n    model3.fit(X_train3, y_train3.iloc[:,i])\n\n    preds[i] = pd.DataFrame()\n    preds[i]['Catboost'] = model0.predict(X_val)\n    preds[i]['RandomForest'] = model1.predict(X_val)\n    preds[i]['XGBoost'] = model2.predict(X_val)\n    preds[i]['LGBM'] = model3.predict(X_val)\n\npreds = pd.DataFrame(np.array(preds).mean(axis=2).T, columns=y_val.columns, index=y_val.index)\nprint('Ensemble error:',\n     mean_squared_log_error(y_val, preds))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:33:55.399826Z","iopub.execute_input":"2021-07-03T15:33:55.400282Z","iopub.status.idle":"2021-07-03T15:34:01.247221Z","shell.execute_reply.started":"2021-07-03T15:33:55.400243Z","shell.execute_reply":"2021-07-03T15:34:01.246304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import sample\n\nsampling = np.array(sample(list(X_train.index),len(X_train))).reshape((4,-1))\n  \nX_train_sc0 = X_train_sc[X_train_sc.index.isin(sampling[0])]\ny_train0 = y_train[y_train.index.isin(sampling[0])]\n\nX_train_sc1 = X_train_sc[X_train_sc.index.isin(sampling[1])]\ny_train1 = y_train[y_train.index.isin(sampling[1])]\n\nX_train_sc2 = X_train_sc[X_train_sc.index.isin(sampling[2])]\ny_train2 = y_train[y_train.index.isin(sampling[2])]\n\nX_train_sc3 = X_train_sc[X_train_sc.index.isin(sampling[3])]\ny_train3 = y_train[y_train.index.isin(sampling[3])]\n\npreds = [[],[],[]]\nfor i in range(3):\n    model0 = CatBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=0, verbose=0,\n                              objective='Tweedie:variance_power=1.5') \n    model0.fit(X_train_sc0, y_train0.iloc[:,i])\n\n    model1 = RandomForestRegressor(n_estimators=100, random_state=0)\n    model1.fit(X_train_sc1, y_train1.iloc[:,i])\n\n    model2 = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0, objective='reg:gamma')\n    model2.fit(X_train_sc2, y_train2.iloc[:,i])\n\n    model3 = LGBMRegressor(n_estimators=500, learning_rate=0.01, random_state=0, objective='gamma')\n    model3.fit(X_train_sc3, y_train3.iloc[:,i])\n\n    preds[i] = pd.DataFrame()\n    preds[i]['Catboost'] = model0.predict(X_val_sc)\n    preds[i]['RandomForest'] = model1.predict(X_val_sc)\n    preds[i]['XGBoost'] = model2.predict(X_val_sc)\n    preds[i]['LGBM'] = model3.predict(X_val_sc)\n\npreds = pd.DataFrame(np.array(preds).mean(axis=2).T, columns=y_val.columns, index=y_val.index)\nprint('Ensemble error (scaled):',\n     mean_squared_log_error(y_val, preds))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:39:02.817008Z","iopub.execute_input":"2021-07-03T15:39:02.81734Z","iopub.status.idle":"2021-07-03T15:39:08.460974Z","shell.execute_reply.started":"2021-07-03T15:39:02.81731Z","shell.execute_reply":"2021-07-03T15:39:08.4601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import StackingRegressor\n\nreg = StackingRegressor(\n        estimators=[\n            ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=0)),\n            ('XGBoost', XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0, objective='reg:gamma')),\n            ('LGBM', LGBMRegressor(n_estimators=500, learning_rate=0.01, random_state=0, objective='gamma')),\n            ('CatBoost', CatBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=0, verbose=0,\n                              objective='Tweedie:variance_power=1.5'))\n        ],\n        final_estimator=GammaRegressor()\n     )\n\nprint('Stacking (scaled):',\n      \"{0:.4f}\".format(score_model(reg, X_train_sc, y_train, X_val_sc, y_val)),\n      '\\nWithout scaling:',\n      \"{0:.4f}\".format(score_model(reg, X_train, y_train, X_val, y_val)))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:40:28.73771Z","iopub.execute_input":"2021-07-03T15:40:28.738169Z","iopub.status.idle":"2021-07-03T15:43:06.413182Z","shell.execute_reply.started":"2021-07-03T15:40:28.738134Z","shell.execute_reply":"2021-07-03T15:43:06.412071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor\n\nreg = VotingRegressor(\n        estimators=[\n            ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=0)),\n            ('XGBoost', XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0, objective='reg:gamma')),\n            ('LGBM', LGBMRegressor(n_estimators=500, learning_rate=0.01, random_state=0, objective='gamma')),\n            ('CatBoost', CatBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=0, verbose=0,\n                              objective='Tweedie:variance_power=1.5'))\n        ]\n     )\n\nprint('Voting (scaled):',\n      \"{0:.4f}\".format(score_model(reg, X_train_sc, y_train, X_val_sc, y_val)),\n      '\\nWithout scaling:',\n      \"{0:.4f}\".format(score_model(reg, X_train, y_train, X_val, y_val)))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:43:06.414922Z","iopub.execute_input":"2021-07-03T15:43:06.415246Z","iopub.status.idle":"2021-07-03T15:43:37.353848Z","shell.execute_reply.started":"2021-07-03T15:43:06.415207Z","shell.execute_reply":"2021-07-03T15:43:37.35268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction\n\nIt seems the voting method with the four methods is the best of all.","metadata":{}},{"cell_type":"code","source":"final_model = VotingRegressor(\n        estimators=[\n            ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=0)),\n            ('XGBoost', XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0, objective='reg:gamma')),\n            ('LGBM', LGBMRegressor(n_estimators=500, learning_rate=0.01, random_state=0, objective='gamma')),\n            ('CatBoost', CatBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=0, verbose=0,\n                              objective='Tweedie:variance_power=1.5'))\n        ]\n     )\npreds = [[],[],[]]\nfor i in range(3):\n    final_model.fit(train, target.iloc[:,i])\n    preds[i] = final_model.predict(test)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:46:34.222233Z","iopub.execute_input":"2021-07-03T15:46:34.222608Z","iopub.status.idle":"2021-07-03T15:46:53.878205Z","shell.execute_reply.started":"2021-07-03T15:46:34.222576Z","shell.execute_reply":"2021-07-03T15:46:53.877309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = pd.DataFrame(data=np.array(preds).T, columns=target.columns, index=test.index)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:47:48.95098Z","iopub.execute_input":"2021-07-03T15:47:48.951436Z","iopub.status.idle":"2021-07-03T15:47:48.958311Z","shell.execute_reply.started":"2021-07-03T15:47:48.951375Z","shell.execute_reply":"2021-07-03T15:47:48.956625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(3,1, figsize=(50,20))\ntarget.target_benzene.plot(ax=ax[0])\npreds.target_benzene.plot(ax=ax[0])\n\ntarget.target_carbon_monoxide.plot(ax=ax[1])\npreds.target_carbon_monoxide.plot(ax=ax[1])\n\ntarget.target_nitrogen_oxides.plot(ax=ax[2])\npreds.target_nitrogen_oxides.plot(ax=ax[2])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:49:48.721307Z","iopub.execute_input":"2021-07-03T15:49:48.721677Z","iopub.status.idle":"2021-07-03T15:49:50.624847Z","shell.execute_reply.started":"2021-07-03T15:49:48.721646Z","shell.execute_reply":"2021-07-03T15:49:50.623981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.reset_index().to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:50:31.993136Z","iopub.execute_input":"2021-07-03T15:50:31.993544Z","iopub.status.idle":"2021-07-03T15:50:32.025895Z","shell.execute_reply.started":"2021-07-03T15:50:31.99351Z","shell.execute_reply":"2021-07-03T15:50:32.024654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}