{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of Contents\n<a id=\"table-of-contents\"></a>\n- [1 Introduction](#Introduction)\n- [2 Import](#import)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"introduction\"></a>\n# Introduction","metadata":{}},{"cell_type":"markdown","source":"More feature engineering and model impplementdation from [EDA, preprocessing pipeline and submission](https://www.kaggle.com/batprem/eda-preprocessing-pipeline-and-submission).","metadata":{}},{"cell_type":"markdown","source":"<a id=\"import\"></a>\n# Import\n<a id=\"modules\"></a>\n## modules","metadata":{}},{"cell_type":"code","source":"# From eda-preprocessing-pipeline-and-submission\n# OS\nimport os\n\n# Data format\nimport datetime\n\n# Tying\nfrom copy import copy\n\n# Data processing\nimport pandas as pd\n\n# Data virtualisation\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport plotly.express as px\n\n# Widgets\nimport ipywidgets as widgets\n\n# Exporter\nfrom inspect import getsource\n\n# Math and model\nimport numpy as np\nimport scipy\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\n\n# Normaliser\nfrom scipy.special import (\n    boxcox,\n    inv_boxcox\n)\n\n# Modules in this notebook\nfrom catboost import Pool, CatBoostRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom lightgbm import LGBMRegressor\nimport tensorflow as tf\n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\nimport xgboost\n\n## Optuna tuner\nimport optuna\nfrom sklearn.metrics import mean_squared_error\n\n# Submission plot\nimport plotly.figure_factory as ff","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:30:29.97947Z","iopub.execute_input":"2021-07-27T07:30:29.980043Z","iopub.status.idle":"2021-07-27T07:30:41.039017Z","shell.execute_reply.started":"2021-07-27T07:30:29.979932Z","shell.execute_reply":"2021-07-27T07:30:41.037719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"Train_data = pd.read_csv('../input/tabular-playground-series-jul-2021/train.csv')\nTest_data = pd.read_csv('../input/tabular-playground-series-jul-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:30:41.040832Z","iopub.execute_input":"2021-07-27T07:30:41.041194Z","iopub.status.idle":"2021-07-27T07:30:41.118439Z","shell.execute_reply.started":"2021-07-27T07:30:41.041154Z","shell.execute_reply":"2021-07-27T07:30:41.117332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pipeline\n\nIn this section, the preprocessing pipelines made in [EDA, preprocessing pipeline and submission](https://www.kaggle.com/batprem/eda-preprocessing-pipeline-and-submission?scriptVersionId=67990508) are imported","metadata":{}},{"cell_type":"code","source":"pipeline_path = '../input/eda-preprocessing-pipeline-and-submission/pipeline/'\nfor node in os.listdir(pipeline_path):\n    with open(pipeline_path + node, 'r') as f:\n        exec(f.read())","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:30:41.120213Z","iopub.execute_input":"2021-07-27T07:30:41.120524Z","iopub.status.idle":"2021-07-27T07:30:41.180994Z","shell.execute_reply.started":"2021-07-27T07:30:41.120493Z","shell.execute_reply":"2021-07-27T07:30:41.179963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_data = preprocess_test(Train_data)\n# Train_data['month'] = list(pd.Series(Train_data.index).apply(lambda date: date.month))\n# Train_data['week_day*hour'] = Train_data['week_day']*Train_data['hour']\nTrain_data = sort_columns(Train_data)\n# Train_data.drop('hour', axis=1, inplace=True)\nTrain_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:30:41.182692Z","iopub.execute_input":"2021-07-27T07:30:41.183082Z","iopub.status.idle":"2021-07-27T07:30:41.2897Z","shell.execute_reply.started":"2021-07-27T07:30:41.183049Z","shell.execute_reply":"2021-07-27T07:30:41.288727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_data = preprocess_test(Test_data)\n# Test_data['month'] = list(pd.Series(Test_data.index).apply(lambda date: date.month))\n# Test_data['week_day*hour'] = Test_data['week_day']*Test_data['hour']\n# Test_data.drop(['hour'], axis=1, inplace=True)\nTest_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:30:41.291251Z","iopub.execute_input":"2021-07-27T07:30:41.29166Z","iopub.status.idle":"2021-07-27T07:30:41.339553Z","shell.execute_reply.started":"2021-07-27T07:30:41.29162Z","shell.execute_reply":"2021-07-27T07:30:41.33854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise Preprocessing\n### Benzene","metadata":{}},{"cell_type":"code","source":"fig = px.parallel_coordinates(\n    Train_data,\n    color='target_benzene',\n    dimensions=[\n        'hour',\n        'relative_humidity',\n        'sensor_3',\n        'absolute_humidity',\n        'deg_C',\n        # 'month'\n        # 'week_day',\n        'sensor_1',\n        'sensor_2',\n        'sensor_4',\n        'sensor_5',\n        # 'week_day*hour',\n        'target_benzene',\n    ],\n    labels={\n            'target_benzene': 'Benzene',\n            'target_nitrogen_oxides': 'Nitrogen oxides',\n            \"target_carbon_monoxide\": \"Carbon monoxide\"\n    },\n    color_continuous_scale=px.colors.diverging.Tealrose,\n    color_continuous_midpoint=2)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-27T07:30:41.341115Z","iopub.execute_input":"2021-07-27T07:30:41.341545Z","iopub.status.idle":"2021-07-27T07:30:42.752578Z","shell.execute_reply.started":"2021-07-27T07:30:41.341496Z","shell.execute_reply":"2021-07-27T07:30:42.751756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Nitrogen oxides","metadata":{}},{"cell_type":"code","source":"fig = px.parallel_coordinates(\n    Train_data,\n    color='target_nitrogen_oxides',\n    dimensions=[\n        'hour',\n        'relative_humidity',\n        'sensor_3',\n        'absolute_humidity',\n        'deg_C',\n        'sensor_1',\n        'sensor_2',\n        # 'week_day',\n        # 'week_day*hour',\n        'target_benzene',\n        \"target_carbon_monoxide\",\n        'sensor_4',\n        'sensor_5',\n        'target_nitrogen_oxides',\n    ],\n    labels={\n            'target_benzene': 'Benzene',\n            'target_nitrogen_oxides': 'Nitrogen oxides',\n            \"target_carbon_monoxide\": \"Carbon monoxide\"\n    },\n    color_continuous_scale=px.colors.diverging.Tealrose,\n    color_continuous_midpoint=2,\n    range_color=[\n        min(Train_data.target_nitrogen_oxides),\n        max(Train_data.target_nitrogen_oxides)\n    ]\n)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-27T07:30:42.753836Z","iopub.execute_input":"2021-07-27T07:30:42.754288Z","iopub.status.idle":"2021-07-27T07:30:42.947153Z","shell.execute_reply.started":"2021-07-27T07:30:42.754251Z","shell.execute_reply":"2021-07-27T07:30:42.946124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Carbon monoxide","metadata":{}},{"cell_type":"code","source":"fig = px.parallel_coordinates(\n    Train_data,\n    color='target_carbon_monoxide',\n    dimensions=[\n        'hour',\n        'relative_humidity',\n        'sensor_3',\n        'absolute_humidity',\n        'deg_C',\n        'sensor_1',\n        'sensor_2',\n        'sensor_4',\n        'sensor_5',\n        # 'week_day',\n        'target_carbon_monoxide',\n    ],\n    labels={\n            'target_benzene': 'Benzene',\n            'target_nitrogen_oxides': 'Nitrogen oxides',\n            \"target_carbon_monoxide\": \"Carbon monoxide\"\n    },\n    color_continuous_scale=px.colors.diverging.Tealrose,\n    color_continuous_midpoint=2,\n    range_color=[\n        min(Train_data.target_carbon_monoxide),\n        max(Train_data.target_carbon_monoxide)\n    ]\n)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-27T07:30:42.949398Z","iopub.execute_input":"2021-07-27T07:30:42.949913Z","iopub.status.idle":"2021-07-27T07:30:43.11693Z","shell.execute_reply.started":"2021-07-27T07:30:42.949844Z","shell.execute_reply":"2021-07-27T07:30:43.115928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"# Classic K fold\nnum_fold = 5\nkf = KFold(n_splits=num_fold, shuffle=True, random_state=1234)\nkf.get_n_splits(Train_data)\n\nprint(kf)\n\nK_FOLD = []\nfor train_index, test_index in kf.split(Train_data):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    K_FOLD.append((train_index, test_index))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:30:43.118652Z","iopub.execute_input":"2021-07-27T07:30:43.118991Z","iopub.status.idle":"2021-07-27T07:30:43.135472Z","shell.execute_reply.started":"2021-07-27T07:30:43.118956Z","shell.execute_reply":"2021-07-27T07:30:43.134222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Back testing\n# num_fold = 5\n# kf = KFold(n_splits=num_fold, shuffle=False)\n# tscv = TimeSeriesSplit()\n# kf.get_n_splits(Train_data)\n\n# print(kf)\n\n# K_FOLD = []\n# for train_index, test_index in tscv.split(Train_data):\n#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n#     K_FOLD.append((train_index, test_index))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:30:43.137399Z","iopub.execute_input":"2021-07-27T07:30:43.137941Z","iopub.status.idle":"2021-07-27T07:30:43.142555Z","shell.execute_reply.started":"2021-07-27T07:30:43.13789Z","shell.execute_reply":"2021-07-27T07:30:43.141531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\ndef save_model(model, filename):\n    with open(filename, 'wb') as f:\n        pickle.dump(model, f)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:30:43.14405Z","iopub.execute_input":"2021-07-27T07:30:43.14438Z","iopub.status.idle":"2021-07-27T07:30:43.154519Z","shell.execute_reply.started":"2021-07-27T07:30:43.14435Z","shell.execute_reply":"2021-07-27T07:30:43.153172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_svr(X_Train, y_Train, X_Test, y_Test, verbose=True, **params):\n    model = make_pipeline(\n        StandardScaler(),\n        SVR(**params)\n        # SVR(C=1.0, epsilon=0.3)\n    )\n    model.fit(X_Train, y_Train)\n    prediction = model.predict(X_Test)\n    rmsle = RMSLE(prediction, y_Test)\n    rmsle = RMSLE(model.predict(X_Train), y_Train)\n    if verbose: print(f\"rmsle Train: {rmsle}\")\n    rmsle = RMSLE(prediction, y_Test)\n    if verbose: print(f\"rmsle validation: {rmsle}\")\n    return model, prediction, y_Test\n\n\ndef objective_decorate(X_Train, y_Train, X_Test, y_Test):\n    def objective(trial):\n        params = {\n            # 'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n            'C': trial.suggest_loguniform('C', 1e-3, 10.0),\n            'epsilon': trial.suggest_loguniform('epsilon', 1e-3, 10.0),\n        }\n\n        train_predictions = np.array([])\n        y_trains = np.array([])\n        predictions = np.array([])\n        y_validations = np.array([])\n\n\n        # print(f'Columns: {y_col}')\n        model, prediction, y_validation = fit_svr(\n            X_Train,\n            y_Train,\n            X_Test,\n            y_Test,\n            verbose=False,\n            **params\n        )\n        train_prediction = model.predict(X_Train).flatten()\n        train_predictions = np.concatenate([train_predictions, train_prediction])\n        y_trains = np.concatenate([y_trains, y_Train.values])\n        predictions = np.concatenate([predictions, prediction])\n        y_validations = np.concatenate([y_validations, y_validation])\n\n        rmsle_train = RMSLE(train_predictions, y_trains)\n        rmsle_test = RMSLE(predictions, y_validations)\n        overfit_protect = rmsle_test * (rmsle_test/rmsle_train)**(2)\n#         print(f\"Overall rmsle train: {rmsle_train}\")\n#         print(f\"Overall rmsle test: {rmsle_test}\")\n#         print(f\"Overfit protect: {overfit_protect}\")\n        return overfit_protect\n    \n    return objective\n\n# study = optuna.create_study(direction='minimize')\n# optuna.logging.disable_default_handler()\n# study.optimize(\n#     objective_decorate(\n#         X_Train=X_Train,\n#         y_Train=y_Train[y_col],\n#         X_Test=X_Test,\n#         y_Test=y_Test[y_col],\n#     ),\n#     n_trials=50,\n# )\n\n# print('Best trial:', study.best_trial.params)\n\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-27T07:30:43.156268Z","iopub.execute_input":"2021-07-27T07:30:43.156609Z","iopub.status.idle":"2021-07-27T07:30:43.170311Z","shell.execute_reply.started":"2021-07-27T07:30:43.156577Z","shell.execute_reply":"2021-07-27T07:30:43.169395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_log_error as rmsle\nfrom sklearn.ensemble import RandomForestRegressor\n\n\n# Metric\ndef RMSLE(pred, act):\n    pred = inv_boxcox(pred, 0.0001)\n    act = inv_boxcox(act, 0.0001)\n    return (np.mean(\n        (np.log(pred + 1) - np.log(act + 1))**2\n    )) ** 0.5\n\n# Fit\ndef fit_catboosts(X_Train, y_Train, X_Test, y_Test):\n    param = {'iterations':5}\n    model = CatBoostRegressor(\n        iterations=50, \n        depth=5, \n        learning_rate=0.1, \n        l2_leaf_reg=0.15, #0.3,\n        loss_function='RMSE'\n    )\n    \n    train_pool = Pool(\n        X_Train,\n        y_Train, \n        cat_features=None\n    )\n    \n    test_pool = Pool(\n        X_Test, \n        cat_features=None\n    )\n    model.fit(X_Train, y_Train, verbose=0)\n    prediction = model.predict(test_pool)\n    \n    rmsle = RMSLE(model.predict(X_Train), y_Train)\n    print(f\"rmsle Train: {rmsle}\")\n    rmsle = RMSLE(prediction, y_Test)\n    print(f\"rmsle validation: {rmsle}\")\n    return model, prediction, y_Test\n\n\ndef fit_lgbm(X_Train, y_Train, X_Test, y_Test):\n    model = LGBMRegressor(\n        reg_lambda=2,\n        reg_alpha=6,\n        random_state=1234\n    )\n    model.fit(X_Train, y_Train)\n    prediction = model.predict(X_Test)\n    rmsle = RMSLE(prediction, y_Test)\n    rmsle = RMSLE(model.predict(X_Train), y_Train)\n    print(f\"rmsle Train: {rmsle}\")\n    rmsle = RMSLE(prediction, y_Test)\n    print(f\"rmsle validation: {rmsle}\")\n    return model, prediction, y_Test\n\n\ndef fit_svr(X_Train, y_Train, X_Test, y_Test, verbose=True, **params):\n    if not params:\n        params = {'C': 1.5395074336816164, 'epsilon': 0.19287719821166877}\n    model = make_pipeline(StandardScaler(), SVR(\n        # C=1.0, epsilon=0.3\n        **params\n    ))\n    model.fit(X_Train, y_Train)\n    prediction = model.predict(X_Test)\n    rmsle = RMSLE(prediction, y_Test)\n    rmsle = RMSLE(model.predict(X_Train), y_Train)\n    if verbose: print(f\"rmsle Train: {rmsle}\")\n    rmsle = RMSLE(prediction, y_Test)\n    if verbose: print(f\"rmsle validation: {rmsle}\")\n    return model, prediction, y_Test\n\n\ndef fit_linear(X_Train, y_Train, X_Test, y_Test):\n    model = make_pipeline(StandardScaler(), Ridge(alpha=1.0))\n    \n    model.fit(X_Train, y_Train)\n    prediction = model.predict(X_Test)\n    \n    feature_importance = dict(\n        zip(X_Train.columns, model[-1].coef_)\n    )\n    feature_importance = {\n        k: v\n        for k, v\n        in sorted(\n            feature_importance.items(),\n            key=lambda item: item[1], reverse=True\n        )\n    }\n    print(\"Feature important\")\n    print(feature_importance)\n    rmsle = RMSLE(prediction, y_Test)\n    rmsle = RMSLE(model.predict(X_Train), y_Train)\n    print(f\"rmsle Train: {rmsle}\")\n    rmsle = RMSLE(prediction, y_Test)\n    print(f\"rmsle validation: {rmsle}\")\n    return model, prediction, y_Test\n\n\n\ndef fit_randomForest(X_Train, y_Train, X_Test, y_Test):\n    model = RandomForestRegressor(max_features=3)\n    model.fit(X_Train, y_Train)\n    prediction = model.predict(X_Test)\n    \n    feature_importance = dict(\n        zip(X_Train.columns, model.feature_importances_)\n    )\n    feature_importance = {\n        k: v\n        for k, v\n        in sorted(\n            feature_importance.items(),\n            key=lambda item: item[1], reverse=True\n        )\n    }\n    print(\"Feature important\")\n    print(feature_importance)\n    rmsle = RMSLE(prediction, y_Test)\n    rmsle = RMSLE(model.predict(X_Train), y_Train)\n    print(f\"rmsle Train: {rmsle}\")\n    rmsle = RMSLE(prediction, y_Test)\n    print(f\"rmsle validation: {rmsle}\")\n    return model, prediction, y_Test\n\n\n# KNeighborsRegressor(10, weights='uniform')\ndef fit_knn(X_Train, y_Train, X_Test, y_Test):\n    # model = make_pipeline(StandardScaler(), LinearRegression())\n    model = make_pipeline(StandardScaler(), KNeighborsRegressor(10, weights='uniform'))\n    \n    model.fit(X_Train, y_Train)\n    prediction = model.predict(X_Test)\n    rmsle = RMSLE(prediction, y_Test)\n    rmsle = RMSLE(model.predict(X_Train), y_Train)\n    print(f\"rmsle Train: {rmsle}\")\n    rmsle = RMSLE(prediction, y_Test)\n    print(f\"rmsle validation: {rmsle}\")\n    return model, prediction, y_Test\n\n\n# def fit_svrWithOptunaTune(X_Train, y_Train, X_Test, y_Test):\n#     study = optuna.create_study(direction='minimize')\n#     optuna.logging.disable_default_handler()\n#     study.optimize(\n#         objective_decorate(\n#             X_Train=X_Train,\n#             y_Train=y_Train,\n#             X_Test=X_Test,\n#             y_Test=y_Test,\n#         ),\n#         n_trials=50,\n#     )\n    \n    \n#     model = make_pipeline(\n#         StandardScaler(),\n#         SVR(\n#             **study.best_params\n#         )\n#     )\n#     print(model)\n    \n#     model.fit(X_Train, y_Train)\n#     prediction = model.predict(X_Test)\n#     rmsle = RMSLE(prediction, y_Test)\n#     rmsle = RMSLE(model.predict(X_Train), y_Train)\n#     print(f\"rmsle Train: {rmsle}\")\n#     rmsle = RMSLE(prediction, y_Test)\n#     print(f\"rmsle validation: {rmsle}\")\n#     return model, prediction, y_Test\n\n\n\ndef fit_xgboost(X_Train, y_Train, X_Test, y_Test, **params):\n    if not params:\n        params = {'reg_lambda': 8.806514467534535, 'reg_alpha': 5.10815789088487}\n    model = xgboost.XGBRegressor(\n        **params\n#         reg_lambda=2,\n#         reg_alpha=5\n    )\n    model.fit(X_Train, y_Train)\n    prediction = model.predict(X_Test)\n    rmsle = RMSLE(prediction, y_Test)\n    rmsle = RMSLE(model.predict(X_Train), y_Train)\n    print(f\"rmsle Train: {rmsle}\")\n    rmsle = RMSLE(prediction, y_Test)\n    print(f\"rmsle validation: {rmsle}\")\n    return model, prediction, y_Test\n\n\n# def fit_stacking(X_Train, y_Train, X_Test, y_Test):\n#     estimators = [\n#         ('svr_rbf', make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))),\n#         (\n#             'lgbm', LGBMRegressor(\n#                 reg_lambda=2,\n#                 reg_alpha=6,\n#                 random_state=1234\n#             )\n#         )\n#     ]\n#     model = StackingRegressor(\n#         estimators=estimators,\n#         final_estimator= make_pipeline(StandardScaler(), Ridge(alpha=0.1))\n#     )\n#     model.fit(X_Train, y_Train)\n#     prediction = model.predict(X_Test)\n#     rmsle = RMSLE(prediction, y_Test)\n#     rmsle = RMSLE(model.predict(X_Train), y_Train)\n#     print(f\"rmsle Train: {rmsle}\")\n#     rmsle = RMSLE(prediction, y_Test)\n#     print(f\"rmsle validation: {rmsle}\")\n#     return model, prediction, y_Test\n\n\n\ndef get_fit_function(key: str):\n    return key.startswith('fit_')\n\nmodels = {}\ncv_report = pd.DataFrame()\n\nfor k, (Train, Test) in enumerate(K_FOLD):\n    print(f\"K: {k}\")\n    \n    # Ge\n    y_columns = list(\n        Train_data.columns[\n            Train_data.columns.str.startswith('target')\n        ]\n    )\n    X_Train = Train_data.iloc[Train].drop(y_columns, axis=1)\n    y_Train = Train_data.iloc[Train][y_columns]\n\n    X_Test = Train_data.iloc[Test].drop(y_columns, axis=1)\n    y_Test = Train_data.iloc[Test][y_columns]\n    \n    \n    \n    for fit in filter(get_fit_function,dict(globals())):\n        _, model_name = fit.split('_')\n        train_predictions = np.array([])\n        y_trains = np.array([])\n        predictions = np.array([])\n        y_validations = np.array([])\n        model = {}\n        for y_col in y_columns:\n            print(y_col)\n            print(f'Model {model_name}')\n            model[y_col], prediction, y_validation = globals()[fit](\n                X_Train, y_Train[y_col],\n                X_Test, y_Test[y_col]\n            )\n            train_prediction = model[y_col].predict(X_Train)\n            train_predictions = np.concatenate([train_predictions, train_prediction])\n            y_trains = np.concatenate([y_trains, y_Train[y_col].values])\n            predictions = np.concatenate([predictions, prediction])\n            y_validations = np.concatenate([y_validations, y_validation])\n            \n            save_model(model[y_col], f\"Fold_{k}_Model_{model_name}_Col_{y_col}.pickle\")\n        \n        rmsle_train = RMSLE(train_predictions, y_trains)\n        rmsle_test = RMSLE(predictions, y_validations)\n        \n        cv_report.loc[k, f'{model_name}_train'] = rmsle_train\n        cv_report.loc[k, f'{model_name}_test'] = rmsle_test\n        if model_name in models:\n            models[model_name].append(model)\n        else:\n            models[model_name] = [model]\n        print('-' * 36)\n        \n    \n#     catboost_models.append(catboost)\n#     svr_models.append(svr)\n#     linear_models.append(linear)\n#     lgbm_models.append(lgbm)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-27T08:02:04.320522Z","iopub.execute_input":"2021-07-27T08:02:04.321019Z","iopub.status.idle":"2021-07-27T08:03:20.508515Z","shell.execute_reply.started":"2021-07-27T08:02:04.320971Z","shell.execute_reply":"2021-07-27T08:03:20.507267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance = dict(zip(X_Train.columns, models['linear'][0]['target_nitrogen_oxides'][-1].coef_))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:39:04.948823Z","iopub.execute_input":"2021-07-27T07:39:04.949389Z","iopub.status.idle":"2021-07-27T07:39:04.953521Z","shell.execute_reply.started":"2021-07-27T07:39:04.949343Z","shell.execute_reply":"2021-07-27T07:39:04.9527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-27T07:40:58.532822Z","iopub.execute_input":"2021-07-27T07:40:58.533421Z","iopub.status.idle":"2021-07-27T07:40:58.542082Z","shell.execute_reply.started":"2021-07-27T07:40:58.533387Z","shell.execute_reply":"2021-07-27T07:40:58.541353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint\n\nfor name, model in models.items():\n    print(f\"{name}:\")\n    pprint(model[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T08:04:31.432765Z","iopub.execute_input":"2021-07-27T08:04:31.433338Z","iopub.status.idle":"2021-07-27T08:04:31.513457Z","shell.execute_reply.started":"2021-07-27T08:04:31.433295Z","shell.execute_reply":"2021-07-27T08:04:31.512328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_report","metadata":{"execution":{"iopub.status.busy":"2021-07-27T08:04:35.309625Z","iopub.execute_input":"2021-07-27T08:04:35.310025Z","iopub.status.idle":"2021-07-27T08:04:35.338023Z","shell.execute_reply.started":"2021-07-27T08:04:35.309991Z","shell.execute_reply":"2021-07-27T08:04:35.336946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_report.mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T08:04:38.856239Z","iopub.execute_input":"2021-07-27T08:04:38.85679Z","iopub.status.idle":"2021-07-27T08:04:38.866362Z","shell.execute_reply.started":"2021-07-27T08:04:38.856747Z","shell.execute_reply":"2021-07-27T08:04:38.865256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n\nfig = go.Figure()\n\n\nmean_submission = pd.read_csv(\n        '../input/tabular-playground-series-jul-2021/sample_submission.csv'\n    )\nmean_submission = mean_submission.set_index('date_time')\nmean_submission['target_carbon_monoxide'] = 0\nmean_submission['target_benzene'] = 0\nmean_submission['target_nitrogen_oxides'] = 0\n\nfor sub_count, fit in enumerate(filter(get_fit_function,dict(globals()))):\n    _, model_name = fit.split('_')\n\n    submission = pd.read_csv(\n        '../input/tabular-playground-series-jul-2021/sample_submission.csv'\n    )\n    submission = submission.set_index('date_time')\n    submission['target_carbon_monoxide'] = 0\n    submission['target_benzene'] = 0\n    submission['target_nitrogen_oxides'] = 0\n    \n    for k in range(num_fold):\n        for y_col in y_columns:\n            submission[y_col] += models[model_name][k][y_col].predict(\n                Test_data\n            )/num_fold\n\n\n    submission = inv_boxcox(submission, 0.0001)\n    submission.to_csv(f'{model_name}_submission.csv')\n    for y_col in y_columns:\n        fig.add_trace(\n            go.Scatter(\n                x=submission.index,\n                y=submission[y_col],\n                mode='lines',\n                name=f'{model_name}_{y_col}')\n        ) \n    mean_submission += submission\n\n    \nmean_submission = mean_submission / (sub_count + 1)\nmean_submission.to_csv('mean_submission.csv')\nfor y_col in y_columns:\n    fig.add_trace(\n        go.Scatter(\n            x=mean_submission.index,\n            y=mean_submission[y_col],\n            mode='lines',\n            name=f'mean_submission_{y_col}')\n    )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T08:10:07.832352Z","iopub.execute_input":"2021-07-27T08:10:07.832708Z","iopub.status.idle":"2021-07-27T08:10:12.253995Z","shell.execute_reply.started":"2021-07-27T08:10:07.832676Z","shell.execute_reply":"2021-07-27T08:10:12.252756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_submission","metadata":{"execution":{"iopub.status.busy":"2021-07-27T08:09:29.319037Z","iopub.execute_input":"2021-07-27T08:09:29.319417Z","iopub.status.idle":"2021-07-27T08:09:29.338638Z","shell.execute_reply.started":"2021-07-27T08:09:29.319384Z","shell.execute_reply":"2021-07-27T08:09:29.337607Z"},"trusted":true},"execution_count":null,"outputs":[]}]}