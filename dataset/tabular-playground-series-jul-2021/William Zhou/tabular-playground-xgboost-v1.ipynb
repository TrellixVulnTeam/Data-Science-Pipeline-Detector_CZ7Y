{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T23:22:46.591789Z","iopub.execute_input":"2021-07-05T23:22:46.592204Z","iopub.status.idle":"2021-07-05T23:22:47.367771Z","shell.execute_reply.started":"2021-07-05T23:22:46.592119Z","shell.execute_reply":"2021-07-05T23:22:47.366858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = \"../input/tabular-playground-series-jul-2021/\"\ntrain_csv = pd.read_csv(INPUT_DIR + 'train.csv')\ntest_csv = pd.read_csv(INPUT_DIR + 'test.csv')\n\nfrom datetime import datetime\ndef log_scaling(col):\n    col = np.log1p(col)\n    return col\ndef treat_data(csv):\n    \"\"\"\n    Takes: pd df input data in a form similar to train.csv\n    Returns: pd df data split into feature and target categories. The date_time column has been \n    converted from string format to datetime format.\n    \n    \"\"\"\n    csv['date_time'] = [datetime.strptime(i, '%Y-%m-%d %H:%M:%S') for i in csv['date_time']]\n    csv['hour'] = [i.hour for i in csv['date_time']]\n    csv['day'] = [i.day for i in csv['date_time']]\n    csv['week'] = [i.week for i in csv['date_time']]\n    #csv['month'] = [i.month for i in csv['date_time']]\n    #csv['year'] = [i.year for i in csv['date_time']]\n    csv['weekday'] = [i.dayofweek for i in csv['date_time']]\n    first_day = min(csv['date_time'])\n    #csv['time_since_start'] = [(i - first_day).days for i in csv['date_time']]\n    csv['weekday'] = csv['weekday'].astype(object)\n    csv['SMC'] = (csv['absolute_humidity'] * 100) / csv['relative_humidity']\n    csv = pd.get_dummies(csv)\n    cols = ['sensor_1', 'sensor_2', 'sensor_3','sensor_5','SMC']\n    for col in cols:\n        csv[col] = log_scaling(csv[col])\n    return csv\ntrain_csv, test_csv = treat_data(train_csv), treat_data(test_csv)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:32:51.783541Z","iopub.execute_input":"2021-07-05T23:32:51.783874Z","iopub.status.idle":"2021-07-05T23:32:52.060108Z","shell.execute_reply.started":"2021-07-05T23:32:51.783847Z","shell.execute_reply":"2021-07-05T23:32:52.059312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = pd.Series(train_csv.columns).drop(0)\nfig, ax = plt.subplots(len(cols), 2, figsize=(12,25))\nn = 0\nfor i in cols:\n    sns.histplot(train_csv[i], ax=ax[n, 0]);\n    sns.histplot(log_scaling(train_csv[i]), ax=ax[n,1])\n    n += 1\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:32:09.862983Z","iopub.execute_input":"2021-07-05T23:32:09.863343Z","iopub.status.idle":"2021-07-05T23:32:19.008104Z","shell.execute_reply.started":"2021-07-05T23:32:09.863314Z","shell.execute_reply":"2021-07-05T23:32:19.006976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:22:48.022088Z","iopub.execute_input":"2021-07-05T23:22:48.022589Z","iopub.status.idle":"2021-07-05T23:22:48.045003Z","shell.execute_reply.started":"2021-07-05T23:22:48.022558Z","shell.execute_reply":"2021-07-05T23:22:48.043692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_csv.describe())\nprint(train_csv.describe())","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:36:22.716777Z","iopub.execute_input":"2021-07-05T23:36:22.717175Z","iopub.status.idle":"2021-07-05T23:36:22.837201Z","shell.execute_reply.started":"2021-07-05T23:36:22.717143Z","shell.execute_reply":"2021-07-05T23:36:22.836116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\ndef pre_inference(csv):\n    # In preparation for training\n    csv = csv.drop(['date_time'], axis=1)\n    return csv\ntrain_csv = pre_inference(train_csv)\n\ndef log_scaling(col):\n    col = np.log1p(col)\n    return col\n\ndef x_y_split(csv):\n    y_csv = csv[['target_carbon_monoxide','target_benzene','target_nitrogen_oxides']]\n    x_csv = csv.drop(['target_carbon_monoxide','target_benzene','target_nitrogen_oxides'], axis=1)\n    return x_csv, y_csv\nX, y = x_y_split(train_csv)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:36:30.174791Z","iopub.execute_input":"2021-07-05T23:36:30.175191Z","iopub.status.idle":"2021-07-05T23:36:30.389861Z","shell.execute_reply.started":"2021-07-05T23:36:30.175157Z","shell.execute_reply":"2021-07-05T23:36:30.388815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.multioutput import MultiOutputRegressor \nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom collections import OrderedDict\nfrom hyperopt import hp, fmin, tpe\nimport warnings\nwarnings.filterwarnings(action='ignore', category=UserWarning)\n\ndef cross_validate(learning_rate=0.1, max_depth=10, colsample_bytree=0.8, subsample=1, n_estimators=100, booster=\"gbtree\"):\n    kf = KFold(n_splits=5)\n    losses = []\n    models = []\n    for index, (train_index, val_index) in enumerate(kf.split(X)):\n        print(\"Split:\",index+1,\"VAL:\", min(val_index),'-',max(val_index))\n        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n        #data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)\n        xg_reg = MultiOutputRegressor(xgb.XGBRegressor(objective ='reg:linear', \n                    colsample_bytree = colsample_bytree, learning_rate = learning_rate,\n                    max_depth = max_depth, alpha = 10, n_estimators = n_estimators,verbosity = 0, random_state=100, booster=booster))\n        xg_reg.fit(X_train,y_train)\n        preds = xg_reg.predict(X_val)\n        RMSLE = np.sqrt(mean_squared_log_error(y_val, np.clip(preds, 0.001, None)))\n        print(\"loss:\",RMSLE)\n        losses.append(RMSLE); models.append(xg_reg) \n    print(\"RMSLE : %f\" % (np.mean(losses)))\n    return models\n\n\"\"\"\nSPACE = OrderedDict([('learning_rate', hp.loguniform('learning_rate', \n                                                     np.log(0.1), np.log(1))),\n                    ('max_depth', hp.choice('max_depth', range(1, 20, 1))),\n                    ('colsample_bytree', hp.loguniform('colsample_bytree', np.log(0.02),np.log(0.5))),\n                    ('subsample', hp.loguniform('subsample', np.log(0.1), np.log(1.0))),\n                    ('n_estimators', hp.choice('n_estimators', range(1,200,1))),\n                    ('booster', hp.choice('booster',['gbtree','gblinear','dart']))\n                    #('gamma', hp.lognormal('gamma', 0.02,0.5))\n                    ])\n\ndef train_evaluate(learning_rate, max_depth, colsample_bytree, subsample, n_estimators, booster):\n    kf = KFold(n_splits=5)\n    losses = []\n    for index, (train_index, val_index) in enumerate(kf.split(X)):\n        #print(\"Split:\",index+1,\"VAL:\", min(val_index),'-',max(val_index))\n        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n        #data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)\n        xg_reg = MultiOutputRegressor(xgb.XGBRegressor(objective ='reg:linear', \n                    colsample_bytree = colsample_bytree, learning_rate = learning_rate,\n                    max_depth = max_depth, alpha = 10, n_estimators = n_estimators,verbosity = 0))\n        xg_reg.fit(X_train,y_train)\n        preds = xg_reg.predict(X_val)\n        RMSLE = np.sqrt(mean_squared_log_error(y_val, np.clip(preds, 0.001, None)))\n        losses.append(RMSLE)    \n    print(\"RMSLE : %f\" % (np.mean(losses)))\n    return np.mean(losses)\ndef objective(params):\n    print(params)\n    return train_evaluate(**params)\nbest = fmin(objective, SPACE, algo=tpe.suggest, max_evals=100)\nprint(best)\"\"\"\npass","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:50:45.921035Z","iopub.execute_input":"2021-07-05T23:50:45.921379Z","iopub.status.idle":"2021-07-05T23:50:45.933757Z","shell.execute_reply.started":"2021-07-05T23:50:45.921351Z","shell.execute_reply":"2021-07-05T23:50:45.932789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = cross_validate()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:50:48.548661Z","iopub.execute_input":"2021-07-05T23:50:48.549105Z","iopub.status.idle":"2021-07-05T23:51:04.336849Z","shell.execute_reply.started":"2021-07-05T23:50:48.549076Z","shell.execute_reply":"2021-07-05T23:51:04.336004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Log\n#---------------\n# Original: RMSLE : 0.327137\n# Big (200 n_estimators): 0.327596 -> not actually a whole lot better\n# Subsample 1: 0.327137 (gah)\n# Learning rate = 0.1 : 0.320755\n# Learning rate = 0.05: 0.322487 -> Bah, these gains are all marginal at best\n\n# Gbtree/Gblinear/Dart: 0.320755 / 0.566162 / 0.322403\n\n# W/Feature engineering v1: 0.262034\n# W/Feature engineering w/out log target modifiers: 0.260650","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train final model\nimport xgboost as xgb\nfrom sklearn.multioutput import MultiOutputRegressor \nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\n\"\"\"\nxg_reg = MultiOutputRegressor(xgb.XGBRegressor(objective ='reg:linear', \n            colsample_bytree = 0.8, learning_rate = 0.1, subsample = 1,\n            max_depth = 10, alpha = 10, n_estimators = 100, booster = 'gbtree'))\nxg_reg.fit(X,y)\npreds = xg_reg.predict(X)\nRMSLE = np.sqrt(mean_squared_log_error(y, np.clip(preds, 0.001, None)))\nprint(\"Train loss: \",RMSLE)\n\nfinal_preds = xg_reg.predict(pre_inference(test_csv))\n\"\"\"\n# K-fold ensemble\npreds = []\nfor model in models:\n    preds.append(model.predict(X))\npreds = np.mean(preds,axis=0)\nRMSLE = np.sqrt(mean_squared_log_error(y, np.clip(preds, 0.001, None)))\nprint(\"Train loss: \",RMSLE)\n\npreds = []\nfor model in models:\n    preds.append(model.predict(pre_inference(test_csv)))\nfinal_preds = np.mean(preds,axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:53:45.481499Z","iopub.execute_input":"2021-07-05T23:53:45.483346Z","iopub.status.idle":"2021-07-05T23:53:45.826205Z","shell.execute_reply.started":"2021-07-05T23:53:45.483313Z","shell.execute_reply":"2021-07-05T23:53:45.82543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pd.Series(X.columns).drop([20,17,11,18,20,14,19,16,15])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:38:31.962353Z","iopub.execute_input":"2021-07-05T20:38:31.962738Z","iopub.status.idle":"2021-07-05T20:38:31.971956Z","shell.execute_reply.started":"2021-07-05T20:38:31.962695Z","shell.execute_reply":"2021-07-05T20:38:31.970943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom xgboost import plot_importance\nfor model in xg_reg.estimators_:\n    # plot\n    plot_importance(model)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:38:31.966649Z","iopub.execute_input":"2021-07-05T23:38:31.967198Z","iopub.status.idle":"2021-07-05T23:38:33.373518Z","shell.execute_reply.started":"2021-07-05T23:38:31.967162Z","shell.execute_reply":"2021-07-05T23:38:33.372776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = ['target_carbon_monoxide','target_benzene','target_nitrogen_oxides']\nfor i in range(3): print(targets[i],\"Train:\",y[targets[i]].mean(),\"Test:\",final_preds[:,i].mean())","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:53:54.855782Z","iopub.execute_input":"2021-07-05T23:53:54.856162Z","iopub.status.idle":"2021-07-05T23:53:54.864691Z","shell.execute_reply.started":"2021-07-05T23:53:54.856124Z","shell.execute_reply":"2021-07-05T23:53:54.863537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame(final_preds)\nsubmission_df.insert(0, 'date_time', test_csv['date_time'])\nsubmission_df.columns = ['date_time','target_carbon_monoxide','target_benzene','target_nitrogen_oxides']\nsubmission_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T23:54:02.775849Z","iopub.execute_input":"2021-07-05T23:54:02.776198Z","iopub.status.idle":"2021-07-05T23:54:02.800706Z","shell.execute_reply.started":"2021-07-05T23:54:02.776169Z","shell.execute_reply":"2021-07-05T23:54:02.800023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(INPUT_DIR + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T20:58:59.847526Z","iopub.execute_input":"2021-07-04T20:58:59.847936Z","iopub.status.idle":"2021-07-04T20:58:59.876147Z","shell.execute_reply.started":"2021-07-04T20:58:59.847905Z","shell.execute_reply":"2021-07-04T20:58:59.87477Z"},"trusted":true},"execution_count":null,"outputs":[]}]}