{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<big>For classical machine learning algorithms, we often use the most popular Python library, Scikit-learn. With Scikit-learn you can fit models and search for optimal parameters, but it sometimes works for hours.</big><br><br>\n\n<big>I want to show you how to use Scikit-learn library and get the results faster without changing the code. To do this, we will make use of another Python library, <strong> <a href='https://github.com/intel/scikit-learn-intelex'>Intel® Extension for Scikit-learn*</a></strong>.</big><br><br>\n\n<big>I will show you how to <strong>speed up your kernel more than 3 times</strong> without changing your code!</big><big>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:12:38.304551Z","iopub.execute_input":"2021-07-23T13:12:38.305267Z","iopub.status.idle":"2021-07-23T13:12:39.707433Z","shell.execute_reply.started":"2021-07-23T13:12:38.305222Z","shell.execute_reply":"2021-07-23T13:12:39.705802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Importing data</h2>","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/tabular-playground-series-jul-2021/train.csv', parse_dates=True)\ntest_data = pd.read_csv('../input/tabular-playground-series-jul-2021/test.csv')\nsemp_sub = pd.read_csv('../input/tabular-playground-series-jul-2021/sample_submission.csv')\npseudolabels = pd.read_csv('../input/tps-lightautoml-baseline-with-pseudolabels/lightautoml_with_pseudolabelling_kernel_version_15.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:12:42.279785Z","iopub.execute_input":"2021-07-23T13:12:42.280148Z","iopub.status.idle":"2021-07-23T13:12:42.38159Z","shell.execute_reply.started":"2021-07-23T13:12:42.280117Z","shell.execute_reply":"2021-07-23T13:12:42.380356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['date_time'] = pd.to_datetime(data['date_time'])\ntest_data['date_time'] = pd.to_datetime(test_data['date_time'])","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:12:45.06305Z","iopub.execute_input":"2021-07-23T13:12:45.063532Z","iopub.status.idle":"2021-07-23T13:12:45.087906Z","shell.execute_reply.started":"2021-07-23T13:12:45.063487Z","shell.execute_reply":"2021-07-23T13:12:45.086559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:12:47.31121Z","iopub.execute_input":"2021-07-23T13:12:47.311602Z","iopub.status.idle":"2021-07-23T13:12:47.347767Z","shell.execute_reply.started":"2021-07-23T13:12:47.311569Z","shell.execute_reply":"2021-07-23T13:12:47.346535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Preprocessing</h2>\n\n<big>I added some features based on date</big>","metadata":{}},{"cell_type":"code","source":"def make_new_features(df):\n    df[\"month\"] = df[\"date_time\"].dt.month\n    df[\"day_of_week\"] = df[\"date_time\"].dt.dayofweek\n    df[\"day_of_year\"] = df[\"date_time\"].dt.dayofyear\n    df[\"hour\"] = df[\"date_time\"].dt.hour\n    df[\"quarter\"] = df[\"date_time\"].dt.quarter\n    df[\"week_of_year\"] = df[\"date_time\"].dt.isocalendar().week.astype(\"int\")\n    df[\"working_hours\"] =  df[\"hour\"].isin(np.arange(8, 21, 1)).astype(\"int\")\n    df[\"is_weekend\"] = (data[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:12:49.754545Z","iopub.execute_input":"2021-07-23T13:12:49.755003Z","iopub.status.idle":"2021-07-23T13:12:49.763791Z","shell.execute_reply.started":"2021-07-23T13:12:49.754965Z","shell.execute_reply":"2021-07-23T13:12:49.762197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_new_features(data)\nmake_new_features(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:12:51.653934Z","iopub.execute_input":"2021-07-23T13:12:51.654349Z","iopub.status.idle":"2021-07-23T13:12:51.709681Z","shell.execute_reply.started":"2021-07-23T13:12:51.654314Z","shell.execute_reply":"2021-07-23T13:12:51.708269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big><strong>Pseudodating</strong></big><br><br>\n<big>I took the previously predicted labels and added them to the test dataset.</big>","metadata":{}},{"cell_type":"code","source":"for col in ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']:\n    test_data[col] = pseudolabels[col]","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:12:53.950074Z","iopub.execute_input":"2021-07-23T13:12:53.950536Z","iopub.status.idle":"2021-07-23T13:12:53.959093Z","shell.execute_reply.started":"2021-07-23T13:12:53.9505Z","shell.execute_reply":"2021-07-23T13:12:53.957589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Now let's combine the test and train datasets.</big>","metadata":{}},{"cell_type":"code","source":"full_data = pd.concat([data, test_data]).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:12:56.096087Z","iopub.execute_input":"2021-07-23T13:12:56.096521Z","iopub.status.idle":"2021-07-23T13:12:56.109686Z","shell.execute_reply.started":"2021-07-23T13:12:56.096481Z","shell.execute_reply":"2021-07-23T13:12:56.108292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>I added new feature to the dataset.</big> \n<big>It was obtained by <code>feature_importances_</code>.</big>","metadata":{}},{"cell_type":"code","source":"test_data = test_data.drop(['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides'], axis=1)\nall_data = [full_data, test_data]\n\nfor df in all_data:\n    df['date_time'] = df['date_time'].astype('datetime64[ns]').astype(np.int64)/10**9\ndata = data.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:12:58.05066Z","iopub.execute_input":"2021-07-23T13:12:58.051042Z","iopub.status.idle":"2021-07-23T13:12:58.065332Z","shell.execute_reply.started":"2021-07-23T13:12:58.051011Z","shell.execute_reply":"2021-07-23T13:12:58.064263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Next step is split the data into features and targets.</big>","metadata":{}},{"cell_type":"code","source":"x_data = full_data.drop(['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides'], axis=1)\ny_data = full_data[['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']]\nx_data.shape, y_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:13:00.775337Z","iopub.execute_input":"2021-07-23T13:13:00.776121Z","iopub.status.idle":"2021-07-23T13:13:00.788131Z","shell.execute_reply.started":"2021-07-23T13:13:00.77608Z","shell.execute_reply":"2021-07-23T13:13:00.787049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Now split the data into training and validation sets.</big>","metadata":{}},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:13:02.989397Z","iopub.execute_input":"2021-07-23T13:13:02.990152Z","iopub.status.idle":"2021-07-23T13:13:03.00028Z","shell.execute_reply.started":"2021-07-23T13:13:02.990109Z","shell.execute_reply":"2021-07-23T13:13:02.998998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Installing Intel(R) Extension for Scikit-learn</h2>\n\n<big>Use Intel® Extension for Scikit-learn* for fast compute Scikit-learn estimators.</big>","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn-intelex -q --progress-bar off","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-23T13:13:05.41406Z","iopub.execute_input":"2021-07-23T13:13:05.414572Z","iopub.status.idle":"2021-07-23T13:13:39.553022Z","shell.execute_reply.started":"2021-07-23T13:13:05.41454Z","shell.execute_reply":"2021-07-23T13:13:39.551663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Patch original scikit-learn.</big>","metadata":{}},{"cell_type":"code","source":"from sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:13:39.55507Z","iopub.execute_input":"2021-07-23T13:13:39.555523Z","iopub.status.idle":"2021-07-23T13:13:40.234623Z","shell.execute_reply.started":"2021-07-23T13:13:39.555471Z","shell.execute_reply":"2021-07-23T13:13:40.233547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Using optuna to select parameters for Stacking algorithm</h2><br><br>\n<big>Stacking or generalization is an ensemble of machine learning algorithms.\n\nThis generalization consists of output combination of individual estimators and the final prediction based on it. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.</big><br><br>\n<big>We adjust hyperparameters for the best result.</big><br><br>\n<big>Parameters for Random Forest:</big><br>\n<big>* <code>n_estimators</code> -  The number of trees to be used in the algorithm.<br></big>\n<big>* <code>min_samples_split</code> - The minimum number of samples in a leaf to split.<br><br> </big>\n<big>Parameter for SVR:</big><br>\n<big>* <code>C</code> -  Parameter inverse to the regularization coefficient<br></big><br>\n<big>Parameter for Lasso:</big><br>\n<big>* <code>alpha</code> - Regularization parameter. Regularization improves the solution and reduces the variance of estimates.<br> </big>\n","metadata":{}},{"cell_type":"code","source":"from sklearn.multioutput import RegressorChain\nfrom sklearn.ensemble import RandomForestRegressor, StackingRegressor\nfrom sklearn.metrics import mean_squared_log_error\nimport numpy as np\nimport optuna \nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import Lasso","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:13:58.1284Z","iopub.execute_input":"2021-07-23T13:13:58.129306Z","iopub.status.idle":"2021-07-23T13:13:59.29824Z","shell.execute_reply.started":"2021-07-23T13:13:58.129254Z","shell.execute_reply":"2021-07-23T13:13:59.297467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stacking_regressor( C1=None,\n                            n_estimators=None, min_samples_split=None,\n                            alpha1=None, alpha2=None\n                            ):\n    svr = SVR(C=C1)\n    rf = RandomForestRegressor(n_estimators=n_estimators, min_samples_split=min_samples_split,\n                               random_state=0, n_jobs=-1)\n    lasso = Lasso(alpha=alpha1, random_state=0, max_iter=100000)\n\n    \n    lasso_f = Lasso(alpha=alpha2, random_state=0, max_iter=100000)\n    stacking_estimators = [\n        ('svr', svr),\n        ('rf', rf),\n        ('lasso', lasso),\n    ]\n    \n    return StackingRegressor(estimators=stacking_estimators, final_estimator=lasso_f)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:14:05.047967Z","iopub.execute_input":"2021-07-23T13:14:05.048713Z","iopub.status.idle":"2021-07-23T13:14:05.057056Z","shell.execute_reply.started":"2021-07-23T13:14:05.048664Z","shell.execute_reply":"2021-07-23T13:14:05.055579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    params ={\n        'n_estimators': trial.suggest_int('n_estimators', 1300, 2000),\n        'alpha1': trial.suggest_float('alpha1', 0.0, 0.15),\n        'alpha2': trial.suggest_float('alpha2', 0.0, 0.05),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n        'C1': trial.suggest_loguniform('C1', 1e-3, 1e2),\n    }\n    model = RegressorChain(get_stacking_regressor(**params), random_state=47).fit(x_train, y_train)\n    y_pred = model.predict(x_val)\n    loss = np.sqrt(mean_squared_log_error(y_val, np.abs(y_pred)))\n    return loss\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:14:06.989365Z","iopub.execute_input":"2021-07-23T13:14:06.990541Z","iopub.status.idle":"2021-07-23T13:14:06.998887Z","shell.execute_reply.started":"2021-07-23T13:14:06.990484Z","shell.execute_reply":"2021-07-23T13:14:06.998053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big><strong>Select parameters</strong></big>","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:14:08.952169Z","iopub.execute_input":"2021-07-23T13:14:08.952897Z","iopub.status.idle":"2021-07-23T13:14:08.962856Z","shell.execute_reply.started":"2021-07-23T13:14:08.952849Z","shell.execute_reply":"2021-07-23T13:14:08.961889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Let's see the execution time.</big>","metadata":{}},{"cell_type":"code","source":"%%time\nstudy.optimize(objective, n_trials=10)","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"scrolled":true,"execution":{"iopub.status.busy":"2021-07-23T13:14:15.840546Z","iopub.execute_input":"2021-07-23T13:14:15.841243Z","iopub.status.idle":"2021-07-23T13:45:39.148103Z","shell.execute_reply.started":"2021-07-23T13:14:15.841185Z","shell.execute_reply":"2021-07-23T13:45:39.146797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Training the model with the selected parameters</h2>","metadata":{}},{"cell_type":"code","source":"%%time\nnew_model_rf = RegressorChain(get_stacking_regressor(**study.best_params)).fit(x_data, y_data)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:52:15.39316Z","iopub.execute_input":"2021-07-23T13:52:15.39365Z","iopub.status.idle":"2021-07-23T13:58:58.541259Z","shell.execute_reply.started":"2021-07-23T13:52:15.393593Z","shell.execute_reply":"2021-07-23T13:58:58.540285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Prediction</h2>","metadata":{}},{"cell_type":"code","source":"%%time\ny_pred = new_model_rf.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:59:48.185822Z","iopub.execute_input":"2021-07-23T13:59:48.186211Z","iopub.status.idle":"2021-07-23T13:59:49.645233Z","shell.execute_reply.started":"2021-07-23T13:59:48.18618Z","shell.execute_reply":"2021-07-23T13:59:49.644181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Save the results in 'submission.csv'.</big>","metadata":{}},{"cell_type":"code","source":"semp_sub['target_carbon_monoxide'] = y_pred[:, 0]\nsemp_sub['target_benzene'] = y_pred[:, 1]\nsemp_sub['target_nitrogen_oxides'] = y_pred[:, 2]\nsemp_sub.to_csv('submission.csv', index=False)\nsemp_sub.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:59:52.084416Z","iopub.execute_input":"2021-07-23T13:59:52.084975Z","iopub.status.idle":"2021-07-23T13:59:52.128224Z","shell.execute_reply.started":"2021-07-23T13:59:52.08494Z","shell.execute_reply":"2021-07-23T13:59:52.126741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Now we use the same algorithms with original scikit-learn<h2>","metadata":{}},{"cell_type":"markdown","source":"<big>Let’s run the same code with original scikit-learn and compare its execution time with the execution time of the patched by Intel(R) Extension for Scikit-learn.</big>","metadata":{}},{"cell_type":"code","source":"from sklearnex import unpatch_sklearn\nunpatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:59:56.409477Z","iopub.execute_input":"2021-07-23T13:59:56.410041Z","iopub.status.idle":"2021-07-23T13:59:56.416017Z","shell.execute_reply.started":"2021-07-23T13:59:56.409989Z","shell.execute_reply":"2021-07-23T13:59:56.414576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import Lasso","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:59:59.960243Z","iopub.execute_input":"2021-07-23T13:59:59.960719Z","iopub.status.idle":"2021-07-23T13:59:59.965166Z","shell.execute_reply.started":"2021-07-23T13:59:59.960684Z","shell.execute_reply":"2021-07-23T13:59:59.964326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Select parameters for Stacking algorithm.</big>","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:00:03.165364Z","iopub.execute_input":"2021-07-23T14:00:03.165899Z","iopub.status.idle":"2021-07-23T14:00:03.172656Z","shell.execute_reply.started":"2021-07-23T14:00:03.165867Z","shell.execute_reply":"2021-07-23T14:00:03.171783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Let's see the execution time without patch.</big>","metadata":{}},{"cell_type":"code","source":"%%time\nstudy.optimize(objective, n_trials=10)","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"scrolled":true,"execution":{"iopub.status.busy":"2021-07-23T14:00:09.862777Z","iopub.execute_input":"2021-07-23T14:00:09.863326Z","iopub.status.idle":"2021-07-23T15:42:00.110372Z","shell.execute_reply.started":"2021-07-23T14:00:09.863293Z","shell.execute_reply":"2021-07-23T15:42:00.108157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nnew_model_rf = RegressorChain(get_stacking_regressor(**study.best_params)).fit(x_data, y_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T15:43:13.331926Z","iopub.execute_input":"2021-07-23T15:43:13.332379Z","iopub.status.idle":"2021-07-23T15:58:47.995664Z","shell.execute_reply.started":"2021-07-23T15:43:13.332343Z","shell.execute_reply":"2021-07-23T15:58:47.99439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Conclusions</h2>\n<big>We can see that using only one classical machine learning algorithm may give you a pretty hight accuracy score. We also use well-known libraries Scikit-learn and Optuna, as well as the increasingly popular library Intel® Extension for Scikit-learn. Noted that Intel® Extension for Scikit-learn gives you opportunities to:</big>\n\n* <big>Use your Scikit-learn code for training and inference without modification.</big>\n* <big>Speed up selection of parameters <strong>from 1 hour 41 minutes to 31 minutes.</strong></big>\n* <big>Get predictions of the similar quality.</big>\n","metadata":{}}]}