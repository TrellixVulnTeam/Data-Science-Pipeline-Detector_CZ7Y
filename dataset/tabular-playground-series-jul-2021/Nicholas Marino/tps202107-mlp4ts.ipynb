{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading modules and packages","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# core\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# pre-processing\nfrom sklearn.preprocessing import MinMaxScaler\n\n# modelling\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import ReLU\nfrom tensorflow.keras.optimizers import Adam\n\n# callbacks\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# model evaluation\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.metrics import RootMeanSquaredError\nfrom tensorflow.keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:42.331747Z","iopub.execute_input":"2021-07-20T20:42:42.332115Z","iopub.status.idle":"2021-07-20T20:42:47.726164Z","shell.execute_reply.started":"2021-07-20T20:42:42.332036Z","shell.execute_reply":"2021-07-20T20:42:47.725327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions used in this notebook","metadata":{}},{"cell_type":"code","source":"# function to engineer features using available information from a dataframe df\ndef engineer_features(df):\n    df['dow']  = df.date_time.dt.day_of_week # day of week\n    df['woy']  = df.date_time.dt.isocalendar().week.astype('int') # week of the year\n    df['hod'] = df.date_time.dt.hour # hour of the day\n    df['working_hours'] = df.date_time.dt.hour.isin(np.arange(8, 19)).astype('int') # indicator of whether the record was made during working hours\n    return df\n\n# function to calculate RMSLE loss directly\ndef rmsle_(y_true, y_pred):\n    msle = tf.keras.losses.MeanSquaredLogarithmicError()\n    return K.sqrt(msle(y_true, y_pred)) ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:47.727621Z","iopub.execute_input":"2021-07-20T20:42:47.727952Z","iopub.status.idle":"2021-07-20T20:42:47.733266Z","shell.execute_reply.started":"2021-07-20T20:42:47.727916Z","shell.execute_reply":"2021-07-20T20:42:47.732495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data","metadata":{}},{"cell_type":"code","source":"train       = pd.read_csv(filepath_or_buffer = '../input/tabular-playground-series-jul-2021/train.csv', parse_dates = ['date_time'])\ntest        = pd.read_csv(filepath_or_buffer = '../input/tabular-playground-series-jul-2021/test.csv', parse_dates = ['date_time'])\nsubmission  = pd.read_csv(filepath_or_buffer = '../input/tabular-playground-series-jul-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:47.73504Z","iopub.execute_input":"2021-07-20T20:42:47.73555Z","iopub.status.idle":"2021-07-20T20:42:47.807214Z","shell.execute_reply.started":"2021-07-20T20:42:47.735496Z","shell.execute_reply":"2021-07-20T20:42:47.806481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"code","source":"# adding engineered features to their respective dataframes\ntrain = engineer_features(train)\ntest  = engineer_features(test)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:47.80911Z","iopub.execute_input":"2021-07-20T20:42:47.809356Z","iopub.status.idle":"2021-07-20T20:42:47.835881Z","shell.execute_reply.started":"2021-07-20T20:42:47.809332Z","shell.execute_reply":"2021-07-20T20:42:47.835162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the target column names\ntarget_columns = [column for column in train.columns if column.startswith('target_')]\n\n# getting the feature column names\nfeature_columns = [column for column in train.columns if column not in ['date_time'] + target_columns]","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:47.838371Z","iopub.execute_input":"2021-07-20T20:42:47.838614Z","iopub.status.idle":"2021-07-20T20:42:47.844802Z","shell.execute_reply.started":"2021-07-20T20:42:47.838591Z","shell.execute_reply":"2021-07-20T20:42:47.843978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlations","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize=(25, 8)) \nsns.heatmap(train.drop(columns = ['date_time']).corr(), cmap = 'RdBu', ax = ax1)\nsns.heatmap(test.drop(columns = ['date_time']).corr(), cmap = 'RdBu', ax = ax2)\nax1.set_title('Correlations on the training set', fontdict = {'size': 14, 'fontweight': 'bold'})\nax2.set_title('Correlations on the test set', fontdict = {'size': 14, 'fontweight': 'bold'})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:47.846537Z","iopub.execute_input":"2021-07-20T20:42:47.846871Z","iopub.status.idle":"2021-07-20T20:42:48.724816Z","shell.execute_reply.started":"2021-07-20T20:42:47.846839Z","shell.execute_reply":"2021-07-20T20:42:48.724002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"markdown","source":"## For the simplest form of the MLP - MLP #1","metadata":{}},{"cell_type":"code","source":"# copying the original dataframe\ndf_mlp_1 = train.copy()\n\n# splitting the targets from the features\nX_mlp_1, y_mlp_1 = df_mlp_1[feature_columns], df_mlp_1[target_columns]\n\n# getting the index of the sensor data and the other features\nsensor_index = [column_index for column_index, column_name in enumerate(X_mlp_1.columns) if column_name.startswith('sensor')]\nother_index = [column_index for column_index in range(X_mlp_1.shape[1]) if column_index not in sensor_index]\n\n# log transforming the target columns\ny_mlp_1 = np.log1p(y_mlp_1)\n\n# instantiating the input scaler\nscaler = MinMaxScaler()\n\n# training the scaler\nscaler.fit(X_mlp_1)\n\n# applying the scaler to the data\nX_mlp_1 = scaler.transform(X_mlp_1)\nX_test  = scaler.transform(test[feature_columns])","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:48.726007Z","iopub.execute_input":"2021-07-20T20:42:48.726515Z","iopub.status.idle":"2021-07-20T20:42:48.74881Z","shell.execute_reply.started":"2021-07-20T20:42:48.726458Z","shell.execute_reply":"2021-07-20T20:42:48.74796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For the multi-output MLP - MLP #2","metadata":{}},{"cell_type":"code","source":"# copying the dataframe from mlp_1 dataframe\nX_mlp_2 = X_mlp_1.copy()\n\n## separating each of the targets\ny_CO, y_BE, y_NO = y_mlp_1.target_carbon_monoxide, y_mlp_1.target_benzene, y_mlp_1.target_nitrogen_oxides","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:48.751905Z","iopub.execute_input":"2021-07-20T20:42:48.752264Z","iopub.status.idle":"2021-07-20T20:42:48.757305Z","shell.execute_reply.started":"2021-07-20T20:42:48.752233Z","shell.execute_reply":"2021-07-20T20:42:48.756354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For the multi-feature-input single-output MLP - MLP #3","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:01:26.093942Z","iopub.execute_input":"2021-07-15T13:01:26.094399Z","iopub.status.idle":"2021-07-15T13:01:26.099083Z","shell.execute_reply.started":"2021-07-15T13:01:26.094362Z","shell.execute_reply":"2021-07-15T13:01:26.097977Z"}}},{"cell_type":"code","source":"# copying the dataframe from mlp_1 dataframe\nX_mlp_3 = X_mlp_1.copy()\n\n# getting the indexes for the sensor data\nX_mlp_3_sensor, X_mlp_3_others = X_mlp_3[:, sensor_index], X_mlp_3[:, other_index]","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:48.7596Z","iopub.execute_input":"2021-07-20T20:42:48.760182Z","iopub.status.idle":"2021-07-20T20:42:48.76726Z","shell.execute_reply.started":"2021-07-20T20:42:48.76014Z","shell.execute_reply":"2021-07-20T20:42:48.766354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For multi-input (autoregressive targets + features) and multi-output MLP - MLP #4","metadata":{}},{"cell_type":"code","source":"## function to split each of the individual sequences for the autoregressive mlp\ndef split_sequences_mlp_4(sequence, n_lagged_inputs):\n    # creating empty lists to store the lagged inputs and the target output\n    lagged_inputs, target_output = list(), list()\n    # looping over the sequence\n    for observation in range(len(sequence)):\n        # defining the last index of this loop step\n        last_idx = observation + n_lagged_inputs\n        # breaking the loop if the index is beyond the number of observations\n        if last_idx > len(sequence) - 1:\n            break\n        # extracting the inputs and output for this loop step\n        inputs, output = sequence[observation:last_idx], sequence[last_idx]\n        # appending the input and output sequences\n        lagged_inputs.append(inputs), target_output.append(output)\n    # returning the inputs and outputs\n    return np.array(lagged_inputs), np.array(target_output)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:48.768537Z","iopub.execute_input":"2021-07-20T20:42:48.76904Z","iopub.status.idle":"2021-07-20T20:42:48.775984Z","shell.execute_reply.started":"2021-07-20T20:42:48.769004Z","shell.execute_reply":"2021-07-20T20:42:48.775181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## extracting the splitted sequences for each of the response variables\nn_ar_inputs = 6\nX_ar_CO_mlp_4, y_ar_CO_mlp_4 = split_sequences_mlp_4(sequence = y_CO, n_lagged_inputs = n_ar_inputs)\nX_ar_BE_mlp_4, y_ar_BE_mlp_4 = split_sequences_mlp_4(sequence = y_BE, n_lagged_inputs = n_ar_inputs)\nX_ar_NO_mlp_4, y_ar_NO_mlp_4 = split_sequences_mlp_4(sequence = y_NO, n_lagged_inputs = n_ar_inputs)\n\n## copying the original data\nX_mlp_4_sensor, X_mlp_4_others = X_mlp_3_sensor.copy(), X_mlp_3_others.copy()\n\n## removing the first 6 rows of data, since these were used to create the autoregressive features\nX_mlp_4_sensor, X_mlp_4_others = X_mlp_4_sensor[n_ar_inputs:, :], X_mlp_4_others[n_ar_inputs:, :]","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:48.777229Z","iopub.execute_input":"2021-07-20T20:42:48.777757Z","iopub.status.idle":"2021-07-20T20:42:51.392838Z","shell.execute_reply.started":"2021-07-20T20:42:48.777719Z","shell.execute_reply":"2021-07-20T20:42:51.391743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For multi-input (autoregressive targets + features) and single output MLP - MLP #5","metadata":{}},{"cell_type":"code","source":"## merging all target in a single \ny_ar_mlp_5 = np.column_stack([y_ar_CO_mlp_4, y_ar_BE_mlp_4, y_ar_NO_mlp_4])","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:51.394266Z","iopub.execute_input":"2021-07-20T20:42:51.394867Z","iopub.status.idle":"2021-07-20T20:42:51.400032Z","shell.execute_reply.started":"2021-07-20T20:42:51.3948Z","shell.execute_reply":"2021-07-20T20:42:51.399153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multi-input (AR targets 6hrs+ AR temperature 12hrs + AR relative humidity 12hrs) and single output MLP - MLP #6","metadata":{}},{"cell_type":"code","source":"## function to split each of the individual sequences for the autoregressive mlp\ndef split_feature_sequences(sequence, n_lagged_inputs):\n    # creating empty lists to store the lagged inputs and the target output\n    lagged_inputs = list()\n    # looping over the sequence\n    for observation in range(len(sequence)):\n        # defining the last index of this loop step\n        last_idx = observation + n_lagged_inputs\n        # breaking the loop if the index is beyond the number of observations\n        if last_idx > len(sequence):\n            break\n        # extracting the inputs and output for this loop step\n        inputs = sequence[observation:last_idx]\n        # appending the input and output sequences\n        lagged_inputs.append(inputs)\n    # returning the inputs and outputs\n    return np.array(lagged_inputs)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:51.401673Z","iopub.execute_input":"2021-07-20T20:42:51.402252Z","iopub.status.idle":"2021-07-20T20:42:51.411086Z","shell.execute_reply.started":"2021-07-20T20:42:51.402213Z","shell.execute_reply":"2021-07-20T20:42:51.410227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## getting the temperature and relative humidity data\nX_temp_mlp_6, X_rl_mlp_6 = X_mlp_1[:, 0], X_mlp_1[:, 1]\n\n## creating the lagged inputs for temperatura and relative humidity data\nn_ar_mlp_6 = 12\nX_temp_mlp_6 = split_feature_sequences(sequence = X_temp_mlp_6, n_lagged_inputs = n_ar_mlp_6)\nX_rl_mlp_6   = split_feature_sequences(sequence = X_rl_mlp_6, n_lagged_inputs = n_ar_mlp_6)\n\n## removing the data for the n_ar_mlp_6 observations from the sensor data\nX_mlp_6_sensor = X_mlp_3_sensor.copy()\nX_mlp_6_sensor = X_mlp_6_sensor[n_ar_mlp_6 - 1:, :]\n\n## removing the first 6 elements of the autoregressive input objects\nX_ar_CO_mlp_6, X_ar_BE_mlp_6, X_ar_NO_mlp_6 = X_ar_CO_mlp_4.copy(), X_ar_BE_mlp_4.copy(), X_ar_NO_mlp_4.copy()\nX_ar_CO_mlp_6, X_ar_BE_mlp_6, X_ar_NO_mlp_6 = X_ar_CO_mlp_6[5:, :], X_ar_BE_mlp_6[5:, :], X_ar_NO_mlp_6[5:, :]\n\n## removing the first 6 elements from the target frame so that they are all aligned\ny_ar_mlp_6 = y_ar_mlp_5.copy()\ny_ar_mlp_6 = y_ar_mlp_6[5:, :]","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:51.412377Z","iopub.execute_input":"2021-07-20T20:42:51.412817Z","iopub.status.idle":"2021-07-20T20:42:51.447454Z","shell.execute_reply.started":"2021-07-20T20:42:51.412782Z","shell.execute_reply":"2021-07-20T20:42:51.446614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating the test set autoregressive features\n## seeding the initial list\ntest_ar_TEMP, test_ar_RL = X_mlp_1[-12:-1, 0].tolist(), X_mlp_1[-12:-1, 1].tolist()\n\n## adding the rest of the time series\ntest_ar_TEMP, test_ar_RL = test_ar_TEMP + X_test[:, 0].tolist(), test_ar_RL + X_test[:, 1].tolist()\n\n## creating the lagged feature sequences on the test set\ntest_ar_TEMP = split_feature_sequences(sequence = test_ar_TEMP, n_lagged_inputs = n_ar_mlp_6)\ntest_ar_RL   = split_feature_sequences(sequence = test_ar_RL, n_lagged_inputs = n_ar_mlp_6)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:51.448713Z","iopub.execute_input":"2021-07-20T20:42:51.449086Z","iopub.status.idle":"2021-07-20T20:42:51.470928Z","shell.execute_reply.started":"2021-07-20T20:42:51.44905Z","shell.execute_reply":"2021-07-20T20:42:51.469919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multi-input (AR targets 12hrs+ AR temperature 12hrs + AR relative humidity 12hrs) and single output MLP - MLP #7","metadata":{}},{"cell_type":"code","source":"## extracting the splitted sequences for each of the response variables\nn_ar_inputs_mlp_7 = 25\nX_ar_CO_mlp_7, y_ar_CO_mlp_7 = split_sequences_mlp_4(sequence = y_CO, n_lagged_inputs = n_ar_inputs_mlp_7)\nX_ar_BE_mlp_7, y_ar_BE_mlp_7 = split_sequences_mlp_4(sequence = y_BE, n_lagged_inputs = n_ar_inputs_mlp_7)\nX_ar_NO_mlp_7, y_ar_NO_mlp_7 = split_sequences_mlp_4(sequence = y_NO, n_lagged_inputs = n_ar_inputs_mlp_7)\n\n## merging the targets in a single array\ny_ar_mlp_7 = np.column_stack([y_ar_CO_mlp_7, y_ar_BE_mlp_7, y_ar_NO_mlp_7])\n\n## removing the data for the n_ar_inputs_mlp_7 observations from the sensor data\nX_mlp_7_sensor = X_mlp_3_sensor.copy()\nX_mlp_7_sensor = X_mlp_7_sensor[n_ar_inputs_mlp_7:, :]\n\n## removing the first instance as it gets the historical data from t0 to t12, and we needed it from t1 to t13\nX_temp_mlp_7 = X_temp_mlp_6.copy()\nX_temp_mlp_7 = X_temp_mlp_7[14:, :]\n\n## removing the first instance as it gets the historical data from t0 to t12, and we needed it from t1 to t13\nX_rl_mlp_7 = X_rl_mlp_6.copy()\nX_rl_mlp_7 = X_rl_mlp_7[14:, :]","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:51.472133Z","iopub.execute_input":"2021-07-20T20:42:51.472754Z","iopub.status.idle":"2021-07-20T20:42:53.545077Z","shell.execute_reply.started":"2021-07-20T20:42:51.472718Z","shell.execute_reply":"2021-07-20T20:42:53.544082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"markdown","source":"## MLP #1 - Simple MLP","metadata":{}},{"cell_type":"code","source":"## creating the layers\n# input layer\ninput_layer = Input(shape = (X_mlp_1.shape[1], ))\n# hidden layers\nhidden_layer = Dense(units = 32, activation = 'relu')(input_layer)\nhidden_layer = Dropout(0.2)(hidden_layer)\nhidden_layer = Dense(units = 32, activation = 'relu')(hidden_layer)\n# output layers\noutput_layer = Dense(units = 3)(hidden_layer)\n\n## creating the model\nmodel = Model(inputs = input_layer, outputs = output_layer)\n\n# compilling the model\nmodel.compile(optimizer = Adam(learning_rate = 0.001), loss = 'mse', metrics = [RootMeanSquaredError()])\n\n# instantiating the early stopping callback\nes = EarlyStopping(monitor = 'val_root_mean_squared_error', patience = 20, min_delta = 0.01, restore_best_weights = True)\n\n# instantiating the learning rate scheduller\nlrs = ReduceLROnPlateau(monitor = 'val_root_mean_squared_error', factor = 0.2, patience = 5)\n\n# fitting the model\nhistory = model.fit(x = X_mlp_1, y = y_mlp_1, validation_split = 0.3, batch_size = 16, epochs = 100, callbacks = [es, lrs])\n\n# training history\nplt.figure(figsize = (10, 6))\nplt.plot(history.history['loss'], label = 'training')\nplt.plot(history.history['val_root_mean_squared_error'], label = 'validation')\nplt.title(label = 'Training over epochs', fontdict = {'size': 14, 'fontweight': 'bold'})\nplt.ylabel(ylabel = 'RMSE', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.xlabel(xlabel = 'Epochs', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.legend(fontsize = 12)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:42:53.546591Z","iopub.execute_input":"2021-07-20T20:42:53.546985Z","iopub.status.idle":"2021-07-20T20:43:21.453126Z","shell.execute_reply.started":"2021-07-20T20:42:53.546941Z","shell.execute_reply":"2021-07-20T20:43:21.452368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## visualizing the model\nplot_model(model, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:43:21.454335Z","iopub.execute_input":"2021-07-20T20:43:21.454658Z","iopub.status.idle":"2021-07-20T20:43:21.854603Z","shell.execute_reply.started":"2021-07-20T20:43:21.454624Z","shell.execute_reply":"2021-07-20T20:43:21.853697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## extracting the predictions on the test set\ntest_preds = model.predict(X_test)\n\n## putting the test predictions back on the original scale\ntest_preds = np.expm1(test_preds)\n\n## copying the submission df\nsubmission_mlp_1 = submission.copy()\n\n## putting the predictions on the submission dataset\nsubmission_mlp_1[target_columns] = test_preds","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:43:21.856117Z","iopub.execute_input":"2021-07-20T20:43:21.8565Z","iopub.status.idle":"2021-07-20T20:43:22.019558Z","shell.execute_reply.started":"2021-07-20T20:43:21.856459Z","shell.execute_reply":"2021-07-20T20:43:22.018735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## predictions\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(range(train.shape[0]), train[target], label = 'Train')\n    plt.plot(range(train.shape[0], train.shape[0] + test.shape[0]), submission_mlp_1[target], label = 'Test')\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Value', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.legend()\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:43:22.020869Z","iopub.execute_input":"2021-07-20T20:43:22.021209Z","iopub.status.idle":"2021-07-20T20:43:22.716246Z","shell.execute_reply.started":"2021-07-20T20:43:22.021172Z","shell.execute_reply":"2021-07-20T20:43:22.715397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## getting the predictions of the model\nmlp_1_predictions = model.predict(X_mlp_1)\n\n## putting the predictions in a dataframe\nmlp_1_predictions = pd.DataFrame(data = mlp_1_predictions, columns = target_columns)\n\n## residuals over time\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(y_mlp_1.loc[:, target] - mlp_1_predictions.loc[:, target])\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Residuals', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()\n\n# distribution of residuals\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.hist(y_mlp_1.loc[:, target] - mlp_1_predictions.loc[:, target], bins = 50)\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Residuals', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Frequency', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:43:22.717374Z","iopub.execute_input":"2021-07-20T20:43:22.717731Z","iopub.status.idle":"2021-07-20T20:43:24.962914Z","shell.execute_reply.started":"2021-07-20T20:43:22.717694Z","shell.execute_reply":"2021-07-20T20:43:24.962109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP #2 - Multi-output MLP","metadata":{}},{"cell_type":"code","source":"## creating the layers\n# input layer\ninput_layer = Input(shape = (X_mlp_2.shape[1],))\n# hidden layers\nhidden_layer = Dense(units = 16, activation = 'relu')(input_layer)\nhidden_layer = Dense(units = 32, activation = 'relu')(hidden_layer)\n# output layers\noutput_CO = Dense(units = 1, name = 'out_CO')(hidden_layer)\noutput_BE = Dense(units = 1, name = 'out_BE')(hidden_layer)\noutput_NO = Dense(units = 1, name = 'out_NO')(hidden_layer)\n\n## creating the model\nmlp_2 = Model(inputs = input_layer, outputs = [output_CO, output_BE, output_NO])\n\n# compilling the model\nmlp_2.compile(optimizer = Adam(learning_rate = 0.001), loss = 'mse', metrics = [RootMeanSquaredError()])\n\n# instantiating the early stopping callback\nes = EarlyStopping(monitor = 'val_loss', patience = 20, min_delta = 0.01, restore_best_weights = True)\n\n# instantiating the learning rate scheduller\nlrs = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 5)\n\n# fitting the model\nhistory = mlp_2.fit(x = X_mlp_2, y = [y_CO, y_BE, y_NO], validation_split = 0.3, batch_size = 8, epochs = 400, callbacks = [es, lrs])\n\n# training history\nplt.figure(figsize = (10, 6))\nplt.plot(history.history['loss'], label = 'training')\nplt.plot(history.history['val_loss'], label = 'validation')\nplt.title(label = 'Training over epochs', fontdict = {'size': 14, 'fontweight': 'bold'})\nplt.ylabel(ylabel = 'MSE', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.xlabel(xlabel = 'Epochs', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.legend(fontsize = 12)\nplt.tight_layout()\nplt.show()\n\n# training history for the targets\nplt.figure(figsize = (10, 6))\nplt.plot(history.history['val_out_CO_root_mean_squared_error'], label = 'CO')\nplt.plot(history.history['val_out_BE_root_mean_squared_error'], label = 'Benzene')\nplt.plot(history.history['val_out_NO_root_mean_squared_error'], label = 'NO')\nplt.title(label = 'Training over epochs', fontdict = {'size': 14, 'fontweight': 'bold'})\nplt.ylabel(ylabel = 'RMSE', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.xlabel(xlabel = 'Epochs', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.legend(fontsize = 12)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:43:24.964287Z","iopub.execute_input":"2021-07-20T20:43:24.96463Z","iopub.status.idle":"2021-07-20T20:45:42.413387Z","shell.execute_reply.started":"2021-07-20T20:43:24.964593Z","shell.execute_reply":"2021-07-20T20:45:42.412564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## visualizing the model\nplot_model(mlp_2, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:45:42.41763Z","iopub.execute_input":"2021-07-20T20:45:42.41789Z","iopub.status.idle":"2021-07-20T20:45:42.554983Z","shell.execute_reply.started":"2021-07-20T20:45:42.417865Z","shell.execute_reply":"2021-07-20T20:45:42.55409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## extracting the predictions on the test set\ntest_preds = mlp_2.predict(X_test)\n\n## reshaping the predictions\ntest_preds = np.column_stack(test_preds)\n\n## putting the test predictions back on the original scale\ntest_preds = np.expm1(test_preds)\n\n## copying the submission df\nsubmission_mlp_2 = submission.copy()\n\n## putting the predictions on the submission dataset\nsubmission_mlp_2[target_columns] = test_preds","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:45:42.557988Z","iopub.execute_input":"2021-07-20T20:45:42.558263Z","iopub.status.idle":"2021-07-20T20:45:42.698409Z","shell.execute_reply.started":"2021-07-20T20:45:42.558236Z","shell.execute_reply":"2021-07-20T20:45:42.697542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## predictions\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(range(train.shape[0]), train[target], label = 'Train')\n    plt.plot(range(train.shape[0], train.shape[0] + test.shape[0]), submission_mlp_2[target], label = 'Test')\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Value', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.legend()\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:45:42.699856Z","iopub.execute_input":"2021-07-20T20:45:42.700203Z","iopub.status.idle":"2021-07-20T20:45:43.367929Z","shell.execute_reply.started":"2021-07-20T20:45:42.700166Z","shell.execute_reply":"2021-07-20T20:45:43.367114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## getting the predictions of the model\nmlp_2_predictions = mlp_2.predict(X_mlp_2)\n\n## reshaping the predictions\nmlp_2_predictions = np.column_stack(mlp_2_predictions)\n\n## putting the predictions in a dataframe\nmlp_2_predictions = pd.DataFrame(data = mlp_2_predictions, columns = target_columns)\n\n## getting the observed values\nobserved_values = pd.DataFrame(data = np.column_stack([y_CO, y_BE, y_NO]), columns = target_columns)\n\n## residuals over time\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(observed_values.loc[:, target] - mlp_2_predictions.loc[:, target])\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Residuals', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()\n\n# distribution of residuals\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.hist(observed_values.loc[:, target] - mlp_2_predictions.loc[:, target], bins = 50)\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Residuals', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Frequency', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:45:43.369121Z","iopub.execute_input":"2021-07-20T20:45:43.369433Z","iopub.status.idle":"2021-07-20T20:45:45.022231Z","shell.execute_reply.started":"2021-07-20T20:45:43.369406Z","shell.execute_reply":"2021-07-20T20:45:45.021401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP #3 - Multi-input MLP","metadata":{}},{"cell_type":"code","source":"### creating the layers\n## SENSOR DATA\n# input layer\ninput_layer_1 = Input(shape = (X_mlp_3_sensor.shape[1], ))\n# hidden layers\nhidden_layer_1 = Dense(units = 32, activation = 'relu')(input_layer_1)\nhidden_layer_1 = BatchNormalization()(hidden_layer_1)\nhidden_layer_1 = Dense(units = 16, activation = 'relu')(hidden_layer_1)\n\n## OTHER FEATURES\n# input layer\ninput_layer_2 = Input(shape = (X_mlp_3_others.shape[1], ))\n# hidden layers\nhidden_layer_2 = Dense(units = 32, activation = 'relu')(input_layer_2)\n\n## MERGING THE TWO INPUTS\nmerge_layer = Concatenate()([hidden_layer_1, hidden_layer_2])\n## one more layer\nhidden_layer = Dense(units = 32, activation = 'relu')(merge_layer)\nhidden_layer = Dropout(0.1)(hidden_layer)\n# output layers\noutput_layer = Dense(units = 3)(hidden_layer)\n\n## creating the model\nmlp_3 = Model(inputs = [input_layer_1, input_layer_2], outputs = output_layer)\n\n# compilling the model\nmlp_3.compile(optimizer = Adam(learning_rate = 0.0005), loss = 'mse', metrics = [RootMeanSquaredError()])\n\n# instantiating the early stopping callback\nes = EarlyStopping(monitor = 'val_root_mean_squared_error', patience = 20, min_delta = 0.002, restore_best_weights = True)\n\n# instantiating the learning rate scheduller\nlrs = ReduceLROnPlateau(monitor = 'val_root_mean_squared_error', factor = 0.2, patience = 5)\n\n# fitting the model\nhistory = mlp_3.fit(x = [X_mlp_3_sensor, X_mlp_3_others], y = y_mlp_1, validation_split = 0.3, batch_size = 16, epochs = 100, callbacks = [es, lrs])\n\n# training history\nplt.figure(figsize = (10, 6))\nplt.plot(history.history['loss'], label = 'training')\nplt.plot(history.history['val_root_mean_squared_error'], label = 'validation')\nplt.title(label = 'Training over epochs', fontdict = {'size': 14, 'fontweight': 'bold'})\nplt.ylabel(ylabel = 'RMSE', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.xlabel(xlabel = 'Epochs', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.legend(fontsize = 12)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:45:45.023459Z","iopub.execute_input":"2021-07-20T20:45:45.023935Z","iopub.status.idle":"2021-07-20T20:46:18.778781Z","shell.execute_reply.started":"2021-07-20T20:45:45.023897Z","shell.execute_reply":"2021-07-20T20:46:18.77799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## visualizing the model\nplot_model(mlp_3, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:46:18.780041Z","iopub.execute_input":"2021-07-20T20:46:18.780383Z","iopub.status.idle":"2021-07-20T20:46:19.223154Z","shell.execute_reply.started":"2021-07-20T20:46:18.780348Z","shell.execute_reply":"2021-07-20T20:46:19.222308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## extracting the predictions on the test set\ntest_preds = mlp_3.predict([X_test[:, sensor_index], X_test[:, other_index]])\n\n## putting the test predictions back on the original scale\ntest_preds = np.expm1(test_preds)\n\n## copying the submission df\nsubmission_mlp_3 = submission.copy()\n\n## putting the predictions on the submission dataset\nsubmission_mlp_3[target_columns] = test_preds","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:46:19.224697Z","iopub.execute_input":"2021-07-20T20:46:19.224967Z","iopub.status.idle":"2021-07-20T20:46:19.391499Z","shell.execute_reply.started":"2021-07-20T20:46:19.224939Z","shell.execute_reply":"2021-07-20T20:46:19.39067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## predictions\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(range(train.shape[0]), train[target], label = 'Train')\n    plt.plot(range(train.shape[0], train.shape[0] + test.shape[0]), submission_mlp_3[target], label = 'Test')\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Value', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.legend()\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:46:19.392808Z","iopub.execute_input":"2021-07-20T20:46:19.393144Z","iopub.status.idle":"2021-07-20T20:46:20.045996Z","shell.execute_reply.started":"2021-07-20T20:46:19.393109Z","shell.execute_reply":"2021-07-20T20:46:20.045199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## getting the predictions of the model\nmlp_3_predictions = mlp_3.predict([X_mlp_3_sensor, X_mlp_3_others])\n\n## putting the predictions in a dataframe\nmlp_3_predictions = pd.DataFrame(data = mlp_3_predictions, columns = target_columns)\n\n## residuals over time\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(y_mlp_1.loc[:, target] - mlp_3_predictions.loc[:, target])\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Residuals', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()\n\n# distribution of residuals\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.hist(y_mlp_1.loc[:, target] - mlp_3_predictions.loc[:, target], bins = 50)\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Residuals', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Frequency', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:46:20.047369Z","iopub.execute_input":"2021-07-20T20:46:20.047735Z","iopub.status.idle":"2021-07-20T20:46:21.739076Z","shell.execute_reply.started":"2021-07-20T20:46:20.047698Z","shell.execute_reply":"2021-07-20T20:46:21.738306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP #4 - Multi-input-output autoregressive MLP ","metadata":{}},{"cell_type":"code","source":"### creating the layers\n## SENSOR DATA\n# input layer\ninput_layer_1 = Input(shape = (X_mlp_4_sensor.shape[1], ))\n# hidden layers\nhidden_layer_1 = Dense(units = 32, activation = 'relu')(input_layer_1)\nhidden_layer_1 = BatchNormalization()(hidden_layer_1)\nhidden_layer_1 = Dense(units = 16, activation = 'relu')(hidden_layer_1)\n\n## OTHER FEATURES\n# input layer\ninput_layer_2 = Input(shape = (X_mlp_4_others.shape[1], ))\n# hidden layers\nhidden_layer_2 = Dense(units = 32, activation = 'relu')(input_layer_2)\n\n## AUTOREGRESSIVE CO\n# input layer\ninput_layer_CO = Input(shape = (X_ar_CO_mlp_4.shape[1], ))\n# hidden layers\nhidden_layer_CO = Dense(units = 32, activation = 'relu')(input_layer_CO)\n\n## AUTOREGRESSIVE BE\n# input layer\ninput_layer_BE = Input(shape = (X_ar_BE_mlp_4.shape[1], ))\n# hidden layers\nhidden_layer_BE = Dense(units = 32, activation = 'relu')(input_layer_BE)\n\n## AUTOREGRESSIVE NO\n# input layer\ninput_layer_NO = Input(shape = (X_ar_NO_mlp_4.shape[1], ))\n# hidden layers\nhidden_layer_NO = Dense(units = 32, activation = 'relu')(input_layer_NO)\n\n## MERGING THE TWO INPUTS\nmerge_layer = Concatenate()([hidden_layer_1, hidden_layer_2, hidden_layer_CO, hidden_layer_BE, hidden_layer_NO])\n## one more layer\nhidden_layer = Dense(units = 32, activation = 'relu')(merge_layer)\nhidden_layer = Dropout(0.1)(hidden_layer)\n# output layers\n# output layers\noutput_CO = Dense(units = 1, name = 'out_CO')(hidden_layer)\noutput_BE = Dense(units = 1, name = 'out_BE')(hidden_layer)\noutput_NO = Dense(units = 1, name = 'out_NO')(hidden_layer)\n\n## creating the model\nmlp_4 = Model(inputs = [input_layer_1, input_layer_2, input_layer_CO, input_layer_BE, input_layer_NO], outputs = [output_CO, output_BE, output_NO])\n\n# compilling the model\nmlp_4.compile(optimizer = Adam(learning_rate = 0.0005), loss = 'mse', metrics = [RootMeanSquaredError()])\n\n# instantiating the early stopping callback\nes = EarlyStopping(monitor = 'val_loss', patience = 20, min_delta = 0.002, restore_best_weights = True)\n\n# instantiating the learning rate scheduller\nlrs = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 5)\n\n# fitting the model\nhistory = mlp_4.fit(x = [X_mlp_4_sensor, X_mlp_4_others, X_ar_CO_mlp_4, X_ar_BE_mlp_4, X_ar_NO_mlp_4], \n                    y = [y_ar_CO_mlp_4, y_ar_BE_mlp_4, y_ar_NO_mlp_4], \n                    validation_split = 0.3, batch_size = 8, epochs = 100, callbacks = [es, lrs])\n\n# training history\nplt.figure(figsize = (10, 6))\nplt.plot(history.history['loss'], label = 'training')\nplt.plot(history.history['val_loss'], label = 'validation')\nplt.title(label = 'Training over epochs', fontdict = {'size': 14, 'fontweight': 'bold'})\nplt.ylabel(ylabel = 'RMSE', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.xlabel(xlabel = 'Epochs', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.legend(fontsize = 12)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:46:21.740382Z","iopub.execute_input":"2021-07-20T20:46:21.740723Z","iopub.status.idle":"2021-07-20T20:49:26.34017Z","shell.execute_reply.started":"2021-07-20T20:46:21.740688Z","shell.execute_reply":"2021-07-20T20:49:26.339387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## visualizing the model\nplot_model(mlp_4, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:49:26.341488Z","iopub.execute_input":"2021-07-20T20:49:26.341827Z","iopub.status.idle":"2021-07-20T20:49:26.565697Z","shell.execute_reply.started":"2021-07-20T20:49:26.341792Z","shell.execute_reply":"2021-07-20T20:49:26.564824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## seeding the model prediction with the last six observations in the train set\ntest_seed_CO, test_seed_BE, test_seed_NO = y_CO[-7:-1].tolist(), y_BE[-7:-1].tolist(), y_NO[-7:-1].tolist()\n\n## looping over each of the rows of the test set and generating the predictions\nfor instance in range(X_test.shape[0]):\n    ## parsing the values to a numpy array\n    test_ar_CO, test_ar_BE, test_ar_NO = np.array(test_seed_CO[-6:]), np.array(test_seed_BE[-6:]), np.array(test_seed_NO[-6:])\n\n    ## extracting the predictions on the test set\n    test_preds = mlp_4.predict([\n        X_test[instance, sensor_index].reshape(1, 5),\n        X_test[instance, other_index].reshape(1, 7),\n        test_ar_CO.reshape(1, n_ar_inputs),\n        test_ar_BE.reshape(1, n_ar_inputs),\n        test_ar_NO.reshape(1, n_ar_inputs)\n    ]\n    )\n    \n    ## reshaping the predictions\n    test_preds = np.reshape(test_preds, (-1, ))\n    \n    ## adding the predictions back to the original lists\n    test_seed_CO.append(test_preds[0]), test_seed_BE.append(test_preds[1]), test_seed_NO.append(test_preds[2])\n    \n    ## printing the progress\n    if instance % 200 == 0:\n        print(f'Calculating the predictions for the time step {instance}.')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:49:26.567299Z","iopub.execute_input":"2021-07-20T20:49:26.567649Z","iopub.status.idle":"2021-07-20T20:51:06.289793Z","shell.execute_reply.started":"2021-07-20T20:49:26.567612Z","shell.execute_reply":"2021-07-20T20:51:06.2888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## stacking the predictions side by side\ntest_preds = np.column_stack([test_seed_CO, test_seed_BE, test_seed_NO])\n\n## removing the first six observation since they come from the train set\ntest_preds = test_preds[6:, :]\n\n## putting the test predictions back on the original scale\ntest_preds = np.expm1(test_preds)\n\n## copying the submission df\nsubmission_mlp_4 = submission.copy()\n\n## putting the predictions on the submission dataset\nsubmission_mlp_4[target_columns] = test_preds","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:51:06.293479Z","iopub.execute_input":"2021-07-20T20:51:06.293774Z","iopub.status.idle":"2021-07-20T20:51:06.304211Z","shell.execute_reply.started":"2021-07-20T20:51:06.293748Z","shell.execute_reply":"2021-07-20T20:51:06.303385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## predictions\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(range(train.shape[0]), train[target], label = 'Train')\n    plt.plot(range(train.shape[0], train.shape[0] + test.shape[0]), submission_mlp_4[target], label = 'Test')\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Value', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.legend()\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:51:06.305399Z","iopub.execute_input":"2021-07-20T20:51:06.305917Z","iopub.status.idle":"2021-07-20T20:51:07.37919Z","shell.execute_reply.started":"2021-07-20T20:51:06.30588Z","shell.execute_reply":"2021-07-20T20:51:07.378307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## getting the predictions of the model\nmlp_4_predictions = mlp_4.predict([X_mlp_4_sensor, X_mlp_4_others, X_ar_CO_mlp_4, X_ar_BE_mlp_4, X_ar_NO_mlp_4])\n\n## reshaping the predictions\nmlp_4_predictions = np.column_stack(mlp_4_predictions)\n\n## putting the predictions in a dataframe\nmlp_4_predictions = pd.DataFrame(data = mlp_4_predictions, columns = target_columns)\n\n## getting the observed values\nobserved_values = pd.DataFrame(data = np.column_stack([y_ar_CO_mlp_4, y_ar_BE_mlp_4, y_ar_NO_mlp_4]), columns = target_columns)\n\n## residuals over time\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(observed_values.loc[:, target] - mlp_4_predictions.loc[:, target])\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Residuals', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()\n\n# distribution of residuals\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.hist(observed_values.loc[:, target] - mlp_4_predictions.loc[:, target], bins = 50)\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Residuals', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Frequency', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:51:07.380597Z","iopub.execute_input":"2021-07-20T20:51:07.381165Z","iopub.status.idle":"2021-07-20T20:51:09.405519Z","shell.execute_reply.started":"2021-07-20T20:51:07.38112Z","shell.execute_reply":"2021-07-20T20:51:09.404587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP #6 - Multi-input single-output MLP on autoregressive targets","metadata":{}},{"cell_type":"code","source":"### creating the layers\n## SENSOR DATA\n# input layer\ninput_layer_1 = Input(shape = (X_mlp_4_sensor.shape[1], ))\n# hidden layers\nhidden_layer_1 = Dense(units = 32, activation = 'relu')(input_layer_1)\nhidden_layer_1 = BatchNormalization()(hidden_layer_1)\nhidden_layer_1 = Dense(units = 16, activation = 'relu')(hidden_layer_1)\n\n## OTHER FEATURES\n# input layer\ninput_layer_2 = Input(shape = (X_mlp_4_others.shape[1], ))\n# hidden layers\nhidden_layer_2 = Dense(units = 32, activation = 'relu')(input_layer_2)\n\n## AUTOREGRESSIVE CO\n# input layer\ninput_layer_CO = Input(shape = (X_ar_CO_mlp_4.shape[1], ))\n# hidden layers\nhidden_layer_CO = Dense(units = 32, activation = 'relu')(input_layer_CO)\n\n## AUTOREGRESSIVE BE\n# input layer\ninput_layer_BE = Input(shape = (X_ar_BE_mlp_4.shape[1], ))\n# hidden layers\nhidden_layer_BE = Dense(units = 32, activation = 'relu')(input_layer_BE)\n\n## AUTOREGRESSIVE NO\n# input layer\ninput_layer_NO = Input(shape = (X_ar_NO_mlp_4.shape[1], ))\n# hidden layers\nhidden_layer_NO = Dense(units = 32, activation = 'relu')(input_layer_NO)\n\n## MERGING THE TWO INPUTS\nmerge_layer = Concatenate()([hidden_layer_1, hidden_layer_2, hidden_layer_CO, hidden_layer_BE, hidden_layer_NO])\n## one more layer\nhidden_layer = Dense(units = 32, activation = 'relu')(merge_layer)\nhidden_layer = Dropout(0.1)(hidden_layer)\n# output layers\noutput_layer = Dense(units = 3)(hidden_layer)\n\n## creating the model\nmlp_5 = Model(inputs = [input_layer_1, input_layer_2, input_layer_CO, input_layer_BE, input_layer_NO], outputs = output_layer)\n\n# compilling the model\nmlp_5.compile(optimizer = Adam(learning_rate = 0.0005), loss = 'mse', metrics = [RootMeanSquaredError()])\n\n# instantiating the early stopping callback\nes = EarlyStopping(monitor = 'val_root_mean_squared_error', patience = 20, min_delta = 0.002, restore_best_weights = True)\n\n# instantiating the learning rate scheduller\nlrs = ReduceLROnPlateau(monitor = 'val_root_mean_squared_error', factor = 0.2, patience = 5)\n\n# fitting the model\nhistory = mlp_5.fit(x = [X_mlp_4_sensor, X_mlp_4_others, X_ar_CO_mlp_4, X_ar_BE_mlp_4, X_ar_NO_mlp_4], \n                    y = y_ar_mlp_5, \n                    validation_split = 0.3, batch_size = 8, epochs = 100, callbacks = [es, lrs])\n\n# training history\nplt.figure(figsize = (10, 6))\nplt.plot(history.history['loss'], label = 'training')\nplt.plot(history.history['val_loss'], label = 'validation')\nplt.title(label = 'Training over epochs', fontdict = {'size': 14, 'fontweight': 'bold'})\nplt.ylabel(ylabel = 'RMSE', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.xlabel(xlabel = 'Epochs', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.legend(fontsize = 12)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:51:09.407015Z","iopub.execute_input":"2021-07-20T20:51:09.407411Z","iopub.status.idle":"2021-07-20T20:53:03.517Z","shell.execute_reply.started":"2021-07-20T20:51:09.40737Z","shell.execute_reply":"2021-07-20T20:53:03.516202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## visualizing the model\nplot_model(mlp_5, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:53:03.518244Z","iopub.execute_input":"2021-07-20T20:53:03.518607Z","iopub.status.idle":"2021-07-20T20:53:03.782594Z","shell.execute_reply.started":"2021-07-20T20:53:03.518572Z","shell.execute_reply":"2021-07-20T20:53:03.781701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## seeding the model prediction with the last six observations in the train set\ntest_seed_CO, test_seed_BE, test_seed_NO = y_CO[-7:-1].tolist(), y_BE[-7:-1].tolist(), y_NO[-7:-1].tolist()\n\n## looping over each of the rows of the test set and generating the predictions\nfor instance in range(X_test.shape[0]):\n    ## parsing the values to a numpy array\n    test_ar_CO, test_ar_BE, test_ar_NO = np.array(test_seed_CO[-6:]), np.array(test_seed_BE[-6:]), np.array(test_seed_NO[-6:])\n\n    ## extracting the predictions on the test set\n    test_preds = mlp_5.predict([\n        X_test[instance, sensor_index].reshape(1, 5),\n        X_test[instance, other_index].reshape(1, 7),\n        test_ar_CO.reshape(1, n_ar_inputs),\n        test_ar_BE.reshape(1, n_ar_inputs),\n        test_ar_NO.reshape(1, n_ar_inputs)\n    ]\n    )\n    \n    ## reshaping the predictions\n    test_preds = np.reshape(test_preds, (-1, ))\n    \n    ## adding the predictions back to the original lists\n    test_seed_CO.append(test_preds[0]), test_seed_BE.append(test_preds[1]), test_seed_NO.append(test_preds[2])\n    \n    ## printing the progress\n    if instance % 200 == 0:\n        print(f'Calculating the predictions for the time step {instance}.')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:53:03.784058Z","iopub.execute_input":"2021-07-20T20:53:03.784382Z","iopub.status.idle":"2021-07-20T20:54:40.949073Z","shell.execute_reply.started":"2021-07-20T20:53:03.78435Z","shell.execute_reply":"2021-07-20T20:54:40.948237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## stacking the predictions side by side\ntest_preds = np.column_stack([test_seed_CO, test_seed_BE, test_seed_NO])\n\n## removing the first six observation since they come from the train set\ntest_preds = test_preds[6:, :]\n\n## putting the test predictions back on the original scale\ntest_preds = np.expm1(test_preds)\n\n## copying the submission df\nsubmission_mlp_5 = submission.copy()\n\n## putting the predictions on the submission dataset\nsubmission_mlp_5[target_columns] = test_preds","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:54:40.950647Z","iopub.execute_input":"2021-07-20T20:54:40.950962Z","iopub.status.idle":"2021-07-20T20:54:40.963777Z","shell.execute_reply.started":"2021-07-20T20:54:40.950928Z","shell.execute_reply":"2021-07-20T20:54:40.96153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## predictions\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(range(train.shape[0]), train[target], label = 'Train')\n    plt.plot(range(train.shape[0], train.shape[0] + test.shape[0]), submission_mlp_5[target], label = 'Test')\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Value', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.legend()\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:54:40.965486Z","iopub.execute_input":"2021-07-20T20:54:40.965914Z","iopub.status.idle":"2021-07-20T20:54:41.701149Z","shell.execute_reply.started":"2021-07-20T20:54:40.965876Z","shell.execute_reply":"2021-07-20T20:54:41.700387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## getting the predictions of the model\nmlp_5_predictions = mlp_5.predict([X_mlp_4_sensor, X_mlp_4_others, X_ar_CO_mlp_4, X_ar_BE_mlp_4, X_ar_NO_mlp_4])\n\n## putting the predictions in a dataframe\nmlp_5_predictions = pd.DataFrame(data = mlp_5_predictions, columns = target_columns)\n\n## getting the observed values\nobserved_values = pd.DataFrame(data = y_ar_mlp_5, columns = target_columns)\n\n## residuals over time\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(observed_values.loc[:, target] - mlp_5_predictions.loc[:, target])\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Residuals', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()\n\n# distribution of residuals\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.hist(observed_values.loc[:, target] - mlp_5_predictions.loc[:, target], bins = 50)\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Residuals', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Frequency', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:54:41.702473Z","iopub.execute_input":"2021-07-20T20:54:41.703014Z","iopub.status.idle":"2021-07-20T20:54:43.722656Z","shell.execute_reply.started":"2021-07-20T20:54:41.70297Z","shell.execute_reply":"2021-07-20T20:54:43.721618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP #6 - Multi-AR inputs (12h lag features + 6h lag targets) and single output MLP ","metadata":{}},{"cell_type":"code","source":"### creating the layers\n## SENSOR DATA\n# input layer\ninput_layer_1 = Input(shape = (X_mlp_6_sensor.shape[1], ))\n# hidden layers\nhidden_layer_1 = Dense(units = 32, activation = 'relu')(input_layer_1)\nhidden_layer_1 = BatchNormalization()(hidden_layer_1)\nhidden_layer_1 = Dense(units = 16, activation = 'relu')(hidden_layer_1)\n\n## TEMPERATURE DATA\n# input layer\ninput_layer_2 = Input(shape = (X_temp_mlp_6.shape[1], ))\n# hidden layers\nhidden_layer_2 = Dense(units = 32, activation = 'relu')(input_layer_2)\n\n## RELATIVE HUMIDITY DATA\n# input layer\ninput_layer_3 = Input(shape = (X_rl_mlp_6.shape[1], ))\n# hidden layers\nhidden_layer_3 = Dense(units = 32, activation = 'relu')(input_layer_3)\n\n## AUTOREGRESSIVE CO\n# input layer\ninput_layer_CO = Input(shape = (X_ar_CO_mlp_6.shape[1], ))\n# hidden layers\nhidden_layer_CO = Dense(units = 32, activation = 'relu')(input_layer_CO)\n\n## AUTOREGRESSIVE BE\n# input layer\ninput_layer_BE = Input(shape = (X_ar_BE_mlp_6.shape[1], ))\n# hidden layers\nhidden_layer_BE = Dense(units = 32, activation = 'relu')(input_layer_BE)\n\n## AUTOREGRESSIVE NO\n# input layer\ninput_layer_NO = Input(shape = (X_ar_NO_mlp_6.shape[1], ))\n# hidden layers\nhidden_layer_NO = Dense(units = 32, activation = 'relu')(input_layer_NO)\n\n## MERGING THE TWO INPUTS\nmerge_layer = Concatenate()([hidden_layer_1, hidden_layer_2, hidden_layer_3, hidden_layer_CO, hidden_layer_BE, hidden_layer_NO])\n## one more layer\nhidden_layer = Dense(units = 32, activation = 'relu')(merge_layer)\nhidden_layer = Dropout(0.1)(hidden_layer)\n# output layers\noutput_layer = Dense(units = 3)(hidden_layer)\n\n## creating the model\nmlp_6 = Model(inputs = [input_layer_1, input_layer_2, input_layer_3, input_layer_CO, input_layer_BE, input_layer_NO], outputs = output_layer)\n\n# compilling the model\nmlp_6.compile(optimizer = Adam(learning_rate = 0.0005), loss = 'mse', metrics = [RootMeanSquaredError()])\n\n# instantiating the early stopping callback\nes = EarlyStopping(monitor = 'val_root_mean_squared_error', patience = 20, min_delta = 0.002, restore_best_weights = True)\n\n# instantiating the learning rate scheduller\nlrs = ReduceLROnPlateau(monitor = 'val_root_mean_squared_error', factor = 0.2, patience = 5)\n\n# fitting the model\nhistory = mlp_6.fit(x = [X_mlp_6_sensor, X_temp_mlp_6, X_rl_mlp_6, X_ar_CO_mlp_6, X_ar_BE_mlp_6, X_ar_NO_mlp_6], \n                    y = y_ar_mlp_6, \n                    validation_split = 0.3, batch_size = 8, epochs = 100, callbacks = [es, lrs])\n\n# training history\nplt.figure(figsize = (10, 6))\nplt.plot(history.history['loss'], label = 'training')\nplt.plot(history.history['val_loss'], label = 'validation')\nplt.title(label = 'Training over epochs', fontdict = {'size': 14, 'fontweight': 'bold'})\nplt.ylabel(ylabel = 'RMSE', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.xlabel(xlabel = 'Epochs', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.legend(fontsize = 12)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:54:43.724155Z","iopub.execute_input":"2021-07-20T20:54:43.724726Z","iopub.status.idle":"2021-07-20T20:56:16.140526Z","shell.execute_reply.started":"2021-07-20T20:54:43.724679Z","shell.execute_reply":"2021-07-20T20:56:16.139584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## visualizing the model\nplot_model(mlp_6, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:56:16.141861Z","iopub.execute_input":"2021-07-20T20:56:16.142203Z","iopub.status.idle":"2021-07-20T20:56:16.39028Z","shell.execute_reply.started":"2021-07-20T20:56:16.142167Z","shell.execute_reply":"2021-07-20T20:56:16.389394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## seeding the model prediction with the last six observations in the train set\ntest_seed_CO, test_seed_BE, test_seed_NO = y_CO[-7:-1].tolist(), y_BE[-7:-1].tolist(), y_NO[-7:-1].tolist()\n\n## looping over each of the rows of the test set and generating the predictions\nfor instance in range(X_test.shape[0]):\n    ## parsing the values to a numpy array\n    test_ar_CO, test_ar_BE, test_ar_NO = np.array(test_seed_CO[-6:]), np.array(test_seed_BE[-6:]), np.array(test_seed_NO[-6:]), \n\n    ## extracting the predictions on the test set\n    test_preds = mlp_6.predict([\n        X_test[instance, sensor_index].reshape(1, X_mlp_6_sensor.shape[1]),\n        test_ar_TEMP[instance, :].reshape(1, X_temp_mlp_6.shape[1]),\n        test_ar_RL[instance, :].reshape(1, X_rl_mlp_6.shape[1]),\n        test_ar_CO.reshape(1, X_ar_CO_mlp_6.shape[1]),\n        test_ar_BE.reshape(1, X_ar_BE_mlp_6.shape[1]),\n        test_ar_NO.reshape(1, X_ar_NO_mlp_6.shape[1])\n    ]\n    )\n    \n    ## reshaping the predictions\n    test_preds = np.reshape(test_preds, (-1, ))\n    \n    ## adding the predictions back to the original lists\n    test_seed_CO.append(test_preds[0]), test_seed_BE.append(test_preds[1]), test_seed_NO.append(test_preds[2])\n    \n    ## printing the progress\n    if instance % 200 == 0:\n        print(f'Calculating the predictions for the time step {instance}.')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:56:16.391914Z","iopub.execute_input":"2021-07-20T20:56:16.392297Z","iopub.status.idle":"2021-07-20T20:58:02.646855Z","shell.execute_reply.started":"2021-07-20T20:56:16.392244Z","shell.execute_reply":"2021-07-20T20:58:02.646034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## stacking the predictions side by side\ntest_preds = np.column_stack([test_seed_CO, test_seed_BE, test_seed_NO])\n\n## removing the first six observation since they come from the train set\ntest_preds = test_preds[6:, :]\n\n## putting the test predictions back on the original scale\ntest_preds = np.expm1(test_preds)\n\n## copying the submission df\nsubmission_mlp_6 = submission.copy()\n\n## putting the predictions on the submission dataset\nsubmission_mlp_6[target_columns] = test_preds","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:58:02.648175Z","iopub.execute_input":"2021-07-20T20:58:02.648513Z","iopub.status.idle":"2021-07-20T20:58:02.661369Z","shell.execute_reply.started":"2021-07-20T20:58:02.648481Z","shell.execute_reply":"2021-07-20T20:58:02.660425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## predictions\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(range(train.shape[0]), train[target], label = 'Train')\n    plt.plot(range(train.shape[0], train.shape[0] + test.shape[0]), submission_mlp_6[target], label = 'Test')\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Value', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.legend()\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:58:02.662809Z","iopub.execute_input":"2021-07-20T20:58:02.663465Z","iopub.status.idle":"2021-07-20T20:58:03.327664Z","shell.execute_reply.started":"2021-07-20T20:58:02.663428Z","shell.execute_reply":"2021-07-20T20:58:03.326871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## getting the predictions of the model\nmlp_6_predictions = mlp_6.predict([X_mlp_6_sensor, X_temp_mlp_6, X_rl_mlp_6, X_ar_CO_mlp_6, X_ar_BE_mlp_6, X_ar_NO_mlp_6])\n\n## putting the predictions in a dataframe\nmlp_6_predictions = pd.DataFrame(data = mlp_6_predictions, columns = target_columns)\n\n## getting the observed values\nobserved_values = pd.DataFrame(data = y_ar_mlp_6, columns = target_columns)\n\n## residuals over time\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(observed_values.loc[:, target] - mlp_6_predictions.loc[:, target])\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Residuals', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()\n\n# distribution of residuals\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.hist(observed_values.loc[:, target] - mlp_6_predictions.loc[:, target], bins = 50)\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Residuals', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Frequency', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T20:58:03.328927Z","iopub.execute_input":"2021-07-20T20:58:03.329263Z","iopub.status.idle":"2021-07-20T20:58:05.185647Z","shell.execute_reply.started":"2021-07-20T20:58:03.329228Z","shell.execute_reply":"2021-07-20T20:58:05.184854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP #7 - Multi-AR inputs (12h lag features + 12h lag targets) and single output MLP","metadata":{}},{"cell_type":"code","source":"### creating the layers\n## SENSOR DATA\n# input layer\ninput_layer_1 = Input(shape = (X_mlp_7_sensor.shape[1], ))\n# hidden layers\nhidden_layer_1 = Dense(units = 32, activation = 'relu')(input_layer_1)\nhidden_layer_1 = BatchNormalization()(hidden_layer_1)\nhidden_layer_1 = Dense(units = 16, activation = 'relu')(hidden_layer_1)\n\n## TEMPERATURE DATA\n# input layer\ninput_layer_2 = Input(shape = (X_temp_mlp_7.shape[1], ))\n# hidden layers\nhidden_layer_2 = Dense(units = 32, activation = 'relu')(input_layer_2)\n\n## RELATIVE HUMIDITY DATA\n# input layer\ninput_layer_3 = Input(shape = (X_rl_mlp_7.shape[1], ))\n# hidden layers\nhidden_layer_3 = Dense(units = 32, activation = 'relu')(input_layer_3)\n\n## AUTOREGRESSIVE CO\n# input layer\ninput_layer_CO = Input(shape = (X_ar_CO_mlp_7.shape[1], ))\n# hidden layers\nhidden_layer_CO = Dense(units = 64, activation = 'relu')(input_layer_CO)\n\n## AUTOREGRESSIVE BE\n# input layer\ninput_layer_BE = Input(shape = (X_ar_BE_mlp_7.shape[1], ))\n# hidden layers\nhidden_layer_BE = Dense(units = 32, activation = 'relu')(input_layer_BE)\n\n## AUTOREGRESSIVE NO\n# input layer\ninput_layer_NO = Input(shape = (X_ar_NO_mlp_7.shape[1], ))\n# hidden layers\nhidden_layer_NO = Dense(units = 32, activation = 'relu')(input_layer_NO)\n\n## MERGING THE TWO INPUTS\nmerge_layer = Concatenate()([hidden_layer_1, hidden_layer_2, hidden_layer_3, hidden_layer_CO, hidden_layer_BE, hidden_layer_NO])\n## one more layer\nhidden_layer = Dense(units = 32, activation = 'relu')(merge_layer)\nhidden_layer = Dropout(0.1)(hidden_layer)\n# output layers\noutput_layer = Dense(units = 3)(hidden_layer)\n\n## creating the model\nmlp_7 = Model(inputs = [input_layer_1, input_layer_2, input_layer_3, input_layer_CO, input_layer_BE, input_layer_NO], outputs = output_layer)\n\n# compilling the model\nmlp_7.compile(optimizer = Adam(learning_rate = 0.0005), loss = 'mse', metrics = [RootMeanSquaredError()])\n\n# instantiating the early stopping callback\nes = EarlyStopping(monitor = 'val_root_mean_squared_error', patience = 20, min_delta = 0.002, restore_best_weights = True)\n\n# instantiating the learning rate scheduller\nlrs = ReduceLROnPlateau(monitor = 'val_root_mean_squared_error', factor = 0.2, patience = 5)\n\n# fitting the model\nhistory = mlp_7.fit(x = [X_mlp_7_sensor, X_temp_mlp_7, X_rl_mlp_7, X_ar_CO_mlp_7, X_ar_BE_mlp_7, X_ar_NO_mlp_7], \n                    y = y_ar_mlp_7, \n                    validation_split = 0.3, batch_size = 8, epochs = 100, callbacks = [es, lrs])\n\n# training history\nplt.figure(figsize = (10, 6))\nplt.plot(history.history['loss'], label = 'training')\nplt.plot(history.history['val_loss'], label = 'validation')\nplt.title(label = 'Training over epochs', fontdict = {'size': 14, 'fontweight': 'bold'})\nplt.ylabel(ylabel = 'RMSE', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.xlabel(xlabel = 'Epochs', fontdict = {'size': 12, 'fontweight': 'bold'})\nplt.legend(fontsize = 12)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T21:21:48.635618Z","iopub.execute_input":"2021-07-20T21:21:48.636038Z","iopub.status.idle":"2021-07-20T21:23:43.664145Z","shell.execute_reply.started":"2021-07-20T21:21:48.636001Z","shell.execute_reply":"2021-07-20T21:23:43.663359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## visualizing the model\nplot_model(mlp_7, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T21:51:28.473259Z","iopub.execute_input":"2021-07-20T21:51:28.473655Z","iopub.status.idle":"2021-07-20T21:51:28.740109Z","shell.execute_reply.started":"2021-07-20T21:51:28.473622Z","shell.execute_reply":"2021-07-20T21:51:28.739166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## seeding the model prediction with the last six observations in the train set\ntest_seed_CO, test_seed_BE, test_seed_NO = y_CO[-26:-1].tolist(), y_BE[-26:-1].tolist(), y_NO[-26:-1].tolist()\n\n## looping over each of the rows of the test set and generating the predictions\nfor instance in range(X_test.shape[0]):\n    ## parsing the values to a numpy array\n    test_ar_CO, test_ar_BE, test_ar_NO = np.array(test_seed_CO[-25:]), np.array(test_seed_BE[-25:]), np.array(test_seed_NO[-25:]), \n\n    ## extracting the predictions on the test set\n    test_preds = mlp_7.predict([\n        X_test[instance, sensor_index].reshape(1, X_mlp_7_sensor.shape[1]),\n        test_ar_TEMP[instance, :].reshape(1, X_temp_mlp_7.shape[1]),\n        test_ar_RL[instance, :].reshape(1, X_rl_mlp_7.shape[1]),\n        test_ar_CO.reshape(1, X_ar_CO_mlp_7.shape[1]),\n        test_ar_BE.reshape(1, X_ar_BE_mlp_7.shape[1]),\n        test_ar_NO.reshape(1, X_ar_NO_mlp_7.shape[1])\n    ]\n    )\n    \n    ## reshaping the predictions\n    test_preds = np.reshape(test_preds, (-1, ))\n    \n    ## adding the predictions back to the original lists\n    test_seed_CO.append(test_preds[0]), test_seed_BE.append(test_preds[1]), test_seed_NO.append(test_preds[2])\n    \n    ## printing the progress\n    if instance % 200 == 0:\n        print(f'Calculating the predictions for the time step {instance}.')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T21:51:28.84922Z","iopub.execute_input":"2021-07-20T21:51:28.849524Z","iopub.status.idle":"2021-07-20T21:53:13.607928Z","shell.execute_reply.started":"2021-07-20T21:51:28.849492Z","shell.execute_reply":"2021-07-20T21:53:13.607096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## stacking the predictions side by side\ntest_preds = np.column_stack([test_seed_CO, test_seed_BE, test_seed_NO])\n\n## removing the first six observation since they come from the train set\ntest_preds = test_preds[25:, :]\n\n## putting the test predictions back on the original scale\ntest_preds = np.expm1(test_preds)\n\n## copying the submission df\nsubmission_mlp_7 = submission.copy()\n\n## putting the predictions on the submission dataset\nsubmission_mlp_7[target_columns] = test_preds","metadata":{"execution":{"iopub.status.busy":"2021-07-20T21:53:13.60952Z","iopub.execute_input":"2021-07-20T21:53:13.609839Z","iopub.status.idle":"2021-07-20T21:53:13.621289Z","shell.execute_reply.started":"2021-07-20T21:53:13.609807Z","shell.execute_reply":"2021-07-20T21:53:13.620482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## predictions\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(range(train.shape[0]), train[target], label = 'Train')\n    plt.plot(range(train.shape[0], train.shape[0] + test.shape[0]), submission_mlp_7[target], label = 'Test')\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Value', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.legend()\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T21:53:13.62293Z","iopub.execute_input":"2021-07-20T21:53:13.623423Z","iopub.status.idle":"2021-07-20T21:53:14.293646Z","shell.execute_reply.started":"2021-07-20T21:53:13.623388Z","shell.execute_reply":"2021-07-20T21:53:14.292837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## getting the predictions of the model\nmlp_7_predictions = mlp_7.predict([X_mlp_7_sensor, X_temp_mlp_7, X_rl_mlp_7, X_ar_CO_mlp_7, X_ar_BE_mlp_7, X_ar_NO_mlp_7])\n\n## putting the predictions in a dataframe\nmlp_7_predictions = pd.DataFrame(data = mlp_7_predictions, columns = target_columns)\n\n## getting the observed values\nobserved_values = pd.DataFrame(data = y_ar_mlp_7, columns = target_columns)\n\n## residuals over time\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.plot(observed_values.loc[:, target] - mlp_7_predictions.loc[:, target])\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Timesteps', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Residuals', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()\n\n# distribution of residuals\nplt.figure(figsize = (25, 6))\nfor idx, target in enumerate(target_columns):\n    plt.subplot(1, 3, idx + 1)\n    plt.hist(observed_values.loc[:, target] - mlp_7_predictions.loc[:, target], bins = 50)\n    plt.title(label = target, fontdict = {'size': 14, 'fontweight': 'bold'})\n    plt.xlabel(xlabel = 'Residuals', fontdict = {'size': 14})\n    plt.ylabel(ylabel = 'Frequency', fontdict = {'size': 14})\n    plt.xticks(fontsize = 12)\n    plt.yticks(fontsize = 12)\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T21:53:14.295046Z","iopub.execute_input":"2021-07-20T21:53:14.295405Z","iopub.status.idle":"2021-07-20T21:53:16.145642Z","shell.execute_reply.started":"2021-07-20T21:53:14.29537Z","shell.execute_reply":"2021-07-20T21:53:16.14483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the submission file","metadata":{}},{"cell_type":"code","source":"submission_mlp_1.to_csv(path_or_buf = 'submission_mlp_1.csv', index = False)\nsubmission_mlp_2.to_csv(path_or_buf = 'submission_mlp_2.csv', index = False)\nsubmission_mlp_3.to_csv(path_or_buf = 'submission_mlp_3.csv', index = False)\nsubmission_mlp_4.to_csv(path_or_buf = 'submission_mlp_4.csv', index = False)\nsubmission_mlp_5.to_csv(path_or_buf = 'submission_mlp_5.csv', index = False)\nsubmission_mlp_6.to_csv(path_or_buf = 'submission_mlp_6.csv', index = False)\nsubmission_mlp_7.to_csv(path_or_buf = 'submission_mlp_7.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T21:01:55.567202Z","iopub.execute_input":"2021-07-20T21:01:55.567542Z","iopub.status.idle":"2021-07-20T21:01:55.696017Z","shell.execute_reply.started":"2021-07-20T21:01:55.567507Z","shell.execute_reply":"2021-07-20T21:01:55.695127Z"},"trusted":true},"execution_count":null,"outputs":[]}]}