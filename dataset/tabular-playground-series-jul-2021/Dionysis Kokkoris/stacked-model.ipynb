{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-13T15:50:17.975592Z","iopub.execute_input":"2022-06-13T15:50:17.976034Z","iopub.status.idle":"2022-06-13T15:50:17.984944Z","shell.execute_reply.started":"2022-06-13T15:50:17.976001Z","shell.execute_reply":"2022-06-13T15:50:17.984006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/tabular-playground-series-jul-2021/train.csv')\ntest=pd.read_csv('/kaggle/input/tabular-playground-series-jul-2021/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.036549Z","iopub.execute_input":"2022-06-13T15:50:18.036955Z","iopub.status.idle":"2022-06-13T15:50:18.087689Z","shell.execute_reply.started":"2022-06-13T15:50:18.036924Z","shell.execute_reply":"2022-06-13T15:50:18.086794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.096284Z","iopub.execute_input":"2022-06-13T15:50:18.097094Z","iopub.status.idle":"2022-06-13T15:50:18.105316Z","shell.execute_reply.started":"2022-06-13T15:50:18.097047Z","shell.execute_reply":"2022-06-13T15:50:18.104039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col4train=['relative_humidity', 'absolute_humidity',\n       'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']\n\ny1=train['target_carbon_monoxide']\ny2=train['target_benzene']\ny3=train['target_nitrogen_oxides']\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.161792Z","iopub.execute_input":"2022-06-13T15:50:18.163079Z","iopub.status.idle":"2022-06-13T15:50:18.170071Z","shell.execute_reply.started":"2022-06-13T15:50:18.163002Z","shell.execute_reply":"2022-06-13T15:50:18.169243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#transformations\ny1 = np.log1p(y1)\ny2 = np.log1p(y2)\ny3 = np.log1p(y3)\n\n\n#for col in col4train:\n    #train[col] = boxcox1p(train[col], lam)\n    \n#for col in col4train:\n    #test[col] = boxcox1p(test[col], lam)\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.246544Z","iopub.execute_input":"2022-06-13T15:50:18.247313Z","iopub.status.idle":"2022-06-13T15:50:18.253516Z","shell.execute_reply.started":"2022-06-13T15:50:18.247273Z","shell.execute_reply":"2022-06-13T15:50:18.252591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nfor col in col4train:\n    train[col] = scaler.fit_transform(train[col].values.reshape(-1,1))\nfor col in col4train:\n    test[col] = scaler.fit_transform(test[col].values.reshape(-1,1))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.316538Z","iopub.execute_input":"2022-06-13T15:50:18.317138Z","iopub.status.idle":"2022-06-13T15:50:18.336018Z","shell.execute_reply.started":"2022-06-13T15:50:18.317103Z","shell.execute_reply":"2022-06-13T15:50:18.335069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train[col4train]\nx=test[col4train]","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.396841Z","iopub.execute_input":"2022-06-13T15:50:18.397606Z","iopub.status.idle":"2022-06-13T15:50:18.403577Z","shell.execute_reply.started":"2022-06-13T15:50:18.397571Z","shell.execute_reply":"2022-06-13T15:50:18.402864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.466496Z","iopub.execute_input":"2022-06-13T15:50:18.467231Z","iopub.status.idle":"2022-06-13T15:50:18.484024Z","shell.execute_reply.started":"2022-06-13T15:50:18.467195Z","shell.execute_reply":"2022-06-13T15:50:18.482732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.541727Z","iopub.execute_input":"2022-06-13T15:50:18.542345Z","iopub.status.idle":"2022-06-13T15:50:18.549423Z","shell.execute_reply.started":"2022-06-13T15:50:18.542309Z","shell.execute_reply":"2022-06-13T15:50:18.548419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.625086Z","iopub.execute_input":"2022-06-13T15:50:18.625694Z","iopub.status.idle":"2022-06-13T15:50:18.643966Z","shell.execute_reply.started":"2022-06-13T15:50:18.625646Z","shell.execute_reply":"2022-06-13T15:50:18.642583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.667066Z","iopub.execute_input":"2022-06-13T15:50:18.668314Z","iopub.status.idle":"2022-06-13T15:50:18.678698Z","shell.execute_reply.started":"2022-06-13T15:50:18.668263Z","shell.execute_reply":"2022-06-13T15:50:18.677145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n                                                 meta_model = lasso)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.704449Z","iopub.execute_input":"2022-06-13T15:50:18.705167Z","iopub.status.idle":"2022-06-13T15:50:18.710816Z","shell.execute_reply.started":"2022-06-13T15:50:18.705114Z","shell.execute_reply":"2022-06-13T15:50:18.709921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_averaged_models.fit(X.values, y1)\npred1 = stacked_averaged_models.predict(x.values)\npred1=np.expm1(pred1)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:50:18.744366Z","iopub.execute_input":"2022-06-13T15:50:18.745514Z","iopub.status.idle":"2022-06-13T15:53:22.961216Z","shell.execute_reply.started":"2022-06-13T15:50:18.745472Z","shell.execute_reply":"2022-06-13T15:53:22.959665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_averaged_models.fit(X.values, y2)\npred2 = stacked_averaged_models.predict(x.values)\npred2=np.expm1(pred2)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:53:22.963508Z","iopub.execute_input":"2022-06-13T15:53:22.964007Z","iopub.status.idle":"2022-06-13T15:56:34.69942Z","shell.execute_reply.started":"2022-06-13T15:53:22.963959Z","shell.execute_reply":"2022-06-13T15:56:34.697992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_averaged_models.fit(X.values, y3)\npred3 = stacked_averaged_models.predict(x.values)\npred3=np.expm1(pred3)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:56:34.701709Z","iopub.execute_input":"2022-06-13T15:56:34.702625Z","iopub.status.idle":"2022-06-13T15:59:43.076267Z","shell.execute_reply.started":"2022-06-13T15:56:34.702569Z","shell.execute_reply":"2022-06-13T15:59:43.074976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'date_time': test.date_time, 'target_carbon_monoxide': pred1, 'target_benzene': pred2, 'target_nitrogen_oxides': pred3})\n# you could use any filename. We choose submission here\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:59:43.078746Z","iopub.execute_input":"2022-06-13T15:59:43.079416Z","iopub.status.idle":"2022-06-13T15:59:43.122751Z","shell.execute_reply.started":"2022-06-13T15:59:43.079369Z","shell.execute_reply":"2022-06-13T15:59:43.121431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:59:43.124533Z","iopub.execute_input":"2022-06-13T15:59:43.125224Z","iopub.status.idle":"2022-06-13T15:59:43.148599Z","shell.execute_reply.started":"2022-06-13T15:59:43.125177Z","shell.execute_reply":"2022-06-13T15:59:43.147506Z"},"trusted":true},"execution_count":null,"outputs":[]}]}