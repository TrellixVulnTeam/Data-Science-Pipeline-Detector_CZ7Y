{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **TabNet: TPS Semi-Supervised Deep Learning Solution** #","metadata":{"jupyter":{"outputs_hidden":true},"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"## Official TabNet github repository is [here](https://github.com/dreamquark-ai/tabnet)\n\n## TabNet: Attentive Interpretable Tabular Learning paper [here](https://arxiv.org/pdf/1908.07442.pdf)\n\nHere we will import the libraries we use in this kernel:\n# About this notebook\n\n- Data: Official competition data only.\n- Data Split: 0.95 train, 0.05 test\n- Features: 15 training, 3 labels\n- Number of Models: 2\n- Models: Unsupervised Pretraining Model, TabNet-Regressor\n- Hyperparameters: None\n- GPUs: Recommended\n- Modules: PyTorch, TabNet-PyTorch, EvalML","metadata":{}},{"cell_type":"markdown","source":"# Step 0 installation\n","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade pytorch-tabnet\n!pip install --upgrade evalml\n","metadata":{"execution":{"iopub.status.busy":"2021-07-31T20:53:06.688836Z","iopub.execute_input":"2021-07-31T20:53:06.689152Z","iopub.status.idle":"2021-07-31T20:54:07.601238Z","shell.execute_reply.started":"2021-07-31T20:53:06.689122Z","shell.execute_reply":"2021-07-31T20:54:07.600299Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n%matplotlib inline\n\n\n\nimport warnings\nimport evalml\n# from evalml.model_understanding.graphs import graph_prediction_vs_actual\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\nfrom pytorch_tabnet.callbacks import EarlyStopping\n\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\n\nimport torch\nfrom torch import nn\n\nimport numpy as np\n\nnp.random.seed(0)\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import mean_squared_log_error\n\nimport os\nfrom matplotlib import pyplot as plt\n\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 1 preprocessing and models preparations\n","metadata":{}},{"cell_type":"markdown","source":"## Step 1.0 data loading","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings('ignore')\npath = \"../input/tabular-playground-series-jul-2021/\"\ntrain_csv = \"train.csv\"\ntest_csv = \"test.csv\"\nsample_csv = \"sample_submission.csv\"\ntorch.cuda.is_available()\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.385127Z","iopub.execute_input":"2021-07-31T20:11:25.385488Z","iopub.status.idle":"2021-07-31T20:11:25.399109Z","shell.execute_reply.started":"2021-07-31T20:11:25.38545Z","shell.execute_reply":"2021-07-31T20:11:25.398132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(path+train_csv)  # reading the train data to a data frame\ntest_sub_data = pd.read_csv(path+test_csv)  # reading the test data into a data frame\nsample_submission = pd.read_csv(path+sample_csv)  # reading the test data into a data frame\n\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.402985Z","iopub.execute_input":"2021-07-31T20:11:25.403315Z","iopub.status.idle":"2021-07-31T20:11:25.440773Z","shell.execute_reply.started":"2021-07-31T20:11:25.403284Z","shell.execute_reply":"2021-07-31T20:11:25.43988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.set_index('date_time')\ntest_sub_data.set_index('date_time')","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.441999Z","iopub.execute_input":"2021-07-31T20:11:25.442351Z","iopub.status.idle":"2021-07-31T20:11:25.466186Z","shell.execute_reply.started":"2021-07-31T20:11:25.442312Z","shell.execute_reply":"2021-07-31T20:11:25.465127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1.2 data preprocessing","metadata":{}},{"cell_type":"code","source":"all_df = pd.concat([train_data, test_sub_data]).reset_index(drop=True)\nprint(all_df.shape)\n\n\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.467994Z","iopub.execute_input":"2021-07-31T20:11:25.468429Z","iopub.status.idle":"2021-07-31T20:11:25.480627Z","shell.execute_reply.started":"2021-07-31T20:11:25.468378Z","shell.execute_reply":"2021-07-31T20:11:25.479253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df['date_time'] = pd.to_datetime(all_df['date_time'])\nall_df[\"hour\"] = all_df[\"date_time\"].dt.hour\nall_df[\"working_hours\"] = all_df[\"hour\"].isin(np.arange(8, 21, 1)).astype(\"int\")\nall_df[\"is_weekend\"] = (all_df[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")\nall_df['hr'] = all_df.date_time.dt.hour * 60 + all_df.date_time.dt.minute\nall_df['deg_C_lag_2'] = all_df['deg_C'] - all_df['deg_C'].shift(periods=2, fill_value=0)\n# all_df['relative_humidity_lag_2'] = all_df['relative_humidity'] - all_df['relative_humidity'].shift(periods=-2, fill_value=0)\n# all_df['absolute_humidity_lag_2'] = all_df['absolute_humidity'] - all_df['absolute_humidity'].shift(periods=-2, fill_value=0)\n\nall_df['satday'] = (all_df.date_time.dt.weekday == 5).astype(\"int\")\n\nall_df[\"SMC\"] = (all_df[\"absolute_humidity\"] * 100) / all_df[\"relative_humidity\"]\n# periods = 2\n# for i in range(1, 5):\n#     all_df[f\"s1-{periods}\"] = all_df[f\"sensor_{i}\"] - all_df[f\"sensor_{i}\"].shift(periods=periods, fill_value=0)\n\ntrain, test_sub = all_df.iloc[:(len(all_df) - len(test_sub_data)), :], all_df.iloc[(len(all_df) - len(test_sub_data)):,\n                                                                       :]\nprint(train.shape, test_sub.shape)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.482299Z","iopub.execute_input":"2021-07-31T20:11:25.482787Z","iopub.status.idle":"2021-07-31T20:11:25.514868Z","shell.execute_reply.started":"2021-07-31T20:11:25.482747Z","shell.execute_reply":"2021-07-31T20:11:25.513814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlabels = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']\nto_drop = [\n              \"date_time\",\n              # \"hour\"\n\n          ] + labels\ntest_sub = test_sub.drop(columns=to_drop)\nX_train = train.drop(columns=to_drop)\ncarbon_monoxide = train['target_carbon_monoxide']\nbenzene = train['target_benzene']\nnitrogen_oxides = train['target_nitrogen_oxides']\nlables = pd.DataFrame()\nlables['target_carbon_monoxide'] = train['target_carbon_monoxide']\nlables['target_benzene'] = train['target_benzene']\nlables['target_nitrogen_oxides'] = train['target_nitrogen_oxides']\n\ntest_sub.shape\n\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.518234Z","iopub.execute_input":"2021-07-31T20:11:25.518643Z","iopub.status.idle":"2021-07-31T20:11:25.537662Z","shell.execute_reply.started":"2021-07-31T20:11:25.518606Z","shell.execute_reply":"2021-07-31T20:11:25.536603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1.3 train test data split\n","metadata":{}},{"cell_type":"code","source":"test_size = 0.05\nX_train_e, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X_train, lables,\n                                                                           problem_type='regression',\n                                                                           test_size=test_size)\n\nX_pretrain = pd.concat([X_train, test_sub]).reset_index(drop=True)\nX_pretrain_e, X_pretrain_holdout, _, _ = evalml.preprocessing.split_data(X_pretrain, X_pretrain,\n                                                                         problem_type='regression',\n                                                                         test_size=test_size,\n                                                                         random_seed=19)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.53989Z","iopub.execute_input":"2021-07-31T20:11:25.540261Z","iopub.status.idle":"2021-07-31T20:11:25.60612Z","shell.execute_reply.started":"2021-07-31T20:11:25.540224Z","shell.execute_reply":"2021-07-31T20:11:25.603826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1.4  objective and parameters\n","metadata":{}},{"cell_type":"code","source":"max_epochs = 1000\npatience = 30\nbatch_size = 1024\nnum_workers = 0","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.607455Z","iopub.execute_input":"2021-07-31T20:11:25.607839Z","iopub.status.idle":"2021-07-31T20:11:25.616887Z","shell.execute_reply.started":"2021-07-31T20:11:25.607801Z","shell.execute_reply":"2021-07-31T20:11:25.615561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MSLELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n\n    def forward(self, pred, actual):\n        c_pred = torch.clip(pred, min=0)\n        c_actual = torch.clip(actual, min=0)\n        return self.mse(torch.log(c_pred + 1), torch.log(c_actual + 1))\n\n\nloss_fn = MSLELoss()\n\n\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.620156Z","iopub.execute_input":"2021-07-31T20:11:25.621522Z","iopub.status.idle":"2021-07-31T20:11:25.640724Z","shell.execute_reply.started":"2021-07-31T20:11:25.620985Z","shell.execute_reply":"2021-07-31T20:11:25.639437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping('valid_rmsle', is_maximize=False, patience=patience * 2, tol=0.001)\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.642535Z","iopub.execute_input":"2021-07-31T20:11:25.64332Z","iopub.status.idle":"2021-07-31T20:11:25.657011Z","shell.execute_reply.started":"2021-07-31T20:11:25.64328Z","shell.execute_reply":"2021-07-31T20:11:25.655502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1.5 models\n","metadata":{}},{"cell_type":"code","source":"DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.658979Z","iopub.execute_input":"2021-07-31T20:11:25.659768Z","iopub.status.idle":"2021-07-31T20:11:25.66758Z","shell.execute_reply.started":"2021-07-31T20:11:25.659654Z","shell.execute_reply":"2021-07-31T20:11:25.66626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nregressor = TabNetRegressor(device_name=DEVICE, )","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.669992Z","iopub.execute_input":"2021-07-31T20:11:25.670871Z","iopub.status.idle":"2021-07-31T20:11:25.678793Z","shell.execute_reply.started":"2021-07-31T20:11:25.670826Z","shell.execute_reply":"2021-07-31T20:11:25.677235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unsupervised_model = TabNetPretrainer(\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2),\n    mask_type=\"sparsemax\",\n    device_name=DEVICE,\n\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.680929Z","iopub.execute_input":"2021-07-31T20:11:25.682252Z","iopub.status.idle":"2021-07-31T20:11:25.694419Z","shell.execute_reply.started":"2021-07-31T20:11:25.682144Z","shell.execute_reply":"2021-07-31T20:11:25.691776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2 train\n\n\n\n\n\n\n## Step 2.1 train Self-Supervised pretraining model","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"\nunsupervised_model.fit(\n    X_train=X_pretrain_e.values,\n    eval_set=[X_pretrain_holdout.values],\n    eval_name=['test'],\n    patience=patience * 4,\n    max_epochs=max_epochs,\n    batch_size=batch_size,\n    num_workers=num_workers,\n\n)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-31T20:11:25.700594Z","iopub.execute_input":"2021-07-31T20:11:25.701162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n## Step 2.2 train TabNet regression model","metadata":{}},{"cell_type":"code","source":"targets_train = y_train.values.reshape(-1, 3)\ntargets_valid = y_holdout.values.reshape(-1, 3)\n\nregressor.fit(\n    X_train_e.values,\n    targets_train,\n    eval_metric=['rmsle', 'rmse', ],\n    eval_name=['train', 'valid'],\n    eval_set=[(X_train_e.values, targets_train),\n              (X_holdout.values, targets_valid)],\n    from_unsupervised=unsupervised_model,\n    patience=patience * 4,\n    max_epochs=max_epochs,\n    batch_size=batch_size,\n    callbacks=[early_stopping],\n\n    loss_fn=loss_fn,\n    num_workers=num_workers,\n)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3 evaluation and submission","metadata":{}},{"cell_type":"markdown","source":"## Step 3.0 predictions and submission","metadata":{}},{"cell_type":"code","source":"def predict_df(model, data):\n    res = model.predict(data.values)\n    pred_cm = pd.Series(np.clip(res[:, 0].reshape(-1, ), a_min=0, a_max=None))\n\n    pred_b = pd.Series(np.clip(res[:, 1].reshape(-1, ), a_min=0, a_max=None))\n\n    pred_no = pd.Series(np.clip(res[:, 2].reshape(-1, ), a_min=0, a_max=None))\n    df = pd.DataFrame()\n    df['target_carbon_monoxide'] = pred_cm\n    df['target_benzene'] = pred_b\n    df['target_nitrogen_oxides'] = pred_no\n    return df","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_test_sub = predict_df(regressor, test_sub)\n\npred_cm = pred_test_sub['target_carbon_monoxide']\n\npred_b = pred_test_sub['target_benzene']\n\npred_no = pred_test_sub['target_nitrogen_oxides']\n\nsample_submission['target_carbon_monoxide'] = pred_cm\nsample_submission['target_benzene'] = pred_b\nsample_submission['target_nitrogen_oxides'] = pred_no\nsample_submission.to_csv('submission.csv', index=False)\n\nsample_submission.shape","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_holdout = predict_df(regressor, X_holdout)\nvalid_cm = pred_holdout['target_carbon_monoxide']\n\nvalid_b = pred_holdout['target_benzene']\n\nvalid_no = pred_holdout['target_nitrogen_oxides']","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3.1 evaluation","metadata":{}},{"cell_type":"code","source":"graph_prediction_vs_actual(\n    valid_cm,\n    y_holdout['target_carbon_monoxide'],\n    outlier_threshold=0.5)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_prediction_vs_actual(\n    valid_b,\n    y_holdout['target_benzene'],\n    outlier_threshold=1)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_prediction_vs_actual(\n    valid_no,\n    y_holdout['target_nitrogen_oxides'],\n    outlier_threshold=30)\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nregressor.feature_importances_","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmsle = \"rmsle\"\nrmse = \"rmse\"\nfig, axs = plt.subplots(2, 1, constrained_layout=True)\nrmsle_plot = axs[0]\nrmse_plot = axs[1]\nlosses = [rmsle, rmse]\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nfor i, loss in enumerate(losses):\n    axs[i].plot(regressor.history[f'train_{loss}'])\n    axs[i].plot(regressor.history[f'valid_{loss}'])\n    axs[i].set_title(loss)\n\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thoughts, Recommendation and Credits","metadata":{}},{"cell_type":"markdown","source":"## Thoughts:\nTabNet proves to be effective and might be even better with\n hyperparameters tuning and/or further features engineering.\n## Credits:\n- Sum parts of this notebook feature engineering are taken from published notebooks, Thanks to those Kagglers (upvoted).\n- Thanks to TabNet contributors in GitHub(link at the start of the notebook).\n- Thanks to EvalML for great tool kits. [link here](https://github.com/alteryx/evalml)\n- Thanks to all upvoters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","metadata":{"pycharm":{"name":"#%% md\n"}}}]}