{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"toc\"></a>\n<h1 style=\"background-color:#fda172; font-size: 3rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center' > Tabular Playground Series July 2021: Holiday Feature </h1>\n\nIn this notebook, we will create some time-related features. Most of the features have been created in\ndifferent notebooks.[\\[2-5\\]](#time_feat_1) However, we have an additional feature called `holiday`.\n\nNote: The style of this table of contents is taken from Ref. [\\[1\\]](#notebook_toc).\n\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>Table of Contents</h2>\n\n- [Import Packages](#import_package)\n\n- [Load Data](#load_data)\n\n- [Feature Engineering](#feature_engineering)\n    - new features: hour, day, day of week, month, year, holiday\n    \n- [Effects of Holiday](#effects_of_holiday)\n    - on [temperature and humidity](#effects_on_temp_hum)\n    - on [carbon monoxide, benzene, nitrogen oxides](#effects_on_targets)\n    - on [sensor 1 to 5](#effects_on_sensors)\n    \n- [Seasonality](#seasonality)\n    - Trends for hour, day, day of week and month\n    \n- [Data Distribution](#data_distribution)    \n    - Check for normality\n    \n- [Simple Models](#simple_model)    \n    - Use Ridge and LGBM model with and without holiday feature\n    \n- [Submission](#submission)    \n     - Submit using holiday feature\n     \n- [References](#references)\n\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"import_package\"></a>\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>Import Packages</h2>\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn as sk\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom pandas.tseries.holiday import USFederalHolidayCalendar\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler\n\nfrom scipy import stats\nfrom datetime import datetime, timedelta\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\nSEED = 2021","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:28:44.635877Z","iopub.execute_input":"2021-07-04T21:28:44.636259Z","iopub.status.idle":"2021-07-04T21:28:44.64214Z","shell.execute_reply.started":"2021-07-04T21:28:44.636213Z","shell.execute_reply":"2021-07-04T21:28:44.641142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"load_data\"></a>\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>Load Data</h2>\n\nStandard procedure of loading data and quick check for basic statistics.\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/tabular-playground-series-jul-2021/train.csv')\nTARGETS = [\"target_carbon_monoxide\", \"target_benzene\", \"target_nitrogen_oxides\"]\n# Check for null columns\nnullindata = False\nfor i, x in enumerate(data.isna().sum()):\n    if x > 0:\n        print(\"{} has {} nans.\".format(columns[i], x))\nif not nullindata:\n    print(\"There is no missing data.\")\n        \n# Neat trick from https://www.kaggle.com/marcinstasko/pca-analysis-tutorial-from-scratch?scriptVersionId=61741932\ndata.describe().drop('count').T\\\n        .style.bar(subset=['mean'])\\\n        .background_gradient(subset=['std'])\\\n        .background_gradient(subset=['50%'])\\\n        .background_gradient(subset=['max'])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:28:44.643828Z","iopub.execute_input":"2021-07-04T21:28:44.644193Z","iopub.status.idle":"2021-07-04T21:28:44.734644Z","shell.execute_reply.started":"2021-07-04T21:28:44.644155Z","shell.execute_reply":"2021-07-04T21:28:44.733651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"feature_engineering\"></a>\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>Feature Engineering</h2>\n\nWe will create new features based on the `date_time` entry. \nMany notebooks have published this but do not include the `holiday` feature.\nThe holiday refers to [standard federal holidays](https://pandas.pydata.org/pandas-docs/version/0.17.1/timeseries.html#holidays-holiday-calendars)\nand weekends (Saturday and Sunday). Refer to the documentation for more info. \n\nWe could also include the traffic hours during the weekdays.\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"code","source":"# Most of the work is needed to process the date\n# Some obvious features is to determine if its a holiday\n# and the hour of the day\n# NOTE: There is only a year worth of data hence no yearly trend\ndef feature_engineering(data):\n    if \"date_time\" in data.columns:\n        data['date_time'] = pd.to_datetime(data.date_time)\n        data['day'] = data.date_time.map(lambda x: x.day)\n        data['month'] = data.date_time.map(lambda x: x.month)\n        data['year'] = data.date_time.map(lambda x: x.year)\n        data['hour'] = data.date_time.map(lambda x: x.hour)\n        data['date'] = data.date_time.map(lambda x: x.date())\n        data['dayofweek'] = data.date_time.map(lambda x: x.dayofweek)\n\n        # Holidays = weekends + federal holidays\n        cal = USFederalHolidayCalendar()\n        holidays = cal.holidays(start=data['date'].min(), end=data['date'].max()+ timedelta(days=1))\n        holidays = holidays.map(lambda x: x.date())\n        data['holiday'] = data.date.isin(holidays) |  (data.dayofweek >=5)\n\n        # Reduce the relative humidity to [0, 1]\n        data['relative_humidity'] = data['relative_humidity']/100.0\n\n        # Kelvin scales from 0 to Infty \n        # Not really useful if we do a standard scaling\n        # Maybe you could try to map [0, inf) -> [0, 1] with 1/(1+x)\n        data['deg_K'] = data['deg_C'] + 273.15\n    return data\ndata = feature_engineering(data)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:28:44.737286Z","iopub.execute_input":"2021-07-04T21:28:44.737715Z","iopub.status.idle":"2021-07-04T21:28:44.99867Z","shell.execute_reply.started":"2021-07-04T21:28:44.737676Z","shell.execute_reply":"2021-07-04T21:28:44.997735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here a the holiday used. You could also try to create a custom holiday calender.","metadata":{}},{"cell_type":"code","source":"# Here are the holidays used\nUSFederalHolidayCalendar().rules","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-04T21:28:45.000535Z","iopub.execute_input":"2021-07-04T21:28:45.000928Z","iopub.status.idle":"2021-07-04T21:28:45.007135Z","shell.execute_reply.started":"2021-07-04T21:28:45.000888Z","shell.execute_reply":"2021-07-04T21:28:45.006232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"effects_of_holiday\"></a>\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>Effects of Holiday</h2>\n\nThis section focuses on holiday and non-holiday seasonalities.\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"code","source":"def plot_trend_by(response=\"target_carbon_monoxide\", title=\"Carbon Monoxide\", grouping=\"holiday\"):\n    timeframe = [[\"hour\", \"Hour of Day\"], [\"dayofweek\", \"Day of Week\"], [\"day\", \"Day of Month\"], [\"month\", \"Month of Year\"]]\n    fig, ax = plt.subplots(4, 1, figsize=(20, 20), dpi=100, sharey=True)\n    for i in range(4):\n        ax1 = sns.violinplot(ax=ax[i], data=data, kind=\"violin\", x=timeframe[i][0], y=response, hue=grouping, split=True)\n        if i == 3:\n            ax1.set(xlabel=timeframe[i][1], ylabel=title)\n        else:\n            ax1.set(ylabel=title)\n    plt.suptitle(title, fontsize=24, y=1)\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:28:45.008705Z","iopub.execute_input":"2021-07-04T21:28:45.009119Z","iopub.status.idle":"2021-07-04T21:28:45.01885Z","shell.execute_reply.started":"2021-07-04T21:28:45.009077Z","shell.execute_reply":"2021-07-04T21:28:45.017958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"effects_on_temp_hum\"></a>\n<h3>Temperature and Humidity</h3>","metadata":{}},{"cell_type":"code","source":"titles = [r\"Temperature ($^{\\circ}$C)\", \"Relative Humidity\", \"Absolute humidity\"]\nfor ii, x in enumerate([\"deg_C\", \"relative_humidity\", \"absolute_humidity\"]):\n    plot_trend_by(response=x, title=titles[ii], grouping=\"holiday\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:28:45.020126Z","iopub.execute_input":"2021-07-04T21:28:45.020475Z","iopub.status.idle":"2021-07-04T21:28:55.490489Z","shell.execute_reply.started":"2021-07-04T21:28:45.020446Z","shell.execute_reply":"2021-07-04T21:28:55.489405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"effects_on_targets\"></a>\n<h3>Targets: Carbon monoxide, Benzene, Nitrogen oxides</h3>\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"code","source":"titles = [\"Carbon monoxide\", \"Benzene\", \"Nitrogen oxides\"]\nfor ii, x in enumerate(TARGETS):\n    plot_trend_by(response=x, title=titles[ii], grouping=\"holiday\")","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-04T21:28:55.492115Z","iopub.execute_input":"2021-07-04T21:28:55.492532Z","iopub.status.idle":"2021-07-04T21:29:06.080719Z","shell.execute_reply.started":"2021-07-04T21:28:55.492479Z","shell.execute_reply":"2021-07-04T21:29:06.079863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"effects_on_sensors\"></a>\n<h3>Sensor 1 to 5</h3>\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"code","source":"for ii in range(1, 6):\n    plot_trend_by(response=\"sensor_{}\".format(ii), title=\"Sensor {}\".format(ii), grouping=\"holiday\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:06.08184Z","iopub.execute_input":"2021-07-04T21:29:06.082295Z","iopub.status.idle":"2021-07-04T21:29:23.206434Z","shell.execute_reply.started":"2021-07-04T21:29:06.082231Z","shell.execute_reply":"2021-07-04T21:29:23.205811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"seasonality\"></a>\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>Seasonality</h2>\n\nSimilar plots as the previous section but focuses on the mean and median measures.\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"code","source":"def plot_trend(data, yval, title):\n    fig, ax = plt.subplots(2, 2, figsize=(8,8), dpi=100)\n    ax[0,0].scatter(data.hour, data[yval], s=10, alpha=0.1)\n    df = data.groupby('hour')\n    ax[0,0].plot(df[yval].mean(), ls=\"--\", c='red', label=\"mean\")\n    ax[0,0].plot(df[yval].median(), ls=\"--\", c='green', label=\"median\")\n    ax[0,0].set_title(\"Hour of day\")\n    ax[0,0].set_xlim(-1, 24)\n    \n    ax[0,1].scatter(data.dayofweek, data[yval], s=10, alpha=0.1)\n    df = data.groupby('dayofweek')\n    ax[0,1].plot(df[yval].mean(), ls=\"--\", c='red', label=\"mean\")\n    ax[0,1].plot(df[yval].median(), ls=\"--\", c='green', label=\"median\")\n    ax[0,1].set_title(\"Day of week\")\n    ax[0,1].set_xlim(-1, 7)\n\n    ax[1,0].scatter(data.day, data[yval], s=10, alpha=0.1)\n    df = data.groupby('day')\n    ax[1,0].plot(df[yval].mean(), ls=\"--\", c='red', label=\"mean\")\n    ax[1,0].plot(df[yval].median(), ls=\"--\", c='green', label=\"median\")\n    ax[1,0].set_title(\"Day of month\")\n    ax[1,0].set_xlim(0, 32)\n\n    ax[1,1].scatter(data.month, data[yval], s=10, alpha=0.1)\n    df = data.groupby('month')\n    ax[1,1].plot(df[yval].mean(), ls=\"--\", c='red', label=\"mean\")\n    ax[1,1].plot(df[yval].median(), ls=\"--\", c='green', label=\"median\")\n    ax[1,1].set_title(\"Month\")\n    ax[1,1].set_xlim(0, 13)\n    ax[0,0].legend()\n    plt.suptitle(title, fontsize=24, y=1)\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:23.20834Z","iopub.execute_input":"2021-07-04T21:29:23.208747Z","iopub.status.idle":"2021-07-04T21:29:23.22274Z","shell.execute_reply.started":"2021-07-04T21:29:23.208718Z","shell.execute_reply":"2021-07-04T21:29:23.221971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_trend(data, \"deg_C\", r\"Temperature ($^{\\circ}$C)\")\nplot_trend(data, \"relative_humidity\", \"Relative Humidity\")\nplot_trend(data, \"absolute_humidity\", \"Absolute humidity\")\n\n# Sensors\nplot_trend(data, \"sensor_1\", \"Sensor 1\")\nplot_trend(data, \"sensor_2\", \"Sensor 2\")\nplot_trend(data, \"sensor_3\", \"Sensor 3\")\nplot_trend(data, \"sensor_4\", \"Sensor 4\")\nplot_trend(data, \"sensor_5\", \"Sensor 5\")\n\n# Targets\nplot_trend(data, \"target_carbon_monoxide\", \"Target carbon monoxide\")\nplot_trend(data, \"target_benzene\", \"Target benzene\")\nplot_trend(data, \"target_nitrogen_oxides\", \"Target nitrogen oxides\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:23.224075Z","iopub.execute_input":"2021-07-04T21:29:23.224365Z","iopub.status.idle":"2021-07-04T21:29:33.033346Z","shell.execute_reply.started":"2021-07-04T21:29:23.224326Z","shell.execute_reply":"2021-07-04T21:29:33.032392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data_distribution\"></a>\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>Data Distribution</h2>\n\nStandard check for normality of data. There are notebooks which do the same thing but we will show it here\nbecause we want to do a quick comparison on a Lightgbm model with and without the `holiday` feature.\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"markdown","source":"The data is not normal except for sensor 4 (without the small peak).\nWe might need to do some boxcox when using linear regression or neural network.\n","metadata":{}},{"cell_type":"code","source":"data.drop(columns=['date_time', 'day', 'month', 'dayofweek', 'hour', 'year']).hist(figsize=(20, 20), density=True, bins=50)\nplt.suptitle(\"Raw data\", fontsize=24, y=1)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:33.034767Z","iopub.execute_input":"2021-07-04T21:29:33.035165Z","iopub.status.idle":"2021-07-04T21:29:36.170488Z","shell.execute_reply.started":"2021-07-04T21:29:33.035128Z","shell.execute_reply":"2021-07-04T21:29:36.169532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NOTE: yeo-johnson method complains about division by zero\npt = PowerTransformer(method='box-cox')\n\n# NOTE: We are dropping the deg_K since deg_C is the same as deg_C\ndata_normalized = data.drop(columns=['date_time', 'day', 'month', 'dayofweek', 'hour', 'year', 'date', 'holiday'])\ndata_normalized = pd.DataFrame(data=pt.fit_transform(data_normalized[data_normalized.columns[:-4]]), columns=data_normalized.columns[:-4])\ndata_normalized['target_carbon_monoxide'] = StandardScaler().fit_transform(np.log(data['target_carbon_monoxide']).to_numpy().reshape(-1,1))\ndata_normalized['target_benzene'] = StandardScaler().fit_transform(np.log(1+data['target_benzene']).to_numpy().reshape(-1,1))\ndata_normalized['target_nitrogen_oxides'] = StandardScaler().fit_transform(np.log(data['target_nitrogen_oxides']).to_numpy().reshape(-1,1))\ndata_normalized.hist(figsize=(20, 20), density=True, bins=50)\nplt.suptitle(\"After normalization\", fontsize=24, y=1)\nplt.tight_layout()\nplt.show()\n\n\n# Add back the missing columns\ndata_normalized[['date_time', 'day', 'month', 'dayofweek', 'hour', 'year', 'date', 'holiday']] = data[['date_time', 'day', 'month', 'dayofweek', 'hour', 'year', 'date', 'holiday']]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:36.171848Z","iopub.execute_input":"2021-07-04T21:29:36.172195Z","iopub.status.idle":"2021-07-04T21:29:39.230831Z","shell.execute_reply.started":"2021-07-04T21:29:36.172159Z","shell.execute_reply":"2021-07-04T21:29:39.229928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Double check the normality of the outputs\n# because it is crucial to have normal distribution\nfig, ax = plt.subplots(1, 3, figsize=(12, 6), dpi=100)\nfor ii, x in enumerate(['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']):\n    stats.probplot(data_normalized[x], plot=ax[ii])\n    ax[ii].set(title=x)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:39.232932Z","iopub.execute_input":"2021-07-04T21:29:39.233215Z","iopub.status.idle":"2021-07-04T21:29:39.749781Z","shell.execute_reply.started":"2021-07-04T21:29:39.23319Z","shell.execute_reply":"2021-07-04T21:29:39.748798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"simple_model\"></a>\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>Simple Models</h2>\n\nHere we will treat the problem as a regular regression problem. For each row of the table\nwe will try to predict the current targets.\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.preprocessing import OneHotEncoder, PowerTransformer, StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import mean_squared_log_error","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:39.750935Z","iopub.execute_input":"2021-07-04T21:29:39.751265Z","iopub.status.idle":"2021-07-04T21:29:39.756404Z","shell.execute_reply.started":"2021-07-04T21:29:39.751221Z","shell.execute_reply":"2021-07-04T21:29:39.755535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LogTransform(BaseEstimator, TransformerMixin):\n    def __init__(self, p1=False, **kwargs):\n        super(LogTransform, self).__init__(**kwargs)\n        self.p1 = p1\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        if self.p1:\n            return np.log(X+1)\n        return np.log(X)\n    \n    def fit_transform(self, X, y=None):\n        return self.transform(X)\n    \n    def inverse_transform(self, X):\n        if self.p1:\n            return np.exp(X)-1\n        return np.exp(X) \n\ndef get_model(estimator, num_feat, cat_feat, other_feat, with_fixed_feat=True):\n    # Given an estimator and some features,\n    # return a model and target transformers\n    \n    # Define preprocessing steps\n    # Apply box-cox to numerical input features\n    num_proc = make_pipeline(PowerTransformer(method='box-cox'))\n\n    # Apply one hot encoding to categorical input feature\n    months = [np.array([i for i in range(1, 13) ])]\n    days = [np.array([i for i in range(1, 32) ])]\n    dayofweeks = [np.array([i for i in range(0, 7) ])]\n    hours = [np.array([i for i in range(0, 24) ])]\n\n    cat_proc = make_pipeline(OneHotEncoder(sparse=False))\n    if with_fixed_feat:\n        fixed_feat = ['hour', 'day', 'dayofweek', 'month']\n        preprocessor = make_column_transformer((num_proc, num_feat),\n                                               (OneHotEncoder(sparse=False, categories=days), ['day']),\n                                               (OneHotEncoder(sparse=False, categories=dayofweeks), ['dayofweek']),\n                                               (OneHotEncoder(sparse=False, categories=months), ['month']),\n                                               (OneHotEncoder(sparse=False, categories=hours), ['hour']),\n                                               (cat_proc, cat_feat), remainder='passthrough')\n    else:\n        fixed_feat = []\n        preprocessor = make_column_transformer((num_proc, num_feat),\n                                               (cat_proc, cat_feat), remainder='passthrough')\n    \n    # Column transformer does not support inverse transform\n    co_proc = make_pipeline(LogTransform(), StandardScaler())\n    bz_proc = make_pipeline(LogTransform(p1=True), StandardScaler())\n    no_proc = make_pipeline(LogTransform(), StandardScaler())\n\n    features = num_feat + cat_feat + other_feat + fixed_feat\n    X = data[features].copy()\n    Y = data[TARGETS].copy()\n    model = make_pipeline(preprocessor, MultiOutputRegressor(estimator))\n    tgt_proc = { 'target_carbon_monoxide': co_proc,\n                 'target_benzene': bz_proc,\n                 'target_nitrogen_oxides': no_proc }\n    return model, X, Y, tgt_proc\n\ndef transform_targets(Y, tgt_proc, fit=False, forward=True):\n    # Transform the target variables\n    if fit and forward:\n        for x in TARGETS:\n            tgt_proc[x].fit(Y[x].values.reshape(-1,1))\n    \n    arr = np.zeros(Y.shape)\n    for ii, x in enumerate(TARGETS):\n        if forward:\n            arr[:,ii] = tgt_proc[x].transform(Y[x].values.reshape(-1,1)).flatten()\n        else:\n            arr[:,ii] = tgt_proc[x].inverse_transform(Y[x].values.reshape(-1,1)).flatten()\n    y_transformed = pd.DataFrame(data=arr, columns=Y.columns)\n    return y_transformed\n\ndef fit_model(model, X, Y, tgt_proc, split=True, test_size=0.3):\n    # Given data, a model and target transformer, fit the model\n    if split:\n        X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=SEED, test_size=test_size)\n        y_train_tf = transform_targets(y_train, tgt_proc, fit=True, forward=True) \n        y_test_tf = transform_targets(y_test, tgt_proc, fit=False, forward=True) \n    else:\n        X_train = X\n        y_train = Y\n        y_train_tf = transform_targets(Y, tgt_proc, fit=True, forward=True) \n        \n    model.fit(X_train, y_train_tf)\n\n    pred_train = model.predict(X_train)\n    pred_train = transform_targets(pd.DataFrame(data=pred_train, columns=TARGETS), tgt_proc, forward=False).to_numpy()\n    assert len(pred_train[pred_train<0]) == 0\n    loss_train = mean_squared_log_error(y_pred=pred_train, y_true=y_train)\n    \n    if split:\n        pred_test = model.predict(X_test)\n        pred_test = transform_targets(pd.DataFrame(data=pred_test, columns=TARGETS), tgt_proc, forward=False).to_numpy()\n        assert len(pred_test[pred_test<0]) == 0\n        loss_test = mean_squared_log_error(y_pred=pred_test, y_true=y_test)\n        print(\"Train: {:.6f}, Test: {:.6f}\".format(loss_train, loss_test))\n    else:\n        print(\"Train: {:.6f}\".format(loss_train))\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:39.757612Z","iopub.execute_input":"2021-07-04T21:29:39.757856Z","iopub.status.idle":"2021-07-04T21:29:39.783262Z","shell.execute_reply.started":"2021-07-04T21:29:39.757833Z","shell.execute_reply":"2021-07-04T21:29:39.782344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Without holiday feature","metadata":{}},{"cell_type":"code","source":"other_feat = []\ncat_feat = []\nnum_feat = ['deg_K', 'absolute_humidity', 'relative_humidity'] + ['sensor_{}'.format(ii) for ii in range(1, 6)]\n\nfor wff in [True, False]:\n    for estimator in [Ridge(alpha=60), LGBMRegressor(random_state=SEED) ]:\n        print(estimator, \"with fixed feat = \", wff)\n        model, X, Y, tgt_proc = get_model(estimator, num_feat, cat_feat, other_feat, with_fixed_feat=wff)\n        model = fit_model(model, X, Y, tgt_proc)\n        print()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:39.784381Z","iopub.execute_input":"2021-07-04T21:29:39.784692Z","iopub.status.idle":"2021-07-04T21:29:41.443071Z","shell.execute_reply.started":"2021-07-04T21:29:39.784665Z","shell.execute_reply":"2021-07-04T21:29:41.442265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With holiday feature","metadata":{}},{"cell_type":"code","source":"other_feat = []\ncat_feat = ['holiday']\nnum_feat = ['deg_K', 'absolute_humidity', 'relative_humidity'] + ['sensor_{}'.format(ii) for ii in range(1, 6)]\n\nfor wff in [True, False]:\n    for estimator in [Ridge(alpha=60), LGBMRegressor(random_state=SEED) ]:\n        print(estimator, \"with fixed feat = \", wff)\n        model, X, Y, tgt_proc = get_model(estimator, num_feat, cat_feat, other_feat, with_fixed_feat=wff)\n        model = fit_model(model, X, Y, tgt_proc)\n        print()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:41.446558Z","iopub.execute_input":"2021-07-04T21:29:41.448446Z","iopub.status.idle":"2021-07-04T21:29:43.15214Z","shell.execute_reply.started":"2021-07-04T21:29:41.448405Z","shell.execute_reply":"2021-07-04T21:29:43.151377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note**: This does not mean that holiday is useful or not useful. Do your own testing.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"submission\"></a>\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>Submission</h2>\n\n\nLet's create a submission using a simple LGBM model with holiday feature.\n\n**Note**: The last entry of our training set is the first entry of our test set. So, we will replace that first entry with our training values\n\n\nPublic score:\n\n1. With LGBM + holiday: 0.35572\n2. With Ridge + holiday: 0.30528\n\n[\\[Back to top\\]](#toc)","metadata":{}},{"cell_type":"code","source":"def submit(estimator, with_fixed_feat=True):\n    # Make prediction and save to file\n    \n    fix_feat = ['hour', 'day', 'dayofweek', 'month']\n    other_feat = []\n    cat_feat = ['holiday']\n    num_feat = ['deg_K', 'absolute_humidity', 'relative_humidity'] + ['sensor_{}'.format(ii) for ii in range(1, 6)]\n    \n    if with_fixed_feat:\n        fix_feat = ['hour', 'day', 'dayofweek', 'month']\n    else:\n        fix_feat = []\n    model, X, Y, tgt_proc = get_model(estimator, num_feat, cat_feat, other_feat, with_fixed_feat=with_fixed_feat)\n    \n    model = fit_model(model, X, Y, tgt_proc, split=False)\n\n    features = num_feat + cat_feat  + fix_feat + other_feat\n    \n    submission = pd.read_csv('/kaggle/input/tabular-playground-series-jul-2021/test.csv')\n    idx = submission.date_time.copy()\n    submission = feature_engineering(submission).copy()[features]\n    pred = model.predict(submission)\n    pred = transform_targets(pd.DataFrame(data=pred, columns=TARGETS), tgt_proc, forward=False).to_numpy()\n    assert len(pred[pred<0]) == 0\n    \n    # Note that the last entry of our training set is the first entry of our test set\n    # So, we will replace that first entry with our training values\n    pred[0,:] = Y.values[-1]\n    \n    df = pd.DataFrame(data=pred, columns=TARGETS, index=idx).reset_index(level=0)\n    df.to_csv('submission.csv', index=False)\n    return pred\n    \n# pred = submit(LGBMRegressor(random_state=SEED))\npred = submit(Ridge(alpha=60))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:43.155528Z","iopub.execute_input":"2021-07-04T21:29:43.157437Z","iopub.status.idle":"2021-07-04T21:29:43.634173Z","shell.execute_reply.started":"2021-07-04T21:29:43.157385Z","shell.execute_reply":"2021-07-04T21:29:43.633016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualizing our predictions**\n\nThe baseline here is taken from [Bojan Tunguz](#baseline).","metadata":{}},{"cell_type":"code","source":"ref = pd.read_csv('/kaggle/input/tps-07-21-simple-linear-baseline-by-tunguz/submission_rr_1.csv')\nref = ref.drop(columns=['date_time']).to_numpy()\n\nfig, ax = plt.subplots(1, 3, figsize=(12, 5), dpi=100)\nfor i in range(3):\n    ax[i].plot(pred[:,i], lw=2, c='b', label=\"This work\")\n    ax[i].plot(ref[:,i], lw=2, c='r', label=\"Baseline\", ls='--')\n    ax[i].legend()\n    ax[i].set_xlabel(\"Index\")\n    ax[i].set_title(TARGETS[i])\nplt.suptitle(\"Submission\", fontsize=24, y=1)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T21:29:43.635938Z","iopub.execute_input":"2021-07-04T21:29:43.636394Z","iopub.status.idle":"2021-07-04T21:29:44.244185Z","shell.execute_reply.started":"2021-07-04T21:29:43.63635Z","shell.execute_reply":"2021-07-04T21:29:44.243331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"references\"></a>\n<h2 style=\"background-color:#f5deb3;font-size: 2.5rem; font-weight: 700; padding: 0.5rem 0 0.5rem 0;\" align = 'center'>References</h2>\n\n[\\[Back to top\\]](#toc)\n\n<a id=\"notebook_toc\"></a><h6>1. Tommaso Guerrini's <a href=\"https://www.kaggle.com/tomwarrens/tps-july-2021-full-eda\">notebook</a> styling is good, well written. People should follow the format. Check out the notebook for more EDA.</h6>\n<a id=\"time_feat_1\"></a><h6>2. Abu Bakar's <a href=\"https://www.kaggle.com/c/tabular-playground-series-jul-2021/discussion/250630\">discussion</a> on time feature engineering. The link to his notebook in the discussion is broken.</h6>\n<a id=\"time_feat_2\"></a><h6>3. Fellipe Gomes's <a href=\"https://www.kaggle.com/c/tabular-playground-series-jul-2021/discussion/250074\">discussion</a> on time feature engineering. In the comment section, Bojan Tunguz suggested an useful feature by using features from previous time step which is common in autoregressive models.</h6>\n<a id=\"time_feat_3\"></a><h6>4. Alessandro Benetti's <a href=\"https://www.kaggle.com/alessandrobenetti/feature-engineering-automl-with-autogluon\">notebook</a> on time feature engineering and AutoML. Impressive score, which means many of us still have lots to learn to beat the machine. </h6>\n<a id=\"time_feat_4\"></a><h6>5. Rajat.P's <a href=\"https://www.kaggle.com/rajatpaliwal02/tps-july-fastai-decision-tress-random-forset\">notebook</a> on using time feature in Decision trees+Random Forest. I could not find the code for <i>add_datepart</i>.</h6>\n<a id=\"baseline\"></a><h6>6. Bojan Tunguz's <a href=\"https://www.kaggle.com/tunguz/tps-07-21-simple-linear-baseline\">notebook</a>. This is the baseline used.</h6>\n","metadata":{}}]}