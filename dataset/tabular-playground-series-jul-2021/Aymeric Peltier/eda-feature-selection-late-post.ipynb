{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-30T14:28:36.418963Z","iopub.execute_input":"2021-08-30T14:28:36.419358Z","iopub.status.idle":"2021-08-30T14:28:36.431156Z","shell.execute_reply.started":"2021-08-30T14:28:36.419322Z","shell.execute_reply":"2021-08-30T14:28:36.429849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE: this notebook was created in July and with a basic non-tuned Random Regressor achieved a RMSE of 0.18893**\n\nThe goal was just to obtain some insights when working with time series.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport pandas_profiling as pp\nimport numpy as np\nfrom datetime import date\nimport scipy.stats as sp\nfrom scipy.special import boxcox, inv_boxcox\nimport math\n\n# scikit-learn modules for feature selection and model evaluation\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_selection import RFE, SelectKBest, SelectFromModel, chi2, f_regression, mutual_info_regression\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:28:36.74234Z","iopub.execute_input":"2021-08-30T14:28:36.742709Z","iopub.status.idle":"2021-08-30T14:28:36.755472Z","shell.execute_reply.started":"2021-08-30T14:28:36.742679Z","shell.execute_reply":"2021-08-30T14:28:36.754123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-jul-2021/train.csv\")\ntrain[\"date_time\"] = pd.to_datetime(train[\"date_time\"], format=\"%Y-%m-%d %H:%M:%S\")\n\ntest = pd.read_csv(\"../input/tabular-playground-series-jul-2021/test.csv\")\ntest[\"date_time\"] = pd.to_datetime(test[\"date_time\"], format=\"%Y-%m-%d %H:%M:%S\")\n\nsubmission = pd.read_csv(\"../input/tabular-playground-series-jul-2021/sample_submission.csv\", index_col = 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:41:08.621675Z","iopub.execute_input":"2021-08-30T14:41:08.62222Z","iopub.status.idle":"2021-08-30T14:41:08.671114Z","shell.execute_reply.started":"2021-08-30T14:41:08.62218Z","shell.execute_reply":"2021-08-30T14:41:08.669976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create a Pandas Profiling report to get a quick grasp of the data\npp.ProfileReport(train)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:28:37.252736Z","iopub.execute_input":"2021-08-30T14:28:37.253112Z","iopub.status.idle":"2021-08-30T14:29:18.40799Z","shell.execute_reply.started":"2021-08-30T14:28:37.25307Z","shell.execute_reply":"2021-08-30T14:29:18.40682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dataset periods\nmin_train_date = train[\"date_time\"].dt.date.min()\nmin_test_date = test[\"date_time\"].dt.date.min()\nmax_train_date = train[\"date_time\"].dt.date.max()\nmax_test_date = test[\"date_time\"].dt.date.max()\n\nprint(f'Train dataset period: {min_train_date} to {max_train_date}')\nprint(f'Test dataset period: {min_train_date} to {max_train_date}')","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:41:11.706232Z","iopub.execute_input":"2021-08-30T14:41:11.706603Z","iopub.status.idle":"2021-08-30T14:41:11.731574Z","shell.execute_reply.started":"2021-08-30T14:41:11.706571Z","shell.execute_reply":"2021-08-30T14:41:11.730389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining the targets and original features\ntargets = train.columns[-3:]\noriginal_features = train.columns[1:-3]\ntrain_original = train.columns\n\n#Creating date features for seasonnality and investigation\nfor df in [train, test]:\n    df[\"year\"] = df[\"date_time\"].dt.year\n    df[\"month\"] = df[\"date_time\"].dt.month\n    df[\"week\"] = df[\"date_time\"].dt.weekofyear\n    df[\"day\"] = df[\"date_time\"].dt.dayofweek\n    df[\"hour\"] = df[\"date_time\"].dt.hour\n    df[\"winter\"] = df[\"month\"].isin([1, 2, 12]).map(lambda x: 1 if x==True else 0)\n    df[\"spring\"] = df[\"month\"].isin([3, 4, 5]).map(lambda x: 1 if x==True else 0)\n    df[\"summer\"] = df[\"month\"].isin([6, 7, 8]).map(lambda x: 1 if x==True else 0)\n    df[\"autumn\"] = df[\"month\"].isin([9, 10, 11]).map(lambda x: 1 if x==True else 0)\n    df[\"working_hours\"] =  df[\"hour\"].isin(np.arange(8, 21, 1)).astype(\"int\")\n    df[\"morning\"] =  df[\"hour\"].isin(np.arange(0, 12, 1)).astype(\"int\")\n    df[\"is_weekend\"] = (df[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")\n    df['day_index'] = (df['date_time'].dt.date - min_train_date).apply(lambda x: x.days)\n    \n#Possible original_features shifts (Did not take the time to fine tune those parameters, so I will let them #):\n# train[\"s1-6\"] = train[\"sensor_1\"] - train[\"sensor_1\"].shift(periods=6, fill_value=0)\n# train[\"s2-1\"] = train[\"sensor_2\"] - train[\"sensor_2\"].shift(periods=1, fill_value=0)\n# train[\"s2-6\"] = train[\"sensor_2\"] - train[\"sensor_2\"].shift(periods=6, fill_value=0)\n# train[\"s2-24\"] = train[\"sensor_2\"] - train[\"sensor_2\"].shift(periods=24, fill_value=0)\n# train[\"s2-7*24\"] = train[\"sensor_2\"] - train[\"sensor_2\"].shift(periods=7*24, fill_value=0)\n# train[\"s3-6\"] = train[\"sensor_3\"] - train[\"sensor_3\"].shift(periods=6, fill_value=0)\n# train[\"s4-6\"] = train[\"sensor_4\"] - train[\"sensor_4\"].shift(periods=6, fill_value=0)\n# train[\"s5-6\"] = train[\"sensor_5\"] - train[\"sensor_5\"].shift(periods=6, fill_value=0)\n\n\n#setting the date_time as index\ntrain.set_index(\"date_time\")\ntest.set_index(\"date_time\")","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:41:12.990461Z","iopub.execute_input":"2021-08-30T14:41:12.990911Z","iopub.status.idle":"2021-08-30T14:41:13.230107Z","shell.execute_reply.started":"2021-08-30T14:41:12.990871Z","shell.execute_reply":"2021-08-30T14:41:13.228775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's make some simple visualization to understand our data (features):\ncolors_train = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\ncolors_test = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n\ndef plot_features(df=train, df2=test):\n    \n    colors_train = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n    colors_test = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n    fig, ax = plt.subplots(len(original_features) + len(targets), 1, figsize = (len(original_features)*2,len(original_features)*6))\n    \n    for i, col in enumerate(original_features):\n        ax[i].plot(df[df.columns[0]], df[df.columns[i+1]], color=colors_train[0])\n        ax[i].plot(df2[df2.columns[0]], df2[df2.columns[i+1]], color=colors_test[1])\n        ax[i].set_title(df.columns[i+1], fontsize=15, color=\"crimson\")\n    \n    for j, col in enumerate(targets):\n        ax[j+len(original_features)].plot( df[df.columns[0]], df[df.columns[len(original_features)+1+j]], color=colors_train[0])\n        ax[j+len(original_features)].set_title(df.columns[len(original_features)+1+j], fontsize=15, color=\"crimson\")\n    \nplot_features(train, test)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:18.691766Z","iopub.execute_input":"2021-08-30T14:29:18.692157Z","iopub.status.idle":"2021-08-30T14:29:21.818359Z","shell.execute_reply.started":"2021-08-30T14:29:18.692119Z","shell.execute_reply":"2021-08-30T14:29:21.817029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's try to get more granular information about the features:\n\ngranularity = [\"month\", \"day\", \"hour\"]\n\ndef plot_targets(df=train):\n    fig, ax = plt.subplots(len(targets), 3, figsize = (len(original_features)*2,len(original_features)*2))\n    colors_train = [\"mediumblue\", \"darkorange\", \"olive\"]\n    \n    for i, col in enumerate(targets):\n        ax[0,i].plot(train.groupby(\"month\")[targets[i]].mean(), color = colors_train[i])\n        ax[0,i].set_title(f\"Month - {targets[i]}\")\n        \n        ax[1,i].plot(train.groupby(\"day\")[targets[i]].mean(), color = colors_train[i])\n        ax[1,i].set_title(f\"Day - {targets[i]}\")\n        \n        ax[2,i].plot(train.groupby(\"hour\")[targets[i]].mean(), color = colors_train[i])\n        ax[2,i].set_title(f\"Hours - {targets[i]}\")\n\nplot_targets(train)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:21.820407Z","iopub.execute_input":"2021-08-30T14:29:21.820984Z","iopub.status.idle":"2021-08-30T14:29:23.340764Z","shell.execute_reply.started":"2021-08-30T14:29:21.820925Z","shell.execute_reply":"2021-08-30T14:29:23.339328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's try to get more granular information about the variables:\n\ngranularity = [\"month\", \"day\", \"hour\"]\n\ndef plot_features2(df=train):\n    fig, ax = plt.subplots(len(original_features), 3, figsize = (len(original_features)*2,len(original_features)*4))\n    colors_train = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n    for i, time in enumerate(granularity):\n        for j, col in enumerate(original_features):\n            ax[j,i].plot(train.groupby(time)[original_features[j]].mean(), color = colors_train[i])\n            ax[j,i].set_title(f\"{granularity[i]} - {original_features[j]}\")\n        \nplot_features2(train)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:45:57.760655Z","iopub.execute_input":"2021-08-30T14:45:57.761082Z","iopub.status.idle":"2021-08-30T14:46:03.524099Z","shell.execute_reply.started":"2021-08-30T14:45:57.761047Z","shell.execute_reply":"2021-08-30T14:46:03.522776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's now have a look at the distribution of the targets & features:\n\nfig, ax = plt.subplots(3, 3,figsize=(15,15))\n\n\nfor i,col in enumerate(original_features):\n    sns.histplot(data=train[original_features[i]], kde = True,  ax = ax[i%3][i//3])\n    ax[i%3][i//3].set_title(f\"{train.columns[i+1]}\", fontsize=12, color=\"crimson\")\n    plt.subplots_adjust(hspace=0.35)\n\nfig.delaxes(ax[2,2])","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:27.265826Z","iopub.execute_input":"2021-08-30T14:29:27.266333Z","iopub.status.idle":"2021-08-30T14:29:29.834097Z","shell.execute_reply.started":"2021-08-30T14:29:27.266276Z","shell.execute_reply":"2021-08-30T14:29:29.832736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(3, 1,figsize=(10,10))\n\nfor i, col in enumerate(targets):\n    sns.histplot(train[col], kde=True, ax= ax[i])\n    ax[i].set_title(targets[i], fontsize=15, color= \"crimson\")\n    ax[i].set_xlabel('')\n    ax[i].spines.top.set_visible(False)\n    ax[i].spines.right.set_visible(False)\n    plt.subplots_adjust(hspace=0.45)\n\n    \nskew = {}\nkurtosis = {}\n\nfor i, col in enumerate(targets):\n    skew[col] = sp.skew(train[col])\n    kurtosis[col] = sp.kurtosis(train[col])\n\nax[0].text(10, 500, f\"skewness: {skew['target_carbon_monoxide']:.2f}\", fontsize=11,fontweight='light',fontfamily='serif',color='#323232')\nax[0].text(10, 450, f\"kurtosis: {kurtosis['target_carbon_monoxide']:.2f}\", fontsize=11,fontweight='light',fontfamily='serif',color='#323232')\n\nax[1].text(52, 450, f\"skewness: {skew['target_benzene']:.2f}\", fontsize=11,fontweight='light',fontfamily='serif',color='#323232')\nax[1].text(52, 400, f\"kurtosis: {kurtosis['target_benzene']:.2f}\", fontsize=11,fontweight='light',fontfamily='serif',color='#323232')\n\nax[2].text(1200, 550, f\"skewness: {skew['target_nitrogen_oxides']:.2f}\", fontsize=11,fontweight='light',fontfamily='serif',color='#323232')\nax[2].text(1200, 500, f\"kurtosis: {kurtosis['target_nitrogen_oxides']:.2f}\", fontsize=11,fontweight='light',fontfamily='serif',color='#323232')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:29.836915Z","iopub.execute_input":"2021-08-30T14:29:29.83746Z","iopub.status.idle":"2021-08-30T14:29:31.147584Z","shell.execute_reply.started":"2021-08-30T14:29:29.837417Z","shell.execute_reply":"2021-08-30T14:29:31.146021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(\"________ORIGINAL_FEATURES_________\")\n    \nfor col in original_features:\n    print(f\"skewness of {col} = {sp.skew(train[col])}\")\n    print(f\"kurtosis of {col} = {sp.kurtosis(train[col])}\")\n    print(\"---------------------------------------------\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:31.150113Z","iopub.execute_input":"2021-08-30T14:29:31.150818Z","iopub.status.idle":"2021-08-30T14:29:31.175126Z","shell.execute_reply.started":"2021-08-30T14:29:31.150757Z","shell.execute_reply":"2021-08-30T14:29:31.173702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Possible boxcox transformation to improve the RMSE\n\nlambda_monoxide = sp.boxcox(train['target_carbon_monoxide'])[1]\ntrain['target_carbon_monoxide'] = sp.boxcox(train['target_carbon_monoxide'])[0]\n\nlambda_benzene = sp.boxcox(train['target_benzene'])[1]\ntrain['target_benzene'] = sp.boxcox(train['target_benzene'])[0]\n\nlambda_nitrogen = sp.boxcox(train['target_nitrogen_oxides'])[1]\ntrain['target_nitrogen_oxides'] = sp.boxcox(train['target_nitrogen_oxides'])[0]\n\nfig, ax = plt.subplots(1, 3,figsize=(15,2))\nfor i in range(3):\n    sns.histplot(train[targets[i]], kde=True, ax= ax[i])\n    ax[i].set_title(targets[i], fontsize=15, color= \"crimson\")\n    \ndisplay(\"________TARGETS_________\")\nfor col in targets:\n    print(f\"skewness of {col} = {sp.skew(train[col])}\")\n    print(f\"kurtosis of {col} = {sp.kurtosis(train[col])}\")\n    print(\"---------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:41:38.103865Z","iopub.execute_input":"2021-08-30T14:41:38.104271Z","iopub.status.idle":"2021-08-30T14:41:38.208766Z","shell.execute_reply.started":"2021-08-30T14:41:38.10423Z","shell.execute_reply":"2021-08-30T14:41:38.207442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\ntrain_features_corr = train[train_original].corr()\nsns.heatmap(train_features_corr , annot=True, annot_kws={\"weight\": \"bold\", \"fontsize\":10}, cmap=\"coolwarm\",mask= np.triu(train_features_corr))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:31.183358Z","iopub.execute_input":"2021-08-30T14:29:31.183692Z","iopub.status.idle":"2021-08-30T14:29:31.983164Z","shell.execute_reply.started":"2021-08-30T14:29:31.183661Z","shell.execute_reply":"2021-08-30T14:29:31.981888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adding features based on other works on air qualities:\ntrain ['Dew_point'] = train ['deg_C'].apply (lambda x: (17.27 * x) / (237.7 + x)) + train ['absolute_humidity'].apply (lambda x: math.log (x) )\ntrain ['Partial_pressure'] = (train ['deg_C'].apply (lambda x: (237.7 + x) * 286.8) * train ['absolute_humidity']) / 100000\ntrain ['Saturated_wvd'] = (train ['absolute_humidity'] * 100) / train ['relative_humidity']\n\ntest ['Dew_point'] = test ['deg_C'].apply (lambda x: (17.27 * x) / (237.7 + x)) + test ['absolute_humidity'].apply (lambda x: math.log (x) )\ntest ['Partial_pressure'] = (test ['deg_C'].apply (lambda x: (237.7 + x) * 286.8) * test ['absolute_humidity']) / 100000\ntest ['Saturated_wvd'] = (test ['absolute_humidity'] * 100) / test ['relative_humidity']","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:31.984734Z","iopub.execute_input":"2021-08-30T14:29:31.985025Z","iopub.status.idle":"2021-08-30T14:29:32.019301Z","shell.execute_reply.started":"2021-08-30T14:29:31.984997Z","shell.execute_reply":"2021-08-30T14:29:32.017954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.heatmap(train.corr() , annot=True, annot_kws={\"weight\": \"bold\", \"fontsize\":10}, cmap=\"coolwarm\",mask= np.triu(train.corr()))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:32.021675Z","iopub.execute_input":"2021-08-30T14:29:32.022333Z","iopub.status.idle":"2021-08-30T14:29:34.894498Z","shell.execute_reply.started":"2021-08-30T14:29:32.02228Z","shell.execute_reply":"2021-08-30T14:29:34.892864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's first try to predict the benzene, considering how highly correlated it is to sensor_2:\n\ntrain_benzene_corr  = train.corr()['target_benzene'].sort_values(ascending=False)\ntrain_benzene_corr","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:34.896488Z","iopub.execute_input":"2021-08-30T14:29:34.897072Z","iopub.status.idle":"2021-08-30T14:29:34.92729Z","shell.execute_reply.started":"2021-08-30T14:29:34.897019Z","shell.execute_reply":"2021-08-30T14:29:34.92582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's quickly fit a model to check how accurate we are:\ndef Select_features(X, Y, n_features):\n    \n    # Split train and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state = 123)\n    \n    #Scaling\n    scaler = StandardScaler().fit(X_train)\n    X_train_scaled = scaler.transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Fit to scaled data, then transform it:\n    selector = SelectKBest(mutual_info_regression, k=n_features)\n    X_new = selector.fit_transform(X_train_scaled, Y_train)\n    \n    # Drop the target variable\n    feature_idx = selector.get_support()\n    feature_names = train.drop(columns=['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides','date_time']).columns[feature_idx]\n\n    \n    return feature_names","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:34.940601Z","iopub.execute_input":"2021-08-30T14:29:34.941085Z","iopub.status.idle":"2021-08-30T14:29:34.957584Z","shell.execute_reply.started":"2021-08-30T14:29:34.941035Z","shell.execute_reply":"2021-08-30T14:29:34.956119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's quickly fit a model to check how accurate we are:\n\ndef fit_model(X, Y):\n    '''Use a RandomForestRegressor for this problem.'''\n    \n    # define the model to use\n    model = RandomForestRegressor(random_state=2)\n    \n    # Train the model\n    model.fit(X, Y)\n    \n    return model\n\ndef train_and_get_metrics(X, Y):\n    '''Train a Random Forest Regressor and get evaluation metrics'''\n    \n    # Split train and test sets\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state = 12)\n\n    # All features of dataset are float values. You normalize all features of the train and test dataset here.\n    scaler = StandardScaler().fit(X_train)\n    X_train_scaled = scaler.transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\n    # Call the fit model function to train the model on the normalized features and the diagnosis values\n    model = fit_model(X_train_scaled, Y_train)\n\n    # Make predictions on test dataset and calculate metrics.\n    y_predict_r = model.predict(X_test_scaled)\n    score = mean_squared_error(Y_test, y_predict_r)\n    \n\n    return score, y_predict_r\n\ndef evaluate_model_on_features(X, Y):\n    '''Train model and display evaluation metrics.'''\n    \n    # Train the model, predict values and get metrics\n    score, y_predict_r = train_and_get_metrics(X, Y)\n\n    # Construct a dataframe to display metrics.\n    display_df = pd.DataFrame([score], columns=[\"MSE\"])\n    \n    return display_df, y_predict_r\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:29:34.959309Z","iopub.execute_input":"2021-08-30T14:29:34.959679Z","iopub.status.idle":"2021-08-30T14:29:34.97302Z","shell.execute_reply.started":"2021-08-30T14:29:34.959644Z","shell.execute_reply":"2021-08-30T14:29:34.971821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Making different test with different number of predictors:\n\n#Split dataframe for feature selection:\nX = train.drop(columns=['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides','date_time'])\nY = train['target_benzene']\n\nall_features_eval_df, y_predict_r = evaluate_model_on_features(X, Y)\nall_features_eval_df.index = ['All_features']\nresults = all_features_eval_df\n\nA1 = Select_features(X, Y, 1)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A1], Y)\nKbest_features_eval_df.index = ['Kbest_features_1']\nresults = results.append(Kbest_features_eval_df)\n\nA10 = Select_features(X, Y, 10)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A10], Y)\nKbest_features_eval_df.index = ['Kbest_features_10']\nresults = results.append(Kbest_features_eval_df)\n\nA18 = Select_features(X, Y, 18)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A18], Y)\nKbest_features_eval_df.index = ['Kbest_features_18']\nresults = results.append(Kbest_features_eval_df)\n\nA20 = Select_features(X, Y, 20)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A20], Y)\nKbest_features_eval_df.index = ['Kbest_features_20']\nresults = results.append(Kbest_features_eval_df)\n\n# Check the metrics\nresults.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:35:26.067374Z","iopub.execute_input":"2021-08-30T14:35:26.067784Z","iopub.status.idle":"2021-08-30T14:35:54.290435Z","shell.execute_reply.started":"2021-08-30T14:35:26.067749Z","shell.execute_reply":"2021-08-30T14:35:54.289384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Making different test with different number of predictors:\n\n#Split dataframe for feature selection:\nX = train.drop(columns=['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides','date_time'])\nY = train['target_carbon_monoxide']\n\nall_features_eval_df, y_predict_r = evaluate_model_on_features(X, Y)\nall_features_eval_df.index = ['All_features']\nresults = all_features_eval_df\n\nA1 = Select_features(X, Y, 1)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A1], Y)\nKbest_features_eval_df.index = ['Kbest_features_1']\nresults = results.append(Kbest_features_eval_df)\n\nA10 = Select_features(X, Y, 10)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A10], Y)\nKbest_features_eval_df.index = ['Kbest_features_10']\nresults = results.append(Kbest_features_eval_df)\n\nA18 = Select_features(X, Y, 18)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A18], Y)\nKbest_features_eval_df.index = ['Kbest_features_18']\nresults = results.append(Kbest_features_eval_df)\n\nA20 = Select_features(X, Y, 20)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A20], Y)\nKbest_features_eval_df.index = ['Kbest_features_20']\nresults = results.append(Kbest_features_eval_df)\n\n# Check the metrics\nresults.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:37:24.455477Z","iopub.execute_input":"2021-08-30T14:37:24.456163Z","iopub.status.idle":"2021-08-30T14:37:50.234412Z","shell.execute_reply.started":"2021-08-30T14:37:24.456094Z","shell.execute_reply":"2021-08-30T14:37:50.233089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Making different test with different number of predictors:\n\n#Split dataframe for feature selection:\nX = train.drop(columns=['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides','date_time'])\nY = train['target_nitrogen_oxides']\n\nall_features_eval_df, y_predict_r = evaluate_model_on_features(X, Y)\nall_features_eval_df.index = ['All_features']\nresults = all_features_eval_df\n\nA1 = Select_features(X, Y, 1)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A1], Y)\nKbest_features_eval_df.index = ['Kbest_features_1']\nresults = results.append(Kbest_features_eval_df)\n\nA10 = Select_features(X, Y, 10)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A10], Y)\nKbest_features_eval_df.index = ['Kbest_features_10']\nresults = results.append(Kbest_features_eval_df)\n\nA18 = Select_features(X, Y, 18)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A18], Y)\nKbest_features_eval_df.index = ['Kbest_features_18']\nresults = results.append(Kbest_features_eval_df)\n\nA20 = Select_features(X, Y, 20)\nKbest_features_eval_df, y_predict_r = evaluate_model_on_features(X[A20], Y)\nKbest_features_eval_df.index = ['Kbest_features_20']\nresults = results.append(Kbest_features_eval_df)\n\n# Check the metrics\nresults.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:37:50.2366Z","iopub.execute_input":"2021-08-30T14:37:50.237634Z","iopub.status.idle":"2021-08-30T14:38:20.132193Z","shell.execute_reply.started":"2021-08-30T14:37:50.237563Z","shell.execute_reply":"2021-08-30T14:38:20.131349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on this simple EDA and formulas, it is quite convenient to look out for better combination of features to integrate in the model (especially the time shifts)","metadata":{}}]}