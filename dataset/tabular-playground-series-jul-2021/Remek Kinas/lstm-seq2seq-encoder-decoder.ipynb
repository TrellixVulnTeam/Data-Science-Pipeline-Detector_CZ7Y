{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## MULTIVARIATE LSTM Sequnece-to-Sequence Encoder-Decoder in Keras\n\nThis notebook is just starter created in few minutes to illustrate:\n- how to implement multivariate timeseries NN approach in Keras using LSTM (here you can examine many different solutions later - so follow this notebook)\n- create function to prepare data - now you can use it as a single (one y value) or multiple steps (many following y values)\n- illustrate how to develop and test simple NN with sliding window\n\nI think that this is great example to use Keras Tuner and find best parameters (length of sliding window, NN parameters etc.)","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-warning\">\n    <strong>Implemented NN architecture so far as an example:</strong>\n    <ul>\n        <li>LSTM -> Encoder-Decoder -> LSTM -> Dense</li>\n        <li>CONV1D -> Encoder-Decoder -> LSTM -> Dense</li>\n        <li>ConvLSTM2D -> Encoder-Decoder -> LSTM -> Dense</li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-info\">\nThis is first step. Notebook is under development but if you want to learn how to deal with timeseries using NN or like ideas please follow this notebook.\n<strong><br>Currently we do not focus on submission ... we will do it after some additional improvements.</strong>\n</div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import RepeatVector\nfrom keras.layers import TimeDistributed\nfrom keras.layers import Conv1D, MaxPooling1D, Flatten, ConvLSTM2D, Dropout\nimport tensorflow.keras.backend as K\n\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:45:15.949877Z","iopub.execute_input":"2021-07-08T10:45:15.950314Z","iopub.status.idle":"2021-07-08T10:45:15.961737Z","shell.execute_reply.started":"2021-07-08T10:45:15.950258Z","shell.execute_reply":"2021-07-08T10:45:15.960327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_steps = 8 # we use 12h window\nn_lookup = 1 # predict series of 4 values in time t1, t2, t3, t4","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:36:09.840496Z","iopub.execute_input":"2021-07-08T10:36:09.840946Z","iopub.status.idle":"2021-07-08T10:36:09.846081Z","shell.execute_reply.started":"2021-07-08T10:36:09.840908Z","shell.execute_reply":"2021-07-08T10:36:09.844694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/tabular-playground-series-jul-2021/train.csv\")\ndf_test = pd.read_csv(\"../input/tabular-playground-series-jul-2021/test.csv\")\ndf_sub = pd.read_csv(\"../input/tabular-playground-series-jul-2021/sample_submission.csv\")\n\nprint(df_test.shape)\nprint(df_sub.shape)\n\nfeatures = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']\ntargets = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']\ntargets_values = np.log1p(df_train[targets]).values\n\n\ndf_test = pd.concat([df_train[len(df_train)-n_steps-1:len(df_train)-1].drop(targets , axis = 1), df_test])\n\ndf_all = pd.concat([df_train.drop(targets , axis = 1), df_test])\n\ndf_all['date_time'] = pd.to_datetime(df_all['date_time'])\n\n\ndf_train.set_index('date_time', inplace=True)\ndf_test.set_index('date_time', inplace=True)\nprint(df_test.shape)\nprint(df_all.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:36:11.428725Z","iopub.execute_input":"2021-07-08T10:36:11.429122Z","iopub.status.idle":"2021-07-08T10:36:11.485277Z","shell.execute_reply.started":"2021-07-08T10:36:11.429082Z","shell.execute_reply":"2021-07-08T10:36:11.483949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head(15)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:16:14.539602Z","iopub.execute_input":"2021-07-08T10:16:14.540045Z","iopub.status.idle":"2021-07-08T10:16:14.572783Z","shell.execute_reply.started":"2021-07-08T10:16:14.540013Z","shell.execute_reply":"2021-07-08T10:16:14.571373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interested in sensor data? Probably ... This is my research ...\n\n- Sensor_1 - (tin oxide) hourly averaged sensor response (nominally CO targeted) \n- Sensor_2 - (titania) hourly averaged sensor response (nominally NMHC targeted) \n- Sensor_3 - (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) \n- Sensor_4 - (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted) \n- Sensor_5 - (indium oxide) hourly averaged sensor response (nominally O3 targeted) ","metadata":{}},{"cell_type":"code","source":"def plot_sensor(name):\n    \n    plt.figure(figsize=(16,4))\n\n    plt.plot(df_train.index, df_train[name], label='train')\n    plt.plot(df_test.index, df_test[name], label='test')\n    plt.ylabel(name)\n    plt.legend()\n    plt.show()\n\nfor col in df_train[features].columns:\n    plot_sensor(col)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:16:17.677568Z","iopub.execute_input":"2021-07-08T10:16:17.677993Z","iopub.status.idle":"2021-07-08T10:16:29.820166Z","shell.execute_reply.started":"2021-07-08T10:16:17.677961Z","shell.execute_reply":"2021-07-08T10:16:29.816451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_autocor(name, df):\n    \n    plt.figure(figsize=(16,4))    \n    timeLags = np.arange(1,2400)\n    plt.plot([df[name].autocorr(dt) for dt in timeLags])\n    plt.title(name); plt.ylabel('autocorr'); plt.xlabel('time lags')\n    plt.show()\n\nfor col in df_train[features].columns:\n    plot_autocor(col, df_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:16:34.193273Z","iopub.execute_input":"2021-07-08T10:16:34.193695Z","iopub.status.idle":"2021-07-08T10:16:47.386792Z","shell.execute_reply.started":"2021-07-08T10:16:34.193663Z","shell.execute_reply":"2021-07-08T10:16:47.385461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### NEW FEATURES","metadata":{}},{"cell_type":"code","source":"def cycle_sin_cos_coder(data, cols):\n    for col in cols:\n        data[col + '_s'] = np.sin(2 * np.pi * data[col]/data[col].max())\n        data[col + '_c'] = np.cos(2 * np.pi * data[col]/data[col].max())\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:37:00.402946Z","iopub.execute_input":"2021-07-08T10:37:00.403388Z","iopub.status.idle":"2021-07-08T10:37:00.412211Z","shell.execute_reply.started":"2021-07-08T10:37:00.403355Z","shell.execute_reply":"2021-07-08T10:37:00.408573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all['month'] = df_all['date_time'].dt.month\ndf_all['day'] = df_all['date_time'].dt.day\ndf_all['hour'] = df_all['date_time'].dt.hour\n\ndf_all = cycle_sin_cos_coder(df_all, ['month','day','hour'])\ndf_all.drop(['month','day','hour'], axis=1, inplace=True)\ndf_all.set_index('date_time', inplace=True)\n\nprint(df_all.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:37:01.988484Z","iopub.execute_input":"2021-07-08T10:37:01.988945Z","iopub.status.idle":"2021-07-08T10:37:02.020264Z","shell.execute_reply.started":"2021-07-08T10:37:01.988912Z","shell.execute_reply":"2021-07-08T10:37:02.018846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:54:12.712649Z","iopub.execute_input":"2021-07-05T20:54:12.712988Z","iopub.status.idle":"2021-07-05T20:54:12.734507Z","shell.execute_reply.started":"2021-07-05T20:54:12.712955Z","shell.execute_reply":"2021-07-05T20:54:12.733638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_all[:len(df_train)]\n\ndf_train [targets] = targets_values\ndf_test = df_all[len(df_train):]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:37:06.767624Z","iopub.execute_input":"2021-07-08T10:37:06.768074Z","iopub.status.idle":"2021-07-08T10:37:06.779813Z","shell.execute_reply.started":"2021-07-08T10:37:06.768042Z","shell.execute_reply":"2021-07-08T10:37:06.778442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:54:12.754283Z","iopub.execute_input":"2021-07-05T20:54:12.754699Z","iopub.status.idle":"2021-07-05T20:54:12.786605Z","shell.execute_reply.started":"2021-07-05T20:54:12.754655Z","shell.execute_reply":"2021-07-05T20:54:12.78567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(df_train, shuffle = False, train_size=0.8)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:37:10.20918Z","iopub.execute_input":"2021-07-08T10:37:10.209528Z","iopub.status.idle":"2021-07-08T10:37:10.216324Z","shell.execute_reply.started":"2021-07-08T10:37:10.209497Z","shell.execute_reply":"2021-07-08T10:37:10.215196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### FEATURE TRANSFORMATION","metadata":{}},{"cell_type":"code","source":"for i in train[features].columns:\n    scaler = MinMaxScaler(feature_range=(-1,1))\n    \n    s_train = scaler.fit_transform(train[i].values.reshape(-1,1))\n    s_test = scaler.transform(test[i].values.reshape(-1,1))\n    s_df_test = scaler.transform(df_test[i].values.reshape(-1,1))\n    \n    s_train = np.reshape(s_train,len(s_train))\n    s_test = np.reshape(s_test,len(s_test))\n    s_df_test = np.reshape(s_df_test,len(s_df_test))\n\n    train[i] = s_train\n    test[i] = s_test\n    df_test[i] = s_df_test","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:37:13.196662Z","iopub.execute_input":"2021-07-08T10:37:13.197066Z","iopub.status.idle":"2021-07-08T10:37:13.221179Z","shell.execute_reply.started":"2021-07-08T10:37:13.197026Z","shell.execute_reply":"2021-07-08T10:37:13.220074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(n_steps+1)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:54:12.815803Z","iopub.execute_input":"2021-07-05T20:54:12.816152Z","iopub.status.idle":"2021-07-05T20:54:12.8429Z","shell.execute_reply.started":"2021-07-05T20:54:12.816108Z","shell.execute_reply":"2021-07-05T20:54:12.84192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SLIDING WINDOW \n\nThis function split data using SLIDING WINDOW approach:\n- n_steps - this is number of steps we want to look into to predict output (one y or series of y)\n- n_lookup - number of steps to predict ","metadata":{}},{"cell_type":"code","source":"def split_sequences(Xsequences, ysequences, n_steps = 6, n_out = 1):\n    X, y = list(), list()\n\n    for i in range(len(Xsequences)):\n        end_index = i + n_steps\n        out_end_index = end_index + n_out\n        \n        if out_end_index > len(Xsequences):\n            break\n        \n        seq_x = Xsequences.iloc[i : end_index, :] \n        if isinstance(ysequences, pd.core.series.Series):\n            seq_y = ysequences.iloc[end_index : out_end_index]\n            y.append(seq_y)\n\n        X.append(seq_x)\n        \n    return array(X), array(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:37:16.341294Z","iopub.execute_input":"2021-07-08T10:37:16.341695Z","iopub.status.idle":"2021-07-08T10:37:16.349362Z","shell.execute_reply.started":"2021-07-08T10:37:16.341665Z","shell.execute_reply":"2021-07-08T10:37:16.347745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrain_seq_tcm, ytrain_seq_tcm = split_sequences(train.drop(targets, axis = 1), train['target_carbon_monoxide'], n_steps, n_lookup)\nXtest_seq_tcm, ytest_seq_tcm = split_sequences(test.drop(targets, axis = 1), test['target_carbon_monoxide'], n_steps, n_lookup)\n\nXtrain_seq_tb, ytrain_seq_tb = split_sequences(train.drop(targets, axis = 1), train['target_benzene'], n_steps, n_lookup)\nXtest_seq_tb, ytest_seq_tb = split_sequences(test.drop(targets, axis = 1), test['target_benzene'], n_steps, n_lookup)\n\nXtrain_seq_tno, ytrain_seq_tno = split_sequences(train.drop(targets, axis = 1), train['target_nitrogen_oxides'], n_steps, n_lookup)\nXtest_seq_tno, ytest_seq_tno = split_sequences(test.drop(targets, axis = 1), test['target_nitrogen_oxides'], n_steps, n_lookup)\n\nn_features = Xtrain_seq_tcm.shape[2]\n\nprint(Xtrain_seq_tcm.shape, ytrain_seq_tcm.shape)\nprint(Xtest_seq_tcm.shape, ytest_seq_tcm.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:37:19.329661Z","iopub.execute_input":"2021-07-08T10:37:19.330056Z","iopub.status.idle":"2021-07-08T10:37:28.275007Z","shell.execute_reply.started":"2021-07-08T10:37:19.330021Z","shell.execute_reply":"2021-07-08T10:37:28.273814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(suppress=True, linewidth=255)\n\nXtest_sub, _ = split_sequences(df_test, [], n_steps, n_lookup)\nprint(Xtest_sub[0])\nprint(Xtest_sub.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:37:35.847402Z","iopub.execute_input":"2021-07-08T10:37:35.847882Z","iopub.status.idle":"2021-07-08T10:37:36.250472Z","shell.execute_reply.started":"2021-07-08T10:37:35.84785Z","shell.execute_reply":"2021-07-08T10:37:36.249223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(suppress=True, linewidth=255)\n\nnum_seq_show = 3\n\nfor i in range(num_seq_show):\n    print(f'X{i}\\n {Xtrain_seq_tcm[i]}')\n    print(f'y{i}\\n {ytrain_seq_tcm[i]} \\n\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:17:23.303516Z","iopub.execute_input":"2021-07-08T10:17:23.303954Z","iopub.status.idle":"2021-07-08T10:17:23.319164Z","shell.execute_reply.started":"2021-07-08T10:17:23.303923Z","shell.execute_reply":"2021-07-08T10:17:23.317601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SIMPLE NN MODEL\nWe use LSTM (but there is more possibilities to examine). I decided to create Endocer-Decoder (RepeatVector) architecture since we are able to predict more steps in future.","metadata":{}},{"cell_type":"code","source":"def rmsle(y_true, y_pred):\n    msle = tf.keras.losses.MeanSquaredLogarithmicError()\n    return K.sqrt(msle(y_true, y_pred)) ","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:17:26.478222Z","iopub.execute_input":"2021-07-08T10:17:26.478601Z","iopub.status.idle":"2021-07-08T10:17:26.487651Z","shell.execute_reply.started":"2021-07-08T10:17:26.47857Z","shell.execute_reply":"2021-07-08T10:17:26.486323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### A. LSTM -> Encoder-Decoder -> LSTM -> Dense","metadata":{}},{"cell_type":"code","source":"model_tcm = Sequential()\nmodel_tcm.add(LSTM(100, activation='tanh', input_shape=(n_steps, n_features)))\nmodel_tcm.add(RepeatVector(n_lookup))\nmodel_tcm.add(LSTM(100, activation='tanh', return_sequences=True))\nmodel_tcm.add(TimeDistributed(Dense(1)))\nmodel_tcm.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.02), loss= rmsle)\n\nmodel_tcm.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:37:51.681909Z","iopub.execute_input":"2021-07-08T10:37:51.682309Z","iopub.status.idle":"2021-07-08T10:37:52.265801Z","shell.execute_reply.started":"2021-07-08T10:37:51.682277Z","shell.execute_reply":"2021-07-08T10:37:52.263737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model_tcm)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:17:33.990351Z","iopub.execute_input":"2021-07-08T10:17:33.990795Z","iopub.status.idle":"2021-07-08T10:17:34.503919Z","shell.execute_reply.started":"2021-07-08T10:17:33.990749Z","shell.execute_reply":"2021-07-08T10:17:34.502799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(patience=10, verbose=0, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True)\nred_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n\ndef plot_model_learning(history):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:17:36.986611Z","iopub.execute_input":"2021-07-08T10:17:36.987056Z","iopub.status.idle":"2021-07-08T10:17:36.997569Z","shell.execute_reply.started":"2021-07-08T10:17:36.987018Z","shell.execute_reply":"2021-07-08T10:17:36.99518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_SAMPLE = 20\nyhat_tcm = np.zeros((Xtest_sub.shape[0],1))\n\nfor samples in tqdm(range(N_SAMPLE)):\n    tf.keras.backend.clear_session()\n    \n    model_tcm.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.02), loss= rmsle)\n    history_tcm = model_tcm.fit(Xtrain_seq_tcm, ytrain_seq_tcm, \n                                validation_data = (Xtest_seq_tcm, ytest_seq_tcm), \n                                epochs=100, \n                                verbose = 0,\n                                batch_size = 16, \n                                callbacks=[es, red_lr])\n    \n  \n    yhat_tcm += np.expm1(model_tcm.predict(Xtest_sub)).reshape(-1,1)\n\nyhat_tcm = yhat_tcm / N_SAMPLE","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:47:43.502656Z","iopub.execute_input":"2021-07-08T10:47:43.50306Z","iopub.status.idle":"2021-07-08T10:56:24.726651Z","shell.execute_reply.started":"2021-07-08T10:47:43.503028Z","shell.execute_reply":"2021-07-08T10:56:24.725447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat_tcm","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:56:33.102751Z","iopub.execute_input":"2021-07-08T10:56:33.103111Z","iopub.status.idle":"2021-07-08T10:56:33.109582Z","shell.execute_reply.started":"2021-07-08T10:56:33.103081Z","shell.execute_reply":"2021-07-08T10:56:33.108405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### B. ConvLSTM2D -> Encoder-Decoder -> LSTM -> Dense","metadata":{}},{"cell_type":"code","source":"n_sub_steps = 4\nn_length = 2\n\nmodel_tb = Sequential()\nmodel_tb.add(ConvLSTM2D(64, (1,2), activation='relu', input_shape=(n_sub_steps, 1, n_length, n_features)))\nmodel_tb.add(Flatten())\nmodel_tb.add(RepeatVector(n_lookup))\nmodel_tb.add(LSTM(200, activation='relu', return_sequences=True))\nmodel_tb.add(TimeDistributed(Dense(100, activation='relu')))\nmodel_tb.add(TimeDistributed(Dense(1)))\n\nmodel_tb.compile(loss='mse', optimizer='adam')\n\nmodel_tb.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:58:10.67879Z","iopub.execute_input":"2021-07-08T10:58:10.679165Z","iopub.status.idle":"2021-07-08T10:58:10.951139Z","shell.execute_reply.started":"2021-07-08T10:58:10.679135Z","shell.execute_reply":"2021-07-08T10:58:10.950027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model_tb)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:54:52.995493Z","iopub.execute_input":"2021-07-05T20:54:52.995908Z","iopub.status.idle":"2021-07-05T20:54:53.151467Z","shell.execute_reply.started":"2021-07-05T20:54:52.995867Z","shell.execute_reply":"2021-07-05T20:54:53.150577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrain_seq_tb = Xtrain_seq_tb.reshape((Xtrain_seq_tb.shape[0], n_sub_steps, 1, n_length, n_features))\nXtest_seq_tb = Xtest_seq_tb.reshape((Xtest_seq_tb.shape[0], n_sub_steps , 1, n_length, n_features))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:58:15.0729Z","iopub.execute_input":"2021-07-08T10:58:15.073243Z","iopub.status.idle":"2021-07-08T10:58:15.080742Z","shell.execute_reply.started":"2021-07-08T10:58:15.073213Z","shell.execute_reply":"2021-07-08T10:58:15.079528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_SAMPLE = 20\nyhat_tb = np.zeros((Xtest_sub.shape[0],1))\n\nfor samples in tqdm(range(N_SAMPLE)):\n    tf.keras.backend.clear_session()\n    \n    model_tb.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.02), loss= rmsle)\n    history_tb = model_tb.fit(Xtrain_seq_tb, ytrain_seq_tb, \n                          validation_data = (Xtest_seq_tb, ytest_seq_tb), \n                          epochs=100,  \n                          batch_size = 16, \n                          verbose = 0, \n                          callbacks=[es, red_lr])\n  \n    yhat_tb += np.expm1(model_tb.predict(Xtest_sub.reshape(Xtest_sub.shape[0], n_sub_steps, 1, n_length, n_features))).reshape(-1,1)\n\nyhat_tb = yhat_tb / N_SAMPLE","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:58:26.105324Z","iopub.execute_input":"2021-07-08T10:58:26.105702Z","iopub.status.idle":"2021-07-08T11:22:55.907177Z","shell.execute_reply.started":"2021-07-08T10:58:26.105669Z","shell.execute_reply":"2021-07-08T11:22:55.906027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CONV1D -> Encoder-Decoder -> LSTM -> Dense","metadata":{}},{"cell_type":"code","source":"model_tno = Sequential()\nmodel_tno.add(Conv1D(64, 3, activation='relu', input_shape=(n_steps, n_features)))\nmodel_tno.add(Conv1D(64, 3, activation='relu'))\nmodel_tno.add(MaxPooling1D())\nmodel_tno.add(Flatten())\nmodel_tno.add(RepeatVector(n_lookup))\nmodel_tno.add(LSTM(100, activation='relu', return_sequences=True))\nmodel_tno.add(TimeDistributed(Dense(64, activation='relu')))\nmodel_tno.add(TimeDistributed(Dense(1)))\n\nmodel_tno.compile(loss='mse', optimizer='adam')\n\nmodel_tno.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:56:24.058528Z","iopub.execute_input":"2021-07-05T20:56:24.059Z","iopub.status.idle":"2021-07-05T20:56:24.198987Z","shell.execute_reply.started":"2021-07-05T20:56:24.058958Z","shell.execute_reply":"2021-07-05T20:56:24.198191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model_tno)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:56:24.200267Z","iopub.execute_input":"2021-07-05T20:56:24.2006Z","iopub.status.idle":"2021-07-05T20:56:24.372607Z","shell.execute_reply.started":"2021-07-05T20:56:24.200562Z","shell.execute_reply":"2021-07-05T20:56:24.371727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_SAMPLE = 20\nyhat_tno = np.zeros((Xtest_sub.shape[0],1))\n\nfor samples in tqdm(range(N_SAMPLE)):\n    tf.keras.backend.clear_session()\n    \n    model_tno.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.02), loss= rmsle)\n    history_tno = model_tno.fit(Xtrain_seq_tno, ytrain_seq_tno, \n                            validation_data = (Xtest_seq_tno, ytest_seq_tno), \n                            epochs=100, \n                            verbose = 0, \n                            batch_size = 16, \n                            callbacks=[es, red_lr])\n    \n  \n    yhat_tno += np.expm1(model_tno.predict(Xtest_sub)).reshape(-1,1)\n\nyhat_tno = yhat_tno / N_SAMPLE","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:56:24.374212Z","iopub.execute_input":"2021-07-05T20:56:24.374529Z","iopub.status.idle":"2021-07-05T20:56:42.628775Z","shell.execute_reply.started":"2021-07-05T20:56:24.374499Z","shell.execute_reply":"2021-07-05T20:56:42.627962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SUBMISSION","metadata":{}},{"cell_type":"code","source":"df_sub['target_carbon_monoxide'] =  yhat_tcm\ndf_sub['target_benzene'] = yhat_tb\ndf_sub['target_nitrogen_oxides'] = yhat_tno\n\ndf_sub.to_csv('lstm_001.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:56:43.251645Z","iopub.execute_input":"2021-07-05T20:56:43.252014Z","iopub.status.idle":"2021-07-05T20:56:43.548317Z","shell.execute_reply.started":"2021-07-05T20:56:43.251977Z","shell.execute_reply":"2021-07-05T20:56:43.547351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:56:43.54957Z","iopub.execute_input":"2021-07-05T20:56:43.54994Z","iopub.status.idle":"2021-07-05T20:56:43.570872Z","shell.execute_reply.started":"2021-07-05T20:56:43.549902Z","shell.execute_reply":"2021-07-05T20:56:43.56997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook is under devleopment. If you like ideas please vote and follow - I will develp this notebook in next days.","metadata":{}}]}