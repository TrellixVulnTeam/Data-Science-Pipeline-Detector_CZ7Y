{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-02T22:49:40.728614Z","iopub.execute_input":"2021-07-02T22:49:40.729014Z","iopub.status.idle":"2021-07-02T22:49:40.742237Z","shell.execute_reply.started":"2021-07-02T22:49:40.728911Z","shell.execute_reply":"2021-07-02T22:49:40.74128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nimport pytorch_lightning as pl\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch\nimport math\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, KFold\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-07-02T22:49:42.028383Z","iopub.execute_input":"2021-07-02T22:49:42.028698Z","iopub.status.idle":"2021-07-02T22:49:45.227325Z","shell.execute_reply.started":"2021-07-02T22:49:42.028669Z","shell.execute_reply":"2021-07-02T22:49:45.226477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSLELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        \n    def forward(self, pred, actual):\n        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))\n    \ndef RMSLE(y_true, y_pred):\n    return np.sqrt(mean_squared_log_error(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T22:49:46.362246Z","iopub.execute_input":"2021-07-02T22:49:46.362782Z","iopub.status.idle":"2021-07-02T22:49:46.369606Z","shell.execute_reply.started":"2021-07-02T22:49:46.362729Z","shell.execute_reply":"2021-07-02T22:49:46.369003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MLP(pl.LightningModule):\n  \n    def __init__(self, X, y, X_test, learning_rate, y_scaler, seed):\n        super().__init__()\n        self.save_hyperparameters()\n        \n        self.layers = nn.Sequential(\n            nn.Linear(11, 32),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Linear(32, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Linear(256, 3),\n            nn.Sigmoid())\n\n        \n        self.X = X\n        self.y = y\n        self.X_test = X_test\n        self.learning_rate = learning_rate\n        self.seed = seed\n        self.y_scaler = y_scaler\n        self.loss = RMSLELoss()\n      \n\n    def forward(self, x):\n        return self.layers(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self.layers(x)\n        loss = self.loss(y_hat, y)\n        self.log('train_loss', loss)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self.layers(x)\n        y_true = self.y_scaler.inverse_transform(y.cpu().numpy())\n        y_pred = self.y_scaler.inverse_transform(y_hat.cpu().numpy())\n        loss = RMSLE(y_true, y_pred)\n        return loss\n    \n    def validation_epoch_end(self, val_step_outputs):\n        loss = sum(val_step_outputs) / len(val_step_outputs)\n        self.log('val_loss', loss)\n        \n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.75, patience=6, verbose = 1,mode = 'min', cooldown = 0, min_lr = 10e-7)\n        optimizer_dict = {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n        return optimizer_dict\n    \n    def setup(self, stage):\n        X = self.X\n        y = self.y\n        X_test = self.X_test\n        \n        X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.85, random_state=self.seed)\n        \n        self.X_train_scaled = X_train\n        self.X_val_scaled = X_val\n        self.X_test_scaled = X_test\n\n        self.y_train_scaled = y_train\n        self.y_val_scaled = y_val\n    \n    def train_dataloader(self):\n        dataset = TensorDataset(torch.FloatTensor(self.X_train_scaled), torch.FloatTensor(self.y_train_scaled))\n        train_loader = DataLoader(dataset, batch_size=256, num_workers=8, shuffle=True)\n        return train_loader\n    \n    def val_dataloader(self):\n        val_dataset = TensorDataset(torch.FloatTensor(self.X_val_scaled), torch.FloatTensor(self.y_val_scaled))\n        val_loader = DataLoader(val_dataset, batch_size=256, num_workers=8, shuffle=False)\n        return val_loader\n    \n    def test_dataloader(self):\n        test_dataset = TensorDataset(torch.FloatTensor(self.X_test_scaled))\n        test_dataloader = DataLoader(test_dataset, batch_size=512, num_workers=8, shuffle=False)\n        return test_dataloader","metadata":{"execution":{"iopub.status.busy":"2021-07-02T22:49:46.62341Z","iopub.execute_input":"2021-07-02T22:49:46.623909Z","iopub.status.idle":"2021-07-02T22:49:46.642909Z","shell.execute_reply.started":"2021-07-02T22:49:46.623863Z","shell.execute_reply":"2021-07-02T22:49:46.642064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-jul-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jul-2021/test.csv')\n\ntrain['hourofday'] = pd.DatetimeIndex(train['date_time']).hour.values.astype(np.float32)\ntest['hourofday'] = pd.DatetimeIndex(test['date_time']).hour.values.astype(np.float32)\n\ntrain['dayoftheweek'] = pd.DatetimeIndex(train['date_time']).dayofweek.values.astype(np.float32)\ntest['dayoftheweek'] = pd.DatetimeIndex(test['date_time']).dayofweek.values.astype(np.float32)\n\ntrain['year'] = pd.DatetimeIndex(train['date_time']).dayofyear.values.astype(np.float32)\ntest['year'] = pd.DatetimeIndex(test['date_time']).dayofyear.values.astype(np.float32)\n\n\nX = train.drop(['date_time','target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides'], axis=1)\ny = train[['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']]\nX_test = test.drop(['date_time'], axis=1)\n\nX_scaler = StandardScaler()\ny_scaler = MinMaxScaler()\n\nX = X_scaler.fit_transform(X)\ny = y_scaler.fit_transform(y)\nX_test = X_scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T22:49:47.980384Z","iopub.execute_input":"2021-07-02T22:49:47.980926Z","iopub.status.idle":"2021-07-02T22:49:48.07588Z","shell.execute_reply.started":"2021-07-02T22:49:47.980878Z","shell.execute_reply":"2021-07-02T22:49:48.074067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_FOLDS = 10\n\nscores=list()\npreds = list()\nfor fold in tqdm(range(N_FOLDS)):\n\n    early_stop_callback = EarlyStopping(\n       monitor='val_loss',\n       min_delta=0.00,\n       patience=20,\n       verbose=True,\n       mode='min',\n    )\n    ckpt_callback = ModelCheckpoint(mode=\"min\", \n                                    monitor=\"val_loss\", \n                                    dirpath='/kaggle/temp/', filename=f'fold_{N_FOLDS}_{fold}')\n    \n    model = MLP(X, y, X_test, 1e-3, y_scaler=y_scaler, seed=42 + fold)\n    trainer = pl.Trainer(auto_lr_find=True)\n    trainer.tune(model)\n    print('Learning rate:', model.learning_rate)\n    trainer = pl.Trainer(callbacks=[early_stop_callback, ckpt_callback])\n    trainer.fit(model)\n    test_loader = model.test_dataloader()\n    \n    print(f'FOLD #{fold}| best rmsle: {ckpt_callback.best_model_score.item():.5g}')\n    \n    model = model.load_from_checkpoint(str(list(Path('/kaggle/temp/').glob(f'fold_{N_FOLDS}_{fold}*ckpt'))[0]))\n    model.eval()\n    y_test = list()\n    for x, in test_loader:\n        y_test.append(model.forward(x.to(model.device)).detach().cpu().numpy())\n    y_test = y_scaler.inverse_transform(np.concatenate(y_test))\n    \n    preds.append(y_test)\n    scores.append(ckpt_callback.best_model_score.item())","metadata":{"execution":{"iopub.status.busy":"2021-07-02T22:49:49.67959Z","iopub.execute_input":"2021-07-02T22:49:49.680086Z","iopub.status.idle":"2021-07-02T23:09:08.962933Z","shell.execute_reply.started":"2021-07-02T22:49:49.680054Z","shell.execute_reply":"2021-07-02T23:09:08.96179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T23:09:43.486192Z","iopub.execute_input":"2021-07-02T23:09:43.486601Z","iopub.status.idle":"2021-07-02T23:09:43.495667Z","shell.execute_reply.started":"2021-07-02T23:09:43.486557Z","shell.execute_reply":"2021-07-02T23:09:43.494747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, pred in enumerate(preds):\n    if i == 0:\n        y_test = pred\n    else:\n        y_test = y_test + pred\ny_test = y_test / len(preds)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T23:09:53.454866Z","iopub.execute_input":"2021-07-02T23:09:53.455486Z","iopub.status.idle":"2021-07-02T23:09:53.461511Z","shell.execute_reply.started":"2021-07-02T23:09:53.455436Z","shell.execute_reply":"2021-07-02T23:09:53.459917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/tabular-playground-series-jul-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T23:11:02.331016Z","iopub.execute_input":"2021-07-02T23:11:02.331352Z","iopub.status.idle":"2021-07-02T23:11:02.349173Z","shell.execute_reply.started":"2021-07-02T23:11:02.331323Z","shell.execute_reply":"2021-07-02T23:11:02.348247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target_carbon_monoxide']=y_test[:,0]\nsubmission['target_benzene']=y_test[:,1]\nsubmission['target_nitrogen_oxides']=y_test[:,2]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T23:11:16.026105Z","iopub.execute_input":"2021-07-02T23:11:16.026701Z","iopub.status.idle":"2021-07-02T23:11:16.032367Z","shell.execute_reply.started":"2021-07-02T23:11:16.026664Z","shell.execute_reply":"2021-07-02T23:11:16.031617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T23:11:25.130492Z","iopub.execute_input":"2021-07-02T23:11:25.131055Z","iopub.status.idle":"2021-07-02T23:11:25.150936Z","shell.execute_reply.started":"2021-07-02T23:11:25.131022Z","shell.execute_reply":"2021-07-02T23:11:25.150213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}