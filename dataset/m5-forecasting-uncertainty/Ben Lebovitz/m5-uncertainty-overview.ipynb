{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Competition overview\nhttps://www.kaggle.com/c/m5-forecasting-uncertainty/overview This contest was the companion contest to the M5 accuracy contest. The difference was to that the submission for certain lines of the submisison were evaluated based using \"weighted scale pinball loss.\"\n\ne.g. CA_HOUSEHOLD_0.005_validation would be evaluated at the .005 quantile.\n\n# Pinball loss evaluation function\nPinball loss is the appropriate metric for a quantile forecast. Like accuracy loss functions (e.g. accuracy, MSE, etc etc), a score of 0 means that perfect predictions were made and loss is increased as predictions deviate from the true value. \n\nIn addition to accuracy loss functions Pinball loss also penalizes for\n1. A how wide the range of prediciton is at a given quantile, and gives even larger penalties for true values that fall outside of the range\n\nPinball loss creates a range where more certian predictions are penalized more for being wrong. i.e. if a prediction of the 99% quantile is off by 100, the loss is greater than for a prediction that is off by 100 at the 75% quantile.\n\n### Notes\n* \"(pinball loss) is biased (on purpose) when it comes to quantile forecasts. Hence the naive comparison observed vs forecasts is not satisfying. The pinball loss function returns a value that can be interpreted as the accuracy of a quantile forecasting model.\"\n* https://www.lokad.com/pinball-loss-function-definition\n*  https://www.kaggle.com/c/m5-forecasting-uncertainty/discussion/137098\n * \"...to optimize the pinball loss, you want the true value of what you are predicting to be less than your quantile prediction 100*q percent of the time. For example, your prediction for the 0.25 quantile should be such that the true value is less than your predicton 25% of the time.... \n * The math of the loss function enforces this by penalizing cases when the truth is on the more unusual side of your prediction more heavily than when it is on the expected side. For example, if the truth is higher than your 0.975 quantile prediction by 1, you will be penalized by 39x more ) than if the truth was 1 below your quantile prediction.\n * Starting with the above intuition, the metric further encourages you to predict as narrow a range of possibilities as possible by weighting the penalty by the absolute difference between the truth and your quantile. If you were to have a model that could perfectly predict the truth everytime, you could set all quantiles to be exactly the truth and get a perfect score of 0.000. However, if you did this and you were not exactly right every time, the loss function would be very large because you would get big penalties when the truth was on the supposed-to-be-more-unusual side of your prediction.\"\n\n### Formula and Examples:\n\n**If Real >= Quantile forecast**\n* Real = 100, quantile forecast = 90\n* Pinball loss = (100-90) * .005 = .05\n\n**If Real < Quantile forecast**\n* Real = 90, quantile forecast = 100\n* Pinball loss = (100 - 90)* (1 -.005)  = 9.95\n\nPredicting lower is better than higher because the quantile should be within the range of predictions.\n\nFor quantiles >= 0.5 it's reversed... i.e. if real <= Quantile forecast as the prediction should be greater than the real value.\n\n### \"Weighted scale\" pinball loss\nThe \"weighted scaale\" part of the metric for this competition refers to revenue weighting for each product.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}