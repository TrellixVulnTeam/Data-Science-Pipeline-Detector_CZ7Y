{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport time\nimport math\nimport datetime\nfrom math import log, floor\nfrom sklearn.neighbors import KDTree\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.utils import shuffle\nfrom tqdm.notebook import tqdm as tqdm\n\nimport seaborn as sns\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utilities","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n#\ndef autocorrelation(ys, t=1):\n    return np.corrcoef(ys[:-t], ys[t:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"INPUT_DIR = '../input/m5-forecasting-uncertainty'\nINPUT_DIR2 = '../input/walmartadd'\ncalendar = pd.read_csv(f'{INPUT_DIR}/calendar.csv')\nselling_prices = pd.read_csv(f'{INPUT_DIR}/sell_prices.csv')\nsample_submission = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')\nsales = pd.read_csv(f'{INPUT_DIR2}/sales.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series_cols = sales.columns[sales.columns.str.contains(\"d_\")].values\nlevel_cols = sales.columns[sales.columns.str.contains(\"d_\")==False].values\ndays = np.arange(1, len(series_cols)+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timeseries = sales[series_cols].sum().values\nlen(timeseries)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train/Test available dates","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.plot(days[0:1913], timeseries[0:1913], label=\"train\")\nplt.plot(days[1914:], timeseries[1914:], label=\"validation\")\nplt.title(\"Top-Level-1: Summed product sales of all stores and states\");\nplt.legend()\nplt.xlabel(\"Day\")\nplt.ylabel(\"Unit sales\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA - Hirerarchical levels","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The dataset hierarchy consits of 12 levels:\n\n- 1 - The top is given by the **unit sales of all products**, aggregated for all stores/states.\n- 2 - Unit sales of all products, aggregated for each **state**.\n- 3 - Unit sales of all products, aggregated for each **store**.\n- 4 - Unit sales of all products, aggregated for each **category**.\n- 5 - Unit sales of all products, aggregated for each **department**.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_palette(\"colorblind\")\n\nfig, ax = plt.subplots(5,1,figsize=(20,28))\nsales[series_cols].sum().plot(ax=ax[0])\nax[0].set_title(\"Top-Level-1: Summed product sales of all stores and states\")\nax[0].set_ylabel(\"Unit sales of all products\");\nsales.groupby(\"state_id\")[series_cols].sum().transpose().plot(ax=ax[1])\nax[1].set_title(\"Level-2: Summed product sales of all stores per state\");\nax[1].set_ylabel(\"Unit sales of all products\");\nsales.groupby(\"store_id\")[series_cols].sum().transpose().plot(ax=ax[2])\nax[2].set_title(\"Level-3: Summed product sales per store\")\nax[2].set_ylabel(\"Unit sales of all products\");\nsales.groupby(\"cat_id\")[series_cols].sum().transpose().plot(ax=ax[3])\nax[3].set_title(\"Level-4: Summed product sales per category\")\nax[3].set_ylabel(\"Unit sales of all products\");\nsales.groupby(\"dept_id\")[series_cols].sum().transpose().plot(ax=ax[4])\nax[4].set_title(\"Level-4: Summed product sales per product department\")\nax[4].set_ylabel(\"Unit sales of all products\");\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocesing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_calendar(calendar):\n    global maps, mods\n    calendar[\"event_name\"] = calendar[\"event_name_1\"]\n    calendar[\"event_type\"] = calendar[\"event_type_1\"]\n\n    map1 = {mod:i for i,mod in enumerate(calendar['event_name'].unique())}\n    calendar['event_name'] = calendar['event_name'].map(map1)\n    map2 = {mod:i for i,mod in enumerate(calendar['event_type'].unique())}\n    calendar['event_type'] = calendar['event_type'].map(map2)\n    calendar['nday'] = calendar['date'].str[-2:].astype(int)\n    maps[\"event_name\"] = map1\n    maps[\"event_type\"] = map2\n    mods[\"event_name\"] = len(map1)\n    mods[\"event_type\"] = len(map2)\n    calendar[\"wday\"] -=1\n    calendar[\"month\"] -=1\n    calendar[\"year\"] -= 2011\n    mods[\"month\"] = 12\n    mods[\"year\"] = 6\n    mods[\"wday\"] = 7\n    mods['snap_CA'] = 2\n    mods['snap_TX'] = 2\n    mods['snap_WI'] = 2\n\n    calendar.drop([\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", \"date\", \"weekday\"], \n                  axis=1, inplace=True)\n    return calendar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_sales(sales, start=1400, upper=1970):\n    if start is not None:\n        print(\"dropping...\")\n        to_drop = [f\"d_{i+1}\" for i in range(start-1)]\n        print(sales.shape)\n        sales.drop(to_drop, axis=1, inplace=True)\n        print(sales.shape)\n    #=======\n    print(\"adding...\")\n    new_columns = ['d_%i'%i for i in range(1942, upper, 1)]\n    for col in new_columns:\n        sales[col] = np.nan\n    print(\"melting...\")\n    sales = sales.melt(id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\",\"scale\",\"start\"],\n                        var_name='d', value_name='demand')\n\n    print(\"generating order\")\n    if start is not None:\n        skip = start\n    else:\n        skip = 1\n    sales[\"nb\"] =sales.index // 42840 + skip\n    return sales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calendar dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"maps = {}\nmods = {}\ncalendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_calendar = preprocess_calendar(calendar)\nmod_calendar.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sales dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"START = 1400","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmod_sales = preprocess_sales(sales, start=1400, upper= 1970)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Enconding of factors - Sales dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\"item_id\", \"dept_id\", \"cat_id\",\"store_id\",\"state_id\"]\nfor col in cols:\n    temp_dct = {mod:i for i, mod in enumerate(mod_sales[col].unique())}\n    mods[col] = len(temp_dct)\n    maps[col] = temp_dct\nfor col in cols:\n    mod_sales[col] = mod_sales[col].map(maps[col])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del temp_dct\nmod_sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add calendar days to sales dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"merge with calendar...\")\nmod_sales = mod_sales.merge(calendar, on='d', how='left')\ndel calendar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_sales = reduce_mem_usage(mod_sales)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"reordering...\")\nmod_sales.sort_values(by=[\"id\",\"nb\"], inplace=True)\nprint(\"re-indexing..\")\nmod_sales.reset_index(inplace=True, drop=True)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_sales['n_week'] = (mod_sales['nb']-1)//7\nmod_sales[\"nday\"] -= 1\nmods['nday'] = 31","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_sales[\"x\"] = mod_sales[\"demand\"] / mod_sales[\"scale\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate Sale lags","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LAGS = [28, 35, 42, 49, 56, 63]\nFEATS = []\nfor lag in tqdm(LAGS):\n    mod_sales[f\"x_{lag}\"] = mod_sales.groupby(\"id\")[\"x\"].shift(lag)\n    FEATS.append(f\"x_{lag}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mod_sales.shape)\nmod_sales = mod_sales.loc[mod_sales.nb>mod_sales.start]\nprint(mod_sales.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb = mod_sales['nb'].values\nMAX_LAG = max(LAGS)\n#tr_mask = np.logical_and(nb>START + MAX_LAG, nb<=1913)\ntr_mask = np.logical_and(nb>START + MAX_LAG, nb<=1941) # SORRY THIS IS FAKE VALIDATION. I DIDN'T THINK IT WOULD HAVE HAD LIFTED UP MY SCORE LIKE THAT\nval_mask = np.logical_and(nb>1913, nb<=1941)\nte_mask = np.logical_and(nb>1941, nb<=1969)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale = mod_sales['scale'].values\nids = mod_sales['id'].values\n#y = sales['demand'].values\n#ys = y / scale\nys = mod_sales['x'].values\nZ = mod_sales[FEATS].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv = scale[val_mask]\nse = scale[te_mask]\nids = ids[te_mask]\nids = ids.reshape((-1, 28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ca = mod_sales[['snap_CA']].values\ntx = mod_sales[['snap_TX']].values\nwi = mod_sales[['snap_WI']].values\nwday = mod_sales[['wday']].values\nmonth = mod_sales[['month']].values\nyear = mod_sales[['year']].values\nevent = mod_sales[['event_name']].values\nnday = mod_sales[['nday']].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item = mod_sales[['item_id']].values\ndept = mod_sales[['dept_id']].values\ncat = mod_sales[['cat_id']].values\nstore = mod_sales[['store_id']].values\nstate = mod_sales[['state_id']].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_data(mask):\n    x = {\"snap_CA\":ca[mask], \"snap_TX\":tx[mask], \"snap_WI\":wi[mask], \"wday\":wday[mask], \n         \"month\":month[mask], \"year\":year[mask], \"event\":event[mask], \"nday\":nday[mask], \n         \"item\":item[mask], \"dept\":dept[mask], \"cat\":cat[mask], \"store\":store[mask], \n         \"state\":state[mask], \"num\":Z[mask]}\n    t = ys[mask]\n    return x, t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xt, yt = make_data(tr_mask) #train\nxv, yv = make_data(val_mask) # val\nxe, ye = make_data(te_mask) # test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = {'xt':xt, 'yt': yt, 'xv': xv, 'yv': yv, 'xe': xe, 'ye': ye}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\nfor filename, data in datasets.items():\n    with open(str(filename) + '.pickle', 'wb') as handle:\n        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#=====\ndef qloss(y_true, y_pred):\n    # Pinball loss for multiple quantiles\n    qs = [0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995]\n    q = tf.constant(np.array([qs]), dtype=tf.float32)\n    e = y_true - y_pred\n    v = tf.maximum(q*e, (q-1)*e)\n    return K.mean(v)\n\n\n#============================#\ndef make_model(n_in):\n    \n    num = L.Input((n_in,), name=\"num\")\n    \n    ca = L.Input((1,), name=\"snap_CA\")\n    tx = L.Input((1,), name=\"snap_TX\")\n    wi = L.Input((1,), name=\"snap_WI\")\n    wday = L.Input((1,), name=\"wday\")\n    month = L.Input((1,), name=\"month\")\n    year = L.Input((1,), name=\"year\")\n    event = L.Input((1,), name=\"event\")\n    nday = L.Input((1,), name=\"nday\")\n    item = L.Input((1,), name=\"item\")\n    dept = L.Input((1,), name=\"dept\")\n    cat = L.Input((1,), name=\"cat\")\n    store = L.Input((1,), name=\"store\")\n    state = L.Input((1,), name=\"state\")\n    inp = {\"snap_CA\":ca, \"snap_TX\":tx, \"snap_WI\":wi, \"wday\":wday, \n           \"month\":month, \"year\":year, \"event\":event, \"nday\":nday,\n           \"item\":item, \"dept\":dept, \"cat\":cat, \"store\":store, \n           \"state\":state, \"num\":num} \n    #\n    ca_ = L.Embedding(mods[\"snap_CA\"], mods[\"snap_CA\"], name=\"ca_3d\")(ca)\n    tx_ = L.Embedding(mods[\"snap_TX\"], mods[\"snap_TX\"], name=\"tx_3d\")(tx)\n    wi_ = L.Embedding(mods[\"snap_WI\"], mods[\"snap_WI\"], name=\"wi_3d\")(wi)\n    wday_ = L.Embedding(mods[\"wday\"], mods[\"wday\"], name=\"wday_3d\")(wday)\n    month_ = L.Embedding(mods[\"month\"], mods[\"month\"], name=\"month_3d\")(month)\n    year_ = L.Embedding(mods[\"year\"], mods[\"year\"], name=\"year_3d\")(year)\n    event_ = L.Embedding(mods[\"event_name\"], mods[\"event_name\"], name=\"event_3d\")(event)\n    nday_ = L.Embedding(mods[\"nday\"], mods[\"nday\"], name=\"nday_3d\")(nday)\n    item_ = L.Embedding(mods[\"item_id\"], 10, name=\"item_3d\")(item)\n    dept_ = L.Embedding(mods[\"dept_id\"], mods[\"dept_id\"], name=\"dept_3d\")(dept)\n    cat_ = L.Embedding(mods[\"cat_id\"], mods[\"cat_id\"], name=\"cat_3d\")(cat)\n    store_ = L.Embedding(mods[\"store_id\"], mods[\"store_id\"], name=\"store_3d\")(store)\n    state_ = L.Embedding(mods[\"state_id\"], mods[\"state_id\"], name=\"state_3d\")(state)\n    \n    p = [ca_, tx_, wi_, wday_, month_, year_, event_, nday_, item_, dept_, cat_, store_, state_]\n    emb = L.Concatenate(name=\"embds\")(p)\n    context = L.Flatten(name=\"context\")(emb)\n    \n    x = L.Concatenate(name=\"x1\")([context, num])\n    x = L.Dense(500, activation=\"relu\", name=\"d1\")(x)\n    x = L.Dropout(0.3)(x)\n    x = L.Concatenate(name=\"m1\")([x, context])\n    x = L.Dense(500, activation=\"relu\", name=\"d2\")(x)\n    x = L.Dropout(0.3)(x)\n    x = L.Concatenate(name=\"m2\")([x, context])\n    x = L.Dense(500, activation=\"relu\", name=\"d3\")(x)\n    preds = L.Dense(9, activation=\"linear\", name=\"preds\")(x)\n    model = M.Model(inp, preds, name=\"M1\")\n    model.compile(loss=qloss, optimizer=\"adam\")\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = make_model(len(FEATS))\nckpt = ModelCheckpoint(\"w.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.001)\nes = EarlyStopping(monitor='val_loss', patience=3)\nprint(net.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net.fit(xt, yt, batch_size=50_000, epochs=20, validation_data=(xv, yv), callbacks=[ckpt, reduce_lr, es])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pv = net.predict(xv, batch_size=50_000, verbose=1)\npe = net.predict(xe, batch_size=50_000, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net.evaluate(xv, yv, batch_size=50_000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pv = pv.reshape((-1, 28, 9))\npe = pe.reshape((-1, 28, 9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv = sv.reshape((-1, 28))\nse = se.reshape((-1, 28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Yv = yv.reshape((-1, 28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = np.random.randint(0, 42840)\n#k = np.random.randint(0, 200)\nprint(ids[k, 0])\nplt.plot(np.arange(28, 56), Yv[k], label=\"true\")\nplt.plot(np.arange(28, 56), pv[k ,:, 3], label=\"q25\")\nplt.plot(np.arange(28, 56), pv[k ,:, 4], label=\"q50\")\nplt.plot(np.arange(28, 56), pv[k, :, 5], label=\"q75\")\nplt.legend(loc=\"best\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = [f\"F{i+1}\" for i in range(28)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"piv = pd.DataFrame(ids[:, 0], columns=[\"id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"QUANTILES = [\"0.005\", \"0.025\", \"0.165\", \"0.250\", \"0.500\", \"0.750\", \"0.835\", \"0.975\", \"0.995\"]\nVALID = []\nEVAL = []\n\nfor i, quantile in tqdm(enumerate(QUANTILES)):\n    t1 = pd.DataFrame(pv[:,:, i]*sv, columns=names)\n    t1 = piv.join(t1)\n    t1[\"id\"] = t1[\"id\"] + f\"_{quantile}_validation\"\n    t2 = pd.DataFrame(pe[:,:, i]*se, columns=names)\n    t2 = piv.join(t2)\n    t2[\"id\"] = t2[\"id\"] + f\"_{quantile}_evaluation\"\n    VALID.append(t1)\n    EVAL.append(t2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame()\nsub = sub.append(VALID + EVAL)\ndel VALID, EVAL, t1, t2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}