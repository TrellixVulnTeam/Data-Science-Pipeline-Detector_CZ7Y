{"cells":[{"metadata":{},"cell_type":"markdown","source":"## M5 Uncertainty Data Preparation\nIn this notebook, we load the unaggregated series from the M5 Uncertainty competition, then aggregate and split them into training and testing sets while stratifying along aggregation levels such as store, and dept. Finally, we append each sequence's weight, taken off github, and write them to TFRecord files.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, KFold\nimport itertools\nimport random\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNITS_PATH = os.path.join(\"..\", \"input\", \"m5-forecasting-uncertainty\", \"sales_train_evaluation.csv\")\nWEIGHTS_PATH = os.path.join(\"..\", \"input\", \"m5git\", \"validation\", \"weights_validation.csv\")\nSEQ_LEN = 1941","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_agg = pd.read_csv(\n    UNITS_PATH\n).astype({f\"d_{n}\": np.float32 for n in range(1, SEQ_LEN)})\n\n# print(store_agg[store_agg.isna().apply(any, axis='columns')])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We begin with the full aggregation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CORRECT_COL_ORDER = store_agg.columns\ncontext_cols = [\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n\nhier_seqs = store_agg.sum(\n).to_frame(\n).transpose(\n).assign(\n    id=\"Total_X\", **{col: \"agg\" for col in context_cols}\n)[CORRECT_COL_ORDER]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now construct the other heirarchical levels.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def agg_and_adjust(levels):\n    agg_cols = [col for col in context_cols if col not in levels]\n    return store_agg.groupby(\n        levels,\n        as_index=False\n    ).sum(\n    ).assign(\n        id=lambda x: x[levels[0]] + \"_\" + (x[levels[1]] if len(levels) == 2 else \"X\"),\n        **{col: \"agg\" for col in agg_cols}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"levels = [[\"state_id\", \"cat_id\"], [\"state_id\", \"dept_id\"],\n          [\"store_id\", \"cat_id\"], [\"store_id\", \"dept_id\"],\n          [\"state_id\"], [\"store_id\"], [\"cat_id\"], [\"dept_id\"]]\nhier_seqs = hier_seqs.append([agg_and_adjust(level) for level in levels],\n                             ignore_index=True, sort=False)    \nframes = [hier_seqs[CORRECT_COL_ORDER]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Unit Sales Agg by Store/State\nIn the following blocks, we aggregate the unit sales of each product by the stated level, and stratify according to department and other relevant levels.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"store_state_agg = agg_and_adjust([\"item_id\"])[CORRECT_COL_ORDER]\nframes.extend([store_state_agg[store_state_agg.item_id.map(lambda x: x[:-4]) == dept]\n                  for dept in store_agg.dept_id.unique()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Unit Sales Agg by State","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_strata(df, levels):\n    cuts = itertools.product(store_agg[levels[0]].unique(),\n                             store_agg[levels[1]].unique())\n    return [(df.item_id.map(lambda x: x[:-4]) == dept)\n                & (df[levels[0]] == level_0) for level_0, dept in cuts]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_agg = agg_and_adjust([\"state_id\", \"item_id\"])[CORRECT_COL_ORDER]\nframes.extend([state_agg[strata] for strata in get_strata(state_agg, [\"state_id\", \"dept_id\"])])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Unit Sales Agg By Store","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"store_agg.id = store_agg.id.map(lambda x: x[:-11])\nframes.extend([store_agg[strata] for strata in get_strata(store_agg, [\"store_id\", \"dept_id\"])])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Weights\nNow, we get the weights so that we can pass them to the tfrecords for training.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = pd.read_csv(WEIGHTS_PATH\n).assign(\n    id=lambda x: x.Agg_Level_1 + \"_\" + x.Agg_Level_2\n).drop(\n    columns=[\"Agg_Level_1\", \"Agg_Level_2\", \"Level_id\"]\n).rename(\n    columns={\"Weight\": \"weights\"}\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TFRecord Writing\nWe begin with a helper function for parsing some columns. Then, define a functon that when applied to a DataFrame writes it's rows to a TFRecord.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col_vals = {\n        \"item_id\": [\"agg\".encode(\"utf-8\")],\n        \"dept_id\": list(range(3)),\n        \"cat_id\": list(range(3)),\n        \"store_id\": list(range(4)),\n        \"state_id\": list(range(3))\n    }\n\nvals = {\n    \"_1\": [0], \"_2\": [1], \"_3\": [2],\n    \"_4\": [3], \"WI\": [0], \"CA\": [1],\n    \"TX\": [2], \"HOUSEHOLD\": [0],\n    \"HOBBIES\": [1], \"FOODS\": [2]        \n}\n\ndef parse(col, row):\n    val = row[col]\n    if val == \"agg\":\n        out = col_vals[col]\n        if col == \"dept_id\" and row[\"cat_id\"] not in [\"FOODS\", \"agg\"]:\n            out = out[:-1]\n        elif col == \"store_id\" and row[\"state_id\"] in [\"TX\", \"WI\"]:\n            out = out[:-1]\n            \n        return out\n    else:\n        if col in {\"dept_id\", \"store_id\"}:\n            val = val[-2:]\n        \n        if col in {\"id\", \"item_id\"}:\n            return [val.encode(\"utf-8\")]\n        else:\n            return vals[val]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_to_tfrecord(row, file):\n    feature = {col: tf.train.Feature(\n        bytes_list=tf.train.BytesList(value=parse(col, row))\n    ) for col in [\"id\", \"item_id\"]}\n    \n    feature.update({col: tf.train.Feature(\n        int64_list=tf.train.Int64List(value=parse(col, row))\n    ) for col in [\"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]})\n    \n    feature[\"weights\"] = tf.train.Feature(\n        float_list=tf.train.FloatList(value=[row[\"weights\"]]))\n    feature[\"units\"] =  tf.train.Feature(\n        float_list=tf.train.FloatList(value=list(row.loc[\"d_1\":f\"d_{SEQ_LEN}\"])))\n    \n    example = tf.train.Example(\n        features=tf.train.Features(feature=feature))\n    file.write(example.SerializeToString())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We conclude with a function to sample the actual train and test frames so that they are approximately the correct proportion of the full frame, before writing the files to the TFRecords.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def stratify_uniformly(in_frames):\n    random.shuffle(in_frames)\n    train, test_frame = train_test_split(in_frames.pop(), test_size=0.2)\n    len_train, len_test = train.shape[0], test_frame.shape[0]\n    k_fold = KFold(shuffle=True)\n    out_frames = [train.iloc[idx]\n                      for _, idx in k_fold.split(train)]\n    for frame in in_frames:\n        train, test = train_test_split(frame, test_size=0.2)\n        len_train += train.shape[0]\n        len_test += test.shape[0]\n        if len_test * 4 - len_train >= 5:\n            train = train.append(test.iloc[-1], ignore_index=True)\n            test = test.iloc[:-1]\n            len_test -= 1\n            len_train += 1\n        \n        test_frame = test_frame.append(test, ignore_index=True)\n        out_frames.sort(key=lambda x: x.shape[0])\n        new_frames = [train.iloc[idx]\n                          for _, idx in k_fold.split(train)]\n        new_frames.sort(key=lambda x: x.shape[0], reverse=True) \n        out_frames = [pd.concat(frames, ignore_index=True)\n                          for frames in zip(out_frames, new_frames)]\n        \n    out_frames.append(test_frame)\n    return out_frames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_frames = stratify_uniformly(frames)\nfor n, frame in enumerate(stratified_frames):\n    frame = weights[[\"weights\", \"id\"]].join(\n        frame.set_index(\"id\"),\n        how=\"right\", on=\"id\"\n    )\n    if n < 5:\n        path = f\"train_{n + 1}.tfrecord\"\n    else:\n        path = \"test.tfrecord\"\n    \n    with tf.io.TFRecordWriter(path) as writer:\n        frame.apply(write_to_tfrecord, axis='columns', args=[writer])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}