{"cells":[{"execution_count":null,"outputs":[],"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"4c1a412b-4535-46d5-8fe3-e8600801817a","collapsed":true,"_uuid":"4e6801037e5274668f0b8667591d41c1abbe8be1"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"import json\nrecipeRaw = pd.read_json(\"../input/whats-cooking/train.json\")\nrecipeRaw[\"ingredientsFlat\"] = recipeRaw[\"ingredients\"].apply(lambda x: ' '.join(x))\nrecipeRaw.head()","metadata":{"_cell_guid":"00d2aeb7-f5f6-407f-9a93-3bd76a6a07ff","collapsed":true,"_uuid":"e88af6df71dc71c31208047b965ac30cdbf39729"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"recipeRawTest = pd.read_json(\"../input/whats-cooking/test.json\")\nrecipeRawTest[\"ingredientsFlat\"] = recipeRawTest[\"ingredients\"].apply(lambda x: ' '.join(x))\ntestdocs = recipeRawTest[\"ingredientsFlat\"].values\nrecipeRawCombined = recipeRaw.append(recipeRawTest)\nrecipeRawCombined[40000:].head()","metadata":{"_cell_guid":"0e1f7eab-ffa0-446a-9c34-daae03c16379","collapsed":true,"_uuid":"1db441bec8a629339122deb853f4757a7f5c8df7"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(recipeRaw[\"cuisine\"].values)\nlist(le.classes_)","metadata":{"_cell_guid":"a5b844ba-7eb5-4a22-a396-5e23eb23cd85","collapsed":true,"_uuid":"5ad902e961a68cd09c05269696439abf9d0f8654"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\ndocs = recipeRaw[\"ingredientsFlat\"].values\ntestdocs = recipeRawTest[\"ingredientsFlat\"].values\ndocsCombined = recipeRawCombined[\"ingredientsFlat\"].values\nlabels_enc = le.transform(recipeRaw[\"cuisine\"].values)\nlabels = to_categorical(labels_enc)\nlabels","metadata":{"_cell_guid":"29a5542b-848b-4428-9217-2000a859a4dc","collapsed":true,"_uuid":"499cd7566059f69ee184d2e0bb56c58274d7bf8f"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n# prepare tokenizer\nt = Tokenizer()\nt.fit_on_texts(docsCombined)\nvocab_size = len(t.word_index) + 1\n# integer encode the documents\nencoded_docs = t.texts_to_sequences(docs)\nencoded_test_docs = t.texts_to_sequences(testdocs)\nprint(vocab_size)\n# pad documents to a max length of 4 words\nmax_length = 40\npadded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\npadded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\nprint(len(padded_docs))","metadata":{"_cell_guid":"7bcf422f-0e75-4d49-b3b1-12553fcaf4ff","collapsed":true,"scrolled":true,"_uuid":"46b7fc9aef5a519f96a295e980ba15deee781e97"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"# load the whole embedding into memory\nembeddings_index = dict()\nf = open('../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Loaded %s word vectors.' % len(embeddings_index))","metadata":{"_cell_guid":"9182c6ea-cd7d-46a1-bd29-a532e0935474","collapsed":true,"_uuid":"31ef8ec3a8d8a6229dc767a90061dfc50294b456"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"vocab = pd.DataFrame.from_dict(t.word_index,orient=\"index\")\nvocab.drop([0],axis=1).reset_index().rename(columns={\"index\":\"word\"}).to_csv(\"vocab.csv\",index=False)","metadata":{"_cell_guid":"97ec3b51-53be-4078-a72a-a4222d2ffac0","collapsed":true,"_uuid":"72b42e2a27337810e4604db0f67d626a62008854"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"# create a weight matrix for words in training docs\nembedding_matrix = np.zeros((vocab_size, 100))\nfor word, i in t.word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"_cell_guid":"fa875535-7cef-40da-9add-dfe1d51395b0","collapsed":true,"_uuid":"befd8941982ee2119daa0b9cc6b10a1e14656239"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"print(embedding_matrix.shape)","metadata":{"_cell_guid":"593bfd0a-b703-4e87-96dd-a7eb98e6940e","collapsed":true,"_uuid":"f71c5f0b731d3418d3cb83be758233b5030da29d"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.layers.convolutional import Conv1D, MaxPooling1D\nfrom keras.layers.embeddings import Embedding\nfrom sklearn.model_selection import KFold\n\n# fix random seed for reproducibility\nseed = 42\nnp.random.seed(seed)\n\n# define 10-fold cross validation test harness\nkfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n\ncvscores = []\nfor train, test in kfold.split(padded_docs, labels):\n    # define the model\n\n    model = Sequential()\n    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=40, trainable=False))\n    model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Flatten())\n    model.add(Dense(250, activation='relu'))\n    model.add(Dense(le.classes_.size, activation='sigmoid'))\n    # compile the model\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n    # summarize the model\n    if cvscores == []:\n        print(model.summary())\n    # fit the model\n    model.fit(padded_docs[train], labels[train], epochs=5, verbose=0)\n    scores = model.evaluate(padded_docs[test], labels[test], verbose=0)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\nprint(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))","metadata":{"_cell_guid":"890c0395-03d7-4608-b540-8ec2401b96a2","collapsed":true,"_uuid":"225c77061e58aa23140df026385bf7cbc02e58e7"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"predictions = model.predict(padded_test_docs)\nprint(predictions.shape)\nrecipeRawTest[\"cuisine\"] = [le.classes_[np.argmax(prediction)] for prediction in predictions]\nrecipeRawTest.head()\nrecipeRawTest.drop([\"ingredients\",\"ingredientsFlat\"],axis=1).to_csv(\"submission.csv\",index=False)","metadata":{"_cell_guid":"cade4e3e-0feb-4cd1-9dfb-3c7f090b7b44","collapsed":true,"_uuid":"caaa007d8244b9f7fcd765aa413d248a603fac67"}}],"nbformat":4,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","version":"3.6.3","pygments_lexer":"ipython3"}},"nbformat_minor":1}