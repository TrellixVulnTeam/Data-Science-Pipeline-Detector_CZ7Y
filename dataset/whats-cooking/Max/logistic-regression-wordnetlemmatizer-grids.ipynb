{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-05T15:04:09.718096Z","iopub.execute_input":"2022-01-05T15:04:09.719218Z","iopub.status.idle":"2022-01-05T15:04:09.755754Z","shell.execute_reply.started":"2022-01-05T15:04:09.719106Z","shell.execute_reply":"2022-01-05T15:04:09.754597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport json \n\nfor t in ['train','test']:\n    with zipfile.ZipFile(\"../input/whats-cooking/{}.json.zip\".format(t),\"r\") as z:\n        z.extractall(\".\")\n    \nwith open('./train.json') as train_file:    \n    train = json.load(train_file)\n    \nwith open('./test.json') as test_file:\n    test = json.load(test_file)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:04:09.758047Z","iopub.execute_input":"2022-01-05T15:04:09.759106Z","iopub.status.idle":"2022-01-05T15:04:10.309579Z","shell.execute_reply.started":"2022-01-05T15:04:09.759061Z","shell.execute_reply":"2022-01-05T15:04:10.308875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.DataFrame(train)\ntest = pd.DataFrame(test)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:04:10.310713Z","iopub.execute_input":"2022-01-05T15:04:10.31131Z","iopub.status.idle":"2022-01-05T15:04:10.392195Z","shell.execute_reply.started":"2022-01-05T15:04:10.311275Z","shell.execute_reply":"2022-01-05T15:04:10.391564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train shape:\", train.shape)\nprint(\"Test shape:\", test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:04:10.393795Z","iopub.execute_input":"2022-01-05T15:04:10.394143Z","iopub.status.idle":"2022-01-05T15:04:10.398611Z","shell.execute_reply.started":"2022-01-05T15:04:10.394114Z","shell.execute_reply":"2022-01-05T15:04:10.397828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:04:10.399762Z","iopub.execute_input":"2022-01-05T15:04:10.399993Z","iopub.status.idle":"2022-01-05T15:04:10.428028Z","shell.execute_reply.started":"2022-01-05T15:04:10.399964Z","shell.execute_reply":"2022-01-05T15:04:10.427426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:04:10.429034Z","iopub.execute_input":"2022-01-05T15:04:10.429287Z","iopub.status.idle":"2022-01-05T15:04:10.46808Z","shell.execute_reply.started":"2022-01-05T15:04:10.429257Z","shell.execute_reply":"2022-01-05T15:04:10.467138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['cuisine'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:04:10.469643Z","iopub.execute_input":"2022-01-05T15:04:10.469961Z","iopub.status.idle":"2022-01-05T15:04:10.487069Z","shell.execute_reply.started":"2022-01-05T15:04:10.469918Z","shell.execute_reply":"2022-01-05T15:04:10.486239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean data\n#converting each ingredients list in one string: ' word1, word2, ...'\ntrain['ingredients_clean_string'] = [' , '.join(z).strip() for z in train['ingredients']]  \ntest['ingredients_clean_string'] = [' , '.join(z).strip() for z in test['ingredients']]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:04:10.488355Z","iopub.execute_input":"2022-01-05T15:04:10.488615Z","iopub.status.idle":"2022-01-05T15:04:10.543948Z","shell.execute_reply.started":"2022-01-05T15:04:10.488585Z","shell.execute_reply":"2022-01-05T15:04:10.542999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom nltk import WordNetLemmatizer\n# further clean data and extract information through word lemmatization\ntrain['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) \n                                         for line in lists]).strip() for lists in train['ingredients']]\n\ntest['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) \n                                          for line in lists]).strip() for lists in test['ingredients']]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:05:24.468225Z","iopub.execute_input":"2022-01-05T15:05:24.468581Z","iopub.status.idle":"2022-01-05T15:05:32.932788Z","shell.execute_reply.started":"2022-01-05T15:05:24.468544Z","shell.execute_reply":"2022-01-05T15:05:32.931893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create corpus based on newly processed data\ntrain_corpus = train['ingredients_string']\ntest_corpus = test['ingredients_string']","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:05:37.241303Z","iopub.execute_input":"2022-01-05T15:05:37.242171Z","iopub.status.idle":"2022-01-05T15:05:37.246473Z","shell.execute_reply.started":"2022-01-05T15:05:37.242123Z","shell.execute_reply":"2022-01-05T15:05:37.245793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# convert a collection of raw documents to a matrix of TF-IDF features\ntrain_vectorizer = TfidfVectorizer(stop_words='english',\n                             ngram_range = ( 1 , 1 ),\n                             analyzer=\"word\", \n                             max_df = .57 , \n                             binary=False , \n                             token_pattern=r'\\w+' , \n                             sublinear_tf=False)\n\ntest_vectorizer = TfidfVectorizer(stop_words='english')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:05:38.377275Z","iopub.execute_input":"2022-01-05T15:05:38.378007Z","iopub.status.idle":"2022-01-05T15:05:38.383349Z","shell.execute_reply.started":"2022-01-05T15:05:38.377966Z","shell.execute_reply":"2022-01-05T15:05:38.382706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform the corpus to a dense matrix representation\ntrain_tfidf = train_vectorizer.fit_transform(train_corpus).todense()\ntest_tfidf = train_vectorizer.transform(test_corpus)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:05:40.239924Z","iopub.execute_input":"2022-01-05T15:05:40.240564Z","iopub.status.idle":"2022-01-05T15:05:42.721352Z","shell.execute_reply.started":"2022-01-05T15:05:40.240514Z","shell.execute_reply":"2022-01-05T15:05:42.720476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare data for prediction\ntrain_predictor = train_tfidf\ntest_predictor = test_tfidf\n\ntrain_target = train['cuisine']","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:05:42.722943Z","iopub.execute_input":"2022-01-05T15:05:42.723169Z","iopub.status.idle":"2022-01-05T15:05:42.727626Z","shell.execute_reply.started":"2022-01-05T15:05:42.723142Z","shell.execute_reply":"2022-01-05T15:05:42.72671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle_cuisine = LabelEncoder()\n\n# encoding 'cuisine'\nle_cuisine.fit(train_target)\nencoded_le_cuisine_new_train = le_cuisine.transform(train_target)\ntrain_target = encoded_le_cuisine_new_train","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:05:42.728789Z","iopub.execute_input":"2022-01-05T15:05:42.729088Z","iopub.status.idle":"2022-01-05T15:05:42.762083Z","shell.execute_reply.started":"2022-01-05T15:05:42.729056Z","shell.execute_reply":"2022-01-05T15:05:42.761114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(train_predictor, train_target, test_size = 0.2, random_state = 0, stratify = train_target)\n\nprint(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:05:44.24056Z","iopub.execute_input":"2022-01-05T15:05:44.241164Z","iopub.status.idle":"2022-01-05T15:05:44.61108Z","shell.execute_reply.started":"2022-01-05T15:05:44.241124Z","shell.execute_reply":"2022-01-05T15:05:44.610167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\n# defining model\nclassifier = LogisticRegression(solver='liblinear')\n\n# fit the model\nclassifier.fit(X_train, y_train)\n\n# predicting X_val\ny_pred = classifier.predict(X_val)\n\n# evaluating\nprint(classification_report(y_val, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:05:45.334652Z","iopub.execute_input":"2022-01-05T15:05:45.334969Z","iopub.status.idle":"2022-01-05T15:05:50.134224Z","shell.execute_reply.started":"2022-01-05T15:05:45.334933Z","shell.execute_reply":"2022-01-05T15:05:50.131051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom sklearn.model_selection import GridSearchCV\n\nparameters = {\n    \"C\": [1, 10] }\n\nmodel = LogisticRegression()\nclassifier = GridSearchCV(model, parameters)\n\nclassifier.fit(X_train, y_train)\nclassifier.best_params_\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:09:20.758704Z","iopub.execute_input":"2022-01-05T15:09:20.759021Z","iopub.status.idle":"2022-01-05T15:11:42.67757Z","shell.execute_reply.started":"2022-01-05T15:09:20.758988Z","shell.execute_reply":"2022-01-05T15:11:42.671299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining model\nbest_classifier = LogisticRegression(solver='liblinear', C = 7)\n\n# fit the model\nbest_classifier.fit(X_train, y_train)\n\n# predicting X_val\ny_pred = best_classifier.predict(X_val)\n\n# evaluating\nprint(classification_report(y_val, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:11:49.89113Z","iopub.execute_input":"2022-01-05T15:11:49.891571Z","iopub.status.idle":"2022-01-05T15:11:57.625463Z","shell.execute_reply.started":"2022-01-05T15:11:49.891529Z","shell.execute_reply":"2022-01-05T15:11:57.624419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction on the test set\npredicted_cuisine = best_classifier.predict(test_predictor)\n\n#predicted_price_range","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:12:03.944376Z","iopub.execute_input":"2022-01-05T15:12:03.944696Z","iopub.status.idle":"2022-01-05T15:12:03.953868Z","shell.execute_reply.started":"2022-01-05T15:12:03.944664Z","shell.execute_reply":"2022-01-05T15:12:03.95312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_cuisine = le_cuisine.inverse_transform(predicted_cuisine)\npredicted_cuisine","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:12:05.798747Z","iopub.execute_input":"2022-01-05T15:12:05.799483Z","iopub.status.idle":"2022-01-05T15:12:05.806045Z","shell.execute_reply.started":"2022-01-05T15:12:05.799426Z","shell.execute_reply":"2022-01-05T15:12:05.805157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating submission file\nsubmission = pd.DataFrame({'id': test['id'],\n                           'cuisine': predicted_cuisine})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T15:12:07.605884Z","iopub.execute_input":"2022-01-05T15:12:07.606326Z","iopub.status.idle":"2022-01-05T15:12:07.638193Z","shell.execute_reply.started":"2022-01-05T15:12:07.606284Z","shell.execute_reply":"2022-01-05T15:12:07.637461Z"},"trusted":true},"execution_count":null,"outputs":[]}]}