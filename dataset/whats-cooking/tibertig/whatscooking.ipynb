{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import *\nfrom sklearn.ensemble import *\nfrom sklearn.metrics import *\nimport seaborn as sns\n%pylab inline"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"trainDf = pd.read_json(\"../input/train.json\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"trainDf['ingredients'] = trainDf['ingredients'].map(lambda x: str(x)[1:-1].split(','))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"trainDf['ingredients_clean_string'] = [' , '.join(z).strip() for z in trainDf['ingredients']]  "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from nltk.stem import WordNetLemmatizer \nimport re\ntrainDf['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in trainDf['ingredients']]       "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"testDf = pd.read_json(\"../input/test.json\") \ntestDf['ingredients_clean_string'] = [' , '.join(z).strip() for z in testDf['ingredients']]\ntestDf['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in testDf['ingredients']]       "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"corpusStr = trainDf['ingredients_string']"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfIdfVect = TfidfVectorizer(stop_words='english', \nngram_range = ( 1 , 1 ),analyzer=\"word\", \n                             max_df = .57 , binary=False , token_pattern=r'\\w+' , sublinear_tf=False)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"tfIdfVect.fit_transform(corpusStr).todense()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"corpusts = testDf['ingredients_string']\nvectorizerts = TfidfVectorizer(stop_words='english')\ntfidfts=tfIdfVect.transform(corpusts)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"predictors_tr = tfIdfVect\ntargets_tr = trainDf['cuisine']\npredictors_ts = tfidfts"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nparameters = {'C':[1,10]}\nclf = LogisticRegression()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn import grid_search"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"classif = grid_search.GridSearchCV(clf, parameters)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"classif"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"classif.fit(predictors_tr,targets_tr)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}