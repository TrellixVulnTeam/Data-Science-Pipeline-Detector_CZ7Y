{"cells":[{"metadata":{},"cell_type":"markdown","source":"**All necessary imports**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"from collections import Counter\nimport zipfile\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.sparse import csr_matrix\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"train_archive = zipfile.ZipFile('/kaggle/input/whats-cooking/train.json.zip', 'r')\ntrain_data = pd.read_json(train_archive.open('train.json'))\nprint('train shape:', train_data.shape)\n\ntest_archive = zipfile.ZipFile('/kaggle/input/whats-cooking/test.json.zip', 'r')\ntest_data = pd.read_json(test_archive.open('test.json'))\nprint('test shape:', test_data.shape)\n\nsample_submission_archive = zipfile.ZipFile('/kaggle/input/whats-cooking/sample_submission.csv.zip', 'r')\nsample_submission_data = pd.read_csv(sample_submission_archive.open('sample_submission.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Take a look at data**"},{"metadata":{"trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"train_data.info()  # clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['size'] = train_data['ingredients'].apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with sns.axes_style('darkgrid'), sns.plotting_context('talk'):\n    pd.value_counts(train_data['cuisine']).plot.bar(figsize=(12, 5))\n    plt.xticks(rotation=80)\n    plt.ylabel('number of recipes')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with sns.axes_style('darkgrid'), sns.plotting_context('talk'):\n    train_data.groupby('cuisine')['size'].mean().plot.bar(figsize=(12, 5))\n    plt.xticks(rotation=80)\n    plt.ylabel('average ingredients count')\n    plt.xlabel('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prepare data (feature engineering)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_counters(recipes):\n    counters = []\n    for recipe in recipes:\n        counters.append(Counter(recipe))\n    return counters\n\n\nclass WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, vocabulary_size=None, accumulate_outliers=False):\n        self.vocabulary_size = vocabulary_size \n        self.bias = int(accumulate_outliers)        \n        \n        \n    def fit(self, X, y=None):\n        total_count = Counter()\n        for word_counts in X:\n            for word, count in word_counts.items():\n                total_count[word] += 1\n        if self.vocabulary_size is None:\n            self.vocabulary_size = len(total_count)\n        most_common = total_count.most_common()[:self.vocabulary_size]\n        self.most_common_ = most_common\n        self.vocabulary_ = {word: index + self.bias for index, (word, count) in enumerate(most_common)}\n        return self\n    \n    \n    def transform(self, X, y=None):\n        rows = []\n        cols = []\n        data = []\n        for row, word_counts in enumerate(X):\n            for word, count in word_counts.items():\n                if self.bias or word in self.vocabulary_:\n                    rows.append(row)\n                    cols.append(self.vocabulary_.get(word, 0))\n                    data.append(count)\n        return csr_matrix((data, (rows, cols)), shape=(len(X), (self.vocabulary_size + self.bias)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data['ingredients'].values\ny = train_data['cuisine'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\ntrain_index, valid_index = next(sss.split(X, y))\nX_train, X_valid = X[train_index], X[valid_index]\ny_train, y_valid = y[train_index], y[valid_index]\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = WordCounterToVectorTransformer()\nX_train_sparce = vectorizer.fit_transform(to_counters(X_train))\nX_valid_sparce = vectorizer.transform(to_counters(X_valid))\nX_train_sparce[X_train_sparce > 1] = 1\nX_valid_sparce[X_valid_sparce > 1] = 1\nX_train_vec = X_train_sparce.toarray()\nX_valid_vec = X_valid_sparce.toarray()\n\nonehot = OneHotEncoder()\ny_train_onehot = onehot.fit_transform(y_train.reshape(-1, 1)).toarray()\ny_valid_onehot = onehot.transform(y_valid.reshape(-1, 1)).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Try ML models**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_classifier(classifier):\n    classifier.fit(X_train_sparce, y_train)\n    y_train_pred = classifier.predict(X_train_sparce)\n    y_valid_pred = classifier.predict(X_valid_sparce)\n    train_acc = accuracy_score(y_train, y_train_pred)\n    valid_acc = accuracy_score(y_valid, y_valid_pred)\n    print(f'train accuracy: {train_acc:.5f}\\nvalidation accuracy: {valid_acc:.5f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb = MultinomialNB()\nfit_classifier(mnb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=10, n_jobs=-1)\nfit_classifier(knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=100, \n                             max_depth=60,\n                             min_samples_leaf=5, \n                             random_state=0, \n                             class_weight='balanced_subsample',                            \n                             max_features=0.2, \n                             n_jobs=-1)\nfit_classifier(rfc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbc = GradientBoostingClassifier(n_estimators=30, max_features=0.2, random_state=0)\nfit_classifier(gbc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = AdaBoostClassifier(n_estimators=100, random_state=0)\nfit_classifier(abc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc_all_h = VotingClassifier(estimators=[('mnb', mnb), ('knn', knn), ('rfc', rfc), ('gbc', gbc), ('abc', abc)], n_jobs=-1)\nfit_classifier(vc_all_h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc_best_h = VotingClassifier(estimators=[('mnb', mnb), ('rfc', rfc), ('gbc', gbc)], n_jobs=-1)\nfit_classifier(vc_best_h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc_all_s = VotingClassifier(estimators=[('mnb', mnb), ('knn', knn), ('rfc', rfc), ('gbc', gbc), ('abc', abc)], voting='soft', n_jobs=-1)\nfit_classifier(vc_all_s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc_best_s = VotingClassifier(estimators=[('mnb', mnb), ('rfc', rfc), ('gbc', gbc)], voting='soft', n_jobs=-1)\nfit_classifier(vc_best_s)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Try DL models**"},{"metadata":{"trusted":true},"cell_type":"code","source":"K.clear_session()\n\ndef create_model():\n    dnn = Sequential()\n    dnn.add(InputLayer(input_shape=[X_train_vec.shape[1]]))\n    dnn.add(Dense(4000, activation='elu', kernel_initializer='he_normal'))\n    dnn.add(Dense(20, activation='softmax'))\n    return dnn\n\ndnn = create_model()\ndnn.compile(loss='categorical_crossentropy',\n            optimizer=Adam(lr=0.0001),\n            metrics=[\"accuracy\"])\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0,\n    patience=5,\n    verbose=0,\n    mode='min',\n    restore_best_weights=True)\ncallbacks = [early_stopping]\n\ndnn.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory = dnn.fit(X_train_vec, y_train_onehot, \n                  epochs=50, \n                  batch_size=128,\n                  validation_data=(X_valid_vec, y_valid_onehot),\n                  callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dnn.evaluate(X_valid_vec, y_valid_onehot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We get a good model configuration, now let's train a final model on the whole dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer_final = WordCounterToVectorTransformer()\nX_vec = vectorizer_final.fit_transform(to_counters(X)).toarray()\nX_vec[X_vec > 1] = 1\n\nonehot_final = OneHotEncoder()\ny_onehot = onehot_final.fit_transform(y.reshape(-1, 1)).toarray()\n\nK.clear_session()\n\ndnn_final = Sequential()\ndnn_final.add(InputLayer(input_shape=[X_vec.shape[1]]))\ndnn_final.add(Dense(4000, activation='elu', kernel_initializer='he_normal'))\ndnn_final.add(Dense(20, activation='softmax'))\ndnn_final.compile(loss='categorical_crossentropy',\n                  optimizer=Adam(lr=0.0001),\n                  metrics=[\"accuracy\"])\n\ndnn_final.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory_final = dnn_final.fit(X_vec, y_onehot, \n                              epochs=6, \n                              batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dnn_final.save('final.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dnn_final = load_model('final.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_data['ingredients'].values\nX_test = vectorizer_final.transform(to_counters(X_test)).toarray()\n\ny_test_pred = dnn_final.predict_classes(X_test)\ny_test_pred = onehot_final.categories_[0][y_test_pred]\n\nanswers = test_data.copy()\nanswers = answers.drop('ingredients', axis=1)\nanswers['cuisine'] = y_test_pred\nanswers.to_csv('answers.csv', index=False)\nanswers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Achieved accuracy in a competition: 79.092%**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}