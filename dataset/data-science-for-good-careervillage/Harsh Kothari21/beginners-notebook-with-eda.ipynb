{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"que = pd.read_csv('../input/data-science-for-good-careervillage/questions.csv')\nans = pd.read_csv('../input/data-science-for-good-careervillage/answers.csv')\nprof = pd.read_csv('../input/data-science-for-good-careervillage/professionals.csv')\nstud = pd.read_csv('../input/data-science-for-good-careervillage/students.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Look into DataSet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ans.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"que.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prof.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"que.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stud.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stud.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stud.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prof.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stud.students_location.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_locations = 20\n\nusers = [\n    ('students', stud),\n    ('professionals', prof)\n]\n\nfor user, df in users:\n    locations = df['{}_location'.format(user)].value_counts().sort_values(ascending=True).tail(n_locations)\n    \n    ax = locations.plot(kind='barh',figsize=(14, 10),width=0.8, fontsize=14) \n    ax.set_title('Top %s {} locations'.format(user) % n_locations, fontsize=20)\n    ax.set_xlabel('Number of {}'.format(user), fontsize=14)\n    for p in ax.patches:\n        ax.annotate(str(p.get_width()), (p.get_width(), p.get_y()), color='w', fontsize=14)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stud.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"que.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Datetime feature preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ans['answers_date_added'] = pd.to_datetime(ans['answers_date_added'], infer_datetime_format=True)\nprof['professionals_date_joined'] = pd.to_datetime(prof['professionals_date_joined'], infer_datetime_format=True)\nque['questions_date_added'] = pd.to_datetime(que['questions_date_added'], infer_datetime_format=True)\nstud['students_date_joined'] = pd.to_datetime(stud['students_date_joined'], infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Users Growth","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"users = [\n    ('students', stud),\n    ('professionals', prof)\n]\n\ncolors = {'students' : 'cyan', 'professionals' : 'mediumvioletred'}\n\nfor user, df in users:\n    \n    years = df['{}_date_joined'.format(user)].dt.year.unique()\n    years.sort()\n    \n    min_date = df['{}_date_joined'.format(user)].min()\n    min_date = min_date.strftime(\"%B %Y\")\n    \n    max_date = df['{}_date_joined'.format(user)].max()\n    max_date = max_date.strftime(\"%B %Y\")\n    \n    \n    amounts = [len(df[df['{}_date_joined'.format(user)].dt.year == y]) for y in years]\n    \n    for i in range(len(amounts)):\n        if i > 0:\n            amounts[i] += amounts[i - 1]\n    to_plot = pd.DataFrame({'years': years, 'users': amounts})\n    plt.figure(figsize=(14, 5))\n    \n    plt.plot('years', 'users', data=to_plot, marker='o', color=colors[user])\n    x = to_plot['years']\n    y = to_plot['users']\n    plt.fill_between(x, y, color=colors[user], alpha = 0.4)\n    \n    plt.ylabel('Users', fontsize=14)\n    plt.title('Growth of {}'.format(user), fontsize=20)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of Answers & Questions added per year","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"entities = [\n    ('questions', que),\n    ('answers', ans)\n]\n\ncolors = {'questions' : 'cyan', 'answers' : 'mediumvioletred'}\n\nfor entity, df in entities:\n    min_date = df['{}_date_added'.format(entity)].min().strftime(\"%B %Y\")\n    max_date = df['{}_date_added'.format(entity)].max().strftime(\"%B %Y\")\n\n    df['year'] = df['{}_date_added'.format(entity)].dt.year\n    plt_data = df.groupby('year').size()\n    plt_data.plot(figsize=(14, 5), color=colors[entity],  marker='o')\n\n    x = plt_data.reset_index()['year']\n    y = plt_data.reset_index()[0]\n    plt.fill_between(x, y, color=colors[entity], alpha = 0.4)\n\n    plt.xlabel('Year', fontsize=15)\n    plt.ylabel('{} Count'.format(entity.capitalize()), fontsize=15)\n    plt.title('Number of {} asked per year ({}-{})'.format(entity.capitalize(), min_date, max_date), fontsize=20)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Professionals Answers & Students Questions amounts","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter \n\nll = [\n    ('students', 'questions', stud, que),\n    ('professionals', 'answers', prof, ans)\n]\n\ncolors = {'students' : 'cyan', 'professionals' : 'mediumvioletred'}\n\nfor user, entity, user_df, entity_df in ll:\n    tm = dict(sorted(Counter(pd.merge(user_df, entity_df, left_on='{}_id'.format(user), right_on='{}_author_id'.format(entity), how='inner').groupby('{}_id'.format(user)).size().values).items())) \n    t_d = {}\n    t_d['{}_amount'.format(entity)] = list(tm.keys())\n    t_d['{}_amount'.format(user)] = list(tm.values())\n\n    plt_data = pd.DataFrame(t_d)\n\n    plt_data.plot(x='{}_amount'.format(entity), y='{}_amount'.format(user), kind='bar', figsize=(14, 5), color=colors[user])\n    plt.xlim(-1, 30)\n    plt.xlabel('{} Count'.format(entity.capitalize()), fontsize=15)\n    plt.ylabel('{} Count'.format(user.capitalize()), fontsize=15)\n    plt.title('{} {} Diagram'.format(user.capitalize(), entity.capitalize()), fontsize=20)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top n Professionals with most Answers & Students with most Questions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 10\n\nll = [\n    ('students', 'questions', stud, que),\n    ('professionals', 'answers', prof, ans)\n]\n\ncolors = {'students' : '#549da8', 'professionals' : '#852ab2'} \n\nfor user, entity, user_df, entity_df in ll:\n    top_n = pd.DataFrame(pd.merge(user_df, entity_df, left_on='{}_id'.format(user), right_on='{}_author_id'.format(entity), how='inner').groupby('{}_id'.format(user)).size().reset_index())\n    plt_data = top_n.rename(index=str, columns={0: '{}_amount'.format(entity)}).sort_values(by=['{}_amount'.format(entity)], ascending=False)[:n]\n\n    plt_data.plot(kind='bar', figsize=(14, 5), color=colors[user])\n    plt.xticks(np.arange(len(plt_data)), tuple(plt_data['{}_id'.format(user)]), rotation=90)\n    plt.xlabel('{} Ids'.format(user.capitalize()), fontsize=15)\n    plt.ylabel('{} Count'.format(entity.capitalize()), fontsize=15)\n    plt.title('Top {} {} with most {}'.format(n, user.capitalize(), entity), fontsize=20)\n    leg = plt.legend(loc='best', fontsize=15)\n    for text in leg.get_texts():\n        plt.setp(text, color = 'w')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First activity after registration \n### There are two general types of users:\n\n- Activity right after registration\n- No activity at all","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"answers = pd.read_csv('../input/data-science-for-good-careervillage/answers.csv')\nanswer_scores = pd.read_csv('../input/data-science-for-good-careervillage/answer_scores.csv')\ncomments = pd.read_csv('../input/data-science-for-good-careervillage/comments.csv')\nemails = pd.read_csv('../input/data-science-for-good-careervillage/emails.csv')\ngroups = pd.read_csv('../input/data-science-for-good-careervillage/groups.csv')\ngroup_memberships = pd.read_csv('../input/data-science-for-good-careervillage/group_memberships.csv')\nmatches = pd.read_csv('../input/data-science-for-good-careervillage/matches.csv')\nprofessionals = pd.read_csv('../input/data-science-for-good-careervillage/professionals.csv')\nquestions = pd.read_csv('../input/data-science-for-good-careervillage/questions.csv')\nquestion_scores = pd.read_csv('../input/data-science-for-good-careervillage/question_scores.csv')\nschool_memberships = pd.read_csv('../input/data-science-for-good-careervillage/school_memberships.csv')\nstudents = pd.read_csv('../input/data-science-for-good-careervillage/students.csv')\ntags = pd.read_csv('../input/data-science-for-good-careervillage/tags.csv')\ntag_questions = pd.read_csv('../input/data-science-for-good-careervillage/tag_questions.csv')\ntag_users = pd.read_csv('../input/data-science-for-good-careervillage/tag_users.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answers['answers_date_added'] = pd.to_datetime(answers['answers_date_added'], infer_datetime_format=True)\ncomments['comments_date_added'] = pd.to_datetime(comments['comments_date_added'], infer_datetime_format=True)\nemails['emails_date_sent'] = pd.to_datetime(emails['emails_date_sent'], infer_datetime_format=True)\nprofessionals['professionals_date_joined'] = pd.to_datetime(professionals['professionals_date_joined'], infer_datetime_format=True)\nquestions['questions_date_added'] = pd.to_datetime(questions['questions_date_added'], infer_datetime_format=True)\nstudents['students_date_joined'] = pd.to_datetime(students['students_date_joined'], infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Last Answer\ntemp = answers.groupby('answers_author_id')['answers_date_added'].max()\nprofessionals['date_last_answer'] = pd.merge(professionals, pd.DataFrame(temp.rename('last_answer')), left_on='professionals_id', right_index=True, how='left')['last_answer']\n# First Answer\ntemp = answers.groupby('answers_author_id')['answers_date_added'].min()\nprofessionals['date_first_answer'] = pd.merge(professionals, pd.DataFrame(temp.rename('first_answer')), left_on='professionals_id', right_index=True, how='left')['first_answer']\n# Last Comment\ntemp = comments.groupby('comments_author_id')['comments_date_added'].max()\nprofessionals['date_last_comment'] = pd.merge(professionals, pd.DataFrame(temp.rename('last_comment')), left_on='professionals_id', right_index=True, how='left')['last_comment']\n# First Comment\ntemp = comments.groupby('comments_author_id')['comments_date_added'].min()\nprofessionals['date_first_comment'] = pd.merge(professionals, pd.DataFrame(temp.rename('first_comment')), left_on='professionals_id', right_index=True, how='left')['first_comment']\n# Last Activity\nprofessionals['date_last_activity'] = professionals[['date_last_answer', 'date_last_comment']].max(axis=1)\n# First Activity\nprofessionals['date_first_activity'] = professionals[['date_first_answer', 'date_first_comment']].min(axis=1)\n# Last activity (Question)\ntemp = questions.groupby('questions_author_id')['questions_date_added'].max()\nstudents['date_last_question'] = pd.merge(students, pd.DataFrame(temp.rename('last_question')), left_on='students_id', right_index=True, how='left')['last_question']\n# First activity (Question)\ntemp = questions.groupby('questions_author_id')['questions_date_added'].min()\nstudents['date_first_question'] = pd.merge(students, pd.DataFrame(temp.rename('first_question')), left_on='students_id', right_index=True, how='left')['first_question']\n# Last activity (Comment)\ntemp = comments.groupby('comments_author_id')['comments_date_added'].max()\nstudents['date_last_comment'] = pd.merge(students, pd.DataFrame(temp.rename('last_comment')), left_on='students_id', right_index=True, how='left')['last_comment']\n# First activity (Comment)\ntemp = comments.groupby('comments_author_id')['comments_date_added'].min()\nstudents['date_first_comment'] = pd.merge(students, pd.DataFrame(temp.rename('first_comment')), left_on='students_id', right_index=True, how='left')['first_comment']\n# Last activity (Total)\nstudents['date_last_activity'] = students[['date_last_question', 'date_last_comment']].max(axis=1)\n# First activity (Total)\nstudents['date_first_activity'] = students[['date_first_question', 'date_first_comment']].min(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pro_emails = pd.merge(professionals, emails, how='inner', left_on='professionals_id', right_on='emails_recipient_id')\npro_emails = pro_emails[pro_emails['emails_frequency_level'] == 'email_notification_immediate']\npro_emails = pro_emails[['professionals_id', 'emails_id', 'emails_date_sent']]\n\npro_email_ques = pro_emails.merge(matches, left_on='emails_id', right_on='matches_email_id')\npro_email_ques = pro_email_ques.drop(columns=['emails_id', 'matches_email_id']) \\\n                 .set_index('professionals_id').rename(columns={'matches_question_id': 'questions_id'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"users = [\n    ('students', students),\n    ('professionals', professionals)\n]\n\nmin_rel_date = '01-01-2016'\nmax_rel_date = '01-01-2019'\n\nplt_data = {}\n\nfor user, df in users:\n    df = df[(df['{}_date_joined'.format(user)] >= min_rel_date) & (df['{}_date_joined'.format(user)] <= max_rel_date)]\n    df = (df['date_first_activity'] - df['{}_date_joined'.format(user)]).dt.days.fillna(10000).astype(int)\n    df = df.groupby(df).size()/len(df)\n    df = df.rename(lambda x: 0 if x < 0 else x)\n    df = df.rename(lambda x: x if x <= 1 or x == 10000 else '> 1')\n    df = df.rename({10000: 'NaN'})\n    df = df.groupby(level=0).sum()\n\n    plt_data[user] = df\n\nplt_data = pd.DataFrame(plt_data)\n\nplt_data.plot(kind='bar', figsize=(14, 5), colors=('#852ab2', '#21b7f2'))\nplt.xlabel('Days', fontsize=15)\nplt.ylabel('Ration', fontsize=15)\nplt.title('Days before first activity after registration', fontsize=20)\nleg = plt.legend(bbox_to_anchor=(1, 0.5), fontsize=15)\nfor text in leg.get_texts():\n    plt.setp(text, color = 'w')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Last activity \nDepending on the last comment, question or answer of a user, we have extracted the last activity date. On the previous plot we have seen, that many users haven't done any activity yet. For the 'last activity' plot we take a look only on users with already have one activity (dropna).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nfrom datetime import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Date of export\ncurrent_date = datetime(2019, 2 ,1)\n\nusers = [\n    ('students', students),\n    ('professionals', professionals)\n]\n\nplt_data = {}\n\nfor user, df in users:\n    df = ((current_date - df['date_last_activity']).dt.days/30).dropna().astype(int)\n    df = df.groupby(df).size()/len(df)\n    df = df.rename(lambda x: 0 if x < 0 else x).rename(lambda x: x if x <= 30 or x == 10000 else '> 30').rename({10000:'NaN'})\n    df = df.groupby(level=0).sum()\n\n    plt_data[user] = df\n\nplt_data = pd.DataFrame(plt_data)\n\nplt_data.plot(kind='bar', figsize=(14, 5), colors=('#852ab2', '#21b7f2'))\nplt.xlabel('Months', fontsize=15)\nplt.ylabel('Ratio', fontsize=15)\nplt.title('Last activity by Month', fontsize=20)\nleg = plt.legend(loc='best', fontsize=15)\nfor text in leg.get_texts():\n    plt.setp(text, color = 'w')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of Emails sent per year\nThe number of emails sent yearly tends to grow each year.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"min_date = emails['emails_date_sent'].min().strftime(\"%B %Y\")\nmax_date = emails['emails_date_sent'].max().strftime(\"%B %Y\")\n\nemails['year'] = emails['emails_date_sent'].dt.year\nplt_data = emails.groupby('year').size()\n\nplt_data.plot(figsize=(14, 5), color='#f4d641',  marker='o')\n\nx = plt_data.reset_index()['year']\ny = plt_data.reset_index()[0]\nplt.fill_between(x, y, color='#f4d641', alpha = 0.4)\n\nplt.xlabel('Year', fontsize=20)\nplt.ylabel('Emails Amount', fontsize=20)\nplt.title('Number of Emails sent per year ({0}, {1})'.format(min_date, max_date), fontsize=20)\nleg = plt.legend(loc='best', fontsize=15)\nfor text in leg.get_texts():\n    plt.setp(text, color = 'w')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How many questions are contained in each email\nMost emails contain 1-3 questions, so an average amount of questions per email is 2.33.\n\nAccessing questions is also possible directly from the Career Village website, so professionals are not restricted to answering emails, so contact method should not be assumed. However, we need inferred links between questions and professionals to build a recommender.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"e_m = pd.DataFrame(pd.merge(emails, matches, how='inner', left_on='emails_id', right_on='matches_email_id').groupby('emails_id').size().reset_index()).rename(index=str, columns={0: \"questions_amount\"}).sort_values(by=['questions_amount'], ascending=False)\nplt_data = e_m.groupby('questions_amount').size().reset_index().rename(index=str, columns={0: \"emails_amount\"})\n\nmapping = {\n    1: '1',\n    2: '2',\n    3: '3',\n    4: '4 - 7',\n    8: '8 - 10',\n}\n\ndef get_key(x):\n    for i in range(x, 0, -1):\n        if i in mapping:\n            return mapping[i]\n\n\nplt_data['groups'] = plt_data['questions_amount'].apply(lambda x: '>10' if x >= 11 else get_key(x))\nplt_data = pd.DataFrame({'groups' :['0'], 'emails_amount' : [len(emails) - len(e_m)]}).append(plt_data.groupby('groups').sum().reset_index()[['groups', 'emails_amount']])\n\nplt_data.plot(kind='bar', figsize=(14, 5), color='#57c6b1')\n\nplt.xticks(np.arange(len(plt_data)), tuple(plt_data['groups']))\nplt.xlabel('Questions Count', fontsize=15)\nplt.ylabel('Emails Count', fontsize=15)\nplt.title('Questions contained in each email', fontsize=20)\nleg = plt.legend(loc='best', fontsize=15)\nfor text in leg.get_texts():\n    plt.setp(text, color = 'w')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tags Wordclouds \nIn most of the cases, students are not using tags. Student tags are similar to questions tags. The current system is recommending questions tags, and they are not that similar to those which professionals are following.\n\nTags of questions and students and more generalized comparing to professionals tags. It means that even if we apply some processing and modeling techniques and deriving similarities out of it, there still be unmatched student and professionals using tags due to generalized vs. specialized tags problem.\n\nOur model also solves this issue.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"entities = [\n    ('students', students),\n    ('professionals', professionals),\n    ('questions', questions)\n]\n\ndfs = []\n\nfor entity, df in entities:\n    if entity == 'questions':\n        df = tag_questions\n        df = pd.merge(df, tags, left_on='tag_questions_tag_id', right_on='tags_tag_id')\n    else:\n        df = tag_users[tag_users['tag_users_user_id'].isin(df['{}_id'.format(entity)])]\n        df = pd.merge(df, tags, left_on='tag_users_tag_id', right_on='tags_tag_id')\n\n    df['entity_type'] = entity\n\n    dfs.append(df)\n\n\nplt_data = pd.concat(dfs)\n\nplt_data = plt_data[['tags_tag_name', 'entity_type']].pivot_table(index='tags_tag_name', columns='entity_type', aggfunc=len, fill_value=0)\n\nfor entity, df in entities:\n    plt_data[entity] = plt_data[entity] / len(df)\n\nplt_data['sum'] = (plt_data['professionals'] + plt_data['students'] + plt_data['questions'])\nplt_data = plt_data.sort_values(by='sum', ascending=False).drop(['sum'], axis=1).head(100)\n\n\n# Wordcloud\nplt.figure(figsize=(20, 20))\nwordloud_values = ['students', 'professionals', 'questions']\naxisNum = 1\nfor wordcloud_value in wordloud_values:\n    wordcloud = WordCloud(margin=0, max_words=20, random_state=42).generate_from_frequencies(plt_data[wordcloud_value])\n    ax = plt.subplot(1, 3, axisNum)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.title(wordcloud_value)\n    plt.axis(\"off\")\n    axisNum += 1\nplt.show()    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}