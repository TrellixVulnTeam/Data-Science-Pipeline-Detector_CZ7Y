{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Methodology\nThis noteook illustrates the idea of recommending professionals based the similairty between the question and professionals' previous answers or user information. The professional are divided into two categories.\n\n## Ref\nThe recommendation system idea based on similary is based on Daniel Becker's [Kernal](https://www.kaggle.com/danielbecker/careervillage-org-recommendation-engine)\n\n## Categories\n- Prof: The professor has answered questions\n- New prof: The professor is new or did not answer any question yet\n### For the Prof (provided answered before)\nThe similarity is based on their previous answers and the new question\n### For the New prof(never answered a question)\nThe similarity is based on their user information, including tags and the new question\n\n\n# Steps for recommending a Prof:\n\n1. Calculate the tf-idf for the query text and all the questions\n2. Use the cosine similiarty to get similiar questions for the query text.\n3. Get the answers and professionals for the similar questions.\n4. Make a recommendation to fit the best professionals to answer the new question."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper libraries\nimport os\nimport math\nimport warnings\nimport pickle\nimport re\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom nltk.corpus import stopwords","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read Data\nfiles = [(f[:-4],\"../input/%s\"%f) for f in os.listdir(\"../input\")]\nfiles = dict(files)\nprint(os.listdir(\"../input\"))\n\ndef read_csv(name):\n    if name not in files:\n        print(\"error\")\n        return None    \n    return pd.read_csv(files[name])\n\n# load data\nquestions = read_csv(\"questions\")\nanswers = read_csv(\"answers\")\nprofessionals = read_csv(\"professionals\")","execution_count":2,"outputs":[{"output_type":"stream","text":"['emails.csv', 'questions.csv', 'professionals.csv', 'comments.csv', 'tag_users.csv', 'group_memberships.csv', 'tags.csv', 'answer_scores.csv', 'students.csv', 'groups.csv', 'tag_questions.csv', 'question_scores.csv', 'matches.csv', 'answers.csv', 'school_memberships.csv']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess the data"},{"metadata":{},"cell_type":"markdown","source":"### The following lines are used for preprocessing data. If no change made, you can just load the presaved data"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Read questions data\nq = questions.copy()\nq['qtext'] = list(q.apply(lambda x:'%s %s' %(x['questions_title'],x['questions_body']), axis=1))\nq = q.drop(['questions_author_id','questions_date_added','questions_body','questions_title'],axis=1)\n\n### Read answers data\na = answers.copy()\na = a.drop(['answers_date_added'],axis=1)\nuri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))'\ntag_re = r'<\\/?[a-z]+>'\n\ndef strip_html_tag(s):\n    temp = re.sub(uri_re, ' ', str(s))\n    return re.sub(tag_re, ' ', temp)\n\na['answers_body'] = a['answers_body'].apply(strip_html_tag)\na.rename(columns={'answers_question_id':'questions_id',\n                  'answers_author_id':'professionals_id',\n                  \"answers_body\":\"atext\"},inplace=True)\n          \n### Read professionals data\np = professionals.copy()\n# Connect these professionals with tags and user_tag tables\ntags = read_csv(\"tags\")\ntag_users = read_csv(\"tag_users\")\n\ntag_users = tag_users[tag_users[\"tag_users_user_id\"].isin(p['professionals_id'])]\ntag_users = tag_users.merge(tags, how=\"left\", left_on=\"tag_users_tag_id\", right_on = \"tags_tag_id\")\n\nt = tag_users.groupby([\"tag_users_user_id\"])['tags_tag_name'].apply(lambda x: ' '.join(x))\nt = t.to_frame().reset_index()\n\np = p.merge(t, how=\"left\", left_on=\"professionals_id\", right_on = \"tag_users_user_id\")\n\n# get text\ntemp = p[['professionals_location','professionals_industry','professionals_headline','tags_tag_name']].fillna('')\n\np['ptext'] = temp['professionals_location']+\" \"+temp['professionals_industry']+\" \"+\\\n             temp['professionals_headline']+\" \"+temp['tags_tag_name']\n\np = p.drop(['professionals_location','professionals_industry','professionals_headline',\\\n           'professionals_date_joined','tag_users_user_id','tags_tag_name'],axis=1)\n\nprint(\"Number of professionals: \",len(p['ptext']),\",with \",sum(p['ptext']!=\"   \"),\" of them having data\" )","execution_count":3,"outputs":[{"output_type":"stream","text":"Number of professionals:  28152 ,with  27770  of them having data\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove general words\nnoise = ['school','would','like', 'want', 'dont', \n         'become','sure','go', 'get', 'college', \n         'career', 'wanted', 'im', 'ing', 'ive',\n         'know', 'high', 'becom', 'job', 'best',\n         'day', 'hi', 'name', 'help', 'people',\n         'year', 'years', 'next', 'interested', \n         'question', 'questions', 'take', 'even',\n         'though', 'please', 'tell']\n\nstop = stopwords.words('english')\n\ndef remove_general_words(df, col):\n    df[col] = df[col].str.lower().str.split() # convert all str to lowercase    \n    df[col] = df[col].apply(lambda x: [item for item in x if item not in stop]) # remove stopwords\n    df[col] = df[col].apply(lambda x: [item for item in x if item not in noise]) # remove general words\n    df[col] = df[col].apply(' '.join) # convert list to str\n    return df\n\nq = remove_general_words(q,'qtext')\np = remove_general_words(p,'ptext')\na = remove_general_words(a,'atext')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# Save the data\npickle.dump(q, open('../input/q.p', 'wb'))\npickle.dump(a, open('../input/a.p', 'wb'))\npickle.dump(p, open('../input/p.p', 'wb'))\n'''","execution_count":5,"outputs":[{"output_type":"error","ename":"OSError","evalue":"[Errno 30] Read-only file system: '../input/q.p'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-dfb6276d7339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/q.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/a.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/p.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '../input/q.p'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# Read saved data\nq = pickle.load(open('../input/q.p', mode='rb'))\na = pickle.load(open('../input/a.p', mode='rb'))\np = pickle.load(open('../input/p.p', mode='rb'))\n'''","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"\"\\n# Read saved data\\nq = pickle.load(open('../input/q.p', mode='rb'))\\na = pickle.load(open('../input/a.p', mode='rb'))\\np = pickle.load(open('../input/p.p', mode='rb'))\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_similar_docs(corpus, query_text, threshold=0.0, top=10):\n    tfidf = TfidfVectorizer(ngram_range=(1,3), stop_words = 'english', max_features = 500, max_df=0.9)\n    corpus_tfidf = tfidf.fit_transform(corpus)\n    text_tfidf = tfidf.transform([query_text])\n    sim = cosine_similarity(corpus_tfidf, text_tfidf)\n    sim_idx = (sim >= threshold).nonzero()[0]\n    result = pd.DataFrame({'similarity':sim[sim_idx].reshape(-1,),\n                          'text':corpus[sim_idx]},\n                          index=sim_idx)\n    result = result.sort_values(by=['similarity'], ascending=False).head(top)\n    return result","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example\ncorpus = q['qtext']\nquery_text = corpus[2]\nprint('Example 1 Question:\\n', query_text)\nsim_questions = get_similar_docs(corpus, query_text)","execution_count":8,"outputs":[{"output_type":"stream","text":"Example 1 Question:\n going abroad first increase chances jobs back home? i'm planning going abroad first job. teaching serious ideas. working stay home instead i'm assuming staying leaving makeba huge difference care about, unless find something first job. think ways going abroad seen good bad. side respectable employers willl side with. #working-abroad #employment- #overseas\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sim_questions","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"       similarity                                               text\n2        1.000000  going abroad first increase chances jobs back ...\n5590     0.667993                 scope b sc (zoology) abroad ? #any\n6551     0.586143  look teaching abroad experience? enjoy tutorin...\n10747    0.579467  what’s hardest part studying abroad student be...\n8972     0.575461  studying abroad summer valencia, spain wonderi...\n20681    0.569156  meaningful trips abroad experience budget? tra...\n18806    0.566032  cashier; settle abroad suggest steps take? com...\n21399    0.552790  learning abroad give leg amongst future compet...\n17864    0.544714  studying abroad change perspective? going coll...\n12330    0.537329  merits studying abroad? second student college...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>similarity</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>going abroad first increase chances jobs back ...</td>\n    </tr>\n    <tr>\n      <th>5590</th>\n      <td>0.667993</td>\n      <td>scope b sc (zoology) abroad ? #any</td>\n    </tr>\n    <tr>\n      <th>6551</th>\n      <td>0.586143</td>\n      <td>look teaching abroad experience? enjoy tutorin...</td>\n    </tr>\n    <tr>\n      <th>10747</th>\n      <td>0.579467</td>\n      <td>what’s hardest part studying abroad student be...</td>\n    </tr>\n    <tr>\n      <th>8972</th>\n      <td>0.575461</td>\n      <td>studying abroad summer valencia, spain wonderi...</td>\n    </tr>\n    <tr>\n      <th>20681</th>\n      <td>0.569156</td>\n      <td>meaningful trips abroad experience budget? tra...</td>\n    </tr>\n    <tr>\n      <th>18806</th>\n      <td>0.566032</td>\n      <td>cashier; settle abroad suggest steps take? com...</td>\n    </tr>\n    <tr>\n      <th>21399</th>\n      <td>0.552790</td>\n      <td>learning abroad give leg amongst future compet...</td>\n    </tr>\n    <tr>\n      <th>17864</th>\n      <td>0.544714</td>\n      <td>studying abroad change perspective? going coll...</td>\n    </tr>\n    <tr>\n      <th>12330</th>\n      <td>0.537329</td>\n      <td>merits studying abroad? second student college...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Merges the questions with the corresponding answers"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_questions_answers(sim_questions):  \n    sim_q_a = sim_questions.merge(q, left_index=True, right_index=True).merge(a)\n    return sim_q_a","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sim_q_a = get_questions_answers(sim_questions)\nsim_q_a.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"   similarity                        ...                                                                      atext\n0    1.000000                        ...                          work global company values highly internationa...\n1    0.667993                        ...                                                                           \n2    0.667993                        ...                                           sameer, could rephrase question?\n3    0.586143                        ...                                                     education key success!\n4    0.579467                        ...                          athena, congrats getting trinity! truly except...\n\n[5 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>similarity</th>\n      <th>text</th>\n      <th>questions_id</th>\n      <th>qtext</th>\n      <th>answers_id</th>\n      <th>professionals_id</th>\n      <th>atext</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>going abroad first increase chances jobs back ...</td>\n      <td>4ec31632938a40b98909416bdd0decff</td>\n      <td>going abroad first increase chances jobs back ...</td>\n      <td>1a6b3749d391486c9e371fbd1e605014</td>\n      <td>7e72a630c303442ba92ff00e8ea451df</td>\n      <td>work global company values highly internationa...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.667993</td>\n      <td>scope b sc (zoology) abroad ? #any</td>\n      <td>89103412bd0f433996599b67c4d2ff5d</td>\n      <td>scope b sc (zoology) abroad ? #any</td>\n      <td>0663b9f6f90a485787865282a8aadb28</td>\n      <td>036358eed7044c66a6058d1006fedbad</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.667993</td>\n      <td>scope b sc (zoology) abroad ? #any</td>\n      <td>89103412bd0f433996599b67c4d2ff5d</td>\n      <td>scope b sc (zoology) abroad ? #any</td>\n      <td>1885ba1004b540be8cf29496beb9fdea</td>\n      <td>58fa5e95fe9e480a9349bbb1d7faaddb</td>\n      <td>sameer, could rephrase question?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.586143</td>\n      <td>look teaching abroad experience? enjoy tutorin...</td>\n      <td>0f12d98bfe5d4aef862bc77f8b40e736</td>\n      <td>look teaching abroad experience? enjoy tutorin...</td>\n      <td>2210b91d822c4c279cf31222b0d92e4a</td>\n      <td>ce169b8f116243849edd246fef5a204b</td>\n      <td>education key success!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.579467</td>\n      <td>what’s hardest part studying abroad student be...</td>\n      <td>13249144c97f4d5e8e69efba68cdb4cc</td>\n      <td>what’s hardest part studying abroad student be...</td>\n      <td>44853686b07549e4adc2ad1c8a4aa8cb</td>\n      <td>8aca53dfdf6e4c2c85a4f0eacd996a46</td>\n      <td>athena, congrats getting trinity! truly except...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Get the top recommended professionals based on questions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_recommendation(df, top_n=5):\n    temp_values = df['similarity']/df['questions_id'].apply(lambda x: df.groupby('questions_id').size()[x])\n    temp_values = temp_values * df['professionals_id'].apply(lambda x: df.groupby('professionals_id').size()[x])\n    df[\"value\"] = temp_values\n    top_prof = df.groupby('professionals_id').sum().reset_index().sort_values('value', ascending = False).head(top_n)\n    top_prof = top_prof[['professionals_id', 'value']]\n    top_prof.columns = ['professional', 'recommendation_score']\n    print(top_prof)        ","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_recommendation(sim_q_a)","execution_count":13,"outputs":[{"output_type":"stream","text":"                        professional  recommendation_score\n10  7e72a630c303442ba92ff00e8ea451df              1.000000\n13  a2a3490912f9435b82172850e907c1c7              0.913240\n15  ce169b8f116243849edd246fef5a204b              0.586143\n16  e44c2855fd6649ae869fe145d167cbe4              0.575461\n2   211e39ac71694bb5af233b205a0f2057              0.566032\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Steps for recommending a new prof"},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"When a new professor has not answered any question, the above method will not be able to pair him to the new questions. We will use prof's information and tags in this case. \n\n1. Filter out the new professionals\n2. Rank the similarity between the new question and professionals' information\n3. Make a recommendation to fit the best professionals to answer the new question."},{"metadata":{"trusted":true},"cell_type":"code","source":"# find the new professionals\npa = p.merge(a, how = \"left\")\np_new = p[pa[\"questions_id\"].isnull()]\nprint (\"There are\",p_new.shape[0],\"new professionals\")","execution_count":14,"outputs":[{"output_type":"stream","text":"There are 4078 new professionals\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n  This is separate from the ipykernel package so we can avoid doing imports until\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example\ncorpus_p = p['ptext']\nprint('Example 2 Question:\\n', query_text)\nsim_professionals = get_similar_docs(corpus_p, query_text, top=2)","execution_count":15,"outputs":[{"output_type":"stream","text":"Example 2 Question:\n going abroad first increase chances jobs back home? i'm planning going abroad first job. teaching serious ideas. working stay home instead i'm assuming staying leaving makeba huge difference care about, unless find something first job. think ways going abroad seen good bad. side respectable employers willl side with. #working-abroad #employment- #overseas\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recommend new professiors\nrec_new = sim_professionals.merge(p, left_index=True, right_index=True)[['professionals_id', 'similarity']]\nrec_new.columns = ['professional', 'recommendation_score']\nrec_new","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"                           professional  recommendation_score\n26052  5f472f31cb784afea23dfa9e8eef4661              0.584398\n27039  b8e73f39630044b19514db3608863805              0.569107","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>professional</th>\n      <th>recommendation_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26052</th>\n      <td>5f472f31cb784afea23dfa9e8eef4661</td>\n      <td>0.584398</td>\n    </tr>\n    <tr>\n      <th>27039</th>\n      <td>b8e73f39630044b19514db3608863805</td>\n      <td>0.569107</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:anaconda]","language":"python","name":"conda-env-anaconda-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.3"}},"nbformat":4,"nbformat_minor":1}