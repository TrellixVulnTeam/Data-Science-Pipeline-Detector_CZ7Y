{"cells":[{"metadata":{},"cell_type":"markdown","source":"### This code was created for submission to Data Science for Good: CareerVillage.org\nHere are the codes for the following two processes:\n\n1, The first process is data reading, copying, tokenizing, etc. The execution time is about 10 minutes on the PC, and is executed when updating data.\n Processing items and flows are as followings.\n- Read csv data\n- Copy \"answers\", \"questions\", \"professionals\" for data processing and addition\n- Add 'score' column from answer_scores to answers_copy\n- Add 'score' column from question_scores to questions_copy\n- Calculate response days from question to the answer, and add it to answers_copy\n- Tokenize from questions_title and questions_body to questions_words\n- Get tags from questions_body to questions_body_tags\n- Merge professionals_industry and professionals_headline, and tokenize them to 'ind_head'.\n- Join ind_head to ind_head_sp with space, for high-speed search\n- Convert professionals_date_joined to professionals_date_joined_dt with Datetime format \n\n2, The second process actually enters a question and selects authors for the answer. \n  Processing items and flows are as follows, and it takes about 6 seconds by PC(i7/8GB)\n- Two input methods are prepared.\n        (1)The first method is to input title and body directly by str.\n        (2)The second is a method of specifying the index of Framedata of \"questions\" by integer.\n- The hyper parameters are below.\n        'number_of_authors': Number of authors to select. default[10]\n        'sample_num': Number of questions to compare similarity, larger number takes processing time. default[10]\n        'tag_coef': Priority coefficient of tag for body words in calculating questions similarity. default[2]\n        'expiration_date': Similar questions prioritize newer ones within 'expiration_date'.  default[1000]\n        'reseponse_time_limit': Similar answer prioritize faster response to the answer within 'reseponse_time_limit'.  default[30] \n        'thank_coef':  Priority coefficient of the number of \"thank\" included in the comment of the answer. default[1]\n        'rand_coef': Random coefficient of 0. to 1., 0.[default]: select from rank high, 1.: 100% random.  default[0] 'rand_coef' can add fluctuation to the selection  \t\t\t\t\t \n- Calucurate questions_copy['questions_similarity'] to input question by Jaccard similarity.\n        questions_similarity = (jaccard_index(word)+jaccard_index(tag)*tag_coef)*(log(score+1)+1)*(1-delta_day/expiration_date)\n- Choose 'questions_selected' of quantity of 'sample_num'\n- Select answers of the 'questions_selected'\n- Count 'thank' from the comments of each answer.\n- Listed aurhors of the selected answers and calculate the author_priority from score, Response_day, questions_similarity and number of \"thank\".      \n        author_selected['author_priority'] = (1 + author_selected['thank_mean'] * thank_coef) * author_selected['similarity_mean'] * author_selected['answer_count'] * (1 - author_selected['respose_day_mean'] / reseponse_time_limit) * author_selected['score_mean']\n- Collect words from the selected authors and aggregate the author_priority to each words.\n- Calculate professionals_priority for all of professionals by words' priority.\n- Set higher 'author_priority' for 'author_selected'\n- Sort professionals by the priority and select recommendation of professionals due to 'rand_coef'\n        select.index = int((1-random.random()**rand_coef)*professionals_sorted.shape[0])"},{"metadata":{},"cell_type":"markdown","source":"Loading Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport math\nimport datetime as dt\nimport sys, time\nfrom datetime import datetime\nfrom tqdm import tqdm_notebook\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nimport copy\nimport random","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#function of delta_days = date1 - date2\ndef delta_days(date1, date2):\n    d1=dt.datetime.strptime(date1[:19], '%Y-%m-%d %H:%M:%S')\n    d2=dt.datetime.strptime(date2[:19], '%Y-%m-%d %H:%M:%S')\n    return (d1-d2).days+(d1-d2).seconds/(3600*24)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function of days_to_now\ndef days_to_now(date):\n    d1=dt.datetime.now()\n    d2=dt.datetime.strptime(date[:19], '%Y-%m-%d %H:%M:%S')\n    return (d1-d2).days+(d1-d2).seconds/(3600*24)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tokenizing function\nstopWords = set(stopwords.words('english'))\nstopWords |= set([\"n't\",\"'m\",\"'re\",\"'ve\",\"'s\",\".\", \"|\", 'ï¼‹', \"^\", \"=\"])\ndef get_word_list(text):\n    text_tokenized = [wt[0].lower() for wt in nltk.pos_tag(nltk.word_tokenize(text)) \\\n                      if ('NN'  in wt[1]) or ('JJ'  in wt[1]) or ('RB'  in wt[1]) or ('VB'  in wt[1])]\n    return [w for w in text_tokenized if w not in stopWords if w!='+']","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function of getting tag list from text\ndef get_tag_list(text):\n    tag_name = []\n    wl=word_tokenize(text)\n    for i,w in enumerate(wl):\n        if ('#' in w) and (i != len(wl)-1) and (len(w)>0):\n            if len(wl[i+1])>1:\n                tag_name.append(wl[i+1].lower())\n    return tag_name","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#jaccard similarity\ndef get_jac_sim(content1,content2):\n    a=set(content1)\n    b=set(content2)\n    if len(a.union(b))==0:\n        return 0\n    else:\n        return len(a.intersection(b))/len(a.union(b))","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading and Data processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading and data preprocessing\ndef processing_data():\n    \n    #Update files\n    print('---  1/10',\"\\r\", end=\"\")\n    answer_scores = pd.read_csv('../input/answer_scores.csv')\n    answers = pd.read_csv('../input/answers.csv')\n    comments = pd.read_csv('../input/comments.csv')\n    professionals = pd.read_csv('../input/professionals.csv')\n    question_scores = pd.read_csv('../input/question_scores.csv')\n    questions = pd.read_csv('../input/questions.csv')\n\n    #Copy three files for data processing\n    print('---  2/10',\"\\r\", end=\"\")\n    answers_copy=copy.copy(answers)\n    questions_copy=copy.copy(questions)\n    professionals_copy=copy.copy(professionals)\n\n    #Add 'score' column from answer_scores to answers_copy\n    print(\"---  3/10\",\"\\r\", end=\"\")\n    answers_copy['score']=0\n    answers_arr=answers_copy.values\n    answer_s_arr=answer_scores.values\n    for i in range(len(answers_arr)):\n        search_arr=np.any(answer_s_arr==answers_arr[i,0], axis=1)\n        if any(search_arr)==True:\n            answers_arr[i,5]=answer_s_arr[search_arr,1][0]\n    answers_copy=pd.DataFrame(answers_arr, index=answers_copy.index, columns=answers_copy.columns)\n\n    #Add 'score' column from question_scores to questions_copy\n    print(\"---  4/10\",\"\\r\", end=\"\")\n    questions_copy['score']=0\n    questions_arr=questions_copy.values\n    question_s_arr=question_scores.values\n    for i in range(len(questions_arr)):\n        searchq_arr=np.any(question_s_arr==questions_arr[i,0], axis=1)\n        if any(searchq_arr)==True:\n            questions_arr[i,5]=question_s_arr[searchq_arr,1][0]\n    questions_copy=pd.DataFrame(questions_arr, index=questions_copy.index, columns=questions_copy.columns)\n\n    #Calculate response days from question to the answer, and add it to answers_copy\n    print(\"---  5/10\",\"\\r\", end=\"\")\n    for i in answers.index:\n        answers_copy.loc[i,'Response_day']=delta_days(answers_copy.loc[i,'answers_date_added'],\n            questions_copy[questions_copy['questions_id']==answers_copy.loc[i,'answers_question_id']].iloc[0]['questions_date_added'])\n\n    #Tokenize from questions_title and questions_body to questions_words\n    print(\"---  6/10\",\"\\r\", end=\"\")\n    questions_copy['questions_words']=[get_word_list(x) for x in (questions_copy['questions_body'] +\n                                                                  ' ' + questions_copy['questions_title'])]\n\n    #Get tags from questions_body to questions_body_tags\n    print(\"---  7/10\",\"\\r\", end=\"\")\n    questions_copy['questions_body_tags']=[get_tag_list(x) for x in questions_copy['questions_body']]\n\n    #Merge (professionals_location,) professionals_industry and professionals_headline to ind_head\n    print(\"---  8/10\",\"\\r\", end=\"\")\n    professionals_copy = professionals_copy.fillna('')\n    professionals_copy['ind_head'] = ''\n    for x in professionals_copy.index:\n        professionals_copy.at[x,'ind_head'] = set(get_word_list(professionals_copy.loc[x,'professionals_industry'])) | \\\n                set(get_word_list(professionals_copy.loc[x,'professionals_headline'])) \n\n    # Join ind_head to ind_head_sp with space for high-speed search \n    print(\"---  9/10\",\"\\r\", end=\"\")\n    professionals_copy['ind_head_sp']=[\" \".join(x) for x in professionals_copy['ind_head']]\n\n    # Convert professionals_date_joined to professionals_date_joined_dt with Datetime format \n    print(\"--- 10/10\",\"\\r\", end=\"\")\n    professionals_copy['professionals_date_joined_dt']=[dt.datetime.strptime(professionals_copy.loc[x,'professionals_date_joined'][:19],\n                                                                        '%Y-%m-%d %H:%M:%S') for x in professionals_copy.index]\n    print(\"Finished \",\"\\r\")\n    return answers_copy, questions_copy, professionals_copy, comments","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time answers_copy, questions_copy, professionals_copy, comments = processing_data()\n# it takes about 12minuts by PC(i7/8GB)","execution_count":8,"outputs":[{"output_type":"stream","text":"Finished  \nCPU times: user 7min 49s, sys: 1.66 s, total: 7min 50s\nWall time: 7min 50s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Select author"},{"metadata":{"trusted":true},"cell_type":"code","source":"def select_author(input_question, number_of_authors, sample_num, tag_coef, expiration_date, \n                  reseponse_time_limit, thank_coef, rand_coef):\n    \n    # calucurate questions_similarity in the case of type(input_question)==int: existing question on the data\n    print('---  1/6',\"\\r\", end=\"\")\n    if type(input_question)==int:\n        if input_question in questions_copy['questions_words']:\n            questions_copy['questions_similarity'] = [(get_jac_sim(questions_copy['questions_words'][input_question],\n                            questions_copy['questions_words'][i]) + get_jac_sim(questions_copy['questions_body_tags'][input_question],\n                            questions_copy['questions_body_tags'][i])*tag_coef)* (math.log10(questions_copy['score'][i]+1)+1)\n                            * (1 - delta_days(questions_copy['questions_date_added'][input_question],\n                            questions_copy['questions_date_added'][i])/expiration_date) for i in questions_copy.index]\n            if questions_copy.loc[input_question,'questions_id'] in answers_copy['answers_question_id'].values:\n                old_item=1\n            else:\n                old_item=0\n        else:\n            print('Err: No applicable questions.index')\n            sys.exit()\n\n    # calucurate questions_similarity in the case of type(input_question)==str: new question\n    elif type(input_question)==str:\n        word_list = get_word_list(input_question)\n        tag_list = get_tag_list(input_question)\n        questions_copy['questions_similarity'] = [(get_jac_sim(word_list, questions_copy['questions_words'][i]) \\\n                            + get_jac_sim(tag_list, questions_copy['questions_body_tags'][i])*tag_coef) \\\n                            * (math.log10(questions_copy['score'][i]+1)+1) * (1 - days_to_now(questions_copy['questions_date_added'][i]) \\\n                            /expiration_date) for i in questions_copy.index]\n        old_item=0\n    else:\n        print('Err: type error')\n        sys.exit()\n        \n    #select questions similar to input\n    print('---  2/6',\"\\r\", end=\"\")\n    questions_selected = questions_copy.sort_values('questions_similarity', ascending=False).iloc[old_item:sample_num+old_item,:]\n    \n    #select answers of the selected questions\n    print('---  3/6',\"\\r\", end=\"\")\n    answers_selected=pd.DataFrame()\n    for i in questions_selected.index:        \n        for j in answers_copy[answers_copy['answers_question_id']==questions_selected['questions_id'].loc[i]].index:\n            answers_selected= answers_selected.append(answers_copy.loc[j,['answers_id','answers_question_id',\n                                                                     'answers_author_id', 'answers_date_added','Response_day','score']])\n            answers_selected.loc[j,'questions_similarity']= questions_selected.loc[i,'questions_similarity']\n            #Count 'thank' from the comments of each answer. \n            answers_selected.loc[j,'thank']=int(any(comments[(comments['comments_parent_content_id']==\n                                                              answers_selected.loc[j, 'answers_id'])]['comments_body'].str.contains('Thank|thank|thk|thnk')))\n    if len(answers_selected)==0:\n        print(\"Err: No similar answers, use larger 'sample_num'\")\n        sys.exit()            \n    #Listed aurhors of the selected answers and calculate the author_priority from score, Response_day, questions_similarity and thank\n    print('---  4/6',\"\\r\", end=\"\")\n    author_selected = answers_selected.groupby('answers_author_id').agg({'answers_id':'count', 'score':'mean', \n                                                                         'Response_day':'mean', 'questions_similarity': 'mean', 'thank': 'mean'})\n    author_selected.columns=['answer_count', 'score_mean', 'respose_day_mean', 'similarity_mean', 'thank_mean']\n    author_selected['score_mean'] = [math.log10(author_selected.loc[x,'score_mean']+1)+1 for x in author_selected.index]\n    author_selected['author_priority'] = (1+author_selected['thank_mean']*thank_coef)*author_selected['similarity_mean']\\\n                * author_selected['answer_count']*(1-author_selected['respose_day_mean']/reseponse_time_limit)\\\n                * author_selected['score_mean']\n    author_selected=author_selected[author_selected['author_priority']>0]\n    author_selected['ind_head']=''\n    for x in author_selected.index:\n        if any(professionals_copy['professionals_id']==x):\n            author_selected.at[x, 'ind_head']=[professionals_copy[professionals_copy['professionals_id']==x]['ind_head'].values[0]]\n\n    #Collect words from the selected authors and aggregate the author_priority.\n    print('---  5/6',\"\\r\", end=\"\")\n    word_set=set()\n    for i in author_selected.index:\n        if author_selected.loc[i, 'ind_head'] != '':\n            word_set|=author_selected.loc[i, 'ind_head'][0]\n\n    word_dict = dict(zip(word_set,np.zeros(len(word_set))))\n    for i in author_selected.index:\n         if author_selected.loc[i, 'ind_head'] != '':\n                for j in author_selected.loc[i, 'ind_head'][0]:\n                    word_dict[j] = word_dict[j]+author_selected.loc[i, 'author_priority']\n\n    word_dict = {k: v for k, v in word_dict.items() if v != 0.0}\n\n    #Calculate professionals_priority by word_dict.\n    print('---  5/6',\"\\r\", end=\"\")\n    professionals_copy['professionals_priority']=0.0\n    for k, v in word_dict.items():\n        professionals_copy.loc[professionals_copy['ind_head_sp'].str.contains(k),'professionals_priority']+=v\n    professionals_priority_max=professionals_copy['professionals_priority'].max()\n    #Set higher 'author_priority' for 'author_selected'\n    for i in author_selected.index:\n        professionals_copy.loc[(professionals_copy['professionals_id']==i),'professionals_priority']+= \\\n                author_selected.loc[i, 'author_priority']+professionals_priority_max\n    \n    #Sort professionals by the priority\n    print('---  6/6',\"\\r\", end=\"\")\n    random.seed(dt.datetime.now().microsecond)\n    professionals_sorted = copy.copy(professionals_copy.sort_values(['professionals_priority','professionals_date_joined_dt'],\n                                                        ascending=[False, False]))\n    professionals_sorted['rank']=[i+1 for i in range(professionals_sorted.shape[0])]\n    selected_professionals = pd.DataFrame()    \n    # and select recommendation of professionals due to 'rand_coef'\n    if (rand_coef>=0) and (rand_coef<=1):\n        for i in range(number_of_authors):\n            ii = int((1-random.random()**(rand_coef))*professionals_sorted.shape[0])\n            selected_professionals = selected_professionals.append(professionals_sorted.iloc[ii,:])\n            professionals_sorted=professionals_sorted.drop(index=professionals_sorted.index[ii])\n        selected_professionals['rank']=selected_professionals['rank'].astype('int64')\n    else:\n        print(\"Err: Input 0. to 1. for 'rand_coef'\")\n        sys.exit()\n    \n    print(\"Finished \",\"\\r\")\n    return selected_professionals.drop(['ind_head', 'ind_head_sp', 'professionals_date_joined_dt','professionals_priority'], axis=1)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameters\nparams = {\n        'number_of_authors': 10,# Number of authors to select\n        'sample_num': 10, # Number of sample questions to compare similarity, the biggest factor of the processing time.\n        'tag_coef': 2, # Priority coefficient of Tag in calculating questions similarity\n        'expiration_date': 1000, # Similar questions prioritize newer ones within 'expiration_date'\n        'reseponse_time_limit': 30, # Similar answer prioritize faster response to the answer within in 30 days \n        'thank_coef': 1, # Priority coefficient of the number of \"thank\" included in the comment of the answer\n        'rand_coef': 0.} # Random coefficient of 0. to 1., 0.[default]: select from high order, 1.: 100% random","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two input methods are prepared.\nThe first method is to input title and body directly by str."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_question_title=\"Is it hard to find a job in graphic design?\"\ninput_question_body=\"I'd like to know how hard it is to find a job straight out of school  #graphic-design #graphics\"\n\ninput_question=input_question_title+' '+input_question_body\n%time select_authors = select_author(input_question, **params)\nselect_authors","execution_count":11,"outputs":[{"output_type":"stream","text":"Finished  \nCPU times: user 4.18 s, sys: 32 ms, total: 4.21 s\nWall time: 4.19 s\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"          professionals_date_joined ...  rank\n18204  2018-04-10 13:19:06 UTC+0000 ...     1\n3070   2015-12-16 23:48:37 UTC+0000 ...     2\n1794   2015-03-09 11:20:00 UTC+0000 ...     3\n3045   2015-12-15 16:59:08 UTC+0000 ...     4\n1121   2014-05-15 16:57:38 UTC+0000 ...     5\n11580  2017-05-22 20:45:47 UTC+0000 ...     6\n23605  2018-09-25 23:10:33 UTC+0000 ...     7\n13045  2017-09-18 22:44:13 UTC+0000 ...     8\n15436  2018-01-17 20:18:04 UTC+0000 ...     9\n8782   2016-12-06 11:49:51 UTC+0000 ...    10\n\n[10 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>professionals_date_joined</th>\n      <th>professionals_headline</th>\n      <th>professionals_id</th>\n      <th>professionals_industry</th>\n      <th>professionals_location</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18204</th>\n      <td>2018-04-10 13:19:06 UTC+0000</td>\n      <td>Creative Director | Art Director | Designer</td>\n      <td>16584031624041119309e01c908a2f1f</td>\n      <td>Marketing and Advertising</td>\n      <td>Austin, Texas</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3070</th>\n      <td>2015-12-16 23:48:37 UTC+0000</td>\n      <td>Principal, Illustrator, Graphic Designer at Ki...</td>\n      <td>349db306672e425f9481e6c30d84afe5</td>\n      <td>GRAPHIC_DESIGN, ILLUSTRATION</td>\n      <td>Seattle, Washington</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1794</th>\n      <td>2015-03-09 11:20:00 UTC+0000</td>\n      <td>Keeping Busy!!! - Illustrator and Designer, al...</td>\n      <td>e01894b52bfb4eabb8791beaef276fa7</td>\n      <td>Civil Engineering</td>\n      <td>Frome, England, United Kingdom</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3045</th>\n      <td>2015-12-15 16:59:08 UTC+0000</td>\n      <td>Illustrator and Graphic Designer</td>\n      <td>4bbd6d03e36b445198780896632a01f1</td>\n      <td>Graphic Design</td>\n      <td>Missoula, Montana</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1121</th>\n      <td>2014-05-15 16:57:38 UTC+0000</td>\n      <td>Principal Artist at Zynga</td>\n      <td>bc46e3699d92477ba8c7aa723e54a151</td>\n      <td>Entertainment</td>\n      <td>San Francisco, California</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11580</th>\n      <td>2017-05-22 20:45:47 UTC+0000</td>\n      <td>Making the donuts at Okta</td>\n      <td>67c1bd0e570e447ba48f25bcdc073297</td>\n      <td>Graphic Design</td>\n      <td>Portland, Oregon</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>23605</th>\n      <td>2018-09-25 23:10:33 UTC+0000</td>\n      <td>Solutions Manager</td>\n      <td>cdeef38b72d54b65b0f826261d33276b</td>\n      <td>Telecommunications</td>\n      <td></td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>13045</th>\n      <td>2017-09-18 22:44:13 UTC+0000</td>\n      <td>Princpal Catalog Expert  at SAP Ariba</td>\n      <td>562bbe2bad304300aa551dceecf5e440</td>\n      <td>Information Services</td>\n      <td>Santa Clarita, California</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>15436</th>\n      <td>2018-01-17 20:18:04 UTC+0000</td>\n      <td></td>\n      <td>a209eed08b8846adaf95f352b1325815</td>\n      <td></td>\n      <td>Hallandale Beach, Florida</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>8782</th>\n      <td>2016-12-06 11:49:51 UTC+0000</td>\n      <td>Advertising &amp; Marketing, Graphic Designer, Art...</td>\n      <td>113c32498e0f4c67929b194a549655db</td>\n      <td>Marketing and Advertising</td>\n      <td>Jeddah, Makkah Province, Saudi Arabia</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The second method is a method of specifying the index of Framedata of \"questions\" by integer."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_question=123\n%time select_authors = select_author(input_question, **params)\nselect_authors","execution_count":12,"outputs":[{"output_type":"stream","text":"Finished  \nCPU times: user 6.05 s, sys: 32 ms, total: 6.08 s\nWall time: 6.06 s\n","name":"stdout"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"          professionals_date_joined ...  rank\n22677  2018-09-01 20:47:44 UTC+0000 ...     1\n27147  2019-01-12 18:57:07 UTC+0000 ...     2\n3698   2016-01-27 14:51:09 UTC+0000 ...     3\n3611   2016-01-22 19:47:04 UTC+0000 ...     4\n16061  2018-02-16 01:56:13 UTC+0000 ...     5\n25354  2018-11-15 03:24:17 UTC+0000 ...     6\n2410   2015-10-19 20:56:49 UTC+0000 ...     7\n27427  2019-01-22 13:33:56 UTC+0000 ...     8\n4588   2016-03-14 16:27:13 UTC+0000 ...     9\n864    2014-02-21 20:16:29 UTC+0000 ...    10\n\n[10 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>professionals_date_joined</th>\n      <th>professionals_headline</th>\n      <th>professionals_id</th>\n      <th>professionals_industry</th>\n      <th>professionals_location</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22677</th>\n      <td>2018-09-01 20:47:44 UTC+0000</td>\n      <td>Adjunct Professor Engineering</td>\n      <td>e2b4c84bf1ca4aea9b108869692d8017</td>\n      <td>Information Technology and Services</td>\n      <td>Greater Chicago Area</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27147</th>\n      <td>2019-01-12 18:57:07 UTC+0000</td>\n      <td>Senior Product Line Manager, Servers &amp; Systems...</td>\n      <td>6cd927ff0179440f955400924564ea78</td>\n      <td>Information Technology and Services</td>\n      <td>Austin, Texas Area</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3698</th>\n      <td>2016-01-27 14:51:09 UTC+0000</td>\n      <td>Retired Engineering Manager with limited consu...</td>\n      <td>81a594b683d54e6dbb4b04ea00a5e25b</td>\n      <td>Chemicals</td>\n      <td>Greensboro, Georgia</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3611</th>\n      <td>2016-01-22 19:47:04 UTC+0000</td>\n      <td>Retired Civil Engineer</td>\n      <td>c3b4e11154f74a858779be7ba9b6f00c</td>\n      <td>Consulting Engineering</td>\n      <td>Kent, Washington</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>16061</th>\n      <td>2018-02-16 01:56:13 UTC+0000</td>\n      <td>Product Manager</td>\n      <td>899f9fcf22d04191a294da40f7cc0ade</td>\n      <td>Telecommunications</td>\n      <td>Newark, New Jersey</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>25354</th>\n      <td>2018-11-15 03:24:17 UTC+0000</td>\n      <td>Product Marketing Dell</td>\n      <td>632f3cc0483642ceb798efef2b284cb0</td>\n      <td>Electrical and Electronic Manufacturing</td>\n      <td>Austin, Texas</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2410</th>\n      <td>2015-10-19 20:56:49 UTC+0000</td>\n      <td>Assist with Recognizing and Developing Potential</td>\n      <td>36ff3b3666df400f956f8335cf53e09e</td>\n      <td>Mental Health Care</td>\n      <td>Cleveland, Ohio</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>27427</th>\n      <td>2019-01-22 13:33:56 UTC+0000</td>\n      <td>PMO Business Manager at AT&amp;T</td>\n      <td>cb9c91e59ab9436d91b43c14e53be4c7</td>\n      <td>IT/Advertising, Analytics</td>\n      <td>Dallas/Fort Worth Area</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4588</th>\n      <td>2016-03-14 16:27:13 UTC+0000</td>\n      <td>Mechanical Engineer I Automotive</td>\n      <td>58fa5e95fe9e480a9349bbb1d7faaddb</td>\n      <td>Automotive</td>\n      <td>Redford Charter Township, Michigan</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>864</th>\n      <td>2014-02-21 20:16:29 UTC+0000</td>\n      <td>Software engineer, data infrastructure at Link...</td>\n      <td>19c30dfeabb64b108617c81d87f538fe</td>\n      <td>Computer Software</td>\n      <td>Sunnyvale, California</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"In the case of 'rand_coef' = 0.0005.\n    It can be used against cold start issue."},{"metadata":{"trusted":true},"cell_type":"code","source":"params['rand_coef']=0.0005\ninput_question=123\n%time select_authors = select_author(input_question, **params)\nselect_authors","execution_count":13,"outputs":[{"output_type":"stream","text":"Finished  \nCPU times: user 6.08 s, sys: 16 ms, total: 6.1 s\nWall time: 6.07 s\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"          professionals_date_joined ...  rank\n13472  2017-10-04 14:28:50 UTC+0000 ...    16\n27326  2019-01-18 21:41:03 UTC+0000 ...    13\n11508  2017-05-18 04:02:35 UTC+0000 ...    29\n16061  2018-02-16 01:56:13 UTC+0000 ...     5\n26857  2019-01-03 19:26:14 UTC+0000 ...    22\n11490  2017-05-17 19:40:56 UTC+0000 ...    19\n23865  2018-10-01 20:03:25 UTC+0000 ...    21\n7329   2016-07-04 07:46:58 UTC+0000 ...    80\n22666  2018-09-01 13:45:55 UTC+0000 ...    31\n27848  2019-01-28 05:25:26 UTC+0000 ...    25\n\n[10 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>professionals_date_joined</th>\n      <th>professionals_headline</th>\n      <th>professionals_id</th>\n      <th>professionals_industry</th>\n      <th>professionals_location</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13472</th>\n      <td>2017-10-04 14:28:50 UTC+0000</td>\n      <td>Engineering Manager at Dell</td>\n      <td>24c5de7ca38647528983454628ff396c</td>\n      <td>Information Technology and Services</td>\n      <td>Bengaluru Area, India</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>27326</th>\n      <td>2019-01-18 21:41:03 UTC+0000</td>\n      <td>Chief Systems Engineer/Systems Engineering Man...</td>\n      <td>0649fc0fba8a45cdb6ce8a54b1cb859c</td>\n      <td>Information Technology and Services</td>\n      <td>Pleasanton, California</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>11508</th>\n      <td>2017-05-18 04:02:35 UTC+0000</td>\n      <td>Engineering Leader @ Okta</td>\n      <td>a0abf3bae68d482091457ef136e628b0</td>\n      <td>Information Technology and Services</td>\n      <td>California, California</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>16061</th>\n      <td>2018-02-16 01:56:13 UTC+0000</td>\n      <td>Product Manager</td>\n      <td>899f9fcf22d04191a294da40f7cc0ade</td>\n      <td>Telecommunications</td>\n      <td>Newark, New Jersey</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>26857</th>\n      <td>2019-01-03 19:26:14 UTC+0000</td>\n      <td>Data Analyst| MS-Information Systems| MBA-Fina...</td>\n      <td>30da6842bc1e48bfb1916e2d1435f69e</td>\n      <td>Information Technology and Services</td>\n      <td>Sunnyvale, California</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>11490</th>\n      <td>2017-05-17 19:40:56 UTC+0000</td>\n      <td>Sr. Engineering Manager at Okta, Inc.</td>\n      <td>7a8c218574a14993863641bc5900a9c1</td>\n      <td>Information Technology and Services</td>\n      <td>Toronto, Ontario, Canada</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>23865</th>\n      <td>2018-10-01 20:03:25 UTC+0000</td>\n      <td>Client Onsite Systems Engineering (OSE) at Dell</td>\n      <td>578f41bd85da4811bc1a677e70e9ae39</td>\n      <td>Information Technology and Services</td>\n      <td>Los Angeles, California</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>7329</th>\n      <td>2016-07-04 07:46:58 UTC+0000</td>\n      <td>Software Development Engineer at Dell R&amp;D</td>\n      <td>c1751fc504af4537986263bfb3ac2ea7</td>\n      <td>Information Technology and Services</td>\n      <td>Bengaluru, Karnataka, India</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>22666</th>\n      <td>2018-09-01 13:45:55 UTC+0000</td>\n      <td>Seeking an Electrical/Computer Engineering Ful...</td>\n      <td>31848459007e48dda2779f38208caeb6</td>\n      <td>Information Technology and Services</td>\n      <td>Hoboken, New Jersey</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>27848</th>\n      <td>2019-01-28 05:25:26 UTC+0000</td>\n      <td>Seeking an Internship/Full-time opportunity an...</td>\n      <td>baa751b8638b4b9ea5e83904c104672f</td>\n      <td>Information Technology and Services</td>\n      <td>Los Angeles, California</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}