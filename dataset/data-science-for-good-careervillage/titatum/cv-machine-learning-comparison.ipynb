{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom time import time\nimport datetime as dt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I. Loading the Test Data Set ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dir = \"../input\"\ntest_dir = os.path.join(input_dir,'cv-machine-learning-gbdts')\ntest_x = pd.read_csv('{}/test_x.gz'.format(test_dir), index_col=0, compression='gzip')\n\nprint('Number of test instances: {}'.format(test_x.shape))\ntest_x.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y = pd.read_csv('{}/test_y.gz'.format(test_dir), header=None, index_col=0, compression='gzip')\nprint('Number of test instances: {}'.format(test_y.shape))\ntest_y.columns = ['Matched']\n\ntest_y.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The number of unmatched instances is {}'.format(sum(test_y['Matched']==0)))\nprint('The number of matched instances is {}'.format(sum(test_y['Matched']==1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Adding questions_id to test instances to evaluate recommendation performance in next sections **"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y = test_x[['questions_id']].merge(test_y, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# II. Loading Gradient Boosting Decision Trees Results #"},{"metadata":{"trusted":true},"cell_type":"code","source":"gbdts_dir = os.path.join(input_dir,'cv-machine-learning-gbdts')\ngbdts_y = pd.read_csv('{}/predicted_test_y.gz'.format(gbdts_dir), index_col=0, compression='gzip')\ngbdts_y.columns = ['GBDTs_Prob']\n\nprint('Number of GBDTs predicted scores: {}'.format(gbdts_y.shape))\ngbdts_y.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_scores= test_y.merge(gbdts_y, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_scores.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# III. Loading Conditional Logistic Regression Results #"},{"metadata":{"trusted":true},"cell_type":"code","source":"clr_dir = os.path.join(input_dir,'cv-machine-learning-conditional-lr')\nprint(os.listdir(clr_dir))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clr_y = pd.read_csv('{}/ConditionalLR_predicted_y.csv'.format(clr_dir), index_col=0)\nprint('Number of CLR predicted scores: {}'.format(clr_y.shape))\nclr_y.columns = ['CLR_Prob']\nclr_y.index = predicted_scores.index\nclr_y.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_scores= predicted_scores.merge(clr_y, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_scores.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IV. Performance Evaluation #"},{"metadata":{},"cell_type":"markdown","source":"## IV.1. Performance Comparison ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_min_rank(rows, col_name):\n    rows['Rank'] = rows[col_name].rank(ascending=False)\n    rows=rows[rows['Matched']==1]\n    return rows['Rank'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_max_rank(rows, col_name):\n    rows['Rank'] = rows[col_name].rank(ascending=False)\n    rows=rows[rows['Matched']==1]\n    return rows['Rank'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cut_points = range(1,20+1)\ndef compute_recall(cut_points, ranked_results):\n    cut_results = {'Top K': [],\n                   'GBDTs': [],\n                   'CLR': [],\n                  }\n    for cut_point in cut_points:\n        cut_results['Top K'].append(cut_point)\n        cut_results['GBDTs'].append(ranked_results[ranked_results['GBDTs'] <= cut_point].shape[0])\n        cut_results['CLR'].append(ranked_results[ranked_results['CLR'] <= cut_point].shape[0])\n\n    cut_results = pd.DataFrame(cut_results)\n    cut_results['GBDTs'] = cut_results['GBDTs'] / ranked_results.shape[0]\n    cut_results['CLR'] = cut_results['CLR'] / ranked_results.shape[0]\n    return cut_results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** 'Min Rank' allows to measure the recall to recover of at least one relevant match. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_ranked_results = pd.DataFrame({'GBDTs': predicted_scores.groupby('questions_id').apply(compute_min_rank, col_name='GBDTs_Prob'),\n                                   'CLR': predicted_scores.groupby('questions_id').apply(compute_min_rank, col_name='CLR_Prob'),\n                                   'Matches': predicted_scores.groupby('questions_id')['Matched'].sum(),\n                                   'Recommendations': predicted_scores.groupby('questions_id')['Matched'].count()})\nmin_ranked_results = min_ranked_results[min_ranked_results['Matches'] > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_ranked_results.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_rank_cut_results = compute_recall(cut_points, min_ranked_results)\nmin_rank_cut_results.set_index('Top K').plot()\nplt.ylabel('At Least One Recall')\nplt.title('At Least One Recall Performance Comparison:\\nConditional Logistic Regression vs GBDTs')\nplt.savefig('min_rank_recommendation_recall.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** 'Max Rank' allows to measure the recall to recover of all relevant matches. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_ranked_results = pd.DataFrame({'GBDTs': predicted_scores.groupby('questions_id').apply(compute_max_rank, col_name='GBDTs_Prob'),\n                                   'CLR': predicted_scores.groupby('questions_id').apply(compute_max_rank, col_name='CLR_Prob'),\n                                   'Matches': predicted_scores.groupby('questions_id')['Matched'].sum(),\n                                   'Recommendations': predicted_scores.groupby('questions_id')['Matched'].count()})\nmax_ranked_results = max_ranked_results[max_ranked_results['Matches'] > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_ranked_results.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_rank_cut_results = compute_recall(cut_points, max_ranked_results)\nmax_rank_cut_results.set_index('Top K').plot()\nplt.ylabel('Full Recall')\nplt.title('Full Recall Performance Comparison:\\nConditional Logistic Regression vs GBDTs')\nplt.savefig('max_rank_recommendation_recall.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IV.1. Improvement Impacts: Decreases in Recommendation Volumes ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_scores['GBDTs_Rank'] = predicted_scores.groupby('questions_id')['GBDTs_Prob'].rank(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Using the top 20 recommendations from our GBDTs model, we can still maintain a high recall but the volume of recommendations to send out can be reduced significantly by more than 15 times. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The total number of correct original recommendations: {}'.format(predicted_scores[\n    (predicted_scores['Matched']==1)].shape[0]))\n\nprint('The total number of correct ML top-20 recommendations: {}'.format(\n    predicted_scores[((predicted_scores['GBDTs_Rank'] <= 20) & (predicted_scores['Matched']==1))].shape[0]))\n\nprint('The ML top-20 accuracy is {}%'.format(np.round(100 * predicted_scores[\n    ((predicted_scores['GBDTs_Rank'] <= 20) & (predicted_scores['Matched']==1))].shape[0] / predicted_scores[(predicted_scores['Matched']==1)].shape[0],1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The total number of original recommendations: {}'.format(predicted_scores.shape[0]))\n\nprint('The total number of ML top-20 recommendations: {}'.format(predicted_scores[\n    predicted_scores['GBDTs_Rank'] <= 20].shape[0]))\n\nprint('The decrease in the number of sent recommendations is {} folds: '.format(\n    np.round(predicted_scores.shape[0] / predicted_scores[\n    predicted_scores['GBDTs_Rank'] <= 20].shape[0], 1)\n))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_scores = test_x[['answer_user_id', 'emails_date_sent']].merge(\n    predicted_scores, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** The distribution of the numbers of questions that professionals receive in each email in the test set using the current tag-based recommendation system. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"before_ml_counts = predicted_scores.groupby(['answer_user_id', 'emails_date_sent'])['questions_id'].count()\nbefore_ml_counts[before_ml_counts <= 30].hist(bins=30)\nplt.ylabel('Emails')\nplt.title('The mean value is {}'.format(round(before_ml_counts.mean(),1)))\nplt.savefig('before_ml_questions_in_each_email.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** The distribution of the numbers of questions that professionals receive in each email in the test set using the proposed ML GBDTs model. On average, the recommendations in each email is reduced by half. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"after_ml_counts = predicted_scores[predicted_scores['GBDTs_Rank'] <= 20\n                ].groupby(['answer_user_id', 'emails_date_sent'])['questions_id'].count()\nafter_ml_counts[after_ml_counts <= 30].hist(bins=30)\nplt.ylabel('Emails')\nplt.title('The mean value is {}'.format(round(after_ml_counts.mean(),1)))\nplt.savefig('after_ml_questions_in_each_email.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V. Saving Results #"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_scores.to_csv('predicted_scores.csv.gz', compression='gzip')\n\nmin_ranked_results.to_csv('min_ranked_results.csv.gz', compression='gzip')\nmin_rank_cut_results.to_csv('min_rank_cut_results.csv.gz', compression='gzip')\n\nmax_ranked_results.to_csv('max_ranked_results.csv.gz', compression='gzip')\nmax_rank_cut_results.to_csv('max_rank_cut_results.csv.gz', compression='gzip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}