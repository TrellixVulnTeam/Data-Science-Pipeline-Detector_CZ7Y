{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">**Summary**</font>"},{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">**Problem description**</font>"},{"metadata":{},"cell_type":"markdown","source":"The U.S. has almost 500 students for every guidance counselor. Underserved youth lack the network to find their career role models, making CareerVillage.org the only option for millions of young people in America and around the globe with nowhere else to turn.\n\nTo date, 25,000 volunteers have created profiles and opted in to receive emails when a career question is a good fit for them. This is where your skills come in. To help students get the advice they need, the team at CareerVillage.org needs to be able to send the right questions to the right volunteers. The notifications sent to volunteers seem to have the greatest impact on how many questions are answered,\n\nSo the objective of this Kernel is to develop a method to recommend relevant questions to the professionals who are most likely to answer them."},{"metadata":{},"cell_type":"markdown","source":"<font size=\"5\">Proposed solution</font>"},{"metadata":{},"cell_type":"markdown","source":"From the fact that the professionals will supposed to answer similar questions they previously answered , so getting a similar questions to the asked question will help a lot ,\nso the supposed recommender consists of two parts :\n1.  In the first module the recommendations are based on the similarities between the question asked by a student and the pre-answered questions by the professionals in the system , where the recommended professionals from this part are the professionals who anweser similar questions and ranked by their activity status (the most recent active one has higher score than the less active one) .\n2. In this module the recommendations are based on the idea that professionals similar to another professional can be used to predict how much this professional will answer a particular question even if he didnâ€™t answer a similar question before.\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Kernel content\n   ## 1. [EDA](#eda)\n   ## 2. [Content based filtering](#cb)\n   ## 3. [Collaborative filtering](#cf)\n  ## 4. [Testing whole model](#tst)\n  ## 5. [How to use the model](#use)\n"},{"metadata":{},"cell_type":"markdown","source":"The recommendation system is a hybrid of content based filtering and collaborative filtering , so the output of content based which named by **ToCollaborative** is passed from content based filtering to collaborative filtering and the final output is sorted_output"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.simplefilter('ignore')\nimport operator\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity\nfrom sklearn.cluster import KMeans\n\nimport re\nimport string \nfrom collections import Counter\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\n\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nfrom plotly import tools\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38a91635142568dca845e2007fc9fb99fe533671"},"cell_type":"code","source":"from nltk.corpus import stopwords\nstop = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26afd5ecdc8f4b7f5fe13e75e01837328963d417"},"cell_type":"markdown","source":"## Read All csv's"},{"metadata":{"trusted":true,"_uuid":"ac92e640882cf16b1daf1190bfab772e547471c4"},"cell_type":"code","source":"emails = pd.read_csv('../input/emails.csv')\nquestions = pd.read_csv('../input/questions.csv')\nprofessionals = pd.read_csv('../input/professionals.csv')\ncomments = pd.read_csv('../input/comments.csv')\ntag_users = pd.read_csv('../input/tag_users.csv')\ngroup_memberships = pd.read_csv('../input/group_memberships.csv')\ntags = pd.read_csv('../input/tags.csv')\nstudents = pd.read_csv('../input/students.csv')\ngroups = pd.read_csv('../input/groups.csv')\ntag_questions = pd.read_csv('../input/tag_questions.csv')\nmatches = pd.read_csv('../input/matches.csv')\nanswers = pd.read_csv('../input/answers.csv')\nschool_memberships = pd.read_csv('../input/school_memberships.csv')\nquestion_score = pd.read_csv('../input/question_scores.csv')\nAnswer_score = pd.read_csv('../input/answer_scores.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA<a id='eda'></a> \n### 1. [Exploring students](#stud)\n### 2. [Exploring questions](#quest)\n### 3. [Exploring students with questions](#st_qt)\n### 4. [Exploring Professionals](#prof)\n### 5. [Exploring comments](#comm)\n### 6. [Exploring professionals with comments](#prof_comm)\n### 7. [Exploring Answers](#ans)\n### 8. [Exploring questions with answers](#qt_ans)\n### 9. [Exploring tags](#tag)\n### 10.[Exploring tags with tag_users](#tag_tgU)\n### 11.[Exploring Emails](#em)\n### 12.[Exploring matches](#mat)"},{"metadata":{},"cell_type":"markdown","source":"### Let's explore students<a id='stud'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(students.shape)\nstudents.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are NAN values ... Let's clean it and continue exploring :D"},{"metadata":{"trusted":true},"cell_type":"code","source":"students=students.dropna(subset = ['students_id','students_location', 'students_date_joined'])\nprint(students.shape)\nstudents.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2033 rows are deleted ... let's continue exploring :D"},{"metadata":{},"cell_type":"markdown","source":"** What is the most region the students comes from ?!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"students['students_location'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_regions_stud = students['students_location'].value_counts().head(10)\nax = top10_regions_stud.plot.bar(x=top10_regions_stud.index, y=top10_regions_stud.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('students count by location')\n#ax.set_facecolor(\"black\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"New York is the largest region the students come from ..."},{"metadata":{},"cell_type":"markdown","source":"Let's see distribution of number of students over years"},{"metadata":{"trusted":true},"cell_type":"code","source":"date=students['students_date_joined'].str.split('-').values\nyears=[]\nfor i in range(0,len(date)):\n    years.append(date[i][0])\n\nstud_join_years = pd.Series(years)\nstud_join_years_counts=stud_join_years.value_counts()\nstud_join_years_counts.sort_index(inplace=True)\nax = stud_join_years_counts.plot.bar(x=stud_join_years_counts.index, y=stud_join_years_counts.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('number of student over years')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems that the community became most popular in 2016 "},{"metadata":{},"cell_type":"markdown","source":"### Let's explore questions<a id='quest'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(questions.shape)\nquestions.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great there is no NAN values .. let's continue exploring"},{"metadata":{},"cell_type":"markdown","source":"let's see if the question body need some cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(questions.iloc[0]['questions_body'])\nprint(questions.iloc[30]['questions_body'])\nprint(questions.iloc[120]['questions_body'])\nprint(questions.iloc[300]['questions_body'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"great it doesn't need cleaning .. it is in good english format"},{"metadata":{},"cell_type":"markdown","source":"What are the most question's titles about?"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_quest_titles=questions['questions_title'].str.cat(sep=' ')\n\nwordcloud = WordCloud(width=1500, height=1500).generate(all_quest_titles)\n\nplt.figure(figsize=(20, 7))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"most of the questions' title about College , Career and jobs"},{"metadata":{},"cell_type":"markdown","source":"Let's see distribution of questions over years"},{"metadata":{"trusted":true},"cell_type":"code","source":"question_date=questions['questions_date_added'].str.split('-').values\nyears_questions=[]\n#months_questions=[]\nfor i in range(0,len(question_date)):\n    years_questions.append(question_date[i][0])\n    #months_questions.append(question_date[i][1])\n\n    \nquestions_date_added = pd.Series(years_questions)\nquestions_date_added_counts=questions_date_added.value_counts()\n\nquestions_date_added_counts.sort_index(inplace=True)\nax = questions_date_added_counts.plot.bar(x=questions_date_added_counts.index, y=questions_date_added_counts.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('number of questions over years')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2016 is the year with largest number of questions ... seems that the community becomes more famous from year 2016"},{"metadata":{},"cell_type":"markdown","source":"### Let's explore students with questions<a id='st_qt'></a>"},{"metadata":{},"cell_type":"markdown","source":"First let's merge students and questions tables"},{"metadata":{"trusted":true},"cell_type":"code","source":"students_questions = pd.merge(students, questions, left_on='students_id',right_on='questions_author_id', how='inner')\nstudents_questions.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Who are the most active students ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"no_questions_Bystudent=students_questions.groupby('students_id').size()\ntop10_activeStudents=no_questions_Bystudent.sort_values(ascending=False).head(10)\nax = top10_activeStudents.plot.bar(x=top10_activeStudents.index, y=top10_activeStudents.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('number of questions asked by students')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's explore professionals<a id='prof'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(professionals.shape)\nprofessionals.head(5)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"professionals.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"professionals=professionals.dropna(subset = ['professionals_location', 'professionals_industry', 'professionals_headline'])\nprint(professionals.shape)\nprofessionals.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5248 rows are deleted ... let's continue exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"professionals['professionals_industry'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_prof_industries = professionals['professionals_industry'].value_counts().head(10)\nax = top10_prof_industries.plot.bar(x=top10_prof_industries.index, y=top10_prof_industries.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('count professionals by Industry')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Information Technology and Services has the largest number of professionals"},{"metadata":{},"cell_type":"markdown","source":"What are the most regions the professionals come from ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"professionals['professionals_location'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_prof_regions = professionals['professionals_location'].value_counts().head(10)\nax = top10_prof_regions.plot.bar(x=top10_prof_regions.index, y=top10_prof_regions.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('count professionals by location')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The largest number of heros from New York"},{"metadata":{},"cell_type":"markdown","source":"What are the most frequent headlines of professionals?"},{"metadata":{"trusted":true},"cell_type":"code","source":"professionals['professionals_headline'].value_counts().sort_values(ascending=False).head(10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 176 professionals without headlines ... Let's remove these rows and continue exploring"},{"metadata":{"trusted":true},"cell_type":"code","source":"professionals=professionals[professionals['professionals_headline'] != '--']\nprofessionals.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"176 rows are removed ... Let's continue exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_profHeadlines = professionals['professionals_headline'].value_counts().sort_values(ascending=False).head(10)\nax = top10_profHeadlines.plot.bar(x=top10_profHeadlines.index, y=top10_profHeadlines.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('count professionals by headlines')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assurance Associate at PwC and Software Engineer are the most two frequent headlines of professionals "},{"metadata":{},"cell_type":"markdown","source":"### Let's explore comments<a id='comm'></a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"comments.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the hottest questions with the largest number of comments ..."},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_number_comments =comments['comments_parent_content_id'].value_counts().head(10)\nax = top10_number_comments.plot.bar(x=top10_number_comments.index, y=top10_number_comments.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('count comments number for questions')\nax.set_xlabel(\"question id\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring professionals with comments<a id='prof_comm'></a>"},{"metadata":{},"cell_type":"markdown","source":"Let's explore comments with professionals and see the most interactive professionals through comments .."},{"metadata":{"trusted":true},"cell_type":"code","source":"comments_profs = pd.merge(comments, professionals, left_on='comments_author_id',right_on='professionals_id',how='inner')\ncomments_profs                          ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_profID_inComments = comments_profs.groupby('professionals_id').size().sort_values(ascending=False).head(10)\nax = top10_profID_inComments.plot.bar(x=top10_profID_inComments.index, y=top10_profID_inComments.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('Top10 professionals make comments')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_prof_inComments_df = professionals.loc[professionals['professionals_id'].isin(top10_profID_inComments.index)]\ntop10_prof_inComments_df['professionals_industry']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The top active professional in comments from Design industry"},{"metadata":{},"cell_type":"markdown","source":"Is there a relations between number of professionals in an industry and number of comments in this industry ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_industry_comments=comments_profs.groupby('professionals_industry').size().sort_values(ascending=False).head(10)\n#ax = top10_industry_comments.plot.bar(x=top10_industry_comments.index, y=top10_industry_comments.values)\n#print(top10_industry_comments)\n\nprof_in_top10Industry_df = professionals.loc[professionals['professionals_industry'].isin(top10_industry_comments.index)]\ntop10_prof_comments=prof_in_top10Industry_df.groupby('professionals_industry').size()                                         \n\n#print(top10_prof_comments)\n\ncommentsVsProf_inIndustry_df=pd.concat([top10_industry_comments.rename('no.comments'), top10_prof_comments.rename('no.profs')], axis=1 )\nax = commentsVsProf_inIndustry_df.plot.bar()\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('no.comments , no.profs VS Industry')\nax.set_xlabel(\"Industry name\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"unexpectedly there is no relation between number of comments and professionals in the same industry"},{"metadata":{},"cell_type":"markdown","source":"### Let's explore Answers<a id='ans'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(answers.shape)\nanswers.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's explore Questions with answers<a id='qt_ans'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"questions.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answers.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's combine Questions and Answers"},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_Answers = pd.merge(questions, answers, left_on='questions_id',right_on='answers_question_id', how='inner')\nquestions_Answers.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"are all the questions take the same time to be answered ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_Answers['questions_date_added'] = pd.to_datetime(questions_Answers['questions_date_added'])\nquestions_Answers['answers_date_added'] = pd.to_datetime(questions_Answers['answers_date_added'])\nquestions_Answers['respond_time'] = (questions_Answers['answers_date_added']-questions_Answers['questions_date_added']).dt.days  \n#questions_Answers['respond_time'].head(10)\nax=questions_Answers['respond_time'].plot()\nax.set_xlim([0,2000])\nax.set_title('questions respond time')\nax.set_xlabel(\"respond time in days\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"response time of questions vary , But what make question be answered faster than the other ? if questions in domains with small number of professionals ? is the length of question effects ? \nWhat make professionals late in the response ?!!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_Answers['number_words_inQuestion'] = questions_Answers['questions_body'].apply(lambda x: len(x.split(' ')))\nquestions_Answers.loc[(questions_Answers['respond_time'] <= 7), 'week'] = 1\nquestions_Answers.loc[(questions_Answers['respond_time'] > 7) & (questions_Answers['respond_time'] <= 14), 'week'] = 2\nquestions_Answers.loc[(questions_Answers['respond_time'] > 14) & (questions_Answers['respond_time'] <= 21), 'week'] = 3\nquestions_Answers.loc[(questions_Answers['respond_time'] > 21) & (questions_Answers['respond_time'] <= 28), 'week'] = 4\nquestions_Answers.loc[(questions_Answers['respond_time'] > 28), 'week'] = 5\n\n\nax = sns.countplot(x=\"week\", data=questions_Answers)\nax.set_title('respond time duration in week')\n\nprint(questions_Answers.groupby('week').size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"what makes 3,140 questions took more than 1 month to answered ? "},{"metadata":{},"cell_type":"markdown","source":"is the lenght of question body significantly effect in the response time ? Let's see the correlation between response time and number of words in the question body !"},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"corr=questions_Answers.plot.scatter(x='number_words_inQuestion',y='respond_time')\ncorr.set_title('response time VS number_words_inQuestion')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"seems there is no correlation at general view?!! let's also check differences between questions answered during first week and those which are answered after more than 1 month"},{"metadata":{"trusted":true},"cell_type":"code","source":"fast_response_words = questions_Answers[ questions_Answers['week']==1]['number_words_inQuestion']\nslow_response_words = questions_Answers[ questions_Answers['week']==5]['number_words_inQuestion']\n\npal = sns.color_palette()\n\nplt.figure(figsize=(18, 8))\nplt.hist(fast_response_words, bins=40, range=[0, 80], color=pal[9], label='fast')\nplt.hist(slow_response_words, bins=40, range=[0, 80], color=pal[3], alpha=0.4, label='slow')\nplt.legend()\nplt.xlabel('Number of words', fontsize=15)\nplt.ylabel('Number of responses', fontsize=15)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"seems that shorter questions are answered faster than the long ones ......\nBut this is by not \nseems it is not the question body length that affects these slow response !!\nAre they belongs to industries with small number of proffesionals ? Let's see.."},{"metadata":{},"cell_type":"markdown","source":"### Let's explore tags<a id='tag'></a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"tags.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 16269 unique tags"},{"metadata":{},"cell_type":"markdown","source":"### Let's Explore tags with tag_users<a id='tag_tgU'></a>"},{"metadata":{},"cell_type":"markdown","source":"Which tags have the largest numbers of followers ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"tag_users.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags_tagUsers = pd.merge(tags, tag_users, left_on='tags_tag_id',right_on='tag_users_tag_id', how='inner')\ntags_tagUsers.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_tags_followed=tags_tagUsers['tags_tag_name'].str.cat(sep=' ')\n\nwordcloud = WordCloud(width=1500, height=800).generate(all_tags_followed)\n\nplt.figure(figsize=(20, 7))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Telecommunications , Information technology and college are most followed hashtags"},{"metadata":{},"cell_type":"markdown","source":"### Let's explore emails<a id='em'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"emails.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emails_frequency=emails['emails_frequency_level'].value_counts()\nprint(emails_frequency)\nax = emails_frequency.plot.bar(x=emails_frequency.index, y=emails_frequency.values)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\nax.set_title('Email frequency level count')\nax.set_xlabel(\"Email freq.Level\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"most subscribers have daily email notification"},{"metadata":{},"cell_type":"markdown","source":"### Let's explore matches<a id='mat'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"what is the top 10 mails containing questions ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_mails = matches.groupby('matches_email_id').size().sort_values(ascending=False).head(10)\nax = top10_mails.plot.bar(x=top10_mails.index, y=top10_mails.values)\nax.set_title('Top10 mails containing questions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's build the model"},{"metadata":{},"cell_type":"markdown","source":"### First split data into train and test "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test= train_test_split(questions, test_size=0.05, random_state=42)\nquestions_Answers = pd.merge(X_train, answers, left_on='questions_id',right_on='answers_question_id', how='inner')\nquestions_Answers_test = pd.merge(X_test, answers, left_on='questions_id',right_on='answers_question_id', how='inner')\nt = pd.merge(tags, tag_questions, left_on='tags_tag_id', right_on='tag_questions_tag_id')\nt_test = pd.merge(t,questions_Answers_test,left_on='tag_questions_question_id',right_on='answers_question_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=questions_Answers_test['answers_author_id'].isin(questions_Answers['answers_author_id'])\nf=questions_Answers_test[k]\nf=f.reset_index()\nUQ=f['questions_body'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's begin with content based recommender<a id='cb'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_text(df, col):\n    df[col] = df[col].str.replace('[^\\w\\s]','') # replacing punctuations\n    df[col] = df[col].str.replace('-',' ') # replacing dashes\n    df[col] = df[col].str.replace('\\d+','') # replacing digits\n    df[col] = df[col].str.lower().str.split() # convert all str to lowercase    \n    df[col] = df[col].apply(lambda x: [item for item in x if item not in stop]) # remove stopwords    \n    df[col] = df[col].apply(' '.join) # convert list to str\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def merging(df1, df2, left, right):\n    return df1.merge(df2, how=\"inner\", left_on=left, right_on=right)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_authors(df):\n    c = df.groupby('questions_id')['answers_author_id'].apply(list)\n    df_z = merging(df, pd.DataFrame(c), 'questions_id', 'questions_id')\n    df_z.drop('answers_author_id_x', axis=1, inplace=True)\n    df_z['answers_author_id_y'] = df_z['answers_author_id_y'].apply(', '.join)\n    df_z.drop_duplicates(inplace=True)\n    return df_z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ques_Ans_sub = questions_Answers[['questions_title', 'questions_body', 'answers_author_id', 'questions_id']].copy()\n\nUniqueQues = combine_authors(Ques_Ans_sub)\n\nQues_Prof = UniqueQues[['questions_id', 'answers_author_id_y']].copy()\n\nUniqueQues.drop('answers_author_id_y', axis=1, inplace=True)\nUniquesQues = process_text(UniqueQues, \"questions_title\") \nUniqueQues = process_text(UniqueQues, \"questions_body\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf = TfidfVectorizer(analyzer='word',\n                         ngram_range=(1,2),\n                         min_df=3,\n                         max_df=0.9,\n                         stop_words='english')\nlst=UniqueQues['questions_body']\ntfidf_matrix = tf.fit(lst)\ntfidfTrans= tfidf_matrix.transform(lst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def CosSim(QuesBody):\n    TargetQues= tfidf_matrix.transform([QuesBody])\n    tfidfTrans.shape\n    cosine_sim = linear_kernel(TargetQues, tfidfTrans)\n    q_titles = UniqueQues['questions_title']\n    q_ids = UniqueQues['questions_id']\n    indices = pd.Series(UniqueQues.index, UniqueQues['questions_title'])\n    return cosine_sim,indices,q_titles,q_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_recommendations_idx(df):\n    sim_scores = list(enumerate(cosine_sim[0]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[0:21]\n    q_indices = [i[0] for i in sim_scores]\n    scores= [i[1] for i in sim_scores]\n    df['scores']=scores\n    return q_indices\n\ndef get_recommendations(df):\n    return q_titles.iloc[get_recommendations_idx(df)]\n    \ndef get_questions_id(df):\n    ls=q_ids.iloc[get_recommendations_idx(df)] \n    df['Ques_ID']=ls.tolist()\n    return df  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's test content based recommender<a id='test'></a>"},{"metadata":{},"cell_type":"markdown","source":"#### note : test is the input question body (asked question)\nto input your test just comment this line : test=f['questions_body'][5]\nand put your input question body \n\n**For ex :**\ntest=\"What is the best road to learn data science ?\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame()\ntest=f['questions_body'][5]\ncosine_sim,indices,q_titles,q_ids=CosSim(test)\nget_questions_id(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=[i for i, value in enumerate(questions_Answers_test['questions_body']) if value in test]\nExpectedProf=questions_Answers_test['answers_author_id'][y]\nExpectedProf=ExpectedProf.reset_index()\nExpectedProf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z=[i for i, value in enumerate(questions_Answers['answers_author_id']) if value in ExpectedProf['answers_author_id'][0]]\nm=questions_Answers.iloc[z]\ntemp5=m['answers_question_id'].isin(df['Ques_ID'])\nRecomProfs5=m[temp5]\nRecomProfs5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ExpectedProf['answers_author_id'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=answers['answers_question_id'].isin(df['Ques_ID'])\nRecomProfs=answers[temp]\ntemp2=comments_profs['professionals_id'].isin(RecomProfs['answers_author_id'])\nActiveProfs=comments_profs[temp2]\nActiveProfs=ActiveProfs[['professionals_id', 'comments_date_added' ]].copy()\nActiveProfs['comments_date_added'] =pd.to_datetime(ActiveProfs.comments_date_added)\nActiveProfs.sort_values(by=['comments_date_added'], inplace=True, ascending=False)\nActiveProfs.drop_duplicates('professionals_id',inplace=True)\nActiveProfs['Active']=ActiveProfs['comments_date_added']>'2018-01-01 00:00:00 UTC+0000'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RecomProfsk=pd.merge(RecomProfs,ActiveProfs,how='left',left_on='answers_author_id',right_on='professionals_id')\nRecomProfs2=RecomProfsk[['answers_question_id','answers_author_id','Active']][:]\nRecomProfs2.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Discovering the last date of professionals's answers"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp3=answers['answers_author_id'].isin(RecomProfs2['answers_author_id'].unique())\nActiveAns=answers[temp3]\nActiveAns['answers_date_added'] =pd.to_datetime(ActiveAns.answers_date_added)\nActiveAns.sort_values(by=['answers_date_added'], inplace=True, ascending=False)\nActiveAns.drop_duplicates('answers_author_id',inplace=True)\nActiveAns['Active']=ActiveAns['answers_date_added']>'2018-01-01 00:00:00'\nActiveAns=ActiveAns[['answers_author_id','answers_question_id','Active']][:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RecomProfsx=pd.merge(RecomProfs2,ActiveAns,how='left',left_on='answers_author_id',right_on='answers_author_id')\nRecomProfsy=RecomProfsx[['answers_question_id_x','answers_author_id','Active_x','Active_y']][:]\nRecomProfsy.fillna(False,inplace=True)\nRecomProfsy['Active']=RecomProfsy['Active_x'] | RecomProfsy['Active_y']\nRecomProfsy.drop(['Active_x','Active_y'], axis=1, inplace=True)\nRecomProfsy.rename(columns={'answers_question_id_x' :'questions_id'},inplace=True)\n\nRecomProfsy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recommending professionals by giving weight=5 to the cosine similarity and 2 for the Active status"},{"metadata":{},"cell_type":"markdown","source":"The id's of recommended professionals by content based is **ToCollaborative**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Recommended_Prof=pd.merge(RecomProfsy,df,how='inner',left_on='questions_id',right_on='Ques_ID')\nRecommended_Prof.drop_duplicates(inplace=True)\nRecommended_Prof['FinalWeight']=(5*Recommended_Prof['scores'])+(2*Recommended_Prof['Active'])\nRecommended_Prof2=Recommended_Prof.groupby(['answers_author_id'],as_index=False).max()\nRecommended_Prof2.sort_values(by=['FinalWeight'], inplace=True, ascending=False)\nToCollaborative=Recommended_Prof2['answers_author_id'].values\nToCollaborative","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### collaborative filtering<a id='cf'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getProfessionalTages(t,id):\n    indices1 = [i for i, value in enumerate(t['answers_author_id']) if value == id]\n    p = t['tags_tag_name'][indices1]\n    comm=np.unique(list(p))\n    return comm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#elbow method to chosse the best number of clusters\ndef elbow(df1):\n    distortions = []\n    k = 50\n    K = []\n    while k < 101:\n        print(k)\n        K.append(k)\n        kmeanModel = KMeans(n_clusters=k).fit(df1)\n        kmeanModel.fit(df1)\n        distortions.append(sum(np.min(cdist(df1, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / df1.shape[0])\n        k += 2\n\n    # # Plot the elbow\n    plt.plot(K, distortions, 'bx-')\n    plt.xlabel('k')\n    plt.ylabel('Distortion')\n    plt.title('The Elbow Method showing the optimal k')\n    plt.show()\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merge the data\nt = pd.merge(tags,tag_questions, left_on='tags_tag_id', right_on='tag_questions_tag_id')\nt = pd.merge(t,questions_Answers,left_on='tag_questions_question_id',right_on='answers_question_id')\ntags=t['tags_tag_name']\n\n#get features form the question using tfidf vectirization\nvectorizer = TfidfVectorizer(max_df=0.5, max_features=100, min_df=2, stop_words='english',use_idf=True)\nvec = vectorizer.fit(tags)\nx=vec.transform(tags)\ndf1=x.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cluster the data using k means\nkm = KMeans(n_clusters=62, init='k-means++', max_iter=100, n_init=1).fit(x)\nlabels = km.labels_.tolist()\n\n#now predict the new professional\nids=ToCollaborative\nmost_common=[]\nfor id in range(len(ids)):\n    out=getProfessionalTages(t,ids[id])\n    out = vec.transform(out)\n    out=out.toarray()\n    pred=km.predict(out)\n    indices = [i for i, value in enumerate(labels) if value in pred]\n    #print(indices)\n    p=t['answers_author_id'][indices]\n    comm=Counter(p)\n    n=10\n    if len(comm)<10:\n        n=len(comm)\n    arr=[]\n    comm=comm.most_common(n)\n    for a,b in comm:\n        arr.append(a)\n    most_common.append(arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_common","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output=dict()\nfor i in range(len(most_common)):\n    for j in range (len(most_common[i])):\n        if most_common[i][j] in output:\n            value=output.get(str(most_common[i][j]))+1\n            key=str(most_common[i][j])\n            output.update({key: value})\n        else:\n            output.setdefault(str(most_common[i][j]), 1)\nsorted_output = sorted(output.items(), key=operator.itemgetter(1),reverse=True)\nn=10\nif len(comm) < 10:\n    n = len(sorted_output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the final recommended professionals' ids is **sorted_output**"},{"metadata":{},"cell_type":"markdown","source":"#### final output<a id='final'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_output[0:n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How to use the model<a id='use'></a>"},{"metadata":{},"cell_type":"markdown","source":"1. write the asked question body in the variable [test](#test)  \n\n2.  the final ids of recommended professionals are in the variable [sorted_output](#final)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}