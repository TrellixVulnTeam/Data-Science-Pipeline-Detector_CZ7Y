{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport warnings\nimport copy\nimport nltk\nimport string\nfrom nltk.corpus import stopwords\nfrom tqdm import tqdm\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom scipy.spatial.distance import pdist, squareform\nwarnings.filterwarnings('ignore')\nroot_path = '../input/'\nprint('The csv files provided are:\\n')\nprint(os.listdir(root_path))","execution_count":1,"outputs":[{"output_type":"stream","text":"The csv files provided are:\n\n['emails.csv', 'questions.csv', 'professionals.csv', 'comments.csv', 'tag_users.csv', 'group_memberships.csv', 'tags.csv', 'answer_scores.csv', 'students.csv', 'groups.csv', 'tag_questions.csv', 'question_scores.csv', 'matches.csv', 'answers.csv', 'school_memberships.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_emails = pd.read_csv(root_path + 'emails.csv')\ndf_questions = pd.read_csv(root_path + 'questions.csv')\ndf_professionals = pd.read_csv(root_path + 'professionals.csv')\ndf_comments = pd.read_csv(root_path + 'comments.csv')\ndf_tag_users = pd.read_csv(root_path + 'tag_users.csv')\ndf_group_memberships = pd.read_csv(root_path + 'group_memberships.csv')\ndf_tags = pd.read_csv(root_path + 'tags.csv')\ndf_answer_scores = pd.read_csv(root_path + 'answer_scores.csv')\ndf_students = pd.read_csv(root_path + 'students.csv')\ndf_groups = pd.read_csv(root_path + 'groups.csv')\ndf_tag_questions = pd.read_csv(root_path + 'tag_questions.csv')\ndf_question_scores = pd.read_csv(root_path + 'question_scores.csv')\ndf_matches = pd.read_csv(root_path + 'matches.csv')\ndf_answers = pd.read_csv(root_path + 'answers.csv')\ndf_school_memberships = pd.read_csv(root_path + 'school_memberships.csv')","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This notebook is a continuation of [Part I: Yet Another EDA, Strategy & Useful Links](https://www.kaggle.com/akshayt19nayak/part-i-yet-another-eda-strategy-useful-links). In this notebook, I am going to focus on building a recommender system **exclusively using tags**. What's funny is that this solution does not involve machine learning in any which way. A recommender system built by extracting data from the body of questions and answers is in the works. I haven't done everything here due to memory and time constraints. There are 3 sections to this notebook:\n\n- [Pre-processing](#Pre-processing)\n- [Recommender System](#Recommender-System)\n- [Real-Time Implementation](#Real-Time-Implementation)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Pre-processing\n\nFirst, we focus on using tags that have a user following of atleast 0.25% of the total number of tagged users and 0.25% of the total number of tagged questions which is about 58 questions. These threshold values have been selected after a bit of experimentation and can be treated as hyperparameters (although they aren't in the technical sense)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tag_users_merged = pd.merge(df_tag_users, df_tags, left_on='tag_users_tag_id', right_on='tags_tag_id', how='inner')\n#To see the tags that are linked with every question\nthresh = 0.0025\ndf_tag_questions_merged = pd.merge(df_tag_questions, df_tags, left_on='tag_questions_tag_id', right_on='tags_tag_id', how='inner')\nuser_tags = list((df_tag_users_merged['tags_tag_name'].value_counts()/df_tag_users_merged['tag_users_user_id'].nunique() \n                     > thresh).index[(df_tag_users_merged['tags_tag_name'].value_counts()/df_tag_users_merged['tag_users_user_id'].nunique() > thresh)])\nquestion_tags = list((df_tag_questions_merged['tags_tag_name'].value_counts()/df_tag_questions_merged['tag_questions_question_id'].nunique() \n                     > thresh).index[(df_tag_questions_merged['tags_tag_name'].value_counts()/df_tag_questions_merged['tag_questions_question_id'].nunique() > thresh)])\nrelevant_tags = set(user_tags).union(set(question_tags))","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we'll look at the coverage of these tags"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"print('The number of relevant tags:', len(relevant_tags))\nprint('Coverage of tagged questions:', df_tag_questions_merged[df_tag_questions_merged['tags_tag_name'].isin(\nrelevant_tags)]['tag_questions_question_id'].nunique()/df_tag_questions_merged['tag_questions_question_id'].nunique())\nprint('Coverage of tagged users:', df_tag_users_merged[df_tag_users_merged['tags_tag_name'].isin(\nrelevant_tags)]['tag_users_user_id'].nunique()/df_tag_users_merged['tag_users_user_id'].nunique())","execution_count":36,"outputs":[{"output_type":"stream","text":"The number of relevant tags: 421\nCoverage of tagged questions: 0.8777911370663002\nCoverage of tagged users: 0.9266935964505661\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"There are a few things we would like to do here:\n- Find tags that are misspelings/similar to the relevant tags\n- Replace the similar tags with the main tags. A good way to decide main tags would be to rank them in order of the people that follow them. Why? Professionals are only going to get alerts/ see questions on the platform if they follow a particular tag\n- Thus increase the coverage"},{"metadata":{},"cell_type":"markdown","source":"### Edit Distance (Levenshtein Distance)\n\n- Edit Distance (a.k.a. Levenshtein Distance) is a measure of similarity between two strings referred to as the source string and the target string.\n\n- The distance between the source string and the target string is the minimum number of edit operations (deletions, insertions, or substitutions) required to transform the source into the target. The lower the distance, the more similar the two strings. ([Source](https://python.gotrained.com/nltk-edit-distance-jaccard-distance/))\n\nTo see an example we'll first test it on the tag 'computer'"},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_if_found(df, column, string):\n    return(df[df[column].str.contains(string)][column].unique())\narray_computer = return_if_found(df_tag_users_merged, 'tags_tag_name', 'computer')\ncomputer_ed = np.array([nltk.edit_distance('computer',word) for word in array_computer])\ndf_computer_ed = pd.DataFrame({'string':array_computer, 'edit_distance':computer_ed})\ndf_computer_ed[df_computer_ed['edit_distance']<=2]","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"        string  edit_distance\n3     computer              0\n22   computers              1\n56  #computers              2\n72   #computer              1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>string</th>\n      <th>edit_distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>computer</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>computers</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>#computers</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>#computer</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The algorithm is as follows:\n- Sort the tags based on the count of tagged users per tag\n- Save the positions (or the rank) of these tags in a seperate dictionary\n- For all the tags in relevant tags, find tags that are at an edit distance of 2 for length of tags greater than 5 and tags that contain a '#' at the beginning or a '-'/'s' at the end of tags that have a length lesser than/equal to 5 (with smaller tags it is possible to entirely change the meaning even with an edit distance of 1)\n- If a higher (highest would be rank 0) ranked tag is included in the list of similar tags for a particular tag, remove it\n- Extend the list of lower ranked tags \n- Remove tags that are in both keys and values of the dictionary of similar tags\n- Make a dictionary of tags to replace with the main tags"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sorting tags based on follower count\ndict_users_tags = df_tag_users_merged['tags_tag_name'].value_counts().to_dict()\nlist_users_tags = sorted(dict_users_tags, key=dict_users_tags.get)[::-1]\ndict_rank_tags = {}\nfor rank, tags in enumerate(list_users_tags):\n    dict_rank_tags[tags] = rank\ndef find_similar(relevant, space):\n    dict_similar_tags = {}\n    for tag_i in tqdm(relevant):\n        dict_similar_tags[tag_i] = []\n        for tag_j in space:\n            if tag_i != tag_j:\n                if (len(tag_i) >5 and nltk.edit_distance(tag_i, tag_j) <= 2): #Condition 1\n                    dict_similar_tags[tag_i].append(tag_j)\n                elif (len(tag_i) <=5 and (tag_j == '#'+tag_i or tag_j == tag_i+'s' or tag_j == tag_i+'-')): #Condition 2\n                    dict_similar_tags[tag_i].append(tag_j)\n    return(dict_similar_tags)\ndict_similar_tags = find_similar(relevant_tags, list_users_tags)","execution_count":6,"outputs":[{"output_type":"stream","text":"100%|██████████| 421/421 [16:51<00:00,  2.31s/it]\n","name":"stderr"}]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"print('Rank of tag internship:', dict_rank_tags['internship'])\nprint('Tags similar to internship:', dict_similar_tags['internship'])\nprint('Rank of tag internship:', dict_rank_tags['internships'])\nprint('Tags similar to internship:', dict_similar_tags['internships'])","execution_count":7,"outputs":[{"output_type":"stream","text":"Rank of tag internship: 204\nTags similar to internship: ['internships', '#internships', '#internship', 'internships2', '#intership', 'externship', 'intership', 'internship2', 'interneships', 'internships-']\nRank of tag internship: 29\nTags similar to internship: ['#internships', 'internship', '#internship', 'internships2', 'intership', 'internship2', 'interneships', 'internships-']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Our job now is to remove the lower ranked tags and couple all variations of the tag 'internship' in the tag 'internships'"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Deepcopy as the value is a mutable data structure\ndict_similar_tags_copy = copy.deepcopy(dict_similar_tags)\nfor tag, similar in dict_similar_tags.items():\n    for subtag in similar:\n        if dict_rank_tags[subtag] < dict_rank_tags[tag]:\n            dict_similar_tags_copy[tag].remove(subtag) \n        else:\n            pass\nfor tag, similar in dict_similar_tags_copy.items():\n    extensions = []\n    for subtag in similar:\n        try:\n            extensions.extend(dict_similar_tags_copy[subtag])\n        except:\n            pass\n    dict_similar_tags_copy[tag].extend(extensions)\n    dict_similar_tags_copy[tag] = list(set(dict_similar_tags_copy[tag]))\n#This is what we'll replace\nsimilar_tags = list(set([item for sublist in list(dict_similar_tags_copy.values()) for item in sublist]))\nlist_keys = list(dict_similar_tags.keys())\nfor tag in list_keys:\n    if tag in similar_tags:\n        del dict_similar_tags_copy[tag]\n#This is what we'll use to replace\nmain_tags = list(dict_similar_tags_copy.keys())","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Tags similar to internships:', dict_similar_tags_copy['internships'])\nprint('Tags similar to internship:\\n')\ntry:\n    print(dict_similar_tags_copy['internship'])\n#internship is not a key on account of being a low ranked tag\nexcept KeyError as e:\n    print('Key Error:', e)","execution_count":9,"outputs":[{"output_type":"stream","text":"Tags similar to internships: ['intership', '#externships', 'internships2', '#internship', 'internship2', 'externship', 'internships-', 'internship', '#intership', 'interneships', '#internships']\nTags similar to internship:\n\nKey Error: 'internship'\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now let's look at the coverage"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"print('The number of relevant tags:', len(main_tags))\nprint('The number of tags that the relevant tags cover:', len(similar_tags))\ndf_tag_users_merged = pd.merge(df_tag_users, df_tags, left_on='tag_users_tag_id', right_on='tags_tag_id', how='inner')\ndf_tag_questions_merged = pd.merge(df_tag_questions, df_tags, left_on='tag_questions_tag_id', right_on='tags_tag_id', how='inner')\nprint('Coverage of tagged questions:', df_tag_questions_merged[df_tag_questions_merged['tags_tag_name'].isin(\n    set(main_tags).union(set(similar_tags)))]['tag_questions_question_id'].nunique()/df_tag_questions_merged['tag_questions_question_id'].nunique())\nprint('Coverage of tagged users:', df_tag_users_merged[df_tag_users_merged['tags_tag_name'].isin(\n    set(main_tags).union(set(similar_tags)))]['tag_users_user_id'].nunique()/df_tag_users_merged['tag_users_user_id'].nunique())","execution_count":39,"outputs":[{"output_type":"stream","text":"The number of relevant tags: 387\nThe number of tags that the relevant tags cover: 1121\nCoverage of tagged users: 0.9358320641017152\nCoverage of tagged questions: 0.895225008588114\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The coverage has definitely improved albeit marginally. Also, the number of tags has reduced. We don't want to consider too many tags as this will just blow up the number of features we have per question and will create computational problems. Now we'll replace the similar tags with the main tags\n\nIn an earlier version of the notebook, we used tags that have usage above a threshold of 0.5% of tagged questions and 0.5% of tagged users. In that case the coverage of tagged questions improved by about 3%, compared to the 2% here. Minor improvements are great as even a 1% improvement translates to 233 questions. Thus, by lowering the threshold and using the algorithm, we have been able to cover 1400 additional questions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#To create a dictionary of tags that'll have the tag to be replaced as the key and the tag to replace it by as the value\ndict_replace_tag = {}\nfor tag, similar in dict_similar_tags_copy.items():\n    for subtag in similar:\n        dict_replace_tag[subtag] = tag\nfor tag in main_tags:\n    dict_replace_tag[tag] = tag\n#Only looking at the questions that have atleast one tag out of the union of main tags and similar tags\ndf_all_tag_questions = df_tag_questions_merged[df_tag_questions_merged['tags_tag_name'].isin(\n    set(main_tags).union(similar_tags))].groupby('tag_questions_question_id', as_index=False).agg({'tags_tag_name':list})\ndef replace(list_tags):\n    replaced_list = []\n    for tag in list_tags:\n        try:\n            replaced_list.append(dict_replace_tag[tag])\n        except:\n            pass\n    return(list(set(replaced_list)))\ndf_all_tag_questions['replaced_tag_name'] = df_all_tag_questions['tags_tag_name'].apply(replace)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cosine Similarity\n\nNow we one-hot encode the questions with tags they are linked with and build a similarity matrix using cosine similarity as the metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create MultiLabelBinarizer object\none_hot = MultiLabelBinarizer()\n#One-hot encode data\ndesign_matrix = one_hot.fit_transform(df_all_tag_questions['replaced_tag_name'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building cosine similarity matrix \ncos_sim = 1-squareform(pdist(design_matrix, metric='cosine')) #pdist computes cosine distance, so we subtract that from 1 to compute similarity\ndel design_matrix #To free up the RAM","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Recommender System\n\nTo make recommendations based on a question:    \n- Find questions that are similar to the one under consideration\n- Find if the similar questions have been answered\n- If yes, find if the professional is active. Active professional has to have answered a question within the last 1 year\n- If multiple professionals fit the criteria, rank them based on the proportion of questions they have answered within 24-48 hours [since that is a key metric](https://www.kaggle.com/c/data-science-for-good-careervillage/discussion/84845#latest-496046) "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#To see the profile of the volunteers and the questions that they have answered\ndf_questions['questions_date_added'] = pd.to_datetime(df_questions['questions_date_added'])\ndf_answers['answers_date_added'] = pd.to_datetime(df_answers['answers_date_added'])\ndf_answers_professionals = pd.merge(df_answers, df_professionals, left_on='answers_author_id', right_on='professionals_id', how='outer')\ndf_questions_answers_professionals = pd.merge(df_questions, df_answers_professionals, left_on='questions_id', right_on='answers_question_id')\ndf_qap_time_taken = df_questions_answers_professionals.groupby(['professionals_id','questions_id']).agg({'questions_date_added':min, 'answers_date_added':min})\ndf_qap_time_taken['less_than_2_days'] = df_qap_time_taken['answers_date_added'] - df_qap_time_taken['questions_date_added'] < '2 days'\ndf_qap_time_taken = df_qap_time_taken.reset_index().groupby('professionals_id', as_index=False).agg({'less_than_2_days':np.mean})\nlast_date = df_questions['questions_date_added'].max() #date of the last question asked on the platform\ndf_ap_grouped = df_answers_professionals.groupby('professionals_id').agg({'answers_date_added':max}).apply(lambda x:\n                                                                                          (last_date-x).dt.days)\ndf_ap_grouped.rename(columns={'answers_date_added':'days_since_answered'}, inplace=True)\nactive_professionals = df_ap_grouped[df_ap_grouped['days_since_answered']<365].index","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Example Recommendation 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"qid = 1\nidx = np.argsort(cos_sim[qid,:])[-6:-1]\nprint('Question Title and Body:\\n')\n#Sample question\nprint(list(df_questions[df_questions['questions_id']==df_all_tag_questions['tag_questions_question_id'].iloc[qid]]['questions_title']))\nprint(list(df_questions[df_questions['questions_id']==df_all_tag_questions['tag_questions_question_id'].iloc[qid]]['questions_body']))","execution_count":67,"outputs":[{"output_type":"stream","text":"Question Title and Body:\n\n['Should I declare a minor during undergrad if I want to be a lawyer?']\n[\"I'm currently an undergrad, but I want to go to law school and be a lawyer. I've been thinking about minoring in psychology but would it be helpful in the long run at all? #psychology #law \"]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing out the question body as it gives more insight into what the student actually wants to ask\nprint('Similar questions ranked by cosine similarity:\\n')\nfor rank, index in enumerate(idx[::-1]):\n    print(rank, '-', list(df_questions[df_questions['questions_id']==df_all_tag_questions.iloc[index]['tag_questions_question_id']]['questions_body']))","execution_count":64,"outputs":[{"output_type":"stream","text":"Similar questions ranked by cosine similarity:\n\n0 - [\"Interested in the field and seeing the various areas of expertise one can have. Also what types of schooling beyond a bachelor's degree could help? #psychology #law #clinical\"]\n1 - [\"I'm asking this because on TV I've seen many shows about people who study the criminal brain and they study how criminals think. This seems very interesting to me but I don't know where to get started. #psychology #law #criminology #behavioral-health\"]\n2 - ['What are some ways to intertwine the two fields? Are there certain jobs that draw aspects from both? #psychology #law']\n3 - ['My life is moving, and I cannot think of something that I would love to do everyday as a job unless it contains those two aspects in some way.  #psychology #law #lawyer #brain']\n4 - ['For an adult-learner with no prior work experience in the legal field, but completing a Certificate in Paralegal Studies, what specific life skills might I use as transferable skills both on my resume and during an interview? #paralegal #legal #law #women-in-law ']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"author_id = df_answers[df_answers['answers_question_id'].isin(df_all_tag_questions.iloc[idx[::-1]]['tag_questions_question_id'])]['answers_author_id']\nactive_author_id = author_id[author_id.isin(active_professionals)]\ndf_recommended_pros = df_qap_time_taken[df_qap_time_taken['professionals_id'].isin(active_author_id)].sort_values('less_than_2_days', ascending=False)\nprint('The recommended professionals ranked by the proportion of questions answered within 48 hours:', df_recommended_pros['professionals_id'].tolist())\nprint('The profile of the professionals:')\ndf_professionals[df_professionals['professionals_id'].isin(df_recommended_pros['professionals_id'])]","execution_count":65,"outputs":[{"output_type":"stream","text":"The recommended professionals ranked by the proportion of questions answered within 48 hours: ['369f1c8646b649f6997eae7809696bd5', 'c5c2ca95fcd3463a8852b8bc9d636313', 'be5d23056fcb4f1287c823beec5291e1', 'e1d39b665987455fbcfbec3fc6df6056', '85f378f43eee44c986addf5fc27038ce', '0d8a769b6e2c447d97a6435f96814029', '874bb5c4fd4b4e498660c1f2c0a4ab3e']\nThe profile of the professionals:\n","name":"stdout"},{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"                       professionals_id              ...                  professionals_date_joined\n1737   369f1c8646b649f6997eae7809696bd5              ...               2015-02-05 17:52:38 UTC+0000\n2546   c5c2ca95fcd3463a8852b8bc9d636313              ...               2015-11-06 15:36:36 UTC+0000\n3581   be5d23056fcb4f1287c823beec5291e1              ...               2016-01-21 03:23:22 UTC+0000\n4397   85f378f43eee44c986addf5fc27038ce              ...               2016-03-07 18:41:34 UTC+0000\n5876   e1d39b665987455fbcfbec3fc6df6056              ...               2016-05-04 18:12:23 UTC+0000\n10426  0d8a769b6e2c447d97a6435f96814029              ...               2017-04-30 17:48:38 UTC+0000\n26953  874bb5c4fd4b4e498660c1f2c0a4ab3e              ...               2019-01-06 13:46:54 UTC+0000\n\n[7 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>professionals_id</th>\n      <th>professionals_location</th>\n      <th>professionals_industry</th>\n      <th>professionals_headline</th>\n      <th>professionals_date_joined</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1737</th>\n      <td>369f1c8646b649f6997eae7809696bd5</td>\n      <td>Harlingen, Texas</td>\n      <td>Information Technology and Services, Franchise...</td>\n      <td>Career Guru</td>\n      <td>2015-02-05 17:52:38 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>2546</th>\n      <td>c5c2ca95fcd3463a8852b8bc9d636313</td>\n      <td>Tampa, Florida</td>\n      <td>Legal Services</td>\n      <td>Immigration Attorney</td>\n      <td>2015-11-06 15:36:36 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>3581</th>\n      <td>be5d23056fcb4f1287c823beec5291e1</td>\n      <td>San Antonio, Texas</td>\n      <td>Legal Services</td>\n      <td>Employment Counselor  | Open Records Specialist</td>\n      <td>2016-01-21 03:23:22 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>4397</th>\n      <td>85f378f43eee44c986addf5fc27038ce</td>\n      <td>Reno, Nevada</td>\n      <td>Law Practice</td>\n      <td>Attorney</td>\n      <td>2016-03-07 18:41:34 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>5876</th>\n      <td>e1d39b665987455fbcfbec3fc6df6056</td>\n      <td>Greater Philadelphia Area</td>\n      <td>Professional Training</td>\n      <td>Industrial-Organizational Psychology &amp; HR Cons...</td>\n      <td>2016-05-04 18:12:23 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>10426</th>\n      <td>0d8a769b6e2c447d97a6435f96814029</td>\n      <td>Moraga, California</td>\n      <td>Health psychology, Wellness and Fitness</td>\n      <td>Oncology Therapist, Wellness Professional</td>\n      <td>2017-04-30 17:48:38 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>26953</th>\n      <td>874bb5c4fd4b4e498660c1f2c0a4ab3e</td>\n      <td>San Antonio, Texas</td>\n      <td>Legal Services</td>\n      <td>Thinks outside the box.</td>\n      <td>2019-01-06 13:46:54 UTC+0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Example Recommendation 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"qid = 512\nidx = np.argsort(cos_sim[qid,:])[-6:-1]\nprint('Question Title and Body:\\n')\n#Sample question. Printing out the question body as it gives more insight into what the student actually wants to ask\nprint(list(df_questions[df_questions['questions_id']==df_all_tag_questions['tag_questions_question_id'].iloc[qid]]['questions_title']))\nprint(list(df_questions[df_questions['questions_id']==df_all_tag_questions['tag_questions_question_id'].iloc[qid]]['questions_body']))","execution_count":69,"outputs":[{"output_type":"stream","text":"Question Title and Body:\n\n[\"My current plan is to go to a one year film college to get a certificate in screenwriting. Many people have mentioned that you really don't need a film degree to get into film, so a certificate is fine. Is this true?\"]\n['#film #film-production #director #screenwriting']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing out the question body as it gives more insight into what the student actually wants to ask\nprint('Similar questions ranked by cosine similarity:\\n')\nfor rank, index in enumerate(idx[::-1]):\n    print(rank, '-', list(df_questions[df_questions['questions_id']==df_all_tag_questions.iloc[index]['tag_questions_question_id']]['questions_body']))","execution_count":58,"outputs":[{"output_type":"stream","text":"Similar questions ranked by cosine similarity:\n\n0 - ['I Am A Junior In Highschool And We Had A Film Project We Worked On For A Bout A Month And I Really Enjoyed Working On It And Seem to Have A Bit Of Luck And Though Into How To Work The Camera Angles And Edit The Video. I Would Like To Learn More About Filming #film #movies-and-cinema']\n1 - ['importance of which classes should be taken first before others. #film ']\n2 - ['i am a senior in high school going on to college soon  to study film, and i am curious to know what are the best steps to take to ensure employment in the film industry after college. #film #in #film-production #industry']\n3 - ['#film #film-production #director #screenwriting']\n4 - ['because i would like to go to school out of state but i would like to make sure that im spending money on a good school that will help my future  #film']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"author_id = df_answers[df_answers['answers_question_id'].isin(df_all_tag_questions.iloc[idx[::-1]]['tag_questions_question_id'])]['answers_author_id']\nactive_author_id = author_id[author_id.isin(active_professionals)]\ndf_recommended_pros = df_qap_time_taken[df_qap_time_taken['professionals_id'].isin(active_author_id)].sort_values('less_than_2_days', ascending=False)\nprint('The recommended professionals ranked by the proportion of questions answered within 48 hours:', df_recommended_pros['professionals_id'].tolist())\nprint('The profile of the professionals:')\ndf_professionals[df_professionals['professionals_id'].isin(df_recommended_pros['professionals_id'])]","execution_count":59,"outputs":[{"output_type":"stream","text":"The recommended professionals ranked by the proportion of questions answered within 48 hours: ['c3c345b8e5044054a0544296ac29cb88', 'a1006e6a58a0447592e2435caa230f78', '70855821c28f4b4c8fb5e627e081bb56', 'e27c43e8671242e1bfb80829744ee3ad', '9a5aead62c344207b2624dba90985dc5', '9421dd803d164e5da26436a01a92ce13', 'cc0ef2b535894a77a92cc740be6c2513']\nThe profile of the professionals:\n","name":"stdout"},{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"                       professionals_id              ...                  professionals_date_joined\n1723   a1006e6a58a0447592e2435caa230f78              ...               2015-01-26 20:00:16 UTC+0000\n2338   c3c345b8e5044054a0544296ac29cb88              ...               2015-10-07 21:32:13 UTC+0000\n3786   cc0ef2b535894a77a92cc740be6c2513              ...               2016-02-08 18:18:52 UTC+0000\n4227   9421dd803d164e5da26436a01a92ce13              ...               2016-02-29 19:43:48 UTC+0000\n5074   70855821c28f4b4c8fb5e627e081bb56              ...               2016-03-30 17:06:05 UTC+0000\n24748  e27c43e8671242e1bfb80829744ee3ad              ...               2018-10-30 18:11:23 UTC+0000\n25379  9a5aead62c344207b2624dba90985dc5              ...               2018-11-15 19:16:05 UTC+0000\n\n[7 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>professionals_id</th>\n      <th>professionals_location</th>\n      <th>professionals_industry</th>\n      <th>professionals_headline</th>\n      <th>professionals_date_joined</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1723</th>\n      <td>a1006e6a58a0447592e2435caa230f78</td>\n      <td>State of Goiás, State of Goiás, Brazil</td>\n      <td>Research</td>\n      <td>Educational Writer- New Heights Educational Group</td>\n      <td>2015-01-26 20:00:16 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>2338</th>\n      <td>c3c345b8e5044054a0544296ac29cb88</td>\n      <td>Santa Monica, California</td>\n      <td>Marketing</td>\n      <td>Accountant, Financial Analyst, Marketing Speci...</td>\n      <td>2015-10-07 21:32:13 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>3786</th>\n      <td>cc0ef2b535894a77a92cc740be6c2513</td>\n      <td>Austin, Texas</td>\n      <td>Motion Pictures and Film</td>\n      <td>Film Editor</td>\n      <td>2016-02-08 18:18:52 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>4227</th>\n      <td>9421dd803d164e5da26436a01a92ce13</td>\n      <td>Ocean Shores, Washington</td>\n      <td>Motion Pictures and Film</td>\n      <td>Writer/Director</td>\n      <td>2016-02-29 19:43:48 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>5074</th>\n      <td>70855821c28f4b4c8fb5e627e081bb56</td>\n      <td>Los Angeles, California</td>\n      <td>Motion Pictures and Film</td>\n      <td>Filmmaker/Screenwriter/Educator</td>\n      <td>2016-03-30 17:06:05 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>24748</th>\n      <td>e27c43e8671242e1bfb80829744ee3ad</td>\n      <td>Chicago, Illinois</td>\n      <td>Entertainment</td>\n      <td>Theatre Professional and Consultant</td>\n      <td>2018-10-30 18:11:23 UTC+0000</td>\n    </tr>\n    <tr>\n      <th>25379</th>\n      <td>9a5aead62c344207b2624dba90985dc5</td>\n      <td>Newark, New Jersey</td>\n      <td>Education</td>\n      <td>Either fall or grow!</td>\n      <td>2018-11-15 19:16:05 UTC+0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The recommendations in both cases do look relevant."},{"metadata":{},"cell_type":"markdown","source":"## Real-Time Implementation\n\n- This isn't the right way to recommend as for a particular question, we only have data available prior to the date at which the question was posted and in this case we have considered all questions for analysis\n- Every time a new tag is added, find the main tag that it is closest to wrt edit distance. In some way, there needs to be more control over tag creation as lesser tags lead to information enrichment. Since it is a forum for asking career based questions and not Twitter/Instagram, it is certainly possible to do this.\n- Also, the feature vector for every question can be stored in the database\n- The cosine similarity of all questions (say m) asked before a given time period needs to be pre-computed and stored in the database since it is a memory and time intensive computation\n- Every time a new question is asked, it can be batched with other questions asked within (say) a 2 hour period and the cosine similarity of these questions (say n) with the questions that have been asked in the past can be computed\n- This way, we aren't computing cosine similarity of (m+n) x (m+n) questions, but (n) x (m+n) questions and the update becomes easier and faster\n- I know the technical details are a little fuzzy but this is just a rough solution to the problem at hand"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}