{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tag Visualization with Universal Sentence Encoder\n\nThis kernel is based on [An Attemplt to Visualize Topic Model (LDA)](https://www.kaggle.com/ceshine/an-attemplt-to-visualize-topic-model-lda). This kernel removes the topic model and instead focus on the sentence embeddings space from the universal sentence encoder model and the (hash)tags.\n\nAs with the previous kernel, hashtags are removed from the question texts. So the universal sentence encoder does **not** have any direct information whatsoever regarding to the questions associated hastags.\n\n> Hashtags are removed. I want to separate natural language understanding from (implicit) tag grouping in this task, that is, only focus on the questions, not tags.\n\nDimension reduction is done via [UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction](https://umap-learn.readthedocs.io/en/latest/). And [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder-large/3) comes from [TensorFlow Hub](https://www.tensorflow.org/hub)."},{"metadata":{},"cell_type":"markdown","source":"## Contents\n\n1. [Imports](#Imports)\n1. [Preprocessing](#Preprocessing)\n  * [Checking](#Checking)\n  * [The Real Deal](#The-Real-Deal)\n1. [Tags](#Tags)\n1. [Sentence Embeddings](#Sentence-Embeddings)\n1. [Visualization (Global)](#Global-Visualization)\n1. [Visualization (Tags)](#Tag-Visualization)\n  * [#medicine & #engineering](##medicine-&-#engineering)\n  * [#medicine & #business](##medicine-&-#business)\n  * [#engineering & #business & #medicine](##engineering-&-#business-&-#medicine)\n1. [Summary](#Summary)"},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## Imports"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"import os\nimport re\nimport html as ihtml\nimport warnings\nimport random\nwarnings.filterwarnings('ignore')\n\nos.environ[\"TFHUB_CACHE_DIR\"] = \"/tmp/\"\n\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport umap\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nimport plotly_express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.max_colwidth', -1)\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_random_seed(SEED)\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"umap.__version__","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"input_dir = '../input'\n\nquestions = pd.read_csv(os.path.join(input_dir, 'questions.csv'))\ntags = pd.read_csv(os.path.join(input_dir, 'tags.csv'))\ntag_questions = pd.read_csv(os.path.join(input_dir, 'tag_questions.csv'))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"def clean_text(text, remove_hashtags=True):\n    text = BeautifulSoup(ihtml.unescape(text), \"lxml\").text\n    text = re.sub(r\"http[s]?://\\S+\", \"\", text)\n    if remove_hashtags:\n        text = re.sub(r\"#[a-zA-Z\\-]+\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text)        \n    return text","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"questions['questions_full_text'] = questions['questions_title'] + ' '+ questions['questions_body']","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true,"hidden":true},"cell_type":"markdown","source":"### Checking"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"sample_text = questions[questions['questions_full_text'].str.contains(\"&a\")][\"questions_full_text\"].iloc[0]\nsample_text","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"sample_text = clean_text(sample_text)\nsample_text","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"### The Real Deal"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"%%time\nquestions['questions_full_text'] = questions['questions_full_text'].apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"questions['questions_full_text'].sample(2)","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## Tags"},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Top tags:"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"tag_questions.groupby(\n    \"tag_questions_tag_id\"\n).size().sort_values(ascending=False).to_frame(\"count\").merge(\n    tags, left_on=\"tag_questions_tag_id\", right_on=\"tags_tag_id\"\n).head(10)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"There are 24 questions tagged both #medicine and #engineering:"},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"questions_id_medicine = set(tag_questions[tag_questions.tag_questions_tag_id == 89].tag_questions_question_id)\nquestions_id_engineering = set(tag_questions[tag_questions.tag_questions_tag_id == 54].tag_questions_question_id)\nlen(questions_id_medicine), len(questions_id_engineering), len(questions_id_medicine.intersection(questions_id_engineering))","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## Sentence Embeddings\n\nThe model used is the universal sentence encoder (large/transformer) version 3. The extracted sentence embeddings will have a dimension of 512. Here we also use cosine similarity."},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"import logging\nfrom tqdm import tqdm_notebook\ntf.logging.set_verbosity(logging.WARNING)\nBATCH_SIZE = 128\n\nsentence_input = tf.placeholder(tf.string, shape=(None))\n# For evaluation we use exactly normalized rather than\n# approximately normalized.\nsentence_emb = tf.nn.l2_normalize(embed(sentence_input), axis=1)\n\nsentence_embeddings = []       \nwith tf.Session() as session:\n    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n    for i in tqdm_notebook(range(0, len(questions), BATCH_SIZE)):\n        sentence_embeddings.append(\n            session.run(\n                sentence_emb, \n                feed_dict={\n                    sentence_input: questions[\"questions_full_text\"].iloc[i:(i+BATCH_SIZE)].values\n                }\n            )\n        )","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"sentence_embeddings = np.concatenate(sentence_embeddings, axis=0)\nsentence_embeddings.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Global Visualization\n\nHere we plot 10,000 samples to give readers a sense of what does the embedding space looks like."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nembedding = umap.UMAP(metric=\"cosine\", n_components=2, random_state=42).fit_transform(sentence_embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_se_emb = pd.DataFrame(embedding, columns=[\"x\", \"y\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_emb_sample = df_se_emb.sample(10000)\nfig, ax = plt.subplots(figsize=(12, 10))\nplt.scatter(\n    df_emb_sample[\"x\"].values, df_emb_sample[\"y\"].values, s=1\n)\nplt.setp(ax, xticks=[], yticks=[])\nplt.title(\"Sentence embeddings embedded into two dimensions by UMAP\", fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"### Examine the outliers\n\n"},{"metadata":{"hidden":true},"cell_type":"markdown","source":"The far right cluster contains questions related to \"stream\". Many of them starts with \"In which stream\". Arguably this is not the best way to map these questions, as it's not useful in recommending questions to the professionals."},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"print(questions[df_se_emb.x > 10].shape[0])\nquestions[df_se_emb.x > 10].questions_full_text.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"The top cluster is related to textbooks. This one looks rather reasonable."},{"metadata":{"hidden":true,"trusted":true},"cell_type":"code","source":"print(questions[df_se_emb.y > 8].shape[0])\nquestions[df_se_emb.y > 8].questions_full_text.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tag Visualization\n\nThe number of questions is relative small here so we could use the new [Plotly Express](https://medium.com/@plotlygraphs/introducing-plotly-express-808df010143d) library to provide interactive visualizations. The legends in the right side are clickable. Use them to help you better distinguish the questions from different tags."},{"metadata":{},"cell_type":"markdown","source":"### #medicine & #engineering"},{"metadata":{"trusted":false},"cell_type":"code","source":"questions_id_medicine = tag_questions[tag_questions.tag_questions_tag_id == 89].tag_questions_question_id\nquestions_id_engineering = tag_questions[tag_questions.tag_questions_tag_id == 54].tag_questions_question_id\ndf_se_emb[\"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_medicine), \"tag\"] = \"medicine\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_engineering), \"tag\"] = \"engineering\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_medicine).intersection(\n    set(questions_id_engineering)))), \"tag\"] = \"both\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_se_emb.tag.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"px.colors.qualitative.D3","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample[\"size\"] = 20\npx.scatter(\n    df_emb_sample, x=\"x\", y=\"y\", color=\"tag\", template=\"plotly_white\", size=\"size\",\n    range_x=((-7, 12)), range_y=((-9, 10)), opacity=0.3, size_max=5,\n    width=800, height=600, color_discrete_sequence=px.colors.qualitative.Vivid\n    \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### #medicine & #business"},{"metadata":{"trusted":false},"cell_type":"code","source":"questions_id_medicine = tag_questions[tag_questions.tag_questions_tag_id == 89].tag_questions_question_id\nquestions_id_biz = tag_questions[tag_questions.tag_questions_tag_id == 27292].tag_questions_question_id\ndf_se_emb[\"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_medicine), \"tag\"] = \"medicine\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_biz), \"tag\"] = \"business\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_medicine).intersection(\n    set(questions_id_biz)))), \"tag\"] = \"both\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample[\"size\"] = 20\npx.scatter(\n    df_emb_sample, x=\"x\", y=\"y\", color=\"tag\", template=\"plotly_white\", size=\"size\",\n    range_x=((-7, 12)), range_y=((-9, 10)), opacity=0.3, size_max=5,\n    width=800, height=600, color_discrete_sequence=px.colors.qualitative.Vivid\n    \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### #engineering & #business & #medicine\n\nIn this plot we remove all the intersections to make the plot cleaner:"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_se_emb[\"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_engineering), \"tag\"] = \"engineering\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_biz), \"tag\"] = \"business\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_medicine), \"tag\"] = \"medicine\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_engineering).intersection(\n    set(questions_id_biz)))), \"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_medicine).intersection(\n    set(questions_id_biz)))), \"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_medicine).intersection(\n    set(questions_id_engineering)))), \"tag\"] = \"none\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample[\"size\"] = 20\npx.scatter(\n    df_emb_sample, x=\"x\", y=\"y\", color=\"tag\", template=\"plotly_white\", size=\"size\",\n    range_x=((-7, 12)), range_y=((-9, 10)), opacity=0.3, size_max=5,\n    width=800, height=600, color_discrete_sequence=px.colors.qualitative.Vivid\n    \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summary\n\nThe questions with #business, #engineering, and #medicine tags each formed one bigger cluster that are clearly separated from each other. Those questions are the \"easy\" ones. We can easily create a tag recommendation model for those questions. The others, however, can be a bit problematic. Many of them are still distinguishable, but might require higher degree of non-linearity to model them.\n\nThe results are better than I expected. At least we did not get something that are fully intertwined. The universal sentence encoder does show some potential for this problem."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":1}