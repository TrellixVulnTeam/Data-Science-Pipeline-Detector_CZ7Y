{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAIN","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import zipfile\n\nzf = zipfile.ZipFile('../input/bosch-production-line-performance/train_date.csv.zip') \ntrain_date_chunks = pd.read_csv(zf.open('train_date.csv'), iterator=True, chunksize=100000)\n\npd.options.display.max_columns = None\npd.options.display.max_rows = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_date_frame():\n    for data_frame in train_date_chunks:\n        yield data_frame\n        \nget_df_date = get_date_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_date = next(get_df_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_date.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_date.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_date.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_list = []\nfirst_features_in_each_station = [] \n\ndf_date_columns = df_date.columns.tolist()\n\nfor feature in df_date_columns[1:]:\n    station = feature[:feature.index('_D')]\n    if station in station_list:\n        continue\n    else:\n        station_list.append(station)\n        first_features_in_each_station.append(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df_time_stamp = pd.DataFrame (np.array(df_date[first_features_in_each_station]), columns = station_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of visited stations: {} calculated from all given parts\".format(len(station_df_time_stamp.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df_time_stamp['Station list'] = station_df_time_stamp.stack().reset_index(level=1).groupby(level=0, sort=False)['level_1'].apply(list)\nstation_df_time_stamp.insert(0, \"Id\", np.array(df_date[[\"Id\"]]))\nstation_df_time_stamp.insert(1, \"#_of_S\",station_df_time_stamp.count(axis=1)-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df_time_stamp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_one_hot = pd.DataFrame (np.array(df_date[first_features_in_each_station]), columns = station_list)\nstation_one_hot = station_one_hot.notnull().astype('int')\nstation_one_hot.insert(0, \"Id\", np.array(df_date[[\"Id\"]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_one_hot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df_time_stamp.to_csv('stations_date_train.csv', index=False)  \nstation_one_hot.to_csv('stations_one_hot_train.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"while True:\n    try:\n        df_date = next(get_df_date)\n    except:\n        break\n    \n   # station with timestamp\n    station_df_time_stamp = pd.DataFrame (np.array(df_date[first_features_in_each_station]), columns = station_list)\n\n    station_df_time_stamp['Station list'] = station_df_time_stamp.stack().reset_index(level=1).groupby(level=0, sort=False)['level_1'].apply(list)\n    station_df_time_stamp.insert(0, \"Id\", np.array(df_date[[\"Id\"]]))\n    station_df_time_stamp.insert(1, \"#_of_S\",station_df_time_stamp.count(axis=1)-2)\n    \n    with open(\"./stations_date_train.csv\", 'a') as f:\n        station_df_time_stamp.to_csv(f, mode='a', header=False, index=False)\n    \n    \n    # station one hot\n    station_one_hot = pd.DataFrame (np.array(df_date[first_features_in_each_station]), columns = station_list)\n    station_one_hot = station_one_hot.notnull().astype('int')\n    station_one_hot.insert(0, \"Id\", np.array(df_date[[\"Id\"]]))\n    \n    with open(\"./stations_one_hot_train.csv\", 'a') as f:\n        station_one_hot.to_csv(f, mode='a', header=False, index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TEST","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"zf = zipfile.ZipFile('../input/bosch-production-line-performance/test_date.csv.zip') \ntest_date_chunks = pd.read_csv(zf.open('test_date.csv'), iterator=True, chunksize=100000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_date_frame():\n    for data_frame in test_date_chunks:\n        yield data_frame\n        \nget_df_date = get_date_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_date = next(get_df_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_list = []\nfirst_features_in_each_station = [] \n\ndf_date_columns = df_date.columns.tolist()\n\nfor feature in df_date_columns[1:]:\n    station = feature[:feature.index('_D')]\n    if station in station_list:\n        continue\n    else:\n        station_list.append(station)\n        first_features_in_each_station.append(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df_time_stamp = pd.DataFrame (np.array(df_date[first_features_in_each_station]), columns = station_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of visited stations: {} calculated from all given parts\".format(len(station_df_time_stamp.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df_time_stamp['Station list'] = station_df_time_stamp.stack().reset_index(level=1).groupby(level=0, sort=False)['level_1'].apply(list)\nstation_df_time_stamp.insert(0, \"Id\", np.array(df_date[[\"Id\"]]))\nstation_df_time_stamp.insert(1, \"#_of_S\",station_df_time_stamp.count(axis=1)-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_one_hot = pd.DataFrame (np.array(df_date[first_features_in_each_station]), columns = station_list)\nstation_one_hot = station_one_hot.notnull().astype('int')\nstation_one_hot.insert(0, \"Id\", np.array(df_date[[\"Id\"]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df_time_stamp.to_csv('stations_date_test.csv', index=False)  \nstation_one_hot.to_csv('stations_one_hot_test.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_one_hot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"while True:\n    try:\n        df_date = next(get_df_date)\n    except:\n        break\n    \n   # station with timestamp\n    station_df_time_stamp = pd.DataFrame (np.array(df_date[first_features_in_each_station]), columns = station_list)\n\n    station_df_time_stamp['Station list'] = station_df_time_stamp.stack().reset_index(level=1).groupby(level=0, sort=False)['level_1'].apply(list)\n    station_df_time_stamp.insert(0, \"Id\", np.array(df_date[[\"Id\"]]))\n    station_df_time_stamp.insert(1, \"#_of_S\",station_df_time_stamp.count(axis=1)-2)\n    \n    with open(\"./stations_date_test.csv\", 'a') as f:\n        station_df_time_stamp.to_csv(f, mode='a', header=False, index=False)\n    \n    \n    # station one hot\n    station_one_hot = pd.DataFrame (np.array(df_date[first_features_in_each_station]), columns = station_list)\n    station_one_hot = station_one_hot.notnull().astype('int')\n    station_one_hot.insert(0, \"Id\", np.array(df_date[[\"Id\"]]))\n    \n    with open(\"./stations_one_hot_test.csv\", 'a') as f:\n        station_one_hot.to_csv(f, mode='a', header=False, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}