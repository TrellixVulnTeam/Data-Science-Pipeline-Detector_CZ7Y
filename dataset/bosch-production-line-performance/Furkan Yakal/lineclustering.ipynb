{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"L0_station = (1, 25)\nL1_station = (25, 27)\nL2_station = (27, 30)\nL3_station = (30, 53)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\n\nzf = zipfile.ZipFile('../input/bosch-production-line-performance/train_numeric.csv.zip') \ntrain_numeric_chunks = pd.read_csv(zf.open('train_numeric.csv'), iterator=True, chunksize=100000)\n\npath = '../input/bosch-dataset/station_one_hot.csv'\none_hot_stations = pd.read_csv(path)\n\nL0_one_hot = one_hot_stations.iloc[:,L0_station[0]:L0_station[1]]\nL1_one_hot = one_hot_stations.iloc[:,L1_station[0]:L1_station[1]]\nL2_one_hot = one_hot_stations.iloc[:,L2_station[0]:L2_station[1]]\nL3_one_hot = one_hot_stations.iloc[:,L3_station[0]:L3_station[1]]\n\npd.options.display.max_columns = None\npd.options.display.max_rows = None\npd.options.display.max_colwidth = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop rows with all 0 for each station\nL0_one_hot = L0_one_hot.loc[~(L0_one_hot==0).all(axis=1)]\nL1_one_hot = L1_one_hot.loc[~(L1_one_hot==0).all(axis=1)]\nL2_one_hot = L2_one_hot.loc[~(L2_one_hot==0).all(axis=1)]\nL3_one_hot = L3_one_hot.loc[~(L3_one_hot==0).all(axis=1)]\n\nprint(\"Parts in L0:{}\".format(len(L0_one_hot)))\nprint(\"Parts in L1:{}\".format(len(L1_one_hot)))\nprint(\"Parts in L2:{}\".format(len(L2_one_hot)))\nprint(\"Parts in L3:{}\".format(len(L3_one_hot)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L0_one_hot.insert(0, \"Id\",one_hot_stations[\"Id\"])\nL1_one_hot.insert(0, \"Id\",one_hot_stations[\"Id\"])\nL2_one_hot.insert(0, \"Id\",one_hot_stations[\"Id\"])\nL3_one_hot.insert(0, \"Id\",one_hot_stations[\"Id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_numeric_frame():\n    for data_frame in train_numeric_chunks:\n        yield data_frame\n\nget_df_numeric = get_numeric_frame()     \ndf_numeric = next(get_df_numeric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"while True:\n    try:\n        response_column = pd.concat([response_column, df_numeric[['Response']]])\n    except:\n        response_column = df_numeric[['Response']]\n    try:\n        df_numeric = next(get_df_numeric)\n    except:\n        break\n\n        L0_one_hot.insert(0, \"Id\",one_hot_stations[\"Id\"])\nL0_one_hot.insert(1, 'Response', response_column['Response'])\nL1_one_hot.insert(1, 'Response', response_column['Response'])\nL2_one_hot.insert(1, 'Response', response_column['Response'])\nL3_one_hot.insert(1, 'Response', response_column['Response'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L0_one_hot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L2_one_hot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L3_one_hot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KMEANS FOR L1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = L1_one_hot.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inertias = []\n\nfor i in range(2, 4):\n    kmeans = KMeans(n_clusters=i)\n    kmeans.fit(L1_one_hot[column_names])\n    inertias.append(kmeans.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(2, 4), inertias, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('inertia')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_clusters = 3\nkmeans = KMeans(n_clusters=n_clusters)\npred_y = kmeans.fit_predict(L1_one_hot[column_names])\n\nL1_one_hot.insert(2, \"Cluster_Numbers_from_KMeans\", pred_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot.loc[L1_one_hot[\"Cluster_Numbers_from_KMeans\"] == 0].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot.loc[L1_one_hot[\"Cluster_Numbers_from_KMeans\"] == 1].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot.loc[L1_one_hot[\"Cluster_Numbers_from_KMeans\"] == 2].sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KMEANS FOR L2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = L2_one_hot.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inertias = []\n\nfor i in range(4, 7):\n    kmeans = KMeans(n_clusters=i)\n    kmeans.fit(L2_one_hot[column_names])\n    inertias.append(kmeans.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(4, 7), inertias, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('inertia')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_clusters = 6\nkmeans = KMeans(n_clusters=n_clusters)\npred_y = kmeans.fit_predict(L2_one_hot[column_names])\n\nL2_one_hot.insert(2, \"Cluster_Numbers_from_KMeans\", pred_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L2_one_hot.sample(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA FOR L0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pc_list = []\nfor i in range(0, len(L0_one_hot.iloc[:,2:].columns)):\n    pc_list.append('PC'+str(i))\n    \npca = PCA(whiten=True).fit(L0_one_hot.iloc[:,2:])\ndf_pca_summary = pd.DataFrame({'var': pca.explained_variance_ratio_, 'PC':pc_list})\n\ndf_pca_summary.plot.bar(x='PC', y='var', rot=0, figsize=(25,10))\nplt.xlabel(\"Variance explained\")\nplt.ylabel(\"Principle components\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pca_summary.loc[0:8]['var'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_components = 9\npca = PCA(n_components = n_components, whiten=True)\n\nsampled_data = L0_one_hot.sample(len(L0_one_hot))\nsampled_data_pca = pca.fit_transform(sampled_data.iloc[:,2:])\n\nPCA_comps = pd.DataFrame({\"Id\":sampled_data.Id , \"Response\":sampled_data.Response})\nfor i in range(n_components):\n    s = \"pc\"+str(i)\n    PCA_comps[s] = sampled_data_pca[:,i]\n    \n# PCA_comps.sort_values(by=['Id'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DBSCAN L0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = PCA_comps.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nkmeans = KMeans(n_clusters=100)\nkmeans.fit(PCA_comps[column_names])\nprint(kmeans.inertia_)\n\n\nkmeans = KMeans(n_clusters=250)\nkmeans.fit(PCA_comps[column_names])\nprint(kmeans.inertia_)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_split = PCA_comps[0:int(len(PCA_comps)/4)]\nsecond_split = PCA_comps[int(len(PCA_comps)/4):int(2*len(PCA_comps)/4)]\nthird_split = PCA_comps[int(2*len(PCA_comps)/4):int(3*len(PCA_comps)/4)]\nfourth_split = PCA_comps[int(3*len(PCA_comps)/4):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n\ndbscan = DBSCAN()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_first_split = dbscan.fit_predict(first_split[column_names])\npreds_second_split = dbscan.fit_predict(second_split[column_names])\npreds_third_split = dbscan.fit_predict(third_split[column_names])\npreds_fourth_split = dbscan.fit_predict(fourth_split[column_names])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of preds_first_split: {}\".format(preds_first_split.shape))\nprint(\"number of clusters in dbscan: {}\".format(np.max(preds_first_split)))\n\nprint(\"Shape of preds_first_split: {}\".format(preds_second_split.shape))\nprint(\"number of clusters in dbscan: {}\".format(np.max(preds_second_split)))\n\nprint(\"Shape of preds_first_split: {}\".format(preds_third_split.shape))\nprint(\"number of clusters in dbscan: {}\".format(np.max(preds_third_split)))\n\nprint(\"Shape of preds_first_split: {}\".format(preds_third_split.shape))\nprint(\"number of clusters in dbscan: {}\".format(np.max(preds_third_split)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_split.insert(2, \"Clusters\", preds_first_split)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_split.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_label_0 = first_split.loc[first_split['Clusters'] == 0]\npart_station_info_c0 = L0_one_hot.loc[L0_one_hot['Id'].isin(cluster_label_0[\"Id\"])]\npart_station_info_c0.insert(1, \"Cluster\", 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"part_station_info_c0.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_label_68 = first_split.loc[first_split['Clusters'] == 68]\npart_station_info_c68 = L0_one_hot.loc[L0_one_hot['Id'].isin(cluster_label_68[\"Id\"])]\npart_station_info_c68.insert(1, \"Cluster\", 68)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"part_station_info_c68.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_label_43 = first_split.loc[first_split['Clusters'] == 43]\npart_station_info_c43 = L0_one_hot.loc[L0_one_hot['Id'].isin(cluster_label_43[\"Id\"])]\npart_station_info_c43.insert(1, \"Cluster\", 43)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"part_station_info_c43.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.cluster import OPTICS\n\noptics = OPTICS(max_eps=2)\npreds = optics.fit_predict(PCA_comps[column_names].sample(100000))\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA for L3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\npc_list = []\nfor i in range(0, len(L3_one_hot.iloc[:,2:].columns)):\n    pc_list.append('PC'+str(i))\n    \npca = PCA(whiten=True).fit(L3_one_hot.iloc[:,2:])\ndf_pca_summary = pd.DataFrame({'var': pca.explained_variance_ratio_, 'PC':pc_list})\n\ndf_pca_summary.plot.bar(x='PC', y='var', rot=0, figsize=(25,10))\nplt.xlabel(\"Variance explained\")\nplt.ylabel(\"Principle components\")\nplt.show()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndf_pca_summary.loc[0:10]['var'].sum()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nn_components = 11\npca = PCA(n_components = n_components, whiten=True)\n\nsampled_data = L3_one_hot.sample(len(L3_one_hot))\nsampled_data_pca = pca.fit_transform(sampled_data.iloc[:,2:])\n\nPCA_comps = pd.DataFrame({\"Id\":sampled_data.Id , \"Response\":sampled_data.Response})\nfor i in range(n_components):\n    s = \"pc\"+str(i)\n    PCA_comps[s] = sampled_data_pca[:,i]\n    \nPCA_comps.sort_values(by=['Id'], inplace=True)\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}