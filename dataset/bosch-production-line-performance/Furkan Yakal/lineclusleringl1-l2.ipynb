{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"L1_station = (25, 27)\nL2_station = (27, 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\n\nzf = zipfile.ZipFile('../input/bosch-production-line-performance/train_numeric.csv.zip') \ntrain_numeric_chunks = pd.read_csv(zf.open('train_numeric.csv'), iterator=True, chunksize=100000)\n\npath = '../input/bosch-stations-one-hot-enc-train-test/stations_one_hot_train.csv'\none_hot_stations = pd.read_csv(path)\n\nL1_one_hot = one_hot_stations.iloc[:,L1_station[0]:L1_station[1]]\nL2_one_hot = one_hot_stations.iloc[:,L2_station[0]:L2_station[1]]\n\npd.options.display.max_columns = None\npd.options.display.max_rows = None\npd.options.display.max_colwidth = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop rows with all 0 for each station\nL1_one_hot = L1_one_hot.loc[~(L1_one_hot==0).all(axis=1)]\nL2_one_hot = L2_one_hot.loc[~(L2_one_hot==0).all(axis=1)]\n\n\nprint(\"Parts in L1:{}\".format(len(L1_one_hot)))\nprint(\"Parts in L2:{}\".format(len(L2_one_hot)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot.insert(0, \"Id\",one_hot_stations[\"Id\"])\nL2_one_hot.insert(0, \"Id\",one_hot_stations[\"Id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_numeric_frame():\n    for data_frame in train_numeric_chunks:\n        yield data_frame\n\nget_df_numeric = get_numeric_frame()     \ndf_numeric = next(get_df_numeric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"while True:\n    try:\n        response_column = pd.concat([response_column, df_numeric[['Response']]])\n    except:\n        response_column = df_numeric[['Response']]\n    try:\n        df_numeric = next(get_df_numeric)\n    except:\n        break\n\nL1_one_hot.insert(1, 'Response', response_column['Response'])\nL2_one_hot.insert(1, 'Response', response_column['Response'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L2_one_hot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_test = '../input/bosch-stations-one-hot-enc-train-test/stations_one_hot_test.csv'\none_hot_stations_test = pd.read_csv(path_test)\n\nL1_one_hot_test = one_hot_stations_test.iloc[:,L1_station[0]:L1_station[1]]\nL2_one_hot_test = one_hot_stations_test.iloc[:,L2_station[0]:L2_station[1]]\n\n\n# Drop rows with all 0 for each station\nL1_one_hot_test = L1_one_hot_test.loc[~(L1_one_hot_test==0).all(axis=1)]\nL2_one_hot_test = L2_one_hot_test.loc[~(L2_one_hot_test==0).all(axis=1)]\n\n\nprint(\"Parts in L1_test:{}\".format(len(L1_one_hot_test)))\nprint(\"Parts in L2_test:{}\".format(len(L2_one_hot_test)))\n\n\nL1_one_hot_test.insert(0, \"Id\",one_hot_stations_test[\"Id\"])\nL2_one_hot_test.insert(0, \"Id\",one_hot_stations_test[\"Id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L2_one_hot_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KMEANS for L1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = L1_one_hot.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inertias = []\n\nfor i in range(2, 4):\n    kmeans = KMeans(n_clusters=i)\n    kmeans.fit(L1_one_hot[column_names])\n    inertias.append(kmeans.inertia_)\n\nplt.plot(range(2, 4), inertias, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('inertia')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_clusters = 3\nkmeans = KMeans(n_clusters=n_clusters)\npred_y = kmeans.fit_predict(L1_one_hot[column_names])\n\npred_y += 1\n\nL1_one_hot.insert(2, \"ClusterL1\", pred_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids_clusters = pd.DataFrame({\"Id\": one_hot_stations['Id'], \"ClusterL1\": 0})\nids_clusters.loc[L1_one_hot.index, ['ClusterL1']] = L1_one_hot['ClusterL1']\nids_clusters.to_csv(\"Cluster_L1_train.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot.loc[L1_one_hot[\"ClusterL1\"] == 1].head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot.loc[L1_one_hot[\"ClusterL1\"] == 2].head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_one_hot.loc[L1_one_hot[\"ClusterL1\"] == 3].head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = kmeans.predict(L1_one_hot_test[column_names])\npred_test += 1\n\nL1_one_hot_test.insert(1, \"ClusterL1\", pred_test)\n\nids_clusters_test = pd.DataFrame({\"Id\": one_hot_stations_test['Id'], \"ClusterL1\": 0})\nids_clusters_test.loc[L1_one_hot_test.index, ['ClusterL1']] = L1_one_hot_test['ClusterL1']\nids_clusters_test.to_csv(\"Cluster_L1_test.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KMEANS for L2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = L2_one_hot.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inertias = []\n\nfor i in range(4, 7):\n    kmeans = KMeans(n_clusters=i)\n    kmeans.fit(L2_one_hot[column_names])\n    inertias.append(kmeans.inertia_)\n    \nplt.plot(range(4, 7), inertias, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('inertia')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_clusters = 6\nkmeans = KMeans(n_clusters=n_clusters)\npred_y = kmeans.fit_predict(L2_one_hot[column_names])\n\npred_y +=1\n\nL2_one_hot.insert(2, \"ClusterL2\", pred_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids_clusters = pd.DataFrame({\"Id\": one_hot_stations['Id'], \"ClusterL2\": 0})\nids_clusters.loc[L2_one_hot.index, ['ClusterL2']] = L2_one_hot['ClusterL2']\nids_clusters.to_csv(\"Cluster_L2_train.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L2_one_hot.loc[L2_one_hot[\"ClusterL2\"] == 1].head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L2_one_hot.loc[L2_one_hot[\"ClusterL2\"] == 2].head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L2_one_hot.loc[L2_one_hot[\"ClusterL2\"] == 6].head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = kmeans.predict(L2_one_hot_test[column_names])\npred_test += 1\n\nL2_one_hot_test.insert(1, \"ClusterL2\", pred_test)\n\nids_clusters_test = pd.DataFrame({\"Id\": one_hot_stations_test['Id'], \"ClusterL2\": 0})\nids_clusters_test.loc[L2_one_hot_test.index, ['ClusterL2']] = L2_one_hot_test['ClusterL2']\nids_clusters_test.to_csv(\"Cluster_L2_test.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}