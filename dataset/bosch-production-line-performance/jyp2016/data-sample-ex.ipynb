{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"934b828d-9de4-dc5b-5d41-252bc3fc66d0"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50f983e1-db98-9ad5-1b46-4bcf697ce8ac"},"outputs":[],"source":"import pandas"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"855fc5a4-8b58-152d-f562-b2b7eba83184"},"outputs":[],"source":"import pandas\n\n# Creating one chunk of 1000 row from each data set and write it to file to work on\nchunk_size = 10 ** 3\nprint('Starting')\nfor data in pandas.read_csv('../input/train_date.csv', iterator=True, chunksize=chunk_size):\n    data.to_csv('date_sample.csv')\n    break\nfor data in pandas.read_csv('../input/train_categorical.csv', iterator=True, chunksize=chunk_size):\n    data.to_csv('categorical_sample.csv')\n    break\nfor data in pandas.read_csv('../input/train_numeric.csv', iterator=True, chunksize=chunk_size):\n    data.to_csv('numeric_sample.csv')\n    break"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}