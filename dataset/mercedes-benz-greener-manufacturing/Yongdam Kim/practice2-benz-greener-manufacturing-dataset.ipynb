{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. 라이브러리 및 데이터 불러오기","metadata":{}},{"cell_type":"code","source":"# 코드 필사를 하면서 데이터에 대해 친해집니다!\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.ensemble import RandomForestRegressor # Random Forest 회귀모델\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ncolor = sns.color_palette()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:24.322266Z","iopub.execute_input":"2021-12-10T06:48:24.322852Z","iopub.status.idle":"2021-12-10T06:48:24.905422Z","shell.execute_reply.started":"2021-12-10T06:48:24.322778Z","shell.execute_reply":"2021-12-10T06:48:24.904395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/mercedes-benz-greener-manufacturing/train.csv.zip\")\ntest_df = pd.read_csv(\"../input/mercedes-benz-greener-manufacturing/test.csv.zip\")\nprint(train_df.shape, test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:24.910131Z","iopub.execute_input":"2021-12-10T06:48:24.910392Z","iopub.status.idle":"2021-12-10T06:48:25.239184Z","shell.execute_reply.started":"2021-12-10T06:48:24.910347Z","shell.execute_reply":"2021-12-10T06:48:25.238065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.240455Z","iopub.execute_input":"2021-12-10T06:48:25.240693Z","iopub.status.idle":"2021-12-10T06:48:25.277981Z","shell.execute_reply.started":"2021-12-10T06:48:25.240664Z","shell.execute_reply":"2021-12-10T06:48:25.276718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Target feature plot","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.y.values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('y', fontsize=12)\nplt.title(\"Target Variable: 'y'\",fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.28176Z","iopub.execute_input":"2021-12-10T06:48:25.282742Z","iopub.status.idle":"2021-12-10T06:48:25.496087Z","shell.execute_reply.started":"2021-12-10T06:48:25.282678Z","shell.execute_reply":"2021-12-10T06:48:25.495466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ulimit = 180\ntrain_df['y'].loc[train_df['y']>ulimit] = ulimit\n\nplt.figure(figsize=(12,8))\nsns.distplot(train_df.y.values, bins=50, kde=False)\nplt.xlabel('y value', fontsize=12)\nplt.title(\"Histogram of Target Feature\",fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.497376Z","iopub.execute_input":"2021-12-10T06:48:25.497646Z","iopub.status.idle":"2021-12-10T06:48:25.762857Z","shell.execute_reply.started":"2021-12-10T06:48:25.497614Z","shell.execute_reply":"2021-12-10T06:48:25.762025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('최소값: {} 최대값: {} 평균값: {} 표준편차: {}'.format(min(train_df['y'].values), max(train_df['y'].values), train_df['y'].values.mean(), train_df['y'].values.std()))\nprint('180보다 큰 숫자들 개수: {}'.format(np.sum(train_df['y'].values > 180)))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.764278Z","iopub.execute_input":"2021-12-10T06:48:25.764485Z","iopub.status.idle":"2021-12-10T06:48:25.773921Z","shell.execute_reply.started":"2021-12-10T06:48:25.76446Z","shell.execute_reply":"2021-12-10T06:48:25.772704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. EDA\n\n- train 데이터에 대한 EDA를 진행합니다.\n\n- 각 feature들이 어떤 특징을 가지고 있는지 확인하고, 분석합니다.\n\n- 데이터와 친해집니다.","metadata":{}},{"cell_type":"code","source":"dtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()\n\n# object : str ---> categorical feature일 가능성이 높다!","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.775793Z","iopub.execute_input":"2021-12-10T06:48:25.77616Z","iopub.status.idle":"2021-12-10T06:48:25.798779Z","shell.execute_reply.started":"2021-12-10T06:48:25.776113Z","shell.execute_reply":"2021-12-10T06:48:25.798047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtype_df.loc[:10,:]","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.800251Z","iopub.execute_input":"2021-12-10T06:48:25.800498Z","iopub.status.idle":"2021-12-10T06:48:25.818509Z","shell.execute_reply.started":"2021-12-10T06:48:25.800469Z","shell.execute_reply":"2021-12-10T06:48:25.817385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_df = train_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df.loc[missing_df['missing_count']>0]\nmissing_df = missing_df.sort_values(by='missing_count')\nmissing_df # No missing values","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.819582Z","iopub.execute_input":"2021-12-10T06:48:25.819852Z","iopub.status.idle":"2021-12-10T06:48:25.849075Z","shell.execute_reply.started":"2021-12-10T06:48:25.81981Z","shell.execute_reply":"2021-12-10T06:48:25.848274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = [c for c in train_df.columns if 'X' in c]\nprint('Number of features: {}'.format(len(cols)))\nprint('Feature types:')\ntrain_df[cols].dtypes.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.850448Z","iopub.execute_input":"2021-12-10T06:48:25.850706Z","iopub.status.idle":"2021-12-10T06:48:25.868855Z","shell.execute_reply.started":"2021-12-10T06:48:25.850673Z","shell.execute_reply":"2021-12-10T06:48:25.868102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts = [[], [], []]\nfor col in cols:\n    _type = train_df[col].dtype\n    unique = len(np.unique(train_df[col]))\n    if unique == 1:\n        counts[0].append(col)\n    elif unique == 2 and _type == np.int64:\n        counts[1].append(col)\n    else:\n        counts[2].append(col)\n        \nprint('Feature 값이 1개인 경우 : {} Feature 값이 2개인 경우: {} 범주형 Feature 인 경우: {}\\n'.format(*[len(c) for c in counts]))\n\nprint('Feature 값이 1개인 경우: ', counts[0])\nprint('Feature 값이 2개인 경우: ', counts[2])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.870327Z","iopub.execute_input":"2021-12-10T06:48:25.870648Z","iopub.status.idle":"2021-12-10T06:48:25.959608Z","shell.execute_reply.started":"2021-12-10T06:48:25.870608Z","shell.execute_reply":"2021-12-10T06:48:25.958643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_values_dict = {}\nfor col in train_df.columns:\n    if col not in [\"ID\", \"y\", \"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n        unique_value = str(np.sort(train_df[col].unique()).tolist())\n        tlist = unique_values_dict.get(unique_value, [])\n        tlist.append(col)\n        unique_values_dict[unique_value] = tlist\nfor unique_val, columns in unique_values_dict.items():\n    print(\"컬럼에 존재하는 유일한 값들 : \", unique_val)\n    print(columns)\n    print(\"-------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:25.961292Z","iopub.execute_input":"2021-12-10T06:48:25.961556Z","iopub.status.idle":"2021-12-10T06:48:26.002279Z","shell.execute_reply.started":"2021-12-10T06:48:25.961523Z","shell.execute_reply":"2021-12-10T06:48:26.001459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Categorical Features","metadata":{}},{"cell_type":"code","source":"cat_feat = counts[2] # object type으로 된 8개의 columns\ntrain_df[cat_feat].head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:26.00577Z","iopub.execute_input":"2021-12-10T06:48:26.006683Z","iopub.status.idle":"2021-12-10T06:48:26.024661Z","shell.execute_reply.started":"2021-12-10T06:48:26.006634Z","shell.execute_reply":"2021-12-10T06:48:26.023172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 357개의 feature를 평균값을 구해서, 오름차순으로 정렬한뒤에\n# 순서대로 3토막(119개씩)을 내어서 각 subplot에 내림차순으로 plotting.\nbinary_means = [np.mean(train_df[col]) for col in counts[1]]\nbinary_names = np.array(counts[1])[np.argsort(binary_means)]\nbinary_means = np.sort(binary_means)\n\nfig, ax = plt.subplots(1, 3, figsize=(12, 30))\nax[0].set_ylabel(\"Feature Name\")\nax[1].set_title(\"Mean value of 2 unique values\")\nfor i in range(3): # 357 / 3\n    names, means = binary_names[i*119 : (i+1)*119], binary_means[i*119 : (i+1)*119]\n    ax[i].barh(range(len(means)), means, color=color[2])\n    ax[i].set_xlabel(\"Mean value\")\n    ax[i].set_yticks(range(len(means)))\n    ax[i].set_yticklabels(names, rotation='horizontal')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:26.026657Z","iopub.execute_input":"2021-12-10T06:48:26.028117Z","iopub.status.idle":"2021-12-10T06:48:30.190065Z","shell.execute_reply.started":"2021-12-10T06:48:26.028068Z","shell.execute_reply":"2021-12-10T06:48:30.189051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Label Encoding --> Ordinal Encoding","metadata":{}},{"cell_type":"code","source":"for feature in [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n    encoder = LabelEncoder()\n    encoder.fit(list(train_df[feature].values))\n    train_df[feature] = encoder.transform(list(train_df[feature].values))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:30.191926Z","iopub.execute_input":"2021-12-10T06:48:30.192557Z","iopub.status.idle":"2021-12-10T06:48:30.232613Z","shell.execute_reply.started":"2021-12-10T06:48:30.192508Z","shell.execute_reply":"2021-12-10T06:48:30.23152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.iloc[:, :10] # Ordinal Encoding (in alphabetical order)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:30.233779Z","iopub.execute_input":"2021-12-10T06:48:30.234091Z","iopub.status.idle":"2021-12-10T06:48:30.255737Z","shell.execute_reply.started":"2021-12-10T06:48:30.23406Z","shell.execute_reply":"2021-12-10T06:48:30.254693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train_df.drop([\"ID\", \"y\"], axis=1)\ny_train = train_df[\"y\"]","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:30.257457Z","iopub.execute_input":"2021-12-10T06:48:30.257878Z","iopub.status.idle":"2021-12-10T06:48:30.282543Z","shell.execute_reply.started":"2021-12-10T06:48:30.257829Z","shell.execute_reply":"2021-12-10T06:48:30.281507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One-hot Encoding","metadata":{}},{"cell_type":"code","source":"# One-hot Encoding ---> feature수가 많이 늘어날 수 있다!\n# Ordinal Encoding ---> 대신에 의도하지 않은 수치적인 order가 들어갈 수 있다!\n\ntrain_OHE = pd.get_dummies(data=train_df, columns=[\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"])\ntrain_OHE","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:30.283976Z","iopub.execute_input":"2021-12-10T06:48:30.284237Z","iopub.status.idle":"2021-12-10T06:48:30.333805Z","shell.execute_reply.started":"2021-12-10T06:48:30.284206Z","shell.execute_reply":"2021-12-10T06:48:30.333104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train_OHE.drop([\"ID\", \"y\"], axis=1)\ny_train = train_OHE[\"y\"]","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:30.335742Z","iopub.execute_input":"2021-12-10T06:48:30.336433Z","iopub.status.idle":"2021-12-10T06:48:30.356987Z","shell.execute_reply.started":"2021-12-10T06:48:30.33639Z","shell.execute_reply":"2021-12-10T06:48:30.356221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Training with RandomForest\n\n- Feature Importance라는 값을 확인하기 위해서!","metadata":{}},{"cell_type":"code","source":"from sklearn import ensemble\nmodel = ensemble.RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_leaf=4, max_features=0.2, n_jobs=-1, random_state=0)\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:30.358329Z","iopub.execute_input":"2021-12-10T06:48:30.358708Z","iopub.status.idle":"2021-12-10T06:48:32.012611Z","shell.execute_reply.started":"2021-12-10T06:48:30.358676Z","shell.execute_reply":"2021-12-10T06:48:32.011512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Importance\n\n- RandomForest 모델이 실제값(target value)을 예측하는 상황에서, 예측에 크게 영향을 주는 변수들을 찾는 방법.\n\n- 어떤 변수(feature)를 Random Forest 모델에 위-아래로 바꿔보면서 성능 편차가 크게 나는 변수는 값을 크게, 그렇지 않은 변수는 값을 작게 부여받는다.","metadata":{}},{"cell_type":"code","source":"feat_names = X_train.columns.values\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\nindices = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importances[indices], color=\"r\", align=\"center\")\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\nplt.xlim([-1, len(indices)])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:32.014256Z","iopub.execute_input":"2021-12-10T06:48:32.014577Z","iopub.status.idle":"2021-12-10T06:48:32.390191Z","shell.execute_reply.started":"2021-12-10T06:48:32.014543Z","shell.execute_reply":"2021-12-10T06:48:32.389113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Perform dimensionality reduction\n\n1) PCA(Principal Component Analysis)\n\n\n\n2) AutoEncoder(최근에 많이 사용하는 딥러닝 기법)","metadata":{}},{"cell_type":"markdown","source":"### 4-1. Dimensionality Reduction by PCA","metadata":{}},{"cell_type":"code","source":"# sklearn에 있는 PCA를 불러옵니다.\nfrom sklearn.decomposition import PCA\n\nX = train_OHE.drop([\"ID\", \"y\"], axis=1) # feature matrix (고차원 데이터)\ny = train_OHE[\"y\"]\n\npca = PCA(n_components=10) # 10차원으로 줄이겠다 <-----> 10개의 eigenvector를 뽑아서 저차원 공간으로 표현하겠다.\npca_10 = pca.fit_transform(X)\npca_10","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:32.391948Z","iopub.execute_input":"2021-12-10T06:48:32.392345Z","iopub.status.idle":"2021-12-10T06:48:32.576495Z","shell.execute_reply.started":"2021-12-10T06:48:32.392298Z","shell.execute_reply":"2021-12-10T06:48:32.575449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### PCA를 수행할 때 몇 차원으로 감소시켜야 할까요?\n","metadata":{}},{"cell_type":"code","source":"# training data와 test data를 모두 PCA를 이용하여 차원 감소를 수행합니다.\npca = PCA(n_components=0.90) # 원래 데이터의 90%를 보존하는 차원으로 내려주세요.\npca_090 = pca.fit(X) # 학습 및 변환\nX_pca_090 = pca_090.transform(X)\nX_pca_090.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:32.57867Z","iopub.execute_input":"2021-12-10T06:48:32.57948Z","iopub.status.idle":"2021-12-10T06:48:33.109825Z","shell.execute_reply.started":"2021-12-10T06:48:32.579416Z","shell.execute_reply":"2021-12-10T06:48:33.108732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [f\"PC{x}\" for x in range(1, X_pca_090.shape[1]+1)]","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:33.112069Z","iopub.execute_input":"2021-12-10T06:48:33.112686Z","iopub.status.idle":"2021-12-10T06:48:33.119805Z","shell.execute_reply.started":"2021-12-10T06:48:33.112627Z","shell.execute_reply":"2021-12-10T06:48:33.118804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_090_variance = np.round(pca_090.explained_variance_ratio_.cumsum()*100, decimals=1)\npca_090_variance","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:33.122014Z","iopub.execute_input":"2021-12-10T06:48:33.123026Z","iopub.status.idle":"2021-12-10T06:48:33.13971Z","shell.execute_reply.started":"2021-12-10T06:48:33.122931Z","shell.execute_reply":"2021-12-10T06:48:33.138559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scree plot을 그려봅니다.\n\nplt.figure(figsize=(25,5))\nplt.bar(x=range(1, len(pca_090_variance)+1), height=pca_090_variance, tick_label=labels) # 완성해서 공유드리겠습니다!\n\nplt.xticks(rotation=90, color='indigo', size=15)\nplt.yticks(rotation=0, color='indigo', size=15)\nplt.title('Scree Plot',color='tab:orange', fontsize=25)\nplt.xlabel('Principal Components', {'color': 'tab:orange', 'fontsize':15})\nplt.ylabel('Cumulative percentage of explained variance ', {'color': 'tab:orange', 'fontsize':15})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:33.142311Z","iopub.execute_input":"2021-12-10T06:48:33.143261Z","iopub.status.idle":"2021-12-10T06:48:34.518011Z","shell.execute_reply.started":"2021-12-10T06:48:33.143191Z","shell.execute_reply":"2021-12-10T06:48:34.517115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_pca_df = pd.DataFrame(X_pca_090, columns=labels)\nX_train_pca_df","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:34.519421Z","iopub.execute_input":"2021-12-10T06:48:34.519755Z","iopub.status.idle":"2021-12-10T06:48:34.559467Z","shell.execute_reply.started":"2021-12-10T06:48:34.519706Z","shell.execute_reply":"2021-12-10T06:48:34.558533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nplt.title('PCA Plot',color='tab:orange', fontsize=20)\nplt.scatter(X_train_pca_df.PC1, X_train_pca_df.PC2)\nplt.xticks(rotation=90, color='indigo', size=15)\nplt.yticks(rotation=0, color='indigo', size=15)\nplt.xlabel('PC1 - {0}%'.format(pca_090_variance[0]), {'color': 'tab:orange', 'fontsize':15});\nplt.ylabel('PC2 - {0}%'.format(pca_090_variance[1]), {'color': 'tab:orange', 'fontsize':15});\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:34.560662Z","iopub.execute_input":"2021-12-10T06:48:34.560893Z","iopub.status.idle":"2021-12-10T06:48:34.840875Z","shell.execute_reply.started":"2021-12-10T06:48:34.560867Z","shell.execute_reply":"2021-12-10T06:48:34.84016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4-2. Dimensionality Reduction by AutoEncoder\n\n(with keras)","metadata":{}},{"cell_type":"code","source":"from time import time\nimport os\nimport pickle\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Reshape\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.optimizers import SGD\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:34.842049Z","iopub.execute_input":"2021-12-10T06:48:34.842629Z","iopub.status.idle":"2021-12-10T06:48:36.682457Z","shell.execute_reply.started":"2021-12-10T06:48:34.842588Z","shell.execute_reply":"2021-12-10T06:48:36.681549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Autoencoder(Model):\n    def __init__(self, input_dim, latent_dim):\n        super(Autoencoder, self).__init__()\n        self.input_dim = input_dim\n        self.latent_dim = latent_dim\n        self.encoder = tf.keras.Sequential([\n            Input(shape=(input_dim, )),\n            Dense(latent_dim, activation=\"relu\")\n        ])\n        self.decoder = tf.keras.Sequential([\n            Dense(input_dim, activation='relu')\n        ])\n        \n    def call(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:36.683697Z","iopub.execute_input":"2021-12-10T06:48:36.683927Z","iopub.status.idle":"2021-12-10T06:48:36.693244Z","shell.execute_reply.started":"2021-12-10T06:48:36.683899Z","shell.execute_reply":"2021-12-10T06:48:36.691709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:36.69569Z","iopub.execute_input":"2021-12-10T06:48:36.696707Z","iopub.status.idle":"2021-12-10T06:48:36.712651Z","shell.execute_reply.started":"2021-12-10T06:48:36.696648Z","shell.execute_reply":"2021-12-10T06:48:36.71193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder = Autoencoder(input_dim=X.shape[1], latent_dim=50)\noptimizer = SGD(lr=0.01, momentum=0.9)\nautoencoder.compile(optimizer=optimizer, loss='mse')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:48:36.714137Z","iopub.execute_input":"2021-12-10T06:48:36.714589Z","iopub.status.idle":"2021-12-10T06:48:36.774044Z","shell.execute_reply.started":"2021-12-10T06:48:36.714555Z","shell.execute_reply":"2021-12-10T06:48:36.773076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10 # 문제집 x회독 수\nbatch_size = 32 \n\nif os.path.exists(f\"model/benz_AE_model({epochs}epochs).h5\"):\n    autoencoder.fit(X, X,\n                                epochs=1,\n                                shuffle=True,\n                                batch_size=batch_size,\n                                verbose=0,\n                                validation_data=(x_test, x_test))\n    autoencoder.load_weights(f\"model/benz_AE_model({epochs}epochs).h5\")\n    start = 0.0\n    end = 0.0\n\nelse:\n    start = time()\n    fmnist_history = autoencoder.fit(X, X,\n                                epochs=epochs,\n                                shuffle=True,\n                                batch_size=batch_size,\n                                verbose=1)\n                                #validation_data=(x_test, x_test))\n\n    end = time()\n\n    #autoencoder.save_weights(f\"model/benz_AE_model({epochs}epochs).h5\")","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:50:04.283314Z","iopub.execute_input":"2021-12-10T06:50:04.283778Z","iopub.status.idle":"2021-12-10T06:50:10.008347Z","shell.execute_reply.started":"2021-12-10T06:50:04.283737Z","shell.execute_reply":"2021-12-10T06:50:10.007201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Elapsed Time for Training Deep Autoencoder : %.3f sec.\" % (end - start))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T06:50:10.010644Z","iopub.execute_input":"2021-12-10T06:50:10.011348Z","iopub.status.idle":"2021-12-10T06:50:10.016891Z","shell.execute_reply.started":"2021-12-10T06:50:10.011299Z","shell.execute_reply":"2021-12-10T06:50:10.016275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**References:**\n> 1. Dataset and problem statement: https://www.kaggle.com/c/mercedes-benz-greener-manufacturing \n> 2. https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion\n> 3. https://medium.com/swlh/greener-manufacturing-with-machine-learning-6ec77d0e7a91\n> 4. How to Perform One Hot Encoding for Multi Categorical Variables https://www.youtube.com/watch?v=6WDFfaYtN6s","metadata":{}}]}