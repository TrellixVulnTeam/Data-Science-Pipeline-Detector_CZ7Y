{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Mercedes-Benz 데이터셋","metadata":{}},{"cell_type":"markdown","source":"- 많은 공정 변수가 포함되어 있는 데이터셋을 통해서, 차원의 저주 문제를 해결해보고 여러가지 전처리 기법들을 적용해봅니다.","metadata":{}},{"cell_type":"markdown","source":"## 1. 라이브러리, 데이터 불러오기","metadata":{}},{"cell_type":"code","source":"# 데이터분석 4종 세트\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:52:59.101981Z","iopub.execute_input":"2022-05-04T05:52:59.102345Z","iopub.status.idle":"2022-05-04T05:52:59.638055Z","shell.execute_reply.started":"2022-05-04T05:52:59.102287Z","shell.execute_reply":"2022-05-04T05:52:59.637117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터를 불러옵니다.\ntrain = pd.read_csv(\"../input/mercedes-benz-greener-manufacturing/train.csv.zip\")\ntest = pd.read_csv(\"../input/mercedes-benz-greener-manufacturing/test.csv.zip\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:52:59.64304Z","iopub.execute_input":"2022-05-04T05:52:59.643383Z","iopub.status.idle":"2022-05-04T05:52:59.952566Z","shell.execute_reply.started":"2022-05-04T05:52:59.643339Z","shell.execute_reply":"2022-05-04T05:52:59.951631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. EDA\n\nExploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"#### 찾은 특징들\n\n\n1. 결측치 : 없음\n\n\n2. dtype이 object인 column : X0 ~ X8까지 8개. (categorical feature)\n\n> -> 어떻게 처리할지 고민해야함. (Ordinal Encoding VS One-Hot Encoding)\n\n> -> categorical feature들은 종류 정보들이 알파벳으로 되어있으며(anomynized) 이 정보들 대비 target값의 차이가 있는지 확인.\n(특별하게 관련 없음)\n\n> -> binary feature들중에서 0만 가지고 있는 column들이 있음.\n\n> -> 정보가 충분하지 않다고 판단(target value와의 관련성 0) 삭제.\n\n\n3. target distribution\n-> train data에 180을 넘는 데이터가 하나 있음. 이 데이터를 outlier라고 생각하고 제거.","metadata":{}},{"cell_type":"code","source":"### outlier 찾아서 지우기!\n\nplt.figure(figsize=(12, 8))\n#sns.histplot(data=train, x=\"y\")\n#sns.boxplot(data=train, x=\"y\", whis=3)\nsns.boxplot(data=train, x=\"y\")\n## train에 y column이 161을 넘는 데이터를 제거하자\noutliers = train.loc[train.y > 135] ## IQR*1.5\ntrain = train.drop(index=outliers.index)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:52:59.953981Z","iopub.execute_input":"2022-05-04T05:52:59.954204Z","iopub.status.idle":"2022-05-04T05:53:00.188996Z","shell.execute_reply.started":"2022-05-04T05:52:59.954177Z","shell.execute_reply":"2022-05-04T05:53:00.187829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X0 ~ X8 : categorical variables --> 8개\ncat_vars = train.columns[2:10]\ncat_vars\n# X10 ~ : binary variables\nbinary_vars = train.columns[10:]\nbinary_vars","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:53:00.191389Z","iopub.execute_input":"2022-05-04T05:53:00.191665Z","iopub.status.idle":"2022-05-04T05:53:00.200858Z","shell.execute_reply.started":"2022-05-04T05:53:00.191635Z","shell.execute_reply":"2022-05-04T05:53:00.200088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train.X0.value_counts()\n#plt.figure(figsize=(12, 8))\n#sns.countplot(data=train, x=\"X3\")\n\n### Encoding Categorical features\n# 1. Ordinal Encoding\nfor var in cat_vars:\n    train[var] = pd.factorize(train[var])[0]\n\n# 2. One-hot Encoding\n#pd.get_dummies(data=train, columns=cat_vars)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:53:00.202408Z","iopub.execute_input":"2022-05-04T05:53:00.20265Z","iopub.status.idle":"2022-05-04T05:53:00.224069Z","shell.execute_reply.started":"2022-05-04T05:53:00.20262Z","shell.execute_reply":"2022-05-04T05:53:00.223205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# binary variable들의 0과 1의 구성 비율을 확인합니다!\n\n# 1. value_counts 함수를 이용한 방법\n# temp = train.X10.value_counts(normalize=True).values * 100\n# print(f\"0의 비율: {temp[0]:.4f}%, 1의 비율: {temp[1]:.4f}%\")\n\n# 2. 1의 개수를 이용한 방법\nall0_cols = [] # column에 있는 모든 데이터가 다 0인 케이스.\n\nfor col in binary_vars:\n    one_percent = train[col].mean() * 100 # 1의 비율을 퍼센트로 표현\n    if one_percent == 0.0: # 1의 개수가 0인 경우.\n        all0_cols.append(col) ## 모든 값이 0인 column들을 추가합니다.\n        \n    print(f\"[{col}]  0의 비율: {100 - one_percent:.2f}%\\t1의 비율: {one_percent:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:53:00.225314Z","iopub.execute_input":"2022-05-04T05:53:00.225707Z","iopub.status.idle":"2022-05-04T05:53:00.375261Z","shell.execute_reply.started":"2022-05-04T05:53:00.225676Z","shell.execute_reply":"2022-05-04T05:53:00.374316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(columns=all0_cols)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:53:00.376764Z","iopub.execute_input":"2022-05-04T05:53:00.377096Z","iopub.status.idle":"2022-05-04T05:53:00.420584Z","shell.execute_reply.started":"2022-05-04T05:53:00.377052Z","shell.execute_reply":"2022-05-04T05:53:00.419846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. feature engineering\n\n1. Correlation\n\n\n2. VIF\n\n\n3. PCA","metadata":{}},{"cell_type":"code","source":"# 1. Correlation이 높은 변수들 찾기 --> 필요없는 column : ID, y\ntemp = train.drop(columns=[\"ID\", \"y\"])\ncorr = temp.corr() # 363 x 363\nthreshold = 0.7\n\n#display(corr.loc[corr.X1 > threshold])\n\n# e.g. X1 ----> [X3, X6, X10]\n#      X2 ----> [....]       \n#      X3 ----> [X1, X6, X10, ..., ...] (skip)\n#      X4 ----> [....]\nhigh_correlated_cols = []\n\nfor col in temp.columns:\n    if col in high_correlated_cols:\n        continue\n    temp_cols = list(corr.loc[(corr[col] > threshold) | (corr[col] < -threshold)].index[1:]) # 보고 있는 column을 제외하고 threshold보다 상관계수가 높은 column들을 리스트로 변환.\n    high_correlated_cols = high_correlated_cols + temp_cols # 리스트 누적\n    \nhigh_correlated_cols = set(high_correlated_cols) # 중복 column들 제거\nhigh_correlated_cols","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:53:00.421578Z","iopub.execute_input":"2022-05-04T05:53:00.421862Z","iopub.status.idle":"2022-05-04T05:53:02.040334Z","shell.execute_reply.started":"2022-05-04T05:53:00.421821Z","shell.execute_reply":"2022-05-04T05:53:02.039739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. VIF가 10이 넘는 변수들 찾기\n## VIF_i = 1 / 1 - R2_i\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif_list = [variance_inflation_factor(temp, idx) for idx in range(len(temp.columns))]\n\nvif_df = pd.DataFrame(index=temp.columns, data=vif_list, columns=[\"VIF\"])\nvif_df.sort_values(by=\"VIF\", ascending=False) # VIF가 큰 순서대로 정렬해서 만든 DataFrame\n\n## VIF가 가장 큰 (또는 10보다 큰 column중에 하나)를 골라서 제거 한 뒤에 다시 VIF 계산. (loop)\n## Continue..","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:53:02.041282Z","iopub.execute_input":"2022-05-04T05:53:02.041986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. PCA(Principal Component Analysis)를 이용하여 변수 크기 줄이기\nfrom sklearn.decomposition import PCA\n\n## PCA의 n_components -----> hyper-parameter!\n# 1. n_components = 6 : 6차원으로 내려주세요.\n# 2. n_components = 0.90 : 원본 데이터의 분포를 90% 보존하는 차원으로 내려주세요.\n\n#pca = PCA(n_components=15)\npca = PCA(n_components=0.95)\nX = pca.fit_transform(temp) # 주성분을 기준으로 데이터를 \"저차원\"으로 변환\npca_columns = [f\"PC{i}\" for i in range(X.shape[1])]\npca_df = pd.DataFrame(columns=pca_columns, data=X)\npca_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}