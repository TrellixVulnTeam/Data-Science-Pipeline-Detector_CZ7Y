{"cells":[{"metadata":{},"cell_type":"markdown","source":"Some data happens to be missing from its required field\nEither from human errors, loss from data entry, or any other forms which led to the data either not being there to begin with or have gotten unstandardised in the proces. \n\nEg: surveys\n\nIndividuals tend to not provide certain data such as their personal information (Contacts, Age, Salary, etc) if not mandated.\n\n---\n\nSome of these missing data can be:\n1. Continuous or\n\n2. Categorical\n\n---\n\nGenerally, there are a few types of missing data:\n\n1. MCAR - missing completely at random. There is no relationship between the data being missing and the existing observations\n\n2. MNAR - missing data not at random/systematic missing values. There is a relationship between the records being missing and the rest of the dataset\n\n3. MAR - missing data at random. Missing from neglegance or preference to not share."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/titanicdataset-traincsv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/titanicdataset-traincsv/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since these data were collected after the incident, there are some missing values in the respective fields. From the output above, we can see the the Age and the Cabin columns have missing values from which it is safe to hypothize that the fields have some form of relationship between them.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Embarked'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Age'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin_Null'] = np.where(df['Cabin'].isnull(),1,0)\ndf['Cabin_Null'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin_Null'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['Survived'])['Cabin_Null'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.876138 of the passengers not survived having missing values\n\n0.602339 of the survived passengers having missing values\nProving the aforementioned hypothesis"},{"metadata":{},"cell_type":"markdown","source":"## Techniques to handle missing data\nThe are various techniques to handle them some of which includes:\n1. Using central tendencies (Mean,media,mode) replacement\n2. Random sample imputation\n3. Capturing null values with a new feature\n4. End of distribution imputation\n5. Arbitrary imputation\n6. Frequent categories imputation"},{"metadata":{},"cell_type":"markdown","source":"### 1. Mean/median/mode imputation \nWhen to apply?\n\nAssumptions made in mean/median/mode imputation are that the missing values are completely at random (MCAR).\n\n|#  |Pros             |Cons                                    |\n|---|----             |----                                    |\n|1. |Easy to implement|Change/distortion in the orginal dataset|\n|2. |Fast             |                                        |\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking certain columns from the dataset\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['PassengerId','Pclass','Name','Sex','SibSp','Parch','Ticket','Cabin','Embarked','Cabin_Null'], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the percentage of missing values\ndf.isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median = df['Age'].median()\ndef impute(dataset, variable, median):\n    df[variable+'_median'] = df[variable].fillna(median)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"impute(df,'Age',median)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.Age.std())-(df.Age_median.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_subplot(111)\ndf['Age'].plot(kind='kde',ax=ax)\ndf['Age_median'].plot(kind='kde',ax=ax,color='red')\nlines,labels = ax.get_legend_handles_labels()\nax.legend(lines,labels, loc='best')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Random sample imputation\nRandom observations are taken from the dataset in order to replace the missing values (MCAR).\n\n|#  |Pros                         |Cons                                       |\n|---|----                         |----                                       |\n|1. |Easy to implement            |Randomness will not work in every situation|\n|2. |Lesser distortion in variance|                                           |\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/titanicdataset-traincsv/train.csv', usecols=['Age', 'Fare', 'Survived'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age'].dropna().sample(df['Age'].isnull().sum(),random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median = df['Age'].median()\ndef impute(dataset, variable, median):\n    df[variable+'_median'] = df[variable].fillna(median)\n    df[variable+'_random'] = df[variable]\n    random_sample = df[variable].dropna().sample(df[variable].isnull().sum(),random_state=0)\n    random_sample.index = df[df[variable].isnull()].index\n    df.loc[df[variable].isnull(),variable+'_random']=random_sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"impute(df,'Age',median)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.Age.std())-(df.Age_random.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_subplot(111)\ndf['Age'].plot(kind='kde',ax=ax)\ndf['Age_median'].plot(kind='kde',ax=ax,color='red')\ndf['Age_random'].plot(kind='kde',ax=ax,color='yellow', alpha=0.3, linewidth=5)\nlines,labels = ax.get_legend_handles_labels()\nax.legend(lines,labels, loc='best')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distortion is much more minimized as compared to the previous imputation"},{"metadata":{},"cell_type":"markdown","source":"### 3. Capturing Null values with new features/variables\nIf the missing data are not MNAR-type, then only it will perform well.\nIt provides the model with atleast some information regarding the missing values.\nAlthough, it will create additional features for each an every missing values which will ultimately increase the number of fields.\n\n|#  |Pros                                 |Cons|\n|---|----                                 |----|\n|1. |Easy to implement                    |Curse of dimensionality|\n|2. |Captures importance of missing values||"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/titanicdataset-traincsv/train.csv', usecols=['Age', 'Fare', 'Survived'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age_Null'] = np.where(df[\"Age\"].isnull(),1,0)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Age.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Age.median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age'].fillna(df.Age.median(),inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. End of distribution imputation\nTaking data from the end of the distribution to impute\n\n\n\n|#  |Pros                                 |Cons                   |\n|---|----                                 |----                   |\n|1. |Easy to implement|Distorts original distribution|\n|2. |Captures the importance of missingness if there is one|If the missingness is not important, it may mask the predictive power of the original variable|\n|3. ||If the number of NAN is large, it will mask true outliers in the distribution|\n|4. ||If the number of NAN is small, the replaced null values may be considered an outlier and the pre-processed in a subsequent step of feature engineering|"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/titanicdataset-traincsv/train.csv', usecols=['Age', 'Fare', 'Survived'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Age.hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Age.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Age.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Age.mean()+3*df.Age.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.boxplot('Age',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median = df.Age.median()\nextreme_value = df.Age.mean()+3*df.Age.std()\n\ndef impute(df, variable, median, extreme_value):\n    df[variable+'_end_of_distribution'] = df[variable].fillna(extreme_value)\n    df[variable].fillna(median,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"impute(df, 'Age', median, extreme_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" df['Age'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" df['Age_end_of_distribution'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot('Age_end_of_distribution',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Arbitrary imputation\n\nDef: Arbitrary value imputation consists of replacing all occurrences of missing values within a variable by an arbitrary value. Ideally arbitrary value should be different from the median/mean/mode, and not within the normal values of the variable.\n\nInvolves replacing NULL values with another arbitrary value besides central tendecies.\nAn unlikely method to be applied. Not suitable for every use case.\n\nProperties:\n* It should not be present frequently i.e. rare values"},{"metadata":{},"cell_type":"markdown","source":"# Handling Categorical Features"},{"metadata":{},"cell_type":"markdown","source":"### 6. Frequent Category Imputation\n\n|#  |Pros                                 |Cons                   |\n|---|----                                 |----                   |\n|1. |Easy and fast to implement|Using the most frequent labels, they may be used in an over represented way given that if there are a higher number of NULL values|\n|2. |Captures missingness of values|Distorts the relationship of the most frequent labels|\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input/house-prices-advanced-regression-techniques'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This dataset was chosen due to it having lots of categorical values  \ndf = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking 3 features for simplicity\ndf = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv', usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().mean().sort_values(ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing the frequency of every feature\n#df['BsmtQual'].value_counts().plot.bar()\ndf.groupby(['BsmtQual'])['BsmtQual'].count().sort_values(ascending=False).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['GarageType'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['FireplaceQu'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['GarageType'].value_counts().index[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imputation function\ndef impute(df, variable):\n    #most_frequent = df[variable].mode()[0]\n    most_frequent = df[variable].value_counts().index[0]\n    df[variable].fillna(most_frequent,inplace=True)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for features in ['BsmtQual','FireplaceQu','GarageType']:\n    impute(df,features)\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Adding a Variable to Capture NULL\n\n|#  |Pros                                 |Cons                   |\n|---|----                                 |----                   |\n|1. |||\n|2. |||\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv', usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['BsmtQual_Nulls'] = np.where(df['BsmtQual'].isnull(),1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frequent = df['BsmtQual'].mode()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['BsmtQual'].fillna(frequent,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['FireplaceQu_Nulls'] = np.where(df['FireplaceQu'].isnull(),1,0)\nfrequent = df['FireplaceQu'].mode()[0]\ndf['FireplaceQu'].fillna(frequent,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# This will distort the distribution of the data\nTherefore, we replace the NULLs with a new category"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv', usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def impute(df,variable):\n    df[variable+'_new_feature'] = np.where(df[variable].isnull(),'Missing',df[variable])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for features in ['BsmtQual','FireplaceQu','GarageType']:\n    impute(df,features)\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['BsmtQual','FireplaceQu','GarageType'],axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/titanicdataset-traincsv/train.csv', usecols=['Sex'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#But instead we can do\npd.get_dummies(df,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/titanicdataset-traincsv/train.csv', usecols=['Embarked'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Embarked.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Embarked.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Dropping the first column because \"C\" \ncould be determined based on the absence \nor presence in the \"Q\" and \"S\" columns''' \n\npd.get_dummies(df,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using a different dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/mercedes-benz-greener-manufacturing/train.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One Hot Encoding with Many Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking only the categorical features\ndf = pd.read_csv('../input/mercedes-benz-greener-manufacturing/train.csv.zip', usecols=['X0','X1','X2','X3','X4','X5','X6','X8'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.X0.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.X1.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.columns:\n    print(len(df[i].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using One Hot Encoding would not be efficient as there already are quite a huge number of columns\n\nTherefore, a slightly different technique should be used\n\nHence, taking the top 10 most frequent features then One Hot Encoding them"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.X0.value_counts().sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_top_10 = list(df.X0.value_counts().sort_values(ascending=False).head(10).index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for categories in list_top_10:\n    df[categories] = np.where(df['X0']==categories,1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_top_10.append('X0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[list_top_10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Showing the presence of the top 10 categories with the highest frequency only"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ordinal Data Encoding\n\nEg: Years of Experience\n\n* 20 years - 1\n* 10 years - 2\n* 5 years - 3\n\nEg: Grades: A,B,C,D,F\n\n* A - 1\n* B - 2\n* C - 3\n* D - 4\n* F - 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"todays_date = datetime.datetime.today()\ntodays_date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dataset\n# List comprehension\ndays = [todays_date - datetime.timedelta(x) for x in range(0,15)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.DataFrame(days)\ndata.columns = [\"Day\"]\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Weekday'] = data['Day'].dt.day_name()\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding the categorical feature, Weekday\n\ndict = {\n    'Monday':1,\n    'Tuesday':2,\n    'Wednesday':3,\n    'Thursday':4,\n    'Friday':5,\n    'Saturday':6,\n    'Sunday':7\n}\ndict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Weekday_Ordinal'] = data['Weekday'].map(dict)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Frequency Encoding / Count Encoding\n\n|#  |Pros             |Cons                   |\n|---|----             |----                   |\n|1. |Easy to implement|If features share the same number of frequency, they will provide the same weight|\n|2. |Not increasing feature space||"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/adult-dataset/adult.csv',header=None)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[1].unique(),len(df[1].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feature_columns = [1,3,5,6,7,8,9,13]\ncat_feature_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[cat_feature_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['Employment', 'Education', 'Status', 'Position', 'Family', 'Race', 'Sex', 'Country']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in df.columns[:]:\n    print(feature, ': ', len(df[feature].unique()), ' labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting to dictionary\ncountry_map = df['Country'].value_counts().to_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Country'] = df['Country'].map(country_map)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Guided Ordinal Encoding\nLabels are ordered according to the target\n\nOr, labels are replaced by the joint probability or being 0 or 1 in classification problems \n\n\n|#  |Pros             |Cons                   |\n|---|----             |----                   |\n|1. |||\n|2. |||"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/titanicdataset-traincsv/train.csv', usecols=['Cabin','Survived'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin'].fillna('Missing',inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Cabin.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first letter represents the block a cabin belongs to"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin'] = df['Cabin'].astype(str).str[0]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Cabin.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['Cabin'])['Survived'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['Cabin'])['Survived'].mean().sort_values().index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_labels = df.groupby(['Cabin'])['Survived'].mean().sort_values().index\nordinal_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enumerate(ordinal_labels,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mapping the labels to a number\nk, key = labels\ni, value = rank\nordinal_labels_2 = {k:i for i,k in enumerate(ordinal_labels,0)}\nordinal_labels_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin_Ordinal_Labels'] = df['Cabin'].map(ordinal_labels_2)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mean Encoding\n\n|#  |Pros             |Cons                   |\n|---|----             |----                   |\n|1. |Captures information within label|Leads to overfitting|\n|2. |Creates monotonic relationship with feature and target||"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['Cabin'])['Survived'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_ordinal = df.groupby(['Cabin'])['Survived'].mean().to_dict()\nmean_ordinal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Mean_Ordinal_Encode'] = df['Cabin'].map(mean_ordinal)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Probability Ratio Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/titanicdataset-traincsv/train.csv', usecols = ['Cabin','Survived'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin'].fillna('Missing',inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin']=df['Cabin'].astype(str).str[0]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Cabin.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_df=df.groupby(['Cabin'])['Survived'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_df=pd.DataFrame(prob_df)\nprob_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_df['Died']=1-prob_df['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_df['Probability_ratio']=prob_df['Survived']/prob_df['Died']\nprob_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probability_encoded=prob_df['Probability_ratio'].to_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin_encoded']=df['Cabin'].map(probability_encoded)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}