{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### A comprehensive and detailed explanation of an award winning strategy to limit feature explosion during encoding categorical variables. \n\n### Do drop a like üëç to support my efforts.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-19T05:31:47.612808Z","iopub.execute_input":"2022-03-19T05:31:47.613354Z","iopub.status.idle":"2022-03-19T05:31:47.647368Z","shell.execute_reply.started":"2022-03-19T05:31:47.613232Z","shell.execute_reply":"2022-03-19T05:31:47.645283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The dataset here is in zip format so we need to first unzip it and extract the csv file.\n# The unzip method extracts the csv file from the zip file and stores in the kaggle working directory.\n\n!unzip ../input/mercedes-benz-greener-manufacturing/train.csv.zip","metadata":{"execution":{"iopub.status.busy":"2022-03-19T06:49:31.729963Z","iopub.execute_input":"2022-03-19T06:49:31.7304Z","iopub.status.idle":"2022-03-19T06:50:27.095919Z","shell.execute_reply.started":"2022-03-19T06:49:31.730366Z","shell.execute_reply":"2022-03-19T06:50:27.094956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading data\ndata = pd.read_csv('./train.csv',usecols=['X1','X2','X3','X4','X5','X6'])","metadata":{"execution":{"iopub.status.busy":"2022-03-19T05:38:56.188643Z","iopub.execute_input":"2022-03-19T05:38:56.188938Z","iopub.status.idle":"2022-03-19T05:38:56.262838Z","shell.execute_reply.started":"2022-03-19T05:38:56.188906Z","shell.execute_reply":"2022-03-19T05:38:56.262126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T05:39:03.827659Z","iopub.execute_input":"2022-03-19T05:39:03.828767Z","iopub.status.idle":"2022-03-19T05:39:03.85338Z","shell.execute_reply.started":"2022-03-19T05:39:03.828712Z","shell.execute_reply":"2022-03-19T05:39:03.852634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the unique labels in each categorical variables.\nfor col in data.columns:\n    print(col,':', len(data[col].unique()),'labels')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T05:40:35.635208Z","iopub.execute_input":"2022-03-19T05:40:35.635911Z","iopub.status.idle":"2022-03-19T05:40:35.653742Z","shell.execute_reply.started":"2022-03-19T05:40:35.635872Z","shell.execute_reply":"2022-03-19T05:40:35.652959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Simple one hot encoding using get_dummies method. It creates separate columns for each label in a categorical variable \n# and drops one of them to solve the problem of multicollinear data\npd.get_dummies(data, drop_first=True).shape","metadata":{"execution":{"iopub.status.busy":"2022-03-19T05:41:04.955978Z","iopub.execute_input":"2022-03-19T05:41:04.956345Z","iopub.status.idle":"2022-03-19T05:41:04.984142Z","shell.execute_reply.started":"2022-03-19T05:41:04.956307Z","shell.execute_reply":"2022-03-19T05:41:04.983408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we had 6 categorical variables. Encoding that with one hot encoding ended up creating 177 new columns for various values of categorical variables. This can be computationally expensive to train our model on this data and cause performance issues.\n\n### What can we do instead?\n\nA very efficient approach was put forward by the Winning solution of the KDD 2009 cup: \" Winning the Cup Orange Challenge with Ensemble Selection\". The authors presented an idea of limiting the one hot encoding to the 10 most frequent labels only. this is equivalent to grouping all the other labels under a new category, that will be dropped in our case for this dataset.\n\nLink to Paper: http://proceedings.mlr.press/v7/niculescu09/niculescu09.pdf\n\nSo in this case the dummy variables will indicate that whether for a particular data all those 10 most frequent labels are present(1) or not (0) for a particular observation.\n\n","metadata":{}},{"cell_type":"code","source":"# Finding the top 10 most frequent categories for the variable X2\n\ndata.X2.value_counts().sort_values(ascending=False).head(20)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T06:06:33.239101Z","iopub.execute_input":"2022-03-19T06:06:33.239719Z","iopub.status.idle":"2022-03-19T06:06:33.250444Z","shell.execute_reply.started":"2022-03-19T06:06:33.239667Z","shell.execute_reply":"2022-03-19T06:06:33.249563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making a list of all the top values in the categorical variable X2\n\ntop_10 = [x for x in data.X2.value_counts().sort_values(ascending=False).head(10).index]\ntop_10","metadata":{"execution":{"iopub.status.busy":"2022-03-19T06:08:39.626219Z","iopub.execute_input":"2022-03-19T06:08:39.626487Z","iopub.status.idle":"2022-03-19T06:08:39.635764Z","shell.execute_reply.started":"2022-03-19T06:08:39.626459Z","shell.execute_reply":"2022-03-19T06:08:39.63489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We now make the binary variables for thr top 10 categories\n\nfor label in top_10:\n    data[label] = np.where(data[\"X2\"]==label,1,0)\n    \ndata[['X2']+top_10].head(40)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T06:13:25.730295Z","iopub.execute_input":"2022-03-19T06:13:25.730597Z","iopub.status.idle":"2022-03-19T06:13:25.772717Z","shell.execute_reply.started":"2022-03-19T06:13:25.730564Z","shell.execute_reply":"2022-03-19T06:13:25.772093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets understand how it happened. \nWe iterate over each of the top 10 labels in the X2 categories that we have stored in the list.\n\nNow for each of the top_10 label we check where in the X2 column that same label occurs. If the label and the X2 categorical value matches then we fix it as 1. Else it is 0 which indicates this value is not among the top 10 labels.","metadata":{}},{"cell_type":"code","source":"# Now we will apply this to all the catgeorical columns to attain the final set of dummy variables\n\ndef one_hot_top_x(df, variable, top_x_labels):\n    # this is the function to create the dummy variables for the most frequent labels\n    # we can also vary the number of most frquent labels to encode. We can make it top 10 or 20.\n    \n    for label in top_x_labels:\n        df[variable+'_'+label] = np.where(data[variable]==label, 1,0)\n\n# reading the data again\n\ndata = pd.read_csv('./train.csv',usecols=['X1','X2','X3','X4','X5','X6'])\n\n#encoding X2 into the top 10 most frequent categories\n\none_hot_top_x(data,'X2',top_10)\ndata.head()\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T06:35:14.665752Z","iopub.execute_input":"2022-03-19T06:35:14.666071Z","iopub.status.idle":"2022-03-19T06:35:14.773035Z","shell.execute_reply.started":"2022-03-19T06:35:14.666026Z","shell.execute_reply":"2022-03-19T06:35:14.771851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding the top 10 most frequent categories in column X1\ntop_10 = [x for x in data.X1.value_counts().sort_values(ascending=False).head(10).index]\ntop_10\n\n# now creating the 10 most frequent dummy variables for X1\none_hot_top_x(data,'X1',top_10)\ndata.head()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T06:36:41.564954Z","iopub.execute_input":"2022-03-19T06:36:41.565283Z","iopub.status.idle":"2022-03-19T06:36:41.604285Z","shell.execute_reply.started":"2022-03-19T06:36:41.56525Z","shell.execute_reply":"2022-03-19T06:36:41.603481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can continue and one hot encode all the the 6 columns to limit the encoding to the top_10 frequent labels of the column. ","metadata":{}},{"cell_type":"markdown","source":"# One hot encoding the Top Variables\n\n## Advantages\n- Very straightforward and easy to implement\n- Saves time and effort in hours of data and variable exploration\n- Limits expansion of feature space(number of columns in the dataset). Initially encoding resulted in 117 columns for 6 categories. Taking top 10 features reduces it to only 60( top 10 * 6 columns =60 ).\n\n## Disadvantages\n- Does not add any information that makes the variable more predictive.\n- Loses informaton of the ignored labels or less frequent labels.\n\n\nIt is not quite unusual that categorical variables have few of the dominating categories and the remaining less frequent labels are mostly noise and distorts the predicitve abilities of the variable. This approach is quite simple and straightforward that can be useful in many occasions.\n\nAlso it is worth noting that taking the top 10 labels is completely arbitrary. It can be top 5 or 20 depending on the distribution of labels in a particular variables.\n","metadata":{}}]}