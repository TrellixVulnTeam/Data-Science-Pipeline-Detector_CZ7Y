{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cdf5a25d-6577-5620-50f3-05b741d42cd5"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import model_selection, preprocessing, ensemble\nfrom sklearn.metrics import r2_score\nimport xgboost as xgb\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0ec5aff3-62f4-eb28-ead3-6ca9c3f6a58a"},"outputs":[],"source":"# read datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# process columns, apply LabelEncoder to categorical features\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"a70def89-8b85-cf40-6e1b-e1d37e421a1e"},"source":"### Add decomposed components: PCA / ICA"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06dcd94c-a5f1-e206-f71a-73fcac6265ed"},"outputs":[],"source":"from sklearn.decomposition import PCA, FastICA\nn_comp = 10\n\n# PCA\npca = PCA(n_components=n_comp, random_state=42)\npca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\npca2_results_test = pca.transform(test)\n\n# ICA\nica = FastICA(n_components=n_comp, random_state=42)\nica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\nica2_results_test = ica.transform(test)\n\n# Append decomposition components to datasets\nfor i in range(1, n_comp+1):\n    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n    \n    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n    \ny_train = train[\"y\"]\ny_mean = np.mean(y_train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"356c4400-526b-7b27-b65e-f7c44af48be0"},"source":"### Preparing xgb model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7584c644-dbee-eaaf-0b7d-6c5b6f7f081a"},"outputs":[],"source":"def runXGB(train_X, train_y, test_X, test_y=None, seed_val=157, num_rounds=1000):\n    param = {}\n    param['objective'] = 'reg:linear'\n    param['eta'] = 0.03\n    param['max_depth'] = 4\n    param['silent'] = 1\n    param['eval_metric'] = 'rmse'\n    param['min_child_weight'] = 1\n    param['subsample'] = 0.7\n    param['colsample_bytree'] = 0.7\n    param['base_score'] = y_mean\n    param['seed'] = seed_val\n    num_rounds = num_rounds\n\n    plst = list(param.items())\n    xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n    if test_y is not None:\n        xgtest = xgb.DMatrix(test_X, label=test_y)\n        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50)\n    else:\n        xgtest = xgb.DMatrix(test_X)\n        model = xgb.train(plst, xgtrain, num_rounds)\n\n    pred_test_y = model.predict(xgtest)\n    return pred_test_y, model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5ccf60b5-3940-f86f-f2d4-5364e1f049a8"},"outputs":[],"source":"X_train = train.drop('y', axis=1).values\nx_test = test.values\n\ncv_scores = []\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\nfor dev_index, val_index in kf.split(range(X_train.shape[0])):\n        dev_X, val_X = X_train[dev_index,:], X_train[val_index,:]\n        dev_y, val_y = y_train[dev_index], y_train[val_index]\n        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n        cv_scores.append(r2_score(val_y, preds))\n        print(cv_scores)\n        break"},{"cell_type":"markdown","metadata":{"_cell_guid":"464c9ef5-bc1e-8298-d3a6-d386092e5ed3"},"source":"## Prepare submission"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"148d3109-ae26-8f63-529f-a9827df19e1a"},"outputs":[],"source":"n_rounds = model.best_ntree_limit\ny_pred, model = runXGB(X_train, y_train, x_test, num_rounds=n_rounds)\n\noutput = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\noutput.to_csv('xgboost-seed157-n{}-pca-ica_v3.csv'.format(model.best_ntree_limit), index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"5ec3dd9c-6669-c91a-6146-0a30a21298da"},"source":"This kernel is based on this https://www.kaggle.com/frednavruzov/baselines-to-start-with-lb-0-56"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}