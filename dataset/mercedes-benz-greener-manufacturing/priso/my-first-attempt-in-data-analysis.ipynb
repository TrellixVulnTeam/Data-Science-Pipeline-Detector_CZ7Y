{"nbformat_minor":1,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","version":"3.6.4","mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","name":"python"}},"cells":[{"metadata":{},"cell_type":"markdown","source":"This is my  first attemp in data analysis. I have just started a week back and have gone through the basic tutorials in python for data analysis and visualization. Any suggestions on improvement are welcome :)  \nLet me first load the train and test files  and understand the data. "},{"execution_count":null,"metadata":{},"cell_type":"code","outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\ntrain_data = pd.read_csv(\"../input/train.csv\")\ntest_data = pd.read_csv(\"../input/test.csv\")\nprint(train_data.shape)\nprint(test_data.shape)\nprint(train_data.columns)\nob_col= (train_data.select_dtypes(include=['object'])).columns\nprint(ob_col)\nprint(train_data.describe())"},{"metadata":{},"cell_type":"markdown","source":"So there are  4209 rows od data with 378 columns in the train data and 377 columns in the test data. The extra column in the train data being the prediction variable 'y'.\nThere are 8 columns which are of type object. All the remaining columns are float type.\n\nWhen we do .describe() we can get the fair view of the data - How the column values are spread.  Wait! The column X11 is all 0s. This will not help much in prediction. Lets remove the columns which have just 1 value for every row."},{"execution_count":null,"metadata":{},"cell_type":"code","outputs":[],"source":"for col in train_data.columns:\n    if len(train_data[col].unique()) == 1:\n        del train_data[col]\nprint(train_data.columns)"},{"metadata":{},"cell_type":"markdown","source":"Now we are down to 366 columns in train_data. Make sure these columns are removed in the test_data as well. or else it might cause some errors when we run the prediction algorithms."},{"execution_count":null,"metadata":{},"cell_type":"code","outputs":[],"source":"y = train_data['y']\nX = train_data.drop(['y'], axis=1)\n\ntest_data_refined = test_data[X.columns]\nprint(X.columns)\nprint(test_data_refined.columns)"},{"metadata":{},"cell_type":"markdown","source":"Now lets understand the other 8 columns with dtype object. And lets see how they are spread. "},{"execution_count":null,"metadata":{},"cell_type":"code","outputs":[],"source":"import matplotlib.pyplot as plt\nfig, axarr = plt.subplots(8, 1, figsize=(10, 30))\ni=0\nfor c in ob_col:\n    X[c].value_counts().sort_index().plot.bar(\n    ax=axarr[i], fontsize=12, color='mediumvioletred')\n    axarr[i].set_title(c, fontsize=12)\n    i=i+1"},{"metadata":{},"cell_type":"markdown","source":"With the above graphs we can see how the predictor variables are spread. For example X4 has many d's.  Now lets convert these columns with dtypes objects to integres which can be inserted to the Randomforest algorithm.  "},{"execution_count":null,"metadata":{},"cell_type":"code","outputs":[],"source":"train_data_onehot = pd.get_dummies(X)\ntest_data_onehot = pd.get_dummies(test_data_refined)\ntrain_predictors,test_predictors = train_data_onehot.align(test_data_onehot,join='inner',axis=1)\n\nprint(train_predictors.shape)\nprint(test_predictors.shape)"},{"metadata":{},"cell_type":"markdown","source":"Let us use the RandomForest to predict"},{"execution_count":null,"metadata":{},"cell_type":"code","outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor()\nmodel.fit(train_predictors,y)\npredictions = model.predict(test_predictors)"},{"metadata":{},"cell_type":"markdown","source":"Let us write the predictions in outputfile before submitting"},{"execution_count":null,"metadata":{},"cell_type":"code","outputs":[],"source":"ans_df = pd.DataFrame({'ID': test_data.ID, 'y': predictions})\nprint(ans_df.describe())\nans_df.to_csv('answer.csv', index=False)"},{"metadata":{},"cell_type":"markdown","source":"Next we will see how can we fine tune the algorithm for better accuracy"}],"nbformat":4}