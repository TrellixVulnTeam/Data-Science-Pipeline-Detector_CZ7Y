{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"6f21b51e-7ef5-4f9e-1e1f-e377739b3efa"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4db9fd72-fbff-b8fc-2250-5240285ca634"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets, linear_model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import BayesianRidge\n# supportive models\nimport xgboost as xgb\n# feature selection (from supportive model)\nfrom sklearn.feature_selection import SelectFromModel\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n\ndef get_models():\n        return {\n            'LinearRegression': linear_model.LinearRegression(),\n            'RandomForestRegressor': RandomForestRegressor(n_estimators = 30, random_state = 0),\n            # 'MLPRegressor': MLPRegressor(),\n            'BayesianRidge': BayesianRidge(),\n        }\n\n\ndef train_models(models, x, y):\n    for name, i_model in models.items():\n        i_model.fit(x, y)\n    return models    \n\ndef competite_model(models, x, y):\n    best_score = -1\n    winner = next(iter(models)) # first key\n    for name, i_model in models.items():\n        if i_model.score(x, y) > best_score:\n            winner = name\n    return winner       \n\ndef create_model():\n    # LinearRegression\n    # regr = linear_model.LinearRegression()\n\n    # random forest\n    # regr = RandomForestRegressor(n_estimators = 30, random_state = 0)\n\n    # neural network\n    # regr = MLPRegressor()\n\n    # BayesianRidge\n    regr = BayesianRidge()\n    return regr\n\n# Any results you write to the current directory are saved as output.\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\ntrain_y = train['y']\ntrain = train.drop(['y', 'ID'], 1)\n\ntrain_x = pd.get_dummies(train)\ntrain_x = train_x.reindex_axis(sorted(train_x.columns), axis=1)\n\ntest_x = pd.get_dummies(test)\ntest_x = test_x.drop('ID', 1)\n# remove untrained features\nunknonw_columns = test_x.columns.difference(train_x.columns)\ntest_x = test_x.drop(unknonw_columns.tolist(), 1)\nmissing_columns = train_x.columns.difference(test_x.columns)\n# test_x = pd.concat([test_x,pd.DataFrame(columns=missing_columns)])\nfor col in missing_columns:\n    test_x[col] = 0\ntest_x = test_x.reindex_axis(sorted(test_x.columns), axis=1)    \ntest_x.head(3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1fd6606-d63e-fae1-29d2-eab65baac8a4"},"outputs":[],"source":"test_x = pd.get_dummies(test)\ntest_x = test_x.drop('ID', 1)\n# remove untrained features\nunknonw_columns = test_x.columns.difference(train_x.columns)\ntest_x = test_x.drop(unknonw_columns.tolist(), 1)\nmissing_columns = train_x.columns.difference(test_x.columns)\n# test_x = pd.concat([test_x,pd.DataFrame(columns=missing_columns)])\nfor col in missing_columns:\n    test_x[col] = 0\ntest_x = test_x.reindex_axis(sorted(test_x.columns), axis=1)\n\nxgb_params = {\n    'n_trees': 500, \n    'eta': 0.004,\n    'max_depth': 4,\n    'subsample': 0.95,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\nclf = xgb.XGBRegressor(**xgb_params)\nclf = clf.fit(train_x, train_y)\nmodel = SelectFromModel(clf, prefit=True)\n\ntrain_x = model.transform(train_x)\ntest_x = model.transform(test_x)\n\ntrain_cross_x, train_cross_test_x, train_cross_y, train_cross_test_y = train_test_split(train_x, train_y, test_size=0.01)\n\npd.DataFrame(train_cross_y).head(4)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ab9e9d4-d73f-247b-6570-7956a7e05e18"},"outputs":[],"source":"pd.DataFrame(train_x).head(4)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"685d1f02-d8e1-b741-6595-2f26553d443a"},"outputs":[],"source":"#MLPRegressor().fit(train_x, train_y)\n#linear_model.LinearRegression().fit(train_cross_x, train_cross_y)\n#RandomForestRegressor(n_estimators = 30, random_state = 0).fit(train_cross_x, train_cross_y)\n#BayesianRidge().fit(train_x, train_y)\n# next(train_cross_x.iterrows())[1]\nmodels = train_models(get_models(), train_cross_x, train_cross_y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6809f3e6-3015-1c80-36e3-ebf441f16827"},"outputs":[],"source":"pd.DataFrame(train_cross_x).head(4)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4bb6876-bfb4-05f5-4ea8-d882fe059cab"},"outputs":[],"source":"train_cross_y = pd.DataFrame(train_cross_y.get_values())\ntrain_cross_x = pd.DataFrame(train_cross_x)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8292115b-59a0-2bd3-03f7-5109ad3c97e9"},"outputs":[],"source":"train_cross_models = list()\ntrain_cross_y_values = train_cross_y.get_values()\nfor idx, x in train_cross_x.iterrows():\n    m = competite_model(models, x.get_values().reshape(1, -1), train_cross_y_values[idx])\n    train_cross_models.append(m)\ntrain_cross_models_df = pd.DataFrame(train_cross_x)\ntrain_cross_models_df['models'] = train_cross_models"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59ff462e-e2dd-96c6-79b6-98e4fe68b836"},"outputs":[],"source":"for m in train_cross_models_df['models']:\n    print(m)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6b0ef77-7722-62dd-a89c-b304747f0b3c"},"outputs":[],"source":"regr = create_model()\nregr.fit(train_cross_x, train_cross_y)\nregr.score(train_cross_test_x, train_cross_test_y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7bd0acd-a7b7-82d2-ec94-15a2ebf95a3f"},"outputs":[],"source":"trained_cross_models = train_models(get_models(), train_cross_x, train_cross_y)\n\nout = {}\nfor name, m in trained_cross_models.items():\n    out[name] = m.score(train_cross_test_x, train_cross_test_y)\nout    \n\ntrain_cross_x_df = pd.DataFrame(train_cross_x)\ntrain_cross_y_df = pd.DataFrame({'y': train_cross_y})\ntrain_cross =  pd.concat([train_cross_x_df, train_cross_y_df], axis=1)\nprint(train_cross.columns.values)\nmodel_series = list()\nfor idx, row in train_cross.iterrows():\n    print(row)\n    m = competite_model(trained_cross_models, row.drop('y').reshape(1, -1), \n                        row['y'].reshape(-1, 1))\n    print(m)\n    model_series.append([m])\nmodel_series    \n# linear_model.LinearRegression().fit(train_cross_x, train_cross_y)\n# RandomForestRegressor(n_estimators = 30, random_state = 0).fit(train_cross_x, train_cross_y)\n# MLPRegressor().fit(train_cross_x, train_cross_y)\n# BayesianRidge().fit(train_cross_x, train_cross_y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d3aab370-3acb-ee72-997f-5884353af87d"},"outputs":[],"source":"#regr.predict(train_cross_test_x)\n#train_cross_test_y.tolist()\nplot_offset = 700\npd.DataFrame({'predicted': regr.predict(train_cross_test_x[plot_offset:plot_offset+20]), \n              'expected': train_cross_test_y.tolist()[plot_offset:plot_offset+20]}).plot(kind='bar')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc6c5670-049d-1e6e-7d51-d2f9632c174b"},"outputs":[],"source":"regr = create_model()\n\nregr.fit(train_x, train_y)\nregr.score(train_x, train_y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc80ff7c-561c-9872-243d-a90a34f33558"},"outputs":[],"source":"# predict\ntest_y = regr.predict(test_x)\ntest_y\n\n# write results\nsolution = pd.DataFrame({\"ID\":test.ID, \"y\":test_y}) \nsolution.to_csv('predicted.csv', index = False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}