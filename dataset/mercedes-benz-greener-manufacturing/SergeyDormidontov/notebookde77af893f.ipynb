{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.metrics import r2_score\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.random_projection import SparseRandomProjection\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import FastICA\nfrom sklearn.decomposition import TruncatedSVD\nimport lightgbm as lgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import Lasso\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/mercedes-benz-greener-manufacturing/train.csv.zip', compression='zip')\ntest = pd.read_csv('../input/mercedes-benz-greener-manufacturing/test.csv.zip', compression='zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.X0.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(train[c].values) + list(test[c].values))\n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train['y'] \ntrain.drop(['y'],inplace=True,axis=1)       \ncombine=pd.concat([train,test])\ncolumns=['X1','X2','X3','X4','X5','X6','X8']\nfor column in columns:\n    temp=pd.get_dummies(pd.Series(combine[column]))\n    combine=pd.concat([combine,temp],axis=1)\n    combine= combine.drop([column], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add unique names to columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=combine[:train.shape[0]]\ntest=combine[train.shape[0]:] \n\n\ndef df_column_uniquify(df):\n    df_columns = df.columns\n    new_columns = []\n    for item in df_columns:\n        counter = 0\n        newitem = item\n        while newitem in new_columns:\n            counter += 1\n            newitem = \"{}_{}\".format(item, counter)\n        new_columns.append(newitem)\n    df.columns = new_columns\n    return df\n\ntrain = df_column_uniquify(train)  \ntest = df_column_uniquify(test)   \ntrain['y']=y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Генерируем производные фичи\n\nFastICA: https://towardsdatascience.com/independent-component-analysis-ica-in-python-a0ef0db0955e  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_additional_features(train,test,magic=False,ID=False):\n    col = list(test.columns)\n    if ID!=True:\n        col.remove('ID')\n    n_comp = 12\n    # tSVD\n    tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n    tsvd_results_train = tsvd.fit_transform(train[col])\n    tsvd_results_test = tsvd.transform(test[col])\n    # PCA\n    pca = PCA(n_components=n_comp, random_state=420)\n    pca2_results_train = pca.fit_transform(train[col])\n    pca2_results_test = pca.transform(test[col])\n    # ICA\n    ica = FastICA(n_components=n_comp, random_state=420)\n    ica2_results_train = ica.fit_transform(train[col])\n    ica2_results_test = ica.transform(test[col])\n    # GRP\n    grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n    grp_results_train = grp.fit_transform(train[col])\n    grp_results_test = grp.transform(test[col])\n    # SRP\n    srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n    srp_results_train = srp.fit_transform(train[col])\n    srp_results_test = srp.transform(test[col])\n    for i in range(1, n_comp + 1):\n        train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n        test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n        train['pca_' + str(i)] = pca2_results_train[:, i - 1]\n        test['pca_' + str(i)] = pca2_results_test[:, i - 1]\n        train['ica_' + str(i)] = ica2_results_train[:, i - 1]\n        test['ica_' + str(i)] = ica2_results_test[:, i - 1]\n        train['grp_' + str(i)] = grp_results_train[:, i - 1]\n        test['grp_' + str(i)] = grp_results_test[:, i - 1]\n        train['srp_' + str(i)] = srp_results_train[:, i - 1]\n        test['srp_' + str(i)] = srp_results_test[:, i - 1]\n    if magic==True:\n        magic_mat = train[['ID','X0','y']]\n        magic_mat = magic_mat.groupby(['X0'])['y'].mean()\n        magic_mat = pd.DataFrame({'X0':magic_mat.index,'magic':list(magic_mat)})\n        mean_magic = magic_mat['magic'].mean()\n        train = train.merge(magic_mat,on='X0',how='left')\n        test = test.merge(magic_mat,on='X0',how = 'left')\n        test['magic'] = test['magic'].fillna(mean_magic)\n    return train,test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Интересная работа с кат. признаком"},{"metadata":{"trusted":true},"cell_type":"code","source":"magic_mat = train[['ID','X0','y']]\nmagic_mat = magic_mat.groupby(['X0'])['y'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"magic_mat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_xgb_stack_data(params,rounds,train,col,label,test):\n    ID = []\n    train = train.reset_index(drop=True)\n    kf = KFold(n_splits=5,shuffle=False)\n    i=0\n    R2_Score = []\n    RMSE = []\n    for train_index, test_index in kf.split(train):\n        print(\"Training \"+str(i+1)+' Fold')\n        X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n        y_train, y_test = label.iloc[train_index],label.iloc[test_index]\n        dtrain = xgb.DMatrix(X_train[col],y_train)\n        dtest = xgb.DMatrix(X_test[col])\n        model = xgb.train(params,dtrain,num_boost_round=rounds)\n        pred = model.predict(dtest)\n        X_test['label'] = list(y_test)\n        X_test['predicted'] = pred\n        r2 = r2_score(y_test,pred)\n        rmse = MSE(y_test,pred)**0.5\n        print('R2 Scored of Fold '+str(i+1)+' is '+str(r2))\n        R2_Score.append(r2)\n        RMSE.append(rmse)\n        print('RMSE of Fold '+str(i+1)+' is '+str(rmse))\n        ID.append(X_test['ID'])\n        if i==0:\n            Final = X_test\n        else:\n            Final = Final.append(X_test,ignore_index=True)\n        i+=1\n    dtrain_ = xgb.DMatrix(train[col],label)\n    dtest_ = xgb.DMatrix(test[col])\n    print('Start Training')\n    model_ = xgb.train(params,dtrain_,num_boost_round=rounds)\n    Final_pred = model_.predict(dtest_)\n    Final_pred = pd.DataFrame({'ID':test['ID'],'y':Final_pred})\n    print('Calculating In-Bag R2 Score')\n    print(r2_score(dtrain_.get_label(), model.predict(dtrain_)))\n    print('Calculating Out-Bag R2 Score')\n    print(np.mean(R2_Score))\n    print('Calculating In-Bag RMSE')\n    print(MSE(dtrain_.get_label(), model.predict(dtrain_))**0.5)\n    print('Calculating Out-Bag RMSE')\n    print(np.mean(RMSE))\n    return Final,Final_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lgb_stack_data(params,rounds,train,col,label,test):\n    ID = []\n    train = train.reset_index(drop=True)\n    kf = KFold(n_splits=5,shuffle=False)\n    i=0\n    R2_Score = []\n    RMSE = []\n    for train_index, test_index in kf.split(train):\n        print(\"Training \"+str(i+1)+' Fold')\n        X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n        y_train, y_test = label.iloc[train_index],label.iloc[test_index]\n        train_lgb=lgb.Dataset(X_train[col],y_train)\n        model = lgb.train(params,train_lgb,num_boost_round=rounds)\n        pred = model.predict(X_test[col])\n        X_test['label'] = list(y_test)\n        X_test['predicted'] = pred\n        r2 = r2_score(y_test,pred)\n        rmse = MSE(y_test,pred)**0.5\n        print('R2 Scored of Fold '+str(i+1)+' is '+str(r2))\n        R2_Score.append(r2)\n        RMSE.append(rmse)\n        print('RMSE of Fold '+str(i+1)+' is '+str(rmse))\n        ID.append(X_test['ID'])\n        if i==0:\n            Final = X_test\n        else:\n            Final = Final.append(X_test,ignore_index=True)\n        i+=1\n    lgb_train_ = lgb.Dataset(train[col],label)\n    print('Start Training')\n    model_ = lgb.train(params,lgb_train_,num_boost_round=rounds)\n    Final_pred = model_.predict(test[col])\n    Final_pred = pd.DataFrame({'ID':test['ID'],'y':Final_pred})\n    print('Calculating In-Bag R2 Score')\n    print(r2_score(label, model.predict(train[col])))\n    print('Calculating Out-Bag R2 Score')\n    print(np.mean(R2_Score))\n    print('Calculating In-Bag RMSE')\n    print(MSE(label, model.predict(train[col]))**0.5)\n    print('Calculating Out-Bag RMSE')\n    print(np.mean(RMSE))\n    return Final,Final_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sklearn_stack_data(model,train,col,label,test):\n    ID = []\n    R2_Score = []\n    RMSE = []\n    train = train.reset_index(drop=True)\n    kf = KFold(n_splits=5,shuffle=False)\n    i=0\n    for train_index, test_index in kf.split(train):\n        print(\"Training \"+str(i+1)+' Fold')\n        X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n        y_train, y_test = label.iloc[train_index],label.iloc[test_index]\n        model.fit(X_train[col],y_train)\n        pred = model.predict(X_test[col])\n        X_test['label'] = list(y_test)\n        X_test['predicted'] = pred\n        r2 = r2_score(y_test,pred)\n        rmse = MSE(y_test,pred)**0.5\n        print('R2 Scored of Fold '+str(i+1)+' is '+str(r2))\n        R2_Score.append(r2)\n        RMSE.append(rmse)\n        print('RMSE of Fold '+str(i+1)+' is '+str(rmse))\n        ID.append(X_test['ID'])\n        if i==0:\n            Final = X_test\n        else:\n            Final = Final.append(X_test,ignore_index=True)\n        i+=1\n    print('Start Training')\n    model.fit(train[col],label)\n    Final_pred = model.predict(test[col])\n    Final_pred = pd.DataFrame({'ID':test['ID'],'y':Final_pred})\n    print('Calculating In-Bag R2 Score')\n    print(r2_score(label, model.predict(train[col])))\n    print('Calculating Out-Bag R2 Score')\n    print(np.mean(R2_Score))\n    print('Calculating In-Bag RMSE')\n    print(MSE(label, model.predict(train[col]))**0.5)\n    print('Calculating Out-Bag RMSE')\n    print(np.mean(RMSE))\n    return Final,Final_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_,test_ = get_additional_features(train,test,magic=True)\ntrain_ = train_.sample(frac=1,random_state=420)\ncol = list(test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb1 = GradientBoostingRegressor(n_estimators=1000,max_features=0.95,learning_rate=0.005,max_depth=4)\ngb1_train,gb1_test = get_sklearn_stack_data(gb1,train_,col,train_['y'],test_)\n\n## Input2: Lasso\nlas1 = Lasso(alpha=5,random_state=42)\nlas1_train,las1_test = get_sklearn_stack_data(las1,train_,col,train_['y'],test_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb1_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n            'objective': 'regression',\n            'metric': 'rmse',\n            'boosting': 'gbdt',\n            'learning_rate': 0.0045 , #small learn rate, large number of iterations\n            'verbose': 0,\n            'num_iterations': 500,\n            'bagging_fraction': 0.95,\n            'bagging_freq': 1,\n            'bagging_seed': 42,\n            'feature_fraction': 0.95,\n            'feature_fraction_seed': 42,\n            'max_bin': 100,\n            'max_depth': 3,\n            'num_rounds': 800\n        }\nlgb_train, lgb_test = get_lgb_stack_data(params,800,train_,col,train_['y'],test_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb1_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stack_train = gb1_train[['label','predicted']]\nstack_train.columns=[['label','gbdt']]\nstack_train['lgb']=lgb_train['predicted']\nstack_train['las'] = las1_train['predicted']\n\nstack_test = gb1_test[['ID','y']]\nstack_test.columns=[['ID','gbdt']]\nstack_test['lgb']=lgb_test['y']\nstack_test['las'] = las1_test['y']\ndel stack_test['ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stack_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_mean = np.mean(train.y)\n\ncol = list(stack_test.columns)\n\nparams = {\n    'eta': 0.005,\n    'max_depth': 2,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'base_score': y_mean, # base prediction = mean(target)\n    'silent': 1\n}\n\ndtrain = xgb.DMatrix(stack_train[col], stack_train[['label']].values.reshape(1,-1)[0])\ndtest = xgb.DMatrix(stack_test[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.train(params,dtrain,num_boost_round =900)\npred_1 = model.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_,test_ = get_additional_features(train,test,ID=True)\n\nxgb_params = {\n        'n_trees': 520, \n        'eta': 0.0045,\n        'max_depth': 4,\n        'subsample': 0.93,\n        'objective': 'reg:linear',\n        'eval_metric': 'rmse',\n        'base_score': y_mean, # base prediction = mean(target)\n        'silent': True,\n        'seed': 42,\n    }\ndtrain = xgb.DMatrix(train_.drop('y', axis=1), train_.y)\ndtest = xgb.DMatrix(test_)\n    \nnum_boost_rounds = 1250\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\ny_pred = model.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Average = 0.7*y_pred + 0.3*pred_1\n\nsub = pd.DataFrame({'ID':test['ID'],'y':Average})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('subXgb_Stack_Stack_No_ID_with_onehot_4.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Average = 0.70*y_pred + 0.30*pred_1\n\nsub = pd.DataFrame({'ID':test['ID'],'y':Average})\n\n## LB Prob Values \n\n## I forget whose credit should be given, Please help me to find him/her!!\n\nleaks = {\n    1:71.34112,\n    12:109.30903,\n    23:115.21953,\n    28:92.00675,\n    42:87.73572,\n    43:129.79876,\n    45:99.55671,\n    57:116.02167,\n    3977:132.08556,\n    88:90.33211,\n    89:130.55165,\n    93:105.79792,\n    94:103.04672,\n    1001:111.65212,\n    104:92.37968,\n    72:110.54742,\n    78:125.28849,\n    105:108.5069,\n    110:83.31692,\n    1004:91.472,\n    1008:106.71967,\n    1009:108.21841,\n    973:106.76189,\n    8002:95.84858,\n    8007:87.44019,\n    1644:99.14157,\n    337:101.23135,\n    253:115.93724,\n    8416:96.84773,\n    259:93.33662,\n    262:75.35182,\n    1652:89.77625\n    }\nsub['y'] = sub.apply(lambda r: leaks[int(r['ID'])] if int(r['ID']) in leaks else r['y'], axis=1)\n\nsub.to_csv('subXgb_Stack_Stack_No_ID_with_onehot.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}