{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7fe1ab1-c575-204a-1121-f5cd12bb5fc0"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.random_projection import SparseRandomProjection\nfrom sklearn.decomposition import TruncatedSVD\nimport xgboost as xgb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df9f0af1-0e5f-58f3-e2e9-e952468b686a"},"outputs":[],"source":"plt.figure(figsize=(12,8))\nsns.distplot(train_df.y.values, bins=50, kde=False)\nplt.xlabel('AVG Time on Test platform', fontsize=12)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7f69d426-0773-f0d9-e442-6f24912bde1f"},"source":"**Model XGBoosting**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2313f84-1217-413e-ff01-0aabc509eefe"},"outputs":[],"source":"# read datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# process columns, apply LabelEncoder to categorical features\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9f1b23f-8f4e-4715-4bec-5ecd0f9cd1cb"},"outputs":[],"source":"##Add decomposed components: PCA / ICA etc.\n\nn_comp = 10\n\n# tSVD\ntsvd = TruncatedSVD(n_components=n_comp, random_state=420)\ntsvd_results_train = tsvd.fit_transform(train.drop([\"y\"], axis=1))\ntsvd_results_test = tsvd.transform(test)\n\n# PCA\npca = PCA(n_components=n_comp, random_state=420)\npca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\npca2_results_test = pca.transform(test)\n\n# ICA\nica = FastICA(n_components=n_comp, random_state=420)\nica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\nica2_results_test = ica.transform(test)\n\n# GRP\ngrp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\ngrp_results_train = grp.fit_transform(train.drop([\"y\"], axis=1))\ngrp_results_test = grp.transform(test)\n\n# SRP\nsrp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\nsrp_results_train = srp.fit_transform(train.drop([\"y\"], axis=1))\nsrp_results_test = srp.transform(test)\n\n# Append decomposition components to datasets\nfor i in range(1, n_comp+1):\n    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n    \n    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n\n    train['tsvd_' + str(i)] = tsvd_results_train[:,i-1]\n    test['tsvd_' + str(i)] = tsvd_results_test[:, i-1]\n    \n    train['grp_' + str(i)] = grp_results_train[:,i-1]\n    test['grp_' + str(i)] = grp_results_test[:, i-1]\n    \n    train['srp_' + str(i)] = srp_results_train[:,i-1]\n    test['srp_' + str(i)] = srp_results_test[:, i-1]\n    \ny_train = train[\"y\"]\ny_mean = np.mean(y_train)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91f8cd38-1041-8610-821f-63848241e56c"},"outputs":[],"source":"\n\n# prepare dict of params for xgboost to run with\nxgb_params = {\n    'n_trees': 700, \n    'eta': 0.005,\n    'max_depth': 4,\n    'subsample': 0.8,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'base_score': y_mean, \n    'silent': 1\n}\n\n# form DMatrices for Xgboost training\ndtrain = xgb.DMatrix(train.drop('y', axis=1), y_train)\ndtest = xgb.DMatrix(test)\n\n# xgboost, cross-validation\ncv_result = xgb.cv(xgb_params, \n                   dtrain, \n                   num_boost_round=1500, # increase to have better results (~700)\n                   early_stopping_rounds=150,\n                   verbose_eval=50, \n                   show_stdv=False\n                  )\n\nnum_boost_rounds = len(cv_result)\nprint(num_boost_rounds)\n\n# train model\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"399890dd-5dea-406a-137e-8b99e58c9412"},"outputs":[],"source":"# check f2-score (to get higher score - increase num_boost_round in previous cell)\nfrom sklearn.metrics import r2_score\n\n# now fixed, correct calculation\nprint(r2_score(dtrain.get_label(), model.predict(dtrain)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1c8b0fd-9043-d529-b48f-2f7978b534ab"},"outputs":[],"source":"15# make predictions and save results\ny_pred = model.predict(dtest)\noutput = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\noutput.to_csv('xgboost_last.csv'.format(xgb_params['max_depth']), index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"77b5df34-7e01-d9e6-83cf-81a6d4cf3b03"},"outputs":[],"source":"\nplt.figure(figsize=(12,8))\nsns.distplot(y_pred, bins=50, kde=False)\nplt.xlabel('Predicted AVG Time on Test platform', fontsize=12)\nplt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}