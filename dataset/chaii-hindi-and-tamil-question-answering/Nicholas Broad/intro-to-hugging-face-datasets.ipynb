{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"text-align:center;\"> Hugging Face Datasets</h1>\n\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://huggingface.co/docs/datasets/_images/datasets_logo.png\" alt=\"hf dataset logo\" style=\"height:300px;margin:3rem auto;\"> </div>\n\n\n#### Recently, `datasets` version 1.12.1 became a default package in Kaggle notebooks. This is a big relief because there were previously issues with `pyarrow` and `fsspec` (depending on which version of `datasets` you used) that made it annoying to use.\n\n#### I thought I would do a quick tour of `datasets` by showing what is possible and how to use it for this competition (full example at the very end).\n\n#### A lot of this is adapted from the [official documentation](https://huggingface.co/docs/datasets/), with some tailored for the chaii-qa competition. I can't possibly cover every feature, so please explore the documentation to see the full extent of what is possible or [check out their course](https://huggingface.co/course/chapter1). I'm sure the developers will continue to add great new features in the future. \n\n#### Also, please explore the publicly available datasets (more than 1,500 as of Sep 30, 2021) at [huggingface.co/datasets](https://huggingface.co/datasets) (or [hf.co/datasets](https://hf.co/datasets) if don't want to type as much ðŸ˜‰). Feel free to add one!\n\n#### Lastly, the team at Hugging Face also has a [paper in EMNLP 2021](https://arxiv.org/abs/2109.02846) that gives a formal overview of the package.","metadata":{}},{"cell_type":"markdown","source":"# ðŸ”¥ The BIGGEST advantage is\n####  the fact that the datasets are memory-mapped using Apache Arrow and cached locally. This means that only the necessary data will be loaded into memory, allowing the possibility to work with a dataset that is larger than the system memory (e.g. c4 is hundreds of GB, mc4 is several TB).  `datasets` can work on local files, data in memory (e.g. a pandas dataframe or a dict), or easily pull from over 1,500 datasets from the Hugging Face Hub. For the large datasets, a streaming mode is also possible (details later), so that you don't have to download a ton of data. Many functions mirror their analogs in sklearn or pandas, and you can even stick the dataset straight into a PyTorch DataLoader!","metadata":{}},{"cell_type":"code","source":"# package details\n!pip show datasets","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:24.267162Z","iopub.execute_input":"2021-10-08T08:18:24.267705Z","iopub.status.idle":"2021-10-08T08:18:33.417163Z","shell.execute_reply.started":"2021-10-08T08:18:24.267585Z","shell.execute_reply":"2021-10-08T08:18:33.4161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading local files\n\n### I'm putting this first because chaii gives the training and test data in csv format. Here is how you could read it.","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv')\ndataset # DatasetDict","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:33.419741Z","iopub.execute_input":"2021-10-08T08:18:33.420167Z","iopub.status.idle":"2021-10-08T08:18:37.743978Z","shell.execute_reply.started":"2021-10-08T08:18:33.420119Z","shell.execute_reply":"2021-10-08T08:18:37.742925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The code above loads a DatasetDict, which is basically a dict object with split names(train, validation, test) as keys and datasets as values.  \n\n## If you specify the split when loading, you can load in multiple files, as seen below.\n\n#### All of the files need to have the same column names and column types.","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"csv\", data_files={\"train\": \"../input/mlqa-hindi-processed/mlqa_hindi.csv\",  \"validation\": \"../input/mlqa-hindi-processed/xquad.csv\"})\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:37.745378Z","iopub.execute_input":"2021-10-08T08:18:37.745619Z","iopub.status.idle":"2021-10-08T08:18:39.365603Z","shell.execute_reply.started":"2021-10-08T08:18:37.74559Z","shell.execute_reply":"2021-10-08T08:18:39.36494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# If you just want to load a file into a Dataset without it turning into a DatasetDict, use the `split` argument\n","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv', split=\"train\")\ndataset # This will be a Dataset and not DatasetDict","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:39.367292Z","iopub.execute_input":"2021-10-08T08:18:39.368058Z","iopub.status.idle":"2021-10-08T08:18:40.332495Z","shell.execute_reply.started":"2021-10-08T08:18:39.368025Z","shell.execute_reply":"2021-10-08T08:18:40.331602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split dataset when loading\n\n### Splitting by percentage","metadata":{}},{"cell_type":"code","source":"dataset_20pct = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv', split=\"train[:20%]\")\ndataset_80pct = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv', split=\"train[:80%]\")\ndataset_20pct, dataset_80pct","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:40.33392Z","iopub.execute_input":"2021-10-08T08:18:40.334153Z","iopub.status.idle":"2021-10-08T08:18:42.277101Z","shell.execute_reply.started":"2021-10-08T08:18:40.334124Z","shell.execute_reply":"2021-10-08T08:18:42.274895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting by slice","metadata":{}},{"cell_type":"code","source":"dataset_first100 = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv', split=\"train[:100]\")\ndataset_last50 = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv', split=\"train[-50:]\")\ndataset_first100, dataset_last50","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:42.278646Z","iopub.execute_input":"2021-10-08T08:18:42.279017Z","iopub.status.idle":"2021-10-08T08:18:44.18433Z","shell.execute_reply.started":"2021-10-08T08:18:42.278973Z","shell.execute_reply":"2021-10-08T08:18:44.18328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10-fold split","metadata":{}},{"cell_type":"code","source":"# 10-fold cross-validation (see also next section on rounding behavior):\n# The validation datasets are each going to be 10%:\n# [0%:10%], [10%:20%], ..., [90%:100%].\n# And the training datasets are each going to be the complementary 90%:\n# [10%:100%] (for a corresponding validation set of [0%:10%]),\n# [0%:10%] + [20%:100%] (for a validation set of [10%:20%]), ...,\n# [0%:90%] (for a validation set of [90%:100%]).\n\n# For fold0, use val_ds_folds[0] and train_ds_folds[0]\nval_ds_folds = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv', split=[f'train[{k}%:{k+10}%]' for k in range(0, 100, 10)])\ntrain_ds_folds = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv', split=[f'train[:{k}%]+train[{k+10}%:]' for k in range(0, 100, 10)])\nval_ds_folds, train_ds_folds","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:44.186035Z","iopub.execute_input":"2021-10-08T08:18:44.186556Z","iopub.status.idle":"2021-10-08T08:18:46.234978Z","shell.execute_reply.started":"2021-10-08T08:18:44.186511Z","shell.execute_reply":"2021-10-08T08:18:46.233945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Funkier splits\n\n### This takes the first 20% and the last 20%","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv', split=\"train[:20%]+train[-20%:]\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:46.236443Z","iopub.execute_input":"2021-10-08T08:18:46.236804Z","iopub.status.idle":"2021-10-08T08:18:47.203901Z","shell.execute_reply.started":"2021-10-08T08:18:46.23674Z","shell.execute_reply":"2021-10-08T08:18:47.202959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split after loading","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('csv', data_files='../input/chaii-hindi-and-tamil-question-answering/train.csv', split=\"train\")\n\nsplits = dataset.train_test_split(test_size=0.2, seed=2021) # sklearn syntax\nsplits","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:47.205153Z","iopub.execute_input":"2021-10-08T08:18:47.205414Z","iopub.status.idle":"2021-10-08T08:18:48.193916Z","shell.execute_reply.started":"2021-10-08T08:18:47.205385Z","shell.execute_reply":"2021-10-08T08:18:48.192746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Selecting data\n\n### For when you don't want all of it.","metadata":{}},{"cell_type":"code","source":"selected  = dataset.select(range(100))\nprint(selected.shape)\nselected = dataset.select(range(1,1000, 100))\nprint(selected.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.197007Z","iopub.execute_input":"2021-10-08T08:18:48.197281Z","iopub.status.idle":"2021-10-08T08:18:48.212622Z","shell.execute_reply.started":"2021-10-08T08:18:48.19725Z","shell.execute_reply":"2021-10-08T08:18:48.211596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset behaves both like a dict and a list\n### Can select by index first or by column name","metadata":{}},{"cell_type":"code","source":"dataset[42][\"question\"], dataset[\"question\"][42]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.213832Z","iopub.execute_input":"2021-10-08T08:18:48.214066Z","iopub.status.idle":"2021-10-08T08:18:48.234405Z","shell.execute_reply.started":"2021-10-08T08:18:48.214037Z","shell.execute_reply":"2021-10-08T08:18:48.233583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[42]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.235909Z","iopub.execute_input":"2021-10-08T08:18:48.236144Z","iopub.status.idle":"2021-10-08T08:18:48.250957Z","shell.execute_reply.started":"2021-10-08T08:18:48.236115Z","shell.execute_reply":"2021-10-08T08:18:48.249883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[\"question\"][:5]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.252451Z","iopub.execute_input":"2021-10-08T08:18:48.253525Z","iopub.status.idle":"2021-10-08T08:18:48.266404Z","shell.execute_reply.started":"2021-10-08T08:18:48.253478Z","shell.execute_reply":"2021-10-08T08:18:48.265276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# pandas behavior that does NOT work: selecting multiple columns at once.\n\n####  To get the same effect, remove all the columns that are not needed (if you have columns A,B,C,D and want A&B, you would have to remove C&D)","metadata":{}},{"cell_type":"code","source":"try:\n    dataset[[\"question\", \"answer_text\"]]\nexcept ValueError as e:\n    print(\"Value Error!\", e)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.268135Z","iopub.execute_input":"2021-10-08T08:18:48.26851Z","iopub.status.idle":"2021-10-08T08:18:48.276249Z","shell.execute_reply.started":"2021-10-08T08:18:48.268466Z","shell.execute_reply":"2021-10-08T08:18:48.275231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# `datasets` does not allow values to be assigned","metadata":{}},{"cell_type":"code","source":"dataset[\"question\"][42] = \"Why does this not work?\"\ndataset[\"question\"][42]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.277685Z","iopub.execute_input":"2021-10-08T08:18:48.278055Z","iopub.status.idle":"2021-10-08T08:18:48.297067Z","shell.execute_reply.started":"2021-10-08T08:18:48.27801Z","shell.execute_reply":"2021-10-08T08:18:48.295666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# nor does it allow a column to be added like pandas","metadata":{}},{"cell_type":"code","source":"try:\n    dataset[\"new column\"] = \"single value\"\nexcept TypeError as e:\n    print(\"TypeError!\", e)\ntry:\n    dataset[\"new column2\"] = [x[0] for x in dataset[\"question\"]]\nexcept TypeError as e:\n    print(\"TypeError!\", e)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.298601Z","iopub.execute_input":"2021-10-08T08:18:48.29982Z","iopub.status.idle":"2021-10-08T08:18:48.310649Z","shell.execute_reply.started":"2021-10-08T08:18:48.299748Z","shell.execute_reply":"2021-10-08T08:18:48.309409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# If the dataset has splits, access each split like a dict\n\n### `splits` is a `DatasetDict`","metadata":{}},{"cell_type":"code","source":"print(splits[\"train\"])\nprint(splits[\"test\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.312437Z","iopub.execute_input":"2021-10-08T08:18:48.312677Z","iopub.status.idle":"2021-10-08T08:18:48.324854Z","shell.execute_reply.started":"2021-10-08T08:18:48.312648Z","shell.execute_reply":"2021-10-08T08:18:48.32382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shuffling\n","metadata":{}},{"cell_type":"code","source":"%%time\nshuffled = dataset.shuffle(seed=2021)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.326201Z","iopub.execute_input":"2021-10-08T08:18:48.326576Z","iopub.status.idle":"2021-10-08T08:18:48.344232Z","shell.execute_reply.started":"2021-10-08T08:18:48.326544Z","shell.execute_reply":"2021-10-08T08:18:48.343118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shuffling is cached so if you run it again, it doesn't have to do all the work over again.\n\n### This is much more important on big datasets than this one.","metadata":{}},{"cell_type":"code","source":"%%time\nshuffled = dataset.shuffle(seed=2021)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.345567Z","iopub.execute_input":"2021-10-08T08:18:48.345888Z","iopub.status.idle":"2021-10-08T08:18:48.360445Z","shell.execute_reply.started":"2021-10-08T08:18:48.345843Z","shell.execute_reply":"2021-10-08T08:18:48.359601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading is also cached\n\n### This is downloading the dataset from the HF Hub. They have many benchmarks (squad, glue) and community-added datasets ","metadata":{}},{"cell_type":"code","source":"%time load_dataset('squad', split=\"validation\")","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:18:48.361914Z","iopub.execute_input":"2021-10-08T08:18:48.362342Z","iopub.status.idle":"2021-10-08T08:19:03.026964Z","shell.execute_reply.started":"2021-10-08T08:18:48.362293Z","shell.execute_reply":"2021-10-08T08:19:03.025907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time load_dataset('squad', split=\"validation\")","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:19:03.028582Z","iopub.execute_input":"2021-10-08T08:19:03.028883Z","iopub.status.idle":"2021-10-08T08:19:05.198841Z","shell.execute_reply.started":"2021-10-08T08:19:03.028853Z","shell.execute_reply":"2021-10-08T08:19:05.197659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Most datasets on the hub have info about them","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('squad', split=\"validation\")\ndataset.info","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:19:05.199929Z","iopub.execute_input":"2021-10-08T08:19:05.20018Z","iopub.status.idle":"2021-10-08T08:19:06.690978Z","shell.execute_reply.started":"2021-10-08T08:19:05.200151Z","shell.execute_reply":"2021-10-08T08:19:06.689916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Processing\n\n### `map` is your go-to function to make changes to the data.\n\n\n### `map` gets passed a single example as a `dict` if not using batches, and when using batches, it gets multiple examples as a `dict` where the keys are the column names and the values are the examples (of length batch_size).  \n\n\n### `map` must return a dict, so modifying the values in place will not change them\n\n```python\ndef map_fn(example):\n    \"\"\"\n    example looks like this when not batched:\n    {\"col a\": 1, \"col b\": \"string_val1\", \"col c\": [1,2,3]}\n    \n    example likes like this when batched (batch_size=4):\n    {\"col a\": [1,2,3,4], \"col b\": [\"string_val1\", \"val2\", \"val3\", \"val4\"], \"col c\": [[1,2,3], [2,4,6], [-1,-2,-3], [0,0,0]]}\n    \"\"\"\n    \n    # this is where you would modify the data\n    example[\"x\"] = example[\"y\"]*10\n    \n    return example\n```","metadata":{}},{"cell_type":"code","source":"def map_fn(example):\n    example[\"banana\"] = \"monkey\"\n    example[\"id\"] = example[\"id\"].upper()\n    \n    # since nothing is returned, this map_fn does nothing\n    \nx = dataset.select(range(1)).map(map_fn)\nx[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:19:06.692612Z","iopub.execute_input":"2021-10-08T08:19:06.692993Z","iopub.status.idle":"2021-10-08T08:19:06.76479Z","shell.execute_reply.started":"2021-10-08T08:19:06.692949Z","shell.execute_reply":"2021-10-08T08:19:06.763373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A common step with these QA datasets\n\n#### Getting it in the right format","metadata":{}},{"cell_type":"code","source":"mlqa = load_dataset(\"csv\", data_files=\"../input/mlqa-hindi-processed/mlqa_hindi.csv\", split=\"train\")\n\ndef form_answers(example):\n    example[\"answers\"] = {\n        \"text\": [example[\"answer_text\"]],\n        \"answer_start\": [example[\"answer_start\"]]\n    }\n    return example\n\nnew_mlqa = mlqa.map(form_answers, remove_columns=[\"answer_text\", \"answer_start\"])\nnew_mlqa[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:19:06.766495Z","iopub.execute_input":"2021-10-08T08:19:06.766886Z","iopub.status.idle":"2021-10-08T08:19:08.949549Z","shell.execute_reply.started":"2021-10-08T08:19:06.766841Z","shell.execute_reply":"2021-10-08T08:19:08.948409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# `map` is good for tokenizing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n\ndef tokenize_function(example):\n    return tokenizer(example[\"context\"])\n\n%time tokenized = dataset.map(tokenize_function)\n[tokenized[0][x][:10] for x in [\"input_ids\", \"attention_mask\"]]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:19:08.950716Z","iopub.execute_input":"2021-10-08T08:19:08.950998Z","iopub.status.idle":"2021-10-08T08:19:35.932984Z","shell.execute_reply.started":"2021-10-08T08:19:08.950967Z","shell.execute_reply":"2021-10-08T08:19:35.931925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using batches usually results in a speed up\n\n### default batch size is 1000\n## Time taken to tokenize the dataset\nwithout batching: ~12s  \nwith batching: ~4s","metadata":{}},{"cell_type":"code","source":"%time tokenized = dataset.map(tokenize_function, batched=True, batch_size=1000)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:19:35.934287Z","iopub.execute_input":"2021-10-08T08:19:35.93462Z","iopub.status.idle":"2021-10-08T08:19:40.384882Z","shell.execute_reply.started":"2021-10-08T08:19:35.934588Z","shell.execute_reply":"2021-10-08T08:19:40.383578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Number of rows and columns before `map` does not have to equal number of rows and columns after `map`\n\n### Especially useful when tokenizing.   \n### NOTE: The number of rows for each column must be the same, so columns that are not being \"wrapped\" need to be removed.  For instance when tokenizing, you could map one example (a long string and its `id`) and get out 3 `input_ids` and 3 `attention_mask` if you return the overflowing tokens. You do not, however, get 3 `id` so `id` either must be duplicated 3 times or dropped.","metadata":{}},{"cell_type":"code","source":"length_before = len(dataset)\n\ndef qa_tokenize_function(examples):\n    return tokenizer(\n            examples[\"question\"],\n            examples[\"context\"],\n            truncation=\"only_second\",\n            max_length=128,\n            stride=64,\n            return_overflowing_tokens=True,\n            return_offsets_mapping=True,\n            padding=\"max_length\",\n        )\n\n# this will error because it doesn't remove the other columns like id\n# tokenized = dataset.map(qa_tokenize_function, batched=True, batch_size=1000) \n\n%time tokenized = dataset.map(qa_tokenize_function, batched=True, batch_size=1000, remove_columns=dataset.column_names) \nlength_before, len(tokenized)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:19:40.38686Z","iopub.execute_input":"2021-10-08T08:19:40.387326Z","iopub.status.idle":"2021-10-08T08:20:20.566059Z","shell.execute_reply.started":"2021-10-08T08:19:40.387277Z","shell.execute_reply":"2021-10-08T08:20:20.565056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Other `map` features: lambda functions and task descriptions\n\n### `remove_columns` does not remove the column name that gets returned from the function. In the example below, \"context\" is included in `dataset.column_names` but the output still has the \"context\" column because it gets returned from the function\n\n### Use `desc` to add a description next to the progress bar. Useful when running a script with multiple mapping steps","metadata":{}},{"cell_type":"code","source":"capitalized = dataset.map(lambda x: {\"context\": x[\"context\"].upper()}, desc=\"Capitalizing\", remove_columns=dataset.column_names)\ncapitalized[0] # should be capitalized","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:20.57051Z","iopub.execute_input":"2021-10-08T08:20:20.570801Z","iopub.status.idle":"2021-10-08T08:20:22.535877Z","shell.execute_reply.started":"2021-10-08T08:20:20.570749Z","shell.execute_reply":"2021-10-08T08:20:22.53512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Format the dataset\n\n### Can turn lists into numpy, torch, or tensorflow tensors","metadata":{}},{"cell_type":"code","source":"# stop annoying tf warnings\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-08T08:20:22.536862Z","iopub.execute_input":"2021-10-08T08:20:22.537506Z","iopub.status.idle":"2021-10-08T08:20:22.541513Z","shell.execute_reply.started":"2021-10-08T08:20:22.537471Z","shell.execute_reply":"2021-10-08T08:20:22.540605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenized[0], \"\\n\")\n\ntorch_tensors = tokenized.with_format(\"torch\", columns=['attention_mask', \"input_ids\"],)\nprint(torch_tensors[0], \"\\n\")\n# print(torch_tensors[0][\"input_ids\"][:10], torch_tensors[0][\"attention_mask\"][:10])\n\nnp_tensors = tokenized.with_format(\"numpy\", columns=['attention_mask', \"input_ids\"])\nprint(np_tensors[0], \"\\n\")\n\ntf_tensors = tokenized.with_format(\"tf\", columns=['attention_mask', \"input_ids\"])\nprint(tf_tensors[0], \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:22.54396Z","iopub.execute_input":"2021-10-08T08:20:22.544235Z","iopub.status.idle":"2021-10-08T08:20:28.329891Z","shell.execute_reply.started":"2021-10-08T08:20:22.544203Z","shell.execute_reply":"2021-10-08T08:20:28.329157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cast data in the dataset\n\n### This is a trivial example where int64 gets cast to int32","metadata":{}},{"cell_type":"code","source":"xquad = load_dataset(\"csv\", data_files=\"../input/mlqa-hindi-processed/xquad.csv\", split=\"train\")\nprint(xquad.features)\n\nfrom datasets import Value\nnew_features = xquad.features.copy()\nnew_features[\"answer_start\"] = Value('int32')\nxquad = xquad.cast(new_features)\nxquad.features","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:28.331138Z","iopub.execute_input":"2021-10-08T08:20:28.331879Z","iopub.status.idle":"2021-10-08T08:20:29.5499Z","shell.execute_reply.started":"2021-10-08T08:20:28.331847Z","shell.execute_reply":"2021-10-08T08:20:29.548975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Filter the dataset\n\n### Use a function that returns `True` if the example should be kept, `False` if ignored.","metadata":{}},{"cell_type":"code","source":"# Let's keep only the examples where the context is less than 200 words when splitting at whitespace\ndef filter_by_num_words(example):\n    return len(example[\"context\"].split()) < 200\n\n\nlength_before = len(dataset)\nfiltered = dataset.filter(filter_by_num_words)\nlength_after = len(filtered)\nlength_before, length_after, filtered[-1][\"context\"]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:29.551377Z","iopub.execute_input":"2021-10-08T08:20:29.551716Z","iopub.status.idle":"2021-10-08T08:20:30.008882Z","shell.execute_reply.started":"2021-10-08T08:20:29.55167Z","shell.execute_reply":"2021-10-08T08:20:30.007815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# lambda functions also possible for `filter`","metadata":{}},{"cell_type":"code","source":"length_before = len(dataset)\nfiltered = dataset.filter(lambda x: \"football\" in x[\"context\"].lower()) # keep examples that have the word football in the context\nlength_after = len(filtered)\nlength_before, length_after, filtered[-1][\"context\"]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:30.010454Z","iopub.execute_input":"2021-10-08T08:20:30.010842Z","iopub.status.idle":"2021-10-08T08:20:30.422443Z","shell.execute_reply.started":"2021-10-08T08:20:30.010793Z","shell.execute_reply":"2021-10-08T08:20:30.421452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remove columns\n\n#### Since there isn't an easy way to select a ","metadata":{}},{"cell_type":"code","source":"original_columns = dataset.column_names\nnew_ds = dataset.remove_columns([x for x in original_columns if x != \"id\"])\nprint(original_columns)\nprint(new_ds.column_names)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:30.423619Z","iopub.execute_input":"2021-10-08T08:20:30.423949Z","iopub.status.idle":"2021-10-08T08:20:30.433254Z","shell.execute_reply.started":"2021-10-08T08:20:30.423919Z","shell.execute_reply":"2021-10-08T08:20:30.432085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Streaming\n\nFor when the datasets are many GBs and you don't want to save it to your disk first.","metadata":{}},{"cell_type":"code","source":"stream_dataset = load_dataset('oscar', \"unshuffled_deduplicated_en\", split='train', streaming=True)\nprint(next(iter(stream_dataset)))","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:30.434297Z","iopub.execute_input":"2021-10-08T08:20:30.434676Z","iopub.status.idle":"2021-10-08T08:20:36.580965Z","shell.execute_reply.started":"2021-10-08T08:20:30.434647Z","shell.execute_reply":"2021-10-08T08:20:36.579814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shuffle a streamed dataset\n\nIt won't shuffle the entire dataset (doing so would require looping through the entire dataset), but it will shuffle one buffer (say, 10,000 examples) at a time","metadata":{}},{"cell_type":"code","source":"shuffled_dataset = stream_dataset.shuffle(buffer_size=10_000, seed=42)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:36.582562Z","iopub.execute_input":"2021-10-08T08:20:36.583034Z","iopub.status.idle":"2021-10-08T08:20:36.602355Z","shell.execute_reply.started":"2021-10-08T08:20:36.582988Z","shell.execute_reply":"2021-10-08T08:20:36.601186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Map a streamed dataset","metadata":{}},{"cell_type":"code","source":"mapped_stream = stream_dataset.map(lambda x: {\"text\": x[\"text\"].upper()})\nprint(next(iter(mapped_stream)))","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:36.604077Z","iopub.execute_input":"2021-10-08T08:20:36.604415Z","iopub.status.idle":"2021-10-08T08:20:37.241513Z","shell.execute_reply.started":"2021-10-08T08:20:36.604371Z","shell.execute_reply":"2021-10-08T08:20:37.240503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Interleave streamed datasets\n### Mix multiple streams","metadata":{}},{"cell_type":"code","source":"from datasets import interleave_datasets\nfrom itertools import islice\nen_dataset = load_dataset('oscar', \"unshuffled_deduplicated_en\", split='train', streaming=True)\nfr_dataset = load_dataset('oscar', \"unshuffled_deduplicated_fr\", split='train', streaming=True)\n\nmultilingual_dataset = interleave_datasets([en_dataset, fr_dataset])\nprint(list(islice(multilingual_dataset, 2)))","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:37.242982Z","iopub.execute_input":"2021-10-08T08:20:37.243955Z","iopub.status.idle":"2021-10-08T08:20:42.667681Z","shell.execute_reply.started":"2021-10-08T08:20:37.24391Z","shell.execute_reply":"2021-10-08T08:20:42.666801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save dataset","metadata":{}},{"cell_type":"code","source":"dataset.to_json(\"dataset.json\")\ndataset.to_csv(\"dataset.csv\", index=False) #  pandas syntax","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:42.669346Z","iopub.execute_input":"2021-10-08T08:20:42.669576Z","iopub.status.idle":"2021-10-08T08:20:44.610999Z","shell.execute_reply.started":"2021-10-08T08:20:42.669548Z","shell.execute_reply":"2021-10-08T08:20:44.609888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save processed dataset\n\nIf the dataset has special types (e.g. tensors) that can't save to csv or json, use `save_to_disk`","metadata":{}},{"cell_type":"code","source":"tokenized.save_to_disk(\"tokenized_dataset\")\n%ls tokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:44.612485Z","iopub.execute_input":"2021-10-08T08:20:44.612822Z","iopub.status.idle":"2021-10-08T08:20:45.520581Z","shell.execute_reply.started":"2021-10-08T08:20:44.612791Z","shell.execute_reply":"2021-10-08T08:20:45.519239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load processed dataset","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\n\nloaded = Dataset.load_from_disk(\"tokenized_dataset\")\n{key:loaded[0][key][:10] for key in [\"input_ids\", \"attention_mask\", \"offset_mapping\"]}","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:45.523795Z","iopub.execute_input":"2021-10-08T08:20:45.524112Z","iopub.status.idle":"2021-10-08T08:20:45.544869Z","shell.execute_reply.started":"2021-10-08T08:20:45.524076Z","shell.execute_reply":"2021-10-08T08:20:45.543911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Concatenate Datasets\n\n### All datasets need to have the exact same features.","metadata":{}},{"cell_type":"code","source":"from datasets import concatenate_datasets\n\nmlqa = load_dataset(\"csv\", data_files=\"../input/mlqa-hindi-processed/mlqa_hindi.csv\", split=\"train\")\nxquad = load_dataset(\"csv\", data_files=\"../input/mlqa-hindi-processed/xquad.csv\", split=\"train\")\n\nconcat = concatenate_datasets([mlqa, xquad])\n\nlen(mlqa), len(xquad), len(concat)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:45.546276Z","iopub.execute_input":"2021-10-08T08:20:45.546529Z","iopub.status.idle":"2021-10-08T08:20:47.499138Z","shell.execute_reply.started":"2021-10-08T08:20:45.5465Z","shell.execute_reply":"2021-10-08T08:20:47.49826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset from memory (pandas or dict)","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\nimport pandas as pd\n\ndf = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/train.csv\")\ndataset = Dataset.from_pandas(df)\n\nmy_dict = {\"col_a\": [\"apple\", \"orange\", \"banana\"], \"col_b\": list(range(3)), \"col_c\": [True, False, True], \"col_d\": [[\"x\", \"y\", \"z\"]]*3}\ndataset = Dataset.from_dict(my_dict)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:47.50043Z","iopub.execute_input":"2021-10-08T08:20:47.500655Z","iopub.status.idle":"2021-10-08T08:20:48.037271Z","shell.execute_reply.started":"2021-10-08T08:20:47.500626Z","shell.execute_reply":"2021-10-08T08:20:48.036338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Example for chaii-qa\n\n### This is slightly modified from Abhishek's notebook here: https://www.kaggle.com/abhishek/hello-friends-tez-se-chaii-train-kar-lo\n\n### My version doesn't use pandas at all ðŸ˜‰","metadata":{}},{"cell_type":"code","source":"from datasets import DatasetDict\nfrom functools import partial\n\ntokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n\nPAD_ON_RIGHT = tokenizer.padding_side == \"right\"\nFOLD = 0\nMAX_LEN = 384\nDOC_STRIDE = 128\n\nchaii_data = load_dataset(\"csv\", data_files=\"../input/chaii-extra/train_folds.csv\", split=\"train\")\nexternal_data = load_dataset(\"csv\", data_files=[\"../input/chaii-extra/mlqa_hindi.csv\", \"../input/chaii-extra/xquad.csv\"], split=\"train\")\n\ntrain_data = chaii_data.filter(lambda x: x[\"kfold\"]!=FOLD)\nvalid_data = chaii_data.filter(lambda x: x[\"kfold\"]==FOLD)\n\ndef form_answers(example):\n    example[\"answers\"] = {\n        \"text\": [example[\"answer_text\"]],\n        \"answer_start\": [example[\"answer_start\"]]\n    }\n    return example\n\ndef add_id(example, idx):\n    # validation features need a unique id\n    example[\"id\"] = \"id\" + str(idx)\n    return example\n\n\ncols = [\"context\", \"question\", \"answer_text\", \"answer_start\"]\n\ntrain_data = train_data.remove_columns([x for x in train_data.column_names if x not in cols])\nvalid_data = valid_data.remove_columns([x for x in valid_data.column_names if x not in cols])\nexternal_data = external_data.remove_columns([x for x in external_data.column_names if x not in cols])\n\nraw_dataset = DatasetDict()\nraw_dataset[\"train\"] = concatenate_datasets([train_data, external_data], axis=0)\nraw_dataset[\"validation\"] = valid_data\n\n# When using map on a DatasetDict, all splits will get mapped\nraw_dataset = raw_dataset.map(form_answers, desc=\"Formatting answers\")\nraw_dataset = raw_dataset.map(add_id, desc=\"Adding id column\", with_indices=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:20:48.038529Z","iopub.execute_input":"2021-10-08T08:20:48.03879Z","iopub.status.idle":"2021-10-08T08:21:02.478656Z","shell.execute_reply.started":"2021-10-08T08:20:48.038744Z","shell.execute_reply":"2021-10-08T08:21:02.477583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `prepare_train_features` and `prepare_validation_features` functions hidden in next cell","metadata":{}},{"cell_type":"code","source":"def prepare_train_features(examples, tokenizer, pad_on_right, max_length, doc_stride):\n    # ref: https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    # The offset mappings will give us a map from token to character position in the original context. This will\n    # help us compute the start_positions and end_positions.\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n\n    # Let's label those examples!\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        # We will label impossible answers with the index of the CLS token.\n        input_ids = tokenized_examples[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        answers = examples[\"answers\"][sample_index]\n        # If no answers are given, set the cls_index as answer.\n        if len(answers[\"answer_start\"]) == 0:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            # Start/end character index of the answer in the text.\n            start_char = answers[\"answer_start\"][0]\n            end_char = start_char + len(answers[\"text\"][0])\n\n            # Start token index of the current span in the text.\n            token_start_index = 0\n            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n                token_start_index += 1\n\n            # End token index of the current span in the text.\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n                token_end_index -= 1\n\n            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                tokenized_examples[\"start_positions\"].append(cls_index)\n                tokenized_examples[\"end_positions\"].append(cls_index)\n            else:\n                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n                # Note: we could go after the last offset if the answer is the last word (edge case).\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples\n\n\ndef prepare_validation_features(examples, tokenizer, pad_on_right, max_length, doc_stride):\n    # ref: https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n\n    # We keep the example_id that gave us this feature and we will store the offset mappings.\n    tokenized_examples[\"example_id\"] = []\n\n    for i in range(len(tokenized_examples[\"input_ids\"])):\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        context_index = 1 if pad_on_right else 0\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n\n        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n        # position is part of the context or not.\n        tokenized_examples[\"offset_mapping\"][i] = [\n            (o if sequence_ids[k] == context_index else None)\n            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n        ]\n\n    return tokenized_examples","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-08T08:21:02.480181Z","iopub.execute_input":"2021-10-08T08:21:02.480428Z","iopub.status.idle":"2021-10-08T08:21:02.504912Z","shell.execute_reply.started":"2021-10-08T08:21:02.480399Z","shell.execute_reply":"2021-10-08T08:21:02.50385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This will tokenize the examples, adding padding, allowing for overflow, and using a stride\n\nThe number of rows and columns before mapping != rows and columns afterwards","metadata":{}},{"cell_type":"code","source":"train_features = raw_dataset[\"train\"].map(\n    partial(\n        prepare_train_features,\n        tokenizer=tokenizer,\n        pad_on_right=PAD_ON_RIGHT,\n        max_length=MAX_LEN,\n        doc_stride=DOC_STRIDE,\n    ),\n    batched=True,\n    remove_columns=raw_dataset[\"train\"].column_names,\n    desc=\"Creating train features\"\n)\n\nvalid_features = raw_dataset[\"validation\"].map(\n    partial(\n        prepare_validation_features,\n        tokenizer=tokenizer,\n        pad_on_right=PAD_ON_RIGHT,\n        max_length=MAX_LEN,\n        doc_stride=DOC_STRIDE,\n    ),\n    batched=True,\n    remove_columns=raw_dataset[\"validation\"].column_names,\n    desc=\"Creating validation features\"\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:21:02.506366Z","iopub.execute_input":"2021-10-08T08:21:02.507241Z","iopub.status.idle":"2021-10-08T08:21:29.932371Z","shell.execute_reply.started":"2021-10-08T08:21:02.507198Z","shell.execute_reply":"2021-10-08T08:21:29.931349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features, valid_features","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:21:29.934004Z","iopub.execute_input":"2021-10-08T08:21:29.934379Z","iopub.status.idle":"2021-10-08T08:21:29.941643Z","shell.execute_reply.started":"2021-10-08T08:21:29.934336Z","shell.execute_reply":"2021-10-08T08:21:29.940651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use with PyTorch DataLoader","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(train_features.with_format(\"torch\"), batch_size=16, num_workers=4, shuffle=True)\nvalid_dataloader = DataLoader(valid_features.with_format(\"torch\"), batch_size=32, num_workers=4, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:21:29.943393Z","iopub.execute_input":"2021-10-08T08:21:29.943949Z","iopub.status.idle":"2021-10-08T08:21:29.994888Z","shell.execute_reply.started":"2021-10-08T08:21:29.943903Z","shell.execute_reply":"2021-10-08T08:21:29.993867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this just prevents annoying warnings from popping up\n%env TOKENIZERS_PARALLELISM=true\n\nfor x in train_dataloader:\n    break\nx","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:21:29.996262Z","iopub.execute_input":"2021-10-08T08:21:29.996783Z","iopub.status.idle":"2021-10-08T08:21:30.247932Z","shell.execute_reply.started":"2021-10-08T08:21:29.996718Z","shell.execute_reply":"2021-10-08T08:21:30.247077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use with Tensorflow","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n\ntf_train_features = train_features.with_format('tensorflow')\n\ntf_train_x = {x: tf_train_features[x].to_tensor(default_value=0, shape=[None, MAX_LEN]) for x in ['input_ids', 'attention_mask']}\ntf_train_y = {x: tf_train_features[x] for x in ['start_positions', 'end_positions']}\n\ntf_train_dataset = tf.data.Dataset.from_tensor_slices((tf_train_x, tf_train_y)).batch(32)\nnext(iter(tf_train_dataset))","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:21:30.249571Z","iopub.execute_input":"2021-10-08T08:21:30.25004Z","iopub.status.idle":"2021-10-08T08:22:21.934028Z","shell.execute_reply.started":"2021-10-08T08:21:30.249996Z","shell.execute_reply":"2021-10-08T08:22:21.932943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# That's it for now. Please check out the documentation at https://huggingface.co/docs/datasets/ or the course at https://huggingface.co/course/chapter1 for more details.","metadata":{}},{"cell_type":"markdown","source":"# Thanks for reading!\n\nI hope it was useful ðŸ˜Š\n\nIf you spot any errors, please let me know! I'm a human, after all. Feedback welcome!\n\n<div style=\"width:100%;text-align: center;\"> \n    <iframe src=\"https://giphy.com/embed/xULW8v7LtZrgcaGvC0\" width=\"480\" height=\"480\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n</div>","metadata":{}}]}