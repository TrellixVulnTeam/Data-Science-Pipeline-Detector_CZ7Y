{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport os\nimport json\nimport pandas as pd\nfrom pathlib import Path","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-22T08:18:52.207909Z","iopub.execute_input":"2021-08-22T08:18:52.208572Z","iopub.status.idle":"2021-08-22T08:18:52.21388Z","shell.execute_reply.started":"2021-08-22T08:18:52.208508Z","shell.execute_reply":"2021-08-22T08:18:52.212805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from plotly import graph_objects as go\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.subplots import make_subplots","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:52.215251Z","iopub.execute_input":"2021-08-22T08:18:52.215622Z","iopub.status.idle":"2021-08-22T08:18:52.226719Z","shell.execute_reply.started":"2021-08-22T08:18:52.215591Z","shell.execute_reply":"2021-08-22T08:18:52.225879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:55.24383Z","iopub.execute_input":"2021-08-22T08:18:55.244342Z","iopub.status.idle":"2021-08-22T08:18:55.247382Z","shell.execute_reply.started":"2021-08-22T08:18:55.244308Z","shell.execute_reply":"2021-08-22T08:18:55.246707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict, Counter","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:55.439248Z","iopub.execute_input":"2021-08-22T08:18:55.439643Z","iopub.status.idle":"2021-08-22T08:18:55.443666Z","shell.execute_reply.started":"2021-08-22T08:18:55.43961Z","shell.execute_reply":"2021-08-22T08:18:55.442611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max_colwidth\", 300)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:55.799659Z","iopub.execute_input":"2021-08-22T08:18:55.800296Z","iopub.status.idle":"2021-08-22T08:18:55.804168Z","shell.execute_reply.started":"2021-08-22T08:18:55.800258Z","shell.execute_reply":"2021-08-22T08:18:55.803338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = Path(\"/kaggle/input/chaii-hindi-and-tamil-question-answering/\")\ntrain_data = pd.read_csv(DATA_DIR / \"train.csv\")\ntest_data = pd.read_csv(DATA_DIR / \"test.csv\")\nsubmission_data = pd.read_csv(DATA_DIR / \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:56.070273Z","iopub.execute_input":"2021-08-22T08:18:56.070698Z","iopub.status.idle":"2021-08-22T08:18:56.598542Z","shell.execute_reply.started":"2021-08-22T08:18:56.070662Z","shell.execute_reply":"2021-08-22T08:18:56.597407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:56.60001Z","iopub.execute_input":"2021-08-22T08:18:56.600327Z","iopub.status.idle":"2021-08-22T08:18:56.615173Z","shell.execute_reply.started":"2021-08-22T08:18:56.600295Z","shell.execute_reply":"2021-08-22T08:18:56.613996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:56.968179Z","iopub.execute_input":"2021-08-22T08:18:56.968579Z","iopub.status.idle":"2021-08-22T08:18:56.980574Z","shell.execute_reply.started":"2021-08-22T08:18:56.968547Z","shell.execute_reply":"2021-08-22T08:18:56.979822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.language.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:58.043341Z","iopub.execute_input":"2021-08-22T08:18:58.043878Z","iopub.status.idle":"2021-08-22T08:18:58.051657Z","shell.execute_reply.started":"2021-08-22T08:18:58.043845Z","shell.execute_reply":"2021-08-22T08:18:58.05089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.language.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:58.396206Z","iopub.execute_input":"2021-08-22T08:18:58.396716Z","iopub.status.idle":"2021-08-22T08:18:58.404452Z","shell.execute_reply.started":"2021-08-22T08:18:58.396683Z","shell.execute_reply":"2021-08-22T08:18:58.40356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"languages = [\"tamil\", \"hindi\"]\nselect_language = lambda x, y: x[x.language == y]","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:18:58.768064Z","iopub.execute_input":"2021-08-22T08:18:58.768778Z","iopub.status.idle":"2021-08-22T08:18:58.774059Z","shell.execute_reply.started":"2021-08-22T08:18:58.768724Z","shell.execute_reply":"2021-08-22T08:18:58.773129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_data(text):\n    text = re.sub(r\"[a-zA-Z_+-]+\", \"\", text)\n    text = re.sub(r\"\\[\\d+\\]\", \"\", text)\n    text = re.sub(r\"\\([\\d\\s Ã—]+\\)\", \"\", text)\n    text = re.sub(r\"\\(\\s*\\)\", \"\", text)\n    text = re.sub(r\"\\n\", \" \", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:20:41.352049Z","iopub.execute_input":"2021-08-22T08:20:41.352439Z","iopub.status.idle":"2021-08-22T08:20:41.357997Z","shell.execute_reply.started":"2021-08-22T08:20:41.352403Z","shell.execute_reply":"2021-08-22T08:20:41.356938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.context = train_data.context.apply(lambda x: clean_data(x))","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:20:41.650075Z","iopub.execute_input":"2021-08-22T08:20:41.65043Z","iopub.status.idle":"2021-08-22T08:20:42.240426Z","shell.execute_reply.started":"2021-08-22T08:20:41.6504Z","shell.execute_reply":"2021-08-22T08:20:42.239445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:20:51.708416Z","iopub.execute_input":"2021-08-22T08:20:51.708783Z","iopub.status.idle":"2021-08-22T08:20:51.722339Z","shell.execute_reply.started":"2021-08-22T08:20:51.708755Z","shell.execute_reply":"2021-08-22T08:20:51.721135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Copied Wordcloud Visualization script from [here](https://www.kaggle.com/hoshi7/chaii-interactive-wordclouds?scriptVersionId=72235241&cellId=8). Thanks [Shivam Ralli](https://www.kaggle.com/hoshi7)","metadata":{}},{"cell_type":"code","source":"from IPython.display import HTML\nimport altair as alt\nfrom  altair.vega import v5","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-08-22T08:20:55.449025Z","iopub.execute_input":"2021-08-22T08:20:55.449396Z","iopub.status.idle":"2021-08-22T08:20:55.454195Z","shell.execute_reply.started":"2021-08-22T08:20:55.449344Z","shell.execute_reply":"2021-08-22T08:20:55.453153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining functions for visualizations: \n\ndef pie_plot(labels, values, colors, title):\n    fig = {\n      \"data\": [\n        {\n          \"values\": values,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .48]},\n          \"name\": \"Job Type\",\n          \"sort\": False,\n          \"marker\": {'colors': colors},\n          \"textinfo\":\"percent+label\",\n          \"textfont\": {'color': '#FFFFFF', 'size': 10},\n          \"hole\": .6,\n          \"type\": \"pie\"\n        } ],\n        \"layout\": {\n            \"title\":title,\n            \"annotations\": [\n                {\n                    \"font\": {\n                        \"size\": 25,\n\n                    },\n                    \"showarrow\": False,\n                    \"text\": \"\"\n\n                }\n            ]\n        }\n    }\n    return fig","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-22T08:20:55.773562Z","iopub.execute_input":"2021-08-22T08:20:55.773949Z","iopub.status.idle":"2021-08-22T08:20:55.781718Z","shell.execute_reply.started":"2021-08-22T08:20:55.773914Z","shell.execute_reply":"2021-08-22T08:20:55.780574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##-----------------------------------------------------------\n# This whole section \nvega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\nvega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\nvega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https://cdn.jsdelivr.net/npm/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"></div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"works?\");\n    }});\n    console.log(\"recheck to see if it works?\");\n    </script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\n\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"</script>\")))\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-08-22T08:20:56.441017Z","iopub.execute_input":"2021-08-22T08:20:56.441369Z","iopub.status.idle":"2021-08-22T08:20:56.458011Z","shell.execute_reply.started":"2021-08-22T08:20:56.441326Z","shell.execute_reply":"2021-08-22T08:20:56.456679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wordcloud function\n\n\ndef word_cloud(df, pixwidth=6000, pixheight=350, column=\"index\", counts=\"count\"):\n    data= [dict(name=\"dataset\", values=df.to_dict(orient=\"records\"))]\n    wordcloud = {\n        \"$schema\": \"https://vega.github.io/schema/vega/v5.json\",\n        \"width\": pixwidth,\n        \"height\": pixheight,\n        \"padding\": 0,\n        \"title\": \"Hover to see number of occureances from all the sequences\",\n        \"data\": data\n    }\n    scale = dict(\n        name=\"color\",\n        type=\"ordinal\",\n        range=[\"cadetblue\", \"royalblue\", \"steelblue\", \"navy\", \"teal\"]\n    )\n    mark = {\n        \"type\":\"text\",\n        \"from\":dict(data=\"dataset\"),\n        \"encode\":dict(\n            enter=dict(\n                text=dict(field=column),\n                align=dict(value=\"center\"),\n                baseline=dict(value=\"alphabetic\"),\n                fill=dict(scale=\"color\", field=column),\n                tooltip=dict(signal=\"datum.count + ' occurrances'\")\n            )\n        ),\n        \"transform\": [{\n            \"type\": \"wordcloud\",\n            \"text\": dict(field=column),\n            \"size\": [pixwidth, pixheight],\n            \"font\": \"Helvetica Neue, Arial\",\n            \"fontSize\": dict(field=\"datum.{}\".format(counts)),\n            \"fontSizeRange\": [10, 60],\n            \"padding\": 2\n        }]\n    }\n    wordcloud[\"scales\"] = [scale]\n    wordcloud[\"marks\"] = [mark]\n    \n    return wordcloud\n\n\n\ndef wordcloud_create(df, field):\n    ult = {}\n    corpus = df[field].values.tolist()\n    final = defaultdict(int) #Declaring an empty dictionary for count (Saves ram usage)\n    for words in corpus:\n        for word in words:\n             final[word]+=1\n    temp = Counter(final)\n    print(\"Number of distinct tokens: \", len(temp))\n    for k, v in  temp.most_common(300):\n        ult[k] = v\n    corpus = pd.Series(ult) #Creating a dataframe from the final default dict\n    return render(word_cloud(corpus.to_frame(name=\"count\").reset_index(), pixheight=600, pixwidth=900))","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-08-22T08:20:56.810746Z","iopub.execute_input":"2021-08-22T08:20:56.8111Z","iopub.status.idle":"2021-08-22T08:20:56.824482Z","shell.execute_reply.started":"2021-08-22T08:20:56.811069Z","shell.execute_reply":"2021-08-22T08:20:56.823685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation against different pretrained tokenizers","metadata":{}},{"cell_type":"code","source":"def analyse_tokenizer(tokenizer_path, train_data):\n    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n\n    train_data['tokens'] = train_data['context'].apply(lambda x: tokenizer.tokenize(x))\n\n    train_data[\"num_tokens\"] = train_data['tokens'].apply(lambda x: len(x))\n\n    languages = [\"tamil\", \"hindi\"]\n    select_language = lambda x, y: x[x.language == y]\n\n    fig = make_subplots(rows= 1, cols= 2,\n                        x_title=\"Number of words\", y_title=\"Number of context\")\n    for idx, lang in enumerate(languages):\n        fig.add_trace(\n            go.Histogram(\n                x = list(select_language(train_data, lang).num_tokens),\n                name = lang.upper()\n            ),\n            row = 1,\n            col = idx + 1,\n        )\n    fig.update_layout(title=\"Distribution of Sequence length\", title_x=0.5)\n    fig.show()\n    \n    for idx, lang in enumerate(languages):\n        # Find number of distinct tokens\n        words_freq = Counter([word for sample in select_language(train_data, lang)[\"tokens\"] for word in sample])\n        print(\"Number of distinct tokens: \", len(words_freq))\n\n        # Plot top tokens to check if it has more tokens\n        x,y = zip(*words_freq.most_common(60))\n        fig = go.Figure()\n        fig.add_trace(go.Bar(x=x, y=y))\n        fig.update_layout(\n            title=\"Frequent words distribution\",\n            title_x=0.5,\n            xaxis_title=\"Tokens\",\n            yaxis_title=\"Frequency\",\n        )\n        fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:20:58.482368Z","iopub.execute_input":"2021-08-22T08:20:58.48271Z","iopub.status.idle":"2021-08-22T08:20:58.494441Z","shell.execute_reply.started":"2021-08-22T08:20:58.482681Z","shell.execute_reply":"2021-08-22T08:20:58.493399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlmr_train_data = train_data.copy()\nanalyse_tokenizer(\"deepset/xlm-roberta-large-squad2\", xlmr_train_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:20:59.442181Z","iopub.execute_input":"2021-08-22T08:20:59.442581Z","iopub.status.idle":"2021-08-22T08:21:49.016828Z","shell.execute_reply.started":"2021-08-22T08:20:59.442542Z","shell.execute_reply":"2021-08-22T08:21:49.016021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud_create(select_language(xlmr_train_data, \"hindi\"), \"tokens\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:21:49.018633Z","iopub.execute_input":"2021-08-22T08:21:49.019071Z","iopub.status.idle":"2021-08-22T08:21:49.418716Z","shell.execute_reply.started":"2021-08-22T08:21:49.019028Z","shell.execute_reply":"2021-08-22T08:21:49.417761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud_create(select_language(xlmr_train_data, \"tamil\"), \"tokens\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:21:49.420526Z","iopub.execute_input":"2021-08-22T08:21:49.420821Z","iopub.status.idle":"2021-08-22T08:21:49.654853Z","shell.execute_reply.started":"2021-08-22T08:21:49.42078Z","shell.execute_reply":"2021-08-22T08:21:49.654138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"muril_train_data = train_data.copy()\nanalyse_tokenizer(\"google/muril-base-cased\", muril_train_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:21:49.656548Z","iopub.execute_input":"2021-08-22T08:21:49.657165Z","iopub.status.idle":"2021-08-22T08:22:08.571364Z","shell.execute_reply.started":"2021-08-22T08:21:49.657121Z","shell.execute_reply":"2021-08-22T08:22:08.570204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud_create(select_language(muril_train_data, \"tamil\"), \"tokens\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:22:08.573823Z","iopub.execute_input":"2021-08-22T08:22:08.574255Z","iopub.status.idle":"2021-08-22T08:22:08.769895Z","shell.execute_reply.started":"2021-08-22T08:22:08.57421Z","shell.execute_reply":"2021-08-22T08:22:08.769216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud_create(select_language(muril_train_data, \"hindi\"), \"tokens\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:23:33.870369Z","iopub.execute_input":"2021-08-22T08:23:33.870921Z","iopub.status.idle":"2021-08-22T08:23:34.248832Z","shell.execute_reply.started":"2021-08-22T08:23:33.870875Z","shell.execute_reply":"2021-08-22T08:23:34.247779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indicbert_train_data = train_data.copy()\nanalyse_tokenizer(\"ai4bharat/indic-bert\", indicbert_train_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:22:09.174159Z","iopub.execute_input":"2021-08-22T08:22:09.174572Z","iopub.status.idle":"2021-08-22T08:22:47.289814Z","shell.execute_reply.started":"2021-08-22T08:22:09.17453Z","shell.execute_reply":"2021-08-22T08:22:47.288871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud_create(select_language(indicbert_train_data, \"tamil\"), \"tokens\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:22:47.297726Z","iopub.execute_input":"2021-08-22T08:22:47.298104Z","iopub.status.idle":"2021-08-22T08:22:47.562813Z","shell.execute_reply.started":"2021-08-22T08:22:47.298071Z","shell.execute_reply":"2021-08-22T08:22:47.561713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud_create(select_language(indicbert_train_data, \"hindi\"), \"tokens\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:22:47.564598Z","iopub.execute_input":"2021-08-22T08:22:47.565042Z","iopub.status.idle":"2021-08-22T08:22:47.953669Z","shell.execute_reply.started":"2021-08-22T08:22:47.564981Z","shell.execute_reply":"2021-08-22T08:22:47.95295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion\nThough XLM-Roberta have tokens of 100 of languages, it has more tokens than indic-bert trained on Indian languages.\nMuril-bert have context richness but it has more unknown words","metadata":{}}]}