{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport torch\nimport pytorch_lightning as pl\nfrom transformers import AutoConfig, AutoTokenizer, AutoModelForQuestionAnswering\nfrom typing import NamedTuple, Dict, List, Set, Callable, Optional\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-14T08:12:38.499979Z","iopub.execute_input":"2021-11-14T08:12:38.500421Z","iopub.status.idle":"2021-11-14T08:12:38.506416Z","shell.execute_reply.started":"2021-11-14T08:12:38.500373Z","shell.execute_reply":"2021-11-14T08:12:38.505711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nanswer_max_tokens = 14\ntop = 20\nthreshold_factor = 0.1\nstride = 64\nmodel_max_length = 512\ngradient_checkpointing = False\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\npd.set_option(\"use_inf_as_na\", True)\npd.set_option(\"max_info_columns\", 9999)\npd.set_option(\"display.max_columns\", 9999)\npd.set_option(\"display.max_rows\", 9999)\npd.set_option('max_colwidth', 9999)\ntqdm.pandas()\npl.seed_everything(31)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:38.507913Z","iopub.execute_input":"2021-11-14T08:12:38.508359Z","iopub.status.idle":"2021-11-14T08:12:38.520967Z","shell.execute_reply.started":"2021-11-14T08:12:38.508319Z","shell.execute_reply":"2021-11-14T08:12:38.520228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cpu')\nsave_function = torch.save\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n    for i in range(torch.cuda.device_count()):\n        print(f\"{i}: {torch.cuda.get_device_name(i)}\")\n        print('Memory Allocated:\\t', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n        print('Memory Cached:\\t\\t', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\nprint(f\"device={device}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:38.521826Z","iopub.execute_input":"2021-11-14T08:12:38.523886Z","iopub.status.idle":"2021-11-14T08:12:38.534306Z","shell.execute_reply.started":"2021-11-14T08:12:38.523851Z","shell.execute_reply":"2021-11-14T08:12:38.533219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nINPUT = '/kaggle/input/'\nDATA = f\"{INPUT}chaii-hindi-and-tamil-question-answering/\"\nTEMP = '/kaggle/temp/'\nOUTPUT = '/kaggle/working/'\nRESOURCE_DIR = f'{INPUT}d/ruhong/chaii-lib/kaggle-chaii-hindi-and-tamil-qa-1.0/'\nPRETRAINED_DIR = f\"{INPUT}pretrained/pretrained/\"\nmodel_name = \"xlm_roberta_large_10\"\n#model_name = \"deepset_xlmr_squad2\"\ntokenizer_dirs = {\n    \"xlm_roberta\": f\"{PRETRAINED_DIR}xlm-roberta-base\",\n    \"xlm_roberta_large_05\": f\"{PRETRAINED_DIR}xlm-roberta-large\",\n    \"xlm_roberta_large_08\": f\"{PRETRAINED_DIR}xlm-roberta-large\",\n    \"xlm_roberta_large_10\": f\"{PRETRAINED_DIR}xlm-roberta-large\",\n    \"deepset_xlmr_squad2\": f\"{PRETRAINED_DIR}deepset/xlm-roberta-base-squad2\",\n}\nmodel_dirs = {\n    \"xlm_roberta\": f\"{RESOURCE_DIR}models/xlm_roberta/20211029_082207/lightning_logs/version_0/checkpoints\",\n    \"xlm_roberta_large_05\": f\"{RESOURCE_DIR}models/xlm_roberta_large/20211105_085009/trial_0/fold_0/lightning_logs/version_0/checkpoints\",\n    \"xlm_roberta_large_08\": f\"{RESOURCE_DIR}models/xlm_roberta_large/20211108_180312/lightning_logs/version_0/checkpoints\",\n    \"xlm_roberta_large_10\": f\"{RESOURCE_DIR}models/xlm_roberta_large/20211110_082218/lightning_logs/version_0/checkpoints\",\n    \"deepset_xlmr_squad2\": f\"{PRETRAINED_DIR}deepset/xlm-roberta-base-squad2\",\n}\nsys.path.append(f'{INPUT}sgcharts-ml/src')\nsys.path.append(f'{RESOURCE_DIR}src')\nimport mylib\nimport scml\nfrom scml import nlp as snlp","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:38.536192Z","iopub.execute_input":"2021-11-14T08:12:38.536691Z","iopub.status.idle":"2021-11-14T08:12:38.543855Z","shell.execute_reply.started":"2021-11-14T08:12:38.536657Z","shell.execute_reply":"2021-11-14T08:12:38.542958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(tokenizer_dirs[model_name], model_max_length=model_max_length)\ninput_keys = [\"labels\"] + tokenizer.model_input_names\nis_right_padding = tokenizer.padding_side == \"right\"\nprint(f\"{repr(tokenizer)}\\ninput_keys={input_keys}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:38.545889Z","iopub.execute_input":"2021-11-14T08:12:38.546765Z","iopub.status.idle":"2021-11-14T08:12:39.352407Z","shell.execute_reply.started":"2021-11-14T08:12:38.54673Z","shell.execute_reply":"2021-11-14T08:12:39.351578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(model_dirs[model_name])\nconfig.gradient_checkpointing = gradient_checkpointing\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_dirs[model_name], config=config)\nprint(repr(model.config))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:39.356509Z","iopub.execute_input":"2021-11-14T08:12:39.358581Z","iopub.status.idle":"2021-11-14T08:12:46.115958Z","shell.execute_reply.started":"2021-11-14T08:12:39.35852Z","shell.execute_reply":"2021-11-14T08:12:46.115211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(col) -> Callable:\n    def f(row) -> str:\n        return mylib.preprocess(row[col])\n    \n    return f","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:46.117244Z","iopub.execute_input":"2021-11-14T08:12:46.117481Z","iopub.status.idle":"2021-11-14T08:12:46.121623Z","shell.execute_reply.started":"2021-11-14T08:12:46.117449Z","shell.execute_reply":"2021-11-14T08:12:46.120946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(f\"{DATA}test.csv\")\ntest.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:46.122805Z","iopub.execute_input":"2021-11-14T08:12:46.1232Z","iopub.status.idle":"2021-11-14T08:12:46.147261Z","shell.execute_reply.started":"2021-11-14T08:12:46.123167Z","shell.execute_reply":"2021-11-14T08:12:46.146568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = [\"question\", \"context\"]\nfor col in cols:\n    print(f\"Preprocess {col}...\")\n    test[col] = test.progress_apply(preprocess(col), axis=1)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:46.14842Z","iopub.execute_input":"2021-11-14T08:12:46.148834Z","iopub.status.idle":"2021-11-14T08:12:46.185527Z","shell.execute_reply.started":"2021-11-14T08:12:46.148803Z","shell.execute_reply":"2021-11-14T08:12:46.184925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions = test[\"question\"].tolist()\ncontexts = test[\"context\"].tolist()\ns1, s2 = contexts, questions\ntruncation = \"only_first\"\nif is_right_padding:\n    s1, s2 = questions, contexts\n    truncation = \"only_second\"","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:46.187876Z","iopub.execute_input":"2021-11-14T08:12:46.188314Z","iopub.status.idle":"2021-11-14T08:12:46.193337Z","shell.execute_reply.started":"2021-11-14T08:12:46.188283Z","shell.execute_reply":"2021-11-14T08:12:46.19269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nx = tokenizer(\n    s1, \n    s2, \n    truncation=truncation, \n    padding=\"max_length\",\n    stride=stride,\n    return_overflowing_tokens=True,\n    return_offsets_mapping=False,\n    return_special_tokens_mask=True,\n)\nprint(f\"{repr(x.keys())}\\nlen={len(x['input_ids'])}\")\n# all only supports torch.uint8 and torch.bool dtypes\nspecial_tokens_mask = torch.tensor(x.pop(\"special_tokens_mask\"), dtype=torch.uint8)\noverflow_to_sample_mapping = x.pop(\"overflow_to_sample_mapping\")\nprint(f\"len={len(overflow_to_sample_mapping)}, overflow_to_sample_mapping={repr(overflow_to_sample_mapping)}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:46.194636Z","iopub.execute_input":"2021-11-14T08:12:46.195088Z","iopub.status.idle":"2021-11-14T08:12:46.270638Z","shell.execute_reply.started":"2021-11-14T08:12:46.195054Z","shell.execute_reply":"2021-11-14T08:12:46.269921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"batches = torch.utils.data.DataLoader(mylib.Dataset(x), batch_size=batch_size, shuffle=False)\nmodel.eval()\nmodel.to(device)\nstart_logits = None\nend_logits = None\nwith torch.no_grad():\n    for batch in tqdm(batches):\n        for k, v in batch.items():\n            batch[k] = v.to(device)\n        outputs = model(**batch)\n        sl = outputs.start_logits\n        el = outputs.end_logits\n        if start_logits is None:\n            start_logits = sl\n        else:\n            start_logits = torch.cat((start_logits, sl), 0)\n        if end_logits is None:\n            end_logits = el\n        else:\n            end_logits = torch.cat((end_logits, el), 0)\nprint(f\"start_logits={start_logits.size()}, end_logits={end_logits.size()}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:46.271842Z","iopub.execute_input":"2021-11-14T08:12:46.272245Z","iopub.status.idle":"2021-11-14T08:12:46.866742Z","shell.execute_reply.started":"2021-11-14T08:12:46.272211Z","shell.execute_reply":"2021-11-14T08:12:46.865935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = x[\"input_ids\"]\nscores = [-999] * len(questions)\nanswers = [\"\"] * len(questions)\nfor i in tqdm(range(len(start_logits))):\n    q = overflow_to_sample_mapping[i]\n    cs = mylib.candidates(\n        start_logits=start_logits[i],\n        end_logits=end_logits[i],\n        region=mylib.context_region(\n            special_tokens_mask[i].tolist(),\n            is_right_padding=is_right_padding,\n        ),\n        answer_max_tokens=answer_max_tokens,\n        threshold_factor=threshold_factor,\n        top=top,\n    )\n    if len(cs) == 0:\n        continue\n    c = cs[0]\n    if c.score > scores[q]:\n        scores[q] = c.score\n        _ids = input_ids[i][c.start:c.end]\n        tokens = tokenizer.convert_ids_to_tokens(_ids)\n        text = tokenizer.convert_tokens_to_string(tokens)\n        #text = mylib.postprocess(text)\n        answers[q] = text","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:46.868219Z","iopub.execute_input":"2021-11-14T08:12:46.868476Z","iopub.status.idle":"2021-11-14T08:12:49.225806Z","shell.execute_reply.started":"2021-11-14T08:12:46.868442Z","shell.execute_reply":"2021-11-14T08:12:49.225093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(scores)\n#print(end_logits[0])","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:49.227213Z","iopub.execute_input":"2021-11-14T08:12:49.227709Z","iopub.status.idle":"2021-11-14T08:12:49.231674Z","shell.execute_reply.started":"2021-11-14T08:12:49.227672Z","shell.execute_reply":"2021-11-14T08:12:49.230597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(f\"{DATA}sample_submission.csv\", engine=\"c\", low_memory=False)\nsub[\"id\"] = test[\"id\"]\nsub[\"PredictionString\"] = answers","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:49.232983Z","iopub.execute_input":"2021-11-14T08:12:49.233442Z","iopub.status.idle":"2021-11-14T08:12:49.246052Z","shell.execute_reply.started":"2021-11-14T08:12:49.233409Z","shell.execute_reply":"2021-11-14T08:12:49.245311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:49.248829Z","iopub.execute_input":"2021-11-14T08:12:49.249618Z","iopub.status.idle":"2021-11-14T08:12:49.262114Z","shell.execute_reply.started":"2021-11-14T08:12:49.249577Z","shell.execute_reply":"2021-11-14T08:12:49.261216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:49.263394Z","iopub.execute_input":"2021-11-14T08:12:49.263748Z","iopub.status.idle":"2021-11-14T08:12:49.27405Z","shell.execute_reply.started":"2021-11-14T08:12:49.263716Z","shell.execute_reply":"2021-11-14T08:12:49.273164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:49.275429Z","iopub.execute_input":"2021-11-14T08:12:49.27597Z","iopub.status.idle":"2021-11-14T08:12:49.282993Z","shell.execute_reply.started":"2021-11-14T08:12:49.275918Z","shell.execute_reply":"2021-11-14T08:12:49.282306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Debug","metadata":{}},{"cell_type":"code","source":"#!pip list","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:12:49.284071Z","iopub.execute_input":"2021-11-14T08:12:49.284626Z","iopub.status.idle":"2021-11-14T08:12:49.290779Z","shell.execute_reply.started":"2021-11-14T08:12:49.284592Z","shell.execute_reply":"2021-11-14T08:12:49.290009Z"},"trusted":true},"execution_count":null,"outputs":[]}]}