{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport gc \ndevice = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:19:46.765402Z","iopub.execute_input":"2021-10-16T02:19:46.765693Z","iopub.status.idle":"2021-10-16T02:19:46.777841Z","shell.execute_reply.started":"2021-10-16T02:19:46.765633Z","shell.execute_reply":"2021-10-16T02:19:46.77686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall fsspec -qq -y\n!pip uninstall transformers -y\n!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq\n\nimport sys\nsys.path.append(\"../input/transformers-master/src/\")","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:19:46.779567Z","iopub.execute_input":"2021-10-16T02:19:46.780177Z","iopub.status.idle":"2021-10-16T02:19:58.893053Z","shell.execute_reply.started":"2021-10-16T02:19:46.780141Z","shell.execute_reply":"2021-10-16T02:19:58.892108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/sample_submission.csv')\nsub.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:19:58.895439Z","iopub.execute_input":"2021-10-16T02:19:58.895823Z","iopub.status.idle":"2021-10-16T02:19:59.017891Z","shell.execute_reply.started":"2021-10-16T02:19:58.895783Z","shell.execute_reply":"2021-10-16T02:19:59.01715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:19:59.019296Z","iopub.execute_input":"2021-10-16T02:19:59.019561Z","iopub.status.idle":"2021-10-16T02:19:59.830744Z","shell.execute_reply.started":"2021-10-16T02:19:59.019537Z","shell.execute_reply":"2021-10-16T02:19:59.829907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.language.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:19:59.832109Z","iopub.execute_input":"2021-10-16T02:19:59.832509Z","iopub.status.idle":"2021-10-16T02:19:59.843686Z","shell.execute_reply.started":"2021-10-16T02:19:59.832467Z","shell.execute_reply":"2021-10-16T02:19:59.842626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:19:59.845468Z","iopub.execute_input":"2021-10-16T02:19:59.845902Z","iopub.status.idle":"2021-10-16T02:19:59.870487Z","shell.execute_reply.started":"2021-10-16T02:19:59.845864Z","shell.execute_reply":"2021-10-16T02:19:59.869501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:19:59.871832Z","iopub.execute_input":"2021-10-16T02:19:59.872209Z","iopub.status.idle":"2021-10-16T02:19:59.878584Z","shell.execute_reply.started":"2021-10-16T02:19:59.872174Z","shell.execute_reply":"2021-10-16T02:19:59.877402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline\n\nBased on: https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb","metadata":{}},{"cell_type":"code","source":"import transformers","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:19:59.882478Z","iopub.execute_input":"2021-10-16T02:19:59.882854Z","iopub.status.idle":"2021-10-16T02:20:01.280328Z","shell.execute_reply.started":"2021-10-16T02:19:59.88282Z","shell.execute_reply":"2021-10-16T02:20:01.279431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = '../input/chaii-model-0816-2/chaii-bert-trained_knr_alex'\nbatch_size = 200","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:01.282876Z","iopub.execute_input":"2021-10-16T02:20:01.283155Z","iopub.status.idle":"2021-10-16T02:20:01.290103Z","shell.execute_reply.started":"2021-10-16T02:20:01.283129Z","shell.execute_reply":"2021-10-16T02:20:01.289279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:01.291261Z","iopub.execute_input":"2021-10-16T02:20:01.291599Z","iopub.status.idle":"2021-10-16T02:20:06.499702Z","shell.execute_reply.started":"2021-10-16T02:20:01.29156Z","shell.execute_reply":"2021-10-16T02:20:06.498845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 384 # The maximum length of a feature (question and context)\ndoc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:06.501249Z","iopub.execute_input":"2021-10-16T02:20:06.501625Z","iopub.status.idle":"2021-10-16T02:20:06.506795Z","shell.execute_reply.started":"2021-10-16T02:20:06.501576Z","shell.execute_reply":"2021-10-16T02:20:06.505688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:06.508472Z","iopub.execute_input":"2021-10-16T02:20:06.508856Z","iopub.status.idle":"2021-10-16T02:20:07.100066Z","shell.execute_reply.started":"2021-10-16T02:20:06.50882Z","shell.execute_reply":"2021-10-16T02:20:07.099265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_answers(r):\n    start = r[0]\n    text = r[1]\n    return {\n        'answer_start': [start],\n        'text': [text]\n    }","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:07.101406Z","iopub.execute_input":"2021-10-16T02:20:07.101893Z","iopub.status.idle":"2021-10-16T02:20:07.108962Z","shell.execute_reply.started":"2021-10-16T02:20:07.101856Z","shell.execute_reply":"2021-10-16T02:20:07.108115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env WANDB_DISABLED=True","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:07.110146Z","iopub.execute_input":"2021-10-16T02:20:07.110499Z","iopub.status.idle":"2021-10-16T02:20:07.117862Z","shell.execute_reply.started":"2021-10-16T02:20:07.110462Z","shell.execute_reply":"2021-10-16T02:20:07.116844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer, AutoTokenizer, default_data_collator\nargs = TrainingArguments(\n    f\"chaii-qa\",\n    do_eval=False,\n    do_predict=True,\n    dataloader_num_workers=2,\n    per_device_eval_batch_size=batch_size,\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:07.119257Z","iopub.execute_input":"2021-10-16T02:20:07.119752Z","iopub.status.idle":"2021-10-16T02:20:07.836116Z","shell.execute_reply.started":"2021-10-16T02:20:07.119717Z","shell.execute_reply":"2021-10-16T02:20:07.835298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import default_data_collator\nfrom scipy.special import softmax\ndata_collator = default_data_collator\nmax_answer_length = 30\nfrom tqdm.auto import tqdm\n\nclass Prep:\n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n        \n    def prepare_validation_features(self, examples):\n        \n        # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n        # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n        # left whitespace\n        examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n        pad_on_right = self.tokenizer.padding_side == \"right\"\n\n        # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n        # in one example possible giving several features when a context is long, each of those features having a\n        # context that overlaps a bit the context of the previous feature.\n        tokenized_examples = self.tokenizer(\n            examples[\"question\" if pad_on_right else \"context\"],\n            examples[\"context\" if pad_on_right else \"question\"],\n            truncation=\"only_second\" if pad_on_right else \"only_first\",\n            max_length=max_length,\n            stride=doc_stride,\n            return_overflowing_tokens=True,\n            return_offsets_mapping=True,\n            padding=\"max_length\",\n        )\n\n        # Since one example might give us several features if it has a long context, we need a map from a feature to\n        # its corresponding example. This key gives us just that.\n        sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n\n        # We keep the example_id that gave us this feature and we will store the offset mappings.\n        tokenized_examples[\"example_id\"] = []\n\n        for i in range(len(tokenized_examples[\"input_ids\"])):\n            # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n            sequence_ids = tokenized_examples.sequence_ids(i)\n            context_index = 1 if pad_on_right else 0\n\n            # One example can give several spans, this is the index of the example containing this span of text.\n            sample_index = sample_mapping[i]\n            tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n\n            # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n            # position is part of the context or not.\n            tokenized_examples[\"offset_mapping\"][i] = [\n                (o if sequence_ids[k] == context_index else None)\n                for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n            ]\n\n        return tokenized_examples\n\n    def postprocess_qa_predictions(self, examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n        all_start_logits, all_end_logits = raw_predictions\n        #all_start_logits = expit(all_start_logits)\n        #all_end_logits = expit(all_end_logits)\n        # Build a map example to its corresponding features.\n        example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n        features_per_example = collections.defaultdict(list)\n        for i, feature in enumerate(features):\n            features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n\n        # The dictionaries we have to fill.\n        predictions = collections.OrderedDict()\n\n        # Logging.\n        print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n\n        #ta_stemmer = TamilStemmer()\n\n        # Let's loop over all the examples!\n        for example_index, example in enumerate(tqdm(examples)):\n            # Those are the indices of the features associated to the current example.\n            feature_indices = features_per_example[example_index]\n\n            min_null_score = None # Only used if squad_v2 is True.\n            valid_answers = []\n\n            context = example[\"context\"]\n            start_flgs = np.ones(len(context)) * (-100)\n            end_flgs = np.ones(len(context)) * (-100)\n            # Looping through all the features associated to the current example.\n            for feature_index in feature_indices:\n                # We grab the predictions of the model for this feature.\n                start_logits = all_start_logits[feature_index]\n                end_logits = all_end_logits[feature_index]\n                # This is what will allow us to map some the positions in our logits to span of texts in the original\n                # context.\n                offset_mapping = features[feature_index][\"offset_mapping\"]\n\n                # Update minimum null prediction.\n                cls_index = features[feature_index][\"input_ids\"].index(self.tokenizer.cls_token_id)\n                feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n                if min_null_score is None or min_null_score < feature_null_score:\n                    min_null_score = feature_null_score\n\n                for i, offset in enumerate(offset_mapping):\n                    if offset is not None:\n                        start_flgs[offset[0]:offset[1]] = start_flgs[offset[0]:offset[1]].clip(start_logits[i], None)\n                        end_flgs[offset[0]:offset[1]] = end_flgs[offset[0]:offset[1]].clip(end_logits[i], None)\n\n\n            best_answer = {\"start_logits\": softmax(start_flgs), \"end_logits\": softmax(end_flgs)}\n\n            # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n            for k, v in example.items():\n                if k not in best_answer:\n                    best_answer[k] = v\n\n            predictions[example[\"id\"]] = best_answer#[\"text\"]#text#best_answer[\"text\"]\n\n        return predictions\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:07.837471Z","iopub.execute_input":"2021-10-16T02:20:07.837842Z","iopub.status.idle":"2021-10-16T02:20:07.855702Z","shell.execute_reply.started":"2021-10-16T02:20:07.837805Z","shell.execute_reply":"2021-10-16T02:20:07.854636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\nimport collections\n\ntest_dataset = Dataset.from_pandas(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:07.857374Z","iopub.execute_input":"2021-10-16T02:20:07.858082Z","iopub.status.idle":"2021-10-16T02:20:07.882907Z","shell.execute_reply.started":"2021-10-16T02:20:07.858043Z","shell.execute_reply":"2021-10-16T02:20:07.882187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_checkpoint = '../input/exp25/chaii/mrm8488_bert-multi-cased-finedtuned-xquad-tydiqa-goldp_exp25/'\n\npaths = [\n    '../input/chaii-model-0816/chaii-bert-trained_knr_gtrain/chaii-bert-trained_knr_gtrain',\n    \n    '../input/exp78-exp79/chaii/deepset_xlm-roberta-large-squad2_exp78',\n    '../input/exp78-exp79/chaii/AlexKay_xlm-roberta-large-qa-multilingual-finedtuned-ru_exp78',\n    '../input/exp78-exp79/chaii/deepset_xlm-roberta-large-squad2_exp79',\n    '../input/exp78-exp79/chaii/AlexKay_xlm-roberta-large-qa-multilingual-finedtuned-ru_exp79',\n    \n    '../input/exp32-exp33-seed1/chaii/deepset_xlm-roberta-large-squad2_exp32',\n    '../input/exp32-exp33-seed1/chaii/AlexKay_xlm-roberta-large-qa-multilingual-finedtuned-ru_exp32',\n        ]\ntokenizer = AutoTokenizer.from_pretrained(paths[0])\nmodel = AutoModelForQuestionAnswering.from_pretrained(paths[0])\n\n\nprep = Prep(tokenizer)\ntest_features = test_dataset.map(\n    prep.prepare_validation_features,\n    batched=True,\n    remove_columns=test_dataset.column_names\n)\ntest_feats_small = test_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\n\npred = [0, 0]\n\nfor path in paths:\n    print(path)\n    checkpoint = torch.load(os.path.join(path, 'pytorch_model.bin'))\n    model.load_state_dict(checkpoint)\n    model.eval()\n    model = model.to(device)\n    trainer = Trainer(\n        model,\n        args,\n        data_collator=data_collator,\n        tokenizer=tokenizer,\n    )\n\n    test_predictions = trainer.predict(test_feats_small)\n    \n    pred[0] += test_predictions.predictions[0] / len(paths)\n    pred[1] += test_predictions.predictions[1] / len(paths)\n    \ntest_features.set_format(type=test_features.format[\"type\"], columns=list(test_features.features.keys()))\nfinal_test_predictions_tkm_xlm = prep.postprocess_qa_predictions(test_dataset, test_features, pred)\n\ndel test_features, model, trainer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:20:07.884087Z","iopub.execute_input":"2021-10-16T02:20:07.884458Z","iopub.status.idle":"2021-10-16T02:23:15.926701Z","shell.execute_reply.started":"2021-10-16T02:20:07.884424Z","shell.execute_reply":"2021-10-16T02:23:15.925452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_checkpoint = '../input/exp25/chaii/mrm8488_bert-multi-cased-finedtuned-xquad-tydiqa-goldp_exp25/'\n\npaths = [\n    '../input/exp32-exp33-rem-info/chaii/google_rembert_exp32',\n    '../input/exp32-exp33-rem-info/chaii/google_rembert_exp33',\n    '../input/exp32-exp33-seed1/chaii/google_rembert_exp32',\n        ]\ntokenizer = AutoTokenizer.from_pretrained(paths[0])\nprep = Prep(tokenizer)\ntest_features = test_dataset.map(\n    prep.prepare_validation_features,\n    batched=True,\n    remove_columns=test_dataset.column_names\n)\ntest_feats_small = test_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\n\npred = [0, 0]\n\nfor path in paths:\n    print(path)\n    \n    model = AutoModelForQuestionAnswering.from_pretrained(path)\n\n    model.to(device)\n    model.eval()\n    trainer = Trainer(\n        model,\n        args,\n        data_collator=data_collator,\n        tokenizer=tokenizer,\n    )\n\n    test_predictions = trainer.predict(test_feats_small)\n    \n    pred[0] += test_predictions.predictions[0] / len(paths)\n    pred[1] += test_predictions.predictions[1] / len(paths)\n    \ntest_features.set_format(type=test_features.format[\"type\"], columns=list(test_features.features.keys()))\nfinal_test_predictions_tkm_rem = prep.postprocess_qa_predictions(test_dataset, test_features, pred)\n\ndel test_features, model, trainer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:23:15.928235Z","iopub.execute_input":"2021-10-16T02:23:15.928675Z","iopub.status.idle":"2021-10-16T02:25:02.42259Z","shell.execute_reply.started":"2021-10-16T02:23:15.928624Z","shell.execute_reply":"2021-10-16T02:25:02.421775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_checkpoint = '../input/exp25/chaii/mrm8488_bert-multi-cased-finedtuned-xquad-tydiqa-goldp_exp25/'\n\npaths = [\n    '../input/exp32-exp33-muril/chaii/google_muril-large-cased_exp32',\n    '../input/exp32-exp33-muril/chaii/google_muril-large-cased_exp33',\n        ]\ntokenizer = AutoTokenizer.from_pretrained(paths[0])\nprep = Prep(tokenizer)\ntest_features = test_dataset.map(\n    prep.prepare_validation_features,\n    batched=True,\n    remove_columns=test_dataset.column_names\n)\ntest_feats_small = test_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\n\npred = [0, 0]\n\nfor path in paths:\n    print(path)\n    \n    model = AutoModelForQuestionAnswering.from_pretrained(path)\n\n    model.to(device)\n    model.eval()\n    trainer = Trainer(\n        model,\n        args,\n        data_collator=data_collator,\n        tokenizer=tokenizer,\n    )\n\n    test_predictions = trainer.predict(test_feats_small)\n    w = 2 if '_exp32' in path else 1\n    pred[0] += test_predictions.predictions[0] * w / 3\n    pred[1] += test_predictions.predictions[1] * w / 3\n    print('w =', w)\n    \ntest_features.set_format(type=test_features.format[\"type\"], columns=list(test_features.features.keys()))\nfinal_test_predictions_tkm_mul = prep.postprocess_qa_predictions(test_dataset, test_features, pred)\n\ndel test_features, model, trainer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:31:11.346704Z","iopub.execute_input":"2021-10-16T02:31:11.347067Z","iopub.status.idle":"2021-10-16T02:31:59.372997Z","shell.execute_reply.started":"2021-10-16T02:31:11.347035Z","shell.execute_reply":"2021-10-16T02:31:59.371932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_checkpoint = '../input/exp25/chaii/mrm8488_bert-multi-cased-finedtuned-xquad-tydiqa-goldp_exp25/'\n\npaths = [\n    '../input/exp32-exp33-rem-info/chaii/microsoft_infoxlm-large_exp32',\n    '../input/exp32-exp33-rem-info/chaii/microsoft_infoxlm-large_exp33',\n    '../input/exp32-exp33-seed1/chaii/microsoft_infoxlm-large_exp32',\n        ]\ntokenizer = AutoTokenizer.from_pretrained(paths[0])\nprep = Prep(tokenizer)\ntest_features = test_dataset.map(\n    prep.prepare_validation_features,\n    batched=True,\n    remove_columns=test_dataset.column_names\n)\ntest_feats_small = test_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\n\npred = [0, 0]\n\nfor path in paths:\n    print(path)\n    \n    model = AutoModelForQuestionAnswering.from_pretrained(path)\n\n    model.to(device)\n    model.eval()\n    trainer = Trainer(\n        model,\n        args,\n        data_collator=data_collator,\n        tokenizer=tokenizer,\n    )\n\n    test_predictions = trainer.predict(test_feats_small)\n    \n    pred[0] += test_predictions.predictions[0] / len(paths)\n    pred[1] += test_predictions.predictions[1] / len(paths)\n    \ntest_features.set_format(type=test_features.format[\"type\"], columns=list(test_features.features.keys()))\nfinal_test_predictions_tkm_info = prep.postprocess_qa_predictions(test_dataset, test_features, pred)\n\ndel test_features, model, trainer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:27:09.333293Z","iopub.execute_input":"2021-10-16T02:27:09.333551Z","iopub.status.idle":"2021-10-16T02:28:49.210624Z","shell.execute_reply.started":"2021-10-16T02:27:09.333519Z","shell.execute_reply":"2021-10-16T02:28:49.209861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"starts = []\nends = []\nfor id_ in tqdm(test['id'].values):\n    start_logit = (final_test_predictions_tkm_xlm[id_]['start_logits'] * 2.2\n                  + final_test_predictions_tkm_rem[id_]['start_logits'] * 1.7\n                  + final_test_predictions_tkm_info[id_]['start_logits'] * 0.3\n                  + final_test_predictions_tkm_mul[id_]['start_logits'] * 1.2\n                  ) / 4.2\n    start_logit += np.arange(start_logit.shape[0])[::-1] * 1.e-10\n    end_logit = (final_test_predictions_tkm_xlm[id_]['end_logits'] * 2.2\n                  + final_test_predictions_tkm_rem[id_]['end_logits'] * 1.7\n                  + final_test_predictions_tkm_info[id_]['end_logits'] * 0.3\n                 + final_test_predictions_tkm_mul[id_]['end_logits'] * 1.2\n                  ) / 4.2\n    end_logit += np.arange(end_logit.shape[0]) * 1.e-10\n    \n    idx, score = max((\n                 ((i, j), start_logit[i] + end_logit[j]) \n                 for i in np.argsort(start_logit)[-20:] \n                 for j in np.argsort(end_logit)[-20:] if i <= j and j - i <= 100\n                ), key=lambda x: x[1])\n    starts.append(idx[0])\n    ends.append(idx[1] + 1)\n    \ntest['start'] = starts\ntest['end'] = ends\ntest['text'] = test.apply(lambda x: x.context[x.start:x.end], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:28:49.212403Z","iopub.execute_input":"2021-10-16T02:28:49.212775Z","iopub.status.idle":"2021-10-16T02:28:49.369327Z","shell.execute_reply.started":"2021-10-16T02:28:49.2127Z","shell.execute_reply":"2021-10-16T02:28:49.368305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nbad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\nbad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n\naaa = [\"கி.பி\",  \n        \"கி.மு\",\n        \"கி.மீ\",\n         \"ई\",\n        \"ई.पू\",\n\"वी.एन\",\n\"कि.मी\",\n      ]\ndeg = '|'.join(aaa)\n\ndef postproc(data):\n    text = data['text']\n    text = text.replace('\\n', '').strip()\n    for s in '()-':\n        text = text.strip(s).strip()\n    text = re.sub('[\\(\\)]', ' ', text)\n    if re.match('^[०१२३४५६७८९]+$', text) is not None:\n        text_ = str(text)\n        for i, s in enumerate('०१२३४५६७८९'):\n            text_ = text_.replace(s, f'{i}')\n        if text_ in data['context']:\n            text = text_\n\n    data['text'] = text\n    return data\n\ndef postproc2(data):\n    pred = data['text']\n    context  = data['context']\n    if pred == \"\":\n        return data\n    while any([pred.startswith(y) for y in bad_starts]):\n        pred = pred[1:]\n    while any([pred.endswith(y) for y in bad_endings]):\n        if pred.endswith(\"...\"):\n            pred = pred[:-3]\n        else:\n            pred = pred[:-1]\n    \n        \n    if re.search(f'({deg})$', pred) is not None and pred + \".\" in context:\n        pred = pred+\".\"\n\n    if pred[-7:] == 'கி.மீ.2':\n        pred = pred[:-1]\n    #if pred[-5:] == 'கிமீ²':\n    #    pred = pred[:-1]\n        \n    pred = re.sub('^0-', '', pred)\n\n    data['text'] = pred\n    return data\n\ntest['PredictionString'] = test.apply(lambda x: postproc2(postproc(x)).text, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:28:49.370804Z","iopub.execute_input":"2021-10-16T02:28:49.371177Z","iopub.status.idle":"2021-10-16T02:28:49.386173Z","shell.execute_reply.started":"2021-10-16T02:28:49.37114Z","shell.execute_reply":"2021-10-16T02:28:49.38515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = test[['id', 'PredictionString']]\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2021-10-16T02:28:49.387382Z","iopub.execute_input":"2021-10-16T02:28:49.387737Z","iopub.status.idle":"2021-10-16T02:28:49.4176Z","shell.execute_reply.started":"2021-10-16T02:28:49.387699Z","shell.execute_reply":"2021-10-16T02:28:49.416877Z"},"trusted":true},"execution_count":null,"outputs":[]}]}