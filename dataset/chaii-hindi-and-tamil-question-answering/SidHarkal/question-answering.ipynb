{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os,gc,re\nimport warnings\nimport sys\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.ticker as ticker\nfrom sklearn.model_selection import train_test_split\nimport unicodedata\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2021-09-11T14:57:21.143132Z","iopub.execute_input":"2021-09-11T14:57:21.143492Z","iopub.status.idle":"2021-09-11T14:57:26.173299Z","shell.execute_reply.started":"2021-09-11T14:57:21.143463Z","shell.execute_reply":"2021-09-11T14:57:26.172451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/chaii-hindi-and-tamil-question-answering/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/chaii-hindi-and-tamil-question-answering/test.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T14:57:29.532991Z","iopub.execute_input":"2021-09-11T14:57:29.533434Z","iopub.status.idle":"2021-09-11T14:57:30.04593Z","shell.execute_reply.started":"2021-09-11T14:57:29.533389Z","shell.execute_reply":"2021-09-11T14:57:30.045126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T14:57:31.930277Z","iopub.execute_input":"2021-09-11T14:57:31.930592Z","iopub.status.idle":"2021-09-11T14:57:31.941344Z","shell.execute_reply.started":"2021-09-11T14:57:31.930564Z","shell.execute_reply":"2021-09-11T14:57:31.940505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T14:57:35.515826Z","iopub.execute_input":"2021-09-11T14:57:35.516161Z","iopub.status.idle":"2021-09-11T14:57:35.535475Z","shell.execute_reply.started":"2021-09-11T14:57:35.516115Z","shell.execute_reply":"2021-09-11T14:57:35.534414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"training data size \",train.shape[0])\nprint(\"testing data size \",test.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T14:57:37.760042Z","iopub.execute_input":"2021-09-11T14:57:37.760391Z","iopub.status.idle":"2021-09-11T14:57:37.768593Z","shell.execute_reply.started":"2021-09-11T14:57:37.760359Z","shell.execute_reply":"2021-09-11T14:57:37.767538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.countplot(data=train, x=\"language\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T14:57:40.424473Z","iopub.execute_input":"2021-09-11T14:57:40.424805Z","iopub.status.idle":"2021-09-11T14:57:40.551436Z","shell.execute_reply.started":"2021-09-11T14:57:40.424776Z","shell.execute_reply":"2021-09-11T14:57:40.550652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,7))\nsns.histplot(train,kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T14:57:42.395878Z","iopub.execute_input":"2021-09-11T14:57:42.396218Z","iopub.status.idle":"2021-09-11T14:57:43.053369Z","shell.execute_reply.started":"2021-09-11T14:57:42.396187Z","shell.execute_reply":"2021-09-11T14:57:43.052579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unicode_to_ascii(s):\n    text = s.encode('utf-8').decode('utf-8')\n    return text\n\n\ndef preprocess_sentence(w):\n    w = unicode_to_ascii(w.lower().strip())\n\n    # creating a space between a word and the punctuation following it\n    w = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", w)\n    w = re.sub(r'[\" \"]+', \" \", w)\n\n    w = w.strip()\n    return w\n\n\nquestions = []\nanswers = []\nfor ques,ans in zip(train['question'],train['answer_text']):\n    questions.append(preprocess_sentence(ques))\n    answers.append(preprocess_sentence(ans))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:10:22.034685Z","iopub.execute_input":"2021-09-11T15:10:22.034994Z","iopub.status.idle":"2021-09-11T15:10:22.066975Z","shell.execute_reply.started":"2021-09-11T15:10:22.034967Z","shell.execute_reply":"2021-09-11T15:10:22.066239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"questions {questions[100]}\")\nprint(f\"answere {answers[100]}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:10:23.004561Z","iopub.execute_input":"2021-09-11T15:10:23.005201Z","iopub.status.idle":"2021-09-11T15:10:23.015593Z","shell.execute_reply.started":"2021-09-11T15:10:23.00512Z","shell.execute_reply":"2021-09-11T15:10:23.013961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n\n# Define start and end token to indicate the start and end of a sentence\nSTART_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n\nVOCAB_SIZE = tokenizer.vocab_size+2","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:10:26.416321Z","iopub.execute_input":"2021-09-11T15:10:26.416627Z","iopub.status.idle":"2021-09-11T15:10:27.5896Z","shell.execute_reply.started":"2021-09-11T15:10:26.4166Z","shell.execute_reply":"2021-09-11T15:10:27.588744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"encoded question example {tokenizer.encode(questions[100])}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:10:30.375364Z","iopub.execute_input":"2021-09-11T15:10:30.375885Z","iopub.status.idle":"2021-09-11T15:10:30.382907Z","shell.execute_reply.started":"2021-09-11T15:10:30.375838Z","shell.execute_reply":"2021-09-11T15:10:30.381854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 1000\n\ndef tokennize_filter(inputs,outputs):\n    tokenized_inputs,tokenized_output = [],[]\n    for (sen1,sen2) in zip(inputs,outputs):\n        sen1 = START_TOKEN + tokenizer.encode(sen1) + END_TOKEN\n        sen2 = START_TOKEN + tokenizer.encode(sen2) + END_TOKEN\n        if len(sen1)<=MAX_LENGTH and len(sen2) <=MAX_LENGTH:\n            tokenized_inputs.append(sen1)\n            tokenized_output.append(sen2)\n            \n    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs,maxlen=MAX_LENGTH,padding='post')\n    tokenized_output = tf.keras.preprocessing.sequence.pad_sequences(tokenized_output,maxlen=MAX_LENGTH,padding='post')\n    return tokenized_inputs,tokenized_output","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:10:33.182452Z","iopub.execute_input":"2021-09-11T15:10:33.182767Z","iopub.status.idle":"2021-09-11T15:10:33.190098Z","shell.execute_reply.started":"2021-09-11T15:10:33.182738Z","shell.execute_reply":"2021-09-11T15:10:33.189176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions,answers = tokennize_filter(questions,answers)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:10:35.109624Z","iopub.execute_input":"2021-09-11T15:10:35.109933Z","iopub.status.idle":"2021-09-11T15:10:35.236145Z","shell.execute_reply.started":"2021-09-11T15:10:35.109905Z","shell.execute_reply":"2021-09-11T15:10:35.235368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Vocab Size {VOCAB_SIZE}')\nprint(f'Number of samples {len(questions)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:10:56.750645Z","iopub.execute_input":"2021-09-11T15:10:56.75097Z","iopub.status.idle":"2021-09-11T15:10:56.75853Z","shell.execute_reply.started":"2021-09-11T15:10:56.750939Z","shell.execute_reply":"2021-09-11T15:10:56.757526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((\n    {'inputs': questions,\n    'dec_inputs':answers[:,:-1]},\n    {'outputs':answers[:,1:]},))\n\ndataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:12:18.761875Z","iopub.execute_input":"2021-09-11T15:12:18.762216Z","iopub.status.idle":"2021-09-11T15:12:18.785911Z","shell.execute_reply.started":"2021-09-11T15:12:18.762184Z","shell.execute_reply":"2021-09-11T15:12:18.785135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nBUFFER_SIZE = 20000","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:12:05.689577Z","iopub.execute_input":"2021-09-11T15:12:05.689889Z","iopub.status.idle":"2021-09-11T15:12:05.696054Z","shell.execute_reply.started":"2021-09-11T15:12:05.689859Z","shell.execute_reply":"2021-09-11T15:12:05.695179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def attention(query,key,value,mask):\n    qk_matmul = tf.matmul(query,key,transpose_b=True)\n    depth= tf.cast(tf.shape(key)[-1],tf.float32)\n    logits = qk_matmul/tf.math.sqrt(depth)\n\n    if mask is not None:\n        logits += (mask *-1e9)\n        attention_weight = tf.nn.softmax(logits,axis=-1)\n        output = tf.matmul(attention_weight,value)\n\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:13:30.077373Z","iopub.execute_input":"2021-09-11T15:13:30.077689Z","iopub.status.idle":"2021-09-11T15:13:30.084104Z","shell.execute_reply.started":"2021-09-11T15:13:30.077662Z","shell.execute_reply":"2021-09-11T15:13:30.083227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n\n  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n    super(MultiHeadAttention, self).__init__(name=name)\n    self.num_heads = num_heads\n    self.d_model = d_model\n\n    assert d_model % self.num_heads == 0\n\n    self.depth = d_model // self.num_heads\n\n    self.query_dense = tf.keras.layers.Dense(units=d_model)\n    self.key_dense = tf.keras.layers.Dense(units=d_model)\n    self.value_dense = tf.keras.layers.Dense(units=d_model)\n\n    self.dense = tf.keras.layers.Dense(units=d_model)\n\n  def split_heads(self, inputs, batch_size):\n    inputs = tf.reshape(\n        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n\n  def call(self, inputs):\n    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n    batch_size = tf.shape(query)[0]\n\n    # linear layers\n    query = self.query_dense(query)\n    key = self.key_dense(key)\n    value = self.value_dense(value)\n\n    # split heads\n    query = self.split_heads(query, batch_size)\n    key = self.split_heads(key, batch_size)\n    value = self.split_heads(value, batch_size)\n\n    # scaled dot-product attention\n    scaled_attention = attention(query, key, value, mask)\n\n    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n\n    # concatenation of heads\n    concat_attention = tf.reshape(scaled_attention,\n                                  (batch_size, -1, self.d_model))\n\n    # final linear layer\n    outputs = self.dense(concat_attention)\n\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:14:29.804961Z","iopub.execute_input":"2021-09-11T15:14:29.805312Z","iopub.status.idle":"2021-09-11T15:14:29.815925Z","shell.execute_reply.started":"2021-09-11T15:14:29.805282Z","shell.execute_reply":"2021-09-11T15:14:29.81507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_padding_mask(x):\n    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n    # (batch_size, 1, 1, sequence length)\n    return mask[:, tf.newaxis, tf.newaxis, :]","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:14:55.422788Z","iopub.execute_input":"2021-09-11T15:14:55.423105Z","iopub.status.idle":"2021-09-11T15:14:55.428092Z","shell.execute_reply.started":"2021-09-11T15:14:55.42307Z","shell.execute_reply":"2021-09-11T15:14:55.427277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_look_ahead_mask(x):\n    seq_len = tf.shape(x)[1]\n    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n    padding_mask = create_padding_mask(x)\n    return tf.maximum(look_ahead_mask, padding_mask)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:15:32.190859Z","iopub.execute_input":"2021-09-11T15:15:32.191207Z","iopub.status.idle":"2021-09-11T15:15:32.197898Z","shell.execute_reply.started":"2021-09-11T15:15:32.191173Z","shell.execute_reply":"2021-09-11T15:15:32.195972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(tf.keras.layers.Layer):\n  def __init__(self,postion,d_model):\n    super(PositionalEncoding,self).__init__()\n    self.pos_encoding = self.postional_encoding(postion,d_model)\n  def get_angles(self,postion,i,d_model):\n    angles = 1/tf.pow(10000,(2*(i//2))/tf.cast(d_model,dtype=tf.float32))\n    return postion*angles\n  def postional_encoding(self,postion,d_model):\n    angle_rads = self.get_angles(\n        postion = tf.range(postion,dtype=tf.float32)[:,tf.newaxis],\n        i = tf.range(d_model,dtype=tf.float32)[tf.newaxis,:],\n        d_model = d_model\n    )\n    # apply sin to even index in the array\n    sines = tf.math.sin(angle_rads[:, 0::2])\n    # apply cos to odd index in the array\n    cosines = tf.math.cos(angle_rads[:, 1::2])\n\n    pos_encoding = tf.concat([sines, cosines], axis=-1)\n    pos_encoding = pos_encoding[tf.newaxis, ...]\n    return tf.cast(pos_encoding, tf.float32)\n\n    def call(self,inputs):\n      return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            \"pos_encoding\":self.pos_encoding\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:15:55.768915Z","iopub.execute_input":"2021-09-11T15:15:55.769263Z","iopub.status.idle":"2021-09-11T15:15:55.780458Z","shell.execute_reply.started":"2021-09-11T15:15:55.769231Z","shell.execute_reply":"2021-09-11T15:15:55.778245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n  attention = MultiHeadAttention(\n      d_model, num_heads, name=\"attention\")({\n          'query': inputs,\n          'key': inputs,\n          'value': inputs,\n          'mask': padding_mask\n      })\n  attention = tf.keras.layers.Dropout(rate=0.3)(attention)\n  attention = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(inputs + attention)\n\n  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n  outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention + outputs)\n\n  return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:16:12.524429Z","iopub.execute_input":"2021-09-11T15:16:12.524745Z","iopub.status.idle":"2021-09-11T15:16:12.532609Z","shell.execute_reply.started":"2021-09-11T15:16:12.524717Z","shell.execute_reply":"2021-09-11T15:16:12.531473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder(vocab_size,num_layers,units,d_model,num_heads,dropout,name='encoder'):\n  inputs = tf.keras.Input(shape=(None,),name='inputs')\n  padding_mask = tf.keras.Input(shape=(1,1,None),name='padding_mask')\n  \n  embeddings = tf.keras.layers.Embedding(vocab_size,d_model)(inputs)\n  embeddings *= tf.math.sqrt(tf.cast(d_model,tf.float32))\n  embeddings = PositionalEncoding(vocab_size,d_model)(embeddings)\n\n  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n  for i in range(num_layers):\n    outputs = encoder_layer(\n        units=units,\n        d_model=d_model,\n        num_heads=num_heads,\n        dropout=dropout,\n        name=\"encoder_layer_{}\".format(i),\n    )([outputs, padding_mask])\n  return tf.keras.Model(\n      inputs=[inputs,padding_mask],outputs=outputs,name=name\n  )","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:16:25.351619Z","iopub.execute_input":"2021-09-11T15:16:25.35193Z","iopub.status.idle":"2021-09-11T15:16:25.359756Z","shell.execute_reply.started":"2021-09-11T15:16:25.351901Z","shell.execute_reply":"2021-09-11T15:16:25.358474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n  \n  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n  \n  look_ahead_mask = tf.keras.Input(\n      shape=(1, None, None), name=\"look_ahead_mask\")\n  \n  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n\n  attention1 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_1\")(inputs={\n          'query': inputs,\n          'key': inputs,\n          'value': inputs,\n          'mask': look_ahead_mask\n      })\n  attention1 = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention1 + inputs)\n\n  attention2 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_2\")(inputs={\n          'query': attention1,\n          'key': enc_outputs,\n          'value': enc_outputs,\n          'mask': padding_mask\n      })\n  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n\n  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n\n  return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],outputs=outputs,name=name)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:19:07.362111Z","iopub.execute_input":"2021-09-11T15:19:07.362465Z","iopub.status.idle":"2021-09-11T15:19:07.374051Z","shell.execute_reply.started":"2021-09-11T15:19:07.362435Z","shell.execute_reply":"2021-09-11T15:19:07.372068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decoder(vocab_size,num_layers,units,d_model,num_heads,dropout,name='decoder'):\n    \n    inputs = tf.keras.Input(shape=(None,), name='inputs')\n    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n  \n    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n\n    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n    for i in range(num_layers):\n        outputs = decoder_layer(units=units,d_model=d_model,num_heads=num_heads,dropout=dropout,name='decoder_layer_{}'.format(i),)(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n\n    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],outputs=outputs,name=name)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:18:36.439062Z","iopub.execute_input":"2021-09-11T15:18:36.439414Z","iopub.status.idle":"2021-09-11T15:18:36.447554Z","shell.execute_reply.started":"2021-09-11T15:18:36.439385Z","shell.execute_reply":"2021-09-11T15:18:36.44651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transformer(vocab_size,num_layers,units,d_model,num_heads,dropout,name=\"transformer\"):\n    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n\n    enc_padding_mask = tf.keras.layers.Lambda(create_padding_mask, output_shape=(1, 1, None),name='enc_padding_mask')(inputs)\n\n    # mask the future tokens for decoder inputs at the 1st attention block\n    look_ahead_mask = tf.keras.layers.Lambda(create_look_ahead_mask,output_shape=(1, None, None),name='look_ahead_mask')(dec_inputs)\n\n    # mask the encoder outputs for the 2nd attention block\n    dec_padding_mask = tf.keras.layers.Lambda(create_padding_mask, output_shape=(1, 1, None),name='dec_padding_mask')(inputs)\n\n    enc_outputs = encoder(vocab_size=vocab_size,num_layers=num_layers,units=units,d_model=d_model,num_heads=num_heads,dropout=dropout)(inputs=[inputs, enc_padding_mask])\n\n    dec_outputs = decoder(vocab_size=vocab_size,num_layers=num_layers,units=units,d_model=d_model,num_heads=num_heads,dropout=dropout,)(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n\n    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n\n    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:21:27.242003Z","iopub.execute_input":"2021-09-11T15:21:27.242372Z","iopub.status.idle":"2021-09-11T15:21:27.251249Z","shell.execute_reply.started":"2021-09-11T15:21:27.24234Z","shell.execute_reply":"2021-09-11T15:21:27.249995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#choosing hyperparameter\nNUM_LAYERS = 2\nD_MODEL = 256\nNUM_HEADS = 8\nUNITS = 512\nDROPOUT = 0.2\n\nmodel = transformer(vocab_size=VOCAB_SIZE,num_layers=NUM_LAYERS,units=UNITS,d_model=D_MODEL,num_heads=NUM_HEADS,dropout=DROPOUT)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:22:05.368283Z","iopub.execute_input":"2021-09-11T15:22:05.368603Z","iopub.status.idle":"2021-09-11T15:22:07.967751Z","shell.execute_reply.started":"2021-09-11T15:22:05.368576Z","shell.execute_reply":"2021-09-11T15:22:07.966871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_function(y_true, y_pred):\n    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n  \n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(y_true, y_pred)\n\n    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n    loss = tf.multiply(loss, mask)\n\n    return tf.reduce_mean(loss)\n\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n\n    def __init__(self, d_model, warmup_steps=4000):\n        super(CustomSchedule, self).__init__()\n\n        self.d_model = d_model\n        self.d_model = tf.cast(self.d_model, tf.float32)\n\n        self.warmup_steps = warmup_steps\n\n    def __call__(self, step):\n        arg1 = tf.math.rsqrt(step)\n        arg2 = step * (self.warmup_steps**-1.5)\n\n        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:23:21.365914Z","iopub.execute_input":"2021-09-11T15:23:21.366264Z","iopub.status.idle":"2021-09-11T15:23:21.376948Z","shell.execute_reply.started":"2021-09-11T15:23:21.36623Z","shell.execute_reply":"2021-09-11T15:23:21.375834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = CustomSchedule(D_MODEL)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n\ndef accuracy(y_true, y_pred):\n    # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:23:53.10008Z","iopub.execute_input":"2021-09-11T15:23:53.100438Z","iopub.status.idle":"2021-09-11T15:23:53.108649Z","shell.execute_reply.started":"2021-09-11T15:23:53.100409Z","shell.execute_reply":"2021-09-11T15:23:53.10763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:24:23.810437Z","iopub.execute_input":"2021-09-11T15:24:23.810759Z","iopub.status.idle":"2021-09-11T15:24:23.827104Z","shell.execute_reply.started":"2021-09-11T15:24:23.81073Z","shell.execute_reply":"2021-09-11T15:24:23.826233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(dataset, epochs=1000)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:24:36.504599Z","iopub.execute_input":"2021-09-11T15:24:36.504911Z","iopub.status.idle":"2021-09-11T15:28:44.430203Z","shell.execute_reply.started":"2021-09-11T15:24:36.504884Z","shell.execute_reply":"2021-09-11T15:28:44.429394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(sentence,model):\n  sentence = preprocess_sentence(sentence)\n\n  sentence = tf.expand_dims(\n      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n\n  output = tf.expand_dims(START_TOKEN, 0)\n\n  for i in range(MAX_LENGTH):\n    predictions = model(inputs=[sentence, output], training=False)\n\n    # select the last word from the seq_len dimension\n    predictions = predictions[:, -1:, :]\n    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n\n    # return the result if the predicted_id is equal to the end token\n    if tf.equal(predicted_id, END_TOKEN[0]):\n      break\n\n    # concatenated the predicted_id to the output which is given to the decoder\n    # as its input.\n    output = tf.concat([output, predicted_id], axis=-1)\n\n  return tf.squeeze(output, axis=0)\n\n\ndef predict(sentence,model):\n  prediction = evaluate(sentence,model)\n\n  predicted_sentence = tokenizer.decode(\n      [i for i in prediction if i < tokenizer.vocab_size])\n\n  print('Input: {}'.format(sentence))\n  print('Output: {}'.format(predicted_sentence))\n\n  return predicted_sentence","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:28:55.970246Z","iopub.execute_input":"2021-09-11T15:28:55.970566Z","iopub.status.idle":"2021-09-11T15:28:55.980768Z","shell.execute_reply.started":"2021-09-11T15:28:55.970539Z","shell.execute_reply":"2021-09-11T15:28:55.978387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/sample_submission.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:28:58.376571Z","iopub.execute_input":"2021-09-11T15:28:58.376902Z","iopub.status.idle":"2021-09-11T15:28:58.401006Z","shell.execute_reply.started":"2021-09-11T15:28:58.376872Z","shell.execute_reply":"2021-09-11T15:28:58.400059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = test[\"question\"]\nquestions=[]\nfor ques in question:\n    questions.append(preprocess_sentence(ques))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:29:00.636908Z","iopub.execute_input":"2021-09-11T15:29:00.637243Z","iopub.status.idle":"2021-09-11T15:29:00.641865Z","shell.execute_reply.started":"2021-09-11T15:29:00.637209Z","shell.execute_reply":"2021-09-11T15:29:00.640753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = []\nfor idx in range(len(question)):\n    pred = predict(question[idx],model)\n    test_preds.append(pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:29:02.008767Z","iopub.execute_input":"2021-09-11T15:29:02.009108Z","iopub.status.idle":"2021-09-11T15:29:02.487663Z","shell.execute_reply.started":"2021-09-11T15:29:02.009077Z","shell.execute_reply":"2021-09-11T15:29:02.486852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['PredictionString'] = test_preds\nsub[['id','PredictionString']].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:29:10.010863Z","iopub.execute_input":"2021-09-11T15:29:10.011202Z","iopub.status.idle":"2021-09-11T15:29:10.022477Z","shell.execute_reply.started":"2021-09-11T15:29:10.011167Z","shell.execute_reply":"2021-09-11T15:29:10.021557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[['id','PredictionString']].to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T15:29:14.573497Z","iopub.execute_input":"2021-09-11T15:29:14.57382Z","iopub.status.idle":"2021-09-11T15:29:14.58238Z","shell.execute_reply.started":"2021-09-11T15:29:14.573794Z","shell.execute_reply":"2021-09-11T15:29:14.581559Z"},"trusted":true},"execution_count":null,"outputs":[]}]}