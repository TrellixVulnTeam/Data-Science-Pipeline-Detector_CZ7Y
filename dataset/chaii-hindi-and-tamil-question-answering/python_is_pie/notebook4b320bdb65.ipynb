{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-11T08:59:13.686215Z","iopub.execute_input":"2021-09-11T08:59:13.686958Z","iopub.status.idle":"2021-09-11T08:59:13.782696Z","shell.execute_reply.started":"2021-09-11T08:59:13.686842Z","shell.execute_reply":"2021-09-11T08:59:13.781758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow\n!pip install tensorflow-datasets","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:13.784402Z","iopub.execute_input":"2021-09-11T08:59:13.784756Z","iopub.status.idle":"2021-09-11T08:59:28.764862Z","shell.execute_reply.started":"2021-09-11T08:59:13.784719Z","shell.execute_reply":"2021-09-11T08:59:28.76403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_datasets as tfds\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom sklearn.model_selection import train_test_split\n\nimport unicodedata\nimport re\nimport io\nimport pandas as pd \nimport numpy as np\nimport time\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:28.768088Z","iopub.execute_input":"2021-09-11T08:59:28.768311Z","iopub.status.idle":"2021-09-11T08:59:34.272352Z","shell.execute_reply.started":"2021-09-11T08:59:28.768284Z","shell.execute_reply":"2021-09-11T08:59:34.271564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_dataset = \"/kaggle/input/chaii-hindi-and-tamil-question-answering/train.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:34.273458Z","iopub.execute_input":"2021-09-11T08:59:34.273721Z","iopub.status.idle":"2021-09-11T08:59:34.277288Z","shell.execute_reply.started":"2021-09-11T08:59:34.273691Z","shell.execute_reply":"2021-09-11T08:59:34.276552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(path_to_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:34.279548Z","iopub.execute_input":"2021-09-11T08:59:34.280089Z","iopub.status.idle":"2021-09-11T08:59:34.973208Z","shell.execute_reply.started":"2021-09-11T08:59:34.280052Z","shell.execute_reply":"2021-09-11T08:59:34.972452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:34.974307Z","iopub.execute_input":"2021-09-11T08:59:34.975168Z","iopub.status.idle":"2021-09-11T08:59:34.999836Z","shell.execute_reply.started":"2021-09-11T08:59:34.975136Z","shell.execute_reply":"2021-09-11T08:59:34.999083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to convert unicode to ascii\ndef unicode_to_ascii(s):\n    text = s.encode('utf-8').decode('utf-8')\n    return text\n#preprcessing with turning specific characters\ndef preprocess_sentence(w):\n    w = unicode_to_ascii(w.lower().strip())\n\n    # creating a space between a word and the punctuation following it\n    w = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", w)\n    w = re.sub(r'[\" \"]+', \" \", w)\n\n    w = w.strip()\n    return w","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:35.001169Z","iopub.execute_input":"2021-09-11T08:59:35.001425Z","iopub.status.idle":"2021-09-11T08:59:35.008457Z","shell.execute_reply.started":"2021-09-11T08:59:35.001392Z","shell.execute_reply":"2021-09-11T08:59:35.007842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = df[\"question\"]\nanswer = df['answer_text']","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:35.009607Z","iopub.execute_input":"2021-09-11T08:59:35.00991Z","iopub.status.idle":"2021-09-11T08:59:35.016805Z","shell.execute_reply.started":"2021-09-11T08:59:35.009861Z","shell.execute_reply":"2021-09-11T08:59:35.016131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions=[]\nanswers=[]\nfor ques,ans in zip(question,answer):\n    questions.append(preprocess_sentence(ques))\n    answers.append(preprocess_sentence(ans))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:35.018217Z","iopub.execute_input":"2021-09-11T08:59:35.018503Z","iopub.status.idle":"2021-09-11T08:59:35.049626Z","shell.execute_reply.started":"2021-09-11T08:59:35.018467Z","shell.execute_reply":"2021-09-11T08:59:35.048871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"questions {questions[10]}\")\nprint(f\"answere {answers[10]}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:35.050583Z","iopub.execute_input":"2021-09-11T08:59:35.050814Z","iopub.status.idle":"2021-09-11T08:59:35.055566Z","shell.execute_reply.started":"2021-09-11T08:59:35.050782Z","shell.execute_reply":"2021-09-11T08:59:35.054913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n\n# Define start and end token to indicate the start and end of a sentence\nSTART_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n\nVOCAB_SIZE = tokenizer.vocab_size+2","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:35.056578Z","iopub.execute_input":"2021-09-11T08:59:35.05744Z","iopub.status.idle":"2021-09-11T08:59:36.226161Z","shell.execute_reply.started":"2021-09-11T08:59:35.057397Z","shell.execute_reply":"2021-09-11T08:59:36.225402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"encoded question example {tokenizer.encode(questions[10])}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:36.227283Z","iopub.execute_input":"2021-09-11T08:59:36.227901Z","iopub.status.idle":"2021-09-11T08:59:36.23316Z","shell.execute_reply.started":"2021-09-11T08:59:36.227849Z","shell.execute_reply":"2021-09-11T08:59:36.232348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#setting maximum length of a sentence\nMAX_LENGTH=100\ndef tokennize_filter(inputs,outputs):\n  tokenized_inputs,tokenized_output = [],[]\n  for (sen1,sen2) in zip(inputs,outputs):\n    sen1 = START_TOKEN + tokenizer.encode(sen1) + END_TOKEN\n    sen2 = START_TOKEN + tokenizer.encode(sen2) + END_TOKEN\n    if len(sen1)<=MAX_LENGTH and len(sen2) <=MAX_LENGTH:\n      tokenized_inputs.append(sen1)\n      tokenized_output.append(sen2)\n  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs,maxlen=MAX_LENGTH,padding='post')\n  tokenized_output = tf.keras.preprocessing.sequence.pad_sequences(tokenized_output,maxlen=MAX_LENGTH,padding='post')\n  return tokenized_inputs,tokenized_output","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:36.234491Z","iopub.execute_input":"2021-09-11T08:59:36.234758Z","iopub.status.idle":"2021-09-11T08:59:36.243391Z","shell.execute_reply.started":"2021-09-11T08:59:36.234723Z","shell.execute_reply":"2021-09-11T08:59:36.242561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions,answers = tokennize_filter(questions,answers)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:36.248856Z","iopub.execute_input":"2021-09-11T08:59:36.2491Z","iopub.status.idle":"2021-09-11T08:59:36.372081Z","shell.execute_reply.started":"2021-09-11T08:59:36.249071Z","shell.execute_reply":"2021-09-11T08:59:36.37139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Vocab Size {VOCAB_SIZE}')\nprint(f'Number of samples {len(questions)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:36.373376Z","iopub.execute_input":"2021-09-11T08:59:36.373611Z","iopub.status.idle":"2021-09-11T08:59:36.378452Z","shell.execute_reply.started":"2021-09-11T08:59:36.37358Z","shell.execute_reply":"2021-09-11T08:59:36.37767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((\n    {\n        'inputs': questions,\n        'dec_inputs':answers[:,:-1]\n    },\n    {\n        'outputs':answers[:,1:]\n    },\n))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:36.379751Z","iopub.execute_input":"2021-09-11T08:59:36.38019Z","iopub.status.idle":"2021-09-11T08:59:37.966919Z","shell.execute_reply.started":"2021-09-11T08:59:36.380155Z","shell.execute_reply":"2021-09-11T08:59:37.965227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=64\nBUFFER_SIZE=20000","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:37.968052Z","iopub.execute_input":"2021-09-11T08:59:37.96855Z","iopub.status.idle":"2021-09-11T08:59:37.972965Z","shell.execute_reply.started":"2021-09-11T08:59:37.96851Z","shell.execute_reply":"2021-09-11T08:59:37.971862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).cache().prefetch(tf.data.experimental.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:37.97402Z","iopub.execute_input":"2021-09-11T08:59:37.974666Z","iopub.status.idle":"2021-09-11T08:59:37.990448Z","shell.execute_reply.started":"2021-09-11T08:59:37.974632Z","shell.execute_reply":"2021-09-11T08:59:37.989599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def attention(query,key,value,mask):\n  qk_matmul = tf.matmul(query,key,transpose_b=True)\n  depth= tf.cast(tf.shape(key)[-1],tf.float32)\n  logits = qk_matmul/tf.math.sqrt(depth)\n\n  if mask is not None:\n    logits += (mask *-1e9)\n  attention_weight = tf.nn.softmax(logits,axis=-1)\n  output = tf.matmul(attention_weight,value)\n\n  return output","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:37.99215Z","iopub.execute_input":"2021-09-11T08:59:37.992851Z","iopub.status.idle":"2021-09-11T08:59:37.99924Z","shell.execute_reply.started":"2021-09-11T08:59:37.992815Z","shell.execute_reply":"2021-09-11T08:59:37.99817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n\n  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n    super(MultiHeadAttention, self).__init__(name=name)\n    self.num_heads = num_heads\n    self.d_model = d_model\n\n    assert d_model % self.num_heads == 0\n\n    self.depth = d_model // self.num_heads\n\n    self.query_dense = tf.keras.layers.Dense(units=d_model)\n    self.key_dense = tf.keras.layers.Dense(units=d_model)\n    self.value_dense = tf.keras.layers.Dense(units=d_model)\n\n    self.dense = tf.keras.layers.Dense(units=d_model)\n\n  def split_heads(self, inputs, batch_size):\n    inputs = tf.reshape(\n        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n\n  def call(self, inputs):\n    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n        'value'], inputs['mask']\n    batch_size = tf.shape(query)[0]\n\n    # linear layers\n    query = self.query_dense(query)\n    key = self.key_dense(key)\n    value = self.value_dense(value)\n\n    # split heads\n    query = self.split_heads(query, batch_size)\n    key = self.split_heads(key, batch_size)\n    value = self.split_heads(value, batch_size)\n\n    # scaled dot-product attention\n    scaled_attention = attention(query, key, value, mask)\n\n    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n\n    # concatenation of heads\n    concat_attention = tf.reshape(scaled_attention,\n                                  (batch_size, -1, self.d_model))\n\n    # final linear layer\n    outputs = self.dense(concat_attention)\n\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.000559Z","iopub.execute_input":"2021-09-11T08:59:38.000821Z","iopub.status.idle":"2021-09-11T08:59:38.021274Z","shell.execute_reply.started":"2021-09-11T08:59:38.000787Z","shell.execute_reply":"2021-09-11T08:59:38.020471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_padding_mask(x):\n  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n  # (batch_size, 1, 1, sequence length)\n  return mask[:, tf.newaxis, tf.newaxis, :]","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.022479Z","iopub.execute_input":"2021-09-11T08:59:38.022743Z","iopub.status.idle":"2021-09-11T08:59:38.030908Z","shell.execute_reply.started":"2021-09-11T08:59:38.022711Z","shell.execute_reply":"2021-09-11T08:59:38.030154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_look_ahead_mask(x):\n  seq_len = tf.shape(x)[1]\n  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n  padding_mask = create_padding_mask(x)\n  return tf.maximum(look_ahead_mask, padding_mask)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.032187Z","iopub.execute_input":"2021-09-11T08:59:38.032514Z","iopub.status.idle":"2021-09-11T08:59:38.04311Z","shell.execute_reply.started":"2021-09-11T08:59:38.032477Z","shell.execute_reply":"2021-09-11T08:59:38.042271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating postional encoding for the layer to get the word postion\nclass PositionalEncoding(tf.keras.layers.Layer):\n  def __init__(self,postion,d_model):\n    super(PositionalEncoding,self).__init__()\n    self.pos_encoding = self.postional_encoding(postion,d_model)\n  def get_angles(self,postion,i,d_model):\n    angles = 1/tf.pow(10000,(2*(i//2))/tf.cast(d_model,dtype=tf.float32))\n    return postion*angles\n  def postional_encoding(self,postion,d_model):\n    angle_rads = self.get_angles(\n        postion = tf.range(postion,dtype=tf.float32)[:,tf.newaxis],\n        i = tf.range(d_model,dtype=tf.float32)[tf.newaxis,:],\n        d_model = d_model\n    )\n    # apply sin to even index in the array\n    sines = tf.math.sin(angle_rads[:, 0::2])\n    # apply cos to odd index in the array\n    cosines = tf.math.cos(angle_rads[:, 1::2])\n\n    pos_encoding = tf.concat([sines, cosines], axis=-1)\n    pos_encoding = pos_encoding[tf.newaxis, ...]\n    return tf.cast(pos_encoding, tf.float32)\n\n    def call(self,inputs):\n      return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            \"pos_encoding\":self.pos_encoding\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.044393Z","iopub.execute_input":"2021-09-11T08:59:38.045182Z","iopub.status.idle":"2021-09-11T08:59:38.05669Z","shell.execute_reply.started":"2021-09-11T08:59:38.045145Z","shell.execute_reply":"2021-09-11T08:59:38.056042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n  attention = MultiHeadAttention(\n      d_model, num_heads, name=\"attention\")({\n          'query': inputs,\n          'key': inputs,\n          'value': inputs,\n          'mask': padding_mask\n      })\n  attention = tf.keras.layers.Dropout(rate=0.3)(attention)\n  attention = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(inputs + attention)\n\n  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n  outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention + outputs)\n\n  return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.057892Z","iopub.execute_input":"2021-09-11T08:59:38.058379Z","iopub.status.idle":"2021-09-11T08:59:38.067191Z","shell.execute_reply.started":"2021-09-11T08:59:38.058342Z","shell.execute_reply":"2021-09-11T08:59:38.066412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder(vocab_size,num_layers,units,d_model,num_heads,dropout,name='encoder'):\n  inputs = tf.keras.Input(shape=(None,),name='inputs')\n  padding_mask = tf.keras.Input(shape=(1,1,None),name='padding_mask')\n  \n  embeddings = tf.keras.layers.Embedding(vocab_size,d_model)(inputs)\n  embeddings *= tf.math.sqrt(tf.cast(d_model,tf.float32))\n  embeddings = PositionalEncoding(vocab_size,d_model)(embeddings)\n\n  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n  for i in range(num_layers):\n    outputs = encoder_layer(\n        units=units,\n        d_model=d_model,\n        num_heads=num_heads,\n        dropout=dropout,\n        name=\"encoder_layer_{}\".format(i),\n    )([outputs, padding_mask])\n  return tf.keras.Model(\n      inputs=[inputs,padding_mask],outputs=outputs,name=name\n  )","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.068602Z","iopub.execute_input":"2021-09-11T08:59:38.069072Z","iopub.status.idle":"2021-09-11T08:59:38.078665Z","shell.execute_reply.started":"2021-09-11T08:59:38.069037Z","shell.execute_reply":"2021-09-11T08:59:38.077963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n  \n  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n  \n  look_ahead_mask = tf.keras.Input(\n      shape=(1, None, None), name=\"look_ahead_mask\")\n  \n  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n\n  attention1 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_1\")(inputs={\n          'query': inputs,\n          'key': inputs,\n          'value': inputs,\n          'mask': look_ahead_mask\n      })\n  attention1 = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention1 + inputs)\n\n  attention2 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_2\")(inputs={\n          'query': attention1,\n          'key': enc_outputs,\n          'value': enc_outputs,\n          'mask': padding_mask\n      })\n  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n  attention2 = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention2 + attention1)\n\n  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n  outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(outputs + attention2)\n\n  return tf.keras.Model(\n      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n      outputs=outputs,\n      name=name)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.07995Z","iopub.execute_input":"2021-09-11T08:59:38.080193Z","iopub.status.idle":"2021-09-11T08:59:38.252015Z","shell.execute_reply.started":"2021-09-11T08:59:38.080163Z","shell.execute_reply":"2021-09-11T08:59:38.251231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decoder(vocab_size,\n            num_layers,\n            units,\n            d_model,\n            num_heads,\n            dropout,\n            name='decoder'):\n  inputs = tf.keras.Input(shape=(None,), name='inputs')\n  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n  look_ahead_mask = tf.keras.Input(\n      shape=(1, None, None), name='look_ahead_mask')\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n  \n  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n\n  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n  for i in range(num_layers):\n    outputs = decoder_layer(\n        units=units,\n        d_model=d_model,\n        num_heads=num_heads,\n        dropout=dropout,\n        name='decoder_layer_{}'.format(i),\n    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n\n  return tf.keras.Model(\n      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n      outputs=outputs,\n      name=name)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.253307Z","iopub.execute_input":"2021-09-11T08:59:38.253668Z","iopub.status.idle":"2021-09-11T08:59:38.264421Z","shell.execute_reply.started":"2021-09-11T08:59:38.25363Z","shell.execute_reply":"2021-09-11T08:59:38.263557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transformer(vocab_size,\n                num_layers,\n                units,\n                d_model,\n                num_heads,\n                dropout,\n                name=\"transformer\"):\n  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n\n  enc_padding_mask = tf.keras.layers.Lambda(\n      create_padding_mask, output_shape=(1, 1, None),\n      name='enc_padding_mask')(inputs)\n  # mask the future tokens for decoder inputs at the 1st attention block\n  look_ahead_mask = tf.keras.layers.Lambda(\n      create_look_ahead_mask,\n      output_shape=(1, None, None),\n      name='look_ahead_mask')(dec_inputs)\n  # mask the encoder outputs for the 2nd attention block\n  dec_padding_mask = tf.keras.layers.Lambda(\n      create_padding_mask, output_shape=(1, 1, None),\n      name='dec_padding_mask')(inputs)\n\n  enc_outputs = encoder(\n      vocab_size=vocab_size,\n      num_layers=num_layers,\n      units=units,\n      d_model=d_model,\n      num_heads=num_heads,\n      dropout=dropout,\n  )(inputs=[inputs, enc_padding_mask])\n\n  dec_outputs = decoder(\n      vocab_size=vocab_size,\n      num_layers=num_layers,\n      units=units,\n      d_model=d_model,\n      num_heads=num_heads,\n      dropout=dropout,\n  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n\n  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n\n  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.266017Z","iopub.execute_input":"2021-09-11T08:59:38.266282Z","iopub.status.idle":"2021-09-11T08:59:38.277317Z","shell.execute_reply.started":"2021-09-11T08:59:38.266248Z","shell.execute_reply":"2021-09-11T08:59:38.276546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#choosing hyperparameter\nNUM_LAYERS=2\nD_MODEL=256\nNUM_HEADS=8\nUNITS = 512\nDROPOUT=0.1\n\nmodel = transformer(vocab_size=VOCAB_SIZE,num_layers=NUM_LAYERS,units=UNITS,d_model=D_MODEL,num_heads=NUM_HEADS,dropout=DROPOUT)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:38.278778Z","iopub.execute_input":"2021-09-11T08:59:38.279042Z","iopub.status.idle":"2021-09-11T08:59:40.756218Z","shell.execute_reply.started":"2021-09-11T08:59:38.279011Z","shell.execute_reply":"2021-09-11T08:59:40.755498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:40.757335Z","iopub.execute_input":"2021-09-11T08:59:40.757582Z","iopub.status.idle":"2021-09-11T08:59:40.771996Z","shell.execute_reply.started":"2021-09-11T08:59:40.757551Z","shell.execute_reply":"2021-09-11T08:59:40.767977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_function(y_true, y_pred):\n  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n  \n  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n      from_logits=True, reduction='none')(y_true, y_pred)\n\n  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n  loss = tf.multiply(loss, mask)\n\n  return tf.reduce_mean(loss)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:40.773213Z","iopub.execute_input":"2021-09-11T08:59:40.773463Z","iopub.status.idle":"2021-09-11T08:59:40.78119Z","shell.execute_reply.started":"2021-09-11T08:59:40.773431Z","shell.execute_reply":"2021-09-11T08:59:40.780446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n\n  def __init__(self, d_model, warmup_steps=4000):\n    super(CustomSchedule, self).__init__()\n\n    self.d_model = d_model\n    self.d_model = tf.cast(self.d_model, tf.float32)\n\n    self.warmup_steps = warmup_steps\n\n  def __call__(self, step):\n    arg1 = tf.math.rsqrt(step)\n    arg2 = step * (self.warmup_steps**-1.5)\n\n    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:40.782623Z","iopub.execute_input":"2021-09-11T08:59:40.78316Z","iopub.status.idle":"2021-09-11T08:59:40.790914Z","shell.execute_reply.started":"2021-09-11T08:59:40.783124Z","shell.execute_reply":"2021-09-11T08:59:40.790247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = CustomSchedule(D_MODEL)\n\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n\ndef accuracy(y_true, y_pred):\n  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:40.79209Z","iopub.execute_input":"2021-09-11T08:59:40.792537Z","iopub.status.idle":"2021-09-11T08:59:40.799709Z","shell.execute_reply.started":"2021-09-11T08:59:40.792504Z","shell.execute_reply":"2021-09-11T08:59:40.799072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:40.801685Z","iopub.execute_input":"2021-09-11T08:59:40.802266Z","iopub.status.idle":"2021-09-11T08:59:40.818147Z","shell.execute_reply.started":"2021-09-11T08:59:40.802232Z","shell.execute_reply":"2021-09-11T08:59:40.817473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 300\n\nmodel.fit(dataset, epochs=EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T08:59:40.819482Z","iopub.execute_input":"2021-09-11T08:59:40.819771Z","iopub.status.idle":"2021-09-11T09:03:17.782649Z","shell.execute_reply.started":"2021-09-11T08:59:40.819705Z","shell.execute_reply":"2021-09-11T09:03:17.781954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(sentence,model):\n  sentence = preprocess_sentence(sentence)\n\n  sentence = tf.expand_dims(\n      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n\n  output = tf.expand_dims(START_TOKEN, 0)\n\n  for i in range(MAX_LENGTH):\n    predictions = model(inputs=[sentence, output], training=False)\n\n    # select the last word from the seq_len dimension\n    predictions = predictions[:, -1:, :]\n    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n\n    # return the result if the predicted_id is equal to the end token\n    if tf.equal(predicted_id, END_TOKEN[0]):\n      break\n\n    # concatenated the predicted_id to the output which is given to the decoder\n    # as its input.\n    output = tf.concat([output, predicted_id], axis=-1)\n\n  return tf.squeeze(output, axis=0)\n\n\ndef predict(sentence,model):\n  prediction = evaluate(sentence,model)\n\n  predicted_sentence = tokenizer.decode(\n      [i for i in prediction if i < tokenizer.vocab_size])\n\n  print('Input: {}'.format(sentence))\n  print('Output: {}'.format(predicted_sentence))\n\n  return predicted_sentence","metadata":{"execution":{"iopub.status.busy":"2021-09-11T09:03:17.784128Z","iopub.execute_input":"2021-09-11T09:03:17.784386Z","iopub.status.idle":"2021-09-11T09:03:17.793577Z","shell.execute_reply.started":"2021-09-11T09:03:17.784352Z","shell.execute_reply":"2021-09-11T09:03:17.792789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output=predict(\"à¤à¥à¤¸à¥à¤¤à¤¾à¤µ à¤à¤¿à¤°à¤à¥à¤« à¤à¤¾ à¤à¤¨à¥à¤® à¤à¤¬ à¤¹à¥à¤ à¤¥à¤¾?\",model)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T09:03:17.795049Z","iopub.execute_input":"2021-09-11T09:03:17.795302Z","iopub.status.idle":"2021-09-11T09:03:17.916988Z","shell.execute_reply.started":"2021-09-11T09:03:17.795271Z","shell.execute_reply":"2021-09-11T09:03:17.916281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/chaii-hindi-and-tamil-question-answering/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T09:03:17.918009Z","iopub.execute_input":"2021-09-11T09:03:17.918244Z","iopub.status.idle":"2021-09-11T09:03:17.936753Z","shell.execute_reply.started":"2021-09-11T09:03:17.918212Z","shell.execute_reply":"2021-09-11T09:03:17.93608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T09:03:17.938002Z","iopub.execute_input":"2021-09-11T09:03:17.938272Z","iopub.status.idle":"2021-09-11T09:03:17.95Z","shell.execute_reply.started":"2021-09-11T09:03:17.938237Z","shell.execute_reply":"2021-09-11T09:03:17.949042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/sample_submission.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T09:03:17.951562Z","iopub.execute_input":"2021-09-11T09:03:17.951835Z","iopub.status.idle":"2021-09-11T09:03:17.970427Z","shell.execute_reply.started":"2021-09-11T09:03:17.951802Z","shell.execute_reply":"2021-09-11T09:03:17.969778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = test[\"question\"]\nquestions=[]\nfor ques in question:\n  questions.append(preprocess_sentence(ques))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T09:04:08.945078Z","iopub.execute_input":"2021-09-11T09:04:08.945654Z","iopub.status.idle":"2021-09-11T09:04:08.951643Z","shell.execute_reply.started":"2021-09-11T09:04:08.945616Z","shell.execute_reply":"2021-09-11T09:04:08.949857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = []\nfor idx in range(len(question)):\n    pred = predict(question[idx],model)\n    test_preds.append(pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T09:05:58.775835Z","iopub.execute_input":"2021-09-11T09:05:58.776422Z","iopub.status.idle":"2021-09-11T09:06:00.727088Z","shell.execute_reply.started":"2021-09-11T09:05:58.776384Z","shell.execute_reply":"2021-09-11T09:06:00.726283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['PredictionString'] = test_preds\nsub[['id','PredictionString']].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T09:09:35.567715Z","iopub.execute_input":"2021-09-11T09:09:35.568324Z","iopub.status.idle":"2021-09-11T09:09:35.57951Z","shell.execute_reply.started":"2021-09-11T09:09:35.568285Z","shell.execute_reply":"2021-09-11T09:09:35.578787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[['id','PredictionString']].to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T09:09:47.541761Z","iopub.execute_input":"2021-09-11T09:09:47.542343Z","iopub.status.idle":"2021-09-11T09:09:47.563223Z","shell.execute_reply.started":"2021-09-11T09:09:47.542307Z","shell.execute_reply":"2021-09-11T09:09:47.562338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}