{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport unicodedata\nimport re\nimport time\n\nfrom transformers import TransfoXLConfig, TFTransfoXLModel\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-13T15:28:36.022122Z","iopub.execute_input":"2021-09-13T15:28:36.022534Z","iopub.status.idle":"2021-09-13T15:28:42.753062Z","shell.execute_reply.started":"2021-09-13T15:28:36.022443Z","shell.execute_reply":"2021-09-13T15:28:42.752236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/chaii-hindi-and-tamil-question-answering/train.csv')\nprint(len(train_data))\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:42.755841Z","iopub.execute_input":"2021-09-13T15:28:42.756126Z","iopub.status.idle":"2021-09-13T15:28:43.449751Z","shell.execute_reply.started":"2021-09-13T15:28:42.756097Z","shell.execute_reply":"2021-09-13T15:28:43.448912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.dropna(axis=0,how='any',inplace=True)\nprint(len(train_data))","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:43.451757Z","iopub.execute_input":"2021-09-13T15:28:43.452353Z","iopub.status.idle":"2021-09-13T15:28:43.471583Z","shell.execute_reply.started":"2021-09-13T15:28:43.452314Z","shell.execute_reply":"2021-09-13T15:28:43.470616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _unicode_to_ascii(s):\n    \"\"\"将文本从unicode转ascii\n\n    Parameters\n    ----------\n    s : str\n        输入文本\n    Returns\n    -------\n    s : str\n        处理后的文本\n    \"\"\"\n    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:43.473175Z","iopub.execute_input":"2021-09-13T15:28:43.473503Z","iopub.status.idle":"2021-09-13T15:28:43.47973Z","shell.execute_reply.started":"2021-09-13T15:28:43.473469Z","shell.execute_reply":"2021-09-13T15:28:43.478797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['context'] = train_data.apply(lambda x: _unicode_to_ascii(x['context']),axis=1)\ntrain_data['question'] = train_data.apply(lambda x: _unicode_to_ascii(x['question']),axis=1)\ntrain_data['answer_text'] = train_data.apply(lambda x: _unicode_to_ascii(x['answer_text']),axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:43.481242Z","iopub.execute_input":"2021-09-13T15:28:43.48172Z","iopub.status.idle":"2021-09-13T15:28:47.305831Z","shell.execute_reply.started":"2021-09-13T15:28:43.481684Z","shell.execute_reply":"2021-09-13T15:28:47.305018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### language类别情况","metadata":{}},{"cell_type":"code","source":"train_data['language'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:47.307257Z","iopub.execute_input":"2021-09-13T15:28:47.307626Z","iopub.status.idle":"2021-09-13T15:28:47.316526Z","shell.execute_reply.started":"2021-09-13T15:28:47.307585Z","shell.execute_reply":"2021-09-13T15:28:47.315711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def include(str1, str2):\n    a = set(str(str1).lower().split())\n    b = set(str(str2).lower().split())\n    c = a.intersection(b)\n    return round(float(len(c)) / len(b), 4)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:47.317779Z","iopub.execute_input":"2021-09-13T15:28:47.318345Z","iopub.status.idle":"2021-09-13T15:28:47.324909Z","shell.execute_reply.started":"2021-09-13T15:28:47.318307Z","shell.execute_reply":"2021-09-13T15:28:47.323966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"question与context的交集除以question","metadata":{}},{"cell_type":"code","source":"context_question_similar = []\nfor index, row in train_data.iterrows():\n    sentence1 = row.context\n    sentence2 = row.question\n    score = include(sentence1, sentence2)\n    context_question_similar.append([sentence1, sentence2, score])\n    \ncontext_question_similar = pd.DataFrame(context_question_similar, columns=['context', 'question', 'score'])\ncontext_question_similar = context_question_similar.sort_values(by='score', ascending=False)\nf, ax = plt.subplots(figsize=(6, 15))\nsns.set_color_codes(\"pastel\")\nsns.countplot(y=\"score\",data=context_question_similar, color=\"b\")","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:47.326485Z","iopub.execute_input":"2021-09-13T15:28:47.327138Z","iopub.status.idle":"2021-09-13T15:28:48.424015Z","shell.execute_reply.started":"2021-09-13T15:28:47.327101Z","shell.execute_reply":"2021-09-13T15:28:48.422158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"answer_text与context的交集除以answer_text","metadata":{}},{"cell_type":"code","source":"context_answer_text_similar = []\nfor index, row in train_data.iterrows():\n    sentence1 = row.context\n    sentence2 = row.answer_text\n    score = include(sentence1, sentence2)\n    context_answer_text_similar.append([sentence1, sentence2, score])\n    \ncontext_answer_text_similar = pd.DataFrame(context_answer_text_similar, columns=['context', 'answer_text', 'score'])\ncontext_answer_text_similar['score'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:48.427056Z","iopub.execute_input":"2021-09-13T15:28:48.427327Z","iopub.status.idle":"2021-09-13T15:28:48.929482Z","shell.execute_reply.started":"2021-09-13T15:28:48.427301Z","shell.execute_reply":"2021-09-13T15:28:48.928601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 句子预处理","metadata":{}},{"cell_type":"code","source":"train_data['context_include_answertext'] = train_data.apply(lambda x: include(x['context'], x['answer_text'])==1,axis=1)\ntrain_data = train_data[train_data['context_include_answertext']==True]\n\nlen(train_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:48.931266Z","iopub.execute_input":"2021-09-13T15:28:48.931629Z","iopub.status.idle":"2021-09-13T15:28:49.300143Z","shell.execute_reply.started":"2021-09-13T15:28:48.93159Z","shell.execute_reply":"2021-09-13T15:28:49.299381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"context句子长度分布","metadata":{}},{"cell_type":"code","source":"index_len = []\ncount = 0\nfor index, row in train_data.iterrows():\n    count += 1\n    index_len.append([count, len(str(row['context']).split())])\n    \nindex_len = pd.DataFrame(index_len, columns=['index', 'len'])\nindex_len = index_len.sort_values(by='len', ascending=False)\n\nf, ax = plt.subplots(figsize=(15, 6))\nsns.lineplot(x=\"index\", y=\"len\", data=index_len)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:49.301676Z","iopub.execute_input":"2021-09-13T15:28:49.302163Z","iopub.status.idle":"2021-09-13T15:28:49.783192Z","shell.execute_reply.started":"2021-09-13T15:28:49.302126Z","shell.execute_reply":"2021-09-13T15:28:49.782333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"answer_text句子长度分布","metadata":{}},{"cell_type":"code","source":"index_len = []\ncount = 0\nfor index, row in train_data.iterrows():\n    count +=1\n    index_len.append([count, len(str(row['answer_text']).split())])\n    \nindex_len = pd.DataFrame(index_len, columns=['index', 'len'])\nindex_len = index_len.sort_values(by='len', ascending=False)\n\nf, ax = plt.subplots(figsize=(15, 6))\nsns.lineplot(x=\"index\", y=\"len\", data=index_len)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:49.784254Z","iopub.execute_input":"2021-09-13T15:28:49.784571Z","iopub.status.idle":"2021-09-13T15:28:50.085562Z","shell.execute_reply.started":"2021-09-13T15:28:49.784537Z","shell.execute_reply":"2021-09-13T15:28:50.084605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 数据重构","metadata":{}},{"cell_type":"code","source":"restructure_data = []\nfor index, row in train_data.iterrows():\n    contexts = re.split(r'(\\n|;|\\.)', row['context'])\n\n    true_flag = False\n    false_count = 0\n    for context in contexts:\n        if re.search(r'^\\s+$', context) is not None or len(context) < len(row['answer_text']):\n            continue\n        result = context.find(row['answer_text'])\n        \n        if result != -1 and true_flag == False:\n            score = 1\n            answer_start = result\n            answer_end = result + len(row['answer_text'])\n            restructure_data.append([context, row['question'], row['answer_text'], answer_start, answer_end, score,row['language']])\n            true_flag = True\n#         elif true_flag:\n#             break\n        elif false_count<3:\n            false_count += 1\n            score = 0\n            answer_start = 0\n            answer_end = 0\n            restructure_data.append([context, row['question'], row['answer_text'], answer_start, answer_end, score,row['language']])\n        elif false_count>=5 and true_flag:\n            break\n        \nrestructure_data = pd.DataFrame(restructure_data, columns=['context', 'question', 'answer_text', 'answer_start', 'answer_end', 'score','language'])\n","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:50.087035Z","iopub.execute_input":"2021-09-13T15:28:50.087369Z","iopub.status.idle":"2021-09-13T15:28:52.345909Z","shell.execute_reply.started":"2021-09-13T15:28:50.087332Z","shell.execute_reply":"2021-09-13T15:28:52.344975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(restructure_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:52.347098Z","iopub.execute_input":"2021-09-13T15:28:52.347446Z","iopub.status.idle":"2021-09-13T15:28:52.353351Z","shell.execute_reply.started":"2021-09-13T15:28:52.347413Z","shell.execute_reply":"2021-09-13T15:28:52.352334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"restructure_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:52.354838Z","iopub.execute_input":"2021-09-13T15:28:52.35524Z","iopub.status.idle":"2021-09-13T15:28:52.372702Z","shell.execute_reply.started":"2021-09-13T15:28:52.355205Z","shell.execute_reply":"2021-09-13T15:28:52.371929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"restructure_data['context_len'] = restructure_data.apply(lambda x: len(str(x['context']).split()) < 140,axis=1)\nrestructure_data = restructure_data[restructure_data['context_len']==True]\n\nlen(restructure_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:52.37372Z","iopub.execute_input":"2021-09-13T15:28:52.37407Z","iopub.status.idle":"2021-09-13T15:28:52.440891Z","shell.execute_reply.started":"2021-09-13T15:28:52.374035Z","shell.execute_reply":"2021-09-13T15:28:52.439986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_len = []\ncount = 0\nfor index, row in restructure_data.iterrows():\n    count += 1\n    index_len.append([count, len(str(row['context']).split())])\n    \nindex_len = pd.DataFrame(index_len, columns=['index', 'len'])\nindex_len = index_len.sort_values(by='len', ascending=False)\n\nf, ax = plt.subplots(figsize=(15, 6))\nsns.lineplot(x=\"index\", y=\"len\", data=index_len[:1000])","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:52.442239Z","iopub.execute_input":"2021-09-13T15:28:52.442567Z","iopub.status.idle":"2021-09-13T15:28:52.987052Z","shell.execute_reply.started":"2021-09-13T15:28:52.442534Z","shell.execute_reply":"2021-09-13T15:28:52.986034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### tokenize","metadata":{}},{"cell_type":"code","source":"metadata = np.concatenate((train_data['context'],train_data['question'],train_data['answer_text']),axis=0)\nprint(np.shape(metadata))\n\ntokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(metadata, target_vocab_size=2**13)\n# sample_string = metadata[0]\n# print ('Tokenized sample_string is {}'.format(sample_string))\n# tokenized_string = tokenizer.encode(sample_string)\n# print ('Tokenized string is {}'.format(tokenized_string))","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:28:52.98862Z","iopub.execute_input":"2021-09-13T15:28:52.988959Z","iopub.status.idle":"2021-09-13T15:30:09.828373Z","shell.execute_reply.started":"2021-09-13T15:28:52.988927Z","shell.execute_reply":"2021-09-13T15:30:09.827446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2\",trainable=True)\n# vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n# do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n# tokenizer = bert.tokenization.FullTokenizer(vocab_file, do_lower_case)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:30:09.829589Z","iopub.execute_input":"2021-09-13T15:30:09.829938Z","iopub.status.idle":"2021-09-13T15:30:09.834428Z","shell.execute_reply.started":"2021-09-13T15:30:09.829902Z","shell.execute_reply":"2021-09-13T15:30:09.833577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_sentence(s, tokenizer):\n    tokens = tokenizer.encode(s)\n    tokens.append(tokenizer.vocab_size+2)\n    return tokens\n#     tokens = list(tokenizer.tokenize(s))\n#     tokens.append('[SEP]')\n#     return tokenizer.convert_tokens_to_ids(tokens)\n\ndef bert_encode(glue_dict, tokenizer):\n    num_examples = len(glue_dict[\"context\"])\n\n    sentence1 = tf.ragged.constant([\n        encode_sentence(s, tokenizer) for s in np.array(glue_dict[\"context\"])])\n    sentence2 = tf.ragged.constant([\n        encode_sentence(s, tokenizer) for s in np.array(glue_dict[\"question\"])])\n\n    cls = [[tokenizer.vocab_size]]*sentence1.shape[0]\n#     cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n\n    input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n\n    input_mask = tf.ones_like(input_word_ids).to_tensor()\n\n    type_cls = tf.zeros_like(cls)\n    type_s1 = tf.zeros_like(sentence1)\n    type_s2 = tf.ones_like(sentence2)\n    input_type_ids = tf.concat([type_cls, type_s1, type_s2], axis=-1).to_tensor()\n    \n    \n    inputs = {\n        'input_word_ids': tf.cast(input_word_ids.to_tensor(), dtype=tf.int64),\n        'input_mask': tf.cast(input_mask, dtype=tf.int64),\n        'input_type_ids': tf.cast(input_type_ids, dtype=tf.int64)}\n\n    return inputs\n\ndef bert_encode_label(glue_dict):\n    answer_start = np.expand_dims(glue_dict['answer_start'], axis=-1)\n    answer_end = np.expand_dims(glue_dict['answer_end'], axis=-1)\n    score = np.expand_dims(glue_dict['score'], axis=-1)\n    \n    labels = tf.concat([answer_start, answer_end, score], axis=-1)\n    labels = tf.cast( labels, dtype=tf.int64)\n    return labels\n        \ninput_shape = ()\nglue_train = bert_encode(restructure_data, tokenizer)\nfor key, value in glue_train.items():\n    input_shape = value.shape\n    print(f'{key:15s} shape: {value.shape}')\n    \nglue_train_labels = bert_encode_label(restructure_data)\nprint(f'glue_train_labels shape: {glue_train_labels.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:30:09.835948Z","iopub.execute_input":"2021-09-13T15:30:09.836535Z","iopub.status.idle":"2021-09-13T15:30:17.875846Z","shell.execute_reply.started":"2021-09-13T15:30:09.836484Z","shell.execute_reply":"2021-09-13T15:30:17.874376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE = 40000\nBATCH_SIZE = 2\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((glue_train, glue_train_labels))\n\ntrain_dataset = train_dataset.cache()\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n\ntrain_inp, train_tar = next(iter(train_dataset))\ntrain_inp, train_tar","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:30:17.878672Z","iopub.execute_input":"2021-09-13T15:30:17.878955Z","iopub.status.idle":"2021-09-13T15:30:17.99499Z","shell.execute_reply.started":"2021-09-13T15:30:17.878929Z","shell.execute_reply":"2021-09-13T15:30:17.994103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransfoXLQA(tf.keras.Model):\n    def __init__(self, input_shape):\n        super(TransfoXLQA, self).__init__()\n        configuration = TransfoXLConfig()\n        self.TransfoXL = TFTransfoXLModel(configuration)\n        self.gapool1d = tf.keras.layers.GlobalAveragePooling1D()\n        \n        self.start = tf.keras.layers.Dense(input_shape[-1])\n        self.end = tf.keras.layers.Dense(input_shape[-1])\n        self.score = tf.keras.layers.Dense(input_shape[-1])\n        \n    def call(self, input_word_ids, input_mask, input_type_ids):\n        \n        outputs = self.TransfoXL({'input_ids': input_word_ids}, training=True)\n        last_hidden_states = outputs.last_hidden_state\n        pool_out = self.gapool1d(last_hidden_states)\n        start = self.start(pool_out)\n        end = self.end(pool_out)\n        score = self.score(pool_out)\n        \n        output = tf.concat([start[:,tf.newaxis,:], end[:,tf.newaxis,:], score[:,tf.newaxis,:]], axis=1)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:30:17.996233Z","iopub.execute_input":"2021-09-13T15:30:17.996561Z","iopub.status.idle":"2021-09-13T15:30:18.005216Z","shell.execute_reply.started":"2021-09-13T15:30:17.996525Z","shell.execute_reply":"2021-09-13T15:30:18.004293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transfoXLQA = TransfoXLQA(input_shape)\n\n# Set up epochs and steps\nepochs = 3\n\n# creates an optimizer with learning rate schedule\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n  def __init__(self, d_model, warmup_steps=4000):\n    super(CustomSchedule, self).__init__()\n\n    self.d_model = d_model\n    self.d_model = tf.cast(self.d_model, tf.float32)\n\n    self.warmup_steps = warmup_steps\n\n  def __call__(self, step):\n    arg1 = tf.math.rsqrt(step)\n    arg2 = step * (self.warmup_steps ** -1.5)\n\n    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n\nlearning_rate = CustomSchedule(1024)\noptimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,  epsilon=1e-9)\n\n\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:30:18.006543Z","iopub.execute_input":"2021-09-13T15:30:18.007081Z","iopub.status.idle":"2021-09-13T15:30:18.377233Z","shell.execute_reply.started":"2021-09-13T15:30:18.007046Z","shell.execute_reply":"2021-09-13T15:30:18.376395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_step_signature = [\n    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n    tf.TensorSpec(shape=(None, None), dtype=tf.int64)\n]\n\n@tf.function(input_signature=train_step_signature)\ndef train_step(input_word_ids, input_mask, input_type_ids, tar):\n    with tf.GradientTape() as tape:\n        predictions = transfoXLQA(input_word_ids, input_mask, input_type_ids)\n        loss = loss_fn(tar[:,2], predictions[:,2,:])\n    gradients = tape.gradient(loss, transfoXLQA.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, transfoXLQA.trainable_variables))\n    \n    train_loss(loss)\n    train_accuracy(tar[:,2], predictions[:,2,:])","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:30:18.378404Z","iopub.execute_input":"2021-09-13T15:30:18.378775Z","iopub.status.idle":"2021-09-13T15:30:18.386858Z","shell.execute_reply.started":"2021-09-13T15:30:18.378738Z","shell.execute_reply":"2021-09-13T15:30:18.385962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    start = time.time()\n\n    train_loss.reset_states()\n    train_accuracy.reset_states()\n    \n    for (batch, (inp, tar)) in enumerate(train_dataset):\n        input_word_ids = inp['input_word_ids']\n        input_mask = inp['input_mask']\n        input_type_ids = inp['input_type_ids']\n        \n        train_step(input_word_ids, input_mask, input_type_ids, tar)\n\n        if batch % 50 == 0:\n            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result()} Accuracy {train_accuracy.result()}')\n    \n    print(f'Epoch {epoch + 1} Loss {train_loss.result()} Accuracy {train_accuracy.result()}')\n    print(f'Time taken for 1 epoch: {time.time() - start} secs\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T15:30:18.388481Z","iopub.execute_input":"2021-09-13T15:30:18.389244Z","iopub.status.idle":"2021-09-13T15:38:02.310096Z","shell.execute_reply.started":"2021-09-13T15:30:18.389205Z","shell.execute_reply":"2021-09-13T15:38:02.307725Z"},"trusted":true},"execution_count":null,"outputs":[]}]}