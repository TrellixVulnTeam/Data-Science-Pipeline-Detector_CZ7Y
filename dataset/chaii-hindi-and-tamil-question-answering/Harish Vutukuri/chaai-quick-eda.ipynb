{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction 📝\n🎯 **Goal:** To predict answers to real questions about Wikipedia articles. You will use `chaii-1`, a new question answering dataset with question-answer pairs. The dataset covers Hindi and Tamil, collected without the use of translation. It provides a realistic information-seeking task with questions written by native-speaking expert data annotators.\n\n📖 **Data:** \n> **train.csv** - the training dataset\n> - ```id``` - a unique identifier\n> - ```context```- the text of the Hindi/Tamil sample from which answers should be derived\n> - ```question``` - the question, in Hindi/Tamil\n> - ```answer_text``` - the answer to the question (note: for test, this is what you are attempting to predict)\n> - ```answer_start``` - the starting character in context for the answer\n> - ```language``` - whether the text in question is in Tamil or Hindi\n\n> **test.csv** - the test dataset\n> - ```id``` - a unique identifier\n> - ```context```- the text of the Hindi/Tamil sample from which answers should be derived\n> - ```question``` - the question, in Hindi/Tamil\n> - ```language``` - whether the text in question is in Tamil or Hindi\n\n> **sample_submission.csv** - the submission format\n> - ```id``` - a unique identifier\n> - ```PredictionString```- string that best answers the provided question based on the context.\n\n\n🧪 **Evaluation metric:** [Jaccard Score](https://en.wikipedia.org/wiki/Jaccard_index)\n> $$Score = \\frac{1}{n} \\sum_{i=1}^n jaccard( gt_i, dt_i )$$\n> where \n> * $n$ = $\\textrm{number of documents}$\n> * $jaccard$ = $J(y_i, \\hat{y}_i) = \\frac{|y_i \\cap \\hat{y}_i|}{|y_i \\cup \\hat{y}_i|}$\n> * $gt_i$ = $\\textrm{the ith ground truth}$\n> * $dt_i$ = $\\textrm{the ith prediction}$","metadata":{"papermill":{"duration":0.032167,"end_time":"2021-05-11T19:12:29.813024","exception":false,"start_time":"2021-05-11T19:12:29.780857","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Import libraries 📚","metadata":{"papermill":{"duration":0.032313,"end_time":"2021-05-11T19:12:29.877934","exception":false,"start_time":"2021-05-11T19:12:29.845621","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\n\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom spacy.lang.hi import Hindi\nfrom spacy.lang.ta import Tamil\nfrom spacy.lang.hi import STOP_WORDS as hindi_stopwords\nfrom spacy.lang.ta import STOP_WORDS as tamil_stopwords\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom typing import Counter\nfrom pandas._typing import FrameOrSeries","metadata":{"_kg_hide-output":true,"papermill":{"duration":16.25819,"end_time":"2021-05-11T19:12:46.168552","exception":false,"start_time":"2021-05-11T19:12:29.910362","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-13T14:26:51.752377Z","iopub.execute_input":"2021-08-13T14:26:51.752801Z","iopub.status.idle":"2021-08-13T14:26:51.761055Z","shell.execute_reply.started":"2021-08-13T14:26:51.752765Z","shell.execute_reply":"2021-08-13T14:26:51.759476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget -q https://www.wfonts.com/download/data/2016/04/29/nirmala-ui/nirmala-ui.zip\n!unzip -q nirmala-ui.zip\n!ls -lrt *.ttf","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:19:27.967099Z","iopub.execute_input":"2021-08-13T14:19:27.967733Z","iopub.status.idle":"2021-08-13T14:19:28.702328Z","shell.execute_reply.started":"2021-08-13T14:19:27.967673Z","shell.execute_reply":"2021-08-13T14:19:28.700975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# configure the Tamil font\ntamil_font = FontProperties(fname='./Nirmala.ttf')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:19:54.897391Z","iopub.execute_input":"2021-08-13T14:19:54.897856Z","iopub.status.idle":"2021-08-13T14:19:54.90445Z","shell.execute_reply.started":"2021-08-13T14:19:54.897814Z","shell.execute_reply":"2021-08-13T14:19:54.902905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/train.csv\")\ntest_df = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/test.csv\")\nprint(f\"Train Shape: {train_df.shape}, Test Shape: {test_df.shape}\")","metadata":{"papermill":{"duration":0.151416,"end_time":"2021-05-11T19:12:48.880919","exception":false,"start_time":"2021-05-11T19:12:48.729503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-13T14:20:18.794493Z","iopub.execute_input":"2021-08-13T14:20:18.794903Z","iopub.status.idle":"2021-08-13T14:20:19.71598Z","shell.execute_reply.started":"2021-08-13T14:20:18.794869Z","shell.execute_reply":"2021-08-13T14:20:19.714919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"papermill":{"duration":0.065223,"end_time":"2021-05-11T19:12:48.984236","exception":false,"start_time":"2021-05-11T19:12:48.919013","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-13T14:20:21.085198Z","iopub.execute_input":"2021-08-13T14:20:21.08563Z","iopub.status.idle":"2021-08-13T14:20:21.117253Z","shell.execute_reply.started":"2021-08-13T14:20:21.085592Z","shell.execute_reply":"2021-08-13T14:20:21.116211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"papermill":{"duration":0.051945,"end_time":"2021-05-11T19:12:49.074866","exception":false,"start_time":"2021-05-11T19:12:49.022921","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2021-08-13T14:20:21.317733Z","iopub.execute_input":"2021-08-13T14:20:21.31814Z","iopub.status.idle":"2021-08-13T14:20:21.333085Z","shell.execute_reply.started":"2021-08-13T14:20:21.318101Z","shell.execute_reply":"2021-08-13T14:20:21.331968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Language Distribution 🃏","metadata":{}},{"cell_type":"code","source":"def target_distribution(df: FrameOrSeries, target_column: str) -> None:\n    \"\"\"\n    Target Variable Distribution\n    Args:\n        df (FrameOrSeries): DataFrame\n        target_column (str): Target column name\n    \"\"\"    \n    vc = df[target_column].value_counts()\n    print(f'Distribution: \\n\\n{vc} \\n')\n    \n    colors = ['#66b3ff', '#ff9999']\n    plt.pie(vc.values, labels=vc.keys(), colors=colors, shadow=True, startangle=90, autopct='%1.1f%%')\n    \n    #draw circle\n    centre_circle = plt.Circle((0,0), 0.80, fc='white')\n    fig = plt.gcf()\n    fig.gca().add_artist(centre_circle)\n    \n    plt.title(f'\"{target_column}\" Distribution')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:20:56.104077Z","iopub.execute_input":"2021-08-13T14:20:56.104473Z","iopub.status.idle":"2021-08-13T14:20:56.112794Z","shell.execute_reply.started":"2021-08-13T14:20:56.104435Z","shell.execute_reply":"2021-08-13T14:20:56.111474Z"},"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Language Distribution across training dataset\n\ntarget_distribution(df=train_df, target_column=\"language\")","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:21:21.692216Z","iopub.execute_input":"2021-08-13T14:21:21.692779Z","iopub.status.idle":"2021-08-13T14:21:21.867484Z","shell.execute_reply.started":"2021-08-13T14:21:21.692733Z","shell.execute_reply":"2021-08-13T14:21:21.866164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Language Distribution across test dataset\n\ntarget_distribution(df=test_df, target_column=\"language\")","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:21:21.948037Z","iopub.execute_input":"2021-08-13T14:21:21.948439Z","iopub.status.idle":"2021-08-13T14:21:22.069641Z","shell.execute_reply.started":"2021-08-13T14:21:21.948388Z","shell.execute_reply":"2021-08-13T14:21:22.068312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing values ❌","metadata":{"papermill":{"duration":0.038472,"end_time":"2021-05-11T19:12:49.25719","exception":false,"start_time":"2021-05-11T19:12:49.218718","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_missing_values(df: FrameOrSeries) -> None:\n    \"\"\"Plot HeatMap of missing values\n    Args:\n        df (FrameOrSeries): DataFrame\n    \"\"\"\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(df.isnull().T, cbar=False)\n    plt.yticks(rotation=45)","metadata":{"papermill":{"duration":0.510256,"end_time":"2021-05-11T19:12:49.883875","exception":false,"start_time":"2021-05-11T19:12:49.373619","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-13T14:23:11.041224Z","iopub.execute_input":"2021-08-13T14:23:11.04159Z","iopub.status.idle":"2021-08-13T14:23:11.050278Z","shell.execute_reply.started":"2021-08-13T14:23:11.041561Z","shell.execute_reply":"2021-08-13T14:23:11.049084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_missing_values(train_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:23:11.134564Z","iopub.execute_input":"2021-08-13T14:23:11.134951Z","iopub.status.idle":"2021-08-13T14:23:12.226538Z","shell.execute_reply.started":"2021-08-13T14:23:11.134917Z","shell.execute_reply":"2021-08-13T14:23:12.224887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ***As the plot is black, there are no Missing Values in the Train dataset***","metadata":{}},{"cell_type":"markdown","source":"# EDA 📊","metadata":{"papermill":{"duration":0.042934,"end_time":"2021-05-11T19:13:10.191192","exception":false,"start_time":"2021-05-11T19:13:10.148258","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_corpus = train_df['context']\ntest_corpus = test_df['context']\n\ndef get_top_n_anigram(corpus, n=None):\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ndef get_top_n_bigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ndef get_top_n_trigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(3, 3)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ndef plot_top_n(corpus: list, title: str = None):\n    df = pd.DataFrame(corpus, columns=['word','freq'])\n    plt.figure(figsize=(16, 8))\n    ax = sns.barplot(x='freq', y='word', data=df, facecolor=(0, 0, 0, 0), linewidth=2, edgecolor=sns.color_palette(\"ch:start=3, rot=.1\",20))\n    ax.bar_label(ax.containers[0], padding=5)\n    \n    plt.title(title)\n    plt.xlabel(\"Frequency\")\n    plt.ylabel(\"Count\")\n    plt.yticks(fontproperties=tamil_font)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:23:48.720507Z","iopub.execute_input":"2021-08-13T14:23:48.721309Z","iopub.status.idle":"2021-08-13T14:23:48.740216Z","shell.execute_reply.started":"2021-08-13T14:23:48.721252Z","shell.execute_reply":"2021-08-13T14:23:48.738594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \"context\" corpus of Training data\n\nplot_top_n(get_top_n_anigram(train_corpus, 20), title=\"Train Top 20 Unigrams\")\nplot_top_n(get_top_n_bigram(train_corpus, 20), title=\"Train Top 20 Bigrams\")\nplot_top_n(get_top_n_trigram(train_corpus, 20), title=\"Train Top 20 Trigrams\")","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:23:49.12961Z","iopub.execute_input":"2021-08-13T14:23:49.130127Z","iopub.status.idle":"2021-08-13T14:24:16.923655Z","shell.execute_reply.started":"2021-08-13T14:23:49.130077Z","shell.execute_reply":"2021-08-13T14:24:16.922581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \"context\" corpus of Test data\n\nplot_top_n(get_top_n_anigram(test_corpus, 20), title=\"Test Top 20 Unigrams\")\nplot_top_n(get_top_n_bigram(test_corpus, 20), title=\"Test Top 20 Bigrams\")\nplot_top_n(get_top_n_trigram(test_corpus, 20), title=\"Test Top 20 Trigrams\")","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:24:16.925396Z","iopub.execute_input":"2021-08-13T14:24:16.925976Z","iopub.status.idle":"2021-08-13T14:24:18.501779Z","shell.execute_reply.started":"2021-08-13T14:24:16.925919Z","shell.execute_reply":"2021-08-13T14:24:18.500746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## WordCloud on \"question\" variable\n\ntamil_text = \" \".join(train_df[train_df[\"language\"]==\"tamil\"][\"question\"])\nhindi_text = \" \".join(train_df[train_df[\"language\"]==\"hindi\"][\"question\"])\n\n# Get the tokens and frequencies for Hindi language\nhindi_nlp = Hindi()\nhindi_doc = hindi_nlp(hindi_text)\nhindi_tokens = set([token.text for token in hindi_doc])\nhindi_tokens_counter = Counter(hindi_tokens)\n\n# Get the tokens and frequencies for Tamil language\ntamil_nlp = Tamil()\ntamil_doc = hindi_nlp(tamil_text)\ntamil_tokens = set([token.text for token in tamil_doc])\ntamil_tokens_counter = Counter(tamil_tokens)\n\ndef plot_wordcloud(frequencies: Counter, stopwords: set, title: str = None):\n    wordcloud = WordCloud(font_path=\"./Nirmala.ttf\",\n                      width=400,\n                      height=400,\n                      background_color=\"white\",\n                      stopwords=stopwords,\n                      collocations=True,\n                      min_font_size=7).generate_from_frequencies(frequencies)\n    \n    plt.figure(figsize=(10, 10))\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()","metadata":{"papermill":{"duration":3.969301,"end_time":"2021-05-11T19:14:15.875603","exception":false,"start_time":"2021-05-11T19:14:11.906302","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-13T14:29:06.769011Z","iopub.execute_input":"2021-08-13T14:29:06.769473Z","iopub.status.idle":"2021-08-13T14:29:06.971478Z","shell.execute_reply.started":"2021-08-13T14:29:06.76944Z","shell.execute_reply":"2021-08-13T14:29:06.970466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_wordcloud(frequencies=hindi_tokens_counter, stopwords=hindi_stopwords, title=\"Hindi WordCloud\")","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:29:17.263372Z","iopub.execute_input":"2021-08-13T14:29:17.263916Z","iopub.status.idle":"2021-08-13T14:29:18.137839Z","shell.execute_reply.started":"2021-08-13T14:29:17.263865Z","shell.execute_reply":"2021-08-13T14:29:18.136519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_wordcloud(frequencies=tamil_tokens_counter, stopwords=tamil_stopwords, title=\"Tamil WordCloud\")","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:29:23.382465Z","iopub.execute_input":"2021-08-13T14:29:23.382836Z","iopub.status.idle":"2021-08-13T14:29:23.934456Z","shell.execute_reply.started":"2021-08-13T14:29:23.382805Z","shell.execute_reply":"2021-08-13T14:29:23.933191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **More EDA and Model Coming Soon**","metadata":{}},{"cell_type":"markdown","source":"<center> <h4> Please <b><span style=\"color:red\">LIKE</span></b> the Notebook if you like it !! </h4></center>","metadata":{}}]}