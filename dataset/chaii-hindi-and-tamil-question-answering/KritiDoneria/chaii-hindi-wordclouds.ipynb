{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Credits: https://www.kaggle.com/hoshi7/chaii-the-beginning-eda-wordclouds by @hoshi7\nThis work is an extension of the work above. \nPlease upvote the original notebook if you find this useful.\nThanks","metadata":{}},{"cell_type":"markdown","source":"# Contents: \n1. [Importing Libraries and Data](#1) \n    1. [Necessary Functions](#necessary_functions)\n3. [Understanding Data](#2)\n3. [Exploratory Data Analysis](#3)\n    1. [What is the number of tamil and hindi rows in the database?](#4) \n    2. [What are the most prevelant words for Hindi?](#5)\n    3. [What are the most prevelant questions words for Hindi?](#6)\n    4. [What are the most prevelant answers for Hindi](#7)","metadata":{}},{"cell_type":"markdown","source":"## [Importing Libraries and Data]()<a id=\"1\"></a> <br>\n","metadata":{}},{"cell_type":"code","source":"#Basic libraries\nimport numpy as np\nimport pandas as pd\n\n#EDA: \nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.tools as tls\nfrom plotly.offline import init_notebook_mode\n## Wordclouds\nimport altair as alt\nfrom  altair.vega import v5\nfrom IPython.display import HTML\nimport json\n\n#Basic Preprocessing\nfrom collections import defaultdict, Counter\n\n#Question-Answering\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:24:43.062265Z","iopub.execute_input":"2021-08-17T09:24:43.062978Z","iopub.status.idle":"2021-08-17T09:24:55.547523Z","shell.execute_reply.started":"2021-08-17T09:24:43.062867Z","shell.execute_reply":"2021-08-17T09:24:55.546435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:24:55.549251Z","iopub.execute_input":"2021-08-17T09:24:55.549759Z","iopub.status.idle":"2021-08-17T09:24:56.519921Z","shell.execute_reply.started":"2021-08-17T09:24:55.549721Z","shell.execute_reply":"2021-08-17T09:24:56.518786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### [Necessary Functions]()<a id=\"necessary_functions\"></a> <br>","metadata":{}},{"cell_type":"code","source":"# Defining functions for visualizations: \n\ndef pie_plot(labels, values, colors, title):\n    fig = {\n      \"data\": [\n        {\n          \"values\": values,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .48]},\n          \"name\": \"Job Type\",\n          \"sort\": False,\n          \"marker\": {'colors': colors},\n          \"textinfo\":\"percent+label\",\n          \"textfont\": {'color': '#FFFFFF', 'size': 10},\n          \"hole\": .6,\n          \"type\": \"pie\"\n        } ],\n        \"layout\": {\n            \"title\":title,\n            \"annotations\": [\n                {\n                    \"font\": {\n                        \"size\": 25,\n\n                    },\n                    \"showarrow\": False,\n                    \"text\": \"\"\n\n                }\n            ]\n        }\n    }\n    return fig","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-17T09:24:56.521775Z","iopub.execute_input":"2021-08-17T09:24:56.522079Z","iopub.status.idle":"2021-08-17T09:24:56.529816Z","shell.execute_reply.started":"2021-08-17T09:24:56.522048Z","shell.execute_reply":"2021-08-17T09:24:56.528661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##-----------------------------------------------------------\n# This whole section \nvega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\nvega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\nvega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https://cdn.jsdelivr.net/npm/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"></div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"works?\");\n    }});\n    console.log(\"recheck to see if it works?\");\n    </script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\n\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"</script>\")))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-17T09:24:56.531701Z","iopub.execute_input":"2021-08-17T09:24:56.532052Z","iopub.status.idle":"2021-08-17T09:24:56.553285Z","shell.execute_reply.started":"2021-08-17T09:24:56.532017Z","shell.execute_reply":"2021-08-17T09:24:56.552354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wordcloud function\n\n\ndef word_cloud(df, pixwidth=6000, pixheight=350, column=\"index\", counts=\"count\"):\n    data= [dict(name=\"dataset\", values=df.to_dict(orient=\"records\"))]\n    wordcloud = {\n        \"$schema\": \"https://vega.github.io/schema/vega/v5.json\",\n        \"width\": pixwidth,\n        \"height\": pixheight,\n        \"padding\": 0,\n        \"title\": \"Hover to see number of occureances from all the sequences\",\n        \"data\": data\n    }\n    scale = dict(\n        name=\"color\",\n        type=\"ordinal\",\n        range=[\"cadetblue\", \"royalblue\", \"steelblue\", \"navy\", \"teal\"]\n    )\n    mark = {\n        \"type\":\"text\",\n        \"from\":dict(data=\"dataset\"),\n        \"encode\":dict(\n            enter=dict(\n                text=dict(field=column),\n                align=dict(value=\"center\"),\n                baseline=dict(value=\"alphabetic\"),\n                fill=dict(scale=\"color\", field=column),\n                tooltip=dict(signal=\"datum.count + ' occurrances'\")\n            )\n        ),\n        \"transform\": [{\n            \"type\": \"wordcloud\",\n            \"text\": dict(field=column),\n            \"size\": [pixwidth, pixheight],\n            \"font\": \"Helvetica Neue, Arial\",\n            \"fontSize\": dict(field=\"datum.{}\".format(counts)),\n            \"fontSizeRange\": [10, 60],\n            \"padding\": 2\n        }]\n    }\n    wordcloud[\"scales\"] = [scale]\n    wordcloud[\"marks\"] = [mark]\n    \n    return wordcloud\n\n\n\ndef wordcloud_create(df, field):\n    ult = {}\n    corpus = df[field].values.tolist()\n    final = defaultdict(int) #Declaring an empty dictionary for count (Saves ram usage)\n    for words in corpus:\n        for word in words.split():\n             final[word]+=1\n    temp = Counter(final)\n    for k, v in  temp.most_common(300):\n        ult[k] = v\n    corpus = pd.Series(ult) #Creating a dataframe from the final default dict\n    return render(word_cloud(corpus.to_frame(name=\"count\").reset_index(), pixheight=600, pixwidth=900))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-17T09:24:56.555078Z","iopub.execute_input":"2021-08-17T09:24:56.555652Z","iopub.status.idle":"2021-08-17T09:24:56.571104Z","shell.execute_reply.started":"2021-08-17T09:24:56.555611Z","shell.execute_reply":"2021-08-17T09:24:56.570024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [Understanding Data]()<a id=\"2\"></a> <br>\n","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:24:56.572641Z","iopub.execute_input":"2021-08-17T09:24:56.573165Z","iopub.status.idle":"2021-08-17T09:24:56.617753Z","shell.execute_reply.started":"2021-08-17T09:24:56.573118Z","shell.execute_reply":"2021-08-17T09:24:56.616912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the columns, we can observe the following columns: \n- **id**: The unique id for that particular row. \n- **context**: The text in hindi/tamil from which the answer needs to be derived. \n- **question**: The question in the respective language\n- **answer_text**: This is the text which signifies the answer. We are trying to predict this for the test set. As this is a text based competition, we will be using jaccard score to evaluate how closely related to the true answer it was. \n- **answer_start**: The starting character index in the context from where the answer begins. \n- **language**: The language of the context and question. ","metadata":{}},{"cell_type":"markdown","source":"## [Exploratory Data Analysis]()<a id=\"3\"></a> <br>","metadata":{}},{"cell_type":"markdown","source":"#### [What is the number of tamil and hindi questions in the dataset?]()<a id=\"4\"></a> <br>","metadata":{}},{"cell_type":"code","source":"value_counts = df['language'].value_counts()\nlabels = value_counts.index.tolist()\npy.iplot(pie_plot(labels, value_counts, ['#1B9E77', '#D95F02'], \"Language breakdown\"))","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:24:56.619027Z","iopub.execute_input":"2021-08-17T09:24:56.619549Z","iopub.status.idle":"2021-08-17T09:24:58.10564Z","shell.execute_reply.started":"2021-08-17T09:24:56.619497Z","shell.execute_reply":"2021-08-17T09:24:58.10474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### [What are the most prevelant words for Hindi?]()<a id=\"5\"></a> <br>","metadata":{}},{"cell_type":"code","source":"hindi_df = df[df['language']=='hindi']\nwordcloud_create(hindi_df, 'context')","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:24:58.107616Z","iopub.execute_input":"2021-08-17T09:24:58.108097Z","iopub.status.idle":"2021-08-17T09:24:58.736207Z","shell.execute_reply.started":"2021-08-17T09:24:58.108049Z","shell.execute_reply":"2021-08-17T09:24:58.73497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As I know hindi, I can look at the above wordcloud and figure out that: \n- The most common words, like English, are the stop words. \n- Punctuation is present for hindi dataset too, such as: , | ? - \n\n\nBased on these, we can formulate a plan for the next steps. \nLet's draw the same for Tamil and see if something can be inferred. ","metadata":{}},{"cell_type":"markdown","source":"As I know hindi, I can look at the above wordcloud and figure out that:\n\nThe most common words, like English, are the stop words.\n**Punctuation is present for hindi dataset too, such as: , | ? -**","metadata":{}},{"cell_type":"markdown","source":"#### [What are the most prevelant question words for Hindi?]()<a id=\"6\"></a> <br>","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:25:29.819667Z","iopub.execute_input":"2021-08-17T09:25:29.820236Z","iopub.status.idle":"2021-08-17T09:25:29.825053Z","shell.execute_reply.started":"2021-08-17T09:25:29.8202Z","shell.execute_reply":"2021-08-17T09:25:29.823736Z"}}},{"cell_type":"code","source":"hindi_df = df[df['language']=='hindi']\nwordcloud_create(hindi_df, 'question')","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:25:58.787669Z","iopub.execute_input":"2021-08-17T09:25:58.788105Z","iopub.status.idle":"2021-08-17T09:25:58.808036Z","shell.execute_reply.started":"2021-08-17T09:25:58.788063Z","shell.execute_reply":"2021-08-17T09:25:58.807151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Alongside punctuations, question words are present as well.**","metadata":{}},{"cell_type":"markdown","source":"#### [What are the most prevelant answers for Hindi?]()<a id=\"7\"></a> <br>","metadata":{}},{"cell_type":"code","source":"hindi_df = df[df['language']=='hindi']\nwordcloud_create(hindi_df, 'answer_text')","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:30:21.315434Z","iopub.execute_input":"2021-08-17T09:30:21.315897Z","iopub.status.idle":"2021-08-17T09:30:21.33741Z","shell.execute_reply.started":"2021-08-17T09:30:21.315853Z","shell.execute_reply":"2021-08-17T09:30:21.336108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now, its apparent proper nouns are most likely to be present in answers than any other parts of speech.\nUnits of measurement ( months, numbers etc) also find place in answers.**","metadata":{}}]}