{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"%%capture\nimport time\nstart = time.time()\n!pip uninstall fsspec -qq -y\n!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq\n!pip install -U --no-build-isolation --no-deps ../input/transformers-master/ -qq","metadata":{"execution":{"iopub.status.busy":"2021-09-12T10:13:40.918245Z","iopub.execute_input":"2021-09-12T10:13:40.91866Z","iopub.status.idle":"2021-09-12T10:14:20.475487Z","shell.execute_reply.started":"2021-09-12T10:13:40.918566Z","shell.execute_reply":"2021-09-12T10:14:20.474393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\ntorch.set_grad_enabled(False)\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering,AutoConfig, AutoModel, XLMRobertaTokenizerFast\nfrom datasets import Dataset\nfrom chaii_utils import prepare_validation_features, postprocess_qa_predictions\nfrom tqdm.notebook import tqdm\nfrom sklearn import preprocessing\nimport torch.nn.functional as F\n# from torch.optim.swa_utils import AveragedModel\nimport collections\nimport re\nimport os\nfrom glob import glob\n# pretrained_paths = ['../input/rembert-pt']\n# pretrained_paths = ['../input/infoxlm-large-squad2']\npretrained_paths = ['../input/rembert-pt', '../input/muril-large-pt/muril-large-cased', '../input/infoxlm-large-squad2', '../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2']\n\n# model_paths = ['../input/0829-rembert']\n# model_paths = ['../input/xlm-roberta-4']\nmodel_paths = ['../input/0829-rembert', '../input/muril-ep1-full', '../input/xlm-roberta-4', '../input/rob-lr1e-5-wd0-do01-ds05']\nmodel_exts = [[], [2], [], [3,4]]\nmymodels = [False,False,False,False]\nmax_lengths = [512,512,512,512]\ndoc_strides = [128,128,128,128]\nweights = [1,1,1,1]\n\n# pretrained_paths = ['../input/muril-large-pt/muril-large-cased']\n# model_paths = ['../input/muril-ep1-full']\n# model_exts = [[0,1,2,3]]\n# mymodels = [False]\n# max_lengths = [512]\n# doc_strides = [128]\n# weights = [1]\n\ndevice = 'cuda'\ndosoftmax = False","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:12:59.003345Z","iopub.execute_input":"2021-09-12T11:12:59.003706Z","iopub.status.idle":"2021-09-12T11:12:59.011011Z","shell.execute_reply.started":"2021-09-12T11:12:59.003668Z","shell.execute_reply":"2021-09-12T11:12:59.010119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_mean(list_of_lists):\n    maxlen = max([len(l) for l in list_of_lists])\n    for i in range(len(list_of_lists)):\n        while len(list_of_lists[i]) < maxlen:\n            list_of_lists[i].append(np.nan)\n    return np.nanmax(list_of_lists, axis=1)\n\ndef get_char_logits(examples, features, raw_predictions):\n    all_start_logits, all_end_logits = raw_predictions\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n\n    all_char_start_logits = {}\n    all_char_end_logits = {}\n    for example_index, example in enumerate(tqdm(examples)):\n        feature_indices = features_per_example[example_index]\n        context = example[\"context\"]\n        char_start_logits = [[] for _ in range(len(context))]\n        char_end_logits = [[] for _ in range(len(context))]\n        for feature_index in feature_indices:\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n            for token_index, om in enumerate(offset_mapping):\n                if om is None:\n                    continue\n                start_char_idx, end_char_idx = om[0], om[1]\n                for char_index in range(start_char_idx, end_char_idx):\n                    char_start_logits[char_index].append(start_logits[token_index])\n                    char_end_logits[char_index].append(end_logits[token_index])\n        char_start_logits = my_mean(char_start_logits)\n        char_start_logits[np.isnan(char_start_logits)] = 0\n        char_end_logits = my_mean(char_end_logits)\n        char_end_logits[np.isnan(char_end_logits)] = 0\n        all_char_start_logits[example['id']] = char_start_logits\n        all_char_end_logits[example['id']] = char_end_logits\n    \n    return all_char_start_logits, all_char_end_logits\n\ndef beam_search(char_start_logits, char_end_logits, beam_size=20, max_len=100):\n    beam_start_indices = np.argsort(char_start_logits)[-beam_size:]\n    beam_end_indices = np.argsort(char_end_logits)[-beam_size:]\n    idx_pairs = []\n    scores = []\n    for sidx in beam_start_indices:\n        for eidx in beam_end_indices:\n            leng = eidx - sidx\n            if leng > 0 and leng < max_len:\n                idx_pairs.append([sidx, eidx])\n                scores.append(char_start_logits[sidx]+char_end_logits[eidx])\n    best_score = -1e5\n    for i, score in enumerate(scores):\n        if score > best_score:\n            best_score = score\n            besti = i\n    if best_score == -1e5:\n        return [0, 0]\n    return idx_pairs[besti]\n\ndef remove_consdup(a, reserve_head=True):\n    array = a if reserve_head else np.flip(a)\n    last_ele = 1e5\n    for i in range(len(array)):\n        if array[i] != last_ele:\n            last_ele = array[i]\n        else:\n            array[i] = -1e5\n    return array if reserve_head else np.flip(array)\n\ndef get_predictions(examples, all_char_start_logits, all_char_end_logits):\n    predictions = {}\n    for example_index, example in enumerate(tqdm(examples)):\n        id_ = example['id']\n        context = example[\"context\"]\n        char_start_logits = remove_consdup(all_char_start_logits[id_], reserve_head=True)\n        char_end_logits = remove_consdup(all_char_end_logits[id_], reserve_head=False)\n        best_start_idx, best_end_idx = beam_search(char_start_logits, char_end_logits, max_len=100)\n        predictions[id_] = context[best_start_idx:best_end_idx+1]\n    return predictions\n\ndef left_strip(s):\n    reg = [' ', '\\n', '(', ')', '.', ',', \"'\", '\\t', '''\"''', '[', ']', '-', '_', '!', '?', '#', '*']\n    while True:\n        if (s[0] not in reg) or (len(s) < 2):\n            break\n        s = s[1:]\n    return s\n\ndef right_strip(s):\n    reg = [' ', '\\n', '(', ')', '.', ',', \"'\", '\\t', '''\"''', '[', ']', '-', '_', '!', '?', '#', '*']\n    while True:\n        if (s[-1] not in reg) or (len(s) < 2):\n            break\n        s = s[:-1]\n    return s\n\ndef find_year(s):\n    match = re.match(r'.*([1-3][0-9]{3})', s)\n    if match is None:\n        return s\n    y = match.group(1)\n    if y + ' ई.' in s:\n        return y + ' ई.'\n    if y + ' ई.पू.' in s:\n        return y + ' ई.पू.'\n    return y\n\ndef find_year_v2(s):\n    words = s.split()\n    year_words = []\n    for w in words:\n        if len(w) == 4 and w.isdigit():\n            year_words.append(w)\n    if year_words:\n        s1 = ' '.join(year_words)\n        if s1 + ' ई.' in s:\n            return s1 + ' ई.'\n        if s1 + ' ई.पू.' in s:\n            return s1 + ' ई.पू.'\n        return s1\n    return s\n\ndef get_number(s):\n    s1 = [c for c in s if c.isdigit() or c in [' ', ',']]\n    s2 = ''\n    for c in s1:\n        if s2 + c in s:\n            s2 += c\n        else:\n            break\n    if not s2:\n        return s\n    return s2\n\ndef get_country(s):\n    tamil_countries = ['ஆப்கானிஸ்தான்', 'அல்பேனியா', 'அல்ஜீரியா', 'அமெரிக்கன் சமோவா',\n       'அன்டோரா', 'அங்கோலா', 'அங்குயில்லா', 'ஆண்டிகுவா & பார்புடா',\n       'அர்ஜென்டினா', 'ஆர்மேனியா', 'அருபா', 'ஆஸ்திரேலியா', 'ஆஸ்திரியா',\n       'அஜர்பைஜான்', 'பஹாமாஸ், தி', 'பஹ்ரைன்', 'பங்களாதேஷ்',\n       'பார்படாஸ்', 'பெலாரஸ்', 'பெல்ஜியம்', 'பெலிஸ்', 'பெனின்',\n       'பெர்முடா', 'பூடான்', 'பொலிவியா', 'போஸ்னியா & ஹெர்சகோவினா',\n       'போட்ஸ்வானா', 'பிரேசில்', 'பிரிட்டிஷ் விர்ஜின் இஸ். ', 'புருனே',\n       'பல்கேரியா', 'புர்கினா பாசோ', 'பர்மா', 'புருண்டி', 'கம்போடியா',\n       'கேமரூன்', 'கனடா', 'கேப் வெர்டே', 'கேமன் தீவுகள்',\n       'மத்திய ஆப்பிரிக்க பிரதிநிதி', 'சாட்', 'சிலி', 'சீனா', 'கொலம்பியா',\n       'கொமரோஸ்', 'காங்கோ, டெம். பிரதிநிதி. ', 'காங்கோ, குடியரசு. இன் ',\n       'குக் தீவுகள்', 'கோஸ்டா ரிகா', \"கோட் டி ஐவரி\", 'குரோஷியா',\n       'கியூபா', 'சைப்ரஸ்', 'செக் குடியரசு', 'டென்மார்க்', 'ஜிபூட்டி',\n       'டொமினிகா', 'டொமினிகன் குடியரசு', 'கிழக்கு திமோர்', 'ஈக்வடார்',\n       'எகிப்து', 'எல் சால்வடார்', 'எக்குவடோரியல் கினியா', 'எரித்ரியா',\n       'எஸ்டோனியா', 'எத்தியோப்பியா', 'ஃபாரோ தீவுகள்', 'பிஜி', 'பின்லாந்து',\n       'பிரான்ஸ்', 'பிரெஞ்சு கயானா', 'பிரெஞ்சு பாலினேசியா', 'கபோன்',\n       'காம்பியா, தி', 'காசா பகுதி', 'ஜார்ஜியா', 'ஜெர்மனி', 'கானா',\n       'ஜிப்ரால்டர்', 'கிரீஸ்', 'கிரீன்லாந்து', 'கிரெனடா', 'குவாடலூப்',\n       'குவாம்', 'குவாத்தமாலா', 'குர்ன்சி', 'கினியா', 'கினியா-பிசாவ்',\n       'கயானா', 'ஹைட்டி', 'ஹோண்டுராஸ்', 'ஹாங்காங்', 'ஹங்கேரி',\n       'ஐஸ்லாந்து', 'இந்தியா', 'இந்தோனேசியா', 'ஈரான்', 'ஈராக்', 'அயர்லாந்து',\n       'ஐல் ஆஃப் மேன்', 'இஸ்ரேல்', 'இத்தாலி', 'ஜமைக்கா', 'ஜப்பான்',\n       'ஜெர்சி', 'ஜோர்டான்', 'கஜகஸ்தான்', 'கென்யா', 'கிரிபதி',\n       'கொரியா, வடக்கு', 'கொரியா, தெற்கு', 'குவைத்', 'கிர்கிஸ்தான்',\n       'லாவோஸ்', 'லாட்வியா', 'லெபனான்', 'லெசோதோ', 'லைபீரியா', 'லிபியா',\n       'லிச்டென்ஸ்டீன்', 'லிதுவேனியா', 'லக்சம்பர்க்', 'மக்காவ்',\n       'மசிடோனியா', 'மடகாஸ்கர்', 'மலாவி', 'மலேசியா', 'மாலத்தீவுகள்',\n       'மாலி', 'மால்டா', 'மார்ஷல் தீவுகள்', 'மார்டினிக்',\n       'மௌரிடானியா', 'மொரிஷியஸ்', 'மயோட்', 'மெக்சிகோ',\n       'மைக்ரோனேசியா, ஃபெட். செயின்ட்', 'மால்டோவா', 'மொனாக்கோ', 'மங்கோலியா',\n       'மான்செராட்', 'மொராக்கோ', 'மொசாம்பிக்', 'நமீபியா', 'நவ்ரு',\n       'நேபாளம்', 'நெதர்லாந்து', 'நெதர்லாந்து அண்டிலிஸ்',\n       'நியூ கலிடோனியா', 'நியூசிலாந்து', 'நிகரகுவா', 'நைஜர்',\n       'நைஜீரியா', 'என். மரியானா தீவுகள்', 'நோர்வே', 'ஓமன்', 'பாகிஸ்தான்',\n       'பலாவ்', 'பனாமா', 'பப்புவா நியூ கினியா', 'பராகுவே', 'பெரு',\n       'பிலிப்பைன்ஸ்', 'போலந்து', 'போர்ச்சுகல்', 'புவேர்ட்டோ ரிக்கோ', 'கத்தார்',\n       'ரீயூனியன்', 'ருமேனியா', 'ரஷ்யா', 'ருவாண்டா', 'செயின்ட் ஹெலினா',\n       'செயின்ட் கிட்ஸ் & நெவிஸ்', 'செயின்ட் லூசியா', 'செயின்ட் பியர் & மிக்குலோன்',\n       'செயின்ட் வின்சென்ட் மற்றும் கிரெனடைன்ஸ்', 'சமோவா', 'சான் மரினோ',\n       'Sao Tome & Principe', 'சவூதி அரேபியா', 'செனகல்', 'செர்பியா',\n       'சீஷெல்ஸ்', 'சியரா லியோன்', 'சிங்கப்பூர்', 'ஸ்லோவாக்கியா',\n       'ஸ்லோவேனியா', 'சாலமன் தீவுகள்', 'சோமாலியா', 'தென் ஆப்பிரிக்கா',\n       'ஸ்பெயின்', 'இலங்கை', 'சூடான்', 'சுரினாம்', 'ஸ்வாசிலாந்து',\n       'ஸ்வீடன்', 'சுவிட்சர்லாந்து', 'சிரியா', 'தைவான்', 'தஜிகிஸ்தான்',\n       'தான்சானியா', 'தாய்லாந்து', 'டோகோ', 'டோங்கா', 'டிரினிடாட் & டொபாகோ',\n       'துனிசியா', 'துருக்கி', 'துர்க்மெனிஸ்தான்', 'டர்க்ஸ் & கெய்கோஸ்',\n       'துவாலு', 'உகாண்டா', 'உக்ரைன்', 'ஐக்கிய அரபு எமிரேட்ஸ்',\n       'யுனைடெட் கிங்டம்', 'யுனைடெட் ஸ்டேட்ஸ்', 'உருகுவே', 'உஸ்பெகிஸ்தான்',\n       'வனுவாடு', 'வெனிசுலா', 'வியட்நாம்', 'விர்ஜின் தீவுகள்',\n       'வாலிஸ் அண்ட் ஃபுடுனா', 'வெஸ்ட் பேங்க்', 'வெஸ்டர்ன் சஹாரா', 'யேமன்',\n       'சாம்பியா', 'ஜிம்பாப்வே']\n    for c in tamil_countries:\n        if c in s:\n            return c\n    return s\n\ndef my_pp(s, question, context):\n    s = left_strip(s)\n    \n    # A.G. \n    sp = s.split()\n    if len(sp) >= 2 and sp[-1][-1] == '.' and sp[-2][-1] == '.':\n        return s\n    \n#     # xxx (xxx\n#     if '(' in s:\n#         s = s[:s.find('(')]\n    \n    s = right_strip(s)\n    \n    \n    # nico pp\n    tamil_ad = \"கி.பி\"\n    tamil_bc = \"கி.மு\"\n    tamil_km = \"கி.மீ\"\n    hindi_ad = \"ई\"\n    hindi_bc = \"ई.पू\"\n    if any([s.endswith(tamil_ad), s.endswith(tamil_bc), s.endswith(tamil_km), s.endswith(hindi_ad), s.endswith(hindi_bc)]) and s+\".\" in context:\n        s = s+\".\"\n    \n#     # hindi which year + tamil which year எந்த ஆண்டு\n    if 'किस वर्ष' in question or 'எந்த ஆண்டு' in question:\n        s = find_year(s)\n    \n    # hindi which year v2\n#     if 'किस वर्ष' in question:\n#         s = find_year_v2(s)\n    \n    # tamil area\n    if question.endswith('பரப்பளவு என்ன?'):\n        if s[-1].isnumeric():\n            if s + ' சதுர கிலோமீட்டர்கள்' in context:\n                s = s + ' சதுர கிலோமீட்டர்கள்'\n            elif s + ' சதுர கிலோ மீட்டர்' in context:\n                s = s + ' சதுர கிலோ மீட்டர்'\n            elif s + ' சதுர கிலோ மீட்டர்கள்' in context:\n                s = s + ' சதுர கிலோ மீட்டர்கள்'\n            elif s + ' சதுர மைல்கள்' in context:\n                s = s + ' சதுர மைல்கள்'\n            elif s + ' சதுர' in context:\n                s = s + ' சதுர'\n            elif s + ' கி.மீ²' in context:\n                s = s + ' கி.மீ²'\n        else:\n            if s + '²' in context:\n                s = s + '²'\n            elif s + '2' in context:\n                s = s + '2'\n    \n    # hindi number\n    if 'संख्या' in question:\n        s = get_number(s)\n        \n    #a(b) -> a\n    if '(' in s:\n        s = s[:s.find('(')]\n        \n    #tamil country extract\n    if question.endswith('நாடு எது?') or question.startswith('எந்த நாடு'):\n        s = get_country(s)\n    \n    # tamil years old\n    if 'வயதில்' in question:\n        s = get_number(s)\n        \n    # negative number recover\n#     if s[0].isdigit():\n#         if context.count(s) == context.count(' -' + s):\n#             s = '-' + s        \n        \n    # fix typos\n    # japan\n    if s == 'சப்பான்' and 'ஜப்பான்' in context:\n        return 'ஜப்பான்'\n    # mubai\n    if s == 'मुंबई' and 'मुम्बई' in context:\n        return 'मुम्बई'\n        \n    return s\n    \n        \ndef softmax(array):\n    ctx = np.exp(array)\n    return ctx / np.sum(ctx)\n\ndef tez_pp(s):\n    from string import punctuation\n    s = \" \".join(s.split())\n    s = s.strip(punctuation)\n    return s\n\ndef get_len(x):\n    x['seq_len'] = len(x['attention_mask'])\n    return x\n\ndef get_batches(features, batch_size=16, pad_id=0):\n    attention_mask = features['attention_mask']\n    input_ids = features['input_ids']\n    ret = []\n    for i in tqdm(range(0, len(attention_mask), batch_size)):\n        batch_attention_mask = attention_mask[i:i+batch_size]\n        batch_input_ids = input_ids[i:i+batch_size]\n        maxlen = max([len(x) for x in batch_attention_mask])\n        padded_batch_attention_mask = [x+[pad_id]*(maxlen-len(x)) for x in batch_attention_mask]\n        padded_batch_input_ids = [x+[pad_id]*(maxlen-len(x)) for x in batch_input_ids]\n        batch = {\n            'attention_mask': torch.tensor(padded_batch_attention_mask, device=device),\n            'input_ids': torch.tensor(padded_batch_input_ids, device=device),\n        }\n        ret.append(batch)\n    return ret\n\ndef pad_back(logits):\n    return F.pad(logits, pad=(0, 512-logits.shape[1]), mode='constant', value=-1e5)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:37:35.346744Z","iopub.execute_input":"2021-09-12T11:37:35.347096Z","iopub.status.idle":"2021-09-12T11:37:35.380271Z","shell.execute_reply.started":"2021-09-12T11:37:35.347065Z","shell.execute_reply":"2021-09-12T11:37:35.379325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\ntest_dataset = Dataset.from_pandas(test)\nexample_id_to_index = {k: i for i, k in enumerate(test_dataset[\"id\"])}\nblend_start_logits, blend_end_logits = collections.defaultdict(list), collections.defaultdict(list)\nfor i in range(len(pretrained_paths)):\n    print(f'#model: {i}')\n    start1 = time.time()\n    pretrained_path = pretrained_paths[i]\n    model_path = model_paths[i]\n    mymodel = mymodels[i]\n    max_length = max_lengths[i]\n    doc_stride = doc_strides[i]\n    \n    if i != 3:\n        tokenizer = AutoTokenizer.from_pretrained(pretrained_path)\n        pad_on_right = tokenizer.padding_side == \"right\"\n        test_features = test_dataset.map(\n            lambda x: prepare_validation_features(x, tokenizer, max_length, doc_stride, pad_on_right, padding=False),\n            batched=True,\n            remove_columns=test_dataset.column_names,\n            num_proc=2\n        )\n        test_features = test_features.map(get_len, num_proc=2)\n        test_features = test_features.sort('seq_len')\n        test_dataloader = get_batches(test_features, batch_size=16, pad_id=tokenizer.pad_token_id)\n    model = ChaiiModelLoadHead(pretrained_path).to(device) if mymodel else AutoModelForQuestionAnswering.from_pretrained(pretrained_path).to(device)\n    model.eval()\n    all_start_logits = []\n    all_end_logits = []\n    print(f'init time {(time.time()-start1)//60} minutes')\n    \n    start1 = time.time()\n    exts = model_exts[i]\n    weight_paths = glob(os.path.join(model_path, '*.pt'))\n    for ii, ext in enumerate(exts):\n        weight_paths = [x for x in weight_paths if f'{ext}.pt' not in x]\n    for weight_path in weight_paths:\n        print('weight:', weight_path)\n        model.load_state_dict(torch.load(weight_path))\n        start_logits = []\n        end_logits = []\n        for batch in tqdm(test_dataloader, leave=False):\n            pred = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n            start_logits.append(pad_back(pred.start_logits))\n            end_logits.append(pad_back(pred.end_logits))\n        start_logits = torch.cat(start_logits, dim=0)\n        end_logits = torch.cat(end_logits, dim=0)\n        start_logits = start_logits.cpu().numpy()\n        end_logits = end_logits.cpu().numpy()\n        all_start_logits.append(start_logits)\n        all_end_logits.append(end_logits)\n    all_start_logits = np.array(all_start_logits)\n    all_end_logits = np.array(all_end_logits)\n    all_start_logits = np.mean(all_start_logits, axis=0)\n    all_end_logits = np.mean(all_end_logits, axis=0)\n    raw_predictions = [all_start_logits, all_end_logits]\n    print(f'inference time {(time.time()-start1)//60} minutes')\n    \n    start1 = time.time()\n    all_char_start_logits, all_char_end_logits = get_char_logits(test_dataset, test_features, raw_predictions)\n    for k in all_char_start_logits:\n        if dosoftmax:\n            blend_start_logits[k].append(softmax(all_char_start_logits[k]))\n            blend_end_logits[k].append(softmax(all_char_end_logits[k]))\n        else:\n            blend_start_logits[k].append(all_char_start_logits[k])\n            blend_end_logits[k].append(all_char_end_logits[k])\n    print(f'char mapping time {(time.time()-start1)//60} minutes')","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:39:17.196641Z","iopub.execute_input":"2021-09-12T11:39:17.197025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blend","metadata":{}},{"cell_type":"code","source":"\nblended_start_logits, blended_end_logits = {}, {}\nfor k in blend_start_logits:\n    blended_start_logits[k] = np.average(np.array(blend_start_logits[k]), axis=0, weights=weights)\n    blended_end_logits[k] = np.average(np.array(blend_end_logits[k]), axis=0, weights=weights)\npredictions = get_predictions(test_dataset, blended_start_logits, blended_end_logits)\npredictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = test.copy().reset_index(drop=True)\nsub['PredictionString'] = sub['id'].apply(lambda r: predictions[r])\n# sub['PredictionString'] = sub['PredictionString'].apply(my_pp)\n# sub['PredictionString'] = sub['PredictionString'].apply(tez_pp)\nfor i in range(len(sub)):\n    pred = sub.loc[i, 'PredictionString']\n    ctx = sub.loc[i, 'context']\n    qst = sub.loc[i, 'question']\n    sub.loc[i, 'PredictionString'] = my_pp(pred, qst, ctx)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/train.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test for leak\nfor i in range(len(sub)):\n    question = sub.loc[i, 'question']\n    context = sub.loc[i, 'context']\n    matches = train[train['question'] == question].reset_index(drop=True)\n    for j in range(len(matches)):\n        new_ans = matches.loc[j, 'answer_text']\n        if new_ans in context:\n            sub.loc[i, 'PredictionString'] = new_ans\n            break\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = sub[['id', 'PredictionString']]\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duration = time.time() - start\nprint(f'duration: {duration//60} minutes')","metadata":{},"execution_count":null,"outputs":[]}]}