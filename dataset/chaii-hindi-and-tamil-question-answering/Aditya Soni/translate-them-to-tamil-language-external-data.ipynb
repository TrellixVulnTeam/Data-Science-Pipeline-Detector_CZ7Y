{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- We are trying to translate a [sample] of the squad dataset into tamil and building one for us!\n\n### blue-print...\n- In the first cell, we do some house keeping stuff and setup precisely what we need.\n- In the second cell, we are downloading the model which can translate to 12 different indic languages.\n\n- Rest cells, I believe are intuitive :) (they include doing some prep stuff, laoding model and finally translating them)\n\n\n\n# citation\n\n**Give credits where it's due....**\n\n```\n@misc{ramesh2021samanantar,\n      title={Samanantar: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages},\n      author={Gowtham Ramesh and Sumanth Doddapaneni and Aravinth Bheemaraj and Mayank Jobanputra and Raghavan AK and Ajitesh Sharma and Sujit Sahoo and Harshita Diddee and Mahalakshmi J and Divyanshu Kakwani and Navneet Kumar and Aswin Pradeep and Kumar Deepak and Vivek Raghavan and Anoop Kunchukuttan and Pratyush Kumar and Mitesh Shantadevi Khapra},\n      year={2021},\n      eprint={2104.05596},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n\nSquad Dataset Used from Kaggle Datasets (by ananthu017) Ref -> https://www.kaggle.com/ananthu017/squad-csv-format\n\n####\n\n> - **PS Let me know if you are looking for a teammate!**\n> - **If this helped, do let me know if there were improvements!\"\n\n\n# What you get as output from the kernel?\n- Extra ~1k Tamil q&a machine translated for training! (Actually it's infinite because you can translate as many as you want)\n\n# version notes\n\n- in v3, Have updated the snips to remove newlines chars.","metadata":{}},{"cell_type":"code","source":"# setting up the env... (will take some time, please be patient, require active internet connection)\n\n# clone the repo for running evaluation\n!git clone https://github.com/AI4Bharat/indicTrans.git\n%cd indicTrans\n# clone requirements repositories\n!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n!git clone https://github.com/rsennrich/subword-nmt.git\n%cd ..\n\n# Install the necessary libraries\n!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n! pip install mosestokenizer subword-nmt\n# Install fairseq from source\n!git clone https://github.com/pytorch/fairseq.git\n%cd fairseq\n# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n!pip install --editable ./\n!python setup.py build_ext --inplace\n%cd ..\n\n# this import might not work without restarting runtime\n# from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# english-to-indic tranlated (machine generated dataset)\n# model from https://indicnlp.ai4bharat.org/indic-trans/\n# will take some time, so sit back and sip your coffee! (please avoid downloading again and again, push it to a kaggle dataset :pray:)\n\n!wget https://storage.googleapis.com/samanantar-public/V0.2/models/en-indic.zip\n!unzip ./en-indic.zip\n!rm -f en-indic.zip","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mosestokenizer import *\nfrom indicnlp.tokenize import sentence_tokenize\n\n# this import might not work without restarting runtime (just restart (clear outputs) and then execute this cell only)\nfrom fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n\n%cd ./indicTrans\n# load the tranlation model from that directory\n# from indicTrans.inference.engine import Model # because of this import, we have to do cd...\n# en2indic_model = Model(expdir='/kaggle/working/en-indic')\n# en2indic_model","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:50:34.559675Z","iopub.execute_input":"2021-08-23T07:50:34.55997Z","iopub.status.idle":"2021-08-23T07:50:37.907626Z","shell.execute_reply.started":"2021-08-23T07:50:34.559903Z","shell.execute_reply":"2021-08-23T07:50:37.90617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's load the sample squad dataset....\nimport pandas as pd\n\ndf = pd.read_csv(\n    \"/kaggle/input/squad-csv-format/SQuAD_csv.csv\", \n    usecols=[\"context\", \"question\", \"id\", \"text\", \"answer_start\"],\n    nrows = 2**10, # sample\n)\ndf.drop_duplicates(subset=[\"context\"], inplace=True)\ndf.reset_index(drop=True, inplace=True)\n\nprint(df.shape)\n\n# items to translate\nen_context = list(df[\"context\"].values)\nen_question = list(df[\"question\"].values)\nen_answer_text = list(df[\"text\"].values)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:50:37.909747Z","iopub.execute_input":"2021-08-23T07:50:37.910132Z","iopub.status.idle":"2021-08-23T07:50:37.9946Z","shell.execute_reply.started":"2021-08-23T07:50:37.910092Z","shell.execute_reply":"2021-08-23T07:50:37.993657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# writing the paragraphs line-by-line\n\nimport io\nfrom tqdm.auto import tqdm\n\nwith io.open(\"en_paragraphs.txt\", \"w\") as f_ptr:\n    for line in en_context:\n        f_ptr.write(line.replace(\"\\n\", \"\").strip())\n        f_ptr.write(\"\\n\")\n\nwith io.open(\"en_question.txt\", \"w\") as f_ptr:\n    for line in en_question:\n        f_ptr.write(line.replace(\"\\n\", \"\").strip())\n        f_ptr.write(\"\\n\")\n\nwith io.open(\"en_answer_text.txt\", \"w\") as f_ptr:\n    for line in en_answer_text:\n        f_ptr.write(line.strip())\n        f_ptr.write(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:50:37.996203Z","iopub.execute_input":"2021-08-23T07:50:37.996561Z","iopub.status.idle":"2021-08-23T07:50:38.005627Z","shell.execute_reply.started":"2021-08-23T07:50:37.996523Z","shell.execute_reply":"2021-08-23T07:50:38.004778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the line counts\n!wc -l \"en_paragraphs.txt\" \"en_answer_text.txt\" \"en_question.txt\"","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:50:38.006996Z","iopub.execute_input":"2021-08-23T07:50:38.007334Z","iopub.status.idle":"2021-08-23T07:50:38.664181Z","shell.execute_reply.started":"2021-08-23T07:50:38.007299Z","shell.execute_reply":"2021-08-23T07:50:38.663098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile joint_translate_updated.sh\n\n#!/bin/bash\necho `date`\ninfname=$1\noutfname=$2\nsrc_lang=$3\ntgt_lang=$4\nexp_dir=$5\nref_fname=$6\n\nSRC_PREFIX='SRC'\nTGT_PREFIX='TGT'\n\n#`dirname $0`/env.sh\nSUBWORD_NMT_DIR='subword-nmt'\nmodel_dir=$exp_dir/model\ndata_bin_dir=$exp_dir/final_bin\n\n### normalization and script conversion\n\necho \"Applying normalization and script conversion\"\ninput_size=`python scripts/preprocess_translate.py $infname $outfname.norm $src_lang true`\necho \"Number of sentences in input: $input_size\"\n\n### apply BPE to input file\n\necho \"Applying BPE\"\npython $SUBWORD_NMT_DIR/subword_nmt/apply_bpe.py \\\n    -c $exp_dir/vocab/bpe_codes.32k.${SRC_PREFIX} \\\n    --vocabulary $exp_dir/vocab/vocab.$SRC_PREFIX \\\n    --vocabulary-threshold 5 \\\n    < $outfname.norm \\\n    > $outfname._bpe\n\n# not needed for joint training\n# echo \"Adding language tags\"\npython scripts/add_tags_translate.py $outfname._bpe $outfname.bpe $src_lang $tgt_lang\n\n### run decoder\n\necho \"Decoding\"\n\nsrc_input_bpe_fname=$outfname.bpe\ntgt_output_fname=$outfname\n\nfairseq-interactive  $data_bin_dir \\\n    -s $SRC_PREFIX -t $TGT_PREFIX \\\n    --distributed-world-size 1 --fp16 \\\n    --path $model_dir/checkpoint_best.pt \\\n    --batch-size 32 --buffer-size 1024 --data-buffer-size 8 --beam 5 --remove-bpe \\\n    --skip-invalid-size-inputs-valid-test \\\n    --user-dir model_configs \\\n    --input $src_input_bpe_fname  >  $tgt_output_fname.log 2>&1\n\n\necho \"Extracting translations, script conversion and detokenization\"\n# this part reverses the transliteration from devnagiri script to target lang and then detokenizes it.\npython scripts/postprocess_translate.py $tgt_output_fname.log $tgt_output_fname $input_size $tgt_lang true\necho \"Translation completed\"","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-23T07:50:38.667767Z","iopub.execute_input":"2021-08-23T07:50:38.668079Z","iopub.status.idle":"2021-08-23T07:50:38.677957Z","shell.execute_reply.started":"2021-08-23T07:50:38.668049Z","shell.execute_reply":"2021-08-23T07:50:38.677184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# joint_translate.sh is a shell script that takes args in the following order as inputs <src_file>, <output_fname>, <src_lang>, <tgt_lang>, <model_folder>\n# it's quite fast if you are using GPU, do increase the. batch size from 64 as well in the shell snip that's hard-coded..\n# <6 mins for ~90k sentences is not bad at all....\n\n# src_file -> input text file to be translated\n# output_fname -> name of the output file (will get created) containing the model predictions\n# src_lang -> source lang code of the input text ( in this case we are using en-indic model and hence src_lang would be 'en')\n# tgt_lang -> target lang code of the input text ( tgt lang for en-indic model would be any of the 11 indic langs we trained on:\n# model_folder -> where's the model file located\n\n\n!chmod 777 ./joint_translate_updated.sh\n\n!./joint_translate_updated.sh en_paragraphs.txt ta_paragraphs.txt \"en\" \"ta\" '../en-indic'\n!./joint_translate_updated.sh en_question.txt ta_question.txt \"en\" \"ta\" '../en-indic'\n!./joint_translate_updated.sh en_answer_text.txt ta_answer_text.txt \"en\" \"ta\" '../en-indic'","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:50:49.247651Z","iopub.execute_input":"2021-08-23T07:50:49.248005Z","iopub.status.idle":"2021-08-23T07:52:28.487413Z","shell.execute_reply.started":"2021-08-23T07:50:49.247973Z","shell.execute_reply":"2021-08-23T07:52:28.486338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# en_context, en_question, en_answer_text -- for english stuff\n\n# read the context from the file \"ta_paragraphs.txt\"\nwith io.open(\"ta_paragraphs.txt\", \"r\") as f_ptr:\n    ta_context = [line.strip() for line in f_ptr]\n\n# read the context from the file \"ta_question.txt\"\nwith io.open(\"ta_question.txt\", \"r\") as f_ptr:\n    ta_question = [line.strip() for line in f_ptr]\n\n# read the context from the file \"ta_answer_text.txt\"\nwith io.open(\"ta_answer_text.txt\", \"r\") as f_ptr:\n    ta_en_answer_text = [line.strip() for line in f_ptr]","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:33.491836Z","iopub.execute_input":"2021-08-23T07:52:33.492227Z","iopub.status.idle":"2021-08-23T07:52:33.500451Z","shell.execute_reply.started":"2021-08-23T07:52:33.492191Z","shell.execute_reply":"2021-08-23T07:52:33.499364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = 0\ngood_ids = set()\nfor idx in range(len(ta_en_answer_text)):\n    if ta_en_answer_text[idx] in ta_context[idx]:\n        # basically naswer is present as-is in the translated text\n        cnt += 1\n        good_ids.add(idx)\ncnt / len(ta_en_answer_text), len(good_ids) # 22% is not bad!","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:33.764381Z","iopub.execute_input":"2021-08-23T07:52:33.764719Z","iopub.status.idle":"2021-08-23T07:52:33.774617Z","shell.execute_reply.started":"2021-08-23T07:52:33.764689Z","shell.execute_reply":"2021-08-23T07:52:33.773613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nwith open(\"ta_question.pkl\", \"wb\") as f_ptr:\n    pickle.dump(ta_question, f_ptr)\n\nwith open(\"ta_en_answer_text.pkl\", \"wb\") as f_ptr:\n    pickle.dump(ta_en_answer_text, f_ptr)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:36.331209Z","iopub.execute_input":"2021-08-23T07:52:36.331605Z","iopub.status.idle":"2021-08-23T07:52:36.337091Z","shell.execute_reply.started":"2021-08-23T07:52:36.331573Z","shell.execute_reply":"2021-08-23T07:52:36.336142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! cp \"ta_paragraphs.txt\" \"/kaggle/working\"\n! cp \"ta_question.txt\" \"/kaggle/working\"\n! cp \"ta_answer_text.txt\" \"/kaggle/working\"\n\n! cp \"en_paragraphs.txt\" \"/kaggle/working\"\n! cp \"en_question.txt\" \"/kaggle/working\"\n! cp \"en_answer_text.txt\" \"/kaggle/working\"\n\n! cp \"ta_en_answer_text.pkl\" \"/kaggle/working\"\n! cp \"ta_question.pkl\" \"/kaggle/working\"","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:36.618464Z","iopub.execute_input":"2021-08-23T07:52:36.618807Z","iopub.status.idle":"2021-08-23T07:52:41.840937Z","shell.execute_reply.started":"2021-08-23T07:52:36.618775Z","shell.execute_reply":"2021-08-23T07:52:41.839824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare the dataframe that we can use directly.\n# sample data\nta_question[0], ta_en_answer_text[0], ta_context[0], en_context[0], en_answer_text[0], en_question[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:41.844739Z","iopub.execute_input":"2021-08-23T07:52:41.845059Z","iopub.status.idle":"2021-08-23T07:52:41.855395Z","shell.execute_reply.started":"2021-08-23T07:52:41.845029Z","shell.execute_reply":"2021-08-23T07:52:41.854442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\n\n@dataclass\nclass TamilExtraData:\n    ta_context :str\n    ta_question :str\n    ta_answer_text :str\n    en_context :str\n    en_question :str\n    en_answer_text :str","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:45.154463Z","iopub.execute_input":"2021-08-23T07:52:45.154803Z","iopub.status.idle":"2021-08-23T07:52:45.162886Z","shell.execute_reply.started":"2021-08-23T07:52:45.154771Z","shell.execute_reply":"2021-08-23T07:52:45.161846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data = []\nfor idx in good_ids:\n    final_data.append(\n        TamilExtraData(\n            ta_context=ta_context[idx], ta_answer_text=ta_en_answer_text[idx], ta_question=ta_question[idx],\n            en_context=en_context[idx], en_answer_text=en_answer_text[idx], en_question=en_question[idx],\n        ).__dict__\n    )","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:45.637374Z","iopub.execute_input":"2021-08-23T07:52:45.637723Z","iopub.status.idle":"2021-08-23T07:52:45.645256Z","shell.execute_reply.started":"2021-08-23T07:52:45.637689Z","shell.execute_reply":"2021-08-23T07:52:45.644306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame.from_records(final_data)\ndf[\"answer_start\"] = df[[\"ta_context\", \"ta_answer_text\"]].apply(lambda row: row[0].find(row[1]), axis=1)\n# df[\"answer_end\"] = df[[\"context\", \"answer_text\"]].apply(lambda row: row[0].find(row[1]) + len(row[1]), axis=1)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:46.232559Z","iopub.execute_input":"2021-08-23T07:52:46.232926Z","iopub.status.idle":"2021-08-23T07:52:46.264412Z","shell.execute_reply.started":"2021-08-23T07:52:46.23286Z","shell.execute_reply":"2021-08-23T07:52:46.263401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"/kaggle/working/tamil_extra_translated_data.csv\", index=None) # almost extra 1000 tamil dataset rows... Enjoy People...","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:47.314751Z","iopub.execute_input":"2021-08-23T07:52:47.315159Z","iopub.status.idle":"2021-08-23T07:52:47.325775Z","shell.execute_reply.started":"2021-08-23T07:52:47.315126Z","shell.execute_reply":"2021-08-23T07:52:47.324954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean-up cell [be SUPER careful when you run this guy]\n!rm -rf *\n%cd ..\n!rm -rf ./en-indic/\n!rm -rf ./fairseq/\n!rm -rf ./indicTrans/\n!ls","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:48.88432Z","iopub.execute_input":"2021-08-23T07:52:48.884668Z","iopub.status.idle":"2021-08-23T07:52:52.577707Z","shell.execute_reply.started":"2021-08-23T07:52:48.884636Z","shell.execute_reply":"2021-08-23T07:52:52.576687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls # much better!","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:52.580582Z","iopub.execute_input":"2021-08-23T07:52:52.580967Z","iopub.status.idle":"2021-08-23T07:52:53.235533Z","shell.execute_reply.started":"2021-08-23T07:52:52.580925Z","shell.execute_reply":"2021-08-23T07:52:53.234495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# translated texts...\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-23T07:52:53.237671Z","iopub.execute_input":"2021-08-23T07:52:53.238055Z","iopub.status.idle":"2021-08-23T07:52:53.258527Z","shell.execute_reply.started":"2021-08-23T07:52:53.238015Z","shell.execute_reply":"2021-08-23T07:52:53.25748Z"},"trusted":true},"execution_count":null,"outputs":[]}]}