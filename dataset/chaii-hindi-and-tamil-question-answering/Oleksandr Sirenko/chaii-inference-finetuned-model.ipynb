{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install --no-index --find-links ../input/huggingface-datasets datasets -qq","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-19T22:02:19.956727Z","iopub.execute_input":"2021-08-19T22:02:19.957179Z","iopub.status.idle":"2021-08-19T22:02:29.890064Z","shell.execute_reply.started":"2021-08-19T22:02:19.95709Z","shell.execute_reply":"2021-08-19T22:02:29.888705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%html\n<style>\ntable {float:left}\n</style>","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-19T22:02:29.894399Z","iopub.execute_input":"2021-08-19T22:02:29.894725Z","iopub.status.idle":"2021-08-19T22:02:29.905497Z","shell.execute_reply.started":"2021-08-19T22:02:29.894688Z","shell.execute_reply":"2021-08-19T22:02:29.904302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is an inference notebook from the finetuned [XLM-Roberta model pretrained on SQUAD](https://www.kaggle.com/oleksandrsirenko/chaii-fine-tuning-model). For training, we used [formatted datasets](https://www.kaggle.com/oleksandrsirenko/chaii-squad) obtained from the original and external data. Scrips for converting data to SQuAD format you can [find here](https://www.kaggle.com/oleksandrsirenko/chaii-dataframe-and-external-data-to-squad).\n\n\n| Model              | Version  | LB Score|\n|:-------------------|:--------:|:-------:|\n| XLM Roberta large  | v11      | 0.736   |\n| XLM Roberta large  | v10      | 0.732   |\n| XLM Roberta large  | v9       | 0.717   |\n| XLM Roberta base   | v5       | 0.617   | \n| XLM Roberta base   | v4       | 0.629   |\n| XLM Roberta base   | v2       | 0.645   |","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport json\nimport collections\n\nfrom pathlib import Path\nfrom typing import List, Dict, Optional\nfrom pydantic import BaseModel\n\nimport datasets\nfrom transformers.trainer_utils import set_seed\nfrom transformers import (AutoTokenizer, PreTrainedTokenizerFast,\n                          AutoModelForQuestionAnswering, TrainingArguments,\n                          Trainer, default_data_collator, DataCollatorWithPadding,)\n\nfrom tqdm.auto import tqdm\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:02:58.56855Z","iopub.execute_input":"2021-08-19T22:02:58.568941Z","iopub.status.idle":"2021-08-19T22:02:58.576432Z","shell.execute_reply.started":"2021-08-19T22:02:58.568898Z","shell.execute_reply":"2021-08-19T22:02:58.574886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_json(from_path: Path) -> dict:\n    with open(from_path, 'r', encoding='utf-8') as out_file:\n        return json.load(out_file)\n        \ndef write_json(data: dict, out_path: Path) -> None:\n    with open(out_path, 'w', encoding='utf-8') as out_file:\n        json.dump(data, out_file, indent=2, sort_keys=True, ensure_ascii=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:28:51.691692Z","iopub.execute_input":"2021-08-19T22:28:51.692113Z","iopub.status.idle":"2021-08-19T22:28:51.701332Z","shell.execute_reply.started":"2021-08-19T22:28:51.69208Z","shell.execute_reply":"2021-08-19T22:28:51.70022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/chaii-roberta-large/'\nconfig = read_json(f'{path}xlm_roberta_large_squad2_finetuned_v11.json')\nconfig['model_path'] = f'{path}xlm-roberta-large-squad2-finetuned-v11/xlm-roberta-large-squad2-finetuned-v11'\nconfig['LB'] = 0.736\nwrite_json(config, './xlm_roberta_large_squad2_finetuned_v11.json')","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:47:46.027873Z","iopub.execute_input":"2021-08-19T22:47:46.028239Z","iopub.status.idle":"2021-08-19T22:47:46.037507Z","shell.execute_reply.started":"2021-08-19T22:47:46.028192Z","shell.execute_reply":"2021-08-19T22:47:46.036182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:36:44.099268Z","iopub.execute_input":"2021-08-19T22:36:44.099698Z","iopub.status.idle":"2021-08-19T22:36:44.105875Z","shell.execute_reply.started":"2021-08-19T22:36:44.099666Z","shell.execute_reply":"2021-08-19T22:36:44.10447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_to_squad_format(path: Path, out_name: str, lang: Optional[str] = None) -> Path:\n    df = pd.read_csv(path)\n    if lang:\n        df = df.loc[df.language == lang].copy()\n        out_name = f'{out_name}_{lang}'\n    \n    data = []\n    for _, row in df.iterrows():\n        answers = {}\n        try:\n            answers['answer_start'] = [int(row['answer_start'])]\n            answers['text'] = [row['answer_text']]\n        except:\n            answers = {'answer_start': [-1], 'text': ['']}\n        data.append(\n            {\n            'answers': answers,\n            'context': row['context'],\n            'id': row['id'],\n            'question': row['question'],\n            'title': ''\n            }\n        )\n    \n    df_as_squad = {'data': data, 'version': out_name}\n    \n    out_path = f'./{out_name}.json'\n    write_json(df_as_squad, out_path)\n    print('The data has been converted to SQuAD format and saved as a JSON object.')\n    return out_path","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:03:02.375911Z","iopub.execute_input":"2021-08-19T22:03:02.376431Z","iopub.status.idle":"2021-08-19T22:03:02.389941Z","shell.execute_reply.started":"2021-08-19T22:03:02.376357Z","shell.execute_reply":"2021-08-19T22:03:02.388591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chaii_test = datasets.load_dataset(\n    'json',\n    data_files=df_to_squad_format(config['test_path'], 'chaii_test'), \n    field='data',\n    split='train'\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:03:49.245863Z","iopub.execute_input":"2021-08-19T22:03:49.24625Z","iopub.status.idle":"2021-08-19T22:04:29.918308Z","shell.execute_reply.started":"2021-08-19T22:03:49.246216Z","shell.execute_reply":"2021-08-19T22:04:29.916791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chaii_test","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:04:34.298932Z","iopub.execute_input":"2021-08-19T22:04:34.299411Z","iopub.status.idle":"2021-08-19T22:04:34.308932Z","shell.execute_reply.started":"2021-08-19T22:04:34.299347Z","shell.execute_reply":"2021-08-19T22:04:34.307686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config['model_path'])\nmodel = AutoModelForQuestionAnswering.from_pretrained(config['model_path'])","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:06:08.321623Z","iopub.execute_input":"2021-08-19T22:06:08.321989Z","iopub.status.idle":"2021-08-19T22:06:33.28856Z","shell.execute_reply.started":"2021-08-19T22:06:08.321957Z","shell.execute_reply":"2021-08-19T22:06:33.287455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert isinstance(tokenizer, PreTrainedTokenizerFast)\npad_on_right = tokenizer.padding_side == \"right\"","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:07:03.019278Z","iopub.execute_input":"2021-08-19T22:07:03.019697Z","iopub.status.idle":"2021-08-19T22:07:03.024837Z","shell.execute_reply.started":"2021-08-19T22:07:03.019664Z","shell.execute_reply":"2021-08-19T22:07:03.023495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_validation_features(examples):\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=config['max_length'],\n        stride=config['doc_stride'],\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    \n    tokenized_examples[\"example_id\"] = []\n\n    for i in range(len(tokenized_examples[\"input_ids\"])):\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        context_index = 1 if pad_on_right else 0\n\n        sample_index = sample_mapping[i]\n        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n\n        tokenized_examples[\"offset_mapping\"][i] = [\n            (o if sequence_ids[k] == context_index else None)\n            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n        ]\n\n    return tokenized_examples","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:07:04.922788Z","iopub.execute_input":"2021-08-19T22:07:04.923191Z","iopub.status.idle":"2021-08-19T22:07:04.932465Z","shell.execute_reply.started":"2021-08-19T22:07:04.923159Z","shell.execute_reply":"2021-08-19T22:07:04.931212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features = chaii_test.map(\n    prepare_validation_features,\n    batched=True,\n    remove_columns=chaii_test.column_names\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:07:07.643052Z","iopub.execute_input":"2021-08-19T22:07:07.643459Z","iopub.status.idle":"2021-08-19T22:07:08.540461Z","shell.execute_reply.started":"2021-08-19T22:07:07.643422Z","shell.execute_reply":"2021-08-19T22:07:08.539354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    data_collator=default_data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:07:10.207531Z","iopub.execute_input":"2021-08-19T22:07:10.20791Z","iopub.status.idle":"2021-08-19T22:07:21.214832Z","shell.execute_reply.started":"2021-08-19T22:07:10.207865Z","shell.execute_reply":"2021-08-19T22:07:21.213617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = trainer.predict(test_features)\ntest_features.set_format(type=test_features.format[\"type\"], columns=list(test_features.features.keys()))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:07:22.809259Z","iopub.execute_input":"2021-08-19T22:07:22.809705Z","iopub.status.idle":"2021-08-19T22:07:29.115828Z","shell.execute_reply.started":"2021-08-19T22:07:22.809672Z","shell.execute_reply":"2021-08-19T22:07:29.114588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def postprocess_qa_predictions(examples, features, raw_predictions, tokenizer=tokenizer,\n                               squad_v2=config['squad_v2'], n_best_size=config['n_best_size'], \n                               max_answer_length=config['max_answer_length']):\n    \n    all_start_logits, all_end_logits = raw_predictions\n    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n\n    predictions = collections.OrderedDict()\n\n    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n    for example_index, example in enumerate(tqdm(examples)):\n        feature_indices = features_per_example[example_index]\n\n        min_null_score = None\n        valid_answers = []\n        \n        context = example[\"context\"]\n        \n        for feature_index in feature_indices:\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n\n            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n            if min_null_score is None or min_null_score < feature_null_score:\n                min_null_score = feature_null_score\n\n            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    if (\n                        start_index >= len(offset_mapping)\n                        or end_index >= len(offset_mapping)\n                        or offset_mapping[start_index] is None\n                        or offset_mapping[end_index] is None\n                    ):\n                        continue\n                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n                        continue\n\n                    start_char = offset_mapping[start_index][0]\n                    end_char = offset_mapping[end_index][1]\n                    valid_answers.append(\n                        {\n                            \"score\": start_logits[start_index] + end_logits[end_index],\n                            \"text\": context[start_char: end_char]\n                        }\n                    )\n        if len(valid_answers) > 0:\n            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n        else:\n            best_answer = {\"text\": \"\", \"score\": 0.0}\n        if not squad_v2:\n            predictions[example[\"id\"]] = best_answer[\"text\"]\n        else:\n            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n            predictions[example[\"id\"]] = answer\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:07:29.117713Z","iopub.execute_input":"2021-08-19T22:07:29.11819Z","iopub.status.idle":"2021-08-19T22:07:29.139678Z","shell.execute_reply.started":"2021-08-19T22:07:29.11813Z","shell.execute_reply":"2021-08-19T22:07:29.138541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = postprocess_qa_predictions(chaii_test, test_features, test_predictions.predictions)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:07:33.416817Z","iopub.execute_input":"2021-08-19T22:07:33.417221Z","iopub.status.idle":"2021-08-19T22:07:34.075223Z","shell.execute_reply.started":"2021-08-19T22:07:33.417187Z","shell.execute_reply":"2021-08-19T22:07:34.070524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(config['test_path'])\ntest_df['PredictionString'] = test_df['id'].apply(lambda x: predictions[x])\ntest_df[['id', 'PredictionString']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:07:36.213926Z","iopub.execute_input":"2021-08-19T22:07:36.214347Z","iopub.status.idle":"2021-08-19T22:07:36.237266Z","shell.execute_reply.started":"2021-08-19T22:07:36.214313Z","shell.execute_reply":"2021-08-19T22:07:36.23614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('./submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-19T22:07:38.285085Z","iopub.execute_input":"2021-08-19T22:07:38.285496Z","iopub.status.idle":"2021-08-19T22:07:38.306835Z","shell.execute_reply.started":"2021-08-19T22:07:38.285458Z","shell.execute_reply":"2021-08-19T22:07:38.305478Z"},"trusted":true},"execution_count":null,"outputs":[]}]}