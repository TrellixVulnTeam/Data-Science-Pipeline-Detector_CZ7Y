{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nimport gc\ngc.enable()\nimport math\nimport json\nimport time\nimport random\nimport multiprocessing\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm, trange\nfrom sklearn import model_selection\nfrom string import punctuation\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\nimport torch.optim as optim\nfrom torch.utils.data import (\n    Dataset, DataLoader,\n    SequentialSampler, RandomSampler\n)\nfrom torch.utils.data.distributed import DistributedSampler\n\ntry:\n    from apex import amp\n    APEX_INSTALLED = True\nexcept ImportError:\n    APEX_INSTALLED = False\n\nimport transformers\nfrom transformers import (\n    WEIGHTS_NAME,\n    AdamW,\n    AutoConfig,\n    AutoModel,\n    AutoTokenizer,\n    get_cosine_schedule_with_warmup,\n    get_linear_schedule_with_warmup,\n    logging,\n    MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n)\nlogging.set_verbosity_warning()\nlogging.set_verbosity_error()\n\ndef fix_all_seeds(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\ndef optimal_num_of_loader_workers():\n    num_cpus = multiprocessing.cpu_count()\n    num_gpus = torch.cuda.device_count()\n    optimal_value = min(num_cpus, num_gpus*4) if num_gpus else num_cpus - 1\n    return optimal_value\n\nprint(f\"Apex AMP Installed :: {APEX_INSTALLED}\")\nMODEL_CONFIG_CLASSES = list(MODEL_FOR_QUESTION_ANSWERING_MAPPING.keys())\nMODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)","metadata":{"papermill":{"duration":10.532611,"end_time":"2021-10-18T12:28:17.336584","exception":false,"start_time":"2021-10-18T12:28:06.803973","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.622059Z","iopub.execute_input":"2021-11-15T15:17:59.622337Z","iopub.status.idle":"2021-11-15T15:17:59.646308Z","shell.execute_reply.started":"2021-11-15T15:17:59.622307Z","shell.execute_reply":"2021-11-15T15:17:59.64557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class hindiConfig:\n    # model\n    model_type = 'xlm_roberta'\n    model_name_or_path = \"../input/roberta-transferred-to-hindi-tamil-with-wechsel/roberta-large-wechsel-hindi\"\n    config_name = \"../input/roberta-transferred-to-hindi-tamil-with-wechsel/roberta-large-wechsel-hindi\"\n    fp16 = True if APEX_INSTALLED else False\n    fp16_opt_level = \"O1\"\n    gradient_accumulation_steps = 2\n\n    # tokenizer\n    tokenizer_name = \"../input/roberta-transferred-to-hindi-tamil-with-wechsel/roberta-large-wechsel-hindi\"\n    max_seq_length = 456\n    doc_stride = 135\n\n    # train\n    epochs = 1\n    train_batch_size = 4\n    eval_batch_size = 128\n\n    # optimzer\n    optimizer_type = 'AdamW'\n    learning_rate = 1e-5\n    weight_decay = 1e-2\n    epsilon = 1e-8\n    max_grad_norm = 1.0\n\n    # scheduler\n    decay_name = 'linear-warmup'\n    warmup_ratio = 0.1\n\n    # logging\n    logging_steps = 10\n\n    # evaluate\n    output_dir = 'output'\n    seed = 42","metadata":{"papermill":{"duration":0.020196,"end_time":"2021-10-18T12:28:17.368906","exception":false,"start_time":"2021-10-18T12:28:17.34871","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.648219Z","iopub.execute_input":"2021-11-15T15:17:59.64848Z","iopub.status.idle":"2021-11-15T15:17:59.654493Z","shell.execute_reply.started":"2021-11-15T15:17:59.648445Z","shell.execute_reply":"2021-11-15T15:17:59.653792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class tamilConfig:\n    # model\n    model_type = 'xlm_roberta'\n    model_name_or_path = \"../input/roberta-transferred-to-hindi-tamil-with-wechsel/roberta-large-wechsel-tamil\"\n    config_name = \"../input/roberta-transferred-to-hindi-tamil-with-wechsel/roberta-large-wechsel-tamil\"\n    fp16 = True if APEX_INSTALLED else False\n    fp16_opt_level = \"O1\"\n    gradient_accumulation_steps = 2\n\n    # tokenizer\n    tokenizer_name = \"../input/roberta-transferred-to-hindi-tamil-with-wechsel/roberta-large-wechsel-tamil\"\n    max_seq_length = 456\n    doc_stride = 135\n\n    # train\n    epochs = 1\n    train_batch_size = 4\n    eval_batch_size = 128\n\n    # optimzer\n    optimizer_type = 'AdamW'\n    learning_rate = 1e-5\n    weight_decay = 1e-2\n    epsilon = 1e-8\n    max_grad_norm = 1.0\n\n    # scheduler\n    decay_name = 'linear-warmup'\n    warmup_ratio = 0.1\n\n    # logging\n    logging_steps = 10\n\n    # evaluate\n    output_dir = 'output'\n    seed = 2021","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:17:59.655881Z","iopub.execute_input":"2021-11-15T15:17:59.658267Z","iopub.status.idle":"2021-11-15T15:17:59.667068Z","shell.execute_reply.started":"2021-11-15T15:17:59.658228Z","shell.execute_reply":"2021-11-15T15:17:59.666354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetRetriever(Dataset):\n    def __init__(self, features, mode='train'):\n        super(DatasetRetriever, self).__init__()\n        self.features = features\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, item):   \n        feature = self.features[item]\n        if self.mode == 'train':\n            return {\n                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n                'offset_mapping':torch.tensor(feature['offset_mapping'], dtype=torch.long),\n                'start_position':torch.tensor(feature['start_position'], dtype=torch.long),\n                'end_position':torch.tensor(feature['end_position'], dtype=torch.long)\n            }\n        else:\n            return {\n                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n                'offset_mapping':feature['offset_mapping'],\n                'sequence_ids':feature['sequence_ids'],\n                'id':feature['example_id'],\n                'context': feature['context'],\n                'question': feature['question']\n            }","metadata":{"papermill":{"duration":0.023541,"end_time":"2021-10-18T12:28:17.404171","exception":false,"start_time":"2021-10-18T12:28:17.38063","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.67008Z","iopub.execute_input":"2021-11-15T15:17:59.670877Z","iopub.status.idle":"2021-11-15T15:17:59.681436Z","shell.execute_reply.started":"2021-11-15T15:17:59.670843Z","shell.execute_reply":"2021-11-15T15:17:59.680708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WeightedLayerPooling(nn.Module):\n    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights=None):\n        super(WeightedLayerPooling, self).__init__()\n        self.layer_start = layer_start\n        self.num_hidden_layers = num_hidden_layers\n        self.layer_weights = layer_weights if layer_weights is not None \\\n            else nn.Parameter(\n            torch.tensor([1] * (num_hidden_layers + 1 - layer_start), dtype=torch.float)\n        )\n\n    def forward(self, all_hidden_states):\n        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n        weighted_average = (weight_factor * all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n        return weighted_average\n\n\nclass Model(nn.Module):\n    def __init__(self, modelname_or_path, config, layer_start, layer_weights=None):\n        super(Model, self).__init__()\n        self.config = config\n        config.update({\n            \"hidden_dropout_prob\": 0.0,\n            \"layer_norm_eps\": 1e-7,\n            \"output_hidden_states\": True\n            \n        })\n        self.xlm_roberta = AutoModel.from_pretrained(modelname_or_path, config=config)\n        self.layer_start = layer_start\n        self.pooling = WeightedLayerPooling(config.num_hidden_layers,\n                                            layer_start=layer_start,\n                                            layer_weights=None)\n        self.layer_norm = nn.LayerNorm(config.hidden_size)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.qa_output = torch.nn.Linear(config.hidden_size, 2)\n        torch.nn.init.normal_(self.qa_output.weight, std=0.02)\n\n    def forward(self, input_ids, attention_mask=None):\n        outputs = self.xlm_roberta(input_ids, attention_mask=attention_mask)\n        all_hidden_states = torch.stack(outputs.hidden_states)\n        weighted_pooling_embeddings = self.layer_norm(self.pooling(all_hidden_states))\n        #weighted_pooling_embeddings = weighted_pooling_embeddings[:, 0]\n\n        norm_embeddings = self.dropout(weighted_pooling_embeddings)\n        logits = self.qa_output(norm_embeddings)\n        start_logits, end_logits = logits.split(1, dim=-1)\n\n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n\n        return start_logits, end_logits","metadata":{"papermill":{"duration":0.023451,"end_time":"2021-10-18T12:28:17.439329","exception":false,"start_time":"2021-10-18T12:28:17.415878","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.683789Z","iopub.execute_input":"2021-11-15T15:17:59.684293Z","iopub.status.idle":"2021-11-15T15:17:59.699259Z","shell.execute_reply.started":"2021-11-15T15:17:59.684252Z","shell.execute_reply":"2021-11-15T15:17:59.698469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_model(args):\n    config = AutoConfig.from_pretrained(args.config_name)\n    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)\n    model = Model(args.model_name_or_path,layer_start=12, config=config)\n    return config, tokenizer, model","metadata":{"papermill":{"duration":0.018186,"end_time":"2021-10-18T12:28:17.469195","exception":false,"start_time":"2021-10-18T12:28:17.451009","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.741456Z","iopub.execute_input":"2021-11-15T15:17:59.742037Z","iopub.status.idle":"2021-11-15T15:17:59.747417Z","shell.execute_reply.started":"2021-11-15T15:17:59.742Z","shell.execute_reply":"2021-11-15T15:17:59.74676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_test_features(args, example, tokenizer):\n    example[\"question\"] = example[\"question\"].lstrip()\n    \n    tokenized_example = tokenizer(\n        example[\"question\"],\n        example[\"context\"],\n        truncation=\"only_second\",\n        max_length=args.max_seq_length,\n        stride=args.doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    features = []\n    for i in range(len(tokenized_example[\"input_ids\"])):\n        feature = {}\n        feature[\"example_id\"] = example['id']\n        feature['context'] = example['context']\n        feature['question'] = example['question']\n        feature['input_ids'] = tokenized_example['input_ids'][i]\n        feature['attention_mask'] = tokenized_example['attention_mask'][i]\n        feature['offset_mapping'] = tokenized_example['offset_mapping'][i]\n        feature['sequence_ids'] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n        features.append(feature)\n    return features","metadata":{"papermill":{"duration":0.021865,"end_time":"2021-10-18T12:28:17.502701","exception":false,"start_time":"2021-10-18T12:28:17.480836","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.749373Z","iopub.execute_input":"2021-11-15T15:17:59.749674Z","iopub.status.idle":"2021-11-15T15:17:59.760213Z","shell.execute_reply.started":"2021-11-15T15:17:59.749641Z","shell.execute_reply":"2021-11-15T15:17:59.759471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections\n\ndef postprocess_hindi_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n    all_start_logits, all_end_logits = raw_predictions\n    \n    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n\n    predictions = collections.OrderedDict()\n\n    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n\n    for example_index, example in examples.iterrows():\n        feature_indices = features_per_example[example_index]\n\n        min_null_score = None\n        valid_answers = []\n        \n        context = example[\"context\"]\n        for feature_index in feature_indices:\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n\n            sequence_ids = features[feature_index][\"sequence_ids\"]\n            context_index = 1\n\n            features[feature_index][\"offset_mapping\"] = [\n                (o if sequence_ids[k] == context_index else None)\n                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n            ]\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n            cls_index = features[feature_index][\"input_ids\"].index(hindi_tokenizer.cls_token_id)\n            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n            if min_null_score is None or min_null_score < feature_null_score:\n                min_null_score = feature_null_score\n\n            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    if (\n                        start_index >= len(offset_mapping)\n                        or end_index >= len(offset_mapping)\n                        or offset_mapping[start_index] is None\n                        or offset_mapping[end_index] is None\n                    ):\n                        continue\n                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n                        continue\n\n                    start_char = offset_mapping[start_index][0]\n                    end_char = offset_mapping[end_index][1]\n                    valid_answers.append(\n                        {\n                            \"score\": start_logits[start_index] + end_logits[end_index],\n                            \"text\": context[start_char: end_char]\n                        }\n                    )\n        \n        if len(valid_answers) > 0:\n            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n        else:\n            best_answer = {\"text\": \"\", \"score\": 0.0}\n        \n        predictions[example[\"id\"]] = best_answer[\"text\"]\n        \n        \n    return predictions","metadata":{"papermill":{"duration":0.030273,"end_time":"2021-10-18T12:28:17.544362","exception":false,"start_time":"2021-10-18T12:28:17.514089","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.761935Z","iopub.execute_input":"2021-11-15T15:17:59.76225Z","iopub.status.idle":"2021-11-15T15:17:59.780301Z","shell.execute_reply.started":"2021-11-15T15:17:59.762188Z","shell.execute_reply":"2021-11-15T15:17:59.779553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def postprocess_tamil_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n    all_start_logits, all_end_logits = raw_predictions\n    \n    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n\n    predictions = collections.OrderedDict()\n\n    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n\n    for example_index, example in examples.iterrows():\n        feature_indices = features_per_example[example_index]\n\n        min_null_score = None\n        valid_answers = []\n        \n        context = example[\"context\"]\n        for feature_index in feature_indices:\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n\n            sequence_ids = features[feature_index][\"sequence_ids\"]\n            context_index = 1\n\n            features[feature_index][\"offset_mapping\"] = [\n                (o if sequence_ids[k] == context_index else None)\n                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n            ]\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n            cls_index = features[feature_index][\"input_ids\"].index(tamil_tokenizer.cls_token_id)\n            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n            if min_null_score is None or min_null_score < feature_null_score:\n                min_null_score = feature_null_score\n\n            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    if (\n                        start_index >= len(offset_mapping)\n                        or end_index >= len(offset_mapping)\n                        or offset_mapping[start_index] is None\n                        or offset_mapping[end_index] is None\n                    ):\n                        continue\n                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n                        continue\n\n                    start_char = offset_mapping[start_index][0]\n                    end_char = offset_mapping[end_index][1]\n                    valid_answers.append(\n                        {\n                            \"score\": start_logits[start_index] + end_logits[end_index],\n                            \"text\": context[start_char: end_char]\n                        }\n                    )\n        \n        if len(valid_answers) > 0:\n            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n        else:\n            best_answer = {\"text\": \"\", \"score\": 0.0}\n        \n        predictions[example[\"id\"]] = best_answer[\"text\"]\n        \n        \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:17:59.783154Z","iopub.execute_input":"2021-11-15T15:17:59.783375Z","iopub.status.idle":"2021-11-15T15:17:59.80028Z","shell.execute_reply.started":"2021-11-15T15:17:59.783329Z","shell.execute_reply":"2021-11-15T15:17:59.799454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:17:59.802667Z","iopub.execute_input":"2021-11-15T15:17:59.803112Z","iopub.status.idle":"2021-11-15T15:17:59.816462Z","shell.execute_reply.started":"2021-11-15T15:17:59.803075Z","shell.execute_reply":"2021-11-15T15:17:59.815844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['context'] = test['context'].apply(lambda x: ' '.join(x.split()))\ntest['question'] = test['question'].apply(lambda x: ' '.join(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:17:59.817466Z","iopub.execute_input":"2021-11-15T15:17:59.817802Z","iopub.status.idle":"2021-11-15T15:17:59.826117Z","shell.execute_reply.started":"2021-11-15T15:17:59.817765Z","shell.execute_reply":"2021-11-15T15:17:59.825345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hindi_test = test[test['language'] == 'hindi']\ntamil_test = test[test['language'] == 'tamil']","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:17:59.827486Z","iopub.execute_input":"2021-11-15T15:17:59.827825Z","iopub.status.idle":"2021-11-15T15:17:59.836185Z","shell.execute_reply.started":"2021-11-15T15:17:59.827787Z","shell.execute_reply":"2021-11-15T15:17:59.835356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hindi_test.reset_index(inplace=True)\nhindi_test.drop(['index'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:17:59.837811Z","iopub.execute_input":"2021-11-15T15:17:59.838176Z","iopub.status.idle":"2021-11-15T15:17:59.847219Z","shell.execute_reply.started":"2021-11-15T15:17:59.838133Z","shell.execute_reply":"2021-11-15T15:17:59.846373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tamil_test.reset_index(inplace=True)\ntamil_test.drop(['index'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:17:59.8486Z","iopub.execute_input":"2021-11-15T15:17:59.848799Z","iopub.status.idle":"2021-11-15T15:17:59.857722Z","shell.execute_reply.started":"2021-11-15T15:17:59.848775Z","shell.execute_reply":"2021-11-15T15:17:59.856633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#base_model_path = '../input/chaii-qa-5-fold-xlmroberta-torch-fit'\n\nhindi_tokenizer = AutoTokenizer.from_pretrained(hindiConfig().tokenizer_name)\ntamil_tokenizer = AutoTokenizer.from_pretrained(tamilConfig().tokenizer_name)\n\nhindi_test_features = []\nfor i, row in hindi_test.iterrows():\n    hindi_test_features += prepare_test_features(hindiConfig(), row, hindi_tokenizer)\n\ntamil_test_features = []\nfor i, row in tamil_test.iterrows():\n    tamil_test_features += prepare_test_features(tamilConfig(), row, tamil_tokenizer)\n\nhindi_args = hindiConfig()\nhindi_test_dataset = DatasetRetriever(hindi_test_features, mode='test')\nhindi_test_dataloader = DataLoader(\n    hindi_test_dataset,\n    batch_size=hindi_args.eval_batch_size, \n    sampler=SequentialSampler(hindi_test_dataset),\n    num_workers=optimal_num_of_loader_workers(),\n    pin_memory=True, \n    drop_last=False\n)\n\n\ntamil_args = tamilConfig()\ntamil_test_dataset = DatasetRetriever(tamil_test_features, mode='test')\ntamil_test_dataloader = DataLoader(\n    tamil_test_dataset,\n    batch_size=tamil_args.eval_batch_size, \n    sampler=SequentialSampler(tamil_test_dataset),\n    num_workers=optimal_num_of_loader_workers(),\n    pin_memory=True, \n    drop_last=False\n)","metadata":{"papermill":{"duration":1.212098,"end_time":"2021-10-18T12:28:18.76809","exception":false,"start_time":"2021-10-18T12:28:17.555992","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.859168Z","iopub.execute_input":"2021-11-15T15:17:59.85944Z","iopub.status.idle":"2021-11-15T15:17:59.981651Z","shell.execute_reply.started":"2021-11-15T15:17:59.859402Z","shell.execute_reply":"2021-11-15T15:17:59.980925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_hindi_predictions(checkpoint_path):\n    config, tokenizer, model = make_model(hindiConfig())\n    model.cuda();\n    model.load_state_dict(\n        torch.load(checkpoint_path)\n    );\n    \n    start_logits = []\n    end_logits = []\n    for batch in hindi_test_dataloader:\n        with torch.no_grad():\n            outputs_start, outputs_end = model(batch['input_ids'].cuda(), batch['attention_mask'].cuda())\n            start_logits.append(outputs_start.cpu().numpy().tolist())\n            end_logits.append(outputs_end.cpu().numpy().tolist())\n            del outputs_start, outputs_end\n    del model, tokenizer, config\n    gc.collect()\n    return np.vstack(start_logits), np.vstack(end_logits)","metadata":{"papermill":{"duration":0.017652,"end_time":"2021-10-18T12:28:18.797944","exception":false,"start_time":"2021-10-18T12:28:18.780292","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.982881Z","iopub.execute_input":"2021-11-15T15:17:59.983128Z","iopub.status.idle":"2021-11-15T15:17:59.990643Z","shell.execute_reply.started":"2021-11-15T15:17:59.983095Z","shell.execute_reply":"2021-11-15T15:17:59.989695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tamil_predictions(checkpoint_path):\n    config, tokenizer, model = make_model(tamilConfig())\n    model.cuda();\n    model.load_state_dict(\n        torch.load(checkpoint_path)\n    );\n    \n    start_logits = []\n    end_logits = []\n    for batch in tamil_test_dataloader:\n        with torch.no_grad():\n            outputs_start, outputs_end = model(batch['input_ids'].cuda(), batch['attention_mask'].cuda())\n            start_logits.append(outputs_start.cpu().numpy().tolist())\n            end_logits.append(outputs_end.cpu().numpy().tolist())\n            del outputs_start, outputs_end\n    del model, tokenizer, config\n    gc.collect()\n    return np.vstack(start_logits), np.vstack(end_logits)","metadata":{"papermill":{"duration":0.020257,"end_time":"2021-10-18T12:28:18.829854","exception":false,"start_time":"2021-10-18T12:28:18.809597","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:17:59.992052Z","iopub.execute_input":"2021-11-15T15:17:59.992369Z","iopub.status.idle":"2021-11-15T15:18:00.000629Z","shell.execute_reply.started":"2021-11-15T15:17:59.99233Z","shell.execute_reply":"2021-11-15T15:17:59.999834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fold 0\nhindi_start_logits1, hindi_end_logits1 = get_hindi_predictions('../input/chaiihindi/output/checkpoint-fold-0-epoch-0/pytorch_model.bin')\ntamil_start_logits1, tamil_end_logits1 = get_tamil_predictions('../input/chaiitamil/output/checkpoint-fold-0-epoch-0/pytorch_model.bin')\n\n#fold 1\nhindi_start_logits2, hindi_end_logits2 = get_hindi_predictions('../input/chaiihindi/output/checkpoint-fold-1-epoch-0/pytorch_model.bin')\ntamil_start_logits2, tamil_end_logits2 = get_tamil_predictions('../input/chaiitamil/output/checkpoint-fold-1-epoch-0/pytorch_model.bin')\n\n#fold 2\nhindi_start_logits3, hindi_end_logits3 = get_hindi_predictions('../input/chaiihindi/output/checkpoint-fold-2-epoch-0/pytorch_model.bin')\ntamil_start_logits3, tamil_end_logits3 = get_tamil_predictions('../input/chaiitamil/output/checkpoint-fold-2-epoch-0/pytorch_model.bin')\n\n#fold 3\nhindi_start_logits4, hindi_end_logits4 = get_hindi_predictions('../input/chaiihindi/output/checkpoint-fold-3-epoch-0/pytorch_model.bin')\ntamil_start_logits4, tamil_end_logits4 = get_tamil_predictions('../input/chaiitamil/output/checkpoint-fold-3-epoch-0/pytorch_model.bin')\n\n#fold 4\nhindi_start_logits5, hindi_end_logits5 = get_hindi_predictions('../input/chaiihindi/output/checkpoint-fold-4-epoch-0/pytorch_model.bin')\ntamil_start_logits5, tamil_end_logits5 = get_tamil_predictions('../input/chaiitamil/output/checkpoint-fold-4-epoch-0/pytorch_model.bin')\n\n# #fold 5\n# hindi_start_logits6, hindi_end_logits6 = get_hindi_predictions('../input/chaii-hindi-model-10folds-2epochs/output/checkpoint-fold-5/pytorch_model.bin')\n# tamil_start_logits6, tamil_end_logits6 = get_tamil_predictions('../input/chaii-tamil-model-10folds-2epochs/output/checkpoint-fold-5/pytorch_model.bin')\n\n# #fold 6\n# hindi_start_logits7, hindi_end_logits7 = get_hindi_predictions('../input/k/awsquickbytes/chaii-hindi-model-10folds-2epochs/output/checkpoint-fold-6/pytorch_model.bin')\n# tamil_start_logits7, tamil_end_logits7 = get_tamil_predictions('../input/k/abhiram4572/chaii-tamil-model-10folds-2epochs/output/checkpoint-fold-6/pytorch_model.bin')\n\n# #fold 7\n# hindi_start_logits8, hindi_end_logits8 = get_hindi_predictions('../input/k/babu1997/chaii-hindi-model-10folds-2epochs/output/checkpoint-fold-7/pytorch_model.bin')\n# tamil_start_logits8, tamil_end_logits8 = get_tamil_predictions('../input/k/vineethakki/chaii-tamil-model-10folds-2epochs/output/checkpoint-fold-7/pytorch_model.bin')\n\n# #fold 8\n# hindi_start_logits9, hindi_end_logits9 = get_hindi_predictions('../input/k/vineethakki/chaii-hindi-model-10folds-2epochs/output/checkpoint-fold-8/pytorch_model.bin')\n# tamil_start_logits9, tamil_end_logits9 = get_tamil_predictions('../input/k/awsquickbytes/chaii-tamil-model-10folds-2epochs/output/checkpoint-fold-8/pytorch_model.bin')\n\n# #fold 9\n# hindi_start_logits10, hindi_end_logits10 = get_hindi_predictions('../input/k/abhiram4572/chaii-hindi-model-10folds-2epochs/output/checkpoint-fold-9/pytorch_model.bin')\n# tamil_start_logits10, tamil_end_logits10 = get_tamil_predictions('../input/k/babu1997/chaii-tamil-model-10folds-2epochs/output/checkpoint-fold-9/pytorch_model.bin')","metadata":{"papermill":{"duration":233.06397,"end_time":"2021-10-18T12:32:11.905646","exception":false,"start_time":"2021-10-18T12:28:18.841676","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:18:00.002078Z","iopub.execute_input":"2021-11-15T15:18:00.002592Z","iopub.status.idle":"2021-11-15T15:20:52.683096Z","shell.execute_reply.started":"2021-11-15T15:18:00.002548Z","shell.execute_reply":"2021-11-15T15:20:52.682328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hindi CV\nCV = np.array([0.66914, 0.67891, 0.66159, 0.67974, 0.65314])\nW = CV/CV.sum()\nW.sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:20:52.685978Z","iopub.execute_input":"2021-11-15T15:20:52.686247Z","iopub.status.idle":"2021-11-15T15:20:52.692957Z","shell.execute_reply.started":"2021-11-15T15:20:52.686212Z","shell.execute_reply":"2021-11-15T15:20:52.692243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tamil CV\nCV2 = np.array([0.60458, 0.57783, 0.6006, 0.64114, 0.57717])\nW2 = CV2/CV2.sum()\nW2.sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:20:52.693971Z","iopub.execute_input":"2021-11-15T15:20:52.695639Z","iopub.status.idle":"2021-11-15T15:20:52.705136Z","shell.execute_reply.started":"2021-11-15T15:20:52.695602Z","shell.execute_reply":"2021-11-15T15:20:52.704374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##hindi logits\nhindi_start_logits = (hindi_start_logits1*W[0] + hindi_start_logits2*W[1]+ hindi_start_logits3*W[2] + hindi_start_logits4*W[3] + hindi_start_logits5*W[4])\nhindi_end_logits = (hindi_end_logits1*W[0] + hindi_end_logits2*W[1]+ hindi_end_logits3*W[2] + hindi_end_logits4*W[3] + hindi_end_logits5*W[4])\n\n##tamil logits\ntamil_start_logits = (tamil_start_logits1*W2[0] + tamil_start_logits2*W2[1]+ tamil_start_logits3*W2[2] + tamil_start_logits4*W2[3] + tamil_start_logits5*W2[4])\ntamil_end_logits = (tamil_end_logits1*W2[0] + tamil_end_logits2*W2[1]+ tamil_end_logits3*W2[2] + tamil_end_logits4*W2[3] + tamil_end_logits5*W2[4])\n\n#### origin\n#hindi logits\n# hindi_start_logits = (hindi_start_logits1 + hindi_start_logits2+ hindi_start_logits3 + hindi_start_logits4 + hindi_start_logits5)/5\n# hindi_end_logits = (hindi_end_logits1 + hindi_end_logits2+ hindi_end_logits3 + hindi_end_logits4 + hindi_end_logits5)/5\n\n# #tamil logits\n# tamil_start_logits = (tamil_start_logits1 + tamil_start_logits2+ tamil_start_logits3 + tamil_start_logits4 + tamil_start_logits5)/5\n# tamil_end_logits = (tamil_end_logits1 + tamil_end_logits2+ tamil_end_logits3 + tamil_end_logits4 + tamil_end_logits5)/5","metadata":{"execution":{"iopub.status.busy":"2021-11-15T15:21:19.315194Z","iopub.execute_input":"2021-11-15T15:21:19.315758Z","iopub.status.idle":"2021-11-15T15:21:19.325029Z","shell.execute_reply.started":"2021-11-15T15:21:19.315719Z","shell.execute_reply":"2021-11-15T15:21:19.324095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hindi_fin_preds = postprocess_hindi_qa_predictions(hindi_test, hindi_test_features, (hindi_start_logits, hindi_end_logits))\ntamil_fin_preds = postprocess_tamil_qa_predictions(tamil_test, tamil_test_features, (tamil_start_logits, tamil_end_logits))","metadata":{"papermill":{"duration":233.06397,"end_time":"2021-10-18T12:32:11.905646","exception":false,"start_time":"2021-10-18T12:28:18.841676","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:21:25.756604Z","iopub.execute_input":"2021-11-15T15:21:25.7573Z","iopub.status.idle":"2021-11-15T15:21:25.783884Z","shell.execute_reply.started":"2021-11-15T15:21:25.757263Z","shell.execute_reply":"2021-11-15T15:21:25.783115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = []\n\nfor p1, p2 in hindi_fin_preds.items():\n    p2 = \" \".join(p2.split())\n    p2 = p2.strip(punctuation)\n    submission.append((p1, p2))\n    \nfor p1, p2 in tamil_fin_preds.items():\n    p2 = \" \".join(p2.split())\n    p2 = p2.strip(punctuation)\n    submission.append((p1, p2))\n    \nsample = pd.DataFrame(submission, columns=[\"id\", \"PredictionString\"])\n\ntest_data =pd.merge(left=test,right=sample,on='id')","metadata":{"papermill":{"duration":233.06397,"end_time":"2021-10-18T12:32:11.905646","exception":false,"start_time":"2021-10-18T12:28:18.841676","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:21:28.005851Z","iopub.execute_input":"2021-11-15T15:21:28.006625Z","iopub.status.idle":"2021-11-15T15:21:28.01539Z","shell.execute_reply.started":"2021-11-15T15:21:28.006576Z","shell.execute_reply":"2021-11-15T15:21:28.01452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\nbad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n\ntamil_ad = \"கி.பி\"\ntamil_bc = \"கி.மு\"\ntamil_km = \"கி.மீ\"\nhindi_ad = \"ई\"\nhindi_bc = \"ई.पू\"\n\n\ncleaned_preds = []\nfor pred, context in test_data[[\"PredictionString\", \"context\"]].to_numpy():\n    if pred == \"\":\n        cleaned_preds.append(pred)\n        continue\n    while any([pred.startswith(y) for y in bad_starts]):\n        pred = pred[1:]\n    while any([pred.endswith(y) for y in bad_endings]):\n        if pred.endswith(\"...\"):\n            pred = pred[:-3]\n        else:\n            pred = pred[:-1]\n    if pred.endswith(\"...\"):\n            pred = pred[:-3]\n    \n    if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n        pred = pred+\".\"\n        \n    cleaned_preds.append(pred)\n\ntest_data[\"PredictionString\"] = cleaned_preds\ntest_data[['id', 'PredictionString']].to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.067297,"end_time":"2021-10-18T12:32:12.000832","exception":false,"start_time":"2021-10-18T12:32:11.933535","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:21:31.725907Z","iopub.execute_input":"2021-11-15T15:21:31.726444Z","iopub.status.idle":"2021-11-15T15:21:31.74887Z","shell.execute_reply.started":"2021-11-15T15:21:31.726396Z","shell.execute_reply":"2021-11-15T15:21:31.747893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data[['id', 'PredictionString']]","metadata":{"papermill":{"duration":0.062168,"end_time":"2021-10-18T12:32:12.081048","exception":false,"start_time":"2021-10-18T12:32:12.01888","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T15:20:52.783436Z","iopub.execute_input":"2021-11-15T15:20:52.783809Z","iopub.status.idle":"2021-11-15T15:20:52.796363Z","shell.execute_reply.started":"2021-11-15T15:20:52.783772Z","shell.execute_reply":"2021-11-15T15:20:52.795551Z"},"trusted":true},"execution_count":null,"outputs":[]}]}