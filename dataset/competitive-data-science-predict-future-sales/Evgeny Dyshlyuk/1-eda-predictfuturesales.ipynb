{"cells":[{"metadata":{},"cell_type":"markdown","source":"### This is the first notebook '1_EDA' of the full solution for Predict Future Sales competition on Kaggle.\n## This notebook describes the first section of the solution: Exploratory Data Analysis and Data Cleaning\nThe full solution consists of 4 notebooks:\n- 1_EDA : Exploratory Data analysis and Data Cleaning\n- 2_FE: Feature Engineering\n- 3_HPO: Models Hyperparameter optimization\n- 4_Ensemble: Ensembling the models\n\nData:\n- The input data is in the 'input' folder of this directory\n- The output data is saved in the 'output' folder of this directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile libraries.py\n# Create a file allowing to import upper level(usefull throughout the whole solution) packages and functions with one line: %run libraries\n\nimport os #The functions that the OS module provides allows you to interface with the underlying operating system that Python is running on \n\nimport pickle # Fast saving/loading data\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)\n\n# Import visualizations\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (30,5) # Set standard output figure size\nimport seaborn as sns # sns visualization library\nfrom IPython.display import display # Allows to nicely display/output several figures or dataframes in one cell\n\n# Create an output' folder to save data from the notebook\ntry: os.mkdir('output') # Try to create\nexcept FileExistsError: pass # if already exist pass\n        \nprint('Upper level libraries loaded')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reset -f\n#reset magic function allows one to release all previously used memory. -f (force) parameter allows to run it without confirmation from the user\n\n%run libraries\n#jupyter magic function loading standard libraries from the created file.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load Data\n\nData Description  \nYou are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.\n\n#### Files description:  \n- sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.  \n- test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.  \n- sample_submission.csv - a sample submission file in the correct format. \n- items.csv - supplemental information about the items/products.  \n- item_categories.csv  - supplemental information about the items categories.  \n- shops.csv- supplemental information about the shops.  \n\n#### Data fields:\n- ID - an Id that represents a (Shop, Item) tuple within the test set\n- shop_id - unique identifier of a shop\n- item_id - unique identifier of a product\n- item_category_id - unique identifier of item category\n- item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n- item_price - current price of an item\n- date - date in format dd/mm/yyyy\n- date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n- item_name - name of item\n- shop_name - name of shop\n- item_category_name - name of item category"},{"metadata":{"_uuid":"f0a1c729d4fb3d6609f9dfb163ebe92fa9dc654c","trusted":true},"cell_type":"code","source":"#Load data from 'input' folder in the current directory\ntrain   = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\nitems   = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\ncats    = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops   = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\ntest    = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')\nsample  = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.set_index('ID') #Set index to ID. This way we do not need to drop ID column every time in future calculations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the Loaded Data\n# display() allows to output multiple dataframes in one cell\ndisplay('train',   train.shape,  train.head(),\n        'items',   items.shape,  items.head(),\n        'cats',    cats.shape,   cats.head(),\n        'shops',   shops.shape,  shops.head(),\n        'test',    test.shape,   test.head(),\n        'sample',  sample.shape, sample.head()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define dataframe information function\ndef df_info(df):\n    print('-------------------------------------------shape----------------------------------------------------------------')\n    print(df.shape)\n    print('-------------------------------------head() and tail(1)---------------------------------------------------------')\n    display(df.head(), df.tail(1))\n    print('------------------------------------------nunique()-------------------------------------------------------------')\n    print(df.nunique())\n    print('-------------------------------------describe().round()---------------------------------------------------------')\n    print(df.describe().round())\n    print('--------------------------------------------info()--------------------------------------------------------------')\n    print(df.info())\n    print('-------------------------------------------isnull()-------------------------------------------------------------')\n    print(df.isnull().sum())\n    print('--------------------------------------------isna()--------------------------------------------------------------')\n    print(df.isna().sum())\n    print('-----------------------------------------duplicated()-----------------------------------------------------------')\n    print(len(df[df.duplicated()]))\n    print('----------------------------------------------------------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_info(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We see 6 duplicates in data, let's drop them\ntrain.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We see a possible typo in item price in train - negative value \ntrain[train.item_price <= 0 ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only one datapoint - it should be safe to simply remove it\ntrain = train[train.item_price > 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train.item_price"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check price distribution\nplt.plot(train.item_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There is one clear outlier\nprint(train[train.item_price > 100000])\nprint(items[items.item_id == 6066])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we see this is a sale of 522 packages in one pack (each one cost 307980/522 = 59 ), let us correct this line\ntrain.item_cnt_day[train.item_id == 6066] = 522\ntrain.item_price[train.item_id == 6066] = 59","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let us plot it again\nplt.plot(train.item_price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see step/piecewise graph here with some outliers. The item price increase (probably because of the inflation of prices with time here - Russia suffered currency crisis in 2014.06-2014.12 with the drop of oil prices - Rubble dropped 2 times). So probably adding prices in USD would help the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us plot variation of the mean item price with time\nplt.plot(train.groupby(['date_block_num'])['item_price'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see the increase in price clearly here"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We do not clearly see much variation of prices within one month of sales \nplt.plot(train[train.date_block_num == 33].item_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us see how price is changing for one of the arbitrary taken items\nid = 1000 # arbitrary id\nplt.figure(figsize=(10,4))\nsns.distplot(train[train.item_id == id].item_price, hist_kws={'log':True}, kde = False, bins = 100)\n\ntrain[train.item_id == id].sort_values(by=['date_block_num'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see the variation in price for a given month for different shops and also variation of price versus time, the price distribution is multimodal."},{"metadata":{},"cell_type":"markdown","source":"### Train.item_cnt_day"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let us plot item_cnt_day\nplt.plot(train.item_cnt_day)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a864412fafc3129a3e9bd5bb1f18a7cf0c62935","trusted":true},"cell_type":"code","source":"# Plot the logarithmic histograms for item_cnt_day\nsns.distplot(train.item_cnt_day, hist_kws={'log':True}, kde = False, bins = 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Couple outliers above 900\ntrain[train.item_cnt_day > 900]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(items[items.item_id == 9248])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(items[items.item_id == 20949],\n        items[items.item_id == 11373])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It's possible that a lot of packets and deliveries were done on some occasion but those have to be some holidays for example.\n# I think it's better to remove the points as outliers\ntrain = train[train.item_cnt_day < 900]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let us plot item_cnt_day\nplt.plot(train.item_cnt_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us see sales distribution per month\nsns.countplot(x='date_block_num', data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We clearly see a pattern here - overall negative trend (crisis in Russia), with a 12 month period sinusoidal - year cycle. Peak sales - December, low sales on summer months."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us see sales distribution over one month\nsns.countplot(x='date', data=train[(train.date_block_num == 21)&(train.shop_id == 12)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Very clear trend in sales - low sales on monday, highest sales on saturday-sunday. Probably adding number of mondays, tuesdays, etc. as features in the particular month would help. Holidays also show higher sales - better take this into account."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the sales per shop\nsns.countplot(x='shop_id', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us plot cumulative sales per shop over time. We will use red color for those shops, that are not present in test set.\n\nfig = plt.figure(figsize=(30,36))\nfor i in range(len(shops)):\n    ts=train[train.shop_id == i].groupby(['date_block_num'])['item_cnt_day'].sum()\n    plt.subplot(10, 6, i+1)\n    plt.bar(ts.index, ts.values)\n    plt.xlim((0, 33))\n    plt.ylim(0, 12000)\n    if i in set(test.shop_id):\n        plt.title(str(i) +' '+ shops.shop_name[i], color = 'k')\n    else: \n        plt.title(str(i) +' '+ shops.shop_name[i], color = 'r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to predict sales only for the shops which were not closed :). It might be a good idea to provide a model with a flag for open/closed shops."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We see that data for some shops was mixed (intentionally I guess), let's fix it\n# Якутск Орджоникидзе, 56\ntrain.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n# Жуковский ул. Чкалова 39м²\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11\n# Now delete those shops from the shops dataframe:\nshops.drop([0, 1, 10], inplace = True)\n\n# I think it is also better to remove any data for outbound trade, \n# which is very unusual and misleading (we are not going to predict the outbound trade)\ntrain = train[train.shop_id != 9]\ntrain = train[train.shop_id != 20]\n# Now delete those shops from the shops dataframe:\nshops.drop([9, 20], inplace = True)\n\n# 12 and 55 are online stores - we cannot remove them because these shops are in test.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us add item_category_id to train and test sets\nitems_dict = dict(zip(items.item_id, items.item_category_id))\ntrain['item_category_id'] = train['item_id'].map(items_dict)\ntest['item_category_id'] = test['item_id'].map(items_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the distribution for sold items relative to the category\nfig, ax =plt.subplots(2,1, figsize=(30,10))\nsns.countplot(train['item_category_id'], ax=ax[0])\nsns.countplot(test['item_category_id'], ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We see that some categories are absent in test data but are present in train. Let us remove those categories from train data to make it closer to test.\nfor i in (set(train.item_category_id) - set(test.item_category_id)):\n    train = train[train.item_category_id != i]\n    items = items[items.item_category_id != i] # remove them from items\n    cats = cats[cats.item_category_id != i]    # remove from cats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the distribution again\nfig, ax =plt.subplots(2,1,  figsize=(30,10))\nsns.countplot(train['item_category_id'], ax=ax[0])\nsns.countplot(test['item_category_id'], ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the distributions of Sales vs CategoryID are slightly different for Test and Train sets - e.g. category# 31 is big in test (many items picked up for test) but small in train (because of relatively low sales of those items)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many samples in train now?\nlen(set(train.shop_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(30,60))\ni = 1\nfor shop_id in set(train.shop_id):\n    ts=train[train.shop_id == shop_id].groupby(['item_category_id'])['item_cnt_day'].sum()\n    plt.subplot(11, 5, i)\n    plt.bar(ts.index, ts.values)\n    plt.xlim((0, 82))\n    if shop_id in set(test.shop_id):\n        plt.title(str(shop_id) +' '+ shops.shop_name[shop_id], color = 'k')\n    else: \n        plt.title(str(shop_id) +' '+ shops.shop_name[shop_id], color = 'r')\n    i+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shop # 40 showing very different trend from other shops, so let us remove it (it is closed long time ago anyway and we don't need to predict for this shop)\ntrain = train[train.shop_id != 40]\n# Now delete the shop from the shops dataframe:\nshops.drop([40], inplace = True)\n\n# we do not remove shops # 12 and 55 which are on-line shops and also show different distribution\n# shop #55 is an online shop for 1-C Software (business accounting software, #1 in Russia). The sales categories from this shop are only present for this shop and are not present in other shops:\nset(train[train.shop_id == 55].item_category_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we will save the data, but we do not want to save modifications to data sets at this stage, here we only cleaned the data, so let us drop newly created columns from data. We will modify the data in the next: 2_FeatureEngineering section\ntrain.drop(columns = 'item_category_id', inplace = True)\ntest.drop(columns = 'item_category_id', inplace = True)\n\n# Save data to the folder to use it in the next part\nwith open(r'output/1_EDA_data.pkl','wb') as f:\n    pickle.dump((train, items, cats, shops, test, sample), f)  \n    \n'''# Load the saved data in the next section as:\nwith open(r'output/1_EDA_data.pkl', 'rb') as f:\n    (train, items, cats, shops, test, sample) = pickle.load(f)'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thank you for your time!\n## Please share your thoughts and comments, as well as suggestions for future improvements."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}