{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Predict Future Sales \nこのkernelは[Feature engineering, xgboost](https://www.kaggle.com/dlarionov/feature-engineering-xgboost)を参考に日本語で整理してまとめています。  \n作成しながら構成の整理等は行なっていきたいと思います。誤った箇所などありましたらご指摘お願いします。"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# データの読み込み\ntrain = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# データサイズの確認\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2013年1月から2015年10月までの日次履歴データ\n# 各カラムの意味\n# date:日付(表示形式:日.月.年っぽい)\n# date_block_num:年月ごとの連番\n# shop_id:店ID\n# item_id:アイテムID\n# item_price:商品価格\n# item_cnt_day:その日に販売された製品の数\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'item_cnt_day']\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.date_block_num==0].sort_values(['shop_id','item_id'], ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['date_block_num'] += 1\ntrain['date_block_num'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2015年11月のショップIDとアイテムIDの売上を予測していく\n# 各カラムの意味\n# ID:インデックス\n# shop_id:店ID\n# item_id:アイテムID\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shop.csvの確認\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv');\nprint(shops.shape)\n# 各カラムの意味\n# shop_name:店名\n# shop_id:店ID\nshops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# item.csvの確認\nitems= pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv');\nprint(items.shape)\n# 各カラムの意味\n# item_name:商品名\n# item_id:商品ID\n# item_category_id:商品カテゴリID\nitems.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# item_categories.csvの確認\ncats= pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv');\nprint(cats.shape)\n# 各カラムの意味\n# item_category_name:商品カテゴリ名\n# item_category_id:商品カテゴリID\ncats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_submission.csvの確認\nsample_submission= pd.read_csv('../input/competitive-data-science-predict-future-sales/sample_submission.csv');\nprint(sample_submission.shape)\n# 各カラムの意味\n# ID:インデックス(test.csvに紐づく)\n# item_cnt_month:その月に販売された製品の数\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 外れ値の確認/除外"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# trainデータにて、「製品の個数」を箱ひげ図で確認する\nfig,ax = plt.subplots(2,1,figsize=(10,4))\n# 尺度の調整\nplt.xlim(-300, 3000)\n# 箱ひげ図を描画\nax[0].boxplot((train.item_cnt_day) , labels=['train.item_cnt_day'], vert=False)\n\n# trainデータにて、「商品の価格」を箱ひげ図で確認する\nplt.xlim(-1000, 350000)\nax[1].boxplot((train.item_price) , labels=['train.item_price'], vert=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"上記の箱ひげ図より、各データで外れ値が存在していることが確認できました。  \ntrain.item_price>100000 および >1001 の外れ値を訓練データから削除します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 外れ値の除外\ntrain = train[train.item_price<100000]\ntrain = train[train.item_cnt_day<1001]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train.item_priceにて0以下の値が誤って存在しています。"},{"metadata":{},"cell_type":"markdown","source":"## 誤って登録されたゴミデータの確認/修正"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0以下の値\ntrain[train.item_price<0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"同じ年月/店ID/商品IDの中央値をこの誤った値に代入します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 同じ年月/店ID/商品IDの中央値を median に代入\nmedian = train[(train.date_block_num==4)&(train.shop_id==32)&(train.item_id==2973)&(train.item_price>0)].item_price.median()\n# median を0以下の値に代入\ntrain.loc[train.item_price<0, 'item_price'] = median\n# 代入されたため、train.item_priceにて0以下の値が存在しないことを確認\ntrain[train.item_price<0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"次に、店情報を確認すると異なる店IDで同じ店名(厳密には等しく無い)が誤って登録されていることが確認できます。  \n(これはロシア後読めないと絶対に気づけない前処理ですね笑)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 店情報を確認(全部で60店しかありません)\nshops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 重複していた店名のIDを統一させます。(train/test両方で処理しておきます)\n# Якутск Орджоникидзе, 56\ntrain.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n# Жуковский ул. Чкалова 39м²\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shop/Cat/Itemの前処理"},{"metadata":{},"cell_type":"markdown","source":"上記のshopデータなどの観察から以下のことがわかります。\n- 店名(shop_name)は、ロシアの各都市名で始まっています。\n - shop_nameの構成は [都市名 店のタイプ \"店名\"]など 必ず都市名で始まっている"},{"metadata":{},"cell_type":"markdown","source":"上記でshopデータを全件確認しているので、データ確認は省きます。  \nshopsデータから確認前処理していきましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# Сергиев Посад = セルギエフ・ポサドがスペースで空いてしまっているので、このスペースを埋めます。\nshops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n# shop_nameの先頭を抽出してshopに新たな列[city(都市)]を追加します\nshops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n# 都市名の先頭に[!]がゴミ(タイポらしい)として入ってしまっているので、これを修正する\nshops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\n# LabelEncoderを使って数値化します。\nshops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n# shopsの構造を['shop_id', 'city_code']に設定する\nshops = shops[['shop_id','city_code']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 前処理後こんな感じになります\nshops.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"次に、catsですが、改めて全件確認してみましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"cats","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"catsの観察で以下の点に気づけます。\n- カテゴリ名は、[タイプ-サブタイプ]の構成となっている  \n\nそのためcatsのカテゴリ名から、タイプ/サブタイプの列を追加していきましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# '-'でカテゴリ名を分割します\ncats['split'] = cats['item_category_name'].str.split('-')\n# typeには-で分割した先頭の値を代入します\ncats['type'] = cats['split'].map(lambda x: x[0].strip())\n# 中にはサブタイプを持たないデータもあるので、その場合はsubtypeにタイプを代入します\ncats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n# LabelEncoderを使って数値化します。\ncats['type_code'] = LabelEncoder().fit_transform(cats['type'])\ncats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n# shopsの構造を['item_category_id', 'type_code', 'subtype_code']に設定する\ncats = cats[['item_category_id','type_code', 'subtype_code']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 前処理後こんな感じになります\ncats.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"次に、itemsを観察してみましょう"},{"metadata":{"trusted":true},"cell_type":"code","source":"items","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"item_nameには特徴量となりそうな情報がないので列ごと抹殺してやりましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"items.drop(['item_name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"抹殺されて、item_idとitem_category_idのみになっていることが確認できます。"},{"metadata":{},"cell_type":"markdown","source":"## 月次売上"},{"metadata":{},"cell_type":"markdown","source":"test.csvは2015年11月の月次売上を求めるために商品ID/店IDの組み合わせから構成されています。   \nその組み合わせの数は 商品数(5100) * 店数(42) = 214200ペアあります。  \ntestに存在して、trainに存在しない商品は363個あります。  \nしたがって、これらの商品に対しての目的変数(今回は月次売上)は予測できないので、0でなければなりません。  \n一方、trainデータが含む全ての商品は過去に売られている(または返品)ペアのみです。\n今回の主となる方針では、月次売上を計算し、そのペアごとに売上を0に拡張していきます。(?)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# test(item_id) - (test(item_id) 積集合 train(item_id)) = trainに存在しないtestの商品IDの数\nprint(len(list(set(test.item_id) - set(test.item_id).intersection(set(train.item_id)))))\n# testの商品IDの数(重複は除く)\nprint(len(list(set(test.item_id))))\n# testの総数\nprint(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.date_block_numにて、列(Series型)ごとにユニークな値を確認(年月の組み合わせは33パターンと確認できる)\ntrain.date_block_num.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n# 複数のリストの直積（デカルト積）を生成するためのライブラリ\nfrom itertools import product\nts = time.time()\n\n# 訓練データに存在する、(年月番号,店ID,商品ID)の全組み合わせを列挙した行列を生成していく\n# 最終的にmatrixを学習モデルの訓練データとする\nmatrix = []\nfor i in range(34):\n    # 変数salesにdate_block_num=iの行列(表)データを代入する\n    sales = train[train.date_block_num==i]\n    # trainデータに存在する、(年月番号,店ID,商品ID)の全組み合わせを列挙した行列を追加していく\n    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n\n# 列名を改めて設定してmatrixを更新\ncols = ['date_block_num','shop_id','item_id']\nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n# .astype(~~~):各特徴量を~~~でキャスト\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\n# colsをソート対象とする、inplace=Trueでオブジェクトをそのまま更新\nmatrix.sort_values(cols,inplace=True)\ntime.time() - ts\n# 20.83844780921936","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainデータに revenue(その日の収支合計) を追加します\ntrain['revenue'] = train['item_price'] *  train['item_cnt_day']\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainデータにて、'date_block_num','shop_id','item_id'でGROUP化したDataFrameGroupByオブジェクトに対して、'item_cnt_day'を集計します\ngroup = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\n# 列名の更新\ngroup.columns = ['item_cnt_month']\n# DataFrameGroupBy -> DataFrame に変換\ngroup.reset_index(inplace=True)\ngroup.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DataFrame同士でcolsを条件に左結合する\nmatrix = pd.merge(matrix, group, on=cols, how='left')\n# item_cnt_monthの前処理\nmatrix['item_cnt_month'] = (matrix['item_cnt_month']\n                                .fillna(0) # 0で穴埋めする\n                                .clip(0,20) # 最小値0/最大値20に収める(なぜこの値？)\n                                .astype(np.float16)) # 型のキャスト\nmatrix.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## テストデータ(前処理を行う)"},{"metadata":{"trusted":true},"cell_type":"code","source":" # 2015年11月のデータのためdate_block_num = 34として列を追加してあげましょう\ntest['date_block_num'] = 34\n# 型のキャスト\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\ntest['shop_id'] = test['shop_id'].astype(np.int8)\ntest['item_id'] = test['item_id'].astype(np.int16)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n# matrixにtestを連結させる\nmatrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\n# NaNを0に変換\nmatrix.fillna(0, inplace=True) # 34 month\ntime.time() - ts\nmatrix[matrix.date_block_num==34]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shop/Cat/Itemの特徴量"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n# Shop/Cat/Itemの特徴量をmatrixに追加する\nmatrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\nmatrix = pd.merge(matrix, items, on=['item_id'], how='left')\nmatrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')\n# 型のキャスト\nmatrix['city_code'] = matrix['city_code'].astype(np.int8)\nmatrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\nmatrix['type_code'] = matrix['type_code'].astype(np.int8)\nmatrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)\ntime.time() - ts\nmatrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 目的変数"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        # 列名の更新\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n# [1,2,3,6,12]に格納された値のヶ月前のitem_cnt_monthを特量量として追加する\nmatrix = lag_feature(matrix, [1,2,3,6,12], 'item_cnt_month')\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import gc\n# import pickle\n# matrix.to_pickle('data.pkl')\n# # del matrix\n# # del cache\n# # del group\n# # del items\n# # del shops\n# # del cats\n# # del train\n# # leave test for submission\n# gc.collect();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## xgboostモデルの構築"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = pd.read_pickle('data.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# matrix.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = data[matrix.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # 訓練用データ\n# X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n# Y_train = data[data.date_block_num < 33]['item_cnt_month']\n# # バリデーション用データ\n# X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n# Y_valid = data[data.date_block_num == 33]['item_cnt_month']\n# # \n# X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del data\n# gc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from xgboost import XGBRegressor\n\n# ts = time.time()\n# model = XGBRegressor(\n#     max_depth=8,\n#     n_estimators=1000,\n#     min_child_weight=300, \n#     colsample_bytree=0.8, \n#     subsample=0.8, \n#     eta=0.3,    \n#     seed=42)\n\n# model.fit(\n#     X_train, \n#     Y_train, \n#     eval_metric=\"rmse\", \n#     eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n#     verbose=True, \n#     early_stopping_rounds = 10)\n\n# time.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Y_pred = model.predict(X_valid).clip(0, 20)\n# Y_test = model.predict(X_test).clip(0, 20)\n\n# submission = pd.DataFrame({\n#     \"ID\": test.index, \n#     \"item_cnt_month\": Y_test\n# })\n# submission.to_csv('xgb_submission.csv', index=False)\n\n# # save predictions for an ensemble\n# pickle.dump(Y_pred, open('xgb_train.pickle', 'wb'))\n# pickle.dump(Y_test, open('xgb_test.pickle', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_features(model, (10,14))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}