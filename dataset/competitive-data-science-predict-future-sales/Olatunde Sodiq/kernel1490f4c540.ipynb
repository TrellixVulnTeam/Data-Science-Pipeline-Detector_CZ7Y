{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom sklearn import *\nimport nltk, datetime\n# Any results you write to the current directory are saved as output.\ntrain = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')\nsubmission = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')\nitems = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\nitem_cats = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\n\n# prepare datetime\n# insert a new column (day, month and year)\ntrain['date'] = pd.to_datetime(train['date'], format='%d.%m.%Y')\ntrain['month'] = train['date'].dt.month\ntrain['year'] = train['date'].dt.year\n\n# Drop unnessary column in \ntrain = train.drop(['date', 'item_price'], axis=1)\n# group by all others columns except item_cnt_day and sum item_cnt_day\ntrain = train.groupby([c for c in train.columns if c not in ['item_cnt_day']], as_index=False)[['item_cnt_day']].sum()\n# rename item_cnt_day to item_cnt_month\ntrain = train.rename(columns={'item_cnt_day': 'item_cnt_month'})\n\n# Find the monthly mean\nshop_item_mean = train[['shop_id', 'item_id', 'item_cnt_month']].groupby(['shop_id', 'item_id'], as_index=False)[['item_cnt_month']].mean()\nshop_item_mean = shop_item_mean.rename(columns={'item_cnt_month': 'item_cnt_month_mean'})\n# Add mean feature to our train set\ntrain = pd.merge(train, shop_item_mean, how='left', on=['shop_id', 'item_id'])\n\n# Add last Month\nshop_prev_month = train[train['date_block_num']==33][['shop_id','item_id', 'item_cnt_month']]\nshop_prev_month = shop_prev_month.rename(columns={'item_cnt_month': 'item_cnt_prev_month'})\n\n# Add previous month feature to train dataset\ntrain = pd.merge(train, shop_prev_month, how='left', on=['shop_id', 'item_id']).fillna(0.)\n\n# add all item features\ntrain = pd.merge(train, items, how='left', on='item_id')\n\n# Adding item category feature\ntrain = pd.merge(train, item_cats, how='left', on='item_category_id')\n\n# adding shop features\ntrain = pd.merge(train, shops, how='left', on='shop_id')\n\n# Test Dataset\n\n#Adding November 2015\ntest['month']=11\ntest['year']=2015\ntest['date_block_num']=34\n\n# Add mean feature\ntest = pd.merge(test, shop_item_mean, how='left', on=['shop_id', 'item_id']).fillna(0.)\n# Add previous month features\ntest = pd.merge(test, shop_prev_month, how='left', on=['shop_id', 'item_id']).fillna(0.)\n\n# Add All items feature\ntest = pd.merge(test, items, how='left', on='item_id')\n# Adding item category feature\ntest = pd.merge(test, item_cats, how='left', on='item_category_id')\n\n#Adding shop feature\ntest = pd.merge(test, shops, how='left', on='shop_id')\n\n#Add column to be predict and set it all to zeros\ntest['item_cnt_month']=0\n\n# Label Encoding\nfor c in ['shop_name', 'item_name', 'item_category_name']:\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(train[c].unique()) + list(test[c].unique()))\n    train[c]=lbl.transform(train[c].astype(str))\n    test[c]=lbl.transform(test[c].astype(str))\n    \n# Let train and predict using Random forest algorithm\ncol = [c for c in train.columns if c not in ['item_cnt_month']]\nx1=train[train['date_block_num']<33]\ny1=np.log1p(x1['item_cnt_month'].clip(0.,20.))\nx1=x1[col]\nx2=train[train['date_block_num']==33]\ny2 = np.log1p(x2['item_cnt_month'].clip(0.,20.))\nx2 = x2[col]\n\nreg = ensemble.ExtraTreesRegressor(n_estimators=40, n_jobs=1, max_depth=20, random_state=18)\nreg.fit(x1,y1)\n\nprint('RMSE value is :', np.sqrt(metrics.mean_squared_error(y2.clip(0.,20.), reg.predict(x2).clip(0.,20.))))\n\nreg.fit(train[col], train['item_cnt_month'].clip(0.,20.))\ntest['item_cnt_month'] = reg.predict(test[col].clip(0.,20.))\ntest[['ID', 'item_cnt_month']].to_csv('submission.csv', index=False)\n\ntest['item_cnt_month'] = np.expm1(test['item_cnt_month'])\ntest[['ID', 'item_cnt_month']].to_csv('final_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}