{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ARIMA Forecasting for Total Monthly Sales \n"},{"metadata":{},"cell_type":"markdown","source":"Citation: https://machinelearningmastery.com/introduction-to-time-series-forecasting-with-python/\n\nI used the above book by Jason Brownlee , Ph.D. as a reference for building the below model. Some of the code snippets used are from the book."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import libraries\n\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Write the csv files to dataframes\nitems=pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nitem_categories=pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops=pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\ntest=pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\nsales_train=pd.read_csv('..//input/competitive-data-science-predict-future-sales/sales_train.csv', parse_dates=['date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Understanding the Data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#print first 5 rows from each file\nprint(items.head())\nprint(item_categories.head())\nprint(shops.head())\nprint(test.head())\nprint(sales_train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print the total number of rows\nprint(items.count())\nprint(item_categories.count())\nprint(shops.count())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 22170 items and they fall into 84 categories. There are 60 shops in total\nThe shops file gives us the mapping between shop name and shop id.\nWe are items file is mapping between item name and item_id. It will not be of much value to us as we can refer to the item by its id. Same with the shops file which has a mapping between the shop name and shop id.\nThe item_categories have a mapping between the item and its category. This could be useful to us but ignoring for now for our prediciton. We need to find out the next months shop->item->Item count number\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compare values hot id and item id for sin train and test data\nprint(test.head())\nprint(sales_train.head())\nprint(sales_train.count(axis=0))\n\nsales_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint('Test shop ids unique: ',test.shop_id.nunique())\n\nprint('Train shop ids unique: ',sales_train.shop_id.nunique())\n\nprint('Test unique item_ids: ',test.item_id.nunique())\nprint('Train unique item_ids: ',sales_train.item_id.nunique())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not all the shop id/item id combinations that exist in the sales file exist in the test file. We can use only the shop id/item ids that exist in test file to forecast our results. First lets get an over all trend and understanding for all the stores and then we can model for individual stores and item ids."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Check for any null values\n\nprint(sales_train.isnull().sum())\n\n#Check for duplicates \n\ndf_items_dup=items[items.duplicated(subset='item_name')]\ndf_shops_dup=shops[shops.duplicated(subset='shop_name')]\nprint(df_items_dup)\nprint(df_shops_dup)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for overall storewide trend"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_monthly=pd.DataFrame()\n\n# Monthly Sales grouped by item_cnt\n\n\nsales_monthly=sales_train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nsales_monthly.index = pd.date_range('1/1/2013', periods=34, freq='M')\nsales_monthly\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see data is resampled with monthly. we will have 34 records. The date block number is 0 to 33 covering 34 months( Jan 2013 to Oct 2015)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_monthly.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# line plot for the time series\nfrom  matplotlib import pyplot\nsales_monthly.plot()\npyplot.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we plot the monthly sales wrt date, we see that there is a decreasing trend . We can also see there is seasonality"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Density plot for the time series\npyplot.subplot(211)\nsales_monthly.hist()\npyplot.subplot(212)\nsales_monthly.plot(kind='kde')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution is not guassian but close. The distribution has a long tail. We need to explore data transformations"},{"metadata":{"trusted":true},"cell_type":"code","source":"#ADF test \nfrom statsmodels.tsa.stattools import adfuller\nX = sales_monthly.values\nresult = adfuller(X)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ADF is greater than critical value 5%. so the data is not stationary . Lets make the data stationary and check the ADF value"},{"metadata":{"trusted":true},"cell_type":"code","source":"#ADF test for stationarity after one differential\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom pandas import Series\n# create a differenced time series\ndef difference(dataset):\n    diff = list()\n    for i in range(1, len(dataset)):\n        value = dataset[i] - dataset[i - 1]\n        diff.append(value)\n    return Series(diff)\n\nX = sales_monthly.values\n# difference data\nstationary = difference(X)\nstationary.index = sales_monthly.index[1:]\n# check if stationary\nresult = adfuller(stationary)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ADF value is less than 5% critical value. So the data is not stationary any more. Null hypothesis can be rejected. In the ARIMA model, the d value could be 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"#ACF and PACF plots\nfrom pandas import read_csv\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom matplotlib import pyplot\npyplot.figure()\npyplot.subplot(211)\nplot_acf(sales_monthly, lags=20, ax=pyplot.gca())\npyplot.subplot(212)\nplot_pacf(sales_monthly, lags=20, ax=pyplot.gca())\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From ACF plot, p value seems to be close to 1 and from PACF plot, q value also seem to be close to one"},{"metadata":{},"cell_type":"markdown","source":"# Hyper Parameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_arima_model(X, arima_order):\n# prepare training dataset\n    X = X.astype('float32')\n    train_size = int(len(X) * 0.80)\n    train, test = X[0:train_size], X[train_size:]\n    history = [x for x in train]\n# make predictions\n    predictions = list()\n    for t in range(len(test)):\n        model = ARIMA(history, order=arima_order)\n        model_fit = model.fit(disp=0)\n        yhat = model_fit.forecast()[0]\n        predictions.append(yhat)\n        history.append(test[t])\n# calculate out of sample error\n    rmse = sqrt(mean_squared_error(test, predictions))\n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef evaluate_models(dataset, p_values, d_values, q_values):\n    dataset = dataset.astype('float32')\n    best_score, best_cfg = float(\"inf\"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    rmse = evaluate_arima_model(dataset, order)\n                    if rmse < best_score:\n                        best_score, best_cfg = rmse, order\n                    print('ARIMA%s RMSE=%.3f' % (order,rmse))\n                except:\n                    continue\n    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nfrom pandas import read_csv\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n# evaluate parameters\np_values = range(0,5)\nd_values = range(0, 2)\nq_values = range(0, 5)\nwarnings.filterwarnings(\"ignore\")\nevaluate_models(sales_monthly.values, p_values, d_values, q_values)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see the best ARIMA order is (0,1,0). So its only a AR and MA seems to be not applicable. Lets check with two orders (0,1,0) and (1,1,0)- the next best"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(sales_monthly, order=(0,1,0))\nmodel_fit = model.fit(disp=0)\nyhat = model_fit.forecast()[0]\nprint(yhat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(sales_monthly, order=(1,1,0))\nmodel_fit = model.fit(disp=0)\nyhat = model_fit.forecast()[0]\nprint(yhat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both the orders give pretty close prediction. Let us see what the Auto Arima gives"},{"metadata":{},"cell_type":"markdown","source":"# Auto ARIMA implmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#install auto arima packages\n! pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Run auto Arima with seasonal = True\nfrom pmdarima import auto_arima\nmodel = auto_arima(sales_monthly, seasonal = True, trace=True, error_action='ignore', suppress_warnings=True)\nmodel.fit(sales_monthly)\nforecast = model.predict(n_periods=1)\nprint(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Auto arima predicted the next month sales to be 71,056 across all stores"},{"metadata":{},"cell_type":"markdown","source":"# Auto ARIMA implemented for each shop_id/item_id combination"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For the test file, add a new column to write the projected value for item_count\ntest['item_cnt_month'] = test.apply(lambda _: '', axis=1)\n\n#for i in range(0,214200):\nfor i in range(0,5000):\n    shop_id=test.iloc[i,1]\n    item_id=test.iloc[i,2]\n    sales_shop=sales_train[sales_train['shop_id']==shop_id]\n    sales_shop_item=sales_shop[sales_shop['item_id']==item_id]\n    if sales_shop_item.empty:\n        test.iloc[i,3]=0\n        continue\n    sales_shop_item.date = [pd.datetime(x.year, x.month,1) for x in sales_shop_item.date.tolist()]\n    sales_by_shop_item = sales_shop_item.resample('M', on='date').sum()\n    sales_monthly_shop_item=sales_by_shop_item.groupby([\"date\"])[\"item_cnt_day\"].sum()\n    sales_monthly_shop_item.index=sales_monthly_shop_item.index.strftime(\"%Y-%m\")\n    date_list= pd.date_range('2013-01', periods=34, freq='M')\n    for date in date_list:\n        if date.strftime(\"%Y-%m\") not in sales_monthly_shop_item.index:\n            sales_monthly_shop_item[date.strftime(\"%Y-%m\")]=0\n    sales_monthly_shop_item.sort_index(inplace=True)\n    \n    from pmdarima import auto_arima\n    model = auto_arima(sales_monthly_shop_item, trace=True, error_action='ignore', suppress_warnings=True)\n    model.fit(sales_monthly_shop_item)\n    forecast = model.predict(n_periods=1)\n    test.iloc[i,3]=forecast\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Running for the first 5000 records in the file as 240000 records are taking a lot of time."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest.to_csv('test_pred.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Limitations of the model:\n1) We ignore some features like item cateogries and item price. We need to check if they impact the model\n\n2) The model is very process intensive as we are looping across shop id and item id  to implement the model at shop id vs item id\n\n3) Need to check if daily resampling gives better results than monthly resampling\n\nTo implement in my next notebook\n\n1) XGBoost to see if regression can be applied and improve the model\n\n2) Prophet and hierarchical time series implmentation since this is a 4 level hierarchy (corp->shops->item categories->items\n\n3) Implement LSTM deep learning model\n\n\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}