{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Carregando o Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"sPathTranslated = '/kaggle/input/predict-future-sales-translated-dataset/'\nsPathTrain = '/kaggle/input/competitive-data-science-predict-future-sales/'\nsPathSup = '/kaggle/input/predict-future-sales-supplementary/'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfShops = pd.read_csv(sPathTranslated + 'shops_en.csv', index_col='shop_id')\ndfItems = pd.read_csv(sPathTranslated + 'items_en.csv', index_col='item_id')\ndfCateg = pd.read_csv(sPathTranslated + 'item_categories_en.csv', index_col='item_category_id')\ndfSalesTrain = pd.read_csv(sPathTrain + 'sales_train.csv')\ndfSalesTest = pd.read_csv(sPathTrain + 'test.csv', index_col='ID')\ndfSubm  = pd.read_csv(sPathTrain + 'sample_submission.csv', index_col='ID')\ndfCalendar = pd.read_csv(sPathSup + 'calendar.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product\nfrom collections import Counter\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nimport category_encoders as ce\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Tratando Features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCateg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extraindo categorias e grupos de categorias\ndfCateg['grupo'] = dfCateg['item_category_name'].str.extract(r'(^[\\w\\s]*)')\ndfCateg['grupo'] = dfCateg['grupo'].str.strip()\n\ndfCateg['group_id'] = le.fit_transform(dfCateg.grupo.values)\ndfCateg.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfItems","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join categoria, grupo e group_id no dfItems\ndfItems = dfItems.join(dfCateg, on='item_category_id')\ndfItems.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Shops/Cats/Items preprocessamento\n**\n\n\nObservações:\n\nCada \"shop_name\" começa com o nome da cidade.\n\nCada \"category\" ou categoria do produto contém um tipo e subtipo em seu nome.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfShops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfShops['shop_name'] = dfShops['shop_name'].str.replace('!','').str.lstrip().str.rstrip()\ndfShops['city'] = dfShops['shop_name'].str.split(' ').map(lambda x: x[0])\ndfShops['city_code'] = LabelEncoder().fit_transform(dfShops['city'])\ndfShops = dfShops[['shop_name','city_code', 'city']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfShops = dfShops.drop([10])\ndfShops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfSalesTrain.loc[dfSalesTrain.shop_id == 10, 'shop_id'] = 11\ndfSalesTrain.loc[dfSalesTrain.shop_id == 11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfSalesTrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tratando Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=dfSalesTrain.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(dfSalesTrain.item_price.min(), dfSalesTrain.item_price.max()*1.1)\nsns.boxplot(x=dfSalesTrain.item_price)\n\ndfSalesTrain = dfSalesTrain[dfSalesTrain.item_price<100000]\ndfSalesTrain = dfSalesTrain[dfSalesTrain.item_cnt_day<1001]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Foi detectado um item com valor abaixo de zero. Será preenchido com o valor médio."},{"metadata":{"trusted":true},"cell_type":"code","source":"median = dfSalesTrain[\n    (dfSalesTrain.shop_id==32)&\n    (dfSalesTrain.item_id==2973)&\n    (dfSalesTrain.date_block_num==4)&\n    (dfSalesTrain.item_price>0)\n].item_price.median()\n\ndfSalesTrain.loc[dfSalesTrain.item_price<0, 'item_price'] = median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfSalesTrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Para cada par shop_id/item_id devemos criar uma linha para cada mês (0 - 33)\n\ngrid = [] \n\nindex_cols = ['date_block_num','shop_id', 'item_id']\nmeses = dfSalesTrain['date_block_num'].unique()\n\n#We construct a grid of all possible shop_id/item_id pairs for a given month\nfor mes in meses:\n    shop_ids = dfSalesTrain[dfSalesTrain['date_block_num'] == mes].shop_id.unique()\n    item_ids = dfSalesTrain[dfSalesTrain['date_block_num'] == mes].item_id.unique()\n    grid.append(np.array(list(product(*[[mes], shop_ids, item_ids])), dtype='int16'))\n\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)  \n\n#We join the grid with the aggregated sales data per month\ngb = dfSalesTrain.groupby(index_cols, as_index = False).agg({ 'item_cnt_day':'sum'})\ngb.rename(columns = {'item_cnt_day':'item_cnt_month'},inplace = True)\ndf_sales = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n\n#We add item price\ngb = dfSalesTrain.groupby('item_id',as_index = False).agg({ 'item_price':'mean'})\ngb.rename(columns ={'item_price':'avg_item_price'}, inplace = True)\ndf_sales = pd.merge(df_sales, gb,how='left', on='item_id').fillna(0)\n\n#Clip target values\ndf_sales['item_cnt_month'] = np.clip(df_sales['item_cnt_month'], 0, 20)\ndf_sales.sort_values(index_cols, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfSalesTest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We assign next Date Block Num to the test set\ndfSalesTest['date_block_num'] = 34\n\n#Concatenate train and test dataframes\ndfSales = pd.concat([dfSalesTrain,dfSalesTest], ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfSales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfSales.fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting training into training and validation\n#Using gridsearch on XGBoost will take very long time, so I decided to go with a fixed validation set for month 33\n#and use evaluation built in functionnality of XGBoost to determine the best iteration\nX_train = df_sales[df_sales['date_block_num'] < 33].drop('item_cnt_month',axis = 1)\ny_train = df_sales[df_sales['date_block_num'] < 33].item_cnt_month\nX_val = df_sales[df_sales['date_block_num'] == 33].drop('item_cnt_month',axis = 1)\ny_val = df_sales[df_sales['date_block_num'] == 33].item_cnt_month\n#Test Set\nX_test  = df_sales[df_sales['date_block_num'] == 34].drop('item_cnt_month',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport sklearn.model_selection as skt\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import plot_importance\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nfrom xgboost import plot_importance\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import ElasticNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model training and fiting\n#Model is already serialized, uncomment to train the model again\nts = time.time()\n\nxgb = XGBRegressor(\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=300, \n    subsample=0.8,\n    colsample_bytree=0.8,\n    eta = 0.3,\n    seed=42)\n\nxgb.fit(\n    X_train, \n    y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, y_train), (X_val, y_val)], \n    verbose=True, \n    early_stopping_rounds = 10)\n\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"in progress... "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}