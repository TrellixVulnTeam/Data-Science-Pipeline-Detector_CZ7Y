{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-27T12:36:19.302425Z","iopub.execute_input":"2022-01-27T12:36:19.302885Z","iopub.status.idle":"2022-01-27T12:36:19.319635Z","shell.execute_reply.started":"2022-01-27T12:36:19.302796Z","shell.execute_reply":"2022-01-27T12:36:19.318569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:19.321337Z","iopub.execute_input":"2022-01-27T12:36:19.321968Z","iopub.status.idle":"2022-01-27T12:36:20.627027Z","shell.execute_reply.started":"2022-01-27T12:36:19.321918Z","shell.execute_reply":"2022-01-27T12:36:20.626069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In this cell, Train and Test sets are loaded\ntrain=pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:20.629206Z","iopub.execute_input":"2022-01-27T12:36:20.629663Z","iopub.status.idle":"2022-01-27T12:36:23.649778Z","shell.execute_reply.started":"2022-01-27T12:36:20.629606Z","shell.execute_reply":"2022-01-27T12:36:23.648693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:23.651663Z","iopub.execute_input":"2022-01-27T12:36:23.652118Z","iopub.status.idle":"2022-01-27T12:36:23.688271Z","shell.execute_reply.started":"2022-01-27T12:36:23.652072Z","shell.execute_reply":"2022-01-27T12:36:23.686992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:23.689745Z","iopub.execute_input":"2022-01-27T12:36:23.690135Z","iopub.status.idle":"2022-01-27T12:36:23.702903Z","shell.execute_reply.started":"2022-01-27T12:36:23.690099Z","shell.execute_reply":"2022-01-27T12:36:23.701746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### From the train set, we can observe that the feature 'date' is trivial as it infers the same as the feature 'date_block_num', hence i will drop this 'date' feature.\n### I will also drop the feature 'item_price' as it is not given in the test data, so what's the purpose of training our model considering this feature if we are not going to make predictions using this feature.","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:58:29.507541Z","iopub.execute_input":"2021-08-26T09:58:29.508051Z","iopub.status.idle":"2021-08-26T09:58:29.513332Z","shell.execute_reply.started":"2021-08-26T09:58:29.508008Z","shell.execute_reply":"2021-08-26T09:58:29.512003Z"}}},{"cell_type":"code","source":"train['item_cnt_day']=abs(train['item_cnt_day'])","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:23.70471Z","iopub.execute_input":"2022-01-27T12:36:23.705148Z","iopub.status.idle":"2022-01-27T12:36:23.73829Z","shell.execute_reply.started":"2022-01-27T12:36:23.70505Z","shell.execute_reply":"2022-01-27T12:36:23.737162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(columns=['date','item_price'],axis=1,inplace=True)\ntrain.drop_duplicates(inplace=True,keep='first',ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:23.743596Z","iopub.execute_input":"2022-01-27T12:36:23.744051Z","iopub.status.idle":"2022-01-27T12:36:24.322051Z","shell.execute_reply.started":"2022-01-27T12:36:23.744012Z","shell.execute_reply":"2022-01-27T12:36:24.320964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:24.324332Z","iopub.execute_input":"2022-01-27T12:36:24.324686Z","iopub.status.idle":"2022-01-27T12:36:24.341496Z","shell.execute_reply.started":"2022-01-27T12:36:24.324653Z","shell.execute_reply":"2022-01-27T12:36:24.340265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here the Target feature is 'item_cnt_day' which is a continuous quantity.\n### But the independent features ['shop_id','item_id'] are discrete/labeled...\n### Hence we go for Pivoting to get the no. of items sold per month for the respective ['shop_id','item_id']","metadata":{}},{"cell_type":"code","source":"train1=pd.pivot_table(train,index=['shop_id','item_id'],columns='date_block_num',values='item_cnt_day',aggfunc=np.sum).reset_index()\ntrain1\n# Here the columns 0,1...33 have the items_per_month values","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:24.343031Z","iopub.execute_input":"2022-01-27T12:36:24.343372Z","iopub.status.idle":"2022-01-27T12:36:26.133082Z","shell.execute_reply.started":"2022-01-27T12:36:24.343339Z","shell.execute_reply":"2022-01-27T12:36:26.131975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In below step, we then merge train1 and test to convert the test[['shop_id','item_id']] into the number of the respected items/sold/month for the past 34 months.","metadata":{}},{"cell_type":"code","source":"test1=test.merge(train1,how='left',on=['shop_id','item_id']).drop(columns=['shop_id','item_id']).fillna(value=0)\ntest1","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:26.134456Z","iopub.execute_input":"2022-01-27T12:36:26.134801Z","iopub.status.idle":"2022-01-27T12:36:26.525382Z","shell.execute_reply.started":"2022-01-27T12:36:26.134766Z","shell.execute_reply":"2022-01-27T12:36:26.524684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train=test1.iloc[:,1:-1]\ny_train=test1.iloc[:,-1]\nx_test=test1.iloc[:,2:]","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:26.526617Z","iopub.execute_input":"2022-01-27T12:36:26.52711Z","iopub.status.idle":"2022-01-27T12:36:26.569054Z","shell.execute_reply.started":"2022-01-27T12:36:26.527078Z","shell.execute_reply":"2022-01-27T12:36:26.568039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:26.570557Z","iopub.execute_input":"2022-01-27T12:36:26.571116Z","iopub.status.idle":"2022-01-27T12:36:26.636569Z","shell.execute_reply.started":"2022-01-27T12:36:26.571081Z","shell.execute_reply":"2022-01-27T12:36:26.635248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:26.638113Z","iopub.execute_input":"2022-01-27T12:36:26.638475Z","iopub.status.idle":"2022-01-27T12:36:26.647391Z","shell.execute_reply.started":"2022-01-27T12:36:26.638418Z","shell.execute_reply":"2022-01-27T12:36:26.646243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:26.648674Z","iopub.execute_input":"2022-01-27T12:36:26.649024Z","iopub.status.idle":"2022-01-27T12:36:26.720186Z","shell.execute_reply.started":"2022-01-27T12:36:26.648994Z","shell.execute_reply":"2022-01-27T12:36:26.719184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr=LinearRegression()\nlr.fit(x_train,y_train)\nprint('Linear Regression model score is:',lr.score(x_train,y_train))\nprint('MSE: ',mean_squared_error(y_train,lr.predict(x_train)))\nlr.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:26.721651Z","iopub.execute_input":"2022-01-27T12:36:26.721942Z","iopub.status.idle":"2022-01-27T12:36:27.183422Z","shell.execute_reply.started":"2022-01-27T12:36:26.721914Z","shell.execute_reply":"2022-01-27T12:36:27.18125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dr=DecisionTreeRegressor()\ndr.fit(x_train,y_train)\nprint('DecisionTreeRegressor model score is:',dr.score(x_train,y_train))\nprint('MSE: ',mean_squared_error(y_train,dr.predict(x_train)))\ndr.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:36:27.18517Z","iopub.execute_input":"2022-01-27T12:36:27.18563Z","iopub.status.idle":"2022-01-27T12:36:28.941917Z","shell.execute_reply.started":"2022-01-27T12:36:27.185581Z","shell.execute_reply":"2022-01-27T12:36:28.940876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gb=GradientBoostingRegressor()\ngb.fit(x_train,y_train)\nprint('GradientBoostRegressor model score is:',gb.score(x_train,y_train))\nprint('MSE: ',mean_squared_error(y_train,gb.predict(x_train)))\ny_pred=gb.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:37:10.212053Z","iopub.execute_input":"2022-01-27T12:37:10.212476Z","iopub.status.idle":"2022-01-27T12:37:29.689366Z","shell.execute_reply.started":"2022-01-27T12:37:10.212441Z","shell.execute_reply":"2022-01-27T12:37:29.688371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rr=RandomForestRegressor()\nrr.fit(x_train,y_train)\nprint('RandomForestRegressor model score is:',rr.score(x_train,y_train))\nprint('MSE: ',mean_squared_error(y_train,rr.predict(x_train)))\nrr.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:37:29.690961Z","iopub.execute_input":"2022-01-27T12:37:29.691283Z","iopub.status.idle":"2022-01-27T12:39:29.032511Z","shell.execute_reply.started":"2022-01-27T12:37:29.691251Z","shell.execute_reply":"2022-01-27T12:39:29.031506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'Id':test1.iloc[:,0],'item_cnt_month': [abs(i) for i in y_pred.tolist()]})\noutput.to_csv('mysubmission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-27T12:39:29.034381Z","iopub.execute_input":"2022-01-27T12:39:29.034733Z","iopub.status.idle":"2022-01-27T12:39:29.912758Z","shell.execute_reply.started":"2022-01-27T12:39:29.0347Z","shell.execute_reply":"2022-01-27T12:39:29.911817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here i am submitting the GradientBoostingRegressor predictions as it is giving the best score among the above all.","metadata":{}}]}