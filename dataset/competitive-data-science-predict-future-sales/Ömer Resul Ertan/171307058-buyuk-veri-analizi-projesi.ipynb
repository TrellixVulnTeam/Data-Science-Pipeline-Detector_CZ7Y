{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport sklearn.metrics as sm\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.ensemble import StackingRegressor\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\ndef metrics(pred, y_test):\n    evs = sm.explained_variance_score(y_test, pred)\n    me = sm.max_error(y_test, pred)\n    mae = sm.mean_absolute_error(y_test, pred)\n    mse = sm.mean_squared_error(y_test, pred)\n    rmse = np.sqrt(mse)\n    #msle = sm.mean_squared_log_error(y_test, pred)\n    m_ae = sm.median_absolute_error(y_test, pred)\n    r2 = sm.r2_score(y_test, pred)\n    #mpd = sm.mean_poisson_deviance(y_test, pred)\n    #mgd = sm.mean_gamma_deviance(y_test, pred)\n    mape = mean_absolute_percentage_error(pred, y_test)\n    return({'Explained Variance Score': evs,\n            'Max Error': me,\n            'Mean Absolute Error': mae,\n            'Mean Squared Error': mse,\n            'Root Mean Squared Error': rmse,\n            #'Mean Squared Log Error': msle,\n            'Median Absolute Error': m_ae,\n            'RÂ² Score': r2,\n            #'Mean Poisson Deviance': mpd,\n            #'Mean Gamma Deviance': mgd,\n            'Mean Absolute Percentage Error': mape\n            })","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n\nitems = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\nitem_cats = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\nsales = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')\nsubmission = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsales_copy = sales.copy()\nsales_copy = sales_copy.pivot_table(\n    index=['shop_id', 'item_id'],\n    values=['item_cnt_day'],\n    columns=['date_block_num'],\n    fill_value=0,\n    aggfunc='sum'\n).reset_index()\n\nsales_copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfirst_train = test.copy()\nfirst_train = first_train.merge(sales_copy, how='left', on=['shop_id', 'item_id']).fillna(0).drop(\n    ['ID', 'shop_id', 'item_id'], axis=1)\nfirst_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = first_train.values[:,:-2], first_train.values[:, -2:-1].ravel()\nX_valid, y_valid = first_train.values[:,1:-1], first_train.values[:, -1:].ravel()\nX_test = first_train.values[:, 2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg1 = LinearRegression()\nreg1.fit(X_train, y_train)\npred1 = reg1.predict(X_valid)\nreg1Metric = metrics(pred1,y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg2 = DecisionTreeRegressor()\nreg2.fit(X_train, y_train)\npred2 = reg2.predict(X_valid)\nreg2Metric = metrics(pred2,y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg3 = RandomForestRegressor()\nreg3.fit(X_train, y_train)\npred3 = reg3.predict(X_valid)\nreg3Metric = metrics(pred3,y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = [('1', reg1), \n              ('2', reg2), \n              ('3', reg3),\n              ]\nvoting_regressor = VotingRegressor(estimators=estimators)\nstacking_regressor = StackingRegressor(estimators=estimators)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vreg = voting_regressor.fit(X_train, y_train)\nsreg = stacking_regressor.fit(X_train, y_train)\n\nvregpred = vreg.predict(X_valid)\nvregmetrics = metrics(vregpred,y_valid)\n\nsregpred = sreg.predict(X_valid)\nsregmetrics = metrics(sregpred,y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = ['LinearRegression', 'DecisionTreeRegressor', 'RandomForestRegressor', 'VotingRegressor','StackingRegressor']\npd.DataFrame([reg1Metric, \n              reg2Metric,\n              reg3Metric,\n              vregmetrics,\n              sregmetrics],\n              index = names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg1Result = reg1.predict(X_test)\nreg2Result = reg2.predict(X_test)\nreg3Result = reg3.predict(X_test)\nvregResult = vreg.predict(X_test)\nsregResult = sreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PredictBag = {\n    'LR':reg1Result,\n    'DTR':reg2Result,\n    'RFR':reg3Result,\n    'VREF':vregResult,\n    'SREF':vregResult,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.concat([submission, pd.DataFrame(PredictBag)], axis = 1).drop([\"item_cnt_month\",\"ID\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meanpredict = predict.mean(axis=1).rename(\"item_cnt_month\").reset_index().rename(columns={'index': 'ID'})\nmeanpredict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meanpredict.to_csv('./results.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\npickle.dump(reg1, open(\"./reg1_model.pkl\", 'wb'))\npickle.dump(reg2, open(\"./reg2_model.pkl\", 'wb'))\npickle.dump(reg3, open(\"./reg3_model.pkl\", 'wb'))\npickle.dump(voting_regressor, open(\"./vref_model.pkl\", 'wb'))\npickle.dump(stacking_regressor, open(\"./sref_model.pkl\", 'wb'))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}