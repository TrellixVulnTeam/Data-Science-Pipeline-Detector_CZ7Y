{"cells":[{"metadata":{},"cell_type":"markdown","source":"# data processing"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb  \n\ntrain=pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest=pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\n\nshops=pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\nitem=pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nitem_category=pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['revenue'] = train['item_price'] *  train['item_cnt_day']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop('date',axis=1)\n\nX_train=train.drop('item_cnt_day',axis=1)\nX_train=X_train.drop('date_block_num',axis=1)\nX_train=X_train.drop('item_price',axis=1)\n\ny_train=train['item_cnt_day']\n\ntest=test.drop('ID',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# data split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split  \n\nX_train,X_valid,y_train,y_valid = train_test_split(X_train,y_train, test_size=0.2, shuffle=True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(X_train, label=y_train)  \ndvalid = xgb.DMatrix(X_valid, label=y_valid) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train lightgbm"},{"metadata":{"trusted":true},"cell_type":"code","source":"from optuna.integration import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = lgb.Dataset(X_train, label=y_train)\neval_data = lgb.Dataset(X_valid, label=y_valid)\n\nparam = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'lambda_l1': 8.72896788870908e-06,\n        'lambda_l2': 5.433642964479813e-07,\n        'num_leaves': 2,\n        'feature_fraction': 0.5402652675292832,\n        'bagging_fraction': 0.5999425893986495,\n        'bagging_freq': 4,\n        'min_child_samples': 14,\n    }\n\nbest = lgb.train(param, \n                 dtrain,\n                 valid_sets=eval_data,\n                 early_stopping_rounds=10)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n\nimport lightgbm as lgb\nimport numpy as np\nimport sklearn.datasets\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split\n\nimport optuna\n\n\n# FYI: Objective functions can take additional arguments\n# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\ndef objective(trial):\n\n    param = {\n        \"objective\": \"regression\",\n        \"metric\": \"rmse\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n\n    gbm = lgb.train(param, dtrain)\n    preds = gbm.predict(X_valid)\n    pred_labels = np.rint(preds)\n    accuracy = sklearn.metrics.accuracy_score(y_valid, pred_labels)\n    return accuracy\n\n\nif __name__ == \"__main__\":\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=100)\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n\n    print(\"  Value: {}\".format(trial.value))\n\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))\n        \n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n\n\nimport lightgbm as lgb\nimport numpy as np\nimport sklearn.datasets\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split\n\nimport optuna\n\nlgbm_params = {\n    'objective': 'regression'\n    \n    }\n\nauc_list = []\nprecision_list = []\nrecall_list = []\n\ndtrain = lgb.Dataset(X_train, label=y_train)\neval_data = lgb.Dataset(X_valid, label=y_valid)\n\n\ndef objective(trial):\n\n    param = {\n        \"objective\": \"regression\",\n        \"metric\": \"rmse\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n\n    gbm = lgb.train(param, dtrain)\n    preds = gbm.predict(X_valid)\n    pred_labels = np.rint(preds)\n    accuracy = sklearn.metrics.accuracy_score(y_valid, pred_labels)\n    return accuracy\n\n\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\n\nprint('Number of finished trials: {}'.format(len(study.trials)))\n\nprint('Best trial:')\ntrial = study.best_trial\n\nprint('  Value: {}'.format(trial.value))\n\nprint('  Params: ')\nfor key, value in trial.params.items():\n    print('    {}: {}'.format(key, value))    \n\n    # optunaでサーチしたパラメータ\ntrial.params['objective'] = 'regression'\nlgbm_params = trial.params\n\n\n    # データセットを生成する\nlgb_train = lgb.Dataset(X_train, y_train)\n\n    # モデル評価用\nlgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n\nmodel = lgb.train(lgbm_params, \n                    lgb_train,\n                    valid_sets=lgb_valid,\n                    num_boost_round=100000,\n                    early_stopping_rounds=10)\n\npredict = model.predict(test, num_iteration=model.best_iteration)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.DataFrame(predict)\ndata=data[:214200]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sumple['item_cnt_month']=data\nsumple.to_csv('last.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}