{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom itertools import product\nfrom sklearn.preprocessing import LabelEncoder\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nimport time\nimport sys\nimport gc\nimport pickle\nsys.version_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\nshops = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\ncats = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\ntrain = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\n# set index to ID to avoid droping it later\ntest  = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Sales Train Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows= 1, ncols= 2, figsize = (12,4))\n\nsns.distplot(train['item_price'], kde= False, ax= ax[0])\nsns.distplot(train['item_cnt_day'], kde= False, ax= ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows= 1, ncols= 2, figsize = (12,4))\n\nsns.boxplot(x = train['item_price'],ax= ax[0])\nsns.boxplot(x = train['item_cnt_day'],ax= ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['item_price', 'item_cnt_day']].describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_price'].nlargest(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_cnt_day'].nlargest(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['item_price'] < 100000]\ntrain = train[train['item_cnt_day'] < 1001]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_price'].nsmallest(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['item_price'] <0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_value = train[(train['shop_id'] == 32) & (train['item_id'] == 2973) & (train['item_price'] > 0)]['item_price'].median()\n\ntrain.loc[train.item_price<0, 'item_price'] = median_value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shop Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shop_names = list(shops['shop_name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Unique Number of Shop Names : {shops['shop_name'].nunique()}\")\nprint(f\"Unique Number of Shop IDs : {shops['shop_id'].nunique()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each Shop Name contains City name in the start. We will extract the city information from the shop name","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shops['city_name'] = shops['shop_name'].apply(lambda x : x.split()[0])\nshops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.drop('shop_name', axis= 1, inplace= True)\nshops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_encoder = LabelEncoder()\nshops['city_code'] = label_encoder.fit_transform(shops['city_name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.drop('city_name', axis= 1, inplace= True)\nshops.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Item & Item Category Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Item type & subtype features\ncats['item_type'] = cats['item_category_name'].apply(lambda x : x.split('-')[0].strip())\ncats['item_subtype'] = cats['item_category_name'].apply(lambda x : x.split('-')[1].strip() if len(x.split('-')) > 1 else x.split('-')[0].strip())\n\n#Encoding them\ncats['item_type_code'] = LabelEncoder().fit_transform(cats['item_type'])\ncats['item_subtype_code'] = LabelEncoder().fit_transform(cats['item_subtype'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats.drop(['item_category_name', 'item_type', 'item_subtype'], axis= 1, inplace= True)\ncats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items = items.merge(cats, on= 'item_category_id', how= 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.drop('item_name', inplace= True, axis= 1)\nitems.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Items which are present in Test but not in Train set\nlen(list(set(test.item_id) - set(test.item_id).intersection(set(train.item_id))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Unique Items in Test Set: {test['item_id'].nunique()}\")\nprint(f\"Unique Shops in Test Set: {test['shop_id'].nunique()}\")\nprint(f\"Total Shop Item pairs : {len(test)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['date_block_num'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = []\n\ncols = ['date_block_num', 'shop_id', 'item_id']\n\nfor i in range(34) :\n    sales = train[train['date_block_num'] == i]\n    matrix.append(np.array(list(product([i], sales['shop_id'].unique(), sales['item_id'].unique() )), dtype='int16'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = pd.DataFrame(np.vstack(matrix), columns= cols)\n\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\n\nmatrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = train.groupby(['date_block_num', 'shop_id', 'item_id']).agg({'item_cnt_day' : 'sum'})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace = True)\n\ngroup.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = pd.merge(matrix, group, on= cols, how ='left')\n\nmatrix['item_cnt_month'] = matrix['item_cnt_month'].fillna(0).clip(0,20).astype(np.float16)\n\nmatrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['date_block_num'] = 34\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\ntest['shop_id'] = test['shop_id'].astype(np.int8)\ntest['item_id'] = test['item_id'].astype(np.int16)\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\nmatrix.fillna(0, inplace=True) \n\nmatrix.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pulling Items & Shops Feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#pulling shop features\nmatrix = pd.merge(matrix, shops, on= 'shop_id', how= 'left')\nmatrix = pd.merge(matrix, items, on= 'item_id', how= 'left')\n\nmatrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix['city_code'] = matrix['city_code'].astype(np.int8)\nmatrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\nmatrix['item_type_code'] = matrix['item_type_code'].astype(np.int8)\nmatrix['item_subtype_code'] = matrix['item_subtype_code'].astype(np.int8)\n\nmatrix.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding Target Lags","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lags = [1,2,3,6,12]\n\nfor lag in lags :\n    matrix[f'Previous_{lag}_month_sales'] = matrix.groupby(['shop_id', 'item_id'])['item_cnt_month'].shift(lag)\n    \nmatrix.fillna(0, inplace= True)\nmatrix.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mean Encoded Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_encoded_features(matrix, columns, lags) :\n    \n    group = matrix.groupby(columns).agg({'item_cnt_month' : 'mean'})\n    new_column_name = '_'.join(columns) + '_item_cnt'\n    group.columns = [new_column_name] \n    group.reset_index(inplace = True)\n    \n    matrix = pd.merge(matrix, group, on= columns, how= 'left')\n    matrix[new_column_name] = matrix[new_column_name].astype(np.float16)\n    \n    for lag in lags :\n        matrix[f'lag_{lag + 1}_{new_column_name}'] = matrix.groupby(['shop_id', 'item_id'])[new_column_name].shift(lag)\n        \n    matrix.drop(new_column_name, axis=1, inplace=True)\n        \n    return matrix\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Month Sales Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num'], lags= [1])\n\n#Month Item Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_id'], lags= [1,2,3,6,12])\n\n#Month Shop Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'shop_id'], lags= [1,2,3,6,12])\n\n#Month Item Category Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_category_id'], lags= [1,2,3,6,12])\n\n#Month Shop Category Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'shop_id', 'item_category_id'], lags= [1])\n\n#Month Shop Type Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'shop_id', 'item_type_code'], lags= [1])\n\n#Month Shop SubType Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'shop_id', 'item_subtype_code'], lags= [1])\n\n#Month City Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'city_code'], lags= [1])\n\n#Month Item City Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_id', 'city_code'], lags= [1])\n\n#Month Type Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_type_code'], lags= [1])\n\n#Month Sub-Type Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_subtype_code'], lags= [1])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trend Features\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding avg price of each item\ngroup = train.groupby(['item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['item_avg_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['item_id'], how='left')\nmatrix['item_avg_price'] = matrix['item_avg_price'].astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding Average Price every month of each item\ngroup = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['date_item_avg_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_price'] = matrix['date_item_avg_price'].astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First Time Sale","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\nmatrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Revenue","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['revenue'] = train['item_price'] *  train['item_cnt_day']\n\n#Month & Shop wise revenue\ngroup = train.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\ngroup.columns = ['date_shop_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n\n#Shop wise Revenue\ngroup = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\ngroup.columns = ['shop_avg_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['shop_id'], how='left')\nmatrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\n\nmatrix['delta_revenue'] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\nmatrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n\nmatrix = mean_encoded_features(matrix, columns= ['delta_revenue'], lags= [1])\n\nmatrix.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#month as per calender\nmatrix['month'] = matrix['date_block_num'] % 12\n\n#number of days in the month \ndays = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\nmatrix['days'] = matrix['month'].map(days).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Training & Test Sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping intial 12 months data\nmatrix = matrix[matrix.date_block_num > 11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = matrix[matrix['date_block_num'] < 34].drop('item_cnt_month', axis = 1)\ny_train = matrix[matrix['date_block_num'] < 34]['item_cnt_month']\n\nX_test = matrix[matrix['date_block_num'] == 34].drop('item_cnt_month', axis = 1)\ny_test = matrix[matrix['date_block_num'] == 34]['item_cnt_month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del matrix\ndel group\ndel items\ndel shops\ndel cats\ndel train\n# leave test for submission\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel = XGBRegressor(max_depth=6, n_estimators=1000, colsample_bytree=0.8, subsample=0.8, eta=0.1,seed=42)\n\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['item_cnt_month'] = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('Xgboost.txt', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}