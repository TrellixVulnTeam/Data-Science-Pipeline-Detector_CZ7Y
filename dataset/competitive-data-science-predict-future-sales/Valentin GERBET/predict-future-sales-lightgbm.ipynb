{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Monthly Sales Prediction","metadata":{}},{"cell_type":"markdown","source":"We are asked to predict next month's total sales for every product and store of the largest Russian software firms - 1C Company. They provided us with a time-series dataset consisting of daily sales data.","metadata":{}},{"cell_type":"markdown","source":"* <a href=\"https://www.kaggle.com/c/competitive-data-science-predict-future-sales\">Competition link</a>\n* Very informative <a href=\"https://www.kaggle.com/gordotron85/future-sales-xgboost-top-3\">kernel</a> that I used as a starting point","metadata":{}},{"cell_type":"markdown","source":"Data Fields:\n- ID - an Id that represents a (Shop, Item) tuple within the test set\n- shop_id - unique identifier of a shop\n- item_id - unique identifier of a product\n- item_category_id - unique identifier of item category\n- item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n- item_price - current price of an item\n- date - date in format dd/mm/yyyy\n- date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n- item_name - name of item\n- shop_name - name of shop\n- item_category_name - name of item category","metadata":{}},{"cell_type":"markdown","source":"## Dependencies","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.preprocessing import LabelEncoder\n\nimport lightgbm as lgb\n\nimport shap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"sales = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv',\n                    parse_dates=[\"date\"])\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nitem_cat = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"### Outliers\nSeveral values of price and count seem abnormal - either extremly high or negative.\nThey might be actual explaination, e.g. a refund. We will ignore these values for now.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 3))\nax.set_xscale('symlog')\nax.set_title('Prices distribution', fontsize=14)\nsns.boxplot(x=sales.item_price, palette='rainbow', ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 3))\nax.set_xscale('symlog')\nax.set_title('Distribution of number of product sold', fontsize=14)\nsns.boxplot(x=sales.item_cnt_day, palette='rainbow', ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales = sales.query('item_cnt_day > 0 & item_cnt_day < 1000').copy()\nsales = sales.query('item_price > 0 & item_price <= 50000').copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Leakage","metadata":{}},{"cell_type":"markdown","source":"Shops missing from the test set are filtered out in the training data.","metadata":{}},{"cell_type":"code","source":"shop_ids = test['shop_id'].unique()\nsales = sales[sales['shop_id'].isin(shop_ids)].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Shops","metadata":{}},{"cell_type":"markdown","source":"Shops dataset has duplicates. The latest entry is considered to be relevant. ","metadata":{}},{"cell_type":"code","source":"print(f\"{shops['shop_name'][0]} VS {shops['shop_name'][57]}\")\nprint(f\"{shops['shop_name'][1]} VS {shops['shop_name'][58]}\")\nprint(f\"{shops['shop_name'][10]} VS {shops['shop_name'][11]}\")\nprint(f\"{shops['shop_name'][39]} VS {shops['shop_name'][40]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ids are uptaded both in training and test datasets.","metadata":{}},{"cell_type":"code","source":"sales.loc[sales['shop_id'] == 0, 'shop_id'] = 57\nsales.loc[sales['shop_id'] == 1, 'shop_id'] = 58\nsales.loc[sales['shop_id'] == 10, 'shop_id'] = 11\nsales.loc[sales['shop_id'] == 39, 'shop_id'] = 40\n\ntest.loc[test['shop_id'] == 0, 'shop_id'] = 57\ntest.loc[test['shop_id'] == 1, 'shop_id'] = 58\ntest.loc[test['shop_id'] == 10, 'shop_id'] = 11\ntest.loc[test['shop_id'] == 39, 'shop_id'] = 40","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A heavy-handed google translation shows that shop_name contains two pieces of information: city name and category of building.","metadata":{}},{"cell_type":"code","source":"shops[\"city\"] = shops.shop_name.apply(lambda x: x.split()[0])\nshops[\"category\"] = shops.shop_name.apply(lambda x: x.split()[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shops.loc[shops['city'] =='!Якутск', 'city'] = 'Якутск'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only important categories are considered.","metadata":{}},{"cell_type":"code","source":"shops_cat = shops.category.value_counts()\nshops_cat.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def thresh_filter(x,\n                  items,\n                  default=\"other\"):\n    return x if (x in items) else default\n\n\nthresh_cat = shops_cat[shops_cat >= 5].index\nshops.category = shops.category.apply(thresh_filter,\n                                      args=([thresh_cat]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"New variables are encoded to be used as features.","metadata":{}},{"cell_type":"code","source":"shops[\"shop_category\"] = LabelEncoder().fit_transform(shops.category)\nshops[\"shop_city\"] = LabelEncoder().fit_transform(shops.city)\nshops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Items","metadata":{}},{"cell_type":"markdown","source":"First sale of each item:","metadata":{}},{"cell_type":"code","source":"items['first_sale_date'] = sales.groupby('item_id')\\\n                                .agg({'date_block_num': 'min'})['date_block_num']\nitems['first_sale_date'] = items['first_sale_date'].fillna(34)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Category_name brings two levels of information on item type.","metadata":{}},{"cell_type":"code","source":"item_cat.item_category_name.unique()[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item_cat['type'] = item_cat.item_category_name.apply(lambda x: x.split()[0])\n\nitem_types = item_cat.type.value_counts()\nthresh_type = item_types[item_types >= 5].index\nitem_cat['type'] = item_cat.type.apply(thresh_filter,\n                                       args=([thresh_type]))\n\ndef get_subtype(x):\n    split = x.split()\n    if len(split) > 1:\n        return split[1].strip()\n    else:\n        return split[0].strip()\n\n    \nitem_cat['subtype'] = item_cat.item_category_name.apply(get_subtype)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item_cat['type_code'] = LabelEncoder().fit_transform(item_cat.type)\nitem_cat['subtype_code'] = LabelEncoder().fit_transform(item_cat.subtype)\nitem_cat = item_cat[[\"item_category_id\", \"subtype_code\", \"type_code\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Monthly sales","metadata":{}},{"cell_type":"markdown","source":"We are interested in predicting the monthly equivalent of item_cnt_day for each tuple (shop, item). Sales data is aggregated.","metadata":{}},{"cell_type":"code","source":"groupby_cols = ['date_block_num', 'shop_id', 'item_id']\n\nsales['transaction'] = sales['item_cnt_day'] * sales['item_price']\n\nmonthly_sales = sales.groupby(by=groupby_cols,\n                              as_index=False).agg({'item_cnt_day': ['sum',\n                                                                    'count'],\n                                                   'transaction': 'sum',\n                                                   'item_price': 'mean',\n                                                   })\nmonthly_sales.columns = ['date_block_num', 'shop_id', 'item_id',\n                         'item_cnt', 'transaction_nb', 'transaction', 'mean_price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Missing records are artificially created to take into account months where no items were sold.","metadata":{}},{"cell_type":"code","source":"def fill_missing_month(monthly_sales):\n    \"\"\"Creates missing tuple (date_block_num, shop_di, item_id)\n    Args:\n        - monthly_sales: pd.DataFrame. Monthly sales\n    Return:\n        pd.DataFrame\n    \"\"\"\n    months_nb = monthly_sales.date_block_num.max()\n    \n    full_df = []\n    for i in range(months_nb + 1):\n        #  Retrieves list of shops and items for this month\n        shops = monthly_sales.query('date_block_num == @i').shop_id.unique()\n        items = monthly_sales.query('date_block_num == @i').item_id.unique()\n        for shop in shops:\n            for item in items:\n                #  Creates entry\n                full_df.append([i, shop, item])\n\n    full_df = pd.DataFrame(full_df,\n                           columns=['date_block_num', 'shop_id', 'item_id'])\n    #  Gets information for existing tuple\n    full_df = full_df.merge(monthly_sales,\n                            how='left',\n                            on=['date_block_num', 'shop_id', 'item_id'])\n    full_df.fillna(0, inplace=True)\n\n    return full_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_sales = fill_missing_month(monthly_sales)\nfull_sales.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top categories visualisation\nWe are zooming out at category level.","metadata":{}},{"cell_type":"code","source":"cat_sales = monthly_sales.merge(items[['item_id', 'item_category_id']],\n                                how='left',\n                                left_on='item_id',\n                                right_on='item_id',\n                                )\ncat_sales = cat_sales.groupby(by=['date_block_num',\n                                  'item_category_id'],\n                              as_index=False).agg({'item_cnt': 'sum'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top categories are defined regarding the total number of items sold, namely more than 100k.","metadata":{}},{"cell_type":"code","source":"cat_group = cat_sales.groupby('item_category_id')\\\n                     .agg({'item_cnt': 'sum'})\\\n                     .sort_values(by='item_cnt',\n                                  ascending=False)\ntop_cat_idx = cat_group.query('item_cnt > 100000').index\ntop_cat = cat_sales[cat_sales.item_category_id.isin(top_cat_idx)].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Names are translated:","metadata":{}},{"cell_type":"code","source":"mapper = {19: 'Games - PS3',\n          20: 'Games - PS4',\n          23: 'Games - XBOX 360',\n          28: 'PC Games - Extensions',\n          30: 'PC Games - Standard edition',\n          37: 'Film - Blu-Ray',\n          40: 'Film - DVD',\n          55: 'Music - CD local production',\n          71: 'Gifts - Bags, Albums, Mouse Pads',}\ntop_cat.item_category_id = top_cat.item_category_id.map(mapper)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interactive chart created with altair:","metadata":{}},{"cell_type":"code","source":"import altair as alt\n\n#  We want to be able to select a specific category on\n#  a bar chart\ncat_filter = alt.selection_multi(fields=[\"item_category_id\"])\ncat_chart = alt.Chart().mark_bar().encode(\n    x=alt.X(\"count()\", title='Age (month)'),\n    y=alt.Y(\"item_category_id:N\"),\n    color=alt.condition(\n        cat_filter,\n        alt.Color(\"item_category_id:N\",\n                  scale=alt.Scale(scheme='category20')),\n        alt.value(\"lightgray\")),\n).properties(width=300,\n             height=300,\n             selection=cat_filter)\n\ndef filtered_bar(x, y, labels, filter):\n    \"\"\"Creates a layered chart of bar plots.\n    The first layer (light gray) contains the plot of the full\n    data, and the second contains the plot of the filtered data.\n    Args:\n     - x: abscissa, split into bins.\n     - y: ordinate, summed up.\n     - label: String labels.\n     - filter: an alt.Selection object to be used to filter the data.\n    \"\"\"\n    base = alt.Chart().mark_bar().encode(\n        x=alt.X(x,\n                bin=alt.Bin(maxbins=34),\n                title=labels[0]),\n        y=alt.Y(y,\n                aggregate='sum',\n                title=labels[1]),\n          ).properties(\n              width=350,\n          )\n    return alt.layer(\n      base.transform_filter(filter),\n      base.encode(color=alt.value('lightgray'),\n                  opacity=alt.value(.7)),\n  ).resolve_scale(y='independent')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alt.hconcat(\n    filtered_bar('date_block_num',\n                 'item_cnt',\n                 ['month', 'Items sold'],\n                 cat_filter),\n    cat_chart,\n    data=top_cat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature engineering","metadata":{}},{"cell_type":"markdown","source":"Test dataset is concatened to conveniently create feature.","metadata":{}},{"cell_type":"code","source":"test['date_block_num'] = 34\n\nfull_sales = pd.concat([full_sales, test.drop('ID', axis=1)],\n                       ignore_index=True,\n                       keys=groupby_cols)\n\nfull_sales = full_sales.fillna(0)\n\nfull_sales.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Categorical features previously defined:","metadata":{}},{"cell_type":"code","source":"full_sales = full_sales.merge(shops,\n                              on='shop_id',\n                              how='left')\nfull_sales = full_sales.merge(items,\n                              on=['item_id'],\n                              how='left')\nfull_sales = full_sales.merge(item_cat,\n                              on='item_category_id',\n                              how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dates","metadata":{}},{"cell_type":"code","source":"def extract_year(date_num_block, thresh=2013):\n    return date_num_block // 12 + thresh\n\n\ndef extract_month(date_num_block):\n    return date_num_block % 12\n\n\nfull_sales['year'] = full_sales.date_block_num.apply(extract_year)\nfull_sales['month'] = full_sales.date_block_num.apply(extract_month)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"New item marker:","metadata":{}},{"cell_type":"code","source":"full_sales['new_item'] = full_sales['first_sale_date'] == full_sales['date_block_num']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time spent since first sale:","metadata":{}},{"cell_type":"code","source":"full_sales['since_first_sale'] = full_sales['date_block_num'] - full_sales['first_sale_date']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Monthly means","metadata":{}},{"cell_type":"code","source":"def get_month_mean(idx_col,\n                   suffixes,\n                   col='item_cnt'):\n    \"\"\"Gets mean value for each month\n    \n    Args:\n     - idx_col: columns to group by\n     - col: column to groub\n    \"\"\"\n    df = full_sales[idx_col + [col]].groupby(idx_col).mean()\n    df = full_sales.merge(df,\n                          how='left',\n                          on=idx_col,\n                          suffixes=suffixes)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mean monthly values:\n* for a specific category in a specific shop\n* for a specific item\n* for a specific item in a specific city\n","metadata":{}},{"cell_type":"code","source":"full_sales = get_month_mean(['date_block_num', 'item_category_id', 'shop_id'],\n                            suffixes=('', '_mean_shop_cat'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_sales = get_month_mean(['date_block_num', 'item_id'],\n                            suffixes=('', '_mean_item'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_sales = get_month_mean(['date_block_num', 'item_id', 'shop_city'],\n                            suffixes=('', '_mean_city'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lag features","metadata":{}},{"cell_type":"markdown","source":"Values taken by features for previous months:\n* number of item sold\n* transaction amount\n* mean price\n* mean values created previously\n","metadata":{}},{"cell_type":"code","source":"lag_list = [1, 2, 3]\ndef get_lag_feature(col,\n                    idx_col,\n                    lag_list=lag_list):\n    \"\"\"Retrives previous values of col for each value of lag\n    \n    Args:\n        - col: column of interest\n        - idx_col: columns to group by\n        - lag_list: intervals of interest\"\"\"\n    for lag in lag_list:\n        ft_name = f'{col}_lag{lag}'\n        full_sales[ft_name] = full_sales.sort_values('date_block_num')\\\n                                        .groupby(idx_col)[col]\\\n                                        .shift(lag)\n        full_sales[ft_name].fillna(0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_lag_feature('item_cnt', ['shop_id', 'item_id'])\nget_lag_feature('transaction_nb', ['shop_id', 'item_id'])\nget_lag_feature('mean_price', ['shop_id', 'item_id'])\nget_lag_feature('item_cnt_mean_city', ['shop_id', 'item_id'])\nget_lag_feature('item_cnt_mean_item', ['shop_id', 'item_id'])\nget_lag_feature('item_cnt_mean_shop_cat', ['shop_id', 'item_id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is specified that target values are clipped into [0,20] range.","metadata":{}},{"cell_type":"code","source":"cnt_cols = []\nfor col in full_sales.columns:\n    if '_cnt' in col:\n        cnt_cols.append(col)\n        \nfor col in cnt_cols:\n    full_sales[col] = full_sales[col].clip(0, 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trends","metadata":{}},{"cell_type":"markdown","source":"Some information on the evolution of the number of product sold in the past months. First over a rolling window of 3 months, then comparing the lagged values.","metadata":{}},{"cell_type":"code","source":"full_sales['item_cnt_trend'] = full_sales[['item_cnt_lag1',\n                                           'item_cnt_lag2',\n                                           'item_cnt_lag3']].mean(axis=1)\nfull_sales['item_cnt_trend'].fillna(0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_sales['trend1'] = full_sales['item_cnt_lag1'] / full_sales['item_cnt_lag2']\nfull_sales['trend1'] = full_sales['trend1'].replace([np.inf, -np.inf], np.nan)\nfull_sales['trend1'] = full_sales['trend1'].fillna(0)\n\nfull_sales['trend2'] = full_sales['item_cnt_lag2'] / full_sales['item_cnt_lag3']\nfull_sales['trend2'] = full_sales['trend2'].replace([np.inf, -np.inf], np.nan)\nfull_sales['trend2'] = full_sales['trend2'].fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cleaning","metadata":{}},{"cell_type":"markdown","source":"The first 3 months were used to create features, thus are removed from the training set.","metadata":{}},{"cell_type":"code","source":"full_sales = full_sales.query('date_block_num >= 3').copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unused columns:","metadata":{}},{"cell_type":"code","source":"droped_col = ['transaction_nb', 'transaction', 'mean_price', 'item_name',\n               'first_sale_date', 'item_cnt_mean_shop_cat', 'item_cnt_mean_item',\n              'item_cnt_mean_city',]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_sales.drop(columns=droped_col, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Downcast:","metadata":{}},{"cell_type":"code","source":"def downcast(df):\n    \"\"\"\n    Reduces allocated memory\n    \n    Args:\n        - df: pd.DataFrame\n    Return:\n        compressed pd.DataFrame\n    \"\"\"\n    for col in df.columns:\n        dtype_name = df[col].dtype.name\n        if dtype_name == 'object' or dtype_name.startswith('date'):\n            pass\n        elif dtype_name == 'bool':\n            df[col] = df[col].astype('int8')\n        elif dtype_name.startswith('int') or (df[col].round() == df[col]).all():\n            df[col] = pd.to_numeric(df[col], downcast='integer')\n        else:\n            df[col] = pd.to_numeric(df[col], downcast='float')\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_sales = downcast(full_sales)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del items, item_cat, sales, monthly_sales, cat_sales, cat_group","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlations","metadata":{}},{"cell_type":"code","source":"corr_matrix = full_sales.corr()\ncorr_matrix = corr_matrix.applymap(abs)\n\nmask = np.zeros_like(corr_matrix)\nmask[np.triu_indices_from(mask)] = True\n\nfig = plt.figure(figsize=(16,8))\nsns.heatmap(corr_matrix,\n            mask=mask,\n            vmin=0,\n            cmap='Blues',\n            annot=True,\n            fmt='.2f',\n            cbar=False)\n\nfig.suptitle('Correlation matrix', fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelisation","metadata":{}},{"cell_type":"markdown","source":"All information regarding the current month has been deleted except, item_cnt that will be our target. The last month available is used for validation purposes.","metadata":{}},{"cell_type":"code","source":"X_train = full_sales.query('date_block_num < 33')\nX_train = X_train.drop(columns=['item_cnt'])\n\nX_valid = full_sales.query('date_block_num == 33')\nX_valid = X_valid.drop(columns=['item_cnt'])\n\nX_test = full_sales.query('date_block_num == 34')\nX_test = X_test.drop(columns=['item_cnt'])\n\n\ny_train = full_sales.query('date_block_num < 33').item_cnt\ny_valid = full_sales.query('date_block_num == 33').item_cnt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LightGBM","metadata":{}},{"cell_type":"code","source":"cat_cols = ['shop_id', 'item_id', 'year', 'month', 'item_category_id',\n            'shop_category', 'shop_city', 'subtype_code', 'type_code', 'new_item']\ncat_cols.sort() #  avoid LigthGBM warning","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtrain = lgb.Dataset(X_train, y_train)\ndvalid = lgb.Dataset(X_valid, y_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A custom GridSearch is performed - we aim to optimise a few hyperparameters:","metadata":{}},{"cell_type":"code","source":"params = dict(metric=['rmse'],\n              num_leaves=[400], #  Default 31 [10, 31, 255, 400]\n              learning_rate=[0.005], #  Default 0.1 [0.005, 0.001, 0.1]\n              max_depth=[-1], #  Default -1 [10, -1]\n              feature_fraction=[0.75],\n              bagging_fraction=[0.75],\n              bagging_freq=[5],\n              random_state=[10],\n              verbose=[-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_results = {}\nfor i, param in enumerate(ParameterGrid(params)):\n    #  At each step a dictionnary is created, containg\n    #  the HPs, the trained model and the validation RMSE\n    grid_results[i] = {}\n    grid_results[i]['params'] = param\n    curr_model = lgb.train(params=param,\n                           train_set=dtrain,\n                           num_boost_round=1500,\n                           valid_sets=(dtrain, dvalid),\n                           early_stopping_rounds=150,\n                           categorical_feature=cat_cols,\n                           verbose_eval=False)\n    grid_results[i]['model'] = curr_model\n    pred = curr_model.predict(X_valid)\n    val_rmse = np.sqrt(mean_squared_error(pred, y_valid))\n    grid_results[i]['val_rmse'] = val_rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_iter = sorted(grid_results,\n                   key=lambda k: grid_results[k]['val_rmse'])[0]\nbest_model = grid_results[best_iter]['model']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature importance","metadata":{}},{"cell_type":"markdown","source":"TreeSHAP is apply on a ~10% sample of testing data.","metadata":{}},{"cell_type":"code","source":"sample_size = int(X_test.shape[0] * 0.1)\ntest_sample = X_test.sample(sample_size)\nbest_model.params[\"objective\"] = \"regression\"\nexplainer = shap.TreeExplainer(best_model)\nshap_values = explainer.shap_values(test_sample)\nshap.summary_plot(shap_values, test_sample, max_display=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"y_test = best_model.predict(X_test).clip(0, 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"ID\": test.index,\n    \"item_cnt_month\": y_test\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}