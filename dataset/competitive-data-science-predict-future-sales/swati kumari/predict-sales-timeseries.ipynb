{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nimport statsmodels.tsa.api as smt\nimport scipy.stats as scs\n\n# settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sale_df = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\nitem_df = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert date column to datetime dtype","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sale_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Aggregate to monthly sale for each shop item pair**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Original dtypes', sale_df.info())\nsale_df.date = sale_df.date.apply(lambda x: datetime.datetime.strptime(x,\"%d.%m.%Y\"))\nprint(sale_df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sale_agg = sale_df.groupby([\"date_block_num\", \"shop_id\",\"item_id\"])[\"item_cnt_day\",\"item_price\"].agg({'item_cnt_day' : 'sum', 'item_price':'mean'}) \nsale_agg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Count number of items in each category","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of items per cat \nx=item_df.groupby(['item_category_id']).count()\nx=x.sort_values(by='item_id',ascending=False)\nx=x.iloc[0:10].reset_index()\nx\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot no of items in each category.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# #plot\nplt.figure(figsize=(8,4))\nax= sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\nplt.title(\"Items per Category\")\nplt.ylabel('# of items', fontsize=12)\nplt.xlabel('Category', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Plot total sales per month.**\n\nThe objective requires us to predict sales for the next month at a store-item combination.\n\nSales over time of each store-item is a time-series in itself. Before we dive into all the combinations, first let's understand how to forecast for a single series.\n\nI've chosen to predict for the total sales per month for the entire company.\n\nFirst let's compute the total sales per month and plot that data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_pm = sale_df.groupby([\"date_block_num\"]).agg({'item_cnt_day':'sum'})\nplt.title('Total sales of the company')\nplt.xlabel('Month')\nplt.ylabel('Sales')\nplt.plot(sales_pm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot rolling mean and standard deviation with a window of 12( one year)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rolling_window = sales_pm.rolling(12)\nplt.figure(figsize= (16,6))\nplt.plot(rolling_window.mean(), label = \"Rolling mean\")\nplt.plot(rolling_window.std(), label = \"Rolling standard deviation\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Quick observations: \nThere is an obvious \"seasonality\" (Eg: peak sales around a time of year) and a decreasing \"Trend\".\n\nLet's check that with a quick decomposition into Trend, seasonality and residuals.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"result1 = sm.tsa.seasonal_decompose(sales_pm,model='additive', freq=12)\nfig1 = result1.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result2 = sm.tsa.seasonal_decompose(sales_pm, model ='multiplicative', freq=12)\nfig2 = result2.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stationarity:\n\nStationarity refers to time-invariance of a series. (ie) Two points in a time series are related to each other by only how far apart they are, and not by the direction(forward/backward)\n\nWhen a time series is stationary, it can be easier to model. Statistical modeling methods assume or require the time series to be stationary.\n\nThere are multiple tests that can be used to check stationarity.\n\nADF( Augmented Dicky Fuller Test)\nKPSS\nPP (Phillips-Perron test)\nLet's just perform the ADF which is the most commonly used one.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def adf_test(timeseries):\n    result = adfuller(timeseries, autolag='AIC')\n    print(f'ADF Statistic: {result[0]}')\n    print(f'p-value: {result[1]}')\n    for key, value in result[4].items():\n        print('Critial Values:')\n        print(f'   {key}, {value}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adf_test(sales_pm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The ADF Statistic value should be less than all critical values and p-value should be within 5% for data to be stationary. This is not the case here. So we de-trend the data first to check whether data is stationary or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# to remove trend\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=sales_pm.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,16))\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts)\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts)\nplt.plot(new_ts)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After De-seasonalization')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts,12)       # assuming the seasonality is 12 months long\nplt.plot(new_ts)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adf_test(new_ts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the statistics, we see that the data is stationary now. We also check for 12 lag differenced on the de-trended data to check its stationarity.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We achieved better stationarity of the data with only de-trending. Hence we will use that data itself. \nNow after the transformations, our p-value for the DF test is well within 5 %. Hence we can assume Stationarity of the series. \nWe can easily get back the original series using the inverse transform function that we have defined above.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **AR, MA and ARMA models:**\nTL: DR version of the models:\n\nMA - Next value in the series is a function of the average of the previous n number of values AR - The errors(difference in mean) of the next value is a function of the errors in the previous n number of values ARMA - a mixture of both.\n\nNow, How do we find out, if our time-series in AR process or MA process?\n\nLet's find out!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsplot(y, lags = None, figsize = (10,8), style ='bmh', title=''):\n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n    with plt.style.context(style):\n        fig = plt.figure(figsize=figsize)\n        layout = (3,2)\n        ts_ax=plt.subplot2grid(layout, (0,0), colspan = 2)\n        acf_ax = plt.subplot2grid(layout, (1,0))\n        pacf_ax = plt.subplot2grid(layout,(1,1))\n        qq_ax = plt.subplot2grid(layout,(2,0))\n        pp_ax = plt.subplot2grid(layout,(2,1))\n        \n        y.plot(ax = ts_ax)\n        ts_ax.set_title(title)\n        smt.graphics.plot_acf(y, lags = lags, ax= acf_ax, alpha = 0.5)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax,alpha = 0.5)\n        sm.qqplot(y, line='s', ax=qq_ax)\n        qq_ax.set_title('QQ Plot')\n        scs.probplot(y, sparams =(y.mean(),y.std()), plot=pp_ax )\n        plt.tight_layout()\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an AR(1) process with alpha = 0.6\nnp.random.seed(1)\nn_samples = 1000\nalpha = 0.6\nx = w = np.random.normal(size = n_samples)\nfor t in range(n_samples):\n    x[t] = alpha * x[t-1] + w[t]\n_ = tsplot(x, lags = 12,title = \"AR(1)  process\" )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# AR(1) process -- has ACF tailing out and PACF cutting off at lag=1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an AR(2) process\nn = int(1000)\nalphas = np.array([.444, .333])\nbetas = np.array([0.])\n\n# Python requires us to specify the zero-lag value which is 1\n# Also note that the alphas for the AR model must be negated\n# We also set the betas for the MA equal to 0 for an AR(p) model\n# For more information see the examples at statsmodels.org\n\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nar2 = smt.arma_generate_sample(ar=ar, ma= ma, nsample = n)\n_ = tsplot(ar2, lags=12, title = \"AR(2) process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# AR(2) process -- has ACF tailing out and PACF cutting off at lag=2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an MA(1) process\nn = int(1000)\n# set the AR(p) alphas equal to 0\nalphas = np.array([0.])\nbetas = np.array([0.8])\n# add zero-lag and negate alphas\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\nma1 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \nlimit=12\n_ = tsplot(ma1, lags=limit,title=\"MA(1) process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MA(1) process -- has ACF cut off at lag=1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate MA(2) process with betas 0.6, 0.4\nn = int(1000)\nalphas = np.array([0.])\nbetas = np.array([0.6, 0.4])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nma3 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n)\n_ = tsplot(ma3, lags=12,title=\"MA(2) process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MA(2) process -- has ACF cut off at lag=2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an ARMA(2, 2) model with alphas=[0.5,-0.25] and betas=[0.5,-0.3]\nmax_lag = 12\n\nn = int(5000) # lots of samples to help estimates\nburn = int(n/10) # number of samples to discard before fit\n\nalphas = np.array([0.8, -0.65])\nbetas = np.array([0.5, -0.7])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\narma22 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n, burnin=burn)\n_ = tsplot(arma22, lags=max_lag,title=\"ARMA(2,2) process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use a systematic approach to finding the order of AR and MA processes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# pick best order by aic \n# smallest aic value wins\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(arma22, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We've correctly identified the order of the simulated process as ARMA(2,2).**\nLets use it for the sales time-series.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# pick best order by aic \n# smallest aic value wins\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(new_ts.values, order=(i, j)).fit(method='mle', trend='nc')\n            # mle = most likelihood estimate, nc = no constant\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus we find the order of our data is ()","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Simply use best_mdl.predict() to predict the next values\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = sale_df.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.index = pd.date_range(start = '2013-01-01', end = '2015-10-01', freq='MS')\nts = ts.reset_index()\nts.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prophet:\nRecently open-sourced by Facebook research. It's a very promising tool, that is often a very handy and quick solution to the frustrating flatline","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\n#prophet reqiures a pandas df at the below config \n# ( date column named as DS and the value column as Y)\nts.columns=['ds','y']\nmodel = Prophet( yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel.fit(ts) #fit the model with your dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict for five months in the future and MS - month start is the frequency\nfuture = model.make_future_dataframe(periods = 5, freq = 'MS')  \n# now lets make the forecasts\nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = model.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig2 = model.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_sales = sale_df.groupby([\"date_block_num\"])['item_cnt_day'].sum()\ndates = pd.date_range(start= '2013-01-01', end = '2015-10-01', freq = 'MS')\ntotal_sales.index = dates\ntotal_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the unique combinations of item-store from the sales data at monthly level\nsale_pm_item = sale_df.groupby(['shop_id', 'item_id', 'date_block_num'])['item_cnt_day'].sum()\n\n# arrange it conviniently to perform the hts \nsale_pm_item = sale_pm_item.unstack(level = -1).fillna(0)\nsale_pm_item = sale_pm_item.T\ndates = pd.date_range(start = '2013-01-01', end = '2015-10-01',freq = 'MS')\nsale_pm_item.index = dates\nsale_pm_item = sale_pm_item.reset_index()\nsale_pm_item.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nstart_time = time.time()\n\n# Bottoms up\n# Calculating the base forecasts using prophet\n# From HTSprophet pachage -- https://github.com/CollinRooney12/htsprophet/blob/master/htsprophet/hts.py\n\nforecastsDict = {}\n\nfor node in range(len(sale_pm_item[0])):\n    nodeToForecast = pd.concat([sale_pm_item.iloc[:,0], sale_pm_item.iloc[:,node+1]], axis = 1)\n    # rename for prophet compatability\n    nodeToForecast.columns = [\"ds\", \"y\"]\n    growth = 'linear'\n    model = Prophet(growth, yearly_seasonality = True)\n    model.fit(nodeToForecast)\n    future = model.make_future_dataframe(periods = 1, freq = 'MS')\n    forecastsDict[node] = model.predict(future)\n    if (node== 10):\n        end_time=time.time()\n        print(\"forecasting for \",node,\"th node and took\",end_time-start_time,\"s\")\n        break\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Middle out:**\n* Let's predict for the store level","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sale_pm_shop = sale_df.groupby([\"date_block_num\", \"shop_id\"])[\"item_cnt_day\"].sum()\n# get the shops to the columns\nsale_pm_shop = sale_pm_shop.unstack(level = 1)\nsale_pm_shop = sale_pm_shop.fillna(0)\nsale_pm_shop.index = dates \nsale_pm_shop = sale_pm_shop.reset_index()\nsale_pm_shop.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\n\n# Bottoms up\n# Calculating the base forecasts using prophet\n# From HTSprophet package -- https://github.com/CollinRooney12/htsprophet/blob/master/htsprophet/hts.py\n\nforecastsDict = {}\n\nfor node in range(len(sale_pm_shop[0])):\n    nodeToForecast = pd.concat([sale_pm_shop.iloc[:,0], sale_pm_shop.iloc[:,node+1]], axis = 1)\n    # rename for prophet compatability\n    nodeToForecast.columns = [\"ds\", \"y\"]\n    growth = 'linear'\n    model = Prophet(growth, yearly_seasonality = True)\n    model.fit(nodeToForecast)\n    future = model.make_future_dataframe(periods = 1, freq = 'MS')\n    forecastsDict[node] = model.predict(future)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in range(len(forecastsDict.keys())):\n    \n    f1 = np.array(forecastsDict[key].yhat)\n    f2 = f1[:,np.newaxis]\n    if key == 0:\n        predictions = f2.copy()\n    else:\n        predictions = np.concatenate((predictions, f2), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[-1]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}