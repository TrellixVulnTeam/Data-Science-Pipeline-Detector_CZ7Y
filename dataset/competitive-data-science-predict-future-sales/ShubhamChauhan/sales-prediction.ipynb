{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport pickle\nimport lightgbm as lgb\nfrom itertools import product","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-24T03:22:41.155912Z","iopub.execute_input":"2022-03-24T03:22:41.156239Z","iopub.status.idle":"2022-03-24T03:22:41.163509Z","shell.execute_reply.started":"2022-03-24T03:22:41.156202Z","shell.execute_reply":"2022-03-24T03:22:41.162136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading all the Data","metadata":{}},{"cell_type":"code","source":"# Loading all the data\nitem_df = pd.read_csv(r'/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\nitem_cat_df = pd.read_csv(r'/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nsales_train_df = pd.read_csv(r'/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\nshops_df = pd.read_csv(r'/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\ntest_df = pd.read_csv(r'/kaggle/input/competitive-data-science-predict-future-sales/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:02:37.627486Z","iopub.execute_input":"2022-03-24T03:02:37.627841Z","iopub.status.idle":"2022-03-24T03:02:40.735456Z","shell.execute_reply.started":"2022-03-24T03:02:37.627801Z","shell.execute_reply":"2022-03-24T03:02:40.734073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Health ChekUp","metadata":{}},{"cell_type":"code","source":"# All about Items\nprint(\"Shape of the Items: \", item_df.shape)\ndisplay(item_df.head())\nprint(\"No of Unique Item Id: \", item_df['item_id'].nunique())\nprint(\"Any Null Values?\")\nprint(item_df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:02:45.65778Z","iopub.execute_input":"2022-03-24T03:02:45.658082Z","iopub.status.idle":"2022-03-24T03:02:45.694711Z","shell.execute_reply.started":"2022-03-24T03:02:45.658051Z","shell.execute_reply":"2022-03-24T03:02:45.693669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All about Items Cateory\nprint(\"Shape of the Items: \", item_cat_df.shape)\ndisplay(item_cat_df.head())\nprint(\"No of Unique Item Category: \", item_cat_df['item_category_id'].nunique())\nprint(\"Any Null Values?\")\nprint(item_cat_df.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:02:47.667987Z","iopub.execute_input":"2022-03-24T03:02:47.668275Z","iopub.status.idle":"2022-03-24T03:02:47.684981Z","shell.execute_reply.started":"2022-03-24T03:02:47.668243Z","shell.execute_reply":"2022-03-24T03:02:47.684242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All about Sales Train\nprint(\"Shape of the Items: \", sales_train_df.shape)\nprint(\"\\n\")\ndisplay(sales_train_df.head())\nprint(\"No of Unique date block num: \", sales_train_df['date_block_num'].nunique())\nprint(\"No of Unique shop id: \", sales_train_df['shop_id'].nunique())\nprint(\"No of Unique item id: \", sales_train_df['item_id'].nunique())\nprint(\"Any Null Values?\")\nprint(sales_train_df.isnull().sum())\n\nprint('\\nBasis Stats of Item Price')\ndisplay(sales_train_df['item_price'].describe())\n\nprint('\\nBasic Stats of Item_count_day')\ndisplay(sales_train_df['item_cnt_day'].describe())\n\nprint(\"\\nThere are few negative values too in the sale and count \\\ndoes they represent any return? How many such values are there?\")\n\ndisplay(sales_train_df[sales_train_df['item_price']<0])\ndisplay(sales_train_df[sales_train_df['item_cnt_day']<0])\n\nprint(\"\\nStats of negative item count day\")\ndisplay(sales_train_df.loc[sales_train_df['item_cnt_day']<0, 'item_cnt_day'].describe())","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:02:48.978267Z","iopub.execute_input":"2022-03-24T03:02:48.978606Z","iopub.status.idle":"2022-03-24T03:02:49.649778Z","shell.execute_reply.started":"2022-03-24T03:02:48.978571Z","shell.execute_reply":"2022-03-24T03:02:49.648669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling the negative value with median value\nmedian = sales_train_df.loc[(sales_train_df['shop_id']==32) &\n                       (sales_train_df['item_id']==2973),\n                       'item_price'\n                      ].median()\n\nprint(\"Median Values: \", median)\n\nsales_train_df.loc[(sales_train_df['shop_id']==32) &\n                   (sales_train_df['item_price']==-1),\n                   'item_price'\n                  ] = median","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:02:50.447265Z","iopub.execute_input":"2022-03-24T03:02:50.447573Z","iopub.status.idle":"2022-03-24T03:02:50.499205Z","shell.execute_reply.started":"2022-03-24T03:02:50.447528Z","shell.execute_reply":"2022-03-24T03:02:50.498024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore more about negative vanlues\nprint(\"Is there any problem with only one shop?\")\nprint(sales_train_df.loc[sales_train_df['item_cnt_day']<0, 'shop_id'].nunique())\n\nprint(\"\\nIs there only item having negative count?\")\nprint(sales_train_df.loc[sales_train_df['item_cnt_day']<0, 'item_id'].nunique())\n\n# print(\"\\nWe will assume that there is data entry issue...and convert all the negative values \\\n# into positive\")\nprint(\"\\n Are negative values coming every month?\")\nprint(sales_train_df.loc[sales_train_df['item_cnt_day']<0, 'date_block_num'].unique())\nprint(\"\\nEvery month negative values are found. Are they return items?\")","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:02:52.117969Z","iopub.execute_input":"2022-03-24T03:02:52.118911Z","iopub.status.idle":"2022-03-24T03:02:52.14529Z","shell.execute_reply.started":"2022-03-24T03:02:52.118854Z","shell.execute_reply":"2022-03-24T03:02:52.144289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Several shops are duplicates of each other (according to its name). Fix train and test set.\n# code taken from 'feature-engineering-xgboost' notebook\n\n# Якутск Орджоникидзе, 56\nsales_train_df.loc[sales_train_df.shop_id == 0, 'shop_id'] = 57\ntest_df.loc[test_df.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\nsales_train_df.loc[sales_train_df.shop_id == 1, 'shop_id'] = 58\ntest_df.loc[test_df.shop_id == 1, 'shop_id'] = 58\n# Жуковский ул. Чкалова 39м²\nsales_train_df.loc[sales_train_df.shop_id == 10, 'shop_id'] = 11\ntest_df.loc[test_df.shop_id == 10, 'shop_id'] = 11","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:02:53.158168Z","iopub.execute_input":"2022-03-24T03:02:53.15848Z","iopub.status.idle":"2022-03-24T03:02:53.252258Z","shell.execute_reply.started":"2022-03-24T03:02:53.158445Z","shell.execute_reply":"2022-03-24T03:02:53.251082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Shops/Cats/Items preprocessing\nObservations:\n* Each shop_name starts with the city name.\n* Each category contains type and subtype in its name.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nshops_df.loc[shops_df.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\nshops_df['city'] = shops_df['shop_name'].str.split(' ').map(lambda x: x[0])\nshops_df.loc[shops_df.city == '!Якутск', 'city'] = 'Якутск'\nshops_df['city_code'] = LabelEncoder().fit_transform(shops_df['city'])\nshops_df = shops_df[['shop_id','city_code']]\n\nitem_cat_df['split'] = item_cat_df['item_category_name'].str.split('-')\nitem_cat_df['type'] = item_cat_df['split'].map(lambda x: x[0].strip())\nitem_cat_df['type_code'] = LabelEncoder().fit_transform(item_cat_df['type'])\n# if subtype is nan then type\nitem_cat_df['subtype'] = item_cat_df['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\nitem_cat_df['subtype_code'] = LabelEncoder().fit_transform(item_cat_df['subtype'])\nitem_cat_df = item_cat_df[['item_category_id','type_code', 'subtype_code']]\n\nitem_df.drop(['item_name'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:02:54.887783Z","iopub.execute_input":"2022-03-24T03:02:54.888252Z","iopub.status.idle":"2022-03-24T03:02:54.918395Z","shell.execute_reply.started":"2022-03-24T03:02:54.888194Z","shell.execute_reply":"2022-03-24T03:02:54.917623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_shops_item = sales_train_df['shop_id'].astype(str) +\"_\"+sales_train_df['item_id'].astype(str)\ntrain_shops_item = train_shops_item.drop_duplicates().reset_index(drop=True)\ntrain_shops_item = sales_train_df['item_id']\n\ntest_shops_item = test_df['shop_id'].astype(str) +\"_\"+test_df['item_id'].astype(str)\ntest_shops_item = test_shops_item.drop_duplicates().reset_index(drop=True)\ntest_shops_item = test_df['item_id']\n\n# No Of Shops And Items not in Train \nprint(\"Total Numbers of Items Not In Train\")\nlen(set(test_shops_item).difference((train_shops_item)))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:02:55.69492Z","iopub.execute_input":"2022-03-24T03:02:55.695891Z","iopub.status.idle":"2022-03-24T03:03:04.919563Z","shell.execute_reply.started":"2022-03-24T03:02:55.695836Z","shell.execute_reply":"2022-03-24T03:03:04.91826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outliers","metadata":{}},{"cell_type":"code","source":"# Check for any anomaly in Item Count\nplt.figure(figsize=(10,4), dpi=80)\nplt.title(\"Item Count\")\nsns.boxplot(x=sales_train_df['item_cnt_day'])\nplt.show()\n\nplt.figure(figsize=(10,4), dpi=80)\nplt.title(\"Looking At Outlier\")\nplt.xlim((2000, 2500))\nsns.boxplot(x=sales_train_df['item_cnt_day'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:03:04.92189Z","iopub.execute_input":"2022-03-24T03:03:04.922179Z","iopub.status.idle":"2022-03-24T03:03:06.072428Z","shell.execute_reply.started":"2022-03-24T03:03:04.922149Z","shell.execute_reply":"2022-03-24T03:03:06.071618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for any anomaly in Item Price\nplt.figure(figsize=(10,4), dpi=80)\nplt.title(\"Item Price\")\nsns.boxplot(x=sales_train_df['item_price'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:03:06.073652Z","iopub.execute_input":"2022-03-24T03:03:06.07389Z","iopub.status.idle":"2022-03-24T03:03:06.995429Z","shell.execute_reply.started":"2022-03-24T03:03:06.073861Z","shell.execute_reply":"2022-03-24T03:03:06.994316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outliers Removal","metadata":{}},{"cell_type":"code","source":"# Removing the anomaly from the data as it can skew out results\ndef remove_outliers(df):\n    \n    df = df[df['item_price'] <= 100000]\n    df = df[df['item_cnt_day'] <= 1500]\n    \n    return df\n\nsales_train_df = remove_outliers(sales_train_df)\n\nprint(\"Check After Outliers Removal\")\n# Check after removing outliers\nplt.figure(figsize=(10,4), dpi=80)\nplt.title(\"Item Count\")\nsns.boxplot(x=sales_train_df['item_cnt_day'])\nplt.show()\n\n# Check for any anomaly in Item Price\nplt.figure(figsize=(10,4), dpi=80)\nplt.title(\"Item Price\")\nsns.boxplot(x=sales_train_df['item_price'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:03:06.997365Z","iopub.execute_input":"2022-03-24T03:03:06.997836Z","iopub.status.idle":"2022-03-24T03:03:08.866633Z","shell.execute_reply.started":"2022-03-24T03:03:06.997798Z","shell.execute_reply":"2022-03-24T03:03:08.865446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Transformation","metadata":{}},{"cell_type":"code","source":"# To make train and test data similar in respect of items and shops\n# We are concating the train and test\n\n# Making datetime pattern\nsales_train_df['date'] = pd.to_datetime(sales_train_df['date'], format=\"%d.%m.%Y\")\n\ntmp = test_df.copy()\ntmp['date_block_num'] = 34\ntmp.drop('ID', axis=1, inplace=True)\n\ntmp = pd.concat([tmp, sales_train_df[['shop_id', 'item_id', 'date_block_num']]],\n                axis=0,\n                ignore_index=True\n               )\n\nmatrix = []\ncols = ['date_block_num','shop_id','item_id']\n\nfor i in range(35):\n    sales = tmp[tmp['date_block_num']==i]\n    \n    matrix.append(np.array(list(product([i],\n                                        sales.shop_id.unique(), \n                                        sales.item_id.unique())),\n                          dtype='int16'))\n    \nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\nprint(matrix.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:24:20.774952Z","iopub.execute_input":"2022-03-24T03:24:20.775293Z","iopub.status.idle":"2022-03-24T03:24:40.509659Z","shell.execute_reply.started":"2022-03-24T03:24:20.77526Z","shell.execute_reply":"2022-03-24T03:24:40.508863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merging the data with the train data\n# Aggregating the train sales data\ntrain_df = sales_train_df.groupby(cols).agg({\n                                             'item_cnt_day':['sum','mean', 'median']\n                                            }).clip(0,20)\ntrain_df.columns = ['item_cnt_month', 'avg_item_cnt_month', 'median_item_cnt_month']\n\ntrain_df.reset_index(inplace=True)\n\ngroup = sales_train_df.groupby(cols).agg({'item_price':'mean'})\n\ntrain_df = pd.merge(train_df, group, on=cols, how='left')\n\n# merging now\ntrain_df = pd.merge(matrix, train_df, on=cols, how='left')\ntrain_df.rename(columns={'item_price': 'avg_item_price'}, inplace=True)\nprint(\"Shape of the train data: \", train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:27:02.575818Z","iopub.execute_input":"2022-03-24T03:27:02.576172Z","iopub.status.idle":"2022-03-24T03:27:09.770996Z","shell.execute_reply.started":"2022-03-24T03:27:02.576136Z","shell.execute_reply":"2022-03-24T03:27:09.770013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculating Avg item price and merging with the train data","metadata":{}},{"cell_type":"code","source":"item_avg_price_df = sales_train_df.groupby(['item_id'])['item_price'].mean().reset_index()\n\n# Merging witht the train\ntrain_df = pd.merge(train_df, item_avg_price_df, how='left', on='item_id')\n\n# Where avg_price is null\ntrain_df['avg_item_price'] = np.where(train_df['avg_item_price'].isnull(),\n                                      train_df['item_price'],\n                                      train_df['avg_item_price']\n                                     )\n\ntrain_df.drop('item_price', axis=1, inplace=True)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:30:19.772985Z","iopub.execute_input":"2022-03-24T03:30:19.773867Z","iopub.status.idle":"2022-03-24T03:30:22.298418Z","shell.execute_reply.started":"2022-03-24T03:30:19.773816Z","shell.execute_reply":"2022-03-24T03:30:22.297157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merging with the other data sets","metadata":{}},{"cell_type":"code","source":"train_df = pd.merge(train_df, item_df, how='left', on='item_id')\ntrain_df = pd.merge(train_df, item_cat_df, how='left', on='item_category_id')\ntrain_df = pd.merge(train_df, shops_df, how='left', on='shop_id')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:31:39.519361Z","iopub.execute_input":"2022-03-24T03:31:39.51977Z","iopub.status.idle":"2022-03-24T03:31:42.652375Z","shell.execute_reply.started":"2022-03-24T03:31:39.519735Z","shell.execute_reply":"2022-03-24T03:31:42.651393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating lag features","metadata":{}},{"cell_type":"code","source":"cols = ['shop_id', \n        'item_id', \n        'date_block_num',\n        'item_cnt_month'\n       ]\n\ncols_to_merge = ['shop_id', \n        'item_id', \n        'date_block_num'\n       ]\n\nlags = [1,3,6,12,18]\n\nfor i in lags:\n    print(i)\n    shifted_df = train_df[cols].copy()\n    shifted_df['date_block_num'] =  shifted_df['date_block_num']+i\n    shifted_df[f\"item_cnt_month_lag_{i}\"] = shifted_df['item_cnt_month']\n    shifted_df.drop('item_cnt_month', axis=1, inplace=True)\n    train_df = pd.merge(train_df, shifted_df, \n                        on=cols_to_merge, \n                        how='left'\n                       )\n    \n# Fill all mising values to 0\ntrain_df = train_df.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:40:32.111147Z","iopub.execute_input":"2022-03-24T03:40:32.111491Z","iopub.status.idle":"2022-03-24T03:41:20.707205Z","shell.execute_reply.started":"2022-03-24T03:40:32.111457Z","shell.execute_reply":"2022-03-24T03:41:20.706222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.fillna(0)\ntrain_df[(train_df['shop_id']==45) & (train_df['item_id']==969)]","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:43:07.358825Z","iopub.execute_input":"2022-03-24T03:43:07.35915Z","iopub.status.idle":"2022-03-24T03:43:08.185168Z","shell.execute_reply.started":"2022-03-24T03:43:07.359117Z","shell.execute_reply":"2022-03-24T03:43:08.184087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['shop_id'].nunique(), train_df['item_id'].nunique(), train_df['item_category_id'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:46:14.092945Z","iopub.execute_input":"2022-03-24T03:46:14.09324Z","iopub.status.idle":"2022-03-24T03:46:14.318861Z","shell.execute_reply.started":"2022-03-24T03:46:14.093209Z","shell.execute_reply":"2022-03-24T03:46:14.318126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Preparation","metadata":{}},{"cell_type":"code","source":"# Splitting the datainto training and testing\ntest = train_df[train_df['date_block_num'] == 34]\ntest.drop('item_cnt_month', axis=1, inplace=True)\n\nvalid_dataset = train_df[train_df['date_block_num'] == 33].copy()\nvalid_target = valid_dataset['item_cnt_month']\nvalid_dataset.drop('item_cnt_month', axis=1, inplace=True)\n\ntrain_dataset =  train_df[train_df['date_block_num'] < 33].copy()\ntrain_target = train_dataset['item_cnt_month']\ntrain_dataset.drop('item_cnt_month', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:47:23.110656Z","iopub.execute_input":"2022-03-24T03:47:23.110955Z","iopub.status.idle":"2022-03-24T03:47:24.776519Z","shell.execute_reply.started":"2022-03-24T03:47:23.110928Z","shell.execute_reply":"2022-03-24T03:47:24.775508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape, valid_dataset.shape, valid_target.shape, train_dataset.shape, train_target.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:47:28.675358Z","iopub.execute_input":"2022-03-24T03:47:28.675658Z","iopub.status.idle":"2022-03-24T03:47:28.682688Z","shell.execute_reply.started":"2022-03-24T03:47:28.675628Z","shell.execute_reply":"2022-03-24T03:47:28.681757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_params = {'metric': {'rmse'},\n              'num_leaves': 12,\n              'learning_rate': 0.02,\n              'feature_fraction': 0.8,\n              'max_depth': 5,\n              'verbose': 0,\n              'num_boost_round': 1000,\n              'early_stopping_rounds': 100,\n              'nthread': -1}\n\nlgbtrain = lgb.Dataset(data=train_dataset, label=train_target)\nlgbval = lgb.Dataset(data=valid_dataset, label=valid_target, reference=lgbtrain)\n\nmodel = lgb.train(lgb_params, lgbtrain,\n                  valid_sets=[lgbtrain, lgbval],\n                  num_boost_round=lgb_params['num_boost_round'],\n                  early_stopping_rounds=lgb_params['early_stopping_rounds'],\n                  verbose_eval=100)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T03:55:03.431447Z","iopub.execute_input":"2022-03-24T03:55:03.432025Z","iopub.status.idle":"2022-03-24T03:59:13.447222Z","shell.execute_reply.started":"2022-03-24T03:55:03.431978Z","shell.execute_reply":"2022-03-24T03:59:13.446434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rf = RandomForestRegressor(n_estimators=500, max_depth=8)\n# rf.fit(train_dataset, train_target)\n\n# # Saving the model\n# with open('model_pkl', 'wb') as files:\n#     pickle.dump(rf, files)\n    \n# # #Loading Model\n# # with open('model_pkl' , 'rb') as f:\n# #     rf = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:16:49.707873Z","iopub.execute_input":"2022-03-09T12:16:49.708175Z","iopub.status.idle":"2022-03-09T12:16:49.837771Z","shell.execute_reply.started":"2022-03-09T12:16:49.708142Z","shell.execute_reply":"2022-03-09T12:16:49.836187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\npred = model.predict(valid_dataset)\nrmse_score = np.sqrt(mean_squared_error(valid_target, pred))\nprint(\"Rmse Score: \", rmse_score)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T04:00:08.385801Z","iopub.execute_input":"2022-03-24T04:00:08.386097Z","iopub.status.idle":"2022-03-24T04:00:11.762688Z","shell.execute_reply.started":"2022-03-24T04:00:08.386067Z","shell.execute_reply":"2022-03-24T04:00:11.761909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_test = pd.DataFrame(model.predict(test), columns=[\"item_cnt_month\"])\npred_test = pd.concat([test_df, pred_test], axis=1)\npred_test = pred_test[['ID', 'item_cnt_month']]\npred_test.to_csv(\"submission_v0_3.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T04:00:23.776642Z","iopub.execute_input":"2022-03-24T04:00:23.777484Z","iopub.status.idle":"2022-03-24T04:00:27.707945Z","shell.execute_reply.started":"2022-03-24T04:00:23.777421Z","shell.execute_reply":"2022-03-24T04:00:27.706938Z"},"trusted":true},"execution_count":null,"outputs":[]}]}