{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read data","metadata":{}},{"cell_type":"code","source":"df_train_sales = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\", parse_dates=['date'])\ndf_item_cat = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")\ndf_items = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\ndf_shops = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")\ndf_test = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")\n\ndf_submission = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_sales.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_sales.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating extra features based on date\ndf_train_sales['year'] = df_train_sales['date'].dt.year\ndf_train_sales['month'] = df_train_sales['date'].dt.month","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merging tables to form a complete dataset","metadata":{}},{"cell_type":"code","source":"df_train_sales_temp = pd.merge(df_train_sales, df_items, on='item_id', how='left')\ndf_train_sales_temp2 = pd.merge(df_train_sales_temp, df_item_cat, on='item_category_id', how='left')\ndf_train_sales_temp3 = pd.merge(df_train_sales_temp2, df_shops, on='shop_id', how='left')\n\ndf_train_sales_temp3.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" No need to train model for shop and items missing in test data?","metadata":{}},{"cell_type":"code","source":"df_train_sales_eda = df_train_sales_temp3.loc[(df_train_sales_temp3['shop_id'].isin(df_test['shop_id'])) &\n                                              (df_train_sales_temp3['item_id'].isin(df_test['item_id']))].copy()\n\ndel df_train_sales_temp, df_train_sales_temp2, df_train_sales_temp3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Overall stats","metadata":{}},{"cell_type":"code","source":"df_train_sales_eda.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Checking diversity of categorical feature item_name and shop_name","metadata":{}},{"cell_type":"code","source":"print(\"No. of unique items sold:\", df_train_sales_eda['item_name'].nunique())\n\nx = df_train_sales_eda['item_name'].value_counts()\nnp.log10(x).hist(bins=25)\nplt.xlabel('count of unique item name');\n\nprint(f\"Item name that repeats more than 5 times: {100*x[x>10].shape[0]/x.shape[0]:1.0f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"only_use_item_names = x[x>10].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Most sold item\nx.nlargest(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No. of unique item category:\", df_train_sales_eda['item_category_name'].nunique())\n\ndf_train_sales_eda['item_category_name'] = df_train_sales_eda['item_category_name'].str.split().str[0]\nx = df_train_sales_eda['item_category_name'].value_counts()\nnp.log10(x).hist(bins=25)\nplt.xlabel('count of unique item name');\n\nprint(f\"Item name that repeats more than 500 times: {100*x[x>5].shape[0]/x.shape[0]:1.0f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"only_use_item_cat_name = x[x>5].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No. of unique shop names:\", df_train_sales_eda['shop_name'].nunique())\nx = df_train_sales_eda['shop_name'].value_counts()\nx.hist(bins=25)\nplt.xlabel('count of unique shop name');\n\nprint(f\"Shop name that repeats more than 300 time: {100*x[x>500].shape[0]/x.shape[0]:1.0f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"only_use_shop_names = x[x>300].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Most item selling shop\nx.nlargest(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Purchase trend by year","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(5,4))\nsns.violinplot(x = df_train_sales_eda[\"year\"]\n               , y = np.log10(df_train_sales_eda['item_price']+0.1)\n               , showfliers=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Purchase trend by year\nfig, ax = plt.subplots(figsize=(5,4))\nsns.boxplot(x = df_train_sales_eda[\"year\"]\n               , y = df_train_sales_eda['item_price']\n               , showfliers=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### What is most selling item/shop by year ? ","metadata":{}},{"cell_type":"code","source":"for year in [2013, 2014, 2015]:\n    x = df_train_sales_eda.loc[df_train_sales_eda['year']==year, 'item_name'].value_counts().nlargest(5)\n    print(f\"Year: {year}\\n\", x, '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for year in [2013, 2014, 2015]:\n    x = df_train_sales_eda.loc[df_train_sales_eda['year']==year, 'shop_name'].value_counts().nlargest(5)\n    print(f\"Year: {year}\\n\", x, '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nsns.countplot(x='shop_name', hue='year'\n              ,data = df_train_sales_eda, ax=ax)\nplt.xticks(rotation=90);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 25 popular shop, by years.\n\nfig, ax = plt.subplots(figsize=(15,5))\nsns.countplot(x='shop_name', hue='year'\n              ,data = df_train_sales_eda.loc[df_train_sales_eda['shop_name'].\\\n                                             isin(df_train_sales_eda['shop_name'].\\\n                                                  value_counts().nlargest(25).index)], ax=ax)\nplt.xticks(rotation=90);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All shop seems to have increasing sales trend with increasing years.","metadata":{}},{"cell_type":"code","source":"# Top 25 popular item, by years.\n\nfig, ax = plt.subplots(figsize=(18,5))\nsns.countplot(x='item_name', hue='year'\n              ,data = df_train_sales_eda.loc[df_train_sales_eda['item_name'].\\\n                                             isin(df_train_sales_eda['item_name'].\\\n                                                  value_counts().nlargest(50).index)], ax=ax)\nplt.xticks(rotation=90);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Item count","metadata":{}},{"cell_type":"code","source":"df_train_sales_eda.\\\n    groupby(['shop_name', 'item_name']).\\\n    agg({'item_cnt_day': 'sum'}).\\\n    sort_values('item_cnt_day', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data cleaning","metadata":{}},{"cell_type":"code","source":"# Remove -ve or extremely high sales\nnp.log10(df_train_sales_eda['item_price']).hist(bins=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing outliers in item_price [10, 10000]\ndf_train_sales_eda = df_train_sales_eda.loc[(df_train_sales_eda['item_price'] > 10) & (df_train_sales_eda['item_price'] < 1e4)].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove non +ve item counts\ndf_train_sales_eda = df_train_sales_eda.loc[(df_train_sales_eda['item_cnt_day']>=1) & (df_train_sales_eda['item_cnt_day']<=10)].copy()\n\nnp.log10(df_train_sales_eda['item_cnt_day']).hist(bins=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shop name\ndf_train_sales_eda['shop_name'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_sales_eda.loc[~df_train_sales_eda['shop_name'].isin(only_use_shop_names), 'shop_name'] = 'Unknown'\ndf_train_sales_eda.loc[~df_train_sales_eda['item_name'].isin(only_use_item_names), 'item_name'] = 'Unknown'\ndf_train_sales_eda.loc[~df_train_sales_eda['item_category_name'].isin(only_use_item_cat_name), 'item_category_name'] = 'Unknown'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparation for model fitting","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Label encoding\nlabel_encoder = LabelEncoder()\ndf_train_sales_eda['shop_name'] = label_encoder.fit_transform(df_train_sales_eda['shop_name'])\n\nlabel_encoder = LabelEncoder()\ndf_train_sales_eda['item_category_name'] = label_encoder.fit_transform(df_train_sales_eda['item_category_name'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create tuple of shop id and item id per date_block_num\n\nmeta_features = ['date_block_num', 'shop_id', 'item_id']\n\ntrain_agg_set = df_train_sales_eda.groupby(meta_features, as_index=False).size()\n\ntrain_agg_set = train_agg_set[meta_features].copy()\n\ntrain_agg_set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Generating group features","metadata":{}},{"cell_type":"code","source":"df_train_sales_eda.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"group1 = df_train_sales_eda.groupby(meta_features, as_index=False).agg({'item_price': 'mean'\n                                                                       ,'item_cnt_day': 'sum'})\n\ntrain_agg_set = pd.merge(train_agg_set, group1, on=meta_features, how='left')\n\ntrain_agg_set = train_agg_set.rename(columns={'item_cnt_day': 'item_cnt_month', 'item_price': 'item_price_mean'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_agg_set.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train/Test","metadata":{}},{"cell_type":"code","source":"train_agg_set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From here heavily influenced by https://www.kaggle.com/werooring/top-3-5-lightgbm-with-feature-engineering\n# Merging train/test into one\n\ndf_test['date_block_num'] = 34\n\ndf_combo = pd.concat([train_agg_set, df_test.drop('ID', axis=1)], ignore_index=True, keys=meta_features)\ndf_combo = df_combo.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train data (Features)\nX_train = df_combo[df_combo['date_block_num'] < 33]\nX_train = X_train.drop(['item_cnt_month'], axis=1)\n\n# Valid data (Features)\nX_valid = df_combo[df_combo['date_block_num'] == 33]\nX_valid = X_valid.drop(['item_cnt_month'], axis=1)\n\n# Test data (Features)\nX_test = df_combo[df_combo['date_block_num'] == 34]\nX_test = X_test.drop(['item_cnt_month'], axis=1)\n\n# Train data (Target values)\ny_train = df_combo[df_combo['date_block_num'] < 33]['item_cnt_month']\n# Valid data (Target values)\ny_valid = df_combo[df_combo['date_block_num'] == 33]['item_cnt_month']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# lgb hyper-parameters\nparams = {'metric': 'rmse',\n          'num_leaves': 200,\n          'learning_rate': 0.003, 'feature_fraction': 0.75,\n          'bagging_fraction': 0.75,\n          'bagging_freq': 5, 'force_col_wise' : True,\n          'random_state': 42}\n\n#cat_features = ['shop_id', 'city', 'item_category_id', 'category', 'month']\n\n# lgb train and valid dataset\ndtrain = lgb.Dataset(X_train, y_train)\ndvalid = lgb.Dataset(X_valid, y_valid)\n \n# Train LightGBM model\nlgb_model = lgb.train(params=params,\n                      train_set=dtrain,\n                      num_boost_round=2500,\n                      valid_sets=(dtrain, dvalid),\n                      early_stopping_rounds=250,\n                      #categorical_feature=cat_features,\n                      verbose_eval=250)      ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = lgb_model.predict(X_test).clip(0,20)\n\ndf_submission['item_cnt_month'] = preds\ndf_submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}