{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"M = pd.read_pickle('/kaggle/input/sales-data-prep/matrix.pkl')\nM.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport gc\nimport pickle\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\n# Retrieve dataset\n\nM = pd.read_pickle('/kaggle/input/sales-data-prep/matrix.pkl')\nM.drop([\"new_item_cat_enc_lag_1\", \"new_item_cat_enc_lag_2\", \"new_item_cat_enc_lag_3\"], axis=1, inplace=True)\nM = M[M[\"date_block_num\"] > 2]\nM.fillna(0)\n#M = pd.read_pickle('/kaggle/input/sales-lag3/matrix.pkl')\n\n#M.drop([\"new_item_cat_enc_lag_1\", \"new_item_cat_enc_lag_2\", \"new_item_cat_enc_lag_3\",\n#        \"item_target_shop_enc_lag_1\", \"item_target_shop_enc_lag_2\", \"item_target_shop_enc_lag_3\"], axis=1, inplace=True)\n\nfor col in M.columns:\n    print(col,M[col].nunique())\n\n# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n# Modified to support timestamp type, categorical type\n# Modified to add option to use float16 or not. feather format does not support float16.\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            # skip datetime type or categorical type\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n# reduce matrix memory usage\n\n#M = reduce_mem_usage(M, use_float16=True)\n\n# Separate Train, Test and Validation\n\nX_train = M[M.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_train = M[M.date_block_num < 33]['item_cnt_month']\n\nX_test = M[M.date_block_num == 34].drop(['item_cnt_month'], axis=1)\n\nX_val = M[M.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_val = M[M.date_block_num == 33]['item_cnt_month']\n\n#Y_train = Y_train.clip(0, 20)\n#Y_val = Y_val.clip(0, 20)\n\ndel M\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit model\n\nmodel = XGBRegressor(\n    max_depth=10,\n    booster='gbtree',\n    n_estimators=1000,\n    min_child_weight=0.5, \n    subsample=0.8,\n    sampling_method=\"uniform\",\n    colsample_bynode=1,\n    colsample_bytree=0.8, \n    eta=0.1,\n    #base_score=0.05,\n    #gamma=0.001,\n    tree_method='gpu_hist',\n    seed=42)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_val, Y_val)], \n    verbose=True, \n    early_stopping_rounds = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save model\n\npickle.dump(model, open(\"model.pkl\", \"wb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Retrieve model\n\nloaded_model = pickle.load(open(\"model.pkl\", \"rb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot feature importance\n\nfig, ax = plt.subplots(1,1,figsize=(15,20))\nplot_importance(booster=loaded_model, ax=ax);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\n\nY_test = loaded_model.predict(X_test).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data for postprocessing\n\nitems=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\nitem_categories=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(items, item_categories)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}