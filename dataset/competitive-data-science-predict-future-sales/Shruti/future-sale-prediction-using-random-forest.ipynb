{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas import Series, DataFrame\n#data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\nimport sklearn\nfrom sklearn import *\nimport nltk,datetime\nfrom sklearn import ensemble, metrics, preprocessing","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"itemcat=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")\nitems=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\ntrain=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\nshops=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")\ntest=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")\nresult=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"itemcat.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33***","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.date_block_num.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train\",train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"row,column\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"test\",test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['date']= pd.to_datetime(train['date'], format='%d.%m.%Y')\ntrain['month']=train['date'].dt.month\ntrain['year']=train['date'].dt.year\ntrain=train.drop(['date','item_price'],axis=1)\ntrain=train.groupby([c for c in  train.columns if c not in ['item_cnt_day']], as_index=False)[['item_cnt_day']].sum()\ntrain=train.rename(columns={'item_cnt_day':'item_cnt_month'})\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"find the monthly mean","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shop_item_mean= train[['shop_id','item_id','item_cnt_month']].groupby(['shop_id','item_id'],as_index=False)[['item_cnt_month']].mean()\nshop_item_mean = shop_item_mean.rename(columns = {'item_cnt_month':'item_cnt_month_mean'})\n\n#just add our mean feature to our train set\n\ntrain = pd.merge(train, shop_item_mean, how='left',on=['shop_id', 'item_id'])\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add last month\nshop_prev_month= train[train['date_block_num']==33][['shop_id','item_id','item_cnt_month']]\nshop_prev_month = shop_prev_month.rename(columns={'item_cnt_month':'item_cnt_prev_month'})\nshop_prev_month.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add previous month feature to train dataset\ntrain = pd.merge(train, shop_prev_month, how= 'left', on =['shop_id','item_id']).fillna(0.)\n\n#add all item features\ntrain =  pd.merge(train, items, how= 'left', on='item_id')\n\n#adding item category features\ntrain = pd.merge(train,itemcat,how='left',on='item_category_id')\n\n#adding shop faetures\ntrain= pd.merge(train,shops,how='left', on='shop_id')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test dataset\n\n#adding november 2015\n\ntest['month']=11\ntest['year']=2015\ntest['date_block_num']=34\n\n#add mean feature\ntest = pd.merge(test,shop_item_mean,how='left',on=['shop_id','item_id']).fillna(0.)\n\n#add previous month feature\ntest = pd.merge(test, shop_prev_month,how='left',on=['shop_id','item_id']).fillna(0.)\n\n#add all the features\ntest= pd.merge(test,items,how='left',on=['item_id'])\n\n#adding item category features\ntest=pd.merge(test,itemcat,how='left',on=['item_category_id'])\n\n#adding shop features \ntest =pd.merge(test,shops,how='left',on='shop_id')\ntest['item_cnt_month']=0\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label encoding\nfor c in ['shop_name','item_name','item_category_name']:\n    lbl= preprocessing.LabelEncoder()\n    lbl.fit(list(train[c].unique())+list(test[c].unique()))\n    train[c]=lbl.transform(train[c].astype(str))\n    test[c]=lbl.transform(test[c].astype(str))\n    print(c)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets train and predict using Random Forest algoritm\n\ncol = [c for c in train.columns if c not in ['item_cnt_month']]\nx1=train[train['date_block_num']<33]\ny1=np.log1p(x1['item_cnt_month'].clip(0.,20.)) #cliping values\nx1=x1[col]\nx2=train[train['date_block_num']==33]\ny2=np.log1p(x2['item_cnt_month'].clip(0.,20.))\nx2=x2[col]\n\n\nreg=ensemble.ExtraTreesRegressor(n_estimators=30,n_jobs=-1,max_depth=20, random_state=18)\n#no of trees are going to be in random forest=n_estimators\nreg.fit(x1,y1)\nprint('RMSE value is:',np.sqrt(metrics.mean_squared_error(y2.clip(0.,20.),reg.predict(x2).clip(0.,20.))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.fit(train[col],train['item_cnt_month'].clip(0.,20.))\ntest['item_cnt_month']=reg.predict(test[col]).clip(0.,20.)\ntest[['ID','item_cnt_month']].to_csv('result.csv',index=False)\n\n\ntest['item_cnt_month']=np.expm1(test['item_cnt_month'])\ntest[['ID','item_cnt_month']].to_csv('final_submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}