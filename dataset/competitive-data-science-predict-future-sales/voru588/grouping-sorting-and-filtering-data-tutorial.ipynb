{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Pandas groupby](https://us.toluna.com/dpolls_images/2018/08/25/620535cf-e152-4bad-a02c-8372063b9fe1.jpg)"},{"metadata":{},"cell_type":"markdown","source":"Hello, everyone,\n\nI just finished working with the **Groupby function by itself and along with .apply(), .filter(), .aggregate(), .transform()** and so on, and thought it might be usefull to some folks too.\n\nPlease, let me know what you think and how it can be made better. Any comments and suggestions are welcome!\n\nDo not forget to **UPVOTE** my Notebook if you found it useful! \n\nThank you, everyone)))"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv', index_col = 'date', parse_dates = True )\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Love this summary:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def summary(df):\n    \n    types = df.dtypes\n    counts = df.apply(lambda x: x.count())\n    uniques = df.apply(lambda x: [x.unique()])\n    nas = df.apply(lambda x: x.isnull().sum())\n    distincts = df.apply(lambda x: x.unique().shape[0])\n    missing = (df.isnull().sum() / df.shape[0]) * 100\n    sk = df.skew()\n    krt = df.kurt()\n    \n    print('Data shape:', df.shape)\n\n    cols = ['Type', 'Total count', 'Null Values', 'Distinct Values', 'Missing Ratio', 'Unique Values', 'Skewness', 'Kurtosis']\n    dtls = pd.concat([types, counts, nas, distincts, missing, uniques, sk, krt], axis=1, sort=False)\n  \n    dtls.columns = cols\n    return dtls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"details = summary(df)\ndetails","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting up an Index"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.index.names = ['Date']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping non-useful column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['date_block_num'], axis = 1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns={'shop_id':'Store ID', 'item_id':'Item ID', 'item_price':'Price', 'item_cnt_day':'Volume'}, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating new column Daily Revenue"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Daily Revenue'] = df['Price']*df['Volume']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Groupby Method:"},{"metadata":{},"cell_type":"markdown","source":"Looking at the average price for each store:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['Store ID','Price']].groupby('Store ID').mean().head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Note: By specifying the column ['Daily Revenue'] before the aggregate function .sum(), you will significantly improve your speed."},{"metadata":{},"cell_type":"markdown","source":"### Note 2: To return a dataframe provide the column name as a list to the comumn selection by using double brackets like that: [['Volume']]"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Store ID')[['Volume']].sum().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This way, it can take a list of column names and perform an aggregation on all of the comumns based on Store ID and Store's Volume by using (['Name 1', 'Name 2'])"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ml = df.groupby(['Store ID', 'Volume']).sum()\ndf_ml.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Note 3: .xs can be used to select subsets of DF while working with MultiIndex tables like this:"},{"metadata":{},"cell_type":"markdown","source":"Tip: For a String use '39'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ml.xs(39, level = 'Store ID').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### groupby() while working with the Time Series."},{"metadata":{},"cell_type":"markdown","source":"Daily Revenue summed up into Monthly Reevenue for every store using .sum() method:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_monthly = df.reset_index().groupby(['Store ID', pd.Grouper(key='Date', freq = 'M')])[['Daily Revenue']].sum().rename(columns = {'Daily Revenue':'Monthly Revenue'})\ndf_monthly.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### .size() method counts rows in each group"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index().groupby(pd.Grouper(key='Date', freq='Q')).size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Note 4: using reset_index() method resets the index into columns"},{"metadata":{},"cell_type":"markdown","source":"Tip: by passing drop = True to the reset_insex(), your dff drops the columns that make up the MultiIndex and creates a new index with integer values."},{"metadata":{},"cell_type":"markdown","source":"### Total Daily Revenue:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Daily Revenue'].reset_index().groupby('Date', as_index = False).sum().rename(columns = {'Daily Revenue':'Total Daily Revenue'}).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another way to look at the data with groupby(). I sort it by Store ID here."},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = df.reset_index().groupby('Store ID')\ngrouped.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's supposed to be a DataFrameGroupBy:"},{"metadata":{"trusted":true},"cell_type":"code","source":"type(grouped)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data filtered out only for store # 36"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped.get_group(36).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Size & pd.qcut() Method:"},{"metadata":{},"cell_type":"markdown","source":"Let's review: How to count rows in each group by using .size()"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped.size().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cutting values into 3 equal buckets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(pd.qcut(x = df['Price'], q=3, labels=['Low', 'Medium','High'])).size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Alloccating Daily Revenue values into custom-sized buckets by specifying the bin boundaries:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(pd.cut(df['Daily Revenue'], [0,500,1000,2500,5000,10000,50000, 100000, 175000, 250000, 500000, 750000, 1000000, 1250000])).size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grouping by multiple columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['Store ID', 'Price']).size().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = df.loc[df['Store ID']==(59)]\ndf_1.groupby(['Volume','Price', 'Daily Revenue']).size().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Aggregate Method:"},{"metadata":{},"cell_type":"markdown","source":"Aggregate by sum and mean:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['Price','Volume','Daily Revenue']].agg(['sum', 'mean'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Passing a dictionary to agg and specify operations for each column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.agg({'Price':['mean'], 'Volume':['sum','mean'], 'Daily Revenue':['sum','mean']})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now, using groupby and aggregate functions together, we get:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_agg(x): \n    names = { \n        'PriceMean': x['Price'].mean(),\n        'VolumeMax': x['Volume'].max(), \n        'DailyRevMean': x['Daily Revenue'].mean(),\n        'DailyRevMax': x['Daily Revenue'].max()\n    }\n\n    return pd.Series(names, index=[ key for key in names.keys()])\n\ndf.groupby('Store ID').apply(my_agg).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another, but not as useful way:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Store ID').agg({'Price':['mean'], 'Volume':['sum','mean'], 'Daily Revenue':['sum','mean']}).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make it horizontal, use transpose function at the end."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Store ID').agg({'Price':['mean'], 'Volume':['sum','mean'], 'Daily Revenue':['sum','mean']}).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The most frequently used functions:\n"},{"metadata":{},"cell_type":"markdown","source":"* 'size' = counts the rows\n* 'sum' = summs up\n* 'max/min' = Maximum/Minimum\n* 'mean/median' = Mean/ Median\n* 'idxmax/idxmin' = Column's index of the max/min\n* pd.Series.nunique = Counts unique values"},{"metadata":{},"cell_type":"markdown","source":"## Apply() Function"},{"metadata":{},"cell_type":"markdown","source":"First, let's take a look at a few examples how apply() function works:"},{"metadata":{},"cell_type":"markdown","source":"Note: By default, it applies the function along axis = 0 or for each column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.apply(sum)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By specifying axis = 1, it will apply the function for the rows"},{"metadata":{},"cell_type":"markdown","source":"### So-called Groupby-Split-Apply-Combine chain mechanism"},{"metadata":{},"cell_type":"markdown","source":"![Mechanism](https://pbs.twimg.com/media/CycthXVXgAAazkz?format=jpg&name=small)"},{"metadata":{},"cell_type":"markdown","source":"1. First, *Groupby*, splits the data into groups by creating a groupby object or DataFrameGroupBy. \n2. Next, *Apply* method, applies a fuction. \n3. And the last step, *Combine*, combines all of the results in a single output."},{"metadata":{},"cell_type":"markdown","source":"For example, applying a lambda function"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Store ID').apply(lambda x:x.mean()).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is another way that produces the same results"},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_mean(x):\n    return x.mean()\ndf.groupby('Store ID').apply(df_mean).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apply() function can be also apply=ied to the Time Series:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index().groupby(pd.Grouper(key = 'Date', freq = 'Q'))['Volume'].apply(sum)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transform function"},{"metadata":{},"cell_type":"markdown","source":"While, for example, aggregate function reduced DF, this function just transforms our DF. That is why it's normally used to assign to a new column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Volume %'] = df.groupby('Store ID')[['Volume']].transform(lambda x: x/sum(x)*100)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filter Method"},{"metadata":{},"cell_type":"markdown","source":"Filtering does not change the data, but only selects a subset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Store ID').filter(lambda x: x['Daily Revenue'].mean() > 1000).head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}