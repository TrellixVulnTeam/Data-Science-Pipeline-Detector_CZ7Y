{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-24T07:33:32.031615Z","iopub.execute_input":"2021-08-24T07:33:32.032017Z","iopub.status.idle":"2021-08-24T07:33:32.041553Z","shell.execute_reply.started":"2021-08-24T07:33:32.03198Z","shell.execute_reply":"2021-08-24T07:33:32.040388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports and data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error as MSE\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom catboost import CatBoostRegressor\nimport lightgbm as lgb\n\ntrain = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')\nshop = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\nitem = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\nitem_category = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nsample_submission = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:33:36.605243Z","iopub.execute_input":"2021-08-24T07:33:36.605641Z","iopub.status.idle":"2021-08-24T07:33:39.559415Z","shell.execute_reply.started":"2021-08-24T07:33:36.605605Z","shell.execute_reply":"2021-08-24T07:33:39.55822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocessing","metadata":{}},{"cell_type":"code","source":"train['pd_date'] = pd.to_datetime(train['date'], format='%d.%m.%Y')\ntrain['year'] = pd.DatetimeIndex(train['pd_date']).year\ntrain['month'] = pd.DatetimeIndex(train['pd_date']).month\n# train['day'] = pd.DatetimeIndex(train['pd_date']).day\n\nindex_cols = ['shop_id', 'item_id', 'date_block_num']\ntrain_grouped = train.loc[ # Outlier\n    (train['item_price'] < 100000) & (train['item_cnt_day'] <= 900)\n].drop(  # item_price is not in X_test\n    columns=['date', 'item_price', 'pd_date']\n).groupby(\n    index_cols\n).agg({'item_cnt_day': 'sum'}).reset_index().rename(\n    columns={'item_cnt_day': 'item_cnt_month'}\n)\n\n# test['year'] = 2015\n# test['month'] = 11\ntest['date_block_num'] = 34\n\ntrain_grouped = pd.concat(\n    [train_grouped, test.drop(columns=['ID'])],\n    axis=0, ignore_index=True, keys=index_cols\n)\nprint(train_grouped.shape, '\\n', train_grouped.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:33:46.32119Z","iopub.execute_input":"2021-08-24T07:33:46.32156Z","iopub.status.idle":"2021-08-24T07:33:48.71193Z","shell.execute_reply.started":"2021-08-24T07:33:46.321521Z","shell.execute_reply":"2021-08-24T07:33:48.7106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lag features","metadata":{}},{"cell_type":"code","source":"# define lag_feature\ndef lag_feature(data, lags, column):\n    temp = data[index_cols + [column]]\n    for lag in lags:\n        shifted = temp.copy()\n        shifted.columns = index_cols + [column + '_lag_' + str(lag)]\n        shifted['date_block_num'] += lag\n        data = pd.merge(data, shifted, on=index_cols, how='left')\n        data[column + '_lag_' + str(lag)] = data[column + '_lag_' + str(lag)].astype('float16')\n    return data\n\ntrain_lagged = lag_feature(train_grouped, [1, 2, 3], 'item_cnt_month')\ntrain_lagged.fillna(0, inplace=True)\ntrain_lagged = train_lagged.loc[train_lagged['date_block_num'] > 2]\ntrain_lagged.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:33:52.525898Z","iopub.execute_input":"2021-08-24T07:33:52.526506Z","iopub.status.idle":"2021-08-24T07:33:55.85368Z","shell.execute_reply.started":"2021-08-24T07:33:52.526432Z","shell.execute_reply":"2021-08-24T07:33:55.852673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Shop feature","metadata":{}},{"cell_type":"code","source":"# extract and encode cities\nshop['city'] = shop['shop_name'].apply(lambda x: x.split()[0].lower())\nshop.loc[shop.city == '!якутск', 'city'] = 'якутск'\nshop['city_code'] = LabelEncoder().fit_transform(shop['city'])\n# add coordinates of cities\ncoords = dict()\ncoords['якутск'] = (62.028098, 129.732555, 4)\ncoords['адыгея'] = (44.609764, 40.100516, 3)\ncoords['балашиха'] = (55.8094500, 37.9580600, 1)\ncoords['волжский'] = (53.4305800, 50.1190000, 3)\ncoords['вологда'] = (59.2239000, 39.8839800, 2)\ncoords['воронеж'] = (51.6720400, 39.1843000, 3)\ncoords['выездная'] = (0, 0, 0)\ncoords['жуковский'] = (55.5952800, 38.1202800, 1)\ncoords['интернет-магазин'] = (0, 0, 0)\ncoords['казань'] = (55.7887400, 49.1221400, 4)\ncoords['калуга'] = (54.5293000, 36.2754200, 4)\ncoords['коломна'] = (55.0794400, 38.7783300, 4)\ncoords['красноярск'] = (56.0183900, 92.8671700, 4)\ncoords['курск'] = (51.7373300, 36.1873500, 3)\ncoords['москва'] = (55.7522200, 37.6155600, 1)\ncoords['мытищи'] = (55.9116300, 37.7307600, 1)\ncoords['н.новгород'] = (56.3286700, 44.0020500, 4)\ncoords['новосибирск'] = (55.0415000, 82.9346000, 4)\ncoords['омск'] = (54.9924400, 73.3685900, 4)\ncoords['ростовнадону'] = (47.2313500, 39.7232800, 3)\ncoords['спб'] = (59.9386300, 30.3141300, 2)\ncoords['самара'] = (53.2000700, 50.1500000, 4)\ncoords['сергиев'] = (56.3000000, 38.1333300, 4)\ncoords['сургут'] = (61.2500000, 73.4166700, 4)\ncoords['томск'] = (56.4977100, 84.9743700, 4)\ncoords['тюмень'] = (57.1522200, 65.5272200, 4)\ncoords['уфа'] = (54.7430600, 55.9677900, 4)\ncoords['химки'] = (55.8970400, 37.4296900, 1)\ncoords['цифровой'] = (0, 0, 0)\ncoords['чехов'] = (55.1477000, 37.4772800, 4)\ncoords['ярославль'] = (57.6298700, 39.8736800, 2) \n\nshop['city_coord_1'] = shop['city'].apply(lambda x: coords[x][0])\nshop['city_coord_2'] = shop['city'].apply(lambda x: coords[x][1])\nshop['country_part'] = shop['city'].apply(lambda x: coords[x][2])\n\nshop.head()\n#shops = shops[['shop_id', 'city_code', 'city_coord_1', 'city_coord_2', 'country_part']]","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:34:00.156226Z","iopub.execute_input":"2021-08-24T07:34:00.156618Z","iopub.status.idle":"2021-08-24T07:34:00.201299Z","shell.execute_reply.started":"2021-08-24T07:34:00.156574Z","shell.execute_reply":"2021-08-24T07:34:00.199754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Item feature","metadata":{}},{"cell_type":"code","source":"cat_map = {\n    'Чистые носители (штучные)': 'Чистые носители',\n    'Чистые носители (шпиль)' : 'Чистые носители',\n    'PC ': 'Аксессуары',\n    'Служебные': 'Служебные '\n}\n# extract common categories\nitem_category['item_category'] = item_category['item_category_name'].apply(\n    lambda x: x.split('-')[0]\n)\nitem_category['item_category'] = item_category['item_category'].apply(\n    lambda x: cat_map[x] if x in cat_map.keys() else x\n)\n# encoding common categories\nitem_category['item_category_common'] = LabelEncoder().fit_transform(\n    item_category['item_category']\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:34:04.799819Z","iopub.execute_input":"2021-08-24T07:34:04.80019Z","iopub.status.idle":"2021-08-24T07:34:04.811029Z","shell.execute_reply.started":"2021-08-24T07:34:04.800159Z","shell.execute_reply":"2021-08-24T07:34:04.809534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def value_reduction(data):\n    for column in data.columns:\n        if data[column].dtype == 'float64':\n            data[column] = data[column].astype(np.float32)\n        if (data[column].dtype == 'int64' or data[column].dtype == 'int32') and (data[column].max() < 32767 and data[column].min() > -32768) and data[column].isnull().sum()==0:\n            data[column] = data[column].astype(np.int16)\n    return data\n\n\n# Join with item and shop\nall_data = train_lagged.join(\n    item.set_index('item_id'), on='item_id'\n).drop(\n    columns=['item_name']\n).join(\n    item_category.drop(\n        columns=['item_category_name', 'item_category']\n    ).set_index('item_category_id'), on='item_category_id'\n).join(\n    shop.drop(columns=['shop_name', 'city']).set_index('shop_id'), on='shop_id'\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:34:09.507842Z","iopub.execute_input":"2021-08-24T07:34:09.508339Z","iopub.status.idle":"2021-08-24T07:34:10.036088Z","shell.execute_reply.started":"2021-08-24T07:34:09.508295Z","shell.execute_reply":"2021-08-24T07:34:10.034869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target encoding","metadata":{}},{"cell_type":"code","source":"def mean_encoding(data, groupby_list, col_list):\n    res = data\n    for i in range(0, len(groupby_list)):\n        groupby = groupby_list[i]\n        col = col_list[i]\n        index = ['date_block_num'] + groupby\n        target_mean = data.groupby(\n            index\n        ).agg(\n            {'item_cnt_month': 'mean'}\n        ).reset_index().rename(\n            columns={\"item_cnt_month\": col},\n            errors=\"raise\"\n        )\n        res = res.join(\n            target_mean.set_index(index), on=index\n        )\n        res[col] = res[\n            col\n        ].fillna(0).astype(np.float16)\n        \n        res = lag_feature(res, [1, 2, 3], col)\n        res.drop(columns=[col], axis=1, inplace=True)\n    return res\n\nmean_encoded = mean_encoding(\n    all_data, [\n        ['item_id'],\n        ['item_id', 'city_code'],\n        ['item_id', 'shop_id']\n    ], [\n        'item_target_enc',\n        'item_loc_target_enc',\n        'item_shop_target_enc'\n    ]\n    \n)\nmean_encoded.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:34:13.033406Z","iopub.execute_input":"2021-08-24T07:34:13.033837Z","iopub.status.idle":"2021-08-24T07:34:27.6554Z","shell.execute_reply.started":"2021-08-24T07:34:13.033803Z","shell.execute_reply":"2021-08-24T07:34:27.654029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add the following columns\n* item_first_sold: the item is first sold in these shops in this month\n* shop_item_sold_before: whether the item has been sold in the same shop before","metadata":{}},{"cell_type":"code","source":"# item_first_sold and shop_item_sold_before\nfirst_item_block = mean_encoded.groupby(['item_id']).agg(\n    {'date_block_num': 'min'}\n).reset_index()\nfirst_item_block['item_first_sold'] = 1\n\nfirst_shop_item_buy_block = mean_encoded[mean_encoded['date_block_num'] > 0].groupby(\n    ['shop_id', 'item_id']\n).agg(\n    {'date_block_num': 'min'}\n).reset_index().rename(\n    columns={\"date_block_num\": \"first_date_block_num\"},\n    errors=\"raise\"\n)\n\nwith_interaction = mean_encoded.join(\n    first_item_block.set_index(['item_id', 'date_block_num']),\n    on=['item_id', 'date_block_num']\n).join(\n    first_shop_item_buy_block.set_index(['item_id', 'shop_id']),\n    on=['item_id', 'shop_id']\n)\n\nwith_interaction['first_date_block_num'].fillna(100, inplace=True)\nwith_interaction['shop_item_sold_before'] = (\n    with_interaction['first_date_block_num'] < with_interaction['date_block_num']\n).astype('int8')\nwith_interaction.drop(['first_date_block_num'], axis=1, inplace=True)\n\nwith_interaction['item_first_sold'].fillna(0, inplace=True)\nwith_interaction['shop_item_sold_before'].fillna(0, inplace=True)\n \nwith_interaction['item_first_sold'] = with_interaction['item_first_sold'].astype('int8')  \nwith_interaction['shop_item_sold_before'] = with_interaction['shop_item_sold_before'].astype('int8') \n\n# add avg category for new features\nitem_id_target_mean = with_interaction[\n    with_interaction['item_first_sold'] == 1\n].groupby(\n    ['date_block_num','item_category_id']\n).agg(\n    {'item_cnt_month': 'mean'}\n).reset_index().rename(\n    columns={'item_cnt_month': 'new_item_cat_avg'}, errors='raise'\n)\n\nwith_interaction = with_interaction.join(\n    item_id_target_mean.set_index(['date_block_num','item_category_id']),\n    on=['date_block_num','item_category_id']\n)\n\nwith_interaction['new_item_cat_avg'] = (\n    with_interaction['new_item_cat_avg'].fillna(0).astype(np.float16)\n)\n\nwith_interaction = lag_feature(with_interaction, [1, 2, 3], 'new_item_cat_avg')\nwith_interaction.drop(['new_item_cat_avg'], axis=1, inplace=True)\n\nprint(\n    first_item_block.head(), '\\n',\n    first_shop_item_buy_block.head(), '\\n',\n    item_id_target_mean.head(), '\\n',\n    with_interaction.head()\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:46:42.358616Z","iopub.execute_input":"2021-08-24T07:46:42.359072Z","iopub.status.idle":"2021-08-24T07:46:47.638318Z","shell.execute_reply.started":"2021-08-24T07:46:42.359034Z","shell.execute_reply":"2021-08-24T07:46:47.637348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare train, valid, test","metadata":{}},{"cell_type":"code","source":"with_interaction.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:50:05.319465Z","iopub.execute_input":"2021-08-24T07:50:05.320453Z","iopub.status.idle":"2021-08-24T07:50:05.549263Z","shell.execute_reply.started":"2021-08-24T07:50:05.320203Z","shell.execute_reply":"2021-08-24T07:50:05.547818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prepared_data = with_interaction.fillna(0)\n\nX_train = prepared_data.loc[prepared_data['date_block_num'] < 33].drop(\n    columns=['item_cnt_month']\n)\ny_train = prepared_data.loc[prepared_data['date_block_num'] < 33].filter(\n    items=['item_cnt_month']\n)\nX_valid = prepared_data.loc[prepared_data['date_block_num'] == 33].drop(\n    columns=['item_cnt_month']\n)\ny_valid = prepared_data.loc[prepared_data['date_block_num'] == 33].filter(\n    items=['item_cnt_month']\n)\nX_test = prepared_data.loc[prepared_data['date_block_num'] == 34].drop(\n    columns=['item_cnt_month']\n)\ncat_features=[\n    'item_category_id', 'item_category_common',\n    'city_code', 'country_part'\n]\nprint(X_train.head(), '\\n', X_test.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:53:30.775558Z","iopub.execute_input":"2021-08-24T07:53:30.775997Z","iopub.status.idle":"2021-08-24T07:53:31.756729Z","shell.execute_reply.started":"2021-08-24T07:53:30.775953Z","shell.execute_reply":"2021-08-24T07:53:31.755207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CatBoost model","metadata":{}},{"cell_type":"code","source":"model_cat = CatBoostRegressor(\n    random_state=1,\n    verbose=50, depth=4,\n    learning_rate=0.01, l2_leaf_reg=7,\n    max_leaves=2047, min_data_in_leaf=1,\n    subsample=0.7,\n    loss_function='RMSE', eval_metric='RMSE',\n    early_stopping_rounds=30,\n    grow_policy='Lossguide',\n    cat_features=cat_features,\n    # iterations=2000, \n    # task_type='GPU', bootstrap_type='Poisson',         \n)\nmodel_cat.fit(\n    X_train, y_train,\n    # eval_set=(X_valid, y_valid),\n    # logging_level='Silent'\n)\nprint(\n    'Train rmse for CatBoost:',\n    np.sqrt(MSE(y_train, model_cat.predict(X_train)))\n)\nprint(\n    'Validation rmse for CatBoost:',\n    np.sqrt(MSE(y_valid, model_cat.predict(X_valid)))\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:53:40.252366Z","iopub.execute_input":"2021-08-24T07:53:40.252831Z","iopub.status.idle":"2021-08-24T08:02:49.212132Z","shell.execute_reply.started":"2021-08-24T07:53:40.252793Z","shell.execute_reply":"2021-08-24T08:02:49.210976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBM","metadata":{}},{"cell_type":"code","source":"params = {\n    'objective': 'rmse',\n    'metric': 'rmse',\n    'num_leaves': 1023,\n    'min_data_in_leaf':10,\n    'feature_fraction': 0.7,\n    'learning_rate': 0.01,\n    'num_rounds': 2000,\n    'early_stopping_rounds': 30,\n    'seed': 1\n}\nmodel_lgb = lgb.train(\n    params=params,\n    train_set=lgb.Dataset(X_train, y_train),\n    valid_sets=(lgb.Dataset(X_train, y_train), lgb.Dataset(X_valid, y_valid)),\n    verbose_eval=50, categorical_feature=cat_features\n)\nprint(\n    'Train rmse for LGBM:',\n    np.sqrt(MSE(y_train, model_lgb.predict(X_train)))\n)\nprint(\n    'Validation rmse for LGBM:',\n    np.sqrt(MSE(y_valid, model_lgb.predict(X_valid)))\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:03:06.735856Z","iopub.execute_input":"2021-08-24T08:03:06.736242Z","iopub.status.idle":"2021-08-24T08:03:55.733338Z","shell.execute_reply.started":"2021-08-24T08:03:06.736208Z","shell.execute_reply":"2021-08-24T08:03:55.73244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random forest","metadata":{}},{"cell_type":"code","source":"model_rf = RandomForestRegressor(\n    random_state = 1, max_depth=10, max_features='sqrt',\n    min_samples_leaf=7, min_samples_split=11, n_estimators=75\n)\nmodel_rf.fit(X_train, y_train)\nprint(\n    'Train rmse for RandomForest:',\n    np.sqrt(MSE(y_train, model_rf.predict(X_train)))\n)\nprint(\n    'Validation rmse for RandomForest:',\n    np.sqrt(MSE(y_valid, model_rf.predict(X_valid)))\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:04:01.368972Z","iopub.execute_input":"2021-08-24T08:04:01.369525Z","iopub.status.idle":"2021-08-24T08:07:00.482782Z","shell.execute_reply.started":"2021-08-24T08:04:01.369484Z","shell.execute_reply":"2021-08-24T08:07:00.481713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"# Fill in the line below: get test predictions\nmodels = {\n    'cat': model_cat,\n    'rf': model_rf,\n    'lgb': model_lgb,\n}\nfor name, model in models.items():\n    preds_test = model.predict(X_test)\n    output = pd.DataFrame({'ID': test.ID,\n                           'item_cnt_month': preds_test})\n    output.to_csv('submission_' + name + '.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T08:15:05.407711Z","iopub.execute_input":"2021-08-24T08:15:05.408147Z","iopub.status.idle":"2021-08-24T08:15:13.57954Z","shell.execute_reply.started":"2021-08-24T08:15:05.40811Z","shell.execute_reply":"2021-08-24T08:15:13.57822Z"},"trusted":true},"execution_count":null,"outputs":[]}]}