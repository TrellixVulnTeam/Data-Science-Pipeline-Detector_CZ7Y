{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/competitive-data-science-predict-future-sales/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npath='/kaggle/input/competitive-data-science-predict-future-sales/'\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nimport warnings\nimport datetime\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport warnings \nwarnings.filterwarnings(action='ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_items = pd.read_csv(path+'items.csv')\ndf_sample= pd.read_csv(path+'sample_submission.csv')\ndf_categ = pd.read_csv(path+'item_categories.csv')\ndf_train = pd.read_csv(path+'sales_train.csv')\ndf_shops = pd.read_csv(path+'shops.csv')\ndf_test  = pd.read_csv(path+'test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_items.columns)\nprint(df_sample.columns)\nprint(df_categ.columns)\nprint(df_train.columns)\nprint(df_shops.columns)\nprint(df_test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.hist(figsize=(20,20),bins=30)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_nan_values(df, percent_base = 100):\n    columns_drop, col2, count_nan2, percent2, type2 = [], [], [], [], []\n\n    for col in df:\n        count_nan = df[col].isna().sum()\n        \n        if count_nan != 0:\n            col2.append(col)\n            count_nan2.append(count_nan)\n            percent2.append(str((count_nan * 100 / df.shape[0]).round(2)) + '%')\n            type2.append(df[col].dtype)\n            \n            if (count_nan * 100 / df.shape[0]).round(2) >= percent_base:\n                columns_drop.append(col)\n\n    result = pd.DataFrame({'col': col2,\n                            'count_nan': count_nan2,\n                            'percent': percent2,\n                            'type': type2}).sort_values(['count_nan'], ascending = [False])\n\n    return result, columns_drop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def one_class(df):\n    df.dropna()\n    one_class = []\n    for var in count_nan_values(df, percent_base = 0)[1]:\n        if df[var].nunique() == 1:\n            print(var, df[var].dtype)\n            one_class.append(var)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"one_class(df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['date']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['date']=pd.to_datetime(df_train['date'], format='%d.%m.%Y')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['date']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df_train[['date','item_price','item_id']].set_index('date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df.item_price != max(df['item_price'])] #delete outlier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('item_id').count().sort_values(by='item_price',ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_1 = df[df['item_id']==20949].drop('item_id',axis=1)\ndf_1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\n# Color pallete for plotting\ncolor_pal = [ \"#D39200\", \"#93AA00\",\n             \"#00BA38\", \"#00C19F\", \"#00B9E3\",\n             \"#619CFF\", \"#DB72FB\"]\ndf_1.plot(style='*', figsize=(15,12), color=color_pal[1], title='Sales Price')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}