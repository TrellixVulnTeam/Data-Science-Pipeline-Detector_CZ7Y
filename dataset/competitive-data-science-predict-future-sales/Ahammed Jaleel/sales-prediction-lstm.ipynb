{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Import Libraries**"},{"metadata":{"_uuid":"768dfba9-b6b3-4d00-bf3a-7641ba4e929a","_cell_guid":"74435351-9094-451e-ad63-4e1843ee0246","trusted":true},"cell_type":"code","source":"import os\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set(style='darkgrid')\npd.set_option('display.float_format',lambda  x: '%.2f' %x)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nitem_cats = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sales:',sales.shape,'test:',test.shape,'items:',items.shape,'item_cats:',item_cats.shape,'shop:',shops.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Change date form to DDMMYYYY"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales['date'] = pd.to_datetime(sales['date'], format='%d.%m.%Y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head(3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_cats.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales[sales['item_price']<=0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales[(sales.shop_id==32)&(sales.item_id==2973)&(sales.date_block_num==4)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median = sales[(sales.shop_id==32)&(sales.item_id==2973)&(sales.date_block_num==4)&\n               (sales.item_price>0)].item_price.median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.loc[sales.item_price<0,'item_price'] =median","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pivot Table **"},{"metadata":{},"cell_type":"markdown","source":"we want get total count value of an item over the whole month for a shop. \nThat why we made shop_id and item_id our indices and date_block_num our column \nthe value we want is item_cnt_day and used sum as aggregating function "},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndataset = sales.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_day'],columns = ['date_block_num'],fill_value = 0,aggfunc='sum')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reset our indices, so that data should be in way we can easily manipulate"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndataset.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge our pivot table with the test_data because we want to keep the data for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.merge(test,dataset,on = ['item_id','shop_id'],how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets fill all NaN values with 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.fillna(0,inplace = True)\n\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop shop_id and item_id because we do not need them"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop(['shop_id','item_id','ID'],inplace = True, axis = 1)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X we will keep all columns execpt the last one \nX_train = np.expand_dims(dataset.values[:,:-1],axis = 2)\n# the last column is our label\ny_train = dataset.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test = np.expand_dims(dataset.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries \nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model = Sequential()\nmy_model.add(LSTM(units = 64,input_shape = (33,1)))\nmy_model.add(Dropout(0.3)) #The dropout rate is set to 30%, meaning one in 3.33 inputs will be randomly excluded from each update cycle.\nmy_model.add(Dense(1))\n\nmy_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nmy_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_pred = my_model.fit(X_train,y_train,batch_size = 4000,epochs = 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = my_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid search\n\nFor simplicity we are keeping less parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef build_classifier(optimizer):\n    grid_model = Sequential()\n    grid_model.add(LSTM(units = 64,input_shape = (33,1)))\n    grid_model.add(Dropout(0.4))\n    grid_model.add(Dense(1))\n\n    grid_model.compile(loss = 'mse',optimizer = optimizer, metrics = ['mean_squared_error'])\n    return my_model\n\ngrid_model = KerasClassifier(build_fn=build_classifier)\nparameters = {'batch_size' : [4000,4080],\n              'epochs' : [8,10],\n              'optimizer' : ['adam','Adadelta'] }\n\ngrid_search  = GridSearchCV(estimator = grid_model,\n                            param_grid = parameters,\n                            scoring = 'accuracy',\n                            cv = 2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search = grid_search.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nbest_parameters = grid_search.best_params_\nbest_accuracy = grid_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us check our best parameters\nbest_parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us check our best accuracy got through grid search\nbest_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(lst_pred.history['loss'], label= 'loss(mse)')\nplt.plot(np.sqrt(lst_pred.history['mean_squared_error']), label= 'rmse')\nplt.legend(loc=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train, y_pred[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating submission file \nsubmission_pfs = my_model.predict(X_test)\n# we will keep every value between 0 and 20\nsubmission_pfs = submission_pfs.clip(0,20)\n# creating dataframe with required columns \nsubmission = pd.DataFrame({'ID':test['ID'],'item_cnt_month':submission_pfs.ravel()})\n# creating csv file from dataframe\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('sub_pfs.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}