{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Büyük Veri Final\nOnur Kaplan - 160202061","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kütüphanelerin Eklenmesi","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport catboost as cb\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\nimport csv\nfrom sklearn.impute import SimpleImputer ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verilerin okunup incelenmesi","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"item_categories = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nitems = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\nsales_train = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv',parse_dates = ['date'])\nsample_submission = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')\nshops = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\ndata_test = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')\n\nprint(f'item_categories.csv : {item_categories.shape}')\nitem_categories.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'items.csv : {items.shape}')\nitems.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'sales_train.csv : {sales_train.shape}')\nprint(sales_train.dtypes)\nsales_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'sample_submission.csv : {sample_submission.shape}')\nsample_submission.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'shops.csv : {shops.shape}')\nshops.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'test.csv : {data_test.shape}')\ndata_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Outlier veri kontrolü","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.scatter(sales_train.item_cnt_day,sales_train.item_price)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Outlier verilerin silinmesi","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train = sales_train[sales_train.item_price<45000]\nsales_train = sales_train[sales_train.item_cnt_day<600]\ncolumns = ['date', 'date_block_num', 'shop_id', 'item_id','item_price','item_cnt_day']\nsales_train.drop_duplicates(columns,keep='first', inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.scatter(sales_train.item_cnt_day,sales_train.item_price)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train verisinin hazırlanması aylık olarak gruplama","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly = sales_train.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\"item_cnt_day\"].agg('sum').reset_index()\nmonthly.columns = ['date_block_num','shop_id','item_id','item_cnt_month']\n\nprice_monthly = sales_train.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\"item_price\"].agg('mean').reset_index()\n\ncombine = pd.merge(monthly, price_monthly)\ncombine.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train['year'] = sales_train['date'].dt.year\nsales_train['day_of_year'] = sales_train['date'].dt.dayofyear\nsales_train['weekday'] = sales_train['date'].dt.weekday\nsales_train['week_of_year'] = sales_train['date'].dt.week\nsales_train['day_of_month'] = sales_train['date'].dt.day\nsales_train['quarter'] = sales_train['date'].dt.quarter\nsales_train['month'] = sales_train['date'].dt.month\nsales_train.drop('date', axis=1, inplace=True)\nsales_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test verisinin hazırlanması date_block_num ve aylık price verisinin eklenmesi","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datatest_monthly = price_monthly.groupby([\"shop_id\",\"item_id\"])[\"item_price\"].agg('mean').reset_index()\ndata_test['date_block_num'] = 34\ndata_test_end = pd.merge(data_test, datatest_monthly,how = 'left')\ndata_test_end = data_test_end.drop(['ID'], axis = 1)\n\nnumeric = SimpleImputer(missing_values=np.nan, strategy='mean')\nnumeric = numeric.fit(data_test_end)\ndata_test_end = numeric.transform(data_test_end)\ndata_test_end = pd.DataFrame(data_test_end,columns=[\"shop_id\",\"item_id\",\"date_block_num\",\"item_price\"])\ndata_test_end.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verilerin train test olarak bölünmesi","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = combine.drop('item_cnt_month', axis=1)\nY = combine.item_cnt_month\ntrain, test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Seçimi\n\nXGBoost Uygulanması","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.XGBRegressor(\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42)\n\nmodel.fit(\n    train, \n    y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(train, y_train), (test, y_test)], \n    verbose=True, \n    early_stopping_rounds = 10)\n\ny_pred = model.predict(test)\ny_pred = y_pred.tolist()\n\nprint('R2 XGBoost: ',r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nxgb.plot_importance(model, importance_type='gain',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CatBoost Uygulanması","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model =  cb.CatBoostRegressor(iterations=1000,\n                             learning_rate=0.01,\n                             depth=16,\n                             eval_metric='RMSE',\n                             random_seed = 42,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 75,\n                             od_wait=100)\n\nmodel.fit(train, y_train,eval_set=(test, y_test),plot=True)\n\ny_pred = model.predict(test)\ny_pred = y_pred.tolist()\n\nprint('R2 CatBoost : ',r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fea_imp = pd.DataFrame({'imp': model.feature_importances_, 'col': combine.drop('item_cnt_month', axis=1).columns})\nfea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\nfea_imp.plot(kind='barh', x='col', y='imp', figsize=(10, 7), legend=None)\nplt.title('CatBoost - Feature Importance')\nplt.ylabel('Features')\nplt.xlabel('Importance');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LightGBM Uygulanması","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'rmse',\n#    'metric': ['l2', 'auc'],\n    'learning_rate': 0.005,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 10,\n    'verbose': 0,\n    \"max_depth\": 8,\n    \"num_leaves\": 128,  \n    \"max_bin\": 512,\n    \"num_iterations\": 1000,\n    \"n_estimators\": 1000\n}\n\nmodel = lgb.LGBMRegressor(**hyper_params)\n\nmodel.fit(train, y_train,\n        eval_set=[(test, y_test)],\n        eval_metric='l1',\n        early_stopping_rounds=1000)\n\ny_pred = model.predict(test)\n\nprint('R2 LightGBM: ',r2_score(y_test,y_pred))\n#print('RMSE : 'metrics.mean_squared_error(y_test, y_pred, squared=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nlgb.plot_importance(model, importance_type='gain', max_num_features=20,figsize=(10,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomForestRegressor Uygulanması","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor(n_estimators=100,random_state=0)\nrf_reg.fit(train,y_train)\n\ny_pred = rf_reg.predict(test)\nprint('R2 RandomForest: ',r2_score(y_test,y_pred))\nprint('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Çıktı\nAlgoritmalardan alınan çıktılar üzerine test verisinin tahmini için RandomForestRegressor algoritması seçilmiştir. \nSeçilen algoritma ile asıl test verisi üzerinde tahmin uygulanıp sonuçları submission.csv'ye kaydedilmiştir. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf_reg.predict(data_test_end)\ny_pred = pd.DataFrame(y_pred,columns=[\"item_cnt_month\"])\ny_pred = y_pred.clip(0,20)\n# print('R2 : ',r2_score(y_test,y_pred))\n# print('Validation rmse:', np.sqrt(mean_squared_error(y_test, y_pred)))\n# print(accuracy_score(y_pred, y_test)*100)\n\nsample_submission = sample_submission.drop(['item_cnt_month'], axis = 1)\nsample_submission=pd.concat([sample_submission,y_pred],axis=1)\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head(5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}