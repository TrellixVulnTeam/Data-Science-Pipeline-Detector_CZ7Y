{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](http://)![](http://)![](http://) <font color='green'> <font color='blue'> ** *Inspired by Some other Kernal* ** </font> \n</font>\n"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Import the Required Module\n   ###       First thing First"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport random as rd\nimport datetime\nimport time\nimport sys\nimport gc\nimport pickle\nsys.version_info\n\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt \nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 4\nimport seaborn as sns \n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.dummy import DummyRegressor\n\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's Put into dataframe every dataset**"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\nitem_categories = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")\nitems = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\nshops = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")\ntest = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")\nsubmission = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we need to understand about the dataset, so that we can work through on it."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sales_train.info())\nprint('----------------------------------')\nprint(items.info())\nprint('----------------------------------')\nprint(item_categories.info())\nprint('----------------------------------')\nprint(shops.info())\nprint('----------------------------------')\nprint(test.info())\nprint('----------------------------------')\nprint(submission.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking Missing Value"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum())\nprint('----------------------------------')\nprint(items.isnull().sum())\nprint('----------------------------------')\nprint(item_categories.isnull().sum())\nprint('----------------------------------')\nprint(shops.isnull().sum())\nprint('----------------------------------')\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Idetifying the Outlier"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=train.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price)\n\nprint(len(train[train.item_cnt_day>999]))\nprint(len(train[train.item_cnt_day>500]))\nprint(len(train[train.item_cnt_day<501]))\n\ntrain = train[train.item_price<100000]\ntrain = train[train.item_cnt_day<1000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing the Outliers, visualization of the item price and item cnt day"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 1000)\nsns.boxplot(x=train.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(0, 100000)\n#plt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Elimination the item price below zero and negative values of item_cnt_day"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.item_price > 0].reset_index(drop=True)\ntrain[train.item_cnt_day <= 0].item_cnt_day.unique()\ntrain.loc[train.item_cnt_day < 1, 'item_cnt_day'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"visualization after dropping the negative values"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 1000)\nsns.boxplot(x=train.item_cnt_day)\n\nplt.figure(figsize=(10,4))\n#plt.xlim(0, 100000)\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shops Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.shop_name.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.groupby(['category']).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_sales=sales_train.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n    \"date\",\"item_price\",\"item_cnt_day\"].agg({\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_sales.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of Items per Catagory"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=items.groupby(['item_category_id']).count()\nx=x.sort_values(by='item_id',ascending=False)\nx=x.iloc[0:10].reset_index()\n\nplt.figure(figsize=(8,4))\nax= sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\nplt.title(\"Items per Category\")\nplt.ylabel('# of items', fontsize=12)\nplt.xlabel('Category', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=sales_train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nres = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"multiplicative\")\nplt.figure(figsize=(16,12))\nfig = res.plot()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"additive\")\nplt.figure(figsize=(16,12))\nfig = res.plot()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stationarity tests\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\ntest_stationarity(ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to remove trend\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=sales_train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,16))\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts)\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts)\nplt.plot(new_ts)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After De-seasonalization')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts,12)       # assuming the seasonality is 12 months long\nplt.plot(new_ts)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now testing the stationarity again after de-seasonality\ntest_stationarity(new_ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsplot(y, lags=None, figsize=(10, 8), style='bmh',title=''):\n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n    with plt.style.context(style):    \n        fig = plt.figure(figsize=figsize)\n        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n        layout = (3, 2)\n        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1, 0))\n        pacf_ax = plt.subplot2grid(layout, (1, 1))\n        qq_ax = plt.subplot2grid(layout, (2, 0))\n        pp_ax = plt.subplot2grid(layout, (2, 1))\n        \n        y.plot(ax=ts_ax)\n        ts_ax.set_title(title)\n        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n        sm.qqplot(y, line='s', ax=qq_ax)\n        qq_ax.set_title('QQ Plot')        \n        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n\n        plt.tight_layout()\n    return ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an AR(1) process with alpha = 0.6\nnp.random.seed(1)\nn_samples = int(1000)\na = 0.6\nx = w = np.random.normal(size=n_samples)\n\nfor t in range(n_samples):\n    x[t] = a*x[t-1] + w[t]\nlimit=12    \n_ = tsplot(x, lags=limit,title=\"AR(1)process\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an AR(2) process\n\nn = int(1000)\nalphas = np.array([.444, .333])\nbetas = np.array([0.])\n\n# Python requires us to specify the zero-lag value which is 1\n# Also note that the alphas for the AR model must be negated\n# We also set the betas for the MA equal to 0 for an AR(p) model\n# For more information see the examples at statsmodels.org\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nar2 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \n_ = tsplot(ar2, lags=12,title=\"AR(2) process\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_lag = 12\n\nn = int(5000) # lots of samples to help estimates\nburn = int(n/10) # number of samples to discard before fit\n\nalphas = np.array([0.8, -0.65])\nbetas = np.array([0.5, -0.7])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\narma22 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n, burnin=burn)\n_ = tsplot(arma22, lags=max_lag,title=\"ARMA(2,2) process\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pick best order by aic \n# smallest aic value wins\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(arma22, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(new_ts.values, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the dates to the Time-series as index\nts=sales_train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.index=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nts=ts.reset_index()\nts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\n#prophet reqiures a pandas df at the below config \n# ( date column named as DS and the value column as Y)\nts.columns=['ds','y']\nmodel = Prophet( yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel.fit(ts) #fit the model with your dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict for five months in the furure and MS - month start is the frequency\nfuture = model.make_future_dataframe(periods = 5, freq = 'MS')  \n# now lets make the forecasts\nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_sales=sales_train.groupby(['date_block_num'])[\"item_cnt_day\"].sum()\ndates=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\n\ntotal_sales.index=dates\ntotal_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the unique combinations of item-store from the sales data at monthly level\nmonthly_sales=sales_train.groupby([\"shop_id\",\"item_id\",\"date_block_num\"])[\"item_cnt_day\"].sum()\n# arrange it conviniently to perform the hts \nmonthly_sales=monthly_sales.unstack(level=-1).fillna(0)\nmonthly_sales=monthly_sales.T\ndates=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nmonthly_sales.index=dates\nmonthly_sales=monthly_sales.reset_index()\nmonthly_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nstart_time=time.time()\n\n# Bottoms up\n# Calculating the base forecasts using prophet\n# From HTSprophet pachage -- https://github.com/CollinRooney12/htsprophet/blob/master/htsprophet/hts.py\nforecastsDict = {}\nfor node in range(len(monthly_sales)):\n    # take the date-column and the col to be forecasted\n    nodeToForecast = pd.concat([monthly_sales.iloc[:,0], monthly_sales.iloc[:, node+1]], axis = 1)\n#     print(nodeToForecast.head())  # just to check\n# rename for prophet compatability\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[0] : 'ds'})\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[1] : 'y'})\n    growth = 'linear'\n    m = Prophet(growth, yearly_seasonality=True)\n    m.fit(nodeToForecast)\n    future = m.make_future_dataframe(periods = 1, freq = 'MS')\n    forecastsDict[node] = m.predict(future)\n    if (node== 10):\n        end_time=time.time()\n        print(\"forecasting for \",node,\"th node and took\",end_time-start_time,\"s\")\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_shop_sales=sales_train.groupby([\"date_block_num\",\"shop_id\"])[\"item_cnt_day\"].sum()\n# get the shops to the columns\nmonthly_shop_sales=monthly_shop_sales.unstack(level=1)\nmonthly_shop_sales=monthly_shop_sales.fillna(0)\nmonthly_shop_sales.index=dates\nmonthly_shop_sales=monthly_shop_sales.reset_index()\nmonthly_shop_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time=time.time()\n\n# Calculating the base forecasts using prophet\n# From HTSprophet pachage -- https://github.com/CollinRooney12/htsprophet/blob/master/htsprophet/hts.py\nforecastsDict = {}\nfor node in range(len(monthly_shop_sales)):\n    # take the date-column and the col to be forecasted\n    nodeToForecast = pd.concat([monthly_shop_sales.iloc[:,0], monthly_shop_sales.iloc[:, node+1]], axis = 1)\n#     print(nodeToForecast.head())  # just to check\n# rename for prophet compatability\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[0] : 'ds'})\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[1] : 'y'})\n    growth = 'linear'\n    m = Prophet(growth, yearly_seasonality=True)\n    m.fit(nodeToForecast)\n    future = m.make_future_dataframe(periods = 1, freq = 'MS')\n    forecastsDict[node] = m.predict(future)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions = np.zeros([len(forecastsDict[0].yhat),1]) \nnCols = len(list(forecastsDict.keys()))+1\nfor key in range(0, nCols-1):\n    f1 = np.array(forecastsDict[key].yhat)\n    f2 = f1[:, np.newaxis]\n    if key==0:\n        predictions=f2.copy()\n       # print(predictions.shape)\n    else:\n       predictions = np.concatenate((predictions, f2), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_unknown=predictions[-1]\npredictions_unknown","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gp = sales_train.groupby(['date_block_num', 'shop_id', 'item_id']).agg({'item_cnt_day': ['sum']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(list(map(list, gp.index.values)))\ny_train = gp.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['date_block_num'] = train['date_block_num'].max() + 1\nX_test = test[['date_block_num', 'shop_id', 'item_id']].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samp = np.random.permutation(np.arange(len(y_train)))[:int(len(y_train)*.2)]\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X[samp,1], X[samp,2], y_train[samp].ravel(), c=X[samp,0], marker='.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oh0 = OneHotEncoder(categories='auto').fit(X[:,0].reshape(-1, 1))\nx0 = oh0.transform(X[:,0].reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oh1 = OneHotEncoder(categories='auto').fit(X[:,1].reshape(-1, 1))\nx1 = oh1.transform(X[:,1].reshape(-1, 1))\nx1_t = oh1.transform(X_test[:,1].reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X[:, :1].shape, x1.toarray().shape, X[:, 2:].shape)\nX_train = np.concatenate((X[:, :1], x1.toarray(), X[:, 2:]), axis=1)\nX_test = np.concatenate((X_test[:, :1], x1_t.toarray(), X_test[:, 2:]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dmy = DummyRegressor().fit(X_train, y_train)\n\nreg = LinearRegression().fit(X_train, y_train)\n\nrfr = RandomForestRegressor().fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse_dmy = np.sqrt(mean_squared_error(y_train, dmy.predict(X_train)))\nprint('Dummy RMSE: %.4f' % rmse_dmy)\nrmse_reg = np.sqrt(mean_squared_error(y_train, reg.predict(X_train)))\nprint('LR RMSE: %.4f' % rmse_reg)\nrmse_rfr = np.sqrt(mean_squared_error(y_train, rfr.predict(X_train)))\nprint('RFR RMSE: %.4f' % rmse_rfr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = rfr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['item_cnt_month'] = y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv('xgb_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}