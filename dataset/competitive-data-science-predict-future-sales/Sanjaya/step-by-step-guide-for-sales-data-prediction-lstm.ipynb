{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Please help by upvoting this kernel if you feel useful. \nIt will motivate me to keep publishing.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This Note book will be easy for who is new to data science libraries. \nI'm importing libraries when ever it is needed, so it will be easy to relate each.\n\n**Problem Statement : **\n\nYou are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Step 1:** Define the problem and expected output. Break down the problem into simple steps.\n1. End Goal ->  Forcast total amount of products sold in every shop for the next month\n2. Notes -> list of shops and products slightly changes every month","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Step 2:** Load the data. \nHere I'm using popular data loading library pandas.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\npath = \"/kaggle/input/competitive-data-science-predict-future-sales/\"\n\nitems = pd.read_csv(path+'/items.csv')\nitem_cats = pd.read_csv(path+'/item_categories.csv')\nshops = pd.read_csv(path+'/shops.csv')\nsales = pd.read_csv(path+'/sales_train.csv')\ntest = pd.read_csv(path+'/test.csv')\nsubmission = pd.read_csv(path+'/sample_submission.csv')\n\nprint(\"Data set loaded successfully.\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Step 2:** Get an idea about the data structure.\nHere I'm using few different commands to list columns in pands dataframe.\n*DataFrame is like a table structure which is having list of columns with data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(items.info())\nprint('Items : \\n\\t'+'\\n\\t'.join(list(items)))\nprint('ItemsCatagories : \\n\\t'+'\\n\\t'.join(list(item_cats.columns.values)))\nprint('Shops : \\n\\t'+'\\n\\t'.join(shops.columns.tolist()))\nprint('Sales : \\n\\t'+'\\n\\t'.join(sales.columns.tolist()))\n## you will get above data set along with row data of sales only in real world senario.\n## based on those, Usually we have to create our training and test data set based on our model which we are going to use \n## Here they giving us and test data set where we can directly use and the sales data we can use for training the model\nprint('TestSet : \\n\\t'+'\\n\\t'.join(list(test)))\nprint('Output : \\n\\t'+'\\n\\t'.join(list(submission)))\n\nsales.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you have clear idea about what is this data about. For getting more idea about data we will try to visualize this data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Step 3:** Visualize data. First try to visualize some random samples extracted from the data. I'm using different methods which we can use to visualize data in tabular way.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Items\")\nprint(items.head(2))\nprint(\"\\nItem Catagerios\")\nprint(item_cats.tail(2))\nprint(\"\\nShops\")\nprint(shops.sample(n=2))\nprint(\"\\nTraining Data Set\")\nprint(sales.sample(n=3,random_state=1))\nprint(\"\\nTest Data Set\")\nprint(test.sample(n=3,random_state=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After seeing this dataset we can catagerioze this data to meta data and effective data.\nSo, shop_names and item names, we don't care much. We can have a shop and item combined id and the\n sales data for the analyze further.\n\nFinal goal to predict sales, so we can ignore names of the products. we are interested in item count in a date time series. And price also can be a factor for the sales.\n\nSo, Try to plot some data which is relavant. \nBefore plotting anything it is better to get an idea about the boundaries of the data set.\n]","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As we can see, simple way to address this is to use sales data and try to group and summarize those.\nFor the conveniet purpose we will split date column to year and month","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nsales['year'] = pd.to_datetime(sales['date']).dt.strftime('%Y')\nsales['month'] = sales.date.apply(lambda x: datetime.strptime(x,'%d.%m.%Y').strftime('%m')) #another way for same thing\n\nsales.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try to plot sales for every year, to understand about seosaonal data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#will make your plot outputs appear and be stored within the notebook.\n%matplotlib inline \n\ngrouped = pd.DataFrame(sales.groupby(['year','month'])['item_cnt_day'].sum().reset_index())\nsns.pointplot(x='month', y='item_cnt_day', hue='year', data=grouped)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Price\ngrouped_price = pd.DataFrame(sales.groupby(['year','month'])['item_price'].mean().reset_index())\nsns.pointplot(x='month', y='item_price', hue='year', data=grouped_price)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By seeing this graph we can see that\n1. last two months of the year having more sales.\n2. 2015, we are expecting more sales.\n\nLet's try to draw Total sales along with the linear month period time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the whole time period')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the distribution, for detectiting outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"item_cnt_day\", y=\"item_price\", data=sales, height=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.item_cnt_day.hist(bins=100)\nsales.item_cnt_day.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, \"item_cnt_day\" > 125 and < 0, \"item_price\" >= 75000  we can treat as outliers,\nIn data cleaing stage we will remove those items.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Step 4: Data Cleaning**\n\nFilter incorrect data. Eg:  \n1. Item price is equal to 0\n2. data not in the test set given\n3. Remove outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Data set size before remove item price 0 cleaning:', sales.shape)\nsales = sales.query('item_price > 0')\nprint('Data set size after remove item price 0 cleaning:', sales.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Data set size before filter valid:', sales.shape)\n# Only shops that exist in test set.\nsales = sales[sales['shop_id'].isin(test['shop_id'].unique())]\n# Only items that exist in test set.\nsales = sales[sales['item_id'].isin(test['item_id'].unique())]\nprint('Data set size after filter valid:', sales.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Data set size before remove outliers:', sales.shape)\nsales = sales.query('item_cnt_day >= 0 and item_cnt_day <= 125 and item_price < 75000')\nprint('Data set size after remove outliers:', sales.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#After cleaning plot\nsns.jointplot(x=\"item_cnt_day\", y=\"item_price\", data=sales, height=8)\nplt.show()\n\ncleaned = pd.DataFrame(sales.groupby(['year','month'])['item_cnt_day'].sum().reset_index())\nsns.pointplot(x='month', y='item_cnt_day', hue='year', data=cleaned)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Step 5:**  Data preprocessing. Identify features. This means, selecting only needed features and create the proper dataset for the processing.\nWe need to find out what are the features that will affect the sales\n1. Price\n2. Month\n3. Year\n4. Item catagory\n\nBased on above features, sales can be vary. So, we will keep only the interested columns and drop others.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aggregate to monthly level the sales\nmonthly_sales=sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n    \"date_block_num\",\"date\",\"item_price\",\"item_cnt_day\"].agg({\"date_block_num\":'mean',\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\n\nmonthly_sales.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the dataset\n\nWe will use LSTM(Long Short Term Memory) algorithum to model this time series data.\nLSTM model will learn a function that maps a sequence of past observations as input to an output observation.\n\nFor this approach, we need to prapare our data set with input and output sequence.\n\nEg:  Let say we have monthly avarage sales as,  \n\n[10, 20, 30, 40, 50, 60, 70, 80, 90]\n\nWe can divide the sequence into multiple input/output patterns called samples, where three time steps are used as input and one time step is used as output for the one-step prediction that is being learned.\n\n            X\t\t y\n    10, 20, 30\t\t40\n    20, 30, 40\t\t50\n    30, 40, 50\t\t60","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Our 'date_block_num' column will be the sequnce index, sales will be the value. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_data_flat = monthly_sales.item_cnt_day.apply(list).reset_index()\n#Keep only the test data of valid\nsales_data_flat = pd.merge(test,sales_data_flat,on = ['item_id','shop_id'],how = 'left')\n#fill na with 0\nsales_data_flat.fillna(0,inplace = True)\nsales_data_flat.drop(['shop_id','item_id'],inplace = True, axis = 1)\nsales_data_flat.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will create pivot table.\n# Rows = each shop+item code\n# Columns will be out time sequence\npivoted_sales = sales_data_flat.pivot_table(index='ID', columns='date_block_num',fill_value = 0,aggfunc='sum' )\npivoted_sales.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Step 6** : Spilit training,validation and test dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# X we will keep all columns execpt the last one \nX_train = np.expand_dims(pivoted_sales.values[:,:-1],axis = 2)\n# the last column is our prediction\ny_train = pivoted_sales.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test = np.expand_dims(pivoted_sales.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout\nfrom keras.models import load_model, Model\n\n# our defining sales model \nsales_model = Sequential()\nsales_model.add(LSTM(units = 64,input_shape = (33,1)))\n#sales_model.add(LSTM(units = 64,activation='relu'))\nsales_model.add(Dropout(0.5))\nsales_model.add(Dense(1))\n\nsales_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nsales_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"sales_model.fit(X_train,y_train,batch_size = 4096,epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_output = sales_model.predict(X_test)\n# creating dataframe with required columns \nsubmission = pd.DataFrame({'ID':test['ID'],'item_cnt_month':submission_output.ravel()})\n# creating csv file from dataframe\n#submission.to_csv('submission.csv',index = False)\nsubmission.to_csv('submission_stacked.csv',index = False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"==================First stage Completed=============================\n\nExpecting your feedback.\n\nThank you.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}