{"cells":[{"metadata":{},"cell_type":"markdown","source":"\nThis challenge serves as final project for the \"How to win a data science competition\" Coursera course.\n\nIn this competition you will work with a challenging time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company.\n\nWe are asking you to predict total sales for every product and store in the next month. By solving this competition you will be able to apply and enhance your data science skills."},{"metadata":{},"cell_type":"markdown","source":"Load libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#load modules\nimport os\nimport pandas as pd\nimport numpy as np\nfrom pandas import read_csv\nfrom pandas import datetime\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Load datasets\ntrain=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\ntest=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")\nsample=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\")\nitems=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\nitem_cat=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\nshops=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert date to datetime format"},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert date to datetime format\ntrain['date'] = pd.to_datetime(train['date'],format = '%d.%m.%Y')\ntrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create pivot table\ndataset = train.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_day'],columns = ['date_block_num'],fill_value = 0,aggfunc='sum')\ndataset.reset_index(inplace = True)\ndataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocess data"},{"metadata":{"trusted":true},"cell_type":"code","source":"ID = test.ID\nID","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(['ID'], axis=1)\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merge pivot table with test set\ndataset = pd.merge(test,dataset,on = ['item_id','shop_id'],how = 'left')\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for any null values\ndataset.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill all NaN values with 0\ndataset.fillna(0,inplace = True)\ndataset.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop shop_id and item_id\ndataset.drop(['shop_id','item_id'],inplace = True, axis = 1)\ndataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create X, y and X_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the dataset in two\n# the last column is our label\ny_train = dataset.iloc[:,-1:]\n#drop last column of data\nX_train = dataset.iloc[:, :-1]\n#drop first colum of data\nX_test = dataset.iloc[:,1:]\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define model"},{"metadata":{},"cell_type":"markdown","source":"An AdaBoost regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = AdaBoostRegressor(base_estimator = RandomForestRegressor(max_depth=10), random_state=0, n_estimators=3000).fit(X_train, y_train)\ny_pred = model.predict(X_train)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.score(X_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test)\npred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submit file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating submission file \nsubmission_file = pred\n# we will keep every value between 0 and 20\nsubmission_file = submission_file.clip(0,20)\n# creating dataframe with required columns \nsubmission_trp = pd.DataFrame({'ID':ID,'item_cnt_month':submission_file.ravel()})\n# creating csv file from dataframe\nsubmission_trp.to_csv('submission.csv',index = False)\nsubmission_trp.head(20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}