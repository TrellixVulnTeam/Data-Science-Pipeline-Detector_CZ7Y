{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport catboost\nfrom catboost import Pool\nfrom catboost import CatBoostRegressor\n\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 100)\n\n\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n%matplotlib inline\n#sns.set(style=\"darkgrid\")\n# pd.set_option('display.float_format', lambda x: '%.2f' % x)\nwarnings.filterwarnings(\"ignore\")\n\nimport time\n\nfrom xgboost import XGBRegressor\nfrom string import punctuation\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv', dtype={'ID': 'int32', 'shop_id': 'int32', \n                                                  'item_id': 'int32'})\nitem_categories = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv', \n                              dtype={'item_category_name': 'str', 'item_category_id': 'int32'})\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv', dtype={'item_name': 'str', 'item_id': 'int32', \n                                                 'item_category_id': 'int32'})\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv', dtype={'shop_name': 'str', 'shop_id': 'int32'})\nsales = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv', \n                    dtype={'date': 'str', 'date_block_num': 'int32', 'shop_id': 'int32', \n                          'item_id': 'int32', 'item_price': 'float32', 'item_cnt_day': 'int32'})\n#sales = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data\n本次資料來源為2013~2015俄羅斯商店銷售資料，希望預測未來銷售數值。\n初步計劃：著重data engineering部分"},{"metadata":{},"cell_type":"markdown","source":"### Sale data (main training data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.date=sales.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))\n# check\nprint(sales.info())\nsales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Link with item catigory"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = sales.join(items, on='item_id', rsuffix='_').join(shops, on='shop_id', rsuffix='_').join(item_categories, on='item_category_id', rsuffix='_').drop(['item_id_', 'shop_id_', 'item_category_id_'], axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_sales=sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n    \"date\",\"item_price\",\"item_cnt_day\"].agg({\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\nmonthly_sales.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find date / price / item sell per day"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Min date from train set: %s' % train['date'].min().date())\nprint('Max date from train set: %s' % train['date'].max().date())\nprint('Min item_price from train set: %s' % train['item_price'].min())\nprint('Max item_price from train set: %s' % train['item_price'].max())\nprint('Min item_cnt_day from train set: %s' % train['item_cnt_day'].min())\nprint('Max item_cnt_day from train set: %s' % train['item_cnt_day'].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 由Max item_cnt_day from train set 得知銷售行為與價格相關 （價格浮動）（特價）\n若價格調降有週期性 -> 銷售量有週期性 -> 不需要觀察價格即可得知\n\n### Future Plan:\n根據價格做預測，進一步預測銷售數量\n"},{"metadata":{},"cell_type":"markdown","source":"### training data info"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 查看價格分佈"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(np.log10(train['item_price']), kde=False)\nplt.yscale('log')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 查看每日銷量分佈"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train.loc[(train['item_cnt_day']<10000)&(train['item_cnt_day']>-5),\n                          'item_cnt_day'], kde=False)\nplt.yscale('log')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 由於分佈有巨大落差，選擇每日銷量<750作為分界點，以避免outlier\n\n多數資料單日有巨大銷量可能因為新品上市(如GTA5)，特價促銷，或某些資料上無法確認的狀態造成。\n\nnote: 750只是一個隨意抓取的數值，有優化空間\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train.loc[(train['item_cnt_day']<750), :]\ntrain_df = train_df.loc[(train_df['item_price']<10**5), :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 查看價格與金額是否有相關性\n\nnote: 一定金額之內有此特性"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nplt.scatter(train_df['item_price'], train_df['item_cnt_day'], alpha=0.25)\nplt.xscale('log')\nplt.yscale('log')\nplt.ylim((1e-1, 1e4))\nplt.xlim((1e-3, 1e6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 由於training data 包含許多非test data中有的item，選擇剔除\n\nfuture plan: 檢查以全數dataset是否能得到更好結果"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_shop_ids = test['shop_id'].unique()\ntest_item_ids = test['item_id'].unique()\n# 在test data中有shop_id\ntrain_in_data = train[train['shop_id'].isin(test_shop_ids)]\n# 在test data中有item_id\ntrain_in_data = train_in_data[train_in_data['item_id'].isin(test_item_ids)]\nprint('Data set size in train:', train.shape[0])\nprint('Data set size in both train & test:', train_in_data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 簡易EDA\n\ncredit: NowYSM@kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"def eda(data):\n    print(\"----------Top-5- Record----------\")\n    print(data.head(5))\n    print(\"-----------Information-----------\")\n    print(data.info())\n    print(\"-----------Data Types-----------\")\n    print(data.dtypes)\n    print(\"----------Missing value-----------\")\n    print(data.isnull().sum())\n    print(\"----------Null value-----------\")\n    print(data.isna().sum())\n    print(\"----------Shape of Data----------\")\n    print(data.shape)\n\ndef graph_insight(data):\n    print(set(data.dtypes.tolist()))\n#     df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num = data.select_dtypes(include = ['float32', 'int32'])\n    df_num.hist(figsize=(16, 16), bins=50, xlabelsize=8, ylabelsize=8);\n    \ndef drop_duplicate(data, subset):\n    print('Before drop shape:', data.shape)\n    before = data.shape[0]\n    data.drop_duplicates(subset,keep='first', inplace=True) #subset is list where you have to put all column for duplicate check\n    data.reset_index(drop=True, inplace=True)\n    print('After drop shape:', data.shape)\n    after = data.shape[0]\n    print('Total Duplicate:', before-after)\neda(train)\ngraph_insight(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 預期default分類方式過細，根據商品型態進行category merge"},{"metadata":{"trusted":true},"cell_type":"code","source":"l = list(item_categories.item_category_name)\nl_cat = l\nl_cat_int = l\nl_cat[0] = 'pc_headphone'\n\nfor ind in range(1,8):\n    l_cat[ind] = 'console_accessory'\n\nl_cat[8] = 'ticket'\nl_cat[9] = 'delivary'\nfor ind in range(10,18):\n    l_cat[ind] = 'console'\nl_cat[12] = 'new_console'\nl_cat[14] = 'new_console'\nl_cat[16] = 'new_console'\n    \nfor ind in range(18,25):\n    l_cat[ind] = 'console_game'\nl_cat[25] = 'console_game_accessory'\nl_cat[21] = 'mobile_game'\nl_cat[22] = 'mobile_game'\nl_cat[26] = 'mobile_game'\nfor ind in range(27,32):\n    l_cat[ind] = 'pc_game'\n\nfor ind in range(32,37):\n    l_cat[ind] = 'payment_card'\n\nfor ind in range(37,42):\n    l_cat[ind] = 'dvd'\n\nfor ind in range(42,55):\n    l_cat[ind] = 'book'\n\nfor ind in range(55,61):\n    l_cat[ind] = 'music'\n\nfor ind in range(61,73):\n    l_cat[ind] = 'gift'\n\nfor ind in range(73,79):\n    l_cat[ind] = 'software'\n\n\n\nitem_categories['my_category_tmp'] = l_cat\n\nl_tmp=[]\nl_cat_int=[]\ninit=0\nfor x in l_cat:\n    if x in l_tmp:\n        l_cat_int.append(l_tmp.index(x))\n    else:\n        l_tmp.append(x)        \n        l_cat_int.append(init)\n        init=init+1\nitem_categories['my_category'] = l_cat_int\n\nitem_categories.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly = train_in_data[['date', 'date_block_num', 'shop_id', 'item_category_id', 'item_id', 'item_price', 'item_cnt_day']]\nshop_ids = train_monthly['shop_id'].unique()\nitem_ids = train_monthly['item_id'].unique()\nempty_df = []\nfor i in range(34):\n    for shop in shop_ids:\n        for item in item_ids:\n            empty_df.append([i, shop, item])\n    \nempty_df = pd.DataFrame(empty_df, columns=['date_block_num','shop_id','item_id'])\ntrain_monthly = pd.merge(empty_df, train_monthly, on=['date_block_num','shop_id','item_id'], how='left')\ntrain_monthly.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly[train_monthly[\"item_cnt_day\"]>20].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 比較每日銷量在20以上/以下 和 僅在test data中出現的item / training data的所有item 的比例\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"unique item day sale cnt>20 amt in train_monthly (keep only item_id in test) is\",len(train_monthly[train_monthly[\"item_cnt_day\"]>20]['item_id'].unique()),\"/\",len(train_monthly[train_monthly[\"item_cnt_day\"]>=0]['item_id'].unique()))\nprint(\"item day sale cnt>20 amt in train_monthly (keep only item_id in test) is\",len(train_monthly[train_monthly[\"item_cnt_day\"]>20]),\"/\",len(train_monthly[train_monthly[\"item_cnt_day\"]>0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"unique item day sale cnt>20 amt in train is\",len(train[train[\"item_cnt_day\"]>20]['item_id'].unique()),\"/\",len(train[train[\"item_cnt_day\"]>=0]['item_id'].unique()))\nprint(\"item day sale cnt>20 amt in train is\",len(train[train[\"item_cnt_day\"]>20]),\"/\",len(train[train[\"item_cnt_day\"]>0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly['date_block_num'] = train_monthly['date_block_num'].astype(int)\ntrain_monthly['shop_id'] = train_monthly['shop_id'].astype(int)\ntrain_monthly['item_category_id'] = train_monthly['item_category_id'].astype(int)\ntrain_monthly['item_id'] = train_monthly['item_id'].astype(int)\n\ntrain_monthly = train_monthly.sort_values('date_block_num').groupby(['date_block_num', 'shop_id', 'item_category_id', 'item_id'], as_index=False)\n# train_monthly = train_monthly.agg({'item_price':['sum', 'mean'], 'item_cnt_day':['sum', 'mean','count']})\n# Rename features.\n# train_monthly.columns = ['date_block_num', 'shop_id', 'item_category_id', 'item_id', 'item_price', 'mean_item_price', 'item_cnt', 'mean_item_cnt', 'transactions']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly = train_monthly.agg({'item_price':['sum', 'mean'], 'item_cnt_day':['sum', 'mean','count']})\n# Rename feature\ntrain_monthly.columns = ['date_block_num', 'shop_id', 'item_category_id', 'item_id', 'item_price', 'mean_item_price', 'item_cnt', 'mean_item_cnt', 'transactions']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly[train_monthly['item_category_id']==40].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_monthly.columns = ['date_block_num', 'shop_id', 'item_id', 'date', 'item_category_id', 'item_price',  'item_cnt', 'mean_item_cnt', 'transactions']\ntrain_monthly['year'] = train_monthly['date_block_num'].apply(lambda x: ((x//12) + 2013))\ntrain_monthly['month'] = train_monthly['date_block_num'].apply(lambda x: (x % 12))\ngp_month_mean = train_monthly.groupby(['month'], as_index=False)['item_cnt'].mean()\ngp_month_sum = train_monthly.groupby(['month'], as_index=False)['item_cnt'].sum()\ngp_category_mean = train_monthly.groupby(['item_category_id'], as_index=False)['item_cnt'].mean()\ngp_category_sum = train_monthly.groupby(['item_category_id'], as_index=False)['item_cnt'].sum()\ngp_shop_mean = train_monthly.groupby(['shop_id'], as_index=False)['item_cnt'].mean()\ngp_shop_sum = train_monthly.groupby(['shop_id'], as_index=False)['item_cnt'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 檢查類別每日銷量"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(2, 1, figsize=(20, 10), sharex=True)\nsns.barplot(x=\"item_category_id\", y=\"item_cnt\", data=gp_category_mean, ax=axes[0], palette=\"mako\").set_title(\"Monthly mean\")\nsns.barplot(x=\"item_category_id\", y=\"item_cnt\", data=gp_category_sum, ax=axes[1], palette=\"mako\").set_title(\"Monthly sum\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 利用boxplot檢查極端值分佈"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10)) \nsns.boxplot(x=\"item_category_id\",y=\"item_cnt\",data=train_monthly,palette=\"mako\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly[train_monthly['item_cnt']>500].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## print('unique shop #: ',len(train_monthly['shop_id'].unique()))\nprint('unique item #: ',len(train_monthly['item_id'].unique()))\nprint('unique category #: ',len(train_monthly['item_category_id'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly.groupby(['month'], as_index=False)['item_cnt'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly[train_monthly['mean_item_price']>10].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data = pd.merge(train_monthly, item_categories.drop(columns=['item_category_name']), on=['item_category_id'])\ninput_data['item_id']= input_data.item_id.astype('str')\ninput_data['item_category_id']= input_data.item_category_id.astype('str')\ninput_data['shop_id']= input_data.shop_id.astype('str')\ninput_data['year']= input_data.year.astype('str')\ninput_data['month']= input_data.month.astype('str')\ninput_data = input_data.drop(['item_price','mean_item_cnt','transactions','my_category_tmp'], axis = 1)\n# remove mean_item_price for now\n\ncols = input_data.columns.tolist()\ncols = cols[5:]+cols[:5]\ninput_data[cols].head()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 使用xgboost訓練/預測"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode Categories\nfrom sklearn import preprocessing\n\ninput_data_clean=input_data[cols]\nnumber = preprocessing.LabelEncoder()\ninput_data_clean[['item_id']] = number.fit_transform(input_data_clean.item_id)\ninput_data_clean[['item_category_id']] = number.fit_transform(input_data_clean.item_category_id)\ninput_data_clean[['shop_id']] = number.fit_transform(input_data_clean.shop_id)\ninput_data_clean[['year']] = number.fit_transform(input_data_clean.year)\ninput_data_clean[['month']] = number.fit_transform(input_data_clean.month)\ninput_data_clean[['my_category']] = number.fit_transform(input_data_clean.my_category)\ninput_data_clean[['date_block_num']] = number.fit_transform(input_data_clean.date_block_num)\ninput_data_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n# input_data_clean=input_data_clean.drop(['my_category'], axis = 1)\n\nX, y = input_data_clean.iloc[:,1:],input_data_clean.iloc[:,0]\n# data_dmatrix = xgb.DMatrix(data=X,label=y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n# xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n#                 max_depth = 10, alpha = 10, n_estimators = 10)\n\nparam = {'max_depth':10, \n         'subsample':1,\n         'min_child_weight':0.5,\n         'eta':0.3, \n         'num_round':1000, \n         'seed':1,\n         'silent':0,\n         'eval_metric':'rmse'}\n\nprogress = dict()\nxgbtrain = xgb.DMatrix(X_train, y_train)\nwatchlist  = [(xgbtrain,'train-rmse')]\n\nbst = xgb.train(param, xgbtrain)\npreds = bst.predict(xgb.DMatrix(X_test))\nfrom sklearn.metrics import mean_squared_error \nrmse = np.sqrt(mean_squared_error(preds,y_test))\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10)) \nxgb.plot_importance(bst)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 可以發現自定義的分類效果有限，重要性遠低於原始定義\n\nfuture plan：\n    1. 去掉自分類\n    2. 此輸入資料單純把xgboost當成回歸工具使用(針對單一item給予item_category_id,shop_id,year,month,date_block_num)，對於週期性波動預測度恐有限。\n       應針對單一item輸入最接近的數筆資料作為預測最新時間點的參考"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}