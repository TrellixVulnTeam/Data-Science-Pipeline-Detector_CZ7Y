{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"INPUT_DIR = '/kaggle/input/competitive-data-science-predict-future-sales/'\n\nsales_train_df = pd.read_csv(f'{INPUT_DIR}/sales_train.csv')\nitem_categories_df = pd.read_csv(f'{INPUT_DIR}/item_categories.csv')\nitems_df = pd.read_csv(f'{INPUT_DIR}/items.csv')\nshops_df = pd.read_csv(f'{INPUT_DIR}/shops.csv')\ntest_df = pd.read_csv(f'{INPUT_DIR}/test.csv')\nsubmission_df = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sales train"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_df.info()\nsales_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of na's\nsales_train_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Item Categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of na's\nitem_categories_df.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Items"},{"metadata":{"trusted":true},"cell_type":"code","source":"items_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Shops"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_df.info()\nshops_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()\ntest_df\n\ntest = test_df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=sales_train_df.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(sales_train_df.item_price.min(), sales_train_df.item_price.max()*1.1)\nsns.boxplot(x=sales_train_df.item_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = sales_train_df.copy()\ntrain = train[train.item_price<100000]\ntrain = train[train.item_cnt_day<1001]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Price below zero"},{"metadata":{"trusted":true},"cell_type":"code","source":"median = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\ntrain.loc[train.item_price<0, 'item_price'] = median","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Duplicated shops"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Якутск Орджоникидзе, 56\ntrain.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n# Жуковский ул. Чкалова 39м²\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cities and item types"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops = shops_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nshops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\nshops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\nshops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\nshops['city_code'] = LabelEncoder().fit_transform(shops['city'])\nshops = shops[['shop_id','city_code']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats = item_categories_df.copy()\nitems = items_df.copy()\ncats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats['split'] = cats['item_category_name'].str.split('-')\ncats['type'] = cats['split'].map(lambda x: x[0].strip())\ncats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n# if subtype is nan then type\ncats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\ncats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\ncats = cats[['item_category_id','type_code', 'subtype_code']]\n\nitems.drop(['item_name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generate matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product\nmatrix = []\ncols = ['date_block_num','shop_id','item_id']\nfor i in range(34):\n    sales = train[train.date_block_num==i]\n    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n    \nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['revenue'] = train['item_price'] *  train['item_cnt_day']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (matrix['item_cnt_month']\n                                .fillna(0)\n                                .clip(0,20)\n                                .astype(np.float16))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding Test Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['date_block_num'] = 34\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\ntest['shop_id'] = test['shop_id'].astype(np.int8)\ntest['item_id'] = test['item_id'].astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\nmatrix.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merge with shops/items/categ."},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\nmatrix = pd.merge(matrix, items, on=['item_id'], how='left')\nmatrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')\nmatrix['city_code'] = matrix['city_code'].astype(np.int8)\nmatrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\nmatrix['type_code'] = matrix['type_code'].astype(np.int8)\nmatrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding lags"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = lag_feature(matrix, [1,2,3,6,9,12], 'item_cnt_month')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num'], how='left')\nmatrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_avg_item_cnt')\nmatrix.drop(['date_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1,2,3,6,9,12], 'date_item_avg_item_cnt')\nmatrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_shop_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\nmatrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1,2,3,6,9,12], 'date_shop_avg_item_cnt')\nmatrix.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_cat_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_category_id'], how='left')\nmatrix['date_cat_avg_item_cnt'] = matrix['date_cat_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_cat_avg_item_cnt')\nmatrix.drop(['date_cat_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_cat_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\nmatrix['date_shop_cat_avg_item_cnt'] = matrix['date_shop_cat_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_shop_cat_avg_item_cnt')\nmatrix.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_type_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'type_code'], how='left')\nmatrix['date_shop_type_avg_item_cnt'] = matrix['date_shop_type_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_shop_type_avg_item_cnt')\nmatrix.drop(['date_shop_type_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_subtype_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\nmatrix['date_shop_subtype_avg_item_cnt'] = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_shop_subtype_avg_item_cnt')\nmatrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_city_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'city_code'], how='left')\nmatrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_city_avg_item_cnt')\nmatrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'item_id', 'city_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_city_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'city_code'], how='left')\nmatrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_item_city_avg_item_cnt')\nmatrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_type_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'type_code'], how='left')\nmatrix['date_type_avg_item_cnt'] = matrix['date_type_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_type_avg_item_cnt')\nmatrix.drop(['date_type_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = matrix.groupby(['date_block_num', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_subtype_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'subtype_code'], how='left')\nmatrix['date_subtype_avg_item_cnt'] = matrix['date_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_subtype_avg_item_cnt')\nmatrix.drop(['date_subtype_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = matrix[matrix.date_block_num > 11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_na(df):\n    for col in df.columns:\n        if ('_lag_' in col) & (df[col].isnull().any()):\n            if ('item_cnt' in col):\n                df[col].fillna(0, inplace=True)         \n    return df\n\nmatrix = fill_na(matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train & test"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = matrix.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[data.date_block_num <= 33].drop(['item_cnt_month'], axis=1)\ny = data[data.date_block_num <= 33]['item_cnt_month']\nX_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\ny_train = data[data.date_block_num < 33]['item_cnt_month']\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\ny_valid = data[data.date_block_num == 33]['item_cnt_month']\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Delete data that is not needed"},{"metadata":{"trusted":true},"cell_type":"code","source":"del matrix\ndel sales_train_df\ndel train\ndel shops_df\ndel shops\ndel cats\ndel item_categories_df\ndel items_df\ndel items","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nreg = LinearRegression()\nreg.fit(X_train,y_train)\n\nprint('Linear Regression RMSE:', mean_squared_error(y_valid, reg.predict(X_valid), squared = False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ridge Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''parameters = {'alpha':[0, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n\nmodel = Ridge()\nRidge_reg= GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error',cv=5)\n\nRidge_reg.fit(X,y)\nprint(Ridge_reg.best_estimator_)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_ridge = Ridge(alpha = 1000)\nreg_ridge.fit(X_train,y_train)\n\nprint('Ridge RMSE:', mean_squared_error(y_valid, reg_ridge.predict(X_valid), squared = False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_ridge.fit(X, y)\nY_test = reg_ridge.predict(X_test).clip(0, 20)\n\nsubmissionRidge = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_model = LGBMRegressor(\n    n_jobs=-1,\n    learning_rate=0.2,\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42\n)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=7)\neval_set = [(X_valid, y_valid)]\n\nlgbm_model.fit(\n    X_train, \n    y_train, \n    eval_metric=\"rmse\", \n    eval_set=eval_set,\n    verbose=True, \n    early_stopping_rounds = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test = lgbm_model.predict(X_test).clip(0, 20)\n\nsubmissionLGBM = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom keras.layers import LSTM, Dense, Dropout\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nmodel = Sequential()\nmodel.add(LSTM(units=64, input_shape=(35, 1)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1))\n\nmodel.compile(loss='mse',\n              optimizer='adam',\n              metrics=['mean_squared_error'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.expand_dims(X_train.values,axis = 2)\nX_test = np.expand_dims(X_test.values,axis = 2)\nX_valid = np.expand_dims(X_valid.values,axis = 2)\n\n\n\nprint(X_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''X_train = X.values\nX_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\nX_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n\nX_valid = np.reshape(X_valid.values, (X_valid.shape[0], 1, X_valid.shape[1]))\n\neval_set = (X_valid, y_valid)\n\n\nhistory = model.fit(X_train, y_train, batch_size=2048, epochs=5, validation_data=eval_set)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Y_test = model.predict(X_test).clip(0, 20)\nprint(Y_test)\n\nsubmissionLSTM = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test.ravel()\n})'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.plot(history.history['val_loss'], label = 'Training Loss')\n#plt.legend(loc = 'best', shadow = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['item_cnt_month'] = ( 0.1*submissionRidge['item_cnt_month'] + 0.9*submissionLGBM['item_cnt_month'])\nsubmission_df.to_csv('submission.csv', index=False)\nprint('output file :','submission','saved')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}