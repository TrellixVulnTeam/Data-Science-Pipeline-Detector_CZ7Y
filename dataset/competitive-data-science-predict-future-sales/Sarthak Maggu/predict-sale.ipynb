{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nfrom itertools import product\nfrom math import ceil\nimport copy\nimport os\nfrom IPython.display import clear_output\nimport nltk\nfrom sklearn.feature_extraction import text\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA, TruncatedSVD, NMF\nimport lightgbm as lgb\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, Lars, ElasticNet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\ntest = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")\nitems = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\nitem_categories = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")\nshops = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sales'] = train['item_cnt_day']*train['item_price']\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.shop_id == 0, \"shop_id\"] = 57\ntest.loc[test.shop_id == 0 , \"shop_id\"] = 57\ntrain.loc[train.shop_id == 1, \"shop_id\"] = 58\ntest.loc[test.shop_id == 1 , \"shop_id\"] = 58\ntrain.loc[train.shop_id == 11, \"shop_id\"] = 10\ntest.loc[test.shop_id == 11, \"shop_id\"] = 10\ntrain.loc[train.shop_id == 40, \"shop_id\"] = 39\ntest.loc[test.shop_id == 40, \"shop_id\"] = 39","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removing Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.boxplot(x= train.item_cnt_day)\nplt.title(\"BoxPlot\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.boxplot(x = train.item_price)\nplt.title(\"BoxPlot\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[(train.item_price < 100000 )& (train.item_cnt_day < 1000)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.boxplot(x= train.item_cnt_day)\nplt.title(\"BoxPlot\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10) )\nsns.boxplot( x = train.item_price)\nplt.title(\"BoxPlot\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.item_price > 0].reset_index(drop = True)\ntrain.loc[train.item_cnt_day < 1, \"item_cnt_day\"] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting categorical feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\nshops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\nshops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\nshops['city_code'] = LabelEncoder().fit_transform(shops['city'])\nshops = shops[['shop_id','city_code']]\nitem_categories['split'] = item_categories['item_category_name'].str.split('-')\nitem_categories['type'] = item_categories['split'].map(lambda x: x[0].strip())\nitem_categories['type_code'] = LabelEncoder().fit_transform(item_categories['type'])\nitem_categories['subtype'] = item_categories['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\nitem_categories['subtype_code'] = LabelEncoder().fit_transform(item_categories['subtype'])\nitem_categories = item_categories[['item_category_id','type_code', 'subtype_code']]\nitems.drop(['item_name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TF-IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"items_1 = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\nitem_categories_1 = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")\nshops_1 = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_features= 10\ntfidf = text.TfidfVectorizer(max_features=nb_features)\nitems_1['item_name_len'] = items_1['item_name'].map(len)  \nitems_1['item_name_wc'] = items_1['item_name'].map(lambda x: len(str(x).split(' ')))\ntxtFeatures = pd.DataFrame(tfidf.fit_transform(items_1['item_name']).toarray())\ncols = txtFeatures.columns\nfor i in range(nb_features):\n    items_1['item_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\nitems_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = text.TfidfVectorizer(max_features = 10)\nshops_1['shop_name_len'] = shops_1['shop_name'].map(len)\nshops_1['shop_name_wc'] = shops_1['shop_name'].map(lambda x: len(str(x).split(' ')))\ntxtFeatures = pd.DataFrame(tfidf.fit_transform(shops_1['shop_name']).toarray())\ncols = txtFeatures.columns\nfor i in range(10):\n    shops_1['shop_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\nshops_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Starting Point(Data Engineering)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train1 = []\ncols = ['date_block_num','shop_id','item_id']\nfor block_num in range(34):\n    temp = train[train.date_block_num==block_num]\n    train1.append(np.array(list(product([block_num], temp['shop_id'].unique(), temp['item_id'].unique()))))\ntrain1 = pd.DataFrame(np.vstack(train1), columns=cols)\ntrain1['date_block_num'] = train1['date_block_num'].astype(np.int8)\ntrain1['shop_id'] = train1['shop_id'].astype(np.int8)\ntrain1['item_id'] = train1['item_id'].astype(np.int16)\ntrain1.sort_values(cols,inplace=True);\ntrain1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ntemp.columns = ['item_cnt_month']\ntemp.reset_index(inplace=True)\ntrain1 = pd.merge(train1, temp, on=cols, how='left')\ntrain1['item_cnt_month'] = (train1['item_cnt_month'].fillna(0).clip(0,20).astype(np.float16))\ntrain1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['date_block_num'] = 34\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\ntest['shop_id'] = test['shop_id'].astype(np.int8)\ntest['item_id'] = test['item_id'].astype(np.int16)\ntrain2 = pd.concat([train1, test], ignore_index=True, sort=False, keys=cols)\ntrain2.fillna(0,inplace=True)\ntrain2.drop([\"ID\"], inplace = True, axis =1)\ntrain2.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lagged Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id', col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train3 = pd.merge(train2, shops, on=['shop_id'], how='left')\ntrain3 = pd.merge(train3, items, on=['item_id'], how='left')\ntrain3 = pd.merge(train3, item_categories, on=['item_category_id'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 1. Create 'date_avg_item_cnt'\ntemp = train3.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_avg_item_cnt']          \ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num'], how='left')\ntrain3 = lag_feature(train3, [1], 'date_avg_item_cnt')\ntrain3.drop(['date_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 2. Create 'date_item_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_item_avg_item_cnt']     ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num','item_id'], how='left')\ntrain3 = lag_feature(train3, [1, 2, 3], 'date_item_avg_item_cnt')\ntrain3.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 3. Create 'date_shop_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_shop_avg_item_cnt']     ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num','shop_id'], how='left')\ntrain3 = lag_feature(train3, [1, 2, 3], 'date_shop_avg_item_cnt')\ntrain3.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 4. Create 'date_cat_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_cat_avg_item_cnt']      ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num','item_category_id'], how='left')\ntrain3 = lag_feature(train3, [1], 'date_cat_avg_item_cnt')\ntrain3.drop(['date_cat_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 5. Create 'date_shop_cat_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_shop_cat_avg_item_cnt']    ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\ntrain3 = lag_feature(train3, [1], 'date_shop_cat_avg_item_cnt')\ntrain3.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 6. Create 'date_shop_type_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_shop_type_avg_item_cnt']    ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num', 'shop_id', 'type_code'], how='left')\ntrain3 = lag_feature(train3, [1], 'date_shop_type_avg_item_cnt')\ntrain3.drop(['date_shop_type_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 7. Create 'date_type_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_type_avg_item_cnt']     ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num', 'type_code'], how='left')\ntrain3 = lag_feature(train3, [1], 'date_type_avg_item_cnt')\ntrain3.drop(['date_type_avg_item_cnt'], axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 8. Create 'date_city_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_city_avg_item_cnt']     ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num', 'city_code'], how='left')\ntrain3 = lag_feature(train3, [1], 'date_city_avg_item_cnt')\ntrain3.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 9. Create 'date_shop_subtype_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_shop_subtype_avg_item_cnt']   ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\ntrain3 = lag_feature(train3, [1], 'date_shop_subtype_avg_item_cnt')\ntrain3.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 10. Create 'date_item_city_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'item_id', 'city_code']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_item_city_avg_item_cnt']     ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num', 'item_id', 'city_code'], how='left')\ntrain3 = lag_feature(train3, [1], 'date_item_city_avg_item_cnt')\ntrain3.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## 11. Create 'date_subtype_avg_item_cnt'\ntemp = train3.groupby(['date_block_num', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_subtype_avg_item_cnt']     ###\ntemp.reset_index(inplace=True)\ntrain3 = pd.merge(train3, temp, on=['date_block_num', 'subtype_code'], how='left')\ntrain3 = lag_feature(train3, [1], 'date_subtype_avg_item_cnt')\ntrain3.drop(['date_subtype_avg_item_cnt'], axis=1, inplace=True)\ntrain3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time series trend features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def select_trend(row):\n    for i in lags:\n        if row['delta_price_lag_'+str(i)]:\n            return row['delta_price_lag_'+str(i)]\n    return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.groupby(['item_id']).agg({'item_price': ['mean']})\ntemp.columns = ['item_avg_item_price']\ntemp.reset_index(inplace=True)\ntrain4 = pd.merge(train3, temp, on=['item_id'], how='left')\ntemp = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\ntemp.columns = ['date_item_avg_item_price']\ntemp.reset_index(inplace=True)\ntrain4 = pd.merge(train4, temp, on=['date_block_num','item_id'], how='left')\nlags = [1,2,3]\ntrain4 = lag_feature(train4, lags, 'date_item_avg_item_price')\nfor i in lags:\n    train4['delta_price_lag_'+str(i)] = \\\n    (train4['date_item_avg_item_price_lag_'+str(i)] - train4['item_avg_item_price']) / train4['item_avg_item_price']\n    \ntrain4['delta_price_lag'] = train4.apply(select_trend, axis=1)\ntrain4['delta_price_lag'].fillna(0, inplace=True)\ndropped_cols = ['item_avg_item_price', 'date_item_avg_item_price']\nfor i in lags:\n    dropped_cols += ['date_item_avg_item_price_lag_'+str(i)]\n    dropped_cols += ['delta_price_lag_'+str(i)]\ntrain4.drop(dropped_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.groupby(['date_block_num','shop_id']).agg({'sales': ['sum']})\ntemp.columns = ['date_shop_revenue']\ntemp.reset_index(inplace=True)\ntrain4 = pd.merge(train4, temp, on=['date_block_num','shop_id'], how='left')\ntemp = train4.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\ntemp.columns = ['shop_avg_revenue']\ntemp.reset_index(inplace=True)\ntrain4 = pd.merge(train4, temp, on=['shop_id'], how='left')\ntrain4['delta_revenue'] = (train4['date_shop_revenue'] - train4['shop_avg_revenue']) / train4['shop_avg_revenue']\ntrain4 = lag_feature(train4, [1], 'delta_revenue')\ntrain4.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train4[train4['date_block_num'] > 10]\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(df, items_1, how='left', on='item_id')\ndf = pd.merge(df, shops_1, how='left', on='shop_id')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['item_name', 'item_name_len', 'item_name_wc', 'item_category_id_y',\n         'shop_name', 'shop_name_len', 'shop_name_wc'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Advanced Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"del train1, train2, train3, train4, temp\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['shop_id', 'item_id', 'city_code', 'item_category_id_x', 'type_code', 'subtype_code']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = KFold(n_splits= 3, shuffle=False)\nnew_features = []\n\ncheck = False\nfor train_idx, valid_idx in cv.split(df):\n    \n    # Train/validation split\n    X_train, X_valid = df.iloc[train_idx,:], df.iloc[valid_idx,:]\n    \n    # Mean encoding\n    for col in cat_features:\n        means = X_valid[col].map(X_train.groupby(col).item_cnt_month.mean())\n        col_new = col+'_target_enc'\n        X_valid[col_new] = means\n        \n        # Results\n        df.loc[valid_idx, col_new] = X_valid\n        \n        # Store new columns\n        if check==False:\n            new_features.append(col_new)\n    \n    check = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_features = ['shop_id_target_enc', 'item_id_target_enc', 'city_code_target_enc',\n                'item_category_id_x_target_enc', 'type_code_target_enc', 'subtype_code_target_enc']\nprior = np.mean(df['item_cnt_month'].values)\ndf[new_features] = df[new_features].fillna(prior)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_features = ['item_name_tfidf_1', 'item_name_tfidf_2',\n                  'item_name_tfidf_3', 'item_name_tfidf_4', 'item_name_tfidf_5',\n                  'shop_name_tfidf_1','shop_name_tfidf_2',  'shop_name_tfidf_3', \n                  'shop_name_tfidf_4','shop_name_tfidf_5']\n\nXtrain = df[df['date_block_num']<34][tfidf_features]\nXtest = df[df['date_block_num']==34][tfidf_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NMF_1 = NMF(n_components= 5, init=None, solver='cd', beta_loss='frobenius', tol=0.0001, max_iter= 50)\nNMF_1.fit(df[tfidf_features]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain = NMF_1.transform(Xtrain)\nXtest = NMF_1.transform(Xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(tfidf_features, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_reduced_df = pd.concat([pd.DataFrame(Xtrain), pd.DataFrame(Xtest)], axis=0)\ntfidf_reduced_df.columns = ['tfidf_interaction_1', 'tfidf_interaction_2', 'tfidf_interaction_3',\n                            'tfidf_interaction_4', 'tfidf_interaction_5']\ntfidf_reduced_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in tfidf_reduced_df.columns:\n    print(col)\n    test1 = tfidf_reduced_df[col].values\n    df[col] = test1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Fitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df[df.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_train = df[df.date_block_num < 33]['item_cnt_month']\nX_valid = df[df.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = df[df.date_block_num == 33]['item_cnt_month']\nX_test = df[df.date_block_num == 34].drop(['item_cnt_month'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, Y_train)\nlgb_valid = lgb.Dataset(X_valid, Y_valid)\n\nparams = {\n    'boosting_type': 'dart',\n    'metric': 'l2_root', # RMSE\n    'verbose': 1,\n    'seed': 0,\n    'max_depth': 8,\n    'learning_rate': 0.1,\n    'reg_lambda': 2.0,\n    'reg_alpha': 2.0,\n    'subsample': 0.7,\n    'num_leaves': 20,\n    'feature_fraction': 0.8,\n    'drop_rate': 0.2\n}\n\nmodel_lgbm = lgb.train(params, lgb_train, num_boost_round=1000, valid_sets=lgb_valid,\n                       early_stopping_rounds=200, categorical_feature=cat_features,\n                       verbose_eval=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sqrt(mean_squared_error(Y_valid, model_lgbm.predict(X_valid))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(model_lgbm, max_num_features=15, figsize=(6,6), title='Feature importance (LightGBM)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler().fit(X_train)\nX_train_std = scaler.transform(X_train)\nX_valid_std = scaler.transform(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del Xtrain, Xtest, tfidf_reduced_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_lgbm = model_lgbm.predict(X_test).clip(0, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame({'ID': test.index, 'item_cnt_month': Y_test_lgbm})\ntemp.to_csv('submission1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Few Changes made, the best score with previous version was 0.96**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}