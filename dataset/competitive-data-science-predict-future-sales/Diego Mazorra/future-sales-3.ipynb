{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random as rd # generating random numbers\nimport datetime # manipulating date formats\n# Viz\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # for prettier plots","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\nitems=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\nshops=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\ncats=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\ntrain=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\ntest=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#telss the unique values in each of the columns\n# some items have the same price., there are 34 months, 60 different shops, about 21,000 different items\ntrain.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cats.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cats.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so the different category of items have thier unique names, but looking at rows 1 - 7 it looks like they have the same initials\nbut its in russia, this can be helpful in feature engineering, maybe we can have a new category with the items having a particular initials"},{"metadata":{"trusted":false},"cell_type":"code","source":"items.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"items.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"shops.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"shops.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from looking at some rows they have similar initials this may be due to the shops located in the same location or it might be a single shop divided into sub-shops, probably check the interpretation of the names in english"},{"metadata":{},"cell_type":"markdown","source":"Looks like there is no missing values in any of the dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can generate columns like the year, weekends and weekdays, maybe sth like festive periods,"},{"metadata":{},"cell_type":"markdown","source":"## Checking Outliers"},{"metadata":{"trusted":false},"cell_type":"code","source":"#train.item_price.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see the price of a data being -1 and also the highest price is 307980, this might be an outlier\nChecking!!"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nflierprops = dict(marker='o', markerfacecolor='purple', markersize=6,\n                  linestyle='none', markeredgecolor='black')\nsns.boxplot(x=train.item_cnt_day, flierprops=flierprops)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price, flierprops=flierprops)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = train[(train.item_price < 300000 )& (train.item_cnt_day < 1000)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = train[train.item_price > 0].reset_index(drop = True)\ntrain.loc[train.item_cnt_day < 1, \"item_cnt_day\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# duplicates of each other. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n# Жуковский ул. Чкалова 39м²\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"shops.loc[ shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"',\"shop_name\" ] = 'СергиевПосад ТЦ \"7Я\"'\nshops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] )\nshops[\"category\"] = shops.shop_name.str.split(\" \").map( lambda x: x[1] )\nshops.loc[shops.city == \"!Якутск\", \"city\"] = \"Якутск\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"category = []\nfor cat in shops.category.unique():\n    if len(shops[shops.category == cat]) >= 5:\n        category.append(cat)\nshops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nshops[\"shop_category\"] = LabelEncoder().fit_transform( shops.category )\nshops[\"shop_city\"] = LabelEncoder().fit_transform( shops.city )\nshops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cats[\"type_code\"] = cats.item_category_name.apply( lambda x: x.split(\" \")[0] ).astype(str)\ncats.loc[ (cats.type_code == \"Игровые\")| (cats.type_code == \"Аксессуары\"), \"category\" ] = \"Игры\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"category = []\nfor cat in cats.type_code.unique():\n    if len(cats[cats.type_code == cat]) >= 5: \n        category.append( cat )\ncats.type_code = cats.type_code.apply(lambda x: x if (x in category) else \"etc\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cats.type_code = LabelEncoder().fit_transform(cats.type_code)\ncats[\"split\"] = cats.item_category_name.apply(lambda x: x.split(\"-\"))\ncats[\"subtype\"] = cats.split.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\ncats[\"subtype_code\"] = LabelEncoder().fit_transform( cats[\"subtype\"] )\ncats = cats[[\"item_category_id\", \"subtype_code\", \"type_code\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Cleaning Item Data¶\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import re\ndef name_correction(x):\n    x = x.lower() # all letters lower case\n    x = x.partition('[')[0] # partition by square brackets\n    x = x.partition('(')[0] # partition by curly brackets\n    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x) # remove special characters\n    x = x.replace('  ', ' ') # replace double spaces with single spaces\n    x = x.strip() # remove leading and trailing white space\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#cleaning item names\n# split item names by first bracket\nitems[\"name1\"], items[\"name2\"] = items.item_name.str.split(\"[\", 1).str\nitems[\"name1\"], items[\"name3\"] = items.item_name.str.split(\"(\", 1).str\n\n# replace special characters and turn to lower case\nitems[\"name2\"] = items.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\nitems[\"name3\"] = items.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n\n# fill nulls with '0'\nitems = items.fillna('0')\n\nitems[\"item_name\"] = items[\"item_name\"].apply(lambda x: name_correction(x))\n\n# return all characters except the last if name 2 is not \"0\" - the closing bracket\nitems.name2 = items.name2.apply( lambda x: x[:-1] if x !=\"0\" else \"0\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Clean item type\nitems[\"type\"] = items.name2.apply(lambda x: x[0:8] if x.split(\" \")[0] == \"xbox\" else x.split(\" \")[0] )\nitems.loc[(items.type == \"x360\") | (items.type == \"xbox360\") | (items.type == \"xbox 360\") ,\"type\"] = \"xbox 360\"\nitems.loc[ items.type == \"\", \"type\"] = \"mac\"\nitems.type = items.type.apply( lambda x: x.replace(\" \", \"\") )\nitems.loc[ (items.type == 'pc' )| (items.type == 'pс') | (items.type == \"pc\"), \"type\" ] = \"pc\"\nitems.loc[ items.type == 'рs3' , \"type\"] = \"ps3\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"group_sum = items.groupby([\"type\"]).agg({\"item_id\": \"count\"})\ngroup_sum = group_sum.reset_index()\ndrop_cols = []\nfor cat in group_sum.type.unique():\n    if group_sum.loc[(group_sum.type == cat), \"item_id\"].values[0] <40:\n        drop_cols.append(cat)\nitems.name2 = items.name2.apply( lambda x: \"other\" if (x in drop_cols) else x )\nitems = items.drop([\"type\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"items.name2 = LabelEncoder().fit_transform(items.name2)\nitems.name3 = LabelEncoder().fit_transform(items.name3)\n\nitems.drop([\"item_name\", \"name1\"],axis = 1, inplace= True)\nitems.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from itertools import product\nimport time\nts = time.time()\nmatrix = []\ncols  = [\"date_block_num\", \"shop_id\", \"item_id\"]\nfor i in range(34):\n    sales = train[train.date_block_num == i]\n    matrix.append( np.array(list( product( [i], sales.shop_id.unique(), sales.item_id.unique() ) ), dtype = np.int16) )\n\nmatrix = pd.DataFrame( np.vstack(matrix), columns = cols )\nmatrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8)\nmatrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8)\nmatrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16)\nmatrix.sort_values( cols, inplace = True )\ntime.time()- ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# add revenue to train df\ntrain[\"revenue\"] = train[\"item_cnt_day\"] * train[\"item_price\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# add revenue to train df\ntrain[\"revenue\"] = train[\"item_cnt_day\"] * train[\"item_price\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = train.groupby( [\"date_block_num\", \"shop_id\", \"item_id\"] ).agg( {\"item_cnt_day\": [\"sum\"]} )\ngroup.columns = [\"item_cnt_month\"]\ngroup.reset_index( inplace = True)\nmatrix = pd.merge( matrix, group, on = cols, how = \"left\" )\nmatrix[\"item_cnt_month\"] = matrix[\"item_cnt_month\"].fillna(0).astype(np.float16)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test[\"date_block_num\"] = 34\ntest[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\ntest[\"shop_id\"] = test.shop_id.astype(np.int8)\ntest[\"item_id\"] = test.item_id.astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\n\nmatrix = pd.concat([matrix, test.drop([\"ID\"],axis = 1)], ignore_index=True, sort=False, keys=cols)\nmatrix.fillna( 0, inplace = True )\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matrix = pd.merge( matrix, shops, on = [\"shop_id\"], how = \"left\" )\nmatrix = pd.merge(matrix, items, on = [\"item_id\"], how = \"left\")\nmatrix = pd.merge( matrix, cats, on = [\"item_category_id\"], how = \"left\" )\nmatrix[\"shop_city\"] = matrix[\"shop_city\"].astype(np.int8)\nmatrix[\"shop_category\"] = matrix[\"shop_category\"].astype(np.int8)\nmatrix[\"item_category_id\"] = matrix[\"item_category_id\"].astype(np.int8)\nmatrix[\"subtype_code\"] = matrix[\"subtype_code\"].astype(np.int8)\nmatrix[\"name2\"] = matrix[\"name2\"].astype(np.int8)\nmatrix[\"name3\"] = matrix[\"name3\"].astype(np.int16)\nmatrix[\"type_code\"] = matrix[\"type_code\"].astype(np.int8)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Feature Ingenering\n\n# Define a lag feature function\ndef lag_feature( df,lags, cols ):\n    for col in cols:\n        print(col)\n        tmp = df[[\"date_block_num\", \"shop_id\",\"item_id\",col ]]\n        for i in lags:\n            shifted = tmp.copy()\n            shifted.columns = [\"date_block_num\", \"shop_id\", \"item_id\", col + \"_lag_\"+str(i)]\n            shifted.date_block_num = shifted.date_block_num + i\n            df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\nmatrix = lag_feature( matrix, [1,2,3], [\"item_cnt_month\"] )\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby( [\"date_block_num\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\ngroup.columns = [\"date_avg_item_cnt\"]\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = [\"date_block_num\"], how = \"left\")\nmatrix.date_avg_item_cnt = matrix[\"date_avg_item_cnt\"].astype(np.float16)\nmatrix = lag_feature( matrix, [1], [\"date_avg_item_cnt\"] )\nmatrix.drop( [\"date_avg_item_cnt\"], axis = 1, inplace = True )\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix.date_item_avg_item_cnt = matrix['date_item_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1,2,3], ['date_item_avg_item_cnt'])\nmatrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\ngroup.columns = [\"date_shop_avg_item_cnt\"]\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\"], how = \"left\")\nmatrix.date_avg_item_cnt = matrix[\"date_shop_avg_item_cnt\"].astype(np.float16)\nmatrix = lag_feature( matrix, [1,2,3], [\"date_shop_avg_item_cnt\"] )\nmatrix.drop( [\"date_shop_avg_item_cnt\"], axis = 1, inplace = True )\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby( [\"date_block_num\",\"shop_id\",\"item_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\ngroup.columns = [\"date_shop_item_avg_item_cnt\"]\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\",\"item_id\"], how = \"left\")\nmatrix.date_avg_item_cnt = matrix[\"date_shop_item_avg_item_cnt\"].astype(np.float16)\nmatrix = lag_feature( matrix, [1,2,3], [\"date_shop_item_avg_item_cnt\"] )\nmatrix.drop( [\"date_shop_item_avg_item_cnt\"], axis = 1, inplace = True )\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_subtype_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\nmatrix.date_shop_subtype_avg_item_cnt = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_shop_subtype_avg_item_cnt'])\nmatrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'shop_city']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_city_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', \"shop_city\"], how='left')\nmatrix.date_city_avg_item_cnt = matrix['date_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_city_avg_item_cnt'])\nmatrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'item_id', 'shop_city']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_city_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_city'], how='left')\nmatrix.date_item_city_avg_item_cnt = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_item_city_avg_item_cnt'])\nmatrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = train.groupby( [\"item_id\"] ).agg({\"item_price\": [\"mean\"]})\ngroup.columns = [\"item_avg_item_price\"]\ngroup.reset_index(inplace = True)\n\nmatrix = matrix.merge( group, on = [\"item_id\"], how = \"left\" )\nmatrix[\"item_avg_item_price\"] = matrix.item_avg_item_price.astype(np.float16)\n\n\ngroup = train.groupby( [\"date_block_num\",\"item_id\"] ).agg( {\"item_price\": [\"mean\"]} )\ngroup.columns = [\"date_item_avg_item_price\"]\ngroup.reset_index(inplace = True)\n\nmatrix = matrix.merge(group, on = [\"date_block_num\",\"item_id\"], how = \"left\")\nmatrix[\"date_item_avg_item_price\"] = matrix.date_item_avg_item_price.astype(np.float16)\nlags = [1, 2, 3]\nmatrix = lag_feature( matrix, lags, [\"date_item_avg_item_price\"] )\nfor i in lags:\n    matrix[\"delta_price_lag_\" + str(i) ] = (matrix[\"date_item_avg_item_price_lag_\" + str(i)]- matrix[\"item_avg_item_price\"] )/ matrix[\"item_avg_item_price\"]\n\ndef select_trends(row) :\n    for i in lags:\n        if row[\"delta_price_lag_\" + str(i)]:\n            return row[\"delta_price_lag_\" + str(i)]\n    return 0\n\nmatrix[\"delta_price_lag\"] = matrix.apply(select_trends, axis = 1)\nmatrix[\"delta_price_lag\"] = matrix.delta_price_lag.astype( np.float16 )\nmatrix[\"delta_price_lag\"].fillna( 0 ,inplace = True)\n\nfeatures_to_drop = [\"item_avg_item_price\", \"date_item_avg_item_price\"]\nfor i in lags:\n    features_to_drop.append(\"date_item_avg_item_price_lag_\" + str(i) )\n    features_to_drop.append(\"delta_price_lag_\" + str(i) )\nmatrix.drop(features_to_drop, axis = 1, inplace = True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ngroup = train.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"revenue\": [\"sum\"] })\ngroup.columns = [\"date_shop_revenue\"]\ngroup.reset_index(inplace = True)\n\nmatrix = matrix.merge( group , on = [\"date_block_num\", \"shop_id\"], how = \"left\" )\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n\ngroup = group.groupby([\"shop_id\"]).agg({ \"date_block_num\":[\"mean\"] })\ngroup.columns = [\"shop_avg_revenue\"]\ngroup.reset_index(inplace = True )\n\nmatrix = matrix.merge( group, on = [\"shop_id\"], how = \"left\" )\nmatrix[\"shop_avg_revenue\"] = matrix.shop_avg_revenue.astype(np.float32)\nmatrix[\"delta_revenue\"] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\nmatrix[\"delta_revenue\"] = matrix[\"delta_revenue\"]. astype(np.float32)\n\nmatrix = lag_feature(matrix, [1], [\"delta_revenue\"])\nmatrix[\"delta_revenue_lag_1\"] = matrix[\"delta_revenue_lag_1\"].astype(np.float32)\nmatrix.drop( [\"date_shop_revenue\", \"shop_avg_revenue\", \"delta_revenue\"] ,axis = 1, inplace = True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matrix[\"month\"] = matrix[\"date_block_num\"] % 12\ndays = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\nmatrix[\"days\"] = matrix[\"month\"].map(days).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\nmatrix[\"item_shop_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\",\"shop_id\"])[\"date_block_num\"].transform('min')\nmatrix[\"item_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\"])[\"date_block_num\"].transform('min')\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\nmatrix = matrix[matrix[\"date_block_num\"] > 3]\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matrix.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Modeling","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import gc\nimport pickle\nfrom xgboost import XGBRegressor\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = matrix.copy()\ndel matrix\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_train = data[data.date_block_num < 33]['item_cnt_month']\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Y_train = Y_train.clip(0, 20)\nY_valid = Y_valid.clip(0, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"del data\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\n\nmodel = XGBRegressor(\n    max_depth=10,\n    n_estimators=1000,\n    min_child_weight=0.5, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,\n#     tree_method='gpu_hist',\n    seed=42)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds = 20)\n\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Y_pred = model.predict(X_valid).clip(0, 20)\nY_test = model.predict(X_test).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('/home/diegomazorra/Documentos/Cursos/how_win_comp/data/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nplot_features(model, (10,14))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}