{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Введение (introduction)"},{"metadata":{},"cell_type":"markdown","source":"Перед нами ежедневные исторические данные о продажах. \nЗадача состоит в том, чтобы спрогнозировать общее количество продуктов, проданных в каждом магазине для тестового набора. Список магазинов и продуктов немного меняется каждый месяц - создание надежной модели, способной справиться с такими ситуациями, является частью задачи."},{"metadata":{},"cell_type":"markdown","source":"**File descriptions**\n* sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.\n* test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.\n* \n* items.csv - дополнительная информация о товарах / продуктах.\n* item_categories.csv  - дополнительная информация о категориях товаров.\n* shops.csv- дополнительная информация о магазинах\n\n**Data fields**\n* ID - an Id that represents a (Shop, Item) tuple within the test set\n* shop_id - unique identifier of a shop\n* item_id - unique identifier of a product\n* item_category_id - unique identifier of item category\n* item_cnt_day - number of products sold (мой прогноз - сумма этой переменной) \n* item_price - current price of an item\n* date - date in format dd/mm/yyyy\n* date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n* item_name - name of item\n* shop_name - name of shop\n* item_category_name - name of item category\n\n***Оценка качества модели будет производиться root mean squared error (RMSE)***"},{"metadata":{},"cell_type":"markdown","source":"# Загрузка данных"},{"metadata":{},"cell_type":"markdown","source":"Загружаем библиотеки и читаем наборы данных для исследовательского анализа и моделирования.\nПосмотрим, какую информацию передают эти данные."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\ncategories = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\nsubmission = pd.read_csv('../input/competitive-data-science-predict-future-sales/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как мы видим, тестовый набор отличается по размеру и структуре по сравнению с обучающим набором. \nУ нас есть функции \"shop_id\" и \"item_id\" в тестовом наборе, которые также присутствуют в обучающем наборе. \nКаждое наблюдение в тестовом наборе имеет связанный с ним идентификатор. Если мы посмотрим на наш файл отправки, нам нужно будет отправить ежемесячный счет (item_cnt_month) для этого конкретного идентификатора. Это означает, что нам нужно предсказать число для ежемесячного количества продажи конкретного товара в конкретном магазине."},{"metadata":{},"cell_type":"markdown","source":"# Визуальный анализ данных"},{"metadata":{},"cell_type":"markdown","source":"Давайте посмотрим на распределение обучающего и тестового набора, чтобы лучше понять наш набор данных и проверить его на совпадение или отсутствие."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18,9))\nplt.subplots_adjust(hspace=.5)\n\nplt.subplot2grid((3,3), (0,0), colspan = 3)\ntrain['shop_id'].value_counts(normalize=True).plot(kind='bar', alpha=0.7)\nplt.title('Shop ID Values in the Training Set (Normalized)')\n\nplt.subplot2grid((3,3), (1,0))\ntrain['item_id'].plot(kind='hist', alpha=0.7)\nplt.title('Item ID Histogram')\n\nplt.subplot2grid((3,3), (1,1))\ntrain['item_price'].plot(kind='hist', alpha=0.7, color='orange')\nplt.title('Item Price Histogram')\n\nplt.subplot2grid((3,3), (1,2))\ntrain['item_cnt_day'].plot(kind='hist', alpha=0.7, color='green')\nplt.title('Item Count Day Histogram')\n\nplt.subplot2grid((3,3), (2,0), colspan = 3)\ntrain['date_block_num'].value_counts(normalize=True).plot(kind='bar', alpha=0.7)\nplt.title('Month (date_block_num) Values in the Training Set (Normalized)')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Приведенные выше графики являются хорошим способом взглянуть на необработанное распределение тестового набора данных. Вот некоторые наблюдения:\n\n* У нас есть 60 'shop_id', но в наборе данных они распределены неравномерно. Четыре (<7%) из этих магазинов составляют ~25% этого набора данных. Это магазины (31, 25, 54, 28).\n\n* Идентификаторы элементов, по-видимому, имеют вариации по частоте. Пока нельзя увидеть этому причину, но мы можем исследовать это дальше. Некоторые категории товаров обязательно будут продаваться лучше и, возможно, товары одной и той же категории будут ближе друг к другу в том, что касается их распределения идентификаторов\n\n* Из огромных пустых пространств в гистограммах \"item_price\" и \"item_cnt_day\" мы можем сделать вывод, что в их распределении есть выбросы. Давайте напишем ниже простой код, чтобы определить значение этих выбросов.\n\n* Построив график отдельных месяцев с января 2013 года по октябрь 2015 года можно заметить, что блок 12 месяца, соответствующий декабрю 2013 года, имел наибольшее количество продаж. 23-й месяц, который соответствует декабрю 2014 года, имел второе по величине количество продаж. Ниже будем использовать несколько лучших графиков для наблюдения за ежемесячными тенденциями продаж."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=train.item_cnt_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=train.item_price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Подготовка данных (Data preporation)"},{"metadata":{},"cell_type":"markdown","source":"**1. Работа с выбросами и их исключение из данных**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_id'].value_counts(ascending=False)[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Взглянув на товар id 20949, который был продан больше всего раз, можно сказать, что это \"пакет\""},{"metadata":{"trusted":true},"cell_type":"code","source":"items.loc[items['item_id']==20949]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories.loc[categories['item_category_id']==71]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[test['item_id']==20949].head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_cnt_day'].sort_values(ascending=False)[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['item_cnt_day'] == 2169]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Товар ID 11373 был продан 2169 раз в магазине 12 в один октябрьский день. \nДавайте еще немного осмотрим этот выброс."},{"metadata":{"trusted":true},"cell_type":"code","source":"items[items['item_id'] == 11373]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на другие дневные продажи этого товара"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['item_id'] == 11373].head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы видим, что товар с ID 11373 обычно продается значительно меньше. \n\nЯ вычислила, что медиана его значения 'item_cnt_day' равна 4. Это подтверждает, что высокое значение 2169 является аномалией, и мы должны избавиться от него."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['item_cnt_day'] < 800]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_price'].sort_values(ascending=False)[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Еще один выброс.\n\nНа этот раз из \"item_price\". Рассмотрим его прежде чем удалять его."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['item_price'] == 307980]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items[items['item_id'] == 6066]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Это антивирус, проданный 522 людям, и цена, вероятно, равна стоимости одной установки, умноженной на 522. \nПосмотрим, есть ли в нашем обучающем наборе другие транзакции, связанные с этим программным обеспечением."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['item_id'] == 6066]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Нет, а значит это Выброс - единственная транзакция. \nВполне оправданно убрать это наблюдение из тренировочного набора."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['item_price'] < 100000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь проверим поле \"item_price\" на наличие выбросов по низким ценам"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_price'].sort_values()[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Существует значение -1. Это ошибка и мы должны проверить это наблюдение дальше"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['item_price'] == -1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Есть ли другие наблюдения для этого предмета (2973), которые могут помочь нам определить его цену"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['item_id'] == 2973].head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Действительно, этот предмет, похоже, был продан по довольно высокой цене, поэтому его значение -1 должно быть изменено. Мы должны заменить его медианой его цены, но это должно быть рассчитано для магазина (ID 12), для которого этот выброс существует. Если есть другие продажи этого товара в этом магазине за тот же месяц (date_block_num 4), то мы должны рассчитать медиану, используя это"},{"metadata":{"trusted":true},"cell_type":"code","source":"price_correction = train[(train['shop_id'] == 32) & (train['item_id'] == 2973) & (train['date_block_num'] == 4) & (train['item_price'] > 0)].item_price.median()\ntrain.loc[train['item_price'] < 0, 'item_price'] = price_correction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. Распределение Тестовых Наборов**"},{"metadata":{},"cell_type":"markdown","source":"Теперь давайте проведем анализ распределения тестового набора и посмотрим, сможем ли мы обнаружить какие-либо различия"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18,8))\nplt.subplots_adjust(hspace=.5)\n\nplt.subplot2grid((3,3), (0,0), colspan = 3)\ntest['shop_id'].value_counts(normalize=True).plot(kind='bar', alpha=0.7)\nplt.title('Shop ID Values in the Test Set (Normalized)')\n\nplt.subplot2grid((3,3), (1,0))\ntest['item_id'].plot(kind='hist', alpha=0.7)\nplt.title('Item ID Histogram - Test Set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Идентификаторы магазина распределены равномерно, в отличие от тренировочного набора. Размер шрифта меток быстро говорит, что в тестовом наборе отсутствуют определенные идентификаторы магазина, так как бары в графике обучающего набора \"shop_id\" были более плотно упакованы.\n2. В то время как идентификаторы элементов на гистограмме сгруппированы, пики в тестовом наборе меньше. Тестовый набор гораздо меньше по форме, чем обучающий, и, естественно, значения частоты значительно ниже. Трудно сделать больше выводов из этой гистограммы.\nПохоже, что некоторые значения shop_id и item_id полностью отсутствуют в тестовом наборе. Давайте посмотрим поближе и добавим некоторые цифры или проценты к этим отсутствующим значениям."},{"metadata":{},"cell_type":"markdown","source":"**3. Анализ магазинов**"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_train = train['shop_id'].nunique()\nshops_test = test['shop_id'].nunique()\nprint('Shops in Training Set: ', shops_train)\nprint('Shops in Test Set: ', shops_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Однако это не означает, что обучающий набор содержит все магазины, присутствующие в тестовом наборе. Для этого нам нужно посмотреть, присутствует ли каждый элемент тестового набора в обучающем наборе. Давайте напишем простой код, чтобы увидеть, является ли список тестовых наборов подмножеством списка обучающих наборов"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_train_list = list(train['shop_id'].unique())\nshops_test_list = list(test['shop_id'].unique())\n\nflag = 0\nif(set(shops_test_list).issubset(set(shops_train_list))): \n    flag = 1\n      \nif (flag) : \n    print (\"Да, список-это подмножество других.\") \nelse : \n    print (\"Нет, список-это не подмножество других.\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Удаляем дубликаты магазинов**"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['shop_id'] == 0, 'shop_id'] = 57\ntest.loc[test['shop_id'] == 0, 'shop_id'] = 57\n\ntrain.loc[train['shop_id'] == 1, 'shop_id'] = 58\ntest.loc[test['shop_id'] == 1, 'shop_id'] = 58\n\ntrain.loc[train['shop_id'] == 10, 'shop_id'] = 11\ntest.loc[test['shop_id'] == 10, 'shop_id'] = 11\n\ntrain.loc[train['shop_id'] == 40, 'shop_id'] = 39\ntest.loc[test['shop_id'] == 40, 'shop_id'] = 39\n\ntrain.loc[train['shop_id'] == 23, 'shop_id'] = 24\ntest.loc[test['shop_id'] == 23, 'shop_id'] = 24","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Извлечение города из названия магазина**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cities = shops['shop_name'].str.split(' ').map(lambda row: row[0])\ncities.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops['city'] = shops['shop_name'].str.split(' ').map(lambda row: row[0])\nshops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nle.fit_transform(shops['city'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь просто добавим эти коды в фрейм данных магазинов. \nМы можем избавиться от 'shop_name' и 'city' сохраняя 'shop_id' и 'city_label'"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops['city_label'] = le.fit_transform(shops['city'])\nshops.drop(['shop_name', 'city'], axis = 1, inplace = True)\nshops.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Анализ товаров**"},{"metadata":{"trusted":true},"cell_type":"code","source":"items_train = train['item_id'].nunique()\nitems_test = test['item_id'].nunique()\nprint('Items in Training Set: ', items_train)\nprint('Items in Test Set: ', items_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В обучающем наборе гораздо больше элементов, чем в тестовом, но это не означает, что обучающий набор содержит все элементы тестового набора. Для этого нам нужно посмотреть, присутствует ли каждый элемент тестового набора в обучающем наборе."},{"metadata":{"trusted":true},"cell_type":"code","source":"items_train_list = list(train['item_id'].unique())\nitems_test_list = list(test['item_id'].unique())\n\nflag = 0\nif(set(items_test_list).issubset(set(items_train_list))): \n    flag = 1\n      \nif (flag) : \n    print (\"Да, список-это подмножество других.\") \nelse : \n    print (\"Нет, список-это не подмножество других.\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Это означает, что есть определенные элементы, которые присутствуют в тестовом наборе, но полностью отсутствуют в тренировочном наборе. Попробуем это исправить"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(items_test_list).difference(items_train_list))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Есть 363 элемента, которые присутствуют в тестовом наборе, но полностью отсутствуют в тренировочном наборе. Это не означает, что прогноз продаж по этим товарам должен быть нулевым, поскольку новые товары могут быть добавлены на рынок, или мы просто не располагали данными по этим товарам раньше. Однако возникают вопросы: как их предсказывать?"},{"metadata":{},"cell_type":"markdown","source":"Прежде чем мы это сделаем, давайте узнаем больше о 5100 элементах в тестовом наборе. К каким категориям они относятся? Для каких категорий мы не должны делать прогнозы в тестовом наборе"},{"metadata":{"trusted":true},"cell_type":"code","source":"categories_in_test = items.loc[items['item_id'].isin(sorted(test['item_id'].unique()))].item_category_id.unique()\ncategories.loc[~categories['item_category_id'].isin(categories_in_test)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Группировка общих категорий и извлечение подкатегорий**"},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\n\nmain_categories = categories['item_category_name'].str.split('-')\ncategories['main_category_id'] = main_categories.map(lambda row: row[0].strip())\ncategories['main_category_id'] = le.fit_transform(categories['main_category_id'])\n\ncategories['sub_category_id'] = main_categories.map(lambda row: row[1].strip() if len(row) > 1 else row[0].strip())\ncategories['sub_category_id'] = le.fit_transform(categories['sub_category_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tеперь произведем обработку **'date'** для создания различных столбцов, связанных с датой, которые могут дать нам большое представление о данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\ntrain['date'] = pd.to_datetime(train['date'],format = '%d.%m.%Y')\nprint('Min date from train set: %s' % train['date'].min().date())\nprint('Max date from train set: %s' % train['date'].max().date())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print min and max num assigned to the months\nprint('Min date_block_num from train set: %s' % train['date_block_num'].min())\nprint('Max date_block_num from train set: %s' % train['date_block_num'].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обучающие данные находятся в периоде с января 2013 года (date_block_num 0) по октябрь 2015 года (date_block_num 33).\nМы должны использовать запись продаж за последние 34 месяца, чтобы предсказать 35-й месяц, который является ноябрь 2015 (date_block_num 34)."},{"metadata":{},"cell_type":"markdown","source":"Так как ответом в задании Predict Future Sales является предсказание совокупной суммы продаж в каждом магазине в Ноябре 2015 на тестовой выборке, найдем количество продаж в месяц на магазин"},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Тестирование генерации декартового произведения за январь 2013 года\nshops_in_jan = train.loc[train['date_block_num']==0, 'shop_id'].unique()\nitems_in_jan = train.loc[train['date_block_num']==0, 'item_id'].unique()\njan = list(product(*[shops_in_jan, items_in_jan, [0]]))\nprint(len(jan))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видно, январь 2013 года содержит 357060 пересечений магазинов и предметов. \nБольшинство из них не будут иметь продаж, и мы можем проверить это, как только проверим наш обучающий набор, который был сгруппирован по месяцам, чтобы увидеть, какие комбинации \"товаров\" и \"магазинов\" имеют количество продаж, связанных с ними.\n\nПеред этим нам нужно сгенерировать это декартово произведение за все 33 месяца в обучающем наборе. Прежде чем сгенерировать его для всех месяцев, я сгенерирую его для февраля 2013 года, объединю его с январем 2013 года и создам фрейм данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_in_feb = train.loc[train['date_block_num']==1, 'shop_id'].unique()\nitems_in_feb = train.loc[train['date_block_num']==1, 'item_id'].unique()\nfeb = list(product(*[shops_in_feb, items_in_feb, [1]]))\nprint(len(feb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cartesian_test = []\ncartesian_test.append(np.array(jan))\ncartesian_test.append(np.array(feb))\ncartesian_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"При попытке создать фрейм данных из списков января и февраля закончилась память. Хитрость заключалась в том, чтобы преобразовать списки в массив numpy. Удобный метод numpy 'vstack' сформирует объект cartesian_test правильным образом, так что мы сможем преобразовать его в длинный фрейм данных формы."},{"metadata":{"trusted":true},"cell_type":"code","source":"cartesian_test = np.vstack(cartesian_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cartesian_test_df = pd.DataFrame(cartesian_test, columns = ['shop_id', 'item_id', 'date_block_num'])\ncartesian_test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cartesian_test_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тест прошел успешно - все работает и не \"кушает\" память. Теперь напишем небольшой скрипт для остальных месяцев"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\n\ndef downcast_dtypes(df):\n    '''\n        Меняем типы столбцов в датафрейме: \n                \n                `float64` type to `float32`\n                `int64`   type to `int32`\n    '''\n    \n    # Select columns to downcast\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n    \n    # Downcast\n    df[float_cols] = df[float_cols].astype(np.float16)\n    df[int_cols]   = df[int_cols].astype(np.int16)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"months = train['date_block_num'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cartesian = []\nfor month in months:\n    shops_in_month = train.loc[train['date_block_num']==month, 'shop_id'].unique()\n    items_in_month = train.loc[train['date_block_num']==month, 'item_id'].unique()\n    cartesian.append(np.array(list(product(*[shops_in_month, items_in_month, [month]])), dtype='int32'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cartesian_df = pd.DataFrame(np.vstack(cartesian), columns = ['shop_id', 'item_id', 'date_block_num'], dtype=np.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cartesian_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5. Агрегирование продаж до месячного уровня и отсечение целевой переменной**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train.groupby(['shop_id', 'item_id', 'date_block_num'])['item_cnt_day'].sum().rename('item_cnt_month').reset_index()\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь нужно объединить два фрейма данных\nCтолбцы, которые мы хотим объединить, являются пересечением shop_id, item_id и data_block_number"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.merge(cartesian_df, x, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"По умолчанию pandas заполняет фреймы данных NaN. Вот почему мы используем fillna для замены всех NaN на ноль"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train['item_cnt_month'] = np.clip(new_train['item_cnt_month'], 0, 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Удаляем из памяти временные переменные"},{"metadata":{"trusted":true},"cell_type":"code","source":"del x\ndel cartesian_df\ndel cartesian\ndel cartesian_test\ndel cartesian_test_df\ndel feb\ndel jan\ndel items_test_list\ndel items_train_list\ndel train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.sort_values(['date_block_num','shop_id','item_id'], inplace = True)\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**6. Добавляем тестовый набор к тренировочному**\n\nВо-первых, давайте вставим функцию data_block_num для тестового набора! Используя метод вставки панд, чтобы поместить этот новый столбец в определенный индекс. Это позволит нам легко связать тестовый набор с обучающим набором, прежде чем мы создадим средние кодировки и функции запаздывания"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.insert(loc=3, column='date_block_num', value=34)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['item_cnt_month'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = new_train.append(test.drop('ID', axis = 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Объединение магазинов, товаров, категорий фреймов данных для добавления метки города, category_id, основной категории и подкатегории"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.merge(new_train, shops, on=['shop_id'], how='left')\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.merge(new_train, items.drop('item_name', axis = 1), on=['item_id'], how='left')\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.merge(new_train, categories.drop('item_category_name', axis = 1), on=['item_category_id'], how='left')\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Generating Lag Features and Mean-Encodings**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_lag(train, months, lag_column):\n    for month in months:\n        # Speed up by grabbing only the useful bits\n        train_shift = train[['date_block_num', 'shop_id', 'item_id', lag_column]].copy()\n        train_shift.columns = ['date_block_num', 'shop_id', 'item_id', lag_column+'_lag_'+ str(month)]\n        train_shift['date_block_num'] += month\n        train = pd.merge(train, train_shift, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del items\ndel categories\ndel shops\ndel test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = downcast_dtypes(new_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc  # сборщик мусора\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Лаг для целевой переменной**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnew_train = generate_lag(new_train, [1,2,3,4,5,6,12], 'item_cnt_month')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Лаг для месячного элемента-целевое среднее значение**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = new_train.groupby(['date_block_num', 'item_id'])['item_cnt_month'].mean().rename('item_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'item_id'], how='left')\nnew_train = generate_lag(new_train, [1,2,3,6,12], 'item_month_mean')\nnew_train.drop(['item_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Лаг для месячного магазина - целевое среднее значение**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = new_train.groupby(['date_block_num', 'shop_id'])['item_cnt_month'].mean().rename('shop_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'shop_id'], how='left')\nnew_train = generate_lag(new_train, [1,2,3,6,12], 'shop_month_mean')\nnew_train.drop(['shop_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Лаг для ежемесячного среднего значения по магазинам-категориям**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = new_train.groupby(['date_block_num', 'shop_id', 'item_category_id'])['item_cnt_month'].mean().rename('shop_category_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\nnew_train = generate_lag(new_train, [1, 2], 'shop_category_month_mean')\nnew_train.drop(['shop_category_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Лаг для месячного среднего значения основной категории**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = new_train.groupby(['date_block_num', 'main_category_id'])['item_cnt_month'].mean().rename('main_category_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'main_category_id'], how='left')\n\nnew_train = generate_lag(new_train, [1], 'main_category_month_mean')\nnew_train.drop(['main_category_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Лаг для среднемесячного значения по подкатегориям**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = new_train.groupby(['date_block_num', 'sub_category_id'])['item_cnt_month'].mean().rename('sub_category_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'sub_category_id'], how='left')\n\nnew_train = generate_lag(new_train, [1], 'sub_category_month_mean')\nnew_train.drop(['sub_category_month_mean'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Создаем прогнозный месяц**"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train['month'] = new_train['date_block_num'] % 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holiday_dict = {\n    0: 6,\n    1: 3,\n    2: 2,\n    3: 8,\n    4: 3,\n    5: 3,\n    6: 2,\n    7: 8,\n    8: 4,\n    9: 8,\n    10: 5,\n    11: 4,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train['holidays_in_month'] = new_train['month'].map(holiday_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = downcast_dtypes(new_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Моделирование"},{"metadata":{},"cell_type":"markdown","source":"Особенности наших данных:\n- данные хорошо структурированы и их много\n- необходимо найти идеальную комбинацию направленную на оптимизацию ПО и железа для получения точных результатов за короткое время с минимальным использованием вычислительных ресурсов\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = new_train[new_train.date_block_num > 11]\n#X_train = new_train[new_train.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n#Y_train = new_train[new_train.date_block_num < 33]['item_cnt_month']\n\n#X_valid = new_train[new_train.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n#Y_valid = new_train[new_train.date_block_num == 33]['item_cnt_month']\n\n#X_test = new_train[new_train.date_block_num == 34].drop(['item_cnt_month'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_na(df):\n    for col in df.columns:\n        if ('_lag_' in col) & (df[col].isnull().any()):\n            df[col].fillna(0, inplace=True)         \n    return df\n\nnew_train = fill_na(new_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lgbtrain():\n    regressor1 = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.01, n_estimators=5000,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n    \n    regressor_1 = regressor1.fit(new_train[new_train.date_block_num < 33].drop(['item_cnt_month'], axis=1).values, \n                               new_train[new_train.date_block_num < 33]['item_cnt_month'].values, \n                               eval_metric = 'rmse', \n                               eval_set = [(new_train[new_train.date_block_num < 33].drop(['item_cnt_month'], axis=1).values, \n                                            new_train[new_train.date_block_num < 33]['item_cnt_month'].values), \n                                           (new_train[new_train.date_block_num == 33].drop(['item_cnt_month'], axis=1).values, \n                                            new_train[new_train.date_block_num == 33]['item_cnt_month'].values)\n                                          ], \n                               verbose=True,\n                               early_stopping_rounds = 50,\n                              )\n    return regressor_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nregressor_1 = lgbtrain()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions1 = regressor_1.predict(new_train[new_train.date_block_num == 34].drop(['item_cnt_month'], axis = 1).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import rcParams\nrcParams['figure.figsize'] = 11.7,8.27\n\ncols = new_train.drop('item_cnt_month', axis = 1).columns\nplt.barh(cols, regressor_1.feature_importances_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgtrain():\n    regressor = xgb.XGBRegressor(n_estimators = 5000,\n                                 learning_rate = 0.01,\n                                 max_depth = 10,\n                                 subsample = 0.5,\n                                 colsample_bytree = 0.5)\n    \n    regressor_ = regressor.fit(new_train[new_train.date_block_num < 33].drop(['item_cnt_month'], axis=1).values, \n                               new_train[new_train.date_block_num < 33]['item_cnt_month'].values, \n                               eval_metric = 'rmse', \n                               eval_set = [(new_train[new_train.date_block_num < 33].drop(['item_cnt_month'], axis=1).values, \n                                            new_train[new_train.date_block_num < 33]['item_cnt_month'].values), \n                                           (new_train[new_train.date_block_num == 33].drop(['item_cnt_month'], axis=1).values, \n                                            new_train[new_train.date_block_num == 33]['item_cnt_month'].values)\n                                          ], \n                               verbose=True,\n                               early_stopping_rounds = 50,\n                              )\n    return regressor_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nregressor_ = xgtrain()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = regressor_.predict(new_train[new_train.date_block_num == 34].drop(['item_cnt_month'], axis = 1).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = 11.7,8.27\n\ncols = new_train.drop('item_cnt_month', axis = 1).columns\nplt.barh(cols, regressor_.feature_importances_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Модели показали хорошие результаты (lgb = 0,96, xgb = 0,928), но XGBoost - король среди алгоритмов по решению задач регрессии.\n\nВысокая результативность алгоритма, т.к.:\n- процессы идут все параллельно\n- использование отсечения деревьев\n- аппаратная оптимизация\n\n*Улучшения алгоритма:*\n1. Регуляризация: Он штрафует сложные модели, используя как регуляризацию LASSO (L1), так и Ridge-регуляризацию (L2), для того, чтобы избежать переобучения.\n2. Работа с разреженными данными: Алгоритм упрощает работу с разреженными данными, в процессе обучения заполняя пропущенные значения в зависимости от значения потерь. К тому же, он позволяет работать с различными узорами разреженности.\n3. Метод взвешенных квантилей: XGBoost использует его для того, чтобы наиболее эффективно находить оптимальные точки разделения в случае работы со взвешенным датасетом.\n4. Кросс-валидация: Алгоритм использует свой собственный метод кросс-валидации на каждой итерации. То есть, нам не нужно отдельно программировать этот поиск и определять количество итераций бустинга для каждого запуска."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['item_cnt_month'] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('sales_faster_learn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLinks\nFileLinks('.')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}