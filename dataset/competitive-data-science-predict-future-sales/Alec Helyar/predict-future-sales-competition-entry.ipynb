{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"file_extension":".py","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Future Sales - First Competition Entry\nI broke this notebook down into multiple stages.  For the sake of RAM, I've error'd out many of the cells which clean the data, but keep the code for others to see.  I used Microsoft's LightGBM for my predictions, and much of the processing was done on a Google cloud instance."},{"execution_count":1,"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"cell_type":"code","source":"import os\nimport re\nimport gc\nimport math\nimport numpy as np\nimport pandas as pd\nimport datetime\nfrom itertools import product\nfrom tqdm import tqdm_notebook as tqdm\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\n\nimport stldecompose\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\n\nskip_processing = False\n\nprint(os.listdir('../input'))","outputs":[]},{"execution_count":23,"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"},"cell_type":"code","source":"sales = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\nsales['date'] = sales.date.apply(lambda x: datetime.datetime.strptime(x, '%d.%m.%Y'))\ncategories = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\nsales.head()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What is the frequency of sales data?\n365"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"len(sales.date.apply(lambda x: x.strftime('%m-%d')).unique())","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How do monthly total sales look?\nWhat months are there?"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"sales.date_block_num.unique()","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"def plot_seasonal(res, axes, axes_col):\n    for i, p in enumerate(['observed', 'trend', 'seasonal', 'resid']):\n        axes[i, axes_col].plot(getattr(res, p))\n        if not axes_col:\n            axes[i, axes_col].set_ylabel(p.title())","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"total_ts = sales.groupby('date_block_num').item_cnt_day.sum()\nfig, axes = plt.subplots(4, 3, figsize=(12, 6))\n\nadd_decomposed = sm.tsa.seasonal_decompose(total_ts.values, freq=12, model=\"additive\")\nmul_decomposed = sm.tsa.seasonal_decompose(total_ts.values, freq=12, model=\"multiplicative\")\nstl_decompose = stldecompose.decompose(total_ts.values, period=12)\n\nplot_seasonal(add_decomposed, axes, 0)\nplot_seasonal(mul_decomposed, axes, 1)\nplot_seasonal(stl_decompose, axes, 2)\n\naxes[0, 0].set_title('Additive')\naxes[0, 1].set_title('Multiplicative')\naxes[0, 2].set_title('Lowess')\nfig.tight_layout();","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How do daily sales by shop look?"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"def plot_monthly_shop_sales(shops_per_row=3, height_scalar=15):\n    shop_sales = sales.groupby(['date', 'shop_id']).agg({'item_cnt_day': 'sum'})\n    shop_sales = shop_sales.unstack(level=0).transpose()\n    \n    num_shops = len(shop_sales.columns)\n    \n    nrows = math.ceil(num_shops / shops_per_row)\n    height = height_scalar * shops_per_row\n    \n    fig, axes = plt.subplots(nrows, 1, figsize=(10, height))\n    for i in range(0, num_shops, shops_per_row):\n        ax_row = axes[int(i / shops_per_row)]\n        shop_sales.iloc[:,i:i+shops_per_row].plot(ax=ax_row, alpha=0.8)\n        ax_row.set_xlabel('')\n        ax_row.set_xticklabels([])\n    fig.tight_layout()\nplot_monthly_shop_sales()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Many shops are limited and infrequent"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"shop_months = [{'shop_id': ind, 'total_months': len(x), 'min': min(x), \n                'max': max(x), 'missing_months': 1 + max(x) - min(x) != len(x)} \n               for ind, x in \n                   sales.groupby(['shop_id']).date_block_num.unique().items()]\nshop_months = pd.DataFrame(shop_months)\nshop_months[shop_months['max'] < 33]","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clearly significant missing data\n## What are these items?"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"items = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nitems.tail()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Item names have inconsistent formats\n* One category per item"},{"metadata":{},"cell_type":"markdown","source":"## What are item categories?"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"categories = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\ncategories.head()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Item names have consistent pattern: Main Category -/() Subcategory"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"categories[categories.item_category_name.apply(lambda x: ' - ' not in x and '(' not in x)]","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ...with some exceptions"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"def get_main_cat(name):\n    if ' - ' in name:\n        return name.split(' - ')[0]\n    elif '(' in name:\n        return name.split('(')[0].strip()\n    return name\ncategories['main_category'] = categories.item_category_name.apply(get_main_cat)\ncategories.main_category.unique()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Better decipher these..."},{"execution_count":null,"metadata":{},"cell_type":"code","source":"translate_categories = {\n    'PC': 'PC',\n    'Аксессуары': 'Accessories',\n    'Цифра': 'Figure',\n    'Доставка товара': 'Delivery of goods',\n    'Игровые консоли': 'Game consoles',\n    'Игры': 'Games',\n    'Игры Android': 'Android games',\n    'Игры MAC': 'Games MAC',\n    'Игры PC': 'Games PC',\n    'Кино, Музыка, Игры': 'Cinema, Music, Games',\n    'Карты оплаты': 'Payment cards',\n    'Кино': 'Cinema',\n    'Билеты': 'Tickets',\n    'Книги': 'Books',\n    'Музыка': 'Music',\n    'Подарки': 'Gifts',\n    'Программы': 'Programs',\n    'Служебные': 'Utilities',\n    'Чистые носители': 'Clean Media',\n    'Элементы питания': 'Batteries'\n}\ncategories['main_category'] = categories.main_category.apply(lambda x: translate_categories[x])\ncategories.main_category.unique()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What are shops?"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"shops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv').set_index('shop_id')\nshops.tail()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shops have a mostly consistent nomenclature: City \"Shop name\"\nNeed to fix some exceptions:"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"_shop_name_replace = {\n    'Выездная Торговля': 'Выездная Торговля \"\"',\n    'Жуковский ул. Чкалова 39м?': 'Жуковский ул. \"Чкалова 39м?\"',\n    'Жуковский ул. Чкалова 39м²': 'Жуковский ул. \"Чкалова 39м²\"',\n    'Воронеж (Плехановская, 13)': 'Воронеж \"Плехановская, 13\"',\n    'Интернет-магазин ЧС': 'Интернет-магазин \"ЧС\"',\n    'Москва Магазин С21': 'Москва \"Магазин С21\"',\n    'Цифровой склад 1С-Онлайн': 'Цифровой склад \"1С-Онлайн\"',\n    'Якутск Орджоникидзе, 56': 'Якутск \"Орджоникидзе, 56\"',\n    '!Якутск Орджоникидзе, 56 фран': 'Якутск \"Орджоникидзе, 56 фран\"',\n    'Воронеж ТРЦ Сити-Парк \"Град\"': 'Воронеж ТРЦ \"Сити-Парк Град\"'\n}\nshops['shop_name'] = shops.shop_name.apply(lambda x: _shop_name_replace[x] if x in _shop_name_replace else x)","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"_shop_type = {\n    'ТЦ': 'Shopping center',\n    'ТРК': 'Dispenser',\n    'ТРЦ': 'Shopping mall',\n    'ТК': 'TC',\n    'МТРЦ': 'MTRC',\n    'Цифровой': 'Digital Warehouse',\n    'Интернет-магазин': 'Online'\n}\n#Get the shop type of the store\n_type = shops.shop_name.apply(lambda x: [w for w in x.split() if w in _shop_type])\nshops['shop_type'] = _type.apply(lambda x: _shop_type[x[0]] if len(x) else np.nan)\n#Get the city from the shop name: !Moscow TC \"Store 26\" -> Moscow\n_city = shops.shop_name.apply(lambda x: x.split(' \"')[0])\n_city = _city.apply(lambda x: \" \".join([w for w in x.split() if w not in _shop_type]))\n_city = _city.str.replace('!', '').str.title()\nshops['shop_city'] = _city\nshops.head()","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"_pop_replace = {\n    '': np.nan, 'Адыгея': 282419, 'Балашиха': 228567, 'Волжский': 320761, 'Вологда': 305397, \n    'Воронеж': 997447, 'Выездная Торговля': np.nan, 'Жуковский Ул.': 107994, 'Казань': 1169000, \n    'Калуга': 328871, 'Коломна': 144838, 'Красноярск': 1007000, 'Курск': 425950, \n    'Москва': 11920000, 'Мытищи': 176825, 'Н.Новгород': 1257000, 'Новосибирск': 1511000, \n    'Омск': 1159000, 'Ростовнадону': 1100000, 'Спб': 4991000, 'Самара': 1170000, \n    'Сергиев Посад': 109076, 'Сургут': 321062, 'Томск': 543596, 'Тюмень': 621918, 'Якутск': 282419, \n    'Уфа': 1075000, 'Химки': 218275, 'Склад': np.nan, 'Чехов': 71301, 'Ярославль': 597161\n}\nshops['shop_city_pop'] = shops.shop_city.map(lambda x: _pop_replace[x])\nshops.head()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finally, what does the test set look like?"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"test = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')\ntest.head()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Need to set date_block_num to 34.  Are there any new items or shops?"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"len(set(test.item_id) - set(sales.item_id)), len(set(test.shop_id) - set(sales.shop_id))","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"363 new items in the test set. No new shops."},{"execution_count":null,"metadata":{},"cell_type":"code","source":"test.shop_id.nunique() * test.item_id.nunique() == test.shape[0]","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test contains all combinations of shops and items, but train contains only combinations which resulted in a sale."},{"metadata":{},"cell_type":"markdown","source":"## Gather all features together\nTest set contains many new items, but train set only includes data where sales have been made.\n\nNeed to index out every shop/item combination for each month."},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\n#Create index for every combination of shop and item per month\nindex = []\nfor dbn in sales.date_block_num.unique():\n    shop_ids = sales[sales.date_block_num == dbn].shop_id.unique()\n    item_ids = sales[sales.date_block_num == dbn].item_id.unique()\n    index.append(np.array(list(product(shop_ids, item_ids, [dbn])), dtype='int16'))\nindex = pd.DataFrame(np.vstack(index), columns=['shop_id', 'item_id', 'date_block_num'])\nindex = index.set_index(['shop_id', 'item_id', 'date_block_num']).index\nindex.shape","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\nsales_train = sales.groupby(['shop_id', 'item_id', 'date_block_num'])\nsales_train = sales_train.agg({'item_cnt_day':'sum'})\nsales_train = sales_train.reindex(index=index)\nsales_train = sales_train.reset_index()\nsales_train = sales_train.rename(columns={'item_cnt_day': 'item_cnt_month'})\nsales_train['item_cnt_month'] = sales_train.item_cnt_month.clip(0, 20).fillna(0)\nsales_train = sales_train.set_index(['shop_id', 'item_id', 'date_block_num'])\nsales_train.shape","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\nsales_train = sales_train.reset_index().merge(items[['item_id', 'item_category_id']], on = 'item_id')\nsales_train.head()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quick Baseline"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\nsales_train = sales_train.fillna(0)\ntrain_X, train_y = sales_train.drop('item_cnt_month', axis=1), sales_train.item_cnt_month.clip(0, 20)\nmodel = lgb.LGBMModel(objective='regression', max_depth=10, n_estimators=100, min_child_weight=0.5, \n                         random_state=40, n_jobs=-1, silent=False)\nmodel.fit(train_X, train_y, eval_metric='rmse')","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\ntest = test.merge(items[['item_id', 'item_category_id']], on='item_id')\ntest = test.set_index('ID')\ntest['date_block_num'] = 34\npred = model.predict(test)\npred = pd.DataFrame(pred, columns=['item_cnt_month']).fillna(0).clip(0, 20)\npred.index.names = ['ID']\npred.to_csv('baseline.csv')","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"def set_type(series, to_float=False):\n    ints = [('int8', 255), ('int16', 65535), ('int32', 2147483647), ('int64', np.inf)]\n    floats = [('float16', 32767), ('float32', 2147483647), ('float64', np.inf)]\n    dtype = series.dtype.name\n    if dtype.startswith('int') and not to_float:\n        maxval = series.abs().max()\n        for key, val in ints:\n            if maxval < val:\n                return series.astype(key)\n    if dtype.startswith('float') or (to_float and dtype.startswith('int')):\n        maxval = series.abs().max()\n        for key, val in floats:\n            if maxval < val:\n                return series.astype(key)\n    if dtype in {'object', 'category'}:\n        l = LabelEncoder()\n        return l.fit_transform(series.fillna('Other')).astype('int8')\n    return series\ndef minimize_memory(df, reset_index=True, to_float=False):\n    if reset_index:\n        df = df.reset_index()\n    for col in df.columns:\n        df[col] = set_type(df[col], to_float)\n    return df","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"del add_decomposed, mul_decomposed, stl_decompose, shop_months, train_X, train_y, model, pred, shop_ids, item_ids\ngc.collect()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building the Model\n#### Feature ideas\n1. Monthly shop and/or item sales lag\n2. Monthly shop and/or item price lag\n3. Number of active days per month\n4. Months/days since last item sale\n5. Months/days since last shop sale\n6. Mean encodings of shops and items\n7. End-of-month percent-of-mean encodings\n8. Shop population, category, and type\n9. Item categories\n10. Monthly revenue lag\n11. Total monthly sale lag\n12. Monhs since first sale\n13. Month number"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\nlags = [1, 2, 3, 6, 12]\n#train\ntrain = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\ntrain = train[train.item_price < 100000]\ntrain = train[train.item_cnt_day <= 1000]\ntrain = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\nmedian = train.loc[(train.shop_id==32) & (train.item_id==2973) & \n                   (train.date_block_num==4) & (train.item_price>0)].item_price.median()\ntrain.loc[train.item_price < 0, 'item_price'] = median\ntrain['item_revenue_month'] = train.item_cnt_day * train.item_price\ntrain = train.groupby(['shop_id', 'item_id', 'date_block_num'])\ntrain = train.agg({'item_cnt_day': 'sum', 'item_price': 'mean', 'item_revenue_month': 'sum'})\ntrain.rename(columns={'item_cnt_day': 'item_cnt_month', 'item_price': 'item_mean_price'}, inplace=True)\ntrain = train.reindex(index=index)\n#test\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\ntest_ids = test.ID\ntest['date_block_num'] = 34\ntest = test.set_index(['shop_id', 'item_id', 'date_block_num']).drop('ID', axis=1)\n#join together\ntrain_test = pd.concat([train, test])\ntrain_test = train_test.fillna(0).astype({'item_cnt_month': 'int32', 'item_mean_price': 'int32'})\ntrain_test = minimize_memory(train_test)\ntrain_test.head()","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"#Remove outliers\nif skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ntrain_test.loc[train_test.shop_id == 0, 'shop_id'] = 57\ntrain_test.loc[train_test.shop_id == 1, 'shop_id'] = 58\ntrain_test.loc[train_test.shop_id == 10, 'shop_id'] = 11\ntrain_test['item_cnt_month'] = train_test.item_cnt_month.fillna(0).clip(0, 20)\ntrain_test.set_index(['shop_id', 'item_id', 'date_block_num'], inplace=True)","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1 & 2. Monthly shop and/or item sales + price lag"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ndef add_aggregate_lags(df, gb_cols, target_col, prefix, astype='float64', \n                       fillna=np.nan, lags=lags, agg='mean'):\n    df = df.reset_index()\n    _gb = df.groupby(gb_cols).agg({target_col: agg})\n    for lag in lags:\n        _temp = _gb.copy()\n        name = prefix + str(lag)\n        _temp.reset_index(inplace=True)\n        _temp['date_block_num'] += lag\n        _temp = _temp.rename(columns={target_col: name})\n        df = pd.merge(df, _temp, on=gb_cols, how='left')\n        df[name] = df[name].fillna(fillna).astype(astype)\n    return df.set_index(['shop_id', 'item_id', 'date_block_num'])\ntrain_test = add_aggregate_lags(train_test, ['shop_id', 'item_id', 'date_block_num'], 'item_cnt_month', \n                                'shop_item_sales_lag_', fillna=0, astype='int16', agg='sum')\ntrain_test = add_aggregate_lags(train_test, ['shop_id', 'date_block_num'], 'item_cnt_month', 'shop_sales_lag_', \n                                fillna=0, astype='int32', agg='sum')\ntrain_test = add_aggregate_lags(train_test, ['item_id', 'date_block_num'], 'item_cnt_month', 'item_sales_lag_', \n                                fillna=0, astype='int32', agg='sum')\ntrain_test = add_aggregate_lags(train_test, ['shop_id', 'item_id', 'date_block_num'], 'item_mean_price', \n                                'shop_item_price_lag_', lags=[1, 2, 3])\ntrain_test = add_aggregate_lags(train_test, ['item_id', 'date_block_num'], 'item_mean_price', \n                                'item_price_lag_', lags=[1, 2, 3])\ntrain_test.tail()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Number of active days per month"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ndays_per_block = pd.DataFrame({'days_per_block': sales.date.apply(lambda x: x.strftime('%m-%d'))})\ndays_per_block['date_block_num'] = sales.date_block_num\ndays_per_block = days_per_block.groupby('date_block_num').nunique()[['days_per_block']].reset_index()\ndays_per_block = days_per_block.append({'date_block_num': 34, 'days_per_block': 30}, ignore_index=True)\ntrain_test = train_test.reset_index().merge(days_per_block, on='date_block_num')\ntrain_test['days_per_block'] = (train_test.days_per_block - 30).astype('int8')\ntrain_test.set_index(['shop_id', 'item_id', 'date_block_num'], inplace=True)\ntrain_test[['days_per_block']].tail()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4 & 5. Months since last item and/or shop sale"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\n#Inspired by dlarionov\ndef add_since_features(df, key_func, name):\n    known = {}\n    df[name] = -1\n    df[name] = df[name].astype(np.int8)\n    for i, row in df.iterrows():    \n        key = key_func(row)\n        if key not in known:\n            if row.item_cnt_month > 0:\n                known[key] = row.date_block_num\n        else:\n            if known[key] < row.date_block_num:\n                df.at[i, name] = row.date_block_num - known[key]\n                known[key] = row.date_block_num  \n    return df\ntrain_test.reset_index(inplace=True)\ntrain_test = add_since_features(train_test, lambda r: str(r.shop_id) + '_' + str(r.item_id), 'm_since_last_shop_item_sale')\ntrain_test = add_since_features(train_test, lambda r: str(r.shop_id), 'm_since_last_shop_sale')\ntrain_test = add_since_features(train_test, lambda r: str(r.item_id), 'm_since_last_item_sale')\ntrain_test.set_index(['shop_id', 'item_id', 'date_block_num'], inplace=True)\ntrain_test.iloc[-5:,-3:]","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Mean encodings of shops and items"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ndef add_mean_encodings(df, index_cols, target_col, name):\n    _gb = df.groupby(index_cols)[[target_col]].mean()\n    _gb.rename(columns={target_col: name}, inplace=True)\n    return pd.merge(df, _gb.reset_index(), on=index_cols, how='left')\ntrain_test.reset_index(inplace=True)\ntrain_test = add_mean_encodings(train_test, ['shop_id'], 'item_cnt_month', 'shop_mean')\ntrain_test = add_mean_encodings(train_test, ['item_id'], 'item_cnt_month', 'item_mean')\ntrain_test.set_index(['shop_id', 'item_id', 'date_block_num'], inplace=True)\ntrain_test = minimize_memory(train_test).set_index(['shop_id', 'item_id', 'date_block_num'])\ntrain_test[['shop_mean', 'item_mean']].tail()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. End-of-month Percent encodings"},{"execution_count":26,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\n_gb = sales.groupby(['shop_id', 'item_id', 'date_block_num']).agg({'item_cnt_day': ['sum', 'last']})\n_gb.columns = ['month_sum', 'month_last']\n_gb = pd.merge(_gb.reset_index(), days_per_block, on='date_block_num')\n_gb['date_block_num'] += 1\n_gb['end_of_month_percent'] = (_gb.month_last / (_gb.month_sum / (_gb.days_per_block + 30)))\n_gb = _gb[['shop_id', 'item_id', 'date_block_num', 'end_of_month_percent']]\n_gb['end_of_month_percent'] = _gb.end_of_month_percent.fillna(0)\ntrain_test = pd.merge(train_test.reset_index(), _gb, \n                      on=['shop_id', 'item_id', 'date_block_num'], how='left')\ntrain_test.set_index(['shop_id', 'item_id', 'date_block_num'], inplace=True)\ntrain_test[['item_cnt_month', 'end_of_month_percent']].head()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Shop population, category, and type"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ntrain_test.reset_index(inplace=True)\ntrain_test = pd.merge(train_test, shops[['shop_type', 'shop_city', 'shop_city_pop']], \n         on='shop_id', validate='many_to_one', how='left')\ntrain_test = add_mean_encodings(train_test, ['shop_type'], 'item_cnt_month', 'shop_type_mean')\ntrain_test = add_mean_encodings(train_test, ['shop_city'], 'item_cnt_month', 'shop_city_mean')\ntrain_test.set_index(['shop_id', 'item_id', 'date_block_num'], inplace=True)\ntrain_test[['shop_type', 'shop_city', 'shop_city_pop']].iloc[20000:20010,:]","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. Item categories"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ntrain_test.reset_index(inplace=True)\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nitems = items.merge(categories, on='item_category_id', validate='m:1', how='left')\ntrain_test = train_test.merge(items[['item_id', 'item_category_name', 'main_category']], \n                              on='item_id', how='left', validate='m:1')\ntrain_test = train_test.rename(columns={'item_category_name': 'item_category_full', 'main_category': 'item_category_main'})\ntrain_test = add_mean_encodings(train_test, ['item_category_full'], 'item_cnt_month', 'item_category_full_mean')\ntrain_test = add_mean_encodings(train_test, ['item_category_main'], 'item_cnt_month', 'item_category_main_mean')\ntrain_test.set_index(['shop_id', 'item_id', 'date_block_num'], inplace=True)\ntrain_test = minimize_memory(train_test).set_index(['shop_id', 'item_id', 'date_block_num'])\ntrain_test.iloc[:5,-4:]","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. Revenue lags"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ntrain_test = add_aggregate_lags(train_test.astype({'item_revenue_month': 'float64'}), ['date_block_num'], \n                                'item_revenue_month', 'monthly_revenue_lag_', \n                                astype='int32', fillna=0, agg='sum')\ntrain_test = add_aggregate_lags(train_test.astype({'item_revenue_month': 'float64'}), \n                                ['shop_id', 'item_id', 'date_block_num'], 'item_revenue_month', \n                                'shop_item_revenue_lag_', astype='int32', fillna=0, agg='sum')\ntrain_test.iloc[:5,:][['item_revenue_month'] + [c for c in train_test.columns if c.startswith('shop_item_rev')]]","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 11. Total monthly sale lags"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ntrain_test = add_aggregate_lags(train_test, ['date_block_num'], 'item_cnt_month', \n                   'monthly_sales_lag', fillna=0, agg='sum', lags=[1, 2, 3, 6, 12])","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 12. Months since first shop/item sale"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\n#Credit to dlarionov\ntrain_test.reset_index(inplace=True)\ntrain_test['m_since_shop_item_first_sale'] = train_test['date_block_num'] - train_test.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\ntrain_test['m_since_item_first_sale'] = train_test['date_block_num'] - train_test.groupby('item_id')['date_block_num'].transform('min')","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 13. Month Number"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ntrain_test['month'] = train_test.date_block_num % 12\ntrain_test.set_index(['shop_id', 'item_id', 'date_block_num'], inplace=True)","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Checkpoint"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"if skip_processing:\n    raise Exception(\"Skipping data processing steps\")\ndel _gb, sales, items, categories, test, train, shops\ngc.collect()\ntrain_test.reset_index(inplace=True)\ntrain_test.replace([np.inf, -np.inf], np.nan, inplace=True)\ntrain_test = minimize_memory(train_test, reset_index=False)\ntrain_test.set_index(['shop_id', 'item_id', 'date_block_num'], inplace=True)\ntrain_test.to_pickle('data.pkl')","outputs":[]},{"execution_count":21,"metadata":{},"cell_type":"code","source":"train_test = pd.read_pickle('../input/traintestset/data.pkl')\ntrain_test.info()","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Validation\n#### Strategy is to train on months 12-32 and validate on month 33"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"train_test.drop(['item_mean_price', 'item_revenue_month'], axis=1, inplace=True) #Only used for lag features\ntrain_test.reset_index(inplace=True)\nX_train = train_test[(12 <= train_test.date_block_num) & (train_test.date_block_num <= 32)].drop('item_cnt_month', axis=1)\ny_train = train_test[(12 <= train_test.date_block_num) & (train_test.date_block_num <= 32)].item_cnt_month\nX_eval = train_test[train_test.date_block_num == 33].drop('item_cnt_month', axis=1)\ny_eval = train_test[train_test.date_block_num == 33].item_cnt_month\ndel train_test\ngc.collect()","outputs":[]},{"execution_count":9,"metadata":{},"cell_type":"code","source":"lgb_model = lgb.LGBMRegressor(objective='regression_l2', n_estimators=1000, reg_alpha=0.0, reg_lambda=0.0, \n                              random_state=40, n_jobs=-1, silent=False, max_depth=15, num_leaves=70, \n                              subsample=0.8, learning_rate=0.1)","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"categoricals = {'shop_type','shop_city','item_category_full','item_category_main'}\ncategoricals = [i for i, n in enumerate(X_train.columns) if n in categoricals]\nlgb_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_eval, y_eval)], \n              verbose=True, eval_names=['Train', 'Eval'], early_stopping_rounds=100,\n              categorical_feature=categoricals)","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"lgb_results = pd.DataFrame({'Eval': lgb_model.evals_result_['Eval']['l2'], 'Train': lgb_model.evals_result_['Train']['l2']})\nax = lgb_results.plot(figsize=(12, 6))\nax.set_title('LightGBM Model RMSE')\nax.set_xlabel('Cycle')\nax.set_ylabel('RMSE');","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"features = pd.DataFrame(list(zip(X_train.columns, lgb_model.feature_importances_)), columns=['Feature', 'Importance'])\nfeatures.sort_values('Importance', ascending=True, inplace=True)\nax = features.plot('Feature', 'Importance', kind='barh', figsize=(15, 12))\nax.set_xlabel('Importance (Higher is better)')\nax.set_ylabel('')\nax.set_title('Feature Importance');","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This model looks very strong, with no signs of overfitting.  Let's train it on months 12-33 and predict month 34.\n# Model Predictions"},{"execution_count":11,"metadata":{},"cell_type":"code","source":"train_test = pd.read_pickle('../input/traintestset/data.pkl')\npred_index = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')","outputs":[]},{"execution_count":12,"metadata":{},"cell_type":"code","source":"train_test.drop(['item_mean_price', 'item_revenue_month'], axis=1, inplace=True) #Only used for lag features\ntrain_test.reset_index(inplace=True)\nX_train = train_test[(12 <= train_test.date_block_num) & (train_test.date_block_num <= 33)].drop('item_cnt_month', axis=1)\ny_train = train_test[(12 <= train_test.date_block_num) & (train_test.date_block_num <= 33)].item_cnt_month\nX_eval = train_test[train_test.date_block_num == 34].drop('item_cnt_month', axis=1)\ndel train_test\ngc.collect()","outputs":[]},{"execution_count":13,"metadata":{},"cell_type":"code","source":"categoricals = {'shop_type','shop_city','item_category_full','item_category_main'}\ncategoricals = [i for i, n in enumerate(X_train.columns) if n in categoricals]\nlgb_model.set_params(n_estimators=332) #Strongest number of trees in last run\nlgb_model.fit(X_train, y_train, eval_set=[(X_train, y_train)], \n              verbose=True, eval_names=['Train'], early_stopping_rounds=50,\n              categorical_feature=categoricals)","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"pred = lgb_model.predict(X_eval)","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"X_eval['item_cnt_month'] = pred\nX_eval = X_eval[['shop_id', 'item_id', 'item_cnt_month']]","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"pred_index = pred_index.reset_index().merge(X_eval, on=['shop_id', 'item_id'], how='left')\npred_index = pred_index[['ID', 'item_cnt_month']].set_index('ID')\npred_index['item_cnt_month'] = pred_index.item_cnt_month.clip(0, 20).fillna(0)\npred_index.to_csv('final.csv')","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost Predictions"},{"execution_count":53,"metadata":{},"cell_type":"code","source":"train_test = pd.read_pickle('../input/traintestset/data.pkl')\ntrain_test.drop(['item_mean_price', 'item_revenue_month'], axis=1, inplace=True) #Only used for lag features\ntrain_test.reset_index(inplace=True)\nX_train = train_test[(12 <= train_test.date_block_num) & (train_test.date_block_num <= 32)].drop('item_cnt_month', axis=1)\ny_train = train_test[(12 <= train_test.date_block_num) & (train_test.date_block_num <= 32)].item_cnt_month\nX_eval = train_test[train_test.date_block_num == 33].drop('item_cnt_month', axis=1)\ny_eval = train_test[train_test.date_block_num == 33].item_cnt_month\ndel train_test\ngc.collect()","outputs":[]},{"execution_count":2,"metadata":{},"cell_type":"code","source":"xgb_model = xgb.XGBRegressor(max_depth=9, learning_rate=0.1, n_estimators=200, subsample=1,\n                             colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1,\n                             verbosity=1, n_jobs=-1, gamma=0, random_state=40, \n                             min_child_weight=1, max_delta_step=0, \n                             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5)","outputs":[]},{"execution_count":null,"metadata":{},"cell_type":"code","source":"xgb_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_eval, y_eval)], \n              verbose=True, early_stopping_rounds=10)","outputs":[]},{"execution_count":3,"metadata":{},"cell_type":"code","source":"#max_depth=3, n_estimators=100 => 0.797904  0.838999 no early stopping, \n#max_depth=9, n_estimators=200 => 0.630982  0.780855 at stop 78\ntrain_test = pd.read_pickle('../input/traintestset/data.pkl')\npred_index = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')\ntrain_test.drop(['item_mean_price', 'item_revenue_month'], axis=1, inplace=True) #Only used for lag features\ntrain_test.reset_index(inplace=True)\nX_train = train_test[(12 <= train_test.date_block_num) & (train_test.date_block_num <= 33)].drop('item_cnt_month', axis=1)\ny_train = train_test[(12 <= train_test.date_block_num) & (train_test.date_block_num <= 33)].item_cnt_month\nX_eval = train_test[train_test.date_block_num == 34].drop('item_cnt_month', axis=1)\ndel train_test\ngc.collect()","outputs":[]},{"execution_count":4,"metadata":{},"cell_type":"code","source":"xgb_model = xgb.XGBRegressor(max_depth=10, learning_rate=0.1, n_estimators=80, subsample=1,\n                             colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1,\n                             verbosity=1, n_jobs=-1, gamma=0, random_state=40, \n                             min_child_weight=1, max_delta_step=0, \n                             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5)\nxgb_model.fit(X_train, y_train, eval_set=[(X_train, y_train)], \n              verbose=True, early_stopping_rounds=50)","outputs":[]},{"execution_count":5,"metadata":{},"cell_type":"code","source":"pred = xgb_model.predict(X_eval)\nX_eval['item_cnt_month'] = pred\nX_eval = X_eval[['shop_id', 'item_id', 'item_cnt_month']]\npred_index = pred_index.reset_index().merge(X_eval, on=['shop_id', 'item_id'], how='left')\npred_index = pred_index[['ID', 'item_cnt_month']].set_index('ID')\npred_index['item_cnt_month'] = pred_index.item_cnt_month.clip(0, 20).fillna(0)\npred_index.to_csv('xgboost_predictions.csv')","outputs":[]},{"execution_count":6,"metadata":{},"cell_type":"code","source":"import pickle\nwith open(r\"xgboost_model.pickle\", \"wb\") as output_file:\n    pickle.dump(xgb_model, output_file)","outputs":[]},{"execution_count":7,"metadata":{},"cell_type":"code","source":"pred_index['item_cnt_month'] = pred_index.item_cnt_month.round()\npred_index.to_csv('xgboost_predictions_rounded.csv')","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stacked Ensemble"},{"execution_count":null,"metadata":{},"cell_type":"code","source":"","outputs":[]}],"nbformat_minor":1,"nbformat":4}