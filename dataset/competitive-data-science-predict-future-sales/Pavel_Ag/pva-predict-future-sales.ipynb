{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T21:29:50.018614Z","iopub.execute_input":"2021-06-29T21:29:50.019072Z","iopub.status.idle":"2021-06-29T21:29:50.033426Z","shell.execute_reply.started":"2021-06-29T21:29:50.019013Z","shell.execute_reply":"2021-06-29T21:29:50.032149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport gc\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:29:50.040139Z","iopub.execute_input":"2021-06-29T21:29:50.040571Z","iopub.status.idle":"2021-06-29T21:29:50.414581Z","shell.execute_reply.started":"2021-06-29T21:29:50.040526Z","shell.execute_reply":"2021-06-29T21:29:50.413501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\nbasicPath = r'../input/competitive-data-science-predict-future-sales/';\noutputPath = ''\n\n# sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.\n#     date     dd.MM.yyyy\n#     shop_id\n#     item_id\n#     item_price  - number of products sold. You are predicting a monthly amount of this measure\n#     date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\ndf_train = pd.read_csv(os.path.join(basicPath, 'sales_train.csv'))\ndf_train['date'] = pd.to_datetime(df_train['date'])\n\n# test.csv - the test set. You need to forecast the sales for these shops and products for November 2015 (monthly!)\ndf_pred  = pd.read_csv(os.path.join(basicPath, 'test.csv'))\n\n#items.csv - supplemental information about the items/products.\ndf_items = pd.read_csv(os.path.join(basicPath, 'items.csv'))\n#item_categories.csv  - supplemental information about the items categories.\ndf_categ = pd.read_csv(os.path.join(basicPath, 'item_categories.csv'))\n#shops.csv- supplemental information about the shops.\ndf_shops = pd.read_csv(os.path.join(basicPath, 'shops.csv'))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:29:50.416615Z","iopub.execute_input":"2021-06-29T21:29:50.417058Z","iopub.status.idle":"2021-06-29T21:29:52.763263Z","shell.execute_reply.started":"2021-06-29T21:29:50.417012Z","shell.execute_reply":"2021-06-29T21:29:52.76232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_train.describe())\nprint(df_items.describe())\nprint(df_train.dtypes)\nprint(df_pred.describe())","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:29:52.764776Z","iopub.execute_input":"2021-06-29T21:29:52.765173Z","iopub.status.idle":"2021-06-29T21:29:53.271793Z","shell.execute_reply.started":"2021-06-29T21:29:52.765131Z","shell.execute_reply":"2021-06-29T21:29:53.270667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes:\n1. There are incorrect item_price (<=0)\n2. There are incorrect item_cnt_day (<=0)\n3. As prediction result we need monthly data, but in input we have daily\n4. In prediction data we have only shop_id and item_id, no price, so we can't use it for training\n5. We can lookup addition data by shop_id and item_id","metadata":{}},{"cell_type":"code","source":"# remove incorrect prices and counts\ndf_train = df_train[df_train['item_price']>0]\ndf_train = df_train[df_train['item_cnt_day']>0]","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:29:53.273317Z","iopub.execute_input":"2021-06-29T21:29:53.273765Z","iopub.status.idle":"2021-06-29T21:29:53.493753Z","shell.execute_reply.started":"2021-06-29T21:29:53.2737Z","shell.execute_reply":"2021-06-29T21:29:53.492753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation\nduplicates = df_items[df_items.duplicated(['item_id'])]\nprint(duplicates)\nduplicates = df_categ[df_categ.duplicated(['item_category_id'])]\nprint(duplicates)\nduplicates = df_shops[df_shops.duplicated(['shop_id'])]\nprint(duplicates)\nduplicates = df_train[df_train.duplicated(['date', 'shop_id', 'item_id'])]\nprint(duplicates)\n\n# delete duplicates\ndf_train.drop_duplicates(subset=['date', 'shop_id', 'item_id'], keep='last', inplace=True)\nduplicates = df_train[df_train.duplicated(['date', 'shop_id', 'item_id'])]\nprint(duplicates)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:29:53.495259Z","iopub.execute_input":"2021-06-29T21:29:53.495689Z","iopub.status.idle":"2021-06-29T21:29:54.945869Z","shell.execute_reply.started":"2021-06-29T21:29:53.495644Z","shell.execute_reply":"2021-06-29T21:29:54.944777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now should be ok\nprint(df_train.describe())\nprint(df_train.dtypes)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:29:54.947248Z","iopub.execute_input":"2021-06-29T21:29:54.947614Z","iopub.status.idle":"2021-06-29T21:29:55.40861Z","shell.execute_reply.started":"2021-06-29T21:29:54.947581Z","shell.execute_reply":"2021-06-29T21:29:55.407581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# item_price distribution\nvar = 'item_price' \ndata = pd.concat([df_train['date'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='date', ylim=(df_train['date'].min(), df_train['date'].max()));","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:29:55.412324Z","iopub.execute_input":"2021-06-29T21:29:55.412656Z","iopub.status.idle":"2021-06-29T21:29:59.95983Z","shell.execute_reply.started":"2021-06-29T21:29:55.412627Z","shell.execute_reply":"2021-06-29T21:29:59.958784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove price anomalies\nmaxPriceValue = 100000\ndf_train = df_train[df_train['item_price']<maxPriceValue]\n\nvar = 'item_price' \ndata = pd.concat([df_train['date'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='date', ylim=(df_train['date'].min(), df_train['date'].max()));","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:29:59.961759Z","iopub.execute_input":"2021-06-29T21:29:59.962043Z","iopub.status.idle":"2021-06-29T21:30:04.617266Z","shell.execute_reply.started":"2021-06-29T21:29:59.962016Z","shell.execute_reply":"2021-06-29T21:30:04.616285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var = 'item_cnt_day' \ndata = pd.concat([df_train['date'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='date', ylim=(df_train['date'].min(), df_train['date'].max()));","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:04.61885Z","iopub.execute_input":"2021-06-29T21:30:04.619154Z","iopub.status.idle":"2021-06-29T21:30:09.12856Z","shell.execute_reply.started":"2021-06-29T21:30:04.619126Z","shell.execute_reply":"2021-06-29T21:30:09.127453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove count anomalies\nmaxCountValue = 1000\ndf_train = df_train[df_train['item_cnt_day']<maxCountValue]\n\nvar = 'item_cnt_day' \ndata = pd.concat([df_train['date'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='date', ylim=(df_train['date'].min(), df_train['date'].max()));","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:09.130222Z","iopub.execute_input":"2021-06-29T21:30:09.130662Z","iopub.status.idle":"2021-06-29T21:30:13.771656Z","shell.execute_reply.started":"2021-06-29T21:30:09.130618Z","shell.execute_reply":"2021-06-29T21:30:13.77023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# selling by shop\nprint(df_train['shop_id'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:13.773336Z","iopub.execute_input":"2021-06-29T21:30:13.773804Z","iopub.status.idle":"2021-06-29T21:30:13.805269Z","shell.execute_reply.started":"2021-06-29T21:30:13.773757Z","shell.execute_reply":"2021-06-29T21:30:13.804122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix shop id data\ndef fixShopId(df):\n    df.loc[df['shop_id'] ==  0, 'shop_id'] = 57\n    df.loc[df['shop_id'] ==  1, 'shop_id'] = 58\n    df.loc[df['shop_id'] == 10, 'shop_id'] = 11\n    df.loc[df['shop_id'] == 40, 'shop_id'] = 39\n    df.loc[df['shop_id'] == 24, 'shop_id'] = 23\n\n    df.loc[df['shop_id'] == 36, 'shop_id'] = 101 # --> Новосибирск\n    df.loc[df['shop_id'] == 37, 'shop_id'] = 101 \n\n    df.loc[df['shop_id'] == 6, 'shop_id'] = 102 # --> Воронеж\n    df.loc[df['shop_id'] == 7, 'shop_id'] = 102\n    df.loc[df['shop_id'] == 8, 'shop_id'] = 102\n\n    df.loc[df['shop_id'] == 57, 'shop_id'] = 103 # --> Якутск\n    df.loc[df['shop_id'] == 58, 'shop_id'] = 103 \n\n    df.loc[df['shop_id'] == 34, 'shop_id'] = 104 # --> Н.Новгород\n    df.loc[df['shop_id'] == 35, 'shop_id'] = 104 \n\n    df.loc[df['shop_id'] == 17, 'shop_id'] = 105 # --> Красноярск\n    df.loc[df['shop_id'] == 18, 'shop_id'] = 105\n    \n    return df\n\ndf_train = fixShopId(df_train)\ndf_shops = fixShopId(df_shops)\n    \nprint(df_train['shop_id'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:13.806781Z","iopub.execute_input":"2021-06-29T21:30:13.807212Z","iopub.status.idle":"2021-06-29T21:30:14.162249Z","shell.execute_reply.started":"2021-06-29T21:30:13.807164Z","shell.execute_reply":"2021-06-29T21:30:14.161138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try to extract city name from shop name\ndf_shops['shop_name'] = df_shops.apply(lambda x: x['shop_name'].strip('!'), axis=1)\ndf_shops['city'] = df_shops.apply(lambda x: x['shop_name'].split()[0], axis=1)\n\ndf_shops.loc[df_shops['city'] == 'Интернет-магазин', 'city'] = 'Интернет'\ndf_shops.loc[df_shops['city'] == 'Цифровой', 'city'] = 'Интернет'\n\ncityList = list(set(list(df_shops['city'])))\ncityList.sort()\nprint(cityList)\n\n# remove duplicates\nduplicates = df_shops[df_shops.duplicated(['shop_id', 'city'])]\nprint(duplicates)\ndf_shops.drop_duplicates(subset=['shop_id', 'city'], keep='last', inplace=True)\nprint(df_shops)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:14.163784Z","iopub.execute_input":"2021-06-29T21:30:14.16424Z","iopub.status.idle":"2021-06-29T21:30:14.193148Z","shell.execute_reply.started":"2021-06-29T21:30:14.164193Z","shell.execute_reply":"2021-06-29T21:30:14.192047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def addLookup(df):\n    # add item_category_id\n    df = df.join(df_items.set_index('item_id'), on='item_id')\n    df.drop(['item_name'], axis=1, inplace=True)\n\n    # add city name\n    df = df.join(df_shops.set_index('shop_id'), on='shop_id')\n    df.drop(['shop_name'], axis=1, inplace=True)\n    \n    df['city'] = df['city'].astype(\"category\")\n    df['item_category_id'] = df['item_category_id'].astype(\"category\")\n    \n    df.drop(['shop_id'], axis=1, inplace=True)\n    df.drop(['item_id'], axis=1, inplace=True)\n    \n    return df\n\ndf_train = addLookup(df_train)\nprint(df_train.head(20))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:14.194729Z","iopub.execute_input":"2021-06-29T21:30:14.195097Z","iopub.status.idle":"2021-06-29T21:30:15.544793Z","shell.execute_reply.started":"2021-06-29T21:30:14.195062Z","shell.execute_reply":"2021-06-29T21:30:15.543802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove all unused columns\ndf_train.drop(['item_price'], axis=1, inplace=True)\ndf_train.drop(['date'], axis=1, inplace=True)\n\nprint(df_train.head(20))\nprint(df_train.columns)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:15.546224Z","iopub.execute_input":"2021-06-29T21:30:15.546537Z","iopub.status.idle":"2021-06-29T21:30:15.608905Z","shell.execute_reply.started":"2021-06-29T21:30:15.546506Z","shell.execute_reply":"2021-06-29T21:30:15.607674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XGrouped = df_train.groupby(by=['date_block_num','item_category_id','city']).agg({'item_cnt_day': 'sum'}).reset_index()\nXGrouped.rename(columns={\"item_cnt_day\": \"item_cnt_month\"}, inplace=True)\nprint(XGrouped.head(10))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:15.610345Z","iopub.execute_input":"2021-06-29T21:30:15.61075Z","iopub.status.idle":"2021-06-29T21:30:17.285643Z","shell.execute_reply.started":"2021-06-29T21:30:15.610705Z","shell.execute_reply":"2021-06-29T21:30:17.284617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# selling by date for one product\n# any ideas? no, sorry\nmaxSell = set(XGrouped[ XGrouped['item_cnt_month'] > 6000 ]['item_category_id'])\nprint(maxSell)\ndata = XGrouped[ XGrouped['item_category_id'] == 40 ]\ndata = pd.concat([data['item_cnt_month'], data['date_block_num']], axis=1)\ndata.plot(x='date_block_num', y='item_cnt_month');\n\ndata = XGrouped[ XGrouped['item_category_id'] == 30 ]\ndata = pd.concat([data['item_cnt_month'], data['date_block_num']], axis=1)\ndata.plot(x='date_block_num', y='item_cnt_month');\n\ndata = XGrouped[ XGrouped['item_category_id'] == 19 ]\ndata = pd.concat([data['item_cnt_month'], data['date_block_num']], axis=1)\ndata.plot(x='date_block_num', y='item_cnt_month');","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:17.286713Z","iopub.execute_input":"2021-06-29T21:30:17.287007Z","iopub.status.idle":"2021-06-29T21:30:17.774958Z","shell.execute_reply.started":"2021-06-29T21:30:17.286974Z","shell.execute_reply":"2021-06-29T21:30:17.773887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# date_block_num is seq numeration 0...33, but it's not useful for ML\n# better to convert it in year of number 1..12\n\ndef convertMonth(df):\n    df['month_num'] = df.apply(lambda x: (x['date_block_num'] % 12)+1, axis=1)\n    df['month_num'] = df['month_num'].astype(\"category\")\n    df.drop(['date_block_num'], axis=1, inplace=True)\n    return df\n\nXGrouped = convertMonth(XGrouped)\nprint(XGrouped.head(10))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:17.776129Z","iopub.execute_input":"2021-06-29T21:30:17.776443Z","iopub.status.idle":"2021-06-29T21:30:18.844019Z","shell.execute_reply.started":"2021-06-29T21:30:17.776416Z","shell.execute_reply":"2021-06-29T21:30:18.842761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XGrouped = pd.get_dummies(XGrouped, drop_first=True)\nprint(XGrouped.head(10))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:18.845726Z","iopub.execute_input":"2021-06-29T21:30:18.846184Z","iopub.status.idle":"2021-06-29T21:30:18.90083Z","shell.execute_reply.started":"2021-06-29T21:30:18.846139Z","shell.execute_reply":"2021-06-29T21:30:18.899631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = XGrouped[['item_cnt_month']]\nX = XGrouped.copy()\nX.drop(['item_cnt_month'], axis=1, inplace=True)\n\nprint(X.head())","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:18.902323Z","iopub.execute_input":"2021-06-29T21:30:18.902661Z","iopub.status.idle":"2021-06-29T21:30:18.929644Z","shell.execute_reply.started":"2021-06-29T21:30:18.902629Z","shell.execute_reply":"2021-06-29T21:30:18.928514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=44, shuffle =True)\nprint('Shape:', X_train.shape, X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:18.931075Z","iopub.execute_input":"2021-06-29T21:30:18.931482Z","iopub.status.idle":"2021-06-29T21:30:19.128538Z","shell.execute_reply.started":"2021-06-29T21:30:18.931439Z","shell.execute_reply":"2021-06-29T21:30:19.127512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# model\nmodel = RandomForestRegressor(n_estimators=50, random_state=0, n_jobs=-1, max_features= 'log2')\n\n# save columns    \nmodel.feature_names = list(X_train.columns.values)    \n    \n# train\nmodel.fit(X_train,  y_train['item_cnt_month'].values)\n\n#score\nprint('Train score is : ' , model.score(X_train, y_train))\nprint('Test  score is : ' , model.score(X_test , y_test ))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:19.130009Z","iopub.execute_input":"2021-06-29T21:30:19.130368Z","iopub.status.idle":"2021-06-29T21:30:23.768769Z","shell.execute_reply.started":"2021-06-29T21:30:19.130336Z","shell.execute_reply":"2021-06-29T21:30:23.767815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data for prediction\n\nI_pred = df_pred['ID']\nX_pred = df_pred.copy()\nX_pred.drop(['ID'], axis=1, inplace=True)\n\nX_pred['date_block_num'] = 34 #  November 2015\nX_pred = fixShopId(X_pred)\nX_pred = addLookup(X_pred)\nX_pred = convertMonth(X_pred)\n\nX_pred = pd.get_dummies(X_pred, drop_first=True)\n\nfor c in model.feature_names:\n    if not(c in X_pred.columns):\n        X_pred[c] = 0\n\nX_pred['month_num_11'] = 1 #  November\n\nprint(len(X_train.columns))\nprint(len(X_pred.columns))\nprint(list(X_pred.columns))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:23.770158Z","iopub.execute_input":"2021-06-29T21:30:23.770553Z","iopub.status.idle":"2021-06-29T21:30:26.581875Z","shell.execute_reply.started":"2021-06-29T21:30:23.77051Z","shell.execute_reply":"2021-06-29T21:30:26.580641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions\ny_pred = model.predict(X_pred)\noutput = pd.DataFrame({'ID': I_pred, 'item_cnt_month': y_pred})\nprint(output.head(5))\noutput.to_csv(os.path.join(outputPath, 'my_submission.csv'), index=False)\nprint(output.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T21:30:26.58317Z","iopub.execute_input":"2021-06-29T21:30:26.583459Z","iopub.status.idle":"2021-06-29T21:30:28.414869Z","shell.execute_reply.started":"2021-06-29T21:30:26.583431Z","shell.execute_reply":"2021-06-29T21:30:28.413572Z"},"trusted":true},"execution_count":null,"outputs":[]}]}