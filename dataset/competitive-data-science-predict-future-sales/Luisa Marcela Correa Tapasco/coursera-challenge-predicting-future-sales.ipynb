{"cells":[{"metadata":{},"cell_type":"markdown","source":"Getting Started\n\n\nI have learned that data science is not only aimed at systems engineers, it is for enthusiastic, creative people, and with a thirst for knowledge, data is currently a gold mine, you just have to learn how to exploit it. There are tools, tutorials, communities, so I'm very excited to start this my first project close to a real problem, so go ahead.\n\nMy plan scheduled in this notebook:\n\n* Understand the data delivered by competition, know data type\n* Do EDA\n* Pre-process given data set and generate new features from existing ones, new features that give courage to achieve the objective as required my challenge:\n    Numeric, categorical, datetime and coordinate features.\n* Make decisions about handling missing data or cleaning data\n* Find insights\n* See differents between test and train\n* Build models over dataset, make training and test\n* Use differents librarys for data plots, visualize the data\n* Create validations for models\n* Forecast the total amount of products sold in every shop for the test set\n* Create baseline and summit\n\nFirst, It is necesary import librarys, a few over of these:\n* *Numpy (linear algebra)*: It's to work with dimensional arrays, has useful routines and random number capabilities for linear algebra.\n* *Pandas*: It allows we to process data like to SQL. Your use is easy intuitive, flexible. \n* *Os*: It is a python's module, it provides functions for interacting with the operating system, and its file system.\n* *matplotlib*: It allows we to create a production-quality graphic, differents plots\n* *seaborn*: It allows we to create a differents plots. Built on top of matplotlib and designed for advanced statistical graphics."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport scipy.sparse\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport base64\nfrom pandas.plotting import scatter_matrix\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout\nfrom IPython.display import FileLink, FileLinks\n        \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading data provide of competition:**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#DEscomentar si es para subir\nROOT_FOLDER         = '/kaggle/input/competitive-data-science-predict-future-sales/'\ndf_items             =  pd.read_csv(os.path.join(ROOT_FOLDER, 'items.csv'))\ndf_item_categories   =  pd.read_csv(os.path.join(ROOT_FOLDER, 'item_categories.csv'))\ndf_sales_train       =  pd.read_csv(os.path.join(ROOT_FOLDER, 'sales_train.csv'))\ndf_shops             =  pd.read_csv(os.path.join(ROOT_FOLDER, 'shops.csv'))\ndf_test              =  pd.read_csv(os.path.join(ROOT_FOLDER, 'test.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's knowledge of dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(' Dataset Items ')\ndf_items.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(' Dataset item_categories ')\ndf_item_categories.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(' Dataset sales_train ')\ndf_sales_train.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(' Dataset test ')\ndf_test.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(' Dataset shops ')\ndf_shops.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's analize data ***sales_train***:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print ('Train min/max date: %s / %s' % (df_sales_train.date_block_num.min(), df_sales_train.date_block_num.max()))\nprint('Sales Train shape: %d rows' % df_sales_train.shape[0])\nprint('Test: %d rows ' % df_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I can to see, that train has more than 14 times rows than test"},{"metadata":{},"cell_type":"markdown","source":"Let's go to see missing values, NaN, null:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of NaNs for columns\ndf_sales_train.isnull().sum(axis=0).head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of NaNs for row\ndf_sales_train.isnull().sum(axis=1).head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I try to group by shop_id,item_id,month:"},{"metadata":{"trusted":true},"cell_type":"code","source":"index_cols = ['shop_id', 'item_id','item_price','date_block_num']\n\n#get aggregated values for (shop_id, item_id,  date_block_num)\ngb_train = df_sales_train.groupby(index_cols,as_index=False).agg({'item_cnt_day':'sum'}, dtype='int32')\ngb_train = gb_train.rename(columns={'item_cnt_day': 'item_cnt_month'})\ngb_train = gb_train[['shop_id', 'item_id','item_price','date_block_num','item_cnt_month']]\ngb_train.fillna(0, inplace=True)\ngb_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shops without sales per month 2826\ngb_train[(gb_train.item_cnt_month == 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_train[((gb_train.shop_id == 2) & (gb_train.item_id == 835))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_train.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot Item Prices versus Sales per day as markers, searching outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"figure, axe = plt.subplots(figsize = (12,12))\naxe.set_title(\" EDA Item Price VS  Sales Day\", weight=\"bold\")\n\nplot = plt.scatter(gb_train.item_price, gb_train.item_cnt_month, marker=\"o\", c=\"yellow\", edgecolor =\"black\", s=30, cmap='viridis', linewidth=0.5)\nplt.xlabel('Item Price')\nplt.ylabel('Sales Day')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I can see outliers when the prices more than 300000, and when  sales per day over 2000, therefor, create a data set without this data"},{"metadata":{"trusted":true},"cell_type":"code","source":"PRICE_OUT = 300000\nSALES_OUT = 2000\ngb_train = gb_train[(gb_train.item_price < PRICE_OUT) & (gb_train.item_cnt_month < SALES_OUT)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_train = gb_train.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_month'],columns = ['date_block_num'],fill_value = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_train.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Doing merge between train_data and test_df as to be suitable for prediction\ndf_all_data = pd.merge(df_test, gb_train,on = ['item_id','shop_id'],how = 'left')\n#Fill NAN's with 0\ndf_all_data.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all_data.drop(['ID','shop_id','item_id'],inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all_data.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X we will keep all columns execpt the last one \nX_train = np.expand_dims(df_all_data.values[:,:-1],axis = 2)\n# the last column is our label\ny_train = df_all_data.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test = np.expand_dims(df_all_data.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_one = Sequential()\nmodel_one.add(LSTM(units = 64,input_shape = (33,1)))\nmodel_one.add(Dropout(0.4))\nmodel_one.add(Dense(1))\n\nmodel_one.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nmodel_one.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_one.fit(X_train,y_train,batch_size = 4096,epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating submission file \nsubmission_file = model_one.predict(X_test)\n# we will keep every value between 0 and 20\nsubmission_file = submission_file.clip(0,20)\n# creating dataframe with required columns \nsubmission = pd.DataFrame({'ID':df_test['ID'],'item_cnt_month':submission_file.ravel()})\nsubmission.to_csv(\"submission_xy.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally generated my csv with data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def download_csv( df, title = \"Download CSV file\", filename = \"submission_xy.csv\"):\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return FileLink(html)\n\ndf = pd.DataFrame(data = submission, columns=['ID', 'item_cnt_month'])\ndownload_csv(df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}