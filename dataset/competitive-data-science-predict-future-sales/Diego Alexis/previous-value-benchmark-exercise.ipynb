{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Introduction**\n\nHello everybody, this is a quick exersice to demostrate the fact that using the previous values benchmark gives us a relative good score. Of course I'm trying more sophisticated model that I'd be sharing in the future.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#First we load the datasets\nitems = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\ntest = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')\nitem_cat = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nsales_train = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\nshops = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\ntest = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales_train.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to use only the \"sales_train\" dataset. Our way is quite simple, first we are going to agreggate sales per month and select total sales per item and shop for October 2015. We use this data to predict November 2015 sales.","metadata":{}},{"cell_type":"code","source":"#this code split dates in months ans years and create a new column with year-month\nsales_train['Month']=[i.split('.')[1] for i in sales_train['date']]\nsales_train['Year']=[i.split('.')[2] for i in sales_train['date']]\nsales_train['Month-Year']=sales_train['Year']+'-'+sales_train['Month']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Here we agreggate total sales per motnh and year. Notice how we select only Octover 2015\ndt=sales_train.groupby(['item_id','shop_id','Month-Year']).sum()[['item_cnt_day']].reset_index()\ndt=dt[dt['Month-Year']=='2015-10']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We know that there are items and shops combinations in test set that don't exist in sales_train set. We'll fill missing values with 0's\nsubmission=pd.merge(test,dt,how='left',on=['item_id','shop_id']).fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We change some columns names\nsubmission.columns=['ID', 'shop_id', 'item_id', 'Month-Year', 'item_cnt_month']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Here We clip item_cnt_month values between 0 and 20\nsubmission['item_cnt_month'] = submission['item_cnt_month'].clip(0,20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We glance at our data\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Finally, I select my columns and create my submission\nsubmission[['ID','item_cnt_month']].to_csv('previous_value_benchmark.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes:\n\n1. This is a really quick kernel mainly created to prove how good the previous values bechmark is as a prediction. Futhermore we can upload our submission clipping our prediction between 0 and 20 and without it for cheking the effects that this has in both submissions.\n\n2. Clipping the prediction column between 0 and 20 is a piece of advice given during the course. \n\n3. The final score is in fact 1.16777 better than a buch of results got it using more sophisticated models.\n\nThank you for reading this.","metadata":{}}]}