{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Problem Statement\n\nPredict total sales for every product and store in the next month."},{"metadata":{},"cell_type":"markdown","source":"#### Data fields\n\n|Field| Meaning|\n| --- | --- |\n|ID | an Id that represents a (Shop, Item) tuple within the test set|\n|shop_id | unique identifier of a shop|\n|item_id | unique identifier of a product|\n|item_category_id | unique identifier of item category|\n|item_cnt_day | number of products sold. You are predicting a monthly amount of this measure|\n|item_price | current price of an item|\n|date | date in format dd/mm/yyyy|\n|date_block_num | a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33|\n|item_name | name of item|\n|shop_name | name of shop|\n|item_category_name | name of item category|"},{"metadata":{},"cell_type":"markdown","source":"#### Data files\n\n|File|descriptions|\n|---|---|\n|sales_train.csv | the training set. Daily historical data from January 2013 to October 2015.|\n|test.csv | the test set. You need to forecast the sales for these shops and products for November 2015.|\n|sample_submission.csv | a sample submission file in the correct format.|\n|items.csv | supplemental information about the items/products.|\n|item_categories.csv  | supplemental information about the items categories.|\n|shops.csv | supplemental information about the shops.|"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport numpy as np\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\npd.set_option('max_colwidth', 400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Download and View Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read CSVs into pandas\ntrain_data = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\nitems_info = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\n\n# Name info uneeded in this model\n#category_info = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\n#shops_info = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Uncomment to see length, dtypes, nulls, memory\nif False:\n    train_data.info()\n    items_info.info()\n    category_info.info()\n    shops_info.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View data sample\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preperation & Feature Creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Format date\ntrain_data[\"date\"] = pd.to_datetime(train_data[\"date\"], dayfirst=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Due to 28 duplucates groupby on \"date\", \"shop_id\", \"item_id\"\nitems_info = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\ngrouped_data = train_data.groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).agg({\"item_price\": [\"mean\", \"max\", \"min\"], \"item_cnt_day\": [\"sum\", \"max\", \"min\", \"median\"]})\ngrouped_data = grouped_data.reset_index()\ngrouped_data = grouped_data.merge(items_info[[\"item_id\", \"item_category_id\"]].drop_duplicates(), left_on = \"item_id\", right_on = \"item_id\", how = \"left\")\ngrouped_data.drop(\"item_id\", axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_data.columns = ['date_block_num', 'shop_id', 'item_id', 'item_price_mean', 'item_price_max', \n                        'item_price_min', 'item_cnt_day_sum', 'item_cnt_day_max', 'item_cnt_day_min',\n                        'item_cnt_day_median', 'item_category_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge with prev month data for prediction\nt_minus1_data = grouped_data.loc[grouped_data.date_block_num != 33, [\"date_block_num\", \"shop_id\", \"item_id\", \"item_price_mean\", \"item_cnt_day_sum\", \"item_cnt_day_median\"]]\nt_minus1_data[\"date_block_num\"] += 1\ndriver_data = grouped_data[grouped_data.date_block_num != 0]\ndriver_data = driver_data.merge(t_minus1_data, left_on = [\"date_block_num\", \"shop_id\", \"item_id\"], right_on = [\"date_block_num\", \"shop_id\", \"item_id\"], suffixes = (\"\", \"_tminus1\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create deltas\nfor col in [\"item_price_mean\", \"item_cnt_day_sum\", \"item_cnt_day_median\"]:\n    driver_data[col + \"_tminus1\"] = np.log(driver_data[col + \"_tminus1\"]) - np.log(driver_data[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy data with all features for later\nsubmission_data = driver_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join with T+1 response data\nresponse_data = grouped_data.loc[grouped_data.date_block_num != 0, [\"date_block_num\", \"shop_id\", \"item_id\", \"item_cnt_day_sum\"]]\ndriver_data = driver_data[driver_data.date_block_num != 33]\nresponse_data[\"date_block_num\"] -= 1\ndriver_data = driver_data.merge(response_data, left_on = [\"date_block_num\", \"shop_id\", \"item_id\"], right_on = [\"date_block_num\", \"shop_id\", \"item_id\"], suffixes = (\"\", \"_realised\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit Xgboost Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model = XGBRegressor(colsample_bylevel=0.8, colsample_bynode=0.8, colsample_bytree=0.8, subsample=0.8, \n                         gamma=10, learning_rate=0.1, max_depth=12, min_child_weight=1, \n                         n_estimators=500, random_state=27, reg_alpha=50, reg_lambda=200)\ntraining_cols = driver_data.drop([\"date_block_num\", \"shop_id\", \"item_id\", \"item_cnt_day_sum_realised\"], axis = 1).columns\nX, y = driver_data.drop([\"date_block_num\", \"shop_id\", \"item_id\", \"item_cnt_day_sum_realised\"], axis = 1).values, driver_data[\"item_cnt_day_sum_realised\"].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_set = [(X_test, y_test)]\nxgb_model.fit(X_train, y_train, early_stopping_rounds=20, eval_set=eval_set, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions for test data\ny_pred = xgb_model.predict(X_test)\npredictions = [round(value) for value in y_pred]\n# evaluate predictions\nrmse = mean_squared_error(y_test, predictions)\n# Default: 103.00\n# Manual tuned 1: 89.51","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bayesian Optimisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Install Gpyopt\n!pip install GPyOpt\nimport GPyOpt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://machinelearningapplied.com/hyperparameter-search-with-gpyopt-part-2-xgboost-classification-and-ensembling/\n\n# hyper param tuning bayes\n# cross validation hyper param tunin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_space = [\n\n       {'name':'colsample_bylevel', 'type':'continuous', 'domain':(0.5, 0.99)},\n       {'name':'colsample_bynode', 'type':'continuous', 'domain':(0.5, 0.99)},\n       {'name':'colsample_bytree', 'type':'continuous', 'domain':(0.5, 0.99)},\n       {'name':'subsample', 'type':'continuous', 'domain':(0.6, 0.99)},\n\n       {'name':'min_child_weight', 'type':'discrete', 'domain':(1, 10)},\n       {'name':'max_depth', 'type':'discrete', 'domain':(8, 9, 10, 11, 12, 13, 14, 15)},\n\n       {'name':'gamma', 'type':'continuous', 'domain':(0.1, 10)},\n       {'name':'reg_alpha', 'type':'discrete', 'domain':(0,1,10,50)},\n       {'name':'reg_lambda', 'type':'discrete', 'domain':(1,10,50,100,150,200,500,1000)}\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgb_function(params):\n    \"\"\"\n    \n    Training data defined outside function\n    \n    Inputs\n    ------\n    \n    Outputs\n    -------\n    \n    \"\"\"\n    \n     \n    dict_parameters = {'colsample_bylevel':params[0][0], \n                         'colsample_bynode':params[0][1],\n                         'colsample_bytree':params[0][2],\n                         'subsample':params[0][3],\n                         'min_child_weight':int(params[0][4]),\n                         'max_depth':int(params[0][5]),\n                         'gamma':params[0][6],\n                         'reg_alpha':int(params[0][7]),\n                         'reg_lambda':int(params[0][8]),\n                         \"random_state\": 27,\n                         \"n_estimators\": 500}\n          \n    opt_model = XGBRegressor(**dict_parameters)\n    opt_model.fit(X_train, y_train, early_stopping_rounds=20, eval_set=eval_set, verbose=False)\n\n    y_pred = opt_model.predict(X_test)\n    predictions = [round(value) for value in y_pred]\n    rmse = mean_squared_error(y_test, predictions)\n     \n    print('\\ndict_parameters:',dict_parameters)\n    print('best_iteration =',opt_model.best_iteration)\n    print('rmse =',rmse)\n     \n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gpyopt_bo = GPyOpt.methods.BayesianOptimization(f=xgb_function, domain=search_space, \n                model_type='GP', initial_design_numdata=5, \n                initial_design_type='random', acquisition_type='EI', \n                normalize_Y=True, exact_feval=False, \n                acquisition_optimizer_type='lbfgs', \n                model_update_interval=1, evaluator_type='sequential', \n                batch_size=1, num_cores=os.cpu_count(), verbosity=True, \n                verbosity_model=False, maximize=False, de_duplication=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gpyopt_bo.run_optimization(max_iter=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"header_params = []\nfor param in search_space:\n    header_params.append(param['name'])\n     \ndf_results = pd.DataFrame(data=gpyopt_bo.X, columns=header_params)\ndf_results[\"rmse\"] = gpyopt_bo.Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_opt_model = XGBRegressor(**{'colsample_bylevel': 0.5095174790289587, 'colsample_bynode': 0.6375048884962791, 'colsample_bytree': 0.6727943521088571, 'subsample': 0.6096441166795321, \n                                'min_child_weight': 10, 'max_depth': 13, 'gamma': 2.797555559145436, 'reg_alpha': 1, 'reg_lambda': 100, 'random_state': 27, 'n_estimators': 500,\n                                'learning_rate': 0.1})\nxgb_opt_model.fit(X_train, y_train, early_stopping_rounds=20, eval_set=eval_set, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions for test data\ny_pred = xgb_opt_model.predict(X_test)\npredictions = [round(value) for value in y_pred]\n# evaluate predictions\nmean_squared_error(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read test CSVs and ID labels\nsample_submission = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\")\ntest_labels = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions and keep last ones\nsubmissions = submission_data.sort_values([\"date_block_num\", \"shop_id\", \"item_id\"], ascending = True).drop_duplicates([\"shop_id\", \"item_id\"], keep = \"last\")\nsubmissions[\"y_predict\"] = xgb_opt_model.predict(submissions[training_cols].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels = test_labels.merge(submissions[[\"shop_id\", \"item_id\", \"y_predict\"]], left_on = [\"shop_id\", \"item_id\"], right_on = [\"shop_id\", \"item_id\"], how = \"right\")\nsample_submission = sample_submission.merge(test_labels[[\"ID\", \"y_predict\"]], left_on = \"ID\", right_on = \"ID\", how = \"left\")\nsample_submission[\"y_predict\"].fillna(1, inplace = True)\nsample_submission.drop(\"item_cnt_month\", axis = 1, inplace = True)\nsample_submission.rename(columns = {\"y_predict\": \"item_cnt_month\"}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}