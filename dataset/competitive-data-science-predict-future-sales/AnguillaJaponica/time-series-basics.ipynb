{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## これはなに？\n個人的な学習のため、[こちら](https://www.kaggle.com/jagangupta/time-series-basics-exploring-traditional-ts)を翻訳しながら内容をつけ加えていったものです。\n\n(日本語に直しながら読むの面倒！という方々向けに役立てば望外の喜びです。voteはリンク先の方に差し上げてください)","metadata":{}},{"cell_type":"markdown","source":"## 時系列解析の基礎:\n\n従来の様々な時系列モデルの基本的な概念と、その背景にある基本的な考え方とを照らし合わせながら、理解を深めていきます。\n\n## 目的:\n「このカーネルは、初心者のための時系列に関する様々な概念の保存場所として作られましたが、専門家の方にも確認用として役立つことを願っています :)」\n\nとのことです(冒頭リンク先の著者の方より)。ありがたい限りですね。。\n\n## もくじ:\n* コンペとデータの概要\n* データとパッケージのインポート\n* 基本的な探査/EDA\n* 単一の時系列\n    * 定常性\n    * 季節性、トレンド、残余\n    * AR , MA , ARMA , ARIMA\n    * AICを用いたPとQの選択\n    * ETS\n    * Prophet\n    * UCM\n* 階層型時系列\n    * ボトムアップ\n    * AHP\n    * PHA \n    * FP \n    \n    \n## コンペとデータの概要:\n\nこのコンペでは、ロシアのソフトウェア会社の来月の全製品・全店舗の総売上高を予測するという課題が与えられています。-[1c company](http://1c.ru/eng/title.htm). \n\n**対象となるソフトウェア会社は何をやるか?:**\n\n1C: Enterprise 8システムのプログラムは、日常的な企業活動の自動化を目的としています。管理会計、ビジネス会計、人事管理、CRM、SRM、MRPなど、経済・経営活動のさまざまなビジネスタスクを対象としています。\n\n**データ**:\n店舗と商品の組み合わせごとに日次の売上データが用意されていますが、今回の課題は月次レベルでの売上予測です。\n\n## インポート:\n","metadata":{"_cell_guid":"0bf81eb9-8749-401f-9a2e-d58447256499","_uuid":"e7de522614a7e048e788bc62b8752e95739fc20a"}},{"cell_type":"code","source":"# まず、ファイルをチェックすることから始めましょう\n!ls ../input/*","metadata":{"_cell_guid":"795bbe4b-51b2-42ec-810a-4f4c18c84f53","_uuid":"e4eb15fdb1237ea12fda77b898eb315b00a205ce","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 基本的なパッケージ\nimport numpy as np # 線形代数\nimport pandas as pd # データの加工, CSVファイルのI/O (e.g. pd.read_csv)\nimport random as rd # 乱数の生成\nimport datetime # manipulating date formats\n# 可視化用\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # for prettier plots\n\n\n# 時系列解析用\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\n\n\n# 設定\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 全てインポート\nsales=pd.read_csv(\"../input/sales_train.csv\")\n\n# 設定\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nitem_cat=pd.read_csv(\"../input/item_categories.csv\")\nitem=pd.read_csv(\"../input/items.csv\")\nsub=pd.read_csv(\"../input/sample_submission.csv\")\nshops=pd.read_csv(\"../input/shops.csv\")\ntest=pd.read_csv(\"../input/test.csv\")","metadata":{"_cell_guid":"6541e1a6-a353-4709-a1fa-730e0f2a308d","_uuid":"debe15ae99f3596923efc37ce2f609920213be54","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 日付カラムを正しくフォーマットする\nsales.date=sales.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))\n# 確認\nprint(sales.info())","metadata":{"_cell_guid":"dc6fc0f9-45a9-4146-b88d-d4bddcb224b2","_uuid":"8e1875bb64b6efc577e8b121217e2ded20ea9ce9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 必要なメトリクスを月次レベルで集計\n\nmonthly_sales=sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n    \"date\",\"item_price\",\"item_cnt_day\"].agg({\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\n\n## コードをブレイクダウンして理解していきます:\n# 日付ブロック（月）とshop_id、item_idによる集計\n# date,item_price,item_cnt(sales)の各カラムを選択\n# どのカラムに対してどのような集約を行うかを示す辞書を用意\n# 日付の最小値と最大値\n# item_priceの平均値\n# 売上高の合計","metadata":{"_cell_guid":"dd800a06-41f7-41d2-a402-80ef2cc4ed2d","_uuid":"0ca7c39c5544de1888d111db2450010f85f1a099","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take a peak\nmonthly_sales.head(20)","metadata":{"_cell_guid":"986b9168-860f-4ae0-8ed7-c42cb65837fb","_uuid":"3d689df5658dfa3bfbfe531488844a9fdd31d804","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# カテゴリごとのアイテム数\nx=item.groupby(['item_category_id']).count()\nx=x.sort_values(by='item_id',ascending=False)\nx=x.iloc[0:10].reset_index()\nx\n# plot\nplt.figure(figsize=(8,4))\nax= sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\nplt.title(\"Items per Category\")\nplt.ylabel('# of items', fontsize=12)\nplt.xlabel('Category', fontsize=12)\nplt.show()","metadata":{"_cell_guid":"c8e0a7f3-9a16-46e0-aae3-273fe0f21d0e","_uuid":"a051b790a453f6e28632435a6c30efae02538113","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"もちろん、このデータセットには他にもたくさんの発見がありますが、時系列のパートに進んでみましょう。\n\n# 単一の時系列:\n\n目的は、ある店舗とアイテムの組み合わせにおける翌月の売上を予測することです。\n\n各店舗アイテムの経時的な売上は、それ自体が時系列です。すべての組み合わせを調べる前に、まず単一の時系列を予測する方法を理解しましょう。\n\nここでは、会社全体の月ごとの総売上高を予測することにします。\n\nまず、月ごとの総売上高を計算し、そのデータをプロットしてみましょう。\n","metadata":{"_cell_guid":"68d378e2-2302-4381-8423-ede818fce32e","_uuid":"8dadea026ac25a550cb6725894e1117c67e88757"}},{"cell_type":"code","source":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","metadata":{"_cell_guid":"a783e367-da29-47fd-97be-f3ff756f32fe","_uuid":"95eaf40635366294662b228680cb6e425940c7db","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.plot(ts.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(ts.rolling(window=12,center=False).std(),label='Rolling sd');\nplt.legend();","metadata":{"_cell_guid":"b98fb1f6-f3a2-434f-94c6-af01f3ffdfd4","_uuid":"bee64faeaacd2f60ff85ac8d2b61eea4e80afda8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**パッと見てわかること:**\n明らかに「季節性」（例：ある時期に売上がピークになる）があり、「トレンド」は減少しています。\n\nそこで、トレンド、季節性、残差に分解して確認してみましょう。\n","metadata":{"_cell_guid":"5fe94fac-46c3-43c5-b032-705cdfd43726","_uuid":"1a06f1b76571d5d09095148d07ddfa1e4e2002cc"}},{"cell_type":"code","source":"import statsmodels.api as sm\n# 積算\nres = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"multiplicative\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","metadata":{"_cell_guid":"b7c4c5fe-8a25-403d-8bb6-fa4f64699c00","_uuid":"611d345c3a3358dd34826c277bd2294247183c0e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 加算モデル\nres = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"additive\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","metadata":{"_cell_guid":"68db7d1b-1a74-48d2-96f0-78c8847981bb","_uuid":"80b4215987ff52e4e514b97093a54fc55461430a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rバージョンのpythonへの移植\n\n# alas ! rpy2 does not exist in Kaggle kernals :( \n# from rpy2.robjects import r\n# def decompose(series, frequency, s_window, **kwargs):\n#     df = pd.DataFrame()\n#     df['date'] = series.index\n#     s = [x for x in series.values]\n#     length = len(series)\n#     s = r.ts(s, frequency=frequency)\n#     decomposed = [x for x in r.stl(s, s_window, **kwargs).rx2('time.series')]\n#     df['observed'] = series.values\n#     df['trend'] = decomposed[length:2*length]\n#     df['seasonal'] = decomposed[0:length]\n#     df['residual'] = decomposed[2*length:3*length]\n#     return df","metadata":{"_cell_guid":"2176681b-44c0-4b11-9a11-f6172ba3d265","_uuid":"6261f5b777f4d539e383e6928f151b7db4dbf443","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"加法モデルを仮定すると、次のように書けます。\n\n> yt=St+Tt+Et \n\nここでytは期間tのデータ、Stは期間tの季節成分、Ttは期間ttのトレンド・サイクル成分、Etは期間tの残余（またはイレギュラー、エラー）成分です。\nMultiplicativeモデルも同様です。\n\n> yt=St  x Tt x Et \n\n## 定常性:\n\n![q](https://static1.squarespace.com/static/53ac905ee4b003339a856a1d/t/5818f84aebbd1ac01c275bac/1478031479192/?format=750w)\n\nStationarity（定常性）とは、時系列の時間的不変性を意味します。すなわち、時系列の2つの点は、互いにどれだけ離れているかだけで関係しており、方向（前進／後退）によっては関係していません。\n\n時系列が定常の場合、モデル化が容易になります。統計的なモデリング手法は、時系列が定常であることを前提としたり、必要としたりします。\n\n定常性をチェックするためには、複数の検定があります。\n* ADF( Augmented Dicky Fuller Test) \n* KPSS \n* PP (Phillips-Perron test)\n\nここでは、最も一般的に使用されているADFを実行してみましょう。\n\n注: [ExcelでDicky Fullerテストを行うためのガイド](http://www.real-statistics.com/time-series-analysis/stochastic-processes/dickey-fuller-test/)\n\n[その他の便利なガイド](http://www.blackarbs.com/blog/time-series-analysis-in-python-linear-models-to-garch/11/1/2016#AR) \n\n[オススメのリファレンス](https://github.com/ultimatist/ODSC17/blob/master/Time%20Series%20with%20Python%20(ODSC)%20STA.ipynb)\n","metadata":{"_cell_guid":"7e6f683b-a27d-4a68-9069-e0c713356339","_uuid":"a243f999421ec6d568a781d8a1f9baea720b09db"}},{"cell_type":"code","source":"# 定常性の検定\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\ntest_stationarity(ts)\n","metadata":{"_cell_guid":"0172ae25-5173-4645-960a-cedcb2800cb9","_uuid":"f98bc8fda199838bfa54b1b406e6c7f5023d16bb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# トレンドを取り除く\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob\n\n","metadata":{"_cell_guid":"0374ddff-dc1f-4d9b-82f9-f3eff9c9c4b0","_uuid":"a85f4e771a553ff529b46f25c183d33708055378","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,16))\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts)\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts)\nplt.plot(new_ts)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After De-seasonalization')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts,12)       # 季節性は12か月とおく\nplt.plot(new_ts)\nplt.plot()","metadata":{"_cell_guid":"c97fbab1-a301-46bd-95cb-5ba01cdef568","_uuid":"0904a2ab681ac5b3042f5e3d3ba9743955865266","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 季節性を除いた上で、改めて定常性の検定を行う\ntest_stationarity(new_ts)","metadata":{"_cell_guid":"9227dec3-bed4-4a12-bc69-563bd68cb3ff","_uuid":"aab34e83d42ceea015ce2f7fe1ace57a115fcd5f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 変換後、DF検定のp値は5%以内に収まっています。したがって、系列の定常性を仮定することができます。\n\n先ほど定義した逆変換関数を使えば、簡単に元のシリーズに戻すことができます。\n\nそれでは早速、予測を行ってみましょう。\n\n# AR, MA, ARMA:\nTL: モデルのDR版:\n\nMA - 系列の次の値は、前のn個の値の平均の関数\nAR - 次の値の誤差(平均値の差)は、前のn個の値の誤差の関数\nARMA - 両者の混合\n\nでは、時系列がARプロセスなのかMAプロセスなのかを調べるにはどうすればよいのでしょうか。\n\n早速見てみましょう！","metadata":{"_cell_guid":"66399279-b53f-4c3b-ad30-68353880a5b0","_uuid":"f6ba95bc505b6de75f94840eb4b1e1ce6ccc90e5"}},{"cell_type":"code","source":"def tsplot(y, lags=None, figsize=(10, 8), style='bmh',title=''):\n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n    with plt.style.context(style):    \n        fig = plt.figure(figsize=figsize)\n        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n        layout = (3, 2)\n        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1, 0))\n        pacf_ax = plt.subplot2grid(layout, (1, 1))\n        qq_ax = plt.subplot2grid(layout, (2, 0))\n        pp_ax = plt.subplot2grid(layout, (2, 1))\n        \n        y.plot(ax=ts_ax)\n        ts_ax.set_title(title)\n        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n        sm.qqplot(y, line='s', ax=qq_ax)\n        qq_ax.set_title('QQ Plot')        \n        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n\n        plt.tight_layout()\n    return ","metadata":{"_cell_guid":"85e12639-f2c2-4ce1-a57a-fba013e0c64c","_uuid":"30302a2f14d1e9a450672504ed3237e10af33d31","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AR(1)過程をalpha = 0.6でシミュレーション\nnp.random.seed(1)\nn_samples = int(1000)\na = 0.6\nx = w = np.random.normal(size=n_samples)\n\nfor t in range(n_samples):\n    x[t] = a*x[t-1] + w[t]\nlimit=12    \n_ = tsplot(x, lags=limit,title=\"AR(1)process\")","metadata":{"_cell_guid":"98e9a6bf-63af-4de5-bc5b-87a2b53749e6","_uuid":"274f0899031c6c8904cc2fc16278210bf60f44cf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AR(1) process -- has ACF tailing out and PACF cutting off at lag=1","metadata":{"_cell_guid":"e737518c-d725-4ed2-a01d-f82986db65af","_uuid":"b3bfab2ac67a745c9aa1c1c495a958383ebd4b45"}},{"cell_type":"code","source":"# AR(2)過程をシミュレーションする\n\nn = int(1000)\nalphas = np.array([.444, .333])\nbetas = np.array([0.])\n\n# Pythonでは、ゼロラグの値を1に指定する必要があります。\n# ARモデルのアルファは否定されなければならないことにも注意してください。\n# AR(p)モデルの場合は、MAのベータ値を0に設定します。\n# 詳細は statsmodels.org の例を参照してください。\n\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nar2 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \n_ = tsplot(ar2, lags=12,title=\"AR(2) process\")","metadata":{"_cell_guid":"c0ae4820-5e6e-4f51-b870-caff9f093a65","_uuid":"bfa6b99d581c1a11248254634fb3932bc0de7a0b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AR(2) process -- has ACF tailing out and PACF cutting off at lag=2","metadata":{"_cell_guid":"789221b6-4c5f-4e22-b740-abd904310050","_uuid":"0e64eb4625e7fed1ea67892cd1ce76f521ed2e43"}},{"cell_type":"code","source":"# MA(1)過程をシミュレーションする\nn = int(1000)\n# set the AR(p) alphas equal to 0\nalphas = np.array([0.])\nbetas = np.array([0.8])\n# add zero-lag and negate alphas\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\nma1 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \nlimit=12\n_ = tsplot(ma1, lags=limit,title=\"MA(1) process\")","metadata":{"_cell_guid":"d87cb6df-a332-4ac0-bf2d-df690a4a3510","_uuid":"8b6e8e1fb9d5d32e925a3eb5718bbb3fed09c585","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MA(1) process -- has ACF cut off at lag=1","metadata":{"_cell_guid":"8974f547-b74a-4b01-822b-0512bcfbd428","_uuid":"bb9116b36c617672b13e339afd14209c0ea72493"}},{"cell_type":"code","source":"# MA(2)過程をbetas=0.6, 0.4でシミュレーションする\nn = int(1000)\nalphas = np.array([0.])\nbetas = np.array([0.6, 0.4])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nma3 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n)\n_ = tsplot(ma3, lags=12,title=\"MA(2) process\")","metadata":{"_cell_guid":"266ed44d-a2af-40b2-bc70-1f8c92c97cd4","_uuid":"50d9e7da3491a1da9c88d2da1038651e4dd18931","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MA(2) process -- has ACF cut off at lag=2","metadata":{"_cell_guid":"cc105523-c043-41f2-8c33-0e73c2b5eef0","_uuid":"1e3b61a68f1d1840e2d136087ed2daa3991c5e18"}},{"cell_type":"code","source":"# ARMA(2, 2)モデルをalphas=[0.5,-0.25], betas=[0.5,-0.3]でシミュレーションする\nmax_lag = 12\n\nn = int(5000) # lots of samples to help estimates\nburn = int(n/10) # number of samples to discard before fit\n\nalphas = np.array([0.8, -0.65])\nbetas = np.array([0.5, -0.7])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\narma22 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n, burnin=burn)\n_ = tsplot(arma22, lags=max_lag,title=\"ARMA(2,2) process\")","metadata":{"_cell_guid":"c9c8d060-8572-426f-87d9-e786d82ad205","_uuid":"3bb2c3992a9b0fdbe9bc1a4f1dfcf7153e925c31","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ここから先は少しぼんやりしています。あまり明確ではありません。\n\n上記のプロットをまとめると、以下のようになります:\n\nACF Shape\t| Indicated Model |\n-- | -- |\n指数関数的に、ゼロまで減衰する |\t自己回帰モデル。部分自己相関プロットを使って自己回帰モデルの次数を特定する |\n正と負を交互に繰り返す、ゼロに減衰する 自己回帰モデル |  部分自己相関プロットを使用して順序を特定する |\n1つ以上のスパイク、残りは基本的にゼロ | 移動平均モデル、プロットがゼロになる場所で順序を識別 |\n数回のラグの後に減衰 |\t混合自己回帰・移動平均（ARMA）モデル | \nすべてゼロまたはゼロに近い | データは基本的にランダム |\n一定の間隔で高い値が出る | 季節性自己回帰項を含む |\nゼロまで減衰しない |\t系列は定常的でない |\n\n\n## ARとMAのプロセスの順番を見つけるために、システム的なアプローチをしてみましょう。","metadata":{"_cell_guid":"50fe1c7f-2524-4fa1-8e30-3f14232b7ac6","_uuid":"8bac724eafd54b4e8c2ec85ccf3f54496a61d525"}},{"cell_type":"code","source":"# aicで最適な順番を選ぶ \n# 最小のaic値が勝つ\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(arma22, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))\n","metadata":{"_cell_guid":"fce4e806-d217-4b2c-9df6-e38c3d03208b","_uuid":"67306349432a683c926a812bd071915bf5e23e18","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## シミュレーションされたプロセスの次数がARMA(2,2)であることを正しく認識しました。\n\n### これをセールスの時系列データに使ってみましょう。\n","metadata":{"_cell_guid":"f9f28bdd-6b6e-4522-9644-f8d6020d830f","_uuid":"e32468dcd2ea44e9477adc212eb7175875dba33b"}},{"cell_type":"code","source":"# aicで最適な順番を選ぶ \n# 最小のaic値が勝つ\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(new_ts.values, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))\n","metadata":{"_cell_guid":"4adcd9c6-63eb-41c2-82f3-4bde0ce556ef","_uuid":"43f731d8b664c9531464d8766f1fc911dd69b2e0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_mdl.predict()を使って次の値を予測するだけです。","metadata":{"_cell_guid":"62dacf92-a612-4342-812f-8936f45c1dce","_uuid":"733861273519695c485dd59e8cb483e0b91802f3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 日付をインデックスとして時系列に追加する\nts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.index=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nts=ts.reset_index()\nts.head()","metadata":{"_cell_guid":"9f22f870-38b0-44f2-b7cf-90dfc3fefaa6","_uuid":"dd7ffaeba28472d4bc2e8a0b4de8b6613b38b83e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prophet: \n\n最近、Facebookの研究によってオープンソース化されました。これは非常に有望なツールで、イライラする**フラットライン**の解決に、しばしば非常に便利で迅速な解決策となります。\n\n![フラットライン](https://i.stack.imgur.com/fWzyX.jpg)\n\n確かに、適切な前処理を行い、パラメータを慎重に調整すれば、上のグラフのようなことは起こらないと言うこともできます。\n\nしかし、実際のところ、私たちのほとんどは、それを実現するための忍耐力も専門知識も持ち合わせていません。\n\nまた、ほとんどの実用的なシナリオでは、予測が必要な時系列がたくさんあるという事実があります。\n例えば、今回のコンペでは、店舗とアイテムレベルの組み合わせについて、翌月の売上を予測する必要がありますが、その数は数千にも及ぶ可能性があります。\n\nもう1つの優れた機能は、典型的な**sklearn**の構文に従っていることです。\n\nProphetメソッドの核となるのは、4つの主要なコンポーネントからなる加法回帰モデルです。\n\n* ピースワイズ・リニアまたはロジスティック成長曲線のトレンド。Prophetは、データからチェンジポイントを選択することで、トレンドの変化を自動的に検出します。\n* フーリエ級数を使ってモデル化された年間の季節成分\n* ダミー変数を使った週単位の季節成分\n* ユーザーが提供した重要な祝日のリスト\n\n**prophetについて詳しく知るためのリソース:**\n* https://www.youtube.com/watch?v=95-HMzxsghY\n* https://facebook.github.io/prophet/docs/quick_start.html#python-api\n* https://research.fb.com/prophet-forecasting-at-scale/\n* https://blog.exploratory.io/is-prophet-better-than-arima-for-forecasting-time-series-fa9ae08a5851","metadata":{"_cell_guid":"5cd6369a-20e7-4586-b9ec-5d804ea64528","_uuid":"d8c35e14d08d580907da6ed43e684ab9b89fb6cf"}},{"cell_type":"code","source":"from fbprophet import Prophet\n# prophetは以下の設定でpandas dfを必要とします。\n# ( date column named as DS and the value column as Y)\nts.columns=['ds','y']\nmodel = Prophet( yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel.fit(ts) #fit the model with your dataframe","metadata":{"_cell_guid":"e0f1d568-e74b-4b4d-970f-17ed78ad6c04","_uuid":"5515d79d56f071c77c955be1ef36de528f953306","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict for five months in the furure and MS - month start is the frequency\nfuture = model.make_future_dataframe(periods = 5, freq = 'MS')  \n# now lets make the forecasts\nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","metadata":{"_cell_guid":"1dc15d33-ea9c-47b3-9f10-379e8f259606","_uuid":"d9377c6f2e7537cfaebc606049977154a4cce49a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.plot(forecast)","metadata":{"_cell_guid":"c1120a17-8947-42cd-84ee-424f0b60d5d7","_uuid":"695836bdeb4e148f08e3f3349e89bf4345781ca1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.plot_components(forecast)","metadata":{"_cell_guid":"9821912e-76eb-4997-a4cc-cb111998370b","_uuid":"d3ea5a00ce7d8e7f568a0c900cacc59d58c2893e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"凄いですね。プロフェットからのトレンドや季節感は、以前に伝統的な方法で行ったものと似ています。\n\n## UCM:\n\nUnobserved Components Modelの略です。ここでの直感は、prophetのそれと似ています。このモデルでは、時系列をトレンド、季節、サイクルといった構成要素に分解し、それらを回帰させ、構成要素の次のポイントを予測し、それらを組み合わせます。\n\n残念ながら、Pythonでこのモデルを実行できる良いパッケージ/コードは見つかりませんでした :( \n\nUCMのRバージョン: https://bicorner.com/2015/12/28/unobserved-component-models-in-r/\n\n# 階層型時系列:\n\nThe [Forecasting: principles and practice](https://www.otexts.org/fpp/9/4) , は、Rob J Hyndman氏による予測のための究極の参考書です。\n彼は、グループ化された、あるいは階層的な予測を扱うための基本を説明しています。次のような簡単なシナリオを考えてみましょう。\n\nHyndmanはこの階層のポイントを推定するために以下の方法を提案しています。直感的に理解できるように言葉を簡略化してみました。\n\n### ボトムアップアプローチ:\n* 任意の方法でベースレベルのシリーズをすべて予測し、それをトップに集約するだけです。\n* 利点: 単純であること、集計によって情報が失われないこと。\n* 不利な点: 下位レベルはノイズが多い\n\n### トップダウンアプローチ:\n* トップレベルを最初に予測する。(例：総売上高を最初に予測する)\n* 次に、ベースレベルの予測に与える必要のある総売上高の割合を示す**重み**を計算します（例：総売上高に対するアイテムの売上の貢献度）。\n* 「ウェイト」を算出する方法はさまざまです。\n    * **過去の平均比率** - 過去数ヶ月間のアイテムの売上貢献度の単純平均値\n    * **過去の平均値に占める割合** - Weightは、下位シリーズの平均値と全シリーズの平均値の比率です。\n    * **予想される割合** - 過去の割合の変化から将来の割合を予測する\n* これらのウェイトを使って、ベースとなる予測値やその他のレベルを算出します。\n\n### ミドルアウト:\n* ボトムアップとトップダウンの両方を併用する。\n* 例：店舗-アイテムレベルの予測を行う問題を考えてみましょう。\n    * 中間レベル（店舗）を取り、店舗の予測を見つける。\n    * ボトムズアップで全体の売上高を求める。\n    * 比例を使って店舗の売上を分解し、トップダウン・アプローチでアイテムレベルの売上を求める。\n    \n### 最適な組み合わせのアプローチ:\n* すべての層を独立して予測する\n* すべての層が独立しているため、階層間の整合性が取れない可能性があります。\n    * 例：アイテムが独立して予測されているため、店舗で販売されたアイテムの合計は、店舗の予測販売額とは一致しない可能性がありますが、ヒンドマンは「集約的な一貫性」と表現しています。\n* 予測を階層と整合させるためのアドホックな調整を行うために、いくつかのマトリックス計算と調整が行われます。\n\n\n### 理論はもういい。予測を始めましょう！\n今回の問題では、アイテム数が22170、ストア数が60です。つまり、予測すべき時系列（アイテムとストアの組み合わせ）は、**約100万個**もあるということです。\n\nそれらを一つ一つ設定するのはほとんど不可能です。そこで、それを代行してくれるProphetを使いましょう。\n\nボトムズアップのアプローチで始めましょう。\n\nここでは他にも考慮すべき点があります。\n* すべての店舗がすべての商品を販売しているわけではない\n* 新商品が出たらどうする？\n* 製品が棚から取り除かれた場合は？","metadata":{"_cell_guid":"4d72929a-1363-40b1-9394-9d9bc3cbbfcd","_uuid":"50aff39e479cc20c9898b3a9e008eae2bc2eb713"}},{"cell_type":"code","source":"total_sales=sales.groupby(['date_block_num'])[\"item_cnt_day\"].sum()\ndates=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\n\ntotal_sales.index=dates\ntotal_sales.head()","metadata":{"_cell_guid":"f628232b-2b87-4ecf-98a9-df85b8cfa079","_uuid":"c32a2ee89ed90af6aa786af833a27b3b2570117f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 月次の販売データからアイテム・ストアのユニークな組み合わせを取得する\nmonthly_sales=sales.groupby([\"shop_id\",\"item_id\",\"date_block_num\"])[\"item_cnt_day\"].sum()\n# arrange it conviniently to perform the hts \nmonthly_sales=monthly_sales.unstack(level=-1).fillna(0)\nmonthly_sales=monthly_sales.T\ndates=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nmonthly_sales.index=dates\nmonthly_sales=monthly_sales.reset_index()\nmonthly_sales.head()","metadata":{"_cell_guid":"8c62a4c2-c482-417c-ba56-b376584706e7","_uuid":"da06ef3cef98055ec146eb21b2ac4cdc580b73c7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nstart_time=time.time()\n\n# Bottoms up\n# Calculating the base forecasts using prophet\n# From HTSprophet pachage -- https://github.com/CollinRooney12/htsprophet/blob/master/htsprophet/hts.py\nforecastsDict = {}\nfor node in range(len(monthly_sales)):\n    # take the date-column and the col to be forecasted\n    nodeToForecast = pd.concat([monthly_sales.iloc[:,0], monthly_sales.iloc[:, node+1]], axis = 1)\n#     print(nodeToForecast.head())  # just to check\n# rename for prophet compatability\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[0] : 'ds'})\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[1] : 'y'})\n    growth = 'linear'\n    m = Prophet(growth, yearly_seasonality=True)\n    m.fit(nodeToForecast)\n    future = m.make_future_dataframe(periods = 1, freq = 'MS')\n    forecastsDict[node] = m.predict(future)\n    if (node== 10):\n        end_time=time.time()\n        print(\"forecasting for \",node,\"th node and took\",end_time-start_time,\"s\")\n        break\n    ","metadata":{"_cell_guid":"ef4ffa1f-170b-421f-9a87-1798cb7ca885","_uuid":"480e0c16e34f95bca30da929861e2c1de14410e4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"~10回の予測で～16秒。100万回の予測が必要です。これではうまくいきません。\n\n# ミドルアウト:\n店舗レベルで予測してみましょう","metadata":{"_cell_guid":"3a0487c9-1e58-4d37-859a-23776598eac2","_uuid":"e60bf72b1fbbf5c11c1a6e6302a8497ecf2c6dd0"}},{"cell_type":"code","source":"monthly_shop_sales=sales.groupby([\"date_block_num\",\"shop_id\"])[\"item_cnt_day\"].sum()\n# get the shops to the columns\nmonthly_shop_sales=monthly_shop_sales.unstack(level=1)\nmonthly_shop_sales=monthly_shop_sales.fillna(0)\nmonthly_shop_sales.index=dates\nmonthly_shop_sales=monthly_shop_sales.reset_index()\nmonthly_shop_sales.head()","metadata":{"_cell_guid":"458386cd-bd4b-41ad-ac59-a2b0135b89fb","_uuid":"0e1e93358ddc83308b5f16910816977750c8ac87","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time=time.time()\n\n# Calculating the base forecasts using prophet\n# From HTSprophet pachage -- https://github.com/CollinRooney12/htsprophet/blob/master/htsprophet/hts.py\nforecastsDict = {}\nfor node in range(len(monthly_shop_sales)):\n    # take the date-column and the col to be forecasted\n    nodeToForecast = pd.concat([monthly_shop_sales.iloc[:,0], monthly_shop_sales.iloc[:, node+1]], axis = 1)\n#     print(nodeToForecast.head())  # just to check\n# rename for prophet compatability\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[0] : 'ds'})\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[1] : 'y'})\n    growth = 'linear'\n    m = Prophet(growth, yearly_seasonality=True)\n    m.fit(nodeToForecast)\n    future = m.make_future_dataframe(periods = 1, freq = 'MS')\n    forecastsDict[node] = m.predict(future)\n    ","metadata":{"_cell_guid":"f812b9fc-a079-4f0f-a19d-5618bf499228","_uuid":"75e7e20609e23bd676cc9781619940a3febf3cab","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predictions = np.zeros([len(forecastsDict[0].yhat),1]) \nnCols = len(list(forecastsDict.keys()))+1\nfor key in range(0, nCols-1):\n    f1 = np.array(forecastsDict[key].yhat)\n    f2 = f1[:, np.newaxis]\n    if key==0:\n        predictions=f2.copy()\n       # print(predictions.shape)\n    else:\n       predictions = np.concatenate((predictions, f2), axis = 1)","metadata":{"_cell_guid":"bc342fe1-72cc-46ba-bc52-5bb4fed994fb","_uuid":"cc93cc3b4f09a2e5a0bbaf86cc683f168557e004","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_unknown=predictions[-1]\npredictions_unknown","metadata":{"_cell_guid":"f6f0ea03-3500-4580-8c3a-b024f8f43a6d","_uuid":"689180c42779b32ab3ea7cffd9f2889e84b0ba4e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 脚注:\n\n私は統計学を専攻しているわけではないので、重要な技術が抜けていたり、内容に間違いがあったりしたら、コメントで教えてください。\n\n時系列に関する別のカーネルをここに追加する予定で、最近の時系列コンペティション（Favorita、Recruitなど）のオープンソースソリューションをこのプレイグラウンドデータセットに適応させることを考えています。\n\nコメントやアップヴォートをお願いします。) ","metadata":{"_cell_guid":"4b521c08-cd33-442b-b639-2163209b3daf","_uuid":"43e42792956ed2c45eb0f650f0e875c73221814f"}}]}