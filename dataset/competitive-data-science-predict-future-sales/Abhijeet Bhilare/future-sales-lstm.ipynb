{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datetime import datetime, date\nfrom dateutil.relativedelta import relativedelta\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom math import ceil\n\nfrom keras.callbacks import LambdaCallback\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers import LSTM\nfrom keras.optimizers import RMSprop\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')\nsubmission = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')\nitems = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\nitem_cats = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_shops = test.shop_id.unique()\ntrain = train[train.shop_id.isin(test_shops)]\ntest_items = test.item_id.unique()\ntrain = train[train.item_id.isin(test_items)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_BLOCK_NUM = train.date_block_num.max()\nMAX_ITEM = len(test_items)\nMAX_CAT = len(item_cats)\nMAX_YEAR = 3\nMAX_MONTH = 4\nMAX_SHOP = len(test_shops)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.set_index('item_id').join(items.set_index('item_id')).drop('item_name', axis=1).reset_index()\ntrain['month'] = train.date.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').strftime('%m'))\ntrain['year'] = train.date.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').strftime('%Y'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop('date', axis=1)\ntrain = train.drop('item_category_id', axis=1)\ntrain = train.groupby(['shop_id', 'item_id', 'date_block_num', 'month', 'year']).sum()\ntrain = train.sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ncnt_scaler = StandardScaler()\n\nscaler.fit(train.item_price.to_numpy().reshape(-1, 1))\ncnt_scaler.fit(train.item_cnt_day.to_numpy().reshape(-1, 1))\n\ntrain.item_price = scaler.transform(train.item_price.to_numpy().reshape(-1, 1))\ntrain.item_cnt_day = cnt_scaler.transform(train.item_cnt_day.to_numpy().reshape(-1, 1))\ntrain.reset_index().groupby(['item_id', 'date_block_num', 'shop_id']).mean()\nprice = train.reset_index().set_index(['item_id', 'shop_id', 'date_block_num'])\nprice = price.sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert(date_block):\n    date = datetime(2013, 1, 1)\n    date += relativedelta(months = date_block)\n    return (date.month, date.year)\n\ndef closest_date_block(current_day, item_id, shop_id):\n    if (item_id, shop_id) in price.index:\n        search_lst = np.array(price.loc[(item_id, shop_id)].index, dtype=np.float16)        \n        return search_lst[np.abs(current_day - search_lst).argmin()]\n    return -1\n                \ndef closest_price(current_day, item_id, shop_id):\n    closest_date = closest_date_block(current_day, item_id, shop_id)\n    if closest_date != -1:\n        return price.loc[( item_id, shop_id, closest_date )]['item_price']\n    return np.nan\n\ndef closest_price_lambda(x):\n    return closest_price(34, x.item_id, x.shop_id)\n\nassert closest_date_block(18, 30, 5) == 18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 4\nstep = 1\nsentences = [[],[],[]]\nnext_chars = [[], []]\nBLOCKS = [6, 18, 30]\n\nfor s in test_shops:\n    shop_items = list(train.loc[s].index.get_level_values(0).unique())\n    for it in shop_items:        \n        for i_index, i in enumerate(BLOCKS):\n            sentence = []\n            closest_pc = closest_price(i, it, s)            \n            for j in range(maxlen+1):\n                if j < maxlen:\n                    if (s, it, i+j) in train.index:\n                        r = train.loc[(s, it, i + j)].to_dict(orient='list')                    \n                        closest_pc = r['item_price'][0]\n                        item_cnt_day = r['item_cnt_day'][0]\n                        row = {'shop_id': s, 'date_block_num': i+j, 'item_cnt_day': item_cnt_day, \n                               'month': month, 'item_id': it, 'item_price': closest_pc, 'year': year}\n                    else:\n                        month, year = convert(i+j)                    \n                        row = {'shop_id': s, 'date_block_num': i+j, 'item_cnt_day': 0, \n                               'month': month, 'item_id': it, 'item_price': closest_pc, 'year': year}\n                    sentence.append(row)\n                elif i_index < 2: \n                    next_chars[i_index].append(row)\n            sentences[i_index].append(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_o = np.array(sentences[0])\nx_val_o = np.array(sentences[1])\nx_test_o = np.array(sentences[2])\ny_train = np.array([x['item_cnt_day'] for x in next_chars[0]])\ny_val = np.array([x['item_cnt_day'] for x in next_chars[1]])\nlength = MAX_SHOP + MAX_ITEM + MAX_MONTH + 1 + 1 + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nshop_le = preprocessing.LabelEncoder()\nshop_le.fit(test_shops)\nshop_dm = dict(zip(test_shops, shop_le.transform(test_shops)))\n\nitem_le = preprocessing.LabelEncoder()\nitem_le.fit(test_items)\nitem_dm = dict(zip(test_items, item_le.transform(test_items)))\n\nmonth_le = preprocessing.LabelEncoder()\nmonth_le.fit(range(7,11))\nmonth_dm = dict(zip(range(7,11), month_le.transform(range(7,11))))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vectorize(inp):\n    x = np.zeros((len(inp), maxlen, length), dtype=np.float16)\n    for i, sentence in enumerate(inp):\n        for t, char in enumerate(sentence):            \n            x[i][t][ shop_dm[char['shop_id']] ] = 1     \n            x[i][t][ MAX_SHOP + item_dm[char['item_id']] ] = 1\n            x[i][t][ MAX_SHOP + MAX_ITEM + month_dm[char['month']] ] = 1\n            x[i][t][ MAX_SHOP + MAX_ITEM + MAX_MONTH + 1 ] = char['item_price']\n            x[i][t][ MAX_SHOP + MAX_ITEM + MAX_MONTH + 1 + 1] = char['item_cnt_day']    \n    return x\nx_train = vectorize(x_train_o)\nx_val = vectorize(x_val_o)\nx_test = vectorize(x_test_o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(32, input_shape=(maxlen, length)))\nmodel.add(Dense(1, activation='relu'))\n\noptimizer = RMSprop(lr=0.005)\nmodel.compile(loss='mean_squared_error', optimizer=optimizer)\n\nmodel.fit(x_train, y_train, batch_size=128, epochs=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test = model.predict(x_test)\npredict_test = cnt_scaler.inverse_transform(predict_test)\ntest = test.set_index(['shop_id', 'item_id'])\ntest['item_cnt_month'] = 0\nfor index, sentence in enumerate(x_test_o):\n    (shop_id, item_id) = (sentence[0]['shop_id'], sentence[0]['item_id'])\n    test.loc[(shop_id, item_id)]['item_cnt_month'] = predict_test[index]\ntest = test.reset_index().drop(['shop_id', 'item_id'], axis=1)\ntest.to_csv('future_sales_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}