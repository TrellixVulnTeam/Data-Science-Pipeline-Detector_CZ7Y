{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Final project"},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## Import packages"},{"metadata":{},"cell_type":"markdown","source":"import textdistance to calculate Levenshtein distance"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"!pip install textdistance","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nfrom itertools import product\nimport textdistance\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\nfrom datetime import datetime, date\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Useful functions"},{"metadata":{},"cell_type":"markdown","source":"create a useful function to reduce data size"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# downcast \ndef downcast(df):\n    df_dtypes = df.dtypes\n    new_dtypes = []\n    for idx, col_dtype in enumerate(df_dtypes):\n        if col_dtype == \"float64\":\n            new_dtypes.append(np.float16)\n        elif col_dtype in [\"int64\", \"int32\", \"int16\"]:\n            if df[df.columns[idx]].min() >= -128 and df[df.columns[idx]].max() <= 127:\n                new_dtypes.append(np.int8)\n            elif df[df.columns[idx]].min() >= -32768 and df[df.columns[idx]].max() <= 32767:\n                new_dtypes.append(np.int16)\n            elif df[df.columns[idx]].min() >= -2147483648  and df[df.columns[idx]].max() <= 2147483647:\n                new_dtypes.append(np.int32)\n            else:\n                new_dtypes.append(np.int64)\n        else:\n            new_dtypes.append(col_dtype)\n            \n    return df.astype(dict(zip(df.columns,new_dtypes)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data"},{"metadata":{},"cell_type":"markdown","source":"I previously translated shops and item_categories data set by googletrans API."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# load data\ntrain = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\n\n# item_categories = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\n# shops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\n\nitem_categories = pd.read_pickle('../input/translated/item_categories.pkl')\nshops = pd.read_pickle('../input/translated/shops.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### panda display option"},{"metadata":{},"cell_type":"markdown","source":"for the purpose of dataframe visulization"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"pd.options.display.precision = 6\npd.options.display.float_format = '{:.2f}'.format","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# check\nprint(\"-----------------train-------------------------\")\ntrain.info()\nprint(train.head())\nprint(train.describe())","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# check\nprint(\"-----------------test-------------------------\")\ntest.info()\nprint(test.head())\nprint(test.describe())","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# check\nprint(\"-----------------item_categories-------------------------\")\nitem_categories.info()\nprint(item_categories.head())\nprint(item_categories.describe())","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# check\nprint(\"-----------------items-------------------------\")\nitems.info()\nprint(items.head())\nprint(items.describe())","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# check\nprint(\"-----------------shops-------------------------\")\nshops.info()\nprint(shops.head())\nprint(shops.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"## Train\n"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# check duplicated rows\nprint(train.duplicated().count())\n\n# delete duplicated rows\ntrain = train[~train.duplicated()]\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# plot\n#date_block_num \n\ntrain[\"date_block_num\"].value_counts(normalize=True).sort_index().plot(kind=\"bar\", figsize = (15,5))\n\n# 11 and 23 have a large number of sales","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"#shop_id   \n\ntrain[\"shop_id\"].value_counts(normalize=True).plot(kind=\"bar\", figsize = (15,5))\n\n# Some shops have a large number of sales, ","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"#item_id     \n\ntrain[\"item_id\"].plot(kind=\"hist\", figsize = (15,5))\n\n# The distribution is not even. Some items seem to have more sales than others.","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.boxplot(train[\"item_id\"].value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"#item_price     \n\ntrain[\"item_price\"].plot(kind=\"hist\", figsize = (15,5))\n\n# Maybe there are outliers","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[\"item_id\"].value_counts().plot(kind=\"hist\", figsize = (15,5))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%   \n"},"trusted":true},"cell_type":"code","source":"#item_cnt_day      \n\ntrain[\"item_cnt_day\"].plot(kind=\"hist\", figsize = (15,5))\n\n# Maybe there are outliers","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[\"item_id\"].value_counts().plot(kind=\"hist\", figsize = (15,5))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[\"item_id\"].value_counts().sort_values(ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers in train"},{"metadata":{},"cell_type":"markdown","source":"#### shop_id  "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"#shop_id   \n\nplt.figure(figsize=(15,5))\nsns.boxplot(train[\"shop_id\"].value_counts(normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[\"shop_id\"].value_counts(normalize=True).sort_values(ascending=False)[:10]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take in account that the distribution of shop sales in uneven"},{"metadata":{},"cell_type":"markdown","source":"#### item_id  "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[\"item_id\"].value_counts().sort_values(ascending=False)[:10]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"item_id 20949 seems to make a large number of sales"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"items.loc[items[\"item_id\"]==20949]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What is that ?"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"item_categories.loc[item_categories[\"item_category_id\"]==71]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"plot item_id 20949 across date_block_num "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train.loc[train[\"item_id\"]==20949][\"date_block_num\"].value_counts(normalize=True).sort_index().plot(kind=\"bar\", figsize = (15,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Except date_block_num 0, 1 and 2, this item has been sold across the entire period. It seems that this item launched on date_block_num 3.   \nIt is something strange that sales decrease towards date_block_num 24. Maybe it is substituted by another item or chaged its price. "},{"metadata":{},"cell_type":"markdown","source":"#### item_price "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"#item_price     \nplt.figure(figsize=(15,5))\nsns.boxplot(train[\"item_price\"])","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[\"item_price\"].sort_values(ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently there are some outliers."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[train['item_price'] == 307980]","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"items.loc[items[\"item_id\"]==6066]","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"item_categories.loc[item_categories[\"item_category_id\"]==75]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Radmin 3 - 522 лиц. seems to be a computer software and this item was sold only one day in the entire period with high price.  \nTherefore, it is reasonable to delete this item from the train set.  \nMake sure that the test set does not contain this item"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test[test[\"item_id\"]==6066].empty","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Delete item_id 6066 from train set"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train = train[train[\"item_id\"] != 6066]\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[train['item_price'] < 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"item_price < 0 is wired. "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"items.loc[items[\"item_id\"]==2978]","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"item_categories.loc[item_categories[\"item_category_id\"]==31]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a pc game but it is not clear why the price is -1. Maybe an eror. So delete item_id 2978."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train = train[train[\"item_id\"] != 2978]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### item_cnt_day"},{"metadata":{"pycharm":{"name":"#%%   \n"},"trusted":true},"cell_type":"code","source":"train[\"item_cnt_day\"].sort_values(ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Outliers ?"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[train[\"item_cnt_day\"] > 999]","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"items.loc[items[\"item_id\"]==11373]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What is that ?"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"item_categories.loc[item_categories[\"item_category_id\"]==9]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Доставка до пункта выдачи (Boxberry) seems to be a delivery service."},{"metadata":{},"cell_type":"markdown","source":"plot item_cnt_day of item_id 11373"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(15,5))\nsns.boxplot(train[train[\"item_id\"]==11373][\"item_cnt_day\"])","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train[train[\"item_id\"]==11373][\"item_cnt_day\"].sort_values(ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As this value is quite extreme, it should be deleted from the train set."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"\ntrain = train[train[\"item_cnt_day\"] < 1000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### test"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# check duplicated rows\nprint(test[[\"shop_id\", \"item_id\"]].duplicated().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no duplicated row in the test set"},{"metadata":{},"cell_type":"markdown","source":"#### shop_id"},{"metadata":{},"cell_type":"markdown","source":"See the distribution"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test[\"shop_id\"].value_counts().sort_index().plot(kind=\"bar\", figsize = (15,5))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test[\"shop_id\"].value_counts().sort_values()[:10]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution is really even ?"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test[\"shop_id\"].value_counts().sort_values()[-5:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"very interesting that all shops have same number of rows, 5100"},{"metadata":{},"cell_type":"markdown","source":"#### item_id\n"},{"metadata":{},"cell_type":"markdown","source":"See the distribution"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.boxplot(test[\"item_id\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test[\"item_id\"].value_counts().sort_values()[:10]","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test[\"item_id\"].value_counts().sort_values()[-10:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"interesting all items appear same number 42 times"},{"metadata":{},"cell_type":"markdown","source":"## Shop"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"mat = np.zeros((shops.shape[0], shops.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"calculate levenshtein distance"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"for row in range(shops.shape[0]):\n    for col in range(shops.shape[0]):\n        mat[row, col] = textdistance.levenshtein.normalized_similarity(shops[\"shop_name\"][row], shops[\"shop_name\"][col])\n# if 1 set as 0\nmat = np.where(mat == 1 , 0, mat)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(mat, vmin = 0.7, xticklabels = 1, yticklabels = 1)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# 0.7 as threshold\nshop_name_duplicated = pd.DataFrame(np.transpose(np.nonzero(np.where(mat > 0.7, mat, 0))))\nshop_name_duplicated = shop_name_duplicated[~shop_name_duplicated.apply(frozenset, axis=1).duplicated()].reset_index(drop=True)\nprint(shop_name_duplicated)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"for index, row in shop_name_duplicated.iterrows():\n    print(\"shop_id:\", row[0], \"shop_name:\", shops.loc[shops[\"shop_id\"] == row[0], \"shop_name\"].values[0])\n    print(\"shop_id:\", row[1], \"shop_name:\", shops.loc[shops[\"shop_id\"] == row[1], \"shop_name\"].values[0])\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some shops seem to be the same."},{"metadata":{},"cell_type":"markdown","source":"plot of item_cnt_days across the entire period (date_block_num) by pairs of shops"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"\nfig, ((ax0,ax1), (ax2,ax3), (ax4,ax5), (ax6,ax7)) = plt.subplots(4, 2, figsize=(15, 20))\n\nfor index, row in shop_name_duplicated.iterrows():\n    data = train[[\"date_block_num\", \"item_cnt_day\", \"shop_id\"]].query('shop_id == @row[0] or shop_id == @row[1]')\\\n        .groupby([\"shop_id\", \"date_block_num\"]).sum().reset_index()\n    sns.lineplot(x=\"date_block_num\", y=\"item_cnt_day\", hue=\"shop_id\", legend = \"full\", data=data, ax=eval(\"ax\" + str(index)),  palette = [\"Blue\", \"Green\"])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plots show that the following shop's names are cosiderated as the same shop:  \n\n- 0 and 57   \n- 1 and 58  \n- 10 and 11  \n- 23 and 24  "},{"metadata":{},"cell_type":"markdown","source":"To correct shop_id in the train and test set, check if the test set contains all these shop_id"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test[test.isin({\"shop_id\":[0,57,1,58,10,11,23,24]})[\"shop_id\"]][\"shop_id\"].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The right way to change shop_id is the following:\n\n- 0 to 57 \n- 1 to 58\n- 23 to 24\n- 11 to 10"},{"metadata":{},"cell_type":"markdown","source":"shop_id 10 and 11"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train.loc[train[\"shop_id\"]==10].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The two lines are overlapped."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train.loc[train[\"shop_id\"]==11].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The shop 11 contains only data of date_block_num 25. "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# plot \nplt.figure(figsize=(15,5))\nsns.countplot(x=\"date_block_num\", hue=\"shop_id\", data = train.query('shop_id == [10, 11]'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The shop 11 might be the shop 10 in the date_block_num 25."},{"metadata":{},"cell_type":"markdown","source":"shop_id correction"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train.loc[train[\"shop_id\"]== 0, \"shop_id\"] = 57\ntest.loc[test[\"shop_id\"]== 0, \"shop_id\"] = 57\n\ntrain.loc[train[\"shop_id\"]== 1, \"shop_id\"] = 58\ntest.loc[test[\"shop_id\"]== 1, \"shop_id\"] = 58\n\ntrain.loc[train[\"shop_id\"]== 23, \"shop_id\"] = 24\ntest.loc[test[\"shop_id\"]== 23, \"shop_id\"] = 24\n\ntrain.loc[train[\"shop_id\"]== 11, \"shop_id\"] = 10\ntest.loc[test[\"shop_id\"]== 11, \"shop_id\"] = 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and Test relationships\n\nTo check all possible combinations of shop_id and item_id of the test data appear at least one in the train data "},{"metadata":{},"cell_type":"markdown","source":"## unique values and combinations"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"print(\"shop_id:\", \"train:\" , len(train[\"shop_id\"].unique()), \"test:\", len(test[\"shop_id\"].unique()))\nprint(\"item_id:\", \"train:\" , len(train[\"item_id\"].unique()), \"test:\", len(test[\"item_id\"].unique()))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_comb = train[[\"shop_id\", \"item_id\"]].drop_duplicates()\nprint(train_comb)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test_comb = test[[\"shop_id\", \"item_id\"]].drop_duplicates()\nprint(test_comb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no duplicated combinations in the test set."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"unseen_shops = test_comb.shop_id[~test_comb[\"shop_id\"].isin(train_comb[\"shop_id\"])].drop_duplicates()\nunseen_items = test_comb.item_id[~test_comb[\"item_id\"].isin(train_comb[\"item_id\"])].drop_duplicates()\nprint(\"In the test set:\", unseen_shops.count(), \"unseen shops\",\"and\", unseen_items.count(), \"unseen items\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All shops appeared at least once but there are 15246 never seen items !!"},{"metadata":{},"cell_type":"markdown","source":"seen items"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"len(test[\"item_id\"].unique()) - unseen_items.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"unseen combinations"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"unseen_combs = []\nseen_others = []\nfor shop in test_comb[\"shop_id\"].unique():\n    test_items = test_comb.loc[test_comb[\"shop_id\"] == shop, [\"item_id\"]].values.reshape(-1)\n    # in the same shop\n    train_items = train_comb.loc[train_comb[\"shop_id\"] == shop, [\"item_id\"]].values.reshape(-1)\n    # but in other shops (maybe overlapped)\n    train_items_others = train_comb.loc[train_comb[\"shop_id\"] != shop, [\"item_id\"]].values.reshape(-1)\n    for item in test_items:\n        if item not in train_items:\n           unseen_combs.append((shop, item))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"to dataframe"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"unseen_combs_df = pd.DataFrame(unseen_combs, columns=[\"shop_id\", \"item_id\"])\nunseen_combs_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"102697 out of 24100 combinations have not seen in the train set."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"unseen_comb_items = unseen_combs_df[\"item_id\"].unique()\nlen(unseen_comb_items)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But actually 363 never seen items and other items have been seen at least once in another shop."},{"metadata":{},"cell_type":"markdown","source":"How many combinations in the test set have been seen ?"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"214200 - 102697","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many items have been seen but not its combination ?"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"102697-363*42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"seen combinations"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"seen_combs = []\nfor shop in test_comb[\"shop_id\"].unique():\n    test_items = test_comb.loc[test_comb[\"shop_id\"] == shop, [\"item_id\"]].values.reshape(-1)\n    # in the same shop\n    train_items = train_comb.loc[train_comb[\"shop_id\"] == shop, [\"item_id\"]].values.reshape(-1)\n    for item in test_items:\n        if item in train_items:\n           seen_combs.append((shop, item))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"print(len(seen_combs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Outdated shop/item"},{"metadata":{},"cell_type":"markdown","source":"As other kernel notebooks have shown, I also considered that items which have not sold for the last 6 months are outdated.  \nAnd shops which have no sales for the last 6 months can be considered outdated."},{"metadata":{},"cell_type":"markdown","source":"#### outdated shops"},{"metadata":{},"cell_type":"markdown","source":"date_blok_num and corresponding year\n\n- 0-11 2013\n- 12-23 2014\n- 24-33 2015"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"last_months_shops_sales = train.query('date_block_num > 27').groupby(\"shop_id\")[\"item_cnt_day\"].sum()\n\nprint(last_months_shops_sales > 0) ","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"last_months_sales_shops = last_months_shops_sales.index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"no_sales_shops = []\nfor shop in test[\"shop_id\"].unique():\n    if shop not in last_months_sales_shops:\n        no_sales_shops.append(shop)\nprint(no_sales_shops)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### outdated items"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"last_months_items_sales = train.query('date_block_num > 27').groupby(\"item_id\")[\"item_cnt_day\"].sum()\nlast_months_items_sales = last_months_items_sales[last_months_items_sales > 0]\nprint(last_months_items_sales) ","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"last_months_sales_items = last_months_items_sales.index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"no_sales_items = []\nfor item in test[\"item_id\"].unique():\n    if item not in last_months_sales_items:\n        no_sales_items.append(item)\nprint(no_sales_items)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"number of no_sales_items"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"len(no_sales_items)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of no_sales_items are unseen_items"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"len(set(no_sales_items) & set(unseen_items))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"outdated_items = list(set(no_sales_items) - set(unseen_items))\nlen(outdated_items)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"186 items of the train set seem to be outdated and test set contains these items.\n186*42 = 7812 combinations in the test set"},{"metadata":{},"cell_type":"markdown","source":"Combinations of outdated items in the test set"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"outdated_combs = []\nfor shop in test_comb[\"shop_id\"].unique():\n    test_items = test_comb.loc[test_comb[\"shop_id\"] == shop, [\"item_id\"]].values.reshape(-1)\n    for item in outdated_items:\n        if item in test_items:\n           outdated_combs.append((shop, item))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"len(outdated_combs)                    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resume before feature engineering\n\n- Items\n    - Never seen 363 items\n    - Seen 4737 items but never sold in a given shop combinations of shop-item no exist\n        - 186 items seem to be outdated as they have not made any sales in the last 6 months\n        - 4551 items have been seen in the last 6 months\n\n- Combinations\n    - Never seen 15246 combinations\n    - 87451 combinations of shop-item no exist, but items have been sold at least once\n    - Seen 111503 combinations of which,\n        - combinations exist in the test set but the item have not seen in the last 6 months (7812 combinations)\n        - combinations exist and have been seen in the last 6 months (111503 - 7812 = 103691 combinations)\n"},{"metadata":{},"cell_type":"markdown","source":"# Text analysis: item_categories/shops"},{"metadata":{},"cell_type":"markdown","source":"## Item categories"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"item_categories.info()\nprint(item_categories.head())\nprint(item_categories.item_category_name.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As item_categories names are separated by \"-\", split it and generate new columns.  "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# split\nno_split = item_categories.item_category_name.str.split(\" \", expand=True, n = 2)\n\n# replace hyphen and None as \"\"\nno_split = no_split.fillna(\"\").apply(lambda x: x.replace(\"-\", \"\"))\nno_split[0] = no_split[0] + \" \" + no_split[1]\n\n# create item category df\nitem_category_df = no_split.drop(columns = 1)\nitem_category_df.columns = [\"big_category_name\", \"sub_category_name\"]\n\n# item_category_df big_category_name column\nbig_category_name = item_category_df.big_category_name.str.strip()\n\n# item_category_df sub_category_name column\nsub_category_name = item_category_df.sub_category_name.apply(lambda x: x.replace(\"-\", \"\")).str.strip()\n\nitem_category_df[\"big_category_name\"] = big_category_name\nitem_category_df[\"sub_category_name\"] = sub_category_name\n\n# item category encoding\nitem_category_df[\"big_category_id\"] = item_category_df.big_category_name.astype(\"category\").cat.codes.to_frame(name = \"big_category_id\")\nitem_category_df[\"sub_category_id\"] = item_category_df.sub_category_name.astype(\"category\").cat.codes.to_frame(name = \"sub_category_id\")\n\n# join to item_categories\nitem_categories = item_categories.join(item_category_df)\nprint(item_categories)\nitem_categories = downcast(item_categories)\n\ndel no_split\ndel item_category_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Items"},{"metadata":{},"cell_type":"markdown","source":"It can no be translated by googletrans API because of its data size."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"print(\"items\")\nitems.info()\nprint(items.head())\nprint(items.item_name.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shops"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"print(\"shops\")\nshops.info()\nprint(shops.head())\nprint(shops.shop_name.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Same as items_categories, split it and generate new columns, extracting city name and shop catgeory."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# split\nsplit = shops.shop_name\n\n# delete \nsplit = split.apply(lambda x:x.replace(\"!\", \"\"))\n#print(split)\n\n# some names seem to be repeated\n\n# with out split \nwithout_split = split.str.split(expand=True)\n#print(without_split)\n\n# city name correction for index 34 35 42 43 and 46 \nto_correct = without_split.iloc[[34, 35, 42, 43, 46]].drop(columns = [3,4,5,6,7])\nto_correct[0] = to_correct[0] + \" \" + to_correct[1]\nto_correct[1] = to_correct[2]\nto_correct.drop(columns = 2, inplace=True)\n\nwithout_split_new = without_split.drop(index= [34, 35, 42, 43, 46]).drop(columns = [2,3,4,5,6,7])\nwithout_split_new = to_correct.join(without_split_new, how=\"outer\", rsuffix=\"_\").fillna(\"\")\n\nwithout_split_new[\"0\"] = without_split_new[\"0\"] + without_split_new[\"0_\"]\nwithout_split_new[\"1\"] = without_split_new[\"1\"] + without_split_new[\"1_\"]\nwithout_split_new.drop(columns = [\"0_\",\"1_\"], inplace=True)\nwithout_split_new.columns = [\"city_name\", \"shop_category_name\"]\nwithout_split_new.city_name = without_split_new.city_name.str.strip()\nwithout_split_new.shop_category_name = without_split_new.shop_category_name.str.strip()\n\n# first column: city name encoding\ncity_name_ids = without_split_new.city_name.astype(\"category\").cat.codes.to_frame(name = \"city_id\")\n# first column: shop category encoding\nshop_category_ids = without_split_new.shop_category_name.astype(\"category\").cat.codes.to_frame(name = \"shop_category_id\")\n\n# create shop_df \nshop_df = without_split_new.join(city_name_ids).join(shop_category_ids)\n\n# and join to shops\nshops = shops.join(shop_df)\nprint(shops)\nshops = downcast(shops)\n\ndel to_correct\ndel shop_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data leakages"},{"metadata":{},"cell_type":"markdown","source":"## Missing values"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"\n\n# NA\nprint(\"train\")\nprint(train.isna().sum())\nprint(\"test\")\nprint(test.isna().sum())\nprint(\"item_categories\")\nprint(item_categories.isna().sum())\nprint(\"items\")\nprint(items.isna().sum())\nprint(\"shops\")\nprint(shops.isna().sum())\n\n# Null\nprint(\"train\")\nprint(train.isnull().sum())\nprint(\"test\")\nprint(test.isnull().sum())\nprint(\"item_categories\")\nprint(item_categories.isnull().sum())\nprint(\"items\")\nprint(items.isnull().sum())\nprint(\"shops\")\nprint(shops.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering"},{"metadata":{},"cell_type":"markdown","source":"## Train set extension"},{"metadata":{},"cell_type":"markdown","source":"Compute item_cnt_days of all combinations of shop and item across date_block_num.  \nIf there is not item_cnt_days for a given combination of shop and item a given date_block_num, item_cnt_days as 0 is computed."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_extended = []\nfor i in range(34):\n    sales = train.query('date_block_num == @i')\n    train_extended.append(np.array(list(product([i] ,sales[\"shop_id\"].unique(), sales[\"item_id\"].unique()))))\n\ncols = [\"date_block_num\", \"shop_id\", \"item_id\"]\nprint(train_extended)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using vstack and make a dataframe"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_extended = pd.DataFrame(np.vstack(train_extended), columns = cols)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_extended.info()\nprint(train_extended.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"downcast"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_extended = downcast(train_extended)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## monthly sales (respect to item_cnt_days)"},{"metadata":{},"cell_type":"markdown","source":"calculate revenue"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# date \n# train[\"date\"] = pd.to_datetime(train[\"date\"], format=\"%d.%m.%Y\")\n# train['year'], train['month'] = train['date'].dt.year, train['date'].dt.month\n\n# revenue\ntrain[\"revenue\"] = train[\"item_price\"] * train[\"item_cnt_day\"] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The train set is grouped by date_block_num to calculate monthly mean of item_cnt_days."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_monthly = train.groupby(['date_block_num', \"shop_id\", \"item_id\"], as_index = False)\\\n    .agg({\"item_cnt_day\" : [\"sum\"]})\n\ntrain_monthly.columns = ['date_block_num',\"shop_id\", \"item_id\", \"item_cnt_month\"]\n\ntrain_monthly = downcast(train_monthly)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clip target values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_monthly[\"item_cnt_month\"] = train_monthly[\"item_cnt_month\"].clip(0,20)\n\n# add year and month\n# data_monthly = data_monthly.merge(train[['date_block_num',\"year\", \"month\"]].drop_duplicates(), on = 'date_block_num')","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"print(train_monthly.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge train_monthly to train_extended"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new = train_extended.merge(train_monthly, on=[\"date_block_num\", \"shop_id\", \"item_id\"], how=\"left\").fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new = downcast(train_new)\ntrain_new[\"item_cnt_month\"] = train_new[\"item_cnt_month\"].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.info()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add test set to the train set"},{"metadata":{},"cell_type":"markdown","source":"November 2015 corresponds to date_block_num 34."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test = test.drop(\"ID\", axis = 1)\ntest.insert(0, \"date_block_num\", 34)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test = downcast(test)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatenate "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new = pd.concat([train_new, test], ignore_index=True, sort=False, keys=[\"date_block_num\", \"shop_id\", \"item_id\", \"item_cnt_month\"])\ntrain_new.describe()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# downcast\ntrain_new = downcast(train_new)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.info()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## add other data frames"},{"metadata":{},"cell_type":"markdown","source":"Add item_categoriees data "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"items_and_item_categories = items.drop(columns=[\"item_name\"])\\\n    .merge(item_categories.drop(columns=[\"item_category_name\", \"big_category_name\", \"sub_category_name\"]))\n\nitems_and_item_categories.info()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new = train_new.merge(items_and_item_categories, on = [\"item_id\"])\ntest = test.merge(items_and_item_categories, on = [\"item_id\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add shops data"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new = train_new.merge(shops.drop(columns=[\"shop_name\", \"city_name\", \"shop_category_name\"]), on = [\"shop_id\"])\ntest = test.merge(shops.drop(columns=[\"shop_name\", \"city_name\", \"shop_category_name\"]), on = [\"shop_id\"])","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.fillna(0, inplace=True)\ntest.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.describe()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.info()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shifted features of the target"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# use this for lag features\nlags = [1,2,3,6,12]\n\ndef lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# target \ntrain_new = lag_feature(train_new, lags, \"item_cnt_month\")\ntrain_new.fillna(0, inplace=True)\ntrain_new = downcast(train_new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## target mean by date_block_num "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# by date_block_num mean\ngroup = train_new.groupby(\"date_block_num\").agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\", \"date_block_item_cnt_mean\"]","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# merge it to train_new, generate lag 1 feature and drop it as date_block_item_cnt_mean for the test set is all zero\ntrain_new =  train_new.merge(group, on=[\"date_block_num\"])\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# lag 1 feature\ntrain_new = lag_feature(train_new, [1], \"date_block_item_cnt_mean\")\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.drop(\"date_block_item_cnt_mean\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num and shop_id "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# use lags as all shops of the test set appear in the train set\ngroup = train_new.groupby([\"date_block_num\",\"shop_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\",\"shop_id\", \"shop_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\", \"shop_id\"])\ntrain_new = lag_feature(train_new, lags, \"shop_item_cnt_mean\")\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new.drop(\"shop_item_cnt_mean\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num and item_id "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# use only lag 1 as there are many unseen items in the test set\ngroup = train_new.groupby([\"date_block_num\",\"item_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\",\"item_id\", \"item_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\", \"item_id\"])\ntrain_new = lag_feature(train_new, [1], \"item_item_cnt_mean\")\ntrain_new.drop(\"item_item_cnt_mean\", axis=1, inplace=True)\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num and item_category_id"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# use only lag 1 as there are many unseen items in the test set\ngroup = train_new.groupby([\"date_block_num\",\"item_category_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\",\"item_category_id\", \"item_category_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\", \"item_category_id\"])\ntrain_new = lag_feature(train_new, [1], \"item_category_item_cnt_mean\")\ntrain_new.drop(\"item_category_item_cnt_mean\", axis=1, inplace=True)\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num and city_id "},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"group = train_new.groupby([\"date_block_num\",\"city_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\",\"city_id\", \"city_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\", \"city_id\"])\ntrain_new = lag_feature(train_new, [1], \"city_item_cnt_mean\")\ntrain_new.drop(\"city_item_cnt_mean\", axis=1, inplace=True)\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num and big_category_id"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"group = train_new.groupby([\"date_block_num\",\"big_category_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\",\"big_category_id\", \"big_category_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\", \"big_category_id\"])\ntrain_new = lag_feature(train_new, [1], \"big_category_item_cnt_mean\")\ntrain_new.drop(\"big_category_item_cnt_mean\", axis=1, inplace=True)\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num and sub_category_id"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"group = train_new.groupby([\"date_block_num\",\"sub_category_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\",\"sub_category_id\", \"sub_category_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\", \"sub_category_id\"])\ntrain_new = lag_feature(train_new, [1], \"sub_category_item_cnt_mean\")\ntrain_new.drop(\"sub_category_item_cnt_mean\", axis=1, inplace=True)\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num, item_category_id and item_id  all"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"group = train_new.groupby([\"date_block_num\",\"item_category_id\", \"item_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\",\"item_category_id\", \"item_id\", \"item_category_item_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\",\"item_category_id\", \"item_id\"])\ntrain_new = lag_feature(train_new, lags, \"item_category_item_item_cnt_mean\")\ntrain_new.drop(\"item_category_item_item_cnt_mean\", axis=1, inplace=True)\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num, shop_id and item_category_id  all"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"group = train_new.groupby([\"date_block_num\", \"shop_id\", \"item_category_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\", \"shop_id\", \"item_category_id\", \"shop_item_category_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\", \"shop_id\", \"item_category_id\"])\ntrain_new = lag_feature(train_new, lags, \"shop_item_category_item_cnt_mean\")\ntrain_new.drop(\"shop_item_category_item_cnt_mean\", axis=1, inplace=True)\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num, shop_id and big_category_id"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"group = train_new.groupby([\"date_block_num\", \"shop_id\", \"big_category_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\", \"shop_id\", \"big_category_id\", \"shop_big_category_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\", \"shop_id\", \"big_category_id\"])\ntrain_new = lag_feature(train_new, [1], \"shop_big_category_item_cnt_mean\")\ntrain_new.drop(\"shop_big_category_item_cnt_mean\", axis=1, inplace=True)\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### target mean by date_block_num, shop_id and sub_category_id"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"group = train_new.groupby([\"date_block_num\", \"shop_id\", \"sub_category_id\"]).agg({\"item_cnt_month\": [\"mean\"]}).reset_index()\ngroup.columns = [\"date_block_num\", \"shop_id\", \"sub_category_id\", \"shop_sub_category_item_cnt_mean\"]\ntrain_new = train_new.merge(group, on=[\"date_block_num\", \"shop_id\", \"sub_category_id\"])\ntrain_new = lag_feature(train_new, [1], \"shop_sub_category_item_cnt_mean\")\ntrain_new.drop(\"shop_sub_category_item_cnt_mean\", axis=1, inplace=True)\ntrain_new.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"print(train_new.describe())\nprint(train_new.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## other features"},{"metadata":{},"cell_type":"markdown","source":"month"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_new[\"month\"] = train_new[\"date_block_num\"] % 12","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"holidays"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# from http://www.timebie.com/calendar/russia2013.php\n\nholidays = [13, 8, 11, 8, 10, 11, 8, 9, 9, 8, 10, 9,\n            12, 8, 10, 4, 11, 10, 8, 10, 8, 8, 12, 8,\n            13, 9, 9, 8, 11, 9, 8, 10, 8, 9, 11]\n\nholidays_dict = dict(zip(list(range(35)), holidays))\n\nprint(holidays_dict)\n\ntrain_new[\"holidays_cnt\"] = train_new[\"date_block_num\"].map(holidays_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"US Dollar per 1 Russian Ruble Monthly average rate from January 2013 to November 2015"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# from https://www.x-rates.com/average/?from=RUB&to=USD&amount=1&year=2013\n\nrates = [\n    \n    0.033064, 0.033135, 0.032450, 0.031901, 0.031923, 0.030951, 0.030517, 0.030310, 0.030674, 0.031174, 0.030592, 0.030425,\n    0.029695, 0.028373, 0.027628, 0.028044, 0.028638, 0.029076, 0.028831, 0.027667, 0.026349, 0.024501, 0.021618, 0.017868,\n    0.015704, 0.015517, 0.016594, 0.018804, 0.019731, 0.018311, 0.017496, 0.015301, 0.014936, 0.015841, 0.015365\n    \n]\n\nrates_dict = dict(zip(list(range(35)), rates))\n\ntrain_new[\"dollar_ruble_rate\"] = train_new[\"date_block_num\"].map(rates_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"number of days"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n\ndays_dict = dict(zip(list(range(13)), rates))\n\ntrain_new[\"days_cnt\"] = train_new[\"month\"].map(days_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Delete first 6 months data from train set as lag features are all 0 for these time periods.  \nI did not split the data randomly because of time-based features. For example, some items are outdated."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test_sort = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\ntest_sort.drop(\"ID\", axis=1, inplace = True)\n\n# drop first 6 months\ntrain = downcast(train_new.query('date_block_num < 31 and date_block_num > 5')) # 1 - 30\nval = downcast(train_new.query('date_block_num > 30 and date_block_num < 34')) # 31 - 33\ntest = downcast(test_sort.merge(train_new.query('date_block_num == 34'), on = [\"shop_id\", \"item_id\"], how=\"left\")) # 34","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train = downcast(train)\nval = downcast(val)\ntest = downcast(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data split\n"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"X_train = train.drop(\"item_cnt_month\", axis = 1).reset_index(drop=True)\nX_val = val.drop(\"item_cnt_month\", axis = 1).reset_index(drop=True)\ny_train = train[[\"item_cnt_month\"]].reset_index(drop=True)\ny_val = val[[\"item_cnt_month\"]].reset_index(drop=True)\nX_test = test.drop(\"item_cnt_month\", axis = 1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"X_train = downcast(X_train)\nX_val = downcast(X_val)\ny_train = downcast(y_train)\ny_val = downcast(y_val)\nX_test = downcast(X_test)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Delete data"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"del train_new\ndel train\ndel test\ndel val\ndel items\ndel shops\ndel item_categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## modeling"},{"metadata":{},"cell_type":"markdown","source":"Because of the kernel capacity, I reduced number of features. Nevertheless, the rmse error does not increase too much."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"xgb_features = ['date_block_num',\n 'shop_id',\n 'item_id',\n 'item_category_id',\n 'big_category_id',\n 'sub_category_id',\n 'city_id',\n 'shop_category_id',\n 'item_cnt_month_lag_1',\n 'item_cnt_month_lag_2',\n 'item_cnt_month_lag_3',\n #'item_cnt_month_lag_6',\n #'item_cnt_month_lag_12',\n 'date_block_item_cnt_mean_lag_1',\n 'shop_item_cnt_mean_lag_1',\n 'shop_item_cnt_mean_lag_2',\n 'shop_item_cnt_mean_lag_3',\n #'shop_item_cnt_mean_lag_6',\n #'shop_item_cnt_mean_lag_12',\n 'item_item_cnt_mean_lag_1',\n 'item_category_item_cnt_mean_lag_1',\n # 'city_item_cnt_mean_lag_1',\n 'big_category_item_cnt_mean_lag_1',\n 'sub_category_item_cnt_mean_lag_1',\n 'shop_category_item_cnt_mean_lag_1',\n 'item_category_item_item_cnt_mean_lag_1',\n 'item_category_item_item_cnt_mean_lag_2',\n#  'item_category_item_item_cnt_mean_lag_3',\n #'item_category_item_item_cnt_mean_lag_6',\n #'item_category_item_item_cnt_mean_lag_12',\n 'shop_item_category_item_cnt_mean_lag_1',\n 'shop_item_category_item_cnt_mean_lag_2',\n#  'shop_item_category_item_cnt_mean_lag_3',\n #'shop_item_category_item_cnt_mean_lag_6',\n #'shop_item_category_item_cnt_mean_lag_12',\n 'shop_big_category_item_cnt_mean_lag_1',\n 'shop_sub_category_item_cnt_mean_lag_1',\n # 'shop_category_item_item_cnt_mean_lag_1',\n # 'shop_category_item_category_item_cnt_mean_lag_1',\n #'item_cnt_rolling_min',\n #'item_cnt_rolling_max',\n # 'item_cnt_rolling_mean',\n # 'item_cnt_rolling_std',\n 'month',\n 'holidays_cnt',\n 'dollar_ruble_rate',\n 'days_cnt']","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"X_train_xgb = X_train.loc[:, xgb_features]\nX_val_xgb = X_val.loc[:, xgb_features]\nX_test_xgb = X_test.loc[:, xgb_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_xgb.fillna(0, inplace=True)\nX_val_xgb.fillna(0, inplace=True)\nX_test_xgb.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Xgboost"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"xgb_model = XGBRegressor(\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=400, \n    colsample_bytree=0.6, \n    subsample=0.6, \n    eta=0.2,    \n    seed=0,\n    learning_rate = 0.1,\n    n_jobs=-1)\n\nxgb_model.fit(\n    X_train_xgb, \n    y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train_xgb, y_train), (X_val_xgb, y_val)], \n    verbose=10, \n    early_stopping_rounds = 10)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"xgb_train_pred = xgb_model.predict(X_train_xgb)\nxgb_val_pred = xgb_model.predict(X_val_xgb)\nxgb_test_pred = xgb_model.predict(X_test_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### plot feature importance"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 15))\nplot_importance(xgb_model,ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{},"cell_type":"markdown","source":"Here, I aslo selected only some features."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"\nrf_features = ['date_block_num',\n 'shop_id',\n 'item_id',\n 'item_category_id',\n 'big_category_id',\n 'sub_category_id',\n 'city_id',\n 'shop_category_id',\n 'item_cnt_month_lag_1',\n 'item_cnt_month_lag_2',\n 'item_cnt_month_lag_3',\n #'item_cnt_month_lag_6',\n #'item_cnt_month_lag_12',\n 'date_block_item_cnt_mean_lag_1',\n 'shop_item_cnt_mean_lag_1',\n 'shop_item_cnt_mean_lag_2',\n # 'shop_item_cnt_mean_lag_3',\n #'shop_item_cnt_mean_lag_6',\n #'shop_item_cnt_mean_lag_12',\n 'item_item_cnt_mean_lag_1',\n 'item_category_item_cnt_mean_lag_1',\n#  'city_item_cnt_mean_lag_1',\n 'big_category_item_cnt_mean_lag_1',\n 'sub_category_item_cnt_mean_lag_1',\n 'shop_category_item_cnt_mean_lag_1',\n 'item_category_item_item_cnt_mean_lag_1',\n # 'item_category_item_item_cnt_mean_lag_2',\n # 'item_category_item_item_cnt_mean_lag_3',\n #'item_category_item_item_cnt_mean_lag_6',\n #'item_category_item_item_cnt_mean_lag_12',\n 'shop_item_category_item_cnt_mean_lag_1',\n 'shop_item_category_item_cnt_mean_lag_2',\n # 'shop_item_category_item_cnt_mean_lag_3',\n #'shop_item_category_item_cnt_mean_lag_6',\n #'shop_item_category_item_cnt_mean_lag_12',\n 'shop_big_category_item_cnt_mean_lag_1',\n 'shop_sub_category_item_cnt_mean_lag_1',\n # 'shop_category_item_item_cnt_mean_lag_1',\n # 'shop_category_item_category_item_cnt_mean_lag_1',\n #'item_cnt_rolling_min',\n #'item_cnt_rolling_max',\n #'item_cnt_rolling_mean',\n #'item_cnt_rolling_std',\n 'month',\n 'holidays_cnt',\n 'dollar_ruble_rate',\n 'days_cnt']","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"X_train_rf = X_train.loc[:, rf_features]\nX_val_rf = X_val.loc[:, rf_features]\nX_test_rf = X_test.loc[:, rf_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rf.fillna(0, inplace=True)\nX_val_rf.fillna(0, inplace=True)\nX_test_rf.fillna(0, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"rf_model = RandomForestRegressor(n_estimators=50, max_depth=7, random_state=0, n_jobs=-1)\nrf_model.fit(X_train_rf, y_train)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"rf_train_pred = rf_model.predict(X_train_rf)\nrf_val_pred = rf_model.predict(X_val_rf)\nrf_test_pred = rf_model.predict(X_test_rf.fillna(0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ensemble\nUse linear model"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"first_level = pd.DataFrame(xgb_val_pred, columns=[\"xgb\"])\nfirst_level[\"rf\"] = rf_val_pred\nfirst_level.info()\n\nfirst_level_test = pd.DataFrame(xgb_test_pred, columns=[\"xgb\"])\nfirst_level_test[\"rf\"] = rf_test_pred\nfirst_level_test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear regression"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"meta_model = LinearRegression(n_jobs=-1)\nmeta_model.fit(first_level, y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"prediction"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test_prediction = meta_model.predict(first_level_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(test_prediction, columns=[\"item_cnt_month\"]).clip(0, 20).reset_index()\nsubmission.columns = [\"ID\", \"item_cnt_month\"]\nprint(submission)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}}},"nbformat":4,"nbformat_minor":1}