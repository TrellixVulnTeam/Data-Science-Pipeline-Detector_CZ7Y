{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predict Future Sales\n\nThis challenge serves as final project for the \"How to win a data science competition\" Coursera course.\n\nIn this competition you will work with a challenging time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company. \n\nWe are asking you to predict total sales for every product and store in the next month. By solving this competition you will be able to apply and enhance your data science skills."},{"metadata":{},"cell_type":"markdown","source":"## Evaluation\n\nSubmissions are evaluated by root mean squared error (**RMSE**). True target values are clipped into [0,20] range;"},{"metadata":{},"cell_type":"markdown","source":"## Submission File\n\nFor each id in the test set, you must predict a total number of sales. The file should contain a header and have the following format:\n\n```\nID,item_cnt_month\n0,0.5\n1,0.5\n2,0.5\n3,0.5\netc.\n```"},{"metadata":{},"cell_type":"markdown","source":"## File descriptions\n- sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.\n- test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.\n- sample_submission.csv - a sample submission file in the correct format.\n- items.csv - supplemental information about the items/products.\n- item_categories.csv  - supplemental information about the items categories.\n- shops.csv- supplemental information about the shops."},{"metadata":{},"cell_type":"markdown","source":"## Data fields\n- ID - an Id that represents a (Shop, Item) tuple within the test set\n- shop_id - unique identifier of a shop\n- item_id - unique identifier of a product\n- item_category_id - unique identifier of item category\n- item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n- item_price - current price of an item\n- date - date in format dd/mm/yyyy\n- date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n- item_name - name of item\n- shop_name - name of shop\n- item_category_name - name of item category"},{"metadata":{},"cell_type":"markdown","source":"## Getting Started"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns, sklearn\n\nfrom scipy.stats import probplot, boxcox_normmax, norm, skew, kurtosis as kurt\nfrom scipy.special import boxcox1p\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import KFold, cross_val_score, learning_curve\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import plot_importance\n\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nimport gc,os,sys,time,pickle\nfrom datetime import datetime\nfrom itertools import product\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nsns.set_style(\"darkgrid\")\n%matplotlib inline\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/competitive-data-science-predict-future-sales/'\n\ntrain_data = pd.read_csv(PATH+'sales_train.csv')\ntest_data = pd.read_csv(PATH+'test.csv').set_index('ID')\nitem_data = pd.read_csv(PATH+'items.csv')\nitem_category_data = pd.read_csv(PATH+'item_categories.csv')\nshop_data = pd.read_csv(PATH+'shops.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*50)\ntrain_data.info()\nprint('='*50)\ntest_data.info()\nprint('='*50)\nitem_data.info()\nprint('='*50)\nitem_category_data.info()\nprint('='*50)\nshop_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PREPROCESS"},{"metadata":{},"cell_type":"markdown","source":"### outliers\n\n- item_cnt_day: 当日销售数超过1001，在box图中看属于严重的离群点极值了，防止其对正常数据的影响，去除；\n- item_price: 大于100k，只有一个，离群明显，去除，另外，item_price有一个负数，属于异常值，用中位数填充；\n- shop: 几家商店从名字上看是重复的，但是id不一致，这里做归一处理；"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.xlim(-100, 3000)\nsns.boxplot(x=train_data.item_cnt_day)\n\nplt.figure(figsize=(20,5))\nplt.xlim(train_data.item_price.min()*1.1, train_data.item_price.max()*1.1)\nsns.boxplot(x=train_data.item_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data.item_price < 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data[train_data.item_cnt_day < 1001]\ntrain_data = train_data[train_data.item_price < 100000]\n\nmedian = train_data[(train_data.shop_id==32)&(train_data.item_id==2973)&(train_data.date_block_num==4)&\n                    (train_data.item_price>0)].item_price.median()\ntrain_data.loc[train_data.item_price < 0, 'item_price'] = median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Якутск Орджоникидзе, 56\n# 0 & 56\ntrain_data.loc[train_data.shop_id == 0, 'shop_id'] = 57\ntest_data.loc[test_data.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\n# 1 & 58\ntrain_data.loc[train_data.shop_id == 1, 'shop_id'] = 58\ntest_data.loc[test_data.shop_id == 1, 'shop_id'] = 58\n# Жуковский ул. Чкалова 39м²\n# 10 & 11\ntrain_data.loc[train_data.shop_id == 10, 'shop_id'] = 11\ntest_data.loc[test_data.shop_id == 10, 'shop_id'] = 11","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shops/Cats/Items\n\n- 商店名字都是以城市名字开头；\n- 每个类别名字都包含type和sub type信息；"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 提取城市信息并label encode，保留shop_id和city_code即可\nshop_data.loc[shop_data.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\nshop_data['city'] = shop_data['shop_name'].str.split(' ').map(lambda x: x[0])\nshop_data.loc[shop_data.city == '!Якутск', 'city'] = 'Якутск'\nshop_data['city_code'] = LabelEncoder().fit_transform(shop_data['city'])\nshop_data = shop_data[['shop_id','city_code']]\n\n# 对类别名进行切分，提取type和sub type，没有sub type时，sub type等于type\nitem_category_data['split'] = item_category_data['item_category_name'].str.split('-')\nitem_category_data['type'] = item_category_data['split'].map(lambda x: x[0].strip())\nitem_category_data['type_code'] = LabelEncoder().fit_transform(item_category_data['type'])\nitem_category_data['subtype'] = item_category_data['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\nitem_category_data['subtype_code'] = LabelEncoder().fit_transform(item_category_data['subtype'])\nitem_category_data = item_category_data[['item_category_id','type_code', 'subtype_code']]\n\n# 丢弃商品名字段，没有分析价值\nitem_data.drop(['item_name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Monthly Sales\n\n训练数据每条记录代表的是某个商店的某个商品的日销量以及价格，而测试数据要的结果则是月销量，因此需要对训练数据做聚合，以使得二者的数据结构维度一致；"},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('trans day to month data')\n\n# dates,date_block_nums,shop_ids,item_ids,item_price_means,item_price_medians,item_cnt_months = [],[],[],[],[],[],[]\n\n# tmp_data = train_data.groupby(by=['shop_id','item_id','date_block_num'])\n# for tmp in tmp_data:\n#     dates.append(tmp[1].date.iloc[0][tmp[1].date.iloc[0].find('.')+1:])\n#     date_block_nums.append(tmp[1].date_block_num.iloc[0])\n#     shop_ids.append(tmp[1].shop_id.iloc[0])\n#     item_ids.append(tmp[1].item_id.iloc[0])\n#     item_price_means.append(tmp[1].item_price.mean())\n#     item_price_medians.append(tmp[1].item_price.median())\n#     item_cnt_months.append(tmp[1].item_cnt_day.count())\n\n# train_data = pd.DataFrame({'date':dates,'date_block_num':date_block_nums,'shop_id':shop_ids,'item_id':item_ids,\n#                                  'item_price_mean':item_price_means,'item_price_median':item_price_medians,\n#                                  'item_cnt_month':item_cnt_months})\n\n# del tmp_data,dates,date_block_nums,shop_ids,item_ids,item_price_means,item_price_medians,item_cnt_months\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 构建目标DataFrame\n# 这里的matrix结构与train完全不一样，这里其实是构建了一个shop*item*block_num的排列组合的矩阵，可以看到数据行数达到了1000w+，远远高于\n# train的行数，这里要搞清楚，不是简单的数据迁移，而是整个结构重组；\nmatrix = []\ncols = ['date_block_num','shop_id','item_id']\nfor i in range(34):# 0~33\n    sales = train_data[train_data.date_block_num==i]# 每个月的数据\n    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))# 将每个shop、item和num进行排列组合\n    \nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\nmatrix.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 销售额特征\ntrain_data['revenue'] = train_data['item_price'] *  train_data['item_cnt_day']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 求月销售数量，基本方法跟原来的一样，区别在于这里用了agg和内置函数sum，效率更高，注意clip(0,20)，这个是题目中有要求的\ngroup = train_data.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (matrix['item_cnt_month']\n                                .fillna(0) # fill NaN with 0\n                                .clip(0,20) # NB clip target here\n                                .astype(np.float16)) # float16 with NaN still float16, int16 will be int64","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 连续特征的数据分布转换\n\n放到这里的原因是如果连接了测试数据，那么就会带来大量的0值，这会影响转换算法的效果；"},{"metadata":{},"cell_type":"markdown","source":"处理train_data数据；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnumerical_features = ['item_price','revenue']\ntransform_data = train_data\ntransform_data[numerical_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntransform_data[numerical_features].apply(lambda x: kurt(x.dropna())).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 偏度最佳为0，此处大于0.5，就满足需要处理的条件\nskewed_features = {feature: skew(transform_data[feature].dropna()-transform_data[feature].min()) for feature in numerical_features if skew(transform_data[feature].dropna()-transform_data[feature].min()) >= .5}\nprint(skewed_features)\n\nboxcox1p_skews = {}\nlog1p_skews = {}\nexp_skews = {}\npower_skews = {}\nbest_skews = {}\nmethods = {}\n\ntmp = pd.DataFrame()\nfor feature in skewed_features.keys():\n    tmp[feature] = boxcox1p(transform_data[feature]-transform_data[feature].min(), boxcox_normmax(transform_data[feature]-transform_data[feature].min() + 1))\n    boxcox1p_skews[feature] = skew(tmp[feature].dropna())\n    tmp[feature] = np.log1p(transform_data[feature]-transform_data[feature].min())\n    log1p_skews[feature] = skew(tmp[feature].dropna())\n    tmp[feature] = np.exp(transform_data[feature]-transform_data[feature].min())\n    exp_skews[feature] = skew(tmp[feature].dropna())\n    tmp[feature] = (transform_data[feature]-transform_data[feature].min())**.5\n    power_skews[feature] = skew(tmp[feature].dropna())\n    best_skews[feature] = min(boxcox1p_skews[feature],log1p_skews[feature],exp_skews[feature],power_skews[feature])\n    methods[feature] = 'boxcox' if best_skews[feature]==boxcox1p_skews[feature] else ('log' if best_skews[feature]==log1p_skews[feature] else ('exp' if best_skews[feature]==exp_skews[feature] else ('power' if best_skews[feature]==power_skews[feature] else 'original')))\n\nprint(methods)\n    \ndf_skew = pd.DataFrame(index=skewed_features.keys(), columns=['Skew', 'Skew after boxcox1p'])\ndf_skew['Skew Original'] = skewed_features.values()\ndf_skew['Skew after boxcox1p'] = boxcox1p_skews.values()\ndf_skew['Skew after log1p'] = log1p_skews.values()\ndf_skew['Skew after exp'] = exp_skews.values()\ndf_skew['Skew after power'] = power_skews.values()\ndf_skew['Skew after compare'] = best_skews.values()\n\nfig = plt.figure(figsize=(22, 6))\n\nsns.pointplot(x=df_skew.index, y='Skew Original', data=df_skew, markers=['o'], linestyles=['-'], label='original')\nsns.pointplot(x=df_skew.index, y='Skew after boxcox1p', data=df_skew, markers=['x'], linestyles=['--'], color='dodgerblue', label='boxcox1p')\nsns.pointplot(x=df_skew.index, y='Skew after log1p', data=df_skew, markers=['s'], linestyles=['--'], color='peru', label='log1p')\nsns.pointplot(x=df_skew.index, y='Skew after exp', data=df_skew, markers=['*'], linestyles=['--'], color='darkorchid', label='exp')\nsns.pointplot(x=df_skew.index, y='Skew after power', data=df_skew, markers=['+'], linestyles=['--'], color='yellow', label='power0.5')\nsns.pointplot(x=df_skew.index, y='Skew after compare', data=df_skew, markers=['v'], linestyles=['--'], color='lawngreen', label='best')\n\nplt.xlabel('Skewed Features', size=20, labelpad=12.5)\nplt.ylabel('Skewness', size=20, labelpad=12.5)\nplt.tick_params(axis='x', labelsize=11)\nplt.tick_params(axis='y', labelsize=15)\nplt.xticks(rotation=70)\nplt.title('Skewed Features Before and After Several Transformation Method', size=20)\n\nplt.legend(loc='best', shadow=True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor feature in numerical_features:\n    method = methods[feature]\n    if method=='boxcox':\n        transform_data[feature] = boxcox1p(transform_data[feature]-transform_data[feature].min(), boxcox_normmax(transform_data[feature]-transform_data[feature].min() + 1))\n    elif method=='log':\n        transform_data[feature] = np.log1p(transform_data[feature]-transform_data[feature].min())\n    elif method=='exp':\n        transform_data[feature] = np.exp(transform_data[feature]-transform_data[feature].min())\n    elif method=='power':\n        transform_data[feature] = (transform_data[feature]-transform_data[feature].min())**.5\n    else:# original\n        pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"处理matrix数据；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnumerical_features = ['item_cnt_month']\ntransform_data = matrix\ntransform_data[numerical_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntransform_data[numerical_features].apply(lambda x: kurt(x.dropna())).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('After log1p transform, skew = ', skew(np.log1p(transform_data[numerical_features]).dropna()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_data[numerical_features] = np.log1p(transform_data[numerical_features])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 测试数据处理"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['date_block_num'] = 34\ntest_data['date_block_num'] = test_data['date_block_num'].astype(np.int8)\ntest_data['shop_id'] = test_data['shop_id'].astype(np.int8)\ntest_data['item_id'] = test_data['item_id'].astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 拼接训练和测试数据，这里时间上是连续的，即0~34\nmatrix = pd.concat([matrix, test_data], ignore_index=True, sort=False, keys=cols)\nmatrix.fillna(0, inplace=True) # item_cnt_month in 34 month fill 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merge item/shop/cat"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmatrix = pd.merge(matrix, shop_data, on=['shop_id'], how='left')\nmatrix = pd.merge(matrix, item_data, on=['item_id'], how='left')\nmatrix = pd.merge(matrix, item_category_data, on=['item_category_id'], how='left')\nmatrix['city_code'] = matrix['city_code'].astype(np.int8)\nmatrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\nmatrix['type_code'] = matrix['type_code'].astype(np.int8)\nmatrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FEATURE ENGENEERING"},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target Lags\n\n新增目标特征的延后特征，分别延后[1,2,3,6,12]，对于每条数据的含义就是增加了5列特征，item_cnt_month_lag_1表示一个月前该商店该商品的月销售量，2,3,6,12同理，这样操作后会产生一些NaN值，类似滑窗处理在边界上总是会有NaN，正常情况；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmatrix = lag_feature(matrix, [1,2,3,6,12], 'item_cnt_month')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 平均编码特征"},{"metadata":{},"cell_type":"markdown","source":"每个月的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num'], how='left')\nmatrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_avg_item_cnt')\nmatrix.drop(['date_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每个商品的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1,2,3,6,12], 'date_item_avg_item_cnt')\nmatrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每家店的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_shop_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\nmatrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1,2,3,6,12], 'date_shop_avg_item_cnt')\nmatrix.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每个类别的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_cat_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_category_id'], how='left')\nmatrix['date_cat_avg_item_cnt'] = matrix['date_cat_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_cat_avg_item_cnt')\nmatrix.drop(['date_cat_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每家店每个类别的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_cat_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\nmatrix['date_shop_cat_avg_item_cnt'] = matrix['date_shop_cat_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_shop_cat_avg_item_cnt')\nmatrix.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每家店每个type的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_type_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'type_code'], how='left')\nmatrix['date_shop_type_avg_item_cnt'] = matrix['date_shop_type_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_shop_type_avg_item_cnt')\nmatrix.drop(['date_shop_type_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每家店每个subtype的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_subtype_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\nmatrix['date_shop_subtype_avg_item_cnt'] = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_shop_subtype_avg_item_cnt')\nmatrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每个城市的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_city_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'city_code'], how='left')\nmatrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_city_avg_item_cnt')\nmatrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每个城市每个商品的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'item_id', 'city_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_city_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'city_code'], how='left')\nmatrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_item_city_avg_item_cnt')\nmatrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每个type的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_type_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'type_code'], how='left')\nmatrix['date_type_avg_item_cnt'] = matrix['date_type_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_type_avg_item_cnt')\nmatrix.drop(['date_type_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个月每个subtype的平均销量；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngroup = matrix.groupby(['date_block_num', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_subtype_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'subtype_code'], how='left')\nmatrix['date_subtype_avg_item_cnt'] = matrix['date_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], 'date_subtype_avg_item_cnt')\nmatrix.drop(['date_subtype_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 趋势特征"},{"metadata":{},"cell_type":"markdown","source":"最后6个月的价格趋势；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 每个商品的平均价格\ngroup = train_data.groupby(['item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['item_id'], how='left')\nmatrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n\n# 每个商品在每个月的平均价格\ngroup = train_data.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['date_item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\n\n# 对每个商品在每个月的平均价格特征做lag处理，分别延后[1,2,3,4,5,6]\nlags = [1,2,3,4,5,6]\nmatrix = lag_feature(matrix, lags, 'date_item_avg_item_price')\n\n# 用1,2,3,4,5,6个月前的每个商品平均价格与商品总平均价格求变化量，即delta\nfor i in lags:\n    matrix['delta_price_lag_'+str(i)] = \\\n        (matrix['date_item_avg_item_price_lag_'+str(i)] - matrix['item_avg_item_price']) / matrix['item_avg_item_price']\n\n# 遍历每一行，如果对应delta有值，返回该值，否则返回0\n# for循环会提前结束，因此这里可能存在多个delta时，返回最近的那个，即如果delta_1有值，则返回，不会再向后遍历\n# 那么delta_price_lag可以理解为最近为一个月的商品价格与全期的商品价格的变化量\ndef select_trend(row):\n    for i in lags:\n        if row['delta_price_lag_'+str(i)]:\n            return row['delta_price_lag_'+str(i)]\n    return 0\n    \nmatrix['delta_price_lag'] = matrix.apply(select_trend, axis=1)\nmatrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\nmatrix['delta_price_lag'].fillna(0, inplace=True)\n\n# 删掉之前添加的每个商品平均和每个月每个商品平均的特征\nfetures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\nfor i in lags:\n    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n    fetures_to_drop += ['delta_price_lag_'+str(i)]\n\nmatrix.drop(fetures_to_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"最后一个月的商品销售额趋势"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 每个商店每个月的总销售额\ngroup = train_data.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\ngroup.columns = ['date_shop_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n\n# 每个商店的平均销售额\ngroup = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\ngroup.columns = ['shop_avg_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['shop_id'], how='left')\nmatrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\n\n# 每个月销售额与总销售额求销售额的变化量\nmatrix['delta_revenue'] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\nmatrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n\n# 变化量lag[1]\nmatrix = lag_feature(matrix, [1], 'delta_revenue')\n\nmatrix.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 其他特征"},{"metadata":{},"cell_type":"markdown","source":"月份、天数；"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 月份\nmatrix['month'] = matrix['date_block_num'] % 12\n# 每个月天数\ndays = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\nmatrix['days'] = matrix['month'].map(days).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个商店的每个商品上一次售出是几个月前；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncache = {}\n# 每个商店的每个商品上一次售出是几个月前\nmatrix['item_shop_last_sale'] = -1\nmatrix['item_shop_last_sale'] = matrix['item_shop_last_sale'].astype(np.int8)\n# for idx, row in matrix.iterrows():    \n#     key = str(row.item_id)+' '+str(row.shop_id)\n#     if key not in cache:\n#         if row.item_cnt_month!=0:\n#             cache[key] = row.date_block_num\n#     else:\n#         last_date_block_num = cache[key]\n#         matrix.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n#         cache[key] = row.date_block_num    \n\nfor row in matrix.itertuples():\n    idx = getattr(row,'Index')\n    item_id = getattr(row,'item_id')\n    shop_id = getattr(row,'shop_id')\n    date_block_num = getattr(row,'date_block_num')\n    item_cnt_month = getattr(row,'item_cnt_month')\n    key = str(item_id)+' '+str(shop_id)\n    if key not in cache:\n        if item_cnt_month!=0:\n            cache[key] = date_block_num\n    else:\n        last_date_block_num = cache[key]\n        matrix.at[idx, 'item_shop_last_sale'] = date_block_num - last_date_block_num\n        cache[key] = date_block_num","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"每个商品上一次售出是几个月前"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncache = {}\nmatrix['item_last_sale'] = -1\nmatrix['item_last_sale'] = matrix['item_last_sale'].astype(np.int8)\n# for idx, row in matrix.iterrows():    \n#     key = row.item_id\n#     if key not in cache:\n#         if row.item_cnt_month!=0:\n#             cache[key] = row.date_block_num\n#     else:\n#         last_date_block_num = cache[key]\n#         if row.date_block_num>last_date_block_num:\n#             matrix.at[idx, 'item_last_sale'] = row.date_block_num - last_date_block_num\n#             cache[key] = row.date_block_num         \n\nfor row in matrix.itertuples():\n    idx = getattr(row,'Index')\n    key = getattr(row,'item_id')\n    date_block_num = getattr(row,'date_block_num')\n    item_cnt_month = getattr(row,'item_cnt_month')\n    if key not in cache:\n        if item_cnt_month!=0:\n            cache[key] = date_block_num\n    else:\n        last_date_block_num = cache[key]\n        if date_block_num>last_date_block_num:\n            matrix.at[idx, 'item_last_sale'] = date_block_num - last_date_block_num\n            cache[key] = date_block_num","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. 每个商店的每个商品第一次售出是几个月前；\n2. 每个商品第一次售出是几个月前；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmatrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\nmatrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 最后处理"},{"metadata":{},"cell_type":"markdown","source":"去掉前一年的数据，即0~11，共12个月的数据，原因是前12个月的数据在target lag特征上都存在NaN，因为target lag最远有一年前，因此最早的一年的数据对应的target lag 12肯定都是NaN，这些数据无法用于训练，因此需要去掉，值得注意的是，即便去掉了这部分数据，也不会减少原始数据的信息量，因为这部分数据的信息量体现在后面数据的lag上；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmatrix = matrix[matrix.date_block_num > 11]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"用0填充月销量，product操作产生了大量的NaN值，月销量作为目标变量，NaN用0填充；"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndef fill_na(df):\n    for col in df.columns:\n        if ('_lag_' in col) & (df[col].isnull().any()):\n            if ('item_cnt' in col):\n                df[col].fillna(0, inplace=True)         \n    return df\n\nmatrix = fill_na(matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"最后浏览下数据结构"},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features = [col for col in matrix.columns if (col.find('cnt')!=-1 or col.find('cnt')!=-1 or col.find('price')!=-1 or col.find('revenue')!=-1 or col.find('sale')!=-1)]\nmatrix[numerical_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix[numerical_features].apply(lambda x: kurt(x.dropna())).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pickle"},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.to_pickle('data.pkl')\n# 保留test_data，用以生成提交文件\ndel matrix, cache, group, train_data, shop_data, item_data, item_category_data\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"1/0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MODELING"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_pickle('data.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SPLIT DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_train = data[data.date_block_num < 33]['item_cnt_month']\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### BASELINE MODEL - xgboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel = XGBRegressor(\n    max_depth=8,\n    n_estimators=1000, # 1000\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8,\n    eta=0.3,\n    seed=10086)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict(X_valid)\nY_pred = np.expm1(Y_pred).clip(0, 20)\nprint('Expm1 after RMSE = ', np.sqrt(sklearn.metrics.mean_squared_error(np.expm1(Y_valid),Y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 特征重要性"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_features(model, (15,15))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correct Factor"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_valid_expm1 = np.expm1(Y_valid)\nY_pred_correct = Y_pred*(np.mean(Y_valid_expm1)/np.mean(Y_pred))\nY_pred_correct_add = Y_pred+(np.mean(Y_valid_expm1-Y_pred))\n\nprint('Mean of pred - valid:', np.mean(Y_pred - Y_valid_expm1))\nprint('Mean of pred_correct - valid:', np.mean(Y_pred_correct - Y_valid_expm1))\nprint('Mean of pred_correct_add - valid:', np.mean(Y_pred_correct_add - Y_valid_expm1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(22, 6))\ncompare_df = pd.DataFrame({'Y_pred':Y_pred[:500], \n                           'Y_valid':Y_valid_expm1[:500], \n                          'Y_pred_correct':Y_pred_correct[:500], \n                          'Y_pred_correct_add':Y_pred_correct_add[:500]})\nsns.lineplot(data=compare_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Expm1 after and Correct Factor RMSE = ', np.sqrt(sklearn.metrics.mean_squared_error(Y_valid_expm1,Y_pred_correct)))\nprint('Expm1 after and Correct Add RMSE = ', np.sqrt(sklearn.metrics.mean_squared_error(Y_valid_expm1,Y_pred_correct_add)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## OUTPUT"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test = np.expm1(model.predict(X_test)).clip(0, 20)+np.mean(Y_valid_expm1-Y_pred)\n\nsubmission = pd.DataFrame({\n    \"ID\": test_data.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('xgb_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}