{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install pytorchts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read in data\n\nFirst we read in the training data, which contains sales of shop + item combinations (lowest level of the hierarchy)."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nsales_train = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\nsales_train.date = pd.to_datetime(sales_train.date)\nsales_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, there are 60 unique shops in the training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.shop_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We remove records having a negative item price."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train = sales_train[sales_train['item_price'] > 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we set the records having a negative count (sales) to zero."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.loc[sales_train['item_cnt_day'] < 0,'item_cnt_day'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot the prices and counts:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nf, (ax1, ax2) = plt.subplots(figsize=(14,4), nrows=1, ncols=2)\nsns.boxplot(sales_train['item_price'].dropna(), ax=ax1)\nsns.boxplot(sales_train['item_cnt_day'].dropna(), ax=ax2)\nf.suptitle('Distribution of item price and item sales per day')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We remove outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train = sales_train[sales_train.item_price < 100000]\nsales_train = sales_train[sales_train.item_cnt_day < 1001]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Middle-out approach: shop level\n\nIn order to perform a middle-out approach, we are going to aggregate the sales at the shop level."},{"metadata":{"trusted":true},"cell_type":"code","source":"per_shop = sales_train.groupby(['shop_id','date'], as_index=False)['item_cnt_day'].sum()\nper_shop","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we create the targets as required by PyTorch-ts. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {}\ndate_indices = pd.date_range(\n        start=per_shop.date.min(),\n        end=per_shop.date.max(),\n        freq='D'\n    )\ntarget = pd.DataFrame(data, index=date_indices)\n\nfor shop_id in range(per_shop.shop_id.nunique()):\n    daily_sales = per_shop.loc[per_shop['shop_id'] == shop_id]\n    daily_sales = daily_sales.drop([\"shop_id\"], axis=1).set_index('date')\n    daily_sales = daily_sales.rename(columns={\"item_cnt_day\": shop_id})\n    # append to dataframe\n    target[shop_id] = daily_sales\n\ntarget.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting the sales of shops"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's plot the first 20 shops\nfor c in range(0,20):\n    fig = plt.figure(figsize=(12,3))\n    plt.plot(target[c])\n    plt.title('shop_id: %d' %(c))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading in the test set\n\nAs we read in the test set, we see that there are actually only 42 of the 60 shops from the training set present."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")\ntest_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.shop_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's filter the targets of the training set, to only contain those of the shops that are present in the test set:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.shop_id.value_counts().index.sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_shops_test_set = target.iloc[:, test_set.shop_id.value_counts().index.sort_values()]\ntargets_shops_test_set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check how many missing values there are for each of the shops:"},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_shops_test_set.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's filling in missing values by zeros:"},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_shops_test_set = targets_shops_test_set.fillna(0)\ntargets_shops_test_set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now plot the sales for each shop of the test set, with the missing values filled in:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's plot the first 20\nfor c in test_set.shop_id.value_counts().index.sort_values()[:20]:\n    fig = plt.figure(figsize=(12,3))\n    plt.plot(targets_shops_test_set[c])\n    plt.title('shop_id: %d' %(c))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the PyTorch TS datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pts.dataset import ListDataset, FieldName\n\nstart = targets_shops_test_set.index[0]\nnum_series = targets_shops_test_set.shape[1]\nprediction_length = 31\nfreq = \"D\"\n\ndata = targets_shops_test_set.T # shape (10, 1913)\n\ntrain_ds = ListDataset([{FieldName.TARGET: target,\n                         FieldName.START: start}\n                        for (target, start) in zip(data.values[:, :-prediction_length], # shape (42, 1003) \n                                                   [pd.Timestamp(start, freq=freq) for _ in range(num_series)])\n                        ],\n                        freq=freq)\n\ntest_ds = ListDataset([{FieldName.TARGET: target,\n                        FieldName.START: start}\n                       for (target, start) in zip(data.values, # shape (42, 1034)\n                                                  [pd.Timestamp(start, freq=freq) for _ in range(num_series)])\n                      ],\n                        freq=freq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pts.dataset import to_pandas\n\n# print out the first time series of the training set\ntrain_entry = next(iter(train_ds))\ntrain_series = to_pandas(train_entry)\ntrain_series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print out the first time series of the test set (which is the same as the one above, but a bit longer)\ntest_entry = next(iter(test_ds))\ntest_series = to_pandas(test_entry)\ntest_series","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualize the first time series (both train + test):"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\n\ntrain_series.plot(ax=ax[0])\nax[0].grid(which=\"both\")\nax[0].legend([\"train series\"], loc=\"upper left\")\n\ntest_series.plot(ax=ax[1])\nax[1].axvline(train_series.index[-1], color='r') # end of train dataset\nax[1].grid(which=\"both\")\nax[1].legend([\"test series\", \"end of train series\"], loc=\"upper left\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As TransformerTempFlow is a multivariate model, we use the grouper to make the target two-dimensional:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pts.dataset import to_pandas, MultivariateGrouper, TrainDatasets\n\ntrain_grouper = MultivariateGrouper(max_target_dim=int(len(train_ds)))\n\ntest_grouper = MultivariateGrouper(num_test_dates=int(len(test_ds)/len(train_ds)), \n                                   max_target_dim=int(len(train_ds)))\n\ndataset_train = train_grouper(train_ds)\ndataset_test = test_grouper(test_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the model (TransformerTempFlow)\n\nWe can now train the TransformerTempFlow model on the grouped dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom pts.model.tempflow import TempFlowEstimator\nfrom pts import Trainer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nestimator = TempFlowEstimator(\n    target_dim=int(len(train_ds)),\n    prediction_length=prediction_length,\n    cell_type='GRU',\n    flow_type='RealNVP',\n    input_size=42,\n    freq=freq,\n    scaling=True,\n    dequantize=True,\n    n_blocks=4,\n    trainer=Trainer(device=device,\n                    epochs=100,\n                    learning_rate=1e-3,\n                    num_batches_per_epoch=100,\n                    batch_size=64)\n)\n\npredictor = estimator.train(training_data=dataset_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Legacy"},{"metadata":{"trusted":true},"cell_type":"code","source":"# add id of test set to training set\nresult = pd.merge(sales_train, test_set, how='left', on=['shop_id','item_id'])\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.loc[result.ID == 0].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.shop_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for shop_id in test_set.shop_id:\n    print(shop_id, result.loc[result.shop_id == shop_id].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.loc[(result['shop_id']==5) & (result['item_id'] == 5037)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.loc[(result['shop_id'] == 25) & (result['item_id'] == 2552)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.ID.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.ID.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.ID.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}