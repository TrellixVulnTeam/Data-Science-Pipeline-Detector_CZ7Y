{"cells":[{"metadata":{},"cell_type":"markdown","source":"## ** LB probing, public/private split and simple seasonal decomposition **\n> \nHello fellow Kagglers :)\n\nThe kernel I'm building here aims at trying to use **leaderboard probing** to obtain a reasonable score on the public LB. The main idea is to **not use any ML model** to predict sales for the month of November 2015."},{"metadata":{},"cell_type":"markdown","source":"## ** Part I - LB probing and forecasting **\n\nWe'll first use sample submissions, one with only 0s and one with only 1s to calculate the mean of true LB values."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from pandas import read_csv\n\nsample_submission = read_csv('../input/sample_submission.csv')\n\nonly0s = sample_submission.assign(item_cnt_month = 0)\nonly1s = sample_submission.assign(item_cnt_month = 1)\n\nonly0s.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"only1s.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The submission with only 0s gives us a score of $1.25011$, and the one with only 1s yields $1.4124$ Using the following formula, those two values allow us to compute the exact mean of true values in public leaderboard.\n\n$$MSE(1) - MSE(0) = \\sum_{i=0}^N \\frac{(y_i - 1)^2}{N} - \\sum_{i=0}^N \\frac{y_i^2}{N}$$\n\n$$ = \\sum_{i=0}^N \\frac{y_i^2 - 2y_i + 1}{N} - \\frac{y_i^2}{N}$$\n\n$$ = \\sum_{i=0}^N \\frac{1 - 2y_i}{N}$$\n\n$$ = 1 - 2\\sum_{i=0}^N \\frac{y_i}{N}$$\n\n$$ = 1 - 2\\overline{y}$$\n\nGiven that $MSE(0) = 1,5627750121$ and $MSE(1) = 1.9949$, we can therefore establish that the mean value of true values is $0.283936502$ (We'll consider $0.284$ for convenience).\n\nIt is interesting to compare with the mean of train set to see **if public/private split can be identified**.\n\nTo do this, we first need to **aggregate train sales monthly** to be on the same page as test. We must not forgt to clamp values between 0 and 20."},{"metadata":{"trusted":true},"cell_type":"code","source":"del only0s, only1s\n\ntrain = read_csv('../input/sales_train.csv')\ntrain_by_month = train.groupby(['date_block_num', 'shop_id', 'item_id'])[['item_cnt_day']].sum().clip(0, 20)\ntrain_by_month.columns = ['item_cnt_month']\ntrain_by_month = train_by_month.reset_index()\ndel train\n\ntrain_by_month.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems good. Now we can compare the mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_by_month.groupby('date_block_num')['item_cnt_month'].mean().tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not quite what we expected ! This surely means that there are a **lot more 0s in test set than in train set**. Are there actually any 0s in train set ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('About %.2f%% of train values are 0s' % (train_by_month[train_by_month['item_cnt_month'] == 0].shape[0] * 100 / train_by_month.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Way less** than test set. There has to be something in the way the organizers built the test set. Let's have a look at it."},{"metadata":{"trusted":true},"cell_type":"code","source":"test = read_csv('../input/test.csv')\nlen(test.shop_id.unique()), len(test.item_id.unique()), len(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**42 * 5100 is 214200** so yes, basically the test set is built using **all combination of those 42 shops and 5100 items**. No wonder there are so many 0s in true values.\n\nWe need to make the **train set equivalent** to this scheme. To do that, we'll simply use those 42 shops and 5100 items, make all possible pairs with **date_block_num** from 0 to 33 and join with train set. Let's see how it goes.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product\nfrom pandas import DataFrame\n\npairs = DataFrame(list(product(list(range(34)), test.shop_id.unique(), test.item_id.unique())), columns = ['date_block_num', 'shop_id', 'item_id'])\npairs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now join with train set. We also downcast values to reduce memory usage."},{"metadata":{"trusted":true},"cell_type":"code","source":"def displayWithSize(df):\n    print('Shape : %i x %i' % df.shape)\n    m = df.memory_usage().sum()\n    if m >= 1000000000:\n        print('Total memory usage : %.2f Go' % (m / 1000000000))\n    else:\n        print('Total memory usage : %.2f Mo' % (m / 1000000))\n    return df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import uint8, uint16, float16\n\npairs_red = pairs.assign(date_block_num = pairs['date_block_num'].astype(uint8))\npairs_red = pairs_red.assign(shop_id = pairs['shop_id'].astype(uint8))\npairs_red = pairs_red.assign(item_id = pairs['item_id'].astype(uint16))\ndel pairs\n\ninflated_train = pairs_red.merge(train_by_month, on=['date_block_num', 'shop_id', 'item_id'], how='left')\ninflated_train.fillna(0.0, inplace=True)\ndel pairs_red\n\ndisplayWithSize(inflated_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inflated_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ** WARNING **\n\n**Downcasting** is a good strategy to help **reduce memory error chances**, but it has its ***limit*** : each data type has its own min and max values, for example **float16 goes from -65504 to +65504**, hence when calculating things like mean or sum, during the calculus **the value can exceed the max and result in a NaN or inf value**. So be careful :)\n\nThat's why we did not downcast **item_cnt_month**."},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import finfo\n\nfinfo(float16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok ! Now we can compare mean values of last month in train and month in test !"},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import float64\n\ninflated_train[inflated_train['date_block_num'] == 33]['item_cnt_month'].astype(float64).clip(0, 20).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Amazing ! This clearly means that public/private split in the leaderboard is **completely random** !!\n\nHow does the sales trend look like with our new train set ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.pyplot import plot\n%matplotlib inline\n\nsales_by_month = inflated_train.groupby('date_block_num')['item_cnt_month'].sum().tolist()\nplot(sales_by_month)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A nice trend draws itself ! It is **going up**, because we are only looking at a **small subset of items/shops**, that is on of the **latest as it is from test set**. Can we use a seasonal decomposition on this one ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\nfrom matplotlib.pyplot import figure\n\ndecomposition = seasonal_decompose(sales_by_month, freq=12, model='multiplicative')\nfig = figure()  \nfig = decomposition.plot()  \nfig.set_size_inches(15, 8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Very interesting ! The residual part **oscillate between 0.9 and 1.1** which is **only 10%** of original data. This is low enough. We can hence build a **multiplicative factor based on trend * seasonal**, that will, combined with latest months, help us build a no-ML based model.\n\nThe strategy for this seasonal decompose is simple : **seasonal part is repetitive** so we will just **use it as is**. **Trend part is not** : we will use a rolling mean scheme to **forecast trend** on month 33 (validation) and 34 (kaggle prediction). We then multiply both, to get a factor. Then, to forecast month n+1, we divide month n sales by the factor for month n, and multiply by factor for month n+1."},{"metadata":{"trusted":true},"cell_type":"code","source":"def rolling_mean(data, timespan):\n    n = len(data)\n    output = []\n    for i in range(n):\n        maxWindow = min(i - max(0, i-timespan//2), min(n, i+timespan//2) - i)\n        output.append(data[i-maxWindow:i+maxWindow+1])\n    return list(map(lambda x: sum(x) / len(x), output))\n\nrmean = rolling_mean(sales_by_month, 12)\nplot(rmean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see a clear divergence at the end, that's because we don't have data about the future. Therefore we need to smoothen it using a mean of last 6 months trend."},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import mean\n\nincr_step = mean(list(map(lambda x: x[0] - x[1], zip(rmean[22:28], rmean[21:27]))))\nincr_step","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmean_corrected = rmean[:28]\ncurrent = rmean_corrected[-1]\n\nfor _ in range(6):\n    current += incr_step\n    rmean_corrected.append(current)\n\nplot(rmean_corrected)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if product of both trend and seasonal is close to reality"},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = list(map(lambda x: x[0] * x[1], zip(rmean_corrected, decomposition.seasonal)))\n\nplot(sales_by_month)\nplot(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks rather nice ! We can forecast for month 34."},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast.append((rmean_corrected[-1] + incr_step) * decomposition.seasonal[-12])\n\nplot(sales_by_month)\nplot(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All right ! We have our forecasted values for both month 33 and 34, let's do some predictions !"},{"metadata":{},"cell_type":"markdown","source":"## ** Part II - No-ML predictions **\n\nThe process is simple. We know data about month N, and we want to predict for month N+1.\n\nWe have real **mean sales for month N** and forecasted **mean sales for month N+1**.\nWe know exactly the **mean values of month N+1** (or at least an estimation).\n\nWe proceed as follow :\n - We take all **item_cnt_month** values from month N\n - We divide values by **mean sales of month N**\n - We multiply values by **mean sales of month N+1**\n - We fill 0 values with a constant value such that the total mean of all values becomes the **mean values of month N+1** (this one goes from the fact that to minimize RMSE with a constant, you need to take the mean of true values)\n \nThe last step is a little bit tricky. Let us note :\n - $C_0$ the number of 0s in values\n - $C$ the number of values\n - $m_c$ the current mean\n - $m_t$ the target mean\n - $y_i$ the value $i$\n \nWe then have :\n\n$$m_c = \\sum_{i=0}^C \\frac{y_i}{C} \\iff m_c = \\sum_{i=0, y_i\\ne0}^C \\frac{y_i}{C}$$\n\nAnd :\n\n$$m_t = m_c + (m_t - m_c) = \\sum_{i=0, y_i\\ne0}^C \\frac{y_i}{C} + \\frac{C_0}{C_0}(m_t - m_c) = \\sum_{i=0, y_i\\ne0}^C \\frac{y_i}{C} + \\sum_{i=0, y_i=0}^C \\frac{C}{C_0}\\frac{m_t - m_c}{C}$$\n\n$$ = \\frac{1}{C}(\\sum_{i=0, y_i\\ne0}^C y_i + \\sum_{i=0, y_i=0}^C \\frac{C}{C_0}(m_t - m_c))$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"month_n = 32\nmonth_n_plus_1 = 33\n\nitem_cnt_month_n = inflated_train[inflated_train['date_block_num'] == month_n]['item_cnt_month']\n\nC0 = sum(item_cnt_month_n == 0)\nC = len(item_cnt_month_n)\nmt = inflated_train[inflated_train['date_block_num'] == month_n_plus_1]['item_cnt_month'].mean()\n\nitem_cnt_month_n_plus_1 = item_cnt_month_n / sales_by_month[month_n]\nitem_cnt_month_n_plus_1 = (item_cnt_month_n_plus_1 * forecast[month_n_plus_1]).clip(0, 20)\nitem_cnt_month_n_plus_1[item_cnt_month_n_plus_1 == 0] = (C / C0) * (mt - item_cnt_month_n_plus_1.mean())\n\nitem_cnt_month_n_plus_1.mean(), mt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What is the RMSE ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom numpy import sqrt\n\ndef rmse(y, y_pred):\n    return sqrt(mean_squared_error(y, y_pred))\n\nrmse(item_cnt_month_n_plus_1, inflated_train[inflated_train['date_block_num'] == month_n_plus_1]['item_cnt_month'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not quite convinced we can call this a good result. But still, it is way better than the constant 0s prediction so...\n\nThe interest lied in the approach anyway :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"month_n = 33\nmonth_n_plus_1 = 34\n\nitem_cnt_month_n = inflated_train[inflated_train['date_block_num'] == month_n]['item_cnt_month']\n\nC0 = sum(item_cnt_month_n == 0)\nC = len(item_cnt_month_n)\nmt = 0.284\n\nitem_cnt_month_n_plus_1 = item_cnt_month_n / sales_by_month[month_n]\nitem_cnt_month_n_plus_1 = (item_cnt_month_n_plus_1 * forecast[month_n_plus_1]).clip(0, 20)\nitem_cnt_month_n_plus_1[item_cnt_month_n_plus_1 == 0] = max(0, min(20, (C / C0) * (mt - item_cnt_month_n_plus_1.mean())))\n\nitem_cnt_month_n_plus_1.mean(), mt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DataFrame(list(zip(range(len(item_cnt_month_n_plus_1)), item_cnt_month_n_plus_1)), columns=['ID', 'item_cnt_month']).to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}