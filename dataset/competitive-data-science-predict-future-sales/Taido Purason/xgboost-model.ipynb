{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport gc\nimport pickle\nimport time\n\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\nfrom joblib import dump, load\n\n\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pkg_resources\nimport types\ndef get_imports():\n    for name, val in globals().items():\n        if isinstance(val, types.ModuleType):\n            # Split ensures you get root package, \n            # not just imported function\n            name = val.__name__.split(\".\")[0]\n\n        elif isinstance(val, type):\n            name = val.__module__.split(\".\")[0]\n\n        # Some packages are weird and have different\n        # imported names vs. system names\n        if name == \"PIL\":\n            name = \"Pillow\"\n        elif name == \"sklearn\":\n            name = \"scikit-learn\"\n\n        yield name\nimports = list(set(get_imports()))\n\nrequirements = []\nfor m in pkg_resources.working_set:\n    if m.project_name in imports and m.project_name!=\"pip\":\n        requirements.append((m.project_name, m.version))\n\nfor r in requirements:\n    print(\"{}=={}\".format(*r))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_pickle('../input/eda-preprocessing-feature-engineering/all_data.pkl')\n# Dropping the first 6 months because they were used for lags\ndata = data[data.date_block_num > 5]\ntest  = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')\n\n# dropping some of the columns that didn't give any improvement\ndropcols = [\n            \"item_cnt_month_lag_12\",\n            \"item_cnt_month_lag_12_adv\",\n            \"date_item_target_enc_lag_12\",\n            \"date_shop_target_enc_lag_12\",\n            \"date_city_target_enc_lag_1\",\n            \"date_city_target_enc_lag_2\",\n            \"date_city_target_enc_lag_3\",\n            \"date_type_target_enc_lag_1\",\n            \"date_subtype_target_enc_lag_1\",\n            \"new_item_cat_avg_lag_1\",\n            \"new_item_cat_avg_lag_2\",\n            \"new_item_cat_avg_lag_3\",\n            \"new_item_shop_cat_avg_lag_1\",\n            \"new_item_shop_cat_avg_lag_2\",\n            \"new_item_shop_cat_avg_lag_3\",\n           ]\n\n# Doing the time based train-val-test split\nX_train = data[data.date_block_num < 33].drop(['item_cnt_month']+dropcols, axis=1)\nY_train = data[data.date_block_num < 33]['item_cnt_month']\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month']+dropcols, axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month']+dropcols, axis=1)\n\ndel data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features used:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using XGBRegressor with tuned parameters. Tried stacking, but didn't manage to get any improvement on the results so sticking with a single model"},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nmodel = XGBRegressor(\n        max_depth=10,\n        n_estimators=1500,\n        min_child_weight=0.5, \n        colsample_bytree=0.8, \n        subsample=0.7, \n        eta=0.01,\n        tree_method='gpu_hist',\n        seed=0)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds = 100)\n\nprint(f\"training took {time.time() - start_time}s\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Importances:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_features(model, (10,14))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submitting the predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting on the test set\n\nstart_time = time.time()\nY_test = model.predict(X_test).clip(0, 20)\nprint(f\"predicting on test set took {time.time() - start_time}s\")\n\n# Predicting on train set\nstart_time = time.time()\nY_train_pred = model.predict(X_train).clip(0, 20)\nprint(f\"Predicting on train set took {time.time() - start_time} s\")\n\n# Predicting on valid set\nstart_time = time.time()\nY_valid_pred = model.predict(X_valid).clip(0, 20)\nprint(f\"Predicting on valid set took {time.time() - start_time} s\")\n\n# Savin the predictions\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('xgb_submission.csv', index=False)\n\ntrain_preds = pd.DataFrame({\n    \"ID\": X_train.index, \n    \"item_cnt_month\": Y_train_pred\n})\ntrain_preds.to_csv('xgb_y_train.csv', index=False)\n\nvalid_preds = pd.DataFrame({\n    \"ID\": X_valid.index, \n    \"item_cnt_month\": Y_valid_pred\n})\nvalid_preds.to_csv('xgb_y_valid.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the model to disk\ndump(model, 'xgb_model.joblib') ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}