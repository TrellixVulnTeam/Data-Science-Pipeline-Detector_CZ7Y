{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport gc\nimport pickle\nimport time\nfrom joblib import dump, load\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This cell is only for displaying package versions. You can ignore it.\n\nimport pkg_resources\nimport types\ndef get_imports():\n    for name, val in globals().items():\n        if isinstance(val, types.ModuleType):\n            # Split ensures you get root package, \n            # not just imported function\n            name = val.__name__.split(\".\")[0]\n\n        elif isinstance(val, type):\n            name = val.__module__.split(\".\")[0]\n\n        # Some packages are weird and have different\n        # imported names vs. system names\n        if name == \"PIL\":\n            name = \"Pillow\"\n        elif name == \"sklearn\":\n            name = \"scikit-learn\"\n\n        yield name\nimports = list(set(get_imports()))\n\nrequirements = []\nfor m in pkg_resources.working_set:\n    if m.project_name in imports and m.project_name!=\"pip\":\n        requirements.append((m.project_name, m.version))\n\nfor r in requirements:\n    print(\"{}=={}\".format(*r))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading the trained models\nxgbm = load(\"../input/xgboost-model/xgb_model.joblib\")\nlgbm = load(\"../input/lightgbm-model/lightgbm_model.joblib\")\nrfm = load(\"../input/randomforest-model/rf_model.joblib\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost model"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(12,8))\nxgb.plot_importance(xgbm, ax=ax);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(\n    lgbm,  \n    importance_type='gain', \n    figsize=(12,8));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest model"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importances = pd.Series(rfm.feature_importances_, index=xgbm.get_booster().feature_names)\nfeat_importances.sort_values().plot(kind='barh', figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the lower level model predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBoost model\nxgb_train  = pd.read_csv('../input/xgboost-model/xgb_y_train.csv').set_index('ID')\nxgb_valid  = pd.read_csv('../input/xgboost-model/xgb_y_valid.csv').set_index('ID')\nxgb_test  = pd.read_csv('../input/xgboost-model/xgb_submission.csv').set_index('ID')\n\n# LightGBM model\nlgb_train  = pd.read_csv('../input/lightgbm-model/gbm_y_train.csv').set_index('ID')\nlgb_valid  = pd.read_csv('../input/lightgbm-model/gbm_y_valid.csv').set_index('ID')\nlgb_test  = pd.read_csv('../input/lightgbm-model/gbm_y_test.csv').set_index('ID')\n\n# RandomForest model\nrf_train  = pd.read_csv('../input/randomforest-model/rf_y_train.csv').set_index('ID')\nrf_valid  = pd.read_csv('../input/randomforest-model/rf_y_valid.csv').set_index('ID')\nrf_test  = pd.read_csv('../input/randomforest-model/rf_y_test.csv').set_index('ID')\n\n# loading test set\ntest  = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding the first level model predictions together\nX_train = np.hstack([xgb_train.values, lgb_train.values, rf_train.values])\nX_valid = np.hstack([xgb_valid.values, lgb_valid.values, rf_valid.values])\nX_test = np.hstack([xgb_test.values, lgb_test.values, rf_test.values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_pickle('../input/eda-preprocessing-feature-engineering/all_data.pkl')\n# Dropping the first 6 months because they were used for lags\ndata = data[data.date_block_num > 5]\n\n# Doing the time based train-val-test split\nY_train = data[data.date_block_num < 33]['item_cnt_month']\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\n\ndel data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{},"cell_type":"markdown","source":"I did not use scaling in preprocessing because it is not necessary for tree based models (all the model on the first level) and the second level model has built in normalization."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"start_time = time.time()\n# Fitting on valid, because the first level models were not trained on it and this way we reduce overfitting\n\n# Using liner regression as the second level model\nlr = LinearRegression(n_jobs=-1, normalize=True)\nlr.fit(X_valid, Y_valid)\n\nprint(f\"Training took {time.time() - start_time} s\")\n\nstart_time = time.time()\nY_valid_pred = lr.predict(X_valid).clip(0, 20)\nprint(f\"Predicting on valid set took {time.time() - start_time} s\")\n\nprint(f\"VALID RMSE: {round(np.sqrt(mean_squared_error(Y_valid, Y_valid_pred)), 5)}\")\n\n\n# Saving the trained model to disk\ndump(lr, 'stacking_model.joblib') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nY_test = lr.predict(X_test).clip(0, 20)\nprint(f\"Predicting test set took {time.time() - start_time} s\")\n\n# Creating the submission\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the stakced model weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = pd.Series(lr.coef_, index=[\"XGBoost\", \"LightGBM\", \"Random Forest\"])\nweights.sort_values().plot(kind='barh', figsize=(12,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}