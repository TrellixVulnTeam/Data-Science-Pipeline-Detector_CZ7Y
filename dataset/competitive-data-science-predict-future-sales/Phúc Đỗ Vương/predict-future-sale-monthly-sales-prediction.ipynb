{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lab 03 - Predict future sales\n\n## File descriptions\n- **sales_train.csv** - the training set. Daily historical data from January 2013 to October 2015.\n- **test.csv** - the test set. You need to forecast the sales for these shops and products for November 2015.\n- **sample_submission.csv** - a sample submission file in the correct format.\n- **items.csv** - supplemental information about the items/products.\n- **item_categories.csv**  - supplemental information about the items categories.\n- **shops.csv** - supplemental information about the shops.\n\n## Data fields\n- **ID** - an Id that represents a (Shop, Item) tuple within the test set\n- **shop_id** - unique identifier of a shop\n- **item_id** - unique identifier of a product\n- **item_category_id** - unique identifier of item category\n- **item_cnt_day** - number of products sold. You are predicting a monthly amount of this measure\n- **item_price** - current price of an item\n- **date** - date in format dd/mm/yyyy\n- **date_block_num** - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n- **item_name** - name of item\n- **shop_name** - name of shop\n- **item_category_name** - name of item category","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"!pip install findspark\n!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:20.956306Z","iopub.execute_input":"2022-05-27T16:24:20.956656Z","iopub.status.idle":"2022-05-27T16:24:38.287939Z","shell.execute_reply.started":"2022-05-27T16:24:20.956625Z","shell.execute_reply":"2022-05-27T16:24:38.286288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import findspark\nfindspark.init()\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom pyspark.sql import SparkSession, Window\n\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import GBTRegressor, LinearRegression, RandomForestRegressor\n\nfrom pyspark.ml.evaluation import RegressionEvaluator","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:38.290313Z","iopub.execute_input":"2022-05-27T16:24:38.291064Z","iopub.status.idle":"2022-05-27T16:24:38.297708Z","shell.execute_reply.started":"2022-05-27T16:24:38.291017Z","shell.execute_reply":"2022-05-27T16:24:38.296986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create spark session","metadata":{}},{"cell_type":"code","source":"spark = SparkSession \\\n    .builder \\\n    .appName(\"Predict future sales\") \\\n    .config(\"spark.ui.showConsoleProgress\", \"false\") \\\n    .config(\"spark.driver.memory\", \"12g\") \\\n    .getOrCreate()\nspark.sparkContext.uiWebUrl","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:38.298561Z","iopub.execute_input":"2022-05-27T16:24:38.298768Z","iopub.status.idle":"2022-05-27T16:24:38.319167Z","shell.execute_reply.started":"2022-05-27T16:24:38.298744Z","shell.execute_reply":"2022-05-27T16:24:38.318519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"markdown","source":"### Main file","metadata":{}},{"cell_type":"code","source":"df = spark.read.csv('../input/competitive-data-science-predict-future-sales/sales_train.csv', header=True, inferSchema=True)\ndf = df.withColumn('date',to_date(df.date,'dd.MM.yyyy'))\n\ndf.show(3)\ndf.printSchema()\nprint(\"Count:\",df.count())","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:38.320731Z","iopub.execute_input":"2022-05-27T16:24:38.321002Z","iopub.status.idle":"2022-05-27T16:24:49.072121Z","shell.execute_reply.started":"2022-05-27T16:24:38.320971Z","shell.execute_reply":"2022-05-27T16:24:49.07125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Items","metadata":{}},{"cell_type":"code","source":"items = spark.read.csv('../input/competitive-data-science-predict-future-sales/items.csv',header=True)\n\nitems.show(3,truncate=False)\nitems.printSchema()\nprint('Count:',items.count())","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:49.073295Z","iopub.execute_input":"2022-05-27T16:24:49.073575Z","iopub.status.idle":"2022-05-27T16:24:50.0906Z","shell.execute_reply.started":"2022-05-27T16:24:49.073536Z","shell.execute_reply":"2022-05-27T16:24:50.089435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categories","metadata":{}},{"cell_type":"code","source":"categories = spark.read.csv('../input/competitive-data-science-predict-future-sales/item_categories.csv',header=True)\n\ncategories.show(3,truncate=False)\ncategories.printSchema()\nprint('Count:',categories.count())","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:50.091829Z","iopub.execute_input":"2022-05-27T16:24:50.092138Z","iopub.status.idle":"2022-05-27T16:24:50.676934Z","shell.execute_reply.started":"2022-05-27T16:24:50.092098Z","shell.execute_reply":"2022-05-27T16:24:50.676063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Shops","metadata":{}},{"cell_type":"code","source":"shops = spark.read.csv('../input/competitive-data-science-predict-future-sales/shops.csv',header=True)\nshops.show(5)\nshops.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:50.678103Z","iopub.execute_input":"2022-05-27T16:24:50.678425Z","iopub.status.idle":"2022-05-27T16:24:51.035998Z","shell.execute_reply.started":"2022-05-27T16:24:50.678384Z","shell.execute_reply":"2022-05-27T16:24:51.034618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Join tables","metadata":{}},{"cell_type":"code","source":"df = df.join(items,on='item_id',how='inner')\ndf = df.join(categories,on='item_category_id',how='inner')\ndf = df.join(shops,on='shop_id',how='inner')\ndf.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:51.037243Z","iopub.execute_input":"2022-05-27T16:24:51.037547Z","iopub.status.idle":"2022-05-27T16:24:51.155903Z","shell.execute_reply.started":"2022-05-27T16:24:51.037501Z","shell.execute_reply":"2022-05-27T16:24:51.154976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"df = df.where(expr(\n    'item_price>0 and item_cnt_day>=0'\n))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:51.157168Z","iopub.execute_input":"2022-05-27T16:24:51.157456Z","iopub.status.idle":"2022-05-27T16:24:51.228821Z","shell.execute_reply.started":"2022-05-27T16:24:51.157423Z","shell.execute_reply":"2022-05-27T16:24:51.227924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"code","source":"def groupCategory(init_category, index):\n    if (index in list(range(1,8))):\n        return 'Access'\n    elif (index in list(range(10,18))):\n        return 'Console'\n    elif (index in list(range(18,25))):\n        return 'Consoles Game'\n    elif (index in list(range(26,28))):\n        return 'Phone Game'\n    elif (index in list(range(28,32))):\n        return 'CD Game'\n    elif (index in list(range(32,37))):\n        return 'Card'\n    elif (index in list(range(37,43))):\n        return 'Movie'\n    elif (index in list(range(43,55))):\n        return 'Book'\n    elif (index in list(range(55,61))):\n        return 'Music'\n    elif (index in list(range(61,73))):\n        return 'Gift'\n    elif (index in list(range(73,79))):\n        return 'Soft'\n    else:\n        return init_category\n\ncategories = categories.rdd.map(lambda r: (\n    groupCategory(r[0], int(r[1])),\n    r[1]\n))\ncategories = categories.toDF([\n    'item_category_name',\n    'item_category_id'\n])\n\ndf = df.drop('item_category_name')\ndf = df.join(categories,on='item_category_id',how='inner')\ndf.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:51.232358Z","iopub.execute_input":"2022-05-27T16:24:51.232946Z","iopub.status.idle":"2022-05-27T16:24:52.196467Z","shell.execute_reply.started":"2022-05-27T16:24:51.2329Z","shell.execute_reply":"2022-05-27T16:24:52.195629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.withColumnRenamed('item_cnt_day','labels')\n\ndf = df.groupby([\n    'shop_id',\n    'shop_name',\n    'item_id',\n    'item_name',\n    'item_category_name',\n    'date_block_num'\n]).agg(\n    sum('labels').alias('labels'),\n    mean('item_price').alias('item_price')\n)\ndf.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:52.197604Z","iopub.execute_input":"2022-05-27T16:24:52.197875Z","iopub.status.idle":"2022-05-27T16:24:52.276379Z","shell.execute_reply.started":"2022-05-27T16:24:52.197838Z","shell.execute_reply":"2022-05-27T16:24:52.275499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.where(expr('labels<=500'))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:52.277469Z","iopub.execute_input":"2022-05-27T16:24:52.277735Z","iopub.status.idle":"2022-05-27T16:24:52.314817Z","shell.execute_reply.started":"2022-05-27T16:24:52.277701Z","shell.execute_reply":"2022-05-27T16:24:52.313962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.withColumn('month',floor(df['date_block_num']/12)+1)\ndf = df.withColumn('isWinter',expr(\n    'cast((10<=month and month<=12) as string)'\n))\ndf.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:52.315937Z","iopub.execute_input":"2022-05-27T16:24:52.316205Z","iopub.status.idle":"2022-05-27T16:24:52.49759Z","shell.execute_reply.started":"2022-05-27T16:24:52.316172Z","shell.execute_reply":"2022-05-27T16:24:52.496809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"window = Window.orderBy('date_block_num').partitionBy('shop_name','item_name')\ndf = df.withColumn(\n    'lag_1', \n    lag('labels',offset=1,default=0).over(window)\n)\ndf = df.withColumn(\n    'lag_2', \n    lag('labels',offset=2,default=0).over(window)\n)\n\ndf.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:52.498637Z","iopub.execute_input":"2022-05-27T16:24:52.498919Z","iopub.status.idle":"2022-05-27T16:24:52.644479Z","shell.execute_reply.started":"2022-05-27T16:24:52.498866Z","shell.execute_reply":"2022-05-27T16:24:52.643613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-test split","metadata":{}},{"cell_type":"markdown","source":"Instead of splitting randomly, the time-series problem must split the train set is the first part of the data, while the test is the later on. Here, we pick records whose block is from `[2,27]` to be the train, and the rest is the test. ","metadata":{}},{"cell_type":"code","source":"train = df.where(expr('2<=date_block_num and date_block_num<28'))\ntest = df.where(expr('date_block_num>=28'))\n\nbackup_train = train","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:52.645636Z","iopub.execute_input":"2022-05-27T16:24:52.648058Z","iopub.status.idle":"2022-05-27T16:24:52.683493Z","shell.execute_reply.started":"2022-05-27T16:24:52.648006Z","shell.execute_reply":"2022-05-27T16:24:52.682616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the categorical features, we first index them into integer values.","metadata":{}},{"cell_type":"code","source":"cat_col = [\n    'shop_name',\n    'item_category_name',\n    'isWinter'\n]\nindex_col = [c+\"_index\" for c in cat_col]\n\nindexer = StringIndexer(\n    inputCols = cat_col,\n    outputCols = index_col,\n    handleInvalid = 'keep'\n).fit(train)\n\ntrain = indexer.transform(train)\ntrain.select(index_col).show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:24:52.685768Z","iopub.execute_input":"2022-05-27T16:24:52.686433Z","iopub.status.idle":"2022-05-27T16:25:12.574165Z","shell.execute_reply.started":"2022-05-27T16:24:52.686385Z","shell.execute_reply":"2022-05-27T16:25:12.573081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thereafter, the indexed columns are now encoded using one-hot encoding technique. This can prevent the model treating the categorical values has the magnitude. ","metadata":{}},{"cell_type":"code","source":"ohe_col = [c+\"_ohe\" for c in cat_col]\n\nohe = OneHotEncoder(\n    inputCols = index_col,\n    outputCols = ohe_col,\n    handleInvalid = 'keep'\n).fit(train)\n\ntrain = ohe.transform(train)\ntrain.select(ohe_col).show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:25:12.575489Z","iopub.execute_input":"2022-05-27T16:25:12.575814Z","iopub.status.idle":"2022-05-27T16:25:19.47872Z","shell.execute_reply.started":"2022-05-27T16:25:12.575757Z","shell.execute_reply":"2022-05-27T16:25:19.477831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, the feature columns are combined into a vector called `features`.","metadata":{}},{"cell_type":"code","source":"feature_col = [\n    'shop_name_ohe',\n    'item_category_name_ohe',\n    'isWinter_ohe',\n    'month',\n    'lag_1',\n    'lag_2',\n    'item_price'\n]\n\nassembler = VectorAssembler(\n    inputCols=feature_col, \n    outputCol='features',\n    handleInvalid='keep'\n)\ntrain = assembler.transform(train)\n\ntrain.select('labels','features').show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:25:19.479906Z","iopub.execute_input":"2022-05-27T16:25:19.480203Z","iopub.status.idle":"2022-05-27T16:25:31.420109Z","shell.execute_reply.started":"2022-05-27T16:25:19.480153Z","shell.execute_reply":"2022-05-27T16:25:31.419136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"### Evaluator","metadata":{}},{"cell_type":"code","source":"evaluator = RegressionEvaluator(\n    labelCol=\"labels\", \n    predictionCol=\"prediction\", \n    metricName=\"rmse\"\n)\ntrain = backup_train","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:25:31.421332Z","iopub.execute_input":"2022-05-27T16:25:31.421634Z","iopub.status.idle":"2022-05-27T16:25:31.436708Z","shell.execute_reply.started":"2022-05-27T16:25:31.421591Z","shell.execute_reply":"2022-05-27T16:25:31.436043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 1 - Gradient Boosting Tree","metadata":{}},{"cell_type":"code","source":"gbt = GBTRegressor(\n    featuresCol = 'features', \n    labelCol = 'labels'\n)\npipeline_1 = Pipeline(stages=[\n    indexer,\n    ohe,\n    assembler, \n    gbt\n])\n\nmodel_1 = pipeline_1.fit(train)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:25:31.438006Z","iopub.execute_input":"2022-05-27T16:25:31.43843Z","iopub.status.idle":"2022-05-27T16:27:18.851356Z","shell.execute_reply.started":"2022-05-27T16:25:31.438399Z","shell.execute_reply":"2022-05-27T16:27:18.850323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred = model_1.transform(train)\ntest_pred = model_1.transform(test)\n\ntest_pred.select(\"prediction\", \"labels\").show(5)\n\nprint(\"RMSE train data = %g\" % evaluator.evaluate(train_pred))\nprint(\"RMSE test data = %g\" % evaluator.evaluate(test_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:18.853419Z","iopub.execute_input":"2022-05-27T16:27:18.853991Z","iopub.status.idle":"2022-05-27T16:27:29.542464Z","shell.execute_reply.started":"2022-05-27T16:27:18.853945Z","shell.execute_reply":"2022-05-27T16:27:29.540939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 2 - Linear regression","metadata":{}},{"cell_type":"code","source":"lr = LinearRegression(\n    regParam = 0.3, \n    elasticNetParam = 0.2, \n    featuresCol = 'features',\n    labelCol = 'labels'\n)\npipeline_2 = Pipeline(stages=[\n    indexer,\n    ohe,\n    assembler, \n    lr\n])\n\nmodel_2 = pipeline_2.fit(train)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:29.543662Z","iopub.status.idle":"2022-05-27T16:27:29.54436Z","shell.execute_reply.started":"2022-05-27T16:27:29.544073Z","shell.execute_reply":"2022-05-27T16:27:29.544102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred = model_2.transform(train)\ntest_pred = model_2.transform(test)\n\ntest_pred.select(\"prediction\", \"labels\").show(5)\n\nprint(\"RMSE train data = %g\" % evaluator.evaluate(train_pred))\nprint(\"RMSE test data = %g\" % evaluator.evaluate(test_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:29.54582Z","iopub.status.idle":"2022-05-27T16:27:29.546357Z","shell.execute_reply.started":"2022-05-27T16:27:29.546091Z","shell.execute_reply":"2022-05-27T16:27:29.546118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 3 - Random Forest","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor (\n    featuresCol='features', \n    labelCol='labels', \n    maxDepth = 3,\n    numTrees = 20\n)\n\npipeline_3 = Pipeline(stages=[\n    indexer,\n    ohe,\n    assembler, \n    lr\n])\n\nmodel_3 = pipeline_3.fit(train)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:29.547985Z","iopub.status.idle":"2022-05-27T16:27:29.548555Z","shell.execute_reply.started":"2022-05-27T16:27:29.548299Z","shell.execute_reply":"2022-05-27T16:27:29.548328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred = model_3.transform(train)\ntest_pred = model_3.transform(test)\n\ntest_pred.select(\"prediction\", \"labels\").show(5)\n\nprint(\"RMSE train data = %g\" % evaluator.evaluate(train_pred))\nprint(\"RMSE test data = %g\" % evaluator.evaluate(test_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:29.549932Z","iopub.status.idle":"2022-05-27T16:27:29.556224Z","shell.execute_reply.started":"2022-05-27T16:27:29.555945Z","shell.execute_reply":"2022-05-27T16:27:29.555979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test create for submission","metadata":{}},{"cell_type":"code","source":"best_pipeline = pipeline_3\nbest_model = best_pipeline.fit(df)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:29.55739Z","iopub.status.idle":"2022-05-27T16:27:29.565214Z","shell.execute_reply.started":"2022-05-27T16:27:29.564942Z","shell.execute_reply":"2022-05-27T16:27:29.564974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_test = spark.read.csv('../input/competitive-data-science-predict-future-sales/test.csv',header=True,inferSchema=True)\n\nprint(\"Count:\",kaggle_test.count())\nkaggle_test.show(3)\nkaggle_test.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:29.566368Z","iopub.status.idle":"2022-05-27T16:27:29.56699Z","shell.execute_reply.started":"2022-05-27T16:27:29.566726Z","shell.execute_reply":"2022-05-27T16:27:29.566754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Join other files\nkaggle_test = kaggle_test.join(items,on='item_id',how='left')\nkaggle_test = kaggle_test.join(categories,on='item_category_id',how='left')\nkaggle_test = kaggle_test.join(shops,on='shop_id',how='left')\n\n# Join for price\nkaggle_test = kaggle_test.join(\n    df.select('shop_id','item_id','item_price')\\\n        .groupby('shop_id','item_id')\\\n        .agg(\n            mean('item_price').alias('item_price')\n        ),\n    on = ['shop_id','item_id'],\n    how = 'left'\n)\n\n# Create feature\nkaggle_test = kaggle_test.withColumn('month',lit(11))\nkaggle_test = kaggle_test.withColumn('isWinter',lit('True'))\n\n# Create lag_1\nkaggle_test = kaggle_test.join(\n    df.where('date_block_num==33').select('shop_id','item_id','lag_1'),\n    on=['shop_id','item_id'],\n    how='left'\n)\n\n# Create lag_2\nkaggle_test = kaggle_test.join(\n    df.where('date_block_num==32').select('shop_id','item_id','lag_2'),\n    on=['shop_id','item_id'],\n    how='left'\n)\n\n# Drop useless columns\nkaggle_test = kaggle_test.drop(\n    'shop_id',\n    'item_id',\n    'item_category_id',\n)\n\n# Fill NaN values by 0\nkaggle_test = kaggle_test.fillna(0)\n\n# Verify the number of samples\nprint(\"Count:\",kaggle_test.count())\nkaggle_test.printSchema()\nkaggle_test.show(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:29.568205Z","iopub.status.idle":"2022-05-27T16:27:29.568607Z","shell.execute_reply.started":"2022-05-27T16:27:29.568391Z","shell.execute_reply":"2022-05-27T16:27:29.568414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_test = best_model.transform(kaggle_test)\nkaggle_test.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:29.570223Z","iopub.status.idle":"2022-05-27T16:27:29.57079Z","shell.execute_reply.started":"2022-05-27T16:27:29.57054Z","shell.execute_reply":"2022-05-27T16:27:29.570566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_test.select(\n    'ID',\n    col('prediction').alias('item_cnt_month')\n).repartition(1).write.csv('submission',header=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T16:27:29.572079Z","iopub.status.idle":"2022-05-27T16:27:29.572592Z","shell.execute_reply.started":"2022-05-27T16:27:29.572356Z","shell.execute_reply":"2022-05-27T16:27:29.572382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nIn general, the problem is quite hard to working as a normal linear regression since we do not know the future. This is actually a time-series problem in which we cannot divide the data randomly. The train set must be the first part of data, while the test is the rest one (on the aspect of time).\n\nSince PySpark still has a lot weakness, we only use some traditional machine learning model provided (e.g. Random Forest, Linear Regression, etc) with feature engineering technique. Overall, the three tested models are achieved the RMSE roughly 4. As a result, the model achieved the score 2.88 on Kaggle contest.\n\nTo improve the performance of the model for this problem, we can consider to calculate the lag of times, difference between trends; or moreover, using AMRA, ARIMA, RNN-like models.","metadata":{}}]}