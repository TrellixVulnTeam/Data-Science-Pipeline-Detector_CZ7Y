{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # for prettier plots\nimport random as rd # generating random numbers\nimport datetime # manipulating date formats\n\nfrom tqdm import tqdm\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load sales\nsales=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\nsales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you can use this tip to save some memory : #downcast data to save memory : from 134.4+ MB, we went to 61.6+ MB\ndef downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\n\nprint(\"-- mem before\", sales.info())\nsales = downcast_dtypes(sales)\nprint(\"-- mem after\", sales.info())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TS des produits les plus rÃ©pandus\n\npour chaque produit \n\n- voir les dates min / max \n- le nombre de dates avec des ventes\n- par jour\n- aggreger par semaine, par mois\n\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from dateutil.parser import parse\nsales['rdate'] = sales['date'].apply(lambda d: parse(d))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = sales.groupby(by = 'item_id').agg({'rdate': [\"min\",\"max\"]}).reset_index()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['days'] =  df.apply(lambda d : (d['rdate']['max'] - d['rdate']['min']).days   , axis = 1   )\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def njours(item_id):\n    return len(sales[ (sales.item_id == item_id)   ].rdate.unique())\n\ndf['njours'] =  df.item_id.apply(lambda id : njours(id) )\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(by = ['njours', 'days'], ascending = [False, False],  inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_id = 5822\n# item_id = 12552\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_ids = df.head(10).item_id.values\n\ndef build_ts(item_id):\n\n    df2 = sales[sales.item_id == item_id][['item_cnt_day', 'rdate']].groupby( by = [ 'rdate']  ).sum().reset_index()\n    ts = pd.Series(index = df2.rdate, data = df2.item_cnt_day.values)\n    return ts\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = build_ts(item_ids[2])\nts.plot(figsize= (18,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Exponential Smoothing\n\n\n$ \\hat{y}_{t+1} = \\alpha . y_t + (1 -\\alpha ) . \\hat{y}_{t} $\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def exponential_smoothing(series, alpha):\n    \"\"\"\n        series - dataset with timestamps\n        alpha - float [0.0, 1.0], smoothing parameter\n    \"\"\"\n    result = [series[0]] # first value is same as series\n    for n in range(1, len(series)):\n        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n    return result\n    \n\n    \ndef plotExponentialSmoothing(series, alphas):\n    \"\"\"\n        Plots exponential smoothing with different alphas\n        \n        series - dataset with timestamps\n        alphas - list of floats, smoothing parameters\n        \n    \"\"\"\n    with plt.style.context('seaborn-white'):    \n        plt.figure(figsize=(18, 7))\n        plt.plot(series.values, \"c\", label = \"Actual\", alpha = 0.5)\n        for alpha in alphas:\n            plt.plot(exponential_smoothing(series, alpha), label=\"Alpha {}\".format(alpha))\n        plt.legend(loc=\"best\")\n        plt.axis('tight')\n        plt.title(\"Exponential Smoothing\")\n        plt.grid(True);\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = build_ts(item_ids[9])\nplotExponentialSmoothing(ts, [0.3, 0.05])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Double exponential smoothing\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def double_exponential_smoothing(series, alpha, beta):\n    \"\"\"\n        series - dataset with timeseries\n        alpha - float [0.0, 1.0], smoothing parameter for level\n        beta - float [0.0, 1.0], smoothing parameter for trend\n    \"\"\"\n    # first value is same as series\n    result = [series[0]]\n    level_ = [series[0]]\n    trend_ = [series[0]]\n    for n in range(1, len(series)+1):\n        if n == 1:\n            level, trend = series[0], series[1] - series[0]\n        if n >= len(series): # forecasting\n            value = result[-1]\n        else:\n            value = series[n]\n        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n        trend = beta*(level-last_level) + (1-beta)*trend\n        result.append(level+trend)\n        level_.append(level)\n        trend_.append(trend)\n    return result, level_, trend_\n\ndef plotDoubleExponentialSmoothing(series, alphas, betas):\n    \"\"\"\n        Plots double exponential smoothing with different alphas and betas\n        \n        series - dataset with timestamps\n        alphas - list of floats, smoothing parameters for level\n        betas - list of floats, smoothing parameters for trend\n    \"\"\"\n    \n    with plt.style.context('seaborn-white'):    \n        plt.figure(figsize=(20, 8))\n        for alpha in alphas:\n            for beta in betas:\n                r, l, t = double_exponential_smoothing(series, alpha, beta)\n                plt.plot(r, label=\"Alpha {}, beta {}\".format(alpha, beta))\n        plt.plot(series.values, label = \"Actual\", alpha = 0.5, linestyle = '-')\n                \n                \n        plt.legend(loc=\"best\")\n        plt.axis('tight')\n        plt.title(\"Double Exponential Smoothing\")\n        plt.grid(True)\n        \n        plt.figure(figsize=(20, 8))\n#         plt.plot(series.values, label = \"Actual\", alpha = 0.5, linestyle = '-')\n        for alpha in alphas:\n            for beta in betas:\n                r, l, t = double_exponential_smoothing(series, alpha, beta)\n                plt.plot(l, label=\"Alpha {}, beta {}\".format(alpha, beta))\n        plt.plot(series.values, label = \"Actual\", alpha = 0.5, linestyle = '-')\n                \n                \n        plt.legend(loc=\"best\")\n        plt.axis('tight')\n        plt.title(\"Double Exponential Smoothing - level\")\n        plt.grid(True)        \n\n        plt.figure(figsize=(20, 8))\n#         plt.plot(series.values, label = \"Actual\", alpha = 0.5, linestyle = '-')\n        for alpha in alphas:\n            for beta in betas:\n                r, l, t = double_exponential_smoothing(series, alpha, beta)\n                plt.plot(t, label=\"Alpha {}, beta {}\".format(alpha, beta))\n        plt.plot(series.values, label = \"Actual\", alpha = 0.5, linestyle = '-')\n                \n                \n        plt.legend(loc=\"best\")\n        plt.axis('tight')\n        plt.title(\"Double Exponential Smoothing - trend\")\n        plt.grid(True)        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = build_ts(item_ids[0])\nplotDoubleExponentialSmoothing(ts, alphas=[0.9], betas=[0.9])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r, l, t = double_exponential_smoothing(ts, 0.5, 0.5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotDoubleExponentialSmoothing(ts, alphas=[0.5, 0.02], betas=[0.9])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# With statsmodels\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = build_ts(item_ids[0])\n\nfrom statsmodels.tsa.api import SimpleExpSmoothing, ExponentialSmoothing,  Holt\n\nmdl = SimpleExpSmoothing(ts, initialization_method=\"estimated\")\nmdl.fit()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18, 8))\nplt.plot(ts)\nplt.plot(mdl.fittedvalues)\n# plt.plot(fcast)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mdl.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fcast = mdl.forecast(12)\nfcast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# mdl = SimpleExpSmoothing.best_params()\n# print('Best Score: ', grid_result.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Holt double exponential smoothing\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = build_ts(item_ids[9])\n\nmdl = Holt(ts, initialization_method=\"estimated\", damped_trend=True).fit(optimized = True)\n\nprint(mdl.params)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18, 8))\nplt.plot(ts)\nplt.plot(mdl.fittedvalues)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fcast = mdl.forecast(12)\nfcast","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Holt Winter"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = build_ts(item_ids[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit1 = ExponentialSmoothing(ts, seasonal_periods=7, trend='add', seasonal='add', use_boxcox=False, initialization_method=\"estimated\").fit()\nfit2 = ExponentialSmoothing(ts, seasonal_periods=7, trend='add', seasonal='mul', use_boxcox=False, initialization_method=\"estimated\").fit()\nfit3 = ExponentialSmoothing(ts, seasonal_periods=7, trend='add', seasonal='add', damped_trend=True, use_boxcox=False, initialization_method=\"estimated\").fit()\nfit4 = ExponentialSmoothing(ts, seasonal_periods=7, trend='add', seasonal='mul', damped_trend=True, use_boxcox=False, initialization_method=\"estimated\").fit()\nresults=pd.DataFrame(index=[r\"$\\alpha$\",r\"$\\beta$\",r\"$\\phi$\",r\"$\\gamma$\",r\"$l_0$\",\"$b_0$\",\"SSE\"])\nparams = ['smoothing_level', 'smoothing_trend', 'damping_trend', 'smoothing_seasonal', 'initial_level', 'initial_trend']\nresults[\"Additive\"]       = [fit1.params[p] for p in params] + [fit1.sse]\nresults[\"Multiplicative\"] = [fit2.params[p] for p in params] + [fit2.sse]\nresults[\"Additive Dam\"]   = [fit3.params[p] for p in params] + [fit3.sse]\nresults[\"Multiplica Dam\"] = [fit4.params[p] for p in params] + [fit4.sse]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit1 = ExponentialSmoothing(ts, seasonal_periods=28, trend='add', seasonal='add', use_boxcox=False, initialization_method=\"estimated\").fit()\nfit2 = ExponentialSmoothing(ts, seasonal_periods=28, trend='add', seasonal='mul', use_boxcox=False, initialization_method=\"estimated\").fit()\nfit3 = ExponentialSmoothing(ts, seasonal_periods=28, trend='add', seasonal='add', damped_trend=True, use_boxcox=False, initialization_method=\"estimated\").fit()\nfit4 = ExponentialSmoothing(ts, seasonal_periods=28, trend='add', seasonal='mul', damped_trend=True, use_boxcox=False, initialization_method=\"estimated\").fit()\nresults=pd.DataFrame(index=[r\"$\\alpha$\",r\"$\\beta$\",r\"$\\phi$\",r\"$\\gamma$\",r\"$l_0$\",\"$b_0$\",\"SSE\"])\nparams = ['smoothing_level', 'smoothing_trend', 'damping_trend', 'smoothing_seasonal', 'initial_level', 'initial_trend']\nresults[\"Additive\"]       = [fit1.params[p] for p in params] + [fit1.sse]\nresults[\"Multiplicative\"] = [fit2.params[p] for p in params] + [fit2.sse]\nresults[\"Additive Dam\"]   = [fit3.params[p] for p in params] + [fit3.sse]\nresults[\"Multiplica Dam\"] = [fit4.params[p] for p in params] + [fit4.sse]\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit1 = ExponentialSmoothing(ts, seasonal_periods=365, trend='add', seasonal='add', use_boxcox=False, initialization_method=\"estimated\").fit()\nfit2 = ExponentialSmoothing(ts, seasonal_periods=365, trend='add', seasonal='mul', use_boxcox=False, initialization_method=\"estimated\").fit()\nfit3 = ExponentialSmoothing(ts, seasonal_periods=365, trend='add', seasonal='add', damped_trend=True, use_boxcox=False, initialization_method=\"estimated\").fit()\nfit4 = ExponentialSmoothing(ts, seasonal_periods=365, trend='add', seasonal='mul', damped_trend=True, use_boxcox=False, initialization_method=\"estimated\").fit()\nresults=pd.DataFrame(index=[r\"$\\alpha$\",r\"$\\beta$\",r\"$\\phi$\",r\"$\\gamma$\",r\"$l_0$\",\"$b_0$\",\"SSE\"])\nparams = ['smoothing_level', 'smoothing_trend', 'damping_trend', 'smoothing_seasonal', 'initial_level', 'initial_trend']\nresults[\"Additive\"]       = [fit1.params[p] for p in params] + [fit1.sse]\nresults[\"Multiplicative\"] = [fit2.params[p] for p in params] + [fit2.sse]\nresults[\"Additive Dam\"]   = [fit3.params[p] for p in params] + [fit3.sse]\nresults[\"Multiplica Dam\"] = [fit4.params[p] for p in params] + [fit4.sse]\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit1 = ExponentialSmoothing(ts, seasonal_periods=365, trend='add', seasonal='add', use_boxcox=False, initialization_method=\"estimated\").fit(smoothing_trend = 0)\nfit2 = ExponentialSmoothing(ts, seasonal_periods=365, trend='add', seasonal='mul', use_boxcox=False, initialization_method=\"estimated\").fit(smoothing_trend = 0)\nfit3 = ExponentialSmoothing(ts, seasonal_periods=365, trend='add', seasonal='add', damped_trend=True, use_boxcox=False, initialization_method=\"estimated\").fit(smoothing_trend = 0)\nfit4 = ExponentialSmoothing(ts, seasonal_periods=365, trend='add', seasonal='mul', damped_trend=True, use_boxcox=False, initialization_method=\"estimated\").fit(smoothing_trend = 0)\nresults=pd.DataFrame(index=[r\"$\\alpha$\",r\"$\\beta$\",r\"$\\phi$\",r\"$\\gamma$\",r\"$l_0$\",\"$b_0$\",\"SSE\"])\nparams = ['smoothing_level', 'smoothing_trend', 'damping_trend', 'smoothing_seasonal', 'initial_level', 'initial_trend']\nresults[\"Additive\"]       = [fit1.params[p] for p in params] + [fit1.sse]\nresults[\"Multiplicative\"] = [fit2.params[p] for p in params] + [fit2.sse]\nresults[\"Additive Dam\"]   = [fit3.params[p] for p in params] + [fit3.sse]\nresults[\"Multiplica Dam\"] = [fit4.params[p] for p in params] + [fit4.sse]\nresults\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18, 8))\nplt.plot(ts)\nplt.plot(fit1.fittedvalues)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(24,9))\n\nplt.plot(ts.values, color='black', alpha = 0.5)\nplt.plot(fit1.fittedvalues.values, marker='x', color='blue')\nfit1.forecast(24).rename('Holt-Winters (add-add-seasonal)').plot(ax=ax, style='--', marker='o', color='red', legend=True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(24,9))\n\nplt.plot(ts.values, color='black', alpha = 0.5)\nplt.plot(fit3.fittedvalues.values, marker='x', color='blue')\nfit3.forecast(24).rename('Holt-Winters').plot(ax=ax, style='--', marker='o', color='red', legend=True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit1.fittedvalues","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}