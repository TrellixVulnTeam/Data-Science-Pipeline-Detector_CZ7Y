{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import feature_extraction, linear_model, model_selection, preprocessing, metrics\nimport string\nfrom nltk.corpus import stopwords\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, classification\nimport time\nimport random","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\ntest = pd.read_csv(\"../input/nlp-getting-started/test.csv\")\ntrain = pd.read_csv(\"../input/nlp-getting-started/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluator(model,train_data,target_data,test_data):\n    model.fit(train_data,target_data)\n    score=model_selection.cross_val_score(model,train_data,target_data,cv=3,scoring='f1')\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#exploring data\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### COUNT VECTORIZER"},{"metadata":{"trusted":true},"cell_type":"code","source":"#count vectorizing string-data\ncount_vectorizer=feature_extraction.text.CountVectorizer()\ntrain_vectors=count_vectorizer.fit_transform(train.text[:])\ntest_vectors=count_vectorizer.transform(test.text[:])\ntarget_vectors=train.target[:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff=train_vectors.mean(axis=0)-test_vectors.mean(axis=0)\nsns.scatterplot(x=np.arange(diff.shape[1]),y=np.array(diff)[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluating val score of count_vectrized Ridge_data\nclf=linear_model.RidgeClassifier()\nclf.fit(train_vectors,target_vectors)\nscore=model_selection.cross_val_score(clf,train_vectors,target_vectors,cv=5,scoring='f1')\na=score\nprint('cross validation score for count_vectorized data:',a.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting for test data\nclf.fit(train_vectors,target_vectors)\ntest_preds=clf.predict(test_vectors)\n\n#making final submission\na=pd.DataFrame({'id':test.id,'target':test_preds})\n#a.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### COUNT VECTORIZER and tf-idf transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf-idf processing the data\ntfidf=feature_extraction.text.TfidfTransformer()\ntrain_tfidf=tfidf.fit_transform(train_vectors)\ntest_tfidf=tfidf.transform(test_vectors)\nclf=linear_model.RidgeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tfidf.todense().shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluation tf_idf data with Ridge classifier (score improvement is observed)\nclf=linear_model.RidgeClassifier()\nclf.fit(train_tfidf,target_vectors)\nscore=model_selection.cross_val_score(clf,train_tfidf,target_vectors,cv=5,scoring='f1')\na=score\nprint('cross validation score for count_vectorized data:',a.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting for test data\nclf.fit(train_tfidf,target_vectors)\ntest_preds=clf.predict(test_tfidf)\n\n#making final submission\na=pd.DataFrame({'id':test.id,'target':test_preds})\n#a.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TEXT CLEANING, COUNT VECTORIZER, TF IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_cleaning(text):\n    a=[char for char in text if char not in string.punctuation]\n    a=''.join(a)\n    a=a.split()\n    #a=[c for c in a if c.lower() not in stopwords.words('english')]\n    return  a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#text cleaning done\ntrain['text'].apply(text_cleaning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer=feature_extraction.text.CountVectorizer(analyzer=text_cleaning).fit(train['text'])\nclf=linear_model.RidgeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vectorizing and tf_idf transforming again and evaluating\ntrain_vectors=count_vectorizer.transform(train.text)\ntest_vectors=count_vectorizer.transform(test.text)\ntarget_vectors=train.target[:]\ntfidf=feature_extraction.text.TfidfTransformer()\ntrain_tfidf=tfidf.fit_transform(train_vectors)\ntest_tfidf=tfidf.transform(test_vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val =train_test_split(train_tfidf, target_vectors, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=linear_model.RidgeClassifier()\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy=[]\nf1_set=[]\nfor i in np.arange(-0.5,1.5,step=0.1):\n    temp=pd.DataFrame(clf.decision_function(X_val))[0].apply(lambda x: 1 if x>i else 0)\n    accuracy.append((temp.values==y_val.values).sum())\n    \n    tn, fp, fn, tp =confusion_matrix(y_val,temp).ravel()\n    precision=tp/(tp+fp)\n    recall=tp/(tp+fn)\n    f1=(2*precision*recall)/(precision+recall)  \n    f1_set.append(f1)\naccuracy=np.array(accuracy)\nf1_set=np.array(f1_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(np.arange(len(f1_set))*0.1-0.5,f1_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_set[f1_set.argmax()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=pd.DataFrame(clf.decision_function(X_val))[0].apply(lambda x: 1 if x>-0 else 0)\nprint((temp.values==y_val.values).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tn, fp, fn, tp =confusion_matrix(y_val,temp).ravel()\nprecision=tp/(tp+fp)\nrecall=tp/(tp+fn)\nf1=(2*precision*recall)/(precision+recall)\nprint(f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting for test data\nclf.fit(train_tfidf,target_vectors)\ntest_preds=pd.DataFrame(clf.decision_function(test_tfidf))[0].apply(lambda x: 1 if x>-0.11 else 0)\n\n#making final submission\na=pd.DataFrame({'id':test.id,'target':test_preds})\na.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_vectors.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LOGISTIC REGRESSION WITH L2 penalty"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=linear_model.LogisticRegression(penalty='l2')\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(pd.DataFrame(clf.predict_proba(X_val))[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(clf.predict_proba(X_val))[1].apply(lambda x: 1 if x>0.42 else 0).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds=pd.DataFrame(clf.predict_proba(test_tfidf))[1].apply(lambda x: 1 if x>0.42 else 0)\n\n#making final submission\na=pd.DataFrame({'id':test.id,'target':test_preds})\na.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ANN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = [X_train.shape[1]]\n\nmodel = keras.Sequential([layers.BatchNormalization(),\n                         layers.Dense(256,activation='relu',input_shape=input_shape),\n                         layers.BatchNormalization(),\n                         layers.Dropout(0.3),\n                         layers.Dense(1,activation='sigmoid')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',\n             loss='binary_crossentropy',\n             metrics=['binary_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\nhistory = model.fit(\n    X_train.toarray(), y_train.values,\n    validation_data=(X_val.toarray(), y_val.values),\n    batch_size=512,\n    epochs=200,\n    callbacks=[early_stopping])\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\nhistory_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df.loc[:, ['loss', 'val_loss']].plot();\nprint(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=model.predict_proba(X_val.toarray())\nsns.distplot(pd.DataFrame(t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_test=pd.DataFrame(model.predict_proba(test_tfidf.toarray()))\nsns.distplot(pd.DataFrame(t_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds=pd.DataFrame(model.predict_proba(test_tfidf.toarray()))[0].apply(lambda x: 1 if x>0.7 else 0)\na=pd.DataFrame({'id':test.id,'target':test_preds})\na.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=tree.DecisionTreeClassifier(max_depth=180)\nclf.fit(X_train,y_train)\nscore=model_selection.cross_val_score(clf,X_train,y_train,cv=5,scoring='f1')\na=score\nprint('cross validation score for count_vectorized data:',a.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=clf.predict_proba(X_val)\npredicted_probs=pd.DataFrame(y_pred)\npredicted_probs[2]=predicted_probs[0].apply(lambda x: 0 if x>0.5 else 1)\ny_prednew=predicted_probs[2].values\ntn, fp, fn, tp =confusion_matrix(y_val,y_prednew).ravel()\nprecision=tp/(tp+fp)\nrecall=tp/(tp+fn)\nf1=(2*precision*recall)/(precision+recall)\nprint(\"f1= \",f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(pd.DataFrame(y_pred)[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting for test data\nclf.fit(train_tfidf,target_vectors)\ntest_preds=clf.predict(test_tfidf)\n\n#making final submission\na=pd.DataFrame({'id':test.id,'target':test_preds})\n#a.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.get_depth()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nerr=[]\nfor i in np.arange(5,411,step=5): \n    clf=tree.DecisionTreeClassifier(max_depth=i)\n    clf.fit(train_tfidf,target_vectors)\n    score=model_selection.cross_val_score(clf,train_tfidf,target_vectors,cv=5,scoring='f1')\n    a=score\n    print('cross validation score for count_vectorized data:',a.mean())\n    err.append(a.mean())\n\nerr=np.array(err)\nplt.scatter(x=range(len(err)),y=err)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x=np.arange(len(err))*5+5,y=err,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_tfidf,target_vectors, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=RandomForestClassifier(max_features=\"sqrt\",n_estimators=400,oob_score=False,random_state=0)\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"err=[]\nfor i in range(400):\n    y_pred=clf.estimators_[i].predict(X_val)\n    tn, fp, fn, tp =confusion_matrix(y_val,y_pred).ravel()\n    precision=tp/(tp+fp)\n    recall=tp/(tp+fn)\n    f1=(2*precision*recall)/(precision+recall)\n    err.append(f1)\n    \nerr=np.array(err)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cum_err=[]\nfor i in range(len(err)):\n    temp=sum(err[0:i]/(i+1))\n    cum_err.append(temp)\n    \ncum_err=np.array(cum_err)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x=np.arange(400)+1,y=cum_err)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"100 trees seem enough"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=RandomForestClassifier(max_features=\"auto\",n_estimators=40,oob_score=False,random_state=0)\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"err=[]\nfor i in range(40):\n    y_pred=clf.estimators_[i].predict(X_val)\n    tn, fp, fn, tp =confusion_matrix(y_val,y_pred).ravel()\n    precision=tp/(tp+fp)\n    recall=tp/(tp+fn)\n    f1=(2*precision*recall)/(precision+recall)\n    err.append(f1)\n    \nerr=np.array(err)\n\ncum_err=[]\nfor i in range(len(err)):\n    temp=sum(err[0:i]/(i+1))\n    cum_err.append(temp)\n    \ncum_err=np.array(cum_err)\n\nplt.scatter(x=np.arange(40)+1,y=cum_err)\nplt.xlabel('number of trees')\nplt.ylabel('f1-score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"depth=[]\nfor i in range(len(clf.estimators_)):\n    depth.append(clf.estimators_[0].get_depth())\n    \ndepth=np.array(depth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"err=[]\nfor i in np.arange(1,180):\n    clf=RandomForestClassifier(max_depth=i,n_estimators=40,oob_score=False,random_state=0)\n    clf.fit(X_train,y_train)\n    y_pred=clf.predict(X_val)\n    tn, fp, fn, tp =confusion_matrix(y_val,y_pred).ravel()\n    precision=tp/(tp+fp)\n    recall=tp/(tp+fn)\n    f1=(2*precision*recall)/(precision+recall)\n    err.append(f1)\n    \nerr=np.array(err)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x=np.arange(len(err))+1,y=err)\nplt.xlabel('max_depth')\nplt.ylabel('f1-score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"max depth of 100 seems fine"},{"metadata":{"trusted":true},"cell_type":"code","source":"err=[]\nfor i in np.arange(1000,26000,step=1000):\n    clf=RandomForestClassifier(max_depth=100,n_estimators=40,max_features=i,random_state=0)\n    clf.fit(X_train,y_train)\n    y_pred=clf.predict(X_val)\n    tn, fp, fn, tp =confusion_matrix(y_val,y_pred).ravel()\n    precision=tp/(tp+fp)\n    recall=tp/(tp+fn)\n    f1=(2*precision*recall)/(precision+recall)\n    err.append(f1)\n    \nerr=np.array(err)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x=np.arange(len(err))+1,y=err)\nplt.xlabel('max_features')\nplt.ylabel('f1-score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"err.argmax()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3000 seems fine"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=time.time()\nclf=RandomForestClassifier(max_features=\"auto\",n_estimators=150,oob_score=False,random_state=0)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_val)\ntn, fp, fn, tp =confusion_matrix(y_val,y_pred).ravel()\nprecision=tp/(tp+fp)\nrecall=tp/(tp+fn)\nf1=(2*precision*recall)/(precision+recall)\nprint(\"f1= \",f1)\nprint(\"time taken\", time.time()-ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.estimators_[3].get_depth()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_set=[]\nfor i in np.arange(0.3,0.9,step=0.01):\n    y_pred=clf.predict_proba(X_val)\n    predicted_probs=pd.DataFrame(y_pred)\n    predicted_probs[2]=predicted_probs[0].apply(lambda x: 0 if x>i else 1)\n    y_prednew=predicted_probs[2].values\n    tn, fp, fn, tp =confusion_matrix(y_val,y_prednew).ravel()\n    precision=tp/(tp+fp)\n    recall=tp/(tp+fn)\n    f1=(2*precision*recall)/(precision+recall)\n    f1_set.append(f1)\n    \nf1_set=np.array(f1_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(np.arange(0.3,0.9,step=0.01),f1_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thres=f1_set.argmax()*0.01+0.3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thres","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RF final model"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=RandomForestClassifier(max_features=\"sqrt\",n_estimators=150,oob_score=False,random_state=0)\nclf.fit(train_tfidf,target_vectors)\ntest_preds=clf.predict_proba(test_tfidf)\npredicted_probs=pd.DataFrame(test_preds)\npredicted_probs[2]=predicted_probs[0].apply(lambda x: 0 if x>0.62 else 1)\ny_prednew=predicted_probs[2].values\n#making final submission\na=pd.DataFrame({'id':test.id,'target':y_prednew})\na.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_probs[2]=predicted_probs[0].apply(lambda x: 0 if x>0.62 else 1)\ny_prednew=predicted_probs[2].values\ny_prednew.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(clf.estimators_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nrandom.seed(0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=time.time()\nclf = GradientBoostingClassifier(n_estimators=600, learning_rate=0.05\n                                 max_depth=3,max_features=\"sqrt\",random_state=0).fit(X_train, y_train)\n\nprint(\"time taken=\",time.time()-ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_sets=[]\nfor i in np.arange(0.3,0.9,step=0.01):\n    y_pred=clf.predict_proba(X_val)\n    predicted_probs=pd.DataFrame(y_pred)\n    predicted_probs[2]=predicted_probs[0].apply(lambda x: 0 if x>i else 1)\n    y_prednew=predicted_probs[2].values\n    tn, fp, fn, tp =confusion_matrix(y_val,y_prednew).ravel()\n    precision=tp/(tp+fp)\n    recall=tp/(tp+fn)\n    f1=(2*precision*recall)/(precision+recall)\n    f1_sets.append(f1)\n\nf1_sets=np.array(f1_sets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thres=f1_sets.argmax()*0.01+0.3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(np.arange(0.3,0.9,step=0.01),f1_sets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thres","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=clf.predict_proba(X_val)\npredicted_probs=pd.DataFrame(y_pred)\npredicted_probs[2]=predicted_probs[0].apply(lambda x: 0 if x>thres else 1)\ny_prednew=predicted_probs[2].values\ntn, fp, fn, tp =confusion_matrix(y_val,y_prednew).ravel()\nprecision=tp/(tp+fp)\nrecall=tp/(tp+fn)\nf1=(2*precision*recall)/(precision+recall)\nprint(\"f1=\",f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=time.time()\nclf = GradientBoostingClassifier(n_estimators=600, learning_rate=1.0,\n                                 max_depth=1, random_state=0).fit(train_tfidf, target_vectors)\n\nprint(\"time taken=\",time.time()-ts)\n\ny_pred=clf.predict_proba(test_tfidf)\npredicted_probs=pd.DataFrame(y_pred)\npredicted_probs[2]=predicted_probs[0].apply(lambda x: 0 if x>thres else 1)\ny_prednew=predicted_probs[2].values\na=pd.DataFrame({'id':test.id,'target':y_prednew})\na.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=time.time()\nf1_sets=[]\nfor  i in np.arange(2000,10000,step=100):\n    clf = GradientBoostingClassifier(n_estimators=i, learning_rate=0.05,\n                                 max_depth=3,max_features=\"sqrt\", random_state=0).fit(X_train, y_train)\n    y_pred=clf.predict_proba(X_val)\n    predicted_probs=pd.DataFrame(y_pred)\n    predicted_probs[2]=predicted_probs[0].apply(lambda x: 0 if x>thres else 1)\n    y_prednew=predicted_probs[2].values\n    tn, fp, fn, tp =confusion_matrix(y_val,y_prednew).ravel()\n    precision=tp/(tp+fp)\n    recall=tp/(tp+fn)\n    f1=(2*precision*recall)/(precision+recall)\n    f1_sets.append(f1)\n    print(\"number of estimators of last run=\",i)\n    print(\"time taken=\",time.time()-ts)\n    \nf1_sets=np.array(f1_sets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(np.arange(2000,5100,step=100),f1_sets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"mean of training targets\",y_train.mean())\nprint(\"mean of validation targets\",y_val.mean())\nprint()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}