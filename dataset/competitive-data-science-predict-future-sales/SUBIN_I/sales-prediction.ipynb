{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## 0.Before Start","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 0.1 Import Packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 0.2 Loading Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')\nshops=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\nitems=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\nitem_cats=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\ntrain=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest=pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ID-테스트 세트 내에서 (Shop, Item) 튜플을 나타내는 Id\\\nshop_id-상점의 고유 식별자\\\nitem_id-상품의 고유 식별자\\\nitem_category_id-항목 카테고리의 고유 식별자\\\nitem_cnt_day-판매 된 제품 수입니다. 이 측정 값의 월별 금액을 예측하고 있습니다.\\\nitem_price-상품의 현재 가격\\\ndate-dd / mm / yyyy 형식의 날짜\\\ndate_block_num-편의를 위해 사용되는 연속 월 번호입니다. 2013 년 1 월은 0, 2013 년 2 월은 1, ..., 2015 년 10 월은 33입니다.\\\nitem_name-항목 이름\\\nshop_name-상점 이름\\\nitem_category_name-항목 카테고리 이름","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_cats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"shape of train:\",train.shape)\nprint(\"shape of test:\",test.shape)\nprint(\"shape of submission:\",submission.shape)\nprint(\"shape of items:\",items.shape)\nprint(\"shape of item_cats:\",item_cats.shape)\nprint(\"shape of shops:\",shops.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Features engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1.1 drop duplicates, remove train which is not in test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop duplicates \nsubset = ['date','date_block_num','shop_id','item_id','item_cnt_day'] \nprint(train.duplicated(subset=subset).value_counts()) \ntrain.drop_duplicates(subset=subset, inplace=True)\nprint(\"shape of train:\",train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop shops&items not in test data \ntest_shops = test.shop_id.unique() \ntest_items = test.item_id.unique() \ntrain = train[train.shop_id.isin(test_shops)] \ntrain = train[train.item_id.isin(test_items)] \nprint(\"shape of train:\",train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Checking outlier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18,9))\nplt.subplots_adjust(hspace=.5)\n\nplt.subplot2grid((3,3), (0,0), colspan = 3)\ntrain['shop_id'].value_counts(normalize=True).plot(kind='bar', alpha=0.7)\nplt.title('Shop ID Values in the Training Set (Normalized)')\n\nplt.subplot2grid((3,3), (1,0))\ntrain['item_id'].plot(kind='hist', alpha=0.7)\nplt.title('Item ID Histogram')\n\nplt.subplot2grid((3,3), (1,1))\ntrain['item_price'].plot(kind='hist', alpha=0.7, color='orange')\nplt.title('Item Price Histogram')\n\nplt.subplot2grid((3,3), (1,2))\ntrain['item_cnt_day'].plot(kind='hist', alpha=0.7, color='green')\nplt.title('Item Count Day Histogram')\n\nplt.subplot2grid((3,3), (2,0), colspan = 3)\ntrain['date_block_num'].value_counts(normalize=True).plot(kind='bar', alpha=0.7)\nplt.title('Month (date_block_num) Values in the Training Set (Normalized)')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,5))\n\nplt.subplot2grid((1,2), (0,0))\ntrain['item_price'].plot(kind='box')\nplt.title('Item price')\n\nplt.subplot2grid((1,2), (0,1))\ntrain['item_cnt_day'].plot(kind='box')\nplt.title('item_cnt_day')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### 1.3 Feature Creation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"month","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['month']=train['date_block_num']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['month']+=1\ntrain['month']%=12\nprint('shape of train',train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['month']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"season","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#season\ntrain['season']=train['month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['season']//=3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['season']=train['season'].replace(0,4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"area","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#area\ntrain=pd.merge(train,shops,how='left',on='shop_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"area = train['shop_name'].apply(lambda x: str.replace(x, '!', '')).apply(lambda x: x.split(' ')[0]) \ntrain['area'] = pd.Categorical(area).codes \ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"discount rate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product\n\nblock_shop_combi = pd.DataFrame(list(product(np.arange(34), test_shops)), columns=['date_block_num','shop_id']) \nshop_item_combi = pd.DataFrame(list(product(test_shops, test_items)), columns=['shop_id','item_id']) \nall_combi = pd.merge(block_shop_combi, shop_item_combi, on=['shop_id'], how='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_base = pd.merge(all_combi, train, on=['date_block_num','shop_id','item_id'], how='left') \ntrain_base['item_cnt_day'].fillna(0, inplace=True) \ntrain_grp = train_base.groupby(['date_block_num','shop_id','item_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_month = pd.DataFrame(train_grp.agg({'item_cnt_day':['sum','count']})).reset_index() \ntrain_month.columns = ['date_block_num','shop_id','item_id','item_cnt','item_order']\ntrain_month.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grp = train_month.groupby(['shop_id', 'item_id']) \ntrain_shop = grp.agg({'item_cnt':['mean','median','std'],'item_order':'mean'}).reset_index() \ntrain_shop.columns = ['shop_id','item_id','cnt_mean_shop','cnt_med_shop','cnt_std_shop','order_mean_shop'] \nprint(train_shop[['cnt_mean_shop','cnt_med_shop','cnt_std_shop']].describe())\ntrain_shop.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price_max = train.groupby(['item_id']).max()['item_price'].reset_index()\nprice_max.rename(columns={'item_price':'item_max_price'}, inplace=True)\nprice_max.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price = train.groupby(['item_id']).mean()['item_price'].reset_index()\nprice.rename(columns={'item_price':'item_mean_price'}, inplace=True)\nprice.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_price_dc = pd.merge(price, price_max, on=['item_id'], how='left') \ntrain_price_dc['discount'] = 1 - (train_price_dc['item_mean_price'] / train_price_dc['item_max_price']) \ntrain_price_dc.drop('item_max_price', axis=1, inplace=True) \ntrain_price_dc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.merge(train,train_price_dc,how='left',on='item_id')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"shop_item_id","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['shop_id']=train['shop_id'].astype(str)\ntrain['item_id']=train['item_id'].astype(str)\ntrain['shop_item']=train['shop_id']+\"-\"+train['item_id']\ntrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"month","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_month['shop_id']=train_month['shop_id'].astype(str)\ntrain_month['item_id']=train_month['item_id'].astype(str)\ntrain_month['shop_item']=train_month['shop_id']+\"-\"+train_month['item_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_month['date_block_num']\ndel train_month['shop_id']\ndel train_month['item_id']\ndel train_month['item_order']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.merge(train,train_month,on='shop_item')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Modeling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.1 SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.iloc[:, 0:12]\nY = train.iloc[:, 12]\nx_train, x_test, y_train, y_test = train_test_split(X, Y, stratify = Y, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(C = 1000, gamma = 0.00001)\nsvc.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"prediction :\", svc.predict(x_test))\nprint(\"train accuracy :\", svc.score(x_train, y_train))\nprint(\"test accuracy :\", svc.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators=10, random_state=0)\nforest.fit(X_train, y_train)\n\nprint(\"prediction :\", forest.predict(X_test))\nprint(\"train accuracy :\", forest.score(X_train, y_train))\nprint(\"test accuracy :\", forest.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Gradient Boosting Regression Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbrt = GradientBoostingClassifier(random_state=0,max_depth=1)\n\ngbrt.fit(X_train,y_train)\n\n\nprint(\"train accuracy :\".format(gbrt.score(X_train,y_train)))\nprint(\"test accuracy :\".format(gbrt.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}