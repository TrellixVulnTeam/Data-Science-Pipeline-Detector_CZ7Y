{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" ","metadata":{"execution":{"iopub.status.busy":"2022-05-22T08:32:40.653856Z","iopub.execute_input":"2022-05-22T08:32:40.654123Z","iopub.status.idle":"2022-05-22T08:32:43.370253Z","shell.execute_reply.started":"2022-05-22T08:32:40.654094Z","shell.execute_reply":"2022-05-22T08:32:43.369408Z"}}},{"cell_type":"markdown","source":"<div style=\"padding:20px;color:white;margin:0;font-size:175%;text-align:center;display:fill;border-radius:5px;background-color:#016CC9;overflow:hidden;font-weight:500\">The power of Pandas</div>","metadata":{}},{"cell_type":"markdown","source":"In this Notebook, we will show how far we can go with Pandas. In this time series prediction competition, we won't use ARIMA or LSTM. Only Pandas and some basic arithmetics. ","metadata":{}},{"cell_type":"markdown","source":"# <b><span style='color:#4B4B4B'>1 |</span><span style='color:#016CC9'>  Looking at the data, understanding the competition.</span></b>","metadata":{}},{"cell_type":"markdown","source":"First, we load train and test DataFrames","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain =pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv') \ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:26.824858Z","iopub.execute_input":"2022-05-25T01:01:26.825573Z","iopub.status.idle":"2022-05-25T01:01:28.558092Z","shell.execute_reply.started":"2022-05-25T01:01:26.825531Z","shell.execute_reply":"2022-05-25T01:01:28.557098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will have a look at train first:","metadata":{}},{"cell_type":"code","source":"print('Number of rows and columns:',train.shape) \nprint('')\nprint ('Columns :')\nprint(train.dtypes)\nprint('')\nprint ('First rows:')\nprint(train.head(5))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:28.559642Z","iopub.execute_input":"2022-05-25T01:01:28.559921Z","iopub.status.idle":"2022-05-25T01:01:28.574266Z","shell.execute_reply.started":"2022-05-25T01:01:28.559888Z","shell.execute_reply":"2022-05-25T01:01:28.57344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are only 6 columns, but a lot of rows, almost 3 million. Each row represents a triplet : date, shop_id, item_id. Each row indicates for a certain day, a certain shop and a certain item, how many items were sold and what was the price.","metadata":{}},{"cell_type":"code","source":"print(train['shop_id'].nunique())\nprint(train['item_id'].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:28.575465Z","iopub.execute_input":"2022-05-25T01:01:28.576177Z","iopub.status.idle":"2022-05-25T01:01:28.621117Z","shell.execute_reply.started":"2022-05-25T01:01:28.576131Z","shell.execute_reply":"2022-05-25T01:01:28.620435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 60 shops and 21807 items in the training set.","metadata":{}},{"cell_type":"code","source":"print(train['date'].nunique())\nprint(train['date_block_num'].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:28.623011Z","iopub.execute_input":"2022-05-25T01:01:28.623425Z","iopub.status.idle":"2022-05-25T01:01:28.865762Z","shell.execute_reply.started":"2022-05-25T01:01:28.623391Z","shell.execute_reply":"2022-05-25T01:01:28.864994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 1034 days in the training set. They are grouped into months indexed by date_block_num. There are 34 months (0 to 33)","metadata":{}},{"cell_type":"markdown","source":"The target of the competition is to predict for a list of pairs (shop, item) the number of items sold during the 35th month (November 2015)","metadata":{}},{"cell_type":"code","source":"print(test.shape) \nprint(test.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:28.867341Z","iopub.execute_input":"2022-05-25T01:01:28.867872Z","iopub.status.idle":"2022-05-25T01:01:28.875472Z","shell.execute_reply.started":"2022-05-25T01:01:28.86781Z","shell.execute_reply":"2022-05-25T01:01:28.874483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The test file indicates all the pairs (shop, item) for which we need to predict the number of items sold during the 35th month. First let's compare the pairs (shop, item) in the test file and in the training file.","metadata":{}},{"cell_type":"code","source":"print(test['shop_id'].nunique())\nprint(test['item_id'].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:28.876921Z","iopub.execute_input":"2022-05-25T01:01:28.877183Z","iopub.status.idle":"2022-05-25T01:01:28.891044Z","shell.execute_reply.started":"2022-05-25T01:01:28.877153Z","shell.execute_reply":"2022-05-25T01:01:28.88993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there are less shops and less items in the test file than in the train file. Let's try to understand why.","metadata":{}},{"cell_type":"markdown","source":"# <b><span style='color:#4B4B4B'>2 |</span><span style='color:#016CC9'>  Evolution of items and shops</span></b>","metadata":{}},{"cell_type":"markdown","source":"As the target of the competiton is a prediction of the monthly sales, we regroup the sales by date_block_num and sum other all the days within a month.","metadata":{}},{"cell_type":"code","source":"train_monthly=train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day':'sum'})\ntrain_monthly.columns=['item_cnt_month']\ntrain_monthly=train_monthly.reset_index()\nprint(train_monthly.shape)\nprint(train_monthly.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:28.892686Z","iopub.execute_input":"2022-05-25T01:01:28.893288Z","iopub.status.idle":"2022-05-25T01:01:29.58057Z","shell.execute_reply.started":"2022-05-25T01:01:28.893246Z","shell.execute_reply":"2022-05-25T01:01:29.579514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We could think that the number of rows would be 30 times less after regrouping in months. But it only dropped from 3 million to 1.6 million. This probably indicates that there are a lot of pairs (shop, item) that appear only once a month.","metadata":{}},{"cell_type":"markdown","source":"We will first analyse the evolution of the number of shops and items during the 34 months in the training file.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nshop_item_history=train_monthly.groupby(['date_block_num']).agg({'shop_id':'nunique','item_id':'nunique'})\nplt.rcParams[\"figure.figsize\"] = (20,5)\nfig, axes = plt.subplots(nrows=1, ncols=2)\nshop_item_history.plot(y='shop_id',label='number of shops',ax=axes[0])\nshop_item_history.plot(y='item_id',label='number of items',ax=axes[1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:29.58211Z","iopub.execute_input":"2022-05-25T01:01:29.582519Z","iopub.status.idle":"2022-05-25T01:01:30.279666Z","shell.execute_reply.started":"2022-05-25T01:01:29.582469Z","shell.execute_reply":"2022-05-25T01:01:30.278833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the number of shops and the number of items have been dropping during the 34 months of the training data. ","metadata":{}},{"cell_type":"markdown","source":"We also notice that there are a total of 21807 items in the training set, but the graph shows that there are never more than 8500 active at any given moment. This indicates a lot of rotations in the items sold, maybe due to new versions coming all the time as the company sells Software.","metadata":{}},{"cell_type":"code","source":"print(shop_item_history.tail())\nprint('There are {} shops and {} items in the test data'.format(test['shop_id'].nunique(),test['item_id'].nunique()) )","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:30.280804Z","iopub.execute_input":"2022-05-25T01:01:30.281024Z","iopub.status.idle":"2022-05-25T01:01:30.29147Z","shell.execute_reply.started":"2022-05-25T01:01:30.280999Z","shell.execute_reply":"2022-05-25T01:01:30.290416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the train data ends with 44 shops and 5413 items, while the test data has 42 shops and 5100 items.\nWe can suspect that the business is not doing well, shops are closing and items are being removed.","metadata":{}},{"cell_type":"markdown","source":"We need to check if new items have been introduced or new shops openend in the test month. This would be a problem because we would have nothing in the train data to help us predict that.","metadata":{}},{"cell_type":"code","source":"shops_train = list(train_monthly['shop_id'].unique())\nshops_test = list(test['shop_id'].unique())\nitems_train = list(train_monthly['item_id'].unique())\nitems_test = list(test['item_id'].unique())\n\nprint('All shops in the test file are in the train file : {}'.format(set(shops_test).issubset(set(shops_train))))\nprint('All items in the test file are in the train file : {}'.format(set(items_test).issubset(set(items_train))))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:30.294376Z","iopub.execute_input":"2022-05-25T01:01:30.29463Z","iopub.status.idle":"2022-05-25T01:01:30.334447Z","shell.execute_reply.started":"2022-05-25T01:01:30.294601Z","shell.execute_reply":"2022-05-25T01:01:30.333518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some items have been newly introduced in the test file. We need to deal with them. Let's see how many new items do we have.","metadata":{}},{"cell_type":"code","source":"new_items = set(items_test).difference(items_train)\nprint ('There are {} new items out of {} in the test file. This is {:.1f}%'.format(len(new_items),len(items_test),len(new_items)/len(items_test)*100.0))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:30.33589Z","iopub.execute_input":"2022-05-25T01:01:30.336141Z","iopub.status.idle":"2022-05-25T01:01:30.345197Z","shell.execute_reply.started":"2022-05-25T01:01:30.33611Z","shell.execute_reply":"2022-05-25T01:01:30.344305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#4B4B4B'>3 |</span><span style='color:#016CC9'>(Item, shop) pairs</span></b>","metadata":{}},{"cell_type":"markdown","source":"Let's now check the pairs (shop_id, item_id). In the test file, there are 42 shops and 5100 items. This makes 42x5100 = 214200 possible pairs. And there are 214200 lines in the test file. So nothing is missing. The target of the competition is to predict the sales of all the items for all the shops in the test file.\nBut an important question is, **how many of these pairs are present in the train file?** We have already determined that 100% of the shops in the test are in the train and that 92.9% of the items in the test are in the train. But what about the pairs ?","metadata":{}},{"cell_type":"code","source":"train_mean = train_monthly.groupby(['shop_id','item_id']).agg({'item_cnt_month':'mean'}).reset_index()\nprint ('There are {} pairs (shop_id,item_id) in the train file'.format(len(train_mean)))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:30.346775Z","iopub.execute_input":"2022-05-25T01:01:30.347281Z","iopub.status.idle":"2022-05-25T01:01:30.582682Z","shell.execute_reply.started":"2022-05-25T01:01:30.347236Z","shell.execute_reply":"2022-05-25T01:01:30.581592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shop_item_train = train_mean[['shop_id','item_id']].apply(tuple, axis=1).tolist()\nshop_item_test = test[['shop_id','item_id']].apply(tuple, axis=1).tolist()\nnew_shop_item = set(shop_item_test).difference(shop_item_train)\n\nprint ('There are {} new pairs (shop,item) out of {} in the test file. This is {:.1f}%'.format(len(new_shop_item),len(shop_item_test),len(new_shop_item)/len(shop_item_test)*100.0))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:30.583814Z","iopub.execute_input":"2022-05-25T01:01:30.584067Z","iopub.status.idle":"2022-05-25T01:01:38.753915Z","shell.execute_reply.started":"2022-05-25T01:01:30.58404Z","shell.execute_reply":"2022-05-25T01:01:38.752951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are bad news. **48% of the pairs we have to predict have never occured in the train file.** When a pair (shop, item) is in the test file but not in the train file, does it mean that the item has never been sold in the shop during the training period? Theoretically, yes. Can we then safely predict to zero a pair we have never seen? The submission files will then have a lot of zeroes (at least 48%). This is probably not the best strategy, but we will try it first and see how it goes. We can refine it later.","metadata":{}},{"cell_type":"markdown","source":"Now enough of these bad news and let's come back to something easier. How did the total number of items sold in all the shops evolved during the training period ?","metadata":{}},{"cell_type":"markdown","source":"# <b><span style='color:#4B4B4B'>4 |</span><span style='color:#016CC9'> Business evolution</span></b>","metadata":{}},{"cell_type":"code","source":"train_total_monthly=train_monthly.groupby(['date_block_num']).agg({'item_cnt_month':'sum'}).reset_index()\ntrain_total_monthly.plot(y='item_cnt_month')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:38.7551Z","iopub.execute_input":"2022-05-25T01:01:38.755425Z","iopub.status.idle":"2022-05-25T01:01:38.987592Z","shell.execute_reply.started":"2022-05-25T01:01:38.755394Z","shell.execute_reply":"2022-05-25T01:01:38.986712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This curve is screaming **non-stationarity**. There is seasonality (12 months cycle) and downtrend. Because the training time series is so short (only 34 time steps), we will try to deal manually with the trend and the seasonality, without using ARIMA or LSTM. ","metadata":{}},{"cell_type":"markdown","source":"# <b><span style='color:#4B4B4B'>5 |</span><span style='color:#016CC9'>  Prediction</span></b>","metadata":{}},{"cell_type":"markdown","source":"We will look for the fitting line to the curve.","metadata":{}},{"cell_type":"code","source":"from scipy.optimize import curve_fit\n\ndef f(x, A, B): #  'straight line' y=f(x)\n    return A*x + B\n\npopt, pcov = curve_fit(f, train_total_monthly['date_block_num'],train_total_monthly['item_cnt_month']) #  data x, y to fit\nprint ('The fitting line equation is: item_cnt_month = {:.0f} x date_block_num + {:.0f}'.format(popt[0], popt[1]))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:38.988792Z","iopub.execute_input":"2022-05-25T01:01:38.98907Z","iopub.status.idle":"2022-05-25T01:01:39.005206Z","shell.execute_reply.started":"2022-05-25T01:01:38.989039Z","shell.execute_reply":"2022-05-25T01:01:39.004327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_total_monthly['date_block_num'], train_total_monthly['item_cnt_month'],label='item_cnt_month')\n\n# Plot another line on the same chart/graph\nplt.plot(train_total_monthly['date_block_num'], f(train_total_monthly['date_block_num'],popt[0],popt[1]),label='fitting line')\nplt.legend(loc=\"upper right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.006547Z","iopub.execute_input":"2022-05-25T01:01:39.00755Z","iopub.status.idle":"2022-05-25T01:01:39.19089Z","shell.execute_reply.started":"2022-05-25T01:01:39.007502Z","shell.execute_reply":"2022-05-25T01:01:39.189846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Based on extrapolation, we expect a total sales count of {:.0f} for the test month'.format(f(34,popt[0],popt[1])))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.192473Z","iopub.execute_input":"2022-05-25T01:01:39.193099Z","iopub.status.idle":"2022-05-25T01:01:39.200123Z","shell.execute_reply.started":"2022-05-25T01:01:39.193037Z","shell.execute_reply":"2022-05-25T01:01:39.199124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, what about the seasonality ? The month to predict is November. Let's look at the ratio November/October that we have in our training data. date_block_num=0 for Jan13. So Oct13 is 9 and Nov13 is 10. Oct14 is 21 and Nov14 is 22. Oct15 is 33 and Nov15 is 34. 34 is the month we have to predict.","metadata":{}},{"cell_type":"code","source":"print ('Nov13 / Oct13 is {:.4f}'.format(train_total_monthly.iloc[10]['item_cnt_month']/train_total_monthly.iloc[9]['item_cnt_month']))\nprint ('Nov14 / Oct14 is {:.4f}'.format(train_total_monthly.iloc[22]['item_cnt_month']/train_total_monthly.iloc[21]['item_cnt_month']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In November, the sales are higher than in October. In average : November/October = 1.0582. This ratio represents the trend and seasonality altogether. We see that the seasonality is stronger than the trend here, as November is higher than October, while the general trend is down. December is even much stronger, but here we just have to focus on November.","metadata":{}},{"cell_type":"code","source":"print('Based on extrapolation and seasonality, we expect a total sales count of {:.0f} for the test month'.format(1.0582*train_total_monthly.iloc[33]['item_cnt_month']))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.21733Z","iopub.execute_input":"2022-05-25T01:01:39.218263Z","iopub.status.idle":"2022-05-25T01:01:39.226697Z","shell.execute_reply.started":"2022-05-25T01:01:39.21821Z","shell.execute_reply":"2022-05-25T01:01:39.225767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So now what should we do with all of this ? we can try a very simple idea. \nWe generated above the Dataframe **train_mean**. This is, for each pair (shop, item) in the train set, the average value of monthly item sold during the training period.","metadata":{}},{"cell_type":"code","source":"print(train_mean.head(5))\nprint ('')\nprint('train_mean number of rows and columns:', train_mean.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.228448Z","iopub.execute_input":"2022-05-25T01:01:39.229089Z","iopub.status.idle":"2022-05-25T01:01:39.243042Z","shell.execute_reply.started":"2022-05-25T01:01:39.229033Z","shell.execute_reply":"2022-05-25T01:01:39.241862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We want to add the column item_cnt_month from train_mean to the test DataFrame, when we find the pairs. so we will merge test and train_mean based on the pair (shop, item) but retain all the rows in test, as this is what we have to submit. ","metadata":{}},{"cell_type":"code","source":"test=pd.merge(test,train_mean,on=['shop_id','item_id'],how='left')\nprint (test.head(10))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.244312Z","iopub.execute_input":"2022-05-25T01:01:39.244916Z","iopub.status.idle":"2022-05-25T01:01:39.340316Z","shell.execute_reply.started":"2022-05-25T01:01:39.244792Z","shell.execute_reply":"2022-05-25T01:01:39.339368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see a lot of NaN. 48% exactly as we have already calculated. Let's check this.","metadata":{}},{"cell_type":"code","source":"print('there are {} NaN. That is {:.1f}% of the rows.'.format(test['item_cnt_month'].isnull().sum(),test['item_cnt_month'].isnull().sum()/len(test)*100.0))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.341474Z","iopub.execute_input":"2022-05-25T01:01:39.341696Z","iopub.status.idle":"2022-05-25T01:01:39.350046Z","shell.execute_reply.started":"2022-05-25T01:01:39.341668Z","shell.execute_reply":"2022-05-25T01:01:39.349004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yahoo ! Always good to check that there is no mistakes. We are going to fill the NaN with zeroes and clip(0,20) as instructed.","metadata":{}},{"cell_type":"code","source":"test.fillna(0,inplace=True)\ntest['item_cnt_month'] = test['item_cnt_month'].clip(0, 20)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.351464Z","iopub.execute_input":"2022-05-25T01:01:39.351743Z","iopub.status.idle":"2022-05-25T01:01:39.36713Z","shell.execute_reply.started":"2022-05-25T01:01:39.351712Z","shell.execute_reply":"2022-05-25T01:01:39.36611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we want to see what is the total number of items sold in the test DataFrame.","metadata":{}},{"cell_type":"code","source":"print('There are {:.0f} item sold in total in the test Dataframe.'.format(test['item_cnt_month'].sum()))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.368984Z","iopub.execute_input":"2022-05-25T01:01:39.369998Z","iopub.status.idle":"2022-05-25T01:01:39.377324Z","shell.execute_reply.started":"2022-05-25T01:01:39.369947Z","shell.execute_reply":"2022-05-25T01:01:39.376553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using this method, we get 202k items sold during Nov15, while the average monthly items sold during the training period is roughly 110k.\nThere is probably a selection process going on. The items which were not selling have been removed and we end up selecting the pairs (shop, item) to get the maximum sales.","metadata":{}},{"cell_type":"markdown","source":"202k is way too high as we are expecting a total of 75k based on trend and seasonality.\nSo let's adjust these values proportionally.","metadata":{}},{"cell_type":"code","source":"test['item_cnt_month']= test['item_cnt_month'] * 75191.0 / 202192.0 ","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.379174Z","iopub.execute_input":"2022-05-25T01:01:39.379804Z","iopub.status.idle":"2022-05-25T01:01:39.389698Z","shell.execute_reply.started":"2022-05-25T01:01:39.379757Z","shell.execute_reply":"2022-05-25T01:01:39.389038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  <b><span style='color:#4B4B4B'>6 |</span><span style='color:#016CC9'> Submission</span></b>","metadata":{}},{"cell_type":"markdown","source":"Let's try to submit these numbers!","metadata":{}},{"cell_type":"code","source":"submission=test[['ID','item_cnt_month']]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.391013Z","iopub.execute_input":"2022-05-25T01:01:39.391493Z","iopub.status.idle":"2022-05-25T01:01:39.401677Z","shell.execute_reply.started":"2022-05-25T01:01:39.391457Z","shell.execute_reply":"2022-05-25T01:01:39.400997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:01:39.402776Z","iopub.execute_input":"2022-05-25T01:01:39.403228Z","iopub.status.idle":"2022-05-25T01:01:40.01564Z","shell.execute_reply.started":"2022-05-25T01:01:39.403191Z","shell.execute_reply":"2022-05-25T01:01:40.014644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RMSE = 1.1413. Not bad, with only a few pandas manipulations and arithmetics!","metadata":{}},{"cell_type":"markdown","source":"to further improve the score we would need to look at all the new pairs (item, shop) that appeared in the test file and were not in the train file. We predicted zero for them but we need somehow to connect them to the train file using the categories.\nIf you liked this Notebook, please upvote.","metadata":{}}]}