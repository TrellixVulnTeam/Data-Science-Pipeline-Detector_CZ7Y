{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport scipy\nfrom scipy import stats\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nprint(\"Setup Complete\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-27T00:41:18.377142Z","iopub.execute_input":"2021-07-27T00:41:18.377549Z","iopub.status.idle":"2021-07-27T00:41:18.393851Z","shell.execute_reply.started":"2021-07-27T00:41:18.377514Z","shell.execute_reply":"2021-07-27T00:41:18.39302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Upload all dataset paths","metadata":{}},{"cell_type":"code","source":"dataset_paths = {\n    'categories': '../input/competitive-data-science-predict-future-sales/item_categories.csv',\n    'items': '../input/competitive-data-science-predict-future-sales/items.csv',\n    'sales': '../input/competitive-data-science-predict-future-sales/sales_train.csv',\n    'shops': '../input/competitive-data-science-predict-future-sales/shops.csv',\n    'test': '../input/competitive-data-science-predict-future-sales/test.csv'\n}\nprint('Paths are ready')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:18.486563Z","iopub.execute_input":"2021-07-27T00:41:18.487095Z","iopub.status.idle":"2021-07-27T00:41:18.492588Z","shell.execute_reply.started":"2021-07-27T00:41:18.487064Z","shell.execute_reply":"2021-07-27T00:41:18.491766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load dataset","metadata":{}},{"cell_type":"code","source":"dataset = { name: pd.read_csv(path) for name, path in dataset_paths.items()}\ndataset.keys()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:18.494011Z","iopub.execute_input":"2021-07-27T00:41:18.494573Z","iopub.status.idle":"2021-07-27T00:41:20.484542Z","shell.execute_reply.started":"2021-07-27T00:41:18.49453Z","shell.execute_reply":"2021-07-27T00:41:20.483207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Look at the dataset tables","metadata":{}},{"cell_type":"code","source":"def take_a_view(dataset: pd.DataFrame):\n    print(dataset.info())\n\n    print(f\"\"\"\n        Searching for duplicates:\n        Found: {sum(dataset.value_counts() > 1)}\n    \"\"\")\n\n    return dataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:20.4868Z","iopub.execute_input":"2021-07-27T00:41:20.487133Z","iopub.status.idle":"2021-07-27T00:41:20.494227Z","shell.execute_reply.started":"2021-07-27T00:41:20.487105Z","shell.execute_reply":"2021-07-27T00:41:20.492893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1) Categories","metadata":{}},{"cell_type":"code","source":"print(f\"\"\"\n        Searching for id duplicates:\n        Found: {sum(dataset['categories'].loc[:,'item_category_id'].value_counts() > 1)}\n    \"\"\")\nprint(f\"\"\"\n        Searching for category name duplicates:\n        Found: {sum(dataset['categories'].loc[:,'item_category_name'].value_counts() > 1)}\n    \"\"\")\ntake_a_view(dataset['categories'])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:20.496503Z","iopub.execute_input":"2021-07-27T00:41:20.497109Z","iopub.status.idle":"2021-07-27T00:41:20.531215Z","shell.execute_reply.started":"2021-07-27T00:41:20.497059Z","shell.execute_reply":"2021-07-27T00:41:20.529799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2) Items","metadata":{}},{"cell_type":"code","source":"print(f\"\"\"\n        Searching for id duplicates:\n        Found: {sum(dataset['items'].loc[:,'item_id'].value_counts() > 1)}\n    \"\"\")\nprint(f\"\"\"\n        Searching for category name duplicates:\n        Found: {sum(dataset['items'].loc[:,'item_name'].value_counts() > 1)}\n    \"\"\")\ntake_a_view(dataset['items'])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:20.534864Z","iopub.execute_input":"2021-07-27T00:41:20.535175Z","iopub.status.idle":"2021-07-27T00:41:20.632387Z","shell.execute_reply.started":"2021-07-27T00:41:20.535146Z","shell.execute_reply":"2021-07-27T00:41:20.630997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3) Sales","metadata":{}},{"cell_type":"code","source":"take_a_view(dataset['sales'])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:20.63374Z","iopub.execute_input":"2021-07-27T00:41:20.634125Z","iopub.status.idle":"2021-07-27T00:41:23.352632Z","shell.execute_reply.started":"2021-07-27T00:41:20.634092Z","shell.execute_reply":"2021-07-27T00:41:23.35141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = dataset['sales'].drop('item_cnt_day', axis=1)\n\ntake_a_view(ds)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:23.353735Z","iopub.execute_input":"2021-07-27T00:41:23.35405Z","iopub.status.idle":"2021-07-27T00:41:26.192721Z","shell.execute_reply.started":"2021-07-27T00:41:23.354019Z","shell.execute_reply":"2021-07-27T00:41:26.191303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Duplicates possibly were created in case of multiple item sales in one shop (maybe data was uploaded more than once a day by portions)","metadata":{}},{"cell_type":"code","source":"duplications = dataset['sales'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:26.194345Z","iopub.execute_input":"2021-07-27T00:41:26.194666Z","iopub.status.idle":"2021-07-27T00:41:28.75737Z","shell.execute_reply.started":"2021-07-27T00:41:26.194635Z","shell.execute_reply":"2021-07-27T00:41:28.755989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplications[duplications > 1]","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:28.760004Z","iopub.execute_input":"2021-07-27T00:41:28.760334Z","iopub.status.idle":"2021-07-27T00:41:28.779852Z","shell.execute_reply.started":"2021-07-27T00:41:28.760305Z","shell.execute_reply":"2021-07-27T00:41:28.778529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Despite the unknown nature of this duplications, I can easily leave them unchaged or regroup in future, because their influence is too small (both in appearance quantity and in item cnt impact) to cause big mistakes.","metadata":{}},{"cell_type":"markdown","source":"4) Shops","metadata":{}},{"cell_type":"code","source":"print(f\"\"\"\n        Searching for id duplicates:\n        Found: {sum(dataset['shops'].loc[:,'shop_id'].value_counts() > 1)}\n    \"\"\")\nprint(f\"\"\"\n        Searching for category name duplicates:\n        Found: {sum(dataset['shops'].loc[:,'shop_name'].value_counts() > 1)}\n    \"\"\")\ntake_a_view(dataset['shops'])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:28.782148Z","iopub.execute_input":"2021-07-27T00:41:28.782515Z","iopub.status.idle":"2021-07-27T00:41:28.814315Z","shell.execute_reply.started":"2021-07-27T00:41:28.782484Z","shell.execute_reply":"2021-07-27T00:41:28.812927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5) Tests","metadata":{}},{"cell_type":"code","source":"take_a_view(dataset['test'])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:28.817973Z","iopub.execute_input":"2021-07-27T00:41:28.818356Z","iopub.status.idle":"2021-07-27T00:41:28.991338Z","shell.execute_reply.started":"2021-07-27T00:41:28.818319Z","shell.execute_reply":"2021-07-27T00:41:28.989863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyze lexical units","metadata":{}},{"cell_type":"markdown","source":"So we have the following string based columns, that can give us some neccesairy information:\n* item_name\n* category_name\n* shop_name\n    ","metadata":{}},{"cell_type":"markdown","source":"First of all I need to find the way to explore this data. Let's start with simple splitting of sentences","metadata":{}},{"cell_type":"code","source":"import re\n\nWORD_PATTERN = r'(?:\\w+)'\n\ndef tokenize(sentence: str) -> list:\n    return list(map(str.lower, re.findall(WORD_PATTERN, sentence)))\n\nassert tokenize(\"Мама мыла раму\") == ['мама', 'мыла', 'раму']","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:28.993392Z","iopub.execute_input":"2021-07-27T00:41:28.993922Z","iopub.status.idle":"2021-07-27T00:41:29.000944Z","shell.execute_reply.started":"2021-07-27T00:41:28.993869Z","shell.execute_reply":"2021-07-27T00:41:28.999606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WordsAnalyzer:\n    def __init__(self, frame: pd.DataFrame, index, value):\n        self._frame = frame\n        self._index = index\n        self._value = value\n        self._categories = list(zip(frame.loc[:, index], frame.loc[:, value]))\n        self.vectors = None\n        self._dataset = None\n    \n    def process(self):\n        if self.vectors == None:\n            self.vectors = {}\n            for category_name, category_id in self._categories:\n                tokens = tokenize(category_name)\n                for token in tokens:\n                    if self.vectors.get(token, None) == None:\n                        self.vectors[token] = [category_id]\n                    else:\n                        self.vectors[token].append(category_id)\n            self._proceed = True\n        return self.vectors\n    \n    def labels(self):\n        return self._frame.index.to_list()\n    \n    def from_idxs(self, idx_list):\n        return self._frame.set_index(self._index).loc[idx_list, self._value].to_list()\n    \n    def from_vals(self, val_list):\n        return self._frame.set_index(self._value).loc[val_list, self._index].to_list()\n    \n    def to_series(self) -> pd.Series:\n        if self._proceed:\n            return pd.Series([tuple(ids) for ids in self.vectors.values()], self.vectors.keys())\n        raise RuntimeError('Analyzer need to process data first')\n        \n    def describe(self):\n        if self._proceed:\n            series = pd.Series([tuple(ids) for ids in self.vectors.values()], self.vectors.keys())\n            print(f\"Token statistic (token appearance quantity -> amount of the following tokens):\\n{series.map(len).value_counts()}\")\n            return None\n        raise RuntimeError('Analyzer need to process data first')\n        \n    def from_tokens(self, token_list: list) -> list:\n        result = set([el[1] for el in self._categories])\n        for token in token_list:\n            result &= set(self.vectors[token])\n        return result\n        \n    def _name_to_vec(self, string):\n        string_tokens = tokenize(string)\n        return np.array([np.int8(token in string_tokens) for token in self.vectors.keys()])\n    \n    def _to_dataset(self):\n        if self._dataset is None:\n            self._dataset =  np.array([\n                self._name_to_vec(category) for category, _ in self._categories\n            ])\n        return self._dataset\n        \n    def process_hierarchical_cluster(self):\n        from scipy.cluster.hierarchy import linkage\n        \n        linked = linkage(self._to_dataset(), metric='cosine', method='complete')\n        \n        return linked\n    \n    def show_clusters(self):\n        from scipy.cluster.hierarchy import dendrogram\n        label_list = [el for el, _ in self._categories]\n        linked = self.process_hierarchical_cluster()\n\n        plt.figure(figsize=(30, 24))\n        dendrogram(linked,\n                    orientation='right',\n                    labels=label_list,\n                    distance_sort='descending',\n                    show_leaf_counts=True)\n        plt.show()\n        return ","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:29.002546Z","iopub.execute_input":"2021-07-27T00:41:29.002875Z","iopub.status.idle":"2021-07-27T00:41:29.025897Z","shell.execute_reply.started":"2021-07-27T00:41:29.002841Z","shell.execute_reply":"2021-07-27T00:41:29.024529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So I decided to use clustering methods to look at the groups of shops based on their tags. Now, I have 2 potential algorithms k-means and hieararchical, but I decided to use the second one in order to be able to easy visualize it's results. \n\nSo I used 'cosine' distance between my categories because I find it more suitable for text analyzing (cosine similarity give smaller error for different text length.\n\nThen I had to choose linkage type between clusters. I've chosen 'complete', because it uses maximal dissimilarity between cluster representatives, so my clusters can be more granular and link slowly, but already created clusters will have stronger relationships. Alternative type was 'average' because it minimize average dissimilarity between representatives.","metadata":{}},{"cell_type":"markdown","source":"### Shop clusterisation","metadata":{}},{"cell_type":"code","source":"shop_tokens = WordsAnalyzer(dataset['shops'], 'shop_name', 'shop_id')\nshop_tokens.process()\n\nshop_tokens.show_clusters()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:29.027392Z","iopub.execute_input":"2021-07-27T00:41:29.027693Z","iopub.status.idle":"2021-07-27T00:41:30.431715Z","shell.execute_reply.started":"2021-07-27T00:41:29.027665Z","shell.execute_reply":"2021-07-27T00:41:30.430555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Category clusterisation","metadata":{}},{"cell_type":"code","source":"category_tokens = WordsAnalyzer(dataset['categories'], 'item_category_name', 'item_category_id')\ncategory_tokens.process()\n\ncategory_tokens.show_clusters()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-27T00:41:30.433147Z","iopub.execute_input":"2021-07-27T00:41:30.433446Z","iopub.status.idle":"2021-07-27T00:41:32.251332Z","shell.execute_reply.started":"2021-07-27T00:41:30.433418Z","shell.execute_reply":"2021-07-27T00:41:32.250053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## In Sales items need to be joined with their category","metadata":{}},{"cell_type":"code","source":"dataset['sales'] = dataset['sales'].merge(dataset['items'][['item_id', 'item_category_id']], on='item_id')\n\ntake_a_view(dataset['sales'])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:32.253371Z","iopub.execute_input":"2021-07-27T00:41:32.253799Z","iopub.status.idle":"2021-07-27T00:41:37.43759Z","shell.execute_reply.started":"2021-07-27T00:41:32.253755Z","shell.execute_reply":"2021-07-27T00:41:37.436391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['sales'].date = dataset['sales'].date.astype('datetime64[ns]')\n\nraw_dataset = dataset['sales']\n\ndate_indexed = dataset['sales'].set_index('date', drop=True)\n\nfrom datetime import date\n\ndate_indexed = date_indexed.loc[date_indexed.index < np.datetime64(date(2015, 11, 1))]\ndate_indexed.tail()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:37.439207Z","iopub.execute_input":"2021-07-27T00:41:37.439524Z","iopub.status.idle":"2021-07-27T00:41:38.272375Z","shell.execute_reply.started":"2021-07-27T00:41:37.439495Z","shell.execute_reply":"2021-07-27T00:41:38.27112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"statistics = {\n    'word_based': {\n        'categories': category_tokens,\n        'shops': shop_tokens\n    },\n    'sales_cnt_based': {\n        'shops': date_indexed.groupby([date_indexed.index.to_period(\"W\"), 'shop_id']).item_cnt_day.sum().unstack(-1).fillna(0),\n        'categories': date_indexed.groupby([date_indexed.index.to_period(\"W\"), 'item_category_id']).item_cnt_day.sum().unstack(-1).fillna(0),\n        'items': date_indexed.groupby([date_indexed.index.to_period(\"W\"), 'item_id']).item_cnt_day.sum().unstack(-1).fillna(0)\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:38.273632Z","iopub.execute_input":"2021-07-27T00:41:38.274051Z","iopub.status.idle":"2021-07-27T00:41:40.198473Z","shell.execute_reply.started":"2021-07-27T00:41:38.274006Z","shell.execute_reply":"2021-07-27T00:41:40.197158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.pairplot(dataset['sales'])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:40.200072Z","iopub.execute_input":"2021-07-27T00:41:40.200541Z","iopub.status.idle":"2021-07-27T00:41:40.205854Z","shell.execute_reply.started":"2021-07-27T00:41:40.200496Z","shell.execute_reply":"2021-07-27T00:41:40.204391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weekly_statistic = pd.DataFrame(date_indexed.groupby(date_indexed.index.to_period(\"D\")).item_cnt_day.sum())\nweekly_statistic['month'] = weekly_statistic.index.month\nweekly_statistic['day'] = weekly_statistic.index.day\nweekly_statistic['year'] = weekly_statistic.index.year\nweekly_statistic['week'] = weekly_statistic.index.week\n\nfrom calendar import month_name \n\nmonth_names = month_name[1:]\n\nfigure, axis = plt.subplots(4, 3 ,figsize=(28, 19))\n\n\n\nmonths = {}\nfor idx, name in enumerate(month_names):\n    months[name] = weekly_statistic.loc[weekly_statistic.month == (idx + 1), ['item_cnt_day', 'day', 'year']]\n    sns.lineplot(ax=axis[idx % 4][idx // 4], data=months[name], y='item_cnt_day', x='day', hue='year')\n    axis[idx % 4][idx // 4].set_title(f'Weekly sales in - {name}')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:40.208161Z","iopub.execute_input":"2021-07-27T00:41:40.208652Z","iopub.status.idle":"2021-07-27T00:41:43.454067Z","shell.execute_reply.started":"2021-07-27T00:41:40.208606Z","shell.execute_reply":"2021-07-27T00:41:43.453036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weekly_statistic","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:43.455504Z","iopub.execute_input":"2021-07-27T00:41:43.455788Z","iopub.status.idle":"2021-07-27T00:41:43.472899Z","shell.execute_reply.started":"2021-07-27T00:41:43.455761Z","shell.execute_reply":"2021-07-27T00:41:43.471746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure, axis = plt.subplots(1, 2,figsize=(20, 12))\n\ndef normal_95_ceil(series):\n    return np.mean(series) + 1.96 * np.std(series)\n\ndef normal_95_floor(series):\n    return np.mean(series) - 1.96 * np.std(series)\n\ndata=weekly_statistic.groupby(['year', 'week']).item_cnt_day.sum().groupby(['week']).agg([np.mean, normal_95_ceil, normal_95_floor])\nsns.lineplot(data=data, ax=axis[0])\nsns.histplot((weekly_statistic.groupby(['year', 'week']).item_cnt_day.sum() - data['mean']) / data['mean'], kde=True, ax=axis[1])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:43.474223Z","iopub.execute_input":"2021-07-27T00:41:43.474525Z","iopub.status.idle":"2021-07-27T00:41:44.010186Z","shell.execute_reply.started":"2021-07-27T00:41:43.474497Z","shell.execute_reply":"2021-07-27T00:41:44.00874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On the left side we can see our weekly sales with their prediction 95% intervals (1,96 std if we assume residuals to be normally distributed). \nOn the right side u can see multiplicative errors (in order to ignore level scale), it is negtively skewed and a bit biased, so we can't assume normal distribution of residuals and it seems that we might have some tendecy","metadata":{}},{"cell_type":"code","source":"figure, axis = plt.subplots(1, 2,figsize=(20, 12))\n\ndata=weekly_statistic[weekly_statistic.year < 2015].groupby(['year', 'week']).item_cnt_day.sum().groupby(['week']).agg([np.mean, normal_95_ceil, normal_95_floor])\nsns.lineplot(data=data, ax=axis[0])\nsns.histplot((weekly_statistic[weekly_statistic.year < 2015].groupby(['year', 'week']).item_cnt_day.sum() - data['mean']) / data['mean'], kde=True, ax=axis[1], stat='probability')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:44.012018Z","iopub.execute_input":"2021-07-27T00:41:44.012485Z","iopub.status.idle":"2021-07-27T00:41:44.525434Z","shell.execute_reply.started":"2021-07-27T00:41:44.012439Z","shell.execute_reply":"2021-07-27T00:41:44.523882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weekly_total_cnt = date_indexed.groupby(date_indexed.index.to_period(freq=\"W\")).item_cnt_day.sum()\n\nplt.figure(figsize=(20, 12))\nplt.title('Sales tendency')\n\nweekly_total_cnt.plot(xlabel='Date', ylabel='Weekly items sold')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:44.527562Z","iopub.execute_input":"2021-07-27T00:41:44.528037Z","iopub.status.idle":"2021-07-27T00:41:45.299544Z","shell.execute_reply.started":"2021-07-27T00:41:44.52799Z","shell.execute_reply":"2021-07-27T00:41:45.298185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_income = date_indexed\ndataset_income['income'] = date_indexed['item_cnt_day'] * date_indexed['item_price'] \n\nweekly_statistic_income = pd.DataFrame(dataset_income.groupby(date_indexed.index.to_period(\"D\")).income.sum())\nweekly_statistic_income['month'] = weekly_statistic_income.index.month\nweekly_statistic_income['day'] = weekly_statistic_income.index.day\nweekly_statistic_income['year'] = weekly_statistic_income.index.year\nweekly_statistic_income['week'] = weekly_statistic_income.index.week\n\nfrom calendar import month_name \n\nmonth_names = month_name[1:]\n\nfigure, axis = plt.subplots(4, 3 ,figsize=(28, 19))\n\n\n\nmonths = {}\nfor idx, name in enumerate(month_names):\n    months[name] = weekly_statistic_income.loc[weekly_statistic_income.month == (idx + 1), ['income', 'day', 'year']]\n    sns.lineplot(ax=axis[idx % 4][idx // 4], data=months[name], y='income', x='day', hue='year')\n    axis[idx % 4][idx // 4].set_title(f'Weekly sales in - {name}')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:45.300726Z","iopub.execute_input":"2021-07-27T00:41:45.30103Z","iopub.status.idle":"2021-07-27T00:41:48.72472Z","shell.execute_reply.started":"2021-07-27T00:41:45.301002Z","shell.execute_reply":"2021-07-27T00:41:48.723683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure, axis = plt.subplots(1, 2,figsize=(20, 12))\n\ndata=weekly_statistic_income.groupby(['year', 'week']).income.sum().groupby(['week']).agg([np.mean, normal_95_ceil, normal_95_floor])\nsns.lineplot(data=data, ax=axis[0])\nsns.histplot((weekly_statistic_income.groupby(['year', 'week']).income.sum() - data['mean']) / data['mean'], kde=True, ax=axis[1])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:48.725971Z","iopub.execute_input":"2021-07-27T00:41:48.726287Z","iopub.status.idle":"2021-07-27T00:41:50.015917Z","shell.execute_reply.started":"2021-07-27T00:41:48.726232Z","shell.execute_reply":"2021-07-27T00:41:50.01499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure, axis = plt.subplots(1, 2,figsize=(20, 12))\n\ndata=weekly_statistic_income[weekly_statistic_income.year < 2015].groupby(['year', 'week']).income.sum().groupby(['week']).agg([np.mean, normal_95_ceil, normal_95_floor])\nsns.lineplot(data=data, ax=axis[0])\nsns.histplot((weekly_statistic_income[weekly_statistic_income.year < 2015].groupby(['year', 'week']).income.sum() - data['mean']) / data['mean'], kde=True, ax=axis[1], stat='probability')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:50.020208Z","iopub.execute_input":"2021-07-27T00:41:50.020762Z","iopub.status.idle":"2021-07-27T00:41:50.561311Z","shell.execute_reply.started":"2021-07-27T00:41:50.020728Z","shell.execute_reply":"2021-07-27T00:41:50.560546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This estimation is less skewed but biased as the previous one","metadata":{}},{"cell_type":"code","source":"weekly_total_sales = dataset_income.groupby(dataset_income.index.to_period(freq='W')).income.sum()\n\nplt.figure(figsize=(20, 12))\nplt.title('Sales tendency')\n\nweekly_total_sales.plot(xlabel='Date', ylabel='Weekly income')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:50.563092Z","iopub.execute_input":"2021-07-27T00:41:50.563541Z","iopub.status.idle":"2021-07-27T00:41:51.314136Z","shell.execute_reply.started":"2021-07-27T00:41:50.56351Z","shell.execute_reply":"2021-07-27T00:41:51.312853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CrossCategoryAnalyzer:\n    def __init__(self, frame, srcs, columns):\n        self._frame = frame\n        self._categories = columns\n        self._srcs = srcs\n        \n    def relation_matrix(self):\n        cat1_values = self._frame.loc[:,self._categories[0]].values\n        cat2_values = self._frame.loc[:,self._categories[1]].values\n        raw_data = getattr(self._frame.groupby(self._categories[1]), self._categories[0], None).value_counts().map(lambda x: 1 if x != 0 else 0).unstack(-1).fillna(0).transpose().to_numpy()\n        return raw_data\n    \n    def process_hierarchical_cluster(self, is_forward=True):\n        from scipy.cluster.hierarchy import linkage\n        \n        linked = linkage(self.relation_matrix() if is_forward else self.relation_matrix().transpose(), metric='cosine', method='complete')\n        \n        return linked\n    \n    def show_clusters(self, is_forward=True):\n        from scipy.cluster.hierarchy import dendrogram\n        \n        label_list = [el for el, _ in self._srcs[not is_forward]._categories]\n        linked = self.process_hierarchical_cluster(is_forward)\n\n        plt.figure(figsize=(30, 24))\n        dendrogram(linked,\n                    orientation='top',\n                    labels=label_list,\n                    distance_sort='descending',\n                    show_leaf_counts=True)\n        plt.show()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-27T00:41:51.315599Z","iopub.execute_input":"2021-07-27T00:41:51.316015Z","iopub.status.idle":"2021-07-27T00:41:51.32793Z","shell.execute_reply.started":"2021-07-27T00:41:51.315969Z","shell.execute_reply":"2021-07-27T00:41:51.326416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Right now we gonna explore relationship between our shops and categories","metadata":{}},{"cell_type":"code","source":"shops_to_categories_rel = CrossCategoryAnalyzer(dataset['sales'], [statistics['word_based']['shops'], statistics['word_based']['categories']], ['shop_id', 'item_category_id'])\nshops_to_categories_rel.show_clusters()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:51.329554Z","iopub.execute_input":"2021-07-27T00:41:51.329978Z","iopub.status.idle":"2021-07-27T00:41:55.277781Z","shell.execute_reply.started":"2021-07-27T00:41:51.329935Z","shell.execute_reply":"2021-07-27T00:41:55.276469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shops_to_categories_rel._frame","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:55.279513Z","iopub.execute_input":"2021-07-27T00:41:55.279834Z","iopub.status.idle":"2021-07-27T00:41:55.304159Z","shell.execute_reply.started":"2021-07-27T00:41:55.279803Z","shell.execute_reply":"2021-07-27T00:41:55.303286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we can see here two little clusters with a very big cosine disimilarity:\n\n1) ['Курск ТЦ \"Пушкинский\"', 'Воронеж ТРЦ \"Максимир\"', 'Москва ТЦ \"МЕГА Белая Дача II\"', 'Москва ТЦ \"МЕГА Теплый Стан\" II', 'Уфа ТЦ \"Семья\" 2', 'Ярославль ТЦ \"Альтаир\"'] + ['Москва ТЦ \"Ареал\" (Беляево)', 'Москва ТЦ \"Семеновский\"', 'Москва МТРЦ \"Афи Молл\"']\n\n2) ['Чехов ТРЦ \"Карнавал\"', 'Коломна ТЦ \"Рио\"'] + ['Москва ТРК \"Атриум\"', 'Омск ТЦ \"Мега\"']","metadata":{}},{"cell_type":"code","source":"shops_to_items_rel = CrossCategoryAnalyzer(dataset['sales'], [statistics['word_based']['shops'], None], ['shop_id', 'item_id'])\nshops_to_items_rel.show_clusters()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:55.305592Z","iopub.execute_input":"2021-07-27T00:41:55.305907Z","iopub.status.idle":"2021-07-27T00:41:59.754909Z","shell.execute_reply.started":"2021-07-27T00:41:55.305878Z","shell.execute_reply":"2021-07-27T00:41:59.753656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## All in all it's just my thoughts so now we'll try to check if sales in this clusters have something in common ","metadata":{}},{"cell_type":"code","source":"class SalesAnalyzer:\n    def __init__(self, frame, src=None):\n        self._frame = frame\n        self._src = src\n        \n    def to_df(self):\n        return self._frame\n    \n    def heatmap(self, absolute=False):\n        plt.figure(figsize=(25,14))\n        \n        matrix = self._frame        \n        label_list = [el for el, _ in self._src._categories] if self._src is not None else matrix.columns        \n        matrix.columns = label_list \n        \n        cat_corr = matrix.corr() if not absolute else matrix.corr().abs() \n\n        sns.heatmap(cat_corr)\n        \n    def multiplot(self, index_list=None, by_label=False, title='Some tendecy'):\n        matrix = self._frame\n        label_list = [el for el, _ in self._src._categories] if self._src is not None and by_label else matrix.columns        \n        matrix.columns = label_list\n        data=matrix[index_list] if index_list is not None else matrix\n        \n        data.plot(figsize=(20, 12), title=title)\n        \n    def process_hierarchical_cluster(self):\n        from scipy.cluster.hierarchy import linkage\n        \n        linked = linkage(self._frame.transpose(), metric='correlation', method='average')\n        \n        return linked\n    \n    def show_clusters(self):\n        from scipy.cluster.hierarchy import dendrogram\n        \n        label_list = [el for el, _ in self._src._categories] if self._src is not None else self._frame.columns    \n        linked = self.process_hierarchical_cluster()\n\n        plt.figure(figsize=(30, 24))\n        dendrogram(linked,\n                    orientation='right',\n                    labels=label_list,\n                    distance_sort='ascending',\n                    show_leaf_counts=True)\n        plt.show()\n        return ","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:59.756784Z","iopub.execute_input":"2021-07-27T00:41:59.757211Z","iopub.status.idle":"2021-07-27T00:41:59.771749Z","shell.execute_reply.started":"2021-07-27T00:41:59.757166Z","shell.execute_reply":"2021-07-27T00:41:59.77034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shop_analyzer = SalesAnalyzer(statistics['sales_cnt_based']['shops'], statistics['word_based']['shops'])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:59.773582Z","iopub.execute_input":"2021-07-27T00:41:59.774021Z","iopub.status.idle":"2021-07-27T00:41:59.78914Z","shell.execute_reply.started":"2021-07-27T00:41:59.773977Z","shell.execute_reply":"2021-07-27T00:41:59.788277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shop_analyzer.heatmap(True)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:41:59.790339Z","iopub.execute_input":"2021-07-27T00:41:59.790757Z","iopub.status.idle":"2021-07-27T00:42:03.954671Z","shell.execute_reply.started":"2021-07-27T00:41:59.790715Z","shell.execute_reply":"2021-07-27T00:42:03.953612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's cover some shops with similar categories","metadata":{}},{"cell_type":"code","source":"shop_analyzer.multiplot(index_list=['Курск ТЦ \"Пушкинский\"', 'Воронеж ТРЦ \"Максимир\"', 'Москва ТЦ \"МЕГА Белая Дача II\"', 'Москва ТЦ \"МЕГА Теплый Стан\" II', 'Уфа ТЦ \"Семья\" 2', 'Ярославль ТЦ \"Альтаир\"', 'Москва ТЦ \"Ареал\" (Беляево)', 'Москва ТЦ \"Семеновский\"', 'Москва МТРЦ \"Афи Молл\"'], by_label=True, title='Shops with common categories')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:03.95612Z","iopub.execute_input":"2021-07-27T00:42:03.956693Z","iopub.status.idle":"2021-07-27T00:42:04.483439Z","shell.execute_reply.started":"2021-07-27T00:42:03.956652Z","shell.execute_reply":"2021-07-27T00:42:04.482498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shop_analyzer.multiplot(index_list=['Чехов ТРЦ \"Карнавал\"', 'Коломна ТЦ \"Рио\"', 'Москва ТРК \"Атриум\"', 'Омск ТЦ \"Мега\"'], by_label=True, title='Shops with common names')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:04.484859Z","iopub.execute_input":"2021-07-27T00:42:04.485475Z","iopub.status.idle":"2021-07-27T00:42:04.929885Z","shell.execute_reply.started":"2021-07-27T00:42:04.485431Z","shell.execute_reply":"2021-07-27T00:42:04.928405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Shops with common naming","metadata":{}},{"cell_type":"code","source":"shop_analyzer.multiplot(index_list=statistics['word_based']['shops'].from_vals(statistics['word_based']['shops'].from_tokens(['москва', 'тц'])), by_label=True, title='Shops with common names')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:04.931714Z","iopub.execute_input":"2021-07-27T00:42:04.932128Z","iopub.status.idle":"2021-07-27T00:42:05.432072Z","shell.execute_reply.started":"2021-07-27T00:42:04.93209Z","shell.execute_reply":"2021-07-27T00:42:05.430613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shop_analyzer.multiplot(index_list=statistics['word_based']['shops'].from_vals(statistics['word_based']['shops'].from_tokens(['мега', 'тц'])), by_label=True, title='Shops with common names')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:05.433803Z","iopub.execute_input":"2021-07-27T00:42:05.434286Z","iopub.status.idle":"2021-07-27T00:42:06.052127Z","shell.execute_reply.started":"2021-07-27T00:42:05.434222Z","shell.execute_reply":"2021-07-27T00:42:06.050784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shop_analyzer.multiplot(index_list=statistics['word_based']['shops'].from_vals(statistics['word_based']['shops'].from_tokens(['якутск'])), by_label=True, title='Shops with common names')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:06.054039Z","iopub.execute_input":"2021-07-27T00:42:06.054471Z","iopub.status.idle":"2021-07-27T00:42:06.501306Z","shell.execute_reply.started":"2021-07-27T00:42:06.054428Z","shell.execute_reply":"2021-07-27T00:42:06.499725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see, shops with common categories have something in commmon with their sales","metadata":{}},{"cell_type":"code","source":"shop_analyzer.show_clusters()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:06.503145Z","iopub.execute_input":"2021-07-27T00:42:06.503599Z","iopub.status.idle":"2021-07-27T00:42:07.891852Z","shell.execute_reply.started":"2021-07-27T00:42:06.503553Z","shell.execute_reply":"2021-07-27T00:42:07.890609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Discovering categories","metadata":{}},{"cell_type":"code","source":"category_analyzer = SalesAnalyzer(statistics['sales_cnt_based']['categories'], statistics['word_based']['categories'])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:07.893386Z","iopub.execute_input":"2021-07-27T00:42:07.893718Z","iopub.status.idle":"2021-07-27T00:42:07.899102Z","shell.execute_reply.started":"2021-07-27T00:42:07.893689Z","shell.execute_reply":"2021-07-27T00:42:07.897535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_analyzer.heatmap(True)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:07.900533Z","iopub.execute_input":"2021-07-27T00:42:07.900859Z","iopub.status.idle":"2021-07-27T00:42:11.555287Z","shell.execute_reply.started":"2021-07-27T00:42:07.900829Z","shell.execute_reply":"2021-07-27T00:42:11.55405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_analyzer.multiplot(index_list=statistics['word_based']['categories'].from_vals(statistics['word_based']['categories'].from_tokens(['игровые', 'консоли'])), by_label=True, title='Category sales tendecy')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:11.556778Z","iopub.execute_input":"2021-07-27T00:42:11.557109Z","iopub.status.idle":"2021-07-27T00:42:12.050479Z","shell.execute_reply.started":"2021-07-27T00:42:11.55708Z","shell.execute_reply":"2021-07-27T00:42:12.049114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_analyzer.multiplot(index_list=statistics['word_based']['categories'].from_vals(statistics['word_based']['categories'].from_tokens(['игры'])), by_label=True, title='Category sales tendecy')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:12.052203Z","iopub.execute_input":"2021-07-27T00:42:12.052659Z","iopub.status.idle":"2021-07-27T00:42:12.751932Z","shell.execute_reply.started":"2021-07-27T00:42:12.052616Z","shell.execute_reply":"2021-07-27T00:42:12.750752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Games are less dependent on seasonality, but have a peak in summer (mostly games are published here)","metadata":{}},{"cell_type":"code","source":"category_analyzer.multiplot(index_list=statistics['word_based']['categories'].from_vals(statistics['word_based']['categories'].from_tokens(['книги'])), by_label=True, title='Category sales tendecy')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:12.753553Z","iopub.execute_input":"2021-07-27T00:42:12.753944Z","iopub.status.idle":"2021-07-27T00:42:13.425103Z","shell.execute_reply.started":"2021-07-27T00:42:12.753904Z","shell.execute_reply":"2021-07-27T00:42:13.423849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Russian people start reading manga & comics","metadata":{}},{"cell_type":"code","source":"category_analyzer.multiplot(index_list=statistics['word_based']['categories'].from_vals(statistics['word_based']['categories'].from_tokens(['литература'])), by_label=True, title='Category sales tendecy')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:13.426613Z","iopub.execute_input":"2021-07-27T00:42:13.426945Z","iopub.status.idle":"2021-07-27T00:42:13.868813Z","shell.execute_reply.started":"2021-07-27T00:42:13.426911Z","shell.execute_reply":"2021-07-27T00:42:13.86743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Maybe some trouble with dataset with literature","metadata":{}},{"cell_type":"code","source":"category_analyzer.multiplot(index_list=statistics['word_based']['categories'].from_vals(statistics['word_based']['categories'].from_tokens(['музыка'])), by_label=True, title='Category sales tendecy')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:13.870721Z","iopub.execute_input":"2021-07-27T00:42:13.871219Z","iopub.status.idle":"2021-07-27T00:42:14.420199Z","shell.execute_reply.started":"2021-07-27T00:42:13.871162Z","shell.execute_reply":"2021-07-27T00:42:14.418882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"People less and less use self-made audio ","metadata":{}},{"cell_type":"code","source":"category_analyzer.multiplot(index_list=statistics['word_based']['categories'].from_vals(statistics['word_based']['categories'].from_tokens(['подарки'])), by_label=True, title='Category sales tendecy')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:14.421632Z","iopub.execute_input":"2021-07-27T00:42:14.421928Z","iopub.status.idle":"2021-07-27T00:42:15.042221Z","shell.execute_reply.started":"2021-07-27T00:42:14.4219Z","shell.execute_reply":"2021-07-27T00:42:15.040668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seasonality itself","metadata":{}},{"cell_type":"code","source":"category_analyzer.multiplot(index_list=statistics['word_based']['categories'].from_vals(statistics['word_based']['categories'].from_tokens(['ps3'])), by_label=True, title='Category sales tendecy')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:15.043956Z","iopub.execute_input":"2021-07-27T00:42:15.044376Z","iopub.status.idle":"2021-07-27T00:42:15.450652Z","shell.execute_reply.started":"2021-07-27T00:42:15.044334Z","shell.execute_reply":"2021-07-27T00:42:15.449213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_analyzer.show_clusters()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:15.45284Z","iopub.execute_input":"2021-07-27T00:42:15.453366Z","iopub.status.idle":"2021-07-27T00:42:17.172673Z","shell.execute_reply.started":"2021-07-27T00:42:15.453304Z","shell.execute_reply":"2021-07-27T00:42:17.171072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pretty reasonable, but strange at times","metadata":{}},{"cell_type":"code","source":"weekly_total_cnt_ = date_indexed.groupby(dataset_income.index).item_cnt_day.sum()\nweekly_total_cnt_","metadata":{"execution":{"iopub.status.busy":"2021-07-27T02:05:58.011444Z","iopub.execute_input":"2021-07-27T02:05:58.011821Z","iopub.status.idle":"2021-07-27T02:05:58.069597Z","shell.execute_reply.started":"2021-07-27T02:05:58.011785Z","shell.execute_reply":"2021-07-27T02:05:58.068622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf\n\nplot_acf(weekly_total_cnt_, lags=[i for i in range(366)])\n_ = plot_acf(weekly_total_cnt_, lags=[i for i in range(25, 40)])\n_ = plot_acf(weekly_total_cnt_, lags=[0, 1, 7, 28, 92, 365])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:17.284435Z","iopub.execute_input":"2021-07-27T00:42:17.284757Z","iopub.status.idle":"2021-07-27T00:42:17.833705Z","shell.execute_reply.started":"2021-07-27T00:42:17.284727Z","shell.execute_reply":"2021-07-27T00:42:17.832762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So as we see auto-correlation function shows us that significant seasonality periods probably can be seen in [1-7, 30-31, 91-92, 365] ","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\ndecomposition = {}\ndecomposition['week'] = seasonal_decompose(weekly_total_cnt_, model='additive', period=7)\ndecomposition['week'].plot()\ndecomposition['month'] = seasonal_decompose(weekly_total_cnt_, model='additive', period=31)\ndecomposition['month'].plot()\ndecomposition['quater'] = seasonal_decompose(weekly_total_cnt_, model='additive', period=92)\ndecomposition['quater'].plot()\ndecomposition['year'] = seasonal_decompose(weekly_total_cnt_, model='additive', period=365)\n_ = decomposition['year'].plot()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T01:05:34.114552Z","iopub.execute_input":"2021-07-27T01:05:34.11495Z","iopub.status.idle":"2021-07-27T01:05:38.036724Z","shell.execute_reply.started":"2021-07-27T01:05:34.114911Z","shell.execute_reply":"2021-07-27T01:05:38.035598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure, axis = plt.subplots(2, 2,figsize=(20, 12))\n\naxis[0][0].title.set_text('Week')\nsns.histplot(decomposition['week'].resid.dropna(), kde=True, ax=axis[0][0], stat=\"probability\")\naxis[0][1].title.set_text('Month')\nsns.histplot(decomposition['month'].resid.dropna(), kde=True, ax=axis[0][1], stat=\"probability\")\naxis[1][0].title.set_text('Quater')\nsns.histplot(decomposition['quater'].resid.dropna(), kde=True, ax=axis[1][0], stat=\"probability\")\naxis[1][1].title.set_text('Year')\nsns.histplot(decomposition['year'].resid.dropna(), kde=True,ax=axis[1][1])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T01:05:54.6075Z","iopub.execute_input":"2021-07-27T01:05:54.607934Z","iopub.status.idle":"2021-07-27T01:05:55.817582Z","shell.execute_reply.started":"2021-07-27T01:05:54.607897Z","shell.execute_reply":"2021-07-27T01:05:55.81656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.holtwinters import SimpleExpSmoothing   \nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\n\nfitted = pd.DataFrame({'base': fits})","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:22.81632Z","iopub.execute_input":"2021-07-27T00:42:22.81662Z","iopub.status.idle":"2021-07-27T00:42:22.839149Z","shell.execute_reply.started":"2021-07-27T00:42:22.816583Z","shell.execute_reply":"2021-07-27T00:42:22.837203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets use ETS with additive trend and seasonality to predict 4 month (from july 2015)","metadata":{}},{"cell_type":"code","source":"_, axs = plt.subplots(1, 1, figsize=(30, 24))\n\nforecaster = ExponentialSmoothing(fitted['base'][:-120], trend='add', seasonal='add', seasonal_periods=365).fit()\n\nfitted['ETS(A,A)'] = forecaster.fittedvalues\nfitted['ETS(A,A)'][-120:] = forecaster.forecast(120) \nfitted.plot(ax = axs)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:42:22.841484Z","iopub.execute_input":"2021-07-27T00:42:22.842059Z","iopub.status.idle":"2021-07-27T00:42:24.040154Z","shell.execute_reply.started":"2021-07-27T00:42:22.842003Z","shell.execute_reply":"2021-07-27T00:42:24.03858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"residuals = fitted['base'][-120:] - fitted['ETS(A,A)'][-120:] \nsns.histplot(residuals, bins=10, kde=True)\nresiduals.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:52:48.756864Z","iopub.execute_input":"2021-07-27T00:52:48.758008Z","iopub.status.idle":"2021-07-27T00:52:49.019159Z","shell.execute_reply.started":"2021-07-27T00:52:48.757933Z","shell.execute_reply":"2021-07-27T00:52:49.017766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, axs = plt.subplots(1, 1, figsize=(16, 9))\n\nfitted.groupby(fitted.index.to_period('W')).agg(np.sum).plot(ax=axs)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T00:45:48.032973Z","iopub.execute_input":"2021-07-27T00:45:48.03344Z","iopub.status.idle":"2021-07-27T00:45:48.438308Z","shell.execute_reply.started":"2021-07-27T00:45:48.0334Z","shell.execute_reply":"2021-07-27T00:45:48.437334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### But we stil have 83 category 60 shops and 22k unique items. How to cover them all... I was told to create simple regression predictors providing something like naive, seasonal naive, mean time based forecast predictors and overall trend. Yeah, I probably know them, but I also read about exponential smoothing and found it more suitable because it provides self trend and seasonality estimation (while regression estimation of this components is less flexible)","metadata":{}},{"cell_type":"code","source":"dframe  = pd.DataFrame(weekly_total_cnt_)\n\ndef name_wrapper(x, name):\n    x.__name__  = name\n    return x\n\nfor i in range(11):\n    dframe[f'is_{month_names[i]}'] = np.int8(dframe.index.month == i + 1)\n    \ndframe.reset_index(inplace=True)\ndframe","metadata":{"execution":{"iopub.status.busy":"2021-07-27T02:15:18.734393Z","iopub.execute_input":"2021-07-27T02:15:18.734763Z","iopub.status.idle":"2021-07-27T02:15:18.780896Z","shell.execute_reply.started":"2021-07-27T02:15:18.734733Z","shell.execute_reply":"2021-07-27T02:15:18.779414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}