{"cells":[{"metadata":{"colab_type":"text","id":"wYgmnfQgtFMv"},"cell_type":"markdown","source":"**Pedict Future Sale**\n\n**Problem:-**\n\nYou are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge."},{"metadata":{"colab_type":"text","id":"ftGEptwmv8dp"},"cell_type":"markdown","source":"# Section 1:"},{"metadata":{"colab_type":"text","id":"YEMjFBJ4t0rz"},"cell_type":"markdown","source":"**1.1: Import Necessary Libraries**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1246,"status":"error","timestamp":1573395888222,"user":{"displayName":"Tech Entertaining","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBD3cpdezmTLK4GmA7Smu2MBHuFgGfZNeLA9aaeUg=s64","userId":"14192496592089419195"},"user_tz":-330},"id":"PMRBAR8ft7vU","outputId":"3bec3102-23f6-4ee6-fbbb-84b16ee6348d","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nimport seaborn as sns\nfrom math import ceil\nimport datetime\n\n# TIME SERIES\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\n\n# settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir('../input/competitive-data-science-predict-future-sales/'))","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442},"colab_type":"code","executionInfo":{"elapsed":1111,"status":"error","timestamp":1573396011614,"user":{"displayName":"Tech Entertaining","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBD3cpdezmTLK4GmA7Smu2MBHuFgGfZNeLA9aaeUg=s64","userId":"14192496592089419195"},"user_tz":-330},"id":"zdv-PjvjwwPy","outputId":"1bd5f8b1-5d8c-4249-847b-95a8d4c788a0","trusted":true},"cell_type":"code","source":"# Import all of them \nsales=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\nitem_cat=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")\nitem=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\nshops=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")\ntest=pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"colab_type":"code","executionInfo":{"elapsed":618,"status":"ok","timestamp":1573374406737,"user":{"displayName":"Tech Entertaining","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBD3cpdezmTLK4GmA7Smu2MBHuFgGfZNeLA9aaeUg=s64","userId":"14192496592089419195"},"user_tz":-330},"id":"BEPXl6IAxmco","outputId":"419d1cd9-9cc1-4b2e-ce50-88205ea5623b","trusted":true},"cell_type":"code","source":"sales.head(2)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"item.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_cat.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.head(2)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"bCH8C0NAypEG"},"cell_type":"markdown","source":"# Section 2: Exploration"},{"metadata":{"colab_type":"text","id":"ULbValjVE3Yg"},"cell_type":"markdown","source":"**2.1: Data Exploration**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","executionInfo":{"elapsed":787,"status":"ok","timestamp":1573374418475,"user":{"displayName":"Tech Entertaining","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBD3cpdezmTLK4GmA7Smu2MBHuFgGfZNeLA9aaeUg=s64","userId":"14192496592089419195"},"user_tz":-330},"id":"NHYxLc1yyrTm","outputId":"c4c549e1-7832-42d5-e156-603607a1af86","trusted":true},"cell_type":"code","source":"train=sales.copy()\ntest_shops = test.shop_id.unique()\ntrain = train[train.shop_id.isin(test_shops)]\ntest_items = test.item_id.unique()\ntrain = train[train.item_id.isin(test_items)]\n\ngrouped = pd.DataFrame(train.groupby(['shop_id', 'date_block_num'])['item_cnt_day'].sum().reset_index())\nfig, axes = plt.subplots(nrows=5, ncols=2, sharex=True, sharey=True, figsize=(16,20))\nnum_graph = 10\nid_per_graph = ceil(grouped.shop_id.max() / num_graph)\ncount = 0\nfor i in range(5):\n    for j in range(2):\n        sns.pointplot(x='date_block_num', y='item_cnt_day', hue='shop_id', data=grouped[np.logical_and(count*id_per_graph <= grouped['shop_id'], grouped['shop_id'] < (count+1)*id_per_graph)], ax=axes[i][j])\n        count += 1","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"0wbhn1--MfnH"},"cell_type":"markdown","source":"# Section 4: Feature Engineering"},{"metadata":{"colab_type":"text","id":"lCcXuRUZMvlh"},"cell_type":"markdown","source":"**4.1: Feature Engineering**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"colab_type":"code","executionInfo":{"elapsed":1508,"status":"ok","timestamp":1573374424047,"user":{"displayName":"Tech Entertaining","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBD3cpdezmTLK4GmA7Smu2MBHuFgGfZNeLA9aaeUg=s64","userId":"14192496592089419195"},"user_tz":-330},"id":"zFkGtTtUL9Hc","outputId":"053e3e97-4cc5-44c9-d7d7-6711e4a6b750","trusted":true},"cell_type":"code","source":"#formatting the date column correctly\nsales.date=sales.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))\n# check\nprint(sales.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aggregate to monthly level the required metrics\nmonthly_sales=sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n    \"date\",\"item_price\",\"item_cnt_day\"].agg({\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.2: Number of Item Per Category"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# number of items per cat \nx=item.groupby(['item_category_id']).count()\nx=x.sort_values(by='item_id',ascending=False)\nx=x.iloc[0:10].reset_index()\nx\n# #plot\nplt.figure(figsize=(8,4))\nax= sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\nplt.title(\"Items per Category\")\nplt.ylabel('# of items', fontsize=12)\nplt.xlabel('Category', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.3: Single Series\n- Sales over time of each store-item is a time-series in itself. Before we dive into all the combinations, first let's understand how to forecast for a single series.\n- I've chosen to predict for the total sales per month for the entire company.\n\n- First let's compute the total sales per month and plot that data."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(10,5))\nplt.title('Total Sales of the company')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.plot(ts.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(ts.rolling(window=12,center=False).std(),label='Rolling sd');\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Quick observations: There is an obvious \"seasonality\" (Eg: peak sales around a time of year) and a decreasing \"Trend\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n# multiplicative\nres = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"multiplicative\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Additive model\nres = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"additive\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.4: Stationarity Test"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Stationarity tests\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\ntest_stationarity(ts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.5: Remove Trends"},{"metadata":{"trusted":true},"cell_type":"code","source":"# to remove trend\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(8,8))\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts)\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts)\nplt.plot(new_ts)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After De-seasonalization')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts,12)       # assuming the seasonality is 12 months long\nplt.plot(new_ts)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# now testing the stationarity again after de-seasonality\ntest_stationarity(new_ts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Now after the transformations, our p-value for the DF test is well within 5 %. Hence we can assume Stationarity of the series\n- We can easily get back the original series using the inverse transform function that we have defined above.\n\n- Now let's dive into making the forecasts!"},{"metadata":{},"cell_type":"markdown","source":"### AR, MA and ARMA models:¶\nTL: DR version of the models:\n\nMA - Next value in the series is a function of the average of the previous n number of values AR - The errors(difference in mean) of the next value is a function of the errors in the previous n number of values ARMA - a mixture of both.\n\nNow, How do we find out, if our time-series in AR process or MA process?\n\nLet's find out!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsplot(y, lags=None, figsize=(10, 8), style='bmh',title=''):\n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n    with plt.style.context(style):    \n        fig = plt.figure(figsize=figsize)\n        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n        layout = (3, 2)\n        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1, 0))\n        pacf_ax = plt.subplot2grid(layout, (1, 1))\n        qq_ax = plt.subplot2grid(layout, (2, 0))\n        pp_ax = plt.subplot2grid(layout, (2, 1))\n        \n        y.plot(ax=ts_ax)\n        ts_ax.set_title(title)\n        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n        sm.qqplot(y, line='s', ax=qq_ax)\n        qq_ax.set_title('QQ Plot')        \n        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n\n        plt.tight_layout()\n    return ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Simulate an AR(1) process with alpha = 0.6\nnp.random.seed(1)\nn_samples = int(1000)\na = 0.6\nx = w = np.random.normal(size=n_samples)\n\nfor t in range(n_samples):\n    x[t] = a*x[t-1] + w[t]\nlimit=12    \n_ = tsplot(x, lags=limit,title=\"AR(1)process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AR(1) process -- has ACF tailing out and PACF cutting off at lag=1"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Simulate an AR(2) process\n\nn = int(1000)\nalphas = np.array([.444, .333])\nbetas = np.array([0.])\n\n# Python requires us to specify the zero-lag value which is 1\n# Also note that the alphas for the AR model must be negated\n# We also set the betas for the MA equal to 0 for an AR(p) model\n# For more information see the examples at statsmodels.org\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nar2 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \n_ = tsplot(ar2, lags=12,title=\"AR(2) process\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AR(2) process -- has ACF tailing out and PACF cutting off at lag=2\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an MA(1) process\nn = int(1000)\n# set the AR(p) alphas equal to 0\nalphas = np.array([0.])\nbetas = np.array([0.8])\n# add zero-lag and negate alphas\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\nma1 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \nlimit=12\n_ = tsplot(ma1, lags=limit,title=\"MA(1) process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MA(1) process -- has ACF cut off at lag=1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate MA(2) process with betas 0.6, 0.4\nn = int(1000)\nalphas = np.array([0.])\nbetas = np.array([0.6, 0.4])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nma3 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n)\n_ = tsplot(ma3, lags=12,title=\"MA(2) process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MA(2) process -- has ACF cut off at lag=2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an ARMA(2, 2) model with alphas=[0.5,-0.25] and betas=[0.5,-0.3]\nmax_lag = 12\n\nn = int(5000) # lots of samples to help estimates\nburn = int(n/10) # number of samples to discard before fit\n\nalphas = np.array([0.8, -0.65])\nbetas = np.array([0.5, -0.7])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\narma22 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n, burnin=burn)\n_ = tsplot(arma22, lags=max_lag,title=\"ARMA(2,2) process\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pick best order by aic \n# smallest aic value wins\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(arma22, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We've correctly identified the order of the simulated process as ARMA(2,2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets use it for the sales time-series.\n#\n# pick best order by aic \n# smallest aic value wins\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(new_ts.values, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simply use best_mdl.predict() to predict the next values\n# adding the dates to the Time-series as index\nts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.index=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nts=ts.reset_index()\nts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_sales=sales.groupby(['date_block_num'])[\"item_cnt_day\"].sum()\ndates=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\n\ntotal_sales.index=dates\ntotal_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the unique combinations of item-store from the sales data at monthly level\nmonthly_sales=sales.groupby([\"shop_id\",\"item_id\",\"date_block_num\"])[\"item_cnt_day\"].sum()\n# arrange it conviniently to perform the hts \nmonthly_sales=monthly_sales.unstack(level=-1).fillna(0)\nmonthly_sales=monthly_sales.T\ndates=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nmonthly_sales.index=dates\nmonthly_sales=monthly_sales.reset_index()\nmonthly_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Middle out:¶\n#Let's predict for the store level\n\nmonthly_shop_sales=sales.groupby([\"date_block_num\",\"shop_id\"])[\"item_cnt_day\"].sum()\n# get the shops to the columns\nmonthly_shop_sales=monthly_shop_sales.unstack(level=1)\nmonthly_shop_sales=monthly_shop_sales.fillna(0)\nmonthly_shop_sales.index=dates\nmonthly_shop_sales=monthly_shop_sales.reset_index()\nmonthly_shop_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"FtNT6CbKfE7I","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"Predict Future Sale.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}