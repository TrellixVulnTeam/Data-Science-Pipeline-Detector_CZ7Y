{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Future Sales Prediction (0p98)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nfrom itertools import product\nimport gc\n\nfrom sklearn import preprocessing\nimport sklearn\nimport lightgbm as lgb","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:39:41.04877Z","iopub.execute_input":"2022-03-21T12:39:41.049385Z","iopub.status.idle":"2022-03-21T12:39:43.053792Z","shell.execute_reply.started":"2022-03-21T12:39:41.049276Z","shell.execute_reply":"2022-03-21T12:39:43.053041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def downcast_dtypes(df):\n    '''\n        Changes column types in the dataframe: \n                \n                `float64` type to `float32`\n                `int64`   type to `int32`\n    '''\n    \n    # Select columns to downcast\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n    \n    # Downcast\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols]   = df[int_cols].astype(np.int32)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:40:20.141878Z","iopub.execute_input":"2022-03-21T12:40:20.142878Z","iopub.status.idle":"2022-03-21T12:40:20.149483Z","shell.execute_reply.started":"2022-03-21T12:40:20.142834Z","shell.execute_reply":"2022-03-21T12:40:20.148445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data files are loaded","metadata":{}},{"cell_type":"code","source":"sales = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nitem_cats = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:40:33.812008Z","iopub.execute_input":"2022-03-21T12:40:33.812764Z","iopub.status.idle":"2022-03-21T12:40:36.70695Z","shell.execute_reply.started":"2022-03-21T12:40:33.812731Z","shell.execute_reply":"2022-03-21T12:40:36.706229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"### Test\nIn the test file there are the \"shop_id\" and \"item_id\" for which we have to predict, for the \"date_block_num\" (month) 34 and for each shop, the number of items sold","metadata":{}},{"cell_type":"code","source":"test.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:40:53.307014Z","iopub.execute_input":"2022-03-21T12:40:53.307355Z","iopub.status.idle":"2022-03-21T12:40:53.324676Z","shell.execute_reply.started":"2022-03-21T12:40:53.307321Z","shell.execute_reply":"2022-03-21T12:40:53.323845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sales","metadata":{}},{"cell_type":"code","source":"sales.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:40:56.750097Z","iopub.execute_input":"2022-03-21T12:40:56.7508Z","iopub.status.idle":"2022-03-21T12:40:56.765819Z","shell.execute_reply.started":"2022-03-21T12:40:56.750751Z","shell.execute_reply":"2022-03-21T12:40:56.765056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. A file that adds test data (with target set to 0) is added to the sales history\n2. Negative \"item_cnt_day\" correspond to returns, so these rows are deleted\n3. If there is a negative price, it is a wrong product etry and it is deleted\n4. The predictions are month based and correspond only to the items sold. Therefore date and price are dropped.","metadata":{}},{"cell_type":"code","source":"# 1. A file that adds test data (with target set to 0) is added to the sales history\nsales = pd.read_csv('../input/salesprediction/sales_train_test.csv')\n# 2. Negative counts are returned objects and they are neglected\nsales.drop(sales[sales['item_cnt_day'] < 0].index, inplace=True)\n# 3. Negative price is an error and is neglegted\nsales.drop(sales[sales['item_price'] < 0].index, inplace=True)\n# 4. Irrelevant columns are deleted\nsales = sales.drop(columns = ['date', 'item_price'])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:42:32.040661Z","iopub.execute_input":"2022-03-21T12:42:32.04092Z","iopub.status.idle":"2022-03-21T12:42:35.320679Z","shell.execute_reply.started":"2022-03-21T12:42:32.040893Z","shell.execute_reply":"2022-03-21T12:42:35.319641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Month is added as a feature to capture seasonal trend","metadata":{}},{"cell_type":"code","source":"sales['month'] = sales['date_block_num'].values % 12 + 1","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:42:43.182Z","iopub.execute_input":"2022-03-21T12:42:43.182337Z","iopub.status.idle":"2022-03-21T12:42:43.233734Z","shell.execute_reply.started":"2022-03-21T12:42:43.182302Z","shell.execute_reply":"2022-03-21T12:42:43.232793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Items\nNo further action is performed with the items information","metadata":{}},{"cell_type":"code","source":"print('There are ' + str(len(items)) + ' different items')\nitems.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:42:47.912195Z","iopub.execute_input":"2022-03-21T12:42:47.912452Z","iopub.status.idle":"2022-03-21T12:42:47.92394Z","shell.execute_reply.started":"2022-03-21T12:42:47.912423Z","shell.execute_reply":"2022-03-21T12:42:47.923068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Item categories","metadata":{}},{"cell_type":"code","source":"print('There are ' + str(len(item_cats)) + ' different items')\nitem_cats.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:42:53.226961Z","iopub.execute_input":"2022-03-21T12:42:53.227631Z","iopub.status.idle":"2022-03-21T12:42:53.238621Z","shell.execute_reply.started":"2022-03-21T12:42:53.227593Z","shell.execute_reply":"2022-03-21T12:42:53.237699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 84 different item categories. Each item belongs to an item category. \nThanks to google translate, names are translated to english and 3 more features have been implemented:\n - cat_1 and cat_2: subcategories of the item category\n - cat_digital: if the item category is digital has a value of 1 and, if not, a value of 0","metadata":{}},{"cell_type":"code","source":"item_cats = pd.read_csv('../input/salesprediction/item_categories_extra.csv', sep=';')\nitem_cats.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:43:02.122969Z","iopub.execute_input":"2022-03-21T12:43:02.123255Z","iopub.status.idle":"2022-03-21T12:43:02.150218Z","shell.execute_reply.started":"2022-03-21T12:43:02.123226Z","shell.execute_reply":"2022-03-21T12:43:02.149498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Shops","metadata":{}},{"cell_type":"code","source":"print('There are ' + str(len(shops)) + ' different shops')\nshops.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:43:09.18594Z","iopub.execute_input":"2022-03-21T12:43:09.186234Z","iopub.status.idle":"2022-03-21T12:43:09.195393Z","shell.execute_reply.started":"2022-03-21T12:43:09.186203Z","shell.execute_reply":"2022-03-21T12:43:09.194868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In a first step are observed the cumulative sold items per month for each shop","metadata":{}},{"cell_type":"code","source":"# All Shop sales per month\nshopsSales = sales.groupby(['shop_id', 'date_block_num'], as_index=False).agg(shop_month_sales = ('item_cnt_day', 'sum'))\nfig = plt.figure()\nax = fig.add_subplot()\nfor shopId in sales['shop_id'].unique():\n    shopSales = shopsSales[shopsSales['shop_id'] == shopId]\n    ax.plot(shopSales['date_block_num'], shopSales['shop_month_sales'])\nax.set_xlabel('date_block_num')\nax.set_ylabel('shop_month_sales')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:43:16.622749Z","iopub.execute_input":"2022-03-21T12:43:16.623048Z","iopub.status.idle":"2022-03-21T12:43:17.189637Z","shell.execute_reply.started":"2022-03-21T12:43:16.623Z","shell.execute_reply":"2022-03-21T12:43:17.18877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown in the previous figure, not all shops are active in all months. Therefore, all shops that do not sell any item in the last month wilol not be considered as it is assumed they are closed","metadata":{}},{"cell_type":"code","source":"minMonth = 33\nclosedShopIds = []\nfor shopId in sales['shop_id'].unique():\n    shopMonths = shopsSales[shopsSales['shop_id'] == shopId]['date_block_num'].unique()\n    if np.amax(shopMonths) < minMonth:\n        closedShopIds.append(shopId)\n\nprint('There are ' + str(len(closedShopIds)) + ' closed shops at the last month')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:43:22.195213Z","iopub.execute_input":"2022-03-21T12:43:22.196098Z","iopub.status.idle":"2022-03-21T12:43:22.266203Z","shell.execute_reply.started":"2022-03-21T12:43:22.19602Z","shell.execute_reply":"2022-03-21T12:43:22.265163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly as for the items categories, with the help of google translate, shops name has been translated to english.\nSome information is obtained and two features are added:\n- shop_type: type of shop according to the name. For example shopping center, online, ...\n- shop_zip: in the shop name, the city is included. Instead of the city name, the city zip code is considered as feature because near cities have similar zip codes\n\nA part from that, there are 3 shops which are duplicated. Therefore the sales dataframe is updated","metadata":{}},{"cell_type":"code","source":"# Duplicated shops are merged\nsales.loc[sales.shop_id == 0, 'shop_id'] = 57\nsales.loc[sales.shop_id == 1, 'shop_id'] = 58\nsales.loc[sales.shop_id == 11, 'shop_id'] = 10\n\nshops = pd.read_csv('../input/salesprediction/shops_extra.csv', sep=';')\nshops.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:43:31.06121Z","iopub.execute_input":"2022-03-21T12:43:31.061473Z","iopub.status.idle":"2022-03-21T12:43:31.152719Z","shell.execute_reply.started":"2022-03-21T12:43:31.061446Z","shell.execute_reply":"2022-03-21T12:43:31.151874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Matrix\nA feature matrix with all possible combinations of items sold per each shop is created. All additional features will be added to this matrix","metadata":{}},{"cell_type":"code","source":"# First month considered to calculate the previous month sells\nfirstMonth = 20 \n# Initial features columns names\nfeatCols = ['shop_id', 'item_id', 'date_block_num']\n# Shop ids to be kept\nshopIds = list(np.setdiff1d(sales['shop_id'].unique(), closedShopIds))\n# All months are considered because the solds in the previous months are necessary\nshopMonths = sales['date_block_num'].unique() \n\n# Feature matrix is initialized\nfeatMat = []\n\nfor shopId in shopIds:\n    shopItems = sales[(sales['date_block_num'] >= firstMonth) & (sales['shop_id'] == shopId)]['item_id'].unique()\n    featMat.append(np.array(list(product(*[[shopId], shopItems, shopMonths])),dtype='int32'))\n# Turn the grid into a dataframe\nfeatMat = pd.DataFrame(np.vstack(featMat), columns = featCols,dtype=np.int32)    \nfeatMat.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:43:36.384921Z","iopub.execute_input":"2022-03-21T12:43:36.385258Z","iopub.status.idle":"2022-03-21T12:43:49.635741Z","shell.execute_reply.started":"2022-03-21T12:43:36.385223Z","shell.execute_reply":"2022-03-21T12:43:49.63479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Target\nThe target is, for each item, shop and month, the total number of articles sold. Target is calculated","metadata":{}},{"cell_type":"code","source":"# Sold items for each shop and month are added. It is the target column\ntargetMat = sales.groupby(['shop_id', 'date_block_num', 'item_id'], as_index=False).agg(target = ('item_cnt_day', 'sum'))\nfeatMat = pd.merge(featMat, targetMat, how='left', on=featCols).fillna(0)\nfig, ax = plt.subplots(figsize=(15, 6), nrows=1, ncols=2)\nax[0].hist(featMat['target'], 100)\nax[0].set_ylabel('occurrencies')\nax[0].set_xlabel('target')\nax[1].hist(featMat['target'], 100)\nax[1].set_ylabel('occurrencies')\nax[1].set_xlabel('target')\nax[1].set_ylim([0, 1000])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:43:55.081895Z","iopub.execute_input":"2022-03-21T12:43:55.082417Z","iopub.status.idle":"2022-03-21T12:44:01.250554Z","shell.execute_reply.started":"2022-03-21T12:43:55.082385Z","shell.execute_reply":"2022-03-21T12:44:01.249799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown, for most of the items only a few articles are sold and in few cases many articles are sold. TIt meanse there is a low probability that for an item, many articles are sold. Therefore, instead of scaling the target between 0 and 20, target is clipped between these values (see https://www.kaggle.com/code/zhixx018/coursera-final-0-98-lgbm/notebook). This way the few occurrencies with many articles sold will not impact the predictions.","metadata":{}},{"cell_type":"code","source":"# Solds are clipped\nfeatMat['target'] = featMat['target'].clip(0, 20).astype(np.int32)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:44:08.669412Z","iopub.execute_input":"2022-03-21T12:44:08.669696Z","iopub.status.idle":"2022-03-21T12:44:08.82024Z","shell.execute_reply.started":"2022-03-21T12:44:08.669667Z","shell.execute_reply":"2022-03-21T12:44:08.819477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Previously described features are added","metadata":{}},{"cell_type":"code","source":"# Month is added as a feature to capture seasonal trend\nfeatMat['month'] = (featMat['date_block_num'].values % 12 + 1).astype(np.int8)\n\n# Item_category id is added as a feature\nitem_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\nfeatMat = pd.merge(featMat, item_category_mapping, how='left', on='item_id').astype(np.int32)\n\n# Item category features are added\n# Categorical features cat_1 and cat_2 are encoded\nle = preprocessing.LabelEncoder()\ncat_1_2 = np.concatenate((item_cats['cat_1'], item_cats['cat_2']))\nle.fit(cat_1_2)\nitem_cats['cat_1'] = le.transform(item_cats['cat_1']).astype(np.int32)\nitem_cats['cat_2'] = le.transform(item_cats['cat_2']).astype(np.int32)\nitem_cats.drop(columns=['item_category_name1', 'item_category_name2'], inplace=True)\nfeatMat = pd.merge(featMat, item_cats, how='left', on='item_category_id')\n\n# Shop features are added\nshops['shop_type'] = le.fit_transform(shops['shop_type']).astype(np.int32)\nshops.drop(columns=['shop_name', 'City'], inplace=True)\nfeatMat = pd.merge(featMat, shops, how='left', on='shop_id')\n\ndel item_cats\ndel items\ndel shops\ndel sales","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:44:11.448901Z","iopub.execute_input":"2022-03-21T12:44:11.449316Z","iopub.status.idle":"2022-03-21T12:44:15.288739Z","shell.execute_reply.started":"2022-03-21T12:44:11.449284Z","shell.execute_reply":"2022-03-21T12:44:15.287828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Additional features\nAdditional features are added:\n- itemMonth: Total item solds per month\n- shopMonth: Total solds per shop each month","metadata":{}},{"cell_type":"code","source":"# Item solds per month are defined as feature\nitemMat = featMat.groupby(['date_block_num', 'item_id'], as_index = False).agg(itemMonth = ('target', 'sum')).astype(np.int32)\n# Total solds per shop each month is added as feature\nshopMat = featMat.groupby(['date_block_num', 'shop_id'], as_index = False).agg(shopMonth = ('target', 'sum')).astype(np.int32)\n\n# New features are merged with the feature matrix\nfeatMat = pd.merge(featMat, itemMat, how='left', on=['date_block_num', 'item_id']).fillna(0)\nfeatMat = pd.merge(featMat, shopMat, how='left', on=['date_block_num', 'shop_id']).fillna(0)\n\n# Downcasting and cleaning is performed\nfeatMat = downcast_dtypes(featMat)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:44:20.157364Z","iopub.execute_input":"2022-03-21T12:44:20.157851Z","iopub.status.idle":"2022-03-21T12:44:27.852831Z","shell.execute_reply.started":"2022-03-21T12:44:20.157788Z","shell.execute_reply":"2022-03-21T12:44:27.852182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lagged features\nFor some features, their value at previous months are added as new features","metadata":{}},{"cell_type":"code","source":"# Previous months are considered\nprevCols = ['target', 'shopMonth', 'itemMonth']\nlastMonth = np.amax(featMat['date_block_num'].unique())\n# Number of previous months to be considered\nprevMonths = range(1, 13, 1)\n\n# New columns are added\nfor prevCol in prevCols:\n    for prevMonth in prevMonths:\n        featMat[prevCol + '_' + str(prevMonth)] = np.zeros(len(featMat))\n\nfor month in range(firstMonth, lastMonth + 1, 1):\n    for prevCol in prevCols:\n        for prevMonth in prevMonths:        \n            featMat.loc[featMat['date_block_num'] == month, prevCol + '_' + str(prevMonth)] = \\\n            featMat.loc[featMat['date_block_num'] == month - prevMonth, prevCol].values\n\n# Once featMat is filled, not necessary months are droped\nfeatMat.drop(featMat.loc[featMat['date_block_num'] < firstMonth].index, inplace=True)\n\n# Downcasting and cleaning is performed\nfeatMat = downcast_dtypes(featMat)\ngc.collect();\n\nfeatMat.head(15)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:44:45.440626Z","iopub.execute_input":"2022-03-21T12:44:45.441178Z","iopub.status.idle":"2022-03-21T12:46:00.083554Z","shell.execute_reply.started":"2022-03-21T12:44:45.441145Z","shell.execute_reply":"2022-03-21T12:46:00.082566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature matrix is saved / loaded","metadata":{}},{"cell_type":"code","source":"featMat.to_csv('feature_matrix.csv', index = False)\n# featMat = pd.read_csv('feature_matrix.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions calculation","metadata":{}},{"cell_type":"markdown","source":"### Train / Test split\nFor a sake of the programming assignment, let's artificially split the data into train and test. We will treat last month data as the test set.","metadata":{}},{"cell_type":"code","source":"dates = featMat['date_block_num']\n\nlast_block = dates.max()\nprint('Test `date_block_num` is %d' % last_block)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:46:27.798941Z","iopub.execute_input":"2022-03-21T12:46:27.799889Z","iopub.status.idle":"2022-03-21T12:46:27.809295Z","shell.execute_reply.started":"2022-03-21T12:46:27.799833Z","shell.execute_reply":"2022-03-21T12:46:27.808412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Features related to the current month solds are deleted because for the month at which predictions are done, their value is 0","metadata":{}},{"cell_type":"code","source":"dates_train = dates[dates <  last_block]\ndates_test  = dates[dates == last_block]\n\nto_drop_cols_mod = ['target', 'date_block_num', 'itemMonth', 'shopMonth']\nX_train = featMat.loc[dates <  last_block].drop(to_drop_cols_mod, axis=1)\nX_test =  featMat.loc[dates == last_block].drop(to_drop_cols_mod, axis=1)\n\ny_train = featMat.loc[dates <  last_block, 'target'].values\ny_test =  featMat.loc[dates == last_block, 'target'].values","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:46:31.220751Z","iopub.execute_input":"2022-03-21T12:46:31.221448Z","iopub.status.idle":"2022-03-21T12:46:32.241962Z","shell.execute_reply.started":"2022-03-21T12:46:31.221403Z","shell.execute_reply":"2022-03-21T12:46:32.241093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model\nlightGBM","metadata":{}},{"cell_type":"code","source":"lgb_params = {\n               'feature_fraction': 0.5,\n               'metric': 'rmse',\n               'nthread':1, \n               'min_data_in_leaf': 2**7, \n               'bagging_fraction': 0.5, \n               'learning_rate': 0.05, \n               'objective': 'rmse', \n               'bagging_seed': 2**7, \n               'num_leaves': 80,\n               'bagging_freq':1,\n               'verbose':0, \n               'lambda_l1': 0.05,\n               'lambda_l2': 0.05\n              }\n\nmodel = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\npred_lgb = model.predict(X_test)\n\npred_lgb_scaled = np.clip(pred_lgb, 0, 20)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:46:37.545829Z","iopub.execute_input":"2022-03-21T12:46:37.546132Z","iopub.status.idle":"2022-03-21T12:48:42.128494Z","shell.execute_reply.started":"2022-03-21T12:46:37.546102Z","shell.execute_reply":"2022-03-21T12:48:42.127507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions file","metadata":{}},{"cell_type":"code","source":"subFileName = './submission.csv'\n# Submissions example file is loaded and predictions values are replaced\nsubFile = pd.read_csv('../input/competitive-data-science-predict-future-sales/sample_submission.csv')\nfeatMat.loc[featMat['date_block_num'] == last_block, 'target'] = pred_lgb_scaled\ntest = pd.merge(test, featMat[featMat['date_block_num'] == last_block], how='left', on=['shop_id', 'item_id'])\nsubFile['item_cnt_month'] = test['target'].values\nsubFile.to_csv(subFileName, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T12:50:16.70483Z","iopub.execute_input":"2022-03-21T12:50:16.705141Z","iopub.status.idle":"2022-03-21T12:50:17.878529Z","shell.execute_reply.started":"2022-03-21T12:50:16.705108Z","shell.execute_reply":"2022-03-21T12:50:17.877942Z"},"trusted":true},"execution_count":null,"outputs":[]}]}