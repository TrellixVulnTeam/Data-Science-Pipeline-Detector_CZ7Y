{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Deep Learning for Time Series Forecasting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install chart_studio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pylab as plt\nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\n\nfrom sklearn import model_selection\nimport tensorflow as tf\nfrom keras import optimizers, regularizers\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, LSTM, Conv1D, Activation, MaxPooling1D, Flatten\nimport keras.backend as K\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Load data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bpath = '../input/competitive-data-science-predict-future-sales/'\ntrain = pd.read_csv(bpath + 'sales_train.csv', parse_dates=['date'], infer_datetime_format=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Explore data \n\n### 2.1. Overall daily sales","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train['sales'] = train.item_price * train.item_cnt_day\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Daily sales","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"daily_sales = train.groupby('date', as_index=False)['sales'].sum()\ndaily_sales = daily_sales.sort_values('date', axis=0)\ndaily_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"daily_sales_sp = go.Scatter(x=daily_sales.date, y=daily_sales.sales)\nlayout = go.Layout(title='Daily Sales', xaxis=dict(title='Date'), yaxis=dict(title='Daily Sales'))\nfig = go.Figure(data=[daily_sales_sp], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3. Daily sales by store","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"daily_sales_by_store = train.groupby(['date', 'shop_id'], axis=0, as_index=False)['sales'].sum()\ndaily_sales_by_store_sp = []\nstores = np.sort(train.shop_id.unique())\nfor store in stores[26:36] :\n    dummy = daily_sales_by_store[daily_sales_by_store.shop_id == store]\n    daily_sales_by_store_sp.append(go.Scatter(x=dummy.date, y=dummy.sales, name='Store %s' % store))\n    \nlayout = go.Layout(title='Daily Sales by Store', xaxis=dict(title='Date'), yaxis=dict(title='Sales'))\nfig = go.Figure(data=daily_sales_by_store_sp, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4. Daily sales by item","execution_count":null},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"daily_sales_by_item = train.groupby(['date', 'item_id'], as_index=False, axis=0)['sales'].sum()\ndaily_sales_by_item = daily_sales_by_item.sort_values('date', axis=0)\n\nitems = train.item_id.unique()\ndaily_sales_by_item_sp = []\nfor item in items[450:550] :\n    dummy = daily_sales_by_item[daily_sales_by_item.item_id == item]\n    daily_sales_by_item_sp.append(go.Scatter(x=dummy.date, y=dummy.sales, name=('item %s' %item)))\n    \nlayout = go.Layout(title='Daily sales by item', xaxis=dict(title='Date'), yaxis=dict(title='sales'))\nfig = go.Figure(data=daily_sales_by_item_sp, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Load test data","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"test = pd.read_csv(bpath + 'test.csv')\nprint(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Prepare time series","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train = train.groupby([train.date.apply(lambda x: x.strftime('%Y-%m')), 'item_id', 'shop_id']).sum().reset_index()\ndf_train = df_train[['date','item_id','shop_id','item_cnt_day']]\ndf_train = df_train.pivot_table(index=['item_id','shop_id'], columns='date',\n                                values='item_cnt_day',fill_value=0).reset_index()\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_test = pd.merge(test, df_train, on=['item_id','shop_id'], how='left')\ndf_test = df_test.fillna(0)\ndf_test = df_test.drop(labels=['ID', 'shop_id', 'item_id'], axis=1)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"last_month = '2015-12'\ny_train = df_test[last_month]\nx_train = df_test.drop(labels=[last_month], axis=1)\nx_train = x_train.to_numpy()\ny_train = y_train.to_numpy()\ntrain_x, valid_x, train_y, valid_y = model_selection.train_test_split(x_train, y_train, \n                                                                      train_size=0.8, shuffle=True)\nprint(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_test = df_test.drop(labels=['2013-01'], axis=1)\nx_test = x_test.to_numpy()\nprint(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Multi-layer perceptron","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"def saleModel_mlp(input_shape) :\n    x_input = Input(input_shape)\n    x = Dense(64, activation='relu', use_bias=True, kernel_regularizer=regularizers.l2(0.01),\n              bias_regularizer=regularizers.l2(0.02))(x_input)\n    x = Dense(32, activation='relu', use_bias=True, kernel_regularizer=regularizers.l2(0.01),\n              bias_regularizer=regularizers.l2(0.02))(x)\n    x_out = Dense(1, activation=None)(x)\n    \n    model = Model(inputs=x_input, outputs=x_out, name='saleModel_mlp')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"mlpModel = saleModel_mlp(np.shape(train_x[1,:]))\nmlpModel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"optim = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.99)\nmlpModel.compile(optimizer=optim, metrics=['accuracy'], loss='mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"nepochs = 200\nmlp_history = mlpModel.fit(x=train_x, y=train_y, validation_data=(valid_x, valid_y), epochs=nepochs, \n                           batch_size=512, verbose=1, shuffle=True, validation_split=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize=(8,4))\nplt.plot(range(nepochs), mlp_history.history['loss'], 'r', label='train')\nplt.plot(range(nepochs), mlp_history.history['val_loss'], 'b', label='valid')\nplt.legend()\nplt.title('multi-layer perceptron')\nplt.xlabel('epochs')\nplt.ylabel('loss');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. LSTM","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"def saleModel_lstm(input_shape) :\n    x_input = Input(input_shape)\n    x = LSTM(units=32, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n                        kernel_initializer='glorot_uniform', return_sequences=True)(x_input)\n    x = LSTM(units=16, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n                        kernel_initializer='glorot_uniform', return_sequences=False)(x)\n    x_out = Dense(1, activation=None)(x)\n    \n    model = Model(inputs=x_input, outputs=x_out, name='saleModel_lstm')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_xx = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\nvalid_xx = valid_x.reshape((valid_x.shape[0], valid_x.shape[1], 1))\ntest_xx = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\nprint(train_xx.shape, valid_xx.shape, test_xx.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lstmModel = saleModel_lstm(np.shape(train_xx[1,:, :]))\nlstmModel.summary()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"lstmModel.compile(optimizer=optim, loss='mean_squared_error', metrics=['accuracy'])\nlstm_history = lstmModel.fit(x=train_xx, y=train_y, validation_data=(valid_xx, valid_y), verbose=1,\n                            epochs=100, batch_size=1024, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize=(8,4))\nplt.plot(range(100), lstm_history.history['loss'], 'r', label='train')\nplt.plot(range(100), lstm_history.history['val_loss'], 'b', label='valid')\nplt.legend()\nplt.title('LSTM')\nplt.xlabel('epochs')\nplt.ylabel('loss');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Convolutional NN","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"def saleModel_cnn(input_shape) :\n    x_input = Input(input_shape)\n    x = Conv1D(filters=64, padding='valid', strides=1, kernel_size=3)(x_input)\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size=2, strides=None, padding='valid')(x)\n    \n    x = Conv1D(filters=32, padding='valid', strides=1, kernel_size=3)(x)\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size=2, strides=None, padding='valid')(x)\n    \n    x = Flatten()(x)\n    x_out = Dense(1, activation=None)(x)\n    \n    model = Model(inputs=x_input, outputs=x_out, name='saleModel_cnn')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cnnModel = saleModel_cnn(np.shape(train_xx[1,:,:]))\ncnnModel.summary()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"cnnModel.compile(optimizer=optim, loss='mse', metrics=['accuracy'])\ncnn_history = cnnModel.fit(x=train_xx, y=train_y, validation_data=(valid_xx, valid_y), verbose=1,\n                          epochs=nepochs, batch_size=512, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize=(5,4))\nplt.plot(range(nepochs), cnn_history.history['loss'], 'r', label='train')\nplt.plot(range(nepochs), cnn_history.history['val_loss'], 'b', label='valid')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.title('1D CNN');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"mlp_pred = mlpModel.predict(x_test)\nlstm_pred = lstmModel.predict(test_xx)\ncnn_pred = cnnModel.predict(test_xx)\nprint(mlp_pred, lstm_pred, cnn_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission = pd.read_csv(bpath + 'sample_submission.csv')\nsubmission.item_cnt_month = lstm_pred\nsubmission.to_csv ('submission.csv', index = None, header = True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}