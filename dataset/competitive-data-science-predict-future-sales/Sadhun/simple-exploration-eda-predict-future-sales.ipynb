{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncolor = sns.color_palette()\n\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing the Dataset**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"items_df=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\nshops_df=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\nsales_train_df=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")\n#sample_df=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\")\nitem_categories_df=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Basic information about each dataframe*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"items_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_df.tail(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking for null values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_list = [items_df, sales_train_df, shops_df,item_categories_df,test_df]\ndf_list_names = [\"items_df\", \"sales_train_df\", \"shops_df\",\"item_categories_df\",\"test_df\"]\n\nfor i, n in zip(df_list, df_list_names):\n    null_status = i.isnull().values.any()\n    if null_status:\n        print(n + \" has null values\")\n    else:\n        print(n + \" doesn't have null values\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding top 10 items sold the most**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. Identifying the unique items and making them as keys for the new dict\n2. Values are calculated by grouping and summing the item_cnt_day for the specific keys","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Initially i wrote the below lines, Later found a line that is faster than the below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#from collections import defaultdict \n#item_cnt_dict=defaultdict()\n#for key in sorted(sales_train_df.item_id.unique()):\n#    item_cnt_dict[key]=[]\n#for key in item_cnt_dict.keys():\n#    item_cnt_dict[key]=sales_train_df[sales_train_df[\"item_id\"]==key][\"item_cnt_day\"].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Values are sorted in descending to find top 30 sold items","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#import operator\n#N=5\n#sorted_df = dict(sorted(item_cnt_dict.items(), key=operator.itemgetter(1),reverse=True)[:N])\n#sorted_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is faster and much simpler","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"item_cnt_df=sales_train_df.groupby('item_id')['item_cnt_day'].sum().to_frame().reset_index().sort_values(by=['item_cnt_day'], ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Converting the dict to a dataframe\n2. Merging the new df with items_df to identify its name and categories","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#item_cnt_df = pd.DataFrame(list(sorted_df.items()),columns = ['item_id','total_count']) \nmerged_item_df = pd.merge(left=items_df, right=item_cnt_df, left_on='item_id', right_on='item_id')\nmerged_item_df = pd.merge(left=merged_item_df, right=item_categories_df, left_on='item_category_id', right_on='item_category_id')\nmerged_item_df=merged_item_df.sort_values('item_cnt_day',ascending=False)\nmerged_item_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(12,8))\n\nsns.barplot(x='item_id', y=\"item_cnt_day\", data=merged_item_df,\n            order=merged_item_df.sort_values('item_cnt_day',ascending = False).item_id,alpha=0.8,color=color[2])\nplt.xlabel('Item_id', fontsize=12)\nplt.ylabel('Total_count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.ylim(0,25000)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Find top 30 shops that sold more items**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import operator\nN=30\nshop_cnt_dict={}\nfor key in np.sort(sales_train_df.shop_id.unique()).tolist():\n    shop_cnt_dict[key]=[]\nfor key in shop_cnt_dict.keys():\n    shop_cnt_dict[key]=sales_train_df[sales_train_df[\"shop_id\"]==key][\"item_cnt_day\"].sum()\nsorted_df = dict(sorted(shop_cnt_dict.items(), key=operator.itemgetter(1),reverse=True)[:N])\nshop_cnt_df = pd.DataFrame(list(sorted_df.items()),columns = ['shop_id','total_count']) \nshop_cnt_df  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(12,8))\n\nsns.barplot(x='shop_id', y=\"total_count\", data=shop_cnt_df,\n            order=shop_cnt_df.sort_values('total_count',ascending = False).shop_id,alpha=0.8,color=color[2])\nplt.xlabel('Shop_id', fontsize=12)\nplt.ylabel('Total_count', fontsize=12)\nplt.xticks(rotation='vertical')\n#plt.ylim(0,25000)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us find out top 30 profitable shops**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shop_price_dict={}\nfor key in np.sort(sales_train_df.shop_id.unique()).tolist():\n    shop_price_dict[key]=[]\nfor key in shop_price_dict.keys():\n    shop_price_dict[key]=sales_train_df[sales_train_df[\"shop_id\"]==key][\"item_price\"].sum()\nsorted_df = dict(sorted(shop_price_dict.items(), key=operator.itemgetter(1),reverse=True)[:N])\nshop_price_df = pd.DataFrame(list(sorted_df.items()),columns = ['shop_id','total_price']) \nshop_price_df  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(12,8))\n\nsns.barplot(x='shop_id', y=\"total_price\", data=shop_price_df,\n            order=shop_price_df.sort_values('total_price',ascending = False).shop_id,alpha=0.8,color=color[2])\nplt.xlabel('Shop_id', fontsize=12)\nplt.ylabel('Total_price', fontsize=12)\nplt.xticks(rotation='vertical')\n#plt.ylim(0,25000)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us explore date w.r.t to dates**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mon_v={'01':'Jan','02':'Feb','03':'Mar','04':'Apr','05':'May','06':'Jun','07':'Jul','08':'Aug','09':'Sep','10':'Oct','11':'Nov','12':'Dec'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=['day','mon','year']\ndatalist = list(map(lambda x: x.split(\".\"), sales_train_df.date)) # create list from entries in \"sec\" \nnewdf = pd.DataFrame(data=datalist, columns=cols)   # create dataframe of new columns\nsales_train_mon_df = pd.concat([sales_train_df, newdf], axis=1) \nsales_train_mon_df['mon'].replace(mon_v,inplace=True)\nsales_train_mon_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us find the top 3 shops which got more revenue each year**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shop_price_2013_df=sales_train_mon_df[sales_train_mon_df['year']=='2013'].groupby('shop_id')['item_price'].sum().to_frame().reset_index().sort_values(by=['item_price'], ascending=False)[:5]\nshop_price_2014_df=sales_train_mon_df[sales_train_mon_df['year']=='2014'].groupby('shop_id')['item_price'].sum().to_frame().reset_index().sort_values(by=['item_price'], ascending=False)[:5]\nshop_price_2015_df=sales_train_mon_df[sales_train_mon_df['year']=='2015'].groupby('shop_id')['item_price'].sum().to_frame().reset_index().sort_values(by=['item_price'], ascending=False)[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,5))\n\n# Divide the figure into a 1x2 grid, and give me the first section\nax1 = fig.add_subplot(131)\nplt.title('2013', fontsize=14)\n\nax2 = fig.add_subplot(132)\nplt.title('2014', fontsize=14)\n\nax3 = fig.add_subplot(133)\nplt.title('2015', fontsize=14)\n\nshop_price_2013_df.plot(kind='bar', ax=ax1)\nshop_price_2014_df.plot(kind='bar', ax=ax2)\nshop_price_2015_df.plot(kind='bar', ax=ax3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Clearly shop 26 is the best seller consistently. Followed by shop 23 and shop 22*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Let us explore monthly sale performance of these shops**\nHere we are summing up the yearly performances within the same month to get the avg performance of the shops.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_mon_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_shop26_df=sales_train_mon_df[sales_train_mon_df['shop_id']==26].groupby('mon')['item_price'].sum().to_frame().reset_index().sort_values(by=['mon'], ascending=False)\nsales_train_shop23_df=sales_train_mon_df[sales_train_mon_df['shop_id']==23].groupby('mon')['item_price'].sum().to_frame().reset_index().sort_values(by=['mon'], ascending=False)\nsales_train_shop22_df=sales_train_mon_df[sales_train_mon_df['shop_id']==22].groupby('mon')['item_price'].sum().to_frame().reset_index().sort_values(by=['mon'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_final_df=pd.merge(sales_train_shop26_df, sales_train_shop23_df, how = 'outer' ,on='mon')\nshops_final_df=pd.merge(shops_final_df, sales_train_shop22_df, how = 'outer' ,on='mon')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_final_df.rename(columns = {'item_price_x':'shop_26', 'item_price_y':'shop_23', 'item_price' : 'shop_22'}, inplace = True) \nshops_final_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_final_df.plot(kind='bar',x='mon', y=['shop_26', 'shop_23','shop_22'], figsize=(15,5), grid=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will see the profitable year for the top 3 shops**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_26_year_df=sales_train_mon_df[sales_train_mon_df['shop_id']==26].groupby('year')['item_price'].sum().to_frame().reset_index().sort_values(by=['year'], ascending=False)\nsales_train_23_year_df=sales_train_mon_df[sales_train_mon_df['shop_id']==23].groupby('year')['item_price'].sum().to_frame().reset_index().sort_values(by=['year'], ascending=False)\nsales_train_22_year_df=sales_train_mon_df[sales_train_mon_df['shop_id']==22].groupby('year')['item_price'].sum().to_frame().reset_index().sort_values(by=['year'], ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_23_year_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\n# plot chart\nax1 = plt.subplot(131, aspect='equal')\nsales_train_26_year_df.plot(kind='pie', y = 'item_price', ax=ax1, autopct='%1.1f%%',title='shop_26' ,\n startangle=90, shadow=False, labels=sales_train_26_year_df['year'], legend = False, fontsize=14)\nax2 = plt.subplot(132, aspect='equal')\nsales_train_23_year_df.plot(kind='pie', y = 'item_price', ax=ax2, autopct='%1.1f%%', title='shop_23' ,\n startangle=90, shadow=False, labels=sales_train_23_year_df['year'], legend = False, fontsize=14)\nax3 = plt.subplot(133, aspect='equal')\nsales_train_22_year_df.plot(kind='pie', y = 'item_price', ax=ax3, autopct='%1.1f%%', title='shop_22' ,\n startangle=90, shadow=False, labels=sales_train_22_year_df['year'], legend = False, fontsize=14)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*2014 was the best for shops 26 and 22. Shop 23 has sold items only on 2013.*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"****","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}