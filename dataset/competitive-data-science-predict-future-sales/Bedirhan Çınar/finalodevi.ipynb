{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Verileri data kısmına input olarak kaggle üzerinden çekip tabloları gösteriyoruz.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nimport matplotlib as mpl\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ntrain = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv' )\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\nsubmission = pd.read_csv('../input/competitive-data-science-predict-future-sales/sample_submission.csv')\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nitem_cats = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\n\n\n\nprint(\"shops \\n \")\nprint(shops)\n\nprint(\" \\n \\n \\nitems \\n \")\nprint(items)\n\nprint(\" \\n \\n \\n item_cats \\n \")\nprint(item_cats)\n\nprint(\" \\n \\n \\n submission \\n \")\nprint(submission)\n\nprint(\" \\n \\n \\n train \\n \")\nprint(train)\n\nprint(\" \\n \\n \\n test \\n \" )\nprint(test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train dataların olduğu tablo ile items tablosunu birleştiriyoruz bunun için pandasın merge fonksiyonunu kulanıyoruz.  Amacımız item_id sayısı çok fazla olduğu için bunu 84 tane olan kategori sayısı ile sınırlandırmak . Train tablosu  test tablosuna benzer hale getirip bu 2 verili tablolar üzerinden bir kümeleme yapabilmek. Shop id si üzerinden category id tahmini yaptırmaya çalışıyoruz. Çok fazla kategori olduğu için iyi bir sonuç beklemiyorum. Daha sonraki kısımlarda daha iyi veriler elde edeceğiz.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = pd.merge(train[['date','shop_id','item_id']], items, how='outer', on='item_id')\ntraindata=traindata.drop_duplicates(subset=['item_category_id', 'shop_id'], keep='first').sort_values(by=['item_category_id'])\ntraindata = traindata[['shop_id','item_category_id']].dropna()\n\n\n\ntestdata = pd.merge(test, items, how='inner', on='item_id')\ntestdata=testdata.drop_duplicates(subset=['item_category_id', 'shop_id'], keep='first').sort_values(by=['item_category_id'])\n\ntestdata = testdata[['shop_id','item_category_id']].dropna()\n\n\n\n\nprint(traindata.head(100))\n\nprint(testdata)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Yukarıda bahsettiğimiz sınıflama işleminin gerçekleştirildiği bölüm burasıdır. SVM destek vektör makineleri ile sınıflandırma yapıyoruz ve 0,016 gibi çok kötü bir sonuç elde ediyoruz. Daha sonraki örnekte çok daha yüksek değerlerle daha tahmin edilebilir ve sınıflandırılabilir veriler üzerinden çalışacağız.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn import svm\n\n\ntrainx = traindata.iloc[:, :1]\ntrainy=traindata.iloc[:, 1:2]\n\ntestx=testdata.iloc[:, :1]\ntesty=testdata.iloc[:, 1:2]\n\nclf = svm.SVC()\nclf.fit(trainx, trainy)\npred=clf.predict(testx)\n\n#print(testy.transpose())\n#print(pred)\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\n\nprint(\" \\n\\n accuracy score\")\nprint(accuracy_score(testy, pred))\nprint(\" \\n\\n f1 score\")\n\nf1_score(testy, pred, average =None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train ve test diye bize verilen tablolardan anlamlı bir sonuç almanın zorluğu ve özellikle test datasının sadece shop ve item id bilgisini içermesi bu iki tabloyu kullanarak yapabileceğimiz işlemleri kısıtladığı için daha farklı çözüm yollarına gidiyoruz. Ve sadece çok uzun olan train verisini kendi içinde test train diye ayırarak işlem yapmanın daha anlamlı sonuçlar almamızı sağlayacağını düşünerek bu şekilde işlemlere başlıyoruz.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Train datamızı detaylı görmek adına okurken date kolonunu tarih olarak alınmasını sağlıyoruz ve daha sonra set index fonksiyonu ile zaman bilgisini index olarak data frame veriyoruz. Veriyi gözlemlemek adına tablonun 1 aylık dönemlerinin ortalamasını alarak 3 milyona yakın veriyi aylık olarak gösteriyoruz.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nmydateparser = lambda x: pd.datetime.strptime(x, \"%d.%m.%Y\")\n\ntrain = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv',parse_dates=['date'], date_parser=mydateparser )\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\nsubmission = pd.read_csv('../input/competitive-data-science-predict-future-sales/sample_submission.csv')\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\nitem_cats = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\n\ntrain=train.set_index('date')\nprint(train)\n\n\nmontly  =train.resample('1M').mean()\n\nmontly","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# İlk olarak uyguladığımız dükkan id sine göre kategori tahmini 0 a yakın bir doğruluk oranı verdiği için başka bir deneme yapıyoruz ve bu sefer direk ham veriler üzerinden item id ile shop id yani ürün ile dükkan tahmini yapıyoruz  fakat bunun doğruluğuda 0.0238 çıkıyor ve train - test tablosu üzerinden anlamlı bir şeyler çıkmayacağına karar kılıyoruz.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.item_id<50]\ntest = test[test.item_id<50]\n\n\n\ntrainx = train[['item_id','shop_id']].iloc[:, :1]\ntrainy=train[['item_id','shop_id']].iloc[:, 1:2]\n\ntestx=test[['item_id','shop_id']].iloc[:, :1]\ntesty=test[['item_id','shop_id']].iloc[:, 1:2]\n\nclf = svm.SVC()\nclf.fit(trainx, trainy)\npred=clf.predict(testx)\n\n#print(testy.transpose())\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\n\nprint(\" \\n\\n accuracy score\")\nprint(accuracy_score(testy, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Bu kısımda artık train data üzeinden test ve train datamızı oluşturacak ve anlamlı bir sonuç üretmeye çalışacağız. Verimizi tekrar date indexi  ile tarih formatıyla alıyoruz.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mydateparser = lambda x: pd.datetime.strptime(x, \"%d.%m.%Y\")\n\ntrain = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv',parse_dates=['date'], date_parser=mydateparser )\n\ntrain=train.set_index('date')\nprint(train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Veriyi daha iyi anlamak için item id ve item fiyatlarını dükkan id si 0 olan dükkan üzerinden çizdirerek  inceliyoruz ve yapacağımız modele karar veriyoruz.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df=train[train.shop_id==0]\nsns.catplot(x=\"item_id\",y=\"item_price\",data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dükkanları kendi içerisinde dükkan idlerine göre gruplayıp ortalamalarını alıyoruz. Bu sayede o dükkanda satılan ürünlerin ortalama fiyatı ve ortalama adedi bilgisini elde etmek istiyoruz. Daha sonda bu dükkanlardan ortalama ürün fiyatı 1000 liranın üzerinde olan dükkanlara YüksekKar etiketi ekliyoruz. Eğer ürünlerinin ortalaması 1000 üzerindeyse yüksekkar değeri true  değilse false çeklinde olacak. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=train.groupby(['shop_id']).mean()\ndf2['YüksekKar']=df2.item_price > 1000\n\ndf2\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Eldeki veriyi 2 kolonlu bir hale getiriyoruz dükkanda satılan ortalama ürün adedi üzerinden bu dükkanın yüksek kar diye tabir ettiğimiz ortalama ürün fiyatı 1000 tl üstünde bir dükkan olup olmadığının tahmin edilmesini istiyoruz. Bunu iki farklı yöntem ile yapacağız önce yukarıda da kullandığımız svm ile daha sonra **KERAS** kullanarak yaptığımız ANN sinir ağları ile modelleyip elde ettiğimiz sonuçlara bakacağız.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\n\n\ntrainx = df2[['item_cnt_day','YüksekKar']].iloc[:49, :1]\ntrainy = df2[['item_cnt_day','YüksekKar']].iloc[:49, 1:2]\n\n\n\ntestx = df2[['item_cnt_day','YüksekKar']].iloc[49:, :1]\ntesty = df2[['item_cnt_day','YüksekKar']].iloc[49:, 1:2]\n\n\n\nclf = svm.SVC()\nclf.fit(trainx, trainy)\npred=clf.predict(testx)\n\n#print(testy.transpose())\n#print(pred)\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\n\nprint(\" \\n\\n accuracy score\")\nprint(accuracy_score(testy, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM  sınıflandırma yaptığımızda elde ettiğimiz sonuç çok yüksek olmasada ilk başta yaptığımız çok kötü tahminlere göre oldukça iyi düzeyde %81 in üzerinde bir doğruluk oranı ile dükkanların sattığı ortalama ürün üzerinden dükkanların ortalama ürün fiyatının 1000 tl nin üzerinde olup olmadığını tahmin ediyor. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Şimdi ise aynı işlemi KERAS üzerinden Neural Network  yapay sinir ağları ile modelleyelim. 1 giriş 1 çıkış ve 2 adet gizli katmanı bulunan bir model tanımlıyoruz. Yukarıda verdiğimiz verinin aynısını veri olarak veriyoruz. 3 vs 2 node olan 2 adet gizli katmanımız 1 adet girdi ve 1 adet çıktı bilgisi içeren düğümümüz yer alıyor. 100 kez epoch ettiriyoruz ve batch_size ımızı 10 olarak ayarlıyoruz. Bu şekilde elde ettiğimiz sonuç %70 lerde kalıyor. \n\n\n\n\n\n# Keras ile nn denememiz svm in classification modellemesine göre daha düşük bir doğruluk oranı veriyor. Bu şekilde 2 farklı yöntem ile birden fazla şekilde test işlemi gerçekleştiriyoruz.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\n\nX = df2[['item_cnt_day','YüksekKar']].iloc[:, :1]\ny = df2[['item_cnt_day','YüksekKar']].iloc[:, 1:2]\n\nmodel = Sequential()\nmodel.add(Dense(3, input_dim=1, activation='relu'))\nmodel.add(Dense(2, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n\nmodel.fit(X, y, epochs=100, batch_size=10)\n\n_, accuracy = model.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sınıflandırma yaparken girdi olarak kullandığımız bir dükkandaki ortalama ürün sayısının şirketlere göre dağılımını görüyoruz buradan dükkanlardaki satılan ürün sayısının genelde 1 ile 1.5 arasına toplandığını görmekteyiz.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[['item_cnt_day','YüksekKar']].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Projenin amacı kapsamında her dükkan ve her ürün için adet hesaplanması yapılmak istendiğinde train tablosuna join ile yeni veriler eklenir.Ve tablodaki bazı gürültüler temizlenir Örneğin satılan ürün sayısında -1 gibi negatif sayılar tabloda olabiliyor. Bu tarz verilerin temizlenmesi.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mydateparser = lambda x: pd.datetime.strptime(x, \"%d.%m.%Y\")\n\ntrain = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv',parse_dates=['date'], date_parser=mydateparser )   #train tablosu date kolonu tarih formatında olacak şekilde okunur\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\n\ntrain=train.set_index('date')  #date kolonu tarih formatında okunduktan sonra index yapılır\n\ntrain= train[train.item_cnt_day>0]  # yanlış girilen gürültülü item bilgileri temizlenir\n\n#traindata = pd.merge(train , items, how='left', on='item_id')    #bu kod ile items tablosu ile train tablosu join yapılır  on kısmında belirtilen parametre üzerinden bu gerçekleştirilir. \n#Bu işlem ek gürültü oluşturduğundan performansı düşürüyor o yüzden kullanılmayıp yorum satırına alınmıştır.\n\n#traindata=traindata.drop_duplicates(subset=['item_category_id', 'shop_id'], keep='first') # tekrar eden veri varsa silinir.\n#traindata = traindata[['shop_id','item_category_id']].dropna()\n\n\n\n\n\nfrom numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\n\nX = train.iloc[:, :4]    # tablonun ilk 4 kolonu aradığımız sonucun bulunması için verilecek datalar olarak ayarlanır.\ny = train.iloc[:, 4:5]  # tablonun 5. kolonu tahmin edilmesi istenen kısımdır. Yani item sayısı\n\nmodel = Sequential()\nmodel.add(Dense(4, input_dim=4, activation='relu'))   #4 input alan o 4 inputtan 4 düğümlü gizli katmana geçen ilk gizli katman oluşturulur.\nmodel.add(Dense(8, activation='relu'))                #1. gizli katmandan veri alan  8 düğümden oluşan 2. gizli katman eklenir.\nmodel.add(Dense(1, activation='sigmoid'))             # Gizli katmanlardan 1 düğümlü çıkış katmanına gelindiği kısım eklenir. \n\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   #model için kullanılacak algoritma ve sonuçta çıkarılacak doğruluk metriği belirlenir.\n\n\nmodel.fit(X, y, epochs=2, batch_size=100)     #modelin kaç kez eğitileceği kaç epoch dan oluşacağı ve verilerin kaçar kaçar verileceği belirlenir.\n\n_, accuracy = model.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))     # doğruluk değeri bastırılır.\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}