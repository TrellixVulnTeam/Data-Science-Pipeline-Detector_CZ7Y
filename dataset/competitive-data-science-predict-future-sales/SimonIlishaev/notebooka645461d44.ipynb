{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Introduction"},{"metadata":{},"cell_type":"markdown","source":"The goal of the competition to predict future sales of items in set of '1C' company's stores for one month given historical data."},{"metadata":{},"cell_type":"markdown","source":"#### Libraries and data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport re #regular expressions\nimport os\nimport time\nimport pickle \nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom itertools import product\nfrom xgboost import XGBRegressor, plot_importance\nfrom matplotlib.pylab import rcParams\nfrom sklearn.preprocessing import LabelEncoder\n\nsns.set(style=\"darkgrid\")\nrcParams['figure.figsize'] = 12, 4","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\nshops = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\ncats = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\ntrain = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\ntest = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"### Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 4))\nplt.xlim(-100, 3000)\nflierprops = dict(marker='o', markerfacecolor='green', markersize=6,\n                  linestyle='none', markeredgecolor='black') #style of outliers\nsns.boxplot(x=train.item_cnt_day, flierprops=flierprops)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price, flierprops=flierprops)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove outliers, chosing thresholds visually - the items sold more than 1000 in one day, and the item with price higher than 300 thounds."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = (\n    train\n    [\n        (train['item_price'] > 0) &\n        (train['item_price'] < 300000) &\n        (train['item_cnt_day'] < 1000)\n    ]\n    .reset_index(drop = True)\n)\n\ntrain.loc[train['item_cnt_day'] < 0, 'item_cnt_day'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also remove rows with negative price value and make zero negative item_cnt_day."},{"metadata":{},"cell_type":"markdown","source":"### Shop Dataframe Cleaning"},{"metadata":{},"cell_type":"markdown","source":"Several entries looks like the data for same stores but for different period."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [(0, 57), (1, 58), (10, 11)]:\n    train.loc[train['shop_id'] == i[0], 'shop_id'] = i[1]\n    test.loc[test['shop_id'] == i[0], 'shop_id'] = i[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Change some shop names and add 'city' and 'category' columns to dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.loc[shops['shop_name'] == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\nshops['city'] = shops.shop_name.str.split(' ').map(lambda x: x[0])\nshops['category'] = shops.shop_name.str.split(' ').map(lambda x: x[1])\nshops.loc[shops['city'] == '!Якутск', 'city'] = 'Якутск'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use only large enough categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = []\nfor categ in shops['category'].unique():\n    if len(shops[shops['category'] == categ]) > 4:\n        categories.append(categ)\nshops['category'] = shops['category'].apply(lambda x: x if x in categories else 'other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops['shop_category'] = LabelEncoder().fit_transform(shops['category'])\nshops['shop_city'] = LabelEncoder().fit_transform(shops['city'])\nshops = shops[['shop_id', 'shop_category', 'shop_city']]\n#shops","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Item Categories Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"cats['type_code'] = (\n    cats['item_category_name']\n    .apply(\n        lambda x: x.split(' ')[0]\n    )\n    .astype(str)\n)\ncats.loc[\n    (cats['type_code'] == 'Игровые') |\n    (cats['type_code'] == 'Аксессуары'),\n    'category'\n] = 'Игры'\n#cats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = []\nfor categ in cats['type_code'].unique():\n    if len(cats[cats['type_code'] == categ]) > 4: \n        categories.append(categ)\ncats['type_code'] = cats['type_code'].apply(lambda x: x if x in categories else 'etc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats['type_code'] = LabelEncoder().fit_transform(cats['type_code'])\ncats['split'] = (\n    cats['item_category_name']\n    .apply(lambda x: x.split('-'))\n)\ncats['subtype'] = (\n    cats['split']\n    .apply(\n        lambda x: x[1].strip() if len(x) >= 2 else x[0].strip()\n    )\n)\ncats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\ncats = cats[['item_category_id', 'subtype_code', 'type_code']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Item Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def name_correction(x):\n    x = x.lower() #lower case\n    x = x.partition('[')[0] # partition by square brackets\n    x = x.partition('(')[0] # partition by curly brackets\n    x = re.sub('\\W+', ' ', x) # remove special characters\n    x = x.replace('  ', ' ') # replace double spaces with single spaces\n    x = x.strip() # remove leading and trailing white space\n    return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean item names"},{"metadata":{"trusted":true},"cell_type":"code","source":"# split item names by first bracket\nitems['name1'], items['name2'] = items['item_name'].str.split('[', 1).str\nitems['name1'], items['name3'] = items['item_name'].str.split('(', 1).str\n\n# replace special characters and turn to lower case\nitems['name2'] = items['name2'].str.replace('\\W+', ' ').str.lower()\nitems['name3'] = items['name3'].str.replace('\\W+', ' ').str.lower()\n\n# fill nulls with '0'\nitems = items.fillna('0')\n\nitems['item_name'] = items['item_name'].apply(lambda x: name_correction(x))\n\n# return all characters except the last if name 2 is not \"0\" - the closing bracket\nitems['name2'] = items['name2'].apply(lambda x: x[:-1] if x != '0' else '0')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean item type"},{"metadata":{"trusted":true},"cell_type":"code","source":"items['type'] = (\n    items['name2']\n    .apply(\n        lambda x: x[0:8] if x.split(' ')[0] == 'xbox' else x.split(' ')[0]\n    )\n)\n\nitems.loc[\n    (items['type'] == 'x360') |\n    (items['type'] == 'xbox360') |\n    (items['type'] == 'xbox 360'),\n    'type'\n] = 'xbox 360'\nitems.loc[items['type'] == '', 'type'] = 'mac'\nitems.type = (\n    items['type']\n    .apply(\n        lambda x: x.replace(' ', '')\n    )\n)\nitems.loc[\n    (items['type'] == 'pc' ) |\n    (items['type'] == 'pс') |\n    (items['type'] == 'pс'),\n    'type'\n] = 'pс'\n\nitems.loc[items['type'] == 'рs3' , 'type'] = 'рs3'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_sum = (\n    items\n    .groupby('type')\n    .agg({'item_id': 'count'})\n    .reset_index()\n)\n\ndrop_cols = []\nfor categ in group_sum['type'].unique():\n    if group_sum.loc[(group_sum['type'] == categ), 'item_id'].values[0] <= 39:\n        drop_cols.append(categ)\n\nitems['name2'] = (\n    items['name2']\n    .apply(\n        lambda x: 'other' if x in drop_cols else x\n    )\n)\nitems = items.drop(['type'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items['name2'] = LabelEncoder().fit_transform(items['name2'])\nitems['name3'] = LabelEncoder().fit_transform(items['name3'])\n\nitems.drop(['item_name', 'name1'], axis=1, inplace=True)\n#items.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data preparation & Feature Enginering"},{"metadata":{},"cell_type":"markdown","source":"Create matrix format dataframe for every month, shop and item id to aggregate data to monthly data. 'Item_cnt_day' summed up to ' item_cnt_month'."},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = []\ncols  = ['date_block_num', 'shop_id', 'item_id']\nfor i in range(34):\n    sales = train[train['date_block_num'] == i]\n    matrix.append(\n        np.array(\n            list(product(\n                [i],\n                sales['shop_id'].unique(),\n                sales['item_id'].unique()\n            )),\n            dtype = np.int16\n        )\n    )\n\nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\nmatrix = matrix.astype({\n    'date_block_num': np.int8, \n    'shop_id': np.int8, \n    'item_id': np.int16\n})\nmatrix.sort_values(cols, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create revenue column\ntrain['revenue'] = train['item_cnt_day'] * train['item_price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = (\n    train\n    .groupby(['date_block_num', 'shop_id', 'item_id'])\n    .agg({\n        'item_cnt_day': 'sum'\n    })\n)\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (\n    matrix['item_cnt_month']\n    .fillna(0)\n    .astype(np.float16)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create test set for 34th month.\ntest['date_block_num'] = 34\ntest = (\n    test\n    .astype({\n        'date_block_num': np.int8, \n        'shop_id': np.int8, \n        'item_id': np.int16\n    })\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Concatenate train and test\nmatrix = pd.concat(\n    [matrix, test.drop(['ID'], axis=1)],\n    ignore_index=True, sort=False, keys=cols\n)\nmatrix.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add all our data categories to matrix\nmatrix = pd.merge(matrix, shops, on='shop_id', how='left')\nmatrix = pd.merge(matrix, items, on='item_id', how='left')\nmatrix = pd.merge(matrix, cats, on='item_category_id', how='left')\nmatrix = (\n    matrix\n    .astype({\n        'shop_city': np.int8,\n        'shop_category': np.int8,\n        'item_category_id': np.int8,\n        'subtype_code': np.int8,\n        'name2': np.int8,\n        'name3': np.int16,\n        'type_code': np.int8\n    })\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Enginering. Add lags to matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define a lag feature function\ndef lag_feature(df, lags, cols):\n    for col in cols:\n        tmp = df[['date_block_num', 'shop_id', 'item_id', col]]\n        for i in lags:\n            shifted = tmp.copy()\n            shifted.columns = ['date_block_num', 'shop_id', 'item_id', col + \"_lag_\" + str(i)]\n            shifted['date_block_num'] = shifted['date_block_num'] + i\n            df = pd.merge(df, shifted, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add item_cnt_month lag features.\nmatrix = lag_feature(matrix, [1, 2, 3], ['item_cnt_month'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add the previous month's average item_cnt.\ngroup = (\n    matrix\n    .groupby('date_block_num')\n    .agg({\n        'item_cnt_month' : 'mean'\n    })\n)\ngroup.columns = ['date_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on='date_block_num', how=\"left\")\nmatrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_avg_item_cnt'])\nmatrix.drop(['date_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add lag values of item_cnt_month for month / item_id.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'item_id'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_item_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id'], how='left')\nmatrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1, 2, 3], ['date_item_avg_item_cnt'])\nmatrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add lag values for item_cnt_month for every month / shop combination.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'shop_id'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_shop_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id'], how='left')\nmatrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1, 2, 3], ['date_shop_avg_item_cnt'])\nmatrix.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add lag values for item_cnt_month for month/shop/item.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'shop_id', 'item_id'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_shop_item_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_id'], how='left')\nmatrix['date_shop_item_avg_item_cnt'] = matrix['date_shop_item_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1, 2, 3], ['date_shop_item_avg_item_cnt'])\nmatrix.drop(['date_shop_item_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add lag values for item_cnt_month for month/shop/item subtype.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'shop_id', 'subtype_code'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_shop_subtype_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\nmatrix['date_shop_subtype_avg_item_cnt'] = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_shop_subtype_avg_item_cnt'])\nmatrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add lag values for item_cnt_month for month/city.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'shop_city'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_city_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_city'], how='left')\nmatrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_city_avg_item_cnt'])\nmatrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add lag values for item_cnt_month for month/city/item.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'item_id', 'shop_city'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_item_city_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_city'], how='left')\nmatrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_item_city_avg_item_cnt'])\nmatrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Add average item price to matix. \n* Add lag values of item price per month.\n* Add delta price values - how current month average pirce relates to global average."},{"metadata":{"trusted":true},"cell_type":"code","source":"group = (\n    train\n    .groupby('item_id')\n    .agg({\n        'item_price': 'mean'\n    })\n)\ngroup.columns = ['item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = matrix.merge(group, on='item_id', how='left')\nmatrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n\n\ngroup = (\n    train\n    .groupby(['date_block_num', 'item_id'])\n    .agg({\n        'item_price': 'mean'\n    })\n)\ngroup.columns = ['date_item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = matrix.merge(group, on=['date_block_num', 'item_id'], how='left')\nmatrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\nlags = [1, 2, 3]\nmatrix = lag_feature(matrix, lags, ['date_item_avg_item_price'])\n\nfor i in lags:\n    matrix['delta_price_lag_' + str(i)] = (\n        matrix['date_item_avg_item_price_lag_' + str(i)] -\\\n        matrix['item_avg_item_price']\n    ) / matrix['item_avg_item_price']\n\ndef select_trends(row) :\n    for i in lags:\n        if row['delta_price_lag_' + str(i)]:\n            return row['delta_price_lag_' + str(i)]\n    return 0\n\nmatrix['delta_price_lag_'] = matrix.apply(select_trends, axis=1)\nmatrix['delta_price_lag_'] = matrix['delta_price_lag_'].astype(np.float16)\nmatrix['delta_price_lag_'].fillna(0, inplace=True)\n\nfeatures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\nfor i in lags:\n    features_to_drop.append('date_item_avg_item_price_lag_' + str(i))\n    features_to_drop.append('delta_price_lag_' + str(i))\nmatrix.drop(features_to_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Add total shop revenue per month to matrix. \n* Add lag values of revenue per month.\n* Add delta revenue values - how current month revenue relates to global average. "},{"metadata":{"trusted":true},"cell_type":"code","source":"group = (\n    train\n    .groupby(['date_block_num', 'shop_id'])\n    .agg({\n        'revenue': 'sum'\n    })\n)\ngroup.columns = ['date_shop_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = matrix.merge(group, on=['date_block_num', 'shop_id'], how='left')\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n\ngroup = (\n    group\n    .groupby('shop_id')\n    .agg({\n        'date_block_num': 'mean'\n    })\n)\ngroup.columns = ['shop_avg_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = matrix.merge(group, on='shop_id', how='left')\nmatrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\nmatrix['delta_revenue'] = (\n    matrix['date_shop_revenue'] - matrix['shop_avg_revenue']\n) / matrix['shop_avg_revenue']\nmatrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float32)\n\nmatrix = lag_feature(matrix, [1], ['delta_revenue'])\nmatrix['delta_revenue_lag_1'] = matrix['delta_revenue_lag_1'].astype(np.float32)\nmatrix.drop(\n    ['date_shop_revenue', 'shop_avg_revenue', 'delta_revenue'],\n    axis=1, inplace=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add month and number of days in each month to matrix\nmatrix['month'] = matrix['date_block_num'] % 12\ndays = pd.Series([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\nmatrix['days'] = matrix['month'].map(days).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add the month of each shop and item first sale.\nmatrix['item_shop_first_sale'] = (\n    matrix['date_block_num'] - matrix.groupby(['item_id', 'shop_id'])['date_block_num'].transform('min')\n)\nmatrix['item_first_sale'] = (\n    matrix['date_block_num'] - matrix.groupby(['item_id'])['date_block_num'].transform('min')\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Delete first three months from matrix. They don't have lag values.\nmatrix = matrix[matrix['date_block_num'] >= 4]\nmatrix.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Modelling"},{"metadata":{},"cell_type":"markdown","source":"### xgboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = matrix.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['date_block_num'] == 34].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use month 34 as validation for training.\nX_train = data[data.date_block_num <= 32].drop(['item_cnt_month'], axis=1)\nY_train = data[data.date_block_num <= 32]['item_cnt_month']\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = Y_train.clip(0, 20)\nY_valid = Y_valid.clip(0, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBRegressor(\n    max_depth=10,\n    n_estimators=1000,\n    min_child_weight=0.5, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,\n    seed=42\n)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric='rmse',\n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds=20\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict(X_valid).clip(0, 20)\nY_test = model.predict(X_test).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    'ID': test.index, \n    'item_cnt_month': Y_test\n})\nsubmission.to_csv('xgb_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1, 1, figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nplot_features(model, (10, 14))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}