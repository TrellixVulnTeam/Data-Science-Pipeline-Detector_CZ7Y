{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-22T11:19:55.08877Z","iopub.execute_input":"2022-01-22T11:19:55.089601Z","iopub.status.idle":"2022-01-22T11:19:55.100064Z","shell.execute_reply.started":"2022-01-22T11:19:55.089562Z","shell.execute_reply":"2022-01-22T11:19:55.099115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import Libraries","metadata":{}},{"cell_type":"code","source":"\nfrom operator import index\nfrom pyexpat.errors import XML_ERROR_TEXT_DECL\nfrom turtle import home\nfrom unicodedata import category\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import rand\nimport seaborn as sns\n\nfrom sklearn.metrics import mean_squared_error\n\nSeed = 42\nnp.random.seed(Seed)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:19:55.101618Z","iopub.execute_input":"2022-01-22T11:19:55.101896Z","iopub.status.idle":"2022-01-22T11:19:55.110389Z","shell.execute_reply.started":"2022-01-22T11:19:55.101859Z","shell.execute_reply":"2022-01-22T11:19:55.109559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build Funcitons\n","metadata":{}},{"cell_type":"code","source":"# Build Funcitons\n\ndef save_csv(y_pred, file_name):\n    submit = pd.read_csv(path + 'sample_submission.csv')\n    submit['item_cnt_month'] = y_pred\n    submit.to_csv(file_name, index = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:19:55.112064Z","iopub.execute_input":"2022-01-22T11:19:55.112603Z","iopub.status.idle":"2022-01-22T11:19:55.120941Z","shell.execute_reply.started":"2022-01-22T11:19:55.112565Z","shell.execute_reply":"2022-01-22T11:19:55.120266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the datasets","metadata":{}},{"cell_type":"code","source":"# Load the datasets\npath = '/kaggle/input/competitive-data-science-predict-future-sales/'\n\ntrain = pd.read_csv(path + './sales_train.csv')\n\nshops = pd.read_csv(path + 'shops.csv')\nitems = pd.read_csv(path + 'items.csv')\nitem_categories = pd.read_csv(path + 'item_categories.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:19:55.123977Z","iopub.execute_input":"2022-01-22T11:19:55.124199Z","iopub.status.idle":"2022-01-22T11:19:56.668676Z","shell.execute_reply.started":"2022-01-22T11:19:55.124165Z","shell.execute_reply":"2022-01-22T11:19:56.66798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### merge categories_id in train set\n- merge categories_id in train set\n* drop string feature from dataset\n* change negative values in item_cnt_day feature","metadata":{}},{"cell_type":"code","source":"# merge categories_id in train set\ntrain = train.merge(right=items, how='inner', on='item_id')\n\n# drop string feature from dataset\ntrain.drop(labels=['item_name'], axis = 1, inplace=True)\n\n# change negative values in item_cnt_day feature\ntrain['item_cnt_day'] = np.abs(train['item_cnt_day'])\n\ngrouped_train = train.groupby(by=['date_block_num', 'shop_id', 'item_category_id', 'item_id'], ).agg({'item_cnt_day':sum}).reset_index()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:19:56.669877Z","iopub.execute_input":"2022-01-22T11:19:56.670205Z","iopub.status.idle":"2022-01-22T11:19:58.157913Z","shell.execute_reply.started":"2022-01-22T11:19:56.670167Z","shell.execute_reply":"2022-01-22T11:19:58.157196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Shffle the dataframe first to random the rows\n* split target from train 'item_cnt_day'\n* drop item_cnt_day and date_block_num features","metadata":{}},{"cell_type":"code","source":"# Shffle the dataframe first to random the rows\ngrouped_train = grouped_train.sample(frac=1, random_state=Seed)\n\n# split target from train 'item_cnt_day'\ntarget  = grouped_train['item_cnt_day']\n\n# drop item_cnt_day and date_block_num features\ngrouped_train.drop(labels=['item_cnt_day', 'date_block_num'], axis =1, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:19:58.159303Z","iopub.execute_input":"2022-01-22T11:19:58.15955Z","iopub.status.idle":"2022-01-22T11:19:58.333144Z","shell.execute_reply.started":"2022-01-22T11:19:58.159517Z","shell.execute_reply":"2022-01-22T11:19:58.332424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### show the correlation between features","metadata":{}},{"cell_type":"code","source":"grouped_train.describe()\n\nsns.heatmap(grouped_train.corr())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:19:58.334587Z","iopub.execute_input":"2022-01-22T11:19:58.334848Z","iopub.status.idle":"2022-01-22T11:19:58.750416Z","shell.execute_reply.started":"2022-01-22T11:19:58.334814Z","shell.execute_reply":"2022-01-22T11:19:58.749728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Split Train and valid data","metadata":{}},{"cell_type":"code","source":"# Split Train and valid data\nfrom sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(grouped_train, target, test_size=10_000)\n\nx_train.shape, x_valid.shape, y_train.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:19:58.751478Z","iopub.execute_input":"2022-01-22T11:19:58.752031Z","iopub.status.idle":"2022-01-22T11:19:58.89891Z","shell.execute_reply.started":"2022-01-22T11:19:58.751991Z","shell.execute_reply":"2022-01-22T11:19:58.898069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prepare test data","metadata":{}},{"cell_type":"code","source":"# Prepare test data\ntest = pd.read_csv(path + 'test.csv')\n\ntest = test.merge(right=items, how='inner', on='item_id')\nx_test = test.drop(labels=['item_name', 'ID'], axis=1)\n\n# change the order of features ['shop_id', 'item_id', 'item_category_id'] to ['shop_id', 'item_category_id', 'item_id']\nx_test = x_test[['shop_id', 'item_category_id', 'item_id']]\n","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:19:58.900272Z","iopub.execute_input":"2022-01-22T11:19:58.900591Z","iopub.status.idle":"2022-01-22T11:19:58.981713Z","shell.execute_reply.started":"2022-01-22T11:19:58.900553Z","shell.execute_reply":"2022-01-22T11:19:58.980963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scale the features","metadata":{}},{"cell_type":"code","source":"# Scale the data using StandardScaler\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_valid = sc.transform(x_valid)\nx_test = sc.transform(x_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:19:58.983131Z","iopub.execute_input":"2022-01-22T11:19:58.983403Z","iopub.status.idle":"2022-01-22T11:19:59.101885Z","shell.execute_reply.started":"2022-01-22T11:19:58.983367Z","shell.execute_reply":"2022-01-22T11:19:59.101153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Build the Models","metadata":{}},{"cell_type":"markdown","source":"##### 1 - RandomForest Algorithm","metadata":{}},{"cell_type":"code","source":"''' 1- Random Forest Model'''\nfrom sklearn.ensemble import RandomForestRegressor\nrnd_reg = RandomForestRegressor(n_estimators=150, max_depth=20, random_state=Seed, \n    n_jobs=-1, criterion='mse')\n\nprint('Training the data....')\nrnd_reg.fit(x_train, y_train)\n\n# Score the model\nprint('Model Accuracy...')\nscore = rnd_reg.score(x_valid, y_valid)\nprint(score)\n\n# Model RMSE\nprint('Model RMSE...')\ny_pred_valid_rnd = rnd_reg.predict(x_valid)\nrmse_rnd = mean_squared_error(y_valid, y_pred_valid_rnd, squared=False)\nprint(rmse_rnd)\n\n# predict the test set\nprint('Predict the test data...')\ny_pred_rnd = rnd_reg.predict(x_test)\ny_pred_rnd = np.round(y_pred_rnd).astype(np.int64)\nprint(y_pred_rnd)\n\n# Save the result\nprint('Save the prediction in submission file')\nsave_csv(y_pred_rnd, file_name = 'submission_solution_rnd_reg.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-22T06:26:31.946636Z","iopub.execute_input":"2022-01-22T06:26:31.946993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 2- Suppor Vector Machine","metadata":{}},{"cell_type":"code","source":"# ''' 2- Suppor Vector Machine '''\n\n# from sklearn.svm import SVR\n# svr_reg = SVR()\n\n# print('Training the data....')\n# svr_reg.fit(x_train, y_train)\n\n# # Score the model\n# print('Model Accuracy...')\n# score = svr_reg.score(x_valid, y_valid)\n# print(score)\n\n# # Model RMSE\n# print('Model RMSE...')\n# y_pred_valid_svr = svr_reg.predict(x_valid)\n# rmse_svr = mean_squared_error(y_valid, y_pred_valid_svr, squared=False)\n# print(rmse_svr)\n\n# # predict the test set\n# print('Predict the test data...')\n# y_pred_svr = svr_reg.predict(x_test)\n# y_pred_svr = np.round(y_pred_svr).astype(np.int64)\n# print(y_pred_svr)\n\n# # Save the result\n# print('Save the prediction in submission file')\n# save_csv(y_pred_svr, file_name = 'submission_solution_svr_reg.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-22T11:20:03.777421Z","iopub.execute_input":"2022-01-22T11:20:03.77795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 3- XGBRegressor","metadata":{}},{"cell_type":"code","source":"'''3- XGBoost'''\n\nimport xgboost as xg\nxg_reg = xg.XGBRegressor(n_estimators =120, learning_rate = .01, random_state = Seed, n_jobs = -1,)\n\n\nprint('Training the data....')\nxg_reg.fit(x_train, y_train)\n\n# Score the model\nprint('Model Accuracy...')\nscore = xg_reg.score(x_valid, y_valid)\nprint(score)\n\n# Model RMSE\nprint('Model RMSE...')\ny_pred_valid_xgb = xg_reg.predict(x_valid)\nrmse_xgb = mean_squared_error(y_valid, y_pred_valid_xgb, squared=False)\nprint(rmse_xgb)\n\n# predict the test set\nprint('Predicting the test data...')\ny_pred_xgb = xg_reg.predict(x_test)\ny_pred_xgb = np.round(y_pred_xgb).astype(np.int64)\nprint(y_pred_xgb)\n\n# Save the result\nprint('Saving the prediction in submission file')\nsave_csv(y_pred_xgb, file_name = 'submission_solution_xg_reg.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-22T10:09:09.536526Z","iopub.execute_input":"2022-01-22T10:09:09.538625Z","iopub.status.idle":"2022-01-22T10:09:10.015853Z","shell.execute_reply.started":"2022-01-22T10:09:09.538398Z","shell.execute_reply":"2022-01-22T10:09:10.014884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}