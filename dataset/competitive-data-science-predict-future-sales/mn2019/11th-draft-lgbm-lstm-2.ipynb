{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\nimport holidays\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nimport matplotlib.pyplot as plt\n\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = 'competitive-data-science-predict-future-sales'\nitem_categories = pd.read_csv('../input/' + PATH + '/item_categories.csv')\nitems = pd.read_csv('../input/' + PATH + '/items.csv')\nsales_train = pd.read_csv('../input/' + PATH + '/sales_train.csv')\nsubmission = pd.read_csv('../input/' + PATH + '/sample_submission.csv')\nshops = pd.read_csv('../input/' + PATH + '/shops.csv')\ntest = pd.read_csv('../input/' + PATH + '/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train['datetime'] = pd.to_datetime(sales_train['date'], format='%d.%m.%Y')\nsales_train['day'] = sales_train['datetime'].dt.day\nsales_train['month'] = sales_train['datetime'].dt.month\nsales_train['year'] = sales_train['datetime'].dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure, axe = plt.subplots(figsize = (8,6))\naxe.set_title(\" EDA Item Price VS  Sales Day\", weight=\"bold\")\n\nplot = plt.scatter(sales_train.item_price, sales_train.item_cnt_day)\nplt.xlabel('Item Price')\nplt.ylabel('Sales Day')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I remove outliers with very large item_price and item_cnt_day ."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train = sales_train[sales_train.item_price<300000]\nsales_train = sales_train[sales_train.item_cnt_day<2000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train[sales_train.item_price<0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One item_price is below zero. I replace it with median."},{"metadata":{"trusted":true},"cell_type":"code","source":"median = sales_train[sales_train.item_price>0].item_price.median()\nsales_train.loc[sales_train.item_price<0, 'item_price'] = median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train[sales_train.item_price<0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Several shops are duplicates of each other (according to its name). Fix train and test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Якутск Орджоникидзе, 56\nsales_train.loc[sales_train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\nsales_train.loc[sales_train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n# Жуковский ул. Чкалова 39м²\nsales_train.loc[sales_train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train['revenue'] = sales_train['item_cnt_day'] * sales_train['item_price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LightGBM"},{"metadata":{},"cell_type":"markdown","source":"I prepare number of weekdays and holidays in each month. "},{"metadata":{"trusted":true},"cell_type":"code","source":"ru_holidays = holidays.Russia()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_day_information = pd.DataFrame(index=[], columns=['year', 'month', 'days_in_month', 'weekdays_in_month', 'holidays_in_month'])\ni = 0\nfor year in [2013, 2014, 2015]:\n    if year==2015:\n        months = 11\n    else:\n        months = 12\n    for month in range(1,months+1):\n        if month==2:\n            days = 28\n        elif month==4 or month==6 or month==9 or month==11:\n            days = 30\n        else:\n            days = 31\n        count = 0\n        for day in range(1,days+1):\n            date = dt.datetime(year, month, day) \n            if date in ru_holidays or date.weekday()==5 or date.weekday()==6:\n                count += 1\n        df_day_information.loc[i] = [year, month, days, days-count, count]\n        i += 1\n\ndf_day_information","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first word of item_category_name represents large category of item. So I use it.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories[\"large_category\"] = item_categories.item_category_name.str.split(\" \").map( lambda x: x[0] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories[\"large_category\"] = LabelEncoder().fit_transform( item_categories.large_category )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first word of shop_name represents city. So I use it.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.loc[ shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"',\"shop_name\" ] = 'СергиевПосад ТЦ \"7Я\"'\nshops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] )\nshops.loc[shops.city == \"!Якутск\", \"city\"] = \"Якутск\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops[\"city\"] = LabelEncoder().fit_transform( shops.city )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features are added by following function. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_df_month(year, month, sales_train, test, df_day_information, items, item_categories, shops):\n    \n    if year==2015 and month==11:\n        df_month = test.loc[:, ['shop_id', 'item_id']]\n    else:\n        # add item_cnt_month\n        df = sales_train[(sales_train.year==year)&(sales_train.month==month)].groupby(['shop_id', 'item_id']).sum()\n        df_2 = pd.merge(test, df, on=['shop_id', 'item_id'], how='left')\n        df_2.fillna(0.0, inplace=True)\n        df_2.rename(columns={'item_cnt_day': 'item_cnt_month'}, inplace=True)\n        df_month = df_2.loc[:, ['shop_id', 'item_id', 'item_cnt_month']]\n        df_month['item_cnt_month'] = df_month.loc[:, 'item_cnt_month'].clip(0,20)\n    \n    # add year and month\n    df_month['year'] = year\n    df_month['year'] = df_month.loc[:,'year'].astype('int16')\n    df_month['month'] = month\n    df_month['month'] = df_month.loc[:,'month'].astype('int8')\n\n    # add item_category    \n    df_month = pd.merge(df_month, items, on=['item_id'], how='left')\n    df_month['item_category_id'] = df_month.loc[:,'item_category_id'].astype('int8')\n    df_month.drop('item_name', axis=1, inplace=True)\n\n    # add large_category\n    df_month = pd.merge(df_month, item_categories, on=['item_category_id'], how='left')\n    df_month['large_category'] = df_month.loc[:,'large_category'].astype('int8')\n    df_month.drop('item_category_name', axis=1, inplace=True)\n    \n    # add city category\n    df_month = pd.merge(df_month, shops, on=['shop_id'], how='left')\n    df_month['city'] = df_month.loc[:,'city'].astype('int8')\n    df_month.drop('shop_name', axis=1, inplace=True)\n\n    # add days_in_month, weekdays_in_month and holidays_in_month\n    days=df_day_information[(df_day_information.year==year)&(df_day_information.month==month)].loc[:,'days_in_month'].values[0]\n    df_month['days_in_month']=days\n    df_month['days_in_month'] = df_month.loc[:,'days_in_month'].astype('int8')\n    days=df_day_information[(df_day_information.year==year)&(df_day_information.month==month)].loc[:,'weekdays_in_month'].values[0]\n    df_month['weekdays_in_month']=days\n    df_month['weekdays_in_month'] = df_month.loc[:,'weekdays_in_month'].astype('int8')\n    days=df_day_information[(df_day_information.year==year)&(df_day_information.month==month)].loc[:,'holidays_in_month'].values[0]\n    df_month['holidays_in_month']=days\n    df_month['holidays_in_month'] = df_month.loc[:,'holidays_in_month'].astype('int8')\n\n    # add item_cnt_month, revenue and item_price for past three months and a year ago\n    for i in [1,2,3,12]:\n        month_2 = month - i\n        if month_2 <= 0:\n            year_2 = year - 1\n            month_2 += 12\n        else:\n            year_2 = year\n        df = sales_train[(sales_train.year==year_2)&(sales_train.month==month_2)].groupby(['shop_id', 'item_id']).sum()\n        df_2 = pd.merge(test, df, on=['shop_id', 'item_id'], how='left')\n        df_2.fillna(0.0, inplace=True)\n        df_2.rename(columns={'item_cnt_day': 'item_cnt_month'}, inplace=True)\n        df_month['item_cnt_month_lag_'+str(i)] = df_2['item_cnt_month'].clip(0,20)\n        df_month['revenue_lag_'+str(i)] = df_2['revenue']\n        if i <= 3:\n            df = sales_train[(sales_train.year==year_2)&(sales_train.month==month_2)].groupby(['shop_id', 'item_id']).mean()\n            df_2 = pd.merge(test, df, on=['shop_id', 'item_id'], how='left')\n            df_2.fillna(sales_train['item_price'].median(), inplace=True)\n            df_month['item_price_lag_'+str(i)] = df_2.loc[:, 'item_price']\n\n    # add item_cnt_month_mean and revenue_mean\n    for i in [6,12]:\n        j = (year-2013)*12 + (month-1)\n        df = sales_train[(sales_train.date_block_num>=j-i)&(sales_train.date_block_num<=j-1)].groupby(['shop_id', 'item_id']).mean()\n        df_2 = pd.merge(test, df, on=['shop_id', 'item_id'], how='left')\n        df_2.fillna(0.0, inplace=True)\n        df_2.rename(columns={'item_cnt_day': 'item_cnt_month'}, inplace=True)\n        df_month['item_cnt_month_mean_last_'+str(i)] = df_2['item_cnt_month'].clip(0,20)\n        df_month['revenue_mean_last_'+str(i)] = df_2['revenue']\n\n    # add item_cnt_month_std\n    for i in [6,12]:\n        j = (year-2013)*12 + (month-1)\n        df = sales_train[(sales_train.date_block_num>=j-i)&(sales_train.date_block_num<=j-1)].groupby(['shop_id', 'item_id']).std()\n        df_2 = pd.merge(test, df, on=['shop_id', 'item_id'], how='left')\n        df_2.fillna(0.0, inplace=True)\n        df_2.rename(columns={'item_cnt_day': 'item_cnt_month'}, inplace=True)\n        df_month['item_cnt_month_std_last_'+str(i)] = df_2['item_cnt_month']\n        df_month['revenue_std_last_'+str(i)] = df_2['revenue']\n\n    return df_month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfor year in [2014, 2015]:\n    if year==2015:\n        max = 11\n    else:\n        max = 12\n    for month in range(1,max+1):\n        i += 1\n        df_month = create_df_month(year, month, sales_train, test, df_day_information, items, item_categories, shops)\n        if i==1:\n            df_train_lgbm = df_month.copy()\n        elif year==2015 and month==10:\n            df_val_lgbm = df_month.copy()\n        elif year==2015 and month==11:\n            df_test_lgbm = df_month.copy()\n        else:\n            df_train_lgbm = pd.concat([df_train_lgbm, df_month], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_lgbm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"random sampling for cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_lgbm = df_train_lgbm.sample(frac=1, random_state=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lgbm = df_train_lgbm.drop('item_cnt_month', axis=1)\ny_train_lgbm = df_train_lgbm.loc[:, 'item_cnt_month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val_lgbm = df_val_lgbm.drop('item_cnt_month', axis=1)\ny_val_lgbm = df_val_lgbm.loc[:, 'item_cnt_month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_lgbm = df_test_lgbm.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_train_lgbm, df_val_lgbm, df_test_lgbm\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grid search (cv = 5 for cross validation)"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"learning_rate\":[0.1],\n          \"max_depth\": [6, 8, 10],\n          \"num_leaves\": [32, 64, 128],\n          \"n_estimators\":[100],\n          \"bagging_fraction\":[0.5],\n          \"feature_fraction\": [1.0],\n          \"min_data_in_leaf\": [5],\n          \"reg_alpha\": [0.1],\n          \"reg_lambda\": [1],\n          \"random_state\": [42],\n         }\n\n\nlgbm_model = LGBMRegressor()\n\ncv = GridSearchCV(lgbm_model, params, cv = 5, scoring= 'neg_root_mean_squared_error', n_jobs =-1, verbose=2)\ncv.fit(X_train_lgbm, y_train_lgbm)\nbest = cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cv.best_params_)\n\ncv_results = pd.DataFrame(cv.cv_results_)\ncv_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(-cv_results['mean_test_score'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I run LGBMRegressor with best parameters to show importance. "},{"metadata":{"trusted":true},"cell_type":"code","source":"params = cv.best_params_\n\nlgbm_model = LGBMRegressor(**params)\n\nlgbm_model.fit(X_train_lgbm, \n               y_train_lgbm, \n               eval_metric=\"rmse\",\n               eval_set=[(X_train_lgbm, y_train_lgbm), (X_val_lgbm, y_val_lgbm)], \n               verbose=10, \n               early_stopping_rounds = 40)\n\nlgb.plot_importance(lgbm_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"best\" is used for prediction. "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_lgbm = best.predict(X_test_lgbm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_df_month_lstm(year, month, sales_train, test):\n    \n    if year==2015 and month==11:\n        df_month = test.loc[:, ['shop_id', 'item_id']]\n    else:\n        # add item_cnt_month\n        df = sales_train[(sales_train.year==year)&(sales_train.month==month)].groupby(['shop_id', 'item_id']).sum()\n        df_2 = pd.merge(test, df, on=['shop_id', 'item_id'], how='left')\n        df_2.fillna(0.0, inplace=True)\n        df_2.rename(columns={'item_cnt_day': 'item_cnt_month'}, inplace=True)\n        df_month = df_2.loc[:, ['shop_id', 'item_id', 'item_cnt_month']]\n        df_month['item_cnt_month'] = df_month.loc[:,'item_cnt_month'].clip(0,20)\n\n    # add item_cnt_month for past 33 months\n    for i in range(33, 0, -1):\n        month_2 = month - i\n        year_2 = year\n        if month_2 <= 0:\n            year_2 = year - 1\n            month_2 += 12\n        if month_2 <= 0:\n            year_2 = year - 1\n            month_2 += 12\n        df = sales_train[(sales_train.year==year_2)&(sales_train.month==month_2)].groupby(['shop_id', 'item_id']).sum()\n        df_2 = pd.merge(test, df, on=['shop_id', 'item_id'], how='left')\n        df_2.fillna(0.0, inplace=True)\n        df_2.rename(columns={'item_cnt_day': 'item_cnt_month'}, inplace=True)\n        df_month['lag_'+str(i)] = df_2['item_cnt_month'].clip(0,20)\n       \n    return df_month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfor year in [2015]:\n    for month in range(10,12):\n        i += 1\n        df_month = create_df_month_lstm(year, month, sales_train, test)       \n        if i==1:\n            df_train_lstm = df_month.copy()\n        else:\n            df_test_lstm = df_month.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_lstm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"random sampling for cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_shuffle_lstm = df_train_lstm.sample(frac=1, random_state=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lstm = np.expand_dims(df_train_shuffle_lstm.drop(['item_cnt_month'], axis=1),axis=2)\ny_train_lstm = np.expand_dims(df_train_shuffle_lstm.loc[:,'item_cnt_month'].values, axis=1)\n\nprint(X_train_lstm.shape,y_train_lstm.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lstm = Sequential()\nmodel_lstm.add(LSTM(units = 64,input_shape = (30,1)))\nmodel_lstm.add(Dropout(0.4))\nmodel_lstm.add(Dense(1))\n\nmodel_lstm.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\nhistory = model_lstm.fit(X_train_lstm, y_train_lstm, batch_size=4096, epochs=EPOCHS,validation_split=0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(1, EPOCHS+1), history.history['mean_squared_error'], label=\"mean_squared_error\")\nplt.plot(range(1, EPOCHS+1), history.history['val_mean_squared_error'], label=\"val_mean_squared_error\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_lstm = np.expand_dims(df_test_lstm,axis=2)\ny_test_lstm = model_lstm.predict(X_test_lstm).clip(0,20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_values = test.copy()\npredicted_values['LGBM'] = y_test_lgbm\npredicted_values['LSTM'] = y_test_lstm\npredicted_values = predicted_values.loc[:, ['LGBM', 'LSTM']]\nsubmission['item_cnt_month'] = np.dot(predicted_values, [0.9, 0.1]).clip(0,20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}