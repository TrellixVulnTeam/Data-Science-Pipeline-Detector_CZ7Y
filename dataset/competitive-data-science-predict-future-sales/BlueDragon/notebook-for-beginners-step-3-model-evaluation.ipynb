{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color: #6c3d75; align:center;color:white;border: 4px solid ; text-align:center;margin: 5px;padding:5px;font-size:20px\">Sales Price Prediction Challenge - Step 3 - Model Building</div>\n<div style=\"text-align: center;\">\n<img height=\"100\" width=\"800\"  src=\"https://sp-ao.shortpixel.ai/client/q_glossy,ret_img,w_1000/https://www.leadsquared.com/wp-content/uploads/2019/02/banner-4.png\" alt=\"C1 Technologies\"></div>","metadata":{"execution":{"iopub.status.busy":"2021-10-11T17:50:54.493753Z","iopub.execute_input":"2021-10-11T17:50:54.494281Z","iopub.status.idle":"2021-10-11T17:50:54.501435Z","shell.execute_reply.started":"2021-10-11T17:50:54.494237Z","shell.execute_reply":"2021-10-11T17:50:54.500155Z"}}},{"cell_type":"markdown","source":"<h3 style=\"color:red;text-align:center\"> * * * Please upvote if you like this kernel. * * *</h3>  \n  <h4>This is step 3 <br><br>Please visit <a href='https://www.kaggle.com/zenstat/notebook-for-beginners-step-1-load-the-data' > step 1 kernal code </a>to understand the basics of loading data. </h4>\n  <h4>Please visit<a href='https://www.kaggle.com/zenstat/notebook-for-beginners-step-2-analyze-data' > step 2 kernal code </a>to understand the basics of analyzing the data. </h4><h4>In this kernal, we will work on the third step of the anaysis which is to select variables and build model. We will learn <br><br>\n    * Feature Engineering<br><br>\n    * Model Selection<br><br>\n    We will load the data same as in <a href='https://www.kaggle.com/zenstat/notebook-for-beginners-step-1-load-the-data' >step 1 kernel</a> and <a href='https://www.kaggle.com/zenstat/notebook-for-beginners-step-2-analyze-data' > step 2 kernal.</a> Be sure to check it out if you haven't and in case any step is not clear. \n</h4>","metadata":{}},{"cell_type":"code","source":"### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-05T17:55:56.085138Z","iopub.execute_input":"2021-11-05T17:55:56.085984Z","iopub.status.idle":"2021-11-05T17:55:56.124006Z","shell.execute_reply.started":"2021-11-05T17:55:56.085851Z","shell.execute_reply":"2021-11-05T17:55:56.123241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npd.options.display.float_format = '{:.2f}'.format","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:55:56.125807Z","iopub.execute_input":"2021-11-05T17:55:56.127915Z","iopub.status.idle":"2021-11-05T17:55:56.132763Z","shell.execute_reply.started":"2021-11-05T17:55:56.127854Z","shell.execute_reply":"2021-11-05T17:55:56.131864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\")\nsample_submission.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:55:56.134489Z","iopub.execute_input":"2021-11-05T17:55:56.13514Z","iopub.status.idle":"2021-11-05T17:55:56.261518Z","shell.execute_reply.started":"2021-11-05T17:55:56.135075Z","shell.execute_reply":"2021-11-05T17:55:56.259984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load items data \nitems = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\n#load items category data\nitemscat = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\n#load shops data\nshops = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\n#load sales train data  \ntrain = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\n#load sales test data  \ntest = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:55:56.264305Z","iopub.execute_input":"2021-11-05T17:55:56.265005Z","iopub.status.idle":"2021-11-05T17:55:59.21968Z","shell.execute_reply.started":"2021-11-05T17:55:56.264958Z","shell.execute_reply":"2021-11-05T17:55:59.218684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge all data \ntrain_data=train.join(items, on='item_id', rsuffix='_').join(shops, on='shop_id', rsuffix='_').join(itemscat, on='item_category_id', rsuffix='_').drop([\"item_id_\",\"shop_id_\",\"item_category_id_\" ], axis=1)\n#fix outliers \ntrain_data['item_cnt_day'] = np.where(train_data['item_cnt_day']>420 , 420,train_data['item_cnt_day'] )\ntrain_data['item_price'] = np.where(train_data['item_price']>45000 , 45000,train_data['item_price'] )\n#remove duplicates\ntrain_final = train_data.drop_duplicates()\ndel(train_data)\n\ntest_data=test.join(items, on='item_id', rsuffix='_').join(shops, on='shop_id', rsuffix='_').join(itemscat, on='item_category_id', rsuffix='_').drop([\"item_id_\",\"shop_id_\",\"item_category_id_\" ], axis=1)\n#test_data['item_cnt_day'] = np.where(test_data['item_cnt_day']>400 , 400,test_data['item_cnt_day'] )\n#test_data['item_price'] = np.where(test_data['item_price']>40000 , 40000,test_data['item_price'] )\ntest_final = test_data.drop_duplicates()\ndel(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:55:59.221062Z","iopub.execute_input":"2021-11-05T17:55:59.221405Z","iopub.status.idle":"2021-11-05T17:56:04.284699Z","shell.execute_reply.started":"2021-11-05T17:55:59.221366Z","shell.execute_reply":"2021-11-05T17:56:04.2839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clean data\ntrain_final.shape, test_final.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:56:04.285844Z","iopub.execute_input":"2021-11-05T17:56:04.286091Z","iopub.status.idle":"2021-11-05T17:56:04.292233Z","shell.execute_reply.started":"2021-11-05T17:56:04.286063Z","shell.execute_reply":"2021-11-05T17:56:04.291274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:56:04.293369Z","iopub.execute_input":"2021-11-05T17:56:04.293593Z","iopub.status.idle":"2021-11-05T17:56:05.349921Z","shell.execute_reply.started":"2021-11-05T17:56:04.293568Z","shell.execute_reply":"2021-11-05T17:56:05.349009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_final.columns.T","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:56:05.351531Z","iopub.execute_input":"2021-11-05T17:56:05.351755Z","iopub.status.idle":"2021-11-05T17:56:05.358503Z","shell.execute_reply.started":"2021-11-05T17:56:05.35173Z","shell.execute_reply":"2021-11-05T17:56:05.357759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop original dependent var and id \nX = train_final.drop(['date', 'date_block_num',  'item_price',         'item_name', 'item_category_id', 'shop_name',       'item_category_name' ],axis=1)\n#dt.drop(['SalePrice'], axis=1)\n#id\tbreath_id\tR\tC\ttime_step\tu_in\tu_out\tpressure\tu_in_sum\tu_in_cumsum\tu_in_std\tu_in_min\tu_in_max\tu_in_cumsum_reverse\tu_in_first\tu_in_last\tu_in_lag1\tu_in_lead1\tu_in_lag1_diff\tu_in_lead1_diff\tu_out_sum\ttime_passed\n\ny=train_final.item_cnt_day\n# Split train test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:56:05.360043Z","iopub.execute_input":"2021-11-05T17:56:05.360311Z","iopub.status.idle":"2021-11-05T17:56:05.820671Z","shell.execute_reply.started":"2021-11-05T17:56:05.360282Z","shell.execute_reply":"2021-11-05T17:56:05.819793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we will split the data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,y,shuffle = False,test_size = 0.3)\n ","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:56:05.822837Z","iopub.execute_input":"2021-11-05T17:56:05.823074Z","iopub.status.idle":"2021-11-05T17:56:05.911611Z","shell.execute_reply.started":"2021-11-05T17:56:05.823045Z","shell.execute_reply":"2021-11-05T17:56:05.910709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we will import linear regression\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(x_train,y_train)\n#LinearRegression()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:56:05.912921Z","iopub.execute_input":"2021-11-05T17:56:05.913168Z","iopub.status.idle":"2021-11-05T17:56:06.1198Z","shell.execute_reply.started":"2021-11-05T17:56:05.913139Z","shell.execute_reply":"2021-11-05T17:56:06.118934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4> Now  we will evaluate the model </h4>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ny_pred = model.predict(x_test)\nmean_squared_error(y_test,y_pred,squared=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T17:56:06.121197Z","iopub.execute_input":"2021-11-05T17:56:06.121927Z","iopub.status.idle":"2021-11-05T17:56:06.161697Z","shell.execute_reply.started":"2021-11-05T17:56:06.121878Z","shell.execute_reply":"2021-11-05T17:56:06.160723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#1. linear regression \nfrom sklearn import linear_model\nlr = linear_model.LinearRegression()\nmodel = lr.fit(X_train, y_train)\n#r square \nprint(\"R-Square : \" ,model.score(X_test,y_test))\n#rmse \npreds = model.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nprint ('RMSE: ', mean_squared_error(y_test, preds))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:37:37.401677Z","iopub.execute_input":"2021-10-23T17:37:37.402364Z","iopub.status.idle":"2021-10-23T17:37:37.712656Z","shell.execute_reply.started":"2021-10-23T17:37:37.402307Z","shell.execute_reply":"2021-10-23T17:37:37.711825Z"}}},{"cell_type":"markdown","source":"test_final.head(), train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:37:37.715104Z","iopub.execute_input":"2021-10-23T17:37:37.71571Z","iopub.status.idle":"2021-10-23T17:37:37.749311Z","shell.execute_reply.started":"2021-10-23T17:37:37.71566Z","shell.execute_reply":"2021-10-23T17:37:37.748453Z"}}},{"cell_type":"markdown","source":"submit= pd.DataFrame()\nsubmit['ID'] = test_final.ID\n#select features \ntest_features = test_final.drop(['ID', 'item_name', 'item_category_id', 'shop_name',  'item_category_name'], axis=1)\npreds = model.predict(test_features)\n#unlog/exp the prediction  \nfinal_preds = np.exp(preds)\nprint('Original preds :\\n', preds[:5])\nprint('Final preds :\\n', final_preds[:5])\nsubmit['pressure'] = final_preds\n#final submission \nfilename= \"sales_price_\"+datetime.today().strftime('%Y-%m-%d-%H:%M:%S').replace(\"-\",\"_\").replace(\":\",\"_\")+\".csv\"\nsubmit.to_csv(filename, index=False)\nprint(filename ,\" generated\")","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:37:37.750956Z","iopub.execute_input":"2021-10-23T17:37:37.752575Z","iopub.status.idle":"2021-10-23T17:37:37.96324Z","shell.execute_reply.started":"2021-10-23T17:37:37.75253Z","shell.execute_reply":"2021-10-23T17:37:37.961747Z"}}},{"cell_type":"markdown","source":"<h3 style=\"color:red;text-align:center\"> * * *  to be continued.. * * * </h3>","metadata":{}}]}