{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernel I will share how I managed to build stacking model wich consists on linear regression with regularization and xgboost. I will use alredy cleaned and prepared train data 'all_data_final.pkl' from my another kernel. https://www.kaggle.com/emaksone/eda-with-feature-engineering this is how obtained it.\n\nPipeline:\n\n* Define validation strategy and leaderboard probing\n* Hyperparameter tuning\n* Stacking\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns; sns.set()\nfrom sklearn.externals import joblib\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\n\nfrom xgboost import XGBRegressor\n\nimport gc\nfrom itertools import product\nimport time","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"all_data = pd.read_pickle('../input/extended-train-data/all_data_final.pkl')\nall_data.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"         shop_id       ...         item_first_sale\n4488710       54       ...                       2\n4488711       54       ...                       1\n4488712       54       ...                       3\n4488713       54       ...                       3\n4488714       54       ...                      10\n\n[5 rows x 72 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>shop_id</th>\n      <th>item_id</th>\n      <th>date_block_num</th>\n      <th>target</th>\n      <th>is_december</th>\n      <th>item_category_id</th>\n      <th>type_code</th>\n      <th>subtype_code</th>\n      <th>city_code</th>\n      <th>date_block_num_enc_lag_1</th>\n      <th>date_block_num_enc_lag_2</th>\n      <th>date_block_num_enc_lag_3</th>\n      <th>date_block_num_enc_lag_6</th>\n      <th>date_block_num_enc_lag_12</th>\n      <th>date_block_num_item_enc_lag_1</th>\n      <th>date_block_num_shop_enc_lag_1</th>\n      <th>date_block_num_cat_enc_lag_1</th>\n      <th>date_block_num_shop_cat_enc_lag_1</th>\n      <th>date_block_num_shop_type_enc_lag_1</th>\n      <th>date_block_num_shop_subtype_enc_lag_1</th>\n      <th>date_block_num_city_enc_lag_1</th>\n      <th>date_block_num_item_city_enc_lag_1</th>\n      <th>date_block_num_type_enc_lag_1</th>\n      <th>date_block_num_subtype_enc_lag_1</th>\n      <th>date_block_num_item_enc_lag_2</th>\n      <th>date_block_num_shop_enc_lag_2</th>\n      <th>date_block_num_cat_enc_lag_2</th>\n      <th>date_block_num_shop_cat_enc_lag_2</th>\n      <th>date_block_num_shop_type_enc_lag_2</th>\n      <th>date_block_num_shop_subtype_enc_lag_2</th>\n      <th>date_block_num_city_enc_lag_2</th>\n      <th>date_block_num_item_city_enc_lag_2</th>\n      <th>date_block_num_type_enc_lag_2</th>\n      <th>date_block_num_subtype_enc_lag_2</th>\n      <th>date_block_num_item_enc_lag_3</th>\n      <th>date_block_num_shop_enc_lag_3</th>\n      <th>date_block_num_cat_enc_lag_3</th>\n      <th>date_block_num_shop_cat_enc_lag_3</th>\n      <th>date_block_num_shop_type_enc_lag_3</th>\n      <th>date_block_num_shop_subtype_enc_lag_3</th>\n      <th>date_block_num_city_enc_lag_3</th>\n      <th>date_block_num_item_city_enc_lag_3</th>\n      <th>date_block_num_type_enc_lag_3</th>\n      <th>date_block_num_subtype_enc_lag_3</th>\n      <th>date_block_num_item_enc_lag_6</th>\n      <th>date_block_num_shop_enc_lag_6</th>\n      <th>date_block_num_cat_enc_lag_6</th>\n      <th>date_block_num_shop_cat_enc_lag_6</th>\n      <th>date_block_num_shop_type_enc_lag_6</th>\n      <th>date_block_num_shop_subtype_enc_lag_6</th>\n      <th>date_block_num_city_enc_lag_6</th>\n      <th>date_block_num_item_city_enc_lag_6</th>\n      <th>date_block_num_type_enc_lag_6</th>\n      <th>date_block_num_subtype_enc_lag_6</th>\n      <th>date_block_num_item_enc_lag_12</th>\n      <th>date_block_num_shop_enc_lag_12</th>\n      <th>date_block_num_cat_enc_lag_12</th>\n      <th>date_block_num_shop_cat_enc_lag_12</th>\n      <th>date_block_num_shop_type_enc_lag_12</th>\n      <th>date_block_num_shop_subtype_enc_lag_12</th>\n      <th>date_block_num_city_enc_lag_12</th>\n      <th>date_block_num_item_city_enc_lag_12</th>\n      <th>date_block_num_type_enc_lag_12</th>\n      <th>date_block_num_subtype_enc_lag_12</th>\n      <th>delta_shop_price_lag</th>\n      <th>delta_item_price_lag</th>\n      <th>month</th>\n      <th>days</th>\n      <th>item_shop_last_sale</th>\n      <th>item_last_sale</th>\n      <th>item_shop_first_sale</th>\n      <th>item_first_sale</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4488710</th>\n      <td>54</td>\n      <td>10297</td>\n      <td>12</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>37</td>\n      <td>11</td>\n      <td>1</td>\n      <td>26</td>\n      <td>0.411377</td>\n      <td>0.303223</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.913086</td>\n      <td>0.989258</td>\n      <td>0.232788</td>\n      <td>0.585938</td>\n      <td>0.727539</td>\n      <td>0.579590</td>\n      <td>0.989258</td>\n      <td>3.0</td>\n      <td>0.270020</td>\n      <td>0.234009</td>\n      <td>0.044434</td>\n      <td>0.796387</td>\n      <td>0.183105</td>\n      <td>0.589844</td>\n      <td>0.720703</td>\n      <td>0.588867</td>\n      <td>0.796387</td>\n      <td>0.0</td>\n      <td>0.221436</td>\n      <td>0.183472</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.132324</td>\n      <td>0.037933</td>\n      <td>0</td>\n      <td>31</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4488711</th>\n      <td>54</td>\n      <td>10296</td>\n      <td>12</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>11</td>\n      <td>1</td>\n      <td>26</td>\n      <td>0.411377</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.521973</td>\n      <td>0.989258</td>\n      <td>0.243652</td>\n      <td>0.551758</td>\n      <td>0.727539</td>\n      <td>0.579590</td>\n      <td>0.989258</td>\n      <td>0.0</td>\n      <td>0.270020</td>\n      <td>0.234009</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.132324</td>\n      <td>0.085205</td>\n      <td>0</td>\n      <td>31</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4488712</th>\n      <td>54</td>\n      <td>10298</td>\n      <td>12</td>\n      <td>14.0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>11</td>\n      <td>4</td>\n      <td>26</td>\n      <td>0.411377</td>\n      <td>0.303223</td>\n      <td>0.290039</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>7.218750</td>\n      <td>0.989258</td>\n      <td>0.291504</td>\n      <td>0.822754</td>\n      <td>0.727539</td>\n      <td>0.822754</td>\n      <td>0.989258</td>\n      <td>20.0</td>\n      <td>0.270020</td>\n      <td>0.291504</td>\n      <td>15.023438</td>\n      <td>0.796387</td>\n      <td>0.244873</td>\n      <td>0.812988</td>\n      <td>0.720703</td>\n      <td>0.812988</td>\n      <td>0.796387</td>\n      <td>20.0</td>\n      <td>0.221436</td>\n      <td>0.244873</td>\n      <td>3.130859</td>\n      <td>0.6875</td>\n      <td>0.236206</td>\n      <td>0.706543</td>\n      <td>0.639160</td>\n      <td>0.706543</td>\n      <td>0.6875</td>\n      <td>7.0</td>\n      <td>0.209961</td>\n      <td>0.236206</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.132324</td>\n      <td>0.439209</td>\n      <td>0</td>\n      <td>31</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4488713</th>\n      <td>54</td>\n      <td>10300</td>\n      <td>12</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>37</td>\n      <td>11</td>\n      <td>1</td>\n      <td>26</td>\n      <td>0.411377</td>\n      <td>0.303223</td>\n      <td>0.290039</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.173828</td>\n      <td>0.989258</td>\n      <td>0.232788</td>\n      <td>0.585938</td>\n      <td>0.727539</td>\n      <td>0.579590</td>\n      <td>0.989258</td>\n      <td>1.0</td>\n      <td>0.270020</td>\n      <td>0.234009</td>\n      <td>7.265625</td>\n      <td>0.796387</td>\n      <td>0.183105</td>\n      <td>0.589844</td>\n      <td>0.720703</td>\n      <td>0.588867</td>\n      <td>0.796387</td>\n      <td>20.0</td>\n      <td>0.221436</td>\n      <td>0.183472</td>\n      <td>1.152344</td>\n      <td>0.6875</td>\n      <td>0.170776</td>\n      <td>0.535645</td>\n      <td>0.639160</td>\n      <td>0.539062</td>\n      <td>0.6875</td>\n      <td>0.0</td>\n      <td>0.209961</td>\n      <td>0.169189</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.132324</td>\n      <td>0.160645</td>\n      <td>0</td>\n      <td>31</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4488714</th>\n      <td>54</td>\n      <td>10284</td>\n      <td>12</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>57</td>\n      <td>13</td>\n      <td>7</td>\n      <td>26</td>\n      <td>0.411377</td>\n      <td>0.303223</td>\n      <td>0.290039</td>\n      <td>0.276855</td>\n      <td>0.0</td>\n      <td>0.086975</td>\n      <td>0.989258</td>\n      <td>0.138306</td>\n      <td>0.455322</td>\n      <td>0.668457</td>\n      <td>0.455322</td>\n      <td>0.989258</td>\n      <td>0.0</td>\n      <td>0.218018</td>\n      <td>0.138306</td>\n      <td>0.066650</td>\n      <td>0.796387</td>\n      <td>0.104553</td>\n      <td>0.388428</td>\n      <td>0.513672</td>\n      <td>0.388428</td>\n      <td>0.796387</td>\n      <td>0.0</td>\n      <td>0.169434</td>\n      <td>0.104553</td>\n      <td>0.108704</td>\n      <td>0.6875</td>\n      <td>0.112976</td>\n      <td>0.408691</td>\n      <td>0.558105</td>\n      <td>0.408691</td>\n      <td>0.6875</td>\n      <td>0.0</td>\n      <td>0.175659</td>\n      <td>0.112976</td>\n      <td>0.195679</td>\n      <td>0.74707</td>\n      <td>0.123169</td>\n      <td>0.513672</td>\n      <td>0.55127</td>\n      <td>0.513672</td>\n      <td>0.74707</td>\n      <td>1.0</td>\n      <td>0.180542</td>\n      <td>0.123169</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.132324</td>\n      <td>-0.073181</td>\n      <td>0</td>\n      <td>31</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**<font size=4>Validation strategy</font>**"},{"metadata":{},"cell_type":"markdown","source":"Our object is to predict sales for next month (i.e. November 2015, or 34 in terms of date_block_num). And we can't just randomly split our data on tran/validation sets for parameters tuning because we need validate parameters on data in month that we didn't use in train set like in test. So,I use rows with date_block_num less than 33 as train set and rows with date_block_num equal 33 I use as validation set.\n\nTo successfully predict sales on test data you also need to have same train and test data. In other words you train and test data should have the same distribution. But stop, distribution in train data we know but how do we know distribution in test data? Such information we can get by **leaderboard probing**. For example we can easily find out mean of sales in public leader board by simlpy submiting two files with all 0's prediction and 0.5's predictions and do some math.\n\n\nAnd the mean of sales equals 0.28394. So mean of train/validation should be close to this number in order to get good results. Let's check mean of the target in our whole train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('mean for whole train set: {0}'.format(np.mean(all_data.loc[all_data['date_block_num']<34, 'target'].astype(np.float32))))\nprint('mean for validation train set: {0}'.format(np.mean(all_data.loc[all_data['date_block_num']<33, 'target'].astype(np.float32))))\nprint('mean for validation test set: {0}'.format(np.mean(all_data.loc[all_data['date_block_num']==33, 'target'].astype(np.float32))))","execution_count":34,"outputs":[{"output_type":"stream","text":"mean for whole train set: 0.28772589564323425\nmean for validation train set: 0.28884848952293396\nmean for validation test set: 0.2585652470588684\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"As you can see every numbers are close to mean of test sales. "},{"metadata":{},"cell_type":"markdown","source":"One thing to notice before start building a model. Let's check if we have new items in test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_items = all_data.loc[all_data['date_block_num']==34,'item_id'].unique()\ntrain_items = all_data.loc[all_data['date_block_num']<34,'item_id'].unique()\nitems_in_test_and_not_in_train = set(test_items).difference(set(train_items))\nprint('Items in test and not in train: {0}'.format(len(items_in_test_and_not_in_train)))\nitems_in_train_and_not_in_test = set(train_items).difference(set(test_items))\nprint('Items in train and not in test: {0}'.format(len(items_in_train_and_not_in_test)))\n\ntest_shops = all_data.loc[all_data['date_block_num']==34,'shop_id'].unique()\nprint('Number of unique shops: {0}'.format(len(test_shops)))","execution_count":4,"outputs":[{"output_type":"stream","text":"Items in test and not in train: 378\nItems in train and not in test: 12332\nNumber of unique shops: 42\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"So, we have items in the test set that do not appear in train. So our model will struggle when see unknown items when predict. To eliminate this issue I will add all missing shop/item pair to every month with 0's.\nBut after this we decrese our target mean that will make our train/test data distributions different. To avoid this I remove rows with target equals 0 and item that does not appear in test. At the end it doesn't change mean of targets and train data set will contain all items that exist in test."},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_shop_item_count = 15876 # 372*42 all missing items per month\nindex_cols = ['shop_id', 'item_id', 'date_block_num']\n\ngrid = [] \nfor block_num in all_data.loc[all_data['date_block_num']<34, 'date_block_num'].unique():\n    print(block_num)\n  \n    zero_target_df = all_data[(all_data['date_block_num'] == block_num) & (all_data['target']==0) & \n                              (all_data['item_id'].isin(items_in_train_and_not_in_test))]\n\n    idx_to_delete = zero_target_df.sample(missing_shop_item_count, random_state=block_num).index\n    all_data.drop(idx_to_delete, inplace=True)\n    temp = np.array(list(product(*[test_shops, items_in_test_and_not_in_train, [block_num]])),dtype='int32')\n    grid.append(temp)\n    \n    del zero_target_df\n    del idx_to_delete\n    del temp\n    gc.collect()\n\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)","execution_count":5,"outputs":[{"output_type":"stream","text":"12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid['shop_id'] = grid['shop_id'].astype(np.int16)\ngrid['item_id'] = grid['item_id'].astype(np.int32)\ngrid['date_block_num'] = grid['date_block_num'].astype(np.int8)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.concat([all_data, grid], ignore_index=True, sort=False, keys=index_cols)\nall_data[['item_shop_last_sale', 'item_last_sale']].fillna(-1, inplace=True) #-1 is default value in this columns\nall_data.fillna(0, inplace=True)\n\ndel grid\ndel test_items\ndel test_shops\ndel train_items\ndel items_in_test_and_not_in_train\ndel items_in_train_and_not_in_test\ngc.collect()","execution_count":7,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  downcast=downcast, **kwargs)\n","name":"stderr"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"7"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['is_december'] = all_data['is_december'].astype(np.int8)\nall_data['item_category_id'] = all_data['item_category_id'].astype(np.int8)\nall_data['type_code'] = all_data['type_code'].astype(np.int8)\nall_data['subtype_code'] = all_data['subtype_code'].astype(np.int8)\nall_data['city_code'] = all_data['city_code'].astype(np.int16)\n\nall_data['month'] = all_data['month'].astype(np.int8)\nall_data['days'] = all_data['days'].astype(np.int8)\nall_data['item_shop_last_sale'] = all_data['item_shop_last_sale'].astype(np.int8)\nall_data['item_last_sale'] = all_data['item_last_sale'].astype(np.int8)\nall_data['item_shop_first_sale'] = all_data['item_shop_first_sale'].astype(np.int8)\nall_data['item_first_sale'] = all_data['item_first_sale'].astype(np.int8)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check our means"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('mean for whole train set: {0}'.format(np.mean(all_data.loc[all_data['date_block_num']<34, 'target'].astype(np.float32))))\nprint('mean for validation train set: {0}'.format(np.mean(all_data.loc[all_data['date_block_num']<33, 'target'].astype(np.float32))))\nprint('mean for validation test set: {0}'.format(np.mean(all_data.loc[all_data['date_block_num']==33, 'target'].astype(np.float32))))","execution_count":9,"outputs":[{"output_type":"stream","text":"mean for whole train set: 0.28772589564323425\nmean for validation train set: 0.28884848952293396\nmean for validation test set: 0.2585652470588684\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Good, As it was before."},{"metadata":{"trusted":true},"cell_type":"code","source":"# put added rows in right position\nall_test_data = all_data[all_data['date_block_num'] == 34]\nall_data = all_data[all_data['date_block_num'] < 34]\nall_data.sort_values(['date_block_num'], inplace=True)\nall_data = pd.concat([all_data, all_test_data], ignore_index=True, sort=False, keys=index_cols)\n\ndel all_test_data\ngc.collect()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now we ready to define train/test split. And after we tune parameters we will use whole data to train a model on this parameters and can use it to predict sales on test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = all_data['date_block_num']\n\nlast_block = dates.max()\nprint('Test `date_block_num` is {0}'.format(last_block))\n\nX_train = all_data.loc[dates <  last_block]\nX_test =  all_data.loc[dates == last_block]\n\ny_train = all_data.loc[dates <  last_block, 'target'].values\ny_test =  all_data.loc[dates == last_block, 'target'].values\n\nX_valid_train = all_data.loc[dates <  last_block-1]\nX_valid_test =  all_data.loc[dates == last_block-1]\n\ny_valid_train = all_data.loc[dates <  last_block-1, 'target'].values\ny_valid_test =  all_data.loc[dates == last_block-1, 'target'].values\n\nall_data.to_pickle('all_data.pkl') # will use it later. Now free RAM\n\ndel dates\ndel all_data\ngc.collect()","execution_count":11,"outputs":[{"output_type":"stream","text":"Test `date_block_num` is 34\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Delete columns that we can't use in test"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_delete = ['date_block_num', 'target']\nX_valid_train = X_valid_train.drop(columns_to_delete, axis=1)\nX_valid_test = X_valid_test.drop(columns_to_delete, axis=1)\n\nX_train = X_train.drop(columns_to_delete, axis=1)\nX_test = X_test.drop(columns_to_delete, axis=1)","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<font size=4>Hyperparameters tuning<font>**"},{"metadata":{},"cell_type":"markdown","source":"I create my own custom grid search method because I use XGBoost with GPU and I didn't find a way to make them work together. If you know how to do it please drop a comment."},{"metadata":{"trusted":true},"cell_type":"code","source":"#validation\ndef validate(estimator, X_train_, y_train_, X_val_, y_val_, grid_params):\n    keys = grid_params.keys()\n    vals = grid_params.values()\n    parameters = []\n    rmses = []\n    rmses_train = []\n    return_obj ={}\n    prods = product(*vals)\n   \n    for idx, instance in enumerate(prods):\n        print('-'*50)\n        print('model {0}:'.format(idx))\n        model_params = dict(zip(keys, instance))\n        parameters.append(model_params)\n        \n        print(model_params)\n        model = estimator(**model_params)\n        model.fit(X_train_, y_train_)\n            \n        pred_test = model.predict(X_val_)       \n        mse = mean_squared_error(y_val_, pred_test)\n        rmse = np.sqrt(mse)\n        print('RMSE: {0}'.format(rmse))\n        rmses = rmses + [rmse]\n        \n        best_rmse_so_far = np.min(rmses)\n        print('Best rmse so far: {0}'.format(best_rmse_so_far))\n        best_model_params_so_far = parameters[np.argmin(rmses)]\n        print('Best model params so far: {0}'.format(best_model_params_so_far))\n        \n        del best_rmse_so_far\n        del best_model_params_so_far\n        del pred_test\n        del model\n        gc.collect()\n    \n    rmses = np.array(rmses)\n    best_rmse = np.min(rmses)\n    print('Best rmse: {0}'.format(best_rmse))\n    best_model_params = parameters[np.argmin(rmses)]\n    print('Best model params: {0}'.format(best_model_params))\n\n    return_obj['rmses'] = rmses\n    return_obj['best_rmse'] = best_rmse\n    return_obj['best_model_params'] = best_model_params\n      \n    return return_obj","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find out optimal paramter for Ridge regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"alphas = [10, 100, 2000, 5000]\ngrid_params = {'alpha':alphas}\nval_res = validate(Ridge, X_valid_train, y_valid_train, \n                   X_valid_test, y_valid_test, grid_params)","execution_count":14,"outputs":[{"output_type":"stream","text":"--------------------------------------------------\nmodel 0:\n{'alpha': 10}\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"RMSE: 0.9780671363589905\nBest rmse so far: 0.9780671363589905\nBest model params so far: {'alpha': 10}\n--------------------------------------------------\nmodel 1:\n{'alpha': 100}\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"RMSE: 0.9780657035917624\nBest rmse so far: 0.9780657035917624\nBest model params so far: {'alpha': 100}\n--------------------------------------------------\nmodel 2:\n{'alpha': 2000}\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"RMSE: 0.9780530491962817\nBest rmse so far: 0.9780530491962817\nBest model params so far: {'alpha': 2000}\n--------------------------------------------------\nmodel 3:\n{'alpha': 5000}\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"RMSE: 0.9780588043518567\nBest rmse so far: 0.9780530491962817\nBest model params so far: {'alpha': 2000}\nBest rmse: 0.9780530491962817\nBest model params: {'alpha': 2000}\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"So 2000 is an optimal parameter for our model. We can use it to train model with all train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# best_alpha=2000\n# ridge_model = Ridge(best_alpha)\n# ridge_model.fit(X_train, y_train)\n# predictions = ridge_model.predict(X_test)","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the same way we can do for XGBoost. But this model has much more parameters to config. https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ this article helps to define strategy to find them starting with some parameters that make highest impact on the model and ending with ones that give lowest.\nSo I came up with this parameters. Note that tree_method, predictor, gpu_id was fixed parameters from the begining to enable gpu. It works extremely slow without it.\n\nNote: Don't forget to enable gpu in kernel settings."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = {'learning_rate': 0.16, 'n_estimators': 500, \n               'max_depth': 6, 'min_child_weight': 7,\n               'subsample': 0.9, 'colsample_bytree': 0.7, 'nthread': -1, \n               'scale_pos_weight': 1, 'random_state': 42, \n               \n               #next parameters are used to enable gpu for fasting fitting\n               'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor', 'gpu_id': 0}","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\nmodel = XGBRegressor(**best_params)\nmodel.fit(X_valid_train.values, \n                y_valid_train,\n                eval_metric=\"rmse\", \n                eval_set=[(X_valid_test.values, y_valid_test)], \n                verbose=True, \n                early_stopping_rounds = 50)\n\n\ntime.time() - ts","execution_count":17,"outputs":[{"output_type":"stream","text":"[0]\tvalidation_0-rmse:1.10977\nWill train until validation_0-rmse hasn't improved in 50 rounds.\n[1]\tvalidation_0-rmse:1.06714\n[2]\tvalidation_0-rmse:1.03737\n[3]\tvalidation_0-rmse:1.01324\n[4]\tvalidation_0-rmse:0.995809\n[5]\tvalidation_0-rmse:0.981793\n[6]\tvalidation_0-rmse:0.96942\n[7]\tvalidation_0-rmse:0.962672\n[8]\tvalidation_0-rmse:0.957375\n[9]\tvalidation_0-rmse:0.952107\n[10]\tvalidation_0-rmse:0.948784\n[11]\tvalidation_0-rmse:0.946856\n[12]\tvalidation_0-rmse:0.944467\n[13]\tvalidation_0-rmse:0.943044\n[14]\tvalidation_0-rmse:0.941548\n[15]\tvalidation_0-rmse:0.940759\n[16]\tvalidation_0-rmse:0.940641\n[17]\tvalidation_0-rmse:0.939734\n[18]\tvalidation_0-rmse:0.939436\n[19]\tvalidation_0-rmse:0.937174\n[20]\tvalidation_0-rmse:0.934588\n[21]\tvalidation_0-rmse:0.932408\n[22]\tvalidation_0-rmse:0.931958\n[23]\tvalidation_0-rmse:0.931964\n[24]\tvalidation_0-rmse:0.931886\n[25]\tvalidation_0-rmse:0.931485\n[26]\tvalidation_0-rmse:0.932094\n[27]\tvalidation_0-rmse:0.932031\n[28]\tvalidation_0-rmse:0.931802\n[29]\tvalidation_0-rmse:0.931386\n[30]\tvalidation_0-rmse:0.931517\n[31]\tvalidation_0-rmse:0.931168\n[32]\tvalidation_0-rmse:0.930958\n[33]\tvalidation_0-rmse:0.929951\n[34]\tvalidation_0-rmse:0.929833\n[35]\tvalidation_0-rmse:0.929549\n[36]\tvalidation_0-rmse:0.930023\n[37]\tvalidation_0-rmse:0.929876\n[38]\tvalidation_0-rmse:0.929919\n[39]\tvalidation_0-rmse:0.929318\n[40]\tvalidation_0-rmse:0.929394\n[41]\tvalidation_0-rmse:0.929405\n[42]\tvalidation_0-rmse:0.928829\n[43]\tvalidation_0-rmse:0.928785\n[44]\tvalidation_0-rmse:0.92869\n[45]\tvalidation_0-rmse:0.928597\n[46]\tvalidation_0-rmse:0.925202\n[47]\tvalidation_0-rmse:0.925454\n[48]\tvalidation_0-rmse:0.9238\n[49]\tvalidation_0-rmse:0.923218\n[50]\tvalidation_0-rmse:0.92329\n[51]\tvalidation_0-rmse:0.923115\n[52]\tvalidation_0-rmse:0.923598\n[53]\tvalidation_0-rmse:0.922852\n[54]\tvalidation_0-rmse:0.923017\n[55]\tvalidation_0-rmse:0.923387\n[56]\tvalidation_0-rmse:0.923275\n[57]\tvalidation_0-rmse:0.92249\n[58]\tvalidation_0-rmse:0.922502\n[59]\tvalidation_0-rmse:0.921729\n[60]\tvalidation_0-rmse:0.921438\n[61]\tvalidation_0-rmse:0.921873\n[62]\tvalidation_0-rmse:0.921826\n[63]\tvalidation_0-rmse:0.921663\n[64]\tvalidation_0-rmse:0.921574\n[65]\tvalidation_0-rmse:0.921465\n[66]\tvalidation_0-rmse:0.921417\n[67]\tvalidation_0-rmse:0.92068\n[68]\tvalidation_0-rmse:0.920025\n[69]\tvalidation_0-rmse:0.919581\n[70]\tvalidation_0-rmse:0.919952\n[71]\tvalidation_0-rmse:0.91991\n[72]\tvalidation_0-rmse:0.919927\n[73]\tvalidation_0-rmse:0.919633\n[74]\tvalidation_0-rmse:0.919262\n[75]\tvalidation_0-rmse:0.91906\n[76]\tvalidation_0-rmse:0.919116\n[77]\tvalidation_0-rmse:0.918813\n[78]\tvalidation_0-rmse:0.918704\n[79]\tvalidation_0-rmse:0.918765\n[80]\tvalidation_0-rmse:0.918803\n[81]\tvalidation_0-rmse:0.917765\n[82]\tvalidation_0-rmse:0.917609\n[83]\tvalidation_0-rmse:0.917657\n[84]\tvalidation_0-rmse:0.917671\n[85]\tvalidation_0-rmse:0.917464\n[86]\tvalidation_0-rmse:0.91733\n[87]\tvalidation_0-rmse:0.917021\n[88]\tvalidation_0-rmse:0.917165\n[89]\tvalidation_0-rmse:0.917074\n[90]\tvalidation_0-rmse:0.917016\n[91]\tvalidation_0-rmse:0.916565\n[92]\tvalidation_0-rmse:0.916569\n[93]\tvalidation_0-rmse:0.916217\n[94]\tvalidation_0-rmse:0.915974\n[95]\tvalidation_0-rmse:0.915195\n[96]\tvalidation_0-rmse:0.915059\n[97]\tvalidation_0-rmse:0.915093\n[98]\tvalidation_0-rmse:0.915062\n[99]\tvalidation_0-rmse:0.914767\n[100]\tvalidation_0-rmse:0.914816\n[101]\tvalidation_0-rmse:0.91474\n[102]\tvalidation_0-rmse:0.914636\n[103]\tvalidation_0-rmse:0.914776\n[104]\tvalidation_0-rmse:0.914777\n[105]\tvalidation_0-rmse:0.914957\n[106]\tvalidation_0-rmse:0.915075\n[107]\tvalidation_0-rmse:0.915077\n[108]\tvalidation_0-rmse:0.915069\n[109]\tvalidation_0-rmse:0.915038\n[110]\tvalidation_0-rmse:0.915251\n[111]\tvalidation_0-rmse:0.915107\n[112]\tvalidation_0-rmse:0.915116\n[113]\tvalidation_0-rmse:0.915122\n[114]\tvalidation_0-rmse:0.915143\n[115]\tvalidation_0-rmse:0.915309\n[116]\tvalidation_0-rmse:0.913765\n[117]\tvalidation_0-rmse:0.913799\n[118]\tvalidation_0-rmse:0.913816\n[119]\tvalidation_0-rmse:0.914053\n[120]\tvalidation_0-rmse:0.914175\n[121]\tvalidation_0-rmse:0.914071\n[122]\tvalidation_0-rmse:0.913876\n[123]\tvalidation_0-rmse:0.914022\n[124]\tvalidation_0-rmse:0.91378\n[125]\tvalidation_0-rmse:0.912709\n[126]\tvalidation_0-rmse:0.912555\n[127]\tvalidation_0-rmse:0.912517\n[128]\tvalidation_0-rmse:0.912452\n[129]\tvalidation_0-rmse:0.912605\n[130]\tvalidation_0-rmse:0.912654\n[131]\tvalidation_0-rmse:0.913203\n[132]\tvalidation_0-rmse:0.913221\n[133]\tvalidation_0-rmse:0.913307\n[134]\tvalidation_0-rmse:0.913074\n[135]\tvalidation_0-rmse:0.913111\n[136]\tvalidation_0-rmse:0.913005\n[137]\tvalidation_0-rmse:0.912977\n[138]\tvalidation_0-rmse:0.912547\n[139]\tvalidation_0-rmse:0.912511\n[140]\tvalidation_0-rmse:0.912605\n[141]\tvalidation_0-rmse:0.912746\n[142]\tvalidation_0-rmse:0.912862\n[143]\tvalidation_0-rmse:0.912236\n[144]\tvalidation_0-rmse:0.912174\n[145]\tvalidation_0-rmse:0.9123\n[146]\tvalidation_0-rmse:0.911524\n[147]\tvalidation_0-rmse:0.911418\n[148]\tvalidation_0-rmse:0.910924\n[149]\tvalidation_0-rmse:0.910967\n[150]\tvalidation_0-rmse:0.910796\n[151]\tvalidation_0-rmse:0.910741\n[152]\tvalidation_0-rmse:0.908847\n[153]\tvalidation_0-rmse:0.908818\n[154]\tvalidation_0-rmse:0.908801\n[155]\tvalidation_0-rmse:0.908843\n[156]\tvalidation_0-rmse:0.908572\n[157]\tvalidation_0-rmse:0.908415\n[158]\tvalidation_0-rmse:0.908008\n[159]\tvalidation_0-rmse:0.908275\n[160]\tvalidation_0-rmse:0.908276\n[161]\tvalidation_0-rmse:0.9082\n[162]\tvalidation_0-rmse:0.908202\n[163]\tvalidation_0-rmse:0.908264\n[164]\tvalidation_0-rmse:0.908288\n[165]\tvalidation_0-rmse:0.907482\n[166]\tvalidation_0-rmse:0.907527\n[167]\tvalidation_0-rmse:0.907647\n[168]\tvalidation_0-rmse:0.907527\n[169]\tvalidation_0-rmse:0.907648\n[170]\tvalidation_0-rmse:0.907763\n[171]\tvalidation_0-rmse:0.907851\n[172]\tvalidation_0-rmse:0.907796\n[173]\tvalidation_0-rmse:0.907797\n[174]\tvalidation_0-rmse:0.907826\n[175]\tvalidation_0-rmse:0.90783\n[176]\tvalidation_0-rmse:0.907719\n[177]\tvalidation_0-rmse:0.90759\n[178]\tvalidation_0-rmse:0.90755\n[179]\tvalidation_0-rmse:0.907448\n[180]\tvalidation_0-rmse:0.907441\n[181]\tvalidation_0-rmse:0.907394\n[182]\tvalidation_0-rmse:0.907329\n[183]\tvalidation_0-rmse:0.907107\n[184]\tvalidation_0-rmse:0.907021\n[185]\tvalidation_0-rmse:0.90704\n[186]\tvalidation_0-rmse:0.907686\n[187]\tvalidation_0-rmse:0.907519\n[188]\tvalidation_0-rmse:0.90758\n[189]\tvalidation_0-rmse:0.907763\n[190]\tvalidation_0-rmse:0.907824\n[191]\tvalidation_0-rmse:0.908134\n[192]\tvalidation_0-rmse:0.908101\n[193]\tvalidation_0-rmse:0.908053\n[194]\tvalidation_0-rmse:0.908022\n[195]\tvalidation_0-rmse:0.907947\n[196]\tvalidation_0-rmse:0.90788\n[197]\tvalidation_0-rmse:0.907847\n[198]\tvalidation_0-rmse:0.908109\n[199]\tvalidation_0-rmse:0.908158\n[200]\tvalidation_0-rmse:0.908121\n[201]\tvalidation_0-rmse:0.908253\n[202]\tvalidation_0-rmse:0.908425\n[203]\tvalidation_0-rmse:0.908429\n[204]\tvalidation_0-rmse:0.90839\n[205]\tvalidation_0-rmse:0.908328\n[206]\tvalidation_0-rmse:0.908524\n[207]\tvalidation_0-rmse:0.908576\n[208]\tvalidation_0-rmse:0.908692\n[209]\tvalidation_0-rmse:0.908779\n[210]\tvalidation_0-rmse:0.90862\n[211]\tvalidation_0-rmse:0.908523\n[212]\tvalidation_0-rmse:0.90782\n[213]\tvalidation_0-rmse:0.907812\n[214]\tvalidation_0-rmse:0.907176\n[215]\tvalidation_0-rmse:0.907084\n[216]\tvalidation_0-rmse:0.90711\n[217]\tvalidation_0-rmse:0.907053\n[218]\tvalidation_0-rmse:0.907085\n[219]\tvalidation_0-rmse:0.90707\n[220]\tvalidation_0-rmse:0.907067\n[221]\tvalidation_0-rmse:0.907074\n[222]\tvalidation_0-rmse:0.907033\n[223]\tvalidation_0-rmse:0.906927\n[224]\tvalidation_0-rmse:0.906947\n[225]\tvalidation_0-rmse:0.907424\n[226]\tvalidation_0-rmse:0.907486\n[227]\tvalidation_0-rmse:0.907494\n[228]\tvalidation_0-rmse:0.907966\n[229]\tvalidation_0-rmse:0.907822\n[230]\tvalidation_0-rmse:0.907691\n[231]\tvalidation_0-rmse:0.907691\n[232]\tvalidation_0-rmse:0.90765\n[233]\tvalidation_0-rmse:0.907594\n[234]\tvalidation_0-rmse:0.907361\n[235]\tvalidation_0-rmse:0.907375\n[236]\tvalidation_0-rmse:0.907431\n[237]\tvalidation_0-rmse:0.907381\n[238]\tvalidation_0-rmse:0.906971\n[239]\tvalidation_0-rmse:0.906857\n[240]\tvalidation_0-rmse:0.906819\n[241]\tvalidation_0-rmse:0.90678\n[242]\tvalidation_0-rmse:0.906758\n[243]\tvalidation_0-rmse:0.906734\n[244]\tvalidation_0-rmse:0.906774\n[245]\tvalidation_0-rmse:0.906848\n[246]\tvalidation_0-rmse:0.90687\n[247]\tvalidation_0-rmse:0.906861\n[248]\tvalidation_0-rmse:0.906807\n[249]\tvalidation_0-rmse:0.907018\n[250]\tvalidation_0-rmse:0.907112\n","name":"stdout"},{"output_type":"stream","text":"[251]\tvalidation_0-rmse:0.907082\n[252]\tvalidation_0-rmse:0.907106\n[253]\tvalidation_0-rmse:0.907086\n[254]\tvalidation_0-rmse:0.906989\n[255]\tvalidation_0-rmse:0.907141\n[256]\tvalidation_0-rmse:0.907\n[257]\tvalidation_0-rmse:0.906858\n[258]\tvalidation_0-rmse:0.906945\n[259]\tvalidation_0-rmse:0.90663\n[260]\tvalidation_0-rmse:0.906662\n[261]\tvalidation_0-rmse:0.9067\n[262]\tvalidation_0-rmse:0.906468\n[263]\tvalidation_0-rmse:0.906443\n[264]\tvalidation_0-rmse:0.906902\n[265]\tvalidation_0-rmse:0.906893\n[266]\tvalidation_0-rmse:0.906803\n[267]\tvalidation_0-rmse:0.906769\n[268]\tvalidation_0-rmse:0.906728\n[269]\tvalidation_0-rmse:0.906697\n[270]\tvalidation_0-rmse:0.906853\n[271]\tvalidation_0-rmse:0.906881\n[272]\tvalidation_0-rmse:0.906881\n[273]\tvalidation_0-rmse:0.907517\n[274]\tvalidation_0-rmse:0.907605\n[275]\tvalidation_0-rmse:0.90752\n[276]\tvalidation_0-rmse:0.907485\n[277]\tvalidation_0-rmse:0.907503\n[278]\tvalidation_0-rmse:0.908068\n[279]\tvalidation_0-rmse:0.908062\n[280]\tvalidation_0-rmse:0.908014\n[281]\tvalidation_0-rmse:0.907964\n[282]\tvalidation_0-rmse:0.907505\n[283]\tvalidation_0-rmse:0.907352\n[284]\tvalidation_0-rmse:0.907372\n[285]\tvalidation_0-rmse:0.907341\n[286]\tvalidation_0-rmse:0.907334\n[287]\tvalidation_0-rmse:0.907487\n[288]\tvalidation_0-rmse:0.907502\n[289]\tvalidation_0-rmse:0.907603\n[290]\tvalidation_0-rmse:0.907736\n[291]\tvalidation_0-rmse:0.907636\n[292]\tvalidation_0-rmse:0.907692\n[293]\tvalidation_0-rmse:0.907849\n[294]\tvalidation_0-rmse:0.90788\n[295]\tvalidation_0-rmse:0.908067\n[296]\tvalidation_0-rmse:0.907994\n[297]\tvalidation_0-rmse:0.907942\n[298]\tvalidation_0-rmse:0.907992\n[299]\tvalidation_0-rmse:0.908043\n[300]\tvalidation_0-rmse:0.908332\n[301]\tvalidation_0-rmse:0.908286\n[302]\tvalidation_0-rmse:0.908412\n[303]\tvalidation_0-rmse:0.90841\n[304]\tvalidation_0-rmse:0.908402\n[305]\tvalidation_0-rmse:0.908392\n[306]\tvalidation_0-rmse:0.90814\n[307]\tvalidation_0-rmse:0.90804\n[308]\tvalidation_0-rmse:0.908005\n[309]\tvalidation_0-rmse:0.907993\n[310]\tvalidation_0-rmse:0.908043\n[311]\tvalidation_0-rmse:0.908054\n[312]\tvalidation_0-rmse:0.908021\n[313]\tvalidation_0-rmse:0.908166\nStopping. Best iteration:\n[263]\tvalidation_0-rmse:0.906443\n\n","name":"stdout"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"52.800353050231934"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Look how better xgboost then simple regression model."},{"metadata":{"trusted":true},"cell_type":"code","source":"joblib.dump(model, 'xgboost_model.pkl')\ndel model\ndel X_train\ndel X_test\ndel y_train\ndel y_test\ndel X_valid_train\ndel X_valid_test\ndel y_valid_train\ndel y_valid_test\n\ngc.collect()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"68"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**<font size=4>Stacking<font>**"},{"metadata":{},"cell_type":"markdown","source":"So now after we find optimal parameters for two models we can use them for stacking. I will do it in the following way: \n\n* take data that date_block_num < 27 as train\n* train a models(Ridge and XGBoost) and predict for date_block_num == 27\n* put this prediction in two columns (xgb_prediction and ridge_prediction)\n* do it for 28, 29, 30, 31, 32, 33, 34 monthes\n* concat all this prediction.\n* fit data from 28 to 33 to Linear regression\n* use this simple model to predict data with month 34"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.read_pickle('all_data.pkl')","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_prediction_for_specifi_month(monthes_before, df, estimator, params, prefix):\n    predictions = pd.DataFrame(columns=['date_block_num', 'pred_'+prefix])\n    for before in monthes_before:\n        last_valid_month = np.max(df['date_block_num'])\n        print('train: 12 to {0}'.format(last_valid_month-before-1))\n        print('test: {0}'.format(last_valid_month-before))\n        \n        cur_train = df[df['date_block_num'] < last_valid_month-before]\n        cur_test = df[df['date_block_num'] == last_valid_month-before]\n        \n        cur_y_train = cur_train['target']\n        cur_train.drop('target', axis=1, inplace=True)\n        cur_test.drop('target', axis=1, inplace=True)\n        \n        model = estimator(**params)\n        model.fit(cur_train.values, cur_y_train.values)\n        pred = model.predict(cur_test.values)\n        cur_df = pd.DataFrame(columns=['date_block_num', 'pred_'+prefix])\n        \n        cur_df['pred_'+prefix] = pred\n        cur_df['date_block_num'] = (last_valid_month-before)\n       \n        predictions = pd.concat([predictions, cur_df])\n        del model\n        del pred\n        del cur_test\n        del cur_df\n        del cur_y_train\n        gc.collect()\n        \n    return predictions","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_param = {\n    'learning_rate' :0.16,\n    'n_estimators':500,\n    'max_depth':6,\n    'min_child_weight':7,\n    'subsample':0.9,\n    'colsample_bytree':0.7,\n    'nthread':-1,\n    'scale_pos_weight':1,\n     #next parameters are used to enable gpu for fasting fitting\n    'random_state':42,\n    'nthread': -1,\n    'tree_method':'gpu_hist',\n    'predictor':'gpu_predictor',\n    'gpu_id': 0,\n}\n\nts= time.time()\nmonthes_before = [6, 5, 4, 3, 2, 1, 0]\n\nstacks_xgb = compute_prediction_for_specifi_month(monthes_before, all_data, XGBRegressor, best_params,'xgb')\ntime.time()-ts","execution_count":21,"outputs":[{"output_type":"stream","text":"train: 12 to 27\ntest: 28\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  errors=errors)\n","name":"stderr"},{"output_type":"stream","text":"train: 12 to 28\ntest: 29\ntrain: 12 to 29\ntest: 30\ntrain: 12 to 30\ntest: 31\ntrain: 12 to 31\ntest: 32\ntrain: 12 to 32\ntest: 33\ntrain: 12 to 33\ntest: 34\n","name":"stdout"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"461.87108540534973"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Clip predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"stacks_xgb['pred_xgb'] = stacks_xgb['pred_xgb'].clip(0, 20)","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And do it for second model"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\nmonthes_before = [6, 5, 4, 3, 2, 1, 0]\nbest_param ={'alpha': 2000}\nstacks_lin_reg = compute_prediction_for_specifi_month(monthes_before, all_data, Ridge, best_param,'lin')\ntime.time() - ts","execution_count":23,"outputs":[{"output_type":"stream","text":"train: 12 to 27\ntest: 28\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  errors=errors)\n/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"train: 12 to 28\ntest: 29\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  errors=errors)\n/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"train: 12 to 29\ntest: 30\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  errors=errors)\n/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"train: 12 to 30\ntest: 31\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  errors=errors)\n/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"train: 12 to 31\ntest: 32\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  errors=errors)\n/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"train: 12 to 32\ntest: 33\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  errors=errors)\n/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"stream","text":"train: 12 to 33\ntest: 34\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  errors=errors)\n/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"121.0373706817627"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Clip predictions again"},{"metadata":{"trusted":true},"cell_type":"code","source":"stacks_lin_reg['pred_lin'] = stacks_lin_reg['pred_lin'].clip(0, 20)","execution_count":26,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And construct train/validation/test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid_train = pd.concat([stacks_xgb[stacks_xgb['date_block_num'] < 33], \n                           stacks_lin_reg[stacks_lin_reg['date_block_num'] < 33]], axis=1)\nX_valid_test = pd.concat([stacks_xgb[stacks_xgb['date_block_num'] == 33], \n                           stacks_lin_reg[stacks_lin_reg['date_block_num'] == 33]], axis=1)\ny_valid_train = all_data.loc[(all_data['date_block_num']<33) & (all_data['date_block_num']>27), 'target']\ny_valid_test = all_data.loc[all_data['date_block_num']==33, 'target']","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([stacks_xgb[stacks_xgb['date_block_num'] < 34], \n                           stacks_lin_reg[stacks_lin_reg['date_block_num'] < 34]], axis=1)\nX_test = pd.concat([stacks_xgb[stacks_xgb['date_block_num'] == 34], \n                           stacks_lin_reg[stacks_lin_reg['date_block_num'] == 34]], axis=1)\ny_train = all_data.loc[(all_data['date_block_num']<34) & (all_data['date_block_num']>27), 'target']","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid_train.drop('date_block_num', axis=1, inplace=True)\nX_valid_test.drop('date_block_num', axis=1, inplace=True)\nX_train.drop('date_block_num', axis=1, inplace=True)\nX_test.drop('date_block_num', axis=1, inplace=True)","execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And use simple linear regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X_valid_train, y_valid_train)\npred = model.predict(X_valid_test).clip(0,20)\n\nrmse = np.sqrt(mean_squared_error(y_valid_test, pred))\nprint('RMSE on valid set: {0}'.format(rmse))","execution_count":30,"outputs":[{"output_type":"stream","text":"RMSE on valid set: 0.900349656662716\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"As you see the rmse is lower then single xgboost model's rmse.\n\nLet's train a stacking model on a whole train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test).clip(0,20)","execution_count":31,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame({'ID':range(len(pred)), 'item_cnt_month': pred})\nsubmit.to_csv('submit.csv', index=False)","execution_count":32,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<font size=4>Summary</font>**"},{"metadata":{},"cell_type":"markdown","source":"In this kernel we learned how to make proper cross validation strategy, tune parameters for single models and finnaly use one of the ensambling methods called stacking to make better predictions."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}