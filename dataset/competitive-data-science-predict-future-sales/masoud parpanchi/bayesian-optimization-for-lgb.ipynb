{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bayesian optimization\n\nin this kernel we want to make prediction for this competition. but we will find our hyperparameters by bayesian optimization.\n\nwe will use pre engineered data from this [kernel](https://www.kaggle.com/emaksone/eda-with-feature-engineering)\n![bayesian optimization](https://github.com/fmfn/BayesianOptimization/raw/master/examples/func.png)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns; sns.set()\nfrom sklearn.externals import joblib\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\n\nfrom xgboost import XGBRegressor\n\nimport gc\nfrom itertools import product\nimport time\n\nfrom bayes_opt import BayesianOptimization\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nfrom bayes_opt.logger import JSONLogger\nfrom bayes_opt.event import Events","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data loading"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"all_data = pd.read_pickle(\"/kaggle/input/eda-with-feature-engineering/all_data.pkl\")\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# a little data prepration\n\na little data prepration .( if  you want, you can Expand cells).this part heavilly inspired by [Manizuk notebook](https://www.kaggle.com/emaksone/linear-model-xgboost-and-stacking/comments)"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"test_items = all_data.loc[all_data['date_block_num']==34,'item_id'].unique()\ntrain_items = all_data.loc[all_data['date_block_num']<34,'item_id'].unique()\nitems_in_test_and_not_in_train = set(test_items).difference(set(train_items))\nprint('Items in test and not in train: {0}'.format(len(items_in_test_and_not_in_train)))\nitems_in_train_and_not_in_test = set(train_items).difference(set(test_items))\nprint('Items in train and not in test: {0}'.format(len(items_in_train_and_not_in_test)))\n\ntest_shops = all_data.loc[all_data['date_block_num']==34,'shop_id'].unique()\nprint('Number of unique shops: {0}'.format(len(test_shops)))\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"missing_shop_item_count = 378 * 42 # all missing item per shop ===> 15876\nindex_cols = ['shop_id', 'item_id', 'date_block_num']\n\ngrid = []\nfor block_num in all_data.loc[all_data['date_block_num']<34, 'date_block_num'].unique():\n    print(block_num)\n    \n    zero_target_df = all_data[(all_data['date_block_num'] == block_num) & (all_data['target']==0) & \n                              (all_data['item_id'].isin(items_in_train_and_not_in_test))]\n    \n    idx_to_delete = zero_target_df.sample(missing_shop_item_count, random_state=block_num).index\n    all_data.drop(idx_to_delete, inplace=True)\n    temp = np.array(list(product(*[test_shops, items_in_test_and_not_in_train, [block_num]])),dtype='int32')\n    grid.append(temp)\n    \n    del zero_target_df\n    del idx_to_delete\n    del temp\n    gc.collect()\n\n#     I think grid is all items that a specific shop(in train data) didn't have in each month\n# یعنی اجناسی که هر مغازه در ماه های قبل ۳۴ نفروخته (یا همون نداشته که بفروشه )\n#  non of grid rows are in all_data\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"grid['shop_id'] = grid['shop_id'].astype(np.int16)\ngrid['item_id'] = grid['item_id'].astype(np.int32)\ngrid['date_block_num'] = grid['date_block_num'].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"all_data = pd.concat([all_data, grid], ignore_index=True, sort=False, keys=index_cols)\nall_data[['item_shop_last_sale', 'item_last_sale']].fillna(-1, inplace=True) #-1 is default value in this columns\nall_data.fillna(0, inplace=True)\n\ndel grid\ndel test_items\ndel test_shops\ndel train_items\ndel items_in_test_and_not_in_train\ndel items_in_train_and_not_in_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"all_data","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"all_data['is_december'] = all_data['is_december'].astype(np.int8)\nall_data['item_category_id'] = all_data['item_category_id'].astype(np.int8)\nall_data['type_code'] = all_data['type_code'].astype(np.int8)\nall_data['subtype_code'] = all_data['subtype_code'].astype(np.int8)\nall_data['city_code'] = all_data['city_code'].astype(np.int16)\n\nall_data['month'] = all_data['month'].astype(np.int8)\nall_data['days'] = all_data['days'].astype(np.int8)\nall_data['item_shop_last_sale'] = all_data['item_shop_last_sale'].astype(np.int8)\nall_data['item_last_sale'] = all_data['item_last_sale'].astype(np.int8)\nall_data['item_shop_first_sale'] = all_data['item_shop_first_sale'].astype(np.int8)\nall_data['item_first_sale'] = all_data['item_first_sale'].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# we added some rows to balance ditribution of our dataset so we need put those new rows in right position\n# put added rows in right position\nall_test_data = all_data[all_data['date_block_num'] == 34]\nall_data = all_data[all_data['date_block_num'] < 34]\nall_data.sort_values(['date_block_num'], inplace=True)\nall_data = pd.concat([all_data, all_test_data], ignore_index=True, sort=False, keys=index_cols)\n\ndel all_test_data\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ok, let's create our test and train data.\nas you may know 34th month is our test set and all before months are train."},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = all_data['date_block_num']\n\nlast_block = dates.max()\nprint('Test `date_block_num` is {0}'.format(last_block))\n\nX_train = all_data.loc[dates <  last_block]\nX_test =  all_data.loc[dates == last_block]\n\ny_train = all_data.loc[dates <  last_block, 'target'].values\ny_test =  all_data.loc[dates == last_block, 'target'].values\n\nX_valid_train = all_data.loc[dates <  last_block-1]\nX_valid_test =  all_data.loc[dates == last_block-1]\n\ny_valid_train = all_data.loc[dates <  last_block-1, 'target'].values\ny_valid_test =  all_data.loc[dates == last_block-1, 'target'].values\n\nall_data.to_pickle('all_data.pkl') # will use it later. Now free RAM\n\ndel dates\ndel all_data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete some rows from test\ncolumns_to_delete = ['date_block_num', 'target']\nX_valid_train = X_valid_train.drop(columns_to_delete, axis=1)\nX_valid_test = X_valid_test.drop(columns_to_delete, axis=1)\n\nX_train = X_train.drop(columns_to_delete, axis=1)\nX_test = X_test.drop(columns_to_delete, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"important to us are : \n* X_valid_train\n* X_valid_test\n* y_valid_train\n* y_valid_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  we need list of column_names in lgb.Dataset()\npredictors = X_valid_train.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# bayesian optimization part\n\n\nso let's go inside the real part of kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"bayesian_tr_index, bayesian_val_index = list(StratifiedKFold(2, random_state=12, shuffle=True).split(X_valid_train, y_valid_train))[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we need a black box function to use bayesian optimization.\n\nthe library will use this function oo gain best result."},{"metadata":{"trusted":true},"cell_type":"code","source":"# in bayesian optimization we need to have a black box. this black box is our algorithm which we want to optimize\ndef lgb_black_box(\n    num_leaves,  # int\n    min_data_in_leaf,  # int\n    learning_rate,\n    min_sum_hessian_in_leaf,    # int  \n    feature_fraction,\n    lambda_l1,\n    lambda_l2,\n    min_gain_to_split,\n    max_depth):\n    \n    # lgb need some inputs as int but BayesianOptimization library send continuous values values. so we change type.\n\n    num_leaves = int(num_leaves)\n    min_data_in_leaf = int(min_data_in_leaf)\n    max_depth = int(max_depth)\n    \n    # all this hyperparameter values are just for test. our goal in this kernel is how to use bayesian optimization\n    # you can see lgb documentation for more info about hyperparameters\n    params = {\n        'num_leaves': num_leaves,\n        'max_bin': 63,\n        'min_data_in_leaf': min_data_in_leaf,\n        'learning_rate': learning_rate,\n        'min_sum_hessian_in_leaf': min_sum_hessian_in_leaf,\n        'bagging_fraction': 1.0,\n        'bagging_freq': 5,\n        'feature_fraction': feature_fraction,\n        'lambda_l1': lambda_l1,\n        'lambda_l2': lambda_l2,\n        'min_gain_to_split': min_gain_to_split,\n        'max_depth': max_depth,\n        'save_binary': True, \n        'seed': 1337,\n        'feature_fraction_seed': 1337,\n        'bagging_seed': 1337,\n        'drop_seed': 1337,\n        'data_random_seed': 1337,\n        'objective': 'regression',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'rmse',\n        'is_unbalance': True,\n        'boost_from_average': False, \n    }\n    \n    train_data = lgb.Dataset(X_valid_train.iloc[bayesian_tr_index].values,\n                            label = y_valid_train[bayesian_tr_index],\n                            feature_name=predictors,\n                            free_raw_data = False)\n    \n    \n    validation_data = lgb.Dataset(X_valid_train.iloc[bayesian_val_index].values,\n                                 label= y_valid_train[bayesian_val_index],\n                                 feature_name=predictors,\n                                 free_raw_data=False)\n    \n    num_round = 5000\n    clf = lgb.train(params, train_data, num_round, valid_sets = [validation_data], verbose_eval=250,\n                 early_stopping_rounds = 50)\n    \n    predictions = clf.predict(X_valid_train.iloc[bayesian_val_index].values,\n                              num_iteration = clf.best_iteration)\n    \n#      we need to compute a regression score. roc_auc_score is a classification score. we can't use it\n#     score = metrics.roc_auc_score(y_valid_train[bayesian_val_index], predictions)\n    mse = mean_squared_error(y_valid_train[bayesian_val_index], predictions)\n    rmse = np.sqrt(mse)\n#     our bayesian optimization expect us to give him increasing number to understand this is getting better\n    return -rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"set range for hyperparams, and library will select best choice for these hyperparams in this range.\n<br>\nto understand these params you can visit [lgbm documentation](https://lightgbm.readthedocs.io/en/latest/Parameters.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# these ranges are not best range for this competition, I just use these base ranges\nLGB_bound = {\n    \"num_leaves\" : (5, 20),\n    \"min_data_in_leaf\" : (5, 20),\n    \"learning_rate\" : (0.01, 0.3),\n    \"min_sum_hessian_in_leaf\" : (0.00001, 0.01),\n    \"feature_fraction\" : (0.05, 0.5),\n    \"lambda_l1\" : (0, 5.0),\n    \"lambda_l2\" : (0, 5.0),\n    'min_gain_to_split': (0, 1.0),\n    'max_depth':(3,15)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\n#  we have 3 parameters for this object. first is function. second is ranges. third is random_state (no matter)\noptimizer = BayesianOptimization(\n    f=lgb_black_box,\n    pbounds = LGB_bound,\n    random_state = 13\n)\nprint(optimizer.space.keys)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you want to read more about this Bayesian library, read [Lib documentation](https://github.com/fmfn/BayesianOptimization)"},{"metadata":{"trusted":true},"cell_type":"code","source":"init_points = 3\nn_iter = 3\n\noptimizer.maximize(init_points = init_points, n_iter = n_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer.max[\"params\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"assume you find some kernel with different hyperparameters, then you want to check if those values are better than yours or not?\n\nI used bayesian optimization another time and found different hyperparameter values.\nnow we can check which one is better."},{"metadata":{"trusted":true},"cell_type":"code","source":"# here i say hey optimizer! search for this new parameter to see if they are really better or not.\n# probe = کاوش\n#  tmp code\n#  feature fraction = 0.3064, l1=  2.659,  l2 =   0.3892, learning =  0.1054,\n# max_depth = 14.76, min_da  19.7,   min_ga = 0.6548,   min_su = 0.000626, num_lea 19.06\n\noptimizer.probe(\n    params = {\n        'feature_fraction': 0.3064, \n            'lambda_l1': 2.659, \n            'lambda_l2': 0.3892, \n            'learning_rate': 0.1054, \n            'max_depth': 14.76, \n            'min_data_in_leaf': 19.7, \n            'min_gain_to_split': 0.6548, \n            'min_sum_hessian_in_leaf': 0.000626, \n            'num_leaves': 19.06\n    },\n    lazy = False\n)\n# if lazy= True  it will run next time I say .maximize\n# if lazy = False it will run the optimizing right now.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer.max[\"params\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\noptimized_lgb_params = {\n        'num_leaves': int(optimizer.max[\"params\"][\"num_leaves\"]),\n        'max_bin': 63,\n        'min_data_in_leaf': int(optimizer.max[\"params\"][\"min_data_in_leaf\"]),\n        'learning_rate': optimizer.max[\"params\"][\"learning_rate\"],\n        'min_sum_hessian_in_leaf': optimizer.max[\"params\"][\"min_sum_hessian_in_leaf\"],\n        'bagging_fraction': 1.0,\n        'bagging_freq': 5,\n        'feature_fraction': optimizer.max[\"params\"][\"feature_fraction\"],\n        'lambda_l1': optimizer.max[\"params\"][\"lambda_l1\"],\n        'lambda_l2': optimizer.max[\"params\"][\"lambda_l2\"],\n        'min_gain_to_split': optimizer.max[\"params\"][\"min_gain_to_split\"],\n        'max_depth': int(optimizer.max[\"params\"][\"max_depth\"]),\n        'save_binary': True, \n        'seed': 1337,\n        'feature_fraction_seed': 1337,\n        'bagging_seed': 1337,\n        'drop_seed': 1337,\n        'data_random_seed': 1337,\n        'objective': 'regression',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'rmse',\n        'is_unbalance': True,\n        'boost_from_average': False, \n    }\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nfold = 5\nimport gc\ngc.collect()\nskf2 = StratifiedKFold(n_splits = nfold, shuffle = True, random_state=68)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# prediction with 5 time prediciting.\n\nlet's create prediction.\n\nthis way of predicting will output 202 rank better than predicting with one time predicting."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"predictions1 = np.zeros((len(y_test), nfold))\ni = 1\nfor train_index, val_index in skf2.split(X_train, y_train):\n    train_set_lgb = lgb.Dataset(X_train.iloc[train_index][predictors].values,\n                                label= y_train[train_index],\n                                feature_name= predictors,\n                                free_raw_data=False)\n    \n    val_set_lgb = lgb.Dataset(X_train.iloc[val_index][predictors].values,\n                                label= y_train[val_index],\n                                feature_name= predictors,\n                                free_raw_data=False)\n    clf = lgb.train(optimized_lgb_params, train_set_lgb, 5000, valid_sets = [val_set_lgb],\n                   verbose_eval=250, early_stopping_rounds = 50)\n    \n    predictions1[:,i-1] += clf.predict(X_test[predictors], num_iteration=clf.best_iteration)\n    i = i + 1\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"su=[sum(i) for i in predictions1]\nnewList = [ x / 5 for x in su]\nnewList","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clipedList = [20 if x > 20 else x  for x in newList ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit3 = pd.DataFrame({'ID':range(214200), 'item_cnt_month': clipedList})\nsubmit3.to_csv('submit3.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# prediction with 1 time of prediction\n\nnext cell is prediction without ranked averaging "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_index2, val_index2 = list(StratifiedKFold(2, random_state=12, shuffle=True).split(X_train, y_train))[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction with 1 time of prediction.\npredictions = np.zeros((len(y_test), nfold))\n\n\ntrain_set_lgb = lgb.Dataset(X_train.iloc[train_index2][predictors].values,\n                            label= y_train[train_index2],\n                            feature_name= predictors,\n                            free_raw_data=False)\n    \nval_set_lgb = lgb.Dataset(X_train.iloc[val_index2][predictors].values,\n                            label= y_train[val_index2],\n                            feature_name= predictors,\n                            free_raw_data=False)\nclf = lgb.train(optimized_lgb_params, train_set_lgb, 5000, valid_sets = [val_set_lgb],\n                verbose_eval=250, early_stopping_rounds = 50)\n    \npredictions = clf.predict(X_test[predictors], num_iteration=clf.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = predictions.clip(0,20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions\n\nsubmit = pd.DataFrame({'ID':range(len(predictions)), 'item_cnt_month': final})\nsubmit.to_csv('submit.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}