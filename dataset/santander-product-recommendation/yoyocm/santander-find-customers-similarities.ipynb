{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c11219ab-0cad-eb9a-0161-69d8c7f055ea"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"364f384d-a1c4-8ea9-a333-d76bb45bdbb2"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7ce92e0-db2a-2a79-d6a7-d551bffa804d"},"outputs":[],"source":"N_ROWS = 1000\nfilename = \"../input/train_ver2.csv\"\n\n#n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\nn = 13647309 #number of records in train_ver2.csv\nprint(n)\nskip = sorted(random.sample(range(1,n+1),n-N_ROWS)) #the 0-indexed header will not be included in the skip list"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3512f550-6da2-9b50-2cb5-c653f3cf8b3c"},"outputs":[],"source":"df = pd.read_csv(filename, skiprows=skip)\nprint(df.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"40c75bde-e621-7686-8cee-118c8443793d"},"outputs":[],"source":"df['fecha_dato'] = pd.to_datetime(df['fecha_dato'])\ndf['fecha_alta'] = pd.to_datetime(df['fecha_alta'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8be32910-b387-ec91-cab5-db016f0d287a"},"outputs":[],"source":"import re \n\npattern = re.compile(\"ind_.*_ult1\")\n\nprod_cols = [ x for x in df.columns if re.match(pattern,x) ]\nprod_cols.append(\"ncodpers\")\nprint(prod_cols)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83a57fb7-3391-50ad-6c2b-64e3d342e4cd"},"outputs":[],"source":"df_dummiesed = pd.get_dummies(df)\ndf_dummiesed = df_dummiesed.drop_duplicates(subset=\"ncodpers\",keep=\"last\")\ndf_dummiesed[\"fecha_alta\"] = pd.to_numeric(df_dummiesed[\"fecha_alta\"])\ndf_dummiesed[\"fecha_dato\"] = pd.to_numeric(df_dummiesed[\"fecha_dato\"])\n#df_dummiesed = df_dummiesed.drop(\"conyuemp\",axis=1).fillna(df_dummiesed.mean())\ndf_dummiesed = df_dummiesed.drop(\"conyuemp\",axis=1).dropna()\n\nprint(df_dummiesed.describe())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a1256b6-fb36-1d94-0cff-1a8b01646d4a"},"outputs":[],"source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ns = []\nfor n_clusters in range(2,20):\n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(df_dummiesed)\n\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n\n    s.append(silhouette_score(df_dummiesed, labels, metric='euclidean'))\n\nplt.plot(s)\nplt.ylabel(\"Silouette\")\nplt.xlabel(\"k\")\nplt.title(\"Silouette for K-means cell's behaviour\")\nsns.despine()"},{"cell_type":"markdown","metadata":{"_cell_guid":"14bbfe31-7498-8fd0-6563-70ba93adcbcd"},"source":"With elbow method, I choose **11** clusters in order to classify customers. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"643e2123-2b5b-f29a-1fa0-6f1ce896eb59"},"outputs":[],"source":"N_CLUSTERS = 11\nkmeans = KMeans(n_clusters=N_CLUSTERS)\nkmeans.fit(df_dummiesed)\n\nprint(kmeans.labels_)\nplt.hist(kmeans.labels_,bins=N_CLUSTERS-1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"647075d2-ba23-df7d-b8c6-fde10a994a6a"},"source":"Here is the customers' similarities matrix. Values are really high because of dummies features but it's still meaningful. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c5783461-1c2a-d20c-7994-b399e0b184d0"},"outputs":[],"source":"from sklearn.metrics.pairwise import cosine_similarity\n\nsim = cosine_similarity(df_dummiesed,dense_output=False)\ndf_sim = pd.DataFrame(sim,columns=df_dummiesed['ncodpers'],index=df_dummiesed['ncodpers'])\n\nprint(df_sim)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}