{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"bed1cdfd-60fa-177d-6239-901f85f90992","_active":false},"source":"HEADS (Data Cleaning/Visualization)","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"96bd1883-1d1a-4ae4-d3ba-2a47f6a22f05","_active":false},"source":"Using Alan (AJ) Pryor, Jr. part code to clean and visualization data. Thnks a lot.","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":45,"metadata":{"_cell_guid":"fdb69dd8-d97d-2655-ecf7-d6760e3852b4","_active":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\nfrom xgboost import plot_tree\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import  train_test_split\nfrom sklearn import metrics\nfrom sklearn.cross_validation import KFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom collections import defaultdict\n%pylab inline\npylab.rcParams['figure.figsize'] = (10, 6)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"c413fa5c-a496-a2d8-1934-06610e3f3387","_active":false},"source":"CALIBRATE (Data Cleaning/Visualization)","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":46,"metadata":{"_cell_guid":"1bb87185-9d71-9b68-8fac-66153b765fe5","_active":false},"outputs":[],"source":"# Calibrate the number of rows to not crash the kernel \nlimit_rows   = 2000000\ndf           = pd.read_csv(\"../input/train_ver2.csv\",dtype={\"sexo\":str,\n                                                    \"ind_nuevo\":str,\n                                                    \"ult_fec_cli_1t\":str,\n                                                    \"indext\":str}, nrows=limit_rows)\n# Format to datetime data,maybe the month of the year is important to purchase\ndf[\"fecha_dato\"] = pd.to_datetime(df[\"fecha_dato\"],format=\"%Y-%m-%d\")\ndf[\"fecha_alta\"] = pd.to_datetime(df[\"fecha_alta\"],format=\"%Y-%m-%d\")\ndf[\"month\"] = pd.DatetimeIndex(df[\"fecha_dato\"]).month\ndf[\"age\"]   = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n# Not very sure just to keep with unique_ids 'cause principal id is fecha_dato + ncodpers and if we\n# eliminate repeated ncodpers we lose some important information.\n#We take unique_ids and unique fecha_datos just to play forward.\nunique_ids   = pd.Series(df[\"ncodpers\"].unique())\nunique_fecha_dato = df[\"fecha_dato\"].unique()\n#df.count()\n#unique_ids.count()\n#limit_people = 1e4\n# unique_id    = unique_ids.sample(n=limit_people)\n# df           = df[df.ncodpers.isin(unique_id)]\ndf.head()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"b5a40578-c405-ae77-54d8-369a3bff9512","_active":false},"source":"Looking for missings values","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":47,"metadata":{"_cell_guid":"e310e577-d5ef-dde5-49b5-9d7e99ac115e","_active":false},"outputs":[],"source":"df.isnull().any()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"820ea45b-72ea-b9b5-bdb4-ad81bd171850","_active":false},"source":"Age Study","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":48,"metadata":{"_cell_guid":"54b801f0-4339-e576-62be-3c8dcd7ee667","_active":false},"outputs":[],"source":"with sns.plotting_context(\"notebook\",font_scale=2.0):\n    sns.set_style(\"darkgrid\")\n    sns.distplot(df[\"age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"tomato\")\n    sns.plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\")","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"bbea4deb-ca8a-03fb-9ff0-8f2c9aa1ada5","_active":false},"source":"Values above 90 and below 18?. Let's separate the distribution and move the outliers to the mean of the closest one.\nMissing was replace with mean? Maybe eliminate?\nTwo important big groups \"College Area\" and \"Middle Age Area\"","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":49,"metadata":{"_cell_guid":"8865b51e-6fb2-9f4f-3a1f-6e11f64757d6","_active":false},"outputs":[],"source":"\ndf.loc[df.age < 18,\"age\"]  = df.loc[(df.age >= 18) & (df.age <= 30),\"age\"].mean(skipna=True)\ndf.loc[df.age > 90,\"age\"] = df.loc[(df.age >= 30) & (df.age <= 90),\"age\"].mean(skipna=True)\ndf[\"age\"].fillna(df[\"age\"].mean(),inplace=True)\ndf[\"age\"] = df[\"age\"].astype(int)","execution_state":"idle"},{"cell_type":"code","execution_count":50,"metadata":{"_cell_guid":"ea9762dd-8ed8-5395-c93a-28fddfcdb387","_active":false},"outputs":[],"source":"with sns.plotting_context(\"notebook\",font_scale=2.0):\n    sns.set_style(\"darkgrid\")\n    sns.distplot(df[\"age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"tomato\")\n    sns.plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\")\n    plt.xlim((15,100))","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"0f41d119-ea07-8e3d-43ce-7659b5619316","_active":false},"source":"Empty columns for some ages?? REVIEW","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":51,"metadata":{"_cell_guid":"0f952008-e006-8839-16cf-05e5e4c982bd","_active":false},"outputs":[],"source":"df[\"ind_nuevo\"].isnull().sum()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"930d8f0e-64fa-fcdb-4f42-cfeea26dbd6b","_active":false},"source":"For missing values in ind_nuevo we can fill in missing values by looking how many months of history these customers have.","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":52,"metadata":{"_cell_guid":"a14296eb-4790-80cf-0889-54cdeac6ed3b","_active":false},"outputs":[],"source":"months_active = df.loc[df[\"ind_nuevo\"].isnull(),:].groupby(\"ncodpers\", sort=False).size()\nmonths_active.max()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"035b174f-4cd0-75d1-ad93-eed0691db16a","_active":false},"source":"Looks like these are all new customers, so replace accordingly.","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":53,"metadata":{"_cell_guid":"fa4e09bd-7bae-a2e2-e3ac-981d0b93ba03","_active":false},"outputs":[],"source":"df.loc[df[\"ind_nuevo\"].isnull(),\"ind_nuevo\"] = 1","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"3215c99e-4ebf-3848-1669-9a65ad31148c","_active":false},"source":"Missing values in Antiguedad","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":54,"metadata":{"_cell_guid":"28a4b1fb-4ca2-406c-3ab3-5ff71164fe11","_active":false},"outputs":[],"source":"df.antiguedad = pd.to_numeric(df.antiguedad,errors=\"coerce\")\nnp.sum(df[\"antiguedad\"].isnull())","execution_state":"idle"},{"cell_type":"code","execution_count":55,"metadata":{"_cell_guid":"b3e120d9-c07a-7d5a-2935-94919d0aeb2e","_active":false},"outputs":[],"source":"df.loc[df[\"antiguedad\"].isnull(),\"ind_nuevo\"].describe()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"66240abd-b9b7-112a-fade-81e497b966ec","_active":false},"source":"Missing Antiguedad = min Antiguedad","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":56,"metadata":{"_cell_guid":"d821dd5f-c01d-16fa-2bc1-2dd4cfbed89d","_active":false},"outputs":[],"source":"df.loc[df.antiguedad.isnull(),\"antiguedad\"] = df.antiguedad.min()\ndf.loc[df.antiguedad <0, \"antiguedad\"] = 0","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"4de052b5-dfa0-ae00-60e5-3ea735040575","_active":false},"source":"Some entries don't have the date they joined the company. I don't think that it is a very important date, just give them something in the middle of the pack (median)","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":57,"metadata":{"_cell_guid":"e102c873-ac8f-d124-90b7-08406ad88afa","_active":false},"outputs":[],"source":"dates=df.loc[:,\"fecha_alta\"].sort_values().reset_index()\nmedian_date = int(np.median(dates.index.values))\ndf.loc[df.fecha_alta.isnull(),\"fecha_alta\"] = dates.loc[median_date,\"fecha_alta\"]\ndf[\"fecha_alta\"].describe()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"7bd0f680-65aa-682a-fa35-9c73c7a51ed6","_active":false},"source":"Missing values in indrel, 1 (First/Primary), 99 (Primary customer during the month but not at the end of the month).\nFill in missing with the more common status? We have to find a package Recursive partitioning type to infer missing values (MICE in R or RPART in R type)","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":58,"metadata":{"_cell_guid":"4114def9-fa85-6b10-fa16-f97eefd0c0b1","_active":false},"outputs":[],"source":"pd.Series([i for i in df.indrel]).value_counts()","execution_state":"idle"},{"cell_type":"code","execution_count":59,"metadata":{"_cell_guid":"698f1edd-9f9a-76d6-b9fd-375efa00336c","_active":false},"outputs":[],"source":"df.loc[df.indrel.isnull(),\"indrel\"] = 1","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"ef005d01-4e78-e06e-513a-87de9bbf7aeb","_active":false},"source":"tipodom doesn't seem to be useful (drop this), and I prefer the province code (is factorized) instead the name of the province in nomprov. We use nomprov for visualization purposes only. (PRINT DISTRIBUTION)","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":60,"metadata":{"_cell_guid":"63b5e698-d96f-f856-14d2-5a2e03e3a591","_active":false},"outputs":[],"source":"df.drop([\"tipodom\"],axis=1,inplace=True)","execution_state":"idle"},{"cell_type":"code","execution_count":61,"metadata":{"_cell_guid":"8bfaf80f-09d9-b942-7fd1-2c4ecfbeb8b6","_active":false},"outputs":[],"source":"df[\"nomprov\"].isnull().sum()","execution_state":"idle"},{"cell_type":"code","execution_count":62,"metadata":{"_cell_guid":"8c4cdf40-4b03-fb27-9343-690230fc16cb","_active":false},"outputs":[],"source":"df[\"cod_prov\"].isnull().sum()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"ae8709bc-1ba0-dffa-4dd7-65a9d8f1cb3e","_active":false},"source":"Zero Value for NaN in cod_prov","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":63,"metadata":{"_cell_guid":"6ae2f1cd-5ec0-7d78-aa6e-e827764d07d0","_active":false},"outputs":[],"source":"unique_cod_prov = df[\"cod_prov\"].unique()\nunique_nomprov = df[\"nomprov\"].unique()\ndf.loc[df.cod_prov.isnull(),\"cod_prov\"] = 0","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"2da61a01-75a7-cd21-00ae-c99cfe8bc8e4","_active":false},"source":"A few values in ind_actividad_cliente are missing. We use the median.\n","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":64,"metadata":{"_cell_guid":"63a64a42-37ef-11bc-6f52-9b58be2f18b6","_active":false},"outputs":[],"source":"np.sum(df[\"ind_actividad_cliente\"].isnull())\ndf.loc[df.ind_actividad_cliente.isnull(),\"ind_actividad_cliente\"] = \\\ndf[\"ind_actividad_cliente\"].median()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"e5cafb4a-b69b-408a-358a-a464489a0ccc","_active":false},"source":"Renta missing values (There is a lot)","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":65,"metadata":{"_cell_guid":"197baa4d-6750-35af-fa50-49fbed087505","_active":false},"outputs":[],"source":"df.renta.isnull().sum()","execution_state":"idle"},{"cell_type":"code","execution_count":66,"metadata":{"_cell_guid":"66b181c0-273f-e5fa-c03a-862088935212","_active":false},"outputs":[],"source":"incomes = df.loc[df.renta.notnull(),:].groupby(\"nomprov\").agg({\"renta\":{\"MedianIncome\":median}})\nincomes.sort_values(by=(\"renta\",\"MedianIncome\"),inplace=True)\nincomes.reset_index(inplace=True)\nincomes.nomprov = incomes.nomprov.astype(\"category\", categories=[i for i in df.nomprov.unique()],ordered=False)\nincomes.head()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"6125e6ea-53ed-a32c-8fd5-49e82c4232c9","_active":false},"source":"No way!! This median renta in Spain it's not real FOR SURE","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":67,"metadata":{"_cell_guid":"6168e27a-39e3-7bae-790a-68694e8c0c6e","_active":false},"outputs":[],"source":"with sns.axes_style({\n        \"axes.facecolor\":   \"blue\",\n        \"axes.grid\"     :    False,\n        \"figure.facecolor\": \"white\"}):\n    h = sns.factorplot(data=incomes,\n                   x=\"nomprov\",\n                   y=(\"renta\",\"MedianIncome\"),\n                   order=(i for i in incomes.nomprov),\n                   size=6,\n                   aspect=1.5,\n                   scale=1.0,\n                   color=\"#ffc400\",\n                   linestyles=\"None\")\nplt.xticks(rotation=90)\nplt.tick_params(labelsize=10,labelcolor=\"black\")#\nplt.ylabel(\"Median Income\",size=18,color=\"black\")\nplt.xlabel(\"City\",size=18,color=\"black\")\nplt.title(\"Income Distribution by City\",size=20,color=\"black\")\nplt.ylim(0,180000)\nplt.yticks(range(0,180000,40000))","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"fb3745d5-b44c-6247-1d5f-611d7c4a16c3","_active":false},"source":" Assigning missing incomes by province is a good idea. First group the data by city, and reduce to get the median. TO REVIEW","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":68,"metadata":{"_cell_guid":"6fa9bcf7-ff01-39c2-fbc2-ae97588e732b","_active":false},"outputs":[],"source":"grouped        = df.groupby(\"nomprov\").agg({\"renta\":lambda x: x.median(skipna=True)}).reset_index()\nnew_incomes    = pd.merge(df,grouped,how=\"inner\",on=\"nomprov\").loc[:, [\"nomprov\",\"renta_y\"]]\nnew_incomes    = new_incomes.rename(columns={\"renta_y\":\"renta\"}).sort_values(\"renta\").sort_values(\"nomprov\")\ndf.sort_values(\"nomprov\",inplace=True)\ndf             = df.reset_index()\nnew_incomes    = new_incomes.reset_index()","execution_state":"idle"},{"cell_type":"code","execution_count":69,"metadata":{"_cell_guid":"3276e665-65a9-f768-aeae-f3d08956a907","_active":false},"outputs":[],"source":"df.loc[df.renta.isnull(),\"renta\"] = new_incomes.loc[df.renta.isnull(),\"renta\"].reset_index()\ndf.loc[df.renta.isnull(),\"renta\"] = df.loc[df.renta.notnull(),\"renta\"].median()\ndf.sort_values(by=\"fecha_dato\",inplace=True)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"6a6f2b62-eb25-8a63-30ba-710a7c0222bb","_active":false},"source":"Drop nomprov column (cod_prov is the same column)","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":70,"metadata":{"_cell_guid":"7cd09ae4-8cec-bad4-ea7c-3b81d6556b84","_active":false},"outputs":[],"source":"df.drop([\"nomprov\"],axis=1,inplace=True)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"99131b0b-1f07-3804-1ca1-bfd097122a74","_active":false},"source":"The next columns with missing data I'll look at are features, which are just a boolean indicator as to whether or not that product was owned that month. We assume that the bank has all his products purchases under control so missing values becomes 0 (not owed).","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":71,"metadata":{"_cell_guid":"da50fb08-66c8-87b4-18e0-5221fb074810","_active":false},"outputs":[],"source":"df.ind_nomina_ult1.isnull().sum()","execution_state":"idle"},{"cell_type":"code","execution_count":72,"metadata":{"_cell_guid":"e89a5f9c-073b-8b5c-c972-9a7231531e7f","_active":false},"outputs":[],"source":"df.ind_nom_pens_ult1.isnull().sum()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"6cb842eb-c880-5c33-402e-06fc0d17da74","_active":false},"source":"REVIEW :The values is assigned like float. Convert float value into int (Did it forward)","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":73,"metadata":{"_cell_guid":"3837add0-32be-b35c-379a-0bca47eeef5d","_active":false},"outputs":[],"source":"df.loc[df.ind_nomina_ult1.isnull(), \"ind_nomina_ult1\"] = 0\ndf.loc[df.ind_nom_pens_ult1.isnull(), \"ind_nom_pens_ult1\"] = 0","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"d7e1ab8e-17c6-7164-9a09-03a30bbc805d","_active":false},"source":"Last columns with missing values: \n'ind_empleado', 'pais_residencia', 'sexo', 'ult_fec_cli_1t', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'segmento'","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":74,"metadata":{"_cell_guid":"220ba588-a639-4f6e-5c72-f1cf77772c41","_active":false},"outputs":[],"source":"string_data = df.select_dtypes(include=[\"object\"])\nmissing_columns = [col for col in string_data if string_data[col].isnull().any()]\nfor col in missing_columns:\n    print(\"Unique values for {0}:\\n{1}\\n\".format(col,string_data[col].unique()))\ndel string_data","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"1bad0326-0bdb-b8df-7632-d2475003d344","_active":false},"source":"Based on that and the definitions of each variable, We fill the empty strings either with the most common value or create an unknown category based on what I think makes more sense.\n\n'indfall': A deceased client is not going to purchase a new product, Is really decisive this feature? CAN WE ELIMINATE THIS FEATURE?\n\n'tiprel_1mes': We must factorize this feature A=1 I=2 P=3 R=4 (P=Former customer and R=Potencial???) df.loc[df.tiprel_1mes==\"A\"] = 1,  convert to int\n\n'ind_empleado','pais_residencia' ,'sexo','ult_fec_cli_1t','indresi','indext','conyuemp','canal_entrada','segmento' -->UNKNOWN Value for missing values","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":75,"metadata":{"_cell_guid":"90c44165-11c1-7c5f-7810-e4094a0514ee","_active":false},"outputs":[],"source":"df.loc[df.indfall.isnull(),\"indfall\"] = \"N\"\ndf.loc[df.tiprel_1mes.isnull(),\"tiprel_1mes\"] = \"A\"\ndf.tiprel_1mes = df.tiprel_1mes.astype(\"category\")\n\n# As suggested by @StephenSmith\nmap_dict = { 1.0  : \"1\",\n            \"1.0\" : \"1\",\n            \"1\"   : \"1\",\n            \"3.0\" : \"3\",\n            \"P\"   : \"P\",\n            3.0   : \"3\",\n            2.0   : \"2\",\n            \"3\"   : \"3\",\n            \"2.0\" : \"2\",\n            \"4.0\" : \"4\",\n            \"4\"   : \"4\",\n            \"2\"   : \"2\"}\n\ndf.indrel_1mes.fillna(\"P\",inplace=True)\ndf.indrel_1mes = df.indrel_1mes.apply(lambda x: map_dict.get(x,x))\ndf.indrel_1mes = df.indrel_1mes.astype(\"category\")\n\n\nunknown_cols = [col for col in missing_columns if col not in [\"indfall\",\"tiprel_1mes\",\"indrel_1mes\"]]\nfor col in unknown_cols:\n    df.loc[df[col].isnull(),col] = \"UNKNOWN\"","execution_state":"idle"},{"cell_type":"code","execution_count":76,"metadata":{"_cell_guid":"db454115-dedc-e4e3-fd35-0b9bcf2d3b6f","_active":false},"outputs":[],"source":"df.isnull().any()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"aae2296f-743c-be0e-e9e8-6262f2d15a99","_active":false},"source":"Convert the products feature columns into integer values","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":77,"metadata":{"_cell_guid":"802d9be6-7d6d-0aa0-84a7-ec4c0daf703d","_active":false,"collapsed":false},"outputs":[],"source":"feature_cols = df.iloc[:1,].filter(regex=\"ind_+.*ult.*\").columns.values\nfor col in feature_cols:\n    df[col] = df[col].astype(int)\n    \n","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"ac12a76d-7ee6-7e3e-e5cf-f533283fb57c","_active":false},"source":"TRAINING MODEL (v1 LogisticRegression -  v2 Gradient Boosting)","outputs":[],"execution_count":null,"execution_state":"idle"},{"cell_type":"code","execution_count":78,"metadata":{"_cell_guid":"0bb017bd-f971-d6c9-c410-da9ee7569049","_active":false,"collapsed":false},"outputs":[],"source":"\nusecols = ['ncodpers', 'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n       \ndf_train = pd.read_csv(\"../input/train_ver2.csv\",dtype={\"sexo\":str,\n                                                    \"ind_nuevo\":str,\n                                                    \"ult_fec_cli_1t\":str,\n                                                    \"indext\":str}, nrows=limit_rows)\n\ndf_test = pd.read_csv(\"../input/test_ver2.csv\",dtype={\"sexo\":str,\n         \"ind_nuevo\":str,\"ult_fec_cli_1t\":str,\"indext\":str}, nrows=limit_rows)\n\n# pd.read_csv('../input/train.csv', usecols=usecols)\n\n\ndf_train = df_train.drop_duplicates(['ncodpers'], keep='last')\ndf_test = df_test.drop_duplicates(['ncodpers'], keep='last')\ndf_train.fillna(0, inplace=True)\ndf_test.fillna(0, inplace=True)","execution_state":"idle"},{"metadata":{"_cell_guid":"b7103f89-92c6-ecc2-aeea-4f6c88163662","_active":false,"collapsed":false},"source":"print(len(df_train['renta']))\nprint(len(df_train))","execution_count":79,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"84598b97-049a-9151-3171-417f5e770588","_active":false,"collapsed":false},"source":null,"execution_count":80,"cell_type":"code","outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":80,"metadata":{"_cell_guid":"ce0c16d5-c5d0-8471-d50d-bdc3af0d5c2c","_active":false,"collapsed":false},"outputs":[],"source":"\n\nmodels = {}\nid_preds = defaultdict(list)\nids = df_train['ncodpers'].values\n\n#Delete in final model (Done before)\nfeature_cols = df.iloc[:1,].filter(regex=\"ind_+.*ult.*\").columns.values\nfor col in feature_cols:\n    df[col] = df[col].astype(int)\n# -------------------------------------------------------------------------------------------#    \nfor c in df_train.filter(regex=\"ind_+.*ult.*\").columns:\n    if c != 'ncodpers':\n        print(c)\n        y_train = df_train[c]\n        x_train = df_train[['renta','ncodpers']]#.drop([c, 'ncodpers'], 1)\n        \n        # For v2 Gradient Boosting\n        #y_test = df_test[c]\n        #x_test = df_test.drop([c, 'ncodpers'], 1)\n        #model = XGBClassifier()\n        #model.fit(x_train,y_train)\n        #p_train = model.predict(x_test)[:,1] \n \n        \n        \n        #models[c] = model\n        #for id, p in zip(ids, p_train):\n        #    id_preds[id].append(p)\n        #    \n        #print(metrics.accuracy_score(y_test, p_train))\n        #----------------------------------------------#\n        \n        # For v1 Logistic Regression\n        clf = LogisticRegression()\n        clf.fit(x_train, y_train)\n        p_train = clf.predict_proba(x_train)[:,1]\n        \n        models[c] = clf\n        for id, p in zip(ids, p_train):\n            id_preds[id].append(p)\n            \n        print(roc_auc_score(y_train, p_train))\n        #----------------------------------------------#","execution_state":"idle"},{"cell_type":"code","execution_count":81,"metadata":{"_cell_guid":"30d5976a-4a20-290d-d2f6-cca263d0ce32","_active":true,"collapsed":false},"outputs":[],"source":"\n# for each ncodpers bring back every active (1) product in a dict ncodper: list of active products\nalready_active = {}\nfor row in df_train.values:\n    row = list(row)\n    id = row.pop(0)\n    active = [c[0] for c in zip(df_train.columns[1:], row) if c[1] > 0]\n    already_active[id] = active\n\n# returns the names of the products in order of probabilities    \n# id_preds is a list of id + probability vector of length 23 (predict value of #25 to #48 columns)\n# and preds just keep the value of probability if the feature is not \"already active\"\n#train_preds = {}\n#for id, p in id_preds.items():\n    # Here be dragons\n    #preds = [i[0] for i in sorted([i for i in zip(df_train.columns[1:], p) if i[0] not in already_active[id]], key=lambda i:i [1], reverse=True)[:7]]\n    #train_preds[id] = preds\n   ","execution_state":"idle"},{"metadata":{"_cell_guid":"4c09aced-b6c1-4f36-d331-505760ce26ad","_active":false,"collapsed":false},"source":"null","execution_count":82,"cell_type":"code","outputs":[],"execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"04479adc-3647-73e2-268b-0dc8a629d944","_active":false},"source":"FINAL TEST (SUBMISSION FORMAT)","outputs":[],"execution_count":null,"execution_state":"idle"},{"metadata":{"_cell_guid":"39eb57e3-fac0-5944-bbea-2a1b2d1510e4","_active":false,"collapsed":false},"source":"df_test[df_test['renta']=='         NA']=0\ndf_test['renta'].describe()","execution_count":88,"cell_type":"code","outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":91,"metadata":{"_cell_guid":"5d2cb2f7-955d-f23f-533c-cafbe0acbe49","_active":false,"collapsed":false},"outputs":[],"source":"colsfinales = [ 'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n\ntest_preds = []\nfor row in df_test.values:\n    df_test['added_products']=''\n    for c in colsfinales:\n        x_test = df_test[['renta','ncodpers']]\n        \n        p_train = models[c].predict_proba(x_test)[:,1]\n        if(p_train[1]>0.5):\n            df_test['added_products']=df_test['added_products']+' '+c\n\n\npd.DataFrame({'added_products': df_test['added_products'], 'ncodpers': df_test['ncodpers']}).to_csv(filename, index=False)","execution_state":"busy"},{"cell_type":"code","execution_count":84,"metadata":{"_cell_guid":"208a818a-669c-1192-5f9b-c5de174ae952","_active":false},"outputs":[],"source":null,"execution_state":"idle"}]}