{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2149f0fc-7cb6-a333-a8ea-9ea683e3a3dd"},"source":"**Santandar Product Recommendation Engine**\n\nThis is my first Kaggle competition. I am starting with a general sketch of my process, will come back and edit as I move along.\n\n1. Data Wrangling \n2. EDA - Exploratory Data Analysis\n3. Feature Engineering\n4. Building Model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b40f8058-f558-289e-b689-42790822b4b8"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n%matplotlib inline\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom collections import OrderedDict\nimport math\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"8c50380f-b843-a2dc-7669-de99da87738d"},"source":"**Loading Data**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c55cb62b-3696-2df4-67a6-243338ce2990"},"outputs":[],"source":"chunksize = 2000000\nfilename = '../input/train_ver2.csv'\n\ndate_list = ['2015-01-28','2015-02-28','2015-03-28','2015-04-28','2015-05-28',\n            '2015-06-28','2015-07-28','2015-08-28','2015-09-28','2015-10-28',\n            '2015-11-28','2015-12-28','2016-01-28','2016-02-28','2016-03-28',\n            '2016-04-28','2016-05-28']\n#date_list = ['2016-01-28','2016-02-28','2016-03-28','2016-04-28','2016-05-28']\ndate_list = ['2016-04-28','2016-05-28']\n\nproduct_list = ['savings_acc','guarantees','current_acc','derivada_acc',\n             'payroll_acc','junior_acc','mas_particular_acc','particular_acc',\n             'particular_plus_acc','short_term_deposits','med_term_deposits',\n             'long_term_deposits','e_accounts','funds','mortgage','pensions_plan',\n             'loans','taxes','credit_card','securities',\n             'home_acc','payroll','pensions_nom', 'direct_debit']\n\nscalar = ['record_dt','employee_index',\n            'cust_residence_country','cust_gender','new_cust_ind',\n            'cust_status','beg_mnth_cust_type','beg_mth_cust_relation',\n            'resident_ind','foreigner_ind','employee_spouse_ind',\n            'entry_channel','deceased_ind','address_type',\n            'cust_address_province_cd','cust_address_province',\n            'cust_activity_index',\n            'cust_segment']\n\nscalar = ['record_dt','employee_index',\n            'cust_residence_country',\n            'cust_status','beg_mnth_cust_type','beg_mth_cust_relation',\n            'employee_spouse_ind',\n            'deceased_ind',\n            'cust_address_province_cd','cust_address_province',\n            'cust_activity_index']\n\ncol_dict = {'fecha_dato':'record_dt',\n            'ncodpers':\t'cust_id','ind_empleado':'employee_index',\n            'pais_residencia': 'cust_residence_country',\n            'sexo':'cust_gender','age':'cust_age',\n            'fecha_alta':'cust_start_dt',\n            'ind_nuevo':'new_cust_ind',\n            'antiguedad':'cust_seniority_mnths',\n            'indrel':'cust_status',\n            'ult_fec_cli_1t':'last_dt_as_prim_cust',\n            'indrel_1mes':'beg_mnth_cust_type',\n            'tiprel_1mes':'beg_mth_cust_relation',\n            'indresi':'resident_ind','indext':'foreigner_ind',\n            'conyuemp':'employee_spouse_ind',\n            'canal_entrada':'entry_channel',\n            'indfall':'deceased_ind',\n            'tipodom':'address_type',\n            'cod_prov':'cust_address_province_cd',\n            'nomprov':'cust_address_province',\n            'ind_actividad_cliente':'cust_activity_index',\n            'renta':'gross_household_income',\n            'segmento': 'cust_segment',\n            'ind_ahor_fin_ult1':'savings_acc',\n            'ind_aval_fin_ult1':'guarantees',\n            'ind_cco_fin_ult1':'current_acc',\n            'ind_cder_fin_ult1':'derivada_acc',\n            'ind_cno_fin_ult1':'payroll_acc',\n            'ind_ctju_fin_ult1':'junior_acc',\n            'ind_ctma_fin_ult1':'mas_particular_acc',\n            'ind_ctop_fin_ult1':'particular_acc',\n            'ind_ctpp_fin_ult1':'particular_plus_acc',\n            'ind_deco_fin_ult1':'short_term_deposits',\n            'ind_deme_fin_ult1':'med_term_deposits',\n            'ind_dela_fin_ult1':'long_term_deposits',\n            'ind_ecue_fin_ult1':'e_accounts',\n            'ind_fond_fin_ult1':'funds',\n            'ind_hip_fin_ult1':'mortgage',\n            'ind_plan_fin_ult1':'pensions_plan',\n            'ind_pres_fin_ult1':'loans',\n            'ind_reca_fin_ult1':'taxes',\n            'ind_tjcr_fin_ult1':'credit_card',\n            'ind_valo_fin_ult1':'securities',\n            'ind_viv_fin_ult1':'home_acc',\n            'ind_nomina_ult1':'payroll',\n            'ind_nom_pens_ult1':'pensions_nom',\n            'ind_recibo_ult1': 'direct_debit'}\nreverse_cols = dict(zip(col_dict.values(),col_dict.keys()))\ncust_cols = ['record_dt','cust_id','cust_gender','cust_age','new_cust_ind','cust_seniority_mnths',\n        'deceased_ind','cust_address_province_cd','cust_address_province','cust_residence_country',\n        'cust_activity_index','cust_status','employee_spouse_ind','employee_index',\n        'gross_household_income','cust_segment','beg_mnth_cust_type','beg_mth_cust_relation']\n\n\ncust_cols = ['cust_id','record_dt','cust_address_province_cd','cust_address_province',\n            'cust_residence_country']\n\ncust_cols = ['cust_id','record_dt']\ncust_cols = cust_cols + product_list\ncust_cols_original = [reverse_cols[i] for i in cust_cols]\ncust_dict = {}\nfor i in cust_cols_original:\n    cust_dict[i] = col_dict[i]\nprint(date_list)\ncust_dict"},{"cell_type":"markdown","metadata":{"_cell_guid":"1bb096f6-bd44-ee1b-5c33-843bb34bf5a1"},"source":"**Knowing the Customer**\n\nHere I am going to try to know more about who the customers are. \nWhat demographic trends can I identify from the data monthly?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb7294c9-bf86-8606-4beb-4dca75c4e034"},"outputs":[],"source":"customer_trend = {}\nscalar_values = {}\nfor dt in date_list:\n    customer_trend[dt] = 0\nfor m in scalar:\n    scalar_values[m]= []\n    \nprint(customer_trend)\n#df_target = pd.DataFrame(index=[0], columns=list(reverse_cols.values()))\ndf_target = pd.DataFrame(index=[0], columns=['cust_id','record_dt','total_products','products']).dropna()\n#df_target = df_target.fillna(0) # with 0s rather than NaNs\n\n#country_province = []\ncountry_province_cols = [reverse_cols['cust_residence_country'],\n                         reverse_cols['cust_address_province_cd'],\n                         reverse_cols['cust_address_province']]\nc_p_rename = {'cod_prov':'cust_address_province_cd',\n              'nomprov':'cust_address_province',\n              'pais_residencia': 'cust_residence_country'}\nscalar_values['country_province'] = pd.DataFrame(index=[0], columns=country_province_cols)\\\n                                      .rename(index=str,columns=c_p_rename).dropna()\n\nuse_cols = ['cust_id','record_dt','cust_address_province_cd','cust_address_province',\n            'cust_residence_country','cust_status','employee_index','employee_spouse_ind',\n           'beg_mnth_cust_type','beg_mth_cust_relation','deceased_ind','cust_activity_index',\n           'cust_seniority_mnths','cust_age'] + product_list\n\n\nuse_cols_ori = [reverse_cols[i] for i in use_cols]\n\ndtype_dict = {reverse_cols['cust_id']:str,reverse_cols['record_dt']:str,\n              reverse_cols['cust_address_province_cd']:str,\n              reverse_cols['cust_address_province']:str,\n              reverse_cols['cust_residence_country']:str,\n              reverse_cols['cust_status']:str,\n              reverse_cols['employee_index']:str,\n              reverse_cols['employee_spouse_ind']:str,\n              reverse_cols['beg_mnth_cust_type']:str,\n              reverse_cols['beg_mth_cust_relation']:str,\n              reverse_cols['deceased_ind']:str,\n              reverse_cols['cust_activity_index']:str,\n              reverse_cols['cust_seniority_mnths']:str,\n              reverse_cols['cust_age']:str,\n              reverse_cols['savings_acc']:str,reverse_cols['guarantees']:str,\n              reverse_cols['current_acc']:str,reverse_cols['derivada_acc']:str,\n              reverse_cols['payroll_acc']:str,reverse_cols['junior_acc']:str,\n              reverse_cols['mas_particular_acc']:str,reverse_cols['particular_acc']:str,\n              reverse_cols['particular_plus_acc']:str,reverse_cols['short_term_deposits']:str,\n              reverse_cols['med_term_deposits']:int,reverse_cols['long_term_deposits']:str,\n              reverse_cols['e_accounts']:str,reverse_cols['funds']:str,\n              reverse_cols['mortgage']:str,reverse_cols['pensions_plan']:str,\n              reverse_cols['loans']:str,reverse_cols['taxes']:str,\n              reverse_cols['credit_card']:str,reverse_cols['securities']:str,\n              reverse_cols['home_acc']:str,reverse_cols['payroll']:str,\n              reverse_cols['pensions_nom']:str, reverse_cols['direct_debit']:str\n             }\n\n\nfor chunk in pd.read_csv(filename, usecols=use_cols_ori, dtype=dtype_dict, chunksize=chunksize):\n    for m in scalar:\n        s = chunk[reverse_cols[m]].dropna().unique().tolist()\n        scalar_values[m] = list(set(scalar_values[m] + s))\n    country_province_curr = chunk[country_province_cols].drop_duplicates().dropna()\\\n                                                        .rename(index=str,columns=c_p_rename)\n    df_c_p = scalar_values['country_province'].append(country_province_curr).drop_duplicates()\n    scalar_values['country_province'] = df_c_p\n    #print(country_province_curr)\n    #country_province = country_province + \n    for dt in date_list:\n        df = chunk[chunk[reverse_cols['record_dt']] ==  dt]\\\n               .drop_duplicates().rename(index=str,columns=col_dict)\n        if len(df)>0:\n            #print(dt)\n            #print(len(df),df.columns)\n            \n            df['cust_seniority_mnths'] = df['cust_seniority_mnths'].apply(lambda x: int(x))\n            df['cust_age'] = df['cust_age'].apply(lambda x: int(x))\n            df['cust_status'] = df['cust_status'].apply(lambda x: int(x))\n            df['cust_activity_index'] = df['cust_activity_index'].apply(lambda x: int(x))\n            \n            # Applying some basic filters\n            # Considering only Primary Account Holders\n            \n            df = df[df['cust_status']== 1]\n\n            # Considering only Non Employees and customers who are not spouse of employees\n            df = df[df['employee_index'] == 'N']\n            df = df[df['employee_spouse_ind'] != 'S']\n        \n            # Considering only those customer records when the customer was Active in the beg of month\n            # and customer relation is Primary in the beginning of the month\n            df = df[df['beg_mnth_cust_type'].isin(['1','1.0'])]\n            df = df[df['beg_mth_cust_relation'] == 'A']\n            df = df[df['cust_activity_index']==1]\n            df = df[df['deceased_ind'] == 'N']\n            \n            \n            df = df[df['cust_seniority_mnths'] >0]\n            df = df[df['cust_age'] >0]\n        \n            mem = df['cust_id'].dropna().unique().tolist()\n            customer_trend[dt] = customer_trend[dt] + len(list(set(mem)))\n            df['total_products'] = 0\n            df['products'] = ''\n            for m in product_list:\n                df[m] = df[m].apply(lambda x: int(x))\n                df['total_products'] += df[m]\n                df['products'] += df[m].apply(lambda x: (m +'|') if x == 1 else '' )\n            \n            #df['cust_id'] = df['cust_id'].apply(lambda x: 'c-'+ int(x))\n            df_target = df_target.append(df[['cust_id','record_dt','total_products','products']])\n            print(len(df_target),'|',dt)\n            print(df_target.head(3))\n    \ncustomer_trend"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4b003f9a-ca88-32ed-ef70-ffb76a9ac278"},"outputs":[],"source":"df_target['total_products'].unique()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d14def9-938c-0553-6c8d-18cb7b7a077d"},"outputs":[],"source":"#list(customer_trend.values())\nprint(customer_trend)\nprint(sorted(customer_trend))\ndt_arr = sorted(customer_trend)\nval_arr = [customer_trend[i] for i in sorted(customer_trend)]\na = np.arange(len(dt_arr))\nprint(a)\nprint(dt_arr[0])\nprint(val_arr[0])\nplt.bar(a,val_arr)\n#plt.bar(['1','2'], [100,200])\nplt.title(\"Santander Customers per Month\")\nplt.ylabel(\"Customer Volume\")\nplt.xticks(a, dt_arr, rotation='vertical')\n\nplt.grid(True)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a705f15f-0d38-a429-6795-364afd2f8250"},"outputs":[],"source":"# An indicator variable is one which takes a few, usually 2 values (1/0, True/False)\n#to code the existence or lack thereof of a property or feature. We look for existing indicators:\ndftouse = df_target.copy()\n\n#Encoding some indicator variables to 1 and 0\n#dftouse['cust_gender'] = dftouse['cust_gender'].apply(lambda m: 1 if m=='H' else 0)\n#dftouse['deceased_ind'] = dftouse['deceased_ind'].apply(lambda m: 1 if m=='S' else 0)\n\n#dftouse['beg_mnth_cust_type'].fillna(0)\n#dftouse['beg_mnth_cust_type'] = dftouse['beg_mnth_cust_type'].apply(lambda m: int(m.strip(\"'\").split('.')[0]) if type(m)==str else int(m))\n\n#Getting a sense of the data impurity. Inspecting for missing and nan values.\nfor v in dftouse.columns:\n    l=dftouse[v].unique()\n    print(v, l,len(l))  \n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1630c168-fa31-c2b1-49e0-f2d1be9ee086"},"outputs":[],"source":"#dftouse['product_id'] = ''\n#for v in dftouse.columns:\n    #l=dftouse[v].unique()\n    #print(v, l,len(l))\n#df_this = pd.DataFrame(index=[0], columns=['cust_id','record_dt','total_products','products','product_id']).dropna()\nfinal = []\nmems_d = dftouse['cust_id'].unique()\nfor m in mems_d[0:20000]:\n    t = dftouse[dftouse['cust_id'] == m]\n    #print(t.head())\n    for row in t.iterrows():\n        #print(row[1]['products'].split('|'))\n        for b in row[1]['products'].split('|'):\n            if b != '':\n                final.append((row[1]['cust_id'],row[1]['record_dt'],b))\nprint(len(mems_d))\nprint(len(final))\nprint(final[0:10])\n#for m in dftouse['products'].unique():\n    #df = dftouse[dftouse['products'] == m][['cust_id','record_dt','total_products','products']].drop_duplicates()\n    #product_id = m.split('|')\n    #dict_f = []\n    #for row in df.iterrows():\n        #print(row[1]['cust_id'])\n        #df_this.append({'cust_id':row[1]['cust_id'],'record_dt':row[1]['record_dt'],\n                       #'total_products':row[1]['total_products'],'products':row[1]['products'],\n                       #'product_id':m\n                     # },ignore_index=True)\n   "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89ade6e1-0fae-aed9-0fe3-32c8fd07770f"},"outputs":[],"source":"similarity = {}\ntotal_count = {}\nprint(len(product_list))\nfor i in product_list:\n    common_support = {}\n    df = dftouse[dftouse[i] == 1.0].drop_duplicates()\n    total_count[i] = len(df['cust_id'].unique())\n    #count how many members common with other product list\n    pdt_list = [x for x in product_list if x != i ]\n    for h in pdt_list:\n        #common = {}\n        common_df = df[df[h] == 1.0].drop_duplicates()\n        #common_df = common_df[['cust_id','record_dt']].drop_duplicates()\n        common_support[h] = len(common_df['cust_id'].unique())\n    similarity[i] = OrderedDict(sorted(common_support.items(), key=lambda t: t[1], reverse=True))\n    #similarity[i] = df[['cust_id','record_dt','g']]\nsimilarity"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"209c6686-0e46-a651-388f-c7a5c187d772"},"outputs":[],"source":"#sorted([(key,value) for (key,value) in total_count.items()])\nOrderedDict(sorted(total_count.items(), key=lambda t: t[1], reverse=True))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}