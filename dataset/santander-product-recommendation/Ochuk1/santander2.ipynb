{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport csv\nimport datetime\nimport random\nfrom operator import sub\n\nimport xgboost as xgb\nfrom sklearn import preprocessing, ensemble\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"start_time = datetime.datetime.now()\nmapping_dict = {'ind_empleado'  : {-99:0, 'N':1, 'B':2, 'F':3, 'A':4, 'S':5},\n'sexo'          : {'V':0, 'H':1, -99:2},\n'ind_nuevo'     : {'0':0, '1':1, -99:1},\n'indrel'        : {'1':0, '99':1, -99:1},\n'indrel_1mes'   : {-99:0, '1.0':1, '1':1, '2.0':2, '2':2, '3.0':3, '3':3, '4.0':4, '4':4, 'P':5},\n'tiprel_1mes'   : {-99:0, 'I':1, 'A':2, 'P':3, 'R':4, 'N':5},\n'indresi'       : {-99:0, 'S':1, 'N':2},\n'indext'        : {-99:0, 'S':1, 'N':2},\n#'conyuemp'      : {-99:0, 'S':1, 'N':2},\n'indfall'       : {-99:0, 'S':1, 'N':2},\n#'tipodom'       : {-99:0, '1':1},\n'ind_actividad_cliente' : {'0':0, '1':1, -99:2},\n'segmento'      : {'02 - PARTICULARES':0, '03 - UNIVERSITARIO':1, '01 - TOP':2, -99:3},\n'pais_residencia' : {'LV': 102, 'BE': 12, 'BG': 50, 'BA': 61, 'BM': 117, 'BO': 62, 'JP': 82, 'JM': 116, 'BR': 17, 'BY': 64, 'BZ': 113, 'RU': 43, 'RS': 89, 'RO': 41, 'GW': 99, 'GT': 44, 'GR': 39, 'GQ': 73, 'GE': 78, 'GB': 9, 'GA': 45, 'GN': 98, 'GM': 110, 'GI': 96, 'GH': 88, 'OM': 100, 'HR': 67, 'HU': 106, 'HK': 34, 'HN': 22, 'AD': 35, 'PR': 40, 'PT': 26, 'PY': 51, 'PA': 60, 'PE': 20, 'PK': 84, 'PH': 91, 'PL': 30, 'EE': 52, 'EG': 74, 'ZA': 75, 'EC': 19, 'AL': 25, 'VN': 90, 'ET': 54, 'ZW': 114, 'ES': 0, 'MD': 68, 'UY': 77, 'MM': 94, 'ML': 104, 'US': 15, 'MT': 118, 'MR': 48, 'UA': 49, 'MX': 16, 'IL': 42, 'FR': 8, 'MA': 38, 'FI': 23, 'NI': 33, 'NL': 7, 'NO': 46, 'NG': 83, 'NZ': 93, 'CI': 57, 'CH': 3, 'CO': 21, 'CN': 28, 'CM': 55, 'CL': 4, 'CA': 2, 'CG': 101, 'CF': 109, 'CD': 112, 'CZ': 36, 'CR': 32, 'CU': 72, 'KE': 65, 'KH': 95, 'SV': 53, 'SK': 69, 'KR': 87, 'KW': 92, 'SN': 47, 'SL': 97, 'KZ': 111, 'SA': 56, 'SG': 66, 'SE': 24, 'DO': 11, 'DJ': 115, 'DK': 76, 'DE': 10, 'DZ': 80, 'MK': 105, -99: 1, 'LB': 81, 'TW': 29, 'TR': 70, 'TN': 85, 'LT': 103, 'LU': 59, 'TH': 79, 'TG': 86, 'LY': 108, 'AE': 37, 'VE': 14, 'IS': 107, 'IT': 18, 'AO': 71, 'AR': 13, 'AU': 63, 'AT': 6, 'IN': 31, 'IE': 5, 'QA': 58, 'MZ': 27},\n'canal_entrada' : {'013': 49, 'KHP': 160, 'KHQ': 157, 'KHR': 161, 'KHS': 162, 'KHK': 10, 'KHL': 0, 'KHM': 12, 'KHN': 21, 'KHO': 13, 'KHA': 22, 'KHC': 9, 'KHD': 2, 'KHE': 1, 'KHF': 19, '025': 159, 'KAC': 57, 'KAB': 28, 'KAA': 39, 'KAG': 26, 'KAF': 23, 'KAE': 30, 'KAD': 16, 'KAK': 51, 'KAJ': 41, 'KAI': 35, 'KAH': 31, 'KAO': 94, 'KAN': 110, 'KAM': 107, 'KAL': 74, 'KAS': 70, 'KAR': 32, 'KAQ': 37, 'KAP': 46, 'KAW': 76, 'KAV': 139, 'KAU': 142, 'KAT': 5, 'KAZ': 7, 'KAY': 54, 'KBJ': 133, 'KBH': 90, 'KBN': 122, 'KBO': 64, 'KBL': 88, 'KBM': 135, 'KBB': 131, 'KBF': 102, 'KBG': 17, 'KBD': 109, 'KBE': 119, 'KBZ': 67, 'KBX': 116, 'KBY': 111, 'KBR': 101, 'KBS': 118, 'KBP': 121, 'KBQ': 62, 'KBV': 100, 'KBW': 114, 'KBU': 55, 'KCE': 86, 'KCD': 85, 'KCG': 59, 'KCF': 105, 'KCA': 73, 'KCC': 29, 'KCB': 78, 'KCM': 82, 'KCL': 53, 'KCO': 104, 'KCN': 81, 'KCI': 65, 'KCH': 84, 'KCK': 52, 'KCJ': 156, 'KCU': 115, 'KCT': 112, 'KCV': 106, 'KCQ': 154, 'KCP': 129, 'KCS': 77, 'KCR': 153, 'KCX': 120, 'RED': 8, 'KDL': 158, 'KDM': 130, 'KDN': 151, 'KDO': 60, 'KDH': 14, 'KDI': 150, 'KDD': 113, 'KDE': 47, 'KDF': 127, 'KDG': 126, 'KDA': 63, 'KDB': 117, 'KDC': 75, 'KDX': 69, 'KDY': 61, 'KDZ': 99, 'KDT': 58, 'KDU': 79, 'KDV': 91, 'KDW': 132, 'KDP': 103, 'KDQ': 80, 'KDR': 56, 'KDS': 124, 'K00': 50, 'KEO': 96, 'KEN': 137, 'KEM': 155, 'KEL': 125, 'KEK': 145, 'KEJ': 95, 'KEI': 97, 'KEH': 15, 'KEG': 136, 'KEF': 128, 'KEE': 152, 'KED': 143, 'KEC': 66, 'KEB': 123, 'KEA': 89, 'KEZ': 108, 'KEY': 93, 'KEW': 98, 'KEV': 87, 'KEU': 72, 'KES': 68, 'KEQ': 138, -99: 6, 'KFV': 48, 'KFT': 92, 'KFU': 36, 'KFR': 144, 'KFS': 38, 'KFP': 40, 'KFF': 45, 'KFG': 27, 'KFD': 25, 'KFE': 148, 'KFB': 146, 'KFC': 4, 'KFA': 3, 'KFN': 42, 'KFL': 34, 'KFM': 141, 'KFJ': 33, 'KFK': 20, 'KFH': 140, 'KFI': 134, '007': 71, '004': 83, 'KGU': 149, 'KGW': 147, 'KGV': 43, 'KGY': 44, 'KGX': 24, 'KGC': 18, 'KGN': 11}\n}\n\ncat_cols = list(mapping_dict.keys())\n\ntarget_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']\ntarget_cols = target_cols[2:]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"20fed64bdb41730b1c9d8810eb53bc79dac49e08"},"cell_type":"code","source":"def getTarget(row):\n\ttlist = []\n\tfor col in target_cols:\n\t\tif row[col].strip() in ['', 'NA']:\n\t\t\ttarget = 0\n\t\telse:\n\t\t\ttarget = int(float(row[col]))\n\t\ttlist.append(target)\n\treturn tlist\n\ndef getIndex(row, col):\n\tval = row[col].strip()\n\tif val not in ['','NA']:\n\t\tind = mapping_dict[col][val]\n\telse:\n\t\tind = mapping_dict[col][-99]\n\treturn ind\n\ndef getAge(row):\n\tmean_age = 40.\n\tmin_age = 18.\n\tmax_age = 100.\n\trange_age = max_age - min_age\n\tage = row['age'].strip()\n\tif age == 'NA' or age == '':\n\t\tage = mean_age\n\telse:\n\t\tage = float(age)\n\t\tif age < min_age:\n\t\t\tage = min_age\n\t\telif age > max_age:\n\t\t\tage = max_age\n\treturn round( (age - min_age) / range_age, 4)\n\ndef getCustSeniority(row):\n\tmin_value = 0.\n\tmax_value = 256.\n\trange_value = max_value - min_value\n\tmissing_value = 0.\n\tcust_seniority = row['antiguedad'].strip()\n\tif cust_seniority == 'NA' or cust_seniority == '':\n\t\tcust_seniority = missing_value\n\telse:\n\t\tcust_seniority = float(cust_seniority)\n\t\tif cust_seniority < min_value:\n\t\t\tcust_seniority = min_value\n\t\telif cust_seniority > max_value:\n\t\t\tcust_seniority = max_value\n\treturn round((cust_seniority-min_value) / range_value, 4)\n\ndef getRent(row):\n\tmin_value = 0.\n\tmax_value = 1500000.\n\trange_value = max_value - min_value\n\trenta_dict = {'ALBACETE': 76895,  'ALICANTE': 60562,  'ALMERIA': 77815,  'ASTURIAS': 83995,  'AVILA': 78525,  'BADAJOZ': 60155,  'BALEARS, ILLES': 114223,  'BARCELONA': 135149,  'BURGOS': 87410, 'NAVARRA' : 101850,\n    'CACERES': 78691,  'CADIZ': 75397,  'CANTABRIA': 87142,  'CASTELLON': 70359,  'CEUTA': 333283, 'CIUDAD REAL': 61962,  'CORDOBA': 63260,  'CORUÃ‘A, A': 103567,  'CUENCA': 70751,  'GIRONA': 100208,  'GRANADA': 80489,\n    'GUADALAJARA': 100635,  'HUELVA': 75534,  'HUESCA': 80324,  'JAEN': 67016,  'LEON': 76339,  'LERIDA': 59191,  'LUGO': 68219,  'MADRID': 141381,  'MALAGA': 89534,  'MELILLA': 116469, 'GIPUZKOA': 101850,\n    'MURCIA': 68713,  'OURENSE': 78776,  'PALENCIA': 90843,  'PALMAS, LAS': 78168,  'PONTEVEDRA': 94328,  'RIOJA, LA': 91545,  'SALAMANCA': 88738,  'SANTA CRUZ DE TENERIFE': 83383, 'ALAVA': 101850, 'BIZKAIA' : 101850,\n    'SEGOVIA': 81287,  'SEVILLA': 94814,  'SORIA': 71615,  'TARRAGONA': 81330,  'TERUEL': 64053,  'TOLEDO': 65242,  'UNKNOWN': 103689,  'VALENCIA': 73463,  'VALLADOLID': 92032,  'ZAMORA': 73727,  'ZARAGOZA': 98827}\n\n\t#missing_value = 101850.\n\trent = row['renta'].strip()\n\tif rent == 'NA' or rent == '':\n\t    if row['nomprov'] == 'NA' or row['nomprov'] == '':\n\t        rent = float(renta_dict['UNKNOWN'])\n\t    else:\n\t        rent = float(renta_dict[row['nomprov']])\n\telse:\n\t\trent = float(rent)\n\t\tif rent < min_value:\n\t\t\trent = min_value\n\t\telif rent > max_value:\n\t\t\trent = max_value\n\n\treturn round((rent-min_value) / range_value, 6)\n\ndef getMarriageIndex(row, age, sex, income):\n    marriage_age = 28\n    modifier = 0\n    if sex == 'V':\n        modifier += -2\n    if income <= 101850:\n        modifier += -1\n    \n    marriage_age_mod = marriage_age + modifier\n    \n    if age <= marriage_age_mod:\n        return 0\n    else:\n        return 1\n\ndef getMonth(row):\n    return int(row['fecha_dato'].split('-')[1])\n\ndef getjoinMonth(row):\n    if row['fecha_alta'].strip() == 'NA' or row['fecha_alta'].strip() == '':\n        return int(random.choice([1,2,3,4,5,6,7,8,9,10,11,12]))\n    else:\n        return int(row['fecha_alta'].split('-')[1])\n    \ndef processDataMK(in_file_name, cust_dict, lag_cust_dict):\n    x_vars_list = []\n    y_vars_list = []\n    \n    for row in csv.DictReader(in_file_name):\n        if row['fecha_dato'] not in ['2015-04-28', '2015-05-28', '2015-06-28', '2016-04-28', '2016-05-28', '2016-06-28']:\n            continue\n        #Leave out first month\n        cust_id = int(row['ncodpers'])\n        if (row['fecha_dato'] in ['2015-04-28', '2016-04-28'] ):\n            target_list = getTarget(row)\n            lag_cust_dict[cust_id] =  target_list[:]\n            continue\n        \n        if (row['fecha_dato'] in ['2015-05-28', '2016-05-28'] ):\n            target_list = getTarget(row)\n            cust_dict[cust_id] =  target_list[:]\n            continue\n        \n        x_vars = []\n        for col in cat_cols:\n            x_vars.append( getIndex(row, col) )\n        sex = getIndex(row, 'sexo')\n        age = getAge(row)\n        x_vars.append(age)\n        x_vars.append( getMonth(row))\n        x_vars.append( getjoinMonth(row))\n        x_vars.append(getCustSeniority(row))\n        income = getRent(row)\n        x_vars.append(income)\n        #x_vars.append(getMarriageIndex(row, age, sex, income) )\n        if row['fecha_dato'] == '2016-06-28':\n            prev_target_list = cust_dict.get(cust_id, [0]*22)\n            lag_target_list = lag_cust_dict.get(cust_id, [0]*22)\n            x_vars_list.append(x_vars + prev_target_list + lag_target_list)\n        elif row['fecha_dato'] == '2015-06-28':\n            prev_target_list = cust_dict.get(cust_id, [0]*22)\n            lag_target_list = lag_cust_dict.get(cust_id, [0]*22)\n            target_list = getTarget(row)\n            new_products = [max(x1 - x2,0) for (x1, x2) in zip(target_list, prev_target_list)]\n            if sum(new_products) > 0:\n                for ind, prod in enumerate(new_products):\n                    if prod>0:\n                        assert len(prev_target_list) == 22\n                        x_vars_list.append(x_vars+prev_target_list+lag_target_list)\n                        y_vars_list.append(ind)\n        \n        \n    return x_vars_list, y_vars_list, cust_dict, lag_cust_dict\n    \ndef processData(in_file_name, cust_dict):\n\tx_vars_list = []\n\ty_vars_list = []\n\tfor row in csv.DictReader(in_file_name):\n\t\t# use only the four months as specified by breakfastpirate #\n\t\tif row['fecha_dato'] not in ['2015-05-28', '2015-06-28', '2016-05-28', '2016-06-28']:\n\t\t\tcontinue\n\n\t\tcust_id = int(row['ncodpers'])\n\t\tif row['fecha_dato'] in ['2015-05-28', '2016-05-28']:\t\n\t\t\ttarget_list = getTarget(row)\n\t\t\tcust_dict[cust_id] =  target_list[:]\n\t\t\tcontinue\n\n\t\tx_vars = []\n\t\tfor col in cat_cols:\n\t\t\tx_vars.append( getIndex(row, col) )\n\t\tsex = getIndex(row, 'sexo')\n\t\tage = getAge(row)\n\t\tx_vars.append( age )\n\t\tx_vars.append( getCustSeniority(row) )\n\t\tincome = getRent(row) \n\t\tx_vars.append( income )\n\t\t#x_vars.append( getMarriageIndex(row, age, sex, income) )\n\n\t\tif row['fecha_dato'] == '2016-06-28':\n\t\t\tprev_target_list = cust_dict.get(cust_id, [0]*22)\n\t\t\tx_vars_list.append(x_vars + prev_target_list)\n\t\telif row['fecha_dato'] == '2015-06-28':\n\t\t\tprev_target_list = cust_dict.get(cust_id, [0]*22)\n\t\t\ttarget_list = getTarget(row)\n\t\t\tnew_products = [max(x1 - x2,0) for (x1, x2) in zip(target_list, prev_target_list)]\n\t\t\tif sum(new_products) > 0:\n\t\t\t\tfor ind, prod in enumerate(new_products):\n\t\t\t\t\tif prod>0:\n\t\t\t\t\t\tassert len(prev_target_list) == 22\n\t\t\t\t\t\tx_vars_list.append(x_vars+prev_target_list)\n\t\t\t\t\t\ty_vars_list.append(ind)\n\n\treturn x_vars_list, y_vars_list, cust_dict\n\t\t\t\ndef runXGB(train_X, train_y, seed_val=845895):\n\tparam = {}\n\tparam['objective'] = 'multi:softprob'\n\tparam['eta'] = 0.09\n\tparam['max_depth'] = 6\n\tparam['silent'] = 1\n\tparam['num_class'] = 22\n\tparam['eval_metric'] = \"mlogloss\"\n\tparam['min_child_weight'] = 12\n\tparam['subsample'] = 0.85\n\tparam['colsample_bytree'] = 0.9\n\tparam['seed'] = seed_val\n\tnum_rounds = 70\n\n\tplst = list(param.items())\n\txgtrain = xgb.DMatrix(train_X, label=train_y)\n\tmodel = xgb.train(plst, xgtrain, num_rounds)\t\n\treturn model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a81aca4c99511abc6dd0eb575b2f6ced2269be6"},"cell_type":"code","source":"if __name__ == \"__main__\":\n\tdata_path = \"../input/\"\n\ttrain_file =  open(data_path + \"train_ver2.csv\")\n\tprint('Starting file processing')\n\t#x_vars_list, y_vars_list, cust_dict = processData(train_file, {})\n\tx_vars_list, y_vars_list, cust_dict, lag_cust_dict = processDataMK(train_file, {}, {})\n\tprint('Finished file processing')\n\ttrain_X = np.array(x_vars_list)\n\ttrain_y = np.array(y_vars_list)\n\tprint(np.unique(train_y))\n\tdel x_vars_list, y_vars_list\n\ttrain_file.close()\n\tprint(train_X.shape, train_y.shape)\n\tprint(datetime.datetime.now()-start_time)\n\ttest_file = open(data_path + \"test_ver2.csv\")\n\tx_vars_list, y_vars_list, cust_dict, lag_cust_dict = processDataMK(test_file, cust_dict, lag_cust_dict)\n\ttest_X = np.array(x_vars_list)\n\tdel x_vars_list\n\ttest_file.close()\n\tprint(test_X.shape)\n\tprint(datetime.datetime.now()-start_time)\n\n\tprint(\"Building model..\")\n\tmodel = runXGB(train_X, train_y, seed_val=0)\n\tdel train_X, train_y\n\tprint(\"Predicting..\")\n\txgtest = xgb.DMatrix(test_X)\n\tpreds = model.predict(xgtest)\n\tdel test_X, xgtest\n\tprint(datetime.datetime.now()-start_time)\n\n\tprint(\"Getting the top products..\")\n\ttest_id = np.array(pd.read_csv(data_path + \"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n\tnew_products = []\n\tfor i, idx in enumerate(test_id):\n\t    new_products.append([max(x1 - x2,0) for (x1, x2) in zip(preds[i,:], cust_dict[idx])])\n\ttarget_cols = np.array(target_cols)\n\tpreds = np.argsort(np.array(new_products), axis=1)\n\tpreds = np.fliplr(preds)[:,:7]\n\tfinal_preds = [\" \".join(list(target_cols[pred])) for pred in preds]\n\tout_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n\tout_df.to_csv('xgb_sub.csv', index=False)\n\tprint(datetime.datetime.now()-start_time)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fda3b5507a0ca6733058f3b712d5b2edec9ef5d7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}