{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\n\ndef apk(actual, predicted, k=7, default=0.0):\n    # MAP@7 이므로, 최대 7개만 사용한다\n    if len(predicted) > k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i, p in enumerate(predicted):\n        # 점수를 부여하는 조건은 다음과 같다 :\n        # 예측값이 정답에 있고 (‘p in actual’)\n        # 예측값이 중복이 아니면 (‘p not in predicted[:i]’) \n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i+1.0)\n\n    # 정답값이 공백일 경우, 무조건 0.0점을 반환한다\n    if not actual:\n        return default\n\n    # 정답의 개수(len(actual))로 average precision을 구한다\n    return score / min(len(actual), k)\n\ndef mapk(actual, predicted, k=7, default=0.0):\n    # list of list인 정답값(actual)과 예측값(predicted)에서 고객별 Average Precision을 구하고, np.mean()을 통해 평균을 계산한다\n    return np.mean([apk(a, p, k, default) for a, p in zip(actual, predicted)]) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\n\nnp.random.seed(2018)\n\n# 데이터를 불러온다.\ntrain_full = pd.read_csv(\"/kaggle/input/santander-product-recommendation/train_ver2.csv.zip\")\ntrn = train_full.sample(n=10000).copy()\ndel train_full","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_full = pd.read_csv(\"/kaggle/input/santander-product-recommendation/test_ver2.csv.zip\")\ntst = test_full.sample(n=10000).copy()\ndel test_full","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tst.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n## 데이터 전처리 ##\n\n# 제품 변수를 별도로 저장해 놓는다.\nprods = trn.columns[24:].tolist()\n\n# 제품 변수 결측값을 미리 0으로 대체한다.\ntrn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 24개 제품 중 하나도 보유하지 않는 고객 데이터를 제거한다.\nno_product = trn[prods].sum(axis=1) == 0\ntrn = trn[~no_product]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 훈련 데이터와 테스트 데이터를 통합한다. 테스트 데이터에 없는 제품 변수는 0으로 채운다.\nfor col in trn.columns[24:]:\n    tst[col] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf = pd.concat([trn, tst], axis=0)\n\n\n# 학습에 사용할 변수를 담는 list이다.\nfeatures = []\n\n# 범주형 변수를 .factorize() 함수를 통해 label encoding한다.\ncategorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\nfor col in categorical_cols:\n    df[col], _ = df[col].factorize(na_sentinel=-99)\nfeatures += categorical_cols\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 수치형 변수의 특이값과 결측값을 -99로 대체하고, 정수형으로 변환한다.\ndf['age'].replace(' NA', -99, inplace=True)\ndf['age'] = df['age'].astype(np.int8)\n\ndf['antiguedad'].replace('     NA', -99, inplace=True)\ndf['antiguedad'] = df['antiguedad'].astype(np.int8)\n\ndf['renta'].replace('         NA', -99, inplace=True)\ndf['renta'].fillna(-99, inplace=True)\ndf['renta'] = df['renta'].astype(float).astype(np.int8)\n\ndf['indrel_1mes'].replace('P', 5, inplace=True)\ndf['indrel_1mes'].fillna(-99, inplace=True)\ndf['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 학습에 사용할 수치형 변수를 features에 추구한다.\nfeatures += ['age','antiguedad','renta','ind_nuevo','indrel','indrel_1mes','ind_actividad_cliente']\n\n# (피쳐 엔지니어링) 두 날짜 변수에서 연도와 월 정보를 추출한다.\ndf['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\ndf['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\nfeatures += ['fecha_alta_month', 'fecha_alta_year']\n\ndf['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\ndf['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\nfeatures += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']\n\n# 그 외 변수의 결측값은 모두 -99로 대체한다.\ndf.fillna(-99, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# (피쳐 엔지니어링) lag-1 데이터를 생성한다.\n# 코드 2-12와 유사한 코드 흐름이다.\n\n# 날짜를 숫자로 변환하는 함수이다. 2015-01-28은 1, 2016-06-28은 18로 변환된다\ndef date_to_int(str_date):\n    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] \n    int_date = (int(Y) - 2015) * 12 + int(M)\n    return int_date\n\n# 날짜를 숫자로 변환하여 int_date에 저장한다\ndf['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n\n# 데이터를 복사하고, int_date 날짜에 1을 더하여 lag를 생성한다. 변수명에 _prev를 추가한다.\ndf_lag = df.copy()\ndf_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]\ndf_lag['int_date'] += 1\n\n# 원본 데이터와 lag 데이터를 ncodper와 int_date 기준으로 합친다. Lag 데이터의 int_date는 1 밀려 있기 때문에, 저번 달의 제품 정보가 삽입된다.\ndf_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n\n# 메모리 효율을 위해 불필요한 변수를 메모리에서 제거한다\ndel df, df_lag\n\n# 저번 달의 제품 정보가 존재하지 않을 경우를 대비하여 0으로 대체한다.\nfor prod in prods:\n    prev = prod + '_prev'\n    df_trn[prev].fillna(0, inplace=True)\ndf_trn.fillna(-99, inplace=True)\n\n# lag-1 변수를 추가한다.\nfeatures += [feature + '_prev' for feature in features]\nfeatures += [prod + '_prev' for prod in prods]\n\n###\n### Baseline 모델 이후, 다양한 피쳐 엔지니어링을 여기에 추가한다.\n###\n\n\n## 모델 학습\n# 학습을 위하여 데이터를 훈련, 테스트용으로 분리한다.\n# 학습에는 2016-01-28 ~ 2016-04-28 데이터만 사용하고, 검증에는 2016-05-28 데이터를 사용한다.\nuse_dates = ['2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\ntrn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\ntst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\ndel df_trn\n\n# 훈련 데이터에서 신규 구매 건수만 추출한다.\nX = []\nY = []\nfor i, prod in enumerate(prods):\n    prev = prod + '_prev'\n    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n    X.append(prX)\n    Y.append(prY)\nXY = pd.concat(X)\nY = np.hstack(Y)\nXY['y'] = Y\n\n# 훈련, 검증 데이터로 분리한다. \nvld_date = '2016-05-28'\nXY_trn = XY[XY['fecha_dato'] != vld_date]\nXY_vld = XY[XY['fecha_dato'] == vld_date]\n\n\n# XGBoost 모델 parameter를 설정한다.\nparam = {\n    'booster': 'gbtree',\n    'max_depth': 8,\n    'nthread': 4,\n    'num_class': len(prods),\n    'objective': 'multi:softprob',\n    'silent': 1,\n    'eval_metric': 'mlogloss',\n    'eta': 0.1,\n    'min_child_weight': 10,\n    'colsample_bytree': 0.8,\n    'colsample_bylevel': 0.9,\n    'seed': 2018,\n    }\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XY_trn[features].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XY_trn[['ind_empleado']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#XY_trn.values(columns=features)\nXY_trn.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 훈련, 검증 데이터를 XGBoost 형태로 변환한다.\n#X_trn = XY_trn.as_matrix(columns=features)\nX_trn = XY_trn[features].values\n#Y_trn = XY_trn.as_matrix(columns=['y'])\nY_trn = XY_trn[['y']].values\n\ndtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n\n#X_vld = XY_vld.as_matrix(columns=features)\nX_vld = XY_vld[features].values\n\n#Y_vld = XY_vld.as_matrix(columns=['y'])\nY_vld = XY_vld[['y']].values\n\ndvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# XGBoost 모델을 훈련 데이터로 학습한다!\nwatch_list = [(dtrn, 'train'), (dvld, 'eval')]\nmodel = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 학습한 모델을 저장한다.\nimport pickle\npickle.dump(model, open(\"./xgb.baseline.pkl\", \"wb\"))\nbest_ntree_limit = model.best_ntree_limit\n\n# MAP@7 평가 척도를 위한 준비작업이다.\n# 고객 식별 번호를 추출한다.\nvld = trn[trn['fecha_dato'] == vld_date]\n#ncodpers_vld = vld.as_matrix(columns=['ncodpers'])\nncodpers_vld = vld[['ncodpers']]\n\n# 검증 데이터에서 신규 구매를 구한다.\nfor prod in prods:\n    prev = prod + '_prev'\n    padd = prod + '_add'\n    vld[padd] = vld[prod] - vld[prev]    \n#add_vld = vld.as_matrix(columns=[prod + '_add' for prod in prods])\nadd_vld = vld[ [prod + '_add' for prod in prods] ]\nadd_vld_list = [list() for i in range(len(ncodpers_vld))]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (len(ncodpers_vld))\nprint (len(prods))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_vld.iloc[0,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_vld.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_vld.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 고객별 신규 구매 정답 값을 add_vld_list에 저장하고, 총 count를 count_vld에 저장한다.\ncount_vld = 0\nfor ncodper in range(len(ncodpers_vld)):\n    for prod in range(len(prods)):\n        if add_vld.iloc[ncodper, prod] > 0:\n            add_vld_list[ncodper].append(prod)\n            count_vld += 1\n                        \n# 검증 데이터에서 얻을 수 있는 MAP@7 최고점을 미리 구한다. (0.042663)\nprint(mapk(add_vld_list, add_vld_list, 7, 0.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vld","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vld.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# 검증 데이터에 대한 예측 값을 구한다.\n#X_vld = vld.as_matrix(columns=features)\nX_vld = vld[features].values\n\n#Y_vld = vld.as_matrix(columns=['y'])\nY_vld = vld[['y']].values\n\ndvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\npreds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n\n# 저번 달에 보유한 제품은 신규 구매가 불가하기 때문에, 확률값에서 미리 1을 빼준다\n#preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])\npreds_vld = preds_vld - vld[[prod + '_prev' for prod in prods]].values\n\n\n# 검증 데이터 예측 상위 7개를 추출한다.\nresult_vld = []\nfor ncodper, pred in zip(ncodpers_vld, preds_vld):\n    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n    result_vld.append([ip for y,p,ip in y_prods])\n    \n# 검증 데이터에서의 MAP@7 점수를 구한다. (0.036466)\nprint(mapk(add_vld_list, result_vld, 7, 0.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# XGBoost 모델을 전체 훈련 데이터로 재학습한다!\nX_all = XY.as_matrix(columns=features)\nY_all = XY.as_matrix(columns=['y'])\ndall = xgb.DMatrix(X_all, label=Y_all, feature_names=features)\nwatch_list = [(dall, 'train')]\n# 트리 개수를 늘어난 데이터 양만큼 비례해서 증가한다.\nbest_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n# XGBoost 모델 재학습!\nmodel = xgb.train(param, dall, num_boost_round=best_ntree_limit, evals=watch_list)\n\n# 변수 중요도를 출력해본다. 예상하던 변수가 상위로 올라와 있는가?\nprint(\"Feature importance:\")\nfor kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n    print(kv)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 캐글 제출을 위하여 테스트 데이터에 대한 예측 값을 구한다.\nX_tst = tst.as_matrix(columns=features)\ndtst = xgb.DMatrix(X_tst, feature_names=features)\npreds_tst = model.predict(dtst, ntree_limit=best_ntree_limit)\nncodpers_tst = tst.as_matrix(columns=['ncodpers'])\npreds_tst = preds_tst - tst.as_matrix(columns=[prod + '_prev' for prod in prods])\n\n# 제출 파일을 생성한다.\nsubmit_file = open('./xgb.baseline.2015-06-28', 'w')\nsubmit_file.write('ncodpers,added_products\\n')\nfor ncodper, pred in zip(ncodpers_tst, preds_tst):\n    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n    y_prods = [p for y,p,ip in y_prods]\n    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}