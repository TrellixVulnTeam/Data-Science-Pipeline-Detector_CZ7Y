{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"Train Photos\", len(train_photos), len(train_photos.columns))\ntrain_photos.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"Train Attributes\", len(train_attr), len(train_attr.columns))\ntrain_attr.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"Train ID\", len(train_id), len(train_id.columns))\ntrain_id.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"Test Photos\", len(test_photos), len(test_photos.columns))\ntest_photos.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"label_notation = {0: 'good_for_lunch', 1: 'good_for_dinner', 2: 'takes_reservations',  3: 'outdoor_seating',\n                  4: 'restaurant_is_expensive', 5: 'has_alcohol', 6: 'has_table_service', 7: 'ambience_is_classy',\n                  8: 'good_for_kids'}"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"for l in label_notation:\n    ids = train_attr[train_attr['labels'].str.contains(str(l))==True].business_id.tolist()[:9]\n    plt.rcParams['figure.figsize'] = (7.0, 7.0)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    for x in range(9):\n        plt.subplot(3, 3, x+1)\n        im = Image.open('../input/train_photos/' + str(train_photos.photo_id[ids[x]]) + '.jpg')\n        im = im.resize((150, 150), Image.ANTIALIAS)\n        plt.imshow(im)\n        plt.axis('off')\n    fig = plt.figure()\n    fig.suptitle(label_notation[l])\n    #fig.savefig(str(label_notation[l]) +'.png')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"Start Training/Predictions: \", round(((time.time() - start_time)/60),2))\nfrom sklearn import ensemble\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.feature_extraction.image  import PatchExtractor\nfrom sklearn import pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import FeatureUnion\n#from sklearn import svm\n#from sklearn.feature_extraction.image import img_to_graph, extract_patches_2d\n#from sklearn.metrics import f1_score\nimport multiprocessing\nimport random; random.seed(2016);\n\nX_train = train_photos\nX_train = X_train.groupby(['business_id'], as_index=False).first()\nX_train = pd.merge(X_train, train_attr, how='left', on='business_id')\nX_train = df_all = pd.concat((X_train.groupby(['labels'], as_index=False).first(), X_train.groupby(['labels'], as_index=False).last()), axis=0, ignore_index=True)\ny_train = X_train['labels'].str.get_dummies(sep=' ')\nX_train = X_train.drop(['labels'],axis=1)\nX_test = test_photos.groupby(['business_id'], as_index=False).first()\nid_test = X_test[\"business_id\"]\n\nprint(len(X_train), len(y_train), len(X_test), len(id_test))\n\ndef image_features(path, tt, buss_id, photo_id):\n    s=[tt, photo_id, buss_id]\n    im = Image.open(path)\n    xheight, xwidth = [100,100]\n    im = im.resize((xheight, xwidth), Image.ANTIALIAS)\n    qu = im.quantize(colors=10, kmeans=3) #if number of colors changes also change file columns number\n    crgb = qu.convert('RGB')\n    col_rank = sorted(crgb.getcolors(xwidth*xheight), reverse=True)\n    for i_rgb in range(len(col_rank)):\n        for t_rgb in range(4):\n            if t_rgb==0:\n                s.append(col_rank[i_rgb][0])\n            else:\n                s.append(col_rank[i_rgb][1][t_rgb-1])\n    im = im.crop((10, 10, 90, 90)) #remove edges\n    im = im.convert('1') #binarize\n    im_data = list(im.getdata())\n    im_data = [r if r == 0 else 1 for r in im_data]\n    st = str(\"\".join(map(str,im_data)))\n    for i in range(0,len(im_data)//16):\n        t = str(st[16*i:16*i+8]) + \".\" + str(st[16*i+8:16*(i+1)])\n        s.append(float(t))\n    f = open(\"data.csv\",\"a\")\n    f.write((',').join(map(str, s)) + '\\n')\n    f.close()\n    return\n\nclass cust_img_features(BaseEstimator, TransformerMixin):\n    def fit(self, x, y=None):\n        return self\n    def transform(self, img_features):\n        d_col_drops=['photo_id','tt']\n        img_features = img_features.drop(d_col_drops,axis=1).values\n        return img_features\n\nclass cust_patch_arr(BaseEstimator, TransformerMixin):\n    def fit(self, x, y=None):\n        return self\n    def transform(self, img_features):\n        if img_features[\"tt\"][0]==\"test\":\n            img_features[\"pic\"] = img_features[\"photo_id\"].map(lambda x: np.asarray(Image.open('../input/test_photos/' + str(x) + '.jpg')))\n        else:\n            img_features[\"pic\"] = img_features[\"photo_id\"].map(lambda x: np.asarray(Image.open('../input/train_photos/' + str(x) + '.jpg')))\n        return img_features[\"pic\"]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"f = open(\"data.csv\",\"w\");\ncol = ['tt', 'photo_id','business_id']\nfor i_rgb in range(10):\n    for t_rgb in range(4):\n        col.append(\"col_feature_\"+str(i_rgb)+\"_\" + \"krgb\"[t_rgb])\nfor i in range(400):\n     col.append(\"img_pixel_set\"+str(i))\nf.write((',').join(map(str,col)) + '\\n')\nf.close()\nprint(\"Start Training/Predictions: \", round(((time.time() - start_time)/60),2))\n\nif __name__ == '__main__':\n    j = []\n    cpu = multiprocessing.cpu_count(); #print (cpu);\n    \n    for s_ in range(0,len(X_train),cpu):     #train\n        for i in range(cpu):\n            i_=s_+i\n            if (i_)<len(X_train):\n                filename='../input/train_photos/' + str(X_train.photo_id[i_]) + '.jpg'\n                p = multiprocessing.Process(target=image_features, args=(filename,'train', X_train.business_id[i_], X_train.photo_id[i_],))\n                j.append(p)\n                p.start()\n    j = []\n    for s_ in range(0,len(X_test),cpu):     #test\n        for i in range(cpu):\n            i_=s_+i\n            if (i_)<len(X_test):\n                filename='../input/test_photos/' + str(X_test.photo_id[i_]) + '.jpg'\n                p = multiprocessing.Process(target=image_features, args=(filename,'test', X_test.business_id[i_], X_test.photo_id[i_],))\n                j.append(p)\n                p.start()\n    \n    df_all = pd.read_csv('data.csv', index_col=None)\n    X_train = df_all[df_all['tt'] == 'train']\n    X_test = df_all[df_all['tt'] == 'test']\n    X_train = X_train.drop(['business_id'],axis=1)\n    X_test = X_test.drop(['business_id'],axis=1)\n    rfr = ensemble.RandomForestClassifier(random_state=2016, n_jobs=-1)\n    ovr = OneVsRestClassifier(rfr, n_jobs=-1)\n    patch1 = PatchExtractor(patch_size=(10,10), max_patches=10, random_state=2016)\n    clf = pipeline.Pipeline([\n            ('union', FeatureUnion(\n                    transformer_list = [\n                        ('cst',  cust_img_features()),  \n                        #('patches', pipeline.Pipeline([('patch_arr', cust_patch_arr()), ('patch', patch1)]))\n                        ],\n                    transformer_weights = {\n                        'cst': 1.0,\n                        #'patches': 1.0\n                        },\n                n_jobs = -1\n                )), \n        ('ovr', ovr)])\n    model = clf.fit(X_train, y_train)\n    y_pred = model.predict_proba(X_test)\n    df = pd.concat((pd.DataFrame(id_test), pd.DataFrame(y_pred)), axis=1)\n    df.columns = ['business_id','0','1','2','3','4','5','6','7','8']\n    df.to_csv('data.csv',index=False)\n    print(\"End Training/Predictions: \", round(((time.time() - start_time)/60),2))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df = pd.read_csv('data.csv')\na = [['business_id','labels']]\nfor i in range(len(df)):\n    b = []\n    for j in range(9):\n        if df[str(j)][i] >= 0.1:\n            b.append(j)\n    a.append([df['business_id'][i],\" \".join(map(str,b))])\npd.DataFrame(a).to_csv('submission.csv',index=False, header=False)\nprint('Done, not much better than random guessing but could increase train data too.')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}