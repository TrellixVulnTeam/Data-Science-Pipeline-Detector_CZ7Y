{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom random import sample\nimport cv2\n\nimport imgaug.augmenters as ia\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# Deep Learning\nimport torch\nfrom torchvision import transforms\nfrom torch.autograd import Variable\nfrom torch.nn import * #Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\nfrom torchvision import models\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import ViTFeatureExtractor, ViTModel\nfrom PIL import Image\nimport requests","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-17T05:10:28.100964Z","iopub.execute_input":"2021-10-17T05:10:28.101863Z","iopub.status.idle":"2021-10-17T05:10:34.633355Z","shell.execute_reply.started":"2021-10-17T05:10:28.101733Z","shell.execute_reply":"2021-10-17T05:10:34.632632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dat = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ny = dat[\"Pawpularity\"].to_numpy()\ny = y/100","metadata":{"execution":{"iopub.status.busy":"2021-10-17T06:28:48.758935Z","iopub.execute_input":"2021-10-17T06:28:48.759202Z","iopub.status.idle":"2021-10-17T06:28:48.782136Z","shell.execute_reply.started":"2021-10-17T06:28:48.759171Z","shell.execute_reply":"2021-10-17T06:28:48.781434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = \"../input/petfinder-pawpularity-score/train/0007de18844b0dbbb5e1f607da0606e0.jpg\"\nimg = cv2.cvtColor(cv2.resize(cv2.imread(p),(244,244)),cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.show()\n\nimages = [img for i in range(8)]\nseq = ia.Sequential([ia.Sometimes(0.75,ia.Sequential([\n    ia.Affine(rotate=(-60, 59)),\n    ia.flip.Fliplr(0.5),\n    ia.flip.Flipud(0.5),\n    ia.Crop(percent=(0, 0.2))])),\n])\n\nimages_aug = seq(images=images)\n\nprint(\"Augmented:\")\nplt.figure(figsize=(100,20))\nplt.imshow(np.hstack(images_aug),)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T06:28:57.044583Z","iopub.execute_input":"2021-10-17T06:28:57.044866Z","iopub.status.idle":"2021-10-17T06:29:00.445921Z","shell.execute_reply.started":"2021-10-17T06:28:57.044829Z","shell.execute_reply":"2021-10-17T06:29:00.443393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\nimage = Image.open(requests.get(url, stream=True).raw)\n\nfeature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\nvit_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T05:10:57.046369Z","iopub.execute_input":"2021-10-17T05:10:57.046613Z","iopub.status.idle":"2021-10-17T05:11:11.212425Z","shell.execute_reply.started":"2021-10-17T05:10:57.046586Z","shell.execute_reply":"2021-10-17T05:11:11.211697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in vit_model.parameters():\n#     print(param.requires_grad)\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-10-17T05:11:11.2141Z","iopub.execute_input":"2021-10-17T05:11:11.214444Z","iopub.status.idle":"2021-10-17T05:11:11.220781Z","shell.execute_reply.started":"2021-10-17T05:11:11.214411Z","shell.execute_reply":"2021-10-17T05:11:11.220121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint('Using {} device'.format(device))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T05:11:11.222101Z","iopub.execute_input":"2021-10-17T05:11:11.222831Z","iopub.status.idle":"2021-10-17T05:11:11.276855Z","shell.execute_reply.started":"2021-10-17T05:11:11.222791Z","shell.execute_reply":"2021-10-17T05:11:11.275255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class model(Module):\n    def __init__(self,vit_model,feature_extractor):\n        super(model, self).__init__()\n        self.vit_model = vit_model\n        self.feature_extractor = feature_extractor\n        self.network = Sequential(\n            Linear(768, 32),\n            ReLU(),\n            Linear(32, 1),\n        )\n\n    def forward(self, x):\n#         inputs = self.feature_extractor(x,return_tensors=\"pt\")\n#         outputs = self.vit_model(**inputs)\n        outputs = self.vit_model(x)\n        x = outputs.pooler_output\n        logits = self.network(x)\n        return logits\n    \nmodel = model(vit_model,feature_extractor).to(device)\n# print(model)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T05:35:14.006681Z","iopub.execute_input":"2021-10-17T05:35:14.007152Z","iopub.status.idle":"2021-10-17T05:35:14.021412Z","shell.execute_reply.started":"2021-10-17T05:35:14.007116Z","shell.execute_reply":"2021-10-17T05:35:14.020693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = MSELoss()#CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.0001)#, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T05:35:16.726699Z","iopub.execute_input":"2021-10-17T05:35:16.727396Z","iopub.status.idle":"2021-10-17T05:35:16.736334Z","shell.execute_reply.started":"2021-10-17T05:35:16.727361Z","shell.execute_reply":"2021-10-17T05:35:16.735661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Data:\n    def __init__(self,path,ids,x=224,y=224,labels=None,aug_arg=False):\n        self.x = x\n        self.y = y\n        self.labels = labels\n#         self.image_list = [t.split(\".\")[0] for t in os.listdir(path)] \n        self.image_list = ids\n        self.path = path\n        self.batch = 0\n        self.aug = aug_arg\n        \n    def load_batch(self,batch_size=1,shuffle=False):\n        if shuffle:\n            b = self.batch\n            batch_list = self.image_list[b*batch_size:(b+1)*batch_size]\n            self.batch = b+1\n            if self.batch>len(self.image_list)//batch_size:\n                self.batch=0\n        else:\n            batch_list = sample(self.image_list,batch_size)\n        images = np.array([cv2.cvtColor(cv2.resize(cv2.imread(self.path+image+\".jpg\"),(self.x,self.y)),cv2.COLOR_BGR2RGB) for image in batch_list])\n        if self.aug:\n            images = seq(images=images)\n        labels = self.labels.loc[batch_list].to_numpy()/100\n\n        return images,labels\n    \n    def loader(self,batch_size=1,shuffle=False):\n        while True:\n            x,y = self.load_batch(batch_size,shuffle)\n            yield x,y\n\nids = dat[\"Id\"].to_list()\ntrain_ids = ids[:int(len(ids)*0.8)]\nval_ids = ids[int(len(ids)*0.8):int(len(ids)*0.9)]\ntest_ids = ids[int(len(ids)*0.9):]\n\npath = \"../input/petfinder-pawpularity-score/train/\"\nlabels = dat.set_index(\"Id\")[\"Pawpularity\"]\nc = Data(path,labels=labels,ids=ids)#,aug_arg=True)\nc_train = Data(path,labels=labels,ids=train_ids)#,aug_arg=True)\nc_val = Data(path,labels=labels,ids=val_ids)\nc_test = Data(path,labels=labels,ids=test_ids)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T06:01:25.145894Z","iopub.execute_input":"2021-10-17T06:01:25.146151Z","iopub.status.idle":"2021-10-17T06:01:25.162328Z","shell.execute_reply.started":"2021-10-17T06:01:25.146123Z","shell.execute_reply":"2021-10-17T06:01:25.161534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# l = np.array([t,t,t,t])\n# l = l.transpose((0,3,1,2))\n# # model.forward(l)\n# k = torch.Tensor(l)#transforms.ToTensor()(l[0])\n# # feature_extractor(images=k,do_resize=False, size = None)\n# o = vit_model(k).pooler_output\n# o.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-17T06:01:27.110263Z","iopub.execute_input":"2021-10-17T06:01:27.110535Z","iopub.status.idle":"2021-10-17T06:01:27.114526Z","shell.execute_reply.started":"2021-10-17T06:01:27.110507Z","shell.execute_reply":"2021-10-17T06:01:27.113583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nsteps = 60\nbatch_size = 256\nfor epoch in range(epochs):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i in range(steps):\n        # get the inputs; data is a list of [inputs, labels]\n        x,y = c_train.load_batch(batch_size)\n        x = (torch.Tensor(x.transpose((0,3,1,2)))-128)/255\n        y = torch.Tensor(y)\n        x, y = x.cuda(), y.cuda() # add this line\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        del x,y, outputs\n        # print statistics\n        running_loss += loss.item()\n        if i % 10 == 9:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T06:31:32.825958Z","iopub.execute_input":"2021-10-17T06:31:32.826713Z","iopub.status.idle":"2021-10-17T06:35:07.215077Z","shell.execute_reply.started":"2021-10-17T06:31:32.826677Z","shell.execute_reply":"2021-10-17T06:35:07.213931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = './cifar_net.pth'\ntorch.save(net.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T05:11:17.348117Z","iopub.status.idle":"2021-10-17T05:11:17.349011Z","shell.execute_reply.started":"2021-10-17T05:11:17.34875Z","shell.execute_reply":"2021-10-17T05:11:17.348791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = np.array([cv2.cvtColor(cv2.resize(cv2.imread(path+image+\".jpg\"),(224,224)),cv2.COLOR_BGR2RGB) for image in test_ids])\ny = labels.loc[test_ids]\nimages = (torch.Tensor(images.transpose((0,3,1,2)))-128)/255\nimages = images.cuda()\ny_pred = model.forward(images)#.to_device()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T06:35:13.192687Z","iopub.execute_input":"2021-10-17T06:35:13.19339Z","iopub.status.idle":"2021-10-17T06:35:23.510611Z","shell.execute_reply.started":"2021-10-17T06:35:13.193351Z","shell.execute_reply":"2021-10-17T06:35:23.509881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(np.abs(y.to_numpy().reshape((-1,1))/100-y_pred.cpu().detach().numpy()))\nprint(\"METRIC : \",np.sqrt(np.sum((y.to_numpy().reshape((-1,1))-y_pred.cpu().detach().numpy()*100)**2)/(y_pred.shape[0])))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T06:35:23.512084Z","iopub.execute_input":"2021-10-17T06:35:23.512412Z","iopub.status.idle":"2021-10-17T06:35:29.198347Z","shell.execute_reply.started":"2021-10-17T06:35:23.512379Z","shell.execute_reply":"2021-10-17T06:35:29.197616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del images\nplt.figure()\nplt.hist(y)\nplt.figure()\nplt.hist(y_pred.cpu().detach().numpy())","metadata":{"execution":{"iopub.status.busy":"2021-10-17T06:35:29.19975Z","iopub.execute_input":"2021-10-17T06:35:29.200023Z","iopub.status.idle":"2021-10-17T06:35:29.611814Z","shell.execute_reply.started":"2021-10-17T06:35:29.199991Z","shell.execute_reply":"2021-10-17T06:35:29.611129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = Net()\nnet.load_state_dict(torch.load(PATH))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T05:11:17.350135Z","iopub.status.idle":"2021-10-17T05:11:17.35085Z","shell.execute_reply.started":"2021-10-17T05:11:17.350593Z","shell.execute_reply":"2021-10-17T05:11:17.350616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        # calculate outputs by running images through the network\n        outputs = net(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T05:11:17.352056Z","iopub.status.idle":"2021-10-17T05:11:17.352739Z","shell.execute_reply.started":"2021-10-17T05:11:17.352503Z","shell.execute_reply":"2021-10-17T05:11:17.352527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}