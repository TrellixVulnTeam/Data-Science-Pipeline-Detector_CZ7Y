{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport PIL\nimport math\nimport glob\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport csv\n\nimport torchvision\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch import Tensor\nimport torch\nimport torch.nn as nn\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-06T08:01:21.084107Z","iopub.execute_input":"2021-12-06T08:01:21.084694Z","iopub.status.idle":"2021-12-06T08:01:22.997696Z","shell.execute_reply.started":"2021-12-06T08:01:21.084599Z","shell.execute_reply":"2021-12-06T08:01:22.99697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, label_path, transform=None):\n        x = []\n        y = []\n\n        with open(label_path, 'r') as infh:\n            for i, line in enumerate(infh):\n                if i == 0:\n                    continue\n                d = line.replace('\\n', '').split(',')\n                x.append(\"../input/petfinder-pawpularity-score/train/\"+d[0]+\".jpg\")\n                y.append(float(d[-1]))\n                \n                self.x = x    \n                self.y = torch.from_numpy(np.array(y)).float().view(-1, 1)\n                self.transform = transform\n                \n    def __len__(self):\n        return len(self.x)\n\n\n    def __getitem__(self, i):\n        img = PIL.Image.open(self.x[i]).convert('RGB')\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, self.y[i]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_dir = \"../input/petfinder-pawpularity-score/train.csv\"\n\n#画像整形\ntransform = torchvision.transforms.Compose([\n    transforms.Resize([224,224]),\n    transforms.ToTensor(),\n])\n\n#バッチサイズ\nbatchsize = 256\n\n#train、validationのDataset作成\ntrainset = MyDataset(train_data_dir, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.vgg16(pretrained=False)\nmodel.load_state_dict(torch.load(\"../input/pytorch-model-zoo/vgg16-397923af.pth\"))\nmodel.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),　　  \n            nn.Linear(4096, 128),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(128, 1),\n        )\n\nfor i, param in enumerate(model.parameters()):\n    if i < 21:\n        param.requires_grad = False\n\ndevice = torch.device('cuda')\nmodel.to(device)\n        \ncriterion = nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(),0.16)\nnum_epoch = 50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = []\n\nfor epoch in range(num_epoch):\n    # 学習\n    model.train()\n    running_train_loss = 0.0\n    with torch.set_grad_enabled(True):\n        for data in trainloader:\n            inputs, labels = data[0], data[1]\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            #forward\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_train_loss += loss.item() * inputs.size(0)\n            \n            #backward\n            loss.backward()\n            optimizer.step()\n    train_loss.append(running_train_loss / len(trainset)) \n\n    print('#epoch:{}\\ttrain loss: {}\\ttrain Rloss: {}'.format(epoch + 1,\n                                                running_train_loss / len(trainset), \n                                                round(np.sqrt(running_train_loss / len(trainset)),3),))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 次の平均、分散を用いて正規化\nnormalize = transforms.Normalize(\n    mean=[0.485, 0.456, 0.406],\n    std=[0.229, 0.224, 0.225])\n# 画像を256x256にリサイズ　→　中央の224を切り取り\npreprocess = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    normalize\n])\n\nimg_list = glob.glob(\"../input/petfinder-pawpularity-score/test/*\")\n\ninf_out_list = []\ninf_out_list.append([\"Id\",\"Pawpularity\"])\n\nwith torch.no_grad():\n    for img_file in img_list:\n        img = Image.open(img_file)\n        # 画像の正規化\n        img_tensor = preprocess(img).to(device)\n\n        model.eval()\n\n        y = model(img_tensor.unsqueeze(0))\n\n        inf_out_list.append([img_file.split(\"/\")[-1].split(\".\")[0],round(y.item(),2)])\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"./submission.csv\",mode=\"w\") as f:\n    writer = csv.writer(f)\n    for row in inf_out_list:\n        writer.writerow(row)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}