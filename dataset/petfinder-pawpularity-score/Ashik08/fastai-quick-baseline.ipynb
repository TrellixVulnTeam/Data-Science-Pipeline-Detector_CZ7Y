{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing Fastai and checking the version \n!pip install ../input/fastai-whl/fastai-2.5.3-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ../input/fastdownload/fastdownload-0.0.5-py3-none-any.whl -f ./ --no-index --no-deps\n\nimport fastai \nprint(fastai.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:48:20.142685Z","iopub.execute_input":"2022-01-08T01:48:20.143078Z","iopub.status.idle":"2022-01-08T01:48:25.764438Z","shell.execute_reply.started":"2022-01-08T01:48:20.142982Z","shell.execute_reply":"2022-01-08T01:48:25.763179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the packages we need \nfrom fastai.vision.all import * \nfrom fastai import * \nimport pandas as pd \nimport numpy as np\nimport fastai \n\n# Checking the version \nprint(fastai.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:48:29.483146Z","iopub.execute_input":"2022-01-08T01:48:29.483449Z","iopub.status.idle":"2022-01-08T01:48:35.543504Z","shell.execute_reply.started":"2022-01-08T01:48:29.483417Z","shell.execute_reply":"2022-01-08T01:48:35.542367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specifying the train and test path for the images \ntrain_imgs_path = '../input/petfinder-pawpularity-score/train/'\ntest_imgs_path = '../input/petfinder-pawpularity-score/test/'\n\ntrain_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntest_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T05:44:15.015455Z","iopub.execute_input":"2021-10-11T05:44:15.016018Z","iopub.status.idle":"2021-10-11T05:44:15.061516Z","shell.execute_reply.started":"2021-10-11T05:44:15.015963Z","shell.execute_reply":"2021-10-11T05:44:15.06086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets normalize the targets \nfrom sklearn.preprocessing import MinMaxScaler \nscaler = MinMaxScaler() \n\n# Fit the scaler to our targets \nscaled_targets = scaler.fit_transform(np.expand_dims(train_df.Pawpularity , axis = 1))\nscaled_targets","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Applying PCA to condense the rest of the variables into one whole column \n\nX = train_df.drop(['Id' , 'Pawpularity'] , axis = 1)\n\nfrom sklearn.decomposition import PCA \npca = PCA(n_components = 1)\n\nX_new = pca.fit_transform(X)\n\n\n\n# Appending the new cols \ntrain_df['Pawpularity_scaled'] = scaled_targets \ntrain_df['reg_block'] = X_new\n\n\n# Append the full path \ndef append_ext(fn , train = True):\n  if train:\n    return f'{train_imgs_path}{fn}.jpg'\n  else:\n    return f'{test_imgs_path}{fn}.jpg'\n\n# Applying the above function on our dataframe \ntrain_df['full_path'] = train_df['Id'].apply(lambda x: append_ext(x))\ntest_df['full_path'] = test_df['Id'].apply(lambda x: append_ext(x , train = False))\n\ntrain_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T05:44:16.791846Z","iopub.execute_input":"2021-10-11T05:44:16.792509Z","iopub.status.idle":"2021-10-11T05:44:16.829949Z","shell.execute_reply.started":"2021-10-11T05:44:16.792475Z","shell.execute_reply":"2021-10-11T05:44:16.829151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying the transforms (basic transformes from the imagenet)\n\nitem_tfms=RandomResizedCrop(460)\nbatch_tfms=[*aug_transforms(size=224, max_warp=0), Normalize.from_stats(*imagenet_stats)]\ntrain_data = Path(train_imgs_path)\n\n\n# Creating the datablock api \npaw_block = DataBlock(blocks = (ImageBlock , RegressionBlock()) , \n                      get_x = ColReader('full_path') , \n                      get_y = ColReader('Pawpularity') , \n                      splitter = RandomSplitter() , \n                      item_tfms = item_tfms , \n                      batch_tfms = batch_tfms)\n\n# Getting the summary \npaw_block.summary(train_df)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T05:44:19.582462Z","iopub.execute_input":"2021-10-11T05:44:19.583254Z","iopub.status.idle":"2021-10-11T05:44:25.288571Z","shell.execute_reply.started":"2021-10-11T05:44:19.583206Z","shell.execute_reply":"2021-10-11T05:44:25.287883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the DataLoaders and specifying the batch size of 32\npaw_dls = paw_block.dataloaders(train_df , batch_size= 32)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T05:44:25.290198Z","iopub.execute_input":"2021-10-11T05:44:25.290451Z","iopub.status.idle":"2021-10-11T05:44:25.394792Z","shell.execute_reply.started":"2021-10-11T05:44:25.29042Z","shell.execute_reply":"2021-10-11T05:44:25.394098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the inference model (that has been trained before on google colab)\nlearn_inf = load_learner('../input/new-model/new_model.pkl')\nlearn_inf","metadata":{"execution":{"iopub.status.busy":"2021-10-11T05:44:49.613531Z","iopub.execute_input":"2021-10-11T05:44:49.61379Z","iopub.status.idle":"2021-10-11T05:44:52.986607Z","shell.execute_reply.started":"2021-10-11T05:44:49.613761Z","shell.execute_reply":"2021-10-11T05:44:52.985943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the teest filenames \ntest_fns = get_image_files(test_imgs_path)\n\n# Creating a dataloader for our test data\ntest_dls = paw_dls.test_dl(test_fns)\n\ntest_dls.show_batch()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T05:44:55.482433Z","iopub.execute_input":"2021-10-11T05:44:55.482684Z","iopub.status.idle":"2021-10-11T05:44:56.083189Z","shell.execute_reply.started":"2021-10-11T05:44:55.482658Z","shell.execute_reply":"2021-10-11T05:44:56.082513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a empty dataframe for the test  data \nimport os \ntest_data = pd.DataFrame()\n\n# Get the predictions \ntest_dl = paw_dls.test_dl(get_image_files(test_imgs_path))\ntest_pred = learn_inf.get_preds(dl = test_dl)\n\ntest_data['Id'] = [img[:-4]for img in os.listdir(test_imgs_path)]\ntest_data","metadata":{"execution":{"iopub.status.busy":"2021-10-11T05:45:01.198473Z","iopub.execute_input":"2021-10-11T05:45:01.198827Z","iopub.status.idle":"2021-10-11T05:45:01.821599Z","shell.execute_reply.started":"2021-10-11T05:45:01.19879Z","shell.execute_reply":"2021-10-11T05:45:01.820888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now adding the pawpularity score to our dataframe \ntest_data['Pawpularity'] = scaler.inverse_transform(test_pred[0].detach().numpy())\ntest_data","metadata":{"execution":{"iopub.status.busy":"2021-10-11T05:45:04.304574Z","iopub.execute_input":"2021-10-11T05:45:04.304836Z","iopub.status.idle":"2021-10-11T05:45:04.315737Z","shell.execute_reply.started":"2021-10-11T05:45:04.304808Z","shell.execute_reply":"2021-10-11T05:45:04.314937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the submission\ntest_data.to_csv('submission.csv' , index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}