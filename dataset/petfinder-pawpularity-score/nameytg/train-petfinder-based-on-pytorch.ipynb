{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/ > /dev/null # no output\n!pip install torch_optimizer --no-index --find-links=file:///kaggle/input/torch-optimizer/torch_optimizer\n    \nimport math\nimport pandas as pd\nimport os \nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch_optimizer as optim\nfrom torch.optim import lr_scheduler\nimport torchvision.models as models\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport sklearn.model_selection\nimport torchvision.datasets\nimport torchvision.transforms as transforms\nimport torch\nimport torchvision\nfrom PIL import Image\nfrom sklearn.metrics import mean_squared_error\nimport efficientnet_pytorch\nfrom glob import glob\nimport gc\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-29T02:47:20.689748Z","iopub.execute_input":"2021-09-29T02:47:20.690773Z","iopub.status.idle":"2021-09-29T02:48:03.195489Z","shell.execute_reply.started":"2021-09-29T02:47:20.690607Z","shell.execute_reply":"2021-09-29T02:48:03.1946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\n# target_data = train_data['Pawpularity']\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:03.199244Z","iopub.execute_input":"2021-09-29T02:48:03.199488Z","iopub.status.idle":"2021-09-29T02:48:03.281269Z","shell.execute_reply.started":"2021-09-29T02:48:03.199462Z","shell.execute_reply":"2021-09-29T02:48:03.280577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images_path = []\nfor dirpath, dirnames, filenames in os.walk(\"../input/petfinder-pawpularity-score/train\"):\n    for filename in [f for f in filenames if f.endswith(\".jpg\")]:\n        train_images_path.append(os.path.join(dirpath, filename))\ntrain_images_path\ntrain_data['input_file_loc'] = sorted(train_images_path)\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:03.282664Z","iopub.execute_input":"2021-09-29T02:48:03.282912Z","iopub.status.idle":"2021-09-29T02:48:08.660194Z","shell.execute_reply.started":"2021-09-29T02:48:03.28288Z","shell.execute_reply":"2021-09-29T02:48:08.659478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.iloc[0,14]","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:08.662166Z","iopub.execute_input":"2021-09-29T02:48:08.662425Z","iopub.status.idle":"2021-09-29T02:48:08.667764Z","shell.execute_reply.started":"2021-09-29T02:48:08.662377Z","shell.execute_reply":"2021-09-29T02:48:08.667133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.Resize((224, 224)),\n     transforms.ToTensor(),\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:08.669112Z","iopub.execute_input":"2021-09-29T02:48:08.669719Z","iopub.status.idle":"2021-09-29T02:48:08.680186Z","shell.execute_reply.started":"2021-09-29T02:48:08.669665Z","shell.execute_reply":"2021-09-29T02:48:08.679471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train_data['Pawpularity'].values\nfeatures","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:08.681508Z","iopub.execute_input":"2021-09-29T02:48:08.681771Z","iopub.status.idle":"2021-09-29T02:48:08.690393Z","shell.execute_reply.started":"2021-09-29T02:48:08.681737Z","shell.execute_reply":"2021-09-29T02:48:08.689318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetDataset(torch.utils.data.Dataset):\n    def __init__(self, df, data_dir, transform=None, mode='train'):\n        self.df = df\n        self.data_dir = data_dir\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img_name = self.df.iloc[idx, 14]\n        dense_features = self.df.iloc[idx, 1:13]\n        img = Image.open(img_name)\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        target = torch.tensor([self.df.iloc[idx, 13]])\n        dense_features = torch.tensor(dense_features)\n        return img, dense_features, target","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:08.692888Z","iopub.execute_input":"2021-09-29T02:48:08.693235Z","iopub.status.idle":"2021-09-29T02:48:08.70297Z","shell.execute_reply.started":"2021-09-29T02:48:08.693199Z","shell.execute_reply":"2021-09-29T02:48:08.702167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularModel(nn.Module):\n    def __init__(self, depth):\n        super(PawpularModel, self).__init__()\n        self.depth = depth\n        self.base = efficientnet_pytorch.EfficientNet.from_name(f'efficientnet-b{self.depth}' )\n        pretrained_file = glob(f'../input/efficientnet-pytorch/efficientnet-b{self.depth}*')[0]\n        checkpoint = torch.load(pretrained_file)\n        self.base.load_state_dict(checkpoint)\n#         self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n        self.base._fc = nn.Linear(self.base._fc.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.fc1 = nn.Linear(140, 64)\n        self.fc2 = nn.Linear(64, 1)\n        self.prelu = nn.PReLU()\n\n    def forward(self, image, features):\n        x = self.base(image)\n        x = self.dropout(x)\n        x = torch.cat([x, features], dim=1)\n        x = self.fc1(x)\n        x = torch.relu(x)\n        x = self.fc2(x)\n        x = self.prelu(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:08.704216Z","iopub.execute_input":"2021-09-29T02:48:08.704779Z","iopub.status.idle":"2021-09-29T02:48:08.714605Z","shell.execute_reply.started":"2021-09-29T02:48:08.704745Z","shell.execute_reply":"2021-09-29T02:48:08.713903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def radam(parameters, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n    if isinstance(betas, str):\n        betas = eval(betas)\n    return optim.RAdam(parameters,\n                      lr=lr,\n                      betas=betas,\n                      eps=eps,\n                      weight_decay=weight_decay)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:08.715634Z","iopub.execute_input":"2021-09-29T02:48:08.716218Z","iopub.status.idle":"2021-09-29T02:48:08.723752Z","shell.execute_reply.started":"2021-09-29T02:48:08.716177Z","shell.execute_reply":"2021-09-29T02:48:08.72306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.MSELoss()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:08.726308Z","iopub.execute_input":"2021-09-29T02:48:08.726642Z","iopub.status.idle":"2021-09-29T02:48:08.734787Z","shell.execute_reply.started":"2021-09-29T02:48:08.726605Z","shell.execute_reply":"2021-09-29T02:48:08.734169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.autograd import Variable\n#add extra one columns\n# train_data['kfold']=-1\n#Distributing the data 5 shares\nkfold = KFold(n_splits=10, shuffle= True, random_state = 0)\nfor fold, (train_indicies, valid_indicies) in enumerate(kfold.split(X=train_data)):\n    model = PawpularModel(0)\n    lr = None\n    optimizer = radam(model.parameters(), lr=1e-3, betas=(0.9,0.999), eps=1e-3, weight_decay=1e-4)\n    model.to(device)\n#     model.train()\n    train_x, valid_x = train_data.loc[train_indicies], train_data.loc[valid_indicies]\n    dataset  = PetDataset(df=train_x, data_dir=\"../input/petfinder-pawpularity-score/train\", transform=transform, mode='train')\n    valid_dataset  = PetDataset(df=valid_x, data_dir=\"../input/petfinder-pawpularity-score/train\", transform=transform, mode='vaild')\n    train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=64, shuffle=True, num_workers=0)\n    vaild_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=64, shuffle=True, num_workers=0)\n    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader)*10, eta_min=1e-6)\n    for epoch in range(10):\n        running_loss = 0.0\n        error = 0.0\n        vaild_num = 0\n        model.train()\n        for i, data in enumerate(train_loader, 0):\n            inputs, features, labels = data\n#             inputs, features, labels = Variable(inputs.to(device)), Variable(features.to(device)), Variable(labels.to(device))\n#             print(inputs.shape,features.shape,labels.shape)\n            \n            features=Variable(features.cuda().to(torch.float32))\n            inputs=Variable(inputs.cuda().to(torch.float32))\n            labels=Variable(labels.cuda().to(torch.float32))\n            \n            outputs = model(inputs, features)\n            outputs=outputs.to(torch.float32)\n        \n            loss = criterion(outputs, labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            lr = optimizer.param_groups[0]['lr']\n            running_loss += loss.item()\n            if i % 20 == 19:    # print every 20 mini-batches\n                print('[%d, %5d] loss: %.3f RMSE: %.3f'%\n                      (epoch + 1, i + 1, running_loss / 20, mean_squared_error(labels.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)))\n                running_loss = 0.0\n        model.eval()\n        for i, vaild in enumerate(vaild_loader, 0): \n            inputs, features, labels = vaild\n            inputs, features, labels = inputs.to(device), features.to(device), labels.to(device)\n            outputs = model(inputs, features)\n            labels=labels.to(torch.float32)\n            outputs=outputs.to(torch.float32)\n            error += mean_squared_error(labels.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)\n            vaild_num = i\n        print('error = ', error/(vaild_num+1))\n    \n    torch.save(model.state_dict(), f'./fold_{fold}.pth')\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n#     dataiter = iter(train_loader)\n#     images, features, labels = dataiter.next()\n\n    \n# print(train_data.kfold.value_counts()) #total data 300000 = kfold split :5 * 60000\n\n#output of train folds data\n# train_data.to_csv(\"trainfold_10.csv\",index=False)\n# train_data","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:48:08.735934Z","iopub.execute_input":"2021-09-29T02:48:08.736232Z"},"trusted":true},"execution_count":null,"outputs":[]}]}