{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n## [PetFinder.my - Pawpularity Contest][1]\n---\n**Comments**: Thanks to previous great Notebooks.\n\n[Vision Transformer (ViT) Fine-tuning][2]\n\n[1]: https://www.kaggle.com/c/petfinder-pawpularity-score\n[2]: https://www.kaggle.com/raufmomin/vision-transformer-vit-fine-tuning","metadata":{}},{"cell_type":"markdown","source":"# 0. Settings","metadata":{}},{"cell_type":"code","source":"# Import dependencies \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport os\nimport pathlib\nimport gc\nimport sys\nimport math \nimport time \nimport tqdm \nfrom tqdm import tqdm \nimport random\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow_hub as hub\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import StratifiedKFold ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-25T05:28:12.709702Z","iopub.execute_input":"2021-11-25T05:28:12.709955Z","iopub.status.idle":"2021-11-25T05:28:18.384942Z","shell.execute_reply.started":"2021-11-25T05:28:12.709884Z","shell.execute_reply":"2021-11-25T05:28:18.384027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# global config\n# When you would like to use another pre-trained model in TensorFlow Hub, you can change 'model_url'. \nconfig = {\n    'data_path': '../input/petfinder-pawpularity-score',\n    'model_1_path': '../input/effnet-v2-s-feature-vector',\n    'model_2_path': '../input/vit-l32',\n    'model_3_path': '../input/keras-xception',\n    'input_path': '../input', \n    'output_path': './',\n    'model_1_url': \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/feature_vector/2\",\n    'nfolds': 10,\n    'batch_size': 16,\n    'learning_rate': 1e-4,\n    'num_epochs': 10,\n    'image_size': (384, 384),\n    'input_shape': (384, 384, 3),\n    'blend_weight': 1/3,\n}\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# For reproducible results    \ndef seed_all(s):\n    random.seed(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(s) \nglobal_seed = 42\nseed_all(global_seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:28:19.916893Z","iopub.execute_input":"2021-11-25T05:28:19.91717Z","iopub.status.idle":"2021-11-25T05:28:19.926494Z","shell.execute_reply.started":"2021-11-25T05:28:19.917136Z","shell.execute_reply":"2021-11-25T05:28:19.924593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. DataFrame Preprocessing","metadata":{}},{"cell_type":"code","source":"data_folder = config['data_path']\ntrain_folder = os.path.join(data_folder, 'train')\ntest_folder = os.path.join(data_folder, 'test')\nsample_submission_path = data_folder + '/sample_submission.csv'\n\ntrain_df = pd.read_csv(os.path.join(data_folder, 'train.csv'))\nprint(train_df.shape)\ntest_df = pd.read_csv(os.path.join(data_folder, 'test.csv'))\nprint(test_df.shape)\n#sample_df = pd.read_csv(sample_submission_path)\n#print(sample_df.shape)\n\n#train_path = pathlib.Path(train_folder); print(train_path)\n#train_photo_list = list(train_path.iterdir()); print(len(train_photo_list))\n#test_path = pathlib.Path(test_folder); print(test_path)\n#test_photo_list = list(test_path.iterdir()); print(len(test_photo_list))\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:28:24.480635Z","iopub.execute_input":"2021-11-25T05:28:24.481333Z","iopub.status.idle":"2021-11-25T05:28:24.545052Z","shell.execute_reply.started":"2021-11-25T05:28:24.48129Z","shell.execute_reply":"2021-11-25T05:28:24.544254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pawpularity Scaling\nscaler = train_df['Pawpularity'].max()\ntrain_df['Pawpularity_scaled'] = train_df['Pawpularity'] / scaler\n\n# add 'Path' column\npath_list = []\nfor id in train_df['Id']:\n    path = os.path.join(train_folder, id) + '.jpg'\n    path_list.append(path)\ntrain_df['Path'] = path_list\n\n# Data Shuffling\ntrain_df_shuffled=train_df.iloc[np.random.permutation(train_df.index)].reset_index(drop=True)\n\n# split validation data\nkf = KFold(n_splits=config['nfolds'])\nfor nfold, (train_index, val_index) in enumerate(kf.split(train_df_shuffled)):\n    train_df_shuffled.loc[val_index, 'fold'] = nfold\nprint(train_df_shuffled.groupby(['fold', train_df_shuffled.fold]).size())\nprint()\n    \n#skf = StratifiedKFold(n_splits=config['nfolds'], shuffle=True, random_state=global_seed)\n#for nfold, (train_index, val_index) in enumerate(skf.split(X=train_df.index,\n#                                                           y=train_df.target)):\n#    train_df.loc[val_index, 'fold'] = nfold\n#print(train_df.groupby(['fold', train_df.target]).size())\n\ntrain_df_shuffled","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:28:26.821374Z","iopub.execute_input":"2021-11-25T05:28:26.821979Z","iopub.status.idle":"2021-11-25T05:28:26.902503Z","shell.execute_reply.started":"2021-11-25T05:28:26.821941Z","shell.execute_reply":"2021-11-25T05:28:26.901726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_trains = []\np_valids = []\nfor p in range(3):\n    p_fold = p\n    p_train = train_df_shuffled.query(f'fold != {p_fold}').reset_index(drop=True)\n    p_valid = train_df_shuffled.query(f'fold == {p_fold}').reset_index(drop=True)\n    p_trains.append(p_train)\n    p_valids.append(p_valid)\n    print('-'*30)\n    print(f'train-{p}\\n', p_train.Pawpularity.describe())\n    print()\n    print(f'valid-{p}\\n', p_valid.Pawpularity.describe())\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:28:29.638728Z","iopub.execute_input":"2021-11-25T05:28:29.641345Z","iopub.status.idle":"2021-11-25T05:28:29.6751Z","shell.execute_reply.started":"2021-11-25T05:28:29.641296Z","shell.execute_reply":"2021-11-25T05:28:29.674415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. DataGenerator","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef preprocessing_img(img):\n    img = tf.expand_dims(img, axis=0)\n    img = tf.image.resize(img, config['image_size'])\n    #img /= 255.0\n    return img\n\ndef load_and_preprocessing_img(path_list):\n    img_list = []\n    for path in path_list:\n        img_raw = tf.io.read_file(path)\n        img_tensor = tf.image.decode_image(img_raw)\n        img_list.append(preprocessing_img(img_tensor))        \n    img_batch = tf.concat(img_list, axis=0)\n    return img_batch\n\nclass ImageSequence(keras.utils.Sequence):\n    def __init__(self, df, batch_size=config['batch_size'], mode='train'):\n        self.l = None\n        self.x = df.Path\n        self.y = df.Pawpularity_scaled\n        self.batch_size = batch_size \n        self.num_samples = len(df)\n        self.mode = mode\n\n    def __len__(self):\n        self.l = self.num_samples // self.batch_size\n        return self.l\n\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx+1) * self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx+1) * self.batch_size]\n        \n        batch_x_img = load_and_preprocessing_img(batch_x)\n        return batch_x_img, np.array(batch_y)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:28:31.579795Z","iopub.execute_input":"2021-11-25T05:28:31.580348Z","iopub.status.idle":"2021-11-25T05:28:31.59151Z","shell.execute_reply.started":"2021-11-25T05:28:31.58031Z","shell.execute_reply":"2021-11-25T05:28:31.590796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gens = []\nvalid_gens = []\n\nfor p in range(3):\n    train_gen = ImageSequence(p_trains[p], mode='train')\n    valid_gen = ImageSequence(p_valids[p], mode='valid')\n    \n    train_gens.append(train_gen)\n    valid_gens.append(valid_gen)\n    \n    print('-'*30)\n    print(f'train_gen_{p+1} length', len(train_gen))\n    print(f'valid_gen_{p+1} length', len(valid_gen))\n    \n    sample = next(iter(train_gen))\n    print(sample[0].shape)\n    print(sample[1].shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:28:34.163089Z","iopub.execute_input":"2021-11-25T05:28:34.163919Z","iopub.status.idle":"2021-11-25T05:28:36.903411Z","shell.execute_reply.started":"2021-11-25T05:28:34.163843Z","shell.execute_reply":"2021-11-25T05:28:36.902233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model Training","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Model_1 (EfficientNet V2 trained on imagenet-21k)","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# Downloading models from TensorFlow Hub (Internet should be avairable).\nbase_model_1 = tf.keras.Sequential([\n    hub.KerasLayer(config['model_1_url'], trainable=False),\n    tf.keras.layers.Dense(512, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\"\"\"\n\nbase_model_1 = tf.keras.Sequential([\n    tf.keras.models.load_model(config['model_1_path']),\n    tf.keras.layers.Dense(512, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\ndata_augmentation = tf.keras.models.Sequential([\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomRotation(0.1),\n    preprocessing.RandomZoom(0.1),\n])\n\ninputs_1 = keras.Input(shape=config['input_shape'])\nx_1 = data_augmentation(inputs_1)\nx_1 = tf.keras.layers.Resizing(384, 384)(x_1)\nx_1 = tf.keras.layers.Rescaling(1. / 255)(x_1)\noutputs_1 = base_model_1(x_1)\nmodel_1 = keras.Model(inputs_1, outputs_1)\n\nmodel_1.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:47:46.030954Z","iopub.execute_input":"2021-11-23T08:47:46.031721Z","iopub.status.idle":"2021-11-23T08:48:04.930737Z","shell.execute_reply.started":"2021-11-23T08:47:46.031678Z","shell.execute_reply":"2021-11-23T08:48:04.929763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\ntrain_gen = train_gens[0]\nvalid_gen = valid_gens[0]\n\nfit_history_1 = model_1.fit_generator(train_gen, epochs=5,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:48:11.772974Z","iopub.execute_input":"2021-11-23T08:48:11.773365Z","iopub.status.idle":"2021-11-23T09:00:41.367083Z","shell.execute_reply.started":"2021-11-23T08:48:11.773323Z","shell.execute_reply":"2021-11-23T09:00:41.366239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finetuning\nfor l in model_1.layers:\n    l.trainable = True\n    \nmodel_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n                loss='mean_squared_error',\n                metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\nmodel_1.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T09:00:58.321683Z","iopub.execute_input":"2021-11-23T09:00:58.321973Z","iopub.status.idle":"2021-11-23T09:00:58.366621Z","shell.execute_reply.started":"2021-11-23T09:00:58.321942Z","shell.execute_reply":"2021-11-23T09:00:58.365729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_history_1 = model_1.fit_generator(train_gen, epochs=2,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T09:01:07.343675Z","iopub.execute_input":"2021-11-23T09:01:07.343962Z","iopub.status.idle":"2021-11-23T09:11:17.197535Z","shell.execute_reply.started":"2021-11-23T09:01:07.34393Z","shell.execute_reply":"2021-11-23T09:11:17.196772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Model_2 (ViT)","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# downloading models from vit-keras (Internet should be avairable).\n!pip install vit-keras -q\n!pip install tensorflow-addons -q\n\nfrom vit_keras import vit\n\nvit_model = vit.vit_l32(\n    image_size=384,\n    pretrained=True,\n    include_top=False,\n    pretrained_top=False,\n)\n\"\"\"\n\nvit_model = tf.keras.models.load_model(config['model_2_path'])\n\nbase_model_2 = tf.keras.Sequential([\n    vit_model,\n    tf.keras.layers.Dense(256, activation='selu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\ndata_augmentation = tf.keras.models.Sequential([\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomRotation(0.1),\n    preprocessing.RandomZoom(0.1),\n])\n\ninputs_2 = keras.Input(shape=config['input_shape'])\nx_2 = data_augmentation(inputs_2)\nx_2 = tf.keras.layers.Resizing(384, 384)(x_2)\nx_2 = tf.keras.layers.Rescaling(1. / 255)(x_2)\noutputs_2 = base_model_2(x_2)\nmodel_2 = keras.Model(inputs_2, outputs_2)\n\nmodel_2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:29:22.701416Z","iopub.execute_input":"2021-11-25T05:29:22.701675Z","iopub.status.idle":"2021-11-25T05:29:29.505381Z","shell.execute_reply.started":"2021-11-25T05:29:22.701647Z","shell.execute_reply":"2021-11-25T05:29:29.504679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in vit_model.layers:\n    layer.trainable = False\n\nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\nfrom tensorflow.keras.optimizers import Adam\n\nnum_epochs = 3\nnum_train_steps = len(train_gen) * num_epochs\n\nlr_scheduler = PolynomialDecay(\n    initial_learning_rate=1e-3, end_learning_rate=1e-4, decay_steps=num_train_steps\n)\n\nmodel_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\nmodel_2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:30:45.848782Z","iopub.execute_input":"2021-11-25T05:30:45.84945Z","iopub.status.idle":"2021-11-25T05:38:11.428996Z","shell.execute_reply.started":"2021-11-25T05:30:45.849413Z","shell.execute_reply":"2021-11-25T05:38:11.42822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = train_gens[1]\nvalid_gen = valid_gens[1]\n\nfit_history_2 = model_2.fit_generator(train_gen, epochs=num_epochs,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finetuning\nfor layer in vit_model.layers:\n    layer.trainable = True\n\nnum_epochs = 2\nnum_train_steps = len(train_gen) * num_epochs\n\nlr_scheduler = PolynomialDecay(\n    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n)\n\nmodel_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\n\nmodel_2.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_history_2 = model_2.fit_generator(train_gen, epochs=num_epochs,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Model_3 (Xception)","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# downloading models (Internet should be avairable).\nbase_model_3 = tf.keras.Sequential([\n    tf.keras.applications.xception.Xception(\n        include_top=False, weights='imagenet', \n        input_shape=(299, 299, 3)),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(512, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\"\"\"\nxception_model =  tf.keras.models.load_model(config['model_3_path'])\n\nbase_model_3 = tf.keras.Sequential([\n    xception_model,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(512, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\ndata_augmentation = tf.keras.models.Sequential([\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomRotation(0.1),\n    preprocessing.RandomZoom(0.1),\n])\n\ninputs_3 = keras.Input(shape=config['input_shape'])\nx_3 = data_augmentation(inputs_3)\nx_3 = tf.keras.layers.Resizing(299, 299)(x_3)\nx_3 = tf.keras.layers.Rescaling(1. / 255)(x_3)\noutputs_3 = base_model_3(x_3)\nmodel_3 = keras.Model(inputs_3, outputs_3)\n\nfor l in xception_model.layers:\n    l.trainable = False\n\nmodel_3.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\ntrain_gen = train_gens[2]\nvalid_gen = valid_gens[2]\n\nfit_history_3 = model_3.fit_generator(train_gen, epochs=3,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finetuning\nfor l in model_3.layers:\n    l.trainable = True\n    \nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\nfrom tensorflow.keras.optimizers import Adam\n\nnum_epochs = 2\nnum_train_steps = len(train_gen) * num_epochs\n\nlr_scheduler = PolynomialDecay(\n    initial_learning_rate=1e-4, end_learning_rate=1e-5, decay_steps=num_train_steps\n)\n\nmodel_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\nmodel_3.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_history_3 = model_3.fit_generator(train_gen, epochs=num_epochs,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Prediction","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Test DataGenerator","metadata":{}},{"cell_type":"code","source":"def preprocess_dataframe(df, mode='train', shuffle=True, nfolds=None):\n    if mode == 'train':\n        img_folder = train_folder\n        \n        # Pawpularity Scaling\n        df['Pawpularity'] = df['Pawpularity'] / df['Pawpularity'].max()\n    else:\n        img_folder = test_folder\n    \n    # add 'Path' column\n    path_list = []\n    for img_id in df['Id']:\n        path = os.path.join(img_folder, img_id) + '.jpg'\n        path_list.append(path)\n    df['Path'] = path_list\n    \n    # Data Shuffling\n    if shuffle == True:\n        df = df.iloc[np.random.permutation(df.index)].reset_index(drop=True)\n        \n    # split validation data\n    if nfolds is not None:\n        kf = KFold(n_splits=config['nfolds'])\n        for nfold, (train_index, val_index) in enumerate(kf.split(df)):\n            df.loc[val_index, 'fold'] = nfold\n        \n    return df\n\ntest_df = preprocess_dataframe(test_df, mode='test', shuffle=False)\ntest_df","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:51:19.644212Z","iopub.execute_input":"2021-11-25T05:51:19.64449Z","iopub.status.idle":"2021-11-25T05:51:19.669131Z","shell.execute_reply.started":"2021-11-25T05:51:19.64446Z","shell.execute_reply":"2021-11-25T05:51:19.668485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestImageSequence(keras.utils.Sequence):\n    def __init__(self, df, batch_size=config['batch_size']):\n        self.l = None\n        self.x = df.Path\n        self.y = None \n        self.num_samples = len(df)\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        if self.num_samples % self.batch_size == 0:\n            self.l = self.num_samples // self.batch_size\n        else:\n            self.l = self.num_samples // self.batch_size + 1\n        return self.l\n\n    def __getitem__(self, idx):\n        if (idx+1) * self.batch_size <= self.l:\n            batch_x = self.x[idx * self.batch_size:(idx+1) * self.batch_size]\n        else:\n            batch_x = self.x[idx * self.batch_size:]\n        batch_x_img = load_and_preprocessing_img(batch_x)\n        return batch_x_img\n    \n# When the batch_size is not '1', submission was failed because of some errors.\ntest_gen = TestImageSequence(test_df, batch_size=1)\nprint(len(test_gen))\n\nsample =  next(iter(test_gen))\nprint(sample.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-25T05:51:22.240664Z","iopub.execute_input":"2021-11-25T05:51:22.240936Z","iopub.status.idle":"2021-11-25T05:51:22.281371Z","shell.execute_reply.started":"2021-11-25T05:51:22.240906Z","shell.execute_reply":"2021-11-25T05:51:22.280528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Model Ensemble","metadata":{}},{"cell_type":"code","source":"pred_score_1 = model_1.predict_generator(test_gen)\npred_score_1 = pred_score_1 * scaler # scaler == train_df['Pawpularity'].max()\n\npred_score_2 = model_2.predict_generator(test_gen)\npred_score_2 = pred_score_2 * scaler # scaler == train_df['Pawpularity'].max()\n\npred_score_3 = model_3.predict_generator(test_gen)\npred_score_3 = pred_score_3 * scaler # scaler == train_df['Pawpularity'].max()\n\nprint(pred_score_1)\nprint(pred_score_2)\nprint(pred_score_3)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T02:44:14.567621Z","iopub.execute_input":"2021-11-16T02:44:14.568206Z","iopub.status.idle":"2021-11-16T02:44:16.950598Z","shell.execute_reply.started":"2021-11-16T02:44:14.568161Z","shell.execute_reply":"2021-11-16T02:44:16.949671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_score = np.mean([pred_score_1, pred_score_2, pred_score_3], axis=0)\n\nprint(pred_score.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Pawpularity'] = pred_score\nsubmission_df = test_df[['Id', 'Pawpularity']]\n\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2021-11-16T02:44:16.952148Z","iopub.execute_input":"2021-11-16T02:44:16.953168Z","iopub.status.idle":"2021-11-16T02:44:16.972324Z","shell.execute_reply.started":"2021-11-16T02:44:16.953131Z","shell.execute_reply":"2021-11-16T02:44:16.971282Z"},"trusted":true},"execution_count":null,"outputs":[]}]}