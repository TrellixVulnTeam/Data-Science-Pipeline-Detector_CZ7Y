{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nMy first thought in this competition was that **cuteness** would be a big deal in predicting animal popularity  \nThis notebook explores using CLIP's multi-modal representations (and understanding of abstract concepts) for feature engineering","metadata":{}},{"cell_type":"code","source":"%%capture\n\n# https://www.kaggle.com/bguberfain/openai-clip-with-train/notebook\n\nimport sys\n!cp -r ../input/openai-clip/CLIP/CLIP-main /tmp/\n\n# Kaggle likes to unpack .gz files in datasets... so we have to pack it back\n!gzip -c /tmp/CLIP-main/clip/bpe_simple_vocab_16e6.txt > /tmp/CLIP-main/clip/bpe_simple_vocab_16e6.txt.gz\nsys.path.append('/tmp/CLIP-main')\n\n!pip install ../input/openai-clip/ftfy-5.9/ftfy-5.9\n!pip install ../input/openai-clip/torch-1.7.1+cu110-cp37-cp37m-linux_x86_64.whl \\\n             ../input/openai-clip/torchvision-0.8.2+cu110-cp37-cp37m-linux_x86_64.whl \\\n             ../input/faiss-163/faiss_gpu-1.6.3-cp37-cp37m-manylinux2010_x86_64.whl","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-16T09:47:54.620313Z","iopub.execute_input":"2021-10-16T09:47:54.62094Z","iopub.status.idle":"2021-10-16T09:48:48.313258Z","shell.execute_reply.started":"2021-10-16T09:47:54.620861Z","shell.execute_reply":"2021-10-16T09:48:48.312253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nfrom os.path import join\nimport numpy as np\nimport pandas as pd\nimport clip, os, skimage\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm import tqdm\n\nclip.available_models()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:48:48.31548Z","iopub.execute_input":"2021-10-16T09:48:48.315768Z","iopub.status.idle":"2021-10-16T09:48:51.452504Z","shell.execute_reply.started":"2021-10-16T09:48:48.315729Z","shell.execute_reply":"2021-10-16T09:48:51.451839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, preprocess = clip.load(\"../input/openai-clip/ViT-B-32.pt\", jit=False)\nmodel = model.cuda().eval()\ninput_resolution = model.visual.input_resolution\ncontext_length = model.context_length\nvocab_size = model.vocab_size\n\nprint(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\nprint(\"Input resolution:\", input_resolution)\nprint(\"Context length:\", context_length)\nprint(\"Vocab size:\", vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:48:51.4539Z","iopub.execute_input":"2021-10-16T09:48:51.45416Z","iopub.status.idle":"2021-10-16T09:49:00.898447Z","shell.execute_reply.started":"2021-10-16T09:48:51.454124Z","shell.execute_reply":"2021-10-16T09:49:00.897024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualising the Data","metadata":{}},{"cell_type":"code","source":"train_image_path = Path(\"../input/petfinder-pawpularity-score/train\")\nfile_names = [f.name for f in train_image_path.iterdir() if f.suffix == \".jpg\"]","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:49:00.900496Z","iopub.execute_input":"2021-10-16T09:49:00.900886Z","iopub.status.idle":"2021-10-16T09:49:01.097713Z","shell.execute_reply.started":"2021-10-16T09:49:00.900838Z","shell.execute_reply":"2021-10-16T09:49:01.096882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_images = []\nimages = []\nplt.figure(figsize=(15, 12))\n\nfor filename in file_names[:9]:\n    image = Image.open(join(train_image_path, filename))\n  \n    plt.subplot(3, 3, len(images) + 1)\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n\n    original_images.append(image)\n    images.append(preprocess(image))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:49:01.098891Z","iopub.execute_input":"2021-10-16T09:49:01.099148Z","iopub.status.idle":"2021-10-16T09:49:02.699403Z","shell.execute_reply.started":"2021-10-16T09:49:01.099115Z","shell.execute_reply":"2021-10-16T09:49:02.698629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prompt Feature Engineering\n[Multimodal Neurons in Artificial Neural Networks](https://openai.com/blog/multimodal-neurons/) shows that CLIP can respond to abstract concepts, such as emotions or geographical regions. With some priors around what makes animals popular, this could create some interesting features.  \n\nIt's possible information around concepts could be extracted from an image, with well-defined prompts  \nWe use the cosine similarity between language and image embeddings to extract features for modelling here","metadata":{}},{"cell_type":"code","source":"texts = ['Cute',\n         'Funny',\n         'Derp', # let's see if this works\n         'Small',\n         'Happy',\n         'Sad',\n         'Aggressive',\n         'Friendly',\n         'Old',\n         'Young',\n         'Love']","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:49:02.700433Z","iopub.execute_input":"2021-10-16T09:49:02.700649Z","iopub.status.idle":"2021-10-16T09:49:02.705308Z","shell.execute_reply.started":"2021-10-16T09:49:02.700622Z","shell.execute_reply":"2021-10-16T09:49:02.704728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_input = torch.tensor(np.stack(images)).cuda()\ntext_tokens = clip.tokenize(texts).cuda()\n\n# text_tokens = clip.tokenize([f\"A {w} photo of a\" + w for w in texts]).cuda()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:49:02.706845Z","iopub.execute_input":"2021-10-16T09:49:02.707284Z","iopub.status.idle":"2021-10-16T09:49:02.725473Z","shell.execute_reply.started":"2021-10-16T09:49:02.70725Z","shell.execute_reply":"2021-10-16T09:49:02.724826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    image_features = model.encode_image(image_input).float()\n    text_features = model.encode_text(text_tokens).float()\n\nimage_features /= image_features.norm(dim=-1, keepdim=True)\ntext_features /= text_features.norm(dim=-1, keepdim=True)\n\nsimilarity_matrix = torch.inner(text_features, image_features).cpu()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:49:02.72678Z","iopub.execute_input":"2021-10-16T09:49:02.727215Z","iopub.status.idle":"2021-10-16T09:49:08.183937Z","shell.execute_reply.started":"2021-10-16T09:49:02.727177Z","shell.execute_reply":"2021-10-16T09:49:08.183173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = len(texts)\n\nplt.figure(figsize=(20, 16))\nplt.imshow(similarity_matrix, vmin=0.1, vmax=0.3, cmap = 'RdBu')\n\nplt.yticks(range(count), texts, fontsize=18)\nplt.xticks([])\n\nfor i, image in enumerate(original_images):\n    plt.imshow(image, extent=(i - 0.5, i + 0.5, -1.6, -0.6), origin=\"lower\")\nfor x in range(similarity_matrix.shape[1]):\n    for y in range(similarity_matrix.shape[0]):\n        plt.text(x, y, f\"{similarity_matrix[y, x]:.2f}\", ha=\"center\", va=\"center\", size=12)\n\nfor side in [\"left\", \"top\", \"right\", \"bottom\"]:\n    plt.gca().spines[side].set_visible(False)\n\nplt.xlim([-0.5, count - 0.5])\nplt.ylim([count + 0.5, -2])\n\nplt.title(\"Cosine similarity matrix between text and image features\", size=20, loc='left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:49:08.185211Z","iopub.execute_input":"2021-10-16T09:49:08.185472Z","iopub.status.idle":"2021-10-16T09:49:09.308708Z","shell.execute_reply.started":"2021-10-16T09:49:08.18544Z","shell.execute_reply":"2021-10-16T09:49:09.307913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Labelling Training Set","metadata":{}},{"cell_type":"code","source":"class PetDataset(Dataset):\n    def __init__(self, path):\n        self.path = path\n        self.files = [f for f in path.iterdir() if f.suffix == \".jpg\"]\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        _im_path = self.files[idx]\n        _img = Image.open(_im_path)\n        _img = preprocess(_img)\n        return _img, _im_path.name.split('.')[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:49:09.311643Z","iopub.execute_input":"2021-10-16T09:49:09.311971Z","iopub.status.idle":"2021-10-16T09:49:09.319271Z","shell.execute_reply.started":"2021-10-16T09:49:09.311935Z","shell.execute_reply":"2021-10-16T09:49:09.318468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_similarity_features(dl):\n    features = []\n    names = []\n    with torch.no_grad():\n        for xb, name in dl:\n            xb = xb.cuda()\n            xb = model.encode_image(xb)\n            xb /= xb.norm(dim=-1, keepdim=True)\n            sim_matrix = torch.inner(text_features, xb.float()).cpu().numpy()\n            features.append(sim_matrix)\n            names.append(name)\n    return features, names","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:49:09.32082Z","iopub.execute_input":"2021-10-16T09:49:09.321082Z","iopub.status.idle":"2021-10-16T09:49:09.329651Z","shell.execute_reply.started":"2021-10-16T09:49:09.321049Z","shell.execute_reply":"2021-10-16T09:49:09.328725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = PetDataset(train_image_path)\ndl = DataLoader(ds, batch_size = 400, shuffle=False)\ntrain_features, train_names = create_similarity_features(dl)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:49:09.33122Z","iopub.execute_input":"2021-10-16T09:49:09.331731Z","iopub.status.idle":"2021-10-16T09:53:04.146755Z","shell.execute_reply.started":"2021-10-16T09:49:09.331694Z","shell.execute_reply":"2021-10-16T09:53:04.145992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features_df = pd.DataFrame(np.hstack(train_features).T,\n                           index = np.hstack(train_names).T,\n                           columns = texts)\ndf_corr = train_features_df.corr()\nplt.figure(figsize=(13,8))\n\nplt.title(\"Correlation matrix between engineered features\", size=20, loc='left') \nsns.heatmap(df_corr, cmap='RdBu', annot=True, linewidths=2)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:53:04.148002Z","iopub.execute_input":"2021-10-16T09:53:04.149943Z","iopub.status.idle":"2021-10-16T09:53:05.034594Z","shell.execute_reply.started":"2021-10-16T09:53:04.149911Z","shell.execute_reply":"2021-10-16T09:53:05.033913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving training features for later use\ntrain_features_df.to_csv('clip_features.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:53:05.036033Z","iopub.execute_input":"2021-10-16T09:53:05.036274Z","iopub.status.idle":"2021-10-16T09:53:05.183786Z","shell.execute_reply.started":"2021-10-16T09:53:05.036241Z","shell.execute_reply":"2021-10-16T09:53:05.182883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# K-Fold Training and Search\nXGB training and hyperparameter search code come from Abhishek Thakur's notebook:  \nhttps://www.kaggle.com/abhishek/optuna-xgboost-meta-features-only","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport optuna\nfrom functools import partial","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:53:05.185331Z","iopub.execute_input":"2021-10-16T09:53:05.185603Z","iopub.status.idle":"2021-10-16T09:53:06.046324Z","shell.execute_reply.started":"2021-10-16T09:53:05.185566Z","shell.execute_reply":"2021-10-16T09:53:06.045564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(trial, fold, df, useful_features):\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n    reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n    reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n    subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n    max_depth = trial.suggest_int(\"max_depth\", 1, 7)\n    \n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n\n    ytrain = xtrain.Pawpularity\n    yvalid = xvalid.Pawpularity\n\n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n\n    model = XGBRegressor(\n        random_state=42,\n        tree_method=\"gpu_hist\",\n        gpu_id=1,\n        n_estimators=10000,\n        predictor=\"gpu_predictor\",\n        learning_rate=learning_rate,\n        reg_lambda=reg_lambda,\n        reg_alpha=reg_alpha,\n        subsample=subsample,\n        colsample_bytree=colsample_bytree,\n        max_depth=max_depth,\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:53:06.047625Z","iopub.execute_input":"2021-10-16T09:53:06.047908Z","iopub.status.idle":"2021-10-16T09:53:06.061464Z","shell.execute_reply.started":"2021-10-16T09:53:06.047852Z","shell.execute_reply":"2021-10-16T09:53:06.060594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/same-old-creating-folds/train_10folds.csv\")\ntest_df = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\nsample_submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\ntest_image_path = train_image_path = Path(\"../input/petfinder-pawpularity-score/test\")\n\nuseful_features = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur',\n    'Cute', 'Funny', 'Derp', 'Small', 'Happy', 'Sad', 'Aggressive',\n    'Friendly', 'Old', 'Young', 'Love']","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:53:06.062798Z","iopub.execute_input":"2021-10-16T09:53:06.063434Z","iopub.status.idle":"2021-10-16T09:53:06.105194Z","shell.execute_reply.started":"2021-10-16T09:53:06.063395Z","shell.execute_reply":"2021-10-16T09:53:06.104467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = PetDataset(test_image_path)\ndl = DataLoader(ds, batch_size = 400, shuffle=False)\ntest_features, test_names = create_similarity_features(dl)\n\ntest_features_df = pd.DataFrame(np.hstack(test_features).T,\n                                index = np.hstack(test_names).T,\n                                columns = texts)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:53:06.106539Z","iopub.execute_input":"2021-10-16T09:53:06.106776Z","iopub.status.idle":"2021-10-16T09:53:06.176433Z","shell.execute_reply.started":"2021-10-16T09:53:06.106744Z","shell.execute_reply":"2021-10-16T09:53:06.175667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.join(train_features_df, on = 'Id')\ntest_df = test_df.join(test_features_df, on = 'Id')","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:53:06.177498Z","iopub.execute_input":"2021-10-16T09:53:06.177751Z","iopub.status.idle":"2021-10-16T09:53:06.197973Z","shell.execute_reply.started":"2021-10-16T09:53:06.177718Z","shell.execute_reply":"2021-10-16T09:53:06.197304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_fun = partial(\n    run,\n    fold=0,\n    df=train_df,\n    useful_features=useful_features,\n)\n\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(opt_fun, n_trials=200)\nprint(study.best_params)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-16T09:53:06.199207Z","iopub.execute_input":"2021-10-16T09:53:06.199538Z","iopub.status.idle":"2021-10-16T09:56:22.085123Z","shell.execute_reply.started":"2021-10-16T09:53:06.199499Z","shell.execute_reply":"2021-10-16T09:56:22.083732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_value, study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:56:31.908522Z","iopub.execute_input":"2021-10-16T09:56:31.908944Z","iopub.status.idle":"2021-10-16T09:56:31.921541Z","shell.execute_reply.started":"2021-10-16T09:56:31.908896Z","shell.execute_reply":"2021-10-16T09:56:31.920634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_predictions(params, fold, df, df_test, useful_features):    \n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.Pawpularity\n    yvalid = xvalid.Pawpularity\n\n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    xtest = xtest[useful_features]\n\n    model = XGBRegressor(\n        random_state=42,\n        tree_method=\"gpu_hist\",\n        gpu_id=1,\n        n_estimators=10000,\n        predictor=\"gpu_predictor\",\n        **params,\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(rmse)\n    return test_preds","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:56:22.094852Z","iopub.execute_input":"2021-10-16T09:56:22.095519Z","iopub.status.idle":"2021-10-16T09:56:22.106774Z","shell.execute_reply.started":"2021-10-16T09:56:22.095473Z","shell.execute_reply":"2021-10-16T09:56:22.105865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = []\nfor fold_ in range(10):\n    final_predictions.append(\n        generate_predictions(\n            study.best_params,\n            fold=fold_,\n            df=train_df,\n            df_test=test_df,\n            useful_features=useful_features,\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:56:22.10804Z","iopub.execute_input":"2021-10-16T09:56:22.108761Z","iopub.status.idle":"2021-10-16T09:56:31.887105Z","shell.execute_reply.started":"2021-10-16T09:56:22.10872Z","shell.execute_reply":"2021-10-16T09:56:31.886371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.Pawpularity = final_predictions\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T09:56:31.88832Z","iopub.execute_input":"2021-10-16T09:56:31.888574Z","iopub.status.idle":"2021-10-16T09:56:31.896698Z","shell.execute_reply.started":"2021-10-16T09:56:31.888539Z","shell.execute_reply":"2021-10-16T09:56:31.895856Z"},"trusted":true},"execution_count":null,"outputs":[]}]}