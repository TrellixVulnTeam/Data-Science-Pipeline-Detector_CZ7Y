{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir('../input/petfinder-pawpularity-score'))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-02T02:15:50.673023Z","iopub.execute_input":"2022-01-02T02:15:50.673458Z","iopub.status.idle":"2022-01-02T02:15:50.771191Z","shell.execute_reply.started":"2022-01-02T02:15:50.673368Z","shell.execute_reply":"2022-01-02T02:15:50.770399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make sure you have keras trained weights downloaded in input directory using https://www.kaggle.com/antoreepjana/tf-keras-pretrained-model-weights .This will be useful as we are not supposed to use internet while running inference ","metadata":{}},{"cell_type":"code","source":"rootDir = \"../input/petfinder-pawpularity-score/\"\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:01.65251Z","iopub.execute_input":"2022-01-02T02:16:01.653229Z","iopub.status.idle":"2022-01-02T02:16:01.657335Z","shell.execute_reply.started":"2022-01-02T02:16:01.653191Z","shell.execute_reply":"2022-01-02T02:16:01.656575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom PIL import Image\nimport cv2\nimport matplotlib.pyplot as plt \nfrom os.path import basename\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:02.41352Z","iopub.execute_input":"2022-01-02T02:16:02.414408Z","iopub.status.idle":"2022-01-02T02:16:06.764447Z","shell.execute_reply.started":"2022-01-02T02:16:02.414369Z","shell.execute_reply":"2022-01-02T02:16:06.763515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainf = pd.read_csv(rootDir + \"train.csv\")\ntestf = pd.read_csv(rootDir + \"test.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:06.768981Z","iopub.execute_input":"2022-01-02T02:16:06.770782Z","iopub.status.idle":"2022-01-02T02:16:06.81679Z","shell.execute_reply.started":"2022-01-02T02:16:06.770745Z","shell.execute_reply":"2022-01-02T02:16:06.816158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainf['imagename'] = trainf['Id'].apply(lambda x : str(x) + \".jpg\")\ntestf['imagename'] = testf['Id'].apply(lambda x : str(x) + \".jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:06.817762Z","iopub.execute_input":"2022-01-02T02:16:06.817987Z","iopub.status.idle":"2022-01-02T02:16:06.83537Z","shell.execute_reply.started":"2022-01-02T02:16:06.817956Z","shell.execute_reply":"2022-01-02T02:16:06.834799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 10\nimgpath = rootDir + \"train/\" + os.listdir(rootDir + \"train/\")[i]\nimgname = basename(imgpath)\nprint(f\"image name is {imgname}\")\npscore = trainf[trainf['imagename']== imgname]['Pawpularity'].unique()[0]\nprint(f\"popularity score is {pscore}\")\nimg = Image.open(imgpath)\nimg","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:06.837106Z","iopub.execute_input":"2022-01-02T02:16:06.837284Z","iopub.status.idle":"2022-01-02T02:16:07.390015Z","shell.execute_reply.started":"2022-01-02T02:16:06.837263Z","shell.execute_reply":"2022-01-02T02:16:07.389227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainf[trainf['imagename']== imgname]","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:07.391084Z","iopub.execute_input":"2022-01-02T02:16:07.391305Z","iopub.status.idle":"2022-01-02T02:16:07.4153Z","shell.execute_reply.started":"2022-01-02T02:16:07.391279Z","shell.execute_reply":"2022-01-02T02:16:07.414626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Base CNN model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image \nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,BatchNormalization,GlobalAveragePooling2D,Flatten,Dropout\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.applications import VGG16,ResNet152\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:07.416633Z","iopub.execute_input":"2022-01-02T02:16:07.417007Z","iopub.status.idle":"2022-01-02T02:16:07.945455Z","shell.execute_reply.started":"2022-01-02T02:16:07.416975Z","shell.execute_reply":"2022-01-02T02:16:07.944758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df,valid_df = train_test_split(trainf,test_size = 0.2,random_state  = 1)\ntrain_df = train_df.reset_index(drop = True)\nvalid_df = valid_df.reset_index(drop = True)\nprint(train_df.shape,valid_df.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:07.946786Z","iopub.execute_input":"2022-01-02T02:16:07.947033Z","iopub.status.idle":"2022-01-02T02:16:07.960127Z","shell.execute_reply.started":"2022-01-02T02:16:07.947002Z","shell.execute_reply":"2022-01-02T02:16:07.959283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:07.961376Z","iopub.execute_input":"2022-01-02T02:16:07.961783Z","iopub.status.idle":"2022-01-02T02:16:07.976827Z","shell.execute_reply.started":"2022-01-02T02:16:07.961749Z","shell.execute_reply":"2022-01-02T02:16:07.976128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:07.978321Z","iopub.execute_input":"2022-01-02T02:16:07.978944Z","iopub.status.idle":"2022-01-02T02:16:07.985926Z","shell.execute_reply.started":"2022-01-02T02:16:07.978908Z","shell.execute_reply":"2022-01-02T02:16:07.985094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Below written code can be used to utilize default keras Imagegenerator class but we can't add tabular features in it hence we would be writing a custome class. Also the following model is a vgg16 based transfer learning model","metadata":{}},{"cell_type":"code","source":"# def transferlearn_model():\n#     imgsize = 224 ## using vgg \n#     vgg_model_wtl = VGG16(weights = \"imagenet\",input_shape = (imgsize,imgsize,3), include_top = False ) \n#     layername = \"block3_conv3\"\n#     mymodel = Model(inputs = vgg_model_wtl.input,outputs = vgg_model_wtl.get_layer(layername).output)\n#     newmodel1 = Sequential()\n#     newmodel1.add(mymodel)\n\n#     newmodel1.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n#     newmodel1.add(MaxPooling2D((2,2),padding='same'))\n\n#     newmodel1.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n#     newmodel1.add(MaxPooling2D((2,2),padding='same'))\n\n\n#     newmodel1.add(Conv2D(256,(3,3),activation='relu',padding='same'))\n#     newmodel1.add(MaxPooling2D((2,2),padding='same'))\n\n#     newmodel1.add(GlobalAveragePooling2D())\n#     newmodel1.add(Dense(64,activation='relu'))\n#     newmodel1.add(BatchNormalization())\n\n#     newmodel1.add(Dense(1,activation='linear'))\n\n#     newmodel1.layers[0].trainable=False\n    \n#     newmodel1.compile(loss='mean_squared_error', optimizer='adam',\n#                   metrics=['mse'])\n#     return newmodel1\n    \n# model2train = transferlearn_model()\n\n# ### train and valid\n# train_datagen = ImageDataGenerator(\n#         rescale=1./255,\n#         shear_range=0.2,\n#         zoom_range=0.2,\n#         horizontal_flip=True)\n\n# train_generator = train_datagen.flow_from_dataframe(\n#         dataframe=train_df,\n#         directory=rootDir + \"train/\",\n#         x_col=\"imagename\",\n#         y_col='Pawpularity', ## need not one hot encode \n#         target_size=(224, 224),\n#         batch_size=32,\n#         class_mode='raw')\n\n# valid_datagen = ImageDataGenerator(rescale=1./255)\n\n\n# validation_generator = valid_datagen.flow_from_dataframe(\n#         dataframe=valid_df,\n#         directory=rootDir + \"train/\",\n#         x_col=\"imagename\",\n#         y_col='Pawpularity',\n#         target_size=(224, 224),\n#         batch_size=32,\n#         class_mode='raw')\n\n\n# ES_PATIENCE = 10\n# RLROP_PATIENCE = 3\n# DECAY_DROP = 0.4\n\n# es = EarlyStopping(monitor='val_loss', mode='min', \n#                    patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n# rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', \n#                           patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n\n# callback_list = [es,rlrop]\n\n# RunRes = model2train.fit_generator(generator=train_generator,\n#                     validation_data=validation_generator,epochs = 5,callbacks=callback_list)\n\n# RunRes.history.keys()\n# fig,axes = plt.subplots(2,2,figsize = (8,8))\n# axes[0,0].plot(RunRes.history['loss'])\n# axes[0,1].plot(RunRes.history['val_loss'])\n# axes[1,0].plot(RunRes.history['mse'])\n# axes[1,1].plot(RunRes.history['val_mse'])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:07.988407Z","iopub.execute_input":"2022-01-02T02:16:07.988702Z","iopub.status.idle":"2022-01-02T02:16:07.995503Z","shell.execute_reply.started":"2022-01-02T02:16:07.988668Z","shell.execute_reply":"2022-01-02T02:16:07.994802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom class to add Image features","metadata":{}},{"cell_type":"code","source":"class customImageGen(tf.keras.utils.Sequence):\n    def __init__(self,imgdir,_dataF,X_col,otherfeats,target,batch_size = 32,dim = (256,256,3),shuffle = True,n_channels = 1,n_classes = 1,flag = \"train\"):\n        self.imgdir  = imgdir \n        self._dataF = _dataF \n        self.target = target\n        self.dim = dim \n        self.shuffle = shuffle \n        self.X_col = X_col\n        self.otherfeats = otherfeats\n        self.n_channels = n_channels\n        self.batch_size = batch_size \n        self.indexes = self._dataF.index\n        self.n_classes = n_classes\n        self.flag = flag\n        \n        \n    def augmen(self,samples):\n        if self.flag == \"train\":\n            datagentrain = ImageDataGenerator(rescale=1. / 255.0,\n                                  horizontal_flip = True,\n                                  vertical_flip = False, \n                                  height_shift_range= 0.1, \n                                  width_shift_range=0.1, \n                                  rotation_range=20, \n                                  shear_range = 0.1,\n                                  zoom_range=0.1)\n\n            it = datagentrain.flow(samples, batch_size=1)\n        elif self.flag == \"val\":\n            datagenval = ImageDataGenerator(rescale=1. / 255.0)\n\n            it = datagenval.flow(samples, batch_size=1)\n        return it.next() \n    \n    def __len__(self):\n        'Denotes number of batches per epoch'\n        return int(np.floor(len(self.indexes)/ self.batch_size))\n    def __getitem__(self,index):\n        \"Generate one batch of data\"\n        indexes = self.indexes[index*self.batch_size:(index + 1)*self.batch_size]\n        \n        ## find List of ids \n        list_IDs_temp = [self.indexes[k] for k in indexes]\n        x,otherfeats,y = self.__data__generation(list_IDs_temp)\n        \n        return [x,otherfeats],y\n    \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.indexes))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data__generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim))\n        y = np.empty((self.batch_size,self.n_classes), dtype=int)\n        otherfeats = np.empty((self.batch_size,len(self.otherfeats)), dtype=int)\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            #img=cv2.imread(train_data_dir + ID)\n            img_initial = image.load_img(self.imgdir + self._dataF.loc[ID][self.X_col])\n            img = img_initial.resize((self.dim[:-1]))\n            img_array = image.img_to_array(img)\n            \n            samples = np.expand_dims(img_array, 0)\n            \n            aug_samples = self.augmen(samples)\n\n            \n            X[i,] = aug_samples\n\n            # Store class\n            y[i] = self._dataF.loc[ID][self.target] #self.labels[ID]  #y[i]\n            \n            otherfeats[i] = self._dataF[self.otherfeats].iloc[ID].values\n            \n            \n            \n#         print(f\"X shape is {X.shape} and otherf shape is {otherfeats.shape}\")\n\n        return X,otherfeats,y\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:07.998508Z","iopub.execute_input":"2022-01-02T02:16:07.998747Z","iopub.status.idle":"2022-01-02T02:16:08.019659Z","shell.execute_reply.started":"2022-01-02T02:16:07.998716Z","shell.execute_reply":"2022-01-02T02:16:08.018939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Additional features\notherfeats = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:08.021048Z","iopub.execute_input":"2022-01-02T02:16:08.021361Z","iopub.status.idle":"2022-01-02T02:16:08.030863Z","shell.execute_reply.started":"2022-01-02T02:16:08.021328Z","shell.execute_reply":"2022-01-02T02:16:08.03019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgg = customImageGen(rootDir + \"train/\",train_df,'imagename',otherfeats,\"Pawpularity\",batch_size = 1,dim = (256,256,3),shuffle = True,n_channels = 3,flag = 'train')","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:08.033507Z","iopub.execute_input":"2022-01-02T02:16:08.033793Z","iopub.status.idle":"2022-01-02T02:16:08.039888Z","shell.execute_reply.started":"2022-01-02T02:16:08.033762Z","shell.execute_reply":"2022-01-02T02:16:08.039104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgg.__getitem__(0)[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:08.040961Z","iopub.execute_input":"2022-01-02T02:16:08.041384Z","iopub.status.idle":"2022-01-02T02:16:08.093252Z","shell.execute_reply.started":"2022-01-02T02:16:08.04135Z","shell.execute_reply":"2022-01-02T02:16:08.092508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check if it is working fine","metadata":{}},{"cell_type":"code","source":"plt.imshow(imgg.__getitem__(0)[0][0][0])\n\nprint(imgg.__getitem__(0)[0][1],imgg.__getitem__(0)[1])","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:08.36324Z","iopub.execute_input":"2022-01-02T02:16:08.363497Z","iopub.status.idle":"2022-01-02T02:16:08.699034Z","shell.execute_reply.started":"2022-01-02T02:16:08.36347Z","shell.execute_reply":"2022-01-02T02:16:08.696114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:08.7053Z","iopub.execute_input":"2022-01-02T02:16:08.705505Z","iopub.status.idle":"2022-01-02T02:16:08.708933Z","shell.execute_reply.started":"2022-01-02T02:16:08.705482Z","shell.execute_reply":"2022-01-02T02:16:08.708293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train and validation generator","metadata":{}},{"cell_type":"code","source":"trainGen = customImageGen(rootDir + \"train/\",train_df,'imagename',otherfeats,\"Pawpularity\",batch_size = batch_size,dim = \\\n                          (256,256,3),shuffle = True,n_channels = 3,flag = 'train')\nvalGen = customImageGen(rootDir + \"train/\",valid_df,'imagename',otherfeats,\"Pawpularity\",batch_size = batch_size,dim = \\\n                        (256,256,3),shuffle = True,n_channels = 3,flag = 'val')","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:09.187974Z","iopub.execute_input":"2022-01-02T02:16:09.189801Z","iopub.status.idle":"2022-01-02T02:16:09.195952Z","shell.execute_reply.started":"2022-01-02T02:16:09.189747Z","shell.execute_reply":"2022-01-02T02:16:09.194858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valGen.indexes.shape +trainGen.indexes.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:09.699991Z","iopub.execute_input":"2022-01-02T02:16:09.700781Z","iopub.status.idle":"2022-01-02T02:16:09.708922Z","shell.execute_reply.started":"2022-01-02T02:16:09.700744Z","shell.execute_reply":"2022-01-02T02:16:09.70808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# valGen.__getitem__(1)[0][0].shape,valGen.__getitem__(1)[0][1].shape\n\nfrom numpy.random import seed\nseed(1)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:16:10.045145Z","iopub.execute_input":"2022-01-02T02:16:10.045709Z","iopub.status.idle":"2022-01-02T02:16:10.049888Z","shell.execute_reply.started":"2022-01-02T02:16:10.045674Z","shell.execute_reply":"2022-01-02T02:16:10.048706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### custom model to utlize both CNN and ANN","metadata":{}},{"cell_type":"code","source":"input_feat_tensor = tf.keras.Input(shape=len(otherfeats),name='feat_input')\n# imgsize = 224\nimport tensorflow.keras.backend as K\n\ndef root_mean_squared_error(y_true, y_pred):\n    y_true = float(y_true)\n    return K.sqrt(K.mean(K.square(y_pred - y_true))) \n### CNN model for images\nimgsize = 128\ndef cnnmod():\n    # Create base model\n    #base_model =VGG16(weights = \"imagenet\",input_shape = (imgsize,imgsize,3), include_top = False ) \n    base_model = ResNet152(weights='../input/tf-keras-pretrained-model-weights/No Top/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False,input_tensor=keras.Input(shape=(imgsize,imgsize,3)))\n    # Freeze base model\n    base_model.trainable = False\n    # Create new model on top.\n    inputs = keras.Input(shape=(imgsize, imgsize, 3))\n    x = base_model(inputs, training=False)\n#     x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n#     x = MaxPooling2D((2,2),padding='same')(x)\n#     x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n#     x = MaxPooling2D((2,2),padding='same')(x)\n#     x = Conv2D(256,(3,3),activation='relu',padding='same')(x)\n#     x = MaxPooling2D((2,2),padding='same')(x)\n#     x = GlobalAveragePooling2D()(x)\n#     x = Dense(64,activation='relu')(x)\n#     x = BatchNormalization()(x)\n#     x = keras.layers.GlobalAveragePooling2D()(x)\n    x = Dense(2048,activation = 'relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1000, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    #x = Dense(600, activation='relu')(x)\n    #x = Dropout(0.5)(x)\n    x = Dense(300, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    \n    x = GlobalAveragePooling2D()(x)\n#     x = MaxPooling2D()(x)\n#     x = Flatten()(x)\n    x = Dense(500,activation='relu', name='final_outputcnn')(x)\n#     final_output = Dense(50, activation='relu', name='final_output')(x)\n#     outputs = Dense(8,activation='relu',name= \"lastcnnlayer\")(x)\n    model = tf.keras.Model(inputs, x)\n    return model\ncreatecnn = cnnmod()\n\n######## MLP model for tabular featues\ndef annmodel():\n    input_feat_tensor = tf.keras.Input(shape=len(otherfeats),name='feat_input')\n    x = Dense(8,activation = 'relu',kernel_initializer=tf.keras.initializers.HeNormal())(input_feat_tensor)\n    x = Dropout(0.5)(x)\n    #x = Dense(6,activation = 'relu',kernel_initializer=tf.keras.initializers.HeNormal())(input_feat_tensor)\n    #x = Dropout(0.5)(x)\n    model = tf.keras.Model(input_feat_tensor,x)\n    return model\ncreateann = annmodel()\n# conlayer = tf.keras.layers.Concatenate(axis=1)([createcnn.output,otherfeatsar ])\n# conlayer = tf.keras.layers.concatenate([createcnn.output, input_feat_tensor])\nconlayer = tf.keras.layers.concatenate([createcnn.output, createann.output])\nconlayer = BatchNormalization(name = \"conclayernorm\")(conlayer)\nconlayer = Dense(200,name = \"nonlinint\",activation = 'relu')(conlayer)\nconlayer = Dropout(0.5)(conlayer)\nconlayer = Dense(100,name = \"nonlinint2\",activation = 'relu')(conlayer)\nconlayer = Dropout(0.5)(conlayer)\nz  = Dense(1,activation='linear', name='final_output')(conlayer)\n# finalmod = Model(inputs = [createcnn.input,keras.layers.Input(shape=(12,))],outputs = z )\n# finalmod = Model(inputs = [createcnn.input,input_feat_tensor],outputs = z )\nfinalmod = Model(inputs = [createcnn.input,createann.input],outputs = z )\nfinalmod.compile(loss=[root_mean_squared_error], optimizer='adam',metrics=['mse']) ## custom rmse loss\n    \n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:26:32.954771Z","iopub.execute_input":"2022-01-02T02:26:32.955342Z","iopub.status.idle":"2022-01-02T02:26:41.632201Z","shell.execute_reply.started":"2022-01-02T02:26:32.955306Z","shell.execute_reply":"2022-01-02T02:26:41.631489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalmod.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:26:41.633767Z","iopub.execute_input":"2022-01-02T02:26:41.634003Z","iopub.status.idle":"2022-01-02T02:26:41.67675Z","shell.execute_reply.started":"2022-01-02T02:26:41.633968Z","shell.execute_reply":"2022-01-02T02:26:41.676082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"createcnn.output,createann.output,createcnn.input,createann.input","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:26:41.677878Z","iopub.execute_input":"2022-01-02T02:26:41.678183Z","iopub.status.idle":"2022-01-02T02:26:41.687037Z","shell.execute_reply.started":"2022-01-02T02:26:41.678149Z","shell.execute_reply":"2022-01-02T02:26:41.686166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### training model and saving weights. I am using few callbacks \n* Early stopping : To stop training if there is no decrease in validation loss after 8 epochs \n* Reduce learning rate on plateau : To decrease LR as training curve hits a plateau\n* Model checkpoint : To save model weights","metadata":{}},{"cell_type":"code","source":"import datetime ,re\ndef cleaner(x):\n    x = re.sub(\"[^0-9]\",\"_\",x)\n    return x\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:27:04.70585Z","iopub.execute_input":"2022-01-02T02:27:04.706388Z","iopub.status.idle":"2022-01-02T02:27:04.710737Z","shell.execute_reply.started":"2022-01-02T02:27:04.70635Z","shell.execute_reply":"2022-01-02T02:27:04.709672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt2attch = cleaner(str(datetime.datetime.now()))\nfilepath=\"./pawweights.best_{epoch:02d}-{val_loss:.2f}\" + \"_\" + dt2attch +\".hdf5\"\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', \n                             verbose=1, save_best_only=True, mode='auto')\n\nES_PATIENCE = 10\nRLROP_PATIENCE = 5\nDECAY_DROP = 0.3\nes = EarlyStopping(monitor='val_loss', mode='min', \n                   patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\nrlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', \n                          patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n\ncallback_list = [checkpoint,es,rlrop]","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:27:05.542919Z","iopub.execute_input":"2022-01-02T02:27:05.543178Z","iopub.status.idle":"2022-01-02T02:27:05.549932Z","shell.execute_reply.started":"2022-01-02T02:27:05.543149Z","shell.execute_reply":"2022-01-02T02:27:05.54924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valGen.indexes.shape[0],trainGen.indexes.shape[0],valGen.indexes.shape[0]//batch_size,trainGen.indexes.shape[0]//batch_size\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:27:06.438769Z","iopub.execute_input":"2022-01-02T02:27:06.439359Z","iopub.status.idle":"2022-01-02T02:27:06.445882Z","shell.execute_reply.started":"2022-01-02T02:27:06.439325Z","shell.execute_reply":"2022-01-02T02:27:06.445131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RunRes = finalmod.fit_generator(trainGen,steps_per_epoch=trainGen.indexes.shape[0]//batch_size,validation_data=valGen,\n                                validation_steps=valGen.indexes.shape[0]//batch_size,\n                                epochs = 50,callbacks=callback_list,verbose=1)\nprint(RunRes.history.keys())\nfig,axes = plt.subplots(2,2,figsize = (8,8))\naxes[0,0].plot(RunRes.history['loss'])\naxes[0,1].plot(RunRes.history['val_loss'])\naxes[1,0].plot(RunRes.history['mse'])\naxes[1,1].plot(RunRes.history['val_mse'])\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T02:27:06.834437Z","iopub.execute_input":"2022-01-02T02:27:06.834742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}