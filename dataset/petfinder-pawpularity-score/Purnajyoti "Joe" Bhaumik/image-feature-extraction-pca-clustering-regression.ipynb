{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#adapted from https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras as keras","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-14T16:39:44.273893Z","iopub.execute_input":"2022-01-14T16:39:44.274254Z","iopub.status.idle":"2022-01-14T16:39:48.525101Z","shell.execute_reply.started":"2022-01-14T16:39:44.274165Z","shell.execute_reply":"2022-01-14T16:39:48.524378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for loading/processing the images  \n\nfrom keras.preprocessing.image import load_img \nfrom keras.preprocessing.image import img_to_array \nfrom keras.applications.vgg16 import preprocess_input \n\n# models \nfrom keras.applications.vgg16 import VGG16 \nfrom keras.models import Model\n\n# clustering and dimension reduction\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AffinityPropagation\nfrom sklearn.decomposition import PCA\n\n# for everything else\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\nimport pandas as pd\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:39:48.529045Z","iopub.execute_input":"2022-01-14T16:39:48.529258Z","iopub.status.idle":"2022-01-14T16:39:49.975969Z","shell.execute_reply.started":"2022-01-14T16:39:48.529232Z","shell.execute_reply":"2022-01-14T16:39:49.9752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n# this list holds all the image filename\npets = []\n\nscores = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\nscores = scores[['Id','Pawpularity']]\n\nfor dirname, _, filenames in os.walk('/kaggle/input/petfinder-pawpularity-score/train'):\n    for i ,filename in enumerate(filenames):\n        pets.append(dirname+'/'+filename)\n\nprint(pets[:10])","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:39:49.977424Z","iopub.execute_input":"2022-01-14T16:39:49.977796Z","iopub.status.idle":"2022-01-14T16:39:52.401103Z","shell.execute_reply.started":"2022-01-14T16:39:49.97776Z","shell.execute_reply":"2022-01-14T16:39:52.400298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the image as a 224x224 array\nimg = load_img(pets[0], target_size=(224,224))\n# convert from 'PIL.Image.Image' to numpy array\nimg = np.array(img)\n\nprint(img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:39:52.403177Z","iopub.execute_input":"2022-01-14T16:39:52.403454Z","iopub.status.idle":"2022-01-14T16:39:52.437354Z","shell.execute_reply.started":"2022-01-14T16:39:52.403418Z","shell.execute_reply":"2022-01-14T16:39:52.436546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reshaped_img = img.reshape(1,224,224,3)\nprint(reshaped_img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:39:52.438784Z","iopub.execute_input":"2022-01-14T16:39:52.439027Z","iopub.status.idle":"2022-01-14T16:39:52.445088Z","shell.execute_reply.started":"2022-01-14T16:39:52.438994Z","shell.execute_reply":"2022-01-14T16:39:52.444295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = preprocess_input(reshaped_img)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:39:52.446466Z","iopub.execute_input":"2022-01-14T16:39:52.446709Z","iopub.status.idle":"2022-01-14T16:39:52.454397Z","shell.execute_reply.started":"2022-01-14T16:39:52.446676Z","shell.execute_reply":"2022-01-14T16:39:52.453691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:39:52.457213Z","iopub.execute_input":"2022-01-14T16:39:52.457791Z","iopub.status.idle":"2022-01-14T16:39:54.434185Z","shell.execute_reply.started":"2022-01-14T16:39:52.457758Z","shell.execute_reply":"2022-01-14T16:39:54.433477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:39:54.435518Z","iopub.execute_input":"2022-01-14T16:39:54.43595Z","iopub.status.idle":"2022-01-14T16:39:54.450301Z","shell.execute_reply.started":"2022-01-14T16:39:54.43591Z","shell.execute_reply":"2022-01-14T16:39:54.448901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nmodel = VGG16()\n# remove the output layer\nmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\nmodel.save('feature_extractor')","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:39:54.452174Z","iopub.execute_input":"2022-01-14T16:39:54.452789Z","iopub.status.idle":"2022-01-14T16:40:02.31177Z","shell.execute_reply.started":"2022-01-14T16:39:54.452754Z","shell.execute_reply":"2022-01-14T16:40:02.311041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/GPU:0'):\n    features = model.predict(reshaped_img)\nprint(features.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:40:02.314857Z","iopub.execute_input":"2022-01-14T16:40:02.315175Z","iopub.status.idle":"2022-01-14T16:40:08.896878Z","shell.execute_reply.started":"2022-01-14T16:40:02.315136Z","shell.execute_reply":"2022-01-14T16:40:08.895919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(file, model):\n    # load the image as a 224x224 array\n    img = load_img(file, target_size=(224,224))\n    # convert from 'PIL.Image.Image' to numpy array\n    img = np.array(img) \n    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n    reshaped_img = img.reshape(1,224,224,3) \n    # prepare image for model\n    imgx = preprocess_input(reshaped_img)\n    # get the feature vector\n    features = model.predict(imgx, use_multiprocessing=True)\n    return features","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:40:08.898468Z","iopub.execute_input":"2022-01-14T16:40:08.898733Z","iopub.status.idle":"2022-01-14T16:40:08.904484Z","shell.execute_reply.started":"2022-01-14T16:40:08.898695Z","shell.execute_reply":"2022-01-14T16:40:08.903709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {}\np = '/kaggle/working/pet_features.pkl'\n\n# lop through each image in the dataset\nfor pet in pets:\n    # try to extract the features and update the dictionary\n    try:\n        with tf.device('/GPU:0'):\n            feat = extract_features(pet,model)\n        data[pet] = feat\n    # if something fails, save the extracted features as a pickle file (optional)\n    except:\n        with open(p,'wb') as file:\n            pickle.dump(data,file)\n          \n \n# get a list of the filenames\nfilenames = np.array(list(data.keys()))\n\n# get a list of just the features\nfeat = np.array(list(data.values()))\nfeat.shape\n\nfeat = feat.reshape(-1,4096)\nprint(feat.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:40:08.905794Z","iopub.execute_input":"2022-01-14T16:40:08.906245Z","iopub.status.idle":"2022-01-14T16:50:23.170662Z","shell.execute_reply.started":"2022-01-14T16:40:08.906182Z","shell.execute_reply":"2022-01-14T16:50:23.169851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components=100, random_state=22)\npca.fit(feat)\npickle.dump(pca,  open('pca.pkl', 'wb'))\nx = pca.transform(feat)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:50:23.172054Z","iopub.execute_input":"2022-01-14T16:50:23.172484Z","iopub.status.idle":"2022-01-14T16:50:25.532716Z","shell.execute_reply.started":"2022-01-14T16:50:23.172445Z","shell.execute_reply":"2022-01-14T16:50:25.531777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sse = []\nlist_k = list(range(3, 50))\n\nfor k in list_k:\n    km = KMeans(n_clusters=k, random_state=22, n_jobs=-1)\n    km.fit(x)\n    \n    sse.append(km.inertia_)\n\n# Plot sse against k\nplt.figure(figsize=(6, 6))\nplt.plot(list_k, sse)\nplt.xlabel(r'Number of clusters *k*')\nplt.ylabel('Sum of squared distance')","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:50:25.541193Z","iopub.execute_input":"2022-01-14T16:50:25.548397Z","iopub.status.idle":"2022-01-14T16:54:55.6429Z","shell.execute_reply.started":"2022-01-14T16:50:25.548347Z","shell.execute_reply":"2022-01-14T16:54:55.642082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#select 20 for number of clusters based on inflection point above\n\nkmeans = KMeans(n_clusters=20,n_jobs=-1, random_state=22)\nkmeans.fit(x)\n\n# af = AffinityPropagation(random_state=5).fit(x)... produces clusters too small for regression step\nos.chdir('/kaggle/working')\nimport pickle\npickle.dump(kmeans,  open('clustering_model.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:54:55.64409Z","iopub.execute_input":"2022-01-14T16:54:55.644352Z","iopub.status.idle":"2022-01-14T16:55:00.363383Z","shell.execute_reply.started":"2022-01-14T16:54:55.644317Z","shell.execute_reply":"2022-01-14T16:55:00.362632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# holds the cluster id and the images { id: [images] }\nimport re\n\ngroups = {}\nfeature_map = dict(zip(filenames, x))\nfeatures = {}\nscore = {} \n\n\nfor file, cluster in zip(filenames,kmeans.labels_):\n    if cluster not in groups.keys():\n        groups[cluster] = []\n        groups[cluster].append(file)\n        features[cluster] = []\n        features[cluster].append(feature_map[file])\n        score[cluster] = []\n        m = re.search('[a-zA-Z0-9]+(?=\\.)', file)\n        score[cluster].append(scores[scores['Id']==m.group(0)]['Pawpularity'].item())\n    else:\n        groups[cluster].append(file)\n        features[cluster].append(feature_map[file])\n        m = re.search('[a-zA-Z0-9]+(?=\\.)', file)\n        score[cluster].append(scores[scores['Id']==m.group(0)]['Pawpularity'].item())\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:55:44.622766Z","iopub.execute_input":"2022-01-14T16:55:44.623057Z","iopub.status.idle":"2022-01-14T16:56:03.216774Z","shell.execute_reply.started":"2022-01-14T16:55:44.623026Z","shell.execute_reply":"2022-01-14T16:56:03.216064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function that lets you view a cluster (based on identifier)        \ndef view_cluster(cluster):\n    plt.figure(figsize = (25,25));\n    # gets the list of filenames for a cluster\n    files = groups[cluster]\n    # only allow up to 30 images to be shown at a time\n    if len(files) > 30:\n        print(f\"Clipping cluster size from {len(files)} to 30\")\n        files = files[:29]\n    # plot each image in the cluster\n    for index, file in enumerate(files):\n        plt.subplot(10,10,index+1);\n        img = load_img(file)\n        img = np.array(img)\n        plt.title('Cluster Number: {}'.format(cluster))\n        plt.imshow(img)\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:56:51.646378Z","iopub.execute_input":"2022-01-14T16:56:51.646905Z","iopub.status.idle":"2022-01-14T16:56:51.653711Z","shell.execute_reply.started":"2022-01-14T16:56:51.646869Z","shell.execute_reply":"2022-01-14T16:56:51.652982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for cluster in (groups.keys()):\n#     view_cluster(cluster)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:55:00.726181Z","iopub.status.idle":"2022-01-14T16:55:00.731513Z","shell.execute_reply.started":"2022-01-14T16:55:00.731273Z","shell.execute_reply":"2022-01-14T16:55:00.731299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install pycaret\n\n# # params = {\"max_depth\": np.random.randint(1, (len(data.columns)*.85),20),\n# #           \"max_features\": np.random.randint(1, len(data.columns),20),\n# #           \"min_samples_leaf\": [2,3,4,5,6],\n# #           \"criterion\": [\"gini\", \"entropy\"]\n# #           }\n\n# from pycaret.regression import *\n# for cluster in (groups.keys()):\n#     a = np.stack(features[cluster], axis = 0)\n#     df = pd.DataFrame(a)\n#     df['score'] = pd.DataFrame(score[cluster])\n#     exp_name = setup(data = df,  target = 'score', use_gpu = True, silent = True)\n#     best = compare_models(exclude = ['catboost'], sort = 'RMSE')\n# #     tuned_top3 = [tune_model(i, optimize ='RMSE', n_iter = 50, custom_grid = params) for i in best]\n#     #stacked = stack_models(best)\n#     # stacker = stack_models(tuned_top3)\n#     # best_rmse_model = automl()\n#     #boosted_best = ensemble_model(best, method = 'Boosting')\n#     save_model(best, 'saved_lr_model_'+str(cluster))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T16:55:00.732334Z","iopub.status.idle":"2022-01-14T16:55:00.733882Z","shell.execute_reply.started":"2022-01-14T16:55:00.733692Z","shell.execute_reply":"2022-01-14T16:55:00.733713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\n\nfor cluster in (groups.keys()):\n    a = np.stack(features[cluster], axis = 0)\n    X = pd.DataFrame(a).values\n    y = pd.DataFrame(score[cluster]).values\n    y = np.reshape(y,(y.shape[0]))\n    ada = AdaBoostRegressor()\n    ada.fit(X, y)\n    pickle.dump(ada,  open('trained_lr_'+str(cluster)+'.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T17:10:12.254672Z","iopub.execute_input":"2022-01-14T17:10:12.254917Z","iopub.status.idle":"2022-01-14T17:10:12.486463Z","shell.execute_reply.started":"2022-01-14T17:10:12.254888Z","shell.execute_reply":"2022-01-14T17:10:12.485769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}