{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import f1_score, roc_curve, auc, mean_squared_error\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV\n\n%matplotlib inline\nmatplotlib.rcParams['figure.figsize'] = (8, 8)\nsns.set_style('whitegrid')\n\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB2\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import StratifiedKFold, KFold","metadata":{"papermill":{"duration":7.019129,"end_time":"2021-12-04T11:38:30.453939","exception":false,"start_time":"2021-12-04T11:38:23.43481","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-05T06:07:10.612995Z","iopub.execute_input":"2021-12-05T06:07:10.613294Z","iopub.status.idle":"2021-12-05T06:07:18.135751Z","shell.execute_reply.started":"2021-12-05T06:07:10.61322Z","shell.execute_reply":"2021-12-05T06:07:18.134927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Источник:\n# https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/image_classification_efficientnet_fine_tuning.ipynb","metadata":{"papermill":{"duration":0.015933,"end_time":"2021-12-04T11:38:30.481705","exception":false,"start_time":"2021-12-04T11:38:30.465772","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 224\nbatch_size = 128\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    print(\"Device:\", tpu.master())\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError:\n    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n    strategy = tf.distribute.MirroredStrategy()\n\n\n# train = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntest = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n# sample_submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\n# train[\"file_path\"] = train[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/train/\" + identifier + \".jpg\")\ntest[\"file_path\"] = test[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/test/\" + identifier + \".jpg\")\ntest.head()","metadata":{"papermill":{"duration":0.095224,"end_time":"2021-12-04T11:38:30.586724","exception":false,"start_time":"2021-12-04T11:38:30.4915","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-05T06:07:18.136871Z","iopub.execute_input":"2021-12-05T06:07:18.137027Z","iopub.status.idle":"2021-12-05T06:07:18.215041Z","shell.execute_reply.started":"2021-12-05T06:07:18.137007Z","shell.execute_reply":"2021-12-05T06:07:18.214587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\n\nimg_augmentation = Sequential(\n    [\n        layers.RandomRotation(factor=0.15),\n        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomFlip(),\n        layers.RandomContrast(factor=0.1),\n    ],\n    name=\"img_augmentation\",\n)\n\nfrom tensorflow.keras.applications import EfficientNetB0","metadata":{"papermill":{"duration":0.055423,"end_time":"2021-12-04T11:38:30.711121","exception":false,"start_time":"2021-12-04T11:38:30.655698","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-05T06:07:18.369155Z","iopub.execute_input":"2021-12-05T06:07:18.369909Z","iopub.status.idle":"2021-12-05T06:07:18.408538Z","shell.execute_reply.started":"2021-12-05T06:07:18.369869Z","shell.execute_reply":"2021-12-05T06:07:18.40788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tabular_columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n\ndef rmse(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    return tf.sqrt(tf.reduce_mean((y_true -  y_pred) ** 2))\n\ndef get_tabular_prediciton_model(inputs):\n    width = 32\n    depth = 3\n    activation = \"relu\"\n    kernel_regularizer = keras.regularizers.l2()\n    x = keras.layers.Dense(\n            width, \n            activation=activation,\n            kernel_regularizer=kernel_regularizer\n        )(inputs)\n    for i in range(depth):\n        if i == 0:\n            x = inputs\n        x = keras.layers.Dense(\n            width, \n            activation=activation,\n            kernel_regularizer=kernel_regularizer\n        )(x)\n        if (i + 1) % 3 == 0:\n            x = keras.layers.Concatenate()([x, inputs])\n    return x\n\n\ndef get_model():\n    image_inputs = layers.Input(shape=(image_size, image_size, 3))\n    image_x = img_augmentation(image_inputs)\n    model = EfficientNetB0(include_top=False, \n                           input_tensor=image_x, \n                           weights=\"../input/b0-weights/efficientnetb0_notop.h5\", \n                           input_shape = (image_size, image_size, 3))\n    # Freeze the pretrained weights\n    model.trainable = False\n    # Rebuild top\n    image_x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n    top_dropout_rate = 0.2\n    image_x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(image_x)\n    \n    tabular_inputs = tf.keras.Input(len(tabular_columns))\n    tabular_x = get_tabular_prediciton_model(tabular_inputs)\n    \n    x = tf.keras.layers.Concatenate(axis=1)([image_x, tabular_x])\n    outputs = layers.Dense(1)(x)\n\n    optimizer = tf.keras.optimizers.Adam(1e-3)\n    model = tf.keras.Model(inputs=[image_inputs, tabular_inputs], outputs=[outputs], name=\"EfficientNet\")\n    model.compile(\n        optimizer=optimizer, loss=rmse, metrics=[\"mae\", \"mape\"]\n    )\n    return model\n\n    \ndef preprocess_test_data(image_url, tabular):\n    print(image_url)\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    # 0 won't be used in prediction, but it's needed in this senario or the tabular variable is treated as label.\n    return (image, tabular), 0\n\n\nmodel_up = get_model()\nmodel_up.load_weights(\"../input/b0-weights/pet_trained_weights_v6.h5\")\n# model_up = tf.keras.models.load_model('../input/b0-weights/pet_model_v3.h5', custom_objects = {\"rmse\": rmse})\n\nds_try = tf.data.Dataset.from_tensor_slices((test[\"file_path\"], test[tabular_columns])).map(preprocess_test_data).batch(batch_size).cache().prefetch(2)\nres_0 = model_up.predict(ds_try).reshape(-1)\nres_0","metadata":{"papermill":{"duration":5.991319,"end_time":"2021-12-04T11:38:36.79803","exception":false,"start_time":"2021-12-04T11:38:30.806711","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-05T06:07:22.678577Z","iopub.execute_input":"2021-12-05T06:07:22.679474Z","iopub.status.idle":"2021-12-05T06:07:28.377859Z","shell.execute_reply.started":"2021-12-05T06:07:22.679418Z","shell.execute_reply":"2021-12-05T06:07:28.376633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_prev = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntest_prev = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\ntrain_x = train_prev.drop(['Id'],axis=1)\ntest_x = test_prev.drop(['Id'],axis=1)\nmodel_prev = RandomForestRegressor(criterion='mse', max_depth = 4, max_features = 6, n_estimators = 1000)\nmodel_prev.fit(train_x.drop(['Pawpularity'],axis=1), train_x.loc[:,['Pawpularity']].values.ravel())\nres_1 = model_prev.predict(test_x)\n\nw = 0.96\npredictions = w*res_0 + (1.0-w)*res_1\n# predictions = res_0\n\ntest['Pawpularity'] = predictions\ntest[['Id', 'Pawpularity']].to_csv('submission.csv', index=False)\ndisplay(test[['Id', 'Pawpularity']].head())","metadata":{"papermill":{"duration":3.025735,"end_time":"2021-12-04T11:38:39.836194","exception":false,"start_time":"2021-12-04T11:38:36.810459","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-05T06:08:07.194368Z","iopub.execute_input":"2021-12-05T06:08:07.194667Z","iopub.status.idle":"2021-12-05T06:08:07.215095Z","shell.execute_reply.started":"2021-12-05T06:08:07.194638Z","shell.execute_reply":"2021-12-05T06:08:07.213751Z"},"trusted":true},"execution_count":null,"outputs":[]}]}