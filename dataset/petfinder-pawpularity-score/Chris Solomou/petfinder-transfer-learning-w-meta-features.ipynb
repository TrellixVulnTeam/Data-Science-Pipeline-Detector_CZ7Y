{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **In this notebook we will be applying a flexible approach for loading and preprocessing the data that will allow for swiflty experimenting between different strategies.** \n## Particularly, this notebook covers:\n\n* **Transfer Learning-Feature Extraction**\n* **Data Augmentation** \n* **Exploiting meta features** \n* **Creating a model with multiple inputs** \n* **Saving the best model and making predictions**","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport albumentations as A\nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nimport pandas as pd\nimport numpy as np \nimport random \nimport cv2 \nimport os","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load train and test data \ntrain_data = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\ntest_data = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\n\n# Store the paths \ntrain_path = '/kaggle/input/petfinder-pawpularity-score/train/'\ntest_path = '/kaggle/input/petfinder-pawpularity-score/test/'","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:39:28.067898Z","iopub.execute_input":"2021-11-15T16:39:28.068285Z","iopub.status.idle":"2021-11-15T16:39:28.111853Z","shell.execute_reply.started":"2021-11-15T16:39:28.068243Z","shell.execute_reply":"2021-11-15T16:39:28.111154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize some random images \nimage_list = os.listdir('/kaggle/input/petfinder-pawpularity-score/train/')\nIMG_SIZE = 512\nrandom.seed(0)\n\nfor i in range(3):\n    ax = plt.subplot(3, 3, i + 1)\n    random_img = random.choice(image_list)\n    x = random_img.split('.')[0]\n    img = cv2.imread(os.path.join(train_path,random_img))\n    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n    pawpularity = train_data.loc[train_data['Id'] == x, 'Pawpularity'].item()\n    plt.title(f'{pawpularity}.')\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:39:28.113175Z","iopub.execute_input":"2021-11-15T16:39:28.113413Z","iopub.status.idle":"2021-11-15T16:39:28.710957Z","shell.execute_reply.started":"2021-11-15T16:39:28.113381Z","shell.execute_reply":"2021-11-15T16:39:28.710141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Since we are loading the data from a directory and utilizing the meta-features (and labels) from a dataframe, we will create a flexible class that allows us to create both training and test data easily.**\n## **Pixel-normalization can be applied, and image augmentation for the training data, although we need to be careful to not have any conflict with the meta-features (e.g. additional blur).**","metadata":{}},{"cell_type":"code","source":"class DataProcessing(): \n    '''\n    Class for creating training and test data. Combines feature extraction with meta-features.\n    Returns featues from the images along with the corrsponding meta-data. \n    '''\n    def __init__(self,train_df,train_path,test_df,test_path,IMG_SIZE):\n        self.augmentation = None \n        self.normalization = None  \n        self.model = None \n        \n        self.train_path = train_path\n        self.train_df = train_df\n        self.test_path = test_path \n        self.test_df = test_df\n        self.IMG_SIZE = IMG_SIZE \n        self.meta_features = ['Subject Focus','Eyes','Face','Near','Action','Accessory',\\\n                              'Group','Collage','Human','Occlusion','Info','Blur']\n        \n        self.transform = A.Compose([ A.CLAHE(),\n                                    A.HorizontalFlip(),\n                                    A.RandomRotate90(),\n                                    A.Transpose(),\n                                    A.ShiftScaleRotate(shift_limit=0.0425,\n                                                       scale_limit=0.40, \n                                                       rotate_limit=25),\n                                    A.HueSaturationValue()])\n        \n        self.normalize = A.Normalize(mean=[0.485, 0.456, 0.406],\n                                    std=[0.229, 0.224, 0.225],\n                                    max_pixel_value=255.0,\n                                    p=1.0)\n        \n    def feature_extractor(self):\n        # Load base model \n        base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n        # Freeze the base model (so the pre-learned patterns remain)\n        base_model.trainable = False\n        # Inputs to the base model\n        inputs = tf.keras.layers.Input(shape=(self.IMG_SIZE, self.IMG_SIZE, 3), name=\"input_layer\")\n        x = base_model(inputs)\n        # Apply global average pooling to the outputs of the base model to aggregate the most important features\n        outputs = tf.keras.layers.GlobalAveragePooling2D(name=\"average_pooling_layer\")(x)\n        model = tf.keras.Model(inputs, outputs)\n        return model \n        \n    def create_training_data(self,target_col,normalization=False,augmentation=False):\n        X = []; y = []; meta = []\n        # Initialize the model for feature extraction\n        self.model = self.feature_extractor()\n        train_img_ids = self.train_df['Id']\n        meta_data = np.array(self.train_df[self.meta_features])\n        for i,img in enumerate(train_img_ids):\n            try:\n                # Get the label of the current img \n                label = self.train_df.loc[self.train_df['Id'] == img, target_col].item()\n                # Add the jpg to the relative path \n                img += '.jpg'\n                # Read and resize the image \n                img = cv2.imread(os.path.join(self.train_path,img))\n                img = cv2.resize(img, (self.IMG_SIZE,self.IMG_SIZE))\n                # Apply image-augmentation if desired\n                if self.augmentation:\n                    img = self.transform(image=img)[\"image\"]\n                # Apply normalization if desired \n                if self.normalization:\n                    img = self.normalize(image = img)['image']\n                # Reshape the img\n                img = img.reshape(1,IMG_SIZE,IMG_SIZE,3)\n                # Extract features using transfer learning\n                img = self.model.predict(img)\n                # Get the meta features for the current img \n                meta_features = meta_data[i]\n                X.append(img.squeeze())\n                y.append(label)\n                meta.append(meta_features)\n            except Exception as e:\n                print(e)     \n        return X, y, meta                \n    \n    def create_test_data(self,normalization=False):\n        X = [] ; meta = []\n        self.model = self.feature_extractor()\n        test_img_ids = self.test_df['Id']\n        meta_data = np.array(self.test_df[self.meta_features])\n        for i,img in enumerate(test_img_ids):\n            try:\n                img += '.jpg'\n                img = cv2.imread(os.path.join(self.test_path,img))\n                img = cv2.resize(img, (self.IMG_SIZE,self.IMG_SIZE))\n                if self.normalization:\n                    img = self.normalize(image = img)['image']\n                img = img.reshape(1,IMG_SIZE,IMG_SIZE,3)\n                img = self.model.predict(img)\n                meta_features = meta_data[i]\n                X.append(img.squeeze())\n                meta.append(meta_features)\n            except Exception as e:\n                print(e)      \n        return X, meta","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:39:28.713284Z","iopub.execute_input":"2021-11-15T16:39:28.713537Z","iopub.status.idle":"2021-11-15T16:39:28.750844Z","shell.execute_reply.started":"2021-11-15T16:39:28.713504Z","shell.execute_reply":"2021-11-15T16:39:28.750065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the training data \npreprocessing = DataProcessing(train_data,train_path,test_data,test_path,IMG_SIZE=512)\nX,y,meta_data = preprocessing.create_training_data(target_col='Pawpularity')\n\nX = np.array(X,dtype=np.float32)\ny = np.array(y,dtype=np.float32)\nmeta_data = np.array(meta_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_img, X_test_img, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\nX_train_meta, X_test_meta, y_train, y_test = train_test_split(meta_data,y, test_size=0.1, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:50:17.409098Z","iopub.execute_input":"2021-11-15T16:50:17.409877Z","iopub.status.idle":"2021-11-15T16:50:17.437845Z","shell.execute_reply.started":"2021-11-15T16:50:17.409811Z","shell.execute_reply":"2021-11-15T16:50:17.437156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build a new model for classification using tensorflow's functional API\ninputs_meta = tf.keras.layers.Input(shape= X_train_img[0].shape, name=\"input_meta_layer\")\ninputs_img = tf.keras.layers.Input(shape= X_train_meta[0].shape, name=\"input_img_layer\")\n# Concatenate both inputs\nmerged = tf.keras.layers.Concatenate()([inputs_meta, inputs_img])\nx = tf.keras.layers.Dense(3000, kernel_initializer='normal',activation = tf.keras.layers.LeakyReLU())(merged)\nx = tf.keras.layers.Dense(2000, kernel_initializer='normal',activation = tf.keras.layers.LeakyReLU())(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Dense(512, kernel_initializer='normal',activation = tf.keras.layers.LeakyReLU())(x)\nx = tf.keras.layers.Dense(256, kernel_initializer='normal',activation = tf.keras.layers.ReLU())(x)\nx = tf.keras.layers.Dense(512, kernel_initializer='normal',activation = tf.keras.layers.ReLU())(x)\nx = tf.keras.layers.Dropout(0.1)(x)\noutputs = tf.keras.layers.Dense(1,kernel_initializer='normal')(x)\nmodel = tf.keras.Model(inputs = [inputs_meta, inputs_img], outputs =outputs )\nmodel.summary()\n# Plot the model's architecture \ntf.keras.utils.plot_model(model,show_shapes=True,rankdir='TB',expand_nested=False,dpi=56)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:50:17.43916Z","iopub.execute_input":"2021-11-15T16:50:17.439628Z","iopub.status.idle":"2021-11-15T16:50:18.361154Z","shell.execute_reply.started":"2021-11-15T16:50:17.439572Z","shell.execute_reply":"2021-11-15T16:50:18.36034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a directory for saving the best model \ndirectory = '/kaggle/working/trained_model'\nos.mkdir(directory)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:50:18.364374Z","iopub.execute_input":"2021-11-15T16:50:18.364607Z","iopub.status.idle":"2021-11-15T16:50:18.369158Z","shell.execute_reply.started":"2021-11-15T16:50:18.364575Z","shell.execute_reply":"2021-11-15T16:50:18.368393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nEPOCHS = 450 \n\n# Define the rmse for tracking model performance \ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n\n# Define the optimizer\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.00003, momentum=0.9)\n\n# Compile the model \nmodel.compile(loss= rmse,\n                  optimizer=optimizer, \n                  metrics=tf.keras.metrics.RootMeanSquaredError())\n\n# Create checkpoints \ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath='/kaggle/working/trained_model',\n                                                monitor = 'val_root_mean_squared_error', \n                                                verbose = 0, \n                                                save_best_only = True)\n# Save history \nhistory = model.fit([X_train_img,X_train_meta],y_train,validation_data = ([X_test_img,X_test_meta],y_test),\n                        epochs=EPOCHS, verbose=0, callbacks=[checkpoint])\n\n\n# Plot the model's loss curves \npd.DataFrame(history.history).plot()\nplt.ylabel(\"loss\")\nplt.xlabel(\"epochs\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:50:18.370489Z","iopub.execute_input":"2021-11-15T16:50:18.371389Z","iopub.status.idle":"2021-11-15T16:57:41.257544Z","shell.execute_reply.started":"2021-11-15T16:50:18.371355Z","shell.execute_reply":"2021-11-15T16:57:41.256855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the best model \nmodel = tf.keras.models.load_model('/kaggle/working/trained_model',compile=False)\n# Utilize the best model for making predictions  \npredictions = model.predict([X_test_img,X_test_meta]).squeeze().round()\n# Get the error of the predictions with the true labels\nrmse(predictions,y_test) ","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:57:41.259008Z","iopub.execute_input":"2021-11-15T16:57:41.259486Z","iopub.status.idle":"2021-11-15T16:57:41.94495Z","shell.execute_reply.started":"2021-11-15T16:57:41.25945Z","shell.execute_reply":"2021-11-15T16:57:41.94401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load test data and make predictions \ntest_features,test_meta = preprocessing.create_test_data()\npredictions = model.predict([np.array(test_features),np.array(test_meta)])\npredictions = predictions.squeeze().squeeze()\ntest_data['Pawpularity'] = predictions ","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:57:41.946609Z","iopub.execute_input":"2021-11-15T16:57:41.946867Z","iopub.status.idle":"2021-11-15T16:57:46.076947Z","shell.execute_reply.started":"2021-11-15T16:57:41.946832Z","shell.execute_reply":"2021-11-15T16:57:46.076181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = test_data[[\"Id\", \"Pawpularity\"]]\ntest_data.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:57:46.07842Z","iopub.execute_input":"2021-11-15T16:57:46.078665Z","iopub.status.idle":"2021-11-15T16:57:46.08643Z","shell.execute_reply.started":"2021-11-15T16:57:46.078631Z","shell.execute_reply":"2021-11-15T16:57:46.08558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2021-11-15T16:58:11.39232Z","iopub.execute_input":"2021-11-15T16:58:11.39286Z","iopub.status.idle":"2021-11-15T16:58:11.406901Z","shell.execute_reply.started":"2021-11-15T16:58:11.392823Z","shell.execute_reply":"2021-11-15T16:58:11.406058Z"},"trusted":true},"execution_count":null,"outputs":[]}]}