{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"オリジナル : [Clean Petfinder& fastai KF 10 Mixup - The best](https://www.kaggle.com/stefanojp/clean-petfinder-fastai-kf-10-mixup-the-best)","metadata":{}},{"cell_type":"markdown","source":"## Identify duplicates","metadata":{}},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport os\nimport glob\nimport itertools\nimport collections\n\nfrom PIL import Image\nimport cv2\n# from tqdm import tqdm_notebook as tqdm\nfrom tqdm.notebook import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport imagehash\n\nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\n\n## Package necessary for Path\nfrom fastai.vision.all import *\n\ndataset_path = Path('../input/petfinder-pawpularity-score/')\n\ntrain['path'] = train['Id'].map(lambda x:str(dataset_path/'train'/x)+'.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:10:42.661558Z","iopub.execute_input":"2022-01-12T13:10:42.662215Z","iopub.status.idle":"2022-01-12T13:10:45.691551Z","shell.execute_reply.started":"2022-01-12T13:10:42.662114Z","shell.execute_reply":"2022-01-12T13:10:45.690757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n    \n    funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash\n    ]\n    \n    pet_ids = []\n    hashes = []\n    \n    for path in tqdm(glob.glob('../input/petfinder-pawpularity-score/train/*.jpg')):\n        \n        image = Image.open(path)\n        image_id = path.split('/')[-1].split('.')[0]\n\n        pet_ids.append(image_id)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n        \n    return pet_ids, np.array(hashes)\n        \n%time pet_ids, hashes_all = run()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:10:45.693098Z","iopub.execute_input":"2022-01-12T13:10:45.693338Z","iopub.status.idle":"2022-01-12T13:20:16.884852Z","shell.execute_reply.started":"2022-01-12T13:10:45.693304Z","shell.execute_reply":"2022-01-12T13:20:16.881646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:16.889644Z","iopub.execute_input":"2022-01-12T13:20:16.889971Z","iopub.status.idle":"2022-01-12T13:20:19.956812Z","shell.execute_reply.started":"2022-01-12T13:20:16.889925Z","shell.execute_reply":"2022-01-12T13:20:19.956103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:19.958628Z","iopub.execute_input":"2022-01-12T13:20:19.958905Z","iopub.status.idle":"2022-01-12T13:20:23.153572Z","shell.execute_reply.started":"2022-01-12T13:20:19.95887Z","shell.execute_reply":"2022-01-12T13:20:23.152788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_pairs(lower_sim=0.0, upper_sim=1.0):\n    indices1 = np.where((sims > lower_sim) & (sims <= upper_sim))\n    indices2 = np.where(indices1[0] != indices1[1])\n    dups = {tuple(sorted([pet_ids[index1], pet_ids[index2]])): sims[index1, index2] \n                for index1, index2 in zip(indices1[0][indices2], indices1[1][indices2])}\n    print('Found %d pairs with similarity 0.9 or more' % len(dups))\n    \n    return dups\n\ndups_90_00 = show_pairs(0.9, 1.0)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:23.154786Z","iopub.execute_input":"2022-01-12T13:20:23.155215Z","iopub.status.idle":"2022-01-12T13:20:23.599272Z","shell.execute_reply.started":"2022-01-12T13:20:23.155175Z","shell.execute_reply":"2022-01-12T13:20:23.598511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 修正点1: 外部データをコピーしている部分は不要だったのコメントアウト\n# !mkdir ../working/petfinder-pawpularity-score-clean\n# !cp -r ../input/petfinder-pawpularity-score/* ../working/petfinder-pawpularity-score-clean","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:23.600457Z","iopub.execute_input":"2022-01-12T13:20:23.601171Z","iopub.status.idle":"2022-01-12T13:20:23.639504Z","shell.execute_reply.started":"2022-01-12T13:20:23.601132Z","shell.execute_reply":"2022-01-12T13:20:23.638641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids1 = np.array(list(dups_90_00.keys()))[:, 0]\nids2 = np.array(list(dups_90_00.keys()))[:, 1]\n\n\ndef average_pawpularity_score_of_duplicates(ids1, ids2):\n    \n    for id1, id2 in zip(ids1, ids2):\n\n        filter1 = train[\"Id\"] == id1\n        filter2 = train[\"Id\"] == id2\n\n        pawpularity_avg = train[train[\"Id\"].where( filter1 | filter2 ).notnull()]['Pawpularity'].mean()\n\n        train.loc[train[\"Id\"].isin([id1, id2]), 'Pawpularity'] = pawpularity_avg\n\naverage_pawpularity_score_of_duplicates(ids1, ids2)\n\ntrain_dedup = train[~train[\"Id\"].isin(ids2)]\ntrain_dedup = train_dedup.reset_index(drop=True)\n\n# 修正点2: 修正点１と関連して、csvへの書き込みは不要なのでコメントアウト(train_dedupはそのまま引き継いで利用する)\n# train_dedup.to_csv('../input/petfinder-pawpularity-score-clean/train.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:23.640731Z","iopub.execute_input":"2022-01-12T13:20:23.641586Z","iopub.status.idle":"2022-01-12T13:20:23.85111Z","shell.execute_reply.started":"2022-01-12T13:20:23.641539Z","shell.execute_reply":"2022-01-12T13:20:23.850333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dedup.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:23.852533Z","iopub.execute_input":"2022-01-12T13:20:23.85279Z","iopub.status.idle":"2022-01-12T13:20:23.908993Z","shell.execute_reply.started":"2022-01-12T13:20:23.852756Z","shell.execute_reply":"2022-01-12T13:20:23.908317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [MEMO]\n- fastaiを利用\n- [timm](https://github.com/rwightman/pytorch-image-models)を利用して転移学習(Transfer learning)をしている  \n -> timmについて : https://nonbiri-tereka.hatenablog.com/entry/2020/08/26/084816  \n -> 利用しているのはswin_transformer(`swin_large_patch4_window7_224`)\n- [sklearn.StratifiedKFold](https://qiita.com/chorome/items/54e99093050a9473a189#stratifiedkfold%E5%B1%A4%E7%8A%B6k%E5%88%86%E5%89%B2)を利用してKFold学習\n- Mixup を利用して画像データを増やしている(?)  \n  -> コードを見るとMixupに関する部分はコメントアウトされていて、有効になっていない気がする...  \n  -> Mixupについて: https://nonbiri-tereka.hatenablog.com/entry/2020/01/06/082921","metadata":{}},{"cell_type":"code","source":"import sys\n# timmと呼ばれるimageライブラリの導入\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nfrom timm import create_model\nfrom timm.data.mixup import Mixup\n\nfrom fastai.vision.all import *\n#from fastai.callback.hook import *","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:23.910408Z","iopub.execute_input":"2022-01-12T13:20:23.910686Z","iopub.status.idle":"2022-01-12T13:20:29.190491Z","shell.execute_reply.started":"2022-01-12T13:20:23.91065Z","shell.execute_reply":"2022-01-12T13:20:29.189615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(1, reproducible=True)\nBATCH_SIZE = 8\nNEED_TRAIN = False\n\nclean_dataset_path = Path('../input/petfinder-pawpularity-score-clean/')\nclean_dataset_path.ls()\n\ndataset_path = Path('../input/petfinder-pawpularity-score/')\ndataset_path.ls()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:29.194446Z","iopub.execute_input":"2022-01-12T13:20:29.194663Z","iopub.status.idle":"2022-01-12T13:20:30.872486Z","shell.execute_reply.started":"2022-01-12T13:20:29.194634Z","shell.execute_reply":"2022-01-12T13:20:30.871658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 修正点3: 前半の重複を取り除いたdataframeをそのまま後半でも利用するようにする\n# train_df = pd.read_csv(clean_dataset_path/'train.csv')\ntrain_df = train_dedup\n\ntrain_df.head()\n\ntrain_df['path'] = train_df['Id'].map(lambda x:str(clean_dataset_path/'train'/x)+'.jpg')\ntrain_df = train_df.drop(columns=['Id']) # Idのカラムを削除\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:30.874294Z","iopub.execute_input":"2022-01-12T13:20:30.874747Z","iopub.status.idle":"2022-01-12T13:20:31.079393Z","shell.execute_reply.started":"2022-01-12T13:20:30.874692Z","shell.execute_reply":"2022-01-12T13:20:31.078636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_df = len(train_df)\nprint(f\"There are {len_df} images\")","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:31.080649Z","iopub.execute_input":"2022-01-12T13:20:31.081118Z","iopub.status.idle":"2022-01-12T13:20:31.157235Z","shell.execute_reply.started":"2022-01-12T13:20:31.081063Z","shell.execute_reply":"2022-01-12T13:20:31.156241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Pawpularity'].hist(figsize = (10, 5))\nprint(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\nprint(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\nprint(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")\n\nprint(f\"There are {len(train_df['Pawpularity'].unique())} unique values of Pawpularity score\")","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:31.158584Z","iopub.execute_input":"2022-01-12T13:20:31.16026Z","iopub.status.idle":"2022-01-12T13:20:31.494875Z","shell.execute_reply.started":"2022-01-12T13:20:31.160231Z","shell.execute_reply":"2022-01-12T13:20:31.494129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scoreを正規化\ntrain_df['norm_score'] = train_df['Pawpularity']/100\ntrain_df['norm_score']","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:31.496117Z","iopub.execute_input":"2022-01-12T13:20:31.496832Z","iopub.status.idle":"2022-01-12T13:20:31.568895Z","shell.execute_reply.started":"2022-01-12T13:20:31.496792Z","shell.execute_reply":"2022-01-12T13:20:31.567965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = Image.open(train_df['path'][1])\nwidth, height = im.size\nprint(width,height)\n\nim","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:31.570774Z","iopub.execute_input":"2022-01-12T13:20:31.571149Z","iopub.status.idle":"2022-01-12T13:20:31.885656Z","shell.execute_reply.started":"2022-01-12T13:20:31.571104Z","shell.execute_reply":"2022-01-12T13:20:31.88502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n    os.makedirs('/root/.cache/torch/hub/checkpoints/')\n!cp '../input/swin-transformer/swin_large_patch4_window7_224_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window7_224_22kto1k.pth'","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:31.886583Z","iopub.execute_input":"2022-01-12T13:20:31.886827Z","iopub.status.idle":"2022-01-12T13:20:42.25397Z","shell.execute_reply.started":"2022-01-12T13:20:31.886799Z","shell.execute_reply":"2022-01-12T13:20:42.252852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pytorchの設定\nseed=12\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:42.255556Z","iopub.execute_input":"2022-01-12T13:20:42.255867Z","iopub.status.idle":"2022-01-12T13:20:42.381051Z","shell.execute_reply.started":"2022-01-12T13:20:42.255825Z","shell.execute_reply":"2022-01-12T13:20:42.380098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sturges' rule\nnum_bins = int(np.floor(1+np.log2(len(train_df))))\nnum_bins","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:42.382485Z","iopub.execute_input":"2022-01-12T13:20:42.382765Z","iopub.status.idle":"2022-01-12T13:20:42.447551Z","shell.execute_reply.started":"2022-01-12T13:20:42.382717Z","shell.execute_reply":"2022-01-12T13:20:42.446604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:42.45018Z","iopub.execute_input":"2022-01-12T13:20:42.450456Z","iopub.status.idle":"2022-01-12T13:20:42.739597Z","shell.execute_reply.started":"2022-01-12T13:20:42.450421Z","shell.execute_reply":"2022-01-12T13:20:42.738924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# データに不均衡があるため普通のKFoldではなくてStratifiedKFoldを利用(?)\n#from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\n\nN_FOLDS = 5\n\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:42.740801Z","iopub.execute_input":"2022-01-12T13:20:42.741136Z","iopub.status.idle":"2022-01-12T13:20:42.81472Z","shell.execute_reply.started":"2022-01-12T13:20:42.741099Z","shell.execute_reply":"2022-01-12T13:20:42.813935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()\n\ntrain_df[train_df['fold']==0].head()\n\ntrain_df[train_df['fold']==0]['bins'].value_counts()\n\ntrain_df[train_df['fold']==1]['bins'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:42.816582Z","iopub.execute_input":"2022-01-12T13:20:42.81726Z","iopub.status.idle":"2022-01-12T13:20:43.139036Z","shell.execute_reply.started":"2022-01-12T13:20:42.817221Z","shell.execute_reply":"2022-01-12T13:20:43.138353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:43.140202Z","iopub.execute_input":"2022-01-12T13:20:43.140925Z","iopub.status.idle":"2022-01-12T13:20:43.201672Z","shell.execute_reply.started":"2022-01-12T13:20:43.140883Z","shell.execute_reply":"2022-01-12T13:20:43.200915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get_learnerから呼び出されるメソッド\ndef get_data(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n#     mixup_fn = Mixup(**mixup_args)\n    \n#     dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n# #                                valid_pct=0.2, #80-20 train-validation random split\n#                                valid_col='is_valid', #\n#                                seed=999, #seed\n#                                fn_col='path', #filename/path is in the second column of the DataFrame\n#                                label_col='norm_score', #label is in the first column of the DataFrame\n#                                y_block=RegressionBlock, #The type of target\n#                                bs=BATCH_SIZE, #pass in batch size\n#                                num_workers=8,\n#                                item_tfms=Resize(224), #pass in item_tfms\n#                                batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n\n    # It looks if seed of RandomSplitter is set, it reduce the score. So we don't set seed here\n    splitter = RandomSplitter(0.2)\n    # Change RandomSplitter to IndexSplitter\n    splitter = IndexSplitter(splitter(range(len(train_df)))[1])\n    \n    dls = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                get_x=ColReader('path'),\n                get_y=ColReader('norm_score'),\n                splitter=splitter,\n                item_tfms=Resize(224), #pass in item_tfms\n                batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])\n               )\n    \n    paw_dls = dls.dataloaders(train_df_f, \n                          bs=BATCH_SIZE,\n                          num_workers=8,\n                          seed=seed)\n    \n    return paw_dls, splitter","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:43.203046Z","iopub.execute_input":"2022-01-12T13:20:43.203817Z","iopub.status.idle":"2022-01-12T13:20:43.267522Z","shell.execute_reply.started":"2022-01-12T13:20:43.203778Z","shell.execute_reply":"2022-01-12T13:20:43.266766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 各Foldから呼び出されるメソッド\ndef get_learner(fold_num):\n    data, splitter = get_data(fold_num)\n    \n    # swin_transformerのモデルを呼び出している\n    model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=data.c)\n    \n    # このLearnerのドキュメントが見たい\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse, cbs=[MixUp(0.2)]).to_fp16()\n    \n    return learn, splitter","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:43.268972Z","iopub.execute_input":"2022-01-12T13:20:43.269263Z","iopub.status.idle":"2022-01-12T13:20:43.332757Z","shell.execute_reply.started":"2022-01-12T13:20:43.269225Z","shell.execute_reply":"2022-01-12T13:20:43.331913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# テストデータ\ntest_df = pd.read_csv(dataset_path/'test.csv')\ntest_df.head()\n\n# if len(test_df) != 8:\n#     NEED_TRAIN = True\nNEED_TRAIN = True\nprint(NEED_TRAIN)\n\ntest_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path/'test'/x)+'.jpg')\ntest_df = test_df.drop(columns=['Id'])\ntrain_df['norm_score'] = train_df['Pawpularity']/100","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:43.334164Z","iopub.execute_input":"2022-01-12T13:20:43.33443Z","iopub.status.idle":"2022-01-12T13:20:43.409726Z","shell.execute_reply.started":"2022-01-12T13:20:43.334395Z","shell.execute_reply":"2022-01-12T13:20:43.409074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\nfrom sklearn.metrics import mean_squared_error\n\nif NEED_TRAIN:\n    all_preds = []\n    train_df['pred'] = -1\n\n    # 設定したFOLD数で動く部分\n    for i in range(N_FOLDS):\n\n        print(f'Fold {i} results')\n\n        learn, splitter = get_learner(fold_num=i)\n\n        learn.fit_one_cycle(5, 2e-5, cbs=[SaveModelCallback(), EarlyStoppingCallback(monitor='petfinder_rmse', comp=np.less, patience=2)]) \n\n        learn.recorder.plot_loss()\n        \n        #over fitting\n        learn.unfreeze()\n        \n        learn.fit_one_cycle(5,lr_max=slice(1e-6,1e-4))\n\n        learn = learn.to_fp32()\n\n        learn.export(f'model_fold_{i}.pkl')\n        #learn.save(f'model_fold_{i}.pkl')\n\n#         dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n#                                    valid_pct=0.2, #80-20 train-validation random split\n#                                    seed=999, #seed\n#                                    fn_col='path', #filename/path is in the second column of the DataFrame\n#                                    label_col='norm_score', #label is in the first column of the DataFrame\n#                                    y_block=RegressionBlock, #The type of target\n#                                    bs=BATCH_SIZE, #pass in batch size\n#                                    num_workers=8,\n#                                    item_tfms=Resize(224), #item_tfms=RandomResizedCrop(224, min_scale=0.3) #pass in item_tfms\n#                                    batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n\n        dls = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                    get_x=ColReader('path'),\n                    get_y=ColReader('norm_score'),\n                    splitter=RandomSplitter(0.2),\n                    item_tfms=Resize(224), #pass in item_tfms\n                    batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])\n                   )\n\n        paw_dls = dls.dataloaders(train_df, \n                              bs=BATCH_SIZE,\n                              num_workers=8,\n                          seed=seed)\n        \n        test_dl = paw_dls.test_dl(test_df)\n\n        preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n\n        all_preds.append(preds)\n        \n        val_idx = splitter(range(len(train_df)))[1]\n        val_df = train_df.loc[val_idx]\n        val_pred, _ = learn.tta(dl=paw_dls.test_dl(val_df), n=5, beta=0)\n        print(val_df['Pawpularity'][:5], val_pred[:5])\n        score = mean_squared_error(val_df['Pawpularity'], val_pred*100, squared=False)\n        print(f'Fold {i} | Score: {score}')\n        # Save prediction of validation as pred\n        train_df.loc[val_idx, 'pred'] = val_pred*100\n\n        del learn\n\n        torch.cuda.empty_cache()\n\n        gc.collect()\n        \n        #Only run one fold for public train as we don't have so many GPU time\n        if len(test_df) == 8:\n            break\n    if len(test_df) == 8:\n        cv_score = mean_squared_error(train_df.loc[train_df['pred']!=-1, 'Pawpularity'], \n                                      train_df.loc[train_df['pred']!=-1, 'pred'], squared=False)\n        print(f'CV Score: {cv_score}')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T13:20:43.410994Z","iopub.execute_input":"2022-01-12T13:20:43.411504Z","iopub.status.idle":"2022-01-12T14:35:53.914183Z","shell.execute_reply.started":"2022-01-12T13:20:43.411468Z","shell.execute_reply":"2022-01-12T14:35:53.91263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if NEED_TRAIN:\n    all_preds, np.mean(np.stack(all_preds*100))\n\nsample_df = pd.read_csv(dataset_path/'sample_submission.csv')\nif NEED_TRAIN:\n    preds = np.mean(np.stack(all_preds), axis=0)\n    sample_df['Pawpularity'] = preds*100\nsample_df.to_csv('submission.csv',index=False)\n\nif not NEED_TRAIN:\n    pd.read_csv('submission.csv').head()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T14:35:53.915479Z","iopub.status.idle":"2022-01-12T14:35:53.918437Z","shell.execute_reply.started":"2022-01-12T14:35:53.918167Z","shell.execute_reply":"2022-01-12T14:35:53.918195Z"},"trusted":true},"execution_count":null,"outputs":[]}]}