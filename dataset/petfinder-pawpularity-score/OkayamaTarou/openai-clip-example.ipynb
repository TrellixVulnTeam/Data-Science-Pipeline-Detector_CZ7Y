{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport cv2\nimport skimage\nimport IPython.display\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nfrom glob import glob\n\nfrom collections import OrderedDict\nimport torch\nimport gc\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-29T07:11:37.036848Z","iopub.execute_input":"2022-03-29T07:11:37.037167Z","iopub.status.idle":"2022-03-29T07:11:38.920193Z","shell.execute_reply.started":"2022-03-29T07:11:37.037102Z","shell.execute_reply":"2022-03-29T07:11:38.919299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/301686  \nPetfinder コンペで優勝したGibaさんのプログラムを利用","metadata":{}},{"cell_type":"markdown","source":"# Install CLIP library","metadata":{}},{"cell_type":"code","source":"!pip install ../input/openaiclipweights/python-ftfy-master/python-ftfy-master\n!pip install ../input/openaiclipweights/clip/CLIP\n!cp ../input/openaiclipweights/CLIP-main/CLIP-main/clip/bpe_simple_vocab_16e6.txt /opt/conda/lib/python3.7/site-packages/clip/.\n!gzip -k /opt/conda/lib/python3.7/site-packages/clip/bpe_simple_vocab_16e6.txt\n!ls /opt/conda/lib/python3.7/site-packages/clip/.","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:11:38.927105Z","iopub.execute_input":"2022-03-29T07:11:38.928327Z","iopub.status.idle":"2022-03-29T07:12:32.500779Z","shell.execute_reply.started":"2022-03-29T07:11:38.928251Z","shell.execute_reply":"2022-03-29T07:12:32.499967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport clip\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader, Dataset\n\nprint(\"Torch version:\", torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:12:32.504035Z","iopub.execute_input":"2022-03-29T07:12:32.50426Z","iopub.status.idle":"2022-03-29T07:12:33.027932Z","shell.execute_reply.started":"2022-03-29T07:12:32.504232Z","shell.execute_reply":"2022-03-29T07:12:33.027068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download some images from open images collection.","metadata":{}},{"cell_type":"code","source":"!wget https://farm8.staticflickr.com/6036/6426668771_b5b915e46c_o.jpg\n!wget https://c6.staticflickr.com/8/7457/10806045045_02d3dbdcee_o.jpg\n!wget https://c1.staticflickr.com/4/3267/2888764405_0a0a608604_o.jpg\n!wget https://farm8.staticflickr.com/4028/4294212194_a49663b2b9_o.jpg\n!wget https://c5.staticflickr.com/9/8173/8019508216_6540c8686a_o.jpg\n!wget https://farm3.staticflickr.com/1146/1357102390_943c5cb999_o.jpg","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:12:33.031542Z","iopub.execute_input":"2022-03-29T07:12:33.032004Z","iopub.status.idle":"2022-03-29T07:12:48.918856Z","shell.execute_reply.started":"2022-03-29T07:12:33.031969Z","shell.execute_reply":"2022-03-29T07:12:48.91797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = glob('*.jpg')\nprint(files)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:12:48.92072Z","iopub.execute_input":"2022-03-29T07:12:48.921019Z","iopub.status.idle":"2022-03-29T07:12:48.926504Z","shell.execute_reply.started":"2022-03-29T07:12:48.920977Z","shell.execute_reply":"2022-03-29T07:12:48.925804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# List pretrained CLIP models available","metadata":{}},{"cell_type":"code","source":"clip.available_models()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:12:48.927809Z","iopub.execute_input":"2022-03-29T07:12:48.928053Z","iopub.status.idle":"2022-03-29T07:12:48.940134Z","shell.execute_reply.started":"2022-03-29T07:12:48.92802Z","shell.execute_reply":"2022-03-29T07:12:48.939425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# List pretrained weights available","metadata":{}},{"cell_type":"code","source":"!ls ../input/openaiclipweights/clip/CLIP/models/","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:12:48.941628Z","iopub.execute_input":"2022-03-29T07:12:48.942232Z","iopub.status.idle":"2022-03-29T07:12:49.598457Z","shell.execute_reply.started":"2022-03-29T07:12:48.942194Z","shell.execute_reply":"2022-03-29T07:12:49.597687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load CLIP Vision Transformer based model","metadata":{}},{"cell_type":"code","source":"model, preprocess = clip.load(\"../input/openaiclipweights/clip/CLIP/models/ViT-B-32.pt\")\nmodel.cuda().eval()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:12:49.600773Z","iopub.execute_input":"2022-03-29T07:12:49.601051Z","iopub.status.idle":"2022-03-29T07:12:55.058085Z","shell.execute_reply.started":"2022-03-29T07:12:49.601012Z","shell.execute_reply":"2022-03-29T07:12:55.057299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For each image we will query for the following senteces and see what CLIP predicts. \n# You can add custom sentences here.","metadata":{}},{"cell_type":"code","source":"QUERIES = [\n    \"a cat in a sofa\",\n    \"a dog\",\n    \"a cat\",\n    \"a elephant\",\n    \"a zebra\",\n    \"a sleeping dog\",\n    \"a sleeping cat\",\n    \"a giraffe\",\n    \"a poodle\",\n    \"animal inside a car\",\n    \"animal outside a car\",\n    \"a sofa\",\n    \"some animals\",\n    \"santa claus\",\n    \"ipod\",\n    \"two mugs\",\n    \"three mugs\",\n    \"blue sky\",\n    \"three mugs and a iphone\",\n] ","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:12:55.059528Z","iopub.execute_input":"2022-03-29T07:12:55.060217Z","iopub.status.idle":"2022-03-29T07:12:55.065944Z","shell.execute_reply.started":"2022-03-29T07:12:55.060166Z","shell.execute_reply":"2022-03-29T07:12:55.065179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Score images vs queries using clip model","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    for file in files:\n        print(file)\n        # Load image from file\n        img = Image.open(file).convert(\"RGB\")\n\n        # Just show image in the notebook\n        plt.imshow(cv2.resize(np.array(img), (256, 256)))\n        plt.show()\n        \n        # Preprocess image using clip\n        img = preprocess(img).unsqueeze(0).cuda()\n        \n        # Get Image embeddings\n        image_embeddings = model.encode_image(img)\n        image_embeddings /= image_embeddings.norm(dim=-1, keepdim=True)\n        \n        \n        score = []\n        for query in QUERIES:\n            texts = clip.tokenize(query).cuda()\n            \n            # Get Text Embeddings\n            text_embeddings = model.encode_text(texts)\n            text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n            \n            # Calc dot product between image and text embeddings\n            sc = float((image_embeddings @ text_embeddings.T).cpu().numpy())\n            score.append(sc)\n        \n        print( pd.DataFrame({'query': QUERIES, 'score': score}).sort_values('score', ascending=False) )\n        print('')\n        print('-------------------------')\n        print('')\n","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:12:55.068759Z","iopub.execute_input":"2022-03-29T07:12:55.069233Z","iopub.status.idle":"2022-03-29T07:13:04.727885Z","shell.execute_reply.started":"2022-03-29T07:12:55.069189Z","shell.execute_reply":"2022-03-29T07:13:04.727002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"画像読み込み関数","metadata":{}},{"cell_type":"code","source":"## 追加\n\nimport io\nimport requests","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:13:04.729524Z","iopub.execute_input":"2022-03-29T07:13:04.729811Z","iopub.status.idle":"2022-03-29T07:13:04.734539Z","shell.execute_reply.started":"2022-03-29T07:13:04.729775Z","shell.execute_reply":"2022-03-29T07:13:04.733808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def softmax(x):\n    u = np.sum(np.exp(x))\n    return np.exp(x)/u","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:13:04.735581Z","iopub.execute_input":"2022-03-29T07:13:04.736287Z","iopub.status.idle":"2022-03-29T07:13:04.754979Z","shell.execute_reply.started":"2022-03-29T07:13:04.736244Z","shell.execute_reply":"2022-03-29T07:13:04.754161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## URL　画像読み込み実験\nimg_urls =[\n#    \"https://drive.google.com/file/d/1UxtPN-SnAIO9hLOZ303eTMTrWb6Ssq55/view\"]\n#           \"https://www.yodosha.co.jp/rnote/gazou_qa/images/9784758115537_2pic1_l.png\"\n#           \"https://phio.panasonic.co.jp/kinen/cxr/cr_image/case82.jpg\"] # 胸部Xp\n#    \"https://www.harasanshin.or.jp/img/seikei-daitaikotsu_kossetsu1.jpg\"] # 大腿骨転子部骨折\n    \"https://univ-journal.jp/wp-content/uploads/2019/08/pixta_46842118_S-1200x675.jpg\"] # 岡山大学\n    \nimg = Image.open((io.BytesIO(requests.get(img_urls[0]).content))).convert(\"RGB\")\n\nplt.imshow(cv2.resize(np.array(img), (256, 256)))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T07:13:04.756071Z","iopub.execute_input":"2022-03-29T07:13:04.756903Z","iopub.status.idle":"2022-03-29T07:13:06.558901Z","shell.execute_reply.started":"2022-03-29T07:13:04.756864Z","shell.execute_reply":"2022-03-29T07:13:06.558217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"外部画像","metadata":{}},{"cell_type":"code","source":"# 問い合わせ文章　長い文章でも良い\nQUERIES = [\n    \"a Ryobi systems\",\n    \"japanese university\",\n    \"a chest x-ray\",\n    \"a hip x-ray\",\n    \"an anterior view of hip x-ray\",\n    \"a lateral view of hip x-ray\",    \n    \"a normal hip x-ray\",\n    \"a fractured hip x-ray\",\n    \"database\",\n    \"a cup\",\n    \"a trophy\",\n    \"a elephant\",\n    \"a zebra\",\n    \"a sleeping dog\",\n    \"a sleeping cat\",\n]","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:52:42.365163Z","iopub.execute_input":"2022-03-18T09:52:42.365869Z","iopub.status.idle":"2022-03-18T09:52:42.372374Z","shell.execute_reply.started":"2022-03-18T09:52:42.365833Z","shell.execute_reply":"2022-03-18T09:52:42.371173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for img_url in img_urls:\n        print(file)\n        # Load image from file\n        #img = Image.open(file).convert(\"RGB\")\n        img = Image.open((io.BytesIO(requests.get(img_url).content))).convert(\"RGB\")\n\n        # Just show image in the notebook\n        plt.imshow(cv2.resize(np.array(img), (256, 256)))\n        plt.show()\n        \n        # Preprocess image using clip\n        img = preprocess(img).unsqueeze(0).cuda()\n        \n        # Get Image embeddings\n        image_embeddings = model.encode_image(img)\n        image_embeddings /= image_embeddings.norm(dim=-1, keepdim=True)\n        \n        \n        score = []\n        for query in QUERIES:\n            texts = clip.tokenize(query).cuda()\n            \n            # Get Text Embeddings\n            text_embeddings = model.encode_text(texts)\n            text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n            \n            # Calc dot product between image and text embeddings\n            sc = float((image_embeddings @ text_embeddings.T).cpu().numpy())\n            score.append(sc)\n        \n        scoreN = [n*100 for n in score]\n        scoreSoftmax = softmax(scoreN)\n        scoreSoftmax = np.round(scoreSoftmax *100)\n        scoreNP = scoreSoftmax\n\n        print( pd.DataFrame({'query': QUERIES, 'score': score, '%': scoreNP}).sort_values('score', ascending=False) )\n        #print( pd.DataFrame({'query': QUERIES, 'score': score}).sort_values('score', ascending=False) )\n        print('')\n        print('-------------------------')\n        print('')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:52:44.183271Z","iopub.execute_input":"2022-03-18T09:52:44.183828Z","iopub.status.idle":"2022-03-18T09:52:45.72469Z","shell.execute_reply.started":"2022-03-18T09:52:44.183788Z","shell.execute_reply":"2022-03-18T09:52:45.723756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:37:17.559942Z","iopub.execute_input":"2022-03-18T09:37:17.560198Z","iopub.status.idle":"2022-03-18T09:37:17.56514Z","shell.execute_reply.started":"2022-03-18T09:37:17.56017Z","shell.execute_reply":"2022-03-18T09:37:17.563812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GPUからCPUに移してtensor -> numpy　\ndevice_cpu = torch.device('cpu')\nimage_embeddings_cpu = image_embeddings.to(device_cpu)\nimage_embeddings_numpy = image_embeddings_cpu.clone().numpy()\n\n# (1,512) なので1次元配列に\nimage_embeddings_numpy_1d = image_embeddings_numpy.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:37:17.566528Z","iopub.execute_input":"2022-03-18T09:37:17.566834Z","iopub.status.idle":"2022-03-18T09:37:17.574719Z","shell.execute_reply.started":"2022-03-18T09:37:17.566795Z","shell.execute_reply":"2022-03-18T09:37:17.573699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(image_embeddings_numpy_1d)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:37:17.576526Z","iopub.execute_input":"2022-03-18T09:37:17.576991Z","iopub.status.idle":"2022-03-18T09:37:17.849116Z","shell.execute_reply.started":"2022-03-18T09:37:17.576942Z","shell.execute_reply":"2022-03-18T09:37:17.848419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convertTorch2Numpy(embeddings):\n    # GPUからCPUに移してtensor -> numpy　\n    device_cpu = torch.device('cpu')\n    embeddings_cpu = embeddings.to(device_cpu)\n    embeddings_numpy = embeddings_cpu.clone().detach().numpy()\n    # (1,512) なので1次元配列に\n    embeddings_numpy_1d = embeddings_numpy.flatten()\n    return embeddings_numpy_1d","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:37:17.850199Z","iopub.execute_input":"2022-03-18T09:37:17.850585Z","iopub.status.idle":"2022-03-18T09:37:17.856339Z","shell.execute_reply.started":"2022-03-18T09:37:17.850546Z","shell.execute_reply":"2022-03-18T09:37:17.855461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getTextEmbeddings(text):\n    # single text\n    texts = clip.tokenize(text).cuda()\n    # Get Text Embeddings\n    text_embeddings = model.encode_text(texts)\n    text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n    return text_embeddings","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:37:17.857891Z","iopub.execute_input":"2022-03-18T09:37:17.858176Z","iopub.status.idle":"2022-03-18T09:37:17.866171Z","shell.execute_reply.started":"2022-03-18T09:37:17.858135Z","shell.execute_reply":"2022-03-18T09:37:17.865381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calcDotProduct(image_embeddings, text_embeddings):\n    # Calc dot product between image and text embeddings\n    sc = float((image_embeddings @ text_embeddings.T).cpu().detach().numpy())\n    return sc ","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:37:17.867306Z","iopub.execute_input":"2022-03-18T09:37:17.86811Z","iopub.status.idle":"2022-03-18T09:37:17.876102Z","shell.execute_reply.started":"2022-03-18T09:37:17.868057Z","shell.execute_reply":"2022-03-18T09:37:17.875223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \nimage_embeddings_np = convertTorch2Numpy(image_embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:37:17.87856Z","iopub.execute_input":"2022-03-18T09:37:17.879605Z","iopub.status.idle":"2022-03-18T09:37:17.885513Z","shell.execute_reply.started":"2022-03-18T09:37:17.879571Z","shell.execute_reply":"2022-03-18T09:37:17.884709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 異なる単語で問い合わせた場合、どれだけ値が異なるかを可視化\n# single text embeddings\ntext1 = \"a Ryobi systems\"\ntext2 = \"a elephant\",\n\ntext_embeddings1 = getTextEmbeddings(text1)\ntext_embeddings_np1 = convertTorch2Numpy(text_embeddings1)\ntext_embeddings2 = getTextEmbeddings(text2)\ntext_embeddings_np2 = convertTorch2Numpy(text_embeddings2)\n\n# graph1\nfig, ax = plt.subplots()\nx = np.linspace(0,511,512)\nax.plot(x,image_embeddings_np)\nax.plot(x,text_embeddings_np1, color='green')\nax.set_title(calcDotProduct(image_embeddings, text_embeddings1))\n\n# graph2\nfig, ax = plt.subplots()\nx = np.linspace(0,511,512)\nax.plot(x,image_embeddings_np)\nax.plot(x,text_embeddings_np2, color='red')\nax.set_title(calcDotProduct(image_embeddings, text_embeddings2))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:58:04.45685Z","iopub.execute_input":"2022-03-18T09:58:04.45713Z","iopub.status.idle":"2022-03-18T09:58:04.992548Z","shell.execute_reply.started":"2022-03-18T09:58:04.457099Z","shell.execute_reply":"2022-03-18T09:58:04.991881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# graph1-2\nfig, ax = plt.subplots()\nx = np.linspace(0,511,512)\nax.plot(x,text_embeddings_np1, color='green')\nax.plot(x,text_embeddings_np2, color='red')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:58:09.600861Z","iopub.execute_input":"2022-03-18T09:58:09.601142Z","iopub.status.idle":"2022-03-18T09:58:09.867779Z","shell.execute_reply.started":"2022-03-18T09:58:09.601112Z","shell.execute_reply":"2022-03-18T09:58:09.866929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 散布図\nplt.scatter(text_embeddings_np1,text_embeddings_np2, c=x, cmap='Blues')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:58:11.847007Z","iopub.execute_input":"2022-03-18T09:58:11.847589Z","iopub.status.idle":"2022-03-18T09:58:12.215628Z","shell.execute_reply.started":"2022-03-18T09:58:11.847522Z","shell.execute_reply":"2022-03-18T09:58:12.214918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"softmax(score)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T09:58:12.292906Z","iopub.execute_input":"2022-03-18T09:58:12.293343Z","iopub.status.idle":"2022-03-18T09:58:12.298517Z","shell.execute_reply.started":"2022-03-18T09:58:12.293309Z","shell.execute_reply":"2022-03-18T09:58:12.297847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"softmaxScore = softmax2(score)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T10:18:16.900941Z","iopub.execute_input":"2022-03-16T10:18:16.90149Z","iopub.status.idle":"2022-03-16T10:18:16.905251Z","shell.execute_reply.started":"2022-03-16T10:18:16.901451Z","shell.execute_reply":"2022-03-16T10:18:16.904245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score","metadata":{"execution":{"iopub.status.busy":"2022-03-16T10:17:08.269416Z","iopub.execute_input":"2022-03-16T10:17:08.269725Z","iopub.status.idle":"2022-03-16T10:17:08.27583Z","shell.execute_reply.started":"2022-03-16T10:17:08.269692Z","shell.execute_reply":"2022-03-16T10:17:08.274822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(softmaxScore)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T10:18:31.469712Z","iopub.execute_input":"2022-03-16T10:18:31.469972Z","iopub.status.idle":"2022-03-16T10:18:31.474801Z","shell.execute_reply.started":"2022-03-16T10:18:31.469944Z","shell.execute_reply":"2022-03-16T10:18:31.474165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"softmaxScore","metadata":{"execution":{"iopub.status.busy":"2022-03-16T10:18:21.307244Z","iopub.execute_input":"2022-03-16T10:18:21.30788Z","iopub.status.idle":"2022-03-16T10:18:21.314154Z","shell.execute_reply.started":"2022-03-16T10:18:21.307841Z","shell.execute_reply":"2022-03-16T10:18:21.313366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}