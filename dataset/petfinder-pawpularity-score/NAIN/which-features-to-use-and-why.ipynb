{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello Kagglers! Welcome to another very interesting PetFinder Competition. The past competitions were amazing and I am pretty sure that this one would be too\n\n# Task\nThe task is pretty simple. Given a photo of a pet along with some features (hand-labeled metadata), we are asked to provide an engagement score or the PawPularity score.\nI will use the terms popularity, engagement, and pawpularity very loosely here. Although the meaning of three can be very different when put in a proper context, I will use them interchangeably. IMO, if a photo is engaging, it will be more popular and will have a high pawpularity score.\nWithout any further delay, let's jump in!","metadata":{}},{"cell_type":"code","source":"! pip install -qq --upgrade seaborn","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:10.945945Z","iopub.execute_input":"2021-09-23T16:26:10.946265Z","iopub.status.idle":"2021-09-23T16:26:18.685077Z","shell.execute_reply.started":"2021-09-23T16:26:10.946233Z","shell.execute_reply":"2021-09-23T16:26:18.684205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport time\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nimport plotly.io as pio\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nsns.set()\npio.templates.default = \"ggplot2\"\n\nseed = 1234\nnp.random.seed(seed)\n\n%config IPCompleter.use_jedi = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-23T16:26:23.73391Z","iopub.execute_input":"2021-09-23T16:26:23.73421Z","iopub.status.idle":"2021-09-23T16:26:24.97482Z","shell.execute_reply.started":"2021-09-23T16:26:23.734178Z","shell.execute_reply":"2021-09-23T16:26:24.974212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset\n\nWe are provided with a `train` csv and a `test` csv. The images for the training data are stored in the `train` directory while the images for test data is stored in the `test` directory ","metadata":{}},{"cell_type":"code","source":"# Path to the data directory\ndata_dir = Path(\"../input/petfinder-pawpularity-score/\")\n\n# Paths to train and test images\ntrain_images_dir = data_dir / \"train\"\ntest_images_dir = data_dir / \"test\"","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:27.543445Z","iopub.execute_input":"2021-09-23T16:26:27.543734Z","iopub.status.idle":"2021-09-23T16:26:27.548694Z","shell.execute_reply.started":"2021-09-23T16:26:27.543707Z","shell.execute_reply":"2021-09-23T16:26:27.547786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the CSVs\ntrain_df = pd.read_csv(data_dir / \"train.csv\")\ntest_df = pd.read_csv(data_dir / \"test.csv\")\n\nprint(\"Number of training samples: \", len(train_df))\nprint(\"Number of test samples: \", len(test_df))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:28.14542Z","iopub.execute_input":"2021-09-23T16:26:28.145718Z","iopub.status.idle":"2021-09-23T16:26:28.17463Z","shell.execute_reply.started":"2021-09-23T16:26:28.145689Z","shell.execute_reply":"2021-09-23T16:26:28.173752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What's in the training data?\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:28.712084Z","iopub.execute_input":"2021-09-23T16:26:28.712387Z","iopub.status.idle":"2021-09-23T16:26:28.728854Z","shell.execute_reply.started":"2021-09-23T16:26:28.712343Z","shell.execute_reply":"2021-09-23T16:26:28.727823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What's in the test data?\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:29.232512Z","iopub.execute_input":"2021-09-23T16:26:29.23357Z","iopub.status.idle":"2021-09-23T16:26:29.24842Z","shell.execute_reply.started":"2021-09-23T16:26:29.233532Z","shell.execute_reply":"2021-09-23T16:26:29.247787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pawpularity Distribution\n\nThe first thing that we will check is the distribution of `pawpularity` score. We will use `sns.histplot(..).` for plotting the distribution. You can read about the API [here](https://seaborn.pydata.org/generated/seaborn.histplot.html)","metadata":{}},{"cell_type":"code","source":"_, ax = plt.subplots(1,1, figsize=(15, 8))\nsns.histplot(data=train_df, x=\"Pawpularity\", color=\"blue\", kde=True, ax=ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:32:52.803237Z","iopub.execute_input":"2021-09-23T16:32:52.804095Z","iopub.status.idle":"2021-09-23T16:32:53.197188Z","shell.execute_reply.started":"2021-09-23T16:32:52.804051Z","shell.execute_reply":"2021-09-23T16:32:53.19628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Things we can notice quickly from the distribution of the scores:\n\n1. Majority of the photos have a pawpularity score between 20-50\n2. We have a long tail on the right-hand side with almost 300 images with a perfect score of 100\n3. We surely can't ignore the images with a perfect score during the training phase","metadata":{}},{"cell_type":"markdown","source":"# Features and PawPularity\n\nWe are provided with **twelve** features, as meta-data, that we can use as additional features for training our models. Each of these features is binary, meaning they are either present or absent in the image. These features are:\n\n1. **Focus** - Pet stands out against the uncluttered background, not too close / far.\n2. **Eyes** - Both eyes are facing front or near-front, with at least 1 eye/pupil decently clear.\n3. **Face** - Decently clear face, facing front or near-front.\n4. **Near** - Single pet taking up a significant portion of photo (roughly over 50% of photo width or height).\n5. **Action** - Pet in the middle of an action (e.g., jumping).\n6. **Accessory** - Accompanying physical or digital accessory/prop (i.e. toy, digital sticker), excluding collar and leash.\n7. **Group** - More than 1 pet in the photo.\n8. **Collage** - Digitally-retouched photo (i.e. with digital photo frame, a combination of multiple photos).\n9. **Human** - Human in the photo.\n10. **Occlusion** - Specific undesirable objects blocking part of the pet (i.e. human, cage, or fence). Note that not all blocking objects are considered occlusion.\n11. **Info** - Custom-added text or labels (i.e. pet name, description).\n12. **Blur** - Noticeably out of focus or noisy, especially for the pet’s eyes and face. For Blur entries, “Eyes” column is always set to 0.\n\nBefore discussing why these features are needed, let's check how the pawpularity score is affected by the presence of a certain feature. We will use the same distribution plot but with `hue` where hue would be a feature from the given features","metadata":{}},{"cell_type":"code","source":"features = train_df.columns[1:-1].tolist()\nnum_cols = 2\nnum_rows = len(features) // num_cols\n\n\nfig, axs = plt.subplots(num_rows,\n                        num_cols,\n                        figsize=(20, 15),\n                        sharex=False,\n                        sharey=True\n                       )\n\nfor i, feature in enumerate(features):\n    _ = sns.histplot(data=train_df,\n                 x=\"Pawpularity\",\n                 kde=False,\n                 ax=axs[i // num_cols, i % num_cols],\n                 hue=feature,\n                )\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:52:25.593741Z","iopub.execute_input":"2021-09-23T16:52:25.594418Z","iopub.status.idle":"2021-09-23T16:52:30.596125Z","shell.execute_reply.started":"2021-09-23T16:52:25.594376Z","shell.execute_reply":"2021-09-23T16:52:30.595243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plot is pretty interesting. A few things that we can notice from this plot:\n\n1. Although one would expect **Subject Focus** to be a very important feature for making a photo popular, in this case, it hardly contributes to a high score.\n2. **Eyes, Face, and Near (Single Pet)** are the only three features that are dominant for a popularity score of more than 50. These are the only features that contributed most to  a score of 100\n3. A group photo with other pets/humans doesn't give a good score\n4. Collage, as expected, doesn't improve the score. The distribution of scores with/without Collage is the same\n5. **Blur(Out of focus or noisy)** tends to decrease the score as expected. Most blurred photos scored between 20-30\n6. Any pet doing an action in a photo doesn't make the pet more attractive, hence the score isn't affected at all\n\n\n# Why are the features important?\n\nEngagement with a photo depends very much on the **aesthetics** of a photo. To give you a simple example, a not-so good looking pet (Sorry, every pet is cute! Here I am just talking in terms of the photo), would look cuter with a focus on the features of the pet rather than a good looking pet doing some weird trick far away from the camera. \n\nAnd aesthetics isn't just that. The term aesthetics itself is very broad as it depends very much on an individual perception of a photo. \"How to capture aesthetics of a photo in an ML model\" is an open research area. So, instead of just looking at raw photos and trying to predict an engagement/pawpularity score is much harder than predicting the score for the same photo but with additional features that aren't directly captured in a simple model, especially traditional ML models ","metadata":{}},{"cell_type":"markdown","source":"# Feature specific photos\n\nWe will do a simple exercise here to visualize the images and their corresponding scores to see if they make sense. We will do the following:\n\n1. Filter the training dataframe using a specific feature\n2. Gather some random samples from the filtered dataframe\n3. Record the pawpularity score for these samples along with the values of some other popular feature\n4. Plot the samples with the above information","metadata":{}},{"cell_type":"code","source":"def plot_images(images, labels, num_images, num_cols=4, figsize=(15, 8), title=\"Images\"):\n    num_rows = num_images // num_cols\n    \n    _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n    \n    for i, img in enumerate(images):\n        ax[i // num_cols, i % num_cols].imshow(images[i])\n        ax[i // num_cols, i % num_cols].axis(\"off\")\n        ax[i // num_cols, i % num_cols].set_title(labels[i])\n        \n    plt.tight_layout()\n    plt.suptitle(title, x=0.5, y=1.09, fontsize=16)\n    plt.show()\n    \n\ndef filter_df(df, feature, sample_size=12):\n    \n    df = df[df[feature]==1].reset_index(drop=True)\n    indices = np.random.choice(np.arange(len(df)), size=sample_size)\n\n    images, labels = [], []\n\n    for idx in indices:\n        img = df.iloc[idx][\"Id\"]\n        face = df.iloc[idx][\"Face\"]\n        near = df.iloc[idx][\"Near\"]\n        score = df.iloc[idx][\"Pawpularity\"]\n        label = f\"Face: {face} Near: {near} Score: {score}\"\n\n        img_path = str(train_images_dir / img)\n        if os.path.exists(img_path + \".jpg\"):\n            img_path = img_path + \".jpg\"\n        else:\n            img_path = img_path + \".png\"\n\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        images.append(img)\n        labels.append(label)\n    \n    return images, labels","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:59:10.405259Z","iopub.execute_input":"2021-09-23T17:59:10.405664Z","iopub.status.idle":"2021-09-23T17:59:10.418088Z","shell.execute_reply.started":"2021-09-23T17:59:10.405589Z","shell.execute_reply":"2021-09-23T17:59:10.417218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Eyes are visible\nimages, labels = filter_df(train_df, feature=\"Eyes\")\nplot_images(images, labels, num_images=len(images), title=\"Photos where eyes are visible clearly\")","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:22:33.125778Z","iopub.execute_input":"2021-09-23T17:22:33.126072Z","iopub.status.idle":"2021-09-23T17:22:35.748961Z","shell.execute_reply.started":"2021-09-23T17:22:33.126042Z","shell.execute_reply":"2021-09-23T17:22:35.748389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Subject Focus\nimages, labels = filter_df(train_df, feature=\"Subject Focus\")\nplot_images(images, labels, num_images=len(images), title=\"Photos where focus is on the subject\")","metadata":{},"execution_count":null,"outputs":[]}]}