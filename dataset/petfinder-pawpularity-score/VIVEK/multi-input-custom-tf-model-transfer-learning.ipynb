{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" ## Problem description\n\nPetFinder.my uses a basic Cuteness Meter to rank pet photos. It analyzes picture composition and other factors compared to the performance of thousands of pet profiles. \n\nWhile this basic tool is helpful, it's still in an experimental stage and the algorithm could be improved. The participants needs to build an AI model using provided data to help make the tool better.  \n\n**Task** \n\nThe task is to predict engagement with a pet's profile( **Pawpularity** ) based on the photograph for that profile. \n\n**Data** \n\nThe dataset for this competition comprises both images and tabular data(hand-labelled metadata for each photo). \n\nThe train set contains 9912 pet photos \n\nThe test set contains 8 pet photos\n> NOTE: The actual test data comprises about **6800** pet photos similar to the training set photos. \n\n\n####  **Previous Notebooks**: \n1. [*Understanding the problem & EDA*](https://www.kaggle.com/vivmankar/understanding-the-problem-eda) \n2. [*ML RandomForestRegressor*](https://www.kaggle.com/vivmankar/ml-randomforestregressor)\n3. [*CNN_Regressor_using_Transfer_Learning_+_tf.data*](https://www.kaggle.com/vivmankar/cnn-regressor-using-transfer-learning-tf-data)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Overview of the Notebook\n\nIn this notebook we will discuss the Transfer Learning + Multi-input custom model approch to the problem \n\n#### Data preprocessing\n\n>   1. Analyze the datset \n>   2. Create the dataset with two inputs and one output (tf.data.dataset ) \n>   2. Batching ( To speedup the treaning ) \n>   3. Configure the dataset for performance ( To speedup the treaning )\n \n#### Model Building \n\n>   1. Load the base model ( DenseNet ) \n>   2. Develope image and tabular data models\n>   2. Develope a final custom model class  \n>   3. Update last layer activation to ReLU(max_value = 100 ) // this helps improving performence \n>   4. Compile model and add callbacks ( Save-Checkpoint, Early Stopping ) \n>   5. Train Model ( MAE on validation split : 13.5925  ) \n","metadata":{}},{"cell_type":"markdown","source":"## Set up","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nimport os \nimport cv2\nimport random\n \nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split \n\nimport warnings \nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:07:53.993137Z","iopub.execute_input":"2021-10-28T17:07:53.993876Z","iopub.status.idle":"2021-10-28T17:07:58.853683Z","shell.execute_reply.started":"2021-10-28T17:07:53.993789Z","shell.execute_reply":"2021-10-28T17:07:58.852954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TensorFlow version: {}\".format(tf.__version__))\nprint(\"Eager execution: {}\".format(tf.executing_eagerly()))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:07:58.855292Z","iopub.execute_input":"2021-10-28T17:07:58.855565Z","iopub.status.idle":"2021-10-28T17:07:58.861004Z","shell.execute_reply.started":"2021-10-28T17:07:58.855531Z","shell.execute_reply":"2021-10-28T17:07:58.860048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(style= 'darkgrid', \n       color_codes=True,\n       font = 'Arial',\n       font_scale= 1.5,\n       rc={'figure.figsize':(12,8)})","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:00.722905Z","iopub.execute_input":"2021-10-28T17:08:00.723493Z","iopub.status.idle":"2021-10-28T17:08:00.729331Z","shell.execute_reply.started":"2021-10-28T17:08:00.723453Z","shell.execute_reply":"2021-10-28T17:08:00.728373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>div.output_scroll { height: 70em; }</style>\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:01.783757Z","iopub.execute_input":"2021-10-28T17:08:01.784799Z","iopub.status.idle":"2021-10-28T17:08:01.793348Z","shell.execute_reply.started":"2021-10-28T17:08:01.784746Z","shell.execute_reply":"2021-10-28T17:08:01.792349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data ","metadata":{}},{"cell_type":"code","source":"data_dir = \"../input/petfinder-pawpularity-score/train/\"\ntest_dir = \"../input/petfinder-pawpularity-score/test/\"\n\ndata = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntest = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\nss = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:04.113004Z","iopub.execute_input":"2021-10-28T17:08:04.113261Z","iopub.status.idle":"2021-10-28T17:08:04.164953Z","shell.execute_reply.started":"2021-10-28T17:08:04.113232Z","shell.execute_reply":"2021-10-28T17:08:04.164267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.shape)\nprint(test.shape)\nprint(ss.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:07.042933Z","iopub.execute_input":"2021-10-28T17:08:07.043189Z","iopub.status.idle":"2021-10-28T17:08:07.04841Z","shell.execute_reply.started":"2021-10-28T17:08:07.043159Z","shell.execute_reply":"2021-10-28T17:08:07.047595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:07.88282Z","iopub.execute_input":"2021-10-28T17:08:07.883202Z","iopub.status.idle":"2021-10-28T17:08:07.906253Z","shell.execute_reply.started":"2021-10-28T17:08:07.883166Z","shell.execute_reply":"2021-10-28T17:08:07.90558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analyze the data","metadata":{}},{"cell_type":"code","source":"_, axs = plt.subplots( 2, 2, figsize=(15, 12))\n\naxs = axs.flatten()\ncol = data.columns.tolist() \n\nfor a, ax in zip(data.sample(4).iterrows(), axs):\n    img = cv2.imread(data_dir + f'{a[1][0]}.jpg')\n    img = cv2.resize(img, (600, 600))\n    other_info = [col[i] for i in range(13) if a[1][i] == 1 ]\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(img)\n    ax.set_title(f'Id: {a[0]}, Pawpularity : {a[1][13]}, ' + \", \".join(other_info), fontsize= 12, fontweight='bold' )\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:17.878499Z","iopub.execute_input":"2021-10-28T17:08:17.879026Z","iopub.status.idle":"2021-10-28T17:08:18.557885Z","shell.execute_reply.started":"2021-10-28T17:08:17.878989Z","shell.execute_reply":"2021-10-28T17:08:18.557203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(data[\"Pawpularity\"])\nplt.title(\"Distribution of Pawpularity\")","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:20.372843Z","iopub.execute_input":"2021-10-28T17:08:20.373118Z","iopub.status.idle":"2021-10-28T17:08:20.97733Z","shell.execute_reply.started":"2021-10-28T17:08:20.373087Z","shell.execute_reply":"2021-10-28T17:08:20.976668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data preprocessing","metadata":{}},{"cell_type":"code","source":"train,val  = train_test_split( data, test_size=0.2)  ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:41.283191Z","iopub.execute_input":"2021-10-28T17:08:41.283936Z","iopub.status.idle":"2021-10-28T17:08:41.290063Z","shell.execute_reply.started":"2021-10-28T17:08:41.283899Z","shell.execute_reply":"2021-10-28T17:08:41.289342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:41.847638Z","iopub.execute_input":"2021-10-28T17:08:41.848246Z","iopub.status.idle":"2021-10-28T17:08:41.853479Z","shell.execute_reply.started":"2021-10-28T17:08:41.848208Z","shell.execute_reply":"2021-10-28T17:08:41.852637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:42.582586Z","iopub.execute_input":"2021-10-28T17:08:42.583169Z","iopub.status.idle":"2021-10-28T17:08:42.588011Z","shell.execute_reply.started":"2021-10-28T17:08:42.583133Z","shell.execute_reply":"2021-10-28T17:08:42.58713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:48.203112Z","iopub.execute_input":"2021-10-28T17:08:48.2034Z","iopub.status.idle":"2021-10-28T17:08:48.208726Z","shell.execute_reply.started":"2021-10-28T17:08:48.203368Z","shell.execute_reply":"2021-10-28T17:08:48.208016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = tf.constant(train.Id.map(lambda x : data_dir + f'{x}.jpg' ).tolist())\nfeaturs = tf.constant(train[['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory','Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']])\nlabels = tf.constant( train.Pawpularity.tolist())\n\ndataset = tf.data.Dataset.from_tensor_slices(( {\"input_1\": filenames, \"input_2\": featurs }, labels))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:08:56.312906Z","iopub.execute_input":"2021-10-28T17:08:56.313175Z","iopub.status.idle":"2021-10-28T17:08:56.331075Z","shell.execute_reply.started":"2021-10-28T17:08:56.313138Z","shell.execute_reply":"2021-10-28T17:08:56.330354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nval_filenames = tf.constant(val.Id.map(lambda x : data_dir + f'{x}.jpg' ).tolist())\nval_featurs = tf.constant(val[['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory','Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']])\nval_labels = tf.constant( val.Pawpularity.tolist() )\n\n\nval_dataset = tf.data.Dataset.from_tensor_slices(({\"input_1\": val_filenames, \"input_2\": val_featurs }, val_labels))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:04.538151Z","iopub.execute_input":"2021-10-28T17:09:04.538848Z","iopub.status.idle":"2021-10-28T17:09:04.550823Z","shell.execute_reply.started":"2021-10-28T17:09:04.538809Z","shell.execute_reply":"2021-10-28T17:09:04.54998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(dataset.as_numpy_iterator())[:5]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:04.682122Z","iopub.execute_input":"2021-10-28T17:09:04.682352Z","iopub.status.idle":"2021-10-28T17:09:06.123049Z","shell.execute_reply.started":"2021-10-28T17:09:04.682324Z","shell.execute_reply":"2021-10-28T17:09:06.122288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Hyperparams \n\nBATCH_SIZE = 64\nIMG_SIZE = ( 224 ,  224) ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:13.489077Z","iopub.execute_input":"2021-10-28T17:09:13.489945Z","iopub.status.idle":"2021-10-28T17:09:13.494108Z","shell.execute_reply.started":"2021-10-28T17:09:13.489898Z","shell.execute_reply":"2021-10-28T17:09:13.493356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### File names to images","metadata":{}},{"cell_type":"code","source":"def _parse_function( inputs,  output):\n\n    filename = inputs[\"input_1\"]\n\n    image_string = tf.io.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string)\n    image_resized = tf.image.resize(image_decoded, IMG_SIZE)\n\n    inputs[\"input_1\"] = image_resized\n\n    return  inputs, output","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:15.598202Z","iopub.execute_input":"2021-10-28T17:09:15.598886Z","iopub.status.idle":"2021-10-28T17:09:15.604173Z","shell.execute_reply.started":"2021-10-28T17:09:15.598848Z","shell.execute_reply":"2021-10-28T17:09:15.603022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(_parse_function)\nval_dataset = val_dataset.map(_parse_function)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:16.807862Z","iopub.execute_input":"2021-10-28T17:09:16.808128Z","iopub.status.idle":"2021-10-28T17:09:16.904531Z","shell.execute_reply.started":"2021-10-28T17:09:16.808093Z","shell.execute_reply":"2021-10-28T17:09:16.903734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print one key val pair \ndef print_pair( input, output):\n\n    image = input[\"input_1\"]\n    feature = input[\"input_2\"]\n\n    print(feature.numpy())\n    print(feature.numpy().shape)\n\n    plt.figure()\n    plt.imshow((image.numpy()).astype(np.uint8))\n    plt.title( output.numpy())\n    plt.axis('off')\n    plt.show()\n    print(\"\\n\\n\\n\")\n\n\nfor input, output  in dataset.take(2):\n    print_pair(input, output)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:29.158324Z","iopub.execute_input":"2021-10-28T17:09:29.159058Z","iopub.status.idle":"2021-10-28T17:09:29.779024Z","shell.execute_reply.started":"2021-10-28T17:09:29.15902Z","shell.execute_reply":"2021-10-28T17:09:29.778213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Perfomence Optimization ","metadata":{}},{"cell_type":"code","source":"dataset = dataset.batch(BATCH_SIZE) \nval_dataset = val_dataset.batch(BATCH_SIZE) ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:38.143759Z","iopub.execute_input":"2021-10-28T17:09:38.144512Z","iopub.status.idle":"2021-10-28T17:09:38.151513Z","shell.execute_reply.started":"2021-10-28T17:09:38.14447Z","shell.execute_reply":"2021-10-28T17:09:38.150461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" \n* **Dataset.cache** keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n* **Dataset.prefetch** overlaps data preprocessing and model execution while training.\n ","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\ndataset = dataset.cache().shuffle(500).prefetch(buffer_size=AUTOTUNE)\nval_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE) ## We dont need to shuffel the validation data ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:38.97314Z","iopub.execute_input":"2021-10-28T17:09:38.973458Z","iopub.status.idle":"2021-10-28T17:09:38.986086Z","shell.execute_reply.started":"2021-10-28T17:09:38.973419Z","shell.execute_reply":"2021-10-28T17:09:38.985272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"markdown","source":"### Download base model \n\nWe will use DenseNet121 as a base model, other opctions for pretrained models can be found [here](https://keras.io/api/applications/)","metadata":{}},{"cell_type":"code","source":"base_image_model = tf.keras.applications.DenseNet121( \n                                               include_top=False,\n                                               weights='imagenet'\n                                               )","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:39.842799Z","iopub.execute_input":"2021-10-28T17:09:39.843575Z","iopub.status.idle":"2021-10-28T17:09:45.220675Z","shell.execute_reply.started":"2021-10-28T17:09:39.843529Z","shell.execute_reply":"2021-10-28T17:09:45.219923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_image_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:09:47.323098Z","iopub.execute_input":"2021-10-28T17:09:47.323782Z","iopub.status.idle":"2021-10-28T17:09:47.343343Z","shell.execute_reply.started":"2021-10-28T17:09:47.32374Z","shell.execute_reply":"2021-10-28T17:09:47.34228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ProcessImageBlock(tf.keras.Model):\n\n    def __init__(self):\n\n        super(ProcessImageBlock, self).__init__()\n\n        self.input_l = tf.keras.layers.InputLayer( input_shape = IMG_SIZE + (3,)  ) \n        self.base_model = base_image_model\n        self.preprocess_input = tf.keras.applications.densenet.preprocess_input \n        \n        self.data_augmentation = tf.keras.Sequential([\n                                tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n                                tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n                                ])\n        self.rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n        self.gap = tf.keras.layers.GlobalAveragePooling2D() ##  ( batch_size , 2048 )\n\n        self.activation = tf.keras.layers.ReLU()\n        self.dense = tf.keras.layers.Dense(512, activation= self.activation )\n        self.final = tf.keras.layers.Dense(64, activation= self.activation )\n\n        \n    def call(self, input_tensor):\n\n        x = self.input_l(input_tensor)\n        x = self.data_augmentation(x)\n        x = self.preprocess_input(x)\n        x = self.base_model(x, training=False)\n        x = self.gap(x)\n\n        x = self.dense(x)\n        x = self.final(x)\n \n        return  x\n\nclass ProcessTabBlock(tf.keras.Model):\n\n    def __init__(self):\n\n        super(ProcessTabBlock, self).__init__()\n\n        self.input_l = tf.keras.layers.InputLayer( input_shape = (12,)  ) \n        self.layer_1 = tf.keras.layers.Dense(32, activation='relu')\n        self.layer_2 = tf.keras.layers.Dense(64, activation='relu')\n        \n    def call(self, input_tensor ):\n        \n        x = self.input_l(input_tensor)\n        x = self.layer_1(x)\n        x = self.layer_2(x)\n\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:10:55.284629Z","iopub.execute_input":"2021-10-28T17:10:55.284913Z","iopub.status.idle":"2021-10-28T17:10:55.297137Z","shell.execute_reply.started":"2021-10-28T17:10:55.284883Z","shell.execute_reply":"2021-10-28T17:10:55.296329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyCustomModel(tf.keras.Model):\n\n    def __init__(self):\n\n        super(MyCustomModel, self).__init__()\n\n        self.process_image_data = ProcessImageBlock()\n        self.process_tabular_data = ProcessTabBlock()\n\n        self.activation_1 = tf.keras.layers.LeakyReLU( alpha=0.3)\n        self.activation_2 = tf.keras.layers.ReLU()\n        self.activation_final = tf.keras.layers.ReLU(max_value = 100 )\n        self.dropout = tf.keras.layers.Dropout(0.2) \n\n        self.dense_1 =   tf.keras.layers.Dense(64,activation= self.activation_1  )\n        self.dense_2 =   tf.keras.layers.Dense(8,activation=  self.activation_2  )\n        self.final =   tf.keras.layers.Dense(1, activation=  self.activation_final )\n    \n    def call(self, inputs ): \n\n        image = inputs[\"input_1\"]\n        feature = inputs[\"input_2\"]\n\n        x1 = self.process_image_data(image)\n        x2 = self.process_tabular_data(feature)\n\n        x = tf.keras.layers.concatenate([x1, x2])## ( batch_size, 128 )\n\n        x = self.dense_1(x)\n        x = self.dropout(x)\n        x = self.dense_2(x)\n\n        x = self.final(x)\n   \n        return  x","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:23:16.618738Z","iopub.execute_input":"2021-10-28T17:23:16.619003Z","iopub.status.idle":"2021-10-28T17:23:16.628891Z","shell.execute_reply.started":"2021-10-28T17:23:16.618975Z","shell.execute_reply":"2021-10-28T17:23:16.62805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compile and Train","metadata":{}},{"cell_type":"code","source":"def create_model():\n    \n    model = MyCustomModel()\n    \n    model.compile(\n        optimizer='adam', \n        loss=\"mse\", # Mean squared error \n        metrics=[\"mae\"] # Mean Absolute Error\n      )\n    \n    return model ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:23:20.427991Z","iopub.execute_input":"2021-10-28T17:23:20.428443Z","iopub.status.idle":"2021-10-28T17:23:20.433437Z","shell.execute_reply.started":"2021-10-28T17:23:20.428404Z","shell.execute_reply":"2021-10-28T17:23:20.432336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:23:23.433622Z","iopub.execute_input":"2021-10-28T17:23:23.434636Z","iopub.status.idle":"2021-10-28T17:23:23.494676Z","shell.execute_reply.started":"2021-10-28T17:23:23.434583Z","shell.execute_reply":"2021-10-28T17:23:23.493811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\n\ncheckpoint_path = \"cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n\nes_callback = tf.keras.callbacks.EarlyStopping(\n                                monitor='val_mae',\n                                patience=3,\n                                verbose=1,\n                                restore_best_weights=True)\n\nhistory = model.fit(\n                    dataset,\n                    validation_data = val_dataset, \n                    epochs=epochs,\n                    callbacks = [cp_callback , es_callback ] ,\n                    )","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:23:24.392912Z","iopub.execute_input":"2021-10-28T17:23:24.393258Z","iopub.status.idle":"2021-10-28T17:25:20.412873Z","shell.execute_reply.started":"2021-10-28T17:23:24.393227Z","shell.execute_reply":"2021-10-28T17:25:20.41199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the saved model ","metadata":{}},{"cell_type":"code","source":"saved_checkpoint_path = \"cp.ckpt\"","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:25:33.033399Z","iopub.execute_input":"2021-10-28T17:25:33.03426Z","iopub.status.idle":"2021-10-28T17:25:33.038935Z","shell.execute_reply.started":"2021-10-28T17:25:33.034212Z","shell.execute_reply":"2021-10-28T17:25:33.037651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a basic model instance\nnew_model = create_model()\n\n# Loads the weights\nnew_model.load_weights(saved_checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:25:33.552482Z","iopub.execute_input":"2021-10-28T17:25:33.553365Z","iopub.status.idle":"2021-10-28T17:25:36.309965Z","shell.execute_reply.started":"2021-10-28T17:25:33.553315Z","shell.execute_reply":"2021-10-28T17:25:36.30915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict on test data","metadata":{}},{"cell_type":"code","source":"def _parse_function_test( inputs):\n\n    filename = inputs[\"input_1\"]\n\n    image_string = tf.io.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string)\n    image_resized = tf.image.resize(image_decoded, IMG_SIZE)\n\n    inputs[\"input_1\"] = image_resized\n\n    return  inputs","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:25:38.082576Z","iopub.execute_input":"2021-10-28T17:25:38.082842Z","iopub.status.idle":"2021-10-28T17:25:38.088111Z","shell.execute_reply.started":"2021-10-28T17:25:38.082811Z","shell.execute_reply":"2021-10-28T17:25:38.087239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_filenames = tf.constant(test.Id.map(lambda x : test_dir + f'{x}.jpg' ).tolist())\ntest_featurs = tf.constant(test[['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory','Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']])\n \ntest_dataset = tf.data.Dataset.from_tensor_slices(({\"input_1\": test_filenames, \"input_2\": test_featurs }))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:28:02.268828Z","iopub.execute_input":"2021-10-28T17:28:02.26964Z","iopub.status.idle":"2021-10-28T17:28:02.279273Z","shell.execute_reply.started":"2021-10-28T17:28:02.269597Z","shell.execute_reply":"2021-10-28T17:28:02.278191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = test_dataset.map(_parse_function_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:28:02.544404Z","iopub.execute_input":"2021-10-28T17:28:02.544997Z","iopub.status.idle":"2021-10-28T17:28:02.562399Z","shell.execute_reply.started":"2021-10-28T17:28:02.54496Z","shell.execute_reply":"2021-10-28T17:28:02.561754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = test_dataset.batch(len(test))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:28:02.73268Z","iopub.execute_input":"2021-10-28T17:28:02.732915Z","iopub.status.idle":"2021-10-28T17:28:02.737593Z","shell.execute_reply.started":"2021-10-28T17:28:02.732888Z","shell.execute_reply":"2021-10-28T17:28:02.736805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = new_model.predict(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:28:03.013114Z","iopub.execute_input":"2021-10-28T17:28:03.013393Z","iopub.status.idle":"2021-10-28T17:28:03.092408Z","shell.execute_reply.started":"2021-10-28T17:28:03.013361Z","shell.execute_reply":"2021-10-28T17:28:03.091671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:28:03.847818Z","iopub.execute_input":"2021-10-28T17:28:03.848081Z","iopub.status.idle":"2021-10-28T17:28:03.860356Z","shell.execute_reply.started":"2021-10-28T17:28:03.848049Z","shell.execute_reply":"2021-10-28T17:28:03.85926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission[\"Id\"] = test[\"Id\"]\nsubmission[\"Pawpularity\"]= predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:28:04.392474Z","iopub.execute_input":"2021-10-28T17:28:04.3927Z","iopub.status.idle":"2021-10-28T17:28:04.398667Z","shell.execute_reply.started":"2021-10-28T17:28:04.392672Z","shell.execute_reply":"2021-10-28T17:28:04.397682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:28:05.432718Z","iopub.execute_input":"2021-10-28T17:28:05.432978Z","iopub.status.idle":"2021-10-28T17:28:05.441865Z","shell.execute_reply.started":"2021-10-28T17:28:05.432949Z","shell.execute_reply":"2021-10-28T17:28:05.44123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss.columns.equals(submission.columns)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:28:05.812555Z","iopub.execute_input":"2021-10-28T17:28:05.812983Z","iopub.status.idle":"2021-10-28T17:28:05.820055Z","shell.execute_reply.started":"2021-10-28T17:28:05.812948Z","shell.execute_reply":"2021-10-28T17:28:05.819038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T17:28:06.877637Z","iopub.execute_input":"2021-10-28T17:28:06.878231Z","iopub.status.idle":"2021-10-28T17:28:06.888194Z","shell.execute_reply.started":"2021-10-28T17:28:06.878191Z","shell.execute_reply":"2021-10-28T17:28:06.887462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion:\n\n> #### In the [*last notebook*](https://www.kaggle.com/vivmankar/cnn-regressor-using-transfer-learning-tf-data) we saw the approach that uses only image data, the test_mae was 15.1742, \n> #### while in this approach we have achieved the test_mae of **13.5925** on the same test split, which is an improvement.","metadata":{}}]}