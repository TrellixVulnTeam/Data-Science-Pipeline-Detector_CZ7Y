{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-04T04:28:27.689243Z","iopub.execute_input":"2021-10-04T04:28:27.689848Z","iopub.status.idle":"2021-10-04T04:28:27.782375Z","shell.execute_reply.started":"2021-10-04T04:28:27.68977Z","shell.execute_reply":"2021-10-04T04:28:27.781572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install timm\n!pip install '../input/timm-package/timm-0.4.12-py3-none-any.whl'\n# !pip install -qq albumentations==1.0.3\n# !pip install -qq grad-cam\n# !pip install -qq ttach","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:28:29.083616Z","iopub.execute_input":"2021-10-04T04:28:29.083886Z","iopub.status.idle":"2021-10-04T04:28:57.584696Z","shell.execute_reply.started":"2021-10-04T04:28:29.083839Z","shell.execute_reply":"2021-10-04T04:28:57.583853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nfrom tqdm.auto import tqdm\nfrom collections import defaultdict\nimport pandas as pd\nimport numpy as np\nimport os\nimport random\nimport gc\nimport cv2\nimport sys\ngc.enable()\npd.set_option('display.max_columns', None)\n\n\n# General\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport glob\nimport random\nimport cv2\npd.set_option('display.max_columns', None)\n\n\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\n\n# Visialisation\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\n\n# Image Aug\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# Deep Learning\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR\nimport torch\nimport torchvision\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\nimport timm\n\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n#Metrics\nfrom sklearn.metrics import mean_squared_error\n\n# Random Seed Initialize\nRANDOM_SEED = 2021\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()\n\n# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:28:57.586611Z","iopub.execute_input":"2021-10-04T04:28:57.586885Z","iopub.status.idle":"2021-10-04T04:29:04.542017Z","shell.execute_reply.started":"2021-10-04T04:28:57.586833Z","shell.execute_reply":"2021-10-04T04:29:04.541304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_dir = '../input/petfinder-pawpularity-score'\ntest_dir = '../input/petfinder-pawpularity-score/test'\ntest_file = '../input/petfinder-pawpularity-score/test.csv'\nsample_sub_file_path = os.path.join(csv_dir, 'sample_submission.csv')\ntest_df = pd.read_csv(test_file)\n\nsample_df = pd.read_csv(sample_sub_file_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:29:04.544462Z","iopub.execute_input":"2021-10-04T04:29:04.544692Z","iopub.status.idle":"2021-10-04T04:29:04.565614Z","shell.execute_reply.started":"2021-10-04T04:29:04.544667Z","shell.execute_reply":"2021-10-04T04:29:04.564933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def return_filpath(name, folder=None):\n    path = os.path.join(folder, f'{name}.jpg')\n    return path\ntest_df['image_path'] = test_df['Id'].apply(lambda x: return_filpath(x, folder=test_dir))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:29:04.567304Z","iopub.execute_input":"2021-10-04T04:29:04.567507Z","iopub.status.idle":"2021-10-04T04:29:04.598521Z","shell.execute_reply.started":"2021-10-04T04:29:04.567483Z","shell.execute_reply":"2021-10-04T04:29:04.597635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_test = {\n    'model': 'tf_efficientnet_b0_ns',\n    'dense_features': ['Subject Focus', 'Eyes', 'Face', 'Near',\n                       'Action', 'Accessory', 'Group', 'Collage',\n                       'Human', 'Occlusion', 'Info', 'Blur'],\n    'pretrained': False,\n    'inp_channels': 3,\n    'im_size': 256,\n    'device': device,\n    'batch_size': 32,\n    'num_workers' : 2,\n    'out_features': 1,\n    'debug': False\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:29:04.599844Z","iopub.execute_input":"2021-10-04T04:29:04.600135Z","iopub.status.idle":"2021-10-04T04:29:04.607902Z","shell.execute_reply.started":"2021-10-04T04:29:04.600098Z","shell.execute_reply":"2021-10-04T04:29:04.607086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_transforms(DIM = params_test['im_size']):\n    return albumentations.Compose(\n        [\n          albumentations.Resize(DIM,DIM),\n          albumentations.Normalize(\n              mean=[0.485, 0.456, 0.406],\n              std=[0.229, 0.224, 0.225],\n              ),\n          ToTensorV2(p=1.0)\n        ]\n    )\n\n\nclass PawDataset(Dataset):\n    def __init__(self, images_filepaths, dense_features, targets, transform=None):\n        self.images_filepaths = images_filepaths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        \n        dense = self.dense_features[idx, :]\n        label = torch.tensor(self.targets[idx]).float()\n        return image, dense, label\n    \n    \nclass PawPetNet(nn.Module):\n    def __init__(self, model_name=params_test['model'], out_features=params_test['out_features'], inp_channels=params_test['inp_channels'],\n                 pretrained=params_test['pretrained'], num_dense=len(params_test['dense_features'])):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n        if model_name.split('_')[0] == 'efficientnet':\n            out_channels = self.model.conv_stem.out_channels\n            kernel_size = self.model.conv_stem.kernel_size\n            stride = self.model.conv_stem.stride\n            padding = self.model.conv_stem.padding\n            bias = self.model.conv_stem.bias\n            self.model.conv_stem = nn.Conv2d(inp_channels, out_channels,\n                                             kernel_size=kernel_size, stride=stride,\n                                             padding=padding, bias=bias)\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Identity()\n        elif model_name.split('_')[0] == 'nfnet':\n            n_features = self.model.head.fc.in_features\n            self.model.head.fc = nn.Identity()\n        elif model_name in ['resnet18d', 'resnet50d', 'resnet152d',\n                            'seresnet50', 'seresnext26d_32x4d', 'seresnext50_32x4d',\n                            'resnetblur18', 'resnetblur50']:\n            n_features = self.model.fc.in_features\n            self.model.fc = nn.Identity()\n        else:\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Identity()\n\n        self.dropout = nn.Dropout(0.2)\n        self.fc = nn.Linear(n_features + num_dense, out_features)\n    \n    def forward(self, image, dense):\n        embeddings = self.model(image)\n        x = self.dropout(embeddings)\n        x = torch.cat([x, dense], dim=1)\n        output = self.fc(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:29:04.611241Z","iopub.execute_input":"2021-10-04T04:29:04.611449Z","iopub.status.idle":"2021-10-04T04:29:04.630556Z","shell.execute_reply.started":"2021-10-04T04:29:04.611421Z","shell.execute_reply":"2021-10-04T04:29:04.629788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_dir = '../input/pawpularity-score-starter'\nprint(f'Models path: {models_dir}')","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:29:04.631737Z","iopub.execute_input":"2021-10-04T04:29:04.632473Z","iopub.status.idle":"2021-10-04T04:29:04.640256Z","shell.execute_reply.started":"2021-10-04T04:29:04.632404Z","shell.execute_reply":"2021-10-04T04:29:04.639395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n        \npredicted_labels = None\nfor model_name in glob.glob(models_dir + '/*.pth'):\n    print(model_name)\n    model = PawPetNet()\n    model.load_state_dict(torch.load(model_name))\n    model = model.to(params_test['device'])\n#     print(model.eval())\n\n    test_dataset = PawDataset(\n        images_filepaths = test_df['image_path'].values,\n        dense_features = test_df[params_test['dense_features']].values,\n        targets = sample_df['Pawpularity'].values,\n        transform = get_test_transforms()\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=params_test['batch_size'],\n        shuffle=False, num_workers=params_test['num_workers'],\n        pin_memory=True\n    )\n\n    temp_preds = None\n    with torch.no_grad():\n        for (images, dense, target) in tqdm(test_loader, desc=f'Predicting. '):\n            images = images.to(params_test['device'], non_blocking=True)\n            dense = dense.to(params_test['device'], non_blocking=True)\n            predictions = model(images, dense).to('cpu').numpy()\n            \n            if temp_preds is None:\n                temp_preds = predictions\n            else:\n                temp_preds = np.vstack((temp_preds, predictions))\n#     print(temp_preds)\n    if predicted_labels is None:\n        predicted_labels = temp_preds\n    else:\n        predicted_labels += temp_preds\n        \n        \npredicted_labels /= (len(glob.glob(models_dir + '/*.pth')))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:32:24.825657Z","iopub.execute_input":"2021-10-04T04:32:24.826039Z","iopub.status.idle":"2021-10-04T04:32:27.576116Z","shell.execute_reply.started":"2021-10-04T04:32:24.826004Z","shell.execute_reply":"2021-10-04T04:32:27.5752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame()\nsub_df['Id'] = test_df['Id']\nsub_df['Pawpularity'] = predicted_labels","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:32:29.79793Z","iopub.execute_input":"2021-10-04T04:32:29.798722Z","iopub.status.idle":"2021-10-04T04:32:29.809775Z","shell.execute_reply.started":"2021-10-04T04:32:29.798682Z","shell.execute_reply":"2021-10-04T04:32:29.809053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['Pawpularity'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:33:21.359697Z","iopub.execute_input":"2021-10-04T04:33:21.360229Z","iopub.status.idle":"2021-10-04T04:33:21.373753Z","shell.execute_reply.started":"2021-10-04T04:33:21.360192Z","shell.execute_reply":"2021-10-04T04:33:21.372844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}