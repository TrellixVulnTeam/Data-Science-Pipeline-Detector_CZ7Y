{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## prepare training and validation data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nimport cv2\nimport os\n\nseed = 1\nbase_dir='/kaggle/input/petfinder-pawpularity-score/'\nimage_size=224\n\ndf = pd.read_csv(os.path.join(base_dir,\"train.csv\"))\ndf['filename'] = df.apply(lambda row: row['Id']+'.jpg',axis=1)\ndf['y']=df.apply(lambda row:row[\"Pawpularity\"]/100,axis=1)\n\ndef prep_fn(img):\n    img = img.astype(np.float32) / 255.0\n    return img\n\ndata_gen_args = dict(preprocessing_function=prep_fn,\n                     width_shift_range=0.2,\n                     height_shift_range=0.2,\n                     zoom_range=0.1,\n                     rotation_range=20,\n                     horizontal_flip=True,\n                     vertical_flip=False,\n                     validation_split=0.1)\n\ntrain_datagen = ImageDataGenerator(**data_gen_args)\nval_datagen = ImageDataGenerator(preprocessing_function=prep_fn,validation_split=0.1)\n\ntrain_generator = train_datagen.flow_from_dataframe(dataframe=df,\n                                                    directory=base_dir+'train/',\n                                                    x_col='filename',\n                                                    y_col=[\"y\"],\n                                                    subset=\"training\",\n                                                    batch_size = 32,\n                                                    seed=seed,\n                                                    shuffle=True,\n                                                    class_mode='raw',\n                                                    target_size=(224,224))\nval_generator = val_datagen.flow_from_dataframe(dataframe=df,\n                                                directory=base_dir+'train/',\n                                                x_col='filename',\n                                                y_col=[\"y\"],\n                                                subset=\"validation\",\n                                                batch_size = 32,\n                                                seed=seed,\n                                                shuffle=True,\n                                                class_mode='raw',\n                                                target_size=(224,224))","metadata":{"execution":{"iopub.status.busy":"2021-12-27T22:49:12.57476Z","iopub.execute_input":"2021-12-27T22:49:12.575157Z","iopub.status.idle":"2021-12-27T22:49:16.481077Z","shell.execute_reply.started":"2021-12-27T22:49:12.575111Z","shell.execute_reply":"2021-12-27T22:49:16.480064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Test data","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(os.path.join(base_dir,\"test.csv\"))\ndf_test['filename'] = df_test.apply(lambda row: row['Id']+'.jpg',axis=1)\ndf_test['y']=0\ntest_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\ntest_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n                                                directory=base_dir+'test/',\n                                                x_col='filename',\n                                                y_col=['y'],\n                                                batch_size = 32,\n                                                shuffle=False,\n                                                class_mode='raw',\n                                                target_size=(224,224))","metadata":{"execution":{"iopub.status.busy":"2021-12-27T22:49:16.482992Z","iopub.execute_input":"2021-12-27T22:49:16.483224Z","iopub.status.idle":"2021-12-27T22:49:16.506309Z","shell.execute_reply.started":"2021-12-27T22:49:16.483195Z","shell.execute_reply":"2021-12-27T22:49:16.505412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"projection_dim = 128\nconv_filters = [32,64, projection_dim]\nnum_patches = (image_size//2**(len(conv_filters))) **2\nnum_heads = 3","metadata":{"execution":{"iopub.status.busy":"2021-12-27T22:49:16.507818Z","iopub.execute_input":"2021-12-27T22:49:16.508231Z","iopub.status.idle":"2021-12-27T22:49:16.514438Z","shell.execute_reply.started":"2021-12-27T22:49:16.508175Z","shell.execute_reply":"2021-12-27T22:49:16.513134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"def mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = L.Dense(units, activation = tf.nn.gelu)(x)\n        x = L.Dropout(dropout_rate)(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-12-27T22:49:16.517441Z","iopub.execute_input":"2021-12-27T22:49:16.518123Z","iopub.status.idle":"2021-12-27T22:49:16.526588Z","shell.execute_reply.started":"2021-12-27T22:49:16.518062Z","shell.execute_reply":"2021-12-27T22:49:16.525424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CCTTokenizer(L.Layer):\n    def __init__(self):\n        super(CCTTokenizer, self).__init__()\n        self.num_patches = num_patches\n        self.projection_dim = projection_dim\n        self.conv_model = keras.Sequential()\n        for i in conv_filters:\n            self.conv_model.add(\n                L.Conv2D(i,(3,3),activation='relu', padding='same')\n            )\n            self.conv_model.add(\n                L.MaxPool2D((2, 2), strides=(2, 2))\n            )\n        \n        self.position_embedding = L.Embedding(\n            input_dim = self.num_patches, output_dim = self.projection_dim\n        )\n\n    def call(self, images):\n        outputs = self.conv_model(images)\n        positions = tf.range(start = 0, limit = self.num_patches, delta = 1)\n        #print(outputs.shape)\n        reshaped = tf.reshape(\n            outputs,\n            (-1, tf.shape(outputs)[1] * tf.shape(outputs)[2], tf.shape(outputs)[-1]),\n        )+ self.position_embedding(positions)\n        #print(tf.shape(reshaped), self.position_embedding(positions).shape)\n        return reshaped","metadata":{"execution":{"iopub.status.busy":"2021-12-27T22:49:16.52846Z","iopub.execute_input":"2021-12-27T22:49:16.528982Z","iopub.status.idle":"2021-12-27T22:49:16.543193Z","shell.execute_reply.started":"2021-12-27T22:49:16.528851Z","shell.execute_reply":"2021-12-27T22:49:16.542108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def attention_block(inputs, key_dim, mlp_dim,dropout=0.1):\n    x = L.LayerNormalization(epsilon = 1e-6)(inputs)\n    attention_output = L.MultiHeadAttention(\n        num_heads = num_heads, key_dim = key_dim, dropout = dropout\n    )(x, x)\n    if(inputs.shape[-1]==key_dim):\n        x = L.Add()([inputs,attention_output])\n    skip = x\n    x = L.LayerNormalization(epsilon = 1e-6)(x)\n    x = mlp(x, hidden_units = mlp_dim, dropout_rate = dropout)\n    if(skip.shape[-1]==x.shape[-1]):\n        x = L.Add()([skip,x])\n    return x\n\ndef vision_transformer():\n    inputs = L.Input(shape = (image_size, image_size, 3))\n\n    #conv_features= convolution_block(inputs)\n\n    # Encode patches.\n    x = CCTTokenizer()(inputs)\n\n    for i in range(4):\n        x = attention_block(x, 128, [256,128], 0.05)\n\n\n    # Create a [batch_size, projection_dim] tensor.\n    x = L.LayerNormalization(epsilon = 1e-6)(x)\n\n    x = x[:,0,:]\n    #x = L.GlobalAveragePooling1D()(x) \n\n    x = L.Dense(64,activation='relu')(x)\n    out = L.Dense(1,activation='sigmoid')(x)\n    \n    # Create the model.\n    model = tf.keras.Model(inputs = inputs, outputs = out)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-27T23:08:30.970226Z","iopub.execute_input":"2021-12-27T23:08:30.970869Z","iopub.status.idle":"2021-12-27T23:08:30.98292Z","shell.execute_reply.started":"2021-12-27T23:08:30.97083Z","shell.execute_reply":"2021-12-27T23:08:30.981872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true))) \nmodel = vision_transformer()\nmodel.compile(optimizer = Adam(learning_rate=0.001), \n              loss=root_mean_squared_error)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T23:08:33.893308Z","iopub.execute_input":"2021-12-27T23:08:33.894127Z","iopub.status.idle":"2021-12-27T23:08:34.452493Z","shell.execute_reply.started":"2021-12-27T23:08:33.894093Z","shell.execute_reply":"2021-12-27T23:08:34.451517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T22:49:17.223129Z","iopub.execute_input":"2021-12-27T22:49:17.223481Z","iopub.status.idle":"2021-12-27T22:49:17.265904Z","shell.execute_reply.started":"2021-12-27T22:49:17.223424Z","shell.execute_reply":"2021-12-27T22:49:17.265013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\nr=model.fit(train_generator, validation_data=val_generator,\n            validation_steps=28,steps_per_epoch=279,epochs=100,callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2021-12-27T23:08:39.54588Z","iopub.execute_input":"2021-12-27T23:08:39.546169Z","iopub.status.idle":"2021-12-27T23:27:49.166662Z","shell.execute_reply.started":"2021-12-27T23:08:39.546141Z","shell.execute_reply":"2021-12-27T23:27:49.165707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred=model.predict(test_generator)\nsubmission=pd.read_csv(os.path.join(base_dir,\"sample_submission.csv\"))\nsubmission[\"Pawpularity\"]=ypred*100\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T23:29:32.924691Z","iopub.execute_input":"2021-12-27T23:29:32.924982Z","iopub.status.idle":"2021-12-27T23:29:32.948612Z","shell.execute_reply.started":"2021-12-27T23:29:32.924954Z","shell.execute_reply":"2021-12-27T23:29:32.947757Z"},"trusted":true},"execution_count":null,"outputs":[]}]}