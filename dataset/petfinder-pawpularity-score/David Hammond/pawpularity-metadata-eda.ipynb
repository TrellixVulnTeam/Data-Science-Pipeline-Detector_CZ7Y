{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Exploratory Data Analysis of Metadata**\n\nThis dataset includes metadata in addition to the image data. We can ask if the metadata has predictive value for the Pawpularity score. One simple way to investigate is to look at the conditional histograms of the Pawpularity, conditioned on the different values of the metadata. In this notebook, I show this simple data analysis.\n","metadata":{}},{"cell_type":"code","source":"# imports and load data set\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndatadir ='../input/petfinder-pawpularity-score/'\ndf_train=pd.read_csv(datadir+'train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T22:43:37.027927Z","iopub.execute_input":"2021-10-18T22:43:37.028508Z","iopub.status.idle":"2021-10-18T22:43:37.36444Z","shell.execute_reply.started":"2021-10-18T22:43:37.028449Z","shell.execute_reply":"2021-10-18T22:43:37.363437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2021-10-18T22:43:37.369063Z","iopub.execute_input":"2021-10-18T22:43:37.369277Z","iopub.status.idle":"2021-10-18T22:43:37.389277Z","shell.execute_reply.started":"2021-10-18T22:43:37.36925Z","shell.execute_reply":"2021-10-18T22:43:37.388404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each metadata feature is binary. We can first look at the value counts for each metadata feature. If nearly all of the values were 0 or nearly all were 1 for a particular feature, then it would be unlikely that that feature would be helpful.","metadata":{}},{"cell_type":"code","source":"metadata_names=df_train.columns[1:-1]\nfor m in metadata_names:\n    vc=df_train[m].value_counts()\n    N=df_train.shape[0]\n    print(\"%15s : %5s 0's (%4.1f%%), %5s 1's (%4.1f%%) \"%(m,vc[0],100*vc[0]/N,vc[1],100*vc[1]/N))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T22:43:37.390322Z","iopub.execute_input":"2021-10-18T22:43:37.390746Z","iopub.status.idle":"2021-10-18T22:43:37.405621Z","shell.execute_reply.started":"2021-10-18T22:43:37.390713Z","shell.execute_reply":"2021-10-18T22:43:37.404754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like \"Subject Focus\" is nearly always 0, and \"Action\" is nearly always 0.","metadata":{}},{"cell_type":"markdown","source":"Let us now look at the conditional histograms. I also compute the conditional means, and the difference of the means, and put them in the figure title for convenience.","metadata":{}},{"cell_type":"code","source":"mean0={}\nmean1={}\nsigma0={}\nsigma1={}\ndiff={}\npawpularity=df_train['Pawpularity']\nfor m in metadata_names:\n    plt.figure()\n    sns.kdeplot(data=df_train,x='Pawpularity',hue=m,common_norm=False)\n    mean0[m]=(pawpularity[df_train[m]==0]).mean()\n    mean1[m]=(pawpularity[df_train[m]==1]).mean()\n    sigma0[m]=(pawpularity[df_train[m]==0]).std()\n    sigma1[m]=(pawpularity[df_train[m]==1]).std()\n    diff[m]=mean1[m]-mean0[m]\n    plt.title('mean0 : %5.3f, mean1 : %5.3f, difference %5.3f'%(mean0[m],\n                                                                mean1[m],\n                                                                diff[m]))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T22:43:37.407144Z","iopub.execute_input":"2021-10-18T22:43:37.407766Z","iopub.status.idle":"2021-10-18T22:43:41.335913Z","shell.execute_reply.started":"2021-10-18T22:43:37.407732Z","shell.execute_reply":"2021-10-18T22:43:41.335285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sadly, it appears that the changes in the histograms based on conditioning on the metadata features are not large.","metadata":{}},{"cell_type":"markdown","source":"By sorting the metadata keys in reverse order, based on the magnitude of the difference, we can see which features give the largest changes in the mean of the distribution.","metadata":{}},{"cell_type":"code","source":"sortkey=lambda m: abs(diff[m])\nsorted_metadata_names=sorted(list(metadata_names),key=sortkey,reverse=True)\n\nprint('%5s %15s %7s'%('rank','feature','diff'))\nfor n,m in enumerate(sorted_metadata_names):\n    print('%5d %15s %7.3f'%(n+1,m,diff[m]))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T22:43:41.336947Z","iopub.execute_input":"2021-10-18T22:43:41.337712Z","iopub.status.idle":"2021-10-18T22:43:41.345874Z","shell.execute_reply.started":"2021-10-18T22:43:41.337681Z","shell.execute_reply":"2021-10-18T22:43:41.345062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This implies that \"Blur\" causes the largest change in the distribution. The effect is negative, implying that Blur=1 images have lower (on average) Pawpularity than Blur=0 images. This makes sense. However the effect here does seem pretty small.\n\nBased on this, the \"Blur\", \"Accessory\" and \"Group\" metadata features would appear be the most useful for predicting the pawpularity score. However as the differences between the conditional means are small, its seems like including this metadata into the prediction model would have a modest benefit at best. I removed \"Subject Focus\" from this list as nearly all (97.2%) of the values of \"Subject Focus\" were 0.","metadata":{}}]}