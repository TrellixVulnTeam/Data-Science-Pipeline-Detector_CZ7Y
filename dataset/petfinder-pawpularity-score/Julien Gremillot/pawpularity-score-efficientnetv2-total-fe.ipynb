{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"/kaggle/input/petfinder-pawpularity-score/train.csv\", sep=',')\ndata['Id'] = data['Id'] + '.jpg'\ndata = data.rename(columns={'Id': 'filename'})\nprint(\"shape data: \", data.shape)\n\ndataset_dir = '/kaggle/input/petfinder-pawpularity-score/train'\nwidth, height = 224, 224\nbatch_size = 32\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ndata_generator = ImageDataGenerator(\n    rescale=1.0 / 255,\n    rotation_range=5,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    brightness_range=(0.75, 1),\n    shear_range=0.1,\n    zoom_range=[0.75, 1],\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ndata_generator = data_generator.flow_from_dataframe(\n    dataframe=data,\n    directory=dataset_dir,\n    x_col=\"filename\",\n    y_col=\"Pawpularity\",\n    class_mode=\"raw\",  # \"raw\" pour les regressions\n    target_size=(width, height),\n    batch_size=batch_size,\n    shuffle=False\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-20T04:36:03.594247Z","iopub.execute_input":"2021-12-20T04:36:03.594816Z","iopub.status.idle":"2021-12-20T04:36:17.996176Z","shell.execute_reply.started":"2021-12-20T04:36:03.594698Z","shell.execute_reply":"2021-12-20T04:36:17.994897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport os\nsys.path.insert(0, \"/kaggle/input/efnetv2src/efficientnet-v2-keras-main\")\nsys.path.append('../input/tfkeras-efficientnetsv2/')\n\nfrom efficientnet_v2 import EfficientNetV2XL\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\nfrom tensorflow.keras.metrics import MeanAbsoluteError, MeanAbsolutePercentageError\nimport tensorflow_addons as tfa\n\nefficientnet = EfficientNetV2XL(\n    include_top=False,\n    weights='../input/tfkeras-efficientnetsv2/21_ft1k_notop/efficientnetv2-xl-21k-ft1k_notop.h5', \n    input_shape=(height, width, 3)\n)\n\nefficientnet.trainable = False\n\nradam = tfa.optimizers.RectifiedAdam(learning_rate=0.001)\noptimizer = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n\nefficientnet.compile(\n    optimizer=optimizer,\n    loss=\"mean_absolute_error\",\n    metrics=[MeanAbsoluteError(), MeanAbsolutePercentageError()]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T04:36:17.999947Z","iopub.execute_input":"2021-12-20T04:36:18.00069Z","iopub.status.idle":"2021-12-20T04:36:44.452771Z","shell.execute_reply.started":"2021-12-20T04:36:18.000631Z","shell.execute_reply":"2021-12-20T04:36:44.451982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ndef preprocess(image):  \n    return (tf.cast(image, dtype=tf.float32) - 128.00) / 128.00\n\nX_csvPath = \"/kaggle/working/X_features.csv\"\ny_csvPath = \"/kaggle/working/y_targets.csv\"\n\nfrom tqdm import tqdm\nX_csv = open(X_csvPath, \"w\")\ny_csv = open(y_csvPath, \"w\")\nbatch_nb = 0\ndata_generator.reset()\nfor images, scores in tqdm(data_generator):  # renvoie des batchs de 32\n    idx = (data_generator.batch_index - 1) * batch_size\n    for i in range(images.shape[0]):\n        image = images[i, :, :, :]  # i-Ã¨me image\n        filename = data_generator.filenames[idx + i]\n        score = scores[i]\n        img = preprocess(image.reshape(1, width, height, 3))\n        img_features = efficientnet.predict(img)\n        # Features: (1, 7, 7, 1280) (62720,)\n        features_vec = \",\".join([str(v) for v in img_features.flatten()])\n        existing_cols = data[data['filename'] == filename]\n        target_col = existing_cols['Pawpularity'].to_csv(header=False, index=False)\n        existing_cols = existing_cols.drop(labels=['filename', 'Pawpularity'], axis=1)\n        existing_cols = existing_cols.to_csv(header=False, index=False).rstrip()  # (i == 0 and idx == 0)\n        X_csv.write(\"{},{}\\n\".format(existing_cols, features_vec))\n        y_csv.write(target_col)\n    if batch_nb > len(data) / batch_size:\n        break\n    batch_nb = batch_nb + 1\nX_csv.close()\ny_csv.close()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T04:52:26.411435Z","iopub.execute_input":"2021-12-20T04:52:26.411786Z","iopub.status.idle":"2021-12-20T04:54:48.701489Z","shell.execute_reply.started":"2021-12-20T04:52:26.411748Z","shell.execute_reply":"2021-12-20T04:54:48.700406Z"},"trusted":true},"execution_count":null,"outputs":[]}]}