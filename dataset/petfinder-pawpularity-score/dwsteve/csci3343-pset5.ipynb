{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CSCI 3343 Pset 5: Transfer Learning\n\n**Posted:** Wednesday, October 20, 2021\n\n**Due:** Friday, October 29, 2021 (11:59 pm)\n\n__Total Points__: 21\n\n__Name__:\n[Your first name] [Your last name], [Your BC username]\n\n(e.g. Donglai Wei, weidf)\n\n__Submission__: please rename the .ipynb file as __\\<your_username\\>_pset5.ipynb__ before you submit it to canvas. Example: weidf_pset5.ipynb.","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nHow to get started for an image understanding task?\nIn the [pset5 writeup](https://www.dropbox.com/s/46gjeg2hqi65u9z/pset5.pdf?dl=0), we list out some good practices.\n\nHere, we will use this pawpularity challenge as a case study to walk you through the [DataOps](https://en.wikipedia.org/wiki/DataOps) and [ModelOps](https://en.wikipedia.org/wiki/ModelOps).\n\n## WARNING!!!\n\n- You only have 41 hours/week of GPU usage on Kaggle.\n- Debug your code in CPU and make sure it works before you turn on the GPU mode.\n- Turn off the GPU mode after you are done","metadata":{}},{"cell_type":"markdown","source":"# Problem 1. DataOps (7 pts)","metadata":{}},{"cell_type":"markdown","source":"## Problem 1.1 Overview: Dataset Statistics with Pandas (4 pts)\n\nOften the metadata is saved as tables and let's load them with the Pandas library ([Tutorial](https://www.w3schools.com/python/pandas/pandas_getting_started.asp)).","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n# load the data\nfoldername = '../input/petfinder-pawpularity-score/'\n# in pandas, \"train\" is called a dataframe (e.g., excel table)\ntrain = pd.read_csv(foldername + 'train.csv')\n\n# print out the data\nprint(train)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:20:58.407122Z","iopub.execute_input":"2021-10-20T09:20:58.407401Z","iopub.status.idle":"2021-10-20T09:20:58.435903Z","shell.execute_reply.started":"2021-10-20T09:20:58.407372Z","shell.execute_reply":"2021-10-20T09:20:58.435218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (a) [1 pt] Get the number of training images and number of attributes","metadata":{}},{"cell_type":"code","source":"### TODO ###\nprint('#training samples', ???)\nprint('#attributes (excluding target score)', ???)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:12:18.560785Z","iopub.execute_input":"2021-10-20T07:12:18.561567Z","iopub.status.idle":"2021-10-20T07:12:18.566834Z","shell.execute_reply.started":"2021-10-20T07:12:18.561532Z","shell.execute_reply":"2021-10-20T07:12:18.565844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (b) [1 pt] Get the average score of all attributes (except the id)","metadata":{}},{"cell_type":"code","source":"### TODO ###\nprint(\"Average score of attributes\", ???)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:43:41.450111Z","iopub.execute_input":"2021-10-20T07:43:41.450781Z","iopub.status.idle":"2021-10-20T07:43:41.52511Z","shell.execute_reply.started":"2021-10-20T07:43:41.450742Z","shell.execute_reply":"2021-10-20T07:43:41.524328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (c) [1 pt] Plot the histogram of the Target (Pawpularity score)","metadata":{}},{"cell_type":"code","source":"### TODO\n???","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:38:05.371795Z","iopub.execute_input":"2021-10-20T09:38:05.372536Z","iopub.status.idle":"2021-10-20T09:38:05.608889Z","shell.execute_reply.started":"2021-10-20T09:38:05.372497Z","shell.execute_reply":"2021-10-20T09:38:05.608219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (d) [1 pt] Baseline Result: predit the mean Pawpularity score","metadata":{}},{"cell_type":"code","source":"### TODO\nbaseline_pred = ???\n\n# compute the root mean square error (used in the leaderboard)\n# hint: the baseline result is not bad ... the dataset is not balanced!\nnp.sqrt(((train.Pawpularity-baseline_pred)**2).mean())","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:50:30.23483Z","iopub.execute_input":"2021-10-20T09:50:30.235244Z","iopub.status.idle":"2021-10-20T09:50:30.240358Z","shell.execute_reply.started":"2021-10-20T09:50:30.235209Z","shell.execute_reply":"2021-10-20T09:50:30.23943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Problem 1.2 Look into Images: Visualization with ipyplot (3 pts)\nLet's train our own brain to get some ideas about the task (e.g., pawpularity score).","metadata":{}},{"cell_type":"markdown","source":"### (a) [2 pts] Visualize \"popular\", \"okay-ish\", and \"not popular\" images\nAs expected, the popularity score can be subjective and noisy...","metadata":{}},{"cell_type":"code","source":"!pip install ipyplot -qq\nimport ipyplot\nfrom PIL import Image\n\n# popular: Pawpularity > 90\n# okay-ish: 60>Pawpularity > 50\n# not popular: Pawpularity < 10\n\npopular = train.Id[train.Pawpularity > 90].values.tolist()\nnot_popular = train.Id[train.Pawpularity < 10].values.tolist()\n#### TODO\n# Hint: similar to numpy array indexing\n# output: list of image ids\nokayish = ???\n\n\nnum_img = 9\npopular_img = [Image.open(foldername + 'train/' + x +'.jpg') for x in popular[:num_img]]\nokayish_img = [Image.open(foldername + 'train/' + x +'.jpg') for x in okayish[:num_img]]\n#### TODO\n# Hint: learn from the example above\nnot_popular_img = ???","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:04:43.392903Z","iopub.execute_input":"2021-10-20T07:04:43.393339Z","iopub.status.idle":"2021-10-20T07:04:43.426755Z","shell.execute_reply.started":"2021-10-20T07:04:43.393293Z","shell.execute_reply":"2021-10-20T07:04:43.426121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Popular images')\nipyplot.plot_images(popular_img, max_images=num_img, img_width=120)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:04:58.198481Z","iopub.execute_input":"2021-10-20T07:04:58.198919Z","iopub.status.idle":"2021-10-20T07:04:58.335926Z","shell.execute_reply.started":"2021-10-20T07:04:58.198879Z","shell.execute_reply":"2021-10-20T07:04:58.33485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Okayish images')\nipyplot.plot_images(okayish_img, max_images=num_img, img_width=120)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:05:47.059423Z","iopub.execute_input":"2021-10-20T07:05:47.059708Z","iopub.status.idle":"2021-10-20T07:05:47.331205Z","shell.execute_reply.started":"2021-10-20T07:05:47.059678Z","shell.execute_reply":"2021-10-20T07:05:47.330059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Not Popular images')\nipyplot.plot_images(not_popular_img, max_images=num_img, img_width=120)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:06:05.630828Z","iopub.execute_input":"2021-10-20T07:06:05.631392Z","iopub.status.idle":"2021-10-20T07:06:05.885506Z","shell.execute_reply.started":"2021-10-20T07:06:05.631349Z","shell.execute_reply":"2021-10-20T07:06:05.884644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (b) [1 pt] Visualize images with each of the attribute\nAs expected, the popularity score can be subjective and noisy...","metadata":{}},{"cell_type":"code","source":"metadata_cols = train.columns[1:-1]\n\nimage_paths = []\nlabels = []\ncustom_texts = []\n\nnum_img = 4\n\nfor col in metadata_cols:\n    ### TODO: select the rows with this col value equal to 1\n    tmp_df = ???\n    for i in range(num_img):\n        image_paths.append(foldername + 'train/'+ tmp_df.iloc[i, 0] + '.jpg')\n        labels.append(col)\n        score = str(tmp_df.iloc[i, -1])\n        meta = tmp_df.iloc[i, :][metadata_cols].values\n        meta = ''.join([f'{col}:{m}, ' for m, col in zip(meta, metadata_cols)])\n        custom_texts.append(f'Pawpularity score: {score} \\n{meta}')","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:25:49.566332Z","iopub.execute_input":"2021-10-20T07:25:49.567145Z","iopub.status.idle":"2021-10-20T07:25:49.612401Z","shell.execute_reply.started":"2021-10-20T07:25:49.567099Z","shell.execute_reply":"2021-10-20T07:25:49.611563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ipyplot.plot_class_tabs(image_paths, labels, custom_texts=custom_texts, force_b64=True, img_width=120)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:25:51.620866Z","iopub.execute_input":"2021-10-20T07:25:51.621159Z","iopub.status.idle":"2021-10-20T07:25:52.838404Z","shell.execute_reply.started":"2021-10-20T07:25:51.621119Z","shell.execute_reply":"2021-10-20T07:25:52.837571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Problem 2. ModelOps (14 pts)","metadata":{}},{"cell_type":"markdown","source":"## Problem 2.1 Minimum Viable Product (MVP) (14 pts)","metadata":{}},{"cell_type":"markdown","source":"### (a1) [1 pt] Download Model: ResNet18","metadata":{}},{"cell_type":"code","source":"import torch\n#### TODO\n# Hint: reuse the code from pset4\nmodel = ???\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:21:04.338837Z","iopub.execute_input":"2021-10-20T09:21:04.339106Z","iopub.status.idle":"2021-10-20T09:21:08.986322Z","shell.execute_reply.started":"2021-10-20T09:21:04.339078Z","shell.execute_reply":"2021-10-20T09:21:08.985487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (a2) [1 pt] Model surgery: change the last linear layer to predict one number instead","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n#### TODO\n# Hint: what's the input and output size of the last linear layer\nmodel.fc = ???","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:21:13.023574Z","iopub.execute_input":"2021-10-20T09:21:13.024315Z","iopub.status.idle":"2021-10-20T09:21:13.028873Z","shell.execute_reply.started":"2021-10-20T09:21:13.024265Z","shell.execute_reply":"2021-10-20T09:21:13.028245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (b) [1 pt] Define loss: Mean-squared error (MSE/L2 regression)","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\ndef criterion(y_gt, y_pred):\n    #### TODO\n    # y_gt is between 0-100 -> scale to 0-1\n    # y_pred is any real number -> add a sigmoid to squash it to 0-1\n    return F.mse_loss(???, ???)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:21:17.163447Z","iopub.execute_input":"2021-10-20T09:21:17.163714Z","iopub.status.idle":"2021-10-20T09:21:17.168107Z","shell.execute_reply.started":"2021-10-20T09:21:17.163683Z","shell.execute_reply":"2021-10-20T09:21:17.167184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (c) [1 pt] Define the optimizer","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\n\n# freeze the weight for all conv layers\n# only learn the last linear layer\nfor name,param in model.named_parameters():\n    if 'fc' in name:\n        param.requires_grad = True\n    else:\n        param.requires_grad = False\n\n#### TODO\n# Hint: copy it from pset 4\noptimizer = ???","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:21:19.783542Z","iopub.execute_input":"2021-10-20T09:21:19.784172Z","iopub.status.idle":"2021-10-20T09:21:19.791072Z","shell.execute_reply.started":"2021-10-20T09:21:19.784127Z","shell.execute_reply":"2021-10-20T09:21:19.78995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (d1) [1 pt] Divide the images into train and validation","metadata":{}},{"cell_type":"code","source":"# from lab3\nimport numpy as np\nnp.random.seed(123)\n\ndef data_split(N, ratio=[8,2]):\n  # generate a shuffle array\n  shuffle_idx = np.arange(N)\n  np.random.shuffle(shuffle_idx)\n  # divide into train-val-test by the ratio\n  data_split = (np.cumsum(ratio)/float(sum(ratio))*N).astype(int)\n  out_idx = [None] * len(ratio)\n  out_idx[0] = shuffle_idx[:data_split[0]]\n  for i in range(1,len(ratio)):\n    out_idx[i] = shuffle_idx[data_split[i-1] : data_split[i]]\n  return out_idx  \n\n# split the dataset into train-val split (8:2 ratio)\nsplit_idx = data_split(len(train))\ndf_train = train.loc[split_idx[0]]\n\n#### TODO\n# Hint: understand what is in split_idx\ndf_valid = ???","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:21:21.591316Z","iopub.execute_input":"2021-10-20T09:21:21.591845Z","iopub.status.idle":"2021-10-20T09:21:21.605718Z","shell.execute_reply.started":"2021-10-20T09:21:21.591808Z","shell.execute_reply":"2021-10-20T09:21:21.604921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (d2) [3 pts] Build dataset class","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\n\nmetadata_cols = train.columns[1:-1]\n# make a child class of PyTorch's dataset class\nclass PawpularityDataset(Dataset):\n    def __init__(self, root_dir, df, transforms=None):\n        # initialization: called only once during creation\n        self.root_dir = root_dir\n        self.df = df\n        column_names = df.columns\n        self.file_names = df['Id'].values\n        self.meta = df[metadata_cols].values\n        if 'Pawpularity' in df.columns:\n            self.targets = df['Pawpularity'].values\n        else:\n            self.targets = None\n        self.transforms = transforms\n        \n    def __len__(self):\n        # determine how many iterations in one epoch\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        # called every time when the dataloader wants a sample\n        # the dataset has a list of image file names\n        # Input: dataloader provides a random index of the list\n        # Output: corresponding image and meta data\n\n        #### TODO\n        img_path = ???\n        img = Image.open(img_path)\n        if self.transforms:\n            img = self.transforms(img)\n        \n        #### TODO\n        meta = ???\n        \n        if self.targets is None:\n            # during deployment, df doesn't have the target value\n            target = 0            \n        else: \n            # otherwise, return the corresponding target value\n            #### TODO\n            target = self.targets[index]\n\n        return img, meta, target","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:23:15.427853Z","iopub.execute_input":"2021-10-20T09:23:15.42858Z","iopub.status.idle":"2021-10-20T09:23:15.437185Z","shell.execute_reply.started":"2021-10-20T09:23:15.428544Z","shell.execute_reply":"2021-10-20T09:23:15.436158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (d3) [1 pt] Build data transform","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\nRGB_MEAN = (0.4914, 0.4822, 0.4465)\nRGB_STD = (0.2023, 0.1994, 0.2010)\n\n# unlike pset4 working on the 32x32 images from CIFAR10\n# we here use the transforms for ImageNet challenge\ntransform_train = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(RGB_MEAN, RGB_STD),\n])\n\ntransform_test = transforms.Compose([\n    #### TODO\n    # hint: there are many \"right\" ways to do it\n    # one idea is to take the center crop without randomflip, compared to transform_train\n    ???\n])","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:23:23.857655Z","iopub.execute_input":"2021-10-20T09:23:23.858362Z","iopub.status.idle":"2021-10-20T09:23:23.864261Z","shell.execute_reply.started":"2021-10-20T09:23:23.858323Z","shell.execute_reply":"2021-10-20T09:23:23.863596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (d4) [1 pt] Build Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataset = PawpularityDataset(foldername + 'train/', df_train, transforms=transform_train)\n\n#### TODO\nvalid_dataset = ???","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:23:26.188486Z","iopub.execute_input":"2021-10-20T09:23:26.189014Z","iopub.status.idle":"2021-10-20T09:23:26.200216Z","shell.execute_reply.started":"2021-10-20T09:23:26.188978Z","shell.execute_reply":"2021-10-20T09:23:26.199421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (e) [3 pts] Train it!\n\nTo get the point, you need to show that the loss is decreasing after a few epoches. As you experienced in Pset4, here is where you will find out potential bugs in your anwsers to previous questions.","metadata":{}},{"cell_type":"code","source":"#### nothing to change in this code block ####\n\nclass Config:  \n  def __init__(self, **kwargs):\n    # util\n    self.batch_size = 16\n    self.epochs = 0\n    self.save_model_path = '' # use your google drive path to save the model\n    self.log_interval = 100 # display after number of batches\n    self.criterion = F.cross_entropy # loss for classification\n    self.mode = 'train'\n    for key, value in kwargs.items():\n      setattr(self, key, value)\n   \nclass Trainer:  \n  def __init__(self, model, config, train_data = None, test_data = None):    \n    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    self.epochs = config.epochs\n    self.save_model_path = config.save_model_path\n    self.log_interval = config.log_interval\n    self.mode = config.mode\n\n    self.globaliter = 0\n    self.train_loader = None\n    self.test_loader = None\n    batch_size = config.batch_size\n    if self.mode == 'train': # training mode\n      self.train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                          shuffle=True, num_workers=1)      \n      #self.tb = TensorBoardColab()\n      self.optimizer = config.optimizer\n    \n    if test_data is not None: # need evaluation\n      self.test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n                                         shuffle=False, num_workers=1)\n    \n    self.model = model.to(self.device)\n    self.criterion = config.criterion # loss function\n    \n                \n  def train(self, epoch):  \n    self.model.train()\n    for batch_idx, (data, meta, target) in enumerate(self.train_loader):      \n      self.globaliter += 1\n      data, target = data.to(self.device), target.to(self.device)\n\n      self.optimizer.zero_grad()\n      predictions = self.model(data)\n\n      loss = self.criterion(predictions, target)\n      loss.backward()\n      self.optimizer.step()\n\n      if batch_idx % self.log_interval == 0:\n        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                  epoch, batch_idx * len(data), len(self.train_loader.dataset),\n                  100. * batch_idx / len(self.train_loader), loss.item()))\n        #self.tb.save_value('Train Loss', 'train_loss', self.globaliter, loss.item())\n        #self.tb.flush_line('train_loss')\n        \n        \n  def test(self, epoch, do_loss = True, return_pred = False):\n    self.model.eval()\n    test_loss = 0\n    correct = 0\n    pred = []\n    with torch.no_grad():\n      print('Start testing...')\n      for data, meta, target in self.test_loader:\n        data = data.to(self.device)\n        predictions = self.model(data)\n        if return_pred:\n          pred.append(predictions.detach().cpu().numpy())\n        if do_loss:\n            target = target.to(self.device)        \n            test_loss += self.criterion(predictions, target).item()*len(target)\n            prediction = predictions.argmax(dim=1, keepdim=True)\n            correct += prediction.eq(target.view_as(prediction)).sum().item()\n      if do_loss:\n          test_loss /= len(self.test_loader.dataset)\n          accuracy = 100. * correct / len(self.test_loader.dataset)\n          print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n              test_loss, correct, len(self.test_loader.dataset), accuracy))\n      \"\"\"\n      if self.mode == 'train': # add validation data to tensorboard\n        self.tb.save_value('Validation Loss', 'val_loss', self.globaliter, test_loss)\n        self.tb.flush_line('val_loss')\n      \"\"\"\n      if return_pred:\n        return np.hstack(pred)\n  def main(self):\n    pred = []\n    if self.mode == 'train':\n      for epoch in range(1, self.epochs + 1):          \n          self.train(epoch)\n          if self.test_loader is not None:\n            # exist validation data\n            self.test(epoch)\n    if (self.save_model_path != ''):\n        torch.save(self.model.state_dict(), self.save_model_path)\n    elif self.mode == 'test':\n      self.test(0)\n    elif self.mode == 'deploy':          \n      pred = self.test(0, False, True)\n      return pred\n","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:28:37.508011Z","iopub.execute_input":"2021-10-20T09:28:37.508456Z","iopub.status.idle":"2021-10-20T09:28:37.532942Z","shell.execute_reply.started":"2021-10-20T09:28:37.508422Z","shell.execute_reply":"2021-10-20T09:28:37.531668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's kick off the training and hope it works!","metadata":{}},{"cell_type":"code","source":"# set of hyperparameters\ntrain_config = Config(    \n    criterion = criterion,\n    save_model_path = '', # if you like, use your google drive path to save the model (mount google drive first)\n    log_interval = 100, # display after number of batches\n    batch_size = 16,\n    optimizer = optimizer,\n    epochs = 10,\n)\nTrainer(model, train_config, train_dataset, valid_dataset).main()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:44:14.960452Z","iopub.execute_input":"2021-10-20T09:44:14.960768Z","iopub.status.idle":"2021-10-20T09:46:49.735772Z","shell.execute_reply.started":"2021-10-20T09:44:14.960716Z","shell.execute_reply":"2021-10-20T09:46:49.734946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (f) [1 pt] Create a submission\nYou'll get the point if the code blocks below run through correctly.","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(foldername + 'test.csv')\ntest_dataset = PawpularityDataset(foldername + 'test/', df_test, transforms=transform_test)\n\ntest_config = Config(mode='deploy', batch_size=8)\ntest_pred = Trainer(model, test_config, None, test_dataset).main()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:46:54.15165Z","iopub.execute_input":"2021-10-20T09:46:54.152278Z","iopub.status.idle":"2021-10-20T09:46:54.266818Z","shell.execute_reply.started":"2021-10-20T09:46:54.152234Z","shell.execute_reply":"2021-10-20T09:46:54.26596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv(foldername + 'sample_submission.csv')\nsubmission_df['Pawpularity'] = test_pred.ravel()\nsubmission_df.to_csv('submission.csv', index = False)\n\n# Summary\nsubmission_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T09:46:57.101593Z","iopub.execute_input":"2021-10-20T09:46:57.102251Z","iopub.status.idle":"2021-10-20T09:46:57.119709Z","shell.execute_reply.started":"2021-10-20T09:46:57.102207Z","shell.execute_reply":"2021-10-20T09:46:57.118978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONGRATULATIONS!!! You completed the MVP for this Kaggle challenge!!!\n\nThis is a template on how to get started for any CV/ML project.","metadata":{}}]}