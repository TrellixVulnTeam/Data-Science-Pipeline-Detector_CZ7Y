{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Notebook Score: CV ~18.2 and LB 18.33","metadata":{}},{"cell_type":"markdown","source":"This notebook implements mixup in a very hacky way. If you don't use tez, consider implementing it in the training step.\n\nSummary:\n* Model: Swin 224\n* Trains on images & meta features + breed\n* Treats regression as classification (BCEwLogits > Sigmoid * 100 > RMSE)\n* Mixup applied on images & meta features\n\n\nI'm very new to image competitions, so any advice would be much appreciated!","metadata":{}},{"cell_type":"markdown","source":"## Libraries","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/tez-lib\")\nsys.path.append(\"../input/timmmaster\")","metadata":{"execution":{"iopub.status.busy":"2021-11-26T03:53:19.301962Z","iopub.execute_input":"2021-11-26T03:53:19.302645Z","iopub.status.idle":"2021-11-26T03:53:19.318843Z","shell.execute_reply.started":"2021-11-26T03:53:19.302554Z","shell.execute_reply":"2021-11-26T03:53:19.318158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport tez\nimport albumentations\nimport timm\nimport torch.nn as nn\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:53:19.320401Z","iopub.execute_input":"2021-11-26T03:53:19.320806Z","iopub.status.idle":"2021-11-26T03:53:28.562502Z","shell.execute_reply.started":"2021-11-26T03:53:19.320769Z","shell.execute_reply":"2021-11-26T03:53:28.561656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class args:\n    batch_size=32\n    image_size=224\n    epochs = 10\n    model_name = \"swin_tiny_patch4_window7_224\"\n    # keep mixup alpha in [0.1,0.4]\n    mixup_alpha = 0.2","metadata":{"execution":{"iopub.status.busy":"2021-11-26T03:53:28.56497Z","iopub.execute_input":"2021-11-26T03:53:28.565849Z","iopub.status.idle":"2021-11-26T03:53:28.570993Z","shell.execute_reply.started":"2021-11-26T03:53:28.565805Z","shell.execute_reply":"2021-11-26T03:53:28.570152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x is images, z is meta features, y is target\ndef mixup_data(x, z, y):\n    if args.mixup_alpha > 0:\n        lam = np.random.beta(args.mixup_alpha, args.mixup_alpha)\n    else:\n        lam = 1\n        \n    batch_size = x.size()[0]\n    # returns list of shuffled indices in batch size\n    index = torch.randperm(batch_size).cuda()\n    \n    # mix current x with lambda n rest with pics from the shuffled indices\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    mixed_z = lam * z + (1 - lam) * z[index, :]\n    \n    # returns targets for current x n ones used for mix\n    y_a, y_b = y, y[index]\n    \n    return mixed_x, mixed_z, y_a, y_b, lam\n\n# where pred is the output from the forward - predictions basically\ndef mixup_loss(loss_fn, pred, y_a, y_b, lam):\n    # get loss from current x n loss from watermarks n add\n    return lam * loss_fn(pred, y_a) + (1 - lam) * loss_fn(pred, y_b)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T03:53:28.573272Z","iopub.execute_input":"2021-11-26T03:53:28.573739Z","iopub.status.idle":"2021-11-26T03:53:28.582018Z","shell.execute_reply.started":"2021-11-26T03:53:28.573704Z","shell.execute_reply":"2021-11-26T03:53:28.581267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset & Model Classes","metadata":{}},{"cell_type":"code","source":"class PawpularDataset:\n    def __init__(self, image_paths, meta_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.meta_features = meta_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, index):\n        # read in as BGR\n        image = cv2.imread(self.image_paths[index])\n        # convert to RGB\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            # applies compose function from albumentations on image\n            augmented = self.augmentations(image=image)\n            # maybe cv2 returns a dict and to access info on image have to call 'image' key\n            image = augmented['image']\n            \n        # transform from HxWxC to CxHxW    \n        image = np.transpose(image, (2,0,1)).astype(np.float32)\n        \n        features = self.meta_features[index, :]\n        # normalize to [0-1] - for classification\n        targets = self.targets[index] / 100.\n        \n        return {\n            'image': torch.tensor(image, dtype=torch.float),\n            'features': torch.tensor(features, dtype=torch.float),\n            'targets': torch.tensor(targets, dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-11-26T03:53:28.584204Z","iopub.execute_input":"2021-11-26T03:53:28.584469Z","iopub.status.idle":"2021-11-26T03:53:28.593881Z","shell.execute_reply.started":"2021-11-26T03:53:28.584433Z","shell.execute_reply":"2021-11-26T03:53:28.593105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularModel(tez.Model):\n    def __init__(self):\n        super().__init__()\n        \n        self.model = timm.create_model(args.model_name, pretrained=True, in_chans=3)\n        self.model.head = nn.Linear(self.model.head.in_features, 128)\n        self.dropout = nn.Dropout(p=0.5)\n        self.dense1 = nn.Linear(128+13,1)\n        \n        self.step_scheduler_after = 'epoch'\n        \n    def monitor_metrics(self, outputs, targets):\n        outputs = outputs.cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        rmse = metrics.mean_squared_error(targets, outputs, squared=False)\n        return {'rmse': rmse}\n    \n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n        return sch\n    \n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=1e-4)\n        return opt\n    \n    def forward(self, image, features, targets=None):        \n        # do mixup when have targets and state is train (doesnt do mixup at val)\n        if ((targets is not None) and (self._train_state == True)):\n            image, features, target_a, target_b, lam = mixup_data(image, features, targets.view(-1,1)) \n            image = image.to(device='cuda', dtype=torch.float)\n            features = features.to(device='cuda', dtype=torch.float)\n            target_a = target_a.to(device='cuda', dtype=torch.float)\n            target_b = target_b.to(device='cuda', dtype=torch.float)\n        x = self.model(image)\n        x = self.dropout(x)\n        # combine with meta features and shrink it down to 1 feature (score)\n        x = torch.cat([x, features], dim=1)\n        x = self.dense1(x)\n        \n        if targets is not None:\n            loss_fn = nn.BCEWithLogitsLoss()\n            if self._train_state == True:\n                loss = mixup_loss(loss_fn, x, target_a, target_b, lam)\n            else:\n                loss = loss_fn(x, targets.view(-1, 1))\n            \n            # sigmoid convert to [0-1] \n            # multiply by 100 to convert to [0-100] which is pawpularity range\n            metrics = self.monitor_metrics(torch.sigmoid(x) * 100, targets * 100)\n            return x, loss, metrics\n        \n        return x, 0, {}","metadata":{"execution":{"iopub.status.busy":"2021-11-26T03:53:28.595471Z","iopub.execute_input":"2021-11-26T03:53:28.595992Z","iopub.status.idle":"2021-11-26T03:53:28.612463Z","shell.execute_reply.started":"2021-11-26T03:53:28.595955Z","shell.execute_reply":"2021-11-26T03:53:28.611777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Augmentations","metadata":{}},{"cell_type":"code","source":"train_aug = albumentations.Compose([\n    albumentations.RandomResizedCrop(\n        height=args.image_size, width=args.image_size,\n        scale=(0.08,1), ratio=(0.75, 1), p=1.0\n    ),\n    # color shift\n    albumentations.HueSaturationValue(\n        hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n    ),\n    albumentations.RandomBrightnessContrast(\n        brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5\n    ),\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=180, p=0.7),\n    albumentations.ShiftScaleRotate(\n        shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=0.5\n    ),\n    albumentations.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225],\n        max_pixel_value=255.0,\n        p=1.0\n    ),\n], p=1.0)\n\nvalid_aug = albumentations.Compose([\n    albumentations.Resize(args.image_size, args.image_size, p=1.0),\n    albumentations.Normalize(\n        mean = [0.485, 0.456, 0.406],\n        std = [0.229, 0.224, 0.225],\n        max_pixel_value = 255.0,\n        p = 1.0,\n    ),\n], p=1.0)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T03:53:28.613746Z","iopub.execute_input":"2021-11-26T03:53:28.614045Z","iopub.status.idle":"2021-11-26T03:53:28.625519Z","shell.execute_reply.started":"2021-11-26T03:53:28.614007Z","shell.execute_reply":"2021-11-26T03:53:28.624806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/no-dupes-pawpularity/train_5folds.csv')\n# Breed: 0 for dog, 1 for cat, 2 for neither\ndf","metadata":{"execution":{"iopub.status.busy":"2021-11-26T03:53:28.628064Z","iopub.execute_input":"2021-11-26T03:53:28.628286Z","iopub.status.idle":"2021-11-26T03:53:28.688609Z","shell.execute_reply.started":"2021-11-26T03:53:28.628261Z","shell.execute_reply":"2021-11-26T03:53:28.687969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_features = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'Breed'\n]","metadata":{"execution":{"iopub.status.busy":"2021-11-26T03:53:28.689826Z","iopub.execute_input":"2021-11-26T03:53:28.690243Z","iopub.status.idle":"2021-11-26T03:53:28.694355Z","shell.execute_reply.started":"2021-11-26T03:53:28.69021Z","shell.execute_reply":"2021-11-26T03:53:28.693724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"for fold_ in range(5):\n    print(f'--- Fold {fold_} ---')\n    # probably means df train is every fold except fold 0 and df valid is just fold 0\n    # reset index doesnt do anything\n    df_train = df[df.kfold != fold_].reset_index(drop=True)\n    df_valid = df[df.kfold == fold_].reset_index(drop=True)\n    \n    train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train['Id'].values]\n    valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid['Id'].values]\n    \n    train_dataset = PawpularDataset(\n        image_paths = train_img_paths,\n        meta_features = df_train[meta_features].values,\n        targets = df_train.Pawpularity.values,\n        augmentations = train_aug,\n        )\n\n    valid_dataset = PawpularDataset(\n        image_paths = valid_img_paths,\n        meta_features = df_valid[meta_features].values,\n        targets = df_valid.Pawpularity.values,\n        augmentations = valid_aug,\n        )\n\n    model = PawpularModel()\n\n    es = EarlyStopping(\n        monitor='valid_rmse',\n        model_path=f'{args.model_name}_f{fold_}.bin',\n        patience=3,\n        mode='min',\n        save_weights_only=True\n    )\n\n    model.fit(\n        train_dataset = train_dataset,\n        valid_dataset = valid_dataset,\n        train_bs = args.batch_size,\n        valid_bs = 2*args.batch_size,\n        device='cuda',\n        epochs=args.epochs,\n        callbacks=[es],\n        fp16=True,\n        n_jobs=2\n    )","metadata":{"execution":{"iopub.status.busy":"2021-11-26T03:53:28.69571Z","iopub.execute_input":"2021-11-26T03:53:28.696244Z","iopub.status.idle":"2021-11-26T03:55:28.805006Z","shell.execute_reply.started":"2021-11-26T03:53:28.696208Z","shell.execute_reply":"2021-11-26T03:55:28.803781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}