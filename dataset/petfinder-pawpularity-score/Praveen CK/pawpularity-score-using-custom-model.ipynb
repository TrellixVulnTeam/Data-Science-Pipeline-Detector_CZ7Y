{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-19T01:20:15.578966Z","iopub.execute_input":"2022-01-19T01:20:15.579357Z","iopub.status.idle":"2022-01-19T01:20:17.868439Z","shell.execute_reply.started":"2022-01-19T01:20:15.579251Z","shell.execute_reply":"2022-01-19T01:20:17.866911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:17.870293Z","iopub.execute_input":"2022-01-19T01:20:17.870555Z","iopub.status.idle":"2022-01-19T01:20:17.874747Z","shell.execute_reply.started":"2022-01-19T01:20:17.87052Z","shell.execute_reply":"2022-01-19T01:20:17.873834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from skimage import io, transform\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport math\nimport cv2\nimport time\nimport os\nimport copy\nfrom ipywidgets import FloatProgress\n\n\nimport os\nfrom sklearn.model_selection import train_test_split\nimport tqdm.notebook as tqdm\n\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils,models\nfrom torchvision.utils import make_grid\n\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:17.876451Z","iopub.execute_input":"2022-01-19T01:20:17.876973Z","iopub.status.idle":"2022-01-19T01:20:27.030153Z","shell.execute_reply.started":"2022-01-19T01:20:17.876881Z","shell.execute_reply":"2022-01-19T01:20:27.029202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pet_meta_data = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\ntest_pet_meta_data = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\ntrain_pet_meta_data","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:27.03447Z","iopub.execute_input":"2022-01-19T01:20:27.036324Z","iopub.status.idle":"2022-01-19T01:20:27.111722Z","shell.execute_reply.started":"2022-01-19T01:20:27.036283Z","shell.execute_reply":"2022-01-19T01:20:27.111067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0. validate all the images in train folders has meta data\n1. Create a pytorch dataset to load image and metadata\n2. Split training data into train and validation set and use test for final evaluation\n3. download pretrained densnet model \n4. modify the model to take meta data as input at after flattening \n5. add dense layers \n","metadata":{}},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_pet_meta_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:27.116903Z","iopub.execute_input":"2022-01-19T01:20:27.118975Z","iopub.status.idle":"2022-01-19T01:20:27.148152Z","shell.execute_reply.started":"2022-01-19T01:20:27.118938Z","shell.execute_reply":"2022-01-19T01:20:27.147343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = \"/kaggle/input/petfinder-pawpularity-score/\"\nplt.figure(figsize=(10,8))\n\nfor i, j in enumerate(np.random.randint(0, 100,size =6)):\n    plt.subplot(2,3, i+1)\n    sample_image = plt.imread( root_dir+ \"train/\" +train_pet_meta_data.Id[j] +\".jpg\")\n    plt.imshow(sample_image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:27.151967Z","iopub.execute_input":"2022-01-19T01:20:27.154209Z","iopub.status.idle":"2022-01-19T01:20:28.383632Z","shell.execute_reply.started":"2022-01-19T01:20:27.15417Z","shell.execute_reply":"2022-01-19T01:20:28.382996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_image.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:28.384579Z","iopub.execute_input":"2022-01-19T01:20:28.384834Z","iopub.status.idle":"2022-01-19T01:20:28.390507Z","shell.execute_reply.started":"2022-01-19T01:20:28.384794Z","shell.execute_reply":"2022-01-19T01:20:28.389875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawPularityDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transforms=None):\n        self.paw_pularity_frame = csv_file\n        self.root_dir = root_dir\n        self.transforms = transforms\n        self.is_test_dataset = True if \"Pawpularity\" not in self.paw_pularity_frame.columns else False\n        \n    def __len__(self):\n        return len(self.paw_pularity_frame)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        image_path = os.path.join(self.root_dir,\n                                self.paw_pularity_frame.iloc[idx, 0] + \".jpg\")\n        image = plt.imread(image_path)\n        id = self.paw_pularity_frame.iloc[idx, 0]\n        \n        \n        \n        meta_data = np.array(self.paw_pularity_frame.iloc[idx, 1:13])\n        meta_data = torch.tensor(meta_data.astype('float'), dtype=torch.float)\n        meta_data = meta_data / 2 + 0.1 \n        sample = {\"image\": image, 'meta_data': meta_data , \"id\":id }\n        \n        if self.is_test_dataset == False:\n            score = self.paw_pularity_frame.iloc[idx, 13]\n            score = torch.tensor(score, dtype=torch.float)\n            score = score.unsqueeze(-1)\n            sample['score'] = score \n        \n        if self.transforms:\n            sample['image'] = self.transforms(sample['image'])\n\n        return sample\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:28.391765Z","iopub.execute_input":"2022-01-19T01:20:28.39213Z","iopub.status.idle":"2022-01-19T01:20:28.406415Z","shell.execute_reply.started":"2022-01-19T01:20:28.392097Z","shell.execute_reply":"2022-01-19T01:20:28.405553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images_data , val_images_data = train_test_split(train_pet_meta_data,train_size=0.8)\nprint(len(train_images_data), len(val_images_data))\n\ntrain_transforms = transforms.Compose([\n     transforms.ToPILImage(),\n    transforms.Resize((224,224)),\n    # transforms.CenterCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\nval_transforms = transforms.Compose([\n     transforms.ToPILImage(),\n    transforms.Resize((224,224)),\n    # transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\nN_EPOCHS = 156\nBATCH_SIZE =128\n\ntrain_dataset = PawPularityDataset(train_images_data, root_dir+\"train\", transforms = train_transforms)\nval_dataset = PawPularityDataset(val_images_data, root_dir+\"train\", transforms = val_transforms)\ntest_dataset = PawPularityDataset(test_pet_meta_data, root_dir+\"test\", transforms = val_transforms)\n\ntrain_loader = DataLoader( train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\nval_loader = DataLoader( val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\ntest_loader = DataLoader( test_dataset, batch_size=1, shuffle=False, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:28.407859Z","iopub.execute_input":"2022-01-19T01:20:28.408332Z","iopub.status.idle":"2022-01-19T01:20:28.427264Z","shell.execute_reply.started":"2022-01-19T01:20:28.408165Z","shell.execute_reply":"2022-01-19T01:20:28.426575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in test_loader:\n    print(item.keys())\n    print(\"image: \", item[\"image\"].shape)\n    print(\"meta_data: \", item[\"meta_data\"].shape)\n    print(\"id: \", len(item[\"id\"]))\n    try:\n        print(\"score: \", item[\"score\"].shape)\n    except:\n        print()\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:28.428203Z","iopub.execute_input":"2022-01-19T01:20:28.430225Z","iopub.status.idle":"2022-01-19T01:20:28.550634Z","shell.execute_reply.started":"2022-01-19T01:20:28.430189Z","shell.execute_reply":"2022-01-19T01:20:28.549973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageTabularDenseNet(nn.Module):\n    def __init__(self, model):\n        super(ImageTabularDenseNet, self).__init__()\n        self.model_features = model\n        \n        for param in self.model_features.parameters():\n            param.requires_grad = False\n        self.model_features.classifier = nn.Sequential( \n            nn.Linear(1024, 1024), \n            nn.ReLU(),)\n        \n        self.model_classifier = nn.Sequential( \n                                    nn.Linear(1024 + 12, 1024),\n                                    nn.BatchNorm1d(1024),\n                                    nn.ReLU(),\n                                    nn.Linear(1024, 512),\n                                    nn.BatchNorm1d(512),\n                                    nn.ReLU(),\n                                    nn.Linear(512, 512),\n                                    nn.BatchNorm1d(512),\n                                    nn.ReLU(),\n                                    nn.Linear(512, 1),\n                                    nn.Sigmoid())\n        \n        for params in self.model_features.named_parameters():\n            if \"features.denseblock4.denselayer16\" in params[0]: \n                # print(params[1].requires_grad)\n                params[1].requires_grad = True\n        \n    def forward(self,images, meta_data):\n        output = self.model_features(images)\n        combined_data = torch.cat([output, meta_data], dim=1)\n        output_1 = self.model_classifier(combined_data)\n        return output_1 * 100\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:28.551887Z","iopub.execute_input":"2022-01-19T01:20:28.552154Z","iopub.status.idle":"2022-01-19T01:20:28.564156Z","shell.execute_reply.started":"2022-01-19T01:20:28.552119Z","shell.execute_reply":"2022-01-19T01:20:28.563437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model_ft = models.densenet121(pretrained=False)\nimage_tabular_net = ImageTabularDenseNet(model_ft)\n# image_tabular_net\n\noptimizer = torch.optim.AdamW(image_tabular_net.parameters(), lr=0.0001)\nloss_function = torch.nn.MSELoss(reduction=\"mean\")","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:28.567306Z","iopub.execute_input":"2022-01-19T01:20:28.567502Z","iopub.status.idle":"2022-01-19T01:20:28.758437Z","shell.execute_reply.started":"2022-01-19T01:20:28.567479Z","shell.execute_reply":"2022-01-19T01:20:28.757723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef train_model(model):\n    best_metric = 9999\n    best_metric_epoch = -1\n    epoch_loss_values = []\n    metric_values = []\n    root_dir =''\n    \n    val_interval = 2\n    model = model.to(device)\n    for epoch in range(N_EPOCHS):\n        print(\"-\" * 10)\n        print(f\"epoch {epoch + 1}/{N_EPOCHS}\")\n        model.train()\n        epoch_loss = 0\n        step = 0\n        for batch_data in train_loader:\n            step += 1\n            images,meta_data, labels = batch_data[\"image\"].to(device), batch_data[\"meta_data\"].to(device), batch_data[\"score\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(images, meta_data)\n            loss = loss_function(outputs, labels)\n            loss = torch.sqrt(loss)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            if step % 5 == 0 : \n                print(\n                    f\"{step}/{len(train_dataset) // train_loader.batch_size}, \"\n                    f\"train_loss: {loss.item():.4f}\")\n            epoch_len = len(train_dataset) // train_loader.batch_size\n        epoch_loss /= step\n        epoch_loss_values.append(epoch_loss)\n        \n        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n\n        if (epoch + 1) % val_interval == 0:\n            model.eval()\n            with torch.no_grad():\n                y_pred = torch.tensor([], dtype=torch.float32, device=device)\n                y = torch.tensor([], dtype=torch.long, device=device)\n                for val_data in val_loader:\n                    val_images,val_meta_data, val_labels = (\n                        val_data[\"image\"].to(device),\n                        val_data[\"meta_data\"].to(device),\n                        val_data[\"score\"].to(device),\n                    )\n                    y_pred = torch.cat([y_pred, model(val_images,val_meta_data)], dim=0)\n                    y = torch.cat([y, val_labels], dim=0)\n                val_loss = loss_function(y_pred, y)\n                val_loss = torch.sqrt(val_loss)\n\n                metric_values.append(val_loss)\n\n                if val_loss < best_metric:\n                    best_metric = val_loss\n                    best_metric_epoch = epoch + 1\n                    torch.save(model.state_dict(), os.path.join(\n                        root_dir, \"best_metric_model.pth\"))\n                    print(\"saved new best metric model\")\n                print(\n                    f\"current epoch: {epoch + 1} current val loss: {val_loss:.4f}\"\n                    f\" val loss: {best_metric:.4f}\"\n                    f\" at epoch: {best_metric_epoch}\"\n                )\n\n    print(\n        f\"train completed, best_metric: {best_metric:.4f} \"\n        f\"at epoch: {best_metric_epoch}\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:28.759945Z","iopub.execute_input":"2022-01-19T01:20:28.760238Z","iopub.status.idle":"2022-01-19T01:20:28.812063Z","shell.execute_reply.started":"2022-01-19T01:20:28.760199Z","shell.execute_reply":"2022-01-19T01:20:28.811357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_tabular_net = train_model(image_tabular_net)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:28.814987Z","iopub.execute_input":"2022-01-19T01:20:28.815455Z","iopub.status.idle":"2022-01-19T01:20:28.823442Z","shell.execute_reply.started":"2022-01-19T01:20:28.815418Z","shell.execute_reply":"2022-01-19T01:20:28.822752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_tabular_net.load_state_dict(torch.load(\"../input/pawpularity-best-model/best_metric_model.pth\"))\nimage_tabular_net.to(device).eval()\nids = []\npredictions = []\nwith torch.no_grad():\n    for test_data in test_loader:\n        test_images,test_meta_data, test_id = (\n            test_data[\"image\"].to(device),\n            test_data[\"meta_data\"].to(device),\n            test_data[\"id\"],\n        )\n        y_pred =  image_tabular_net(test_images,test_meta_data)\n        \n        for i in range(y_pred.shape[0]):\n            predictions.append(y_pred[i].item())\n            ids.append(test_id[i])\n\nresults_df = pd.DataFrame({\"id\":ids, \"predictions\": predictions})\n\nresults_df.to_csv(\"submission.csv\", index=False)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:20:28.824743Z","iopub.execute_input":"2022-01-19T01:20:28.825079Z","iopub.status.idle":"2022-01-19T01:20:40.236127Z","shell.execute_reply.started":"2022-01-19T01:20:28.825042Z","shell.execute_reply":"2022-01-19T01:20:40.235384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}