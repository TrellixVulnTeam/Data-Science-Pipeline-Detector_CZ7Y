{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%sh\npip install -U --no-build-isolation --no-deps ../input/pytorch-timm/pytorch-image-models-master/ -qq","metadata":{"id":"-JO6jg8LrzbZ","papermill":{"duration":38.86128,"end_time":"2021-11-22T12:55:06.244959","exception":false,"start_time":"2021-11-22T12:54:27.383679","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/poolformer/poolformer-main')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport cv2\nimport timm\nfrom timm.models import load_checkpoint\n\nimport models\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader\n\nimport gc\nimport wandb\nimport warnings\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\nwarnings.simplefilter('ignore')","metadata":{"id":"rK-YtcAWrr5U","papermill":{"duration":8.459847,"end_time":"2021-11-22T12:55:14.716131","exception":false,"start_time":"2021-11-22T12:55:06.256284","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Config = {\n    'CSV_PATH': \"../input/petfinder-pawpularity-score/test.csv\",\n    'IMG_PATH': \"../input/petfinder-pawpularity-score/test\",\n    'N_ACCUM': 2,\n    'N_SPLITS': 5,\n    'TRAIN_BS': 64,\n    'VALID_BS': 64,\n    'N_EPOCHS': 5,\n    'NUM_WORKERS': 4,\n    'LR': 1e-5,\n    'OPTIM': \"AdamW\",\n    'LOSS': \"BCELogits\",\n    'ARCH': \"../input/poolformerweights/poolformer_m36.pth.tar\",\n    'IMG_SIZE': 224,\n    'DEVICE': \"cuda\",\n    \"T_0\": 20,\n    \"Î·_min\": 1e-4,\n    'infra': \"Kaggle\",\n    'competition': 'petfinder',\n    '_wandb_kernel': 'tanaym',\n    \"wandb\": False,\n}","metadata":{"id":"LyoL1zR_stux","papermill":{"duration":0.018392,"end_time":"2021-11-22T12:55:14.802359","exception":false,"start_time":"2021-11-22T12:55:14.783967","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(output, target):\n    \"\"\"\n    Returns root mean squared error loss\n    \"\"\"\n    return mean_squared_error(output, target, squared=False)","metadata":{"id":"TcKg0-K8c_OK","papermill":{"duration":0.017684,"end_time":"2021-11-22T12:55:14.773075","exception":false,"start_time":"2021-11-22T12:55:14.755391","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetfinderData(Dataset):\n    def __init__(self, df, config=Config, augments=None, is_test=False):\n        self.df = df\n        self.augments = augments\n        self.is_test = is_test\n        self.config = config\n        \n        self.img_paths = self._get_img_paths(self.df, self.config)\n        self.meta_feats = self._get_meta_feats(self.df, self.is_test)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.img_paths[idx])\n        img = cv2.resize(img, (Config['IMG_SIZE'], Config['IMG_SIZE']))\n        meta_feats = torch.tensor(self.meta_feats.iloc[idx].values).float()\n\n        if self.augments:\n            img = Image.fromarray(img)\n            img = self.augments(img)\n        \n        if self.is_test:\n            return (img, meta_feats)\n        else:\n            target = torch.tensor(self.df['Pawpularity'].iloc[idx]).float()\n            return (img, meta_feats, target)\n    \n    def __len__(self):\n        return len(self.df)\n\n    def _get_img_paths(self, df, config):\n        \"\"\"\n        Returns the image paths in a list\n        \"\"\"\n        imgs = df['Id'].apply(lambda x: os.path.join(config['IMG_PATH'], x + \".jpg\")).tolist()\n        return imgs\n    \n    def _get_meta_feats(self, df, is_test):\n        \"\"\"\n        Returns the meta features in a df\n        \"\"\"\n        if self.is_test:\n            meta = self.df.drop(['Id'], axis=1)\n            return meta\n        else:\n            meta = self.df.drop(['Id', 'Pawpularity'], axis=1)\n            return meta","metadata":{"id":"V2kmmhnisUgC","papermill":{"duration":0.023961,"end_time":"2021-11-22T12:55:14.837033","exception":false,"start_time":"2021-11-22T12:55:14.813072","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegressionHeadModel(nn.Module):\n    def __init__(self, backbone_arch, pretrained=True, in_chans=3):\n        super(RegressionHeadModel, self).__init__()\n        self.backbone = models.poolformer_m36(pretrained=pretrained)\n        load_checkpoint(model=self.backbone, checkpoint_path=backbone_arch)\n        self.backbone.head = nn.Linear(self.backbone.head.in_features, 128)\n        self.drop = nn.Dropout(0.3)\n        self.fc1 = nn.Linear(140, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.fc3 = nn.Linear(32, 1)\n    \n    def forward(self, img, meta):\n        emb = self.backbone(img)\n        x = self.drop(emb)\n        x = torch.cat([x, meta], dim=1)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.fc3(x)\n\n        return x","metadata":{"id":"aIys8hdbv47i","papermill":{"duration":0.034265,"end_time":"2021-11-22T12:55:14.881725","exception":false,"start_time":"2021-11-22T12:55:14.84746","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mixup_augmentation(x:torch.Tensor, y:torch.Tensor, alpha:float = 1.0):\n    \"\"\"\n    Function which performs Mixup augmentation\n    \"\"\"\n    assert alpha > 0, \"Alpha must be greater than 0\"\n    assert x.shape[0] > 1, \"Need more than 1 sample to apply mixup\"\n\n    lam = np.random.beta(alpha, alpha)\n    rand_idx = torch.randperm(x.shape[0])\n    mixed_x = lam * x + (1 - lam) * x[rand_idx, :]\n\n    target_a, target_b = y, y[rand_idx]\n\n    return mixed_x, target_a, target_b, lam","metadata":{"id":"cTBi1vKPs3j8","papermill":{"duration":0.031065,"end_time":"2021-11-22T12:55:14.931026","exception":false,"start_time":"2021-11-22T12:55:14.899961","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Augments:\n    IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n    IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n    train_augments = T.Compose(\n            [\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                T.ToTensor(),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        )\n    valid_augments = T.Compose(\n            [\n                T.ToTensor(),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        )","metadata":{"id":"yzzrD7XugseU","papermill":{"duration":0.032324,"end_time":"2021-11-22T12:55:15.08286","exception":false,"start_time":"2021-11-22T12:55:15.050536","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Inferencer:\n    def __init__(self, config, dataloader, model, device=\"cuda:0\", apex=False):\n        self.test_loader= dataloader\n        self.model = model\n        self.device = torch.device(device)\n        self.config = config\n\n   \n    @torch.no_grad()\n    def inference(self):\n        \"\"\"\n        Inference\n        \"\"\"\n        self.model.eval()\n        test_pbar = tqdm(enumerate(self.test_loader), total=len(self.test_loader))\n        test_preds = []\n\n        for idx, cache in test_pbar:\n            img = self._convert_if_not_tensor(cache[0], dtype=torch.float32)\n            meta = self._convert_if_not_tensor(cache[1], dtype=torch.float32)\n\n            output = self.model(img, meta).squeeze()\n\n            output = output.sigmoid().detach() * 100.0\n\n            test_preds += [output.cpu().numpy()]\n\n        all_test_preds = np.concatenate(test_preds)\n        \n        # Tidy\n        del img, meta, test_preds,  output\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        return all_test_preds\n\n\n\n    def _convert_if_not_tensor(self, x, dtype):\n        if self._tensor_check(x):\n            return x.to(self.device, dtype=dtype)\n        else:\n            return torch.tensor(x, dtype=dtype, device=self.device)\n\n    def _tensor_check(self, x):\n        return isinstance(x, torch.Tensor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    test_file = pd.read_csv(Config['CSV_PATH'])    \n    submission_df=pd.DataFrame(columns=[\"Id\",\"Pawpularity\"])\n    submission_df[\"Id\"]=test_file[\"Id\"]\n    for fold in range(Config[\"N_SPLITS\"]): \n        test_set = PetfinderData(\n            df = test_file,\n            config = Config,\n            is_test=True,\n            augments=Augments.valid_augments)\n\n\n        test_loader = DataLoader(\n            test_set,\n            batch_size = Config['TRAIN_BS'],\n            shuffle = False,\n            num_workers = Config['NUM_WORKERS'],\n            pin_memory = True\n        )\n\n        model = RegressionHeadModel(backbone_arch=Config['ARCH'])\n        model = model.to(torch.device(Config['DEVICE']))\n\n        model.load_state_dict(torch.load(f\"../input/pet-pawpularity-poolformer/models/poolformer_s36_fold_{fold}_model.bin\"))\n\n        inferencer = Inferencer(\n            config = Config,\n            dataloader=test_loader,\n            model = model,\n            apex=True\n        )\n\n        fold_pred = inferencer.inference()\n\n        submission_df[fold] = fold_pred\n    submission_df[\"Pawpularity\"]=(submission_df[0] +submission_df[1] +submission_df[2] +submission_df[3] +submission_df[4])/5.0\n    submission_df[[\"Id\",\"Pawpularity\"]].to_csv(\"submission.csv\", index=None)\n    submission_df.head()","metadata":{"papermill":{"duration":20562.426512,"end_time":"2021-11-22T18:37:57.526652","exception":false,"start_time":"2021-11-22T12:55:15.10014","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}