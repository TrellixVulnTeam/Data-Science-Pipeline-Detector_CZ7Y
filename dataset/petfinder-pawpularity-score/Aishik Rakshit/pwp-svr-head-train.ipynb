{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%sh\npip install -U --no-build-isolation --no-deps ../input/pytorch-timm/pytorch-image-models-master/ -qq","metadata":{"id":"-JO6jg8LrzbZ","papermill":{"duration":38.86128,"end_time":"2021-11-22T12:55:06.244959","exception":false,"start_time":"2021-11-22T12:54:27.383679","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T06:37:44.472314Z","iopub.execute_input":"2022-01-06T06:37:44.472628Z","iopub.status.idle":"2022-01-06T06:38:08.417613Z","shell.execute_reply.started":"2022-01-06T06:37:44.472544Z","shell.execute_reply":"2022-01-06T06:38:08.41654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cuml, pickle\nfrom cuml.svm import SVR\nfrom cuml.ensemble import RandomForestRegressor as cuRFR\nprint('RAPIDS version',cuml.__version__,'\\n')\n\nimport os\nimport cv2\nimport timm\nfrom timm.models import load_checkpoint\n\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader\n\nimport gc\nimport wandb\nimport warnings\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\nwarnings.simplefilter('ignore')","metadata":{"id":"rK-YtcAWrr5U","papermill":{"duration":8.459847,"end_time":"2021-11-22T12:55:14.716131","exception":false,"start_time":"2021-11-22T12:55:06.256284","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T06:38:08.419745Z","iopub.execute_input":"2022-01-06T06:38:08.420078Z","iopub.status.idle":"2022-01-06T06:38:12.535964Z","shell.execute_reply.started":"2022-01-06T06:38:08.420015Z","shell.execute_reply":"2022-01-06T06:38:12.535125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Config = {\n    'CSV_PATH': \"../input/petfinder-pawpularity-score/train.csv\",\n    'IMG_PATH': \"../input/petfinder-pawpularity-score/train\",\n    'N_ACCUM': 2,\n    'N_SPLITS': 5,\n    'TRAIN_BS': 64,\n    'VALID_BS': 64,\n    'N_EPOCHS': 5,\n    'NUM_WORKERS': 4,\n    'LR': 1e-5,\n    'OPTIM': \"AdamW\",\n    'LOSS': \"BCELogits\",\n    'ARCH': \"swin_large_patch4_window12_384_in22k\",\n    'IMG_SIZE': 384,\n    'DEVICE': \"cuda\",\n    \"T_0\": 20,\n    \"Î·_min\": 1e-4,\n    'infra': \"Kaggle\",\n    'competition': 'petfinder',\n    '_wandb_kernel': 'tanaym',\n    \"wandb\": False,\n}","metadata":{"id":"LyoL1zR_stux","papermill":{"duration":0.018392,"end_time":"2021-11-22T12:55:14.802359","exception":false,"start_time":"2021-11-22T12:55:14.783967","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T06:38:12.537542Z","iopub.execute_input":"2022-01-06T06:38:12.538394Z","iopub.status.idle":"2022-01-06T06:38:12.545112Z","shell.execute_reply.started":"2022-01-06T06:38:12.538351Z","shell.execute_reply":"2022-01-06T06:38:12.544222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(output, target):\n    \"\"\"\n    Returns root mean squared error loss\n    \"\"\"\n    return mean_squared_error(output, target, squared=False)","metadata":{"id":"TcKg0-K8c_OK","papermill":{"duration":0.017684,"end_time":"2021-11-22T12:55:14.773075","exception":false,"start_time":"2021-11-22T12:55:14.755391","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-06T06:38:12.547661Z","iopub.execute_input":"2022-01-06T06:38:12.547975Z","iopub.status.idle":"2022-01-06T06:38:12.557661Z","shell.execute_reply.started":"2022-01-06T06:38:12.547935Z","shell.execute_reply":"2022-01-06T06:38:12.556904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetfinderData(Dataset):\n    def __init__(self, df, config=Config, augments=None, is_test=False):\n        self.df = df\n        self.augments = augments\n        self.is_test = is_test\n        self.config = config\n        \n        self.img_paths = self._get_img_paths(self.df, self.config)\n        self.meta_feats = self._get_meta_feats(self.df, self.is_test)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.img_paths[idx])\n        img = cv2.resize(img, (Config['IMG_SIZE'], Config['IMG_SIZE']))\n        meta_feats = torch.tensor(self.meta_feats.iloc[idx].values).float()\n\n        if self.augments:\n            img = Image.fromarray(img)\n            img = self.augments(img)\n        \n        if self.is_test:\n            return (img, meta_feats)\n        else:\n            target = torch.tensor(self.df['Pawpularity'].iloc[idx]).float()\n            return (img, meta_feats, target)\n    \n    def __len__(self):\n        return len(self.df)\n\n    def _get_img_paths(self, df, config):\n        \"\"\"\n        Returns the image paths in a list\n        \"\"\"\n        imgs = df['Id'].apply(lambda x: os.path.join(config['IMG_PATH'], x + \".jpg\")).tolist()\n        return imgs\n    \n    def _get_meta_feats(self, df, is_test):\n        \"\"\"\n        Returns the meta features in a df\n        \"\"\"\n        if self.is_test:\n            meta = self.df.drop(['Id'], axis=1)\n            return meta\n        else:\n            meta = self.df.drop(['Id', 'Pawpularity'], axis=1)\n            return meta","metadata":{"id":"V2kmmhnisUgC","papermill":{"duration":0.023961,"end_time":"2021-11-22T12:55:14.837033","exception":false,"start_time":"2021-11-22T12:55:14.813072","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T06:38:12.55876Z","iopub.execute_input":"2022-01-06T06:38:12.560604Z","iopub.status.idle":"2022-01-06T06:38:12.572576Z","shell.execute_reply.started":"2022-01-06T06:38:12.560518Z","shell.execute_reply":"2022-01-06T06:38:12.571595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegressionHeadModel(nn.Module):\n    def __init__(self, backbone_arch, pretrained= False, in_chans=3):\n        super(RegressionHeadModel, self).__init__()\n        self.backbone = timm.create_model(backbone_arch, pretrained=pretrained)\n        self.backbone.head = nn.Linear(self.backbone.head.in_features, 128)\n        self.drop = nn.Dropout(0.3)\n        self.fc1 = nn.Linear(140, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.fc3 = nn.Linear(32, 1)\n    \n    def forward(self, img, meta):\n        emb = self.backbone(img)\n        x = self.drop(emb)\n        x = torch.cat([x, meta], dim=1)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.fc3(x)\n        concatenated = torch.cat([x, emb, meta], dim=1)\n        return concatenated","metadata":{"id":"aIys8hdbv47i","papermill":{"duration":0.034265,"end_time":"2021-11-22T12:55:14.881725","exception":false,"start_time":"2021-11-22T12:55:14.84746","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T06:38:12.573717Z","iopub.execute_input":"2022-01-06T06:38:12.574432Z","iopub.status.idle":"2022-01-06T06:38:12.584937Z","shell.execute_reply.started":"2022-01-06T06:38:12.574392Z","shell.execute_reply":"2022-01-06T06:38:12.584228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mixup_augmentation(x:torch.Tensor, y:torch.Tensor, alpha:float = 1.0):\n    \"\"\"\n    Function which performs Mixup augmentation\n    \"\"\"\n    assert alpha > 0, \"Alpha must be greater than 0\"\n    assert x.shape[0] > 1, \"Need more than 1 sample to apply mixup\"\n\n    lam = np.random.beta(alpha, alpha)\n    rand_idx = torch.randperm(x.shape[0])\n    mixed_x = lam * x + (1 - lam) * x[rand_idx, :]\n\n    target_a, target_b = y, y[rand_idx]\n\n    return mixed_x, target_a, target_b, lam","metadata":{"id":"cTBi1vKPs3j8","papermill":{"duration":0.031065,"end_time":"2021-11-22T12:55:14.931026","exception":false,"start_time":"2021-11-22T12:55:14.899961","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T06:38:12.586338Z","iopub.execute_input":"2022-01-06T06:38:12.586794Z","iopub.status.idle":"2022-01-06T06:38:12.594872Z","shell.execute_reply.started":"2022-01-06T06:38:12.586755Z","shell.execute_reply":"2022-01-06T06:38:12.594072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Augments:\n    IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n    IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n    train_augments = T.Compose(\n            [\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                T.ToTensor(),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        )\n    valid_augments = T.Compose(\n            [\n                T.ToTensor(),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        )","metadata":{"id":"yzzrD7XugseU","papermill":{"duration":0.032324,"end_time":"2021-11-22T12:55:15.08286","exception":false,"start_time":"2021-11-22T12:55:15.050536","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T06:38:12.596215Z","iopub.execute_input":"2022-01-06T06:38:12.596602Z","iopub.status.idle":"2022-01-06T06:38:12.604862Z","shell.execute_reply.started":"2022-01-06T06:38:12.596566Z","shell.execute_reply":"2022-01-06T06:38:12.604078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SVRModule:\n    def __init__(self, config, dataloaders, model, device=\"cuda:0\", apex=False):\n        self.train_loader, self.valid_loader= dataloaders\n        self.model = model\n        self.device = torch.device(device)\n        self.config = config\n\n   \n    @torch.no_grad()\n    def fit(self, model_name):\n        \"\"\" \n        SVR Training\n        \"\"\"\n        self.model.eval()\n        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n        train_preds = []\n        train_targets = []\n        train_embeddings = []\n\n        for idx, cache in train_pbar:\n            img = self._convert_if_not_tensor(cache[0], dtype=torch.float32)\n            meta = self._convert_if_not_tensor(cache[1], dtype=torch.float32)\n            target = self._convert_if_not_tensor(cache[2], dtype=torch.float32)\n            \n            output = self.model(img, meta).squeeze()\n            \n            embedding = output[:, 1:]\n            output = output[:, 0]\n            \n            output = output.sigmoid() * 100.0\n            \n            train_preds += [output.cpu().numpy()]\n            train_embeddings += [embedding.cpu().numpy()]\n            train_targets += [target.cpu().numpy()]\n            \n        all_train_preds = np.concatenate(train_preds)\n        all_train_embeddings = np.concatenate(train_embeddings)\n        all_train_targets = np.concatenate(train_targets)\n        \n        del self.model \n        gc.collect()\n        \n        print('Fitting SVR...')\n#         clf = SVR(C=20.0)\n        clf = cuRFR(max_features=1.0, n_bins=128,\n                    min_samples_leaf=1,\n                    min_samples_split=2,\n                    n_estimators=100, accuracy_metric='r2')\n        clf.fit(all_train_embeddings.astype('float32'), all_train_targets.astype('int32'))\n        \n        pickle.dump(clf, open(model_name, \"wb\"))\n        # Tidy\n        del img, meta, train_preds,  output, train_embeddings, all_train_embeddings, all_train_preds, train_targets, all_train_targets\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        return clf\n\n    @torch.no_grad()\n    def validation(self, model_name):\n        \"\"\" \n        SVR Validation\n        \"\"\"\n        \n        clf = pickle.load(open(model_name, \"rb\"))\n        self.model.eval()\n        valid_pbar = tqdm(enumerate(self.valid_loader), total=len(self.valid_loader))\n        valid_preds = []\n        valid_embeddings = []\n        valid_targets = []\n\n        for idx, cache in valid_pbar:\n            img = self._convert_if_not_tensor(cache[0], dtype=torch.float32)\n            meta = self._convert_if_not_tensor(cache[1], dtype=torch.float32)\n            target = self._convert_if_not_tensor(cache[2], dtype=torch.float32)\n            output = self.model(img, meta).squeeze()\n\n            embedding = output[:, 1:]\n            output = output[:, :1]\n            \n            output=output.sigmoid() * 100\n            \n            valid_preds += [output.cpu().numpy()]\n            valid_embeddings += [embedding.cpu().numpy()]\n            valid_targets += [target.cpu().numpy()]\n            \n        all_valid_preds = np.concatenate(valid_preds)\n        all_valid_embeddings = np.concatenate(valid_embeddings)\n        all_valid_targets = np.concatenate(valid_targets)\n        \n        all_valid_SVR_prediction = clf.predict(all_valid_embeddings)\n        loss_SVR = rmse(all_valid_SVR_prediction, all_valid_targets)\n        \n        loss_nn = rmse(all_valid_preds, all_valid_targets)\n        \n        ensemble_prediction = (all_valid_SVR_prediction + all_valid_preds.reshape(-1))/2.0\n        loss_ensemble = rmse(ensemble_prediction, all_valid_targets)\n        \n        print(f\"Valid RF Loss: {loss_SVR} Valid NN Loss: {loss_nn} Valid Ensemble Loss: {loss_ensemble}\")\n        # Tidy\n        del img, meta, valid_preds, valid_targets, valid_embeddings, all_valid_preds, all_valid_targets, all_valid_embeddings, output, target, embedding, all_valid_SVR_prediction, ensemble_prediction\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        return loss_ensemble\n\n    def _convert_if_not_tensor(self, x, dtype):\n        if self._tensor_check(x):\n            return x.to(self.device, dtype=dtype)\n        else:\n            return torch.tensor(x, dtype=dtype, device=self.device)\n\n    def _tensor_check(self, x):\n        return isinstance(x, torch.Tensor)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T06:53:46.619404Z","iopub.execute_input":"2022-01-06T06:53:46.61968Z","iopub.status.idle":"2022-01-06T06:53:46.641819Z","shell.execute_reply.started":"2022-01-06T06:53:46.619651Z","shell.execute_reply":"2022-01-06T06:53:46.641088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    test_file = pd.read_csv(Config['CSV_PATH'])    \n    submission_df=pd.DataFrame(columns=[\"Id\",\"Pawpularity\"])\n    submission_df[\"Id\"]=test_file[\"Id\"]\n    kf = StratifiedKFold(n_splits=Config['N_SPLITS'])\n    train_file = pd.read_csv(Config['CSV_PATH'])\n    loss=0 \n    \n    for fold_, (train_idx, valid_idx) in enumerate(kf.split(X=train_file, y=train_file['Pawpularity'])):\n        print(f\"{'='*40} Fold: {fold_+1} / {Config['N_SPLITS']} {'='*40}\")\n        \n        train_ = train_file.loc[train_idx]\n        valid_ = train_file.loc[valid_idx]\n        train_set = PetfinderData(\n            df = train_,\n            config = Config,\n            is_test=False,\n            augments=Augments.valid_augments\n        )\n        valid_set = PetfinderData(\n            df = valid_,\n            config = Config,\n            is_test=False,\n            augments=Augments.valid_augments\n        )\n        \n        train_loader = DataLoader(\n            train_set,\n            batch_size = Config['TRAIN_BS'],\n            shuffle = False,\n            num_workers = Config['NUM_WORKERS'],\n            pin_memory = True\n        )\n        valid_loader = DataLoader(\n            valid_set,\n            batch_size = Config['TRAIN_BS'],\n            shuffle = False,\n            num_workers = Config['NUM_WORKERS'],\n            pin_memory = True\n        )          \n\n        model = RegressionHeadModel(backbone_arch=Config['ARCH'])\n        model = model.to(torch.device(Config['DEVICE']))\n\n        model.load_state_dict(torch.load(f\"../input/pwp-swintransformer/models/swin_large_patch4_window12_384_in22k_{fold_}_model.bin\"))\n\n        svrmodule = SVRModule(\n            config = Config,\n            dataloaders=(train_loader, valid_loader),\n            model = model,\n            apex=True\n        )\n        clf= svrmodule.fit(f'swin_large_patch4_window12_384_in22k_RF_{fold_}.pkl')\n        \n        svrmodule = SVRModule(\n            config = Config,\n            dataloaders=(train_loader, valid_loader),\n            model = model,\n            apex=True\n        )\n        loss += svrmodule.validation(f'swin_large_patch4_window12_384_in22k_RF_{fold_}.pkl')\n        print(f\"Cross Validation Loss Mean: {loss/5.0}\")","metadata":{"papermill":{"duration":20562.426512,"end_time":"2021-11-22T18:37:57.526652","exception":false,"start_time":"2021-11-22T12:55:15.10014","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T06:53:47.353061Z","iopub.execute_input":"2022-01-06T06:53:47.353559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}