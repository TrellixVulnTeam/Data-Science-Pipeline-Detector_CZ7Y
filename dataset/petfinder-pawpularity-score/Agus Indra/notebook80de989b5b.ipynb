{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"NIM: 6701194043\n\nNama: Muhammad Agus Indra Dharmawan\n\nKelas: D3SI-43-04\n\n","metadata":{"id":"XfSnJqLLk-SF"}},{"cell_type":"markdown","source":"#Assessment 2: PetFinder.my - Pawpularity Contest\n**Memprediksi popularitas foto hewan peliharaan yang ada di penampungan**\n\n**Link kompetisi:** https://www.kaggle.com/c/petfinder-pawpularity-score/overview\n\nJutaan hewan liar menderita di jalanan dan di tempat penampungan setiap hari di seluruh dunia. Anda mungkin mengharapkan hewan peliharaan dengan foto yang menarik untuk meningkatkan lebih banyak minat orang sehingga dapat diadopsi lebih cepat. Tapi apa yang membuat gambar bagus? Dengan bantuan data science anda mungkin dapat secara akurat menentukan daya tarik foto hewan peliharaan dan bahkan menyarankan perbaikan untuk memberi hewan penyelamat ini kesempatan yang lebih tinggi untuk diadopsi.\n\nPetFinder.my adalah platform kesejahteraan hewan terkemuka di Malaysia, menampilkan lebih dari 180.000 hewan dengan 54.000 diantaranya telah diadopsi. PetFinder bekerja sama dengan pecinta hewan, media, perusahaan, dan organisasi global untuk meningkatkan kesejahteraan hewan.\n\nSaat ini, PetFinder.my menggunakan Pengukur Kelucuan (*Cuteness Meter*) untuk menentukan peringkat foto hewan peliharaan. Tool ini menganalisis komposisi gambar dan faktor lain dibandingkan dengan kinerja ribuan profil hewan peliharaan. Meskipun tool dasar ini bermanfaat, tool ini masih dalam tahap percobaan dan performansi algoritma masih dapat ditingkatkan.\n\nDalam kompetisi ini, Anda akan menganalisis **gambar mentah** dan **metadata** untuk memprediksi **\"Pawpularity\"** foto hewan peliharaan. Anda akan melatih dan menguji model Anda di ribuan profil hewan peliharaan PetFinder.my. Versi pemenang akan menawarkan rekomendasi akurat yang akan meningkatkan kesejahteraan hewan.\n\nJika berhasil, solusi Anda akan diadaptasi menjadi tool kecerdasan buatan yang akan memandu tempat penampungan dan penyelamat di seluruh dunia untuk meningkatkan daya tarik profil hewan peliharaan mereka, secara otomatis meningkatkan kualitas foto, dan merekomendasikan perbaikan komposisi. Akibatnya, anjing dan kucing liar dapat menemukan rumah mereka lebih cepat. Dengan sedikit bantuan dari komunitas Kaggle, banyak nyawa yang berharga dapat diselamatkan dan lebih banyak keluarga bahagia tercipta.\n\nPeserta teratas dapat diundang untuk berkolaborasi dalam mengimplementasikan solusi mereka dan secara kreatif meningkatkan kesejahteraan hewan global dengan keterampilan AI mereka.\n","metadata":{"id":"iKUzARBEDX9W"}},{"cell_type":"markdown","source":"**Jenis data yang disediakan**\n\n**1. Photo Metadata**\nFile **train.csv dan test.csv** masing-masing berisi metadata untuk foto di data pelatihan dan data pengujian. Setiap foto hewan peliharaan diberi label dengan nilai 1 (Ya) atau 0 (Tidak) untuk setiap fitur berikut:\n\nFocus - Hewan peliharaan menonjol dengan latar belakang yang rapi, tidak terlalu dekat / jauh.\n\nEyes - Kedua mata menghadap ke depan atau dekat ke depan, dengan setidaknya 1 mata / pupil cukup jelas.\n\nFace - Wajah yang cukup jernih, menghadap ke depan atau dekat ke depan.\n\nNear - Hewan peliharaan tampil dominan pada foto (kira-kira lebih dari 50% lebar atau tinggi foto).\n\nAction - Hewan peliharaan sedang beraksi (mis., Melompat).\n\nAccessory - Aksesori / penyangga fisik atau digital yang dipakai oleh hewan ( mainan, stiker digital, dll), tidak termasuk kerah dan tali.\n\nGroup - Lebih dari 1 hewan peliharaan di foto.\n\nCollage - Foto yang diubah secara digital (yaitu dengan bingkai foto digital, kombinasi beberapa foto).\n\nHuman - Terdapat orang yang ada di foto.\n\nOcclusion - Objek tertentu yang tidak diinginkan menghalangi bagian dari hewan peliharaan (yaitu manusia, kandang atau pagar). Perhatikan bahwa tidak semua objek yang menghalangi dianggap sebagai occlusion.\n\nInfo - Teks atau label yang ditambahkan khusus (yaitu nama hewan peliharaan, deskripsi).\n\nBlur - Terlihat tidak fokus atau terdapat noise, terutama untuk mata dan wajah hewan peliharaan. Untuk entri Blur, kolom \"Eyes\" selalu disetel ke 0.\n\n**2. File foto**\nFoto asli hewan peliharaan dengan nama file sesuai dengan **kolom ID** yang ada pada **train.csv**. File foto ini tidak bisa langsung dipakai oleh algoritma machine learning sehingga harus dilakukan ekstraksi fitur. **Ekstraksi fitur bertujuan untuk mengkonversi foto menjadi nilai numerik** yang bisa dijadikan input ke algoritma machine learning.\n\n**Keterangan:**\n1. Anda bisa menggunakan dua jenis data tersebut atau hanya memilih salah satu.\n\n2. Anda bebas menggunakan metode untuk seleksi fitur, ekstraksi fitur, dan regressor untuk menghasilkan **Root Mean Square Error (RMSE)** terendah.\n3. Anda wajib menuliskan jawaban pada cell yang terdapat tulisan **\"#Isi jawaban di sini\"**","metadata":{"id":"08Fse4VHF3B9"}},{"cell_type":"markdown","source":"#Install library skfeature","metadata":{"id":"OeYgMyG5Ji5D"}},{"cell_type":"code","source":"!pip install skfeature-chappers","metadata":{"id":"ML49iGnM7dh7","outputId":"08d02ca0-e466-469d-ed8a-20dfb707f7e8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Import library yang dibutuhkan dan mount Google Drive","metadata":{"id":"aO9Rv3hoJ1OB"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom skfeature.function.similarity_based import fisher_score, reliefF, trace_ratio\nfrom skfeature.function.statistical_based import f_score, chi_square, gini_index\nfrom skfeature.function.information_theoretical_based import FCBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\n\nfrom google.colab import drive\ndrive.mount('/content/drive', force_remount=True)\n%cd /content/drive/My Drive/dataset_ilmu_data\n!ls","metadata":{"id":"-nRg3nqU7vLP","outputId":"43c378c5-7aba-4c0b-b869-3333c81beda8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Load dataset metadata untuk memprediksi Pawpularity","metadata":{"id":"11zKGefmKWUn"}},{"cell_type":"code","source":"#load data google drive\ndf_train_metadata = pd.read_csv('/content/drive/My Drive/dataset_ilmu_data/assessment/petfinder/train.csv')\ndf_test_metadata = pd.read_csv('/content/drive/My Drive/dataset_ilmu_data/assessment/petfinder/test.csv')","metadata":{"id":"X-F2Ar5P70Ql"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Load file gambar dari pet (hewan peliharaan)","metadata":{"id":"bhlydwBOuYCE"}},{"cell_type":"code","source":"import tensorflow as tf\nimport cv2\nimport missingno as msno\n\ntrain_image = df_train_metadata.copy()\ntest_image = df_test_metadata.copy()\n\ntrain_image[\"file_path\"] = df_train_metadata[\"Id\"].apply(lambda x: \"/content/drive/My Drive/dataset_ilmu_data/assessment/petfinder/train/\" + x + \".jpg\")\ntest_image[\"file_path\"] = df_test_metadata[\"Id\"].apply(lambda x: \"/content/drive/My Drive/dataset_ilmu_data/assessment/petfinder/test/\" + x + \".jpg\")\n\nplt.figure(figsize=(20, 20))\nrow, col = 5, 4\nfor i in range(row * col):\n    plt.subplot(row, col, i+1)\n    image = cv2.imread(train_image.loc[i, 'file_path'])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    target = train_image.loc[i, 'Pawpularity']\n    plt.imshow(image)\n    plt.title(f\"No: {i}\" f\"   Pawpularity: {target}\")\nplt.show()\n\n# def preprocess(image_url):\n#   image_string = tf.io.read_file(image_url)\n#   image = tf.image.decode_jpeg(image_string, channels=3)\n#   image = tf.cast(image, tf.float32) / 255.0\n#   image = tf.image.central_crop(image, 1.0)\n#   image = tf.image.resize(image, (128, 128))\n#   return image\n\n# x_train_image=[]\n# for i in train_image['file_path']:\n#     x1=preprocess(i)\n#     x_train_image.append(x1)\n\n#x_train_image = pd.DataFrame(x_train_image)\n\n#print(x_train_image)\n#x_train_image.to_csv('image_features.csv')","metadata":{"id":"vDqreNDG_B0S","outputId":"9c78b714-4930-4966-926c-52a132e00708"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Contoh ekstraksi fitur gambar menggunakan fitur statistik, ex: mean, stdev, skewness, kurtosis pada sumbu-x dan sumbu-y gambar (anda boleh menggunakan metode ekstraksi yang lain)","metadata":{"id":"ktXuYZrJuuVB"}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n#Here is the business:\ndef image_statistics(Z):\n    #Input: Z, a 2D array, hopefully containing some sort of peak\n    #Output: cx,cy,sx,sy,skx,sky,kx,ky\n    #cx and cy are the coordinates of the centroid\n    #sx and sy are the stardard deviation in the x and y directions\n    #skx and sky are the skewness in the x and y directions\n    #kx and ky are the Kurtosis in the x and y directions\n    #Note: this is not the excess kurtosis. For a normal distribution\n    #you expect the kurtosis will be 3.0. Just subtract 3 to get the\n    #excess kurtosis.\n    import numpy as np\n\n    h,w = np.shape(Z)\n\n    x = range(w)\n    y = range(h)\n\n\n    #calculate projections along the x and y axes\n    yp = np.sum(Z,axis=1)\n    xp = np.sum(Z,axis=0)\n\n    #centroid\n    cx = np.sum(x*xp)/np.sum(xp)\n    cy = np.sum(y*yp)/np.sum(yp)\n\n    #standard deviation\n    x2 = (x-cx)**2\n    y2 = (y-cy)**2\n\n    sx = np.sqrt( np.sum(x2*xp)/np.sum(xp) )\n    sy = np.sqrt( np.sum(y2*yp)/np.sum(yp) )\n\n    #skewness\n    x3 = (x-cx)**3\n    y3 = (y-cy)**3\n\n    skx = np.sum(xp*x3)/(np.sum(xp) * sx**3)\n    sky = np.sum(yp*y3)/(np.sum(yp) * sy**3)\n\n    #Kurtosis\n    x4 = (x-cx)**4\n    y4 = (y-cy)**4\n    kx = np.sum(xp*x4)/(np.sum(xp) * sx**4)\n    ky = np.sum(yp*y4)/(np.sum(yp) * sy**4)\n\n\n    return cx,cy,sx,sy,skx,sky,kx,ky\n\n#We can check that the result is the same if we use the full 2D data array\ndef image_statistics_2D(Z):\n    h,w = np.shape(Z)\n\n    x = range(w)\n    y = range(h)\n\n    X,Y = np.meshgrid(x,y)\n\n    #Centroid (mean)\n    cx = np.sum(Z*X)/np.sum(Z)\n    cy = np.sum(Z*Y)/np.sum(Z)\n\n    ###Standard deviation\n    x2 = (range(w) - cx)**2\n    y2 = (range(h) - cy)**2\n\n    X2,Y2 = np.meshgrid(x2,y2)\n\n    #Find the variance\n    vx = np.sum(Z*X2)/np.sum(Z)\n    vy = np.sum(Z*Y2)/np.sum(Z)\n\n    #SD is the sqrt of the variance\n    sx,sy = np.sqrt(vx),np.sqrt(vy)\n\n    ###Skewness\n    x3 = (range(w) - cx)**3\n    y3 = (range(h) - cy)**3\n\n    X3,Y3 = np.meshgrid(x3,y3)\n\n    #Find the thid central moment\n    m3x = np.sum(Z*X3)/np.sum(Z)\n    m3y = np.sum(Z*Y3)/np.sum(Z)\n\n    #Skewness is the third central moment divided by SD cubed\n    skx = m3x/sx**3\n    sky = m3y/sy**3\n\n    ###Kurtosis\n    x4 = (range(w) - cx)**4\n    y4 = (range(h) - cy)**4\n\n    X4,Y4 = np.meshgrid(x4,y4)\n\n    #Find the fourth central moment\n    m4x = np.sum(Z*X4)/np.sum(Z)\n    m4y = np.sum(Z*Y4)/np.sum(Z)\n\n    #Kurtosis is the fourth central moment divided by SD to the fourth power\n    kx = m4x/sx**4\n    ky = m4y/sy**4\n\n    return cx,cy,sx,sy,skx,sky,kx,ky\n","metadata":{"id":"hm9cSuTiP0ZH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Melakukan ekstraksi fitur dari gambar\n File gambar akan diekstrak dan disimpan pada file \"image_features_train.csv\" dan \"image_features_test.csv\". **Proses ini agak lama, kalau sudah pernah dijalankan sebaiknya tidak usah dijalankan lagi kecuali ada perubahan.**","metadata":{"id":"QYw6k6Jru7nP"}},{"cell_type":"code","source":"from skimage.io import imread, imshow\n\n#df_label = pd.DataFrame(columns=['Label'])\n\nimage_features_train = pd.DataFrame(\n    columns=[\n             'centroid_pr_x','centroid_pr_y','stddev_pr_x','stddev_pr_y','skewness_pr_x','skewness_pr_y','kurtosis_pr_x','kurtosis_pr_y'\n                ])\n\nfor i in train_image[\"file_path\"]:\n    #print('image1:',df_train['image_1'][i])\n    image = cv2.imread(i)\n    #print('/content/drive/MyDrive/NDSC/training_img/{}'.format(df_train['image_1'][i]))\n    #print(image1)\n    #imshow(image);\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    #Calculate the image statistics using the projection method\n    stats_pr = image_statistics(gray_image)\n    print(stats_pr)\n    #Confirm that they are the same by using a 2D calculation\n    #stats_2d = image_statistics_2D(gray_image)\n    baris = [\n             stats_pr[0], stats_pr[1], stats_pr[2], stats_pr[3], stats_pr[4], stats_pr[5], stats_pr[6], stats_pr[7]\n            ]\n    \n    image_features_train.loc[len(image_features_train.index)] = baris\n\nimage_features_train.to_csv('/content/drive/My Drive/dataset_ilmu_data/assessment/petfinder/image_features_train.csv')","metadata":{"id":"7CxLappkQjWC","outputId":"8e4bb67b-740d-4031-df17-febef5a0b0d7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.io import imread, imshow\n\n#df_label = pd.DataFrame(columns=['Label'])\n\nimage_features_test = pd.DataFrame(\n    columns=[\n             'centroid_pr_x','centroid_pr_y','stddev_pr_x','stddev_pr_y','skewness_pr_x','skewness_pr_y','kurtosis_pr_x','kurtosis_pr_y'\n                ])\n\nfor i in test_image[\"file_path\"]:\n    #print('image1:',df_train['image_1'][i])\n    image = cv2.imread(i)\n    #print('/content/drive/MyDrive/NDSC/training_img/{}'.format(df_train['image_1'][i]))\n    #print(image1)\n    #imshow(image);\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    #Calculate the image statistics using the projection method\n    stats_pr = image_statistics(gray_image)\n    print(stats_pr)\n    #Confirm that they are the same by using a 2D calculation\n    #stats_2d = image_statistics_2D(gray_image)\n    baris = [\n             stats_pr[0], stats_pr[1], stats_pr[2], stats_pr[3], stats_pr[4], stats_pr[5], stats_pr[6], stats_pr[7]\n            ]\n    \n    image_features_test.loc[len(image_features_test.index)] = baris\n\nimage_features_test.to_csv('/content/drive/My Drive/dataset_ilmu_data/assessment/petfinder/image_features_test.csv')","metadata":{"id":"IrbABb_juJQn","outputId":"67c0e44e-5d5e-431a-cc45-7cb14c2c80fb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Load data hasil ekstraksi fitur gambar","metadata":{"id":"jAuAD_eMvm_Y"}},{"cell_type":"code","source":"#load data google drive\nimage_features_train = pd.read_csv('/content/drive/My Drive/dataset_ilmu_data/assessment/petfinder/image_features_train.csv')\nimage_features_test = pd.read_csv('/content/drive/My Drive/dataset_ilmu_data/assessment/petfinder/image_features_test.csv')","metadata":{"id":"v4k2vhR48Fys"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Menggabungkan fitur metadata dan fitur gambar","metadata":{"id":"n633Dm26ws05"}},{"cell_type":"code","source":"#df_train_metadata.loc[:,'Subject Focus':'Blur']\n\ndf_train = pd.concat([df_train_metadata['Pawpularity'], df_train_metadata.loc[:,'Subject Focus':'Blur'],image_features_train.loc[:,'centroid_pr_x':'kurtosis_pr_y']], axis=1)\ndf_test = pd.concat([df_test_metadata.loc[:,'Subject Focus':'Blur'],image_features_test.loc[:,'centroid_pr_x':'kurtosis_pr_y']], axis=1)\n\ndf_test.head(3)","metadata":{"id":"WYEgUEq4tjyN","outputId":"32afbf95-258c-4f56-a473-8594e3617285"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Soal no 1: Melakukan proses seleksi fitur (20 poin)\n1. Silahkan menggunakan salah satu algoritma seleksi fitur\n2. Jelaskan alasan penggunaan metode tersebut\n\n\n","metadata":{"id":"3Mhg19l0wpGW"}},{"cell_type":"code","source":"from skfeature.function.similarity_based import fisher_score, reliefF, trace_ratio\nfrom skfeature.function.statistical_based import f_score, chi_square, gini_index\nfrom skfeature.function.information_theoretical_based import FCBF, CMIM, JMI\n\n#ambil kolom untuk label diskrit\nlabel_diskrit = np.asarray(df_train['Pawpularity'])\n# print(label_diskrit)\n\n#ambil kolom untuk label kontinu\nlabel_kontinu = np.asarray(df_test['Face'])\n#print(label_kontinu)\n\n#ambil kolom untuk features\nfeatures = np.asarray(df_train.loc[:, 'Subject Focus':'Blur'])\n\n#melakukan label encoding label diskrit\nencoder = preprocessing.LabelEncoder().fit(label_diskrit)\ntransformed_label_diskrit = encoder.transform(label_diskrit)\n# print(transformed_label_diskrit)\n\n# melakukan feature scaling\nscaler = preprocessing.MinMaxScaler(feature_range=(0, 10)).fit(features)\nscaled_feature = scaler.transform(features)\n\n\nranked_index = fisher_score.fisher_score(scaled_feature, transformed_label_diskrit, mode='raw')\nprint(\"\\nfisher score raw\")\nprint(ranked_index)\n\n# menampilkan fitur yang sudah diurutkan berdasarkan seleksi fitur\nresult = scaled_feature[:, ranked_index[:]]\nprint(result)","metadata":{"id":"uN9H3RLn8iLK","outputId":"46fc00b2-97f8-40d6-c0fe-a8e1e19b97a0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Mendefinisikan fungsi Root Mean Square Error (RMSE) sebagai metrik/scoring performansi","metadata":{"id":"SOux7Yuywz_L"}},{"cell_type":"code","source":"def rmse(predict, actual):\n    predict = np.array(predict)\n    actual = np.array(actual)\n\n    distance = predict - actual\n\n    square_distance = distance ** 2\n\n    mean_square_distance = square_distance.mean()\n\n    score = np.sqrt(mean_square_distance)\n\n    return score","metadata":{"id":"ckTwqdju_DmJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Soal no 2: Menentukan kombinasi fitur dan parameter terbaik (20 poin)\nBerdasarkan hasil seleksi fitur, jumlah dan kombinasi fitur terbaik ditentukan termasuk melakukan optimasi hyperparameter","metadata":{"id":"l0rj7vARxhdU"}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVR\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import r2_score\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import AdaBoostClassifier\n\njumlah_fitur = range(1,scaled_feature.shape[1]+1)\nscores = []\nscore = 0\nbest_score = 0\nbest_feature_number = 0\n\n#Mencoba optimasi hyperparameter untuk setiap kombinasi/jumlah fitur\nfor jumlah_fitur_terbaik in jumlah_fitur:\n    #print(jumlah_fitur_terbaik)\n    selected_features = result[:,0:jumlah_fitur_terbaik]\n    #split data training dan data testing\n    X_train, X_test, y_train, y_test = train_test_split(selected_features, label_diskrit, test_size=0.3, random_state=0)\n\n    classifier = DecisionTreeClassifier()\n    #classifier = KNeighborsClassifier()\n    # classifier = SVC()\n    \n    # optimasi hyperparameter\n    param_grid = [\n    # {'n_neighbors':[3,5,7,9,11,13,15], 'metric':['euclidean','manhattan','chebyshev','minkowski','wminkowski','seuclidean','mahalanobis']}\n    # {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n    #{'n_estimators': [50, 100, 150, 200], 'criterion':['gini', 'entropy'], 'max_depth':[5, 10, 15], 'min_samples_split':[0.1, 1.0, 10], 'min_samples_leaf':[0.1, 0.5, 5]}\n    {'criterion':['gini', 'entropy'], 'max_depth':[5, 10, 15], 'min_samples_split':[0.1, 1.0, 10], 'min_samples_leaf':[0.1, 0.5, 5]}\n    #{'n_estimators': [50, 100, 150, 200],'learning_rate': [0.1,0.2,0.3],}\n    ]\n    \n    #menentukan prioritas scoring menggunakan apa (accuracy/precision/recall, dll)\n    metric = make_scorer(recall_score, average='weighted')\n\n    model = GridSearchCV(classifier, param_grid, scoring=metric, cv=5, refit = True, verbose = 3) \n    # fitting the model for grid search \n    model.fit(X_train, y_train)\n\n    # print best parameter after tuning \n    print(model.best_params_) \n      \n    # print how our model looks after hyper-parameter tuning \n    print(model.best_estimator_)\n\n    #model_predictions = model.predict(X_test) \n\n    #model.fit(X_train, y_train)\n    score = model.score(X_test, y_test)\n    scores.append(score)\n\n    #menentukan model terbaik berdasarkan score terbaik menggunakan kombinasi jumlah fitur dan optimasi hyperparameter\n    if(best_score < score):\n      best_score = score\n      best_model = model\n      best_feature_number = jumlah_fitur_terbaik\n      best_parameter = model.best_params_\n      \n      #menyimpan best_X_test dengan jumlah fitur terbaik\n      best_X_test = X_test\n\n\nplt.figure()\nplt.xlabel('jumlah_fitur_terbaik')\nplt.ylabel('score')\nplt.scatter(jumlah_fitur, scores)\nplt.grid()\n\nprint(scores);\nprint('Jumlah fitur terbaik adalah: ',best_feature_number)\nprint('Score terbaik adalah: ',best_score)\nprint('Parameter terbaik adalah: ',best_parameter)\n\nfinal_predictions = best_model.predict(best_X_test) \n  \n# print classification report \nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, final_predictions)) \n\n# plot confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(best_model, best_X_test, y_test)  \nplt.show()","metadata":{"id":"khcrWBo19rYo","outputId":"79fcea48-59c9-4ee3-9280-af3ff9ce77de"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Plot visualisasi hasil regresi\n\n","metadata":{"id":"pMHWr53ux2BT"}},{"cell_type":"code","source":"#isi jawaban plot regresi dt\nfrom sklearn.metrics import r2_score\n\nfig, ax = plt.subplots()\nax.text(1, 9.5,'$R^2=$'+str(round(r2_score(y_test, final_predictions),4)), fontsize=12, verticalalignment='top', multialignment='center')\nax.text(1, 9,'$MSE=$'+str(round(rmse(y_test, final_predictions),4)), fontsize=12, verticalalignment='top', multialignment='center')\n\nax.set_xlim(xmin=1)\nax.set_ylim(ymin=1)\nax.set_xlim(xmax=100)\nax.set_ylim(ymax=100)\n\nax.set_xlabel('Actual Value', fontsize=14)\nax.set_ylabel('Predicted Value', fontsize=14)\nax.scatter(y_test, final_predictions, s=100, c=y_test, cmap='viridis')\n\nlims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n]\n\n# now plot both limits against eachother\nax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\nax.set_aspect('equal')\nax.set_xlim(lims)\nax.set_ylim(lims)\nax.grid(True, which='both')\n\nxvalue = np.linspace(1,10,10)\nlsigma = ax.fill_between(xvalue, xvalue+1, xvalue-1, color='blue', alpha=0.3)\n\nplt.show()","metadata":{"id":"TahUzefaD16n","outputId":"93dde52a-660d-4e50-cbe5-033a5e58416f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Generate file hasil prediksi berdasarkan data testing dari Kaggle","metadata":{"id":"1Ss2qo81x9rU"}},{"cell_type":"code","source":"hasil_klasifikasi = classifier.predict(X_test)\ndf_hasil = pd.DataFrame({\"Id\":df_test.Id,\"Pawpularity\":hasil_klasifikasi})\n\n#menyimpan hasil di Google Drive masing-masing, silahkan di-download dan disubmit ke kaggle jika model sudah dirasa bagus\n#%cd /content/drive/MyDrive/Colab Notebooks/Assesment01/titanic/titanic_result.csv\ndf_hasil.to_csv('/content/drive/MyDrive/Colab Notebooks/assessment/ass2/petfinder/submission.csv', index=False)\ndf_hasil.head()","metadata":{"id":"fxnpIRBYmWah","outputId":"c45951d9-25ef-4d05-ddfb-0eb2387d0e09"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features_test = result_test[:, 0:best_feature_number]\nfinal_predictions = best_model.predict(selected_features) \nfinal_predictions\n\ndf_hasil = pd.DataFrame({\"Id\":df_train_metadata.Id,\"Pawpularity\":final_predictions})\n\ndf_hasil.to_csv('/content/drive/MyDrive/Colab Notebooks/assessment/ass2/petfinder/submission.csv', index=False)\ndf_hasil.head()","metadata":{"id":"6RWBaGr9TpFQ","outputId":"d44de958-7b3d-424f-c3a9-f9bdb7a6c4a2"},"execution_count":null,"outputs":[]}]}