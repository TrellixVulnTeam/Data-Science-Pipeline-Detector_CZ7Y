{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PetFinder | Identify Duplicates and Share Findings\n\n![](https://i.postimg.cc/W1TZZrhN/download-5.png)\n\nAs mentioned by the admin in the [discussion](https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/278309), there are duplicate images in the dataset. In this notebook, I will try to:\n* identify those duplicates\n* share the findings\n* create a dataset without the duplicates\n\nThe findings are also summarized in [Discussion](https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/278497).\n\nThe method for identifying duplicates is based on the [notebook \"Let's find out duplicate images with imagehash\"](https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash) shared by [Appian](https://www.kaggle.com/appian) for the previous PetFinder competition. This method uses image hashes, and is very simple yet powerful.\n\n# Table of Contents\n* [Identify duplicates](#1)\n* [Share the findings](#2)\n* [Create new dataset](#3)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# Identify duplicates\nAgain, this method is based on [Let's find out duplicate images with imagehash](https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash).","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:51:23.38297Z","iopub.execute_input":"2021-10-14T07:51:23.383755Z","iopub.status.idle":"2021-10-14T07:51:23.417922Z","shell.execute_reply.started":"2021-10-14T07:51:23.383688Z","shell.execute_reply":"2021-10-14T07:51:23.416225Z"}}},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport os\nimport glob\nimport itertools\nimport collections\n\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport pandas as pd\nimport numpy as np\nimport torch\nimport imagehash\n\nimport matplotlib.pyplot as plt\n\n\ntrain = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:05:48.435291Z","iopub.execute_input":"2021-10-15T05:05:48.435873Z","iopub.status.idle":"2021-10-15T05:05:53.066948Z","shell.execute_reply.started":"2021-10-15T05:05:48.43577Z","shell.execute_reply":"2021-10-15T05:05:53.066211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculate hash values of every train image. This takes around 10 minutes in a Kaggle Notebook.","metadata":{}},{"cell_type":"code","source":"def run():\n\n    funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash,\n    ]\n\n    petids = []\n    hashes = []\n    for path in tqdm(glob.glob('../input/petfinder-pawpularity-score/train/*.jpg')):\n\n        image = Image.open(path)\n        imageid = path.split('/')[-1].split('.')[0]\n\n        petids.append(imageid)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n\n    return petids, np.array(hashes)\n\n%time petids, hashes_all = run()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:05:53.068387Z","iopub.execute_input":"2021-10-15T05:05:53.068637Z","iopub.status.idle":"2021-10-15T05:15:23.287217Z","shell.execute_reply.started":"2021-10-15T05:05:53.068604Z","shell.execute_reply":"2021-10-15T05:15:23.286462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:23.288356Z","iopub.execute_input":"2021-10-15T05:15:23.289093Z","iopub.status.idle":"2021-10-15T05:15:28.4996Z","shell.execute_reply.started":"2021-10-15T05:15:23.289057Z","shell.execute_reply":"2021-10-15T05:15:28.49887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculate similarity (normalized to 0-1 range) between all image pairs.","metadata":{}},{"cell_type":"code","source":"%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:28.501389Z","iopub.execute_input":"2021-10-15T05:15:28.501641Z","iopub.status.idle":"2021-10-15T05:15:31.820902Z","shell.execute_reply.started":"2021-10-15T05:15:28.501611Z","shell.execute_reply":"2021-10-15T05:15:31.820033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define a function that allow us to display and retrieve the pairs with in a given threshold range of similarity.","metadata":{}},{"cell_type":"code","source":"def show_pairs(lower_sim=0.0, upper_sim=1.0, max_shown=100):\n    indices1 = np.where((sims > lower_sim) & (sims <= upper_sim))\n    indices2 = np.where(indices1[0] != indices1[1])\n    dups = {tuple(sorted([petids[index1], petids[index2]])): sims[index1, index2] \n                for index1, index2 in zip(indices1[0][indices2], indices1[1][indices2])}\n    print('Found %d pairs' % len(dups))\n    \n    cnt = 1\n    for (id1, id2), sim in dups.items():\n        path1 = f'../input/petfinder-pawpularity-score/train/{id1}.jpg'\n        path2 = f'../input/petfinder-pawpularity-score/train/{id2}.jpg'\n        pawp1 = train[train['Id'] == id1]['Pawpularity'].iloc[-1]\n        pawp2 = train[train['Id'] == id2]['Pawpularity'].iloc[-1]\n\n        image1 = cv2.imread(path1)\n        image2 = cv2.imread(path2)\n        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n        image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n\n        fig, axes = plt.subplots(nrows=1, ncols=2)\n        fig.set_size_inches(12, 6)\n        axes[0].title.set_text(f'Pawpularity: {pawp1} \\n ID: {id1}')\n        axes[0].imshow(image1)\n        axes[1].title.set_text(f'Pawpularity: {pawp2} \\n ID: {id2}')\n        axes[1].imshow(image2)\n        fig.suptitle(f'Simularity: {sim}')\n        plt.show()\n        \n        if cnt >= max_shown:\n            break\n        \n        cnt += 1\n    \n    return dups","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:31.822303Z","iopub.execute_input":"2021-10-15T05:15:31.822637Z","iopub.status.idle":"2021-10-15T05:15:31.861823Z","shell.execute_reply.started":"2021-10-15T05:15:31.822601Z","shell.execute_reply":"2021-10-15T05:15:31.861196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# Share the findings\n\nFirst, let's look at the distribution of similarity using a box plot. \n\nNote that the similarity is expressed in matrix form, and that we are only interested in the non-diagonal component, since the diagonal component is always 1, which is the similarity to itself.","metadata":{}},{"cell_type":"code","source":"def offdiagonal(X, axis1, axis2):\n    X = np.moveaxis(X, (axis1, axis2), (-2, -1))\n    *s, n, _ = X.shape\n    X = X.reshape(*s, n*n)[..., :-1].reshape(*s, n-1, n+1)[..., 1:].reshape(*s, n, n-1)\n    return np.moveaxis(X, (-2, -1), (axis1, axis2))\n\n\nplt.figure(figsize=(12, 4))\nplt.title('Distribution of similarity')\nplt.boxplot(offdiagonal(sims, 0, 1).flatten(), vert=False);","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:31.862747Z","iopub.execute_input":"2021-10-15T05:15:31.863067Z","iopub.status.idle":"2021-10-15T05:15:36.507703Z","shell.execute_reply.started":"2021-10-15T05:15:31.863033Z","shell.execute_reply":"2021-10-15T05:15:36.507045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this box plot, we can see isolated clusters around 1, which we assume to be duplicate images.\n\nNow, let's look at the images for each threshold range of similarity.","metadata":{}},{"cell_type":"markdown","source":"## Similarity 0.9 - 1\n\n* 27 pairs in this range\n* Most pairs are idendical, at least in appearance","metadata":{}},{"cell_type":"code","source":"dups_90_00 = show_pairs(0.9, 1.0, max_shown=5)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:36.509058Z","iopub.execute_input":"2021-10-15T05:15:36.50931Z","iopub.status.idle":"2021-10-15T05:15:39.603363Z","shell.execute_reply.started":"2021-10-15T05:15:36.509266Z","shell.execute_reply":"2021-10-15T05:15:39.602661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this range, almost all images appear to be duplicates. However, for those that do not have a similarity of 1, there must have been a very slight modification to the image. The most obvious pair is the one below, where you can observe that the right image has a slightly higher contrast.\n\n![](https://i.postimg.cc/KYnpctkn/pair1.png)","metadata":{}},{"cell_type":"markdown","source":"## Similarity 0.85 - 0.9\n- 5 pairs in this range\n- Interesting patterns can be seen.","metadata":{}},{"cell_type":"code","source":"dups_85_90 = show_pairs(0.85, 0.9, max_shown=5)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:39.604731Z","iopub.execute_input":"2021-10-15T05:15:39.605056Z","iopub.status.idle":"2021-10-15T05:15:42.577523Z","shell.execute_reply.started":"2021-10-15T05:15:39.605021Z","shell.execute_reply":"2021-10-15T05:15:42.576738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Interesting patterns\n- The same pet photographed at a slight different time  \n\n![](https://i.postimg.cc/wvgf13Ln/pairs2.png)  \n![](https://i.postimg.cc/7Lf7m4Db/pairs3.png)\n\n\n- Cropped\n\n![](https://i.postimg.cc/Pxy6YhMJ/pairs4.png)  \n![](https://i.postimg.cc/zBYBKYGs/pairs5.png)","metadata":{}},{"cell_type":"markdown","source":"## Similarity 0.8-0.85\n- 174 pairs in this range\n- Most of the pairs are completely different, but some interesting patterns can be seen.","metadata":{}},{"cell_type":"code","source":"dups_80_85 = show_pairs(0.80, 0.85, max_shown=5)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:42.578746Z","iopub.execute_input":"2021-10-15T05:15:42.579077Z","iopub.status.idle":"2021-10-15T05:15:45.605479Z","shell.execute_reply.started":"2021-10-15T05:15:42.579044Z","shell.execute_reply":"2021-10-15T05:15:45.604724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Interesting patterns\n- Different pets with the same background and the same frame  \n![](https://i.postimg.cc/Zn0LNNRs/download.png)\n\n- Similar pets with similar background and the same frame  \n![](https://i.postimg.cc/wxPXP73H/download-1.png)\n\n- Cropped  \n![](https://i.postimg.cc/br2t89dP/download-2.png)\n\n- Different pets with the same template  \n![](https://i.postimg.cc/P51Q1TXH/download-4.png)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# Create new dataset\nHere, I create a dataset that excludes only obvious duplicates with a similarity of 0.9 or higher.   \nYou can make your own dataset with different thresholds or processing of Pawpularity, too.\n\nThe dataset is also uploaded as a Kaggle Dataset. Feel free to use it.  \nhttps://www.kaggle.com/schulta/petfinder-pawpularity-score-clean","metadata":{}},{"cell_type":"code","source":"!mkdir ../working/petfinder-pawpularity-score-clean\n!cp -r ../input/petfinder-pawpularity-score/* ../working/petfinder-pawpularity-score-clean","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:45.607912Z","iopub.execute_input":"2021-10-15T05:15:45.608181Z","iopub.status.idle":"2021-10-15T05:15:55.098384Z","shell.execute_reply.started":"2021-10-15T05:15:45.608146Z","shell.execute_reply":"2021-10-15T05:15:55.097389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids1 = np.array(list(dups_90_00.keys()))[:, 0]\nids2 = np.array(list(dups_90_00.keys()))[:, 1]\n\ntrain_new = train[~train[\"Id\"].isin(ids2)]\ntrain_new = train_new.reset_index(drop=True)\n\ntrain_new.to_csv('../working/petfinder-pawpularity-score-clean/train.csv', \n                 index=False)\ntrain_new","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:55.099913Z","iopub.execute_input":"2021-10-15T05:15:55.100197Z","iopub.status.idle":"2021-10-15T05:15:55.209985Z","shell.execute_reply.started":"2021-10-15T05:15:55.100161Z","shell.execute_reply":"2021-10-15T05:15:55.209254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for id1, id2 in dups_90_00.keys():\n    path2 = f'../working/petfinder-pawpularity-score-clean/train/{id2}.jpg'\n    os.remove(path2)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T05:15:55.212294Z","iopub.execute_input":"2021-10-15T05:15:55.212786Z","iopub.status.idle":"2021-10-15T05:15:55.244717Z","shell.execute_reply.started":"2021-10-15T05:15:55.212741Z","shell.execute_reply":"2021-10-15T05:15:55.244077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}