{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/tez-lib/\")\nsys.path.append(\"../input/timmmaster/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-19T13:22:04.880408Z","iopub.execute_input":"2021-12-19T13:22:04.880661Z","iopub.status.idle":"2021-12-19T13:22:04.980188Z","shell.execute_reply.started":"2021-12-19T13:22:04.880585Z","shell.execute_reply":"2021-12-19T13:22:04.979444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport timm\nimport torch.nn as nn\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\nimport math","metadata":{"execution":{"iopub.status.busy":"2021-12-19T13:22:04.981932Z","iopub.execute_input":"2021-12-19T13:22:04.98244Z","iopub.status.idle":"2021-12-19T13:22:13.255678Z","shell.execute_reply.started":"2021-12-19T13:22:04.982402Z","shell.execute_reply":"2021-12-19T13:22:13.254827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi\n!mkdir paw-models","metadata":{"execution":{"iopub.status.busy":"2021-12-19T13:22:13.257037Z","iopub.execute_input":"2021-12-19T13:22:13.257284Z","iopub.status.idle":"2021-12-19T13:22:14.631609Z","shell.execute_reply.started":"2021-12-19T13:22:13.257252Z","shell.execute_reply":"2021-12-19T13:22:14.630705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class args:\n    batch_size = 4\n    image_size = 384\n    epochs = 10\n    fold = 10\n    \ndef sigmoid(x):\n    return 1 / (1 + math.exp(-x))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T13:22:14.634709Z","iopub.execute_input":"2021-12-19T13:22:14.635131Z","iopub.status.idle":"2021-12-19T13:22:14.641021Z","shell.execute_reply.started":"2021-12-19T13:22:14.63509Z","shell.execute_reply":"2021-12-19T13:22:14.640386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-12-19T13:22:14.64561Z","iopub.execute_input":"2021-12-19T13:22:14.645884Z","iopub.status.idle":"2021-12-19T13:22:14.660999Z","shell.execute_reply.started":"2021-12-19T13:22:14.64585Z","shell.execute_reply":"2021-12-19T13:22:14.660365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularModel(tez.Model):\n    def __init__(self):\n        super().__init__()\n        \n        # Transformer\n        self.model1 = timm.create_model(\"swin_large_patch4_window12_384\", pretrained=True, \n                                        in_chans=3)\n        n_features_1 = self.model1.head.in_features\n        self.model1.head = nn.Linear(n_features_1, 128)\n        \n        # CNN\n        self.model2 = timm.create_model('efficientnet_b4', pretrained=True,\n                                         in_chans=3)\n        out_channels = self.model2.conv_stem.out_channels\n        kernel_size = self.model2.conv_stem.kernel_size\n        stride = self.model2.conv_stem.stride\n        padding = self.model2.conv_stem.padding\n        bias = self.model2.conv_stem.bias\n        self.model2.conv_stem = nn.Conv2d(in_channels=3, out_channels=out_channels,\n                                           kernel_size=kernel_size,\n                                           stride=stride, padding=padding,\n                                           bias=bias)\n        n_features_2 = self.model2.classifier.in_features\n        self.model2.classifier = nn.Linear(n_features_2, 128)\n        \n        # NN head\n        self.fc = nn.Sequential(\n            nn.Linear(128 + 128 + 12, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        self.dropout = nn.Dropout(0.2)\n        \n        self.step_scheduler_after = \"epoch\"\n\n    def monitor_metrics(self, outputs, targets):\n        outputs = outputs.cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        # hand-written numpy sigmoid function here\n        rmse = metrics.mean_squared_error(targets, 1.0 / (1.0 + np.exp(-outputs)) * 100, squared=False)\n        return {\"rmse\": rmse}\n\n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n        return sch\n\n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=1e-4)\n        return opt\n\n    def forward(self, image, features, targets=None):\n        transformer_embeddings = self.model1(image)\n        conv_embeddings = self.model2(image)\n        x = torch.cat([transformer_embeddings, conv_embeddings, features], dim=1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        \n        # train mode\n        if targets is not None:\n            loss = nn.BCEWithLogitsLoss()(x, targets.view(-1, 1) / 100)\n            metrics = self.monitor_metrics(x, targets)\n            return x, loss, metrics\n        \n        # test mode, return embeddings and features\n        x = torch.cat([x, transformer_embeddings, conv_embeddings, features], dim=1)\n        return x, 0, {}","metadata":{"execution":{"iopub.status.busy":"2021-12-19T13:22:14.662653Z","iopub.execute_input":"2021-12-19T13:22:14.662956Z","iopub.status.idle":"2021-12-19T13:22:14.681101Z","shell.execute_reply.started":"2021-12-19T13:22:14.662931Z","shell.execute_reply":"2021-12-19T13:22:14.68031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.HueSaturationValue(\n            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n        ),\n        albumentations.RandomBrightnessContrast(\n            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n        ),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T13:22:14.682367Z","iopub.execute_input":"2021-12-19T13:22:14.683146Z","iopub.status.idle":"2021-12-19T13:22:14.695475Z","shell.execute_reply.started":"2021-12-19T13:22:14.683106Z","shell.execute_reply":"2021-12-19T13:22:14.694736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/same-old-creating-folds/train_10folds.csv\")\n\ndf_valid = df[df.kfold == args.fold].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T13:22:14.696766Z","iopub.execute_input":"2021-12-19T13:22:14.697742Z","iopub.status.idle":"2021-12-19T13:22:14.760695Z","shell.execute_reply.started":"2021-12-19T13:22:14.697644Z","shell.execute_reply":"2021-12-19T13:22:14.759761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train 10 folds, 1 model for each fold\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n\n    # dataset setting\n    df_train = df[df.kfold != fold_].reset_index(drop=True)#.iloc[:320]\n    train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n    df_valid = df[df.kfold == fold_].reset_index(drop=True)#.iloc[:160]\n    valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    train_dataset = PawpularDataset(\n        image_paths=train_img_paths,\n        dense_features=df_train[dense_features].values,\n        targets=df_train.Pawpularity.values,\n        augmentations=train_aug,\n    )\n\n    valid_dataset = PawpularDataset(\n        image_paths=valid_img_paths,\n        dense_features=df_valid[dense_features].values,\n        targets=df_valid.Pawpularity.values,\n        augmentations=valid_aug,\n    )\n    \n    # model setting\n    model = PawpularModel()\n\n    es = EarlyStopping(\n        monitor=\"valid_rmse\",\n        model_path=f\"model_f{args.fold}.bin\",\n        patience=3,\n        mode=\"min\",\n        save_weights_only=True,\n    )\n\n    # train\n    model.fit(\n        train_dataset,\n        valid_dataset=valid_dataset,\n        train_bs=args.batch_size,\n        valid_bs=2*args.batch_size,\n        device=\"cuda\",\n        epochs=args.epochs,\n        callbacks=[es],\n        fp16=True,\n    )\n    \n    model.save(f\"./paw-models/model_f{fold_}.bin\")","metadata":{"execution":{"iopub.status.busy":"2021-12-19T13:22:14.76297Z","iopub.execute_input":"2021-12-19T13:22:14.763197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}