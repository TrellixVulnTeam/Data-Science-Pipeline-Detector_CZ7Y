{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Starter\n\n\n#### Hello readers,\n\n#### In this notebook, we will try to explore different ways of developing the machine learning model for this competition.\n\n#### Few points to consider before we begin :\n\n* This notebook basically focuses on the CNN-based approaches.\n* We cover the topics like Transfer learning and Fine-tuning the pre-trained CNN models.\n* *THIS IS A DEMONSTRATION NOTEBOOK THEREFORE WE ONLY USE THE 100 IMAGES OTU OF ~9900 ( FOR FAST PROCESSING )*.\n* Note that because of the above reason the performance of the model is not the true indicator of its abilities.\n\n\n#### A brief about what we are going to cover in this notebook \n\n* Data analysis and preprocessing. \n* Transfer learning ( pre-trained model selection ).\n* Fine-tuning the pre-trained model.\n\n\n#### A brief about the approach we are taking :\n\n* As the score ranges from 1 to 100, i.e every image has a score between 1 to 100. We just need to find the score of an image. One possible approach is to treat the problem as a multiclass classification problem, where we have an image and we want to classify it as one of the 100 categories. \n\n#### Let’s begin, Hope you enjoy this notebook! \n","metadata":{}},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"background: #f4c2c2 ;\">_</h1></center>","metadata":{}},{"cell_type":"markdown","source":"<center><h1>Data analysis and preprocessing  </h1></center>","metadata":{}},{"cell_type":"markdown","source":"### Let's have a look at train.csv","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv',usecols = ['Id','Pawpularity'])\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:22:52.774141Z","iopub.execute_input":"2021-10-06T05:22:52.774809Z","iopub.status.idle":"2021-10-06T05:22:52.820744Z","shell.execute_reply.started":"2021-10-06T05:22:52.774776Z","shell.execute_reply":"2021-10-06T05:22:52.819867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### we have image id and its respective score in the train.csv","metadata":{}},{"cell_type":"markdown","source":"### Let's have a look at some images from the train folder ","metadata":{}},{"cell_type":"code","source":"import cv2\nimport random\n\nimage_1 = cv2.imread('../input/petfinder-pawpularity-score/train/' +random.choice(train_df['Id']) + '.jpg' )\nimage_2 = cv2.imread('../input/petfinder-pawpularity-score/train/' +random.choice(train_df['Id']) + '.jpg' )\n\nprint(image_1.shape)\nprint(image_2.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:22:52.822305Z","iopub.execute_input":"2021-10-06T05:22:52.822721Z","iopub.status.idle":"2021-10-06T05:22:53.011657Z","shell.execute_reply.started":"2021-10-06T05:22:52.822658Z","shell.execute_reply":"2021-10-06T05:22:53.010939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can see the problem here, The input to the model is an image and the size of the input has to be constant, but in the dataset, we don't have all the images with the fixed dimensions, Well we can easily crop the image to the desired size.\n\n#### which brings us to our question what should be the size of the input image ?, It’s very important that we find the correct size. If the image size is very small we are simply losing a lot of information and if the size is very high, that adds extra non-sence information (padding ) as well as a lot of processing overhead ( high ram consumption ). \n\n#### Here we will iterate through all the image’s shapes and take the average of all and use that as the final image size. \n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\n\nfrom PIL import Image\n\n\npath = '../input/petfinder-pawpularity-score/train/'\n\nimages = []\nlabels = []\n\nimage_heights = []\nimage_widths = []\n\ncount = 1\nMax_examples = 100\n\n\nfor id_,y in zip(train_df['Id'],train_df['Pawpularity']):\n    \n    img = cv2.imread(path + id_ + '.jpg', cv2.COLOR_BGR2RGB)\n    \n    images.append(img)\n    \n    image_heights.append(img.shape[0])\n    image_widths.append(img.shape[1])\n    \n    labels.append(y-1)\n    \n    if count == Max_examples:\n        break\n    \n    count+=1\n\navg_h = sum(image_heights)//len(image_heights)\navg_w = sum(image_widths)//len(image_widths)\n\n    \nprint(f'average image hieght is {avg_h}')\n\nprint(f'average image width is {avg_w}')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:22:53.013051Z","iopub.execute_input":"2021-10-06T05:22:53.013328Z","iopub.status.idle":"2021-10-06T05:22:54.776972Z","shell.execute_reply.started":"2021-10-06T05:22:53.013293Z","shell.execute_reply":"2021-10-06T05:22:54.77559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now let's convert the images in the desired format ","metadata":{}},{"cell_type":"code","source":"X_train = []\n\nfor img in images:\n    \n    img = cv2.resize(img,(avg_h,avg_w),interpolation = cv2.INTER_AREA)\n    img = np.array(img)\n    img = img.astype('float32')\n    img /= 255 \n    \n    X_train.append(img)\n    \nX_train = np.array(X_train)\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:22:54.779101Z","iopub.execute_input":"2021-10-06T05:22:54.779359Z","iopub.status.idle":"2021-10-06T05:22:55.900221Z","shell.execute_reply.started":"2021-10-06T05:22:54.779325Z","shell.execute_reply":"2021-10-06T05:22:55.899441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SHAPE = (avg_w,avg_h,3)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:22:55.901499Z","iopub.execute_input":"2021-10-06T05:22:55.901769Z","iopub.status.idle":"2021-10-06T05:22:55.908408Z","shell.execute_reply.started":"2021-10-06T05:22:55.901742Z","shell.execute_reply":"2021-10-06T05:22:55.907618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's prepare the y_train in the correct format ","metadata":{}},{"cell_type":"code","source":"Y_train = np.array(labels)\n\nY_train = Y_train.reshape(100,1)\nprint(Y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:22:55.909878Z","iopub.execute_input":"2021-10-06T05:22:55.910134Z","iopub.status.idle":"2021-10-06T05:22:55.916592Z","shell.execute_reply.started":"2021-10-06T05:22:55.910103Z","shell.execute_reply":"2021-10-06T05:22:55.915744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DONE","metadata":{}},{"cell_type":"code","source":"#end","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:22:55.918169Z","iopub.execute_input":"2021-10-06T05:22:55.918467Z","iopub.status.idle":"2021-10-06T05:22:55.92369Z","shell.execute_reply.started":"2021-10-06T05:22:55.918435Z","shell.execute_reply":"2021-10-06T05:22:55.922843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Important NOTE   ","metadata":{}},{"cell_type":"markdown","source":"#### The above method for preparing the data is very basic and high ram consuming, If we do not have access to high ram machines we should use the Image data generator, which loads the batch of images instead of loading all the images in the ram.\n\n#### Image data generator is an efficient approach but relatively complicated, here we are trying to explore and thus I have added this simple approach instead. \n","metadata":{}},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"background: #f4c2c2 ;\">_</h1></center>","metadata":{}},{"cell_type":"markdown","source":"<center><h1>Transfer learning ( pre-trained model selection ) </h1></center>","metadata":{}},{"cell_type":"markdown","source":"#### Transfer learning is the process of using the models that have been trained on the very large image datasets, And utilize the learned information (weights ) and model architecture for the give use cases. \n\n#### You can learn more about transfer learning here: https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n\n#### let's start \n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:22:55.92512Z","iopub.execute_input":"2021-10-06T05:22:55.925396Z","iopub.status.idle":"2021-10-06T05:23:00.295422Z","shell.execute_reply.started":"2021-10-06T05:22:55.925364Z","shell.execute_reply":"2021-10-06T05:23:00.29467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are a lot of pre-trained models that we can use, different models have different properties and we can select the model based on the use case. But ultimately it’s a matter of trying, i.e we have to try and find the best model for our use-cases out of all the pre-trained models. \n\n#### you can find the pre-trained models here: https://keras.io/api/applications/\n\n#### here we will be using resnet50 as the pre-trained model, you can learn more about resnet50 here: https://keras.io/api/applications/resnet/#resnet50-function\n","metadata":{}},{"cell_type":"code","source":"Pretrained_model = tf.keras.applications.resnet50.ResNet50(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:23:00.296569Z","iopub.execute_input":"2021-10-06T05:23:00.297464Z","iopub.status.idle":"2021-10-06T05:23:05.826638Z","shell.execute_reply.started":"2021-10-06T05:23:00.297433Z","shell.execute_reply":"2021-10-06T05:23:05.82591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now that we have loaded the pre-trained model, We are just gonna use the learned information from this model by integrating the pre-trained model with our model.\n","metadata":{}},{"cell_type":"markdown","source":"## Feature extraction : Freeze the convolutional base","metadata":{}},{"cell_type":"markdown","source":"#### freezing the layers prevents the layer’s weight from being updated during the training. Because we want to use that information as it is.","metadata":{}},{"cell_type":"code","source":"Pretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:23:05.830225Z","iopub.execute_input":"2021-10-06T05:23:05.830467Z","iopub.status.idle":"2021-10-06T05:23:05.83965Z","shell.execute_reply.started":"2021-10-06T05:23:05.830433Z","shell.execute_reply":"2021-10-06T05:23:05.838958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Pretrained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:23:05.840799Z","iopub.execute_input":"2021-10-06T05:23:05.841563Z","iopub.status.idle":"2021-10-06T05:23:05.925798Z","shell.execute_reply.started":"2021-10-06T05:23:05.841517Z","shell.execute_reply":"2021-10-06T05:23:05.925145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now that the pre-trained model is ready we can start developing the main model here","metadata":{}},{"cell_type":"code","source":"# model \nInputs = tf.keras.Input(IMG_SHAPE)\n\nx = Pretrained_model(Inputs, training=False)\n\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\nx = tf.keras.layers.Dropout(0.2)(x)\nx =  tf.keras.layers.Dense(256)(x)\nx = tf.keras.layers.Dropout(0.1)(x)\nOutputs = tf.keras.layers.Dense(100)(x)\n\nModel = tf.keras.Model(Inputs, Outputs)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:23:05.926862Z","iopub.execute_input":"2021-10-06T05:23:05.928256Z","iopub.status.idle":"2021-10-06T05:23:06.462368Z","shell.execute_reply.started":"2021-10-06T05:23:05.928228Z","shell.execute_reply":"2021-10-06T05:23:06.461674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### simple explanation of the above model \n\n* Image enters into the model as a multidimensional array\n* We pass the image to pretrained mode \n* Pre-trained model returns the vectorized representation of the image \n* these vector passes through the Feedforward network \n* final output is generated \n","metadata":{}},{"cell_type":"markdown","source":"#### Now We are going to compile the model and set the hyperparameters for our model, here we will be using the adam optimizer and SparseCategoricalCrossentropy as a loss function.","metadata":{}},{"cell_type":"code","source":"Optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\nLoss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\nMetrics=['accuracy']\n\nModel.compile(optimizer=Optimizer,\n              loss = Loss,\n              metrics = Metrics)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:23:06.463689Z","iopub.execute_input":"2021-10-06T05:23:06.463955Z","iopub.status.idle":"2021-10-06T05:23:06.482973Z","shell.execute_reply.started":"2021-10-06T05:23:06.463923Z","shell.execute_reply":"2021-10-06T05:23:06.482347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:23:06.484059Z","iopub.execute_input":"2021-10-06T05:23:06.484321Z","iopub.status.idle":"2021-10-06T05:23:06.504538Z","shell.execute_reply.started":"2021-10-06T05:23:06.484288Z","shell.execute_reply":"2021-10-06T05:23:06.503882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### defining the callbacks is very important, we can decide the behavior of the training.\n#### Tune the bellow parameters as needed.","metadata":{}},{"cell_type":"code","source":"callbacks =[tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=10, verbose=0,\n    mode='auto', baseline=None, restore_best_weights=False\n),\ntf.keras.callbacks.ModelCheckpoint(\n    filepath = './model', monitor='val_loss', verbose=1, save_best_only=True,\n    save_weights_only=False, mode='auto', save_freq='epoch',\n    options=None\n)]","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:23:06.50556Z","iopub.execute_input":"2021-10-06T05:23:06.506259Z","iopub.status.idle":"2021-10-06T05:23:06.512106Z","shell.execute_reply.started":"2021-10-06T05:23:06.506219Z","shell.execute_reply":"2021-10-06T05:23:06.511309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As this is the demonstration we will only train this model for 10 epochs  \n\n## Let's start the training ;)\n","metadata":{}},{"cell_type":"code","source":"history = Model.fit(X_train, Y_train, epochs=10, \n                    validation_split = 0.1, verbose = 1,callbacks = callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:23:06.513476Z","iopub.execute_input":"2021-10-06T05:23:06.513791Z","iopub.status.idle":"2021-10-06T05:28:22.422847Z","shell.execute_reply.started":"2021-10-06T05:23:06.513736Z","shell.execute_reply":"2021-10-06T05:28:22.42193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's see the performance  ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='lower right')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:28:22.435486Z","iopub.execute_input":"2021-10-06T05:28:22.435738Z","iopub.status.idle":"2021-10-06T05:28:22.72983Z","shell.execute_reply.started":"2021-10-06T05:28:22.435711Z","shell.execute_reply":"2021-10-06T05:28:22.729175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As we can see the performance is not so good but the model's performance can be increased significantly if\n\n* we use 100% of the data ( in the above example we used ~ 10% of the data )\n* we add more layers\n* We try different pre-trained model\n* We do long training of the model\n\n#### In the next section, we will try to improve the performance \n","metadata":{}},{"cell_type":"code","source":"#end","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:28:22.73096Z","iopub.execute_input":"2021-10-06T05:28:22.731209Z","iopub.status.idle":"2021-10-06T05:28:22.735739Z","shell.execute_reply.started":"2021-10-06T05:28:22.731166Z","shell.execute_reply":"2021-10-06T05:28:22.734842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"background: #f4c2c2 ;\">_</h1></center>","metadata":{}},{"cell_type":"markdown","source":"<center><h1>Fine-tuning the pre-trained mode</h1></center>","metadata":{}},{"cell_type":"markdown","source":"#### Fine Tunning is the process of updating the weights of the pre-trained model in order to increase the accuracy, you can learn more about fine-tuning the pre-trained model here: https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/ \n\n#### Similar to transfer learning in fine-tuning the pre-trained model is used, but here we allow the pre-trained model’s layer's weights to get updated during the training.\n\n#### We can eighter train all the layers or we can train only a few layers.\n","metadata":{}},{"cell_type":"markdown","source":"### Un-freeze some layers of the model","metadata":{}},{"cell_type":"code","source":"Pretrained_model.trainable = True","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:28:22.737359Z","iopub.execute_input":"2021-10-06T05:28:22.737798Z","iopub.status.idle":"2021-10-06T05:28:22.749629Z","shell.execute_reply.started":"2021-10-06T05:28:22.737764Z","shell.execute_reply":"2021-10-06T05:28:22.748951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len( Pretrained_model.layers)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:28:22.750958Z","iopub.execute_input":"2021-10-06T05:28:22.751269Z","iopub.status.idle":"2021-10-06T05:28:22.7595Z","shell.execute_reply.started":"2021-10-06T05:28:22.751215Z","shell.execute_reply":"2021-10-06T05:28:22.758685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### we can see that there are 175 layers in the pre-trained model, here we will start fine-tuning the model from the 100th layer.\n","metadata":{}},{"cell_type":"code","source":"\nstart_ = 100\n\nfor layer in Pretrained_model.layers[:start_]:\n    layer.trainable =  False","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:28:22.761012Z","iopub.execute_input":"2021-10-06T05:28:22.761271Z","iopub.status.idle":"2021-10-06T05:28:22.770648Z","shell.execute_reply.started":"2021-10-06T05:28:22.761243Z","shell.execute_reply":"2021-10-06T05:28:22.770012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### importent note: \n    \n#### now we are training a much larger model than before, we need to be careful while setting the learning rate of the model, the learning rate should be lower otherwise model could overfit very quickly.\n","metadata":{}},{"cell_type":"code","source":"\nOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\nLoss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\nMetrics=['accuracy']\n\nModel.compile(optimizer=Optimizer,\n              loss = Loss,\n              metrics = Metrics)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:28:22.77192Z","iopub.execute_input":"2021-10-06T05:28:22.772764Z","iopub.status.idle":"2021-10-06T05:28:22.791286Z","shell.execute_reply.started":"2021-10-06T05:28:22.77273Z","shell.execute_reply":"2021-10-06T05:28:22.790612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:28:22.792477Z","iopub.execute_input":"2021-10-06T05:28:22.792761Z","iopub.status.idle":"2021-10-06T05:28:22.81452Z","shell.execute_reply.started":"2021-10-06T05:28:22.792727Z","shell.execute_reply":"2021-10-06T05:28:22.813725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's start the training.","metadata":{}},{"cell_type":"code","source":"history = Model.fit(X_train, Y_train, epochs=10, \n                    validation_split = 0.1, verbose = 1,callbacks = callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:28:22.815889Z","iopub.execute_input":"2021-10-06T05:28:22.816191Z","iopub.status.idle":"2021-10-06T05:33:30.018687Z","shell.execute_reply.started":"2021-10-06T05:28:22.816158Z","shell.execute_reply":"2021-10-06T05:33:30.017868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's have look at performance ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='lower right')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:33:30.029783Z","iopub.execute_input":"2021-10-06T05:33:30.029999Z","iopub.status.idle":"2021-10-06T05:33:30.273082Z","shell.execute_reply.started":"2021-10-06T05:33:30.029975Z","shell.execute_reply":"2021-10-06T05:33:30.270128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#end","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:33:30.274442Z","iopub.execute_input":"2021-10-06T05:33:30.274771Z","iopub.status.idle":"2021-10-06T05:33:30.278833Z","shell.execute_reply.started":"2021-10-06T05:33:30.274716Z","shell.execute_reply":"2021-10-06T05:33:30.278113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Note :\n\n* We have seen the different approaches that we can use here in the context of CNN only.\n* One other approach that we can use is transformers, have a look here: https://keras.io/examples/vision/image_classification_with_vision_transformer/\n\n* The metadata can also be used for the training of the model.\n* Simple techniques like hyperparameter tunning, long training, image data extraction ... can be used to improve the model performance.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Thank you for reading, please share your thoughts/suggestions  ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}