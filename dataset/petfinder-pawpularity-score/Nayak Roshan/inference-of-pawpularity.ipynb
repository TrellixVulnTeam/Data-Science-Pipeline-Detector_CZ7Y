{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## For the training part refer to link https://www.kaggle.com/nayakroshan/pytorch-efficientnet-folds","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2 as cv\nimport glob\n\nfrom tqdm.auto import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\n\nimport gc\ngc.enable()\n\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:18:59.324612Z","iopub.execute_input":"2021-10-17T13:18:59.325331Z","iopub.status.idle":"2021-10-17T13:19:07.628303Z","shell.execute_reply.started":"2021-10-17T13:18:59.325216Z","shell.execute_reply":"2021-10-17T13:19:07.627501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:19:07.630007Z","iopub.execute_input":"2021-10-17T13:19:07.630267Z","iopub.status.idle":"2021-10-17T13:19:07.679553Z","shell.execute_reply.started":"2021-10-17T13:19:07.630239Z","shell.execute_reply":"2021-10-17T13:19:07.678729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetNet(nn.Module):\n    def __init__(self, model_name, out_features, inp_channels, pretrained, num_dense):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, 128)\n        self.fc = nn.Sequential(\n            nn.Linear(128 + num_dense, 64),\n            nn.ReLU(),\n            nn.Linear(64, out_features)\n        )\n        self.dropout = nn.Dropout(0.2)\n    \n    def forward(self, image, dense):\n        embeddings = self.model(image)\n        x = self.dropout(embeddings)\n        x = torch.cat([x, dense], dim=1)\n        output = self.fc(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:19:28.330311Z","iopub.execute_input":"2021-10-17T13:19:28.330676Z","iopub.status.idle":"2021-10-17T13:19:28.339982Z","shell.execute_reply.started":"2021-10-17T13:19:28.330645Z","shell.execute_reply":"2021-10-17T13:19:28.339135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_fn(test_loader, model, device):\n    model.eval()\n    stream = tqdm(test_loader)\n    final_outputs = []\n    \n    with torch.no_grad():\n        for i, (image, dense) in enumerate(stream, start=1):\n            image = image.to(device, non_blocking=True)\n            dense = dense.to(device, non_blocking=True)\n            output = model(image, dense)\n            outputs = (torch.sigmoid(output).detach().cpu().numpy()*100).tolist()\n            final_outputs.extend(outputs)\n        \n    return final_outputs","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:19:07.692584Z","iopub.execute_input":"2021-10-17T13:19:07.69297Z","iopub.status.idle":"2021-10-17T13:19:07.700594Z","shell.execute_reply.started":"2021-10-17T13:19:07.692921Z","shell.execute_reply":"2021-10-17T13:19:07.699808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_transform_object(DIM = 384):\n    return albumentations.Compose(\n        [\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:19:07.701615Z","iopub.execute_input":"2021-10-17T13:19:07.702047Z","iopub.status.idle":"2021-10-17T13:19:07.711819Z","shell.execute_reply.started":"2021-10-17T13:19:07.702013Z","shell.execute_reply":"2021-10-17T13:19:07.711077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetTestset(Dataset):\n    \n    def __init__(self, image_paths, dense_features, transform=None):\n        self.image_paths = image_paths\n        self.dense_feats = dense_features\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, index):\n        #read the image using the path.\n        img = cv.imread(self.image_paths[index], 1)\n        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        img = cv.resize(img, (224, 224), interpolation = cv.INTER_AREA)\n#         img = np.transpose(img, (2, 0, 1))\n#         img = torch.Tensor(img)\n        \n        if self.transform is not None:\n            img = self.transform(image=img)['image']\n            \n        img = img.float()\n            \n        #get the dense features.\n        dense = self.dense_feats[index, :]\n        \n        return (img, dense)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:19:07.712906Z","iopub.execute_input":"2021-10-17T13:19:07.71332Z","iopub.status.idle":"2021-10-17T13:19:07.721896Z","shell.execute_reply.started":"2021-10-17T13:19:07.713287Z","shell.execute_reply":"2021-10-17T13:19:07.721114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels = None\nmodels_dir = '../input/modelv7'\nmodel_params = {\n    'model_name' : 'swin_small_patch4_window7_224',\n    'out_features' : 1,\n    'inp_channels' : 3,\n    'num_dense' : 12,\n    'pretrained' : False\n}\n\ndef get_testset(df, images):\n    ids = list(df['Id'])\n    image_paths = [os.path.join(images, idx + '.jpg') for idx in ids]\n    df.drop(['Id'], inplace=True, axis=1)\n    dense_feats = df.values\n    test_transform = test_transform_object()\n    return PetTestset(image_paths, dense_feats, test_transform)\n\noutputs = None\nfor model_name in glob.glob(models_dir + '/*.pth'):\n    model = PetNet(**model_params)\n    model.load_state_dict(torch.load(model_name))\n    model = model.to(device)\n    \n    test_images = '../input/petfinder-pawpularity-score/test'\n    test_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n    testset = get_testset(test_df, test_images)\n    test_loader = DataLoader(testset, batch_size=16, shuffle=False)\n    \n    if outputs is None:\n        outputs = test_fn(test_loader, model, device)\n    else:\n        temp = test_fn(test_loader, model, device)\n        for i in range(len(temp)):\n            outputs[i].append(temp[i][0])\n            \nfor i in range(len(outputs)):\n    outputs[i] = [sum(outputs[i]) / (len(glob.glob(models_dir + '/*.pth')))]","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:19:31.729865Z","iopub.execute_input":"2021-10-17T13:19:31.730581Z","iopub.status.idle":"2021-10-17T13:20:04.273271Z","shell.execute_reply.started":"2021-10-17T13:19:31.730543Z","shell.execute_reply":"2021-10-17T13:20:04.272488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_csv = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\nfor i in range(len(outputs)):\n    sub_csv.loc[i, 'Pawpularity'] = outputs[i][0]","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:20:04.274841Z","iopub.execute_input":"2021-10-17T13:20:04.275176Z","iopub.status.idle":"2021-10-17T13:20:04.286429Z","shell.execute_reply.started":"2021-10-17T13:20:04.27514Z","shell.execute_reply":"2021-10-17T13:20:04.285685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_csv.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:20:04.289475Z","iopub.execute_input":"2021-10-17T13:20:04.289767Z","iopub.status.idle":"2021-10-17T13:20:04.296746Z","shell.execute_reply.started":"2021-10-17T13:20:04.289744Z","shell.execute_reply":"2021-10-17T13:20:04.296026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_csv.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T13:20:04.298738Z","iopub.execute_input":"2021-10-17T13:20:04.299021Z","iopub.status.idle":"2021-10-17T13:20:04.315283Z","shell.execute_reply.started":"2021-10-17T13:20:04.298986Z","shell.execute_reply":"2021-10-17T13:20:04.314466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}