{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"color:#8BB065;font-size:50px;\"><strong>My first <strong style=\"color:#974949\"> Convolutional Neural Network</strong></strong></h1>\n\n\n<img src=\"https://i.ibb.co/VMSgnJ5/header.png\" alt=\"header\" border=\"0\">\n\nLearning CNN from this notebook: [Link](https://www.kaggle.com/alexteboul/tutorial-part-3-cnn-image-modeling-1)","metadata":{}},{"cell_type":"code","source":"#load in packages\nimport os\nimport pandas as pd\nfrom glob import glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport gc\nfrom tqdm import tqdm\n\n#images\nimport cv2\n\n#modeling\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.client import device_lib\n\n#visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T06:53:52.310286Z","iopub.execute_input":"2021-11-22T06:53:52.310568Z","iopub.status.idle":"2021-11-22T06:53:52.316482Z","shell.execute_reply.started":"2021-11-22T06:53:52.310535Z","shell.execute_reply":"2021-11-22T06:53:52.315831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#source path (where the Pawpularity contest data resides)\npath = '../input/petfinder-pawpularity-score/'\n\n#Get the metadata (the .csv data) and put it into DataFrames\ntrain_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\n\n#Get the image data (the .jpg data) and put it into lists of filenames\ntrain_jpg = glob(path + \"train/*.jpg\")\ntest_jpg = glob(path + \"test/*.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:31.038164Z","iopub.execute_input":"2021-11-22T06:48:31.03905Z","iopub.status.idle":"2021-11-22T06:48:31.102651Z","shell.execute_reply.started":"2021-11-22T06:48:31.039012Z","shell.execute_reply":"2021-11-22T06:48:31.102011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape, len(train_jpg)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:31.104288Z","iopub.execute_input":"2021-11-22T06:48:31.104762Z","iopub.status.idle":"2021-11-22T06:48:31.110199Z","shell.execute_reply.started":"2021-11-22T06:48:31.104726Z","shell.execute_reply":"2021-11-22T06:48:31.109565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:31.11156Z","iopub.execute_input":"2021-11-22T06:48:31.111976Z","iopub.status.idle":"2021-11-22T06:48:31.12697Z","shell.execute_reply.started":"2021-11-22T06:48:31.111942Z","shell.execute_reply":"2021-11-22T06:48:31.125529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"color:#189AB4;font-size:20px;\"><strong>EDA<strong style=\"color:black\"></strong></strong></h1>","metadata":{}},{"cell_type":"code","source":"sns.histplot(train_df['Pawpularity']);\n\nplt.axvline(train_df['Pawpularity'].mean(),color='red')\nplt.axvline(train_df['Pawpularity'].median(),color='green')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:31.129265Z","iopub.execute_input":"2021-11-22T06:48:31.12976Z","iopub.status.idle":"2021-11-22T06:48:31.467632Z","shell.execute_reply.started":"2021-11-22T06:48:31.129722Z","shell.execute_reply":"2021-11-22T06:48:31.466969Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[['Pawpularity']].describe().T","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:31.468984Z","iopub.execute_input":"2021-11-22T06:48:31.469238Z","iopub.status.idle":"2021-11-22T06:48:31.490287Z","shell.execute_reply.started":"2021-11-22T06:48:31.469202Z","shell.execute_reply":"2021-11-22T06:48:31.489527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:31.491551Z","iopub.execute_input":"2021-11-22T06:48:31.49182Z","iopub.status.idle":"2021-11-22T06:48:31.500229Z","shell.execute_reply.started":"2021-11-22T06:48:31.491785Z","shell.execute_reply":"2021-11-22T06:48:31.4992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n\nfor col in cols:\n    fig, ax = plt.subplots(1,2)\n    sns.violinplot(data = train_df,y ='Pawpularity', x=col, ax=ax[0])\n    sns.histplot(data = train_df,x ='Pawpularity',hue=col,kde=True,fill=True, ax=ax[1])\n    \n    plt.suptitle(str(col), fontsize=18, fontweight='bold')\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:31.502191Z","iopub.execute_input":"2021-11-22T06:48:31.50265Z","iopub.status.idle":"2021-11-22T06:48:40.048617Z","shell.execute_reply.started":"2021-11-22T06:48:31.502608Z","shell.execute_reply":"2021-11-22T06:48:40.047817Z"},"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = '../input/petfinder-pawpularity-score/train/'\next = '.jpg'\n\nnums = len(cols)\n\n# col = 'Eyes'\nfor count, col in enumerate(cols):\n    sample = train_df.loc[train_df[col] == 1,'Id'].head(100).values[np.random.randint(10)]\n    \n    pawpularity = train_df.loc[train_df['Id'] == sample, 'Pawpularity'].head(1).values[-1]\n    \n    image_loc = img_path + sample + ext\n\n    image_array = plt.imread(image_loc)\n    plt.imshow(image_array)\n    \n    plt.title(f'Image of pet with {col}\\nPawpularity Score: {pawpularity}') \n    plt.axis('off') #turns off the gridlines\n    plt.show()\n\n    del sample, image_loc, image_array\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:40.049922Z","iopub.execute_input":"2021-11-22T06:48:40.05023Z","iopub.status.idle":"2021-11-22T06:48:45.286611Z","shell.execute_reply.started":"2021-11-22T06:48:40.050193Z","shell.execute_reply":"2021-11-22T06:48:45.285926Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Modify the Id such that each Id is the full image path. In the form\ndef train_id_to_path(x):\n    return '../input/petfinder-pawpularity-score/train/' + x + \".jpg\"\ndef test_id_to_path(x):\n    return '../input/petfinder-pawpularity-score/test/' + x + \".jpg\"\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:45.297333Z","iopub.execute_input":"2021-11-22T06:48:45.298293Z","iopub.status.idle":"2021-11-22T06:48:45.312953Z","shell.execute_reply.started":"2021-11-22T06:48:45.298256Z","shell.execute_reply":"2021-11-22T06:48:45.312187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check to see\ntf.config.get_visible_devices()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:45.31409Z","iopub.execute_input":"2021-11-22T06:48:45.314337Z","iopub.status.idle":"2021-11-22T06:48:45.324159Z","shell.execute_reply.started":"2021-11-22T06:48:45.314304Z","shell.execute_reply":"2021-11-22T06:48:45.323486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read in the data and drop unnecessary columns\ntrain = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntrain = train.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\n\ntest = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest = test.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:45.325401Z","iopub.execute_input":"2021-11-22T06:48:45.325744Z","iopub.status.idle":"2021-11-22T06:48:45.352041Z","shell.execute_reply.started":"2021-11-22T06:48:45.325716Z","shell.execute_reply":"2021-11-22T06:48:45.351428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Add the .jpg extensions to the image file name ids\ntrain[\"img_path\"] = train[\"Id\"].apply(train_id_to_path)\ntest[\"img_path\"] = test[\"Id\"].apply(test_id_to_path)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:45.353211Z","iopub.execute_input":"2021-11-22T06:48:45.353515Z","iopub.status.idle":"2021-11-22T06:48:45.364888Z","shell.execute_reply.started":"2021-11-22T06:48:45.35344Z","shell.execute_reply":"2021-11-22T06:48:45.364273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#binning columns to test models\ntrain['two_bin_pawp'] = pd.qcut(train['Pawpularity'], q=2, labels=False)\ntrain = train.astype({\"two_bin_pawp\": str})\n\ntrain['four_bin_pawp'] = pd.qcut(train['Pawpularity'], q=4, labels=False)\ntrain = train.astype({\"four_bin_pawp\": str})\n\ntrain['ten_bin_pawp'] = pd.qcut(train['Pawpularity'], q=10, labels=False)\ntrain = train.astype({\"ten_bin_pawp\": str})","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:48:54.275722Z","iopub.execute_input":"2021-11-22T06:48:54.275982Z","iopub.status.idle":"2021-11-22T06:48:54.328133Z","shell.execute_reply.started":"2021-11-22T06:48:54.275952Z","shell.execute_reply":"2021-11-22T06:48:54.327386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set the size image you want to use\nimage_height = 128\nimage_width = 128\n\n#define a function that accepts an image url and outputs an eager tensor\ndef path_to_eagertensor(image_path):\n    raw = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(raw, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    #image = tf.image.resize_with_pad(image, image_height, image_width) #optional with padding to retain original dimensions\n    image = tf.image.resize(image, (image_height, image_width))\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:54:10.123346Z","iopub.execute_input":"2021-11-22T06:54:10.124061Z","iopub.status.idle":"2021-11-22T06:54:10.130039Z","shell.execute_reply.started":"2021-11-22T06:54:10.124022Z","shell.execute_reply":"2021-11-22T06:54:10.129298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get all the images in the training folder and put their tensors in a list\nX = []\nfor img in tqdm(train['img_path']):\n    new_img_tensor = path_to_eagertensor(img)\n    X.append(new_img_tensor)\n    \nprint(type(X),len(X))\nX = np.array(X)\nprint(type(X),X.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:54:10.583309Z","iopub.execute_input":"2021-11-22T06:54:10.584176Z","iopub.status.idle":"2021-11-22T06:55:35.609338Z","shell.execute_reply.started":"2021-11-22T06:54:10.584126Z","shell.execute_reply":"2021-11-22T06:55:35.608591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get all the images in the test folder and put their tensors in a list\nX_submission = []\nfor img in tqdm(test['img_path']):\n    new_img_tensor = path_to_eagertensor(img)\n    X_submission.append(new_img_tensor)\n    \nprint(type(X_submission),len(X_submission))\nX_submission = np.array(X_submission)\nprint(type(X_submission),X_submission.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:55:35.610947Z","iopub.execute_input":"2021-11-22T06:55:35.61136Z","iopub.status.idle":"2021-11-22T06:55:35.658214Z","shell.execute_reply.started":"2021-11-22T06:55:35.611322Z","shell.execute_reply":"2021-11-22T06:55:35.655834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grab the target variable. In our case, Pawpularity\ny = train['Pawpularity']\nprint(type(y))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:56:39.977469Z","iopub.execute_input":"2021-11-22T06:56:39.978282Z","iopub.status.idle":"2021-11-22T06:56:39.983841Z","shell.execute_reply.started":"2021-11-22T06:56:39.978229Z","shell.execute_reply":"2021-11-22T06:56:39.983038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:57:01.846161Z","iopub.execute_input":"2021-11-22T06:57:01.846423Z","iopub.status.idle":"2021-11-22T06:57:02.247287Z","shell.execute_reply.started":"2021-11-22T06:57:01.846393Z","shell.execute_reply":"2021-11-22T06:57:02.246556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show the shape of each of the new arrays\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:57:03.941886Z","iopub.execute_input":"2021-11-22T06:57:03.942329Z","iopub.status.idle":"2021-11-22T06:57:03.947652Z","shell.execute_reply.started":"2021-11-22T06:57:03.942293Z","shell.execute_reply":"2021-11-22T06:57:03.946537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(SEED=42):\n    tf.keras.backend.clear_session()\n    np.random.seed(SEED)\n    tf.random.set_seed(SEED)\n    \n    input_ = keras.Input(shape=(X.shape[1],X.shape[2],3))\n\n    x = keras.layers.Conv2D(filters = 16, kernel_size=[7,7], strides=[2,2], padding='valid', kernel_initializer='he_normal',\n                           kernel_regularizer=l2(0.0005), activation = 'relu')(input_)\n\n    x = keras.layers.Conv2D(filters = 32, kernel_size=[3,3], padding='same', kernel_initializer='he_normal',\n                           activation = 'relu')(x)\n\n    x = keras.layers.BatchNormalization()(x)\n\n    x = keras.layers.Conv2D(filters = 32, kernel_size=[3,3],strides=[2,2], padding='same', kernel_initializer='he_normal',\n                           activation = 'relu', kernel_regularizer=l2(0.0005))(x)\n\n    x = keras.layers.BatchNormalization()(x)\n\n    x = keras.layers.Dropout(0.25)(x)\n\n    x = keras.layers.Conv2D(filters = 64, kernel_size=[3,3], padding='same', kernel_initializer='he_normal', activation='relu'\n                            ,kernel_regularizer=l2(0.0002))(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same',\n                               kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Dropout(0.25)(x)\n\n    #####\n    x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Dropout(0.25)(x)\n\n    x = tf.keras.layers.Flatten()(x)\n\n    x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n\n    x = tf.keras.layers.Dropout(0.5)(x)\n\n    output = tf.keras.layers.Dense(1)(x)\n\n    model = tf.keras.Model(inputs = input_, outputs = output)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:16:45.513758Z","iopub.execute_input":"2021-11-22T07:16:45.51401Z","iopub.status.idle":"2021-11-22T07:16:45.53069Z","shell.execute_reply.started":"2021-11-22T07:16:45.513981Z","shell.execute_reply":"2021-11-22T07:16:45.529849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compile the model\nmodel.compile(\n    loss = 'mse', \n    optimizer = 'Adam', \n    metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:27:43.951267Z","iopub.execute_input":"2021-11-22T07:27:43.951549Z","iopub.status.idle":"2021-11-22T07:27:43.970227Z","shell.execute_reply.started":"2021-11-22T07:27:43.951514Z","shell.execute_reply":"2021-11-22T07:27:43.969418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = ImageDataGenerator(rotation_range=15, zoom_range=0.15, width_shift_range = 0.2, \n    height_shift_range = 0.2, \n    shear_range = 0.1,\n    horizontal_flip = True, \n    fill_mode = \"nearest\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:27:44.565646Z","iopub.execute_input":"2021-11-22T07:27:44.566018Z","iopub.status.idle":"2021-11-22T07:27:44.576725Z","shell.execute_reply.started":"2021-11-22T07:27:44.565974Z","shell.execute_reply":"2021-11-22T07:27:44.575708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kall = keras.callbacks.EarlyStopping(monitor='val_rmse',patience=10,restore_best_weights=True)\n\nhistory = model.fit(\n    data_augmentation.flow(x_train,y_train,batch_size=1024),\n    validation_data = (x_test,y_test),\n    steps_per_epoch = len(x_train) // 1024,\n    epochs = 600, callbacks=[kall]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:27:45.394395Z","iopub.execute_input":"2021-11-22T07:27:45.394679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.plot(history.history[\"rmse\"], label=\"train_rmse\")\nplt.plot(history.history[\"val_rmse\"], label=\"val_rmse\")\nplt.title(\"RMSE train/validation by Epoch\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"RMSE\")\nplt.legend(loc=\"upper right\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict on the submission data\ncnn_pred = model.predict(X_submission)\nprint(X_submission.shape, type(X_submission))\nprint(cnn_pred.shape, type(cnn_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#put the submission predictions alongside their associated Ids\ncnn = pd.DataFrame()\ncnn['Id'] = test['Id']\ncnn['Pawpularity'] = cnn_pred\ncnn.to_csv('submission.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_example_image = plt.imread('../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg') \nprint(testing_example_image.shape)\n#then plt.imshow() can display it for you\nplt.imshow(testing_example_image)\nplt.title('First Testing Image \\n Predicted Pawpularity = {}'.format(cnn['Pawpularity'].iloc[0])) \nplt.axis('off') #turns off the gridlines\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}