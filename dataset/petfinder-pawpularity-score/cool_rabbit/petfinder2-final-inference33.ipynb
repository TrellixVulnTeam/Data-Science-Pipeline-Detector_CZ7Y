{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# クーラビ part","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-3monthsold/pytorch-image-models-master 2')\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.notebook import tqdm\nimport os, gc\nimport random\nfrom PIL import Image\nimport tifffile as tiff\nimport cv2\nimport zipfile\nimport collections\nfrom PIL import Image\nfrom sklearn import preprocessing\nfrom random import randint\nfrom glob import glob\nimport shutil\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torchvision\nfrom torchvision import transforms\nimport albumentations as A\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed = 2020\nseed_everything(seed)\nsz1 = 224\nsz2 = 384\nNFOLDS = 5\npet_num = 4\n\n#ImageNet\nmean = np.array([[[0.485, 0.456, 0.406]]])\nstd = np.array([[[0.229, 0.224, 0.225]]])","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:12:23.298115Z","iopub.execute_input":"2022-01-13T05:12:23.298421Z","iopub.status.idle":"2022-01-13T05:12:24.683404Z","shell.execute_reply.started":"2022-01-13T05:12:23.298381Z","shell.execute_reply":"2022-01-13T05:12:24.682647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')\n#test_df = pd.concat([pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')]*900, ignore_index=True)\ntest_df['class'] = -1\ntest_df['conf'] = -1\ntest_ids = test_df.Id.to_list()\n#test_ids = ['0013fd999caf9a3efe1352ca1b0d937e', '0009c66b9439883ba2750fb825e1d7db', '0007de18844b0dbbb5e1f607da0606e0']\ntest_dir = \"/kaggle/input/petfinder-pawpularity-score/test/\"\n#test_dir = '/kaggle/input/petfinder2-sample-images/'\nshutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\nos.chdir('/kaggle/working/yolov5')","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:12:24.684973Z","iopub.execute_input":"2022-01-13T05:12:24.685236Z","iopub.status.idle":"2022-01-13T05:12:25.321892Z","shell.execute_reply.started":"2022-01-13T05:12:24.685198Z","shell.execute_reply":"2022-01-13T05:12:25.321083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = pd.DataFrame(columns=test_df.columns)\ntmp","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:12:25.323454Z","iopub.execute_input":"2022-01-13T05:12:25.323719Z","iopub.status.idle":"2022-01-13T05:12:25.338465Z","shell.execute_reply.started":"2022-01-13T05:12:25.323666Z","shell.execute_reply":"2022-01-13T05:12:25.337604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py\\\n--weights /kaggle/input/ultralyticsyolov5aweights/yolov5x.pt\\\n--class 15 16\\\n--img 512\\\n--conf 0.3\\\n--iou 0.5\\\n--source $test_dir\\\n--name inference\\\n--save-txt --save-conf --exist-ok","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-13T05:12:25.339847Z","iopub.execute_input":"2022-01-13T05:12:25.341094Z","iopub.status.idle":"2022-01-13T05:12:38.449766Z","shell.execute_reply.started":"2022-01-13T05:12:25.341056Z","shell.execute_reply":"2022-01-13T05:12:38.448878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir('/kaggle/working')\nsave_dir = f'/kaggle/working/crop_images/'\nos.makedirs(save_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:12:38.45174Z","iopub.execute_input":"2022-01-13T05:12:38.452029Z","iopub.status.idle":"2022-01-13T05:12:38.458645Z","shell.execute_reply.started":"2022-01-13T05:12:38.45199Z","shell.execute_reply":"2022-01-13T05:12:38.457276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for n, image_id in tqdm(enumerate(test_ids)):\n    orig_image = cv2.imread(f'/kaggle/input/petfinder-pawpularity-score/test/{image_id}.jpg')\n    orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n    height = orig_image.shape[0]\n    width = orig_image.shape[1]\n    try:\n        file_path = f'/kaggle/working/yolov5/runs/detect/inference/labels/{image_id}.txt'\n        f = open(file_path, 'r')\n        data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n        data = data[:, [0, 5, 1, 2, 3, 4]]\n        data = data[np.argsort(data[:, 1])[::-1]]  #sort by conf\n        for i, d in enumerate(data):\n            xmin = int((d[2]-d[4]/2)*width)\n            ymin = int((d[3]-d[5]/2)*height)\n            xmax = int((d[2]+d[4]/2)*width)\n            ymax = int((d[3]+d[5]/2)*height)\n            width_half = (xmax - xmin) // 2\n            height_half = (ymax - ymin) // 2\n            r = np.maximum(width_half, height_half)\n            xc = (xmin + xmax) // 2\n            yc = (ymin + ymax) // 2\n            final_xmin = np.maximum(xc-r, 0)\n            final_ymin = np.maximum(yc-r, 0)\n            final_xmax = np.minimum(xc+r, width)\n            final_ymax = np.minimum(yc+r, height)\n            crop_img = orig_image[final_ymin:final_ymax, final_xmin:final_xmax, :]\n            np.save(save_dir + f'{image_id}-{i}', crop_img.astype(np.uint8))\n            df = pd.DataFrame(columns=test_df.columns)\n            df.loc[0, 'Id'] = f'{image_id}-{i}'\n            df.loc[0, 'class'] = d[0]\n            df.loc[0, 'conf'] = d[1]\n            tmp = tmp.append(df, ignore_index=True)\n            \n    except:\n        np.save(save_dir + f'{image_id}-0', orig_image.astype(np.uint8))\n        df = pd.DataFrame(columns=test_df.columns)\n        df.loc[0, 'Id'] = f'{image_id}-0'\n        df.loc[0, 'class'] = 'NA'\n        df.loc[0, 'conf'] = 'NA'\n        tmp = tmp.append(df, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:12:38.460275Z","iopub.execute_input":"2022-01-13T05:12:38.461185Z","iopub.status.idle":"2022-01-13T05:12:38.554198Z","shell.execute_reply.started":"2022-01-13T05:12:38.461146Z","shell.execute_reply":"2022-01-13T05:12:38.553508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = tmp.rename(columns={'Id': 'Id2'})\ntmp['img_idx'] = tmp['Id2'].apply(lambda x: x.split('-')[1])\ntmp['Id'] = tmp['Id2'].apply(lambda x: x.split('-')[0])\ntmp","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:12:38.555573Z","iopub.execute_input":"2022-01-13T05:12:38.556055Z","iopub.status.idle":"2022-01-13T05:12:38.575667Z","shell.execute_reply.started":"2022-01-13T05:12:38.556019Z","shell.execute_reply":"2022-01-13T05:12:38.575015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, df, size, transform=None):\n        self.df = df\n        self.size = size\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image_id = self.df.loc[idx, 'Id2']\n        img = np.load(f'/kaggle/working/crop_images/{image_id}.npy')\n        img = cv2.resize(img, (self.size, self.size)).astype(np.float32)\n        \n        if self.transform:\n            sample = self.transform(image=img)\n            img = sample['image']\n        \n        img = (img/255.0 - mean) / std\n        img = np.transpose(img, (2, 0, 1))\n        img = torch.from_numpy(img)\n\n        return img\n    \n    \nclass Dataset2(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image_id = self.df.loc[idx, 'Id']\n        img = np.load(f'/kaggle/working/crop_images/{image_id}.npy').astype(np.float32)\n        \n        if self.transform:\n            sample = self.transform(image=img)\n            img = sample['image']\n        \n        img = (img/255.0 - mean) / std\n        img = np.transpose(img, (2, 0, 1))\n        img = torch.from_numpy(img)\n\n        return img\n    \n\ndef inference_fn1(data_loader, model, device):\n    model.eval()    \n    val_preds = []\n    \n    for i, x in enumerate(data_loader):\n        img = x\n        img = img.to(device, dtype=torch.float)\n        \n        with torch.no_grad():\n            pred = model(img)\n            val_preds.append(nn.Softmax()(pred).detach().cpu().numpy())\n            \n    val_preds = np.concatenate(val_preds)\n                \n    return val_preds\n\n\ndef inference_fn2(data_loader, model, device):\n    model.eval()    \n    val_preds = []\n    \n    for i, x in enumerate(data_loader):\n        img = x\n        img = img.to(device, dtype=torch.float)\n        \n        with torch.no_grad():\n            pred = model(img)\n            val_preds.append(nn.Sigmoid()(pred).detach().cpu().numpy() * 100)\n            \n    val_preds = np.concatenate(val_preds)\n                \n    return val_preds\n\n\nclass Model(nn.Module):\n    def __init__(self, model_name=None, pretrained=False, num_classes=100):\n        super().__init__()\n        self.model = timm.create_model(\n            model_name=model_name, \n            in_chans=3, \n            pretrained=pretrained\n            )\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, num_classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:12:38.577098Z","iopub.execute_input":"2022-01-13T05:12:38.57758Z","iopub.status.idle":"2022-01-13T05:12:38.597379Z","shell.execute_reply.started":"2022-01-13T05:12:38.577544Z","shell.execute_reply":"2022-01-13T05:12:38.59652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#224x224\n#5folds\n#cropped imgs\ntest_ds = Dataset(df=tmp, size=sz1, transform=None)\ntest_dl = DataLoader(dataset=test_ds, batch_size=256, shuffle=False, num_workers=2)\ntarget_cols = np.arange(1, 101)\npredictions1 = 0\npredictions2 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    \n    #SwinT type1: 100 outputs\n    model1 = Model(model_name='swin_large_patch4_window7_224_in22k', num_classes=100)\n    model1.load_state_dict(torch.load(f'/kaggle/input/petfinder2-swint1-weight-016/swint1_fold_{fold}.pth'))\n    model1.to(device)\n    prediction1 = inference_fn1(test_dl, model1, device)\n    predictions1 += (target_cols.reshape(-1, 100) * prediction1.reshape(-1, 100)).sum(axis=1) / NFOLDS\n    \n    #SwinT type2: 1 output\n    model2 = Model(model_name='swin_large_patch4_window7_224_in22k', num_classes=1)\n    model2.model.head = nn.Sequential(\n        nn.Linear(model2.model.head.in_features, 128),\n        nn.Dropout(0.0),\n        nn.Linear(128, 64),\n        nn.Linear(64, 1)\n    )\n    model2.load_state_dict(torch.load(f'/kaggle/input/petfinder2-swint2-weight-011/swint2_fold_{fold}.pth'))\n    model2.to(device)\n    prediction2 = inference_fn2(test_dl, model2, device).flatten()\n    predictions2 += prediction2 / NFOLDS\n    \n    del model1, model2, prediction1, prediction2\n    gc.collect()\n    \ntmp['pred1'] = predictions1\ntmp['pred2'] = predictions2\n\ndel test_ds, test_dl, predictions1, predictions2\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:12:38.598415Z","iopub.execute_input":"2022-01-13T05:12:38.600149Z","iopub.status.idle":"2022-01-13T05:15:26.631367Z","shell.execute_reply.started":"2022-01-13T05:12:38.600108Z","shell.execute_reply":"2022-01-13T05:15:26.630571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#384x384\n#5folds\n#cropped imgs\ntest_ds = Dataset(df=tmp, size=sz2, transform=None)\ntest_dl = DataLoader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=2)\ntarget_cols = np.arange(1, 101)\npredictions3 = 0\npredictions4 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    \n    #SwinT type1: 100 outputs\n    model1 = Model(model_name='swin_large_patch4_window12_384_in22k', num_classes=100)\n    model1.load_state_dict(torch.load(f'/kaggle/input/petfinder2-swint1-weight-068/swint1_fold_{fold}.pth'))\n    model1.to(device)\n    prediction3 = inference_fn1(test_dl, model1, device)\n    predictions3 += (target_cols.reshape(-1, 100) * prediction3.reshape(-1, 100)).sum(axis=1) / NFOLDS\n    \n    #SwinT type2: 1 output\n    model2 = Model(model_name='swin_large_patch4_window12_384_in22k', num_classes=1)\n    model2.model.head = nn.Sequential(\n        nn.Linear(model2.model.head.in_features, 128),\n        nn.Dropout(0.0),\n        nn.Linear(128, 64),\n        nn.Linear(64, 1)\n    )\n    model2.load_state_dict(torch.load(f'/kaggle/input/petfinder2-swint2-weight-028/swint2_fold_{fold}.pth'))\n    model2.to(device)\n    prediction4 = inference_fn2(test_dl, model2, device).flatten()\n    predictions4 += prediction4 / NFOLDS\n    \n    del model1, model2, prediction3, prediction4\n    gc.collect()\n    \ntmp['pred3'] = predictions3\ntmp['pred4'] = predictions4\n\ndel test_ds, test_dl, predictions3, predictions4\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:15:26.632908Z","iopub.execute_input":"2022-01-13T05:15:26.633792Z","iopub.status.idle":"2022-01-13T05:17:59.949365Z","shell.execute_reply.started":"2022-01-13T05:15:26.63375Z","shell.execute_reply":"2022-01-13T05:17:59.948585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:17:59.950853Z","iopub.execute_input":"2022-01-13T05:17:59.951752Z","iopub.status.idle":"2022-01-13T05:17:59.969601Z","shell.execute_reply.started":"2022-01-13T05:17:59.951711Z","shell.execute_reply":"2022-01-13T05:17:59.968842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#postprocessing by multi-pets\ntest_df = tmp.groupby('Id').head(pet_num).groupby('Id').mean().reset_index()\ntest_df","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:17:59.970956Z","iopub.execute_input":"2022-01-13T05:17:59.971284Z","iopub.status.idle":"2022-01-13T05:17:59.990326Z","shell.execute_reply.started":"2022-01-13T05:17:59.971246Z","shell.execute_reply":"2022-01-13T05:17:59.989542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\ncoorabi = pd.concat(\n    [sub, \n     test_df[['pred1']], \n     test_df[['pred2']], \n     test_df[['pred3']], \n     test_df[['pred4']]\n    ], axis=1\n)\ncoorabi","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:17:59.992636Z","iopub.execute_input":"2022-01-13T05:17:59.993161Z","iopub.status.idle":"2022-01-13T05:18:00.016204Z","shell.execute_reply.started":"2022-01-13T05:17:59.993124Z","shell.execute_reply":"2022-01-13T05:18:00.015532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r /kaggle/working/yolov5\n!rm -r /kaggle/working/crop_images","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:18:00.017521Z","iopub.execute_input":"2022-01-13T05:18:00.018032Z","iopub.status.idle":"2022-01-13T05:18:00.463926Z","shell.execute_reply.started":"2022-01-13T05:18:00.017993Z","shell.execute_reply":"2022-01-13T05:18:00.46295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fastai\n#224x224\n#5folds\n#original imgs\nimport fastai\nfrom fastai.vision.all import *\nfrom fastai.callback.all import *\nimport torchvision.models as torch_models\n\ndef petfinder_rmse(input, target):\n    return 100 * torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ntest_df = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')\ntest_df['Path'] = '../input/petfinder-pawpularity-score/test/' + test_df['Id'] + '.jpg'\npredictions5 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    learn = load_learner(fname = Path(f'/kaggle/input/petfinder2-swint3-weight-001/swint3_fold_{fold}.pkl'), cpu=False)\n    test_dl = learn.dls.test_dl(test_df)\n    preds, _ = learn.get_preds(dl=test_dl)\n    predictions5 += preds * 100 / NFOLDS\n    del learn, test_dl, preds\n    gc.collect()\n    \ncoorabi['pred5'] = predictions5\n\ndel predictions5\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:18:00.465965Z","iopub.execute_input":"2022-01-13T05:18:00.466254Z","iopub.status.idle":"2022-01-13T05:18:40.971416Z","shell.execute_reply.started":"2022-01-13T05:18:00.466216Z","shell.execute_reply":"2022-01-13T05:18:40.970601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#224x224\n#5folds\n#center crop\ntest_df = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')\ntest_ids = test_df.Id.to_list()\nos.chdir('/kaggle/working')\nsave_dir = f'/kaggle/working/crop_images/'\nos.makedirs(save_dir, exist_ok=True)\n\nfor n, image_id in tqdm(enumerate(test_ids)):\n    orig_image = cv2.imread(f'/kaggle/input/petfinder-pawpularity-score/test/{image_id}.jpg')\n    orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n    height = orig_image.shape[0]\n    width = orig_image.shape[1]\n    xc = width // 2\n    yc = height // 2\n    r = np.minimum(xc, yc)\n    xmin = np.maximum(xc-r, 0)\n    ymin = np.maximum(yc-r, 0)\n    xmax = np.minimum(xc+r, width)\n    ymax = np.minimum(yc+r, height)\n    crop_img = orig_image[ymin:ymax, xmin:xmax, :]\n    crop_img = cv2.resize(crop_img, (sz1, sz1)).astype(np.uint8)\n    np.save(save_dir + f'{image_id}', crop_img)\n\ntest_ds = Dataset2(df=coorabi, transform=None)\ntest_dl = DataLoader(dataset=test_ds, batch_size=256, shuffle=False, num_workers=2)\ntarget_cols = np.arange(1, 101)\npredictions6 = 0\npredictions7 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    \n    #SwinT type1: 100 outputs\n    model1 = Model(model_name='swin_large_patch4_window7_224_in22k', num_classes=100)\n    model1.load_state_dict(torch.load(f'/kaggle/input/petfinder2-swint1-weight-076/swint1_fold_{fold}.pth'))\n    model1.to(device)\n    prediction6 = inference_fn1(test_dl, model1, device)\n    predictions6 += (target_cols.reshape(-1, 100) * prediction6.reshape(-1, 100)).sum(axis=1) / NFOLDS\n    \n    #SwinT type2: 1 output\n    model2 = Model(model_name='swin_large_patch4_window7_224_in22k', num_classes=1)\n    model2.model.head = nn.Sequential(\n        nn.Linear(model2.model.head.in_features, 128),\n        nn.Dropout(0.0),\n        nn.Linear(128, 64),\n        nn.Linear(64, 1)\n    )\n    model2.load_state_dict(torch.load(f'/kaggle/input/petfinder2-swint2-weight-036/swint2_fold_{fold}.pth'))\n    model2.to(device)\n    prediction7 = inference_fn2(test_dl, model2, device).flatten()\n    predictions7 += prediction7 / NFOLDS\n    \n    del model1, model2, prediction6, prediction7\n    gc.collect()\n    \ncoorabi['pred6'] = predictions6\ncoorabi['pred7'] = predictions7\n\n!rm -r /kaggle/working/crop_images\ndel test_ds, test_dl, predictions6, predictions7\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:18:40.973276Z","iopub.execute_input":"2022-01-13T05:18:40.974016Z","iopub.status.idle":"2022-01-13T05:20:56.443148Z","shell.execute_reply.started":"2022-01-13T05:18:40.973973Z","shell.execute_reply":"2022-01-13T05:20:56.442377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#384x384\n#5folds\n#center crop\ntest_df = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')\ntest_ids = test_df.Id.to_list()\nos.chdir('/kaggle/working')\nsave_dir = f'/kaggle/working/crop_images/'\nos.makedirs(save_dir, exist_ok=True)\n\nfor n, image_id in tqdm(enumerate(test_ids)):\n    orig_image = cv2.imread(f'/kaggle/input/petfinder-pawpularity-score/test/{image_id}.jpg')\n    orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n    height = orig_image.shape[0]\n    width = orig_image.shape[1]\n    xc = width // 2\n    yc = height // 2\n    r = np.minimum(xc, yc)\n    xmin = np.maximum(xc-r, 0)\n    ymin = np.maximum(yc-r, 0)\n    xmax = np.minimum(xc+r, width)\n    ymax = np.minimum(yc+r, height)\n    crop_img = orig_image[ymin:ymax, xmin:xmax, :]\n    crop_img = cv2.resize(crop_img, (sz2, sz2)).astype(np.uint8)\n    np.save(save_dir + f'{image_id}', crop_img)\n\ntest_ds = Dataset2(df=coorabi, transform=None)\ntest_dl = DataLoader(dataset=test_ds, batch_size=64, shuffle=False, num_workers=2)\ntarget_cols = np.arange(1, 101)\npredictions8 = 0\npredictions9 = 0\n\nfor fold in range(NFOLDS):\n    print(f'======== FOLD:{fold} inference ========')\n    \n    #SwinT type1: 100 outputs\n    model1 = Model(model_name='swin_large_patch4_window12_384_in22k', num_classes=100)\n    model1.load_state_dict(torch.load(f'/kaggle/input/petfinder2-swint1-weight-077/swint1_fold_{fold}.pth'))\n    model1.to(device)\n    prediction8 = inference_fn1(test_dl, model1, device)\n    predictions8 += (target_cols.reshape(-1, 100) * prediction8.reshape(-1, 100)).sum(axis=1) / NFOLDS\n    \n    #SwinT type2: 1 output\n    model2 = Model(model_name='swin_large_patch4_window12_384_in22k', num_classes=1)\n    model2.model.head = nn.Sequential(\n        nn.Linear(model2.model.head.in_features, 128),\n        nn.Dropout(0.0),\n        nn.Linear(128, 64),\n        nn.Linear(64, 1)\n    )\n    model2.load_state_dict(torch.load(f'/kaggle/input/petfinder2-swint2-weight-037/swint2_fold_{fold}.pth'))\n    model2.to(device)\n    prediction9 = inference_fn2(test_dl, model2, device).flatten()\n    predictions9 += prediction9 / NFOLDS\n    \n    del model1, model2, prediction8, prediction9\n    gc.collect()\n    \ncoorabi['pred8'] = predictions8\ncoorabi['pred9'] = predictions9\n\n!rm -r /kaggle/working/crop_images\ndel test_ds, test_dl, predictions8, predictions9\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:20:56.444977Z","iopub.execute_input":"2022-01-13T05:20:56.445435Z","iopub.status.idle":"2022-01-13T05:23:27.172476Z","shell.execute_reply.started":"2022-01-13T05:20:56.445392Z","shell.execute_reply":"2022-01-13T05:23:27.171574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coorabi['Pawpularity'] = ((coorabi['pred1'] * 0.275 + coorabi['pred2'] * 0.225 + coorabi['pred3'] * 0.275 + coorabi['pred4'] * 0.225) * 0.75 + coorabi['pred5'] * 0.25) * 0.6 + (coorabi['pred6'] * 0.22 + coorabi['pred7'] * 0.18 + coorabi['pred8'] * 0.33 + coorabi['pred9'] * 0.27) * 0.4","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:23:27.174182Z","iopub.execute_input":"2022-01-13T05:23:27.175043Z","iopub.status.idle":"2022-01-13T05:23:27.185995Z","shell.execute_reply.started":"2022-01-13T05:23:27.175002Z","shell.execute_reply":"2022-01-13T05:23:27.185105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coorabi","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:23:27.187291Z","iopub.execute_input":"2022-01-13T05:23:27.187797Z","iopub.status.idle":"2022-01-13T05:23:27.212063Z","shell.execute_reply.started":"2022-01-13T05:23:27.187757Z","shell.execute_reply":"2022-01-13T05:23:27.210044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coorabi[['Id', 'Pawpularity']].to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T05:23:27.362877Z","iopub.execute_input":"2022-01-13T05:23:27.363636Z","iopub.status.idle":"2022-01-13T05:23:27.371938Z","shell.execute_reply.started":"2022-01-13T05:23:27.363588Z","shell.execute_reply":"2022-01-13T05:23:27.371016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}