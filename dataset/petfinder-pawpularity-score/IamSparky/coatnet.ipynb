{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/cpythonlibrary/cpython-master/\")\nsys.path.append(\"../input/coatnet-module-for-img-classification/External-Attention-pytorch-master/model/attention/\")","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:17.358638Z","iopub.execute_input":"2021-11-13T17:54:17.358954Z","iopub.status.idle":"2021-11-13T17:54:17.377595Z","shell.execute_reply.started":"2021-11-13T17:54:17.358875Z","shell.execute_reply":"2021-11-13T17:54:17.376892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport albumentations\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport gc\nimport cv2\nimport warnings\n\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom Lib import copy \nfrom CoAtNet import CoAtNet\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:17.37906Z","iopub.execute_input":"2021-11-13T17:54:17.379807Z","iopub.status.idle":"2021-11-13T17:54:20.787794Z","shell.execute_reply.started":"2021-11-13T17:54:17.379772Z","shell.execute_reply":"2021-11-13T17:54:20.787069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    TRAINING_FILE = \"../input/petfinder-pawpularity-score/train.csv\"\n    TRAINING_IMAGE_PATH = \"../input/petfinder-pawpularity-score/train/\"\n    DEVICE = torch.device(\"cuda\")\n    TRAIN_BATCH_SIZE = 64\n    VALID_BATCH_SIZE = 64\n    EPOCHS = 5\n    \nclass AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:20.790951Z","iopub.execute_input":"2021-11-13T17:54:20.792325Z","iopub.status.idle":"2021-11-13T17:54:20.800341Z","shell.execute_reply.started":"2021-11-13T17:54:20.792286Z","shell.execute_reply":"2021-11-13T17:54:20.799667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train = pd.read_csv(config.TRAINING_FILE)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:20.802454Z","iopub.execute_input":"2021-11-13T17:54:20.803008Z","iopub.status.idle":"2021-11-13T17:54:20.845496Z","shell.execute_reply.started":"2021-11-13T17:54:20.802963Z","shell.execute_reply":"2021-11-13T17:54:20.844878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create folds\nfrom sklearn import model_selection\n\nnew_train[\"kfold\"] = -1    \nnew_train = new_train.sample(frac=1).reset_index(drop=True)\ny = new_train.Pawpularity.values\nkf = model_selection.StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X = new_train, y = y)):\n    new_train.loc[v_, 'kfold'] = f","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:20.847341Z","iopub.execute_input":"2021-11-13T17:54:20.847835Z","iopub.status.idle":"2021-11-13T17:54:20.874563Z","shell.execute_reply.started":"2021-11-13T17:54:20.8478Z","shell.execute_reply":"2021-11-13T17:54:20.873825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class petFinderDataset:\n    def __init__(self, dataframe, is_valid = 0):\n        self.dataframe = dataframe\n        self.is_valid = is_valid\n        if self.is_valid == 1: # transforms for validation images\n            self.aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(224, 224),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            )], p=1.)\n\n        else:       # transfoms for training images \n            self.aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(224, 224),\n            albumentations.Transpose(p=0.5),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n            albumentations.CoarseDropout(p=0.5),\n            albumentations.Cutout(p=0.5)], p=1.)\n    \n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, item):\n        df = self.dataframe.iloc[item, :]\n\n        # converting jpg format of images to numpy array\n        img = np.array(Image.open(config.TRAINING_IMAGE_PATH + df[\"Id\"] + '.jpg')) \n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = self.aug(image = img)['image']\n        img = np.transpose(img , (2,0,1)).astype(np.float32) # 2,0,1 because pytorch excepts image channel first then dimension of image\n        \n        return {\n            'image': torch.tensor(img, dtype = torch.float),\n            'tabular_data' : torch.tensor(df[1:-2], dtype = torch.float),\n            'target' : torch.tensor(df['Pawpularity'], dtype = torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:20.875942Z","iopub.execute_input":"2021-11-13T17:54:20.876218Z","iopub.status.idle":"2021-11-13T17:54:20.892873Z","shell.execute_reply.started":"2021-11-13T17:54:20.876171Z","shell.execute_reply":"2021-11-13T17:54:20.8921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = petFinderDataset(new_train)[71]['image']\nplt.imshow(np.transpose(img.numpy(), (1,2,0)))\npetFinderDataset(new_train)[71]['tabular_data']","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:20.894011Z","iopub.execute_input":"2021-11-13T17:54:20.894247Z","iopub.status.idle":"2021-11-13T17:54:21.283148Z","shell.execute_reply.started":"2021-11-13T17:54:20.89421Z","shell.execute_reply":"2021-11-13T17:54:21.282493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class coAtNet_Model(nn.Module):\n    def __init__(self):\n        super(coAtNet_Model, self).__init__()\n        self.model = CoAtNet(3,224)\n        self.add_1 = nn.Linear(9633792, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(128 + 12, 1)\n        \n    def forward(self, image, tabular_data_inputs):\n        x = self.model(image)\n        x = self.add_1(torch.flatten(x))\n        x = self.dropout(x)\n        x = torch.cat([x, tabular_data_inputs], dim=1)\n        x = self.out(x)\n        \n        return x\n    \nmodel = coAtNet_Model()\nmodel = model.to(config.DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:21.284088Z","iopub.execute_input":"2021-11-13T17:54:21.284316Z","iopub.status.idle":"2021-11-13T17:54:35.803963Z","shell.execute_reply.started":"2021-11-13T17:54:21.284284Z","shell.execute_reply":"2021-11-13T17:54:35.803226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(x, y):\n    criterion = nn.MSELoss()\n    loss = torch.sqrt(criterion(x, y))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:35.805161Z","iopub.execute_input":"2021-11-13T17:54:35.805427Z","iopub.status.idle":"2021-11-13T17:54:35.811827Z","shell.execute_reply.started":"2021-11-13T17:54:35.805394Z","shell.execute_reply":"2021-11-13T17:54:35.811094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n    running_loss = 0\n    model.train()\n    \n    losses = AverageMeter()\n    tqdm_ob = tqdm(data_loader, total = len(data_loader))\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        target = dataset[\"target\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n\n        outputs = model(image, tabular_data)\n        loss = loss_fn(outputs , target)\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        losses.update(loss.item(), image.size(0))\n        tqdm_ob.set_postfix(loss = losses.avg)\n            \n        del image, tabular_data, target\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        running_loss += loss.item() \n    train_loss = running_loss/ (batch_index + 1)\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:35.814296Z","iopub.execute_input":"2021-11-13T17:54:35.814746Z","iopub.status.idle":"2021-11-13T17:54:35.826532Z","shell.execute_reply.started":"2021-11-13T17:54:35.814709Z","shell.execute_reply":"2021-11-13T17:54:35.82582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_loop_fn(data_loader, model, device):\n    running_loss = 0\n    model.eval()\n    \n    losses = AverageMeter()\n    tqdm_ob = tqdm(data_loader, total = len(data_loader))\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        target = dataset[\"target\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n\n        outputs = model(image, tabular_data)\n        loss = loss_fn(outputs , target)\n        losses.update(loss.item(), image.size(0))\n        tqdm_ob.set_postfix(loss = losses.avg)\n            \n        del image, tabular_data, target\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        running_loss += loss.item() \n    val_loss = running_loss/ (batch_index + 1)\n    return val_loss","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:35.827807Z","iopub.execute_input":"2021-11-13T17:54:35.828317Z","iopub.status.idle":"2021-11-13T17:54:35.839587Z","shell.execute_reply.started":"2021-11-13T17:54:35.828279Z","shell.execute_reply":"2021-11-13T17:54:35.838846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 * 0.95)\n\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n    \n    a_string = \"*\" * 20\n    for i in range(5):\n        print(a_string, \" FOLD NUMBER \", i, a_string)\n        df_train = new_train[new_train.kfold != i].reset_index(drop=True)\n        df_valid = new_train[new_train.kfold == i].reset_index(drop=True)\n\n        train_data = petFinderDataset(df_train)\n        val_data = petFinderDataset(df_valid, is_valid = 1)\n\n        train_data_loader = DataLoader(train_data,\n                                num_workers=4,\n                                batch_size=config.TRAIN_BATCH_SIZE,\n                                shuffle=True,\n                                drop_last=True)\n\n        valid_data_loader = DataLoader(val_data,\n                                num_workers=4,\n                                batch_size=config.VALID_BATCH_SIZE,\n                                shuffle=False,\n                                drop_last=False)\n        \n        all_rmse = []\n        for epoch in range(config.EPOCHS):\n            print(f\"Epoch --> {epoch+1} / {config.EPOCHS}\")\n            print(f\"-------------------------------\")\n            train_rmse = train_loop_fn(train_data_loader, model, optimizer, config.DEVICE, scheduler)\n            print(f\"Training Root Mean Square Error = {train_rmse}\")\n            val_rmse = eval_loop_fn(valid_data_loader, model, config.DEVICE)\n            print(f\"Validation Root Mean Square Error = {val_rmse}\")\n            \n            all_rmse.append(val_rmse)\n        print('\\n')\n        \n        if i < 1:\n            best_RMSE = min(all_rmse)\n            best_model = copy.deepcopy(model)\n            all_rmse = []\n        else:\n            if min(all_rmse) < best_RMSE:\n                best_RMSE = min(all_rmse)\n                best_model = copy.deepcopy(model)\n                all_rmse = []\n                \n    torch.save(best_model,'./second_timm_efficientnet_b0_ns_model.bin')\n    print()\n    print(f\"The lowest RMSE score that we got across all the folds is : {best_RMSE}\")\n    \n    return best_model\n                \nif __name__ == \"__main__\":\n    run()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:54:35.841009Z","iopub.execute_input":"2021-11-13T17:54:35.841284Z","iopub.status.idle":"2021-11-13T17:54:46.418036Z","shell.execute_reply.started":"2021-11-13T17:54:35.841248Z","shell.execute_reply":"2021-11-13T17:54:46.416494Z"},"trusted":true},"execution_count":null,"outputs":[]}]}