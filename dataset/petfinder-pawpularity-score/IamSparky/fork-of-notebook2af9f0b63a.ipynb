{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/cpythonlibrary/cpython-master/\")\nsys.path.append(\"../input/timmmaster/\")\nsys.path.append(\"../input/sam-optimizer/sam-main/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-30T15:39:23.457883Z","iopub.execute_input":"2021-09-30T15:39:23.45833Z","iopub.status.idle":"2021-09-30T15:39:23.559591Z","shell.execute_reply.started":"2021-09-30T15:39:23.458248Z","shell.execute_reply":"2021-09-30T15:39:23.558212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport albumentations\nimport torch.nn as nn\nimport timm\nimport torch.nn.functional as F\nimport gc\nimport cv2\nimport warnings\nfrom sam import SAM\n\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom Lib import copy \n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:23.562224Z","iopub.execute_input":"2021-09-30T15:39:23.562805Z","iopub.status.idle":"2021-09-30T15:39:30.953803Z","shell.execute_reply.started":"2021-09-30T15:39:23.562752Z","shell.execute_reply":"2021-09-30T15:39:30.952969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    TRAINING_FILE = \"../input/petfinder-pawpularity-score/train.csv\"\n    TRAINING_IMAGE_PATH = \"../input/petfinder-pawpularity-score/train/\"\n    DEVICE = torch.device(\"cuda\")\n    TRAIN_BATCH_SIZE = 64\n    VALID_BATCH_SIZE = 64\n    EPOCHS = 5\n    \nclass AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:30.95703Z","iopub.execute_input":"2021-09-30T15:39:30.957237Z","iopub.status.idle":"2021-09-30T15:39:30.965461Z","shell.execute_reply.started":"2021-09-30T15:39:30.957212Z","shell.execute_reply":"2021-09-30T15:39:30.964764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train = pd.read_csv(config.TRAINING_FILE)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:30.967844Z","iopub.execute_input":"2021-09-30T15:39:30.968492Z","iopub.status.idle":"2021-09-30T15:39:31.003146Z","shell.execute_reply.started":"2021-09-30T15:39:30.968455Z","shell.execute_reply":"2021-09-30T15:39:31.002554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create folds\nfrom sklearn import model_selection\n\nnew_train[\"kfold\"] = -1    \nnew_train = new_train.sample(frac=1).reset_index(drop=True)\ny = new_train.Pawpularity.values\nkf = model_selection.StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X = new_train, y = y)):\n    new_train.loc[v_, 'kfold'] = f","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:31.00424Z","iopub.execute_input":"2021-09-30T15:39:31.004603Z","iopub.status.idle":"2021-09-30T15:39:31.283878Z","shell.execute_reply.started":"2021-09-30T15:39:31.004578Z","shell.execute_reply":"2021-09-30T15:39:31.283182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class petFinderDataset:\n    def __init__(self, constant_func, dataframe, is_valid = 0):\n        self.constant_func = constant_func\n        self.dataframe = dataframe\n        self.is_valid = is_valid\n        if self.is_valid == 1: # transforms for validation images\n            self.aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(224, 224),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            )], p=1.)\n\n        else:       # transfoms for training images \n            self.aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(224, 224),\n            albumentations.Transpose(p=0.5),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n            albumentations.CoarseDropout(p=0.5),\n            albumentations.Cutout(p=0.5)], p=1.)\n    \n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, item):\n        df = self.dataframe.iloc[item, :]\n\n        # converting jpg format of images to numpy array\n        img = np.array(Image.open(self.constant_func.TRAINING_IMAGE_PATH + df[\"Id\"] + '.jpg')) \n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = self.aug(image = img)['image']\n        img = np.transpose(img , (2,0,1)).astype(np.float32) # 2,0,1 because pytorch excepts image channel first then dimension of image\n        \n        return {\n            'image': torch.tensor(img, dtype = torch.float),\n            'tabular_data' : torch.tensor(df[1:-2], dtype = torch.float),\n            'target' : torch.tensor(df['Pawpularity'], dtype = torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:31.285301Z","iopub.execute_input":"2021-09-30T15:39:31.28554Z","iopub.status.idle":"2021-09-30T15:39:31.299378Z","shell.execute_reply.started":"2021-09-30T15:39:31.285508Z","shell.execute_reply":"2021-09-30T15:39:31.298397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = petFinderDataset(config, new_train)[71]['image']\nplt.imshow(np.transpose(img.numpy(), (1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:31.300926Z","iopub.execute_input":"2021-09-30T15:39:31.30127Z","iopub.status.idle":"2021-09-30T15:39:31.62432Z","shell.execute_reply.started":"2021-09-30T15:39:31.301235Z","shell.execute_reply":"2021-09-30T15:39:31.623611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass TimmEfficientNet_b0(nn.Module):\n    def __init__(self):\n        super(TimmEfficientNet_b0, self).__init__()\n        self.model = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained=True, in_chans=3)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(128 + 12, 1)\n        \n    def forward(self, image ,tabular_data_inputs):\n        x = self.model(image)\n        x = self.dropout(x)\n        x = torch.cat([x, tabular_data_inputs], dim=1)\n        x = self.out(x)\n        \n        return x\n    \nmodel = TimmEfficientNet_b0()\nmodel = model.to(config.DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:31.62541Z","iopub.execute_input":"2021-09-30T15:39:31.625684Z","iopub.status.idle":"2021-09-30T15:39:37.557215Z","shell.execute_reply.started":"2021-09-30T15:39:31.625649Z","shell.execute_reply":"2021-09-30T15:39:37.556489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_optimizer = torch.optim.Adam\noptimizer = SAM(model.parameters(), base_optimizer, lr = 1e-3 * 0.95)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n    )\n\ndef loss_fn(x, y):\n    criterion = nn.MSELoss()\n    loss = torch.sqrt(criterion(x, y))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:37.560283Z","iopub.execute_input":"2021-09-30T15:39:37.560496Z","iopub.status.idle":"2021-09-30T15:39:37.571132Z","shell.execute_reply.started":"2021-09-30T15:39:37.560471Z","shell.execute_reply":"2021-09-30T15:39:37.570436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n    running_loss = 0\n    model.train()\n    \n    losses = AverageMeter()\n    tqdm_ob = tqdm(data_loader, total = len(data_loader))\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        target = dataset[\"target\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n\n        # first forward-backward pass\n        outputs = model(image, tabular_data)\n        loss = loss_fn(outputs , target)\n        loss.backward()\n        optimizer.first_step(zero_grad=True)\n        \n        # second forward-backward pass\n        outputs = model(image, tabular_data)\n        loss = loss_fn(outputs , target)\n        loss.backward()\n        optimizer.second_step(zero_grad=True)\n        \n        scheduler.step()\n        losses.update(loss.item(), image.size(0))\n        tqdm_ob.set_postfix(loss = losses.avg)\n            \n        del image, tabular_data, target\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        running_loss += loss.item() \n    train_loss = running_loss/ (batch_index + 1)\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:37.574124Z","iopub.execute_input":"2021-09-30T15:39:37.574397Z","iopub.status.idle":"2021-09-30T15:39:37.587021Z","shell.execute_reply.started":"2021-09-30T15:39:37.574364Z","shell.execute_reply":"2021-09-30T15:39:37.585901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_loop_fn(data_loader, model, device):\n    running_loss = 0\n    model.eval()\n    \n    losses = AverageMeter()\n    tqdm_ob = tqdm(data_loader, total = len(data_loader))\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        target = dataset[\"target\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n\n        outputs = model(image, tabular_data)\n        loss = loss_fn(outputs , target)\n        losses.update(loss.item(), image.size(0))\n        tqdm_ob.set_postfix(loss = losses.avg)\n            \n        del image, tabular_data, target\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        running_loss += loss.item() \n    val_loss = running_loss/ (batch_index + 1)\n    return val_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:37.588331Z","iopub.execute_input":"2021-09-30T15:39:37.58882Z","iopub.status.idle":"2021-09-30T15:39:37.60009Z","shell.execute_reply.started":"2021-09-30T15:39:37.588782Z","shell.execute_reply":"2021-09-30T15:39:37.599213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n    a_string = \"*\" * 20\n    for i in range(5):\n        print(a_string, \" FOLD NUMBER \", i, a_string)\n        df_train = new_train[new_train.kfold != i].reset_index(drop=True)\n        df_valid = new_train[new_train.kfold == i].reset_index(drop=True)\n\n        train_data = petFinderDataset(config, df_train)\n        val_data = petFinderDataset(config, df_valid, is_valid = 1)\n\n        train_data_loader = DataLoader(train_data,\n                                num_workers=4,\n                                batch_size=config.TRAIN_BATCH_SIZE,\n                                shuffle=True,\n                                drop_last=True)\n\n        valid_data_loader = DataLoader(val_data,\n                                num_workers=4,\n                                batch_size=config.VALID_BATCH_SIZE,\n                                shuffle=False,\n                                drop_last=False)\n        \n        all_rmse = []\n        for epoch in range(config.EPOCHS):\n            print(f\"Epoch --> {epoch+1} / {config.EPOCHS}\")\n            print(f\"-------------------------------\")\n            train_rmse = train_loop_fn(train_data_loader, model, optimizer, config.DEVICE, scheduler)\n            print(f\"Training Root Mean Square Error = {train_rmse}\")\n            val_rmse = eval_loop_fn(valid_data_loader, model, config.DEVICE)\n            print(f\"Validation Root Mean Square Error = {val_rmse}\")\n            \n            all_rmse.append(val_rmse)\n        print('\\n')\n        \n        if i < 1:\n            best_RMSE = min(all_rmse)\n            best_model = copy.deepcopy(model)\n            all_rmse = []\n        else:\n            if min(all_rmse) < best_RMSE:\n                best_RMSE = min(all_rmse)\n                best_model = copy.deepcopy(model)\n                all_rmse = []\n                \n    torch.save(best_model,'./second_timm_efficientnet_b0_ns_model.bin')\n    print()\n    print(f\"The lowest RMSE score that we got across all the folds is : {best_RMSE}\")\n    \n    return best_model\n                \nif __name__ == \"__main__\":\n    run()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T15:39:37.601511Z","iopub.execute_input":"2021-09-30T15:39:37.601795Z","iopub.status.idle":"2021-09-30T16:39:35.685725Z","shell.execute_reply.started":"2021-09-30T15:39:37.60176Z","shell.execute_reply":"2021-09-30T16:39:35.683953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}