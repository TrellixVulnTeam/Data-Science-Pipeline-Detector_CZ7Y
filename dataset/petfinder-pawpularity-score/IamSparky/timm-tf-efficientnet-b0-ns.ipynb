{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/cpythonlibrary/cpython-master/\")\nsys.path.append(\"../input/timmmaster/\")","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:02.274528Z","iopub.execute_input":"2021-09-27T09:14:02.275018Z","iopub.status.idle":"2021-09-27T09:14:02.420369Z","shell.execute_reply.started":"2021-09-27T09:14:02.274906Z","shell.execute_reply":"2021-09-27T09:14:02.419657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport albumentations\nimport torch.nn as nn\nimport timm\nimport torch.nn.functional as F\nimport gc\nimport cv2\nimport warnings\n\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom Lib import copy \n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:02.424963Z","iopub.execute_input":"2021-09-27T09:14:02.427028Z","iopub.status.idle":"2021-09-27T09:14:10.17259Z","shell.execute_reply.started":"2021-09-27T09:14:02.426988Z","shell.execute_reply":"2021-09-27T09:14:10.171651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    TRAINING_FILE = \"../input/petfinder-pawpularity-score/train.csv\"\n    TRAINING_IMAGE_PATH = \"../input/petfinder-pawpularity-score/train/\"\n    DEVICE = torch.device(\"cuda\")\n    TRAIN_BATCH_SIZE = 64\n    VALID_BATCH_SIZE = 64\n    EPOCHS = 5\n    \nclass AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:10.174137Z","iopub.execute_input":"2021-09-27T09:14:10.174402Z","iopub.status.idle":"2021-09-27T09:14:10.186219Z","shell.execute_reply.started":"2021-09-27T09:14:10.174354Z","shell.execute_reply":"2021-09-27T09:14:10.185471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train = pd.read_csv(config.TRAINING_FILE)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:10.189952Z","iopub.execute_input":"2021-09-27T09:14:10.190143Z","iopub.status.idle":"2021-09-27T09:14:10.224404Z","shell.execute_reply.started":"2021-09-27T09:14:10.190121Z","shell.execute_reply":"2021-09-27T09:14:10.223786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create folds\nfrom sklearn import model_selection\n\nnew_train[\"kfold\"] = -1    \nnew_train = new_train.sample(frac=1).reset_index(drop=True)\ny = new_train.Pawpularity.values\nkf = model_selection.StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X = new_train, y = y)):\n    new_train.loc[v_, 'kfold'] = f","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:10.226207Z","iopub.execute_input":"2021-09-27T09:14:10.226541Z","iopub.status.idle":"2021-09-27T09:14:10.519792Z","shell.execute_reply.started":"2021-09-27T09:14:10.226508Z","shell.execute_reply":"2021-09-27T09:14:10.519075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class petFinderDataset:\n    def __init__(self, constant_func, dataframe, is_valid = 0):\n        self.constant_func = constant_func\n        self.dataframe = dataframe\n        self.is_valid = is_valid\n        if self.is_valid == 1: # transforms for validation images\n            self.aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(224, 224),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            )], p=1.)\n\n        else:       # transfoms for training images \n            self.aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(224, 224),\n            albumentations.Transpose(p=0.5),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n            albumentations.CoarseDropout(p=0.5),\n            albumentations.Cutout(p=0.5)], p=1.)\n    \n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, item):\n        df = self.dataframe.iloc[item, :]\n\n        # converting jpg format of images to numpy array\n        img = np.array(Image.open('../input/petfinder-pawpularity-score/train/' + df[\"Id\"] + '.jpg')) \n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = self.aug(image = img)['image']\n        img = np.transpose(img , (2,0,1)).astype(np.float32) # 2,0,1 because pytorch excepts image channel first then dimension of image\n        \n        return {\n            'image': torch.tensor(img, dtype = torch.float),\n            'tabular_data' : torch.tensor(df[1:-2], dtype = torch.float),\n            'target' : torch.tensor(df['Pawpularity'], dtype = torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:10.52095Z","iopub.execute_input":"2021-09-27T09:14:10.521232Z","iopub.status.idle":"2021-09-27T09:14:10.535727Z","shell.execute_reply.started":"2021-09-27T09:14:10.521199Z","shell.execute_reply":"2021-09-27T09:14:10.534308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = petFinderDataset('config', new_train)[71]['image']\nplt.imshow(np.transpose(img.numpy(), (1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:10.537143Z","iopub.execute_input":"2021-09-27T09:14:10.537387Z","iopub.status.idle":"2021-09-27T09:14:10.862983Z","shell.execute_reply.started":"2021-09-27T09:14:10.53735Z","shell.execute_reply":"2021-09-27T09:14:10.862267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TimmEfficientNet_b0(nn.Module):\n    def __init__(self):\n        super(TimmEfficientNet_b0, self).__init__()\n        self.model = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained=True, in_chans=3)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(128 + 12, 1)\n        \n    def forward(self, image ,tabular_data_inputs):\n        x = self.model(image)\n        x = self.dropout(x)\n        x = torch.cat([x, tabular_data_inputs], dim=1)\n        x = self.out(x)\n        \n        return x\n    \nmodel = TimmEfficientNet_b0()\nmodel = model.to(config.DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:10.863962Z","iopub.execute_input":"2021-09-27T09:14:10.86421Z","iopub.status.idle":"2021-09-27T09:14:17.032364Z","shell.execute_reply.started":"2021-09-27T09:14:10.864181Z","shell.execute_reply":"2021-09-27T09:14:17.031535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(x, y):\n    criterion = nn.MSELoss()\n    loss = torch.sqrt(criterion(x, y))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:17.033664Z","iopub.execute_input":"2021-09-27T09:14:17.033944Z","iopub.status.idle":"2021-09-27T09:14:17.041103Z","shell.execute_reply.started":"2021-09-27T09:14:17.033909Z","shell.execute_reply":"2021-09-27T09:14:17.040415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n    running_loss = 0\n    model.train()\n    \n    losses = AverageMeter()\n    tqdm_ob = tqdm(data_loader, total = len(data_loader))\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        target = dataset[\"target\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n\n        outputs = model(image, tabular_data)\n        loss = loss_fn(outputs , target)\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        losses.update(loss.item(), image.size(0))\n        tqdm_ob.set_postfix(loss = losses.avg)\n            \n        del image, tabular_data, target\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        running_loss += loss.item() \n    train_loss = running_loss/ (batch_index + 1)\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:17.044892Z","iopub.execute_input":"2021-09-27T09:14:17.045086Z","iopub.status.idle":"2021-09-27T09:14:17.055912Z","shell.execute_reply.started":"2021-09-27T09:14:17.045065Z","shell.execute_reply":"2021-09-27T09:14:17.055171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_loop_fn(data_loader, model, device):\n    running_loss = 0\n    model.eval()\n    \n    losses = AverageMeter()\n    tqdm_ob = tqdm(data_loader, total = len(data_loader))\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        target = dataset[\"target\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n\n        outputs = model(image, tabular_data)\n        loss = loss_fn(outputs , target)\n        losses.update(loss.item(), image.size(0))\n        tqdm_ob.set_postfix(loss = losses.avg)\n            \n        del image, tabular_data, target\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        running_loss += loss.item() \n    val_loss = running_loss/ (batch_index + 1)\n    return val_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:17.059204Z","iopub.execute_input":"2021-09-27T09:14:17.059429Z","iopub.status.idle":"2021-09-27T09:14:17.068751Z","shell.execute_reply.started":"2021-09-27T09:14:17.059396Z","shell.execute_reply":"2021-09-27T09:14:17.067304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 * 0.95)\n\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n    \n    a_string = \"*\" * 20\n    for i in range(5):\n        print(a_string, \" FOLD NUMBER \", i, a_string)\n        df_train = new_train[new_train.kfold != i].reset_index(drop=True)\n        df_valid = new_train[new_train.kfold == i].reset_index(drop=True)\n\n        train_data = petFinderDataset('config', df_train)\n        val_data = petFinderDataset('config', df_valid, is_valid = 1)\n\n        train_data_loader = DataLoader(train_data,\n                                num_workers=4,\n                                batch_size=config.TRAIN_BATCH_SIZE,\n                                shuffle=True,\n                                drop_last=True)\n\n        valid_data_loader = DataLoader(val_data,\n                                num_workers=4,\n                                batch_size=config.VALID_BATCH_SIZE,\n                                shuffle=False,\n                                drop_last=False)\n        \n        all_rmse = []\n        for epoch in range(config.EPOCHS):\n            print(f\"Epoch --> {epoch+1} / {config.EPOCHS}\")\n            print(f\"-------------------------------\")\n            train_rmse = train_loop_fn(train_data_loader, model, optimizer, config.DEVICE, scheduler)\n            print(f\"Training Root Mean Square Error = {train_rmse}\")\n            val_rmse = eval_loop_fn(valid_data_loader, model, config.DEVICE)\n            print(f\"Validation Root Mean Square Error = {val_rmse}\")\n            \n            all_rmse.append(val_rmse)\n        print('\\n')\n        \n        if i < 1:\n            best_RMSE = min(all_rmse)\n            best_model = copy.deepcopy(model)\n            all_rmse = []\n        else:\n            if min(all_rmse) < best_RMSE:\n                best_RMSE = min(all_rmse)\n                best_model = copy.deepcopy(model)\n                all_rmse = []\n                \n    torch.save(best_model,'./second_timm_efficientnet_b0_ns_model.bin')\n    print()\n    print(f\"The lowest RMSE score that we got across all the folds is : {best_RMSE}\")\n    \n    return best_model\n                \nif __name__ == \"__main__\":\n    run()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T09:14:17.070546Z","iopub.execute_input":"2021-09-27T09:14:17.07081Z","iopub.status.idle":"2021-09-27T09:28:24.553495Z","shell.execute_reply.started":"2021-09-27T09:14:17.070774Z","shell.execute_reply":"2021-09-27T09:28:24.551202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  ","metadata":{},"execution_count":null,"outputs":[]}]}