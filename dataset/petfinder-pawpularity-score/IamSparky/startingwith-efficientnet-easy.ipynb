{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet_pytorch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-26T05:51:04.685614Z","iopub.execute_input":"2021-09-26T05:51:04.686068Z","iopub.status.idle":"2021-09-26T05:51:11.225013Z","shell.execute_reply.started":"2021-09-26T05:51:04.686033Z","shell.execute_reply":"2021-09-26T05:51:11.219499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ../input/cpythonlibrary/cpython-master\nfrom Lib import copy\n%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:11.227454Z","iopub.execute_input":"2021-09-26T05:51:11.227756Z","iopub.status.idle":"2021-09-26T05:51:11.242251Z","shell.execute_reply.started":"2021-09-26T05:51:11.227713Z","shell.execute_reply":"2021-09-26T05:51:11.241589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport albumentations\nimport torch.nn as nn\nimport efficientnet_pytorch\nimport torch.nn.functional as F\nimport gc\nimport warnings\n\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nfrom tqdm import tqdm\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:14.416076Z","iopub.execute_input":"2021-09-26T05:51:14.416344Z","iopub.status.idle":"2021-09-26T05:51:14.422072Z","shell.execute_reply.started":"2021-09-26T05:51:14.416315Z","shell.execute_reply":"2021-09-26T05:51:14.421382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    TRAINING_FILE = \"../input/petfinder-pawpularity-score/train.csv\"\n    TRAINING_IMAGE_PATH = \"../input/petfinder-pawpularity-score/train/\"\n    DEVICE = torch.device(\"cuda\")\n    TRAIN_BATCH_SIZE = 64\n    VALID_BATCH_SIZE = 64\n    EPOCHS = 5\n    \nclass AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:14.878859Z","iopub.execute_input":"2021-09-26T05:51:14.879683Z","iopub.status.idle":"2021-09-26T05:51:14.890699Z","shell.execute_reply.started":"2021-09-26T05:51:14.879637Z","shell.execute_reply":"2021-09-26T05:51:14.889776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train = pd.read_csv(config.TRAINING_FILE)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:46.698999Z","iopub.execute_input":"2021-09-26T05:51:46.699258Z","iopub.status.idle":"2021-09-26T05:51:46.724765Z","shell.execute_reply.started":"2021-09-26T05:51:46.699229Z","shell.execute_reply":"2021-09-26T05:51:46.72403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create folds\nfrom sklearn import model_selection\n\nnew_train[\"kfold\"] = -1    \nnew_train = new_train.sample(frac=1).reset_index(drop=True)\ny = new_train.Pawpularity.values\nkf = model_selection.StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X = new_train, y = y)):\n    new_train.loc[v_, 'kfold'] = f","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:47.138294Z","iopub.execute_input":"2021-09-26T05:51:47.138569Z","iopub.status.idle":"2021-09-26T05:51:47.159151Z","shell.execute_reply.started":"2021-09-26T05:51:47.13854Z","shell.execute_reply":"2021-09-26T05:51:47.158365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class petFinderDataset:\n    def __init__(self, constant_func, dataframe, is_valid = 0):\n        self.constant_func = constant_func\n        self.dataframe = dataframe\n        self.is_valid = is_valid\n        if self.is_valid == 1: # transforms for validation images\n            self.aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(224, 224),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            )], p=1.)\n\n        else:       # transfoms for training images \n            self.aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(224, 224),\n            albumentations.Transpose(p=0.5),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n            albumentations.CoarseDropout(p=0.5),\n            albumentations.Cutout(p=0.5)], p=1.)\n    \n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, item):\n        df = self.dataframe.iloc[item, :]\n\n        # converting jpg format of images to numpy array\n        img = np.array(Image.open('../input/petfinder-pawpularity-score/train/' + df[\"Id\"] + '.jpg')) \n        img = self.aug(image = img)['image']\n        img = np.transpose(img , (2,0,1)).astype(np.float32) # 2,0,1 because pytorch excepts image channel first then dimension of image\n        \n        if self.is_valid == 1:\n            return {\n                'image': torch.tensor(img, dtype = torch.float),\n                'tabular_data' : torch.tensor(df[1:-2], dtype = torch.float),\n                'target' : torch.tensor(df['Pawpularity'], dtype = torch.float)\n            }\n        else:\n            return {\n                'image': torch.tensor(img, dtype = torch.float),\n                'tabular_data' : torch.tensor(df[1:-2], dtype = torch.float),\n                'target' : torch.tensor(df['Pawpularity'], dtype = torch.float)\n            }","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:48.639307Z","iopub.execute_input":"2021-09-26T05:51:48.640261Z","iopub.status.idle":"2021-09-26T05:51:48.656571Z","shell.execute_reply.started":"2021-09-26T05:51:48.640211Z","shell.execute_reply":"2021-09-26T05:51:48.655808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = petFinderDataset('config', new_train)[71]['image']\nplt.imshow(np.transpose(img.numpy(), (1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:50.501776Z","iopub.execute_input":"2021-09-26T05:51:50.502739Z","iopub.status.idle":"2021-09-26T05:51:50.771208Z","shell.execute_reply.started":"2021-09-26T05:51:50.502695Z","shell.execute_reply":"2021-09-26T05:51:50.770512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EfficientNet_b0(nn.Module):\n    def __init__(self):\n        super(EfficientNet_b0, self).__init__()\n        self.model = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b0')\n        self.dropout = nn.Dropout(0.1)\n        self.final_layer = nn.Linear(1280 , 1)\n        \n        self.tabular_dense_layer_1 = nn.Linear(12, 8)\n        self.tabular_dense_layer_2 = nn.Linear(8, 4)\n        self.tabular_dense_layer_3 = nn.Linear(4, 1)\n        self.relu = nn.ReLU()\n        \n        self.outputs = nn.Linear(2 , 1)\n        \n    def forward(self, inputs ,tabular_data_inputs):\n        batch_size, _, _, _ = inputs.shape\n        \n        x = self.model.extract_features(inputs)\n\n        # Pooling and final linear layer\n        x = self.model._avg_pooling(x)\n        \n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        x = self.final_layer(self.dropout(x))\n        \n        tab = self.tabular_dense_layer_1(tabular_data_inputs)\n        tab = self.relu(tab)\n        tab = self.tabular_dense_layer_2(tab)\n        tab = self.relu(tab)\n        tab = self.tabular_dense_layer_3(tab)\n        tab = self.relu(tab)\n        \n        op = torch.cat((x, tab), dim=1)\n        op = self.relu(op)\n\n        return self.outputs(op)\n    \nmodel = EfficientNet_b0()\nmodel = model.to(config.DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:53.30417Z","iopub.execute_input":"2021-09-26T05:51:53.304436Z","iopub.status.idle":"2021-09-26T05:51:53.447694Z","shell.execute_reply.started":"2021-09-26T05:51:53.304406Z","shell.execute_reply":"2021-09-26T05:51:53.446852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(x, y):\n    criterion = nn.MSELoss()\n    loss = torch.sqrt(criterion(x, y))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:55.141019Z","iopub.execute_input":"2021-09-26T05:51:55.14164Z","iopub.status.idle":"2021-09-26T05:51:55.151133Z","shell.execute_reply.started":"2021-09-26T05:51:55.141565Z","shell.execute_reply":"2021-09-26T05:51:55.150083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n    running_loss = 0\n    model.train()\n    \n    losses = AverageMeter()\n    tqdm_ob = tqdm(data_loader, total = len(data_loader))\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        target = dataset[\"target\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n\n        outputs = model(image, tabular_data)\n        loss = loss_fn(outputs , target)\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        losses.update(loss.item(), image.size(0))\n        tqdm_ob.set_postfix(loss = losses.avg)\n            \n        del image, tabular_data, target\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        running_loss += loss.item() \n    train_loss = running_loss/ (batch_index + 1)\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:56.329682Z","iopub.execute_input":"2021-09-26T05:51:56.329955Z","iopub.status.idle":"2021-09-26T05:51:56.343029Z","shell.execute_reply.started":"2021-09-26T05:51:56.329928Z","shell.execute_reply":"2021-09-26T05:51:56.342159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_loop_fn(data_loader, model, device):\n    running_loss = 0\n    model.eval()\n    \n    losses = AverageMeter()\n    tqdm_ob = tqdm(data_loader, total = len(data_loader))\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        target = dataset[\"target\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n\n        outputs = model(image, tabular_data)\n        loss = loss_fn(outputs , target)\n        losses.update(loss.item(), image.size(0))\n        tqdm_ob.set_postfix(loss = losses.avg)\n            \n        del image, tabular_data, target\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        running_loss += loss.item() \n    val_loss = running_loss/ (batch_index + 1)\n    return val_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:51:57.359383Z","iopub.execute_input":"2021-09-26T05:51:57.359687Z","iopub.status.idle":"2021-09-26T05:51:57.368538Z","shell.execute_reply.started":"2021-09-26T05:51:57.359656Z","shell.execute_reply":"2021-09-26T05:51:57.367589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 * 0.95)\n\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n    \n    a_string = \"*\" * 20\n    for i in range(5):\n        print(a_string, \" FOLD NUMBER \", i, a_string)\n        df_train = new_train[new_train.kfold != i].reset_index(drop=True)\n        df_valid = new_train[new_train.kfold == i].reset_index(drop=True)\n\n        train_data = petFinderDataset('config', df_train)\n        val_data = petFinderDataset('config', df_valid, is_valid = 1)\n\n        train_data_loader = DataLoader(train_data,\n                                num_workers=4,\n                                batch_size=config.TRAIN_BATCH_SIZE,\n                                shuffle=True,\n                                drop_last=True)\n\n        valid_data_loader = DataLoader(val_data,\n                                num_workers=4,\n                                batch_size=config.VALID_BATCH_SIZE,\n                                shuffle=False,\n                                drop_last=False)\n        \n        all_rmse = []\n        for epoch in range(config.EPOCHS):\n            print(f\"Epoch --> {epoch+1} / {config.EPOCHS}\")\n            print(f\"-------------------------------\")\n            train_rmse = train_loop_fn(train_data_loader, model, optimizer, config.DEVICE, scheduler)\n            print(f\"Training Root Mean Square Error = {train_rmse}\")\n            val_rmse = eval_loop_fn(valid_data_loader, model, config.DEVICE)\n            print(f\"Validation Root Mean Square Error = {val_rmse}\")\n            \n            all_rmse.append(val_rmse)\n        print('\\n')\n        \n        if i < 1:\n            best_RMSE = min(all_rmse)\n            best_model = copy.deepcopy(model)\n            all_rmse = []\n        else:\n            if min(all_rmse) < best_RMSE:\n                best_RMSE = min(all_rmse)\n                best_model = copy.deepcopy(model)\n                all_rmse = []\n                \n    torch.save(best_model,'./first_basic_model.bin')\n    print()\n    print(f\"The lowest RMSE score that we got across all the folds is : {best_RMSE}\")\n    \n    return best_model\n                \nif __name__ == \"__main__\":\n    run()","metadata":{"execution":{"iopub.status.busy":"2021-09-26T05:52:37.757399Z","iopub.execute_input":"2021-09-26T05:52:37.757688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}