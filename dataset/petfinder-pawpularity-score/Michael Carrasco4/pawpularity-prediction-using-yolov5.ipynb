{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pet Popularity Prediction Need\n\nThousands of animals are euthanized in shelters each day. Many are still in completely good health but are sadly still put down. \nOne key way of increasing the likelihood of an animal being adopted is by increasing its picture quality. \n\nThis project will take this a step further by not only looking at the quality of a photo, but also a variety of other variables. Then from these variables creating a machine learning model to predict the popularity scores of future photos.\n","metadata":{}},{"cell_type":"markdown","source":"# Data Description\n\nThe given dataset contains 9923 different pet photos from PetFinder.my. These photos contain cats and\ndogs in a variety of different poses and backgrounds. The dataset also contains photo metadata manually\nlabeling each photo with key variables such as if the pet is in proper focus, currently in an action or taking up\na significant portion of the photo. These variables are labeled with a value of 0 for no, and yes for 1. \n\nA \"pawpularity” score is also given with each photo in the training set. \nThis score signifies how much user engagement each photo received, and is the\nscore this project will be predicting. ","metadata":{}},{"cell_type":"markdown","source":"## Photo Metadata\nEach pet photo is labeled with the value of 1 (Yes) or 0 (No) for each of the following features:\n\nFocus - Pet stands out against uncluttered background, not too close / far.\n\nEyes - Both eyes are facing front or near-front, with at least 1 eye / pupil decently clear.\n\nFace - Decently clear face, facing front or near-front.\n\nNear - Single pet taking up significant portion of photo (roughly over 50% of photo width or height).\n\nAction - Pet in the middle of an action (e.g., jumping).\n\nAccessory - Accompanying physical or digital accessory / prop (i.e. toy, digital sticker), excluding collar and leash.\n\nGroup - More than 1 pet in the photo.\n\nCollage - Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).\n\nHuman - Human in the photo.\n\nOcclusion - Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are considered occlusion.\n\nInfo - Custom-added text or labels (i.e. pet name, description).\n\nBlur - Noticeably out of focus or noisy, especially for the pet’s eyes and face. For Blur entries, “Eyes” column is always set to 0.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport math\nfrom tqdm.notebook import tqdm\nimport imageio\nimport torch\nimport matplotlib.patches as patches\nimport os \nimport matplotlib.image as img\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n#load sklearn models and metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.svm import SVR\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:47:53.889711Z","iopub.execute_input":"2022-05-10T17:47:53.89109Z","iopub.status.idle":"2022-05-10T17:47:56.925936Z","shell.execute_reply.started":"2022-05-10T17:47:53.890926Z","shell.execute_reply":"2022-05-10T17:47:56.924681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/train-data/save_data.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:47:56.927855Z","iopub.execute_input":"2022-05-10T17:47:56.928284Z","iopub.status.idle":"2022-05-10T17:47:57.020964Z","shell.execute_reply.started":"2022-05-10T17:47:56.928242Z","shell.execute_reply":"2022-05-10T17:47:57.019826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!Github clone https://github.com/ultralytics/yolov5\n#loads yolov5 with internet","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:47:57.022465Z","iopub.execute_input":"2022-05-10T17:47:57.0227Z","iopub.status.idle":"2022-05-10T17:47:57.027925Z","shell.execute_reply.started":"2022-05-10T17:47:57.022673Z","shell.execute_reply":"2022-05-10T17:47:57.026873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Print out top/low scoring pictures","metadata":{}},{"cell_type":"code","source":"train_image='../input/petfinder-pawpularity-score/train'\ntop_images=train.sort_values(by='Pawpularity',ascending=False)\ntop_images=top_images['Id'][:6]\n\nfig=plt.figure(figsize=(30,30))\nfig.suptitle('Top 6 Pawpularity Score',fontsize=80)\nfor i in range(0,6):\n    image=img.imread(os.path.join(train_image,list(top_images)[i]+'.jpg'))\n    fi=fig.add_subplot(2,3,i+1)\n    plt.imshow(image)  \n    \nplt.show()    \n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:47:57.03137Z","iopub.execute_input":"2022-05-10T17:47:57.03229Z","iopub.status.idle":"2022-05-10T17:47:59.864638Z","shell.execute_reply.started":"2022-05-10T17:47:57.032233Z","shell.execute_reply":"2022-05-10T17:47:59.863824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"worst_images=train.sort_values(by='Pawpularity',ascending=True)\nworst_images=worst_images['Id'][:6]\nfig=plt.figure(figsize=(30,30))\nfig.suptitle('Bottom 6 Pawpularity Score',fontsize=80)\nfor i in range(0,6):\n    image=img.imread(os.path.join(train_image,list(worst_images)[i]+'.jpg'))\n    fi=fig.add_subplot(2,3,i+1)\n    plt.imshow(image)  \n    \nplt.show()    ","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:47:59.865739Z","iopub.execute_input":"2022-05-10T17:47:59.865972Z","iopub.status.idle":"2022-05-10T17:48:02.578424Z","shell.execute_reply.started":"2022-05-10T17:47:59.865945Z","shell.execute_reply":"2022-05-10T17:48:02.577343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quick glance\nTaking a look at the top and bottom scoring pictures it was noticed that\nsome of the lower scoring pictures tended to be blurrier, the animals were further in ther background, and there was more \"clutter\" in the picture. However for many of the other pictures it was hard to discern any meaningful differences between top and bottom scoring pictures.","metadata":{}},{"cell_type":"markdown","source":"# Load YOLOv5 model\nApply YOLOv5 to extract more data from given pictures.","metadata":{}},{"cell_type":"markdown","source":"### Below code was first run and result was saved into this notebook. YOLOv5 model code was then commented out to shorten running time for performing future changes or adjustments. ","metadata":{}},{"cell_type":"code","source":"\n#!cp -R '../input/torch-hub/torch/root/.cache/torch' '/root/.cache/torch'\n\n#!cp -R '../input/torch-hub/ultralytics/root/.config/Ultralytics' '/root/.config/Ultralytics'\n# yolov5x6_model = torch.hub.load('ultralytics/yolov5', 'yolov5x6')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:02.58227Z","iopub.execute_input":"2022-05-10T17:48:02.582593Z","iopub.status.idle":"2022-05-10T17:48:02.587463Z","shell.execute_reply.started":"2022-05-10T17:48:02.58256Z","shell.execute_reply":"2022-05-10T17:48:02.58644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Find our image file and append that to our training dataset\n\n# def get_image_file_path(image_id):\n#     return f'../input/petfinder-pawpularity-score/train/{image_id}.jpg'\n\n\n# train['file_path'] = train['Id'].apply(get_image_file_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:02.589028Z","iopub.execute_input":"2022-05-10T17:48:02.589447Z","iopub.status.idle":"2022-05-10T17:48:02.601109Z","shell.execute_reply.started":"2022-05-10T17:48:02.589409Z","shell.execute_reply":"2022-05-10T17:48:02.59977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# widths = []\n# heights = []\n# ratios = []\n# for file_path in (train['file_path']):\n#     image = imageio.imread(file_path)\n#     h, w, _ = image.shape\n#     heights.append(h)\n#     widths.append(w)\n#     ratios.append(w / h)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:02.602676Z","iopub.execute_input":"2022-05-10T17:48:02.603256Z","iopub.status.idle":"2022-05-10T17:48:02.614962Z","shell.execute_reply.started":"2022-05-10T17:48:02.603214Z","shell.execute_reply":"2022-05-10T17:48:02.614103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Get Image Info\n# def get_image_info(file_path, plot=False):\n#     # Read Image\n#     image = imageio.imread(file_path)\n#     h, w, c = image.shape\n    \n#     if plot: # Debug Plots\n#         fig, ax = plt.subplots(1, 2, figsize=(8,8))\n#         ax[0].set_title('Pets detected in Image', size=16)\n#         ax[0].imshow(image)\n        \n#     # Get YOLOV5 results using Test Time Augmentation for better result\n#     results = yolov5x6_model(image, augment=True)\n    \n#     # Mask for pixels containing pets, initially all set to zero\n#     pet_pixels = np.zeros(shape=[h, w], dtype=np.uint8)\n    \n#     # Dictionary to Save Image Info\n#     h, w, _ = image.shape\n#     image_info = { \n#         'n_pets': 0, # Number of pets in the image\n#         'labels': [], # Label assigned to found objects\n#         'thresholds': [], # confidence score\n#     }\n    \n#     # Save found pets to draw bounding boxes\n#     pets_found = []\n    \n#     # Save info for each pet\n#     for x1, y1, x2, y2, treshold, label in results.xyxy[0].cpu().detach().numpy():\n#         label = results.names[int(label)]\n#         if label in ['dog', 'cat']:\n#             image_info['n_pets'] += 1\n#             image_info['labels'].append(label)\n#             image_info['thresholds'].append(treshold)\n\n            \n#             # Set pixels containing pets to 1\n#             pet_pixels[int(y1):int(y2), int(x1):int(x2)] = 1\n            \n#             # Add found pet\n#             pets_found.append([x1, x2, y1, y2, label])\n\n#     if plot:\n#         for x1, x2, y1, y2, label in pets_found:\n#             c = 'red' if label == 'dog' else 'blue'\n#             rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor=c, facecolor='none')\n#             # Add the patch to the Axes\n#             ax[0].add_patch(rect)\n#             ax[0].text(max(25, (x2+x1)/2), max(25, y1-h*0.02), label, c=c, ha='center', size=14)\n                \n#     # Add Pet Ratio in Image\n#     image_info['pet_ratio'] = pet_pixels.sum() / (h*w)\n\n#     if plot:\n#         # Show pet pixels\n#         ax[1].set_title('Pixels Containing Pets', size=16)\n#         ax[1].imshow(pet_pixels)\n#         plt.show()\n        \n#     return image_info","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:02.616419Z","iopub.execute_input":"2022-05-10T17:48:02.616865Z","iopub.status.idle":"2022-05-10T17:48:02.631479Z","shell.execute_reply.started":"2022-05-10T17:48:02.616829Z","shell.execute_reply":"2022-05-10T17:48:02.630508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Saves our newly calculated image Info\n# IMAGES_INFO = {\n#     'n_pets': [],\n#     'label': [],\n#     'pet_ratio': [],\n# }","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:02.634687Z","iopub.execute_input":"2022-05-10T17:48:02.635079Z","iopub.status.idle":"2022-05-10T17:48:02.649287Z","shell.execute_reply.started":"2022-05-10T17:48:02.635015Z","shell.execute_reply":"2022-05-10T17:48:02.648422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Prints out results of YOLOv5 model\n# for file_path in train['file_path'].head(10):\n#     get_image_info(file_path, plot=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:02.650666Z","iopub.execute_input":"2022-05-10T17:48:02.651208Z","iopub.status.idle":"2022-05-10T17:48:02.66391Z","shell.execute_reply.started":"2022-05-10T17:48:02.651152Z","shell.execute_reply":"2022-05-10T17:48:02.663077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for idx, file_path in enumerate(tqdm(train['file_path'])):\n#     image_info = get_image_info(file_path, plot=False)\n#     IMAGES_INFO['n_pets'].append(image_info['n_pets'])\n#     IMAGES_INFO['pet_ratio'].append(image_info['pet_ratio'])\n    \n#     # Not Every Image is correctly classified\n#     labels = image_info['labels']\n#     if len(set(labels)) == 1: # unanimous label\n#         IMAGES_INFO['label'].append(labels[0])\n#     elif len(set(labels)) > 1: # Get label with highest confidence\n#         IMAGES_INFO['label'].append(labels[0])\n#     else: # unknown label, yolo could not find pet\n#         IMAGES_INFO['label'].append('unknown')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:02.665496Z","iopub.execute_input":"2022-05-10T17:48:02.665977Z","iopub.status.idle":"2022-05-10T17:48:02.676201Z","shell.execute_reply.started":"2022-05-10T17:48:02.665938Z","shell.execute_reply":"2022-05-10T17:48:02.675141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Add Image Info to Train dataset\n# for k, v in IMAGES_INFO.items():\n#     train[k] = v\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:02.677887Z","iopub.execute_input":"2022-05-10T17:48:02.678213Z","iopub.status.idle":"2022-05-10T17:48:02.690335Z","shell.execute_reply.started":"2022-05-10T17:48:02.678175Z","shell.execute_reply":"2022-05-10T17:48:02.689287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data analysis","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize= (15, 15))\nsns.heatmap(train.corr(), annot=True, fmt='.1g' )\nplt.title('Correlation Matrix', fontweight='bold', fontsize=20)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:39.429685Z","iopub.execute_input":"2022-05-10T17:48:39.43003Z","iopub.status.idle":"2022-05-10T17:48:41.144938Z","shell.execute_reply.started":"2022-05-10T17:48:39.429995Z","shell.execute_reply":"2022-05-10T17:48:41.143776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.hist(column='Pawpularity', bins=20)\nplt.title(\"Total Pawpularity Distribution\")\nplt.xlabel('Pawpularity')\nplt.ylabel('Picture Count')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:10:41.74448Z","iopub.execute_input":"2022-05-10T18:10:41.745679Z","iopub.status.idle":"2022-05-10T18:10:42.110982Z","shell.execute_reply.started":"2022-05-10T18:10:41.745623Z","shell.execute_reply":"2022-05-10T18:10:42.110017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Note:\nMost of the pawpularity points lie in the 20-40 range. Care will need to be taken that any models created do not just purely focus on this area, without taking into account higher and lower range values.","metadata":{}},{"cell_type":"code","source":"\ntrain.hist(column='Pawpularity',by='Blur', bins=10)\nplt.xlabel('Blur')\nplt.ylabel('Pawpularity')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:10:02.583031Z","iopub.execute_input":"2022-05-10T18:10:02.583428Z","iopub.status.idle":"2022-05-10T18:10:03.135599Z","shell.execute_reply.started":"2022-05-10T18:10:02.58339Z","shell.execute_reply":"2022-05-10T18:10:03.134669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.hist(column='Pawpularity',by='Near', bins=10)\nplt.xlabel('Near')\nplt.ylabel('Pawpularity')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:54.575481Z","iopub.execute_input":"2022-05-10T17:48:54.575797Z","iopub.status.idle":"2022-05-10T17:48:55.167315Z","shell.execute_reply.started":"2022-05-10T17:48:54.57576Z","shell.execute_reply":"2022-05-10T17:48:55.166114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.hist(column='Pawpularity',by='Group', bins=10)\nplt.xlabel('Group')\nplt.ylabel('Pawpularity')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:58.249448Z","iopub.execute_input":"2022-05-10T17:48:58.249792Z","iopub.status.idle":"2022-05-10T17:48:58.810687Z","shell.execute_reply.started":"2022-05-10T17:48:58.24976Z","shell.execute_reply":"2022-05-10T17:48:58.809571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pawpularity meta data values\n\nLooking at the \"pawpularity\" score against some of the variables, it looks as if there is no clear difference between a 0 or 1 value. \n\nThis is odd, because one would first guess certain variables would have a large coorelation with a pictures \"pawpularity\" score. For example, the \"blur\" variable which tells whether or not an image is blurry or in focus shows no discernable difference in their score.","metadata":{}},{"cell_type":"code","source":"# catc = sum(x == 'cat' for x in IMAGES_INFO['label'])\n# dogc = sum(x == 'dog' for x in IMAGES_INFO['label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:04.540249Z","iopub.status.idle":"2022-05-10T17:48:04.541007Z","shell.execute_reply.started":"2022-05-10T17:48:04.540811Z","shell.execute_reply":"2022-05-10T17:48:04.540831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DOG_MEAN = train.loc[train['label'] == 'dog', 'Pawpularity'].mean()\n# CAT_MEAN = train.loc[train['label'] == 'cat', 'Pawpularity'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:04.542227Z","iopub.status.idle":"2022-05-10T17:48:04.542569Z","shell.execute_reply.started":"2022-05-10T17:48:04.542397Z","shell.execute_reply":"2022-05-10T17:48:04.542415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# fig = plt.figure()\n# ax = fig.add_axes([0,0,1,2])\n# langs = ['Dog', 'Cat']\n# species = [DOG_MEAN,CAT_MEAN]\n\n# ax.bar(langs,species)\n# ax.set_ylabel('Mean',fontsize=20)\n# ax.set_xlabel('Species',fontsize=20)\n# ax.set_title('Pawpularity Mean by Species',fontsize=20)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:04.543894Z","iopub.status.idle":"2022-05-10T17:48:04.544695Z","shell.execute_reply.started":"2022-05-10T17:48:04.544301Z","shell.execute_reply":"2022-05-10T17:48:04.544349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change label of of dog and cat to 0 and 1 respectively\ntrain.label=train.label.replace(0,'dog')\ntrain.label=train.label.replace(1,'cat')\ntrain.label=train.label.replace(2,'unknown')\n\n\nplt.figure(figsize=(15, 8))\nplt.title('Pawpularity Distribution by species', size=24)\ntrain.loc[train['label'] != 'unknown'].groupby('label')['Pawpularity'].plot(kind='hist', \n                                                                            bins=20, alpha=0.50)\nplt.legend(prop={'size': 20})\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:56:04.521424Z","iopub.execute_input":"2022-05-10T17:56:04.521733Z","iopub.status.idle":"2022-05-10T17:56:05.007141Z","shell.execute_reply.started":"2022-05-10T17:56:04.5217Z","shell.execute_reply":"2022-05-10T17:56:05.005905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.label=train.label.replace('dog',0)\ntrain.label=train.label.replace('cat',1)\ntrain.label=train.label.replace('unknown',2)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:56:09.916975Z","iopub.execute_input":"2022-05-10T17:56:09.917834Z","iopub.status.idle":"2022-05-10T17:56:09.925924Z","shell.execute_reply.started":"2022-05-10T17:56:09.917792Z","shell.execute_reply":"2022-05-10T17:56:09.924969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filter features by variance","metadata":{}},{"cell_type":"code","source":"train.var()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:56:22.988246Z","iopub.execute_input":"2022-05-10T17:56:22.988726Z","iopub.status.idle":"2022-05-10T17:56:23.002916Z","shell.execute_reply.started":"2022-05-10T17:56:22.988693Z","shell.execute_reply":"2022-05-10T17:56:23.001636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing all features below .1 variance\npd.set_option('display.max_columns', None)\ntrain2 = train.drop(columns=['file_path','Id','Blur','Action','Subject Focus','Action','pet_ratio','Info','Collage','Accessory','Face']) \ntrain2.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:56:25.31034Z","iopub.execute_input":"2022-05-10T17:56:25.31065Z","iopub.status.idle":"2022-05-10T17:56:25.332001Z","shell.execute_reply.started":"2022-05-10T17:56:25.310616Z","shell.execute_reply":"2022-05-10T17:56:25.331238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filter features by coorelation","metadata":{}},{"cell_type":"code","source":"abs(train.corr()['Pawpularity'])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:56:40.720601Z","iopub.execute_input":"2022-05-10T17:56:40.720967Z","iopub.status.idle":"2022-05-10T17:56:40.740728Z","shell.execute_reply.started":"2022-05-10T17:56:40.720929Z","shell.execute_reply":"2022-05-10T17:56:40.739766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing all features below .01 coorelation\ntrain2 = train.drop(columns=['file_path','Id','Near','Action','Collage','Occlusion','Info','Human','Subject Focus','Eyes','Face','pet_ratio'])\ntrain2.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:56:43.111639Z","iopub.execute_input":"2022-05-10T17:56:43.111973Z","iopub.status.idle":"2022-05-10T17:56:43.126103Z","shell.execute_reply.started":"2022-05-10T17:56:43.111933Z","shell.execute_reply":"2022-05-10T17:56:43.125151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# note add Univariate feature selection vs recursive feature elimination","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:48:04.554279Z","iopub.status.idle":"2022-05-10T17:48:04.554706Z","shell.execute_reply.started":"2022-05-10T17:48:04.554548Z","shell.execute_reply":"2022-05-10T17:48:04.554565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create testing and training sets","metadata":{}},{"cell_type":"code","source":"X = train2.drop(columns=['Pawpularity'])\ny = train2['Pawpularity']\n\nX_train, X_val, y_train, y_val =train_test_split(\n    X, y, test_size=0.25, random_state=7)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:56:55.038364Z","iopub.execute_input":"2022-05-10T17:56:55.038809Z","iopub.status.idle":"2022-05-10T17:56:55.048908Z","shell.execute_reply.started":"2022-05-10T17:56:55.038753Z","shell.execute_reply":"2022-05-10T17:56:55.047976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prints out visual of predicted values compared to actual\n\nimport matplotlib.patches as mpatches\ndef ActualvPredictionsGraph(y_test,y_pred,title):\n    if max(y_test) >= max(y_pred):\n        my_range = int(max(y_test))\n    else:\n        my_range = int(max(y_pred))\n    plt.figure(figsize=(12,3))\n    plt.scatter(range(len(y_test)), y_test, color='blue')\n    plt.scatter(range(len(y_pred)), y_pred, color='red')\n    plt.xlabel('Index ')\n    plt.ylabel('Pawpularity ')\n    plt.title(title,fontdict = {'fontsize' : 15})\n    plt.legend(handles = [mpatches.Patch(color='red', label='prediction'),mpatches.Patch(color='blue', label='actual')])\n    plt.show()\n    return","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-10T17:56:57.910457Z","iopub.execute_input":"2022-05-10T17:56:57.910914Z","iopub.status.idle":"2022-05-10T17:56:57.921287Z","shell.execute_reply.started":"2022-05-10T17:56:57.910862Z","shell.execute_reply":"2022-05-10T17:56:57.919975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Grid search algorithm \n\nThis algorithm is used to find the best hyperparameters for our models from a provided list of parameters.\nCross validation is also used to prevent overfitting and hopefully achieve a better model.","metadata":{}},{"cell_type":"code","source":"\nmodel_params = {\n    'svc': {\n        'model': svm.SVR(),\n        'params' : {\n            'C': [1,5,50,100],\n            'kernel': ['rbf','linear','poly']\n        }  \n    },\n    'Decision_tree': {\n        'model': tree.DecisionTreeRegressor(),\n        'params' : {\n            'max_depth': [2,3,5,10,100],\n            'min_samples_split': [2,3,5,10],\n            'min_samples_leaf' :[2,3,5],\n        }\n    },\n    'naive_bayes_gaussian': {\n        'model': GaussianNB(),\n        'params': {\n            'var_smoothing': np.logspace(0,-9, num=100)\n        }\n    \n\n    },\n\n}\nscores = []\n\nfor model_name, mp in model_params.items():\n    clf =  GridSearchCV(mp['model'], mp['params'], cv=3, return_train_score=False)\n    clf.fit(X_train, y_train)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })   \nresults = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T17:57:01.72738Z","iopub.execute_input":"2022-05-10T17:57:01.728178Z","iopub.status.idle":"2022-05-10T18:07:59.188502Z","shell.execute_reply.started":"2022-05-10T17:57:01.728117Z","shell.execute_reply":"2022-05-10T18:07:59.187456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_columns = None\npd.options.display.max_rows = None\nresults\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:07:59.207245Z","iopub.execute_input":"2022-05-10T18:07:59.207892Z","iopub.status.idle":"2022-05-10T18:07:59.229523Z","shell.execute_reply.started":"2022-05-10T18:07:59.207854Z","shell.execute_reply":"2022-05-10T18:07:59.22815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Results","metadata":{}},{"cell_type":"markdown","source":"### Decision Tree Model","metadata":{}},{"cell_type":"code","source":"model=tree.DecisionTreeRegressor(splitter='best',max_depth= 4, min_samples_leaf=5)\ntree_model=model.fit(X_train,y_train)\ntree_y_pred = tree_model.predict(X_val)\n\n\nMSE=mean_squared_error(y_val, tree_y_pred)\nRMSE = math.sqrt(MSE)\nx=RMSE\nprint(\"Root Mean Square Error:\",RMSE)\n\nActualvPredictionsGraph(y_val[0:9912], tree_y_pred[0:9912], \"Actual vs. Predicted over all values\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:07:59.232153Z","iopub.execute_input":"2022-05-10T18:07:59.233032Z","iopub.status.idle":"2022-05-10T18:07:59.774419Z","shell.execute_reply.started":"2022-05-10T18:07:59.232976Z","shell.execute_reply":"2022-05-10T18:07:59.773657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The decision tree model interestingly tended to predict most points at about the 40 mark, and also at about the 35 mark. There were a few predictions out of this range but these were very negligible.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Visualization of tree model\n\nfig = plt.figure(figsize=(20,5))\n_ = tree.plot_tree(model,filled=True,feature_names=['Accesory','Group','Blur','N_Pets','Label'])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-10T18:07:59.775607Z","iopub.execute_input":"2022-05-10T18:07:59.775961Z","iopub.status.idle":"2022-05-10T18:08:01.241158Z","shell.execute_reply.started":"2022-05-10T18:07:59.775932Z","shell.execute_reply":"2022-05-10T18:08:01.240443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Support Vector Machine Model","metadata":{}},{"cell_type":"code","source":"model=svm.SVR(C=1,kernel='rbf')\nsvm_model=model.fit(X_train,y_train)\nsvm_y_pred = svm_model.predict(X_val)\n\n\nMSE=mean_squared_error(y_val, svm_y_pred)\nRMSE = math.sqrt(MSE)\nz=RMSE\nprint(\"Root Mean Square Error:\",RMSE)\n\nActualvPredictionsGraph(y_val[0:9912], svm_y_pred[0:9912], \"Actual vs. Predicted over all values\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:08:01.242246Z","iopub.execute_input":"2022-05-10T18:08:01.242999Z","iopub.status.idle":"2022-05-10T18:08:05.388285Z","shell.execute_reply.started":"2022-05-10T18:08:01.242963Z","shell.execute_reply":"2022-05-10T18:08:05.387133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The SVM model mainly predicted in the 20-40 range as feared. While being slightly more scattered in its predictions than our decision tree model it wasn't by much. ","metadata":{}},{"cell_type":"markdown","source":"### GaussianNB Model","metadata":{}},{"cell_type":"code","source":"model=GaussianNB(var_smoothing= 0.43287612810830584)\ngaussian_model=model.fit(X_train,y_train)\ngaussian_y_pred = gaussian_model.predict(X_val)\n\nMSE=mean_squared_error(y_val, gaussian_y_pred)\nRMSE = math.sqrt(MSE)\ny=RMSE\nprint(\"Root Mean Square Error:\",RMSE)\n\nActualvPredictionsGraph(y_val[0:9912], gaussian_y_pred[0:9912], \"Actual vs. Predicted over all values\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:08:05.389942Z","iopub.execute_input":"2022-05-10T18:08:05.390316Z","iopub.status.idle":"2022-05-10T18:08:05.934028Z","shell.execute_reply.started":"2022-05-10T18:08:05.390271Z","shell.execute_reply":"2022-05-10T18:08:05.933138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Naïve Bayes model gave the most interesting results. Without tuning this model had an RMSE score of\n58.922, which was drastically improved after the grid search algorithm to a score of 24.60. Also, unlike the \nprevious models which only guessed in the middle where most points lie, this model also predicted in the high \nextremes of 100. However, even with more variability in its predictions or more likely because of, this model \nscored the worst RMSE of all the created models.","metadata":{}},{"cell_type":"markdown","source":"### Ensemble Model-Averaging","metadata":{}},{"cell_type":"code","source":"a=tree_y_pred\nb=gaussian_y_pred\nc=svm_y_pred\npred_final = (a+b+c)/3.0\n\n\nMSE=mean_squared_error(y_val, pred_final)\nRMSE = math.sqrt(MSE)\nw=RMSE\nprint(\"Root Mean Square Error:\",RMSE)\n\nActualvPredictionsGraph(y_val[0:9912], pred_final[0:9912], \"Actual vs. Predicted over all values\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:08:05.935763Z","iopub.execute_input":"2022-05-10T18:08:05.936086Z","iopub.status.idle":"2022-05-10T18:08:06.497347Z","shell.execute_reply.started":"2022-05-10T18:08:05.936024Z","shell.execute_reply":"2022-05-10T18:08:06.496045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names=['SVM.SVR','Decision Tree','GaussianNB','Ensemble']\nvalues=[z,x,y,w]\nplt.title('Model RSME comparison')\nplt.ylabel('RMSE Value')\nplt.bar(names,values)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:08:06.498959Z","iopub.execute_input":"2022-05-10T18:08:06.499363Z","iopub.status.idle":"2022-05-10T18:08:06.746159Z","shell.execute_reply.started":"2022-05-10T18:08:06.499325Z","shell.execute_reply":"2022-05-10T18:08:06.745175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Takeaway\n\nThese models show that the given variables along with our extracted image values are not a good predictor for an image's popularity. It is likely that these models would perform poorly given new data that didnt center around the 20-40 range.\n\nTo fix this issue different data would be needed. It is highly possible that some other unusued variable would have a larger coorelation to a pictures popularity. \nThis could be something having nothing to do with whats inside the picture itself. For example, one possibly important variable could be the time/day the picture was posted. One study found that during certain times of different days, a instagram picture was more likely to have increased instagram engagement. Meaning that the popularity scores of these pet photos could be following a similar trend.\n","metadata":{}},{"cell_type":"markdown","source":"# Reference\n###  [PetFinder EDA + YOLOV5 Obj Detection + TFRecords](https://www.kaggle.com/markwijkhuizen/petfinder-eda-yolov5-obj-detection-tfrecords)","metadata":{}}]}