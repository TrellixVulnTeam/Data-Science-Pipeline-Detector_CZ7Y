{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install python-box timm pytorch-lightning==1.4.0 grad-cam ttach","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:45:25.105662Z","iopub.execute_input":"2021-11-07T09:45:25.106068Z","iopub.status.idle":"2021-11-07T09:45:47.5703Z","shell.execute_reply.started":"2021-11-07T09:45:25.105977Z","shell.execute_reply":"2021-11-07T09:45:47.569498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom box import Box\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\n\n#from pytorch_grad_cam import GradCAMPlusPlus\n#from pytorch_grad_cam.utils.image import show_cam_on_image\nfrom pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule\n\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:45:47.572378Z","iopub.execute_input":"2021-11-07T09:45:47.572743Z","iopub.status.idle":"2021-11-07T09:45:54.77513Z","shell.execute_reply.started":"2021-11-07T09:45:47.572703Z","shell.execute_reply":"2021-11-07T09:45:54.774355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"config = {'seed': 2021,\n          'root': '/kaggle/input/petfinder-pawpularity-score/', \n          'n_splits': 2,\n          'epoch': 2,\n          'trainer': {\n              'gpus': 1,\n              'accumulate_grad_batches': 1,\n              'progress_bar_refresh_rate': 1,\n              'fast_dev_run': False,\n              'num_sanity_val_steps': 0,\n              'resume_from_checkpoint': None,\n          },\n          'transform':{\n              'name': 'get_default_transforms',\n              'image_size': 224\n          },\n          'train_loader':{\n              'batch_size': 128, # 64\n              'shuffle': True,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': True,\n          },\n          'val_loader': {\n              'batch_size': 128, # 64\n              'shuffle': False,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': False\n         },\n          'model':{\n              'name': 'swin_tiny_patch4_window7_224',\n              'output_dim': 1\n          },\n          'optimizer':{\n              'name': 'optim.AdamW',\n              'params':{\n                  'lr': 1e-5\n              },\n          },\n          'scheduler':{\n              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n              'params':{\n                  'T_0': 20,\n                  'eta_min': 1e-4,\n              }\n          },\n          'loss': 'nn.BCEWithLogitsLoss',\n}\n\nconfig = Box(config)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-07T09:45:54.776707Z","iopub.execute_input":"2021-11-07T09:45:54.776953Z","iopub.status.idle":"2021-11-07T09:45:54.78597Z","shell.execute_reply.started":"2021-11-07T09:45:54.776922Z","shell.execute_reply":"2021-11-07T09:45:54.784939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pprint(config)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:45:54.787978Z","iopub.execute_input":"2021-11-07T09:45:54.788228Z","iopub.status.idle":"2021-11-07T09:45:54.809772Z","shell.execute_reply.started":"2021-11-07T09:45:54.788195Z","shell.execute_reply":"2021-11-07T09:45:54.809081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"code","source":"class PetfinderDataset(Dataset):\n    def __init__(self, df, image_size=224):\n        self._X = df[\"Id\"].values\n        self._y = None\n        if \"Pawpularity\" in df.keys():\n            self._y = df[\"Pawpularity\"].values\n        self._transform = T.Resize([image_size, image_size])\n\n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        image_path = self._X[idx]\n        image = read_image(image_path)\n        image = self._transform(image)\n        if self._y is not None:\n            label = self._y[idx]\n            return image, label\n        return image\n\nclass PetfinderDataModule(LightningDataModule):\n    def __init__(\n        self,\n        train_df,\n        val_df,\n        cfg,\n    ):\n        super().__init__()\n        self._train_df = train_df\n        self._val_df = val_df\n        self._cfg = cfg\n\n    def __create_dataset(self, train=True):\n        return (\n            PetfinderDataset(self._train_df, self._cfg.transform.image_size)\n            if train\n            else PetfinderDataset(self._val_df, self._cfg.transform.image_size)\n        )\n\n    def train_dataloader(self):\n        dataset = self.__create_dataset(True)\n        return DataLoader(dataset, **self._cfg.train_loader)\n\n    def val_dataloader(self):\n        dataset = self.__create_dataset(False)\n        return DataLoader(dataset, **self._cfg.val_loader)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:45:54.810951Z","iopub.execute_input":"2021-11-07T09:45:54.8113Z","iopub.status.idle":"2021-11-07T09:45:54.823055Z","shell.execute_reply.started":"2021-11-07T09:45:54.81126Z","shell.execute_reply":"2021-11-07T09:45:54.822216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## visualize data","metadata":{}},{"cell_type":"code","source":"torch.autograd.set_detect_anomaly(True)\nseed_everything(config.seed)\n\ndf = pd.read_csv(os.path.join(config.root, \"train.csv\"))\ndf[\"Id\"] = df[\"Id\"].apply(lambda x: os.path.join(config.root, \"train\", x + \".jpg\"))\ndf\ndf.to_csv(\"/kaggle/working/sample2.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:45:54.824637Z","iopub.execute_input":"2021-11-07T09:45:54.825248Z","iopub.status.idle":"2021-11-07T09:45:54.987378Z","shell.execute_reply.started":"2021-11-07T09:45:54.825215Z","shell.execute_reply":"2021-11-07T09:45:54.986625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:45:54.988493Z","iopub.execute_input":"2021-11-07T09:45:54.988753Z","iopub.status.idle":"2021-11-07T09:45:54.99938Z","shell.execute_reply.started":"2021-11-07T09:45:54.98872Z","shell.execute_reply":"2021-11-07T09:45:54.998439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_dataloader = PetfinderDataModule(df, df, config).val_dataloader()\nimages, labels = iter(sample_dataloader).next()\n\nshow_expand = 2\n\nplt.figure(figsize=(12, 12*show_expand))\nfor it, (image, label) in enumerate(zip(images[:16*show_expand], labels[:16*show_expand])):\n    print(it)\n    plt.subplot(4*show_expand, 4, it+1)\n    plt.imshow(image.permute(1, 2, 0))\n    plt.axis('off')\n    plt.title(f'Pawpularity: {int(label)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:45:55.001106Z","iopub.execute_input":"2021-11-07T09:45:55.001668Z","iopub.status.idle":"2021-11-07T09:46:02.623531Z","shell.execute_reply.started":"2021-11-07T09:45:55.001629Z","shell.execute_reply":"2021-11-07T09:46:02.622722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## augmentation","metadata":{}},{"cell_type":"code","source":"IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\ndef get_default_transforms():\n    transform = {\n        \"train\": T.Compose(\n            [\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n        \"val\": T.Compose(\n            [\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n    }\n    return transform\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:46:02.624744Z","iopub.execute_input":"2021-11-07T09:46:02.625059Z","iopub.status.idle":"2021-11-07T09:46:02.634189Z","shell.execute_reply.started":"2021-11-07T09:46:02.625015Z","shell.execute_reply":"2021-11-07T09:46:02.633181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n    assert alpha > 0, \"alpha should be larger than 0\"\n    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n\n    lam = np.random.beta(alpha, alpha)\n    rand_index = torch.randperm(x.size()[0])\n    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n    target_a, target_b = y, y[rand_index]\n    return mixed_x, target_a, target_b, lam\n\nclass Model(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.__build_model()\n        self._criterion = eval(self.cfg.loss)()\n        self.transform = get_default_transforms()\n        self.save_hyperparameters(cfg)\n\n    def __build_model(self):\n        self.backbone = create_model(\n            self.cfg.model.name, pretrained=True, num_classes=0, in_chans=3\n        )\n        num_features = self.backbone.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)\n        )\n\n    def forward(self, x):\n        f = self.backbone(x)\n        out = self.fc(f)\n        return out\n\n    def training_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'train')\n        return {'loss': loss, 'pred': pred, 'labels': labels}\n        \n    def validation_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'val')\n        return {'pred': pred, 'labels': labels}\n    \n    def __share_step(self, batch, mode):\n        images, labels = batch\n        labels = labels.float() / 100.0\n        images = self.transform[mode](images)\n        \n        if torch.rand(1)[0] < 0.5 and mode == 'train':\n            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n            logits = self.forward(mix_images).squeeze(1)\n            loss = self._criterion(logits, target_a) * lam + \\\n                (1 - lam) * self._criterion(logits, target_b)\n        else:\n            logits = self.forward(images).squeeze(1)\n            loss = self._criterion(logits, labels)\n        \n        pred = logits.sigmoid().detach().cpu() * 100.\n        labels = labels.detach().cpu() * 100.\n        return loss, pred, labels\n        \n    def training_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'train')\n\n    def validation_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'val')    \n        \n    def __share_epoch_end(self, outputs, mode):\n        preds = []\n        labels = []\n        for out in outputs:\n            pred, label = out['pred'], out['labels']\n            preds.append(pred)\n            labels.append(label)\n        preds = torch.cat(preds)\n        labels = torch.cat(labels)\n        metrics = torch.sqrt(((labels - preds) ** 2).mean())\n        self.log(f'{mode}_loss', metrics)\n    \n    def check_gradcam(self, dataloader, target_layer, target_category, reshape_transform=None):\n\n        cam = GradCAMPlusPlus(\n            model=self,\n            target_layers = [target_layer], \n            use_cuda=self.cfg.trainer.gpus, \n            reshape_transform=reshape_transform)\n        \n        org_images, labels = iter(dataloader).next()\n        cam.batch_size = len(org_images)\n        images = self.transform['val'](org_images)\n        images = images.to(self.device)\n        logits = self.forward(images).squeeze(1)\n        pred = logits.sigmoid().detach().cpu().numpy() * 100\n        labels = labels.cpu().numpy()\n        \n        grayscale_cam = cam(input_tensor=images, target_category=target_category, eigen_smooth=True)\n        org_images = org_images.detach().cpu().numpy().transpose(0, 2, 3, 1) / 255.\n        return org_images, grayscale_cam, pred, labels\n\n    def configure_optimizers(self):\n        optimizer = eval(self.cfg.optimizer.name)(\n            self.parameters(), **self.cfg.optimizer.params\n        )\n        scheduler = eval(self.cfg.scheduler.name)(\n            optimizer,\n            **self.cfg.scheduler.params\n        )\n        return [optimizer], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:46:02.637682Z","iopub.execute_input":"2021-11-07T09:46:02.638226Z","iopub.status.idle":"2021-11-07T09:46:02.672316Z","shell.execute_reply.started":"2021-11-07T09:46:02.63819Z","shell.execute_reply":"2021-11-07T09:46:02.671516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train","metadata":{}},{"cell_type":"code","source":"\nskf = StratifiedKFold(\n    n_splits=config.n_splits, shuffle=True, random_state=config.seed\n)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df[\"Id\"], df[\"Pawpularity\"])):\n    train_df = df.loc[train_idx].reset_index(drop=True)\n    val_df = df.loc[val_idx].reset_index(drop=True)\n    datamodule = PetfinderDataModule(train_df, val_df, config)\n    model = Model(config)\n    earystopping = EarlyStopping(monitor=\"val_loss\")\n    lr_monitor = callbacks.LearningRateMonitor()\n    loss_checkpoint = callbacks.ModelCheckpoint(\n        # dirpath=\"/kaggle/working\",\n        filename=\"best_loss\",\n        monitor=\"val_loss\",\n        save_top_k=-1,\n        mode=\"min\",\n        save_last=False,\n    )\n    logger = TensorBoardLogger(config.model.name)\n    \n    trainer = pl.Trainer(\n        logger=logger,\n        max_epochs=config.epoch,\n        callbacks=[lr_monitor, loss_checkpoint, earystopping],\n        **config.trainer,\n    )\n    trainer.fit(model, datamodule=datamodule)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:46:02.674087Z","iopub.execute_input":"2021-11-07T09:46:02.674798Z","iopub.status.idle":"2021-11-07T09:54:20.771424Z","shell.execute_reply.started":"2021-11-07T09:46:02.67476Z","shell.execute_reply":"2021-11-07T09:54:20.770625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# class activation map","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gradcam reshape_transform for vit\ndef reshape_transform(tensor, height=7, width=7):\n    print(\"tensor:{}\".format(tensor.shape))\n    result = tensor.reshape(tensor.size(0),\n                            height, width, tensor.size(2))\n\n    # like in CNNs.\n    result = result.permute(0, 3, 1, 2)\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:54:20.773253Z","iopub.execute_input":"2021-11-07T09:54:20.773528Z","iopub.status.idle":"2021-11-07T09:54:20.780038Z","shell.execute_reply.started":"2021-11-07T09:54:20.77349Z","shell.execute_reply":"2021-11-07T09:54:20.778995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working/swin_tiny_patch4_window7_224/default/version_3/checkpoints","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:54:20.781425Z","iopub.execute_input":"2021-11-07T09:54:20.781672Z","iopub.status.idle":"2021-11-07T09:54:21.605724Z","shell.execute_reply.started":"2021-11-07T09:54:20.78164Z","shell.execute_reply":"2021-11-07T09:54:21.604716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.backbone.layers[-2].blocks[-1].norm1","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:54:21.610113Z","iopub.execute_input":"2021-11-07T09:54:21.610385Z","iopub.status.idle":"2021-11-07T09:54:21.623193Z","shell.execute_reply.started":"2021-11-07T09:54:21.610349Z","shell.execute_reply":"2021-11-07T09:54:21.622421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VisualGradCam():\n    \"\"\"display dataframe\"\"\"\n    def __init__(self):\n\n        model = Model(config) \n        model.load_state_dict(torch.load(f'{config.model.name}/default/version_0/checkpoints/best_loss.ckpt')['state_dict'])\n        # model.load_state_dict(torch.load('./best_loss.ckpt')['state_dict']) # ./best_loss.ckpt ./best_loss.ckpt\n        self.model = model.cuda().eval()\n        config.val_loader.batch_size = 16\n        self.datamodule = PetfinderDataModule(train_df, val_df, config)\n\n    def _visual_single_layer(self, target_layer):\n        print(\"++++++++++++++++++++++++++++++++++++++++++++++++\")\n        print(\"target layer : {}\".format(target_layer))\n        images, grayscale_cams, preds, labels = model.check_gradcam(\n                                                    datamodule.val_dataloader(), \n                                                    target_layer=target_layer,\n                                                    target_category=None,\n                                                    reshape_transform=reshape_transform)\n        plt.figure(figsize=(12, 12))\n        for it, (image, grayscale_cam, pred, label) in enumerate(zip(images, grayscale_cams, preds, labels)):\n            plt.subplot(4, 4, it + 1)\n            visualization = show_cam_on_image(image, grayscale_cam)\n            plt.imshow(visualization)\n            plt.title(f'pred: {pred:.1f} label: {label}')\n            plt.axis('off')\n    \n    def visual_grad(self):\n        \n        self._visual_single_layer(target_layer=model.backbone.layers[-1].blocks[-1].norm1)\n\n#print(model.backbone)\nVGC = VisualGradCam()\nVGC.visual_grad()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:54:21.627657Z","iopub.execute_input":"2021-11-07T09:54:21.628181Z","iopub.status.idle":"2021-11-07T09:54:27.055765Z","shell.execute_reply.started":"2021-11-07T09:54:21.628136Z","shell.execute_reply":"2021-11-07T09:54:27.055072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(config) \nmodel.load_state_dict(torch.load(f'{config.model.name}/default/version_0/checkpoints/best_loss.ckpt')['state_dict'])\n# model.load_state_dict(torch.load('./best_loss.ckpt')['state_dict']) # ./best_loss.ckpt ./best_loss.ckpt\nmodel = model.cuda().eval()\nconfig.val_loader.batch_size = 16\ndatamodule = PetfinderDataModule(train_df, val_df, config)\n\nprint(model.backbone)\nimages, grayscale_cams, preds, labels = model.check_gradcam(\n                                            datamodule.val_dataloader(), \n                                            target_layer=model.backbone.layers[-1].blocks[-1].norm1,\n                                            target_category=None,\n                                            reshape_transform=reshape_transform)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:54:27.057042Z","iopub.execute_input":"2021-11-07T09:54:27.058039Z","iopub.status.idle":"2021-11-07T09:54:30.405414Z","shell.execute_reply.started":"2021-11-07T09:54:27.057996Z","shell.execute_reply":"2021-11-07T09:54:30.404006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor it, (image, grayscale_cam, pred, label) in enumerate(zip(images, grayscale_cams, preds, labels)):\n    plt.subplot(4, 4, it + 1)\n    visualization = show_cam_on_image(image, grayscale_cam)\n    plt.imshow(visualization)\n    plt.title(f'pred: {pred:.1f} label: {label}')\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:54:30.407761Z","iopub.execute_input":"2021-11-07T09:54:30.408078Z","iopub.status.idle":"2021-11-07T09:54:31.832236Z","shell.execute_reply.started":"2021-11-07T09:54:30.408039Z","shell.execute_reply":"2021-11-07T09:54:31.831433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualize result","metadata":{}},{"cell_type":"code","source":"from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n\npath = glob(f'./{config.model.name}/default/version_0/events*')[0]\nevent_acc = EventAccumulator(path, size_guidance={'scalars': 0})\nevent_acc.Reload()\n\nscalars = {}\nfor tag in event_acc.Tags()['scalars']:\n    events = event_acc.Scalars(tag)\n    scalars[tag] = [event.value for event in events]","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:54:31.833513Z","iopub.execute_input":"2021-11-07T09:54:31.833941Z","iopub.status.idle":"2021-11-07T09:54:31.867836Z","shell.execute_reply.started":"2021-11-07T09:54:31.833907Z","shell.execute_reply":"2021-11-07T09:54:31.867199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\n\nplt.figure(figsize=(16, 6))\nplt.subplot(1, 2, 1)\nplt.plot(range(len(scalars['lr-AdamW'])), scalars['lr-AdamW'])\nplt.xlabel('epoch')\nplt.ylabel('lr')\nplt.title('adamw lr')\n\nplt.subplot(1, 2, 2)\nplt.plot(range(len(scalars['train_loss'])), scalars['train_loss'], label='train_loss')\nplt.plot(range(len(scalars['val_loss'])), scalars['val_loss'], label='val_loss')\nplt.legend()\nplt.ylabel('rmse')\nplt.xlabel('epoch')\nplt.title('train/val rmse')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:54:31.869232Z","iopub.execute_input":"2021-11-07T09:54:31.869503Z","iopub.status.idle":"2021-11-07T09:54:32.505457Z","shell.execute_reply.started":"2021-11-07T09:54:31.869469Z","shell.execute_reply":"2021-11-07T09:54:32.504792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('best_val_loss', min(scalars['val_loss']))","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:54:32.506586Z","iopub.execute_input":"2021-11-07T09:54:32.507358Z","iopub.status.idle":"2021-11-07T09:54:32.512634Z","shell.execute_reply.started":"2021-11-07T09:54:32.507317Z","shell.execute_reply":"2021-11-07T09:54:32.511791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}