{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport sys\nimport time\nimport shutil\nimport random\nfrom glob import glob\nimport gc\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom scipy.special import softmax\n\nimport torch\nimport torchvision.utils as vutils\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-06T14:47:45.83014Z","iopub.execute_input":"2022-01-06T14:47:45.831Z","iopub.status.idle":"2022-01-06T14:47:49.31883Z","shell.execute_reply.started":"2022-01-06T14:47:45.830912Z","shell.execute_reply":"2022-01-06T14:47:49.318059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:47:53.81345Z","iopub.execute_input":"2022-01-06T14:47:53.813721Z","iopub.status.idle":"2022-01-06T14:47:58.626374Z","shell.execute_reply.started":"2022-01-06T14:47:53.813692Z","shell.execute_reply":"2022-01-06T14:47:58.625483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED=777\nrandom.seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:47:58.628621Z","iopub.execute_input":"2022-01-06T14:47:58.628918Z","iopub.status.idle":"2022-01-06T14:47:58.636758Z","shell.execute_reply.started":"2022-01-06T14:47:58.62887Z","shell.execute_reply":"2022-01-06T14:47:58.636016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False#False\nN_BINS = 10\nN_TTA_384 = 4\nN_TTA_224 = 6\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:47:58.638028Z","iopub.execute_input":"2022-01-06T14:47:58.638422Z","iopub.status.idle":"2022-01-06T14:47:58.645303Z","shell.execute_reply.started":"2022-01-06T14:47:58.638384Z","shell.execute_reply":"2022-01-06T14:47:58.644615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10 bins\nBIN2PAW_LIST_pawpularity = np.array([5.15555556,\n                                     16.57213439,\n                                     25.87837352,\n                                     35.01965812,\n                                     44.98826119,\n                                     55.20275862,\n                                     64.98190045,\n                                     74.85964912,\n                                     84.91907514,\n                                     98.53865979])","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:47:58.647084Z","iopub.execute_input":"2022-01-06T14:47:58.647396Z","iopub.status.idle":"2022-01-06T14:47:58.654596Z","shell.execute_reply.started":"2022-01-06T14:47:58.647361Z","shell.execute_reply":"2022-01-06T14:47:58.653926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATHS = glob('../input/swinl224384jointregbin/*/*.pth')\n#MODEL_PATHS = np.array(MODEL_PATHS)[np.array(['Seed777' in _ for _ in MODEL_PATHS])].tolist()\n\nALPHAS = [float(_.split('-')[-1][0:-4]) for _ in MODEL_PATHS]\nINPUT_SIZES = [int(m_path.split('/')[-2].split('SwinL')[1].split('-')[0]) for m_path in MODEL_PATHS]\n\nbin2paw_lists = [BIN2PAW_LIST_pawpularity]*len(MODEL_PATHS)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:47:58.656305Z","iopub.execute_input":"2022-01-06T14:47:58.656494Z","iopub.status.idle":"2022-01-06T14:47:58.684938Z","shell.execute_reply.started":"2022-01-06T14:47:58.656472Z","shell.execute_reply":"2022-01-06T14:47:58.684287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ALPHAS)\nprint(MODEL_PATHS)\nprint(INPUT_SIZES)\nprint(len(ALPHAS), len(MODEL_PATHS))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:47:58.686079Z","iopub.execute_input":"2022-01-06T14:47:58.686385Z","iopub.status.idle":"2022-01-06T14:47:58.692491Z","shell.execute_reply.started":"2022-01-06T14:47:58.68635Z","shell.execute_reply":"2022-01-06T14:47:58.691728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    IMAGE_DIR_PATH = '../input/petfinder-pawpularity-score/train/'\n    df_test = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\n    #df_test = df_test.iloc[0:3000]\n    df_test = df_test.iloc[0:10]\nelse:\n    IMAGE_DIR_PATH = '../input/petfinder-pawpularity-score/test/'\n    df_test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:47:58.693989Z","iopub.execute_input":"2022-01-06T14:47:58.69447Z","iopub.status.idle":"2022-01-06T14:47:58.727622Z","shell.execute_reply.started":"2022-01-06T14:47:58.694436Z","shell.execute_reply":"2022-01-06T14:47:58.726959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:48:00.859833Z","iopub.execute_input":"2022-01-06T14:48:00.860723Z","iopub.status.idle":"2022-01-06T14:48:00.886916Z","shell.execute_reply.started":"2022-01-06T14:48:00.860683Z","shell.execute_reply":"2022-01-06T14:48:00.886225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transform(image_size, flip=False):\n    if flip:\n        valid_aug = A.Compose([\n            A.SmallestMaxSize(max_size=image_size, p=1.0),\n            A.CenterCrop(height=image_size, width=image_size, p=1.0),\n            A.HorizontalFlip(p=1.0),\n            A.Normalize(p=1.0),\n            ToTensorV2(p=1.0)\n        ])\n    \n    else:\n        valid_aug = A.Compose([\n            A.SmallestMaxSize(max_size=image_size, p=1.0),\n            A.CenterCrop(height=image_size, width=image_size, p=1.0),\n            A.Normalize(p=1.0),\n            ToTensorV2(p=1.0)\n        ])\n\n    return valid_aug\n\n\n\n\ndef get_transform2(image_size):\n    train_aug = A.Compose([\n                           A.Rotate(limit=15, always_apply=True),#p=1),\n                           #A.LongestMaxSize(max_size=image_size, p=1.0),\n                           A.SmallestMaxSize(max_size=image_size, always_apply=True),\n                           A.OneOf([\n                                    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1, p=0.75),# all 0.75\n                                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.75),\n                                    A.RandomGamma(p=0.75)\n                           ], p=1.0),\n                           #A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=0, p=1.0),\n                           A.HorizontalFlip(p=0.5),\n                           A.OneOf([\n                                    A.CoarseDropout(min_holes=2,\n                                                    max_holes=10,\n                                                    max_width=image_size//5,\n                                                    min_width=image_size//20,\n                                                    max_height=image_size//5,\n                                                    min_height=image_size//20,\n                                                    fill_value=(0,0,0),\n                                                    p=0.75),# all 0.75\n                                    A.CoarseDropout(min_holes=2,\n                                                    max_holes=10,\n                                                    max_width=image_size//5,\n                                                    min_width=image_size//20,\n                                                    max_height=image_size//5,\n                                                    min_height=image_size//20,\n                                                    fill_value=(127,127,127),\n                                                    p=0.75),\n                                    A.CoarseDropout(min_holes=2,\n                                                    max_holes=10,\n                                                    max_width=image_size//5,\n                                                    min_width=image_size//20,\n                                                    max_height=image_size//5,\n                                                    min_height=image_size//20,\n                                                    fill_value=(255,255,255),\n                                                    p=0.75)\n                           ], p=1.0),\n                           A.RandomCrop(height=image_size, width=image_size, always_apply=True),\n                           A.Normalize(always_apply=True),\n                           ToTensorV2(always_apply=True)\n    ])\n    return train_aug","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:48:01.640245Z","iopub.execute_input":"2022-01-06T14:48:01.640508Z","iopub.status.idle":"2022-01-06T14:48:01.656841Z","shell.execute_reply.started":"2022-01-06T14:48:01.640478Z","shell.execute_reply":"2022-01-06T14:48:01.656104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetfinderDataset(Dataset):\n    def __init__(self, df, augs=None):\n        self.paths = IMAGE_DIR_PATH + np.array(df['Id']) + '.jpg'\n        self.feats = np.array(df[['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']]).astype(np.int)\n        self.augs = augs\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        image = cv2.imread(self.paths[idx])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.uint8)\n        \n        if self.augs:\n            image = self.augs(image=image)['image']\n\n        return image, torch.tensor(self.feats[idx], dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:48:02.217385Z","iopub.execute_input":"2022-01-06T14:48:02.217643Z","iopub.status.idle":"2022-01-06T14:48:02.225305Z","shell.execute_reply.started":"2022-01-06T14:48:02.217613Z","shell.execute_reply":"2022-01-06T14:48:02.224377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model","metadata":{}},{"cell_type":"code","source":"class swin_model_WithMeta3(nn.Module):\n    def __init__(self, pretrained=True, input_size=None):\n        super().__init__()\n\n        if input_size==224:\n            self.model = timm.create_model('swin_large_patch4_window7_224', pretrained=pretrained)\n        elif input_size==384:\n            self.model = timm.create_model('swin_large_patch4_window12_384', pretrained=pretrained)\n        else:\n            self.model = None\n\n        image_embedding_dim = self.model.head.in_features\n        self.model.head = nn.Identity()\n\n        neck_dim = 512#512\n        self.fc1 = nn.Linear(image_embedding_dim, neck_dim)\n        self.fc2 = nn.Linear(12, neck_dim)\n\n        self.fc3 = nn.Linear(neck_dim, 1)# regression\n        self.fc4 = nn.Linear(neck_dim, N_BINS)# classification\n        \n\n    def forward(self, input_image, input_features):\n        # image feature\n        y_image = self.fc1(self.model(input_image))\n\n        # meta feature\n        y_feat = torch.sigmoid(self.fc2(input_features))\n\n        # fuse two features\n        y = torch.mul(y_image, y_feat)\n        y_reg = self.fc3(y)\n        y_cls = self.fc4(y)\n        \n        return y_reg, y_cls","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:48:03.061939Z","iopub.execute_input":"2022-01-06T14:48:03.062604Z","iopub.status.idle":"2022-01-06T14:48:03.071885Z","shell.execute_reply.started":"2022-01-06T14:48:03.062566Z","shell.execute_reply":"2022-01-06T14:48:03.070985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigmoid(x):\n    y = 1.0 / (1.0 + np.exp(-x))\n    return y\n\ndef logit2paw(logit, bin2paw_list):\n    probs = softmax(logit, axis=1)\n    expects = np.sum(probs*bin2paw_list, axis=1)\n    return expects","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:48:03.721526Z","iopub.execute_input":"2022-01-06T14:48:03.7218Z","iopub.status.idle":"2022-01-06T14:48:03.726879Z","shell.execute_reply.started":"2022-01-06T14:48:03.721767Z","shell.execute_reply":"2022-01-06T14:48:03.725969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(valid_loader, model, device, bin2paw_list):\n    model.eval()\n    #model.half()#\n    \n    reg_preds, cls_preds = [], []\n    for images, features in tqdm(valid_loader):\n        images, features = images.to(device), features.to(device)\n        \n        #with torch.no_grad():\n        with torch.inference_mode():\n            reg_pred, cls_pred = model(images, features)\n        \n        reg_preds.append(reg_pred.to('cpu').detach().numpy())\n        cls_preds.append(cls_pred.to('cpu').detach().numpy())\n        \n    cls_preds = logit2paw(np.concatenate(cls_preds), bin2paw_list)\n    reg_preds = sigmoid(np.concatenate(reg_preds))*99 + 1\n    \n    return reg_preds.squeeze(), cls_preds.squeeze()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:48:04.11751Z","iopub.execute_input":"2022-01-06T14:48:04.118048Z","iopub.status.idle":"2022-01-06T14:48:04.124955Z","shell.execute_reply.started":"2022-01-06T14:48:04.11801Z","shell.execute_reply":"2022-01-06T14:48:04.123879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nformer_input_size = 0\n\nfor model_path, alpha, bin2paw_list, input_size in zip(MODEL_PATHS, ALPHAS, bin2paw_lists, INPUT_SIZES):\n    _=gc.collect()\n    \n    if former_input_size != input_size:\n        # switch model\n        model = swin_model_WithMeta3(pretrained=False, input_size=input_size)\n        _ = model.to(device)\n        print('model switched')\n    former_input_size = input_size\n        \n    \n    # model\n    print(model_path)\n    model.load_state_dict(torch.load(model_path))\n    \n    # augmentation\n    if input_size == 224:\n        valid_augs = [get_transform2(input_size)]*N_TTA_224\n    elif input_size == 384:\n        valid_augs = [get_transform2(input_size)]*N_TTA_384\n    else:\n        None\n    \n    preds_TTA = []\n    for valid_aug in valid_augs:\n        # dataset\n        valid_data = PetfinderDataset(df_test.reset_index(drop=True), augs=valid_aug)\n        valid_loader = DataLoader(valid_data,\n                                  shuffle=False,\n                                  num_workers=2,\n                                  pin_memory=True,\n                                  batch_size=BATCH_SIZE)\n        \n        \n        # predict\n        reg_preds, cls_preds = valid_fn(valid_loader, model, device, bin2paw_list)\n        pred = alpha*reg_preds + (1.0-alpha)*cls_preds\n        preds_TTA.append(pred) # TTAの回数分推論結果を保管\n        \n    mean_pred_TTA = np.mean(preds_TTA, axis=0) # TTA結果を単純平均\n    preds.append(mean_pred_TTA) # モデル毎に結果を保管\n\npreds = np.array(preds)\nprint(preds.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:48:05.647229Z","iopub.execute_input":"2022-01-06T14:48:05.64783Z","iopub.status.idle":"2022-01-06T14:53:11.799996Z","shell.execute_reply.started":"2022-01-06T14:48:05.647789Z","shell.execute_reply":"2022-01-06T14:53:11.797807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 単純平均\npred_final = np.mean(preds, axis=0)\n\n# LogMeanExp\n#pred_final = LogMeanExp(preds, temperature=20)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T14:53:12.595412Z","iopub.execute_input":"2022-01-06T14:53:12.59597Z","iopub.status.idle":"2022-01-06T14:53:12.603541Z","shell.execute_reply.started":"2022-01-06T14:53:12.595927Z","shell.execute_reply":"2022-01-06T14:53:12.602767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['Pawpularity'] = pred_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submit = df_test[['Id', 'Pawpularity']]\ndf_submit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submit['Pawpularity'] = df_submit['Pawpularity'].round(1)\ndf_submit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submit.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}