{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I write same code for practice with reference to [PHALANX's notebook](https://www.kaggle.com/phalanx/train-swin-t-pytorch-lightning)  . PHALANX used Swin-Transfomer model.  Maybe you should see PHALANX's notebook than this notebook.","metadata":{}},{"cell_type":"code","source":"!pip install python-box timm pytorch-lightning==1.4.0 grad-cam ttach","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:33:41.492987Z","iopub.execute_input":"2021-11-11T04:33:41.49341Z","iopub.status.idle":"2021-11-11T04:34:06.007314Z","shell.execute_reply.started":"2021-11-11T04:33:41.493299Z","shell.execute_reply":"2021-11-11T04:34:06.006551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom box import Box\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\nfrom pytorch_grad_cam import GradCAMPlusPlus\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:06.009414Z","iopub.execute_input":"2021-11-11T04:34:06.011893Z","iopub.status.idle":"2021-11-11T04:34:13.436883Z","shell.execute_reply.started":"2021-11-11T04:34:06.011853Z","shell.execute_reply":"2021-11-11T04:34:13.436123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"config = {'seed': 2021,\n          'root': '/kaggle/input/petfinder-pawpularity-score/', \n          'n_splits': 5,\n          'epoch': 20,\n          'trainer': {\n              'gpus': 1,\n              'accumulate_grad_batches': 1,\n              'progress_bar_refresh_rate': 1,\n              'fast_dev_run': False,\n              'num_sanity_val_steps': 0,\n              'resume_from_checkpoint': None,\n          },\n          'transform':{\n              'name': 'get_default_transforms',\n              'image_size': 224\n          },\n          'train_loader':{\n              'batch_size': 64,\n              'shuffle': True,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': True,\n          },\n          'val_loader': {\n              'batch_size': 64,\n              'shuffle': False,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': False\n         },\n          'test_loader' : {\n              'batch_size' : 64,\n              'shuffle' : False,\n              'num_workers' : 4,\n              'pin_memory' : False,\n              'drop_last' : False\n          },\n          'model':{\n              'name': 'swin_tiny_patch4_window7_224',\n              'output_dim': 1\n          },\n          'optimizer':{\n              'name': 'optim.AdamW',\n              'params':{\n                  'lr': 1e-5\n              },\n          },\n          'scheduler':{\n              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n              'params':{\n                  'T_0': 20,\n                  'eta_min': 1e-4,\n              }\n          },\n          'loss': 'nn.BCEWithLogitsLoss',\n}\n\nconfig = Box(config)\npprint(config)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:13.438393Z","iopub.execute_input":"2021-11-11T04:34:13.438687Z","iopub.status.idle":"2021-11-11T04:34:13.461301Z","shell.execute_reply.started":"2021-11-11T04:34:13.438624Z","shell.execute_reply":"2021-11-11T04:34:13.460455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"markdown","source":"torchvisioin\n\nPyTorchと連携するコンピュータービジョン用のライブラリです。効率的な画像およびビデオ変換用のユーティリティ、一般的に使用される事前トレーニング済みモデル、および一部のデータセットtorchvisionがあります\n\n1.transformsによる前処理の定義、2.Datasetsによる前処理&ダウンロード　3.DataloaderによるDatasetの使用という流れになる\n\n\nDataset\nデータセットを作成する\n\n1.transformsによる前処理の定義、2.Datasetsによる前処理&ダウンロード　3.DataloaderによるDatasetの使用という流れになる\n\nDataLoader\n\nDataset からサンプルを取得して、ミニバッチを作成するクラスです。基本的には、サンプルを取得する Dataset とバッチサイズを指定して作成します。","metadata":{}},{"cell_type":"code","source":"class PetfinderDataset(Dataset):\n    \"\"\"画像:image\n       label:pawpularity\n       の二つだけが含まれたデータセットを作る\n    \"\"\"\n    def __init__(self, df, image_size=224):\n        self._X = df[\"Id\"].values\n        self._y = None\n        if \"Pawpularity\" in df.keys():\n            self._y = df[\"Pawpularity\"].values\n        self._transform = T.Resize([image_size, image_size])#torchvision.transforms\n    \n    def __len__(self):\n        \"\"\"データ数を返す\"\"\"\n        return len(self._X)\n    \n    def __getitem__(self, idx):\n        \"\"\"pawpularityがあれば、pawpularity と　画像を返す\n            pawpularityがなければ、画像だけ返す\n        \"\"\"\n        image_path = self._X[idx]\n        image = read_image(image_path)#torchvision.io\n        image = self._transform(image)\n        if self._y is not None:\n            label = self._y[idx]# insert pawpulariy\n            return image, label\n        return image\n    \n\nclass PetfinderDataModule(LightningDataModule):\n    def __init__(\n        self,\n        train_df,\n        val_df,\n        cfg,\n    ):\n        super().__init__()\n        self._train_df = train_df\n        self._val_df = val_df\n        self._cfg = cfg\n        \n    def __create_dataset(self, train=True):\n        \"\"\"訓練データか検証データか判定して、データセットを作成\"\"\"\n        return(\n            PetfinderDataset(self._train_df, self._cfg.transform.image_size)\n            if train#後置if\n            else PetfinderDataset(self._val_df, self._cfg.transform.image_size)\n        )\n    \n    def train_dataloader(self):\n        dataset = self.__create_dataset(True)\n        #{'batch_size': 64,\n        #'drop_last': False,\n        #'num_workers': 4,\n        #'pin_memory': False,\n        #'shuffle': False}}\n        return DataLoader(dataset, **self._cfg.train_loader)#configのval_loaderキーの値を渡す\n    \n    def val_dataloader(self):\n        dataset = self.__create_dataset(False)\n        return DataLoader(dataset, **self._cfg.val_loader)\n    \nclass PetfindertestDataModule(LightningDataModule):\n    def __init__(self, test_df, cfg):\n        super().__init__()\n        self._test_df = test_df\n        self._cfg = cfg\n        \n    def __create_test_dataset(self):\n        \"\"\"テストデータ用のデータセット作成\"\"\"\n        return PetfinderDataset(self._test_df, self._cfg.transform.image_size)\n    \n    def test_dataloader(self):\n        dataset = self.__create_test_dataset()\n        return DataLoader(dataset, **self._cfg.test_loader)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:13.463281Z","iopub.execute_input":"2021-11-11T04:34:13.46365Z","iopub.status.idle":"2021-11-11T04:34:13.476896Z","shell.execute_reply.started":"2021-11-11T04:34:13.463597Z","shell.execute_reply":"2021-11-11T04:34:13.476061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## visualize data","metadata":{}},{"cell_type":"markdown","source":"seed_everything\n\nFunction that sets seed for pseudo-random number generators in: pytorch, numpy, python.random In addition, sets the following environment \nvariables:\n\nutograd.set_detect_anomaly\n\nContext-manager that enable anomaly detection for the autograd engine.\n\nThis does two things:\n\nRunning the forward pass with detection enabled will allow the backward pass to print the traceback of the forward operation that created the failing backward function.\n\nAny backward computation that generate “nan” value will raise an error.\n\nanomaly detetionは異常検知の意味\n\n","metadata":{}},{"cell_type":"code","source":"torch.autograd.set_detect_anomaly(True)\nseed_everything(config.seed)#seed_everything(config.seed)\n\n\n\ndf = pd.read_csv(os.path.join(config.root, \"train.csv\"))\n#configファイル 'root': '/kaggle/input/petfinder-pawpularity-score/'\ndf[\"Id\"] = df[\"Id\"].apply(lambda x: os.path.join(config.root, \"train\", x + \".jpg\"))","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:13.478311Z","iopub.execute_input":"2021-11-11T04:34:13.478556Z","iopub.status.idle":"2021-11-11T04:34:13.561734Z","shell.execute_reply.started":"2021-11-11T04:34:13.478522Z","shell.execute_reply":"2021-11-11T04:34:13.561047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Id\"][0]","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:13.563224Z","iopub.execute_input":"2021-11-11T04:34:13.563753Z","iopub.status.idle":"2021-11-11T04:34:13.571901Z","shell.execute_reply.started":"2021-11-11T04:34:13.563716Z","shell.execute_reply":"2021-11-11T04:34:13.571043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_dataloader = PetfinderDataModule(df, df, config).val_dataloader()\nimages, labels = iter(sample_dataloader).next()#iterとnextを組み合わせることで、最初の要素からnextを実行するたびに順番に取り出すことができる\n\nplt.figure(figsize = (12, 12))\nfor it, (image, label) in enumerate(zip(images[:16], labels[:16])):\n    plt.subplot(4, 4, it + 1)\n    plt.imshow(image.permute(1, 2, 0))#指定した次元に行列を変換\n    plt.axis(\"off\")\n    plt.title(f'Pawpularity : {int(label)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:13.57333Z","iopub.execute_input":"2021-11-11T04:34:13.573895Z","iopub.status.idle":"2021-11-11T04:34:20.038077Z","shell.execute_reply.started":"2021-11-11T04:34:13.57386Z","shell.execute_reply":"2021-11-11T04:34:20.037204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## augmentation","metadata":{}},{"cell_type":"markdown","source":"compose\n指定した変換を上から順番に一つずつやっていく\n\n\nconcertImageDtype\n\nConvert a tensor image to the given dtype and scale the values accordingly This function does not support PIL Image.\n\nNormalize\n\n正規化を行う Transform です。 nn 個のチャンネルごとの平均 (m_1, m_2, \\cdots, m_n)(m \n1\n​\n ,m \n2\n​\n ,⋯,m \nn\n​\n ) 及び標準偏差 (s_1, s_2, \\cdots, s_n)(s \n1\n​\n ,s \n2\n​\n ,⋯,s \nn\n​\n ) が与えられたとき、チャンネルごとに次のように標準化を行います。\n\noutput = (input-m)/s\n\nアフィン変換\n画像を行列を使って、拡大・縮小・回転・平行移動すること","metadata":{}},{"cell_type":"code","source":"IMAGENET_MEAN = [0.485, 0.456, 0.406]#RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]#RGB\n\ndef get_default_transforms():\n    transform = {\n        \"train\" : T.Compose(\n            [\n                T.RandomHorizontalFlip(),#左右反転\n                T.RandomVerticalFlip(),#上下反転\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),#ランダムにアフィン変換\n                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),#ランダムに明るさ、コントラスト、彩度、色相を変化させる\n                T.ConvertImageDtype(torch.float),#torchのfloat型に写真データを変換\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),#正規化\n            ]\n        ),\n        \"val\":T.Compose(\n            [\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n    }\n    \n    return transform","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:20.039206Z","iopub.execute_input":"2021-11-11T04:34:20.039439Z","iopub.status.idle":"2021-11-11T04:34:20.048687Z","shell.execute_reply.started":"2021-11-11T04:34:20.039404Z","shell.execute_reply":"2021-11-11T04:34:20.047693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"markdown","source":"　Pythonのassert文は、基本的には、条件をテストするデバッグ支援ツールです。アサーションの条件がTrueの場合は何も起きず、プログラムは何事もなく動作し続けます。しかし、アサーションの条件がFalseと評価された場合はAssertionError例外が送出され、必要に応じてエラーメッセージが生成されます。\n \n assert 条件式, 条件式がFalseの場合に出力するメッセージ\n \n randperm\n Tensor0 から n - 1 までの整数のランダム順列を返します。\n randperm(4) →　[2, 1, 0, 3]\n \n lightningModule →　生PyTorchで書かなければならない学習ループやバリデーションループ等を各hookのメソッドとして整理したフレームワークです。他にもGPUの制御やコールバックといった処理もフレームワークに含み、可読性や学習の再現性を上げています。\n                     torch.nn.Moduleの作成と似ていますが、ニューラルネットワークのmodelを定義するだけでなく、バッチに対するlossの計算、optimizerまで定義するクラスになっています。作成したモデルをTrainerクラスに渡してfitメソッドで学習を行います。","metadata":{}},{"cell_type":"markdown","source":"create_model:画像認識事前学習済みモデルライブラリpretrained→事前学習済みのモデルを使うか　num_classes→予測するクラス数 in_chain→学習の回数？連鎖率？\n\nnn.Sequential →　各層をつなげるもの kerasのsequantialと同じ","metadata":{}},{"cell_type":"markdown","source":"lightningmodule 参考サイト\n\nhttps://qiita.com/ground0state/items/c1d705ca2ee329cdfae4#pytorch_lightninglightningmodule","metadata":{}},{"cell_type":"markdown","source":"scheduler epoch毎に学習率を変化させてくれるもの\nhttp://blog.livedoor.jp/dividend_tomtom/archives/9193475.html","metadata":{}},{"cell_type":"code","source":"def mixup(x: torch.Tensor, y:torch.Tensor, alpha: float=1.0):\n    assert alpha > 0, \"alpha shoula be larger than 0\"\n    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance\"\n    \n    lam = np.random.beta(alpha, alpha)#np.random.beta()は、パラメータa, bのベータ分布に従う乱数を返す\n    rand_index = torch.randperm(x.size()[0])\n    mixed_x = lam*x + (1 - lam) * x[rand_index, :]\n    target_a, target_b = y, y[rand_index]\n    return mixed_x, target_a, target_b, lam\n\nclass Model(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.__build_model()\n        self._criterion = eval(self.cfg.loss)()\n        self.transform = get_default_transforms()\n        self.save_hyperparameters(cfg)\n        \n        \n    def __build_model(self):\n        self.backbone = create_model(\n            self.cfg.model.name, pretrained=True, num_classes=0, in_chans=3\n        )#ニューラルネットワークのmodelをreturnします。\n        num_features = self.backbone.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)#追加で学習させる層num_featureの正体は？ #Linearは直線\n        )\n    \n    def forward(self, x):\n        \"\"\"順伝播処理\"\"\"\n        f = self.backbone(x)\n        out = self.fc(f)\n        return out\n    \n    def training_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, \"train\")\n        return {\"loss\" : loss, \"pred\" : pred, \"labels\" : labels}\n    \n    def validation_step(self, batch, batch_index):\n        loss, pred, labels = self.__share_step(batch, \"val\")\n        return {\"pred\" : pred, \"labels\" : labels}\n    \n    def __share_step(self, batch, mode):\n        images, labels = batch\n        labels = labels.float() / 100.0\n        images = self.transform[mode](images)#modeに応じてaugmentationを実行\n        \n        if torch.rand(1)[0] < 0.5 and mode == \"train\":\n            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n            logits = self.forward(mix_images).squeeze(1)\n            loss = self._criterion(logits, target_a) * lam + (1 - lam)*self._criterion(logits, target_b)\n        else:\n            logits = self.forward(images).squeeze(1)#指定した次元（axis=1の次元を削除）\n            loss = self._criterion(logits, labels)\n            \n        pred = logits.sigmoid().detach().cpu() * 100.#detach 同一デバイス上に新しいテンソルを作成、計算グラフから切り離される\n        labels = labels.detach().cpu() * 100.\n        return loss, pred, labels\n    \n    def trainig_epoch_end(self, outputs):\n        \"\"\"1エポック終わった後の処理\"\"\"\n        self.__share_epoch_end(outputs, \"train\")\n        \n    def validation_epoch_end(self, outputs):\n        \"\"\"１エポック終わった後の処理\"\"\"\n        self.__share_epoch_end(outputs, \"val\")\n        \n    def __share_epoch_end(self, outputs, mode):\n        preds = []\n        labels = []\n        for out in outputs:\n            pred, label = out[\"pred\"], out[\"labels\"]\n            preds.append(pred)\n            labels.append(label)\n        preds = torch.cat(preds)\n        labels= torch.cat(labels)\n        metrics = torch.sqrt(((labels - preds) ** 2).mean())#RMSE\n        self.log(f'{mode}_loss', metrics )\n        \n    def check_gradcam(self, dataloader, target_layer, target_category, reshape_transform=None):\n        \"\"\"画像のどこに注目しているのか描画する\"\"\"\n        cam = GradCAMPlusPlus(\n            model = self,\n            #target_layer = [target_layer],#モデルごとに決まっている定数\n            target_layers = [target_layer],\n            use_cuda = self.cfg.trainer.gpus,#1\n            reshape_transform = reshape_transform)\n        org_images, labels = iter(dataloader).next()#orginalの画像とlbaleを取り出す\n        cam.batch_size = len(org_images)\n        images = self.transform[\"val\"](org_images)#val用のaugmentation\n        images = images.to(self.device)#GPUの切り替え\n        logits = self.forward(images).squeeze(1)\n        pred = logits.sigmoid().detach().cpu().numpy() * 100\n        labels = labels.cpu().numpy()\n        \n        grayscale_cam = cam(input_tensor=images, target_category=target_category, eigen_smooth = True)#eigen_camをsmooth_gradで実行\n        org_images = org_images.detach().cpu().numpy().transpose(0, 2, 3, 1) / 255.#transpose配列の順番の入れ替え\n\n        return org_images, grayscale_cam, pred, labels\n    \n    def configure_optimizers(self):\n        \"\"\"optimizerをreturnする。\n        schedulerを使用する場合はreturnをoptimizerのリストと\n        schedulerのリストのタプルとする。\"\"\"\n        optimizer = eval(self.cfg.optimizer.name)(#optim.AdamW\n            self.parameters(), **self.cfg.optimizer.params#lr=1e-5\n        )\n        scheduler = eval(self.cfg.scheduler.name)(#optim.lr_sccheduler.CosineAnnealingWarmRestarts\n            optimizer,\n            **self.cfg.scheduler.params#T_0:2θ,eta_min:1e-4\n        )\n        return [optimizer], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:20.050153Z","iopub.execute_input":"2021-11-11T04:34:20.050703Z","iopub.status.idle":"2021-11-11T04:34:20.083015Z","shell.execute_reply.started":"2021-11-11T04:34:20.050606Z","shell.execute_reply":"2021-11-11T04:34:20.082358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = np.arange(9)\na = a.reshape(3, 3)\nprint(a)\nb = np.zeros((3, 1, 1, 1))\nprint(b)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:20.085651Z","iopub.execute_input":"2021-11-11T04:34:20.085999Z","iopub.status.idle":"2021-11-11T04:34:20.096384Z","shell.execute_reply.started":"2021-11-11T04:34:20.085962Z","shell.execute_reply":"2021-11-11T04:34:20.095539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b.squeeze(1)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:20.097716Z","iopub.execute_input":"2021-11-11T04:34:20.098336Z","iopub.status.idle":"2021-11-11T04:34:20.10556Z","shell.execute_reply.started":"2021-11-11T04:34:20.0983Z","shell.execute_reply":"2021-11-11T04:34:20.104606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train","metadata":{}},{"cell_type":"markdown","source":"callbacks.LearningRateMonitor\n\nAutomatically monitor and logs learning rate for learning rate schedulers during training.\n\nmodelcheckpoint\n\nAutomatically save model checkpoints during training.\n\nhttps://torch.classcat.com/2021/02/22/pytorch-lightning-1-1-notebooks-05-trainer-flags-overview-2/\nhttps://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.model_checkpoint.html\n\nTensorBoardLogger\n\nLog to local file system in TensorBoard format.\n\nhttp://maruo51.com/2020/02/17/pytorch_lightning_log/\n","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(\n    n_splits=config.n_splits, shuffle=True, random_state=config.seed\n)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df[\"Id\"], df[\"Pawpularity\"])):\n    train_df = df.loc[train_idx].reset_index(drop=True)\n    val_df = df.loc[val_idx].reset_index(drop=True)\n    datamodule = PetfinderDataModule(train_df, val_df, config)\n    model = Model(config)\n    earystopping = EarlyStopping(monitor=\"val_loss\")\n    lr_monitor = callbacks.LearningRateMonitor()\n    loss_checkpoint = callbacks.ModelCheckpoint(\n        filename=\"best_loss\",\n        monitor=\"val_loss\",\n        save_top_k=1,\n        mode=\"min\",\n        save_last=False,\n    )\n    logger = TensorBoardLogger(config.model.name)\n    \n    trainer = pl.Trainer(\n        logger=logger,\n        max_epochs=config.epoch,\n        callbacks=[lr_monitor, loss_checkpoint, earystopping],\n        **config.trainer,\n    )\n    trainer.fit(model, datamodule=datamodule)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T04:34:20.106901Z","iopub.execute_input":"2021-11-11T04:34:20.10728Z","iopub.status.idle":"2021-11-11T07:52:25.308242Z","shell.execute_reply.started":"2021-11-11T04:34:20.107242Z","shell.execute_reply":"2021-11-11T07:52:25.307362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## class activation map","metadata":{}},{"cell_type":"code","source":"# gradsam reshape_transform for vit\n\ndef reshape_transform(tensor, height=7, width = 7):\n    result = tensor.reshape(tensor.size(0),\n                           height, width, tensor.size(2))\n    \n    #like in CNNs.\n    result = result.permute(0, 3, 1, 2)\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-11-11T07:52:25.313139Z","iopub.execute_input":"2021-11-11T07:52:25.315121Z","iopub.status.idle":"2021-11-11T07:52:25.324187Z","shell.execute_reply.started":"2021-11-11T07:52:25.315079Z","shell.execute_reply":"2021-11-11T07:52:25.323125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #gradcam reshape_transform for vit\ndef reshape_transform(tensor, height=7, width=7):\n    result = tensor.reshape(tensor.size(0),\n                            height, width, tensor.size(2))\n\n    # like in CNNs.\n    result = result.permute(0, 3, 1, 2)\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-11-11T07:52:25.330558Z","iopub.execute_input":"2021-11-11T07:52:25.332769Z","iopub.status.idle":"2021-11-11T07:52:25.343258Z","shell.execute_reply.started":"2021-11-11T07:52:25.332727Z","shell.execute_reply":"2021-11-11T07:52:25.341264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(config) \nmodel.load_state_dict(torch.load(f'{config.model.name}/default/version_0/checkpoints/best_loss.ckpt')['state_dict'])\nmodel = model.cuda().eval()\nconfig.val_loader.batch_size = 16\ndatamodule = PetfinderDataModule(train_df, val_df, config)\nimages, grayscale_cams, preds, labels = model.check_gradcam(\n                                            datamodule.val_dataloader(), \n                                            target_layer=model.backbone.layers[-1].blocks[-1].norm1,\n                                            target_category=None,\n                                            reshape_transform=reshape_transform)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T07:52:25.345136Z","iopub.execute_input":"2021-11-11T07:52:25.345387Z","iopub.status.idle":"2021-11-11T07:52:30.500237Z","shell.execute_reply.started":"2021-11-11T07:52:25.345353Z","shell.execute_reply":"2021-11-11T07:52:30.499088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 12))\nfor it, (image, grayscale_cam, pred, label) in enumerate(zip(images, grayscale_cams, preds, labels)):\n    plt.subplot(4, 4, it + 1)\n    visualization = show_cam_on_image(image, grayscale_cam)#heatmapをのせた画像を作成\n    plt.imshow(visualization)\n    plt.title(f'pred : {pred:.1f} label : {label}')\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-11-11T07:52:30.507211Z","iopub.execute_input":"2021-11-11T07:52:30.509574Z","iopub.status.idle":"2021-11-11T07:52:31.855387Z","shell.execute_reply.started":"2021-11-11T07:52:30.509519Z","shell.execute_reply":"2021-11-11T07:52:31.854619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### visualize result","metadata":{}},{"cell_type":"code","source":"from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n\n\npath = glob(f'./{config.model.name}/default/version_0/events*')[0]\nevent_acc = EventAccumulator(path, size_guidance={\"scalars\" : 0})\nevent_acc.Reload()\n\nscalars = {}\nfor tag in event_acc.Tags()[\"scalars\"]:\n    events = event_acc.Scalars(tag)\n    scalars[tag] = [event.value for event in events]","metadata":{"execution":{"iopub.status.busy":"2021-11-11T07:52:31.856357Z","iopub.execute_input":"2021-11-11T07:52:31.856579Z","iopub.status.idle":"2021-11-11T07:52:31.942511Z","shell.execute_reply.started":"2021-11-11T07:52:31.856549Z","shell.execute_reply":"2021-11-11T07:52:31.941842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nsns.set()\n\nplt.figure(figsize = (16, 6))\nplt.subplot(1, 2, 1)\nplt.plot(range(len(scalars[\"lr-AdamW\"])), scalars[\"lr-AdamW\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"lr\")\nplt.title(\"adamw lr\")\n\nplt.subplot(1, 2, 2)\n#plt.plot(range(len(scalars['train_loss'])), scalars['train_loss'], label = 'train_loss')\nplt.plot(range(len(scalars['val_loss'])), scalars['val_loss'], label = 'val_loss')\nplt.legend()\nplt.ylabel(\"rmse\")\nplt.xlabel(\"epoch\")\nplt.title(\"train/val rmse\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T07:52:31.94387Z","iopub.execute_input":"2021-11-11T07:52:31.944356Z","iopub.status.idle":"2021-11-11T07:52:32.510288Z","shell.execute_reply.started":"2021-11-11T07:52:31.944308Z","shell.execute_reply":"2021-11-11T07:52:32.509605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"best_val_loss\", min(scalars[\"val_loss\"]))","metadata":{"execution":{"iopub.status.busy":"2021-11-11T07:52:32.511373Z","iopub.execute_input":"2021-11-11T07:52:32.512249Z","iopub.status.idle":"2021-11-11T07:52:32.517974Z","shell.execute_reply.started":"2021-11-11T07:52:32.512208Z","shell.execute_reply":"2021-11-11T07:52:32.517218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}