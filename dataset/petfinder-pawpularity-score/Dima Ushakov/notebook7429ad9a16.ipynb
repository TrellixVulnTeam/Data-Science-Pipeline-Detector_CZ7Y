{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.preprocessing import image\nfrom sklearn.preprocessing import StandardScaler\nimport cv2\nimport os\nimport tensorflow as tf\ntf.random.set_seed(42)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-11T09:10:36.013521Z","iopub.execute_input":"2021-11-11T09:10:36.014024Z","iopub.status.idle":"2021-11-11T09:10:44.791302Z","shell.execute_reply.started":"2021-11-11T09:10:36.013881Z","shell.execute_reply":"2021-11-11T09:10:44.790615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n    # Currently, memory growth needs to be the same across GPUs\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        # Memory growth must be set before GPUs have been initialized\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:27:13.581476Z","iopub.execute_input":"2021-11-11T08:27:13.582354Z","iopub.status.idle":"2021-11-11T08:27:13.589518Z","shell.execute_reply.started":"2021-11-11T08:27:13.582308Z","shell.execute_reply":"2021-11-11T08:27:13.588722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/petfinder-pawpularity-score/train/\"\npath_test = \"/kaggle/input/petfinder-pawpularity-score/test/\"","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:27:13.591278Z","iopub.execute_input":"2021-11-11T08:27:13.591628Z","iopub.status.idle":"2021-11-11T08:27:13.601936Z","shell.execute_reply.started":"2021-11-11T08:27:13.591577Z","shell.execute_reply":"2021-11-11T08:27:13.601187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\nss = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')\nprint(data.shape)\nprint(ss.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:41.23985Z","iopub.execute_input":"2021-11-11T08:41:41.24019Z","iopub.status.idle":"2021-11-11T08:41:41.267666Z","shell.execute_reply.started":"2021-11-11T08:41:41.240156Z","shell.execute_reply":"2021-11-11T08:41:41.266748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = [\"pixel\", 'ratio', \"st_size\", \"mean\", \"form\"]\nd = {i:[] for i in d}\nfor i in data[\"Id\"]:\n    i+=\".jpg\"\n    img_path = os.path.join(path, i)\n    x = os.stat(img_path)\n    file_pr = {k: getattr(x, k) for k in dir(x) if k in d}\n    for i in file_pr:\n        d[i].append(file_pr[i])\n    \n    img = image.load_img(img_path)\n    img_pr = img.__dict__\n    try:\n        _size_1, _size_2 = img_pr.get(\"_size\")\n    except:\n        print(img_pr.get(\"_size\"))\n    d[\"pixel\"].append(_size_1*_size_2)\n    d['ratio'].append(_size_1/_size_2)\n    d[\"mean\"].append(np.mean(img))\n    \n    if _size_1==_size_2:\n        fm =  \"sqr\"\n    elif _size_1<_size_2:\n        fm =  \"falt\"\n    elif _size_1>_size_2:\n        fm =  \"front\"\n    d[\"form\"].append(fm)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:28:57.559412Z","iopub.execute_input":"2021-11-11T08:28:57.559705Z","iopub.status.idle":"2021-11-11T08:31:25.594187Z","shell.execute_reply.started":"2021-11-11T08:28:57.559674Z","shell.execute_reply":"2021-11-11T08:31:25.592982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_info = pd.DataFrame.from_dict(d)\nimg_info['size_h'] = img_info['st_size'] / img_info['ratio']\nimg_info['size_mean'] = img_info['st_size'] / img_info['mean']\nimg_info['ratio_max'] = img_info['ratio'] / img_info['mean']\nimg_info['ratio_p'] = img_info['pixel'] / img_info['mean']","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:45.85797Z","iopub.execute_input":"2021-11-11T08:41:45.858812Z","iopub.status.idle":"2021-11-11T08:41:45.885262Z","shell.execute_reply.started":"2021-11-11T08:41:45.85876Z","shell.execute_reply":"2021-11-11T08:41:45.884402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([data, img_info], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:46.762719Z","iopub.execute_input":"2021-11-11T08:41:46.763349Z","iopub.status.idle":"2021-11-11T08:41:46.770115Z","shell.execute_reply.started":"2021-11-11T08:41:46.763293Z","shell.execute_reply":"2021-11-11T08:41:46.769381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(data[['pixel', 'ratio', 'st_size', 'mean', 'size_h', 'size_mean', 'ratio_max', 'ratio_p']])\ndata[['pixel', 'ratio', 'st_size', 'mean', 'size_h', 'size_mean', 'ratio_max', 'ratio_p']] = scaler.transform(data[['pixel', 'ratio', 'st_size', 'mean', 'size_h', 'size_mean', 'ratio_max', 'ratio_p']])","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:47.445745Z","iopub.execute_input":"2021-11-11T08:41:47.446406Z","iopub.status.idle":"2021-11-11T08:41:47.464626Z","shell.execute_reply.started":"2021-11-11T08:41:47.446349Z","shell.execute_reply":"2021-11-11T08:41:47.463488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"minus = [\"Eyes\", \"Action\", \"Info\", \"Blur\"]\nplus = [\"Face\", \"Near\", \"Accessory\", \"Group\", \"Collage\", \"Human\", \"Occlusion\"]\ndata['minus'] = data['Subject Focus']\ndata['plus'] = data['Face']\n\nfor i in plus:\n    data['plus'] = data['plus'] + data[i]\n    \nfor i in minus:\n    data['minus'] = data['minus'] + data[i]","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:47.792368Z","iopub.execute_input":"2021-11-11T08:41:47.792643Z","iopub.status.idle":"2021-11-11T08:41:47.805297Z","shell.execute_reply.started":"2021-11-11T08:41:47.792615Z","shell.execute_reply":"2021-11-11T08:41:47.804063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fr = pd.get_dummies(data['form'])\ndata = pd.concat([data, fr], axis=1)\ndata = data.drop([\"form\", \"falt\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:48.138469Z","iopub.execute_input":"2021-11-11T08:41:48.138931Z","iopub.status.idle":"2021-11-11T08:41:48.152275Z","shell.execute_reply.started":"2021-11-11T08:41:48.138867Z","shell.execute_reply":"2021-11-11T08:41:48.151304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[['pixel', 'ratio', 'st_size', 'mean', 'size_h', 'size_mean', 'ratio_max', 'ratio_p']] = data[['pixel', 'ratio', 'st_size', 'mean', 'size_h', 'size_mean', 'ratio_max', 'ratio_p']].astype('float32')","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:48.377897Z","iopub.execute_input":"2021-11-11T08:41:48.378222Z","iopub.status.idle":"2021-11-11T08:41:48.388287Z","shell.execute_reply.started":"2021-11-11T08:41:48.37819Z","shell.execute_reply":"2021-11-11T08:41:48.387241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \ntrain,val = train_test_split(data, test_size=0.2,random_state=42) ","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:48.726465Z","iopub.execute_input":"2021-11-11T08:41:48.726897Z","iopub.status.idle":"2021-11-11T08:41:48.73653Z","shell.execute_reply.started":"2021-11-11T08:41:48.726866Z","shell.execute_reply":"2021-11-11T08:41:48.735648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape, val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:49.076385Z","iopub.execute_input":"2021-11-11T08:41:49.076914Z","iopub.status.idle":"2021-11-11T08:41:49.081951Z","shell.execute_reply.started":"2021-11-11T08:41:49.076863Z","shell.execute_reply":"2021-11-11T08:41:49.080979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Hyperparams \n\nBATCH_SIZE = 16\nIMG_SIZE = ( 224 ,  224) ","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:49.422985Z","iopub.execute_input":"2021-11-11T08:41:49.423436Z","iopub.status.idle":"2021-11-11T08:41:49.426959Z","shell.execute_reply.started":"2021-11-11T08:41:49.423401Z","shell.execute_reply":"2021-11-11T08:41:49.426297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = ['front', 'sqr', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action',\n       'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur',\n       'pixel', 'ratio', 'st_size', 'mean', 'size_h',\n       'size_mean', 'ratio_max', 'ratio_p', 'minus', 'plus']","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:41:49.995966Z","iopub.execute_input":"2021-11-11T08:41:49.996591Z","iopub.status.idle":"2021-11-11T08:41:50.003256Z","shell.execute_reply.started":"2021-11-11T08:41:49.996534Z","shell.execute_reply":"2021-11-11T08:41:50.002071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils  import Sequence\nclass DataGenerator(Sequence):\n    'Generates data for Keras'\n    def __init__(self, metadata, labels, path, batch_size=16, w=224, h=224, n_channels=3, shuffle=True):\n        'Initialization'\n        self.dim = (w,h)\n        self.batch_size = batch_size\n        self.labels = labels\n        self.data_dir = path\n        self.metadata = metadata\n        self.list_IDs = metadata['Id'].to_list()\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X1 = np.empty((self.batch_size, *self.dim, self.n_channels))\n        X2 = np.empty((self.batch_size, 24))\n        y = np.empty((self.batch_size), dtype=int)\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            img = ID + \".jpg\"\n            img_path = os.path.join(self.data_dir, img)\n            im = cv2.resize(cv2.imread(img_path), self.dim).astype(np.float32)\n            X1[i,] = im\n            X2[i,] = self.metadata[col][self.metadata['Id']==ID]\n\n            # Store class\n            y[i] = self.labels[ID]\n            \n        return {\"image\": X1, \"features\": X2}, y","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:47:56.419251Z","iopub.execute_input":"2021-11-11T08:47:56.419918Z","iopub.status.idle":"2021-11-11T08:47:56.437282Z","shell.execute_reply.started":"2021-11-11T08:47:56.419846Z","shell.execute_reply":"2021-11-11T08:47:56.436294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = dict(data[['Id',\"Pawpularity\"]].values)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:47:57.614582Z","iopub.execute_input":"2021-11-11T08:47:57.615276Z","iopub.status.idle":"2021-11-11T08:47:57.638111Z","shell.execute_reply.started":"2021-11-11T08:47:57.615217Z","shell.execute_reply":"2021-11-11T08:47:57.637269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = DataGenerator(train, labels, path)\nval_datagen = DataGenerator(val, labels, path)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:47:58.220199Z","iopub.execute_input":"2021-11-11T08:47:58.220695Z","iopub.status.idle":"2021-11-11T08:47:58.226621Z","shell.execute_reply.started":"2021-11-11T08:47:58.220639Z","shell.execute_reply":"2021-11-11T08:47:58.225949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense\nfrom tensorflow.keras.layers import AvgPool2D, GlobalAveragePooling2D, MaxPool2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import ReLU, concatenate\nimport tensorflow.keras.backend as K\ndef densenet(input_shape, filters = 64):\n    model = tf.keras.Sequential()\n    model.add(tf.keras.Input(shape=input_shape))\n    model.add(Conv2D(filters=filters,padding=\"same\",kernel_size=(3,3), activation='relu'))\n    model.add(MaxPool2D(2,2))\n\n    model.add(Conv2D(filters=filters,padding=\"same\",kernel_size=(3,3), activation='relu'))\n    model.add(MaxPool2D(2,2))\n\n    model.add(Conv2D(filters=filters,padding=\"same\",kernel_size=(3,3),activation='relu'))\n    model.add(MaxPool2D(2,2))\n\n    return model\nbase_image_model = densenet(input_shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:50:07.346173Z","iopub.execute_input":"2021-11-11T08:50:07.347092Z","iopub.status.idle":"2021-11-11T08:50:07.400871Z","shell.execute_reply.started":"2021-11-11T08:50:07.347034Z","shell.execute_reply":"2021-11-11T08:50:07.400123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ProcessImageBlock(tf.keras.Model):\n\n    def __init__(self):\n\n        super(ProcessImageBlock, self).__init__()\n\n        self.input_l = tf.keras.layers.InputLayer( input_shape = IMG_SIZE + (3,)  ) \n        self.base_model = base_image_model\n        self.preprocess_input = tf.keras.applications.densenet.preprocess_input \n        \n        self.data_augmentation = tf.keras.Sequential([\n                                tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n                                tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n                                ])\n        self.rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n#         self.gap = tf.keras.layers.GlobalAveragePooling2D() ##  ( batch_size , 2048 )\n        self.flat = tf.keras.layers.Flatten() ##  ( batch_size , 2048 )\n\n        self.activation = tf.keras.layers.ReLU()\n        self.dense = tf.keras.layers.Dense(512, activation= self.activation )\n        self.final = tf.keras.layers.Dense(128, activation= self.activation )\n\n        \n    def call(self, input_tensor):\n\n        x = self.input_l(input_tensor)\n        x = self.data_augmentation(x)\n        x = self.preprocess_input(x)\n        x = self.base_model(x, training=True)\n#         x = self.gap(x)\n        x = self.flat(x)\n\n        x = self.dense(x)\n        x = self.final(x)\n \n        return  x\n\nclass ProcessTabBlock(tf.keras.Model):\n\n    def __init__(self):\n\n        super(ProcessTabBlock, self).__init__()\n\n        self.input_l = tf.keras.layers.InputLayer( input_shape = (24,)  ) \n        self.layer_1 = tf.keras.layers.Dense(64, activation='relu')\n        self.layer_2 = tf.keras.layers.Dense(128, activation='relu')\n        \n    def call(self, input_tensor ):\n        \n        x = self.input_l(input_tensor)\n        x = self.layer_1(x)\n        x = self.layer_2(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:50:11.529392Z","iopub.execute_input":"2021-11-11T08:50:11.529995Z","iopub.status.idle":"2021-11-11T08:50:11.543792Z","shell.execute_reply.started":"2021-11-11T08:50:11.529956Z","shell.execute_reply":"2021-11-11T08:50:11.542808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyCustomModel(tf.keras.Model):\n\n    def __init__(self):\n\n        super(MyCustomModel, self).__init__()\n\n        self.process_image_data = ProcessImageBlock()\n        self.process_tabular_data = ProcessTabBlock()\n\n        self.activation_1 = tf.keras.layers.LeakyReLU( alpha=0.3)\n        self.activation_2 = tf.keras.layers.ReLU()\n        self.activation_final = tf.keras.layers.ReLU(max_value = 100 )\n        self.dropout = tf.keras.layers.Dropout(0.2) \n\n        self.dense_1 =   tf.keras.layers.Dense(64,activation= self.activation_1  )\n        self.dense_2 =   tf.keras.layers.Dense(16,activation=  self.activation_2  )\n        self.final =   tf.keras.layers.Dense(1, activation=  self.activation_final )\n    \n    def call(self, inputs ):\n\n        image = inputs[\"image\"]\n        feature = inputs[\"features\"]\n\n        x1 = self.process_image_data(image)\n        x2 = self.process_tabular_data(feature)\n\n\n        x = tf.keras.layers.concatenate([x1, x2])\n        x = self.dropout(x)## ( batch_size, 128 )\n        x = self.dense_1(x)\n        x = self.dense_2(x)\n\n        x = self.final(x)\n   \n        return  x","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:50:16.137324Z","iopub.execute_input":"2021-11-11T08:50:16.137618Z","iopub.status.idle":"2021-11-11T08:50:16.151471Z","shell.execute_reply.started":"2021-11-11T08:50:16.137588Z","shell.execute_reply":"2021-11-11T08:50:16.150439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    \n    model = MyCustomModel()\n    \n    model.compile(\n        optimizer='rmsprop', \n        loss=\"mse\",\n        metrics=[tf.keras.metrics.MeanSquaredError(name=\"mean_squared_error\", \n                                                   dtype=None)]\n      )\n    \n    return model ","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:50:17.269812Z","iopub.execute_input":"2021-11-11T08:50:17.270111Z","iopub.status.idle":"2021-11-11T08:50:17.277894Z","shell.execute_reply.started":"2021-11-11T08:50:17.270082Z","shell.execute_reply":"2021-11-11T08:50:17.276724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:50:20.757277Z","iopub.execute_input":"2021-11-11T08:50:20.757554Z","iopub.status.idle":"2021-11-11T08:50:20.79724Z","shell.execute_reply.started":"2021-11-11T08:50:20.757525Z","shell.execute_reply":"2021-11-11T08:50:20.796355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\n\ncheckpoint_path = \"cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n\nes_callback = tf.keras.callbacks.EarlyStopping(\n                                monitor='val_mean_squared_error',\n                                patience=5,\n                                verbose=1,\n                                restore_best_weights=True)\n\ntf.keras.backend.set_floatx('float32')\n\nwith tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n    history = model.fit_generator(\n                    train_datagen,\n                    validation_data = val_datagen,\n                    epochs=epochs,\n                    verbose=1,\n                    callbacks = [cp_callback , es_callback ] ,\n                    )","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:50:52.424932Z","iopub.execute_input":"2021-11-11T08:50:52.425261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saved_checkpoint_path = \"cp.ckpt\"","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:46:05.781433Z","iopub.status.idle":"2021-11-11T08:46:05.781763Z","shell.execute_reply.started":"2021-11-11T08:46:05.781593Z","shell.execute_reply":"2021-11-11T08:46:05.78161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model = create_model()\nnew_model.load_weights(saved_checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:46:05.782808Z","iopub.status.idle":"2021-11-11T08:46:05.783159Z","shell.execute_reply.started":"2021-11-11T08:46:05.782987Z","shell.execute_reply":"2021-11-11T08:46:05.783005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\ntest_d = [\"pixel\", 'ratio', \"st_size\", \"mean\", \"form\"]\ntest_d = {i:[] for i in test_d}\nfor i in test[\"Id\"]:\n    i+=\".jpg\"\n    img_path = os.path.join(path_test, i)\n    x = os.stat(img_path)\n    file_pr = {k: getattr(x, k) for k in dir(x) if k in test_d}\n    for i in file_pr:\n        test_d[i].append(file_pr[i])\n    \n    img = image.load_img(img_path)\n    img_pr = img.__dict__\n    try:\n        _size_1, _size_2 = img_pr.get(\"_size\")\n    except:\n        print(img_pr.get(\"_size\"))\n    test_d[\"pixel\"].append(_size_1*_size_2)\n    test_d['ratio'].append(_size_1/_size_2)\n    test_d[\"mean\"].append(np.mean(img))\n    \n    if _size_1==_size_2:\n        fm =  \"sqr\"\n    elif _size_1<_size_2:\n        fm =  \"falt\"\n    elif _size_1>_size_2:\n        fm =  \"front\"\n    test_d[\"form\"].append(fm)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:46:05.784102Z","iopub.status.idle":"2021-11-11T08:46:05.784414Z","shell.execute_reply.started":"2021-11-11T08:46:05.784245Z","shell.execute_reply":"2021-11-11T08:46:05.784261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_info = pd.DataFrame.from_dict(test_d)\nimg_info['size_h'] = img_info['st_size'] / img_info['ratio']\nimg_info['size_mean'] = img_info['st_size'] / img_info['mean']\nimg_info['ratio_max'] = img_info['ratio'] / img_info['mean']\nimg_info['ratio_p'] = img_info['pixel'] / img_info['mean']","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:27:25.190557Z","iopub.status.idle":"2021-11-11T08:27:25.191354Z","shell.execute_reply.started":"2021-11-11T08:27:25.191107Z","shell.execute_reply":"2021-11-11T08:27:25.191135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.concat([test, img_info], axis=1)\ntest[['pixel', 'ratio', 'st_size', 'mean', 'size_h', 'size_mean', 'ratio_max', 'ratio_p']] = scaler.transform(test[['pixel', 'ratio', 'st_size', 'mean', 'size_h', 'size_mean', 'ratio_max', 'ratio_p']])\nminus = [\"Eyes\", \"Action\", \"Info\", \"Blur\"]\nplus = [\"Face\", \"Near\", \"Accessory\", \"Group\", \"Collage\", \"Human\", \"Occlusion\"]\ntest['minus'] = test['Subject Focus']\ntest['plus'] = test['Face']\n\n\nfor i in plus:\n    test['plus'] = test['plus'] + test[i]\n    \nfor i in minus:\n    test['minus'] = test['minus'] + test[i]\nfr = pd.get_dummies(test['form'])\ntest = pd.concat([test, fr], axis=1)\ntest = test.drop([\"form\"], axis=1)\nif 'falt' in test.columns:\n    test.drop(['\"falt\"'], axis=1)\nif 'front' not in test.columns:\n    test['front'] = 0","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:27:25.192884Z","iopub.status.idle":"2021-11-11T08:27:25.193284Z","shell.execute_reply.started":"2021-11-11T08:27:25.19309Z","shell.execute_reply":"2021-11-11T08:27:25.193114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = dict(test[['Id',\"pixel\"]].values)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:27:25.194514Z","iopub.status.idle":"2021-11-11T08:27:25.195184Z","shell.execute_reply.started":"2021-11-11T08:27:25.194969Z","shell.execute_reply":"2021-11-11T08:27:25.194992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"st = len(test)//2 if len(test)<= 32 else 32","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:27:25.196479Z","iopub.status.idle":"2021-11-11T08:27:25.196824Z","shell.execute_reply.started":"2021-11-11T08:27:25.196647Z","shell.execute_reply":"2021-11-11T08:27:25.196671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datagen = DataGenerator(test, labels, path_test, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:27:25.198155Z","iopub.status.idle":"2021-11-11T08:27:25.198505Z","shell.execute_reply.started":"2021-11-11T08:27:25.198318Z","shell.execute_reply":"2021-11-11T08:27:25.198342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final = new_model.predict_generator(test_datagen, steps = st)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:27:25.199935Z","iopub.status.idle":"2021-11-11T08:27:25.200277Z","shell.execute_reply.started":"2021-11-11T08:27:25.20009Z","shell.execute_reply":"2021-11-11T08:27:25.200108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"Pawpularity\"] = final\n\nsubmission = test[[\"Id\", \"Pawpularity\"]]\nsubmission.to_csv(\"submission.csv\", index = False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-11T08:27:25.201278Z","iopub.status.idle":"2021-11-11T08:27:25.201603Z","shell.execute_reply.started":"2021-11-11T08:27:25.201429Z","shell.execute_reply":"2021-11-11T08:27:25.201447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}