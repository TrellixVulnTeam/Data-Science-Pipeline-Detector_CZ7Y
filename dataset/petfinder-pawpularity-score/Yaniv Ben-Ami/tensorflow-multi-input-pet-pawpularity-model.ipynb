{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TensorFlow multi-input Pet Pawpularity Model\n\n## Table of Contents\n- Summary\n- Set up\n- Import datasets\n- Data Preprocessing\n- Model Development\n- Model Evaluation\n- Submission\n\n\n## Summary\nIn this notebook, I will build a TensorFlow multi-input Model that can receive image inputs and tabular inputs at the same time for training, so that I can get the most out of this dataset.\n## Set up","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:07:04.608773Z","iopub.execute_input":"2021-10-03T23:07:04.609066Z","iopub.status.idle":"2021-10-03T23:07:08.928749Z","shell.execute_reply.started":"2021-10-03T23:07:04.609037Z","shell.execute_reply":"2021-10-03T23:07:08.928017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/more-cute-pets/","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:07:08.930173Z","iopub.execute_input":"2021-10-03T23:07:08.930407Z","iopub.status.idle":"2021-10-03T23:07:09.608442Z","shell.execute_reply.started":"2021-10-03T23:07:08.930377Z","shell.execute_reply":"2021-10-03T23:07:09.607648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import datasets","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntest = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\nsample_submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:07:09.610046Z","iopub.execute_input":"2021-10-03T23:07:09.610345Z","iopub.status.idle":"2021-10-03T23:07:09.657391Z","shell.execute_reply.started":"2021-10-03T23:07:09.610307Z","shell.execute_reply":"2021-10-03T23:07:09.656771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:07:09.658807Z","iopub.execute_input":"2021-10-03T23:07:09.658997Z","iopub.status.idle":"2021-10-03T23:07:09.668909Z","shell.execute_reply.started":"2021-10-03T23:07:09.658976Z","shell.execute_reply":"2021-10-03T23:07:09.668133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:07:10.814742Z","iopub.execute_input":"2021-10-03T23:07:10.81532Z","iopub.status.idle":"2021-10-03T23:07:10.841513Z","shell.execute_reply.started":"2021-10-03T23:07:10.815283Z","shell.execute_reply":"2021-10-03T23:07:10.84063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exog = sm.add_constant(train.drop(['Pawpularity', 'Id'], axis=1))\nexog","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:16:49.147513Z","iopub.execute_input":"2021-10-03T23:16:49.148188Z","iopub.status.idle":"2021-10-03T23:16:49.180866Z","shell.execute_reply.started":"2021-10-03T23:16:49.148122Z","shell.execute_reply":"2021-10-03T23:16:49.179997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\n\nsm.OLS(endog=train['Pawpularity'], exog=exog).fit().summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:09:46.164173Z","iopub.execute_input":"2021-10-03T23:09:46.164884Z","iopub.status.idle":"2021-10-03T23:09:46.224998Z","shell.execute_reply.started":"2021-10-03T23:09:46.16485Z","shell.execute_reply":"2021-10-03T23:09:46.22421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train.Id == '0007de18844b0dbbb5e1f607da0606e0']","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:14:04.266129Z","iopub.execute_input":"2021-10-03T23:14:04.266842Z","iopub.status.idle":"2021-10-03T23:14:04.283025Z","shell.execute_reply.started":"2021-10-03T23:14:04.266798Z","shell.execute_reply":"2021-10-03T23:14:04.282352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Pawpularity'].hist()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:14:04.540046Z","iopub.execute_input":"2021-10-03T23:14:04.54076Z","iopub.status.idle":"2021-10-03T23:14:04.79185Z","shell.execute_reply.started":"2021-10-03T23:14:04.540724Z","shell.execute_reply":"2021-10-03T23:14:04.791181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file = '../input/petfinder-pawpularity-score/train/0007de18844b0dbbb5e1f607da0606e0.jpg'\n\nfrom IPython.display import Image\nImage(filename=file) ","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:14:04.862785Z","iopub.execute_input":"2021-10-03T23:14:04.863459Z","iopub.status.idle":"2021-10-03T23:14:04.882841Z","shell.execute_reply.started":"2021-10-03T23:14:04.863419Z","shell.execute_reply":"2021-10-03T23:14:04.882208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:14:05.260022Z","iopub.execute_input":"2021-10-03T23:14:05.260592Z","iopub.status.idle":"2021-10-03T23:14:05.271457Z","shell.execute_reply.started":"2021-10-03T23:14:05.260555Z","shell.execute_reply":"2021-10-03T23:14:05.27047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"file_path\"] = train[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/train/\" + identifier + \".jpg\")\ntest[\"file_path\"] = test[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/test/\" + identifier + \".jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:14:05.605988Z","iopub.execute_input":"2021-10-03T23:14:05.606787Z","iopub.status.idle":"2021-10-03T23:14:05.618434Z","shell.execute_reply.started":"2021-10-03T23:14:05.606737Z","shell.execute_reply":"2021-10-03T23:14:05.617361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:14:06.084664Z","iopub.execute_input":"2021-10-03T23:14:06.085518Z","iopub.status.idle":"2021-10-03T23:14:06.100554Z","shell.execute_reply.started":"2021-10-03T23:14:06.085467Z","shell.execute_reply":"2021-10-03T23:14:06.099776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Pawpularity\"].hist()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:14:06.626577Z","iopub.execute_input":"2021-10-03T23:14:06.627272Z","iopub.status.idle":"2021-10-03T23:14:06.845877Z","shell.execute_reply.started":"2021-10-03T23:14:06.627237Z","shell.execute_reply":"2021-10-03T23:14:06.845134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Development","metadata":{}},{"cell_type":"code","source":"tabular_columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\nimage_size = 150\nbatch_size = 128","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:34:52.463869Z","iopub.execute_input":"2021-10-03T23:34:52.464132Z","iopub.status.idle":"2021-10-03T23:34:52.47094Z","shell.execute_reply.started":"2021-10-03T23:34:52.464102Z","shell.execute_reply":"2021-10-03T23:34:52.470196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(image_url, tabular):\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    return (image, tabular[1:]), tabular[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:34:53.014585Z","iopub.execute_input":"2021-10-03T23:34:53.01484Z","iopub.status.idle":"2021-10-03T23:34:53.020378Z","shell.execute_reply.started":"2021-10-03T23:34:53.014813Z","shell.execute_reply":"2021-10-03T23:34:53.019698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(y_true, y_pred):\n    return tf.sqrt(tf.reduce_mean((y_true - y_pred) ** 2))","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:34:54.518563Z","iopub.execute_input":"2021-10-03T23:34:54.51911Z","iopub.status.idle":"2021-10-03T23:34:54.523349Z","shell.execute_reply.started":"2021-10-03T23:34:54.519073Z","shell.execute_reply":"2021-10-03T23:34:54.52267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def block(x, filters, kernel_size, repetitions, pool_size=2, strides=2):\n    for i in range(repetitions):\n        x = tf.keras.layers.Conv2D(filters, kernel_size, activation='relu', padding='same')(x)\n    x = tf.keras.layers.MaxPooling2D(pool_size, strides)(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:34:58.694897Z","iopub.execute_input":"2021-10-03T23:34:58.695455Z","iopub.status.idle":"2021-10-03T23:34:58.700222Z","shell.execute_reply.started":"2021-10-03T23:34:58.695416Z","shell.execute_reply":"2021-10-03T23:34:58.69951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras as keras\n\nbase_model = keras.applications.Xception(\n    weights = '../input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5',  # Load weights pre-trained on ImageNet.\n    input_shape=(image_size, image_size, 3),\n    include_top=False) ","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:58:43.745085Z","iopub.execute_input":"2021-10-03T23:58:43.745681Z","iopub.status.idle":"2021-10-03T23:58:46.810982Z","shell.execute_reply.started":"2021-10-03T23:58:43.745643Z","shell.execute_reply":"2021-10-03T23:58:46.810227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:51:11.460025Z","iopub.execute_input":"2021-10-03T23:51:11.460626Z","iopub.status.idle":"2021-10-03T23:51:11.477039Z","shell.execute_reply.started":"2021-10-03T23:51:11.460585Z","shell.execute_reply":"2021-10-03T23:51:11.476306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    \n    image_inputs = tf.keras.Input((image_size, image_size , 3))\n    tabular_inputs = tf.keras.Input(len(tabular_columns))\n\n    image_x = base_model(image_inputs)\n#     image_x = block(image_inputs, 8, 3, 2)\n#     image_x = block(image_x, 16, 3, 2)\n#     image_x = block(image_x, 32, 3, 2)\n#     image_x = block(image_x, 64, 3, 2)\n#     image_x = block(image_x, 128, 3, 2)\n    image_x = tf.keras.layers.Dropout(0.8)(image_x)\n    image_x = tf.keras.layers.Flatten()(image_x)\n    image_x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2())(image_x)\n\n    tabular_x = tf.keras.layers.Dense(16, activation=\"relu\")(tabular_inputs)\n    tabular_x = tf.keras.layers.Dense(16, activation=\"relu\")(tabular_x)\n    tabular_x = tf.keras.layers.Dense(16, activation=\"relu\")(tabular_x)\n    tabular_x = tf.keras.layers.Dense(16, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2())(tabular_x)\n    x = tf.keras.layers.Concatenate(axis=1)([image_x, tabular_x])\n    output = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs=[image_inputs, tabular_inputs], outputs=[output])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-04T00:00:08.606944Z","iopub.execute_input":"2021-10-04T00:00:08.607768Z","iopub.status.idle":"2021-10-04T00:00:08.617824Z","shell.execute_reply.started":"2021-10-04T00:00:08.607712Z","shell.execute_reply":"2021-10-04T00:00:08.616974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's have a big picture of how this Model looks like.","metadata":{}},{"cell_type":"code","source":"model =  get_model()\ntf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T00:00:09.775381Z","iopub.execute_input":"2021-10-04T00:00:09.776192Z","iopub.status.idle":"2021-10-04T00:00:10.52804Z","shell.execute_reply.started":"2021-10-04T00:00:09.776133Z","shell.execute_reply":"2021-10-04T00:00:10.527258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T00:00:10.530358Z","iopub.execute_input":"2021-10-04T00:00:10.530651Z","iopub.status.idle":"2021-10-04T00:00:10.55304Z","shell.execute_reply.started":"2021-10-04T00:00:10.530614Z","shell.execute_reply":"2021-10-04T00:00:10.552391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This Model accepts images with shape (image_size, image_size, 3) and tabular information with shape (12) as input. Since it's a Regression problem, it generate output with shape (1). ","metadata":{}},{"cell_type":"code","source":"image = np.random.normal(size=(2, image_size, image_size, 3))\ntabular = np.random.normal(size=(2, len(tabular_columns)))\nprint(image.shape, tabular.shape)\nprint(model((image, tabular)).shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T00:00:11.476826Z","iopub.execute_input":"2021-10-04T00:00:11.477262Z","iopub.status.idle":"2021-10-04T00:00:11.537988Z","shell.execute_reply.started":"2021-10-04T00:00:11.477224Z","shell.execute_reply":"2021-10-04T00:00:11.537279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Training\nI will use tensorflow Dataset here to preprocess and cache tensors, first epoch is very slow because it's preprocessing data; after that, it would be must faster.","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodels = []\nhistorys = []\nkfold = KFold(n_splits=5, shuffle=True, random_state=997)\n# For the current random state, 5th fold can generate a better validation rmse and faster convergence.\ntrain_best_fold = False\nbest_fold = 4\nfor index, (train_indices, val_indices) in enumerate(kfold.split(train)):\n    if train_best_fold and index != best_fold:\n        continue\n    x_train = train.loc[train_indices, \"file_path\"]\n    tabular_train = train.loc[train_indices, [\"Pawpularity\"] + tabular_columns]\n    x_val= train.loc[val_indices, \"file_path\"]\n    tabular_val = train.loc[val_indices, [\"Pawpularity\"] + tabular_columns]\n    checkpoint_path = \"model_%d.h5\"%(index)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        checkpoint_path, \n        monitor='val_rmse', \n        mode=\"min\",\n        save_best_only=True,\n        restore_best_weights = True\n    )\n    early_stop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_rmse', \n        mode=\"min\",\n        min_delta=1e-4, \n        patience=10\n    )\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_rmse', \n        mode=\"min\",\n        factor=0.5,\n        patience=2, \n        min_lr=1e-6\n    )\n    callbacks = [early_stop, checkpoint, reduce_lr]\n    \n    loss = tf.keras.losses.MeanSquaredError()\n\n    optimizer = tf.keras.optimizers.Adam()\n    \n    train_ds = tf.data.Dataset.from_tensor_slices((x_train, tabular_train)).map(preprocess).shuffle(512).batch(batch_size).cache().prefetch(2)\n    val_ds = tf.data.Dataset.from_tensor_slices((x_val, tabular_val)).map(preprocess).batch(batch_size).cache().prefetch(2)\n    model = get_model()\n    model.compile(loss=loss, optimizer=optimizer, metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])\n    history = model.fit(train_ds, epochs=300, validation_data=val_ds, callbacks=callbacks)\n    for metrics in [(\"loss\", \"val_loss\"), (\"mae\", \"val_mae\", \"rmse\", \"val_rmse\"), (\"mape\", \"val_mape\"), [\"lr\"]]:\n        pd.DataFrame(history.history, columns=metrics).plot()\n        plt.show()\n    model.load_weights(checkpoint_path)\n    historys.append(history)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T00:00:12.966165Z","iopub.execute_input":"2021-10-04T00:00:12.967191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"def preprocess_test_data(image_url, tabular):\n    print(image_url, tabular)\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    return (image, tabular), 0","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:58:23.136034Z","iopub.status.idle":"2021-10-03T23:58:23.136465Z","shell.execute_reply.started":"2021-10-03T23:58:23.1362Z","shell.execute_reply":"2021-10-03T23:58:23.136227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = tf.data.Dataset.from_tensor_slices((test[\"file_path\"], test[tabular_columns])).map(preprocess_test_data).batch(batch_size).cache().prefetch(2)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:58:23.14106Z","iopub.status.idle":"2021-10-03T23:58:23.143892Z","shell.execute_reply.started":"2021-10-03T23:58:23.143699Z","shell.execute_reply":"2021-10-03T23:58:23.143728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_best_result = False\nif use_best_result:\n    if train_best_fold:\n        best_model = models[0]\n    else:\n        best_fold = 0\n        best_score = 10e8\n        for fold, history in enumerate(historys):\n            for val_rmse in history.history[\"val_rmse\"]:\n                if val_rmse < best_score:\n                    best_score = val_rmse\n                    best_fold = fold\n        print(\"Best Score:%.2f Best Fold: %d\"%(best_score, best_fold + 1))\n        best_model = models[best_fold]\n    sample_submission[\"Pawpularity\"] = best_model.predict(test_ds).reshape(-1)\n    sample_submission.to_csv(\"submission.csv\", index=False)\nelse:\n    total_results = []\n    for model in models:\n        total_results.append(model.predict(test_ds).reshape(-1))\n    results = np.mean(total_results, axis=0).reshape(-1)\n    sample_submission[\"Pawpularity\"] = results\n    sample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T23:58:23.144966Z","iopub.status.idle":"2021-10-03T23:58:23.14587Z","shell.execute_reply.started":"2021-10-03T23:58:23.145601Z","shell.execute_reply":"2021-10-03T23:58:23.145625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}