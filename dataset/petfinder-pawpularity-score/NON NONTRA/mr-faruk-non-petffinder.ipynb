{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom pathlib import Path\nimport os\n\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-24T16:19:28.971911Z","iopub.execute_input":"2021-10-24T16:19:28.972649Z","iopub.status.idle":"2021-10-24T16:19:35.016323Z","shell.execute_reply.started":"2021-10-24T16:19:28.972447Z","shell.execute_reply":"2021-10-24T16:19:35.015116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regression\n\n# Data Preprocesing Process\n\n# Training Datasets\ntrain_dataset = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\nX = train_dataset.iloc[0:, 1:-1].values\ny = train_dataset['Pawpularity'].values\n\nprint(X)\n\n\n# Training Datasets\ntest_dataset = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\ntest_X = test_dataset.iloc[0:, 1:].values\ntest_Id = test_dataset.iloc[0:, 0:1].values\n\nprint(test_Id)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T16:19:37.285016Z","iopub.execute_input":"2021-10-24T16:19:37.285342Z","iopub.status.idle":"2021-10-24T16:19:37.354625Z","shell.execute_reply.started":"2021-10-24T16:19:37.285306Z","shell.execute_reply":"2021-10-24T16:19:37.353474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Regression\n\nbase_dir = Path('/kaggle/input')\n\nfilepaths = pd.Series(list(base_dir.glob(r'**/*.jpg')), name='Filepath').astype(str)\n\nanimal_types = pd.Series(filepaths.apply(lambda x: os.path.split(os.path.split(x)[0])[1]), name='Animal Type').astype(np.str)\n\nfor idx, value in enumerate(animal_types):\n    if(value == 'test'):\n        animal_types[idx] = 1.0\n    elif(value == 'train'):\n        animal_types[idx] = 2.0\n\nimages = pd.concat([filepaths, animal_types], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)\n\nprint(images)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T16:19:40.884369Z","iopub.execute_input":"2021-10-24T16:19:40.885409Z","iopub.status.idle":"2021-10-24T16:19:47.257736Z","shell.execute_reply.started":"2021-10-24T16:19:40.885345Z","shell.execute_reply":"2021-10-24T16:19:47.256502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regression\n\n# Data Preprocesing Proces \n# We could train and test by calculate a standardisation, normalization value from scratch. In contrast, this code use imported library instead.\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\n# Training a data\n# Below line is a vector of predicted value from X_train which is Salary\nregressor.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T16:19:49.804784Z","iopub.execute_input":"2021-10-24T16:19:49.805327Z","iopub.status.idle":"2021-10-24T16:19:49.92199Z","shell.execute_reply.started":"2021-10-24T16:19:49.805289Z","shell.execute_reply":"2021-10-24T16:19:49.921066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regression\n\n# y_pred is a vector of predicted value from X_test which is Salary\ny_pred = regressor.predict(test_X)\n\nprint('y_pred', y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T16:19:52.100773Z","iopub.execute_input":"2021-10-24T16:19:52.101955Z","iopub.status.idle":"2021-10-24T16:19:52.111011Z","shell.execute_reply.started":"2021-10-24T16:19:52.101906Z","shell.execute_reply":"2021-10-24T16:19:52.109888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Regression\n\nimage_df = images.sample(5000, random_state=1).reset_index(drop=True)\n\ntrain_df, test_df = train_test_split(images, train_size=0.7, shuffle=True, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:46:08.283119Z","iopub.execute_input":"2021-10-24T15:46:08.283621Z","iopub.status.idle":"2021-10-24T15:46:08.293446Z","shell.execute_reply.started":"2021-10-24T15:46:08.283566Z","shell.execute_reply":"2021-10-24T15:46:08.292796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Regression\n\ntrain_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:46:10.430427Z","iopub.execute_input":"2021-10-24T15:46:10.43104Z","iopub.status.idle":"2021-10-24T15:46:10.435321Z","shell.execute_reply.started":"2021-10-24T15:46:10.431006Z","shell.execute_reply":"2021-10-24T15:46:10.434775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regression\n\nimport csv\n\nheader = ['Id', 'Pawpularity']\ndata = []\n\nfor index in range(len(y_pred)): \n    data.append([test_Id[index, 0], y_pred[index]])\n    \nwith open('/kaggle/working/submission.csv', 'w', encoding='UTF8', newline='') as f:\n    writer = csv.writer(f)\n\n    # write the header\n    writer.writerow(header)\n\n    # write multiple rows\n    writer.writerows(data)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T16:19:55.01155Z","iopub.execute_input":"2021-10-24T16:19:55.011874Z","iopub.status.idle":"2021-10-24T16:19:55.019043Z","shell.execute_reply.started":"2021-10-24T16:19:55.011838Z","shell.execute_reply":"2021-10-24T16:19:55.018141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Regression\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Animal Type',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='raw',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Animal Type',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='raw',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Animal Type',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='raw',\n    batch_size=32,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:46:13.489311Z","iopub.execute_input":"2021-10-24T15:46:13.489783Z","iopub.status.idle":"2021-10-24T15:46:14.67347Z","shell.execute_reply.started":"2021-10-24T15:46:13.48975Z","shell.execute_reply":"2021-10-24T15:46:14.672295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new_train_images = np.asarray(train_images).astype(np.float32)\n# new_val_images = np.asarray(val_images).astype(np.float32)\n\ninputs = tf.keras.Input(shape=(120, 120, 3))\nx = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\nx = tf.keras.layers.MaxPool2D()(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='linear')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='mse'\n)\n\n# history = model.fit(\n#     new_train_images,\n#     validation_data=new_val_images,\n#     epochs=1,\n#     callbacks=[\n#         tf.keras.callbacks.EarlyStopping(\n#             monitor='val_loss',\n#             patience=5,\n#             restore_best_weights=True\n#         )\n#     ]\n# )","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:58:39.178192Z","iopub.execute_input":"2021-10-24T15:58:39.178734Z"},"trusted":true},"execution_count":null,"outputs":[]}]}