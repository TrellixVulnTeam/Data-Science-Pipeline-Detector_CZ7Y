{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport sys\n\nsys.path.append('../input/swintransformertf')\n\nfrom swintransformer import SwinTransformer\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras import backend as K\nimport os\nfrom sklearn.model_selection import StratifiedKFold\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.476739Z","iopub.execute_input":"2021-12-14T01:26:29.477202Z","iopub.status.idle":"2021-12-14T01:26:29.4831Z","shell.execute_reply.started":"2021-12-14T01:26:29.477154Z","shell.execute_reply":"2021-12-14T01:26:29.482043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\nIMG_SIZE = 224\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nlabel='Pawpularity'\n\nlr = 2e-5\nepochs = 5\n\nSEED=999\n\n\ntf.random.set_seed(SEED)\n\n#decay_steps = 100\n#decay_rate = 0.96","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.484749Z","iopub.execute_input":"2021-12-14T01:26:29.48525Z","iopub.status.idle":"2021-12-14T01:26:29.494238Z","shell.execute_reply.started":"2021-12-14T01:26:29.48521Z","shell.execute_reply":"2021-12-14T01:26:29.493419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset Function","metadata":{}},{"cell_type":"code","source":"def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.496601Z","iopub.execute_input":"2021-12-14T01:26:29.496819Z","iopub.status.idle":"2021-12-14T01:26:29.504216Z","shell.execute_reply.started":"2021-12-14T01:26:29.496796Z","shell.execute_reply":"2021-12-14T01:26:29.503553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef get_box(lambda_value):\n    cut_rat = tf.math.sqrt(1.0 - lambda_value)\n\n    cut_w = IMG_SIZE * cut_rat  # rw\n    cut_w = tf.cast(cut_w, tf.int32)\n\n    cut_h = IMG_SIZE * cut_rat  # rh\n    cut_h = tf.cast(cut_h, tf.int32)\n\n    cut_x = tf.random.uniform((1,), minval=0, maxval=IMG_SIZE, dtype=tf.int32)  # rx\n    cut_y = tf.random.uniform((1,), minval=0, maxval=IMG_SIZE, dtype=tf.int32)  # ry\n\n    boundaryx1 = tf.clip_by_value(cut_x[0] - cut_w // 2, 0, IMG_SIZE)\n    boundaryy1 = tf.clip_by_value(cut_y[0] - cut_h // 2, 0, IMG_SIZE)\n    bbx2 = tf.clip_by_value(cut_x[0] + cut_w // 2, 0, IMG_SIZE)\n    bby2 = tf.clip_by_value(cut_y[0] + cut_h // 2, 0, IMG_SIZE)\n\n    target_h = bby2 - boundaryy1\n    if target_h == 0:\n        target_h += 1\n\n    target_w = bbx2 - boundaryx1\n    if target_w == 0:\n        target_w += 1\n\n    return boundaryx1, boundaryy1, target_h, target_w\n\n\n@tf.function\ndef cutmix(train_ds_one, train_ds_two):\n    (image1, label1), (image2, label2) = train_ds_one, train_ds_two\n\n    alpha = [0.25]\n    beta = [0.25]\n\n    # Get a sample from the Beta distribution\n    lambda_value = sample_beta_distribution(1, alpha, beta)\n\n    # Define Lambda\n    lambda_value = lambda_value[0][0]\n\n    # Get the bounding box offsets, heights and widths\n    boundaryx1, boundaryy1, target_h, target_w = get_box(lambda_value)\n\n    # Get a patch from the second image (`image2`)\n    crop2 = tf.image.crop_to_bounding_box(\n        image2, boundaryy1, boundaryx1, target_h, target_w\n    )\n    # Pad the `image2` patch (`crop2`) with the same offset\n    image2 = tf.image.pad_to_bounding_box(\n        crop2, boundaryy1, boundaryx1, IMG_SIZE, IMG_SIZE\n    )\n    # Get a patch from the first image (`image1`)\n    crop1 = tf.image.crop_to_bounding_box(\n        image1, boundaryy1, boundaryx1, target_h, target_w\n    )\n    # Pad the `image1` patch (`crop1`) with the same offset\n    img1 = tf.image.pad_to_bounding_box(\n        crop1, boundaryy1, boundaryx1, IMG_SIZE, IMG_SIZE\n    )\n\n    # Modify the first image by subtracting the patch from `image1`\n    # (before applying the `image2` patch)\n    image1 = image1 - img1\n    # Add the modified `image1` and `image2`  together to get the CutMix image\n    image = image1 + image2\n\n    # Adjust Lambda in accordance to the pixel ration\n    lambda_value = 1 - (target_w * target_h) / (IMG_SIZE * IMG_SIZE)\n    lambda_value = tf.cast(lambda_value, tf.float32)\n\n    # Combine the labels of both images\n    label = lambda_value * label1 + (1 - lambda_value) * label2\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.506287Z","iopub.execute_input":"2021-12-14T01:26:29.506847Z","iopub.status.idle":"2021-12-14T01:26:29.522544Z","shell.execute_reply.started":"2021-12-14T01:26:29.50681Z","shell.execute_reply":"2021-12-14T01:26:29.521776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def id_to_path(img_id,dir):\n    return os.path.join(dir, f'{img_id}.jpg')\n\ndef get_image(path):\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.float32)\n    return image\n\ndef process_dataset(path, label):\n    return get_image(path), label\n\n\ndef get_dataset(x,y=None,train=True):\n    if train:\n        y=tf.cast(y,'float32')\n        ds_one = tf.data.Dataset.from_tensor_slices((x, y)).map(process_dataset, num_parallel_calls=AUTOTUNE).shuffle(256)\\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n        \n        ds_two = tf.data.Dataset.from_tensor_slices((x, y)).map(process_dataset, num_parallel_calls=AUTOTUNE).shuffle(256)\\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n        \n        train_ds = tf.data.Dataset.zip((ds_one,ds_two))\n        \n        return train_ds.shuffle(256).map(cutmix, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n    \n    else:\n        ds= tf.data.Dataset.from_tensor_slices((x, y)).map(process_dataset, num_parallel_calls=AUTOTUNE).shuffle(256)\\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n        \n        return ds","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.524373Z","iopub.execute_input":"2021-12-14T01:26:29.525218Z","iopub.status.idle":"2021-12-14T01:26:29.537342Z","shell.execute_reply.started":"2021-12-14T01:26:29.525192Z","shell.execute_reply":"2021-12-14T01:26:29.536566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Kfolds Training","metadata":{}},{"cell_type":"markdown","source":"#### Model","metadata":{}},{"cell_type":"code","source":"#loss\ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_true*100 - tf.nn.sigmoid(y_pred)*100)))\n    \ndef focal_cross_entropy(y_true,y_pred):\n    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.538844Z","iopub.execute_input":"2021-12-14T01:26:29.5392Z","iopub.status.idle":"2021-12-14T01:26:29.546317Z","shell.execute_reply.started":"2021-12-14T01:26:29.539164Z","shell.execute_reply":"2021-12-14T01:26:29.545623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Crossing(tf.keras.layers.Layer):\n    def __init__(self,dim=None):\n        super().__init__()\n        self.c1=tfa.layers.PolynomialCrossing(projection_dim=dim)\n        self.c2=tfa.layers.PolynomialCrossing(projection_dim=dim)\n        self.c3=tfa.layers.PolynomialCrossing(projection_dim=dim)\n        self.c4=tfa.layers.PolynomialCrossing(projection_dim=dim)\n        self.c5=tfa.layers.PolynomialCrossing(projection_dim=dim)\n        \n        self.network=tf.keras.Sequential([\n            tf.keras.layers.Dense(32,activation='elu'),\n            tf.keras.layers.Dense(32,activation='elu'),\n            tf.keras.layers.Dense(32,activation='elu'),\n            tf.keras.layers.Dense(32,activation='elu'),\n            tf.keras.layers.Dense(32,activation='elu'),\n        ])\n        \n    def call(self,x,training=False):\n        x1=self.c1((x,x),training=training)\n        x2=self.c2((x,x1),training=training)\n        x3=self.c3((x,x2),training=training)\n        x4=self.c4((x,x3),training=training)\n        x5=self.c5((x,x4),training=training)\n        h=self.network(x,training=training)\n        o=tf.concat([x5,h],axis=-1)\n        return o","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.658825Z","iopub.execute_input":"2021-12-14T01:26:29.659429Z","iopub.status.idle":"2021-12-14T01:26:29.669259Z","shell.execute_reply.started":"2021-12-14T01:26:29.659396Z","shell.execute_reply":"2021-12-14T01:26:29.668346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training","metadata":{}},{"cell_type":"code","source":"train_data_csv = '../input/petfinder-pawpularity-score/train.csv'\ntest_data_csv  = '../input/petfinder-pawpularity-score/test.csv'\ntrain_folder = '../input/petfinder2-cropped-dataset/crop'\ntest_folder  = '../input/petfinder-pawpularity-score/test'","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.671031Z","iopub.execute_input":"2021-12-14T01:26:29.671629Z","iopub.status.idle":"2021-12-14T01:26:29.67914Z","shell.execute_reply.started":"2021-12-14T01:26:29.671594Z","shell.execute_reply":"2021-12-14T01:26:29.678353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv(train_data_csv)\ndata_test = pd.read_csv(test_data_csv)\n\ndata_train['path'] = data_train['Id'].apply(lambda x: id_to_path(x, train_folder))\ndata_test['path'] = data_test['Id'].apply(lambda x: id_to_path(x, test_folder))","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.681737Z","iopub.execute_input":"2021-12-14T01:26:29.682331Z","iopub.status.idle":"2021-12-14T01:26:29.729039Z","shell.execute_reply.started":"2021-12-14T01:26:29.682292Z","shell.execute_reply":"2021-12-14T01:26:29.728343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfolds=5\nskfold=StratifiedKFold(n_splits=kfolds,shuffle=True,random_state=SEED)\n\n#callbacks\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=2, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:26:29.731646Z","iopub.execute_input":"2021-12-14T01:26:29.731836Z","iopub.status.idle":"2021-12-14T01:26:29.735789Z","shell.execute_reply.started":"2021-12-14T01:26:29.731813Z","shell.execute_reply":"2021-12-14T01:26:29.734925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loss\ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_true*100 - tf.nn.sigmoid(y_pred)*100)))\n    \ndef cross_entropy(y_true,y_pred):\n    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n\n\ndef get_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Lambda(lambda data: tf.keras.applications.imagenet_utils.preprocess_input(\n            tf.cast(data, tf.float32), mode=\"torch\"), input_shape=[IMG_SIZE,IMG_SIZE,3]),\n        SwinTransformer('swin_large_224', include_top=False, pretrained=True), #1536\n        tf.keras.layers.Dense(32,activation='elu'),\n        tf.keras.layers.Dense(1)\n    ])\n    \n    #compile\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n                    loss=cross_entropy,\n                    metrics=[cross_entropy,rmse])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:27:42.535757Z","iopub.execute_input":"2021-12-14T01:27:42.536056Z","iopub.status.idle":"2021-12-14T01:27:42.547458Z","shell.execute_reply.started":"2021-12-14T01:27:42.536021Z","shell.execute_reply":"2021-12-14T01:27:42.546714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,(train_idx,val_idx) in enumerate(skfold.split(data_train['path'],data_train[label])):\n    print(f'fold_{i}')\n    train=data_train.loc[train_idx]\n    val=data_train.loc[val_idx]\n    \n    x_train,y_train=train['path'],train[label]/100.\n    x_val,y_val=val['path'],val[label]/100.\n    \n    train_data=get_dataset(x_train,y_train)\n    val_data=get_dataset(x_val,y_val)\n    \n    tf.keras.backend.clear_session()\n    model=get_model()\n    \n    history=model.fit(train_data,validation_data=val_data,\n                  epochs=epochs,verbose=1,callbacks=[early_stop],use_multiprocessing=True, workers=-1)\n    \n    print('save model....')\n    tf.keras.models.save_model(model,f'./model_{i}')","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:27:45.536567Z","iopub.execute_input":"2021-12-14T01:27:45.537153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}