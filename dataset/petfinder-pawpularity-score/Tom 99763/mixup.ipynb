{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport sys\n\nsys.path.append('../input/swintransformertf')\nsys.path.append('../input/polynomial/high-order-layers-master')\n\nfrom swintransformer import SwinTransformer\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras import backend as K\nimport os\nfrom sklearn.model_selection import StratifiedKFold\n\nimport matplotlib.pyplot as plt\n\nimport high_order_layers.PolynomialLayers as poly","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:32.675561Z","iopub.execute_input":"2021-12-14T07:10:32.675972Z","iopub.status.idle":"2021-12-14T07:10:38.324306Z","shell.execute_reply.started":"2021-12-14T07:10:32.67588Z","shell.execute_reply":"2021-12-14T07:10:38.323546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\nIMG_SIZE = 224\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nlabel='Pawpularity'\n\nlr = 2e-5\nepochs = 5\n\nSEED=999\n\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.326133Z","iopub.execute_input":"2021-12-14T07:10:38.326392Z","iopub.status.idle":"2021-12-14T07:10:38.332108Z","shell.execute_reply.started":"2021-12-14T07:10:38.326358Z","shell.execute_reply":"2021-12-14T07:10:38.331337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CutMix","metadata":{}},{"cell_type":"code","source":"def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.333704Z","iopub.execute_input":"2021-12-14T07:10:38.334033Z","iopub.status.idle":"2021-12-14T07:10:38.341633Z","shell.execute_reply.started":"2021-12-14T07:10:38.333996Z","shell.execute_reply":"2021-12-14T07:10:38.340939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef get_box(lambda_value):\n    cut_rat = tf.math.sqrt(1.0 - lambda_value)\n\n    cut_w = IMG_SIZE * cut_rat  # rw\n    cut_w = tf.cast(cut_w, tf.int32)\n\n    cut_h = IMG_SIZE * cut_rat  # rh\n    cut_h = tf.cast(cut_h, tf.int32)\n\n    cut_x = tf.random.uniform((1,), minval=0, maxval=IMG_SIZE, dtype=tf.int32)  # rx\n    cut_y = tf.random.uniform((1,), minval=0, maxval=IMG_SIZE, dtype=tf.int32)  # ry\n\n    boundaryx1 = tf.clip_by_value(cut_x[0] - cut_w // 2, 0, IMG_SIZE)\n    boundaryy1 = tf.clip_by_value(cut_y[0] - cut_h // 2, 0, IMG_SIZE)\n    bbx2 = tf.clip_by_value(cut_x[0] + cut_w // 2, 0, IMG_SIZE)\n    bby2 = tf.clip_by_value(cut_y[0] + cut_h // 2, 0, IMG_SIZE)\n\n    target_h = bby2 - boundaryy1\n    if target_h == 0:\n        target_h += 1\n\n    target_w = bbx2 - boundaryx1\n    if target_w == 0:\n        target_w += 1\n\n    return boundaryx1, boundaryy1, target_h, target_w\n\n\n@tf.function\ndef cutmix(train_ds_one, train_ds_two):\n    (image1, label1), (image2, label2) = train_ds_one, train_ds_two\n\n    alpha = [0.25]\n    beta = [0.25]\n\n    # Get a sample from the Beta distribution\n    lambda_value = sample_beta_distribution(1, alpha, beta)\n\n    # Define Lambda\n    lambda_value = lambda_value[0][0]\n\n    # Get the bounding box offsets, heights and widths\n    boundaryx1, boundaryy1, target_h, target_w = get_box(lambda_value)\n\n    # Get a patch from the second image (`image2`)\n    crop2 = tf.image.crop_to_bounding_box(\n        image2, boundaryy1, boundaryx1, target_h, target_w\n    )\n    # Pad the `image2` patch (`crop2`) with the same offset\n    image2 = tf.image.pad_to_bounding_box(\n        crop2, boundaryy1, boundaryx1, IMG_SIZE, IMG_SIZE\n    )\n    # Get a patch from the first image (`image1`)\n    crop1 = tf.image.crop_to_bounding_box(\n        image1, boundaryy1, boundaryx1, target_h, target_w\n    )\n    # Pad the `image1` patch (`crop1`) with the same offset\n    img1 = tf.image.pad_to_bounding_box(\n        crop1, boundaryy1, boundaryx1, IMG_SIZE, IMG_SIZE\n    )\n\n    # Modify the first image by subtracting the patch from `image1`\n    # (before applying the `image2` patch)\n    image1 = image1 - img1\n    # Add the modified `image1` and `image2`  together to get the CutMix image\n    image = image1 + image2\n\n    # Adjust Lambda in accordance to the pixel ration\n    lambda_value = 1 - (target_w * target_h) / (IMG_SIZE * IMG_SIZE)\n    lambda_value = tf.cast(lambda_value, tf.float32)\n\n    # Combine the labels of both images\n    label = lambda_value * label1 + (1 - lambda_value) * label2\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.342937Z","iopub.execute_input":"2021-12-14T07:10:38.343143Z","iopub.status.idle":"2021-12-14T07:10:38.359471Z","shell.execute_reply.started":"2021-12-14T07:10:38.343118Z","shell.execute_reply":"2021-12-14T07:10:38.358729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def id_to_path(img_id,dir):\n    return os.path.join(dir, f'{img_id}.jpg')\n\ndef get_image(path):\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.float32)\n    return image\n\ndef process_dataset(path, label):\n    return get_image(path), label\n\n\ndef get_dataset(x,y=None,train=True):\n    if train:\n        y=tf.cast(y,'float32')\n        ds_one = tf.data.Dataset.from_tensor_slices((x, y)).map(process_dataset, num_parallel_calls=AUTOTUNE).shuffle(256)\\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n        \n        ds_two = tf.data.Dataset.from_tensor_slices((x, y)).map(process_dataset, num_parallel_calls=AUTOTUNE).shuffle(256)\\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n        \n        train_ds = tf.data.Dataset.zip((ds_one,ds_two))\n        \n        return train_ds.shuffle(256).map(cutmix, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n    \n    else:\n        ds= tf.data.Dataset.from_tensor_slices((x, y)).map(process_dataset, num_parallel_calls=AUTOTUNE).shuffle(256)\\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n        \n        return ds","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.362865Z","iopub.execute_input":"2021-12-14T07:10:38.363236Z","iopub.status.idle":"2021-12-14T07:10:38.373346Z","shell.execute_reply.started":"2021-12-14T07:10:38.363207Z","shell.execute_reply":"2021-12-14T07:10:38.372701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_csv = '../input/petfinder-pawpularity-score/train.csv'\ntest_data_csv  = '../input/petfinder-pawpularity-score/test.csv'\ntrain_folder = '../input/petfinder2-cropped-dataset/crop'\ntest_folder  = '../input/petfinder-pawpularity-score/test'","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.374678Z","iopub.execute_input":"2021-12-14T07:10:38.375454Z","iopub.status.idle":"2021-12-14T07:10:38.38548Z","shell.execute_reply.started":"2021-12-14T07:10:38.375344Z","shell.execute_reply":"2021-12-14T07:10:38.384749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv(train_data_csv)\ndata_test = pd.read_csv(test_data_csv)\n\ndata_train['path'] = data_train['Id'].apply(lambda x: id_to_path(x, train_folder))\ndata_test['path'] = data_test['Id'].apply(lambda x: id_to_path(x, test_folder))","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.38681Z","iopub.execute_input":"2021-12-14T07:10:38.387369Z","iopub.status.idle":"2021-12-14T07:10:38.455779Z","shell.execute_reply.started":"2021-12-14T07:10:38.387333Z","shell.execute_reply":"2021-12-14T07:10:38.455074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"#loss\ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_true*100 - tf.nn.sigmoid(y_pred)*100)))\n    \ndef cross_entropy(y_true,y_pred):\n    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=y_true))","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.457148Z","iopub.execute_input":"2021-12-14T07:10:38.457592Z","iopub.status.idle":"2021-12-14T07:10:38.463098Z","shell.execute_reply.started":"2021-12-14T07:10:38.457558Z","shell.execute_reply":"2021-12-14T07:10:38.462472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Lambda(lambda data: tf.keras.applications.imagenet_utils.preprocess_input(\n            tf.cast(data, tf.float32), mode=\"torch\"), input_shape=[IMG_SIZE,IMG_SIZE,3]),\n        SwinTransformer('swin_large_224', include_top=False, pretrained=True), #1536\n        tf.keras.layers.Dense(32,activation='elu'),\n        poly.Polynomial(1, basis=poly.b7)\n    ])\n    \n    #compile\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n                    loss=cross_entropy,\n                    metrics=[cross_entropy,rmse])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.464501Z","iopub.execute_input":"2021-12-14T07:10:38.46498Z","iopub.status.idle":"2021-12-14T07:10:38.472871Z","shell.execute_reply.started":"2021-12-14T07:10:38.464946Z","shell.execute_reply":"2021-12-14T07:10:38.47215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#callbacks\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=2, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.475658Z","iopub.execute_input":"2021-12-14T07:10:38.476126Z","iopub.status.idle":"2021-12-14T07:10:38.484437Z","shell.execute_reply.started":"2021-12-14T07:10:38.476067Z","shell.execute_reply":"2021-12-14T07:10:38.4837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Training","metadata":{}},{"cell_type":"code","source":"kfolds=5\nskfold=StratifiedKFold(n_splits=kfolds,shuffle=True,random_state=SEED)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.485562Z","iopub.execute_input":"2021-12-14T07:10:38.486301Z","iopub.status.idle":"2021-12-14T07:10:38.49282Z","shell.execute_reply.started":"2021-12-14T07:10:38.486264Z","shell.execute_reply":"2021-12-14T07:10:38.492047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,(train_idx,val_idx) in enumerate(skfold.split(data_train['path'],data_train[label])):\n    print(f'fold_{i}')\n    train=data_train.loc[train_idx]\n    val=data_train.loc[val_idx]\n    \n    x_train,y_train=train['path'],train[label]/100.\n    x_val,y_val=val['path'],val[label]/100.\n    \n    train_data=get_dataset(x_train,y_train)\n    val_data=get_dataset(x_val,y_val,train=False)\n    \n    tf.keras.backend.clear_session()\n    model=get_model()\n    \n    history=model.fit(train_data,validation_data=val_data,\n                  epochs=epochs,verbose=1,callbacks=[early_stop],use_multiprocessing=True, workers=-1)\n    \n    print('save model....')\n    tf.keras.models.save_model(model,f'./model_{i}')\n    \n    del train_data\n    del val_data\n    del model","metadata":{"execution":{"iopub.status.busy":"2021-12-14T07:10:38.494587Z","iopub.execute_input":"2021-12-14T07:10:38.494762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}