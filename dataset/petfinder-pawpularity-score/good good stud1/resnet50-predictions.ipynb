{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:09.518959Z","iopub.execute_input":"2021-12-21T11:17:09.519262Z","iopub.status.idle":"2021-12-21T11:17:09.544241Z","shell.execute_reply.started":"2021-12-21T11:17:09.519184Z","shell.execute_reply":"2021-12-21T11:17:09.543507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomRotation, RandomContrast","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:09.545929Z","iopub.execute_input":"2021-12-21T11:17:09.546183Z","iopub.status.idle":"2021-12-21T11:17:15.150185Z","shell.execute_reply.started":"2021-12-21T11:17:09.546149Z","shell.execute_reply":"2021-12-21T11:17:15.149487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install keras","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.15134Z","iopub.execute_input":"2021-12-21T11:17:15.15353Z","iopub.status.idle":"2021-12-21T11:17:15.159676Z","shell.execute_reply.started":"2021-12-21T11:17:15.153496Z","shell.execute_reply":"2021-12-21T11:17:15.158405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntest = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\nsample_submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-21T11:17:15.162691Z","iopub.execute_input":"2021-12-21T11:17:15.163086Z","iopub.status.idle":"2021-12-21T11:17:15.221181Z","shell.execute_reply.started":"2021-12-21T11:17:15.163048Z","shell.execute_reply":"2021-12-21T11:17:15.220391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.224287Z","iopub.execute_input":"2021-12-21T11:17:15.22453Z","iopub.status.idle":"2021-12-21T11:17:15.247058Z","shell.execute_reply.started":"2021-12-21T11:17:15.224502Z","shell.execute_reply":"2021-12-21T11:17:15.246292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.248506Z","iopub.execute_input":"2021-12-21T11:17:15.24876Z","iopub.status.idle":"2021-12-21T11:17:15.259775Z","shell.execute_reply.started":"2021-12-21T11:17:15.248724Z","shell.execute_reply":"2021-12-21T11:17:15.259009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"file_path\"] = train[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/train/\" + identifier + \".jpg\")\ntest[\"file_path\"] = test[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/test/\" + identifier + \".jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.261429Z","iopub.execute_input":"2021-12-21T11:17:15.261974Z","iopub.status.idle":"2021-12-21T11:17:15.275058Z","shell.execute_reply.started":"2021-12-21T11:17:15.261937Z","shell.execute_reply":"2021-12-21T11:17:15.274257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.276598Z","iopub.execute_input":"2021-12-21T11:17:15.276874Z","iopub.status.idle":"2021-12-21T11:17:15.292863Z","shell.execute_reply.started":"2021-12-21T11:17:15.276839Z","shell.execute_reply":"2021-12-21T11:17:15.291878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.294522Z","iopub.execute_input":"2021-12-21T11:17:15.294942Z","iopub.status.idle":"2021-12-21T11:17:15.301813Z","shell.execute_reply.started":"2021-12-21T11:17:15.294873Z","shell.execute_reply":"2021-12-21T11:17:15.300906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.305656Z","iopub.execute_input":"2021-12-21T11:17:15.306054Z","iopub.status.idle":"2021-12-21T11:17:15.310085Z","shell.execute_reply.started":"2021-12-21T11:17:15.306022Z","shell.execute_reply":"2021-12-21T11:17:15.309203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 128\nbatch_size = 256","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.311604Z","iopub.execute_input":"2021-12-21T11:17:15.31186Z","iopub.status.idle":"2021-12-21T11:17:15.31666Z","shell.execute_reply.started":"2021-12-21T11:17:15.311828Z","shell.execute_reply":"2021-12-21T11:17:15.315811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(image_url, tabular):\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    return (image, tabular[1:]), tf.cast(tabular[0], tf.float32)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.318288Z","iopub.execute_input":"2021-12-21T11:17:15.318766Z","iopub.status.idle":"2021-12-21T11:17:15.327953Z","shell.execute_reply.started":"2021-12-21T11:17:15.318729Z","shell.execute_reply":"2021-12-21T11:17:15.327205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_tabular_model(inputs):\n   \n    x = keras.layers.Dense(12,  activation='relu')(inputs)\n    x = keras.layers.Dense(64,  activation='relu')(x)\n    x = keras.layers.Dense(128, activation='relu')(x)                 #加一层\n    x = keras.layers.Dropout(0.3)(x)\n    x = keras.layers.BatchNormalization()(x)\n    #x = keras.layers.Dense(256, activation='relu')(x)   \n    x = keras.layers.Dense(128, activation='relu')(x)\n    x = keras.layers.Dense(64,  activation='relu')(x)\n    x = keras.layers.Concatenate()([x, inputs])\n    return x","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-21T11:17:15.328913Z","iopub.execute_input":"2021-12-21T11:17:15.32915Z","iopub.status.idle":"2021-12-21T11:17:15.339155Z","shell.execute_reply.started":"2021-12-21T11:17:15.329117Z","shell.execute_reply":"2021-12-21T11:17:15.338126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def block(x, filters, kernel_size, repetitions, pool_size=2, strides=2):\n    for i in range(repetitions):\n        x = tf.keras.layers.Conv2D(filters, kernel_size, activation='relu', padding='same')(x)\n    x = tf.keras.layers.MaxPooling2D(pool_size, strides)(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.340354Z","iopub.execute_input":"2021-12-21T11:17:15.340793Z","iopub.status.idle":"2021-12-21T11:17:15.346791Z","shell.execute_reply.started":"2021-12-21T11:17:15.340668Z","shell.execute_reply":"2021-12-21T11:17:15.345882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    image_inputs = tf.keras.Input((image_size, image_size , 3))\n    tabular_inputs = tf.keras.Input(len(columns))\n    \n    #resnet = ResNet50(include_top=False, pooling=None)\n    resnet = keras.models.load_model('../input/d/aeryss/keras-pretrained-models/ResNet50V2_NoTop_ImageNet.h5')\n    resnet.trainable = False\n    \n    image_x = resnet(RandomContrast(factor = 0.1)(RandomRotation(factor = 0.3)(image_inputs)))   # factor was 0.15\n    #image_x = resnet((image_inputs))\n\n    image_x = tf.keras.layers.GlobalAveragePooling2D()(image_x)\n    \n    tabular_x = build_tabular_model(tabular_inputs)\n    \n    x = tf.keras.layers.Concatenate(axis=1)([image_x, tabular_x])#从第n=1维进行拼接\n    #x = image_x\n    x = tf.keras.layers.Dense(1024)(x)\n    x = keras.layers.Dropout(0.1)(x)\n    x = tf.keras.layers.Dense(64)(x)\n    output = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs=[image_inputs, tabular_inputs], outputs=[output]) #通过训练和推理功能将layer分组为一个对象。进行实例化，使用“API”，从开始，链接层调用以指定模型的正向传递，最后从输入和输出创建模型\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.348281Z","iopub.execute_input":"2021-12-21T11:17:15.348603Z","iopub.status.idle":"2021-12-21T11:17:15.360225Z","shell.execute_reply.started":"2021-12-21T11:17:15.348566Z","shell.execute_reply":"2021-12-21T11:17:15.359514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\ntf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:15.361241Z","iopub.execute_input":"2021-12-21T11:17:15.361473Z","iopub.status.idle":"2021-12-21T11:17:22.705208Z","shell.execute_reply.started":"2021-12-21T11:17:15.361426Z","shell.execute_reply":"2021-12-21T11:17:22.704429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(y_true, y_pred):\n    return tf.sqrt(tf.reduce_mean((y_true -  y_pred) ** 2))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:22.706593Z","iopub.execute_input":"2021-12-21T11:17:22.706794Z","iopub.status.idle":"2021-12-21T11:17:22.711326Z","shell.execute_reply.started":"2021-12-21T11:17:22.706768Z","shell.execute_reply":"2021-12-21T11:17:22.710673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tf.keras.backend.clear_session()\nmodels = []\nhistorys = []\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\ntrain_best_fold = True\nbest_fold = 0\nfor index, (train_indices, val_indices) in enumerate(kfold.split(train)):\n    if train_best_fold and index != best_fold: continue#\n    x_train = train.loc[train_indices, \"file_path\"]\n    tabular_train = train.loc[train_indices, [\"Pawpularity\"] + columns]\n    x_val= train.loc[val_indices, \"file_path\"]\n    tabular_val = train.loc[val_indices, [\"Pawpularity\"] + columns]\n    checkpoint_path = \"model_%d.h5\"%(index)#保存模型路径\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)\n    early_stop = tf.keras.callbacks.EarlyStopping(min_delta=1e-4, patience=1000)\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.3,patience=2, min_lr=1e-7)      #f was 0.3\n    callbacks = [early_stop, checkpoint, reduce_lr]    \n    optimizer = tf.keras.optimizers.Adam(1e-3)    \n    train_ds = tf.data.Dataset.from_tensor_slices((x_train, tabular_train)).map(preprocess).shuffle(512).batch(batch_size).cache().prefetch(2)\n    val_ds = tf.data.Dataset.from_tensor_slices((x_val, tabular_val)).map(preprocess).batch(batch_size).cache().prefetch(2)\n    model = get_model()\n    model.compile(loss = \"mse\", optimizer = optimizer, metrics = [\"mae\", rmse, \"mape\"])\n    history = model.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks, batch_size = 8)\n    for metrics in [(\"rmse\", \"val_rmse\"), (\"loss\", \"val_loss\"), (\"mae\", \"val_mae\"), (\"mape\", \"val_mape\"), [\"lr\"]]:\n        pd.DataFrame(history.history, columns=metrics).plot()\n        plt.show() \n    model.load_weights(checkpoint_path)\n    historys.append(history)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:17:22.713313Z","iopub.execute_input":"2021-12-21T11:17:22.713821Z","iopub.status.idle":"2021-12-21T11:22:36.681306Z","shell.execute_reply.started":"2021-12-21T11:17:22.71378Z","shell.execute_reply":"2021-12-21T11:22:36.680498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_test_data(image_url, tabular):\n    print(image_url, tabular)\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    # 0 won't be used in prediction, but it's needed in this senario or the tabular variable is treated as label.\n    return (image, tabular), 0","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:22:36.684121Z","iopub.execute_input":"2021-12-21T11:22:36.685033Z","iopub.status.idle":"2021-12-21T11:22:36.692187Z","shell.execute_reply.started":"2021-12-21T11:22:36.684992Z","shell.execute_reply":"2021-12-21T11:22:36.691498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = tf.data.Dataset.from_tensor_slices((test[\"file_path\"], test[columns])).map(preprocess_test_data).batch(batch_size).cache().prefetch(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:22:36.694163Z","iopub.execute_input":"2021-12-21T11:22:36.695165Z","iopub.status.idle":"2021-12-21T11:22:36.817963Z","shell.execute_reply.started":"2021-12-21T11:22:36.695125Z","shell.execute_reply":"2021-12-21T11:22:36.817056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_best_result = False\nif use_best_result:\n    if train_best_fold:\n        best_model = models[0]\n    else:\n        best_fold = 0\n        best_score = 10e8\n        for fold, history in enumerate(historys):\n            for val_rmse in history.history[\"val_rmse\"]:\n                if val_rmse < best_score:\n                    best_score = val_rmse\n                    best_fold = fold\n        print(\"Best Score:%.2f Best Fold: %d\"%(best_score, best_fold + 1))\n        best_model = models[best_fold]\n    results = best_model.predict(test_ds).reshape(-1)\nelse:\n    total_results = []\n    for model in models:\n        total_results.append(model.predict(test_ds).reshape(-1))\n    results = np.mean(total_results, axis=0).reshape(-1)\nsample_submission[\"Pawpularity\"] = results\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:22:36.819505Z","iopub.execute_input":"2021-12-21T11:22:36.819912Z","iopub.status.idle":"2021-12-21T11:22:38.027319Z","shell.execute_reply.started":"2021-12-21T11:22:36.819872Z","shell.execute_reply":"2021-12-21T11:22:38.02658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build the model","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}