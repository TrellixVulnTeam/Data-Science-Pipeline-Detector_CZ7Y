{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Loading","metadata":{"papermill":{"duration":0.023362,"end_time":"2021-08-04T01:25:11.97904","exception":false,"start_time":"2021-08-04T01:25:11.955678","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Data preprocessing\nimport numpy as np \nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\n\n\n# Plotting\nimport matplotlib.pyplot as plt\n\n# ANN + ML\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts, ReduceLROnPlateau\nimport lightgbm as lgb\n\n\n\n# Image preprocessing\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n\n# Miscellanous\nimport os\nimport sys\nimport math\nimport time\nimport pickle\nimport random\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\nimport timm\nimport warnings\n\n\nwarnings.filterwarnings('ignore')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":0.740547,"end_time":"2021-08-04T01:25:12.74294","exception":false,"start_time":"2021-08-04T01:25:12.002393","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.7819Z","iopub.execute_input":"2021-10-08T05:53:12.782217Z","iopub.status.idle":"2021-10-08T05:53:12.789461Z","shell.execute_reply.started":"2021-10-08T05:53:12.782187Z","shell.execute_reply":"2021-10-08T05:53:12.788772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntest_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')","metadata":{"papermill":{"duration":1.174264,"end_time":"2021-08-04T01:25:13.941421","exception":false,"start_time":"2021-08-04T01:25:12.767157","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.79103Z","iopub.execute_input":"2021-10-08T05:53:12.791459Z","iopub.status.idle":"2021-10-08T05:53:12.824045Z","shell.execute_reply.started":"2021-10-08T05:53:12.79141Z","shell.execute_reply":"2021-10-08T05:53:12.823372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    return \"../input/petfinder-pawpularity-score/train/{}.jpg\".format(image_id)\n\ndef get_test_file_path(image_id):\n    return \"../input/petfinder-pawpularity-score/test/{}.jpg\".format(image_id)\n\ntrain_df['file_path'] = train_df['Id'].apply(get_train_file_path)\ntest_df['file_path'] = test_df['Id'].apply(get_test_file_path)","metadata":{"papermill":{"duration":1.174264,"end_time":"2021-08-04T01:25:13.941421","exception":false,"start_time":"2021-08-04T01:25:12.767157","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.826532Z","iopub.execute_input":"2021-10-08T05:53:12.826731Z","iopub.status.idle":"2021-10-08T05:53:12.837941Z","shell.execute_reply.started":"2021-10-08T05:53:12.826709Z","shell.execute_reply":"2021-10-08T05:53:12.837314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T05:53:12.839704Z","iopub.execute_input":"2021-10-08T05:53:12.840152Z","iopub.status.idle":"2021-10-08T05:53:12.861319Z","shell.execute_reply.started":"2021-10-08T05:53:12.840117Z","shell.execute_reply":"2021-10-08T05:53:12.860504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T05:53:12.862916Z","iopub.execute_input":"2021-10-08T05:53:12.863255Z","iopub.status.idle":"2021-10-08T05:53:12.878065Z","shell.execute_reply.started":"2021-10-08T05:53:12.863222Z","shell.execute_reply":"2021-10-08T05:53:12.877235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"papermill":{"duration":0.044382,"end_time":"2021-08-04T01:25:16.530141","exception":false,"start_time":"2021-08-04T01:25:16.485759","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.87935Z","iopub.execute_input":"2021-10-08T05:53:12.879635Z","iopub.status.idle":"2021-10-08T05:53:12.885285Z","shell.execute_reply.started":"2021-10-08T05:53:12.879604Z","shell.execute_reply":"2021-10-08T05:53:12.88446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{"papermill":{"duration":0.035693,"end_time":"2021-08-04T01:25:16.603286","exception":false,"start_time":"2021-08-04T01:25:16.567593","status":"completed"},"tags":[]}},{"cell_type":"code","source":"CFG = {'num_workers':4, \n       'size': 512, \n       'batch_size':32,\n       'model_name':'tf_efficientnet_b0_ns',\n       'seed':42,\n       'target_size':1,\n       'target_col':'Pawpularity',\n       'n_fold':5,\n       'apex': False,\n       'gradient_accumulation_steps':1,\n       'print_freq':10,\n       'max_grad_norm':1000,\n       'train':True,\n       'grad_cam':False,\n       'trn_fold':[0, 1, 2, 3, 4],\n       'lr':1e-4,\n       'weight_decay':1e-6,\n       'scheduler':'CosineAnnealingLR',\n       'target_col':'Pawpularity',\n       'epochs':3,\n       #'factor':0.2,# ReduceLROnPlateau\n       #'patience':4, # ReduceLROnPlateau\n       #'eps':1e-6, # ReduceLROnPlateau\n       'T_max':3, # CosineAnnealingLR\n       #T_0:3, # CosineAnnealingWarmRestarts\n       'min_lr':1e-6\n      }","metadata":{"papermill":{"duration":0.04513,"end_time":"2021-08-04T01:25:16.683443","exception":false,"start_time":"2021-08-04T01:25:16.638313","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.886773Z","iopub.execute_input":"2021-10-08T05:53:12.887024Z","iopub.status.idle":"2021-10-08T05:53:12.89499Z","shell.execute_reply.started":"2021-10-08T05:53:12.886994Z","shell.execute_reply":"2021-10-08T05:53:12.894191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"papermill":{"duration":0.051924,"end_time":"2021-08-04T01:25:27.152541","exception":false,"start_time":"2021-08-04T01:25:27.100617","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n    return score\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG['seed'])","metadata":{"papermill":{"duration":0.078664,"end_time":"2021-08-04T01:25:27.284121","exception":false,"start_time":"2021-08-04T01:25:27.205457","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.896071Z","iopub.execute_input":"2021-10-08T05:53:12.896392Z","iopub.status.idle":"2021-10-08T05:53:12.906455Z","shell.execute_reply.started":"2021-10-08T05:53:12.896358Z","shell.execute_reply":"2021-10-08T05:53:12.905648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV split","metadata":{"papermill":{"duration":0.055844,"end_time":"2021-08-04T01:25:27.390591","exception":false,"start_time":"2021-08-04T01:25:27.334747","status":"completed"},"tags":[]}},{"cell_type":"code","source":"num_bins = int(np.floor(1 + np.log2(len(train_df))))\ntrain_df[\"bins\"] = pd.cut(train_df[CFG['target_col']], bins=num_bins, labels=False)\n\nFold = KFold(n_splits=CFG['n_fold'], shuffle=True, random_state=CFG['seed'])\nfor n, (train_index, val_index) in enumerate(Fold.split(train_df, train_df[\"Pawpularity\"])):\n    train_df.loc[val_index, 'fold'] = int(n)\n\ntrain_df['fold'] = train_df['fold'].astype(int)\n# train_df.groupby(['fold', \"bins\"]).size()","metadata":{"papermill":{"duration":0.382316,"end_time":"2021-08-04T01:25:27.823267","exception":false,"start_time":"2021-08-04T01:25:27.440951","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.909056Z","iopub.execute_input":"2021-10-08T05:53:12.909347Z","iopub.status.idle":"2021-10-08T05:53:12.926305Z","shell.execute_reply.started":"2021-10-08T05:53:12.909312Z","shell.execute_reply":"2021-10-08T05:53:12.92567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T05:53:12.927227Z","iopub.execute_input":"2021-10-08T05:53:12.927541Z","iopub.status.idle":"2021-10-08T05:53:12.941915Z","shell.execute_reply.started":"2021-10-08T05:53:12.927507Z","shell.execute_reply":"2021-10-08T05:53:12.941135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_pickle(OUTPUT_DIR+'train_fold.pkl')","metadata":{"execution":{"iopub.status.busy":"2021-10-08T05:53:12.943035Z","iopub.execute_input":"2021-10-08T05:53:12.943752Z","iopub.status.idle":"2021-10-08T05:53:12.956798Z","shell.execute_reply.started":"2021-10-08T05:53:12.943717Z","shell.execute_reply":"2021-10-08T05:53:12.956187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"papermill":{"duration":0.033889,"end_time":"2021-08-04T01:25:27.897251","exception":false,"start_time":"2021-08-04T01:25:27.863362","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class PawpularityDataset(Dataset):\n    def __init__(self, df, transform = None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG['target_col']].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        filename = self.file_names[idx]\n        image = cv2.imread(filename)\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            image = self.transform(image = image)['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return image, label\n\n    ","metadata":{"papermill":{"duration":0.045394,"end_time":"2021-08-04T01:25:27.976623","exception":false,"start_time":"2021-08-04T01:25:27.931229","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.959342Z","iopub.execute_input":"2021-10-08T05:53:12.959811Z","iopub.status.idle":"2021-10-08T05:53:12.967035Z","shell.execute_reply.started":"2021-10-08T05:53:12.959785Z","shell.execute_reply":"2021-10-08T05:53:12.966253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforms","metadata":{"papermill":{"duration":0.034446,"end_time":"2021-08-04T01:25:28.12532","exception":false,"start_time":"2021-08-04T01:25:28.090874","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def image_transform(data):\n    if data== 'train':\n        return A.Compose([A.RandomResizedCrop(CFG['size'],CFG['size'],scale = (0.85, 1.0)),\n                         A.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n                          ToTensorV2()])\n    \n    elif data == 'valid':\n        return A.Compose([A.Resize(CFG['size'],CFG['size']),\n                         A.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n                          ToTensorV2()])","metadata":{"papermill":{"duration":0.04224,"end_time":"2021-08-04T01:25:28.202021","exception":false,"start_time":"2021-08-04T01:25:28.159781","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.968517Z","iopub.execute_input":"2021-10-08T05:53:12.968971Z","iopub.status.idle":"2021-10-08T05:53:12.976727Z","shell.execute_reply.started":"2021-10-08T05:53:12.968936Z","shell.execute_reply":"2021-10-08T05:53:12.975826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = PawpularityDataset(train_df, transform=image_transform(data='train'))\n\nfor i in range(5):\n    plt.figure(figsize=(4, 4))\n    image, label = train_dataset[i]\n    plt.imshow(image[0],cmap = 'gray')\n    plt.title(f'label: {label}')\n    plt.show() ","metadata":{"papermill":{"duration":0.86067,"end_time":"2021-08-04T01:25:29.096515","exception":false,"start_time":"2021-08-04T01:25:28.235845","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:12.977981Z","iopub.execute_input":"2021-10-08T05:53:12.978342Z","iopub.status.idle":"2021-10-08T05:53:14.339843Z","shell.execute_reply.started":"2021-10-08T05:53:12.978308Z","shell.execute_reply":"2021-10-08T05:53:14.339149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL","metadata":{"papermill":{"duration":0.045247,"end_time":"2021-08-04T01:25:29.187985","exception":false,"start_time":"2021-08-04T01:25:29.142738","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class PawpularityModel(nn.Module):\n    def __init__(self, cfg, pretrained = False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model(self.cfg['model_name'], pretrained=pretrained)\n        self.features = self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.fc = nn.Linear(self.features, self.cfg['target_size'])\n        \n    def feature(self, image):\n        feature = self.model(image)\n        return feature\n    \n    def forward(self, image):\n        feature = self.feature(image)\n        output = self.fc(feature)\n        return output","metadata":{"papermill":{"duration":0.072697,"end_time":"2021-08-04T01:25:29.305374","exception":false,"start_time":"2021-08-04T01:25:29.232677","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:14.341144Z","iopub.execute_input":"2021-10-08T05:53:14.341555Z","iopub.status.idle":"2021-10-08T05:53:14.349224Z","shell.execute_reply.started":"2021-10-08T05:53:14.341516Z","shell.execute_reply":"2021-10-08T05:53:14.348506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{}},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self, eps=1e-6):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        self.eps = eps\n\n    def forward(self, yhat, y):\n        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2021-10-08T05:53:14.35133Z","iopub.execute_input":"2021-10-08T05:53:14.351552Z","iopub.status.idle":"2021-10-08T05:53:14.361718Z","shell.execute_reply.started":"2021-10-08T05:53:14.351525Z","shell.execute_reply":"2021-10-08T05:53:14.361017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{"papermill":{"duration":0.071264,"end_time":"2021-08-04T01:25:29.451162","exception":false,"start_time":"2021-08-04T01:25:29.379898","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    model.train()\n    if CFG['apex']:\n        scaler = GradScaler()\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        if CFG['apex']:\n            with autocast():\n                y_preds = model(images)\n                loss = criterion(y_preds.view(-1), labels)\n        else:\n            y_preds = model(images)\n            loss = criterion(y_preds.view(-1), labels)\n        # record loss\n        losses.update(loss.item(), batch_size)\n        if CFG['gradient_accumulation_steps'] > 1:\n            loss = loss / CFG['gradient_accumulation_steps']\n        if CFG['apex']:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG['max_grad_norm'])\n        if (step + 1) % CFG['gradient_accumulation_steps'] == 0:\n            if CFG['apex']:\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                optimizer.step()\n            optimizer.zero_grad()\n            global_step += 1\n        end = time.time()\n        if step % CFG['print_freq'] == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  'LR: {lr:.6f}  '\n                  .format(epoch+1, step, len(train_loader), \n                          remain=timeSince(start, float(step+1)/len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm,\n                          lr=scheduler.get_lr()[0]))\n        print({f\"[fold{fold}] loss\": losses.val,\n                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    model.eval()\n    losses = AverageMeter()\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds.view(-1), labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        preds.append(y_preds.to('cpu').numpy())\n        if CFG['gradient_accumulation_steps'] > 1:\n            loss = loss / CFG['gradient_accumulation_steps']\n        end = time.time()\n        if step % CFG['print_freq'] == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","metadata":{"papermill":{"duration":0.112331,"end_time":"2021-08-04T01:25:29.638305","exception":false,"start_time":"2021-08-04T01:25:29.525974","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:14.365299Z","iopub.execute_input":"2021-10-08T05:53:14.365504Z","iopub.status.idle":"2021-10-08T05:53:14.388733Z","shell.execute_reply.started":"2021-10-08T05:53:14.365482Z","shell.execute_reply":"2021-10-08T05:53:14.387931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train loop","metadata":{"papermill":{"duration":0.052219,"end_time":"2021-08-04T01:25:29.904968","exception":false,"start_time":"2021-08-04T01:25:29.852749","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(folds, fold):\n    \n    print(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CFG['target_col']].values\n\n    train_dataset = PawpularityDataset(train_folds, transform=image_transform(data='train'))\n    valid_dataset = PawpularityDataset(valid_folds, transform=image_transform(data='train'))\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG['batch_size'], \n                              shuffle=True, \n                              num_workers=CFG['num_workers'], pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG['batch_size'] * 2, \n                              shuffle=False, \n                              num_workers=CFG['num_workers'], pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG['scheduler']=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG['factor'], patience=CFG['patience'], verbose=True, eps=CFG['eps'])\n        elif CFG['scheduler']=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG['T_max'], eta_min=CFG['min_lr'], last_epoch=-1)\n        elif CFG['scheduler']=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = PawpularityModel(CFG, pretrained=True)\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'], amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = RMSELoss()\n\n    best_score = np.inf\n    best_loss = np.inf\n    \n    for epoch in range(CFG['epochs']):\n        \n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds)\n\n        elapsed = time.time() - start_time\n\n        print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        print(f'Epoch {epoch+1} - Score: {score:.4f}')\n\n        if score < best_score:\n            best_score = score\n            print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+'{}_fold{}_best.pth'.format(CFG['model_name'],fold))\n    \n    valid_folds['preds'] = torch.load(OUTPUT_DIR+'{}_fold{}_best.pth'.format(CFG['model_name'],fold), \n                                      map_location=torch.device('cpu'))['preds']\n\n    return valid_folds","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.075124,"end_time":"2021-08-04T01:25:30.031874","exception":false,"start_time":"2021-08-04T01:25:29.95675","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:14.390119Z","iopub.execute_input":"2021-10-08T05:53:14.390549Z","iopub.status.idle":"2021-10-08T05:53:14.408714Z","shell.execute_reply.started":"2021-10-08T05:53:14.390515Z","shell.execute_reply":"2021-10-08T05:53:14.407778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# main\n# ====================================================\ndef main():\n\n    \"\"\"\n    Prepare: 1.train \n    \"\"\"\n\n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG['target_col']].values\n        score = get_score(labels, preds)\n        print(f'Score: {score:<.4f}')\n    \n    if CFG['train']:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG['n_fold']):\n            if fold in CFG['trn_fold']:\n                _oof_df = train_loop(train_df, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                print(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        # CV result\n        print(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)","metadata":{"papermill":{"duration":0.073141,"end_time":"2021-08-04T01:25:30.156241","exception":false,"start_time":"2021-08-04T01:25:30.0831","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:14.409952Z","iopub.execute_input":"2021-10-08T05:53:14.410312Z","iopub.status.idle":"2021-10-08T05:53:14.421553Z","shell.execute_reply.started":"2021-10-08T05:53:14.410241Z","shell.execute_reply":"2021-10-08T05:53:14.420865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":25805.563027,"end_time":"2021-08-04T08:35:35.784865","exception":false,"start_time":"2021-08-04T01:25:30.221838","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-08T05:53:14.422537Z","iopub.execute_input":"2021-10-08T05:53:14.422739Z"},"trusted":true},"execution_count":null,"outputs":[]}]}