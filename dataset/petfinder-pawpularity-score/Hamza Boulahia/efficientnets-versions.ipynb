{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing libraries\nimport os\nimport random\nimport gc\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.data import Dataset\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Dropout, concatenate, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.utils import plot_model\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\n\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-06T18:32:43.090337Z","iopub.execute_input":"2021-12-06T18:32:43.09064Z","iopub.status.idle":"2021-12-06T18:32:43.098164Z","shell.execute_reply.started":"2021-12-06T18:32:43.090601Z","shell.execute_reply":"2021-12-06T18:32:43.097402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess Data","metadata":{}},{"cell_type":"code","source":"# Importing the training data\nTrain_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\nTrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:32:43.099698Z","iopub.execute_input":"2021-12-06T18:32:43.100282Z","iopub.status.idle":"2021-12-06T18:32:43.132969Z","shell.execute_reply.started":"2021-12-06T18:32:43.100243Z","shell.execute_reply":"2021-12-06T18:32:43.132286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the test data\nTest_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\nTest_id = Test_df.Id.copy()\nTest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:32:43.134432Z","iopub.execute_input":"2021-12-06T18:32:43.134706Z","iopub.status.idle":"2021-12-06T18:32:43.151245Z","shell.execute_reply.started":"2021-12-06T18:32:43.134671Z","shell.execute_reply":"2021-12-06T18:32:43.1505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting seeds\nseed = 42\nnp.random.seed(seed)\nrandom.seed(seed)\ntf.random.set_seed(seed)\n\n# Setting constants\nbatch_size = 32\nimage_size = 224\nchannels = 3\nshuffle_size = 1024 \n\n# Setting auto tune\nAUTOTUNE = tf.data.experimental.AUTOTUNE  ","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:32:43.152672Z","iopub.execute_input":"2021-12-06T18:32:43.152928Z","iopub.status.idle":"2021-12-06T18:32:43.160636Z","shell.execute_reply.started":"2021-12-06T18:32:43.152894Z","shell.execute_reply":"2021-12-06T18:32:43.15863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping the images ID to the image paths\nTrain_df.Id = Train_df.Id.map(lambda x: '../input/petfinder-pawpularity-score/train/' + x + '.jpg')\nTest_df.Id = Test_df.Id.map(lambda x: '../input/petfinder-pawpularity-score/test/' + x + '.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:32:43.164787Z","iopub.execute_input":"2021-12-06T18:32:43.16508Z","iopub.status.idle":"2021-12-06T18:32:43.176725Z","shell.execute_reply.started":"2021-12-06T18:32:43.165043Z","shell.execute_reply":"2021-12-06T18:32:43.175857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining functions to decode image paths and preprocess images \ndef read_img(labeled):\n    def img_to_array(path):\n        image = tf.io.read_file(path)\n        image = tf.image.decode_jpeg(image, channels=channels)\n        image = tf.cast(image, tf.float32)\n        image = tf.image.resize(image, (image_size, image_size))\n        image = tf.keras.applications.efficientnet.preprocess_input(image)\n        return image\n    def mapping_train(path, struct_data, score):\n        return (img_to_array(path),struct_data), score\n    def mapping_test(path, struct_data):\n        return (img_to_array(path),struct_data)\n    return mapping_train if labeled else mapping_test\n\ndef augment(data, score):\n    image, struct_data = data\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_saturation(image, 0.95, 1.05)\n    image = tf.image.random_contrast(image, 0.95, 1.05)\n    image = tf.image.random_brightness(image, 0.1)\n    return (image, struct_data), score\n\ndef preprocess(ds, batch_size, ds_type, labeled):\n    labeled_read_img = read_img(labeled)\n    ds = ds.map(labeled_read_img, num_parallel_calls=AUTOTUNE)\n    if ds_type=='train':\n        ds = ds.map(augment, num_parallel_calls=AUTOTUNE)\n        ds = ds.shuffle(shuffle_size, reshuffle_each_iteration=True)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:32:43.178091Z","iopub.execute_input":"2021-12-06T18:32:43.178418Z","iopub.status.idle":"2021-12-06T18:32:43.191304Z","shell.execute_reply.started":"2021-12-06T18:32:43.17837Z","shell.execute_reply":"2021-12-06T18:32:43.190467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_ds(df, ds_type, labeled):\n    ds = Dataset.from_tensor_slices((df['Id'].values,df.iloc[:,1:-1],df['Pawpularity'].values))\n    ds = preprocess(ds, batch_size, ds_type, labeled)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:32:43.192675Z","iopub.execute_input":"2021-12-06T18:32:43.193238Z","iopub.status.idle":"2021-12-06T18:32:43.199167Z","shell.execute_reply.started":"2021-12-06T18:32:43.193202Z","shell.execute_reply":"2021-12-06T18:32:43.198416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating & Training models","metadata":{}},{"cell_type":"markdown","source":"The first model imported below i.e:```EffB0_1``` was obtained using the command ``` tf.keras.applications.efficientnet.EfficietNetB0(include_top=False)```, but here was imported from a Dataset so that we don't use internet in this kernel.\n\nThe second model imported below i.e:``` EffB0_2``` was obtained from a Github [repo](https://github.com/leondgarse/keras_efficientnet_v2#training-detail-from-article) under the name (EffV1B0), however it was imported here from a Dataset for the same reason cited above.\n\nBoth imported versions are of pretrained EfficientNetB0 on Imagenet and without the top of the neural network.\n","metadata":{}},{"cell_type":"code","source":"# Importing EfficientNetB0 pretrained model obtained from Keras Applications API\nEffNetB0_1_path = \"../input/efficientnetb0-pretrained/EfficientNetB0.h5\"\nEffB0_1 = tf.keras.models.load_model(EffNetB0_1_path)\nEffB0_1.trainable=False\n\n\n# Importing EfficientNetB0 pretrained model obtained from a Github Repo\nEffNetB0_2_path = \"../input/efficientnetsv2-keras-notop-models/EfficientnetV1/Imagenet/efficientnetv1-b0-imagenet.h5\"\nEffB0_2 = tf.keras.models.load_model(EffNetB0_2_path)\nEffB0_2.trainable=False","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:32:43.200433Z","iopub.execute_input":"2021-12-06T18:32:43.200889Z","iopub.status.idle":"2021-12-06T18:32:47.150125Z","shell.execute_reply.started":"2021-12-06T18:32:43.200851Z","shell.execute_reply":"2021-12-06T18:32:47.149415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the neural network model\n# The named layers are going to be used to extract features for the catboost model training\ndef create_model(version):\n    Inp1 = Input(shape=(image_size,image_size,channels))\n    if version == '1':\n        out1 = EffB0_1(Inp1)\n    else:\n        out1 = EffB0_2(Inp1)\n        out1 = GlobalAveragePooling2D()(out1)\n    out1 = Dropout(0.2)(out1)\n    #out1 = BatchNormalization()(out1)\n    out1 = Dense(16, activation='relu', kernel_initializer='he_normal')(out1)\n    out1 = Dense(16, activation='relu', kernel_initializer='he_normal', name=\"Last_layer_Eff\")(out1)\n\n    Inp2 = Input(shape=(12,))\n    out2 = Dense(16, activation='relu', kernel_initializer='he_normal', name=\"Last_layer_FFN\")(Inp2)\n\n    out = concatenate([out1,out2], axis=1)\n    out = Dense(16, activation='relu', kernel_initializer='he_normal')(out)\n    out = Dense(1, activation='relu')(out)\n\n    PawModel = Model(inputs=[Inp1,Inp2], outputs=out)\n    return PawModel","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:32:47.152594Z","iopub.execute_input":"2021-12-06T18:32:47.153087Z","iopub.status.idle":"2021-12-06T18:32:47.161239Z","shell.execute_reply.started":"2021-12-06T18:32:47.153046Z","shell.execute_reply":"2021-12-06T18:32:47.160359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr_metric(optimizer):\n    def lr(y_true, y_pred):\n        return optimizer._decayed_lr(tf.float32) # I use ._decayed_lr method instead of .lr\n    return lr","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:32:47.164105Z","iopub.execute_input":"2021-12-06T18:32:47.1643Z","iopub.status.idle":"2021-12-06T18:32:47.175824Z","shell.execute_reply.started":"2021-12-06T18:32:47.164276Z","shell.execute_reply":"2021-12-06T18:32:47.175109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training over 3 epochs only and using a third of the available data for a faster training and just to show the differences in the results of both models**\n\n### Training using the first version","metadata":{}},{"cell_type":"code","source":"#Training\nTrain = Train_df.iloc[:3000]\nVal = Train_df.iloc[3000:3300]\n\nTrain_ds = create_ds(Train, ds_type='train', labeled=True)\nVal_ds = create_ds(Val, ds_type='train', labeled=True)\n\nmodel = create_model(version='1')\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.01)\nlr_metric = get_lr_metric(opt)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=1e-6)\nmodel.compile(loss='mse', \n          optimizer = opt, \n          metrics=[tf.keras.metrics.RootMeanSquaredError(), lr_metric])\nresults = model.fit(Train_ds,\n                  epochs=3,\n                  validation_data = Val_ds,\n                  callbacks=[reduce_lr], verbose=1)\nprint('='*25)\n\n# Freeing up memory\ndel model, results\ndel Train_ds, Val_ds\ndel Train, Val\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:38:59.728018Z","iopub.execute_input":"2021-12-06T18:38:59.728305Z","iopub.status.idle":"2021-12-06T18:41:09.033033Z","shell.execute_reply.started":"2021-12-06T18:38:59.728275Z","shell.execute_reply":"2021-12-06T18:41:09.032353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training using the second version under the same settings as the first version ","metadata":{}},{"cell_type":"code","source":"#Training\nTrain = Train_df.iloc[:3000]\nVal = Train_df.iloc[3000:3300]\n\nTrain_ds = create_ds(Train, ds_type='train', labeled=True)\nVal_ds = create_ds(Val, ds_type='train', labeled=True)\n\nmodel = create_model(version='2')\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.01)\nlr_metric = get_lr_metric(opt)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=1e-6)\nmodel.compile(loss='mse', \n          optimizer = opt, \n          metrics=[tf.keras.metrics.RootMeanSquaredError(), lr_metric])\nresults = model.fit(Train_ds,\n                  epochs=3,\n                  validation_data = Val_ds,\n                  callbacks=[reduce_lr], verbose=1)\nprint('='*25)\n\n# Freeing up memory\ndel model, results\ndel Train_ds, Val_ds\ndel Train, Val\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-06T18:42:35.29226Z","iopub.execute_input":"2021-12-06T18:42:35.292563Z","iopub.status.idle":"2021-12-06T18:44:05.294364Z","shell.execute_reply.started":"2021-12-06T18:42:35.292519Z","shell.execute_reply":"2021-12-06T18:44:05.293618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Both the validation, and training accuracy after 3 epochs of the second version is far worse from the ones of the first virsions!**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}