{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This example shows how to use [AutoGluon](https://auto.gluon.ai) to build a solution with private LB: 16.96991 and public LB: 17.89868 (equivalent to 20rd/3537 in the competition). \n\nAutoGluon is an AutoML toolkit that makes it easy to build strong ML models for your application that may involve image, text and tabular data. In the recent 0.5 release, AutoGluon launched a new feature called `autogluon.multimodal`, or [AutoMM](https://auto.gluon.ai/stable/tutorials/multimodal/index.html). AutoMM is a deep learning “model zoo” of model zoos that integrates popular DL packages like [timm](https://github.com/rwightman/pytorch-image-models), [huggingface/transformers](https://github.com/huggingface/transformers), [openai/CLIP](https://github.com/openai/CLIP), etc. Users can easily build deep learning models that fuse these backbones to tackle both unimodal and multimodal problems. Details about how to train models for this competition is described in [this example](https://github.com/awslabs/autogluon/tree/master/examples/automm/kaggle_pawpularity). In short, we ensembled models with three backbones: `vit_large_patch16_384`, `swin_large_patch4_window12_384`,`convnext_large_384_in22ft2k` and `swin_large_patch4_window7_224`, the first two models are fusion models that combine the image and the metadata, while the last two only use models in timm.\n\nFor more details about AutoGluon, check our website: https://auto.gluon.ai, Github repo: https://github.com/awslabs/autogluon, or install it via `pip install autogluon`. We are actively improving the package and definitely welcome feedback and contributions!","metadata":{}},{"cell_type":"code","source":"!nvidia-smi\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:41:15.804827Z","iopub.execute_input":"2022-06-25T16:41:15.805391Z","iopub.status.idle":"2022-06-25T16:41:16.552017Z","shell.execute_reply.started":"2022-06-25T16:41:15.805308Z","shell.execute_reply":"2022-06-25T16:41:16.551175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/autogluon-standalone-install/autogluon_standalone/antlr4-python3-runtime-4.8/antlr4-python3-runtime-4.8/src/')\n!pip install --no-deps --no-index --quiet ../input/autogluon-standalone-install/autogluon_standalone/*.whl --find-links autogluon_standalone","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:41:16.554298Z","iopub.execute_input":"2022-06-25T16:41:16.554575Z","iopub.status.idle":"2022-06-25T16:41:21.120002Z","shell.execute_reply.started":"2022-06-25T16:41:16.554539Z","shell.execute_reply":"2022-06-25T16:41:21.119188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from autogluon.multimodal import AutoMMPredictor\nimport pandas as pd\nimport numpy as np\nimport torch\nimport os\n\n\ndata_path = \"../input/petfinder-pawpularity-score/\"\n\nconfig_6 = {\n    \"save_path\": \"../input/pawpularity-automm-result/result6/result\",\n    \"per_gpu_batch_size_evaluation\": 32,\n    \"N_fold\": 5,\n}\nconfig_7 = {\n    \"save_path\": \"../input/pawpularity-automm-result/result7/result\",\n    \"per_gpu_batch_size_evaluation\": 3,\n    \"N_fold\": 5,\n}\nconfig_13 = {\n    \"save_path\": \"../input/pawpularity-automm-result/result13/result\",\n    \"per_gpu_batch_size_evaluation\": 32,\n    \"N_fold\": 5,\n}\nconfig_26 = {\n    \"save_path\": \"../input/pawpularity-automm-result26/result\",\n    \"per_gpu_batch_size_evaluation\": 3,\n    \"N_fold\": 5,\n}\nconfig_30 = {\n    \"save_path\": \"../input/pawpularity-automm-result30/result\",\n    \"per_gpu_batch_size_evaluation\": 32,\n    \"N_fold\": 5,\n}\n\n\ndef load_data(data_path):\n    train_df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n    train_df.rename(columns={\"Id\": \"Image Path\"}, inplace=True)\n    train_df[\"Image Path\"] = train_df[\"Image Path\"].apply(lambda s: os.path.join(data_path, \"train\", s + \".jpg\"))\n\n    test_df = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n    test_df.rename(columns={\"Id\": \"Image Path\"}, inplace=True)\n    test_df[\"Image Path\"] = test_df[\"Image Path\"].apply(lambda s: os.path.join(data_path, \"test\", s + \".jpg\"))\n    return train_df, test_df\n\n\ntrain_df, test_df = load_data(data_path)\n\nif __name__ == \"__main__\":\n    submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\n    \n    configs = [config_6, config_7, config_26, config_13]\n    model_preds = np.empty(shape=[0,submission.shape[0]])\n    for perconfig in configs:\n        print(perconfig)\n        save_standalone_path = perconfig[\"save_path\"] + '_standalone'\n        all_preds = []\n        for fold in range(perconfig[\"N_fold\"]):\n            pretrained_model = AutoMMPredictor.load(path=save_standalone_path + f'_fold{fold}/')\n            pretrained_model._config.env.per_gpu_batch_size_evaluation = perconfig[\"per_gpu_batch_size_evaluation\"]\n            df_test = pretrained_model.predict(test_df)\n            all_preds.append(df_test)\n            del pretrained_model\n            torch.cuda.empty_cache()\n        model_preds = np.append(model_preds, [np.mean(np.stack(all_preds), axis=0)], axis=0)\n    submission[\"Pawpularity\"] = model_preds[0] * 0.3 + model_preds[1] * 0.4  + model_preds[2] * 0.2 + model_preds[3] * 0.1 #Model ensemble.\n    submission.to_csv(\"submission.csv\", index=False)\n\n    print(submission)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:41:21.12199Z","iopub.execute_input":"2022-06-25T16:41:21.122281Z"},"trusted":true},"execution_count":null,"outputs":[]}]}