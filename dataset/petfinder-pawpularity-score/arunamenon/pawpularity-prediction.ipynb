{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PetFinder.my - Pawpularity Contest\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/25383/logos/header.png?t=2021-08-31-18-49-29&quot)","metadata":{}},{"cell_type":"markdown","source":"# Competiton Description:\n\nhttps://www.petfinder.my/cutenessmeter\n\nA picture is worth a thousand words. But did you know a picture can save a thousand lives? Millions of stray animals suffer on the streets or are euthanized in shelters every day around the world. You might expect pets with attractive photos to generate more interest and be adopted faster. But what makes a good picture? With the help of data science, you may be able to accurately determine a pet photo’s appeal and even suggest improvements to give these rescue animals a higher chance of loving homes.\n\nPetFinder.my is Malaysia’s leading animal welfare platform, featuring over 180,000 animals with 54,000 happily adopted. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.\n\nCurrently, PetFinder.my uses a basic Cuteness Meter to rank pet photos. It analyzes picture composition and other factors compared to the performance of thousands of pet profiles. While this basic tool is helpful, it's still in an experimental stage and the algorithm could be improved.\n\nIn this competition, you’ll analyze raw images and metadata to predict the “Pawpularity” of pet photos. You'll train and test your model on PetFinder.my's thousands of pet profiles. Winning versions will offer accurate recommendations that will improve animal welfare.\n\nIf successful, your solution will be adapted into AI tools that will guide shelters and rescuers around the world to improve the appeal of their pet profiles, automatically enhancing photo quality and recommending composition improvements. As a result, stray dogs and cats can find their \"furever\" homes much faster. With a little assistance from the Kaggle community, many precious lives could be saved and more happy families created.\n\nTop participants may be invited to collaborate on implementing their solutions and creatively improve global animal welfare with their AI skills.","metadata":{}},{"cell_type":"markdown","source":"# Data Decsription:\n\nIn this competition, your task is to predict engagement with a pet's profile based on the photograph for that profile. You are also provided with hand-labelled metadata for each photo. The dataset for this competition therefore comprises both images and tabular data.\n\n## How Pawpularity Score Is Derived:\n\nThe Pawpularity Score is derived from each pet profile's page view statistics at the listing pages, using an algorithm that normalizes the traffic data across different pages, platforms (web & mobile) and various metrics.\nDuplicate clicks, crawler bot accesses and sponsored profiles are excluded from the analysis.\n\n## Purpose of Photo Metadata:\n\nWe have included optional Photo Metadata, manually labeling each photo for key visual quality and composition parameters.\nThese labels are not used for deriving our Pawpularity score, but it may be beneficial for better understanding the content and co-relating them to a photo's attractiveness. Our end goal is to deploy AI solutions that can generate intelligent recommendations (i.e. show a closer frontal pet face, add accessories, increase subject focus, etc) and automatic enhancements (i.e. brightness, contrast) on the photos, so we are hoping to have predictions that are more easily interpretable.\nYou may use these labels as you see fit, and optionally build an intermediate / supplementary model to predict the labels from the photos. If your supplementary model is good, we may integrate it into our AI tools as well.\nIn our production system, new photos that are dynamically scored will not contain any photo labels. If the Pawpularity prediction model requires photo label scores, we will use an intermediary model to derive such parameters, before feeding them to the final model.\n\n## Training Data:\n\ntrain/ - Folder containing training set photos of the form {id}.jpg, where {id} is a unique Pet Profile ID.\n\ntrain.csv - Metadata (described below) for each photo in the training set as well as the target, the photo's Pawpularity score. The Id column gives the photo's unique Pet Profile ID corresponding the photo's file name.\n\n## Example Test Data:\n\nIn addition to the training data, we include some randomly generated example test data to help you author submission code. When your submitted notebook is scored, this example data will be replaced by the actual test data (including the sample submission).\n\ntest/ - Folder containing randomly generated images in a format similar to the training set photos. The actual test data comprises about 6800 pet photos similar to the training set photos.\n\ntest.csv - Randomly generated metadata similar to the training set metadata.\n\nsample_submission.csv - A sample submission file in the correct format.\n\n## Photo Metadata:\n\nThe train.csv and test.csv files contain metadata for photos in the training set and test set, respectively. Each pet photo is labeled with the value of 1 (Yes) or 0 (No) for each of the following features:\n\nFocus - Pet stands out against uncluttered background, not too close / far.\n\nEyes - Both eyes are facing front or near-front, with at least 1 eye / pupil decently clear.\n\nFace - Decently clear face, facing front or near-front.\n\nNear - Single pet taking up significant portion of photo (roughly over 50% of photo width or height).\n\nAction - Pet in the middle of an action (e.g., jumping).\n\nAccessory - Accompanying physical or digital accessory / prop (i.e. toy, digital sticker), excluding collar and leash.\n\nGroup - More than 1 pet in the photo.\n\nCollage - Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).\n\nHuman - Human in the photo.\n\nOcclusion - Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are considered occlusion.\n\nInfo - Custom-added text or labels (i.e. pet name, description).\n\nBlur - Noticeably out of focus or noisy, especially for the pet’s eyes and face. For Blur entries, “Eyes” column is always set to 0.","metadata":{}},{"cell_type":"markdown","source":"# Import packages","metadata":{}},{"cell_type":"code","source":"# Install packages\n# !pip install pip install efficientnet_pytorch\n# !pip install boostaroota\n!pip install ../input/kerasapplications/ > /dev/null\n!pip install ../input/efficientnet-keras-source-code/ > /dev/null","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:41:35.719681Z","iopub.execute_input":"2021-10-17T21:41:35.720282Z","iopub.status.idle":"2021-10-17T21:42:35.003532Z","shell.execute_reply.started":"2021-10-17T21:41:35.720171Z","shell.execute_reply":"2021-10-17T21:42:35.002586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\npyo.init_notebook_mode() # Set notebook mode to work in offline\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nfrom sklearn import model_selection as sk_model_selection\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\nfrom sklearn import metrics\nimport optuna\n# from boostaroota import BoostARoota\nfrom sklearn.metrics import log_loss\nfrom optuna.samplers import TPESampler\nimport functools\nfrom functools import partial\nimport xgboost as xgb\nimport joblib\nimport sys\npackage_path = '/kaggle/input/efficientnet100minimal/'\nsys.path.append(package_path)\nimport efficientnet.keras as efn \n\nSEED = 42","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:35.005756Z","iopub.execute_input":"2021-10-17T21:42:35.006041Z","iopub.status.idle":"2021-10-17T21:42:42.971217Z","shell.execute_reply.started":"2021-10-17T21:42:35.006Z","shell.execute_reply":"2021-10-17T21:42:42.970517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data files","metadata":{}},{"cell_type":"code","source":"train_metadata = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntest_metadata = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\nsample_submission = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:42.979622Z","iopub.execute_input":"2021-10-17T21:42:42.980066Z","iopub.status.idle":"2021-10-17T21:42:43.029211Z","shell.execute_reply.started":"2021-10-17T21:42:42.98002Z","shell.execute_reply":"2021-10-17T21:42:43.028443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"print(train_metadata.shape)\nprint('\\n# Ids:',train_metadata['Id'].nunique())\ntrain_metadata.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:43.030434Z","iopub.execute_input":"2021-10-17T21:42:43.030685Z","iopub.status.idle":"2021-10-17T21:42:43.064567Z","shell.execute_reply.started":"2021-10-17T21:42:43.030651Z","shell.execute_reply":"2021-10-17T21:42:43.063749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_metadata.shape)\ntest_metadata.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:43.065834Z","iopub.execute_input":"2021-10-17T21:42:43.066155Z","iopub.status.idle":"2021-10-17T21:42:43.080405Z","shell.execute_reply.started":"2021-10-17T21:42:43.066117Z","shell.execute_reply":"2021-10-17T21:42:43.079511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_submission.shape)\nsample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:43.082287Z","iopub.execute_input":"2021-10-17T21:42:43.082603Z","iopub.status.idle":"2021-10-17T21:42:43.096652Z","shell.execute_reply.started":"2021-10-17T21:42:43.082564Z","shell.execute_reply":"2021-10-17T21:42:43.095674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_metadata.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:43.098557Z","iopub.execute_input":"2021-10-17T21:42:43.099143Z","iopub.status.idle":"2021-10-17T21:42:43.15049Z","shell.execute_reply.started":"2021-10-17T21:42:43.099104Z","shell.execute_reply":"2021-10-17T21:42:43.149618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of pawpularity by various metadata features","metadata":{}},{"cell_type":"code","source":"fig = px.box(train_metadata, y=\"Pawpularity\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:43.151909Z","iopub.execute_input":"2021-10-17T21:42:43.152166Z","iopub.status.idle":"2021-10-17T21:42:44.13066Z","shell.execute_reply.started":"2021-10-17T21:42:43.152132Z","shell.execute_reply":"2021-10-17T21:42:44.13Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(train_metadata, x=\"Pawpularity\", nbins=20)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:44.133463Z","iopub.execute_input":"2021-10-17T21:42:44.133874Z","iopub.status.idle":"2021-10-17T21:42:44.24054Z","shell.execute_reply.started":"2021-10-17T21:42:44.133834Z","shell.execute_reply":"2021-10-17T21:42:44.239739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def box_plot_by_metadata(metadata):\n    fig = px.box(train_metadata, y=\"Pawpularity\", x = metadata)\n    fig.show()\n    \nmetadata_list = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n\nw = widgets.interactive(box_plot_by_metadata, metadata = metadata_list)\ndisplay(w)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:44.2422Z","iopub.execute_input":"2021-10-17T21:42:44.242456Z","iopub.status.idle":"2021-10-17T21:42:44.367772Z","shell.execute_reply.started":"2021-10-17T21:42:44.242413Z","shell.execute_reply":"2021-10-17T21:42:44.367131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def box_plot_by_multiple_metadata(subject_focus, eyes, face, near, action, accessory, group, collage, human, occlusion, info, blur):\n    data = train_metadata.copy(deep = True)\n    data['Filter'] = 0\n    list_filters = [subject_focus, eyes, face, near, action, accessory, group, collage, human, occlusion, info, blur]\n    \n    for i in range(0, len(metadata_list)):\n        col = metadata_list[i]\n        col_value = list_filters[i]\n        if col_value == 1:\n            data['Filter'] = np.where(data[col]==1, 1, data['Filter'])\n    fig = px.box(data, y=\"Pawpularity\", x = 'Filter')\n    print('Filters: \\n',metadata_list,'\\n',list_filters)\n    fig.show()\n    \nw = widgets.interactive(box_plot_by_multiple_metadata,\n                        subject_focus = [0,1],\n                        eyes = [0,1],\n                        face = [0,1],\n                        near = [0,1],\n                        action = [0,1],\n                        accessory = [0,1],\n                        group = [0,1],\n                        collage = [0,1],\n                        human = [0,1],\n                        occlusion = [0,1],\n                        info = [0,1],\n                        blur = [0,1])\ndisplay(w)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:44.368868Z","iopub.execute_input":"2021-10-17T21:42:44.369399Z","iopub.status.idle":"2021-10-17T21:42:44.628456Z","shell.execute_reply.started":"2021-10-17T21:42:44.369359Z","shell.execute_reply":"2021-10-17T21:42:44.62775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Look at photos","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = '../input/petfinder-pawpularity-score/train/'\n\nsample_id = '0007de18844b0dbbb5e1f607da0606e0'\ndisplay(train_metadata[train_metadata['Id']==sample_id])\nimg=mpimg.imread(TRAIN_PATH + sample_id + '.jpg')\nplt.imshow(img)\nplt.show()\nimg.shape, img.min(), img.max(), img.mean()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:44.629745Z","iopub.execute_input":"2021-10-17T21:42:44.630438Z","iopub.status.idle":"2021-10-17T21:42:45.014671Z","shell.execute_reply.started":"2021-10-17T21:42:44.630399Z","shell.execute_reply":"2021-10-17T21:42:45.01383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"# Load model\nmodel = efn.EfficientNetB7(include_top=False, input_shape=(256,256,3), weights=None)\n# now this would usually download the weights, but because this is offline we will import \n# the weights from another datasource\n# just be sure to add the matching b0 to b7 number, depending on which model you started above\nmodel.load_weights('../input/efficientnetb0b7-keras-weights/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:45.01957Z","iopub.execute_input":"2021-10-17T21:42:45.02287Z","iopub.status.idle":"2021-10-17T21:42:56.352818Z","shell.execute_reply.started":"2021-10-17T21:42:45.022826Z","shell.execute_reply":"2021-10-17T21:42:56.352031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_metadata = train_metadata.head(100) - take a sample to test model\n\nlist_features_from_model = ['feature_' + str(x+1) for x in range(0, 2560)]\ntrain_data = train_metadata.copy(deep = True)\ntrain_data[list_features_from_model] = np.NaN\n\ntest_data = test_metadata.copy(deep = True)\ntest_data[list_features_from_model] = np.NaN\n\nprint('For train data')\nfor i in tqdm(range(0, train_data.shape[0])):\n    id_ = train_data['Id'].iloc[i]\n    img=mpimg.imread(TRAIN_PATH + id_ + '.jpg')\n    features = tf.keras.layers.GlobalAveragePooling2D()(model(np.expand_dims(cv2.resize(img, (256, 256)) / 255, axis = 0)))\n    train_data.iloc[i] = list(train_data[[x for x in train_data.columns if 'feature' not in x]].iloc[i]) + list(np.array(features)[0])\n    \nprint('\\nFor test data')\nfor i in tqdm(range(0, test_data.shape[0])):\n    id_ = test_data['Id'].iloc[i]\n    img=mpimg.imread(TRAIN_PATH.replace('train','test') + id_ + '.jpg')\n    features = tf.keras.layers.GlobalAveragePooling2D()(model(np.expand_dims(cv2.resize(img, (256, 256)) / 255, axis = 0)))\n    test_data.iloc[i] = list(test_data[[x for x in test_data.columns if 'feature' not in x]].iloc[i]) + list(np.array(features)[0])","metadata":{"execution":{"iopub.status.busy":"2021-10-17T21:42:56.354143Z","iopub.execute_input":"2021-10-17T21:42:56.354435Z","iopub.status.idle":"2021-10-17T23:31:27.770988Z","shell.execute_reply.started":"2021-10-17T21:42:56.354389Z","shell.execute_reply":"2021-10-17T23:31:27.770041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective_regressor(X_train, y_train, X_val, y_val, target_value, trial):\n    \"\"\"It tries to find the best hyper-parameters for XGBOOST model for given task\n\n        Details:\n            It uses OPTUNA library which is based on Baseian-optimization to tune the hyper-params.\n\n        Args:\n            X_train: training data\n            X_test: testing data\n            y_tain: training label\n            y_val: validation label\n            trail: object of optuna for optimizing the task in hand\n\n        Returns:\n            best score till now\n\n    \"\"\"\n    if ((target_value)):\n        tree_methods = ['approx', 'hist', 'exact']\n#         tree_methods = ['gpu_hist']\n        boosting_lists = ['gbtree', 'gblinear']\n        objective_list_reg = ['reg:squarederror']  # 'reg:gamma', 'reg:tweedie'\n        boosting = trial.suggest_categorical('boosting', boosting_lists),\n        tree_method = trial.suggest_categorical('tree_method', tree_methods),\n        n_estimator = trial.suggest_int('n_estimators',20, 200, 10),\n        max_depth = trial.suggest_int('max_depth', 1, 50),\n        reg_alpha = trial.suggest_int('reg_alpha', 5,10),\n        reg_lambda = trial.suggest_int('reg_lambda', 5,10),\n        min_child_weight = trial.suggest_int('min_child_weight', 2,5),\n        gamma = trial.suggest_int('gamma', 1, 5),\n        learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n        objective = trial.suggest_categorical('objective', objective_list_reg),\n        colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.8, 1, 0.05),\n        colsample_bynode = trial.suggest_discrete_uniform('colsample_bynode', 0.8, 1, 0.05),\n        colsample_bylevel = trial.suggest_discrete_uniform('colsample_bylevel', 0.8, 1, 0.05),\n        subsample = trial.suggest_discrete_uniform('subsample', 0.7, 1, 0.05),\n        nthread = -1\n        \n        \n    xgboost_tune = xgb.XGBRegressor(\n        tree_method=tree_method[0],\n        boosting=boosting[0],\n        reg_alpha=reg_alpha[0],\n        reg_lambda=reg_lambda[0],\n        gamma=gamma[0],\n        objective=objective[0],\n        colsample_bynode=colsample_bynode[0],\n        colsample_bylevel=colsample_bylevel[0],\n        n_estimators=n_estimator[0],\n        max_depth=max_depth[0],\n        min_child_weight=min_child_weight[0],\n        learning_rate=learning_rate[0],\n        subsample=subsample[0],\n        colsample_bytree=colsample_bytree[0],\n#         scale_pos_weight=scale_pos_weight,\n        eval_metric='rmse',\n        n_jobs=nthread,\n        random_state=SEED)\n    \n    xgboost_tune.fit(X_train, y_train)\n    pred_val = xgboost_tune.predict(X_val)\n    \n    return mean_squared_error(y_val, pred_val, squared=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T23:31:27.775025Z","iopub.execute_input":"2021-10-17T23:31:27.775307Z","iopub.status.idle":"2021-10-17T23:31:27.800316Z","shell.execute_reply.started":"2021-10-17T23:31:27.77527Z","shell.execute_reply":"2021-10-17T23:31:27.799218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost model\ndf_train, df_valid = sk_model_selection.train_test_split(\n    train_data, \n    test_size=0.15, \n    random_state=42)\n\nfeature_cols = [x for x in train_data.columns if x not in ['Id','Pawpularity']]\n\nX_train = df_train[feature_cols]\ny_train = df_train[['Pawpularity']]\nX_valid = df_valid[feature_cols]\ny_valid = df_valid[['Pawpularity']]\n\n# br = BoostARoota(metric='rmse', silent = True)\n# br.fit(X_train,y_train)\n# X_train=X_train[br.keep_vars_.tolist()]\n# X_valid=X_valid[br.keep_vars_.tolist()]\n\nstudy = optuna.create_study(direction='minimize', sampler=TPESampler(seed=SEED))\nstudy.optimize(\n    functools.partial(objective_regressor, X_train, y_train, X_valid, y_valid,'trial'),\n            timeout=500)\n\nmodel_xgb = xgb.XGBRegressor(**study.best_params, random_state=SEED)\nmodel_xgb.fit(X_train,y_train)\n\nprint('\\nTrain data performance:')\ny_predicted = model_xgb.predict(X_train)\nprint('RMSE: ', mean_squared_error(y_train, y_predicted, squared=False))\nprint('\\nValidation data performance:')\ny_predicted = model_xgb.predict(X_valid)\nprint('RMSE: ', mean_squared_error(y_valid, y_predicted, squared=False))\n\nprint(\"Saving model .. \",end=\" \")\njoblib.dump(model_xgb,\"XGBoost_model.pkl\")","metadata":{"execution":{"iopub.status.busy":"2021-10-17T23:31:27.806124Z","iopub.execute_input":"2021-10-17T23:31:27.806414Z","iopub.status.idle":"2021-10-18T00:08:02.670227Z","shell.execute_reply.started":"2021-10-17T23:31:27.806378Z","shell.execute_reply":"2021-10-18T00:08:02.669478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model with full data and optimal hyperparameters\n\nmodel_xgb = joblib.load(\"XGBoost_model.pkl\")\nmodel_xgb.fit(pd.concat([X_train, X_valid], axis = 0).reset_index(drop = True), pd.concat([y_train, y_valid], axis = 0).reset_index(drop = True))\n\nprint('\\nTrain data performance:')\ny_predicted = model_xgb.predict(X_train)\nprint('RMSE: ', mean_squared_error(y_train, y_predicted, squared=False))\nprint('\\nValidation data performance:')\ny_predicted = model_xgb.predict(X_valid)\nprint('RMSE: ', mean_squared_error(y_valid, y_predicted, squared=False))\n\nprint(\"Saving model .. \",end=\" \")\njoblib.dump(model_xgb,\"XGBoost_model_full_data.pkl\")","metadata":{"execution":{"iopub.status.busy":"2021-10-18T00:08:02.671502Z","iopub.execute_input":"2021-10-18T00:08:02.671833Z","iopub.status.idle":"2021-10-18T00:08:41.33197Z","shell.execute_reply.started":"2021-10-18T00:08:02.671794Z","shell.execute_reply":"2021-10-18T00:08:41.331295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions on test data","metadata":{}},{"cell_type":"code","source":"X_test = test_data[feature_cols]\ny_predicted = model_xgb.predict(X_test)\noutput_df = sample_submission.copy(deep = True)\noutput_df['Pawpularity'] = y_predicted","metadata":{"execution":{"iopub.status.busy":"2021-10-18T00:08:41.333175Z","iopub.execute_input":"2021-10-18T00:08:41.33357Z","iopub.status.idle":"2021-10-18T00:08:41.348333Z","shell.execute_reply.started":"2021-10-18T00:08:41.333531Z","shell.execute_reply":"2021-10-18T00:08:41.347517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_df","metadata":{"execution":{"iopub.status.busy":"2021-10-18T00:08:41.351666Z","iopub.execute_input":"2021-10-18T00:08:41.353293Z","iopub.status.idle":"2021-10-18T00:08:41.368064Z","shell.execute_reply.started":"2021-10-18T00:08:41.35326Z","shell.execute_reply":"2021-10-18T00:08:41.367321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_df['Pawpularity'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T00:08:41.369251Z","iopub.execute_input":"2021-10-18T00:08:41.369592Z","iopub.status.idle":"2021-10-18T00:08:41.380426Z","shell.execute_reply.started":"2021-10-18T00:08:41.369552Z","shell.execute_reply":"2021-10-18T00:08:41.37953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T00:08:41.381784Z","iopub.execute_input":"2021-10-18T00:08:41.382326Z","iopub.status.idle":"2021-10-18T00:08:41.391021Z","shell.execute_reply.started":"2021-10-18T00:08:41.382286Z","shell.execute_reply":"2021-10-18T00:08:41.390053Z"},"trusted":true},"execution_count":null,"outputs":[]}]}