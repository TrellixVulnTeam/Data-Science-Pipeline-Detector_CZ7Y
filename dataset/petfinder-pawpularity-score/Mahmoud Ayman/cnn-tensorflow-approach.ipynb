{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Importing Packages","metadata":{}},{"cell_type":"code","source":"# import data processing and visualisation libraries\nimport numpy as np\nimport pandas as pd\nimport keras\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# import tensorflow and keras\nimport tensorflow as tf\n#from tensorflow import keras\nimport os\n\nprint(\"Packages imported...\")","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:07.693932Z","iopub.execute_input":"2022-01-21T13:29:07.694613Z","iopub.status.idle":"2022-01-21T13:29:13.609554Z","shell.execute_reply.started":"2022-01-21T13:29:07.694503Z","shell.execute_reply":"2022-01-21T13:29:13.607605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\nwith tf.device('/GPU:0'):\n    print('Yes, there is GPU')\n    \ntf.debugging.set_log_device_placement(True)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:13.612698Z","iopub.execute_input":"2022-01-21T13:29:13.613004Z","iopub.status.idle":"2022-01-21T13:29:16.160339Z","shell.execute_reply.started":"2022-01-21T13:29:13.612964Z","shell.execute_reply":"2022-01-21T13:29:16.159349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MAKE THE SEED FIXED FOR PRODUCTIVITY\n# Lets set all random seeds\nimport random\nimport time, datetime\n\ndef get_current_time() -> str:\n    \"\"\"returns the current time in (str)\"\"\"\n    time_string = datetime.datetime.fromtimestamp(time.time()).strftime(\"%Y_%m_%d_%H_%M\")\n    return str(time_string)\ndef seed_everything(seed=0):\n    \n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 21\nseed_everything(seed)\n#warnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:16.162603Z","iopub.execute_input":"2022-01-21T13:29:16.163007Z","iopub.status.idle":"2022-01-21T13:29:16.177009Z","shell.execute_reply.started":"2022-01-21T13:29:16.16296Z","shell.execute_reply":"2022-01-21T13:29:16.175885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Exploring data","metadata":{}},{"cell_type":"code","source":"## Exploring files in folder\nfolder_path = '../input/petfinder-pawpularity-score/'\n#print(list(os.walk(folder_path)))\nfor path, directories, files in os.walk(folder_path):\n    print(path,'--> number of files : ', len(files))\n# I SEE TEST DATA IS MEANT TO BE TEST IN WILD. but it's kinda usless honestly it's taken from same dataset, same human hand","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:16.181802Z","iopub.execute_input":"2022-01-21T13:29:16.182571Z","iopub.status.idle":"2022-01-21T13:29:25.340725Z","shell.execute_reply.started":"2022-01-21T13:29:16.182526Z","shell.execute_reply":"2022-01-21T13:29:25.339783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preparing data in dataframe for easier data handling\ntrain_file = '../input/petfinder-pawpularity-score/train.csv'\ndata_df = pd.read_csv(train_file)\ndata_df['path'] = data_df['Id'].map(lambda x: str(folder_path+'/train/'+x)+'.jpg')\n#train_df = train_df.drop(columns=['Id'])\n#train_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ndata_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:25.342032Z","iopub.execute_input":"2022-01-21T13:29:25.342347Z","iopub.status.idle":"2022-01-21T13:29:25.438859Z","shell.execute_reply.started":"2022-01-21T13:29:25.342305Z","shell.execute_reply":"2022-01-21T13:29:25.437723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distrubtion of the target\ntarget_col = 'Pawpularity'\nfig, ax = plt.subplots(figsize =(20, 10))\nax.hist(data_df[target_col], bins=100)\nax.set_title(f'Targets Histogram ')\nplt.show()\n# honeslty I didn't need the visuals as I saw the count frequency of the folder, but hey it won't bite","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-21T13:29:25.440727Z","iopub.execute_input":"2022-01-21T13:29:25.441148Z","iopub.status.idle":"2022-01-21T13:29:25.940402Z","shell.execute_reply.started":"2022-01-21T13:29:25.441103Z","shell.execute_reply":"2022-01-21T13:29:25.93942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SHOWING SOME RANDOM IMAGES\nimport random\nimport matplotlib.image as mpimg\n\nsigns = data_df[target_col].unique().tolist()\nimages = []\nprint(f'total number of unique traget : {len(signs)}')\nno_of_samples = 5\nrandom_signs = random.choices(signs, k=no_of_samples)\nfor sign in random_signs:\n    rows = data_df[data_df[target_col]==sign]['path']\n    #print(rows)\n    filepath = random.choice(list(rows))\n    #print(filepath)\n    img = mpimg.imread(filepath)\n    plt.figure()\n    plt.title(sign)\n    plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:25.94226Z","iopub.execute_input":"2022-01-21T13:29:25.942778Z","iopub.status.idle":"2022-01-21T13:29:27.628543Z","shell.execute_reply.started":"2022-01-21T13:29:25.942732Z","shell.execute_reply":"2022-01-21T13:29:27.627359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data Prepocessing\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#ENCODING LABEL to 0,1,2,3,4,5,6, etc..\n# parameters\nx_col = 'path'\ny_col = 'Pawpularity'\ntest_size = 0.2\n# NO NEED TO DO SPLITTIN< JUST EVALUATE ON THE TEST SAMPLE PROVIDED. LAST YEAR SHOULD BE MAPPED FROM 0 to 100.\n\n#splitting data ..................\ntrain_df, test_df = train_test_split(data_df, test_size= test_size, random_state=seed, stratify=data_df[[y_col]])\nprint(f'train size : {len(train_df)}')\nprint(f'test size : {len(test_df)}')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:27.630344Z","iopub.execute_input":"2022-01-21T13:29:27.630953Z","iopub.status.idle":"2022-01-21T13:29:28.374634Z","shell.execute_reply.started":"2022-01-21T13:29:27.630909Z","shell.execute_reply":"2022-01-21T13:29:28.373567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATING DATA GENERATORS\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# for efficentNetB0 input is 224\n# for B2 260\n\nimg_width, img_height = 300, 300\nbatch_size = 32\nno_of_classes = 1\n\n# NO AUGMENTAION, JUST NRORMALIZING THE DATA\n# TRAINING GENERATOR\n# WITH AUGMENTAIONS\ntrain_datagen = ImageDataGenerator(preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True,\n                                   vertical_flip = True,\n                                   fill_mode = 'nearest'\n                                  )\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,x_col=x_col, y_col=y_col,\n    target_size=(img_width, img_height),\n    class_mode='raw',\n    batch_size=batch_size,\n    seed=seed,\n    shuffle=True,\n)\n\n# TESTING GENERATOR\nvalidation_datagen = ImageDataGenerator(preprocessing_function = tf.keras.applications.efficientnet.preprocess_input)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    dataframe=test_df, x_col=x_col, y_col=y_col,\n    target_size=(img_width, img_height),\n    class_mode='raw',\n    batch_size=batch_size,\n    seed=seed,\n    shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:28.376533Z","iopub.execute_input":"2022-01-21T13:29:28.376915Z","iopub.status.idle":"2022-01-21T13:29:32.73766Z","shell.execute_reply.started":"2022-01-21T13:29:28.376854Z","shell.execute_reply":"2022-01-21T13:29:32.736739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Modeling","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n#from keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB3\n\n# I FEEL LIKE THE DROPOUT IS A BIT LARGE\ndef create_model():\n    model = Sequential()\n    # initialize the model with input shape\n    model.add(\n        EfficientNetB3(\n            input_shape = (img_width, img_height, 3), \n            include_top = False,\n            weights='imagenet',\n            drop_connect_rate=0.6,\n        )\n    )\n    model.add(GlobalAveragePooling2D())\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n    model.add(Dropout(0.5))\n    model.add(Dense(no_of_classes))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:32.741964Z","iopub.execute_input":"2022-01-21T13:29:32.742209Z","iopub.status.idle":"2022-01-21T13:29:32.759093Z","shell.execute_reply.started":"2022-01-21T13:29:32.74218Z","shell.execute_reply":"2022-01-21T13:29:32.758127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #import keras\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Dense, Flatten, BatchNormalization, Dropout, Input\n\n# # SIMPLE MODEL \n# model = Sequential()\n\n# # model.add(Conv2D(32, (5, 5), input_shape=(img_width, img_height, 3)))\n\n# # model.add(BatchNormalization())\n# # model.add(Activation('relu'))\n# # model.add(MaxPooling2D((2, 2)))\n# # model.add(Dropout(0.4))\n\n# # model.add(Conv2D(64, (3, 3)))\n# # model.add(BatchNormalization())\n# # model.add(Activation('relu'))\n# # model.add(MaxPooling2D((2, 2)))\n# # model.add(Dropout(0.4))\n\n# # model.add(Conv2D(64, (3, 3)))\n# # model.add(BatchNormalization())\n# # model.add(Activation('relu'))\n# # model.add(MaxPooling2D((2, 2)))\n# # model.add(Dropout(0.4))\n\n# # model.add(Flatten())\n\n# # model.add(Dense(512, activation='relu'))\n\n# # model.add(Dense(no_of_classes))\n\n# # EFFICENT NET SOLUTION\n# # Importing EfficientNets pretrained model\n# # MODEL ONE \n# img_mod = \"/kaggle/input/keras-applications-models/EfficientNetB0.h5\"\n# efnet_model = tf.keras.models.load_model(img_mod)\n# efnet_model.trainable = False\n\n# model = Sequential()\n\n# model.add(Input(shape=(img_width, img_height, 3)))\n# model.add(efnet_model)\n# # OUTPUT OF EFNET is 1280 \n# model.add(BatchNormalization())\n# model.add(Dropout(0.2))          \n# model.add(Dense(128, activation='relu'))\n# model.add(Dense(no_of_classes))\n# ##############################\n\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:32.761095Z","iopub.execute_input":"2022-01-21T13:29:32.761695Z","iopub.status.idle":"2022-01-21T13:29:32.782288Z","shell.execute_reply.started":"2022-01-21T13:29:32.761646Z","shell.execute_reply":"2022-01-21T13:29:32.78119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_model().summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:32.786251Z","iopub.execute_input":"2022-01-21T13:29:32.786974Z","iopub.status.idle":"2022-01-21T13:29:39.211036Z","shell.execute_reply.started":"2022-01-21T13:29:32.78694Z","shell.execute_reply":"2022-01-21T13:29:39.209836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.utils import plot_model\n# plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:39.212357Z","iopub.execute_input":"2022-01-21T13:29:39.212896Z","iopub.status.idle":"2022-01-21T13:29:39.21921Z","shell.execute_reply.started":"2022-01-21T13:29:39.212824Z","shell.execute_reply":"2022-01-21T13:29:39.217489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# OERFORMING EARLY STOPS \n\ndef compile_model(model):\n    # put model trackers\n    model.compile(optimizer='adam',\n                  loss='mse',\n                  metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:39.220362Z","iopub.execute_input":"2022-01-21T13:29:39.220713Z","iopub.status.idle":"2022-01-21T13:29:39.237545Z","shell.execute_reply.started":"2022-01-21T13:29:39.220668Z","shell.execute_reply":"2022-01-21T13:29:39.23617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n\nfrom tensorflow.compat.v1.keras import backend as K\nK.set_session(sess)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:39.239332Z","iopub.execute_input":"2022-01-21T13:29:39.24027Z","iopub.status.idle":"2022-01-21T13:29:39.778591Z","shell.execute_reply.started":"2022-01-21T13:29:39.240223Z","shell.execute_reply":"2022-01-21T13:29:39.777488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## K-FOLDING\n\nfrom sklearn.model_selection import StratifiedKFold\n#### STRAIFY LABEL CUT TO 20 PIECES\nQ = 20\ndata_df['stratify_label'] = pd.qcut(data_df['Pawpularity'], q = Q, labels = range(Q))\n########################################################################################\n# NO OF FOLDS\n# NOF O EPCOSH\nk_folds = 5\nepochs = 50\nkfold = StratifiedKFold(n_splits = k_folds, shuffle = True, random_state = seed)\nkfold_splits = kfold.split(data_df.index, data_df['stratify_label'])\n\nhistory_objs = []\ncurrent_time = get_current_time()\nfor fold, (train_index, val_index) in enumerate(kfold_splits):\n    # CREATE MODEL, MAYBE IT RESET WEIGHTS?\n    # CREATE THE MODEL FROM SCRATCH AND COMPILE IT EACH FOLD\n    model = create_model()\n    model = compile_model(model)\n    train_df = data_df.loc[train_index].reset_index()\n    test_df = data_df.loc[val_index].reset_index()\n    # GENERATE THE DATA\n    train_generator = train_datagen.flow_from_dataframe(\n        dataframe=train_df,x_col=x_col, y_col=y_col,\n        target_size=(img_width, img_height),class_mode='raw', batch_size=batch_size,\n        shuffle=False,\n    )\n    validation_generator = validation_datagen.flow_from_dataframe(\n        dataframe=test_df, x_col=x_col, y_col=y_col,\n        target_size=(img_width, img_height), class_mode='raw', batch_size=batch_size,\n        shuffle=False\n    )\n    \n    # MAKE THE CHECKPOINTS\n    early_stop = EarlyStopping(patience=10, monitor='val_mae', restore_best_weights=True)\n    ckpt = ModelCheckpoint(f'feature_model_{fold}_{current_time}.h5',\n                                          verbose = 1, \n                                          monitor = 'val_mae',\n                                          mode = 'min', \n                                          save_weights_only = True,\n                                          save_best_only = True)\n    with tf.device('/GPU:0'):\n        history = model.fit(train_generator,\n                            epochs=epochs,\n                            verbose=1,\n                            validation_data=validation_generator,\n                            callbacks = [early_stop, ckpt]\n                           )\n        history_objs.append(history)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:29:39.780308Z","iopub.execute_input":"2022-01-21T13:29:39.780593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # TRAINNING\n\n# epochs = 50\n# history = model.fit(train_generator,\n#                     epochs=epochs,\n#                     verbose=1,\n#                     validation_data=validation_generator,\n#                     callbacks = [early_stop]\n#                    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The model metrics are\")\nfor idx, history in enumerate(history_objs):\n    print(idx)\n    metrics = pd.DataFrame(history.history)\n    display(metrics)\n    print('==========================================================')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, history in enumerate(history_objs):\n    print(idx)\n    acc=history.history['rmse']\n    val_acc=history.history['val_rmse']\n    loss=history.history['loss']\n    val_loss=history.history['val_loss']\n\n    epochs=range(len(acc))\n\n    fig = plt.figure(figsize=(14,7))\n    plt.plot(epochs, acc, 'r', label=\"Training RMSE\")\n    plt.plot(epochs, val_acc, 'b', label=\"Validation RMSE\")\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Training and validation RMSE')\n    plt.legend(loc='lower right')\n    plt.show()\n    fig = plt.figure(figsize=(14,7))\n    plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n    plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n    plt.legend(loc='upper right')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and validation loss')\n    plt.show()\n    print('=====================================================================================================')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Predictions","metadata":{}},{"cell_type":"code","source":"# #Preparing data in dataframe for easier data handling\n# test_file = '../input/petfinder-pawpularity-score/test.csv'\n# test_df = pd.read_csv(test_file)\n# test_df['path'] = test_df['Id'].map(lambda x: str(folder_path+'/test/'+x)+'.jpg')\n# #train_df = train_df.drop(columns=['Id'])\n# #train_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n# test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_datagen = ImageDataGenerator(rescale=1./255)\n# train_generator = test_datagen.flow_from_dataframe(\n#     dataframe=test_df, x_col=x_col,\n#     target_size=(img_width, img_height),class_mode=None,\n#     #validate_filenames=False,\n#     shuffle=False) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predictions = model.predict(train_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result_df = pd.DataFrame()\n# result_df['Id'] = test_df['Id']\n# result_df['Pawpularity'] = predictions\n# result_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}