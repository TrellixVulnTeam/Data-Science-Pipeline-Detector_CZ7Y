{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null 2>&1\n!python pytorch-xla-env-setup.py --version 20210331 --apt-packages libomp5 libopenblas-dev > /dev/null 2>&1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-05T12:46:46.591468Z","iopub.execute_input":"2021-10-05T12:46:46.592157Z","iopub.status.idle":"2021-10-05T12:47:49.588475Z","shell.execute_reply.started":"2021-10-05T12:46:46.592053Z","shell.execute_reply":"2021-10-05T12:47:49.586753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/timm-pytorch-image-models/pytorch-image-models-master/\")\n\nimport platform\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm.notebook import tqdm\nimport cv2\nimport random\nimport glob\nimport gc\nfrom math import ceil\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\nfrom skimage.exposure import exposure, equalize_hist,equalize_adapthist\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport torch\nimport timm\nimport time\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR, StepLR\nimport torch_xla\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.utils as xu\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.test.test_utils as test_utils\nimport warnings\n\nwarnings.simplefilter('ignore')\nnp.set_printoptions(suppress=True)\nos.environ['XLA_USE_BF16']=\"1\"\nos.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:49.59175Z","iopub.execute_input":"2021-10-05T12:47:49.591975Z","iopub.status.idle":"2021-10-05T12:47:54.968837Z","shell.execute_reply.started":"2021-10-05T12:47:49.591944Z","shell.execute_reply":"2021-10-05T12:47:54.967711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.autograd import Variable\n\nclass bceFocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n        \n    def forward(self, input, target, reduction='mean'):\n        n = input.shape[-1]\n        input = input.view(-1).float()\n        target = target.view(-1).float()\n        loss = -target*F.logsigmoid(input)*torch.exp(self.gamma*F.logsigmoid(-input)) -\\\n           (1.0 - target)*F.logsigmoid(-input)*torch.exp(self.gamma*F.logsigmoid(input))\n        \n        return n*loss.mean() if reduction=='mean' else loss\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=0, alpha=None, size_average=True):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n        self.size_average = size_average\n\n    def forward(self, input, target):\n        if input.dim()>2:\n            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n        target = target.view(-1,1)\n\n        logpt = F.log_softmax(input)\n        logpt = logpt.gather(1,target)\n        logpt = logpt.view(-1)\n        pt = Variable(logpt.data.exp())\n\n        if self.alpha is not None:\n            if self.alpha.type()!=input.data.type():\n                self.alpha = self.alpha.type_as(input.data)\n            at = self.alpha.gather(0,target.data.view(-1))\n            logpt = logpt * Variable(at)\n\n        loss = -1 * (1-pt)**self.gamma * logpt\n        if self.size_average: return loss.mean()\n        else: return loss.sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:54.970065Z","iopub.execute_input":"2021-10-05T12:47:54.970292Z","iopub.status.idle":"2021-10-05T12:47:54.988331Z","shell.execute_reply.started":"2021-10-05T12:47:54.970265Z","shell.execute_reply":"2021-10-05T12:47:54.987482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    image_size = 384\n    batch_size = 8*8\n    epochs = 15\n    seed = 2021\n    lr = 5e-5 / 8  \n    workers = 8\n    drop_last = True\n    \n    def get_loss_fn():\n        #return nn.CrossEntropyLoss()\n        return nn.MSELoss()\n        #return FocalLoss(gamma=1.5)\n\n    def get_optimizer(model, learning_rate):\n        return torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n    def get_scheduler(optimizer):\n        return ReduceLROnPlateau(optimizer, \n                                 mode='min', \n                                 factor=0.5, \n                                 patience=3, \n                                 threshold=0.0001,\n                                 verbose=False, \n                                 min_lr=1e-6,\n                                 eps=1e-08)\n    \n\n# Make results reproducible\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(Config.seed)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:54.989492Z","iopub.execute_input":"2021-10-05T12:47:54.989737Z","iopub.status.idle":"2021-10-05T12:47:55.003681Z","shell.execute_reply.started":"2021-10-05T12:47:54.989712Z","shell.execute_reply":"2021-10-05T12:47:55.002733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/simple-eda-using-pandas-profiling/train.csv\",index_col=0)\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:55.006143Z","iopub.execute_input":"2021-10-05T12:47:55.006472Z","iopub.status.idle":"2021-10-05T12:47:55.138586Z","shell.execute_reply.started":"2021-10-05T12:47:55.00644Z","shell.execute_reply":"2021-10-05T12:47:55.137788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# check shape\n\n512,768,1024","metadata":{}},{"cell_type":"code","source":"classes = train.columns[1:13]\ncategory_name_to_id = {index:class_name for index, class_name in enumerate(classes)}\nlen(category_name_to_id)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:55.139885Z","iopub.execute_input":"2021-10-05T12:47:55.140089Z","iopub.status.idle":"2021-10-05T12:47:55.147059Z","shell.execute_reply.started":"2021-10-05T12:47:55.140066Z","shell.execute_reply":"2021-10-05T12:47:55.146351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose(\n            [\n             A.RandomSizedCrop(\n                         min_max_height=[int(0.95*Config.image_size), int(1.0*Config.image_size)],\n                         height=Config.image_size,\n                         width=Config.image_size, \n                         p=1.0),\n                      \n              #A.HorizontalFlip(p=0.5),\n              #A.VerticalFlip(p=0.5),\n              A.Rotate(\n                    limit=5,\n                    p=0.6,\n                ),              \n            ])","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:55.148084Z","iopub.execute_input":"2021-10-05T12:47:55.148286Z","iopub.status.idle":"2021-10-05T12:47:55.157142Z","shell.execute_reply.started":"2021-10-05T12:47:55.148263Z","shell.execute_reply":"2021-10-05T12:47:55.156475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class inputds(Dataset):\n    def __init__(self, df, augments=True):\n        super().__init__()\n        self.df = df.sample(frac=1).reset_index(drop=True)\n        if augments:\n          self.augments = get_train_transforms()\n        else:\n          self.augments = None\n\n        \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        index = row.Id\n        imagepad = cv2.imread(f\"../input/petfinder-imgds/image_size{Config.image_size}/image_size{Config.image_size}/{index}.jpg\", cv2.IMREAD_COLOR)\n        h,w,c= imagepad.shape\n        image = np.zeros((Config.image_size,Config.image_size,3))\n        if h > w:\n          x = h\n          y = random.randint(0,Config.image_size-w)\n          image[0:x,y:y+w] = imagepad\n        else:\n          x = random.randint(0,Config.image_size-h)\n          y = w\n          image[x:x+h,0:y] = imagepad\n\n\n        #image = cv2.resize(image,(384,224))\n        #if self.augments:\n        #image = self.augments(image=image)[\"image\"]\n        image = torch.tensor(image/255.0,dtype=torch.float)\n        image = image.permute(2, 0, 1)\n        labels = np.array([row[category_name_to_id[i]] for i in range(12)])\n        score = row.Pawpularity/100\n\n        return image, labels, score\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:55.158525Z","iopub.execute_input":"2021-10-05T12:47:55.158928Z","iopub.status.idle":"2021-10-05T12:47:55.17148Z","shell.execute_reply.started":"2021-10-05T12:47:55.158896Z","shell.execute_reply":"2021-10-05T12:47:55.170747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nds =  inputds(train,augments=True)\nfor i,(image,labels, score) in enumerate(ds):\n    print(image.shape,labels.shape,score)\n    plt.imshow(image.permute(1,2,0))\n    plt.show()\n    if i==20:\n        break\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:55.172696Z","iopub.execute_input":"2021-10-05T12:47:55.172901Z","iopub.status.idle":"2021-10-05T12:47:55.185981Z","shell.execute_reply.started":"2021-10-05T12:47:55.172878Z","shell.execute_reply":"2021-10-05T12:47:55.185228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\nRANDOM_STATE = 35\n\nkfold = KFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\n#skfold = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\nsplits= kfold.split(train)\ntrain_indexs = []\ntest_indexs = []\nfor i,(train_index, test_index) in enumerate(splits):\n    print(train_index.shape,test_index.shape)\n    train_indexs.append(train_index)\n    test_indexs.append(test_index)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:55.187021Z","iopub.execute_input":"2021-10-05T12:47:55.187347Z","iopub.status.idle":"2021-10-05T12:47:55.204565Z","shell.execute_reply.started":"2021-10-05T12:47:55.187304Z","shell.execute_reply":"2021-10-05T12:47:55.203551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from timm.models.efficientnet import *\nclass Net0(nn.Module):\n    def __init__(self):\n        super(Net0, self).__init__()\n\n        self.eff = tf_efficientnet_b3(pretrained=True, drop_rate=0.3, drop_path_rate=0.2,in_chans=3)\n\n        self.rlogit = nn.Linear(1000,128)\n        self.dropout = nn.Dropout(0.1)\n        self.fc1 = nn.Linear(140,64)\n        self.fc2 = nn.Linear(64,1)\n\n    # @torch.cuda.amp.autocast()\n    def forward(self, image, dense):\n        #batch_size = len(image)\n        x = image\n\n        x = self.eff(x)  \n        x = self.dropout(x)\n        x = self.rlogit(x)\n        x = torch.cat([x, dense], dim=1)\n        x = self.fc1(x)\n        score = self.fc2(x)\n        \n        return score","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:55.205965Z","iopub.execute_input":"2021-10-05T12:47:55.20624Z","iopub.status.idle":"2021-10-05T12:47:55.216246Z","shell.execute_reply.started":"2021-10-05T12:47:55.206205Z","shell.execute_reply":"2021-10-05T12:47:55.215389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install torchsummary\n#from torchsummary import summary\n#summary(Net0(),(3,384,384))\nmodel_=Net0()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:55.217702Z","iopub.execute_input":"2021-10-05T12:47:55.217927Z","iopub.status.idle":"2021-10-05T12:47:57.184976Z","shell.execute_reply.started":"2021-10-05T12:47:55.217899Z","shell.execute_reply":"2021-10-05T12:47:57.184202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Record:\n    '''\n    Records labels and predictions within one epoch\n    '''\n    def __init__(self):\n        self.labels = []\n        self.preds = []\n        \n    def update(self, cur_labels, cur_logits):\n        cur_labels = cur_labels.detach().cpu().numpy()\n        cur_logits = cur_logits.sigmoid().detach().cpu().numpy()\n        #cur_logits = np.exp(cur_logits.detach().cpu().numpy())\n        #cur_preds = cur_logits / np.sum(cur_logits, axis=1, keepdims=True)\n        self.labels.append(cur_labels)\n        self.preds.append(cur_logits)\n\n    def get_labels(self):\n        return np.concatenate(self.labels) # (n, )\n\n    def get_preds(self):\n        return np.concatenate(self.preds, axis=0) # (n, 4)\n    \n    @staticmethod\n    def get_acc(confusion_mat):\n        return round(np.sum(np.eye(4) * confusion_mat) / np.sum(confusion_mat) * 100, 2)\n\n    @staticmethod\n    def get_rmse(preds,labels):\n        return np.sqrt(mean_squared_error(preds*100, labels*100))","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:57.186272Z","iopub.execute_input":"2021-10-05T12:47:57.186496Z","iopub.status.idle":"2021-10-05T12:47:57.195874Z","shell.execute_reply.started":"2021-10-05T12:47:57.186471Z","shell.execute_reply":"2021-10-05T12:47:57.195254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, optimizer, loss_fn, maskloss_fn, device):\n        \"\"\"\n        Constructor for Trainer class\n        \"\"\"\n        self.model = model\n        self.optimizer = optimizer\n        self.loss_fn = loss_fn\n        self.maskloss_fn = maskloss_fn\n        self.device = device\n    \n    def train_one_cycle(self, train_loader):\n        \"\"\"\n        Runs one epoch of training, backpropagation and optimization\n        \"\"\"\n        self.model.train()\n        total_loss = 0\n        total_nums = 0\n        #record = Record()\n\n        for idx, (xtrain, xlabel, ys) in enumerate(train_loader):\n            xtrain = xtrain.to(self.device, dtype=torch.float)\n            xlabel = xlabel.to(self.device, dtype=torch.float)\n            ys = ys.to(self.device, dtype=torch.float)\n            \n\n            self.optimizer.zero_grad()\n            preds = self.model(xtrain,xlabel)\n            loss1 = self.loss_fn(preds[:,0], ys)\n            loss = torch.sqrt(loss1)\n            \n            total_loss += (loss.detach().item() * ys.size(0))\n            total_nums += ys.size(0)\n            \n            loss.backward()\n            del loss\n            xm.optimizer_step(self.optimizer)\n            \n        self.model.eval()\n        return total_loss / total_nums\n\n    def valid_one_cycle(self, valid_loader):\n        \"\"\"\n        Runs one epoch of prediction\n        \"\"\"\n        self.model.eval()\n        total_loss = 0\n        total_nums = 0\n        record = Record()\n        \n        for idx, (xval, xlabel, ys) in enumerate(valid_loader):\n            with torch.no_grad():\n                xval = xval.to(self.device, dtype=torch.float)\n                xlabel = xlabel.to(self.device, dtype=torch.float)\n                ys = ys.to(self.device, dtype=torch.float)\n\n                pred = self.model(xval,xlabel)\n                record.update(ys, pred)\n\n        return record.get_labels(), record.get_preds()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:57.198545Z","iopub.execute_input":"2021-10-05T12:47:57.198793Z","iopub.status.idle":"2021-10-05T12:47:57.214065Z","shell.execute_reply.started":"2021-10-05T12:47:57.198764Z","shell.execute_reply":"2021-10-05T12:47:57.213219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _mp_fn(rank, flags):\n    '''\n    Train and valid\n    '''\n    torch.set_default_tensor_type('torch.FloatTensor')\n\n    # Sets a common random seed both for initialization and ensuring graph is the same\n    torch.manual_seed(Config.seed)\n\n    # Acquires the (unique) Cloud TPU core corresponding to this process's index\n    device = xm.xla_device()\n    \n    # load the model into each tpu core\n    model = model_.to(device)\n    \n    # Creates the (distributed) train sampler\n    # which let this process only access its portion of the training dataset.  \n    train_sampler = DistributedSampler(\n        train_set,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True,\n    )\n    train_loader = DataLoader(\n        train_set,\n        batch_size=int(Config.batch_size/xm.xrt_world_size()),\n        sampler=train_sampler,\n        drop_last=Config.drop_last,\n        num_workers=Config.workers,\n    )\n    valid_sampler = DistributedSampler(\n        valid_set,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False,\n    )\n    valid_loader = DataLoader(\n        valid_set,\n        batch_size=int(Config.batch_size/xm.xrt_world_size()),\n        sampler=valid_sampler,\n        drop_last=Config.drop_last,\n        num_workers=Config.workers,\n    )\n\n    optimizer = Config.get_optimizer(model, Config.lr * xm.xrt_world_size())\n    #loss_fn = Config.get_loss_fn()\n    loss_fn = nn.BCEWithLogitsLoss()\n    maskloss_fn = bceFocalLoss(gamma=1.5)\n    #maskloss_fn = nn.BCEWithLogitsLoss()\n                               \n    scheduler = Config.get_scheduler(optimizer)\n    \n    trainer = Trainer(\n        model=model,\n        optimizer=optimizer,\n        loss_fn=loss_fn,\n        maskloss_fn = maskloss_fn,\n        device=device,\n    )\n\n    \n    for epoch in range(Config.epochs):\n        xm.master_print(f\"{'-'*30} EPOCH: {epoch+1}/{Config.epochs} {'-'*30}\")\n        \n        # Run one training epoch\n        para_loader = pl.ParallelLoader(train_loader, [device])\n        train_loss = trainer.train_one_cycle(para_loader.per_device_loader(device))\n\n        # Compute training metrics\n        train_loss_avg = xm.mesh_reduce('train_loss_reduce', train_loss, lambda alist: sum(alist) / len(alist))\n        xm.master_print(f\"Train Loss: {train_loss_avg:.4f}\")\n        \n\n        # Run one validation epoch\n        para_loader = pl.ParallelLoader(valid_loader, [device])\n        valid_labels, valid_preds = trainer.valid_one_cycle(para_loader.per_device_loader(device))\n        \n        valid_labels_concat = xm.mesh_reduce('valid_labels_concat', valid_labels, lambda alist: np.concatenate(alist))\n        valid_preds_concat = xm.mesh_reduce('valid_preds_concat', valid_preds, lambda alist: np.concatenate(alist, axis=0))\n        valid_loss_avg = Record.get_rmse(valid_preds_concat,valid_labels_concat)\n        xm.master_print(f\"Valid Loss: {valid_loss_avg:.4f}\")\n        savename = f\"pretrained_model_{flags['fold']}_{valid_loss_avg}.bin\"\n        xm.master_print(f\"saveweight:{savename}\")\n        xm.save(model.state_dict(),savename)\n        if rank == 0:\n          for path in sorted(glob.glob(f\"pretrained_model_{flags['fold']}_*.bin\"))[2:]:\n            os.remove(path)\n        \n\n        scheduler.step(valid_loss_avg/100)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:47:57.215564Z","iopub.execute_input":"2021-10-05T12:47:57.215815Z","iopub.status.idle":"2021-10-05T12:47:57.235289Z","shell.execute_reply.started":"2021-10-05T12:47:57.215789Z","shell.execute_reply":"2021-10-05T12:47:57.234677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\nfor i in range(5):\n    FLAGS = {}\n    FLAGS['fold'] = i\n    fold = i\n    train_data, valid_data = train.iloc[train_indexs[fold],:],train.iloc[test_indexs[fold],:]\n    print(f\"fold:{fold},Training on {train_data.shape[0]} samples and Validation on {valid_data.shape[0]} samples\")\n\n    train_set = inputds(df=train_data, augments=True)\n    valid_set = inputds(df=valid_data, augments=False)\n    xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')\n    #break","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:56:24.31248Z","iopub.execute_input":"2021-10-05T12:56:24.31279Z","iopub.status.idle":"2021-10-05T13:37:19.371749Z","shell.execute_reply.started":"2021-10-05T12:56:24.312756Z","shell.execute_reply":"2021-10-05T13:37:19.370314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}