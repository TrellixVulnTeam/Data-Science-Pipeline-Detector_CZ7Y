{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Let's use SBER AutoML lib \n> Only for this you can give me an upvote ðŸŒŸ \n\n> And feel free to comment your opinion and anything you want :) \n\n> This will motivate me to do more experiments :)","metadata":{}},{"cell_type":"markdown","source":"# ChangeLog\n* v1 - install, import, quick EDA, train, predict, submit, Error with offline lib\n* v2 - changed offline lib \n* v3 - forget to pip install offline packages\n* v4 - look for duplicates in image and pawpularity\n* v5 - added meta features from [here](https://www.kaggle.com/nexus6roy/extract-extra-data-from-image) and remove duplicates taken from [here](https://www.kaggle.com/yingpengchen/find-duplicate-images)\n* v6 - hide large output, remove meta features, change the print from previous notebook","metadata":{}},{"cell_type":"code","source":"# if we have internet connection\n#!pip install lightautoml -q\n\n# else\n!tar xvfz ../input/lightautoml-tar/lightautoml.tgz > /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-16T08:59:01.908663Z","iopub.execute_input":"2021-11-16T08:59:01.909414Z","iopub.status.idle":"2021-11-16T08:59:25.054567Z","shell.execute_reply.started":"2021-11-16T08:59:01.909313Z","shell.execute_reply":"2021-11-16T08:59:25.051894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Install the offline packages into our kernel\n!pip install lightautoml --no-index --find-links=file:./lightautoml/  -q","metadata":{"execution":{"iopub.status.busy":"2021-11-16T08:59:25.060084Z","iopub.execute_input":"2021-11-16T08:59:25.060467Z","iopub.status.idle":"2021-11-16T08:59:45.006741Z","shell.execute_reply.started":"2021-11-16T08:59:25.060414Z","shell.execute_reply":"2021-11-16T08:59:45.005632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standard libs","metadata":{}},{"cell_type":"code","source":"# Standard python libraries\nimport os\nimport time\nimport re\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Imports from LightAutoML package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.tasks import Task\nfrom pandas_profiling import ProfileReport\n\nimport cv2\nimport datetime\nimport gc\nimport glob\nimport imagehash\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport sys\nimport tqdm\nimport PIL\nfrom keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2021-11-16T08:59:45.008647Z","iopub.execute_input":"2021-11-16T08:59:45.008928Z","iopub.status.idle":"2021-11-16T09:00:00.437408Z","shell.execute_reply.started":"2021-11-16T08:59:45.008884Z","shell.execute_reply":"2021-11-16T09:00:00.436508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '../input/petfinder-pawpularity-score/'\ntrain_data = pd.read_csv(DATA_DIR + 'train.csv')\ntest_data = pd.read_csv(DATA_DIR + 'test.csv')\nsample_submission = pd.read_csv(DATA_DIR + 'sample_submission.csv')\nsubmission = pd.read_csv(DATA_DIR+'sample_submission.csv')\n\nX_test = test_data.values","metadata":{"execution":{"iopub.status.busy":"2021-11-16T09:00:00.439598Z","iopub.execute_input":"2021-11-16T09:00:00.439865Z","iopub.status.idle":"2021-11-16T09:00:00.515304Z","shell.execute_reply.started":"2021-11-16T09:00:00.439837Z","shell.execute_reply":"2021-11-16T09:00:00.514438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Look for Duplicates and remove\n> [Thanks to](https://www.kaggle.com/yingpengchen/find-duplicate-images)","metadata":{}},{"cell_type":"code","source":"def images_find_duplicates(image_files, threshold=0.9):\n    \"\"\"\n    Function to find duplicates in images.\n    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash\n    Args:\n        image_files:\n        threshold:\n\n    Returns:\n\n    \"\"\"\n    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]\n    image_ids = image_files\n    hashes = []\n    for file in tqdm.tqdm(image_files):\n        image = PIL.Image.open(file)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n    hashes_all = np.array(hashes)\n\n    # Comparisons without Pytorch\n    sim_list = []\n    for i in tqdm.tqdm(range(hashes_all.shape[0])):\n        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)\n\n    # nxn-matrix of similarities (n = # of images), upper triangular matrix\n    similarities = np.triu(np.array(sim_list), 1)\n\n    idx_pair = np.where(similarities > threshold)\n    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],\n                             'image2': [image_ids[i] for i in list(idx_pair[1])],\n                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})\n\n    idx_group = np.zeros(len(image_files))\n    group_id = 1\n    for i1, i2 in zip(idx_pair[0], idx_pair[1]):\n        if idx_group[i1] == 0 and idx_group[i2] == 0:\n            idx_group[i1] = group_id\n            idx_group[i2] = group_id\n            group_id += 1\n        elif idx_group[i1] != 0 and idx_group[i2] == 0:\n            idx_group[i2] = idx_group[i1]\n        elif idx_group[i1] == 0 and idx_group[i2] != 0:\n            idx_group[i1] = idx_group[i2]\n        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:\n            common_id = min(idx_group[i1], idx_group[i2])\n            idx_group[idx_group == idx_group[i1]] = common_id\n            idx_group[idx_group == idx_group[i2]] = common_id\n\n    group_list = []\n    for i in range(1, group_id + 1):\n        group_ids = list(np.where(idx_group == i)[0])\n        if len(group_ids) > 0:\n            group_list.append([image_ids[j] for j in group_ids])\n\n    return df_pairs, group_list","metadata":{"execution":{"iopub.status.busy":"2021-11-16T05:05:15.206867Z","iopub.execute_input":"2021-11-16T05:05:15.207256Z","iopub.status.idle":"2021-11-16T05:05:15.227624Z","shell.execute_reply.started":"2021-11-16T05:05:15.207227Z","shell.execute_reply":"2021-11-16T05:05:15.226874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files = []\nfor image in train_data['Id']:\n    image_path = f'{DATA_DIR}/train/{image}.jpg'\n    train_files.append(image_path)\nprint(f'Number of Petfinder training files: {len(train_files)}')\n\ntotal_files = []\ntotal_files.extend(train_files)\n\ndf_pairs, group_list = images_find_duplicates(total_files, threshold=0.90)\n\nprint(f'\\nNumber of duplicate pairs: {len(df_pairs)}')\n\nids_to_delete = []\nfor path1,path2 in zip(df_pairs['image1'],df_pairs['image2']):\n    image_id1 = path1.split('/')[-1].split('.')[0]\n    \n    #print(train_data[train_data.Id == image_id1])\n    ids_to_delete.append(image_id1)\nprint(\"Size of DF before deleting duplicates\",len(train_data))\n\nids_to_delete = list(set(ids_to_delete))\nprint(\"Duplicates count = \", len(ids_to_delete))\n\nfor ids in ids_to_delete:\n    train_data = train_data[train_data.Id != ids]\nprint(\"Size of DF after removing Duplicates\",len(train_data))","metadata":{"execution":{"iopub.status.busy":"2021-11-16T05:05:15.229214Z","iopub.execute_input":"2021-11-16T05:05:15.229664Z","iopub.status.idle":"2021-11-16T05:16:31.487133Z","shell.execute_reply.started":"2021-11-16T05:05:15.229616Z","shell.execute_reply":"2021-11-16T05:16:31.486216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Quick EDA","metadata":{}},{"cell_type":"code","source":"%%time\nprofile = ProfileReport(train_data, title=\"Pandas Profiling Report\")\nprofile","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profile.to_file(\"PetFinder Meta features.html\")","metadata":{"execution":{"iopub.status.busy":"2021-11-16T04:57:48.007531Z","iopub.execute_input":"2021-11-16T04:57:48.007892Z","iopub.status.idle":"2021-11-16T04:57:48.075679Z","shell.execute_reply.started":"2021-11-16T04:57:48.007858Z","shell.execute_reply":"2021-11-16T04:57:48.074663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T05:16:48.240631Z","iopub.execute_input":"2021-11-16T05:16:48.241411Z","iopub.status.idle":"2021-11-16T05:16:48.264224Z","shell.execute_reply.started":"2021-11-16T05:16:48.241356Z","shell.execute_reply":"2021-11-16T05:16:48.263054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_data.Pawpularity.values\nX = train_data.drop(['Pawpularity'], axis=1).values","metadata":{"execution":{"iopub.status.busy":"2021-11-16T05:16:48.266544Z","iopub.execute_input":"2021-11-16T05:16:48.266909Z","iopub.status.idle":"2021-11-16T05:16:48.295213Z","shell.execute_reply.started":"2021-11-16T05:16:48.266863Z","shell.execute_reply":"2021-11-16T05:16:48.294216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spilit","metadata":{}},{"cell_type":"code","source":"%%time\n\ntr_data, valid_data = train_test_split(train_data, test_size=0.2,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T05:16:48.296984Z","iopub.execute_input":"2021-11-16T05:16:48.297323Z","iopub.status.idle":"2021-11-16T05:16:48.308647Z","shell.execute_reply.started":"2021-11-16T05:16:48.297278Z","shell.execute_reply":"2021-11-16T05:16:48.307758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Task object\n> Below this line we are ready to build the model for Price target variable prediction. First of all, we setup the type of model we need using LightAutoML Task class object, there the valid values can be:\n\n* â€˜binaryâ€™ for binary classification\n* â€˜regâ€™ for regression and\n* â€˜multiclassâ€™ for multiclass classification","metadata":{}},{"cell_type":"code","source":"task = Task('reg', metric='mse',greater_is_better=False, loss='mse')","metadata":{"execution":{"iopub.status.busy":"2021-11-16T05:16:48.310912Z","iopub.execute_input":"2021-11-16T05:16:48.311155Z","iopub.status.idle":"2021-11-16T05:16:48.318391Z","shell.execute_reply.started":"2021-11-16T05:16:48.311126Z","shell.execute_reply":"2021-11-16T05:16:48.317642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nroles = {'target': 'Pawpularity','drop': 'id','category':'format'}","metadata":{"execution":{"iopub.status.busy":"2021-11-16T05:16:48.319852Z","iopub.execute_input":"2021-11-16T05:16:48.320082Z","iopub.status.idle":"2021-11-16T05:16:48.331341Z","shell.execute_reply.started":"2021-11-16T05:16:48.320055Z","shell.execute_reply":"2021-11-16T05:16:48.330692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train of dataset\n> Now we know what model to use to receive good results on the dataset","metadata":{}},{"cell_type":"code","source":"%%time\nautoml = TabularUtilizedAutoML(task = task, \n                       timeout = 10800, # 3 hours\n                       cpu_limit = 4, # Optimal for Kaggle kernels\n                       general_params = {'use_algos': [['linear_l2', 'lgb_tuned','cb_tuned']]})","metadata":{"execution":{"iopub.status.busy":"2021-11-16T05:16:48.332599Z","iopub.execute_input":"2021-11-16T05:16:48.332881Z","iopub.status.idle":"2021-11-16T05:16:48.375092Z","shell.execute_reply.started":"2021-11-16T05:16:48.33285Z","shell.execute_reply":"2021-11-16T05:16:48.37404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\noof_pred = automl.fit_predict(tr_data, roles = roles)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T05:16:48.376693Z","iopub.execute_input":"2021-11-16T05:16:48.377135Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Valid","metadata":{}},{"cell_type":"code","source":"valid_pred = automl.predict(valid_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF score","metadata":{}},{"cell_type":"code","source":"print('OOF RMSE: {}'.format(mean_squared_error(tr_data['Pawpularity'].values, oof_pred.data[:, 0],squared=False)))\nprint('VAL RMSE: {}'.format(mean_squared_error(valid_data['Pawpularity'].values, valid_pred.data[:, 0],squared=False)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test prediction","metadata":{}},{"cell_type":"code","source":"test_pred = automl.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission['Pawpularity'] = (test_pred.data[:, 0]).astype(int)\nsubmission.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EOF","metadata":{}}]}