{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install python-box timm pytorch-lightning==1.4.0 grad-cam==1.3.1 ttach","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:30:28.400404Z","iopub.execute_input":"2022-04-27T23:30:28.400672Z","iopub.status.idle":"2022-04-27T23:30:53.428721Z","shell.execute_reply.started":"2022-04-27T23:30:28.400643Z","shell.execute_reply":"2022-04-27T23:30:53.42791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom box import Box\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\nfrom pytorch_grad_cam import GradCAMPlusPlus\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule\n\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:30:53.43163Z","iopub.execute_input":"2022-04-27T23:30:53.432452Z","iopub.status.idle":"2022-04-27T23:31:00.378492Z","shell.execute_reply.started":"2022-04-27T23:30:53.432408Z","shell.execute_reply":"2022-04-27T23:31:00.37762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"config = {'seed': 2021,\n          'root': '/kaggle/input/petfinder-pawpularity-score/', \n          'n_splits': 5,\n          'epoch': 20,\n          'trainer': {\n              'gpus': 1,\n              'accumulate_grad_batches': 1,\n              'progress_bar_refresh_rate': 1,\n              'fast_dev_run': False,\n              'num_sanity_val_steps': 0,\n              'resume_from_checkpoint': None,\n          },\n          'transform':{\n              'name': 'get_default_transforms',\n              'image_size': 224\n          },\n          'train_loader':{\n              'batch_size': 64,\n              'shuffle': True,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': True,\n          },\n          'val_loader': {\n              'batch_size': 64,\n              'shuffle': False,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': False\n         },\n          'model':{\n              'name': 'swin_tiny_patch4_window7_224',\n              'output_dim': 1\n          },\n          'optimizer':{\n              'name': 'optim.AdamW',\n              'params':{\n                  'lr': 1e-5\n              },\n          },\n          'scheduler':{\n              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n              'params':{\n                  'T_0': 20,\n                  'eta_min': 1e-4,\n              }\n          },\n          'loss': 'nn.BCEWithLogitsLoss',\n}\n\nconfig = Box(config)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T23:31:00.379773Z","iopub.execute_input":"2022-04-27T23:31:00.380048Z","iopub.status.idle":"2022-04-27T23:31:00.388763Z","shell.execute_reply.started":"2022-04-27T23:31:00.380013Z","shell.execute_reply":"2022-04-27T23:31:00.388098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pprint(config)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:31:00.390916Z","iopub.execute_input":"2022-04-27T23:31:00.391339Z","iopub.status.idle":"2022-04-27T23:31:00.420069Z","shell.execute_reply.started":"2022-04-27T23:31:00.391305Z","shell.execute_reply":"2022-04-27T23:31:00.419409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"code","source":"class PetfinderDataset(Dataset):\n    def __init__(self, df, image_size=224):\n        self._X = df[\"Id\"].values\n        self._y = None\n        if \"Pawpularity\" in df.keys():\n            self._y = df[\"Pawpularity\"].values\n        self._transform = T.Resize([image_size, image_size])\n\n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        image_path = self._X[idx]\n        image = read_image(image_path)\n        image = self._transform(image)\n        if self._y is not None:\n            label = self._y[idx]\n            return image, label\n        return image\n\nclass PetfinderDataModule(LightningDataModule):\n    def __init__(\n        self,\n        train_df,\n        val_df,\n        cfg,\n    ):\n        super().__init__()\n        self._train_df = train_df\n        self._val_df = val_df\n        self._cfg = cfg\n\n    def __create_dataset(self, train=True):\n        return (\n            PetfinderDataset(self._train_df, self._cfg.transform.image_size)\n            if train\n            else PetfinderDataset(self._val_df, self._cfg.transform.image_size)\n        )\n\n    def train_dataloader(self):\n        dataset = self.__create_dataset(True)\n        return DataLoader(dataset, **self._cfg.train_loader)\n\n    def val_dataloader(self):\n        dataset = self.__create_dataset(False)\n        return DataLoader(dataset, **self._cfg.val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:31:00.421288Z","iopub.execute_input":"2022-04-27T23:31:00.421631Z","iopub.status.idle":"2022-04-27T23:31:00.432646Z","shell.execute_reply.started":"2022-04-27T23:31:00.421599Z","shell.execute_reply":"2022-04-27T23:31:00.43195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## visualize data","metadata":{}},{"cell_type":"code","source":"torch.autograd.set_detect_anomaly(True)\nseed_everything(config.seed)\n\ndf = pd.read_csv(os.path.join(config.root, \"train.csv\"))\ndf[\"Id\"] = df[\"Id\"].apply(lambda x: os.path.join(config.root, \"train\", x + \".jpg\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:31:00.433906Z","iopub.execute_input":"2022-04-27T23:31:00.434364Z","iopub.status.idle":"2022-04-27T23:31:00.525721Z","shell.execute_reply.started":"2022-04-27T23:31:00.434328Z","shell.execute_reply":"2022-04-27T23:31:00.525065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_dataloader = PetfinderDataModule(df, df, config).val_dataloader()\nimages, labels = iter(sample_dataloader).next()\n\nplt.figure(figsize=(12, 12))\nfor it, (image, label) in enumerate(zip(images[:16], labels[:16])):\n    plt.subplot(4, 4, it+1)\n    plt.imshow(image.permute(1, 2, 0))\n    plt.axis('off')\n    plt.title(f'Pawpularity: {int(label)}')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:31:00.526967Z","iopub.execute_input":"2022-04-27T23:31:00.527366Z","iopub.status.idle":"2022-04-27T23:31:05.532527Z","shell.execute_reply.started":"2022-04-27T23:31:00.527333Z","shell.execute_reply":"2022-04-27T23:31:05.53176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## augmentation","metadata":{}},{"cell_type":"code","source":"IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\ndef get_default_transforms():\n    transform = {\n        \"train\": T.Compose(\n            [\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n        \"val\": T.Compose(\n            [\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n    }\n    return transform\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:31:05.533803Z","iopub.execute_input":"2022-04-27T23:31:05.534049Z","iopub.status.idle":"2022-04-27T23:31:05.543483Z","shell.execute_reply.started":"2022-04-27T23:31:05.534017Z","shell.execute_reply":"2022-04-27T23:31:05.542562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n    assert alpha > 0, \"alpha should be larger than 0\"\n    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n\n    lam = np.random.beta(alpha, alpha)\n    rand_index = torch.randperm(x.size()[0])\n    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n    target_a, target_b = y, y[rand_index]\n    return mixed_x, target_a, target_b, lam\n\nclass Model(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.__build_model()\n        self._criterion = eval(self.cfg.loss)()\n        self.transform = get_default_transforms()\n        self.save_hyperparameters(cfg)\n\n    def __build_model(self):\n        self.backbone = create_model(\n            self.cfg.model.name, pretrained=True, num_classes=0, in_chans=3\n        )\n        num_features = self.backbone.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)\n        )\n\n    def forward(self, x):\n        f = self.backbone(x)\n        out = self.fc(f)\n        return out\n\n    def training_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'train')\n        return {'loss': loss, 'pred': pred, 'labels': labels}\n        \n    def validation_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'val')\n        return {'pred': pred, 'labels': labels}\n    \n    def __share_step(self, batch, mode):\n        images, labels = batch\n        labels = labels.float() / 100.0\n        images = self.transform[mode](images)\n        \n        if torch.rand(1)[0] < 0.5 and mode == 'train':\n            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n            logits = self.forward(mix_images).squeeze(1)\n            loss = self._criterion(logits, target_a) * lam + \\\n                (1 - lam) * self._criterion(logits, target_b)\n        else:\n            logits = self.forward(images).squeeze(1)\n            loss = self._criterion(logits, labels)\n        \n        pred = logits.sigmoid().detach().cpu() * 100.\n        labels = labels.detach().cpu() * 100.\n        return loss, pred, labels\n        \n    def training_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'train')\n\n    def validation_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'val')    \n        \n    def __share_epoch_end(self, outputs, mode):\n        preds = []\n        labels = []\n        for out in outputs:\n            pred, label = out['pred'], out['labels']\n            preds.append(pred)\n            labels.append(label)\n        preds = torch.cat(preds)\n        labels = torch.cat(labels)\n        metrics = torch.sqrt(((labels - preds) ** 2).mean())\n        self.log(f'{mode}_loss', metrics)\n    \n    def check_gradcam(self, dataloader, target_layer, target_category, reshape_transform=None):\n        cam = GradCAMPlusPlus(\n            model=self,\n            target_layer=target_layer, \n            use_cuda=self.cfg.trainer.gpus, \n            reshape_transform=reshape_transform)\n        \n        org_images, labels = iter(dataloader).next()\n        cam.batch_size = len(org_images)\n        images = self.transform['val'](org_images)\n        images = images.to(self.device)\n        logits = self.forward(images).squeeze(1)\n        pred = logits.sigmoid().detach().cpu().numpy() * 100\n        labels = labels.cpu().numpy()\n        \n        grayscale_cam = cam(input_tensor=images, target_category=target_category, eigen_smooth=True)\n        org_images = org_images.detach().cpu().numpy().transpose(0, 2, 3, 1) / 255.\n        return org_images, grayscale_cam, pred, labels\n\n    def configure_optimizers(self):\n        optimizer = eval(self.cfg.optimizer.name)(\n            self.parameters(), **self.cfg.optimizer.params\n        )\n        scheduler = eval(self.cfg.scheduler.name)(\n            optimizer,\n            **self.cfg.scheduler.params\n        )\n        return [optimizer], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:31:05.544964Z","iopub.execute_input":"2022-04-27T23:31:05.545309Z","iopub.status.idle":"2022-04-27T23:31:05.578921Z","shell.execute_reply.started":"2022-04-27T23:31:05.545276Z","shell.execute_reply":"2022-04-27T23:31:05.578254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GradCAMPlusPlus??","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:31:05.582778Z","iopub.execute_input":"2022-04-27T23:31:05.582985Z","iopub.status.idle":"2022-04-27T23:31:05.647802Z","shell.execute_reply.started":"2022-04-27T23:31:05.582955Z","shell.execute_reply":"2022-04-27T23:31:05.647116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(\n    n_splits=config.n_splits, shuffle=True, random_state=config.seed\n)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df[\"Id\"], df[\"Pawpularity\"])):\n    train_df = df.loc[train_idx].reset_index(drop=True)\n    val_df = df.loc[val_idx].reset_index(drop=True)\n    datamodule = PetfinderDataModule(train_df, val_df, config)\n    model = Model(config)\n    earystopping = EarlyStopping(monitor=\"val_loss\")\n    lr_monitor = callbacks.LearningRateMonitor()\n    loss_checkpoint = callbacks.ModelCheckpoint(\n        filename=\"best_loss\",\n        monitor=\"val_loss\",\n        save_top_k=1,\n        mode=\"min\",\n        save_last=False,\n    )\n    logger = TensorBoardLogger(config.model.name)\n    \n    trainer = pl.Trainer(\n        logger=logger,\n        max_epochs=config.epoch,\n        callbacks=[lr_monitor, loss_checkpoint, earystopping],\n        **config.trainer,\n    )\n    trainer.fit(model, datamodule=datamodule)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T23:31:05.648927Z","iopub.execute_input":"2022-04-27T23:31:05.649263Z","iopub.status.idle":"2022-04-28T02:34:10.07399Z","shell.execute_reply.started":"2022-04-27T23:31:05.649229Z","shell.execute_reply":"2022-04-28T02:34:10.073172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# class activation map","metadata":{}},{"cell_type":"code","source":"# gradcam reshape_transform for vit\ndef reshape_transform(tensor, height=7, width=7):\n    result = tensor.reshape(tensor.size(0),\n                            height, width, tensor.size(2))\n\n    # like in CNNs.\n    result = result.permute(0, 3, 1, 2)\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:34:10.075535Z","iopub.execute_input":"2022-04-28T02:34:10.075791Z","iopub.status.idle":"2022-04-28T02:34:10.080556Z","shell.execute_reply.started":"2022-04-28T02:34:10.075755Z","shell.execute_reply":"2022-04-28T02:34:10.079901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(config) \nmodel.load_state_dict(torch.load(f'{config.model.name}/default/version_0/checkpoints/best_loss.ckpt')['state_dict'])\nmodel = model.cuda().eval()\nconfig.val_loader.batch_size = 16\ndatamodule = PetfinderDataModule(train_df, val_df, config)\nimages, grayscale_cams, preds, labels = model.check_gradcam(\n                                            datamodule.val_dataloader(), \n                                            target_layer=model.backbone.layers[-1].blocks[-1].norm1,\n                                            target_category=None,\n                                            reshape_transform=reshape_transform)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:34:10.081875Z","iopub.execute_input":"2022-04-28T02:34:10.082264Z","iopub.status.idle":"2022-04-28T02:34:14.65127Z","shell.execute_reply.started":"2022-04-28T02:34:10.082227Z","shell.execute_reply":"2022-04-28T02:34:14.650059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor it, (image, grayscale_cam, pred, label) in enumerate(zip(images, grayscale_cams, preds, labels)):\n    plt.subplot(4, 4, it + 1)\n    visualization = show_cam_on_image(image, grayscale_cam)\n    plt.imshow(visualization)\n    plt.title(f'pred: {pred:.1f} label: {label}')\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:34:14.6577Z","iopub.execute_input":"2022-04-28T02:34:14.660007Z","iopub.status.idle":"2022-04-28T02:34:16.040675Z","shell.execute_reply.started":"2022-04-28T02:34:14.659955Z","shell.execute_reply":"2022-04-28T02:34:16.040026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualize result","metadata":{}},{"cell_type":"code","source":"from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n\npath = glob(f'./{config.model.name}/default/version_0/events*')[0]\nevent_acc = EventAccumulator(path, size_guidance={'scalars': 0})\nevent_acc.Reload()\n\nscalars = {}\nfor tag in event_acc.Tags()['scalars']:\n    events = event_acc.Scalars(tag)\n    scalars[tag] = [event.value for event in events]","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:34:16.041863Z","iopub.execute_input":"2022-04-28T02:34:16.042624Z","iopub.status.idle":"2022-04-28T02:34:16.088577Z","shell.execute_reply.started":"2022-04-28T02:34:16.042581Z","shell.execute_reply":"2022-04-28T02:34:16.08794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\n\nplt.figure(figsize=(16, 6))\nplt.subplot(1, 2, 1)\nplt.plot(range(len(scalars['lr-AdamW'])), scalars['lr-AdamW'])\nplt.xlabel('epoch')\nplt.ylabel('lr')\nplt.title('adamw lr')\n\nplt.subplot(1, 2, 2)\nplt.plot(range(len(scalars['train_loss'])), scalars['train_loss'], label='train_loss')\nplt.plot(range(len(scalars['val_loss'])), scalars['val_loss'], label='val_loss')\nplt.legend()\nplt.ylabel('rmse')\nplt.xlabel('epoch')\nplt.title('train/val rmse')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:34:16.089674Z","iopub.execute_input":"2022-04-28T02:34:16.089998Z","iopub.status.idle":"2022-04-28T02:34:16.59037Z","shell.execute_reply.started":"2022-04-28T02:34:16.089963Z","shell.execute_reply":"2022-04-28T02:34:16.589692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('best_val_loss', min(scalars['val_loss']))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T02:34:16.591488Z","iopub.execute_input":"2022-04-28T02:34:16.592243Z","iopub.status.idle":"2022-04-28T02:34:16.597141Z","shell.execute_reply.started":"2022-04-28T02:34:16.592202Z","shell.execute_reply":"2022-04-28T02:34:16.59639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}