{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport copy\nimport random\nimport numpy as np\nfrom PIL import Image\nimport cv2\nimport pandas as pd\n\n#modeling\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torchvision\n\n#visualizations\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-10T08:30:34.684112Z","iopub.execute_input":"2021-12-10T08:30:34.684471Z","iopub.status.idle":"2021-12-10T08:30:34.690897Z","shell.execute_reply.started":"2021-12-10T08:30:34.684436Z","shell.execute_reply":"2021-12-10T08:30:34.690036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/petfinder-pawpularity-score/'\n\ntrain_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\n\n#Get the image data (the .jpg data) and put it into lists of filenames\ntrain_jpg = glob.glob(path + \"train/*.jpg\")\ntest_jpg = glob.glob(path + \"test/*.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:30:34.692619Z","iopub.execute_input":"2021-12-10T08:30:34.693077Z","iopub.status.idle":"2021-12-10T08:30:34.792476Z","shell.execute_reply.started":"2021-12-10T08:30:34.693038Z","shell.execute_reply":"2021-12-10T08:30:34.791856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape, len(train_jpg)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:30:34.793895Z","iopub.execute_input":"2021-12-10T08:30:34.794401Z","iopub.status.idle":"2021-12-10T08:30:34.801026Z","shell.execute_reply.started":"2021-12-10T08:30:34.794367Z","shell.execute_reply":"2021-12-10T08:30:34.800161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read in the data and drop unnecessary columns\ntrain = pd.read_csv(path + 'train.csv')\ntest = pd.read_csv(path + 'test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:30:34.803412Z","iopub.execute_input":"2021-12-10T08:30:34.804111Z","iopub.status.idle":"2021-12-10T08:30:34.839038Z","shell.execute_reply.started":"2021-12-10T08:30:34.804069Z","shell.execute_reply":"2021-12-10T08:30:34.838074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Add the .jpg extensions to the image file name ids\ntrain[\"img_path\"] = train[\"Id\"].apply(lambda x: path + 'train/' + x + \".jpg\")\ntest[\"img_path\"] = test[\"Id\"].apply(lambda x: path + 'test/' + x + \".jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:30:34.841041Z","iopub.execute_input":"2021-12-10T08:30:34.841386Z","iopub.status.idle":"2021-12-10T08:30:34.855015Z","shell.execute_reply.started":"2021-12-10T08:30:34.841351Z","shell.execute_reply":"2021-12-10T08:30:34.854169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train[\"img_path\"].values\ny = np.expand_dims(train['Pawpularity'].values/100, -1)\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7)\n#Show the shape of each of the new arrays\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:30:34.856036Z","iopub.execute_input":"2021-12-10T08:30:34.856883Z","iopub.status.idle":"2021-12-10T08:30:34.866379Z","shell.execute_reply.started":"2021-12-10T08:30:34.856845Z","shell.execute_reply":"2021-12-10T08:30:34.865532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetfinderDataset(torch.utils.data.Dataset):\n    def __init__(self, img_path, y=None, image_size=128, scale=True):\n        self._X = img_path\n        self._y = y\n        self._transform = torchvision.transforms.Resize([image_size, image_size])\n        self.scale = scale\n\n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        image_path = self._X[idx]\n        image = torchvision.io.read_image(image_path)\n        image = self._transform(image)\n        if self.scale:\n            image = image.float() / 255\n        if self._y is not None:\n            label = self._y[idx]\n            return image, label\n        return image\n    \ntrain_dataset = PetfinderDataset(x_train, torch.FloatTensor(y_train))\ntest_dataset = PetfinderDataset(x_test, torch.FloatTensor(y_test))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:30:34.867716Z","iopub.execute_input":"2021-12-10T08:30:34.868094Z","iopub.status.idle":"2021-12-10T08:30:34.879204Z","shell.execute_reply.started":"2021-12-10T08:30:34.868057Z","shell.execute_reply":"2021-12-10T08:30:34.878459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 1024\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:30:34.880353Z","iopub.execute_input":"2021-12-10T08:30:34.881073Z","iopub.status.idle":"2021-12-10T08:30:34.891875Z","shell.execute_reply.started":"2021-12-10T08:30:34.881022Z","shell.execute_reply":"2021-12-10T08:30:34.89098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(torch.nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv0 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(7,7), stride=(2,2), padding=0)\n        self.conv1 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(32)\n        \n        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), stride=(2,2), padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(32)\n        self.drop1 = torch.nn.Dropout2d(p=0.25)\n        \n        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(64)\n        \n        self.conv4 = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(2,2), padding=1)\n        self.bn4 = torch.nn.BatchNorm2d(64)\n        self.drop2 = torch.nn.Dropout2d(p=0.25)\n        \n        self.conv5 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=1)\n        self.bn5 = torch.nn.BatchNorm2d(128)\n        self.mp1 = torch.nn.MaxPool2d((2, 2))\n        \n        self.conv6 = torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding=1)\n        self.bn6 = torch.nn.BatchNorm2d(128)\n        self.drop3 = torch.nn.Dropout2d(p=0.25)\n\n        self.linear1 = torch.nn.Linear(8192, 512)\n        self.drop4 = torch.nn.Dropout(p=0.5)\n        self.linear2 = torch.nn.Linear(512, 1)\n        \n        \n    def forward(self, x):\n        x = torch.nn.functional.relu(self.conv0(x))\n        x = torch.nn.functional.relu(self.conv1(x))\n        x = self.bn1(x)\n        \n        x = torch.nn.functional.relu(self.conv2(x))\n        x = self.bn2(x)\n        x = self.drop1(x)\n        \n        x = torch.nn.functional.relu(self.conv3(x))\n        x = self.bn3(x)\n        \n        x = torch.nn.functional.relu(self.conv4(x))\n        x = self.bn4(x)\n        x = self.drop2(x)\n        \n        x = torch.nn.functional.relu(self.conv5(x))\n        x = self.bn5(x)\n        x = self.mp1(x)\n        \n        x = torch.nn.functional.relu(self.conv6(x))\n        x = self.bn6(x)\n        x = self.drop3(x)\n        \n        x = torch.nn.Flatten()(x)\n        x = torch.nn.functional.relu(self.linear1(x))\n        x = self.drop4(x)\n        x = torch.nn.functional.hardsigmoid(self.linear2(x))\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:30:34.935358Z","iopub.execute_input":"2021-12-10T08:30:34.936299Z","iopub.status.idle":"2021-12-10T08:30:34.958494Z","shell.execute_reply.started":"2021-12-10T08:30:34.936248Z","shell.execute_reply":"2021-12-10T08:30:34.957534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Net()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = torch.nn.MSELoss()\nepoch_num = 100\nbest_model = copy.deepcopy(model)\nbest_eval_loss = 1e9\nno_update_cnt = 0\nno_update_thresh = 5\n\nfor epoch in range(epoch_num):\n    model.train()\n    train_loss = 0\n    train_step = 0\n    if epoch != 0:\n        for x, y in tqdm(train_loader):\n            output = model(x)\n            loss = criterion(output, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            train_step += 1\n        train_loss /= train_step\n        \n    eval_loss = 0\n    eval_step = 0\n    model.eval()\n    with torch.no_grad():\n        for x, y in test_loader:\n            output = model(x)\n            loss = criterion(output, y)\n            \n            eval_loss += loss.item()\n            eval_step += 1\n        eval_loss /= eval_step\n    \n    if eval_loss < best_eval_loss:\n        best_model = copy.deepcopy(model)\n        best_eval_loss = eval_loss\n        no_update_cnt = 0\n    else:\n        no_update_cnt += 1\n        \n    print(\"epoch: {} train_loss: {} eval_loss:{} no_update_cnt:{}\".format(epoch, train_loss, eval_loss, no_update_cnt))\n        \n    if 20 <= epoch and no_update_thresh <= no_update_cnt:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:30:34.959806Z","iopub.execute_input":"2021-12-10T08:30:34.960342Z","iopub.status.idle":"2021-12-10T08:34:01.849417Z","shell.execute_reply.started":"2021-12-10T08:30:34.960305Z","shell.execute_reply":"2021-12-10T08:34:01.848506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_dataset = PetfinderDataset(test[\"img_path\"].values)\nsubmit_dataloader = torch.utils.data.DataLoader(submit_dataset, batch_size=64)\n\ny_pred = []\n\nfor x in tqdm(submit_dataloader):\n    output = model(x)\n    y_pred.extend(output.squeeze(1).to('cpu').detach().tolist())\n    \nsubmit = pd.DataFrame()\nsubmit['Id'] = test['Id']\nsubmit['Pawpularity'] = np.array(y_pred) * 100\nsubmit.to_csv('submission.csv',index=False)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-10T08:43:17.302281Z","iopub.execute_input":"2021-12-10T08:43:17.302548Z","iopub.status.idle":"2021-12-10T08:43:17.378302Z","shell.execute_reply.started":"2021-12-10T08:43:17.30252Z","shell.execute_reply":"2021-12-10T08:43:17.377739Z"},"trusted":true},"execution_count":null,"outputs":[]}]}