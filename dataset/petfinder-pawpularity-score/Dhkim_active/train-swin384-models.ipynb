{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PetFinder Image and Tabular Regression\n\n## [목차]\n1. 모듈 임포트 및 하이퍼 파라미터 설정\n2. 데이터 읽기\n3. 데이터 전처리 클래스 및 함수 작성\n4. 훈련 준비 - 기학습 모델 불러오기\n5. 훈련 수행\n6. 훈련 모델을 바탕으로 테스트\n7. 훈련된 모델을 저장\n8. 파인튜닝 훈련한 모델을 로드해서 추론 하기\n\n\n<br>\n### [참고 자료]\n\n","metadata":{"id":"lPkiXm2oXI81","papermill":{"duration":0.022038,"end_time":"2021-11-08T02:10:37.00098","exception":false,"start_time":"2021-11-08T02:10:36.978942","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## [사전작업] 기반 라이브러리 설치","metadata":{"id":"u6T4Gm4oXgM2","papermill":{"duration":0.018737,"end_time":"2021-11-08T02:10:37.040506","exception":false,"start_time":"2021-11-08T02:10:37.021769","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# !pip install torch==1.7.0\n# !pip install tqdm\n# !pip install numpy==1.19.5\n# !pip install seqeval\n# !pip install scikit-learn==0.23.2\n# !pip install pandas==1.2.4\n# !pip install opencv-python-headless==4.5.2.54\n# !pip install transformers==4.6.1\n# !pip install albumentations==1.0.1\n# !pip install timm\n# # !pip install pydicom==2.1.2\n# !pip install matplotlib\n# !pip install tez","metadata":{"id":"IO8CPgvOaJG3","outputId":"21bacac2-94d5-4b46-be70-c4a2b2c687b1","papermill":{"duration":0.025475,"end_time":"2021-11-08T02:10:37.084403","exception":false,"start_time":"2021-11-08T02:10:37.058928","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !nvidia-smi\n# !lsb_release -a\n# !python --version","metadata":{"id":"MqVTsNTyhR8Q","outputId":"57653ecc-6026-4cf8-f00e-f598ba329f7a","papermill":{"duration":0.023445,"end_time":"2021-11-08T02:10:37.126715","exception":false,"start_time":"2021-11-08T02:10:37.10327","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pynvml\n\n# pynvml.nvmlInit()\n# handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n# device_name = pynvml.nvmlDeviceGetName(handle)\n\n# if device_name != b'Tesla T4':\n#   raise Exception(\"\"\"\n#     Unfortunately this instance does not have a T4 GPU.\n    \n#     Please make sure you've configured Colab to request a GPU instance type.\n    \n#     Sometimes Colab allocates a Tesla K80 instead of a T4. Resetting the instance.\n\n#     If you get a K80 GPU, try Runtime -> Reset all runtimes...\n#   \"\"\")\n# else:\n#   print('Woo! You got the right kind of GPU!')","metadata":{"id":"_2yb_rAIiSS7","outputId":"ce833f51-c522-439a-a5e5-df5f632b16d5","papermill":{"duration":0.023819,"end_time":"2021-11-08T02:10:37.168778","exception":false,"start_time":"2021-11-08T02:10:37.144959","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [1] swin_large_patch4_window12_384 + SVR\n\nhttps://www.kaggle.com/abhishek/tez-pawpular-training\n\nhttps://www.kaggle.com/abhishek/tez-pawpular-swin-ference\n\nhttps://www.kaggle.com/cdeotte/rapids-svr-boost-17-8\n\nhttps://www.kaggle.com/manabendrarout/transformers-classifier-method-starter-infer\n\nhttps://www.kaggle.com/manabendrarout/transformers-classifier-method-starter-train\n\nhttps://www.kaggle.com/markerkor/petfindder-updated-rules-cheol-5fold/notebook\n\n\n\n\n","metadata":{"id":"Oep3XgenwGdO","papermill":{"duration":0.019316,"end_time":"2021-11-08T02:10:37.206411","exception":false,"start_time":"2021-11-08T02:10:37.187095","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 1. 모듈 임포트 및 하이퍼 파라미터 설정","metadata":{"id":"cE4ggRYbXsCa","papermill":{"duration":0.018444,"end_time":"2021-11-08T02:10:37.243258","exception":false,"start_time":"2021-11-08T02:10:37.224814","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/tez-lib/\")\nsys.path.append(\"../input/timmmaster/\")\n\nimport tez\nfrom tez.callbacks import EarlyStopping\nimport sys\nimport platform\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm.notebook import tqdm\nimport cv2\nfrom PIL import Image\nimport random\nimport glob\nimport gc\nimport copy\nfrom math import ceil\nimport math\nfrom albumentations import Compose, Normalize, HueSaturationValue, RandomBrightnessContrast, HorizontalFlip, VerticalFlip, Rotate, ShiftScaleRotate, RGBShift, augmentations\nfrom albumentations import Resize as Resize_alb\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, KFold\nimport torch\nimport shutil\nfrom torchvision.transforms import ToTensor\nimport time\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR, StepLR, CosineAnnealingWarmRestarts\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport cuml, pickle\nfrom cuml.svm import SVR\nprint('RAPIDS version',cuml.__version__,'\\n')","metadata":{"id":"JEefJUDoPb5O","outputId":"ca82dc3d-55d3-42d5-ed04-3cdb945bf560","papermill":{"duration":11.842895,"end_time":"2021-11-08T02:10:49.104752","exception":false,"start_time":"2021-11-08T02:10:37.261857","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MODEL_NAME = 'tf_efficientnet_b0_ns'\n# MODEL_NAME = 'vit_large_patch32_384'\nMODEL_NAME = 'swin_large_patch4_window12_384'\nIMAGE_SIZE = 384 # swin large should be 384\nBATCH_SIZE = 4# 32 \nEPOCHS = 10 # 20\nSEED = 1234\nLEARNING_RATE = 1e-4 #5e-5  \nWORKERS = 8 \n# drop_last = True\nNUM_FOLDS = 5\nEARLY_STOP = 5\nDO_CLIP_GRAD = False\nUSE_SWIN_SVR = False\n\n# AUGMENTS = Compose(\n#     [\n#         Resize_alb(IMAGE_SIZE, IMAGE_SIZE, p=1),\n#         HueSaturationValue(\n#             hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n#         ),\n#         RandomBrightnessContrast(\n#             brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n#         ),\n#         Normalize(\n#             mean=[0.500, 0.500, 0.500],\n#             std=[0.270, 0.270, 0.270],\n#             max_pixel_value=255.0,\n#             p=1.0,\n#         ),\n#     ],\n#     p=1.0,\n# )\n\nAUGMENTS = Compose(\n    [\n        Resize_alb(IMAGE_SIZE, IMAGE_SIZE, p=1),\n        Normalize(\n            mean=[0.500, 0.500, 0.500],\n            std=[0.270, 0.270, 0.270],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        Rotate(limit=180, p=0.7),\n        ShiftScaleRotate(\n                shift_limit = 0.1, scale_limit=0.1, rotate_limit=45, p=0.5\n            ),\n        HueSaturationValue(\n            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n        ),\n        RandomBrightnessContrast(\n            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n        ),\n\n    ],\n    p=1.0,\n)\n\nAUGMENTS2 = Compose(\n    [\n        Resize_alb(IMAGE_SIZE, IMAGE_SIZE, p=1),\n        Normalize(\n            mean=[0.500, 0.500, 0.500],\n            std=[0.270, 0.270, 0.270],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nAUGMENTS3 = Compose(\n    [\n        Resize_alb(IMAGE_SIZE, IMAGE_SIZE, p=1),\n        ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n        RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n        RandomBrightnessContrast(p=0.5),\n        \n        \n        Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\n# Brightness(), Contrast(), Hue(), Saturation()\n\nAUGMENTS4 = Compose(\n    [\n        Resize_alb(IMAGE_SIZE, IMAGE_SIZE, p=1),\n        ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n        RandomBrightnessContrast(p=0.5),\n        augmentations.transforms.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, always_apply=False, p=0.5),\n        \n        Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nDO_KFOLD_TRAINING = False\n# DATA_IN_PATH = '/content/drive/MyDrive/Colab_Notebooks/data/petfinder/'\n# SAVE_MODEL_PATH = '/content/drive/MyDrive/Portfolio_for_AI/'\nDATA_IN_PATH = '../input/petfinder-pawpularity-score/'\nSAVE_MODEL_PATH = '../input/petfinder-trained-model-v2/'\nDO_SVR_TRAIN = False\n\nDENSE_FEATURES = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n]\n\n# Make results reproducible\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(SEED)\n\n# Disable Debug APIs for Final Training\ntorch.autograd.set_detect_anomaly(False)\ntorch.autograd.profiler.profile(False)\ntorch.autograd.profiler.emit_nvtx(False)","metadata":{"id":"xhEAzNkEAnya","outputId":"e1d4a7a6-5f2d-427d-9155-87cbe37fea7b","papermill":{"duration":0.05224,"end_time":"2021-11-08T02:10:49.176448","exception":false,"start_time":"2021-11-08T02:10:49.124208","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. 데이터 읽기","metadata":{"id":"jltJepXCCBku","papermill":{"duration":0.019001,"end_time":"2021-11-08T02:10:49.214358","exception":false,"start_time":"2021-11-08T02:10:49.195357","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"q-2DsnOWvb8x","outputId":"0d6f9f44-8ba6-4e50-b806-f4f48b2c882f","papermill":{"duration":0.02519,"end_time":"2021-11-08T02:10:49.258588","exception":false,"start_time":"2021-11-08T02:10:49.233398","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df = pd.read_csv(f\"{DATA_IN_PATH}train.csv\")\n\nprint(\"텍스트 회귀 학습_검증 데이터 개수: {}\".format(len(dataset_df)))","metadata":{"id":"wHKjqzWXLrp9","outputId":"5fd94727-5334-4895-edcf-6c3e04d7fa9f","papermill":{"duration":0.055216,"end_time":"2021-11-08T02:10:49.333093","exception":false,"start_time":"2021-11-08T02:10:49.277877","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\nprint(dataset_df)","metadata":{"id":"JRCMz7sAM0ew","outputId":"b604e444-7be2-4b82-8187-82c48b24d352","papermill":{"duration":0.036528,"end_time":"2021-11-08T02:10:49.389127","exception":false,"start_time":"2021-11-08T02:10:49.352599","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. 데이터 전처리 클래스 및 함수 작성","metadata":{"id":"MVW9haB8YNY-","papermill":{"duration":0.019642,"end_time":"2021-11-08T02:10:49.428586","exception":false,"start_time":"2021-11-08T02:10:49.408944","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class PawpularDataset(Dataset):\n    def __init__(self, image_paths, dense_features, targets=None, augmentations=None):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n\n        if self.targets is not None:\n            targets = self.targets[item]\n            return (torch.tensor(image, dtype=torch.float), \n                    torch.tensor(features, dtype=torch.float),\n                    torch.tensor(targets, dtype=torch.float))\n        else:\n            return (torch.tensor(image, dtype=torch.float), \n                    torch.tensor(features, dtype=torch.float))\n        \nclass PawpularDataset2:\n    def __init__(self, image_paths, dense_features, targets=None, augmentations=None):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }\n","metadata":{"id":"H6JmVcXsE_Gn","papermill":{"duration":0.036248,"end_time":"2021-11-08T02:10:49.484532","exception":false,"start_time":"2021-11-08T02:10:49.448284","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3-1) 위에서 작성한 전처리 함수들 테스트해보기 ","metadata":{"id":"GUnMipCoZNgF","papermill":{"duration":0.019672,"end_time":"2021-11-08T02:10:49.523742","exception":false,"start_time":"2021-11-08T02:10:49.50407","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tmp_df = dataset_df.iloc[:100]\nimg_paths = [f\"{DATA_IN_PATH}train/{x}.jpg\" for x in tmp_df[\"Id\"].values]\n# img_paths += [f\"{DATA_IN_PATH}cropped_train/{x}.jpg\" for x in tmp_df[\"Id\"].values]\n# tmp_df = pd.concat([tmp_df, tmp_df], axis=0)\ntmp_dataset = PawpularDataset2(\n    image_paths=img_paths,\n    dense_features=tmp_df[DENSE_FEATURES].values,\n    targets=tmp_df.Pawpularity.values/100.0,\n    augmentations=AUGMENTS,\n)\nprint(tmp_dataset[10])","metadata":{"id":"2ZhOIdGJapih","outputId":"74f82080-ac7c-4062-e4b5-610dce800a23","papermill":{"duration":0.183149,"end_time":"2021-11-08T02:10:49.727425","exception":false,"start_time":"2021-11-08T02:10:49.544276","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. 훈련 준비 - 기학습 모델 불러오기","metadata":{"id":"T1hWj1gdG8L0","papermill":{"duration":0.020484,"end_time":"2021-11-08T02:10:49.768009","exception":false,"start_time":"2021-11-08T02:10:49.747525","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"TgBRJ-nVWSYr","papermill":{"duration":0.026096,"end_time":"2021-11-08T02:10:49.815169","exception":false,"start_time":"2021-11-08T02:10:49.789073","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nloss_fn = nn.MSELoss()\nscaler = GradScaler()\nsoftmax_fn = nn.Softmax(dim=1)\n\ndef sigmoid(x):\n    return 1 / (1 + math.exp(-x))\n\nclass RMSELoss(torch.nn.Module):\n    def __init__(self):\n        super(RMSELoss,self).__init__()\n        self.criterion = nn.MSELoss()\n \n    def forward(self,x,y):\n        x, y = x.type(torch.FloatTensor), y.type(torch.FloatTensor)\n        loss = torch.sqrt(self.criterion(x, y)).type(torch.FloatTensor)\n        return loss\n\nclass PawpularModel(nn.Module):\n    def __init__(self, model_name, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        # self.model.classifier = nn.Linear(self.model.classifier.in_features, 128) # effnet\n        self.model.head = nn.Linear(self.model.head.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(140, 64)\n        self.dense2 = nn.Linear(64, 1)\n        self.activation = nn.Sigmoid()\n\n    def forward(self, image, features):\n        x = self.model(image)\n        x = self.dropout(x)\n        x = torch.cat([x, features], dim=1)\n        x = self.dense1(x)\n        x = self.dense2(x)\n        x = self.activation(x)\n        return x\n\nclass PawpularModel2(nn.Module):\n    def __init__(self, model_name, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        self.model.head = nn.Linear(self.model.head.in_features, 128)\n        self.fc = nn.Sequential(\n            nn.Linear(140, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        self.dropout = nn.Dropout(0.2)\n        self.activation = nn.Sigmoid()\n    \n    def forward(self, image, dense):\n        embeddings = self.model(image)\n        x = self.dropout(embeddings)\n        x = torch.cat([x, dense], dim=1)\n        x = self.fc(x)\n        x = self.activation(x)\n        return x\n\n \nclass PawpularModel3(tez.Model):\n    def __init__(self, model_name, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        self.model.head = nn.Linear(self.model.head.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(140, 64)\n        self.dense2 = nn.Linear(64, 1)\n\n    def forward(self, image, features, targets=None):\n        x1 = self.model(image)\n        x = self.dropout(x1)\n        x = torch.cat([x, features], dim=1)\n        x = self.dense1(x)\n        x = self.dense2(x)\n        \n        x = torch.cat([x, x1, features], dim=1)\n        return x, 0, {}\n    \n\n\n# # https://www.kaggle.com/h053473666/siim-covid19-efnb7-train-study\n# class EfficientNetModel(nn.Module):\n#     \"\"\"\n#     Model Class for EfficientNet Model\n#     \"\"\"\n#     def __init__(self, num_classes=4, model_name=MODEL_NAME, pretrained=True):\n#         super(EfficientNetModel, self).__init__()\n#         self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n#         # weights='imagenet'\n#         #self.model.global_pool = nn.AdaptiveAvgPool2d(self.model.classifier.in_features)\n#         self.model.classifier = nn.Linear(self.model.classifier.in_features, num_classes)\n#         # self.soft = nn.Softmax(dim=1)\n        \n#     def forward(self, x):\n#         x = self.model(x)\n#         return x\n    \n\n# class NFNetModel(nn.Module):\n#     \"\"\"\n#     Model Class for EfficientNet Model\n#     \"\"\"\n#     def __init__(self, num_classes=4, model_name=MODEL_NAME, pretrained=True):\n#         super(NFNetModel, self).__init__()\n#         self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n#         self.model.head.fc = nn.Linear(self.model.head.fc.in_features, num_classes)\n#         # self.soft = nn.Softmax(dim=1)\n        \n#     def forward(self, x):\n#         x = self.model(x)\n#         return x\n","metadata":{"id":"fSR14BcTMp_x","papermill":{"duration":0.043451,"end_time":"2021-11-08T02:10:49.878681","exception":false,"start_time":"2021-11-08T02:10:49.83523","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. 훈련 수행 함수 \n\n- 훈련셋에 대해서 정해진 epoch 수 만큼 훈련을 하면서 정확도와 F1스코어를 출력\n\n- 훈련셋 minibatch 마다 validset evaluation 수행하여 최적 모델 저장","metadata":{"id":"hLpCnPpFZmOG","papermill":{"duration":0.019952,"end_time":"2021-11-08T02:10:49.91872","exception":false,"start_time":"2021-11-08T02:10:49.898768","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def evaluate(model, test_dataset, phrase='test'):\n  test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, \n                           num_workers = WORKERS, pin_memory = True)\n \n  model.eval()\n \n  total_loss = 0.0\n  batches = 0\n  total_cnt = 0\n  correct_cnt = 0\n  all_labels = list()\n  all_preds = list()\n  num_batches = len(test_loader)\n  if phrase.lower() != 'test':\n    phrase = 'Validation: '\n  else:\n    phrase = 'Testing: '\n  with torch.no_grad():\n    progress_bar = tqdm(test_loader, desc=phrase, unit='batch')\n    for i, mini_batch in enumerate(progress_bar):\n      inputs = {'image': mini_batch[0].to(device, dtype=torch.float), \n                'features': mini_batch[1].to(device, dtype=torch.float)}\n      outputs = model(**inputs)\n      \n      loss = loss_fn(outputs, mini_batch[2].to(device, dtype=torch.float))\n \n      batches += 1\n      total_loss += loss.item()\n      avg_loss = total_loss / batches\n \n      if 'test' not in phrase.lower():\n        progress_bar.set_postfix_str('|val_loss|=%.4f' % (avg_loss))\n      else:\n        progress_bar.set_postfix_str('|test_loss|=%.4f' % (avg_loss))\n      torch.cuda.empty_cache()\n\n    del inputs, outputs\n    gc.collect()\n    torch.cuda.empty_cache()\n    progress_bar.close()\n \n  return avg_loss\n ","metadata":{"id":"eGr0Ai9ZI_xT","papermill":{"duration":0.032744,"end_time":"2021-11-08T02:10:49.971716","exception":false,"start_time":"2021-11-08T02:10:49.938972","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://spell.ml/blog/mixed-precision-training-with-pytorch-Xuk7YBEAACAASJam\ndef train_validate(model, train_ml_df, valid_ml_df, epochs=EPOCHS):\n  lowest_loss = int(1e09)\n  lowest_after = 0\n  for i in range(epochs):\n    train_ml_df = train_ml_df.sample(frac=1)\n    train_img_paths = [f\"{DATA_IN_PATH}train/{x}.jpg\" for x in train_ml_df[\"Id\"].values]\n    train_img_paths += [f\"{DATA_IN_PATH}cropped_train/{x}.jpg\" for x in train_ml_df[\"Id\"].values]\n    new_train_ml_df = pd.concat([train_ml_df, train_ml_df], axis=0)\n    valid_ml_df = valid_ml_df.sample(frac=1)\n    valid_img_paths = [f\"{DATA_IN_PATH}train/{x}.jpg\" for x in valid_ml_df[\"Id\"].values]\n    valid_img_paths += [f\"{DATA_IN_PATH}cropped_train/{x}.jpg\" for x in valid_ml_df[\"Id\"].values]\n    new_valid_ml_df = pd.concat([valid_ml_df, valid_ml_df], axis=0)\n    train_dataset = PawpularDataset(\n        image_paths=train_img_paths,\n        dense_features=new_train_ml_df[DENSE_FEATURES].values,\n        targets=new_train_ml_df.Pawpularity.values/100.0,\n        augmentations=AUGMENTS\n    )\n    valid_dataset = PawpularDataset(\n        image_paths=valid_img_paths,\n        dense_features=new_valid_ml_df[DENSE_FEATURES].values,\n        targets=new_valid_ml_df.Pawpularity.values/100.0,\n        augmentations=AUGMENTS2\n    )\n\n    total_loss = 0.0\n    batches = 0\n    all_train_labels = np.array([]).astype(int)\n    all_train_preds = np.array([]).astype(int)\n    model.train()\n    # https://betterprogramming.pub/how-to-make-your-pytorch-code-run-faster-93079f3c1f7b\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n                              num_workers = WORKERS, pin_memory = True)\n    progress_bar = tqdm(train_loader, desc=f'[EPOCHS#{i}] Training: ', unit='epochs')\n    total_cnt = 0\n    correct_cnt = 0\n    for mini_batch in progress_bar:\n      optimizer.zero_grad() \n      inputs = {'image': mini_batch[0].to(device, dtype=torch.float), \n                'features': mini_batch[1].to(device, dtype=torch.float)}\n      with autocast():\n        outputs = model(**inputs)\n        loss = loss_fn(outputs, mini_batch[2].to(device, dtype=torch.float))\n      scaler.scale(loss).backward()\n      # loss.backward()\n      if DO_CLIP_GRAD:\n        adaptive_clip_grad(model.parameters(), clip_factor=0.01, eps=1e-3, norm_type=2.0)\n\n      scaler.step(optimizer)\n      scaler.update()\n      # optimizer.step()\n      scheduler.step(loss)\n\n      batches += 1\n      total_loss += loss.item()\n      avg_loss = total_loss / batches\n      progress_bar.set_postfix_str('|train_loss|=%.4f' % (avg_loss))\n      torch.cuda.empty_cache()\n\n    del inputs, outputs\n    gc.collect()\n    torch.cuda.empty_cache()\n    progress_bar.close()\n \n    val_avg_loss = evaluate(model, valid_dataset, phrase='validation')\n    # scheduler.step(val_avg_loss)\n    # train loss(avg_loss)가 너무 작으면 오버 피팅 되므로 valid loss와 차이가 근소해야\n    if val_avg_loss < lowest_loss: # and (abs(val_avg_loss - avg_loss) < 0.1 or val_avg_loss < avg_loss):\n        # update if there is an improvement\n        lowest_loss = val_avg_loss\n        lowest_after = 0\n        torch.save(model.state_dict(), SAVE_PRETRAINED_PATH)\n    else:\n        # model.load_state_dict(torch.load(SAVE_PRETRAINED_PATH))\n        lowest_after += 1\n        if lowest_after >= EARLY_STOP and EARLY_STOP > 0:\n            break\n ","metadata":{"id":"yXqxHpjYJAll","papermill":{"duration":0.03877,"end_time":"2021-11-08T02:10:50.030916","exception":false,"start_time":"2021-11-08T02:10:49.992146","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 훈련 수행","metadata":{"id":"Yy3eyRvLgHHz","papermill":{"duration":0.020134,"end_time":"2021-11-08T02:10:50.071379","exception":false,"start_time":"2021-11-08T02:10:50.051245","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"! 아직 오프라인으로는 timm이 모델 파일이 수행 안됨\n\nhttps://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-keras-study-train-tpu-cv0-805","metadata":{"id":"L7uJjaU-wGdU","papermill":{"duration":0.019879,"end_time":"2021-11-08T02:10:50.111066","exception":false,"start_time":"2021-11-08T02:10:50.091187","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def implement_kfold_training(epochs: int = 20, \n                             lr: float = 1e-4, \n                             retricted_folds: list = [2,3,4], \n                             model_version: str = 'v1', lr_cycle: int = 1):\n  kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n  for fold, (train_indices, val_indices) in enumerate(kfold.split(dataset_df)):\n    if fold in retricted_folds:\n      continue\n    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n    train_ml_df = dataset_df.iloc[train_indices]\n    valid_ml_df = dataset_df.iloc[val_indices]\n    model = PawpularModel3(model_name=MODEL_NAME, pretrained=True)\n    global optimizer, scheduler, SAVE_PRETRAINED_PATH\n    SAVE_PRETRAINED_PATH = f\"/content/drive/MyDrive/Portfolio_for_AI/swin_f{fold}_{model_version}.bin\"\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    # scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=0, verbose=False, min_lr=1e-6)\n    # scheduler = get_cosine_schedule_with_warmup(\n    #   optimizer,\n    #   num_warmup_steps=0,\n    #   num_training_steps=epochs * 284\n    #   )\n    scheduler = CosineAnnealingWarmRestarts(\n        optimizer, T_0=5, eta_min=1e-7, last_epoch=-1)\n\n    train_validate(model, train_ml_df, valid_ml_df, epochs)\n    del model\n    gc.collect()\n\nif DO_KFOLD_TRAINING:\n    implement_kfold_training(epochs=EPOCHS, lr=LEARNING_RATE, retricted_folds=[], model_version='petfinder_v1') ","metadata":{"id":"t8bEYUROMMCv","outputId":"99d20db2-7e79-4d02-eac8-d0b7845ca4c4","papermill":{"duration":0.029907,"end_time":"2021-11-08T02:10:50.160759","exception":false,"start_time":"2021-11-08T02:10:50.130852","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. 훈련 모델을 바탕으로 테스트","metadata":{"id":"vneu5HDHZ00O","papermill":{"duration":0.019821,"end_time":"2021-11-08T02:10:50.200565","exception":false,"start_time":"2021-11-08T02:10:50.180744","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if USE_SWIN_SVR:\n    NUM_FOLDS = 10\n    retricted_folds = []\n\n    super_final_predictions = []\n    super_final_predictions2 = []\n    super_final_predictions3 = []\n    super_final_predictions4 = []\n\n    testset_df = pd.read_csv(f\"{DATA_IN_PATH}test.csv\")\n    img_paths = [f\"{DATA_IN_PATH}test/{x}.jpg\" for x in testset_df[\"Id\"].values]\n    test_dataset = PawpularDataset2(\n        image_paths=img_paths,\n        dense_features=testset_df[DENSE_FEATURES].values,\n        targets=np.ones(len(img_paths)),\n        augmentations=AUGMENTS3,\n    )\n    test_dataset2 = PawpularDataset2(\n        image_paths=img_paths,\n        dense_features=testset_df[DENSE_FEATURES].values,\n        targets=np.ones(len(img_paths)),\n        augmentations=AUGMENTS4,\n    )\n\n    kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n    for fold, (train_indices, val_indices) in enumerate(kfold.split(dataset_df)):\n        if fold in retricted_folds:\n          continue\n        name = f\"SVR_fold_{fold}.pkl\"\n        print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n        train_ml_df = dataset_df.iloc[train_indices]\n        valid_ml_df = dataset_df.iloc[val_indices]\n        model = PawpularModel3(model_name=MODEL_NAME, pretrained=False)\n        SAVE_PRETRAINED_PATH = f\"{SAVE_MODEL_PATH}swin_f{fold}.bin\"\n        model.load(SAVE_PRETRAINED_PATH, device=\"cuda\", weights_only=True)\n\n        if DO_SVR_TRAIN:\n            train_ml_df = train_ml_df.sample(frac=1)\n            train_img_paths = [f\"{DATA_IN_PATH}train/{x}.jpg\" for x in train_ml_df[\"Id\"].values]\n            train_img_paths += [f\"{DATA_IN_PATH}cropped_train/{x}.jpg\" for x in train_ml_df[\"Id\"].values]\n            new_train_ml_df = pd.concat([train_ml_df, train_ml_df], axis=0)\n            train_dataset = PawpularDataset(\n                image_paths=train_img_paths,\n                dense_features=new_train_ml_df[DENSE_FEATURES].values,\n                targets=new_train_ml_df.Pawpularity.values/100.0,\n                augmentations=AUGMENTS\n            )\n\n            train_predictions = model.predict(train_dataset, batch_size=2*BATCH_SIZE, n_jobs=-1)\n            embed = np.array([]).reshape((0,128+12))\n            for preds in train_predictions:\n                embed = np.concatenate([embed, preds[:,1:]],axis=0)\n\n            # fit RAPID SVR\n            clf = SVR(C=20.0)\n            clf.fit(embed.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n            pickle.dump(clf, open(SAVE_MODEL_PATH+name, \"wb\"))\n\n        else:\n            # LOAD RAPIDS SVR \n            print('Loading SVR...',SAVE_MODEL_PATH+name)\n            clf = pickle.load(open(SAVE_MODEL_PATH+name, \"rb\"))\n\n        print('Predicting test...')\n        test_predictions = model.predict(test_dataset, batch_size=2*BATCH_SIZE, n_jobs=-1)\n        test_predictions2 = model.predict(test_dataset2, batch_size=2*BATCH_SIZE, n_jobs=-1)\n\n        # AUGMENTS3 version\n        final_test_predictions = []\n        embed = np.array([]).reshape((0,128+12))\n        for preds in test_predictions: #tqdm\n            final_test_predictions.extend(preds[:,:1].ravel().tolist())\n            embed = np.concatenate([embed,preds[:,1:]],axis=0)\n\n        final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n        final_test_predictions2 = clf.predict(embed)\n        super_final_predictions.append(final_test_predictions)\n        super_final_predictions2.append(final_test_predictions2)\n\n        # AUGMENTS4 version\n        final_test_predictions = []\n        embed = np.array([]).reshape((0,128+12))\n        for preds in test_predictions2: #tqdm\n            final_test_predictions.extend(preds[:,:1].ravel().tolist())\n            embed = np.concatenate([embed,preds[:,1:]],axis=0)\n\n        final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n        final_test_predictions2 = clf.predict(embed)\n        super_final_predictions3.append(final_test_predictions)\n        super_final_predictions4.append(final_test_predictions2)\n\n\n    # 최종 submission 파일 제출\n    super_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\n    super_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\n    super_final_predictions3 = np.mean(np.column_stack(super_final_predictions3), axis=1)\n    super_final_predictions4 = np.mean(np.column_stack(super_final_predictions4), axis=1)\n    # testset_df[\"Pawpularity\"] = 0.8*super_final_predictions + 0.2*super_final_predictions2\n    # testset_df[\"Pawpularity\"] = 0.64*super_final_predictions + 0.16*super_final_predictions2 + 0.16*super_final_predictions3 + 0.04*super_final_predictions4\n    preds1 = 0.72*super_final_predictions + 0.18*super_final_predictions2 + 0.08*super_final_predictions3 + 0.02*super_final_predictions4","metadata":{"id":"zhh0P0DJrYSo","papermill":{"duration":153.357859,"end_time":"2021-11-08T02:13:23.578151","exception":false,"start_time":"2021-11-08T02:10:50.220292","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. FastAI를 활용한 모델 예측","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/timmmaster\")\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nfrom timm import create_model\nfrom timm.data.mixup import Mixup\nfrom fastai.vision.all import *\n\nif not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n    os.makedirs('/root/.cache/torch/hub/checkpoints/')\n!cp '../input/swin-transformer/swin_large_patch4_window7_224_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window7_224_22kto1k.pth'\n!cp '../input/timmswin/swin_large_patch4_window12_384_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window12_384_22kto1k.pth'\n# !cp '../input/beit-large-patch16/beit_large_patch16_384_pt22k_ft22kto1k.pth' '/root/.cache/torch/hub/checkpoints/beit_large_patch16_384_pt22k_ft22kto1k.pth'\n!cp '../input/beit-large-patch16/beit_large_patch16_224_pt22k_ft22kto1k.pth' '/root/.cache/torch/hub/checkpoints/beit_large_patch16_224_pt22k_ft22kto1k.pth'\n\nUSE_FASTAI_SWIN = True\nBATCH_SIZE = 8 #32 Only if inference\nN_FOLDS = 5\nSEED=999\nKFOLD_TRAIN = False\nMODEL_NAME = 'swin_large_patch4_window7_224'\nIMAGE_SIZE = 384 # swin large should be 224\nPRETRAINED_MODEL_PATH = '../input/petfinder-pretrained-model'\nPRETRAINED_MODEL_NAME = 'swin_large_patch4_window12_384_rmse15p30'\nEPOCHS = 5 \nWORKERS = 4\nLEARNING_RATE = 2e-5\n# TRAINED_MODEL_PATH = \"../input/petfinder-trained-model-rmse17p41-v3\"\n# TRAINED_MODEL_PATH = \"../input/petfinder-trained-model-rmse16p86-v4\"\nTRAINED_MODEL_PATH = \"../input/petfinder-trained-model-16p57-384-v1\"\n\nset_seed(SEED, reproducible=True)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True\n\ndataset_path = Path('../input/petfinder-pawpularity-score/')\ndataset_path.ls()\n\ntrain_df = pd.read_csv(dataset_path/'train.csv')\ntrain_df.head()\n\ntrain_df['path'] = train_df['Id'].map(lambda x:str(dataset_path/'train'/x)+'.jpg')\ntrain_df = train_df.drop(columns=['Id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df.head()\n\nlen_df = len(train_df)\nprint(f\"There are {len_df} images\")\n\ntrain_df['norm_score'] = train_df['Pawpularity']/100\n\n#Sturges' rule\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n\ntrain_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T14:23:23.736293Z","iopub.execute_input":"2022-01-05T14:23:23.736643Z","iopub.status.idle":"2022-01-05T14:23:37.074249Z","shell.execute_reply.started":"2022-01-05T14:23:23.73661Z","shell.execute_reply":"2022-01-05T14:23:37.073123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\n\ndef petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ndef get_data(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n#                                valid_pct=0.2, #80-20 train-validation random split\n                                   valid_col='is_valid', #\n                                   seed=SEED, #seed\n                                   fn_col='path', #filename/path is in the second column of the DataFrame\n                                   label_col='norm_score', #label is in the first column of the DataFrame\n                                   y_block=RegressionBlock, #The type of target\n                                   bs=BATCH_SIZE, #pass in batch size\n                                   num_workers=WORKERS,\n                                   item_tfms=Resize(IMAGE_SIZE), #pass in item_tfms\n                                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n    \n    return dls\n\ndef get_learner(fold_num):\n    data = get_data(fold_num)\n    \n    model = create_model(MODEL_NAME, pretrained=True, num_classes=data.c)\n\n    # learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse).to_fp16()\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse, cbs=[MixUp(0.2)]).to_fp16()\n    \n    return learn\n\n\ntrain_df['fold'] = -1\n\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=SEED, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\n\nif USE_FASTAI_SWIN:\n    BATCH_SIZE = 8\n    #Valid Kfolder size\n    the_data = get_data(0)\n    assert (len(the_data.train) + len(the_data.valid)) == (len(train_df)//BATCH_SIZE)\n\n    test_df = pd.read_csv(dataset_path/'test.csv')\n    test_df.head()\n\n    test_df['Pawpularity'] = [1]*len(test_df)\n    test_df['path'] = test_df['Id'].map(lambda x:str(dataset_path/'test'/x)+'.jpg')\n    test_df = test_df.drop(columns=['Id'])\n    train_df['norm_score'] = train_df['Pawpularity']/100\n    \n#     LEARNING_RATE_SUGGESTED = []\n#     for i in range(5):\n#         learner = get_learner(fold_num=i)\n#         lr_sug = learner.lr_find(end_lr=3e-2)\n#         LEARNING_RATE_SUGGESTED.append(lr_sug.valley)\n#         print(f'Fold{i} suggested lr: ', lr_sug.valley)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T14:24:58.99302Z","iopub.execute_input":"2022-01-05T14:24:58.993802Z","iopub.status.idle":"2022-01-05T14:24:59.095401Z","shell.execute_reply.started":"2022-01-05T14:24:58.993766Z","shell.execute_reply":"2022-01-05T14:24:59.094225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# self training을 위한 준비: 추가 학습 데이터 만들기\n# img_path_list = []\n# test2_dir_path = '../input/petfinder-adoption-prediction/test_images'\n# for image_file in os.listdir(test2_dir_path):\n#     img_path_list.append(test2_dir_path + '/' + image_file)\n    \n# train2_dir_path = '../input/petfinder-adoption-prediction/train_images'\n# for image_file in os.listdir(train2_dir_path):\n#     img_path_list.append(train2_dir_path + '/' + image_file)\n\n# # img_path_list = img_path_list[:10]\n# test_df = pd.DataFrame({'path': img_path_list, 'Pawpularity': [1]*len(img_path_list)})\n# test_df\n# self training을 위한 준비: 추가 학습셋으로 훈련하기\n# pretrain_df = pd.read_csv('~submission.csv')\n# pretrain_df['fold'] = 1\n# pretrain_df = pretrain_df.rename(columns={'Pawpularity': 'norm_score'})\n# pretrain_df = pretrain_df[['path', 'norm_score', 'fold']]\n# train_df['fold'] = 0\n# train_df = train_df[['path', 'norm_score', 'fold']]\n# test_df = train_df[['path', 'norm_score']]\n# train_df = pd.concat([pretrain_df, train_df], axis=0)\n# N_FOLDS = 1","metadata":{"execution":{"iopub.status.busy":"2022-01-05T14:25:02.699188Z","iopub.execute_input":"2022-01-05T14:25:02.699485Z","iopub.status.idle":"2022-01-05T14:25:02.704808Z","shell.execute_reply.started":"2022-01-05T14:25:02.699452Z","shell.execute_reply":"2022-01-05T14:25:02.703433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n# LEARNING_RATE_SUGGESTED = [5.477225568029098e-05, 2.9154431103961542e-05, 0.00024877983378246427, 0.00010290031059412286, 0.00021930268849246204]\n\ndef fastai_swin_kfolds():\n    all_preds = []\n    global TRAINED_MODEL_PATH, TRAINED_MODEL_PATH2\n    for i in range(N_FOLDS):\n        if i in [3, 4] and 'beit' in TRAINED_MODEL_PATH:\n            TRAINED_MODEL_PATH = TRAINED_MODEL_PATH2\n        print(f'Fold {i} results')\n        learn = get_learner(fold_num=i)\n        if KFOLD_TRAIN:\n            original_model_dir = learn.model_dir\n            learn.model_dir = PRETRAINED_MODEL_PATH\n            learn.load(PRETRAINED_MODEL_NAME)\n            learn.model_dir = original_model_dir\n            learn.fit_one_cycle(EPOCHS, LEARNING_RATE, cbs=[SaveModelCallback(), EarlyStoppingCallback(monitor='petfinder_rmse', comp=np.less, patience=2)]) \n\n            learn.recorder.plot_loss()\n\n            learn = learn.to_fp32()\n            learn.export(f'model_fold_{i}.pkl')\n            learn.save(f'model_fold_{i}.pkl')\n\n        else:\n            learn.model_dir = TRAINED_MODEL_PATH\n            learn.load(f'model_fold_{i}.pkl')\n\n        dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                                       valid_pct=0.2, #80-20 train-validation random split\n                                       seed=SEED, #seed\n                                       fn_col='path', #filename/path is in the second column of the DataFrame\n                                       label_col='norm_score', #label is in the first column of the DataFrame\n                                       y_block=RegressionBlock, #The type of target\n                                       bs=BATCH_SIZE, #pass in batch size\n                                       num_workers=WORKERS,\n                                       item_tfms=Resize(IMAGE_SIZE), #pass in item_tfms\n                                       batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n\n\n\n        test_dl = dls.test_dl(test_df)\n\n        preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n\n        all_preds.append(preds)\n\n        del learn\n\n        torch.cuda.empty_cache()\n\n        gc.collect()\n\n    preds = np.mean(np.stack(all_preds), axis=0)\n    # preds = preds*100\n    return preds\n\nif USE_FASTAI_SWIN:\n    KFOLD_TRAIN = True\n    BATCH_SIZE = 8 # when inference. train 시는 batch size 8로 해야\n    MODEL_NAME = 'swin_large_patch4_window12_384'\n    IMAGE_SIZE = 384 \n    TRAINED_MODEL_PATH = \"../input/petfinder-trained-model-16p52-384-v2\"\n    preds2 = fastai_swin_kfolds()\n    \n#     MODEL_NAME = 'swin_large_patch4_window7_224'\n#     IMAGE_SIZE = 224 \n#     TRAINED_MODEL_PATH = \"../input/petfinder-trained-model-16p67-224-v2\"\n#     preds3 = fastai_swin_kfolds()\n    \n#     MODEL_NAME = 'beit_large_patch16_224'\n#     IMAGE_SIZE = 224 \n#     TRAINED_MODEL_PATH = \"../input/petfinder-trained-model-beit-224-rmse16p83-v1\"\n#     TRAINED_MODEL_PATH2 = \"../input/petfinder-trained-model-beit-224-rmse16p85-v1-2\"\n#     preds4 = fastai_swin_kfolds()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T14:25:03.10442Z","iopub.execute_input":"2022-01-05T14:25:03.104906Z","iopub.status.idle":"2022-01-05T14:27:21.561824Z","shell.execute_reply.started":"2022-01-05T14:25:03.104869Z","shell.execute_reply":"2022-01-05T14:27:21.559852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_df = pd.read_csv(dataset_path/'sample_submission.csv')\n# # sample_df['Pawpularity'] = preds1*0.10 + preds2*0.55 + preds3*0.15 + preds4*0.20\n# # LB version\n# # sample_df['Pawpularity'] = preds1*0.02 + preds2*0.04 + preds3*0.85 + preds4*0.09\n# # Val version\n# sample_df['Pawpularity'] = preds1*0.05 + preds2*0.55 + preds3*0.16 + preds4*0.24\n# # sample_df['Pawpularity'] = preds2\n# sample_df.to_csv('submission.csv',index=False)\n# print(sample_df.head())","metadata":{"id":"AoeAcetqbP8M","papermill":{"duration":0.073669,"end_time":"2021-11-08T02:13:23.702537","exception":false,"start_time":"2021-11-08T02:13:23.628868","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df['Pawpularity'] = preds2*0.65 + preds3*0.20 + preds4*0.15\ntest_df['Pawpularity'] = preds2\ntest_df.to_csv('submission.csv',index=False)\nprint(test_df.head())","metadata":{"papermill":{"duration":0.050468,"end_time":"2021-11-08T02:13:23.803929","exception":false,"start_time":"2021-11-08T02:13:23.753461","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}