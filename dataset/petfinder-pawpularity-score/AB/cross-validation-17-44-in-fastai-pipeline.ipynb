{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm\nfrom timm import create_model\n! pip install fastai --upgrade #restart kernel\nfrom fastai.vision.all import *\ndataset_path = Path('../input/petfinder-pawpularity-score')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T11:15:26.091664Z","iopub.execute_input":"2021-12-22T11:15:26.092056Z","iopub.status.idle":"2021-12-22T11:15:46.904019Z","shell.execute_reply.started":"2021-12-22T11:15:26.091962Z","shell.execute_reply":"2021-12-22T11:15:46.903088Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**A lot of people in discussions seem to be having trouble in calculating accruate CV scores. So here I demnstrate how to do the same using inference on your saved models adapted from cdeotte's rapids svr pipeline.**","metadata":{}},{"cell_type":"markdown","source":"# Sturges Bins OOF Inference","metadata":{}},{"cell_type":"code","source":"#creating train df for using st\n\nset_seed(999, reproducible=True)\nBATCH_SIZE = 8                       \n\ntrain_df = pd.read_csv(dataset_path/'train.csv')\ntrain_df['path'] = train_df['Id'].map(lambda x:str(dataset_path/'train'/x)+'.jpg')\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n\ntrain_df['norm_score'] = train_df['Pawpularity']/100\ntrain_df['norm_score']\n\nseed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True\n#Sturges' rule\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n# num_bins\n\ntrain_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\ntrain_df['fold'] = -1\nN_FOLDS = 10        #was10\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\ntrain_df.fold.value_counts().plot.bar()\n\ndef petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ndef get_data(fold):\n    train_df_f = train_df.copy()  # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    dls = ImageDataLoaders.from_df(\n                    train_df_f, #pass in train DataFrame\n                   valid_col='is_valid', #\n                   seed=999, #seed\n                   fn_col='path', #filename/path is in the second column of the DataFrame\n                   label_col='norm_score', #label is in the first column of the DataFrame\n                   y_block=RegressionBlock, #The type of target\n                   bs=BATCH_SIZE, #pass in batch size\n                   num_workers=8,\n                   item_tfms=Resize(384), #pass in item_tfms\n                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(), Flip()]) #pass in batch_tfms\n                            ) \n    \n    return dls\n\ndef get_learner(fold_num):\n    data = get_data(fold_num)\n    model = create_model('swin_large_patch4_window12_384', pretrained=True, num_classes=data.c)\n    rmse = AccumMetric(petfinder_rmse)\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=[rmse]).to_fp16()\n    return learn","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:15:46.906131Z","iopub.execute_input":"2021-12-22T11:15:46.906415Z","iopub.status.idle":"2021-12-22T11:15:47.315568Z","shell.execute_reply.started":"2021-12-22T11:15:46.906375Z","shell.execute_reply":"2021-12-22T11:15:47.31488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nfor i in range(1): #1 for demonstration substitute N_FOLDS for all oof files\n\n    print(f'Fold {i} results')\n    learn = get_learner(fold_num=i)\n    if i<5: learn.path=Path('../input/sturges-bins-10fold-p1')   # download models 0-4 to {dir_name}/models\n    else: learn.path=Path('../input/sturges-bins-10fold-p2')     # download models 5-9 to {dir_name}/models from colab/kernels or local machine\n\n    #learn.model_dir=Path('models')\n    learn = learn.load(f\"model_fold_{i}\")\n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                            seed=999, #seed\n                            fn_col='path', #filename/path is in the second column of the DataFrame\n                            label_col='norm_score', #label is in the first column of the DataFrame\n                            y_block=RegressionBlock, #The type of target\n                            bs=BATCH_SIZE, #pass in batch size\n                            num_workers=8,\n                            item_tfms=Resize(384), #pass in item_tfms\n                            batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(), Flip()])) \n\n    valid = train_df[train_df.fold == i].reset_index(drop=True) # VALID, OOF Preds \n    train_predictions,_ = learn.tta(dl=dls.test_dl(valid), n=7, beta=0)\n    \n    valid['Pawpularity'] = np.stack(train_predictions)*100\n    valid.to_csv(f'oof_preds_sturges_fold_{i}.csv')\n    \n    del learn; torch.cuda.empty_cache(); gc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:26:06.113232Z","iopub.execute_input":"2021-12-22T11:26:06.113499Z","iopub.status.idle":"2021-12-22T11:33:36.772804Z","shell.execute_reply.started":"2021-12-22T11:26:06.113468Z","shell.execute_reply":"2021-12-22T11:33:36.772068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Rice Bins OOF Inference","metadata":{}},{"cell_type":"code","source":"#creating train df for using sturges bins\n\nset_seed(365, reproducible=True)\nBATCH_SIZE = 8                       \n\ntrain_df = pd.read_csv(dataset_path/'train.csv')\ntrain_df['path'] = train_df['Id'].map(lambda x:str(dataset_path/'train'/x)+'.jpg')\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n\ntrain_df['norm_score'] = train_df['Pawpularity']/100\ntrain_df['norm_score']\n\nseed=365\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True\n\nimport math\n\n#Rice rule\n\nnum_bins = int(np.ceil(2*((len(train_df))**(1./3))))\nnum_bins\n\ntrain_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\n\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\ntrain_df['fold'] = -1\nN_FOLDS = 10        #was10\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\ntrain_df.fold.value_counts().plot.bar()\n\ndef petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ndef get_data(fold):\n    train_df_f = train_df.copy()  # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    dls = ImageDataLoaders.from_df(\n                    train_df_f, #pass in train DataFrame\n                   valid_col='is_valid', #\n                   seed=365, #seed\n                   fn_col='path', #filename/path is in the second column of the DataFrame\n                   label_col='norm_score', #label is in the first column of the DataFrame\n                   y_block=RegressionBlock, #The type of target\n                   bs=BATCH_SIZE, #pass in batch size\n                   num_workers=8,\n                   item_tfms=Resize(384), #pass in item_tfms\n                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(), Flip()]) #pass in batch_tfms\n                            ) \n    \n    return dls\n\n\ndef get_learner(fold_num):\n    data = get_data(fold_num)\n    model = create_model('swin_large_patch4_window12_384', pretrained=True, num_classes=data.c)\n    rmse = AccumMetric(petfinder_rmse)\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=[rmse]).to_fp16()\n    return learn","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:33:36.774746Z","iopub.execute_input":"2021-12-22T11:33:36.775395Z","iopub.status.idle":"2021-12-22T11:33:37.134507Z","shell.execute_reply.started":"2021-12-22T11:33:36.775354Z","shell.execute_reply":"2021-12-22T11:33:37.133835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nfor i in range(1):\n\n    print(f'Fold {i} results')\n    learn = get_learner(fold_num=i)\n    if i<5: learn.path=Path('../input/rice-bins-10fold-p1')   # download models 0-4 to {dir_name}/models, for me I used gdown to download models to a kernel and saved\n    else: learn.path=Path('../input/rice-bins-10fold-p2')     # download models 5-9 to {dir_name}/models from colab/kernels or local machine\n\n    #learn.model_dir=Path('models')\n    learn = learn.load(f\"model_fold_{i}\")\n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                            seed=365, #seed\n                            fn_col='path', #filename/path is in the second column of the DataFrame\n                            label_col='norm_score', #label is in the first column of the DataFrame\n                            y_block=RegressionBlock, #The type of target\n                            bs=BATCH_SIZE, #pass in batch size\n                            num_workers=8,\n                            item_tfms=Resize(384), #pass in item_tfms\n                            batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(), Flip()])) \n\n    valid = train_df[train_df.fold == i].reset_index(drop=True) # VALID, OOF Preds \n    train_predictions,_ = learn.tta(dl=dls.test_dl(valid), n=7, beta=0)\n    \n    valid['Pawpularity'] = np.stack(train_predictions)*100\n    valid.to_csv(f'oof_preds_rice_fold_{i}.csv')\n    \n    del learn; torch.cuda.empty_cache(); gc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:33:37.135782Z","iopub.execute_input":"2021-12-22T11:33:37.136053Z","iopub.status.idle":"2021-12-22T11:41:19.741902Z","shell.execute_reply.started":"2021-12-22T11:33:37.136004Z","shell.execute_reply":"2021-12-22T11:41:19.737037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV Scores using CSV OOF Preds files","metadata":{}},{"cell_type":"code","source":"print(\"strurges bins individual CV Scores\")\nfor i in range(10):\n    train=pd.read_csv(f'../input/sturgesoof/oof_preds_fold_{i}.csv')\n    oof = np.hstack(train['Pawpularity']/100)\n    true = np.hstack(train.norm_score.values)\n    rmse = np.sqrt( np.mean( (oof - true)**2.0 ))\n    print(f'fold{i} rmse = ', rmse)\n    \nprint(\"rice bins individual CV Scores\")\nfor i in range(10):\n    train=pd.read_csv(f'../input/rice-oof/oof_preds_fold_{i}.csv')\n    oof = np.hstack(train['Pawpularity']/100)\n    true = np.hstack(train.norm_score.values)\n    rmse = np.sqrt( np.mean( (oof - true)**2.0 ))\n    print(f'fold{i} rmse = ', rmse)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:41:19.746103Z","iopub.execute_input":"2021-12-22T11:41:19.746398Z","iopub.status.idle":"2021-12-22T11:41:20.55987Z","shell.execute_reply.started":"2021-12-22T11:41:19.74636Z","shell.execute_reply":"2021-12-22T11:41:20.559232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"strurges bins\")\noof_preds = []\noof_true = []\nfor i in range(10):\n    train=pd.read_csv(f'../input/sturgesoof/oof_preds_fold_{i}.csv')\n    oof_preds.append(train['Pawpularity']/100); oof_true.append(train.norm_score.values) \n\ntrue = np.hstack(oof_true); oof = np.hstack(oof_preds)   \nrmse = 100*np.sqrt( np.mean( (oof - true)**2.0 ))\nprint(\"overall CV\", rmse)\n\nprint(\"rice bins\")\noof_preds = []\noof_true = []\nfor i in range(10):\n    train=pd.read_csv(f'../input/rice-oof/oof_preds_fold_{i}.csv')\n    oof_preds.append(train['Pawpularity']/100); oof_true.append(train.norm_score.values) \n\ntrue = np.hstack(oof_true); oof = np.hstack(oof_preds)   \nrmse = 100*np.sqrt( np.mean( (oof - true)**2.0 ))\nprint(\"overall CV\", rmse)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:41:31.581697Z","iopub.execute_input":"2021-12-22T11:41:31.581953Z","iopub.status.idle":"2021-12-22T11:41:31.694427Z","shell.execute_reply.started":"2021-12-22T11:41:31.581924Z","shell.execute_reply":"2021-12-22T11:41:31.693707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_preds = []; oof_true = []\ntrain=pd.read_csv(f'./oof_preds_sturges_fold_0.csv')\noof_preds.append(train['Pawpularity']/100); oof_true.append(train.norm_score.values) \ntrue = np.hstack(oof_true); oof = np.hstack(oof_preds)   \nrmse = 100*np.sqrt( np.mean( (oof - true)**2.0 ))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:44:45.552649Z","iopub.execute_input":"2021-12-22T11:44:45.553467Z","iopub.status.idle":"2021-12-22T11:44:45.567758Z","shell.execute_reply.started":"2021-12-22T11:44:45.553426Z","shell.execute_reply":"2021-12-22T11:44:45.566817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:44:46.118057Z","iopub.execute_input":"2021-12-22T11:44:46.118376Z","iopub.status.idle":"2021-12-22T11:44:46.123764Z","shell.execute_reply.started":"2021-12-22T11:44:46.118347Z","shell.execute_reply":"2021-12-22T11:44:46.122992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}