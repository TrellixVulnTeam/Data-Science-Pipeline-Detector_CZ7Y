{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Using FNET : [Paper_Link](https://arxiv.org/abs/2105.03824)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        break\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-31T12:22:20.439815Z","iopub.execute_input":"2021-10-31T12:22:20.440647Z","iopub.status.idle":"2021-10-31T12:22:23.257693Z","shell.execute_reply.started":"2021-10-31T12:22:20.440524Z","shell.execute_reply":"2021-10-31T12:22:23.256932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/input/petfinder-pawpularity-score')","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:22:28.712633Z","iopub.execute_input":"2021-10-31T12:22:28.713333Z","iopub.status.idle":"2021-10-31T12:22:28.730853Z","shell.execute_reply.started":"2021-10-31T12:22:28.713258Z","shell.execute_reply":"2021-10-31T12:22:28.729934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_PATH = '/kaggle/input/petfinder-pawpularity-score/train/'","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:22:28.733557Z","iopub.execute_input":"2021-10-31T12:22:28.733888Z","iopub.status.idle":"2021-10-31T12:22:28.73872Z","shell.execute_reply.started":"2021-10-31T12:22:28.733848Z","shell.execute_reply":"2021-10-31T12:22:28.737778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:22:29.422792Z","iopub.execute_input":"2021-10-31T12:22:29.423231Z","iopub.status.idle":"2021-10-31T12:22:29.462477Z","shell.execute_reply.started":"2021-10-31T12:22:29.423182Z","shell.execute_reply":"2021-10-31T12:22:29.461708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:22:29.464125Z","iopub.execute_input":"2021-10-31T12:22:29.46457Z","iopub.status.idle":"2021-10-31T12:22:29.472492Z","shell.execute_reply.started":"2021-10-31T12:22:29.464526Z","shell.execute_reply":"2021-10-31T12:22:29.471692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:22:30.121915Z","iopub.execute_input":"2021-10-31T12:22:30.122178Z","iopub.status.idle":"2021-10-31T12:22:30.143527Z","shell.execute_reply.started":"2021-10-31T12:22:30.122145Z","shell.execute_reply":"2021-10-31T12:22:30.142834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import io\nimport shutil, random\nimport tensorflow as tf\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:22:30.221024Z","iopub.execute_input":"2021-10-31T12:22:30.221317Z","iopub.status.idle":"2021-10-31T12:22:34.712223Z","shell.execute_reply.started":"2021-10-31T12:22:30.22128Z","shell.execute_reply":"2021-10-31T12:22:34.711485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom pathlib import Path\nfrom tensorflow import keras\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras import layers\nfrom keras.preprocessing import image\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:22:34.713952Z","iopub.execute_input":"2021-10-31T12:22:34.714403Z","iopub.status.idle":"2021-10-31T12:22:35.421881Z","shell.execute_reply.started":"2021-10-31T12:22:34.714366Z","shell.execute_reply":"2021-10-31T12:22:35.421169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weight_decay = 0.0001\nbatch_size = 64\nnum_epochs = 5\ndropout_rate = 0.2\nimage_size = 224  # We'll resize input images to this size.\npatch_size = 8  # Size of the patches to be extracted from the input images.\nnum_patches = (image_size // patch_size) ** 2  # Size of the data array.\nembedding_dim = 256  # Number of hidden units.\nnum_blocks = 4  # Number of blocks.\nnum_classes = 1","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:49:15.533396Z","iopub.execute_input":"2021-10-31T12:49:15.534262Z","iopub.status.idle":"2021-10-31T12:49:15.540564Z","shell.execute_reply.started":"2021-10-31T12:49:15.534213Z","shell.execute_reply":"2021-10-31T12:49:15.539564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_data = []\nlabels = []\n\nfor idx in range(df_train.shape[0]):\n#     print(df_train['Id'][idx], df_train['Pawpularity'][idx])\n    img_path = IMG_PATH + str(df_train['Id'][idx]) + '.jpg'\n    try:\n        img = tf.keras.preprocessing.image.load_img(img_path, color_mode='rgb', target_size= (image_size, image_size))\n        img = np.array(img)\n        image_data.append(img)\n        labels.append(df_train['Pawpularity'][idx])\n    except:\n        ...\n    else:\n        ...","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:43:25.085778Z","iopub.execute_input":"2021-10-31T12:43:25.086595Z","iopub.status.idle":"2021-10-31T12:45:01.571429Z","shell.execute_reply.started":"2021-10-31T12:43:25.086545Z","shell.execute_reply":"2021-10-31T12:45:01.570643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(image_data),len(labels))","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:09.855089Z","iopub.execute_input":"2021-10-31T12:45:09.855378Z","iopub.status.idle":"2021-10-31T12:45:09.860621Z","shell.execute_reply.started":"2021-10-31T12:45:09.855347Z","shell.execute_reply":"2021-10-31T12:45:09.859521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined = list(zip(image_data,labels))\nrandom.shuffle(combined)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:13.655022Z","iopub.execute_input":"2021-10-31T12:45:13.65531Z","iopub.status.idle":"2021-10-31T12:45:13.685145Z","shell.execute_reply.started":"2021-10-31T12:45:13.655264Z","shell.execute_reply":"2021-10-31T12:45:13.684423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(image_data)\nY_train = np.array(labels)\nY_train = Y_train.reshape((Y_train.shape[0], 1))\nY_train = Y_train.astype(\"float32\")\nprint(X_train.shape)\nprint(Y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:15.005535Z","iopub.execute_input":"2021-10-31T12:45:15.008778Z","iopub.status.idle":"2021-10-31T12:45:15.464036Z","shell.execute_reply.started":"2021-10-31T12:45:15.008727Z","shell.execute_reply":"2021-10-31T12:45:15.463286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:16.705081Z","iopub.execute_input":"2021-10-31T12:45:16.705363Z","iopub.status.idle":"2021-10-31T12:45:17.137847Z","shell.execute_reply.started":"2021-10-31T12:45:16.705333Z","shell.execute_reply":"2021-10-31T12:45:17.137015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.dtype","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:18.224964Z","iopub.execute_input":"2021-10-31T12:45:18.225703Z","iopub.status.idle":"2021-10-31T12:45:18.230914Z","shell.execute_reply.started":"2021-10-31T12:45:18.225655Z","shell.execute_reply":"2021-10-31T12:45:18.230265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n## Use data augmentation\n\"\"\"\n\ndata_augmentation = keras.Sequential(\n    [\n        layers.Normalization(),\n        layers.Resizing(image_size, image_size),\n        layers.RandomFlip(\"horizontal\"),\n        layers.RandomFlip(\"vertical\"),\n        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n    ],\n    name=\"data_augmentation\",\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:22.786601Z","iopub.execute_input":"2021-10-31T12:45:22.787173Z","iopub.status.idle":"2021-10-31T12:45:22.803773Z","shell.execute_reply.started":"2021-10-31T12:45:22.787132Z","shell.execute_reply":"2021-10-31T12:45:22.803073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n## Build a regression model\nWe implement a method that builds a regression model given the processing blocks.\n\"\"\"\n\n\ndef build_classifier(blocks, positional_encoding=False):\n    inputs = layers.Input(shape=(image_size, image_size, 3))\n    # Augment data.\n    augmented = data_augmentation(inputs)\n    # Create patches.\n    patches = Patches(patch_size, num_patches)(augmented)\n    # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n    x = layers.Dense(units=embedding_dim)(patches)\n    if positional_encoding:\n        positions = tf.range(start=0, limit=num_patches, delta=1)\n        position_embedding = layers.Embedding(\n            input_dim=num_patches, output_dim=embedding_dim\n        )(positions)\n        x = x + position_embedding\n    # Process x using the module blocks.\n    x = blocks(x)\n    # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor.\n    representation = layers.GlobalAveragePooling1D()(x)\n    # Apply dropout.\n    representation = layers.Dropout(rate=dropout_rate)(representation)\n    # Compute logits outputs.\n    logits = layers.Dense(num_classes, activation = 'linear')(representation)\n    # Create the Keras model.\n    return keras.Model(inputs=inputs, outputs=logits)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:33.657263Z","iopub.execute_input":"2021-10-31T12:45:33.657559Z","iopub.status.idle":"2021-10-31T12:45:33.665398Z","shell.execute_reply.started":"2021-10-31T12:45:33.657528Z","shell.execute_reply":"2021-10-31T12:45:33.664688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def root_mean_squared_error(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred - y_true))) ","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:35.555381Z","iopub.execute_input":"2021-10-31T12:45:35.556078Z","iopub.status.idle":"2021-10-31T12:45:35.563018Z","shell.execute_reply.started":"2021-10-31T12:45:35.556018Z","shell.execute_reply":"2021-10-31T12:45:35.562196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n## Define an experiment\nWe implement a utility function to compile, train, and evaluate a given model.\n\"\"\"\n\n\ndef run_experiment(model):\n    # Create Adam optimizer with weight decay.\n    optimizer = tfa.optimizers.AdamW(\n        learning_rate=learning_rate, weight_decay=weight_decay,\n    )\n    \n    # Compile the model.\n    model.compile(\n        optimizer = optimizer,\n        loss = root_mean_squared_error,\n        metrics=[\n            keras.metrics.RootMeanSquaredError()\n        ],\n    )\n    \n    # Fit the model.\n    history = model.fit(\n        x=x_train,\n        y=y_train,\n        batch_size=batch_size,\n        epochs=num_epochs,\n        validation_split=0.1,\n    )\n    \n    print(model.evaluate(x_test, y_test))\n\n    # Return history to plot learning curves.\n    return history\n    \n#     _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n#     print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n#     print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:44.363592Z","iopub.execute_input":"2021-10-31T12:45:44.364185Z","iopub.status.idle":"2021-10-31T12:45:44.370316Z","shell.execute_reply.started":"2021-10-31T12:45:44.36415Z","shell.execute_reply":"2021-10-31T12:45:44.369615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n## Implement patch extraction as a layer\n\"\"\"\n\n\nclass Patches(layers.Layer):\n    def __init__(self, patch_size, num_patches):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n        self.num_patches = num_patches\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=[1, self.patch_size, self.patch_size, 1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n        return patches","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:55.357325Z","iopub.execute_input":"2021-10-31T12:45:55.357622Z","iopub.status.idle":"2021-10-31T12:45:55.366323Z","shell.execute_reply.started":"2021-10-31T12:45:55.357592Z","shell.execute_reply":"2021-10-31T12:45:55.365468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n## The FNet model\nThe FNet uses a similar block to the Transformer block. However, FNet replaces the self-attention layer\nin the Transformer block with a parameter-free 2D Fourier transformation layer:\n1. One 1D Fourier Transform is applied along the patches.\n2. One 1D Fourier Transform is applied along the channels.\n\"\"\"\n\n\"\"\"\n### Implement the FNet module\n\"\"\"\n\nclass FNetLayer(layers.Layer):\n    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n        super(FNetLayer, self).__init__(*args, **kwargs)\n\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(units=embedding_dim),\n                tfa.layers.GELU(),\n                layers.Dropout(rate=dropout_rate),\n                layers.Dense(units=embedding_dim),\n            ]\n        )\n\n        self.normalize1 = layers.LayerNormalization(epsilon=1e-6)\n        self.normalize2 = layers.LayerNormalization(epsilon=1e-6)\n\n    def call(self, inputs):\n        # Apply fourier transformations.\n        x = tf.cast(\n            tf.signal.fft2d(tf.cast(inputs, dtype=tf.dtypes.complex64)),\n            dtype=tf.dtypes.float32,\n        )\n        # Add skip connection.\n        x = x + inputs\n        # Apply layer normalization.\n        x = self.normalize1(x)\n        # Apply Feedfowrad network.\n        x_ffn = self.ffn(x)\n        # Add skip connection.\n        x = x + x_ffn\n        # Apply layer normalization.\n        return self.normalize2(x)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:45:59.646097Z","iopub.execute_input":"2021-10-31T12:45:59.64639Z","iopub.status.idle":"2021-10-31T12:45:59.654834Z","shell.execute_reply.started":"2021-10-31T12:45:59.646358Z","shell.execute_reply":"2021-10-31T12:45:59.654143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n### Build, train, and evaluate the FNet model\n\"\"\"\n\nfnet_blocks = keras.Sequential(\n    [FNetLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n)\nlearning_rate = 0.001\nfnet_classifier = build_classifier(fnet_blocks, positional_encoding=True)\nhistory = run_experiment(fnet_classifier)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:49:36.437347Z","iopub.execute_input":"2021-10-31T12:49:36.437712Z","iopub.status.idle":"2021-10-31T12:52:06.793449Z","shell.execute_reply.started":"2021-10-31T12:49:36.437678Z","shell.execute_reply":"2021-10-31T12:52:06.792703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:23.703321Z","iopub.execute_input":"2021-10-31T12:52:23.703579Z","iopub.status.idle":"2021-10-31T12:52:23.7142Z","shell.execute_reply.started":"2021-10-31T12:52:23.703551Z","shell.execute_reply":"2021-10-31T12:52:23.713339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:24.304885Z","iopub.execute_input":"2021-10-31T12:52:24.305671Z","iopub.status.idle":"2021-10-31T12:52:24.319427Z","shell.execute_reply.started":"2021-10-31T12:52:24.305622Z","shell.execute_reply":"2021-10-31T12:52:24.317595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = df_test = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:24.993777Z","iopub.execute_input":"2021-10-31T12:52:24.994231Z","iopub.status.idle":"2021-10-31T12:52:25.002482Z","shell.execute_reply.started":"2021-10-31T12:52:24.994194Z","shell.execute_reply":"2021-10-31T12:52:25.001554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:25.755222Z","iopub.execute_input":"2021-10-31T12:52:25.755833Z","iopub.status.idle":"2021-10-31T12:52:25.768717Z","shell.execute_reply.started":"2021-10-31T12:52:25.75579Z","shell.execute_reply":"2021-10-31T12:52:25.764635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_IMG_PATH = '/kaggle/input/petfinder-pawpularity-score/test/'","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:35.78676Z","iopub.execute_input":"2021-10-31T12:52:35.787023Z","iopub.status.idle":"2021-10-31T12:52:35.792863Z","shell.execute_reply.started":"2021-10-31T12:52:35.786995Z","shell.execute_reply":"2021-10-31T12:52:35.792028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = {\n    'Id' : [],\n    'Pawpularity' : []\n}\n\nfor idx in range(df_test.shape[0]):\n#     print(df_train['Id'][idx], df_train['Pawpularity'][idx])\n    img_path = TEST_IMG_PATH + str(df_test['Id'][idx]) + '.jpg'\n    try:\n        image = tf.keras.preprocessing.image.load_img(img_path, color_mode='rgb', target_size= (image_size, image_size))\n        image = np.array(image)\n        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n        preds = fnet_classifier.predict(image)\n        output['Id'].append(df_test['Id'][idx])\n        output['Pawpularity'].append(preds[0][0])\n#         print(preds[0][0])\n    except:\n        ...\n    else:\n        ...","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:36.326989Z","iopub.execute_input":"2021-10-31T12:52:36.327806Z","iopub.status.idle":"2021-10-31T12:52:37.051061Z","shell.execute_reply.started":"2021-10-31T12:52:36.327768Z","shell.execute_reply":"2021-10-31T12:52:37.05034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(output)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:37.05256Z","iopub.execute_input":"2021-10-31T12:52:37.052807Z","iopub.status.idle":"2021-10-31T12:52:37.05758Z","shell.execute_reply.started":"2021-10-31T12:52:37.052773Z","shell.execute_reply":"2021-10-31T12:52:37.056764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:37.565798Z","iopub.execute_input":"2021-10-31T12:52:37.566055Z","iopub.status.idle":"2021-10-31T12:52:37.572485Z","shell.execute_reply.started":"2021-10-31T12:52:37.566015Z","shell.execute_reply":"2021-10-31T12:52:37.571354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:38.126539Z","iopub.execute_input":"2021-10-31T12:52:38.127432Z","iopub.status.idle":"2021-10-31T12:52:38.135944Z","shell.execute_reply.started":"2021-10-31T12:52:38.127395Z","shell.execute_reply":"2021-10-31T12:52:38.13519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T12:52:44.543058Z","iopub.execute_input":"2021-10-31T12:52:44.543362Z","iopub.status.idle":"2021-10-31T12:52:44.55604Z","shell.execute_reply.started":"2021-10-31T12:52:44.543327Z","shell.execute_reply":"2021-10-31T12:52:44.555134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}