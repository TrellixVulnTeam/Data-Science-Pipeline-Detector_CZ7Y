{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function, division\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torchvision\nimport pandas as pd\nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport torch.nn as nn\nimport albumentations","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:14:38.016146Z","iopub.execute_input":"2021-10-23T16:14:38.016853Z","iopub.status.idle":"2021-10-23T16:14:42.057155Z","shell.execute_reply.started":"2021-10-23T16:14:38.016757Z","shell.execute_reply":"2021-10-23T16:14:42.056439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom skimage import io, transform\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self,image_path,targets,augmentations=None):\n        self.image_path = image_path\n#         self.features = features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_path)\n    \n    def __getitem__(self,item):\n        image = io.imread(self.image_path[item])\n#         features = self.features[item,:]\n        targets = self.targets[item]\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n#             \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:14:49.167188Z","iopub.execute_input":"2021-10-23T16:14:49.167904Z","iopub.status.idle":"2021-10-23T16:14:49.176504Z","shell.execute_reply.started":"2021-10-23T16:14:49.167859Z","shell.execute_reply":"2021-10-23T16:14:49.175338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:14:55.614781Z","iopub.execute_input":"2021-10-23T16:14:55.615047Z","iopub.status.idle":"2021-10-23T16:15:00.78776Z","shell.execute_reply.started":"2021-10-23T16:14:55.615019Z","shell.execute_reply":"2021-10-23T16:15:00.78681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nmodel_name = 'tf_efficientnet_b2_ns'\n# file_name = \"../input/tf-efficientnet-b2-ns/tf_efficientnet_b2_ns-00306e48.pth\"\nout_dim    = 1\n\ndef get_model():\n    model = timm.create_model(model_name, pretrained=False)\n    \n#     model.load_state_dict(torch.load(file_name))\n    model.classifier = nn.Linear(model.classifier.in_features, \n                             out_dim)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:15:04.912145Z","iopub.execute_input":"2021-10-23T16:15:04.912871Z","iopub.status.idle":"2021-10-23T16:15:04.919035Z","shell.execute_reply.started":"2021-10-23T16:15:04.912825Z","shell.execute_reply":"2021-10-23T16:15:04.917998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom sklearn import metrics\nimport albumentations\ndevice = 'cuda'\nepochs = 12\ndata_path = '../input/petfinder-pawpularity-score'\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(256, 256, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:17:10.263829Z","iopub.execute_input":"2021-10-23T16:17:10.264095Z","iopub.status.idle":"2021-10-23T16:17:10.271045Z","shell.execute_reply.started":"2021-10-23T16:17:10.264066Z","shell.execute_reply":"2021-10-23T16:17:10.27009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import chain\ndevice = 'cuda'\nmodel_f = get_model()\nmodel_f.to(device)\nmodel_f.load_state_dict(torch.load('../input/model-0-effnet/model-epoch0.pth'))\ndata_path = '../input/petfinder-pawpularity-score'\ndevice = 'cuda'\ndf_test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest_images = df_test.Id.values.tolist()\ntest_images = [os.path.join(data_path,'test',i + '.jpg') for i in test_images]\n\ntest_dataset =  CustomDataset(image_path = test_images,targets = np.ones(len(test_images)),augmentations=valid_aug)\ntest_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=False) \n\n\nfinal_outputs = []\n \nwith torch.no_grad():\n    for data in test_loader:\n        inputs = data['image']\n        inputs = inputs.to(device, dtype=torch.float)\n        output = model_f(inputs)\n        output = output.detach().cpu().numpy().tolist()\n        final_outputs.extend(output)\n        \n\nfinal_outputs = list(chain.from_iterable(final_outputs))        \nsubmission = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\nsubmission['Pawpularity'] = final_outputs\nsubmission.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:17:15.543873Z","iopub.execute_input":"2021-10-23T16:17:15.544541Z","iopub.status.idle":"2021-10-23T16:17:21.986195Z","shell.execute_reply.started":"2021-10-23T16:17:15.544503Z","shell.execute_reply":"2021-10-23T16:17:21.98548Z"},"trusted":true},"execution_count":null,"outputs":[]}]}