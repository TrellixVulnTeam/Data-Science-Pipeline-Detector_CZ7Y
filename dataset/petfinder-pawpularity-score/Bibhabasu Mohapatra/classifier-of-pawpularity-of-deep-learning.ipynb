{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom skimage import io, transform\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self,image_path,features,targets,augmentations=None):\n        self.image_path = image_path\n        self.features = features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_path)\n    \n    def __getitem__(self,item):\n        image = io.imread(self.image_path[item])\n        features = self.features[item,:]\n        targets = self.targets[item]\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }\n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:25.881276Z","iopub.execute_input":"2021-11-08T06:41:25.882043Z","iopub.status.idle":"2021-11-08T06:41:31.603459Z","shell.execute_reply.started":"2021-11-08T06:41:25.881924Z","shell.execute_reply":"2021-11-08T06:41:31.602463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install timm","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:31.606352Z","iopub.execute_input":"2021-11-08T06:41:31.606994Z","iopub.status.idle":"2021-11-08T06:41:42.614719Z","shell.execute_reply.started":"2021-11-08T06:41:31.606936Z","shell.execute_reply":"2021-11-08T06:41:42.613587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:42.617169Z","iopub.execute_input":"2021-11-08T06:41:42.617549Z","iopub.status.idle":"2021-11-08T06:41:43.820986Z","shell.execute_reply.started":"2021-11-08T06:41:42.617488Z","shell.execute_reply":"2021-11-08T06:41:43.819871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timm.list_models('*swin*')","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:43.823938Z","iopub.execute_input":"2021-11-08T06:41:43.824214Z","iopub.status.idle":"2021-11-08T06:41:43.834628Z","shell.execute_reply.started":"2021-11-08T06:41:43.824178Z","shell.execute_reply":"2021-11-08T06:41:43.833646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# m = timm.create_model('swin_large_patch4_window12_384')\n# m","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:43.835989Z","iopub.execute_input":"2021-11-08T06:41:43.837197Z","iopub.status.idle":"2021-11-08T06:41:43.847928Z","shell.execute_reply.started":"2021-11-08T06:41:43.837154Z","shell.execute_reply":"2021-11-08T06:41:43.846849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,train_loader,device,optimizer):\n    model.train()\n    running_train_loss = 0.0\n    for data in train_loader:\n        inputs = data['image']\n        features = data['features']\n        targets = data['targets']\n\n        inputs = inputs.to(device, dtype=torch.float)\n        features = features.to(device,dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n\n        optimizer.zero_grad()\n        outputs = model(inputs,features)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n        running_train_loss +=loss.item()\n        \n    train_loss_value = running_train_loss/len(train_loader)\n    print(f'train BCE loss is {train_loss_value}')\n    \ndef eval(model,valid_loader,device,optimizer):\n    model.eval()\n    final_targets = []\n    final_outputs = []\n    running_val_loss = 0.0\n    with torch.no_grad():\n        for data in valid_loader:\n            inputs = data['image']\n            features = data['features']\n            targets = data['targets']\n            inputs = inputs.to(device, dtype=torch.float)\n            features = features.to(device,dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n\n            output = model(inputs,features)\n            running_val_loss += nn.BCEWithLogitsLoss()(output, targets.view(-1, 1))\n            targets = (targets.detach().cpu().numpy()*100).tolist()\n            output = (torch.sigmoid(output).detach().cpu().numpy()*100).tolist()\n            final_outputs.extend(output)\n            final_targets.extend(targets)\n        val_loss = running_val_loss/len(valid_loader)    \n        print(f'valid BCE loss is {val_loss}')\n    return final_outputs,final_targets      \n           ","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:43.85072Z","iopub.execute_input":"2021-11-08T06:41:43.851792Z","iopub.status.idle":"2021-11-08T06:41:43.86707Z","shell.execute_reply.started":"2021-11-08T06:41:43.851755Z","shell.execute_reply":"2021-11-08T06:41:43.865663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nmodel_name = 'swin_large_patch4_window12_384_in22k'\n\nout_dim    = 1\n\nclass get_model(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=True)\n        self.model.head = nn.Sequential(nn.Linear(self.model.head.in_features,768),\n                                              nn.Linear(768,256))\n        self.last = nn.Linear(256 + 12, 128)\n        self.depth1 = nn.Linear(128,64)\n        self.depth2 = nn.Linear(64,1)\n    def forward(self, image, features):\n        x = self.model(image)\n        x = self.last(torch.cat([x, features], dim=1))\n        x = self.depth1(x)\n        x = self.depth2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:43.868934Z","iopub.execute_input":"2021-11-08T06:41:43.869674Z","iopub.status.idle":"2021-11-08T06:41:43.883138Z","shell.execute_reply.started":"2021-11-08T06:41:43.869631Z","shell.execute_reply":"2021-11-08T06:41:43.882117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import model_selection\ndf = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ndf[\"kfold\"] = -1\n\ndf = df.sample(frac=1).reset_index(drop=True)\n\nkf = model_selection.StratifiedKFold(n_splits=5, shuffle=False)\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X=df,y=df.Pawpularity.values)):\n    print(len(train_idx), len(val_idx))\n    df.loc[val_idx, 'kfold'] = fold","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:43.884987Z","iopub.execute_input":"2021-11-08T06:41:43.885657Z","iopub.status.idle":"2021-11-08T06:41:44.119889Z","shell.execute_reply.started":"2021-11-08T06:41:43.885614Z","shell.execute_reply":"2021-11-08T06:41:44.118217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom sklearn import metrics\nimport albumentations\ndevice = 'cuda'\nepochs = 3\ndata_path = '../input/petfinder-pawpularity-score'\n# train_aug = albumentations.Compose(                  ##  AUGMENTATIONs TAKEN FROM ABHISHEK THAKUR's tez Pawpular training\n#     [\n#         albumentations.Resize(224,224, p=1),\n#         albumentations.Normalize(\n#             mean=[0.485, 0.456, 0.406],\n#             std=[0.229, 0.224, 0.225],\n#             max_pixel_value=255.0,\n#             p=1.0,\n#         ),\n#         albumentations.RandomBrightnessContrast(\n#             brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n#         ),\n#         albumentations.HorizontalFlip(p=0.4),         ##  THis part is from  Manav  check out his NB\n#          albumentations.VerticalFlip(p=0.3),\n#         albumentations.ShiftScaleRotate(\n#                 shift_limit = 0.1, scale_limit=0.1, rotate_limit=45, p=0.5\n#             ),\n#     ],\n#     p=1.0,\n# )\n\n# valid_aug = albumentations.Compose(\n#     [\n#         albumentations.Resize(224, 224, p=1),\n#         albumentations.Normalize(\n#             mean=[0.485, 0.456, 0.406],\n#             std=[0.229, 0.224, 0.225],\n#             max_pixel_value=255.0,\n#             p=1.0,\n#         ),\n#     ],\n#     p=1.0,\n# )\n\ntrain_aug = albumentations.Compose(\n    [\n        albumentations.Resize(384, 384, p=1),\n        albumentations.HueSaturationValue(\n            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n        ),\n        albumentations.RandomBrightnessContrast(\n            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n        ),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(384, 384, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:44.122749Z","iopub.execute_input":"2021-11-08T06:41:44.123084Z","iopub.status.idle":"2021-11-08T06:41:45.018907Z","shell.execute_reply.started":"2021-11-08T06:41:44.123056Z","shell.execute_reply":"2021-11-08T06:41:45.017901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n]","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:45.022197Z","iopub.execute_input":"2021-11-08T06:41:45.02263Z","iopub.status.idle":"2021-11-08T06:41:45.030659Z","shell.execute_reply.started":"2021-11-08T06:41:45.022564Z","shell.execute_reply":"2021-11-08T06:41:45.029668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import chain\nscores = []\nfor fold in range(5):\n        model = get_model()\n        model.to(device)\n        df_train = df[df.kfold != fold].reset_index(drop=True)\n        df_valid = df[df.kfold == fold].reset_index(drop=True)\n\n        df_train = df_train.drop(columns = 'kfold')\n        df_valid = df_valid.drop(columns = 'kfold')\n\n        train_images = df_train.Id.values.tolist()\n        train_images = [os.path.join(data_path,'train',i + '.jpg') for i in train_images]\n        valid_images = df_valid.Id.values.tolist()\n        valid_images = [os.path.join(data_path,'train',i + '.jpg') for i in valid_images]\n\n        train_targets = df_train.Pawpularity.values/100\n        valid_targets = df_valid.Pawpularity.values/100\n\n        train_dataset = CustomDataset(image_path = train_images,features=df_train[feats].values,targets = train_targets,augmentations=train_aug)\n        train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=8,shuffle=True,pin_memory=True) \n        valid_dataset = CustomDataset(image_path = valid_images,features=df_valid[feats].values,targets =valid_targets,augmentations=valid_aug)\n        valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=8,shuffle=False,pin_memory=True) \n\n        optimizer = torch.optim.Adam(model.parameters(),lr=1e-6)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=1, eta_min=1e-4, last_epoch=- 1, verbose=True)\n        print(f'============================== FOLD -- {fold} ==============================')\n        for epoch in range(epochs):\n            print(f'==================== Epoch -- {epoch} ====================')\n            train(model=model,train_loader=train_loader,device=device,optimizer=optimizer)\n            \n            final_outputs,final_targets = eval(model=model,valid_loader=valid_loader,device=device,optimizer=optimizer)\n    \n            RMSE = np.sqrt(metrics.mean_squared_error(final_targets,final_outputs))\n            scheduler.step()\n            \n            print(f'valid RMSE={RMSE}')\n        torch.save(model.state_dict(),'model-epoch'+str(fold)+'.pth')\n        scores.append(RMSE)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:41:45.033019Z","iopub.execute_input":"2021-11-08T06:41:45.033877Z","iopub.status.idle":"2021-11-08T06:42:43.042062Z","shell.execute_reply.started":"2021-11-08T06:41:45.033834Z","shell.execute_reply":"2021-11-08T06:42:43.040402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(scores)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:42:43.04361Z","iopub.status.idle":"2021-11-08T06:42:43.044415Z","shell.execute_reply.started":"2021-11-08T06:42:43.044086Z","shell.execute_reply":"2021-11-08T06:42:43.044121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from itertools import chain\n# max = 200\n# model_no = 0\n# for i in range(5):\n#     if score[i] < max:\n#         model_no = i\n#         max = scores[i]\n        \n        \n# model_f = get_model()\n# model_f.to(device)\n# model_f.load_state_dict(torch.load('./model-epoch'+str(model_no)+'.pth'))\n# data_path = '../input/petfinder-pawpularity-score'\n# device = 'cuda'\n# df_test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n# test_images = df_test.Id.values.tolist()\n# test_images = [os.path.join(data_path,'test',i + '.jpg') for i in test_images]\n\n# test_dataset =  CustomDataset(image_path = test_images,targets = np.ones(len(test_images)),augmentations=valid_aug)\n# test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=False) \n\n\n# final_outputs = []\n \n# with torch.no_grad():\n#     for data in test_loader:\n#         inputs = data['image']\n#         inputs = inputs.to(device, dtype=torch.float)\n#         output = model_f(inputs)\n#         output = output.detach().cpu().numpy().tolist()\n#         final_outputs.extend(output)\n        \n\n# final_outputs = list(chain.from_iterable(final_outputs))        \n# submission = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\n# submission['Pawpularity'] = final_outputs\n# submission.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:42:43.046043Z","iopub.status.idle":"2021-11-08T06:42:43.04684Z","shell.execute_reply.started":"2021-11-08T06:42:43.046497Z","shell.execute_reply":"2021-11-08T06:42:43.046532Z"},"trusted":true},"execution_count":null,"outputs":[]}]}