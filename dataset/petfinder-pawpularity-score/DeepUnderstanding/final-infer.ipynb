{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Public Notebook\nhttps://www.kaggle.com/cdeotte/rapids-svr-boost-17-8","metadata":{"papermill":{"duration":0.008276,"end_time":"2021-10-05T01:29:50.73785","exception":false,"start_time":"2021-10-05T01:29:50.729574","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# based on the post here: https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/275094\n\nimport sys\nsys.path.append(\"../input/tez-lib/\")\ntimm_path = \"../input/timm-pytorch-image-models/pytorch-image-models-master\"\nimport sys\nsys.path.append(timm_path)\nimport timm\n\nimport tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport timm\nimport random\nimport torch.nn as nn\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\nimport math\nimport os\n\nclass args:\n    batch_size = 16\n    image_size = 384\n    \ndef sigmoid(x):\n    return 1 / (1 + math.exp(-x))","metadata":{"_kg_hide-input":true,"papermill":{"duration":8.607495,"end_time":"2021-10-05T01:29:59.353831","exception":false,"start_time":"2021-10-05T01:29:50.746336","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T19:22:30.179072Z","iopub.execute_input":"2022-01-06T19:22:30.17939Z","iopub.status.idle":"2022-01-06T19:22:39.598668Z","shell.execute_reply.started":"2022-01-06T19:22:30.179311Z","shell.execute_reply":"2022-01-06T19:22:39.597914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        \nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T19:22:39.600228Z","iopub.execute_input":"2022-01-06T19:22:39.600481Z","iopub.status.idle":"2022-01-06T19:22:39.65561Z","shell.execute_reply.started":"2022-01-06T19:22:39.600449Z","shell.execute_reply":"2022-01-06T19:22:39.654962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }\n    \nclass PawpularModel(tez.Model):\n    def __init__(self, model_name):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n        self.model.head = nn.Linear(self.model.head.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(140, 64)\n        self.dense2 = nn.Linear(64, 1)\n\n    def forward(self, image, features, targets=None):\n        x1 = self.model(image)\n        x = self.dropout(x1)\n        x = torch.cat([x, features], dim=1)\n        x = self.dense1(x)\n        x = self.dense2(x)\n        \n        x = torch.cat([x, x1, features], dim=1)\n        return x, 0, {}\n    \ntest_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n        albumentations.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n        albumentations.RandomBrightnessContrast(p=0.5),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.028308,"end_time":"2021-10-05T01:29:59.409017","exception":false,"start_time":"2021-10-05T01:29:59.380709","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T19:22:39.658254Z","iopub.execute_input":"2022-01-06T19:22:39.658613Z","iopub.status.idle":"2022-01-06T19:22:39.675389Z","shell.execute_reply.started":"2022-01-06T19:22:39.658585Z","shell.execute_reply":"2022-01-06T19:22:39.674784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import RAPIDS","metadata":{"papermill":{"duration":0.00919,"end_time":"2021-10-05T01:29:59.427243","exception":false,"start_time":"2021-10-05T01:29:59.418053","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import cuml, pickle\nfrom cuml.svm import SVR\nprint('RAPIDS version',cuml.__version__,'\\n')\n\nLOAD_SVR_FROM_PATH = '../input/svr-models-10-folds/'\n\ndf = pd.read_csv('../input/same-old-creating-folds/train_10folds.csv')\nprint('Train shape:', df.shape )\ndf.head()","metadata":{"papermill":{"duration":3.453807,"end_time":"2021-10-05T01:30:02.890319","exception":false,"start_time":"2021-10-05T01:29:59.436512","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-11T12:33:29.641137Z","iopub.execute_input":"2022-01-11T12:33:29.641723Z","iopub.status.idle":"2022-01-11T12:33:34.00142Z","shell.execute_reply.started":"2022-01-11T12:33:29.64169Z","shell.execute_reply":"2022-01-11T12:33:34.00028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cuml, pickle\nfrom cuml.svm import SVR","metadata":{"execution":{"iopub.status.busy":"2022-01-06T19:22:43.847602Z","iopub.execute_input":"2022-01-06T19:22:43.847902Z","iopub.status.idle":"2022-01-06T19:22:43.852962Z","shell.execute_reply.started":"2022-01-06T19:22:43.847868Z","shell.execute_reply":"2022-01-06T19:22:43.852001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_true = []\n\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n    \n    model = PawpularModel(model_name=\"swin_large_patch4_window12_384\")\n    model.load(f\"../input/paw-models/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n    test_img_paths = [f\"../input/petfinder-pawpularity-score/test/{x}.jpg\" for x in df_test[\"Id\"].values]\n        \n    df_valid = df[df.kfold == fold_].reset_index(drop=True)#.iloc[:160]\n    valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    name = f\"SVR_fold_{fold_}.pkl\" \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        df_train = df[df.kfold != fold_].reset_index(drop=True)\n        train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n        train_dataset = PawpularDataset(\n            image_paths=train_img_paths,\n            dense_features=df_train[dense_features].values,\n            targets=df_train['Pawpularity'].values/100.0,\n            augmentations=test_aug,\n        )\n        print('Extracting train embedding...')\n        train_predictions = model.predict(train_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n        \n    \n        embed = np.array([]).reshape((0,128+12))\n        for preds in train_predictions:\n            embed = np.concatenate([embed,preds[:,1:]],axis=0)\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        clf = SVR(C=20.0)\n\n        clf.fit(embed.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n    \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n    test_dataset = PawpularDataset(\n        image_paths=test_img_paths,\n        dense_features=df_test[dense_features].values,\n        targets=np.ones(len(test_img_paths)),\n        augmentations=test_aug,\n    )\n    print('Predicting test...')\n    test_predictions = model.predict(test_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n    #print(test_predictions.shape)\n\n    final_test_predictions = []\n    embed = np.array([]).reshape((0,128+12))\n    for preds in test_predictions: #tqdm\n        final_test_predictions.extend(preds[:,:1].ravel().tolist())\n        embed = np.concatenate([embed,preds[:,1:]],axis=0)\n\n    \n\n    final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n    final_test_predictions2 = clf.predict(embed)\n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    ","metadata":{"papermill":{"duration":569.218368,"end_time":"2021-10-05T01:39:32.138933","exception":false,"start_time":"2021-10-05T01:30:02.920565","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T19:22:43.854485Z","iopub.execute_input":"2022-01-06T19:22:43.854761Z","iopub.status.idle":"2022-01-06T19:24:47.126768Z","shell.execute_reply.started":"2022-01-06T19:22:43.854724Z","shell.execute_reply":"2022-01-06T19:24:47.125488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FORCE SVR WEIGHT TO LOWER VALUE TO HELP PUBLIC LB\nbest_w = 0.5","metadata":{"execution":{"iopub.status.busy":"2022-01-06T19:24:47.128557Z","iopub.execute_input":"2022-01-06T19:24:47.128865Z","iopub.status.idle":"2022-01-06T19:24:47.134763Z","shell.execute_reply.started":"2022-01-06T19:24:47.128826Z","shell.execute_reply":"2022-01-06T19:24:47.133041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\ndf_test[\"Pawpularity\"] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\ndf_test = df_test[[\"Id\", \"Pawpularity\"]]\n","metadata":{"papermill":{"duration":0.228278,"end_time":"2021-10-05T01:39:34.518785","exception":false,"start_time":"2021-10-05T01:39:34.290507","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-06T19:24:47.136354Z","iopub.execute_input":"2022-01-06T19:24:47.137192Z","iopub.status.idle":"2022-01-06T19:24:47.149501Z","shell.execute_reply.started":"2022-01-06T19:24:47.137083Z","shell.execute_reply":"2022-01-06T19:24:47.148781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T19:24:47.150844Z","iopub.execute_input":"2022-01-06T19:24:47.151187Z","iopub.status.idle":"2022-01-06T19:24:47.165765Z","shell.execute_reply.started":"2022-01-06T19:24:47.151151Z","shell.execute_reply":"2022-01-06T19:24:47.164762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Our models","metadata":{}},{"cell_type":"code","source":"timm_path = \"../input/timm-pytorch-image-models/pytorch-image-models-master\"\nimport sys\nsys.path.append(timm_path)\nimport timm\nfrom timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch import optim\nimport shutil\nfrom shutil import copyfile\nimport random\nimport PIL\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings('ignore')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:30:49.636654Z","iopub.execute_input":"2022-01-11T12:30:49.63706Z","iopub.status.idle":"2022-01-11T12:30:58.220093Z","shell.execute_reply.started":"2022-01-11T12:30:49.636951Z","shell.execute_reply":"2022-01-11T12:30:58.219023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = \"../input/petfinder-pawpularity-score/test\"\ntest = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:30:58.222871Z","iopub.execute_input":"2022-01-11T12:30:58.223199Z","iopub.status.idle":"2022-01-11T12:30:58.240453Z","shell.execute_reply.started":"2022-01-11T12:30:58.223151Z","shell.execute_reply":"2022-01-11T12:30:58.239561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# YOLO detection","metadata":{}},{"cell_type":"code","source":"if not os.path.exists('/kaggle/working/yolov5s-master'):\n    shutil.copytree('/kaggle/input/yolov5s-master', '/kaggle/working/yolov5x6')\n\n# Can't figure out how to disable the font download in torchhub, so I manually copy it over to satisfy the check in plot.py\nos.mkdir('/root/.config/Ultralytics/')\ncopyfile('/kaggle/input/yolov5-model/Arial.ttf', '/root/.config/Ultralytics/Arial.ttf')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:30:58.242023Z","iopub.execute_input":"2022-01-11T12:30:58.24238Z","iopub.status.idle":"2022-01-11T12:30:58.922474Z","shell.execute_reply.started":"2022-01-11T12:30:58.242339Z","shell.execute_reply":"2022-01-11T12:30:58.921392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use torch hub to load our model locally\nmodel = torch.hub.load('/kaggle/working/yolov5x6', 'custom', path='/kaggle/input/yolov5-model/yolov5x6.pt', source='local')\nmodel.max_det = 1\nmodel.classes = [15,16]\nmodel.multi_label = False","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:30:58.925031Z","iopub.execute_input":"2022-01-11T12:30:58.925267Z","iopub.status.idle":"2022-01-11T12:31:10.911621Z","shell.execute_reply.started":"2022-01-11T12:30:58.925239Z","shell.execute_reply":"2022-01-11T12:31:10.910529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, row in test.iterrows():\n    img = Image.open(test_dir + \"/\" + row['Id'] + \".jpg\")\n    imgs = [img]\n    results = model(imgs, size=1280)\n    results.crop(save=True)\n    results.save()\n    df = results.pandas().xyxy[0]\n    \n    pet_class = \"unknown\"\n    if len(df) > 0:\n        pet_class = df['name'].values[0]\n          \n    test.loc[test['Id'] == row['Id'], 'pet_class'] = pet_class\n    \ntest.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:10.913332Z","iopub.execute_input":"2022-01-11T12:31:10.913892Z","iopub.status.idle":"2022-01-11T12:31:12.421336Z","shell.execute_reply.started":"2022-01-11T12:31:10.913844Z","shell.execute_reply":"2022-01-11T12:31:12.420049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['path'] = [test_dir +'/' + x + '.jpg' for x in test[\"Id\"].values]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.423457Z","iopub.execute_input":"2022-01-11T12:31:12.423801Z","iopub.status.idle":"2022-01-11T12:31:12.43179Z","shell.execute_reply.started":"2022-01-11T12:31:12.423757Z","shell.execute_reply":"2022-01-11T12:31:12.430381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.rmtree('./runs')\nshutil.rmtree('./yolov5x6')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.433408Z","iopub.execute_input":"2022-01-11T12:31:12.434184Z","iopub.status.idle":"2022-01-11T12:31:12.452369Z","shell.execute_reply.started":"2022-01-11T12:31:12.434141Z","shell.execute_reply":"2022-01-11T12:31:12.45125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.454559Z","iopub.execute_input":"2022-01-11T12:31:12.45491Z","iopub.status.idle":"2022-01-11T12:31:12.47671Z","shell.execute_reply.started":"2022-01-11T12:31:12.45487Z","shell.execute_reply":"2022-01-11T12:31:12.475701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dividing data into cats/dogs","metadata":{}},{"cell_type":"code","source":"cats = test[test.pet_class == 'cat'].reset_index(drop=True)\ndogs_unk = test[test.pet_class != 'cat'].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.478349Z","iopub.execute_input":"2022-01-11T12:31:12.478884Z","iopub.status.idle":"2022-01-11T12:31:12.488359Z","shell.execute_reply.started":"2022-01-11T12:31:12.478842Z","shell.execute_reply":"2022-01-11T12:31:12.487374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models\n","metadata":{}},{"cell_type":"code","source":"class Model1(nn.Module):\n    def __init__(self,pretrained):\n        super().__init__()\n        self.backbone = timm.create_model(\"tf_efficientnet_b4_ns\", pretrained=pretrained, num_classes=0, drop_rate=0., drop_path_rate=0.,global_pool='')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc3_A = nn.Linear(1792,12)\n        self.fc3_B = nn.Linear(1792,1)\n    \n    def forward(self,image):\n        image = self.backbone(image)\n        \n        if(len(image.shape) == 4):#for efficientnet models\n            image = self.pool(image)\n            image = image.view(image.shape[0], -1)\n\n        dec2 = self.fc3_B(image)\n        dec1 = self.fc3_A(image)\n        return image , dec2","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.493613Z","iopub.execute_input":"2022-01-11T12:31:12.494372Z","iopub.status.idle":"2022-01-11T12:31:12.505543Z","shell.execute_reply.started":"2022-01-11T12:31:12.49433Z","shell.execute_reply":"2022-01-11T12:31:12.504516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model2(nn.Module):\n    def __init__(self,pretrained):\n        super().__init__()\n        self.backbone = timm.create_model('swin_base_patch4_window12_384_in22k', pretrained=pretrained, num_classes=0, drop_rate=0., drop_path_rate=0.,global_pool='')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc3_A = nn.Linear(1024,12)\n        self.fc3_B = nn.Linear(1024,1)\n    \n    def forward(self,x):\n        x = self.backbone(x)\n        dec2 = self.fc3_B(x)\n        dec1 = self.fc3_A(x)\n        return x,dec2","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.507161Z","iopub.execute_input":"2022-01-11T12:31:12.507554Z","iopub.status.idle":"2022-01-11T12:31:12.516695Z","shell.execute_reply.started":"2022-01-11T12:31:12.50751Z","shell.execute_reply":"2022-01-11T12:31:12.515477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model3(nn.Module):\n    def __init__(self,pretrained):\n        super().__init__()\n        self.backbone = timm.create_model(\"swin_large_patch4_window7_224\", pretrained=False, num_classes=0, drop_rate=0.0, drop_path_rate=0.0,global_pool='')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc3_A = nn.Linear(1536,12)\n        self.fc3_B = nn.Linear(1536,1)\n        self.do = nn.Dropout(p=0.3)\n    \n    def forward(self,image):\n        image = self.backbone(image)\n        \n        if(len(image.shape) == 4):#for efficientnet models\n            image = self.pool(image)\n            image = image.view(image.shape[0], -1)\n\n        dec2 = self.fc3_B(image)\n      \n        return image , dec2","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.518741Z","iopub.execute_input":"2022-01-11T12:31:12.519374Z","iopub.status.idle":"2022-01-11T12:31:12.530413Z","shell.execute_reply.started":"2022-01-11T12:31:12.51933Z","shell.execute_reply":"2022-01-11T12:31:12.529339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model4(nn.Module):\n    def __init__(self,pretrained):\n        super().__init__()\n        self.backbone = timm.create_model(\"swin_large_patch4_window12_384\", pretrained=False, num_classes=0, drop_rate=0.0, drop_path_rate=0.0,global_pool='')\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc3_A = nn.Linear(1536,12)\n        self.fc3_B = nn.Linear(1536,1)\n        self.do = nn.Dropout(p=0.3)\n    \n    def forward(self,image):\n        image = self.backbone(image)\n        \n        if(len(image.shape) == 4):#for efficientnet models\n            image = self.pool(image)\n            image = image.view(image.shape[0], -1)\n\n        dec2 = self.fc3_B(image)\n      \n        return image , dec2","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.532093Z","iopub.execute_input":"2022-01-11T12:31:12.532712Z","iopub.status.idle":"2022-01-11T12:31:12.5451Z","shell.execute_reply.started":"2022-01-11T12:31:12.532667Z","shell.execute_reply":"2022-01-11T12:31:12.544094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augs","metadata":{}},{"cell_type":"code","source":"val_aug2 = A.Compose(\n    [ \n        A.Resize(320,320,p=1.0),\n        A.CenterCrop(224,224,p=1.0),\n        A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n        ToTensorV2()\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.5475Z","iopub.execute_input":"2022-01-11T12:31:12.547837Z","iopub.status.idle":"2022-01-11T12:31:12.55586Z","shell.execute_reply.started":"2022-01-11T12:31:12.547793Z","shell.execute_reply":"2022-01-11T12:31:12.554658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 384\nval_aug1 = A.Compose(\n    [ \n        A.Resize(480,480,p=1.0),\n        A.CenterCrop(image_size,image_size,p=1.0),\n\n        A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n        ToTensorV2()\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.557425Z","iopub.execute_input":"2022-01-11T12:31:12.558458Z","iopub.status.idle":"2022-01-11T12:31:12.566536Z","shell.execute_reply.started":"2022-01-11T12:31:12.558415Z","shell.execute_reply":"2022-01-11T12:31:12.565501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset class","metadata":{}},{"cell_type":"code","source":"class Pets(Dataset):\n    def __init__(self , df,augs = None):\n        self.df = df\n        self.augs = augs\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,idx):\n        img_src = self.df.loc[idx,'path']\n        image = cv2.imread(img_src)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        transformed = self.augs(image=image)\n        image = transformed['image']\n       \n        return image","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.568037Z","iopub.execute_input":"2022-01-11T12:31:12.56991Z","iopub.status.idle":"2022-01-11T12:31:12.579519Z","shell.execute_reply.started":"2022-01-11T12:31:12.569877Z","shell.execute_reply":"2022-01-11T12:31:12.578568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference functions","metadata":{}},{"cell_type":"code","source":"def inference_func1(test_loader , path):\n    m = Model1(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(test_loader)\n\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            _,output = m(x)\n            output = output.sigmoid()\n            output = output*100\n            PREDS += [output.detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()  \n    return PREDS","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.581397Z","iopub.execute_input":"2022-01-11T12:31:12.581772Z","iopub.status.idle":"2022-01-11T12:31:12.594191Z","shell.execute_reply.started":"2022-01-11T12:31:12.581732Z","shell.execute_reply":"2022-01-11T12:31:12.592924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_func2(test_loader , path):\n    m = Model2(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(test_loader)\n\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            _,output = m(x)\n            output = output.sigmoid()\n            output = output*100\n            PREDS += [output.detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()  \n    return PREDS","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.597209Z","iopub.execute_input":"2022-01-11T12:31:12.597589Z","iopub.status.idle":"2022-01-11T12:31:12.607582Z","shell.execute_reply.started":"2022-01-11T12:31:12.59756Z","shell.execute_reply":"2022-01-11T12:31:12.606288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_func3(test_loader , path):\n    m = Model3(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(test_loader)\n\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            _,output = m(x)\n            output = output.sigmoid()\n            output = output*100\n            PREDS += [output.detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()  \n    return PREDS","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.609993Z","iopub.execute_input":"2022-01-11T12:31:12.61129Z","iopub.status.idle":"2022-01-11T12:31:12.621244Z","shell.execute_reply.started":"2022-01-11T12:31:12.611217Z","shell.execute_reply":"2022-01-11T12:31:12.620208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dogs_unk_dataset1 = Pets(dogs_unk.reset_index(drop=True),augs = val_aug1)\ndogs_unk_loader1 = DataLoader(dogs_unk_dataset1, batch_size=16, shuffle=False,  num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.622991Z","iopub.execute_input":"2022-01-11T12:31:12.623402Z","iopub.status.idle":"2022-01-11T12:31:12.632692Z","shell.execute_reply.started":"2022-01-11T12:31:12.623359Z","shell.execute_reply":"2022-01-11T12:31:12.631387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dogs_unk_dataset2 = Pets(dogs_unk.reset_index(drop=True),augs = val_aug2)\ndogs_unk_loader2 = DataLoader(dogs_unk_dataset2, batch_size=16, shuffle=False,  num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.634139Z","iopub.execute_input":"2022-01-11T12:31:12.634889Z","iopub.status.idle":"2022-01-11T12:31:12.643765Z","shell.execute_reply.started":"2022-01-11T12:31:12.634843Z","shell.execute_reply":"2022-01-11T12:31:12.642731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting for !Cats ","metadata":{}},{"cell_type":"code","source":"if(len(dogs_unk) > 0):\n    yp1  = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 0 - val rmse 18.9697.pth')\n    yp2  = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 1 - val rmse 19.0007.pth')\n    yp3  = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 2 - val rmse 19.5034.pth')\n    yp4  = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 3 - val rmse 20.1689.pth')\n    yp5  = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 4 - val rmse 19.3915.pth')\n    yp6  = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 5 - val rmse 19.9424.pth')\n    yp7  = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 6 - val rmse 19.6432.pth')\n    yp8  = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 7 - val rmse 20.5341.pth')\n    yp9  = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 8 - val rmse 19.4683.pth')\n    yp10 = inference_func1(dogs_unk_loader1,'../input/pawpularity-models-dog-v2/tf_efficientnet_b4_ns - dog - Fold 9 - val rmse 19.4951.pth')\n    yp11 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 0 with val_rmse 18.57408182689726.pth')\n    yp12 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 1 with val_rmse 20.93912210908539.pth')\n    yp13 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 2 with val_rmse 19.520618494757.pth')\n    yp14 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 3 with val_rmse 19.780201070324544.pth')\n    yp15 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 4 with val_rmse 19.5155116100269.pth')\n    yp16 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 5 with val_rmse 20.58098075077962.pth')\n    yp17 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 6 with val_rmse 19.79990146746921.pth')\n    yp18 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 7 with val_rmse 19.779097576099065.pth')\n    yp19 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 8 with val_rmse 19.374419857287354.pth')\n    yp20 = inference_func3(dogs_unk_loader2,'../input/exp1-224-dogs/Fold 9 with val_rmse 19.94593150668674.pth')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.645338Z","iopub.execute_input":"2022-01-11T12:31:12.645892Z","iopub.status.idle":"2022-01-11T12:31:12.658703Z","shell.execute_reply.started":"2022-01-11T12:31:12.645848Z","shell.execute_reply":"2022-01-11T12:31:12.657531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(len(dogs_unk) > 0):\n    dogs_unk['Pawpularity'] = (yp1+ yp2+ yp3+yp4+yp5+yp6+yp7+yp8+yp9+yp10+yp11+yp12+yp13+yp14+yp15+yp16+yp17+yp18+yp19+yp20 )/20.","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.660274Z","iopub.execute_input":"2022-01-11T12:31:12.66179Z","iopub.status.idle":"2022-01-11T12:31:12.671555Z","shell.execute_reply.started":"2022-01-11T12:31:12.661745Z","shell.execute_reply":"2022-01-11T12:31:12.670545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dogs_unk","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.672953Z","iopub.execute_input":"2022-01-11T12:31:12.674554Z","iopub.status.idle":"2022-01-11T12:31:12.69192Z","shell.execute_reply.started":"2022-01-11T12:31:12.674491Z","shell.execute_reply":"2022-01-11T12:31:12.690971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting for images cats","metadata":{}},{"cell_type":"code","source":"cats_dataset = Pets(cats.reset_index(drop=True),augs = val_aug1)\ncats_loader = DataLoader(cats_dataset, batch_size=16, shuffle=False,  num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.693693Z","iopub.execute_input":"2022-01-11T12:31:12.694264Z","iopub.status.idle":"2022-01-11T12:31:12.700096Z","shell.execute_reply.started":"2022-01-11T12:31:12.694223Z","shell.execute_reply":"2022-01-11T12:31:12.699023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(len(cats) > 0):\n    y_p1 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 0 - val rmse 15.4214.pth')\n    y_p2 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 1 - val rmse 14.8935.pth')\n    y_p3 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 2 - val rmse 15.8637.pth')\n    y_p4 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 3 - val rmse 15.2904.pth')\n    y_p5 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 4 - val rmse 14.5136.pth')\n    y_p6 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 5 - val rmse 15.7827.pth')\n    y_p7 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 6 - val rmse 16.0911.pth')\n    y_p8 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 7 - val rmse 15.7253.pth')\n    y_p9 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 8 - val rmse 15.3140.pth')\n    y_p10 = inference_func1(cats_loader,'../input/paw-models-cat-v2/tf_efficientnet_b4_ns - cat - Fold 9 - val rmse 15.4286.pth')\n    y_p11 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 0 - val rmse 14.8155.pth')\n    y_p12 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 1 - val rmse 14.4614.pth')\n    y_p13 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 2 - val rmse 15.0405.pth')\n    y_p14 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 3 - val rmse 14.8688.pth')\n    y_p15 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 4 - val rmse 15.6885.pth')\n    y_p16 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 5 - val rmse 15.0525.pth')\n    y_p17 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 6 - val rmse 14.4531.pth')\n    y_p18 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 7 - val rmse 14.9049.pth')\n    y_p19 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 8 - val rmse 15.0138.pth')\n    y_p20 = inference_func2(cats_loader,'../input/paw-models-swin-cat/swin_base_patch4_window12_384_in22k - cat - Fold 9 - val rmse 14.6707.pth')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:31:12.702164Z","iopub.execute_input":"2022-01-11T12:31:12.702999Z","iopub.status.idle":"2022-01-11T12:32:24.588224Z","shell.execute_reply.started":"2022-01-11T12:31:12.702939Z","shell.execute_reply":"2022-01-11T12:32:24.587113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(len(cats) > 0):\n    cats['Pawpularity'] = (y_p1+ y_p2+ y_p3+y_p4+y_p5+y_p6+y_p7+y_p8+y_p9+y_p10+y_p11+y_p12+y_p13+y_p14+y_p15+y_p16+y_p17+y_p18+y_p19+y_p20 )/20.","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:32:24.590461Z","iopub.execute_input":"2022-01-11T12:32:24.591095Z","iopub.status.idle":"2022-01-11T12:32:24.599868Z","shell.execute_reply.started":"2022-01-11T12:32:24.591029Z","shell.execute_reply":"2022-01-11T12:32:24.598402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cats","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:32:24.608623Z","iopub.execute_input":"2022-01-11T12:32:24.609603Z","iopub.status.idle":"2022-01-11T12:32:24.635316Z","shell.execute_reply.started":"2022-01-11T12:32:24.609562Z","shell.execute_reply":"2022-01-11T12:32:24.634236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['path'] = [test_dir +'/' + x + '.jpg' for x in test[\"Id\"].values]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:32:24.637338Z","iopub.execute_input":"2022-01-11T12:32:24.637746Z","iopub.status.idle":"2022-01-11T12:32:24.645702Z","shell.execute_reply.started":"2022-01-11T12:32:24.637706Z","shell.execute_reply":"2022-01-11T12:32:24.644467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicing for \"All\"","metadata":{}},{"cell_type":"markdown","source":"# Effnet","metadata":{}},{"cell_type":"code","source":"def inference_funcx(oof , path):\n    oof_dataset = Pets(oof.reset_index(drop=True),augs = val_aug1)\n    oof_loader = DataLoader(oof_dataset, batch_size=16, shuffle=False,  num_workers=4)\n    m = Model1(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(oof_loader)\n\n    PREDS1 = []\n    PREDS2 = []\n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            output1,output2 = m(x)\n            output2 = output2.sigmoid()\n            output2 = output2*100\n            PREDS1 += [output1.detach().cpu()]\n            PREDS2 += [output2.detach().cpu()]\n        PREDS1 = torch.cat(PREDS1).cpu().numpy()\n        PREDS2 = torch.cat(PREDS2).cpu().numpy()  \n    return PREDS1,PREDS2","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:32:24.647657Z","iopub.execute_input":"2022-01-11T12:32:24.648Z","iopub.status.idle":"2022-01-11T12:32:24.660141Z","shell.execute_reply.started":"2022-01-11T12:32:24.647959Z","shell.execute_reply":"2022-01-11T12:32:24.659037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = []\npath.append(\"../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 0 - val rmse 17.3108.pth\")\npath.append('../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 1 - val rmse 17.4745.pth')\npath.append('../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 2 - val rmse 16.9196.pth')\npath.append('../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 3 - val rmse 17.4784.pth')\npath.append('../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 4 - val rmse 17.0746.pth')\npath.append('../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 5 - val rmse 16.9158.pth')\npath.append('../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 6 - val rmse 17.7258.pth')\npath.append('../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 7 - val rmse 16.9325.pth')\npath.append('../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 8 - val rmse 16.7591.pth')\npath.append('../input/paw-pl-models/tf_efficientnet_b4_ns - all - Fold 9 - val rmse 17.5080.pth')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:32:24.66227Z","iopub.execute_input":"2022-01-11T12:32:24.662727Z","iopub.status.idle":"2022-01-11T12:32:24.672694Z","shell.execute_reply.started":"2022-01-11T12:32:24.662686Z","shell.execute_reply":"2022-01-11T12:32:24.671414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOAD_SVR_FROM_PATH = '../input/effnet-svm-train/'","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:34:46.380737Z","iopub.execute_input":"2022-01-11T12:34:46.381149Z","iopub.status.idle":"2022-01-11T12:34:46.387013Z","shell.execute_reply.started":"2022-01-11T12:34:46.381093Z","shell.execute_reply":"2022-01-11T12:34:46.385746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_true = []\n\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n        \n    #model.load(f\"../input/paw-models/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    #df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n    #df_test['path'] = [f\"../input/petfinder-pawpularity-score/test/{x}.jpg\" for x in df_test[\"Id\"].values]\n        \n    #df_valid = df[df.kfold == fold_]\n    #valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    name = f\"eff_SVR_fold_{fold_}.pkl\" \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        df_train = df[df.kfold != fold_]\n        #train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n        print('Extracting train embedding...')\n        embedx,_ = inference_func(df_train , path[fold_])\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        clf = SVR(C=20.0)\n        clf.fit(embedx.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n    \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n\n    print('Predicting test...')\n    embedt,final_test_predictions = inference_funcx(test , path[fold_])\n\n    #final_test_predictions = []\n   \n\n    #final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n    final_test_predictions2 = clf.predict(embedt)\n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    ##################\n    \n    ##################","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:34:46.737014Z","iopub.execute_input":"2022-01-11T12:34:46.737361Z","iopub.status.idle":"2022-01-11T12:35:22.68039Z","shell.execute_reply.started":"2022-01-11T12:34:46.737312Z","shell.execute_reply":"2022-01-11T12:35:22.679381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_w = 0.45\nsuper_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\ntest['x'] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:35:22.682975Z","iopub.execute_input":"2022-01-11T12:35:22.683296Z","iopub.status.idle":"2022-01-11T12:35:22.709221Z","shell.execute_reply.started":"2022-01-11T12:35:22.683255Z","shell.execute_reply":"2022-01-11T12:35:22.708087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Swin 384","metadata":{}},{"cell_type":"code","source":"#image_size = 384\nval_augy =A.Compose(\n    [ \n        A.Resize(480,480,p=1.0),\n        A.CenterCrop(384,384,p=1.0),\n        A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n        ToTensorV2()\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:35:22.711266Z","iopub.execute_input":"2022-01-11T12:35:22.712226Z","iopub.status.idle":"2022-01-11T12:35:22.720572Z","shell.execute_reply.started":"2022-01-11T12:35:22.712161Z","shell.execute_reply":"2022-01-11T12:35:22.719417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_funcy(oof , path):\n    oof_dataset = Pets(oof.reset_index(drop=True),augs = val_augy)\n    oof_loader = DataLoader(oof_dataset, batch_size=16, shuffle=False,  num_workers=4)\n    m = Model4(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(oof_loader)\n\n    PREDS1 = []\n    PREDS2 = []\n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            output1,output2 = m(x)\n            output2 = output2.sigmoid()\n            output2 = output2*100\n            PREDS1 += [output1.detach().cpu()]\n            PREDS2 += [output2.detach().cpu()]\n        PREDS1 = torch.cat(PREDS1).cpu().numpy()\n        PREDS2 = torch.cat(PREDS2).cpu().numpy()  \n    return PREDS1,PREDS2","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:35:22.724049Z","iopub.execute_input":"2022-01-11T12:35:22.724619Z","iopub.status.idle":"2022-01-11T12:35:22.734822Z","shell.execute_reply.started":"2022-01-11T12:35:22.724575Z","shell.execute_reply":"2022-01-11T12:35:22.733759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pathy= []\npathy.append(\"../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 0 - val rmse 17.2610.pth\")\npathy.append('../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 1 - val rmse 17.2024.pth')\npathy.append('../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 2 - val rmse 16.8636.pth')\npathy.append('../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 3 - val rmse 17.7805.pth')\npathy.append('../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 4 - val rmse 16.9883.pth')\npathy.append('../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 5 - val rmse 16.5446.pth')\npathy.append('../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 6 - val rmse 16.8143.pth')\npathy.append('../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 7 - val rmse 16.8518.pth')\npathy.append('../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 8 - val rmse 16.6582.pth')\npathy.append('../input/paw-models-384-large-all/swin_large_patch4_window12_384 - all - Fold 9 - val rmse 17.6446.pth')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:35:22.736823Z","iopub.execute_input":"2022-01-11T12:35:22.737739Z","iopub.status.idle":"2022-01-11T12:35:22.748812Z","shell.execute_reply.started":"2022-01-11T12:35:22.737638Z","shell.execute_reply":"2022-01-11T12:35:22.747895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOAD_SVR_FROM_PATH = '../input/swin-svm-train-384/'\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:35:22.750399Z","iopub.execute_input":"2022-01-11T12:35:22.750817Z","iopub.status.idle":"2022-01-11T12:35:22.75929Z","shell.execute_reply.started":"2022-01-11T12:35:22.750775Z","shell.execute_reply":"2022-01-11T12:35:22.758348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_true = []\n\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n        \n    #model.load(f\"../input/paw-models/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    #df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n    #df_test['path'] = [f\"../input/petfinder-pawpularity-score/test/{x}.jpg\" for x in df_test[\"Id\"].values]\n        \n    #df_valid = df[df.kfold == fold_]\n    #valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    name = f\"SVR_fold_{fold_}.pkl\" \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        df_train = df[df.kfold != fold_]\n        #train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n        print('Extracting train embedding...')\n        embedx,_ = inference_func(df_train , pathy[fold_])\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        clf = SVR(C=20.0)\n        clf.fit(embedx.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n    \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n\n    print('Predicting test...')\n    embedt,final_test_predictions = inference_funcy(test , pathy[fold_])\n\n    #final_test_predictions = []\n   \n\n    #final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n    final_test_predictions2 = clf.predict(embedt)\n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    ##################\n    \n    ##################","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:35:22.762899Z","iopub.execute_input":"2022-01-11T12:35:22.763189Z","iopub.status.idle":"2022-01-11T12:37:34.451414Z","shell.execute_reply.started":"2022-01-11T12:35:22.763138Z","shell.execute_reply":"2022-01-11T12:37:34.450255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_w = 0.45\nsuper_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\ntest['y'] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:37:34.459475Z","iopub.execute_input":"2022-01-11T12:37:34.459804Z","iopub.status.idle":"2022-01-11T12:37:34.485556Z","shell.execute_reply.started":"2022-01-11T12:37:34.459756Z","shell.execute_reply":"2022-01-11T12:37:34.484482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# swin 224","metadata":{}},{"cell_type":"code","source":"val_augz =  A.Compose(\n    [ \n        A.Resize(329,320,p=1.0),\n        A.CenterCrop(224,224,p=1.0),\n        A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n        ToTensorV2()\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:37:34.487716Z","iopub.execute_input":"2022-01-11T12:37:34.488595Z","iopub.status.idle":"2022-01-11T12:37:34.499065Z","shell.execute_reply.started":"2022-01-11T12:37:34.488462Z","shell.execute_reply":"2022-01-11T12:37:34.498203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_funcz(oof , path):\n    oof_dataset = Pets(oof.reset_index(drop=True),augs = val_augz)\n    oof_loader = DataLoader(oof_dataset, batch_size=16, shuffle=False,  num_workers=4)\n    m = Model3(False)\n    m = m.to(device)\n    m.load_state_dict(torch.load(path))\n    m.eval()\n    bar = tqdm(oof_loader)\n\n    PREDS1 = []\n    PREDS2 = []\n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            output1,output2 = m(x)\n            output2 = output2.sigmoid()\n            output2 = output2*100\n            PREDS1 += [output1.detach().cpu()]\n            PREDS2 += [output2.detach().cpu()]\n        PREDS1 = torch.cat(PREDS1).cpu().numpy()\n        PREDS2 = torch.cat(PREDS2).cpu().numpy()  \n    return PREDS1,PREDS2","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:37:34.50349Z","iopub.execute_input":"2022-01-11T12:37:34.503721Z","iopub.status.idle":"2022-01-11T12:37:34.51349Z","shell.execute_reply.started":"2022-01-11T12:37:34.503693Z","shell.execute_reply":"2022-01-11T12:37:34.512379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pathz = []\npathz.append(\"../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 0 - val rmse 17.5231.pth\")\npathz.append('../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 1 - val rmse 17.8166.pth')\npathz.append('../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 2 - val rmse 17.4906.pth')\npathz.append('../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 3 - val rmse 17.5070.pth')\npathz.append('../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 4 - val rmse 17.4393.pth')\npathz.append('../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 5 - val rmse 17.2695.pth')\npathz.append('../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 6 - val rmse 17.9887.pth')\npathz.append('../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 7 - val rmse 17.2341.pth')\npathz.append('../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 8 - val rmse 17.0782.pth')\npathz.append('../input/paw-models-all-5-epoch/swin_large_patch4_window7_224_in22k - all - Fold 9 - val rmse 17.7036.pth')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:37:34.51526Z","iopub.execute_input":"2022-01-11T12:37:34.515823Z","iopub.status.idle":"2022-01-11T12:37:34.525695Z","shell.execute_reply.started":"2022-01-11T12:37:34.515779Z","shell.execute_reply":"2022-01-11T12:37:34.524647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOAD_SVR_FROM_PATH = '../input/svm-swin-train-224/'","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:37:34.527604Z","iopub.execute_input":"2022-01-11T12:37:34.528018Z","iopub.status.idle":"2022-01-11T12:37:34.5401Z","shell.execute_reply.started":"2022-01-11T12:37:34.527975Z","shell.execute_reply":"2022-01-11T12:37:34.538969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:37:34.542Z","iopub.execute_input":"2022-01-11T12:37:34.542471Z","iopub.status.idle":"2022-01-11T12:37:34.568945Z","shell.execute_reply.started":"2022-01-11T12:37:34.542429Z","shell.execute_reply":"2022-01-11T12:37:34.568037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_true = []\n\nfor fold_ in range(10):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n        \n    #model.load(f\"../input/paw-models/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    #df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n    #df_test['path'] = [f\"../input/petfinder-pawpularity-score/test/{x}.jpg\" for x in df_test[\"Id\"].values]\n        \n    #df_valid = df1[df1.kfold == fold_]\n    #valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n    \n    name = f\"SVR_fold_{fold_}.pkl\" \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        df_train = df1[df1.kfold != fold_]\n        #train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n        \n        print('Extracting train embedding...')\n        embedx,_ = inference_funcz(df_train , pathz[fold_])\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        clf = SVR(C=20.0)\n        clf.fit(embedx.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n    \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n\n    print('Predicting test...')\n    embedt,final_test_predictions = inference_funcz(test , pathz[fold_])\n\n    #final_test_predictions = []\n   \n\n    #final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n    final_test_predictions2 = clf.predict(embedt)\n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    ##################\n    \n    ##################","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:37:34.572205Z","iopub.execute_input":"2022-01-11T12:37:34.572466Z","iopub.status.idle":"2022-01-11T12:39:45.493743Z","shell.execute_reply.started":"2022-01-11T12:37:34.57244Z","shell.execute_reply":"2022-01-11T12:39:45.492752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_w = 0.55\nsuper_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\ntest['z'] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:39:45.495953Z","iopub.execute_input":"2022-01-11T12:39:45.496345Z","iopub.status.idle":"2022-01-11T12:39:45.525319Z","shell.execute_reply.started":"2022-01-11T12:39:45.496274Z","shell.execute_reply":"2022-01-11T12:39:45.524349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['xx'] = (test.x+test.z+test.y)/3.","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:39:45.526869Z","iopub.execute_input":"2022-01-11T12:39:45.527221Z","iopub.status.idle":"2022-01-11T12:39:45.619493Z","shell.execute_reply.started":"2022-01-11T12:39:45.527157Z","shell.execute_reply":"2022-01-11T12:39:45.618562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"Pawpularity\"] = -1.\ntest[\"Pawpularity\"] = test[\"Pawpularity\"].astype(np.float)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:39:45.621218Z","iopub.execute_input":"2022-01-11T12:39:45.621571Z","iopub.status.idle":"2022-01-11T12:39:45.648028Z","shell.execute_reply.started":"2022-01-11T12:39:45.62153Z","shell.execute_reply":"2022-01-11T12:39:45.646942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(len(cats) > 0):\n    for index, row in cats.iterrows():\n        test.loc[test['Id'] == row['Id'], 'Pawpularity'] = row['Pawpularity']\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:32:25.039638Z","iopub.status.idle":"2022-01-11T12:32:25.040169Z","shell.execute_reply.started":"2022-01-11T12:32:25.039873Z","shell.execute_reply":"2022-01-11T12:32:25.039901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(len(dogs_unk) > 0):\n    for index, row in dogs_unk.iterrows():\n        test.loc[test['Id'] == row['Id'], 'Pawpularity'] = row['Pawpularity']","metadata":{"execution":{"iopub.status.busy":"2022-01-11T12:32:25.042102Z","iopub.status.idle":"2022-01-11T12:32:25.042685Z","shell.execute_reply.started":"2022-01-11T12:32:25.042384Z","shell.execute_reply":"2022-01-11T12:32:25.042412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Weighted Averaging different models","metadata":{}},{"cell_type":"code","source":"test[\"Pawpularity\"] =  0.45*test[\"Pawpularity\"] + 0.55*test['xx']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = test[[\"Id\" , \"Pawpularity\"]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[\"Pawpularity\"] = 0.5*sub[\"Pawpularity\"] + 0.5*df_test[\"Pawpularity\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{},"execution_count":null,"outputs":[]}]}