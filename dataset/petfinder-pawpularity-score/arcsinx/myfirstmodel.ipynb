{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\n\nimport numpy as np\nimport pandas as pd\n\nimport albumentations\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-29T07:50:25.760708Z","iopub.execute_input":"2021-12-29T07:50:25.761378Z","iopub.status.idle":"2021-12-29T07:50:25.765356Z","shell.execute_reply.started":"2021-12-29T07:50:25.761341Z","shell.execute_reply":"2021-12-29T07:50:25.764574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CSV-data reading\n\ndf_train = pd.read_csv(\"/kaggle/input/petfinder-pawpularity-score/train.csv\")\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:50:26.607377Z","iopub.execute_input":"2021-12-29T07:50:26.607892Z","iopub.status.idle":"2021-12-29T07:50:26.634652Z","shell.execute_reply.started":"2021-12-29T07:50:26.607853Z","shell.execute_reply":"2021-12-29T07:50:26.633909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Small changes in dataframe for convenience\n\n#df_train.rename(columns = lambda x: x.lower(), inplace=True)\ndf_train['Id'] = df_train['Id'].astype(str) + \".jpg\"","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:50:28.97901Z","iopub.execute_input":"2021-12-29T07:50:28.979594Z","iopub.status.idle":"2021-12-29T07:50:28.987466Z","shell.execute_reply.started":"2021-12-29T07:50:28.979557Z","shell.execute_reply":"2021-12-29T07:50:28.986785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EDA and data preprocessing","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:50:30.480097Z","iopub.execute_input":"2021-12-29T07:50:30.480534Z","iopub.status.idle":"2021-12-29T07:50:30.487447Z","shell.execute_reply.started":"2021-12-29T07:50:30.480497Z","shell.execute_reply":"2021-12-29T07:50:30.486504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data generators for loading\n\nTRAIN_DIR = '/kaggle/input/petfinder-pawpularity-score/train'\n#TEST_DIR = '/kaggle/input/petfinder-pawpularity-score/test'\n\nWIDTH = 64\nHEIGHT = 64\nBATCH_SIZE = 16\n\nimg_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n                        rescale = 1./255, horizontal_flip = True,\n                        fill_mode = \"nearest\", zoom_range = 0.2,\n                        width_shift_range = 0.2, height_shift_range=0.2,\n                        rotation_range=30, validation_split=0.2) \n\ntrain_img_generator = img_datagen.flow_from_dataframe(\n                        dataframe = df_train, directory = TRAIN_DIR, \n                        x_col = \"Id\", y_col = df_train.columns[1:],\n                        class_mode = \"raw\", target_size = (WIDTH, HEIGHT), \n                        batch_size = BATCH_SIZE, subset=\"training\")\n\ntest_img_generator = img_datagen.flow_from_dataframe(\n                        dataframe = df_train, directory = TRAIN_DIR, \n                        x_col = \"Id\", y_col = df_train.columns[1:],\n                        class_mode = \"raw\", target_size = (WIDTH, HEIGHT), \n                        batch_size = BATCH_SIZE, subset=\"validation\")\n\ndef train_custom_generator():\n    # to keep track of complete epoch\n    count = 0 \n    while True:\n        if count == 495:\n            train_img_generator.reset()\n            count = 0 \n            #break\n        count += 1\n        data = train_img_generator.next()\n       \n        imgs = []\n        cols = []\n        targets = []\n\n        # iterate the data and append the necessary columns in the corresponding arrays \n        for k in range(BATCH_SIZE):\n            # the first array contains all images\n            imgs.append(data[0][k])\n      \n            # the second array contains all features with last column as class, so [:-1]\n            cols.append(data[1][k][:-1])\n\n            # the last column in the second array from data is the class\n            targets.append(data[1][k][-1])\n\n        # this will yield the result as you expect.\n        yield [np.array(imgs), np.array(cols)], np.array(targets)\n        \ndef test_custom_generator():\n    # to keep track of complete epoch\n    count = 0 \n    while True:\n        if count == 123:\n            count = 0 \n            # if the count is matching with the length of df, \n            # the one pass is completed, so reset the generator\n            test_img_generator.reset()\n            #break\n        count += 1\n        # get the data from the generator\n        data = test_img_generator.next()\n\n        # the data looks like this [[img,img] , [other_cols,other_cols]]  based on the batch size        \n        imgs = []\n        cols = []\n        targets = []\n\n        # iterate the data and append the necessary columns in the corresponding arrays \n        for k in range(BATCH_SIZE):\n            # the first array contains all images\n            imgs.append(data[0][k])\n      \n            # the second array contains all features with last column as class, so [:-1]\n            cols.append(data[1][k][:-1])\n\n            # the last column in the second array from data is the class\n            targets.append(data[1][k][-1])\n\n        # this will yield the result as you expect.\n        yield [np.array(imgs), np.array(cols)], np.array(targets)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:50:30.844437Z","iopub.execute_input":"2021-12-29T07:50:30.844928Z","iopub.status.idle":"2021-12-29T07:50:33.958727Z","shell.execute_reply.started":"2021-12-29T07:50:30.844876Z","shell.execute_reply":"2021-12-29T07:50:33.957972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model creation\n\"\"\"\ninput1 = tf.keras.layers.Input(shape = (WIDTH, HEIGHT, 3, ), name = 'input1')\ninput2 = tf.keras.layers.Input(shape = (12,), name = 'input2')\n\nconv1 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=(WIDTH, HEIGHT, 3))(input1)\nmaxp1 = tf.keras.layers.MaxPooling2D((2, 2))(conv1)\n\nconv2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(maxp1)\nmaxp2 = tf.keras.layers.MaxPooling2D((2, 2))(conv2)\n\nconv3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(maxp2)\nmaxp3 = tf.keras.layers.MaxPooling2D((2, 2))(conv3)\n\nflat1 = tf.keras.layers.Flatten()(conv3)\ndense1 = tf.keras.layers.Dense(12, activation='relu')(flat1)\nmerge1 = tf.keras.layers.Concatenate(axis = 1, name = 'inputs_merge_1')([dense1, input2])\n\ndense2 = tf.keras.layers.Dense(64, activation='relu')(merge1)\ndense3 = tf.keras.layers.Dense(32, activation='relu')(dense2)\n\npred = tf.keras.layers.Dense(1, activation='linear')(dense3)\n\n# Model init and check out\n\nmodel = tf.keras.models.Model(inputs = [input1, input2], outputs = pred)\nmodel.summary()\n\nnb_train_steps = math.floor(7930 / BATCH_SIZE)\nnb_valid_steps = math.floor(1982 / BATCH_SIZE)\n\nnb_epochs = 50\n\nprint(nb_train_steps * BATCH_SIZE)\nprint(nb_valid_steps * BATCH_SIZE)\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\"),\n              metrics=['mse'])\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:32:06.790016Z","iopub.execute_input":"2021-12-29T07:32:06.790259Z","iopub.status.idle":"2021-12-29T07:32:06.796953Z","shell.execute_reply.started":"2021-12-29T07:32:06.790225Z","shell.execute_reply":"2021-12-29T07:32:06.796284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_input = tf.keras.layers.Input(shape = (12, ), name = 'CSV_Input')\nimg_input = tf.keras.layers.Input(shape = (WIDTH, HEIGHT, 3, ), name = 'IMG_Input')\n\ncsv_hidden1 = tf.keras.layers.Dense(50, activation='relu', name='CSV_Hidden1')(csv_input)\ncsv_hidden2 = tf.keras.layers.Dense(80, activation='relu', name='CSV_Hidden2')(csv_hidden1)\ncsv_hidden3 = tf.keras.layers.Dense(100, activation='relu', name='CSV_Hidden3')(csv_hidden2)\ncsv_hidden4 = tf.keras.layers.Dense(300, activation='relu', name='CSV_Hidden4')(csv_hidden3)\ncsv_dropout = tf.keras.layers.Dropout(0.15, name ='CSV_Dropout')(csv_hidden4)\n\nimg_batch1 = tf.keras.layers.BatchNormalization(name='IMG_Normal1')(img_input)\nimg_conv1 = tf.keras.layers.Conv2D(1000, 4, padding = 'same', activation = 'relu', name='IMG_Conv1' ,use_bias=False)(img_batch1)\nimg_pooling1 = tf.keras.layers.MaxPooling2D(4, name= 'IMG_Max1')(img_conv1)\nimg_batch2 = tf.keras.layers.BatchNormalization(name='IMG_Normal2')(img_pooling1)\nimg_conv2 = tf.keras.layers.Conv2D(1000, 4, padding = 'same', activation = 'relu', name='IMG_Conv2' ,use_bias=False)(img_batch2)\nimg_batch3 = tf.keras.layers.BatchNormalization(name='IMG_Normal3')(img_conv2)\nimg_conv3 = tf.keras.layers.Conv2D(1000, 4, padding = 'same', activation = 'relu', name='IMG_Conv3' ,use_bias=False)(img_batch3)\nimg_pooling2 = tf.keras.layers.MaxPooling2D(4, name= 'IMG_Max2')(img_conv3)\nimg_batch4 = tf.keras.layers.BatchNormalization(name='IMG_Normal4')(img_pooling2)\nimg_conv4 = tf.keras.layers.Conv2D(1000, 4, padding = 'same', activation = 'relu', name='IMG_Conv4' ,use_bias=False)(img_pooling2)\nimg_batch5 = tf.keras.layers.BatchNormalization(name='IMG_Normal5')(img_conv4)\nimg_conv5 = tf.keras.layers.Conv2D(1000, 4, padding = 'same', activation = 'relu', name='IMG_Conv5' ,use_bias=False)(img_batch5)\nimg_pooling3 = tf.keras.layers.MaxPooling2D(4, name= 'IMG_Max3')(img_conv5)\n\nflatten = tf.keras.layers.Flatten(name='IMG_Flatten')(img_pooling3)\nimg_batch6 = tf.keras.layers.BatchNormalization(name='IMG_Normal6')(flatten)\nimg_hidden1 = tf.keras.layers.Dense(2000, activation='relu', name='IMG_hidden1' ,use_bias=False)(img_batch6)\nimg_dropout1 = tf.keras.layers.Dropout(0.15, name='IMG_Dropout1')(img_hidden1)\nimg_batch7 = tf.keras.layers.BatchNormalization(name='IMG_Normal7')(img_dropout1)\nimg_hidden2 = tf.keras.layers.Dense(1000, activation='relu', name='IMG_hidden2' ,use_bias=False)(img_batch7)\nimg_dropout2 = tf.keras.layers.Dropout(0.15, name='IMG_Dropout2')(img_hidden2)\n\n#csv_output = tf.keras.layers.Dense(1, name = 'CSV_Output')(csv_dropout)\n#img_output = tf.keras.layers.Dense(1,name = 'IMG_Output')(img_dropout2)\n\nmerge1 = tf.keras.layers.Concatenate(axis = 1, name = 'inputs_merge_1')([csv_dropout, img_dropout2])\noutput = tf.keras.layers.Dense(1, name = 'output')(merge1)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:32:06.798216Z","iopub.execute_input":"2021-12-29T07:32:06.798635Z","iopub.status.idle":"2021-12-29T07:32:09.207347Z","shell.execute_reply.started":"2021-12-29T07:32:06.798601Z","shell.execute_reply":"2021-12-29T07:32:09.206329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Model(inputs=[img_input, csv_input], outputs = output, name='model_reg')\n\nopt = tf.keras.optimizers.Ftrl(learning_rate = 0.003, learning_rate_power = -0.5)\n#model.compile(loss=['mse','mse'], loss_weights=[0.3, 0.7], optimizer = opt, metrics = ['mape'])\nmodel.compile(loss=tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\"),\n              metrics=['mse', 'mape'], optimizer = opt)\n\ncheck_1 = tf.keras.callbacks.ModelCheckpoint('model_reg.h5', save_best_only=True, verbose=2)\n\nnb_train_steps = math.floor(7930 / BATCH_SIZE)\nnb_valid_steps = math.floor(1982 / BATCH_SIZE)\n\nnb_epochs = 20\n\nm = model.fit( \n    train_custom_generator(), \n    steps_per_epoch = nb_train_steps, \n    epochs = nb_epochs, \n    validation_data = test_custom_generator(),\n    validation_steps = nb_valid_steps,\n    callbacks = [check_1])\n    # workers = 3 // generator isn't safe for multiprocessing","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:32:09.209215Z","iopub.execute_input":"2021-12-29T07:32:09.20984Z","iopub.status.idle":"2021-12-29T07:39:41.148219Z","shell.execute_reply.started":"2021-12-29T07:32:09.2098Z","shell.execute_reply":"2021-12-29T07:39:41.147203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/petfinder-pawpularity-score/test.csv\")\n\n#df_test.rename(columns = lambda x: x.lower(), inplace=True)\ndf_test['Id'] = df_test['Id'].astype(str) + \".jpg\"","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:50:43.798665Z","iopub.execute_input":"2021-12-29T07:50:43.798931Z","iopub.status.idle":"2021-12-29T07:50:43.809551Z","shell.execute_reply.started":"2021-12-29T07:50:43.798885Z","shell.execute_reply":"2021-12-29T07:50:43.807735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_DIR = '/kaggle/input/petfinder-pawpularity-score/test'\n\nWIDTH = 64\nHEIGHT = 64\nTEST_BATCH_SIZE = 1\n\nimg_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255) \n\nimg_generator = img_datagen.flow_from_dataframe(\n                dataframe = df_test, directory = TEST_DIR, \n                x_col = \"Id\", y_col = df_test.columns[1:],\n                class_mode = \"raw\", target_size = (WIDTH, HEIGHT), \n                batch_size = TEST_BATCH_SIZE)\n  \ndef custom_generator(df, batch_size):\n    count = 0 \n    while True:\n        print(count)\n        if count == len(df)/batch_size:\n            print(len(df)/batch_size)\n            count = 0 \n            img_generator.reset()\n            break\n            \n        data = img_generator.next()\n        count += 1\n        imgs = []\n        cols = []\n        for k in range(TEST_BATCH_SIZE):\n            imgs.append(data[0][k])\n            cols.append(data[1][k])\n        yield [np.array(imgs), np.array(cols)]","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:50:53.046328Z","iopub.execute_input":"2021-12-29T07:50:53.046587Z","iopub.status.idle":"2021-12-29T07:50:53.06835Z","shell.execute_reply.started":"2021-12-29T07:50:53.046558Z","shell.execute_reply":"2021-12-29T07:50:53.067587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = tf.keras.models.load_model('model_reg.h5')\nresult = best_model.predict(custom_generator(df = df_test, batch_size = 1))\nfinal_result = pd.DataFrame(result)\nfinal_result.columns =['Pawpularity']\nfinal_result","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:50:56.884186Z","iopub.execute_input":"2021-12-29T07:50:56.884875Z","iopub.status.idle":"2021-12-29T07:50:59.014412Z","shell.execute_reply.started":"2021-12-29T07:50:56.884837Z","shell.execute_reply":"2021-12-29T07:50:59.013715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\ndf_test['Id'] = df_test['Id'].str.replace(\".jpg\", \"\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:51:03.058621Z","iopub.execute_input":"2021-12-29T07:51:03.058879Z","iopub.status.idle":"2021-12-29T07:51:03.068506Z","shell.execute_reply.started":"2021-12-29T07:51:03.058852Z","shell.execute_reply":"2021-12-29T07:51:03.067563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nisExist = os.path.exists('./working')\nif not isExist:\n  os.makedirs('./working')\n\ntry:\n    f = open(\"submission.csv\", \"x\")\n    f.close()\nexcept Exception as error:\n        print('Caught this error: ' + repr(error))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T08:01:36.336633Z","iopub.execute_input":"2021-12-29T08:01:36.336882Z","iopub.status.idle":"2021-12-29T08:01:36.342601Z","shell.execute_reply.started":"2021-12-29T08:01:36.336856Z","shell.execute_reply":"2021-12-29T08:01:36.341797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ids, paw in zip(df_test['Id'], final_result['Pawpularity']):\n    location = submission[submission['Id'] == ids].index[0]\n    submission['Pawpularity'].loc[location] = paw\nsubmission\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T08:01:37.901194Z","iopub.execute_input":"2021-12-29T08:01:37.90145Z","iopub.status.idle":"2021-12-29T08:01:37.915467Z","shell.execute_reply.started":"2021-12-29T08:01:37.901416Z","shell.execute_reply":"2021-12-29T08:01:37.914668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}