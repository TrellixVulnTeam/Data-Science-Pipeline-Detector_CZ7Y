{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [PetFinder.my - Pawpularity Contest](https://www.kaggle.com/c/petfinder-pawpularity-score)\n> Predict the popularity of shelter pet photos\n\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/25383/logos/header.png)","metadata":{}},{"cell_type":"markdown","source":"# Idea:\n* Basic idea of this notebook is to use only **Image** Feature.\n* Tabular data will be merged on later Notebooks. \n* **Wandb** is integrated hence we can use this notebook to track which experiemnt is peforming better and also do error analysis using **Grad-CAM** at the end.\n","metadata":{}},{"cell_type":"markdown","source":"# Notebooks:\n* train: [[TF] PetFinder: Image [TPU][Train] üê∂](https://www.kaggle.com/awsaf49/tf-petfinder-image-tpu-train)\n* infer: [[TF] PetFinder: Image [TPU][Infer] üê∂](https://www.kaggle.com/awsaf49/tf-petfinder-image-tpu-infer)\n","metadata":{}},{"cell_type":"markdown","source":"# Content:\n* Install Libraries.\n* Import Libraries.\n* Libraries Version Check\n* Configuration.\n* DEVICE Configs.\n* Meta Data.\n* Train-Test Distrubution\n* Data Augmentation.\n* Data Pipeline.\n* Model Config.\n* Inference\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Install Libraries","metadata":{}},{"cell_type":"code","source":"!pip install -q /kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle","metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-26T13:00:44.652768Z","iopub.execute_input":"2021-09-26T13:00:44.653196Z","iopub.status.idle":"2021-09-26T13:00:54.77775Z","shell.execute_reply.started":"2021-09-26T13:00:44.653072Z","shell.execute_reply":"2021-09-26T13:00:54.776925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np, random,os, shutil\nimport tensorflow as tf, re, math\nimport tensorflow.keras.backend as K\nimport efficientnet.tfkeras as efn\nimport sklearn\nimport matplotlib.pyplot as plt\nimport tensorflow_addons as tfa\nimport yaml\n\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-09-26T13:00:54.779698Z","iopub.execute_input":"2021-09-26T13:00:54.77997Z","iopub.status.idle":"2021-09-26T13:00:59.948077Z","shell.execute_reply.started":"2021-09-26T13:00:54.779934Z","shell.execute_reply":"2021-09-26T13:00:59.947324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Version Check","metadata":{}},{"cell_type":"code","source":"print('np:', np.__version__)\nprint('pd:', pd.__version__)\nprint('sklearn:', sklearn.__version__)\nprint('tf:',tf.__version__)\nprint('tfa:', tfa.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T13:00:59.949101Z","iopub.execute_input":"2021-09-26T13:00:59.949349Z","iopub.status.idle":"2021-09-26T13:00:59.959768Z","shell.execute_reply.started":"2021-09-26T13:00:59.949319Z","shell.execute_reply":"2021-09-26T13:00:59.957609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # DBUG OR not\n    debug = False\n    \n    # DEVICE\n    device = 'GPU'\n\n\n    # IMAGE SIZE\n    img_size = [512, 512]\n\n    # BATCH SIZE AND EPOCHS\n    batch_size  = 32\n\n    # CFG.augmentATION\n    augment   = True\n    transform = False\n\n    # TRANSFORMATION\n    fill_mode = 'nearest'\n    rot    = 10.0\n    shr    = 5.0\n    hzoom  = 30.0\n    wzoom  = 30.0\n    hshift = 30.0\n    wshift = 30.0\n\n    # FLIP\n    hflip = True\n    vflip = False\n\n    # CLIP [0, 1]\n    clip = False\n\n    # Dropout\n    drop_prob   = 0.75\n    drop_cnt    = 10\n    drop_size   = 0.05\n\n    #bri, contrast\n    sat  = [0.7, 1.3]\n    cont = [0.8, 1.2]\n    bri  =  0.15\n    hue  = 0.05\n\n    # TEST TIME CFG.augmentATION STEPS\n    tta = 5\n    \n    tab_cols    = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n                   'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n    target_col  = ['Pawpularity']","metadata":{"execution":{"iopub.status.busy":"2021-09-26T13:00:59.962944Z","iopub.execute_input":"2021-09-26T13:00:59.964016Z","iopub.status.idle":"2021-09-26T13:00:59.971994Z","shell.execute_reply.started":"2021-09-26T13:00:59.963988Z","shell.execute_reply":"2021-09-26T13:00:59.971261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DEVICE Configs","metadata":{}},{"cell_type":"code","source":"if CFG.device == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        CFG.device = \"GPU\"\n\nif CFG.device != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif CFG.device == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-26T13:00:59.973202Z","iopub.execute_input":"2021-09-26T13:00:59.973747Z","iopub.status.idle":"2021-09-26T13:01:00.133711Z","shell.execute_reply.started":"2021-09-26T13:00:59.973712Z","shell.execute_reply":"2021-09-26T13:01:00.132225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Base Path for Dataset","metadata":{}},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/petfinder-pawpularity-score'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-26T13:01:00.1348Z","iopub.execute_input":"2021-09-26T13:01:00.135082Z","iopub.status.idle":"2021-09-26T13:01:00.141597Z","shell.execute_reply.started":"2021-09-26T13:01:00.135041Z","shell.execute_reply":"2021-09-26T13:01:00.140896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Meta Data","metadata":{}},{"cell_type":"code","source":"# Train Data\ndf = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ndf['image_path'] = BASE_PATH + '/train/' + df.Id + '.jpg'\ndisplay(df.head(2))\n\n# Test Data\ntest_df  = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest_df['image_path'] = BASE_PATH + '/test/' + test_df.Id + '.jpg'\n\ndisplay(test_df.head(2))","metadata":{"execution":{"iopub.status.busy":"2021-09-26T13:01:00.143175Z","iopub.execute_input":"2021-09-26T13:01:00.144174Z","iopub.status.idle":"2021-09-26T13:01:00.224148Z","shell.execute_reply.started":"2021-09-26T13:01:00.144138Z","shell.execute_reply":"2021-09-26T13:01:00.223525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train-Test Ditribution","metadata":{}},{"cell_type":"code","source":"print('train_files:',df.shape[0])\nprint('test_files:',test_df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-26T13:01:00.225322Z","iopub.execute_input":"2021-09-26T13:01:00.225575Z","iopub.status.idle":"2021-09-26T13:01:00.231124Z","shell.execute_reply.started":"2021-09-26T13:01:00.225544Z","shell.execute_reply":"2021-09-26T13:01:00.229784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation\nUsed simple augmentations, some of them may hurt the model.\n* RandomFlip (Left-Right)\n* No Rotation\n* RandomBrightness\n* RndomContrast\n* Shear\n* Zoom\n* Coarsee Dropout/Cutout","metadata":{}},{"cell_type":"code","source":"def get_mat(shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    #rotation = math.pi * rotation / 180.\n    shear    = math.pi * shear    / 180.\n\n    def get_3x3_mat(lst):\n        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n    \n    # ROTATION MATRIX\n#     c1   = tf.math.cos(rotation)\n#     s1   = tf.math.sin(rotation)\n    one  = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    \n#     rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n#                                    -s1,  c1,   zero, \n#                                    zero, zero, one])    \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)    \n    \n    shear_matrix = get_3x3_mat([one,  s2,   zero, \n                               zero, c2,   zero, \n                                zero, zero, one])        \n    # ZOOM MATRIX\n    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n                               zero,            one/width_zoom, zero, \n                               zero,            zero,           one])    \n    # SHIFT MATRIX\n    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n                                zero, one,  width_shift, \n                                zero, zero, one])\n    \n\n    return  K.dot(shear_matrix,K.dot(zoom_matrix, shift_matrix)) #K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))                  \n\ndef transform(image, DIM=CFG.img_size):#[rot,shr,h_zoom,w_zoom,h_shift,w_shift]):\n    if DIM[0]!=DIM[1]:\n        pad = (DIM[0]-DIM[1])//2\n        image = tf.pad(image, [[0, 0], [pad, pad+1],[0, 0]])\n        \n    NEW_DIM = DIM[0]\n    \n    rot = CFG.rot * tf.random.normal([1], dtype='float32')\n    shr = CFG.shr * tf.random.normal([1], dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / CFG.hzoom\n    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / CFG.wzoom\n    h_shift = CFG.hshift * tf.random.normal([1], dtype='float32') \n    w_shift = CFG.wshift * tf.random.normal([1], dtype='float32') \n    \n    transformation_matrix=tf.linalg.inv(get_mat(shr,h_zoom,w_zoom,h_shift,w_shift))\n    \n    flat_tensor=tfa.image.transform_ops.matrices_to_flat_transforms(transformation_matrix)\n    \n    image=tfa.image.transform(image,flat_tensor, fill_mode=CFG.fill_mode)\n    \n    rotation = math.pi * rot / 180.\n    \n    image=tfa.image.rotate(image,-rotation, fill_mode=CFG.fill_mode)\n    \n    if DIM[0]!=DIM[1]:\n        image=tf.reshape(image, [NEW_DIM, NEW_DIM,3])\n        image = image[:, pad:DIM[1]+pad,:]\n    image = tf.reshape(image, [*DIM, 3])    \n    return image\n\ndef dropout(image,DIM=CFG.img_size, PROBABILITY = 0.6, CT = 5, SZ = 0.1):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image with CT squares of side size SZ*DIM removed\n    \n    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n    if (P==0)|(CT==0)|(SZ==0): \n        return image\n    \n    for k in range(CT):\n        # CHOOSE RANDOM LOCATION\n        x = tf.cast( tf.random.uniform([],0,DIM[1]),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM[0]),tf.int32)\n        # COMPUTE SQUARE \n        WIDTH = tf.cast( SZ*min(DIM),tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH//2)\n        yb = tf.math.minimum(DIM[0],y+WIDTH//2)\n        xa = tf.math.maximum(0,x-WIDTH//2)\n        xb = tf.math.minimum(DIM[1],x+WIDTH//2)\n        # DROPOUT IMAGE\n        one = image[ya:yb,0:xa,:]\n        two = tf.zeros([yb-ya,xb-xa,3], dtype = image.dtype) \n        three = image[ya:yb,xb:DIM[1],:]\n        middle = tf.concat([one,two,three],axis=1)\n        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM[0],:,:]],axis=0)\n        image = tf.reshape(image,[*DIM,3])\n\n#     image = tf.reshape(image,[*DIM,3])\n    return image","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-26T13:01:00.232367Z","iopub.execute_input":"2021-09-26T13:01:00.232803Z","iopub.status.idle":"2021-09-26T13:01:00.400267Z","shell.execute_reply.started":"2021-09-26T13:01:00.23277Z","shell.execute_reply":"2021-09-26T13:01:00.399393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Pipeline\n* Reads the raw file and then decodes it to tf.Tensor\n* Resizes the image in desired size\n* Chages the datatype to **float32**\n* Caches the Data for boosting up the speed.\n* Uses Augmentations to reduce overfitting and make model more robust.\n* Finally, splits the data into batches.\n","metadata":{}},{"cell_type":"code","source":"def build_decoder(with_labels=True, target_size=CFG.img_size, ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.image.resize(img, target_size)\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.reshape(img, [*target_size, 3])\n\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), tf.cast(label, tf.float32)\n    \n    return decode_with_labels if with_labels else decode\n\n\ndef build_augmenter(with_labels=True, dim=CFG.img_size):\n    def augment(img, dim=dim):\n        img = transform(img,DIM=dim) if CFG.transform else img\n        img = tf.image.random_flip_left_right(img) if CFG.hflip else img\n        img = tf.image.random_flip_up_down(img) if CFG.vflip else img\n        img = tf.image.random_hue(img, CFG.hue)\n        img = tf.image.random_saturation(img, CFG.sat[0], CFG.sat[1])\n        img = tf.image.random_contrast(img, CFG.cont[0], CFG.cont[1])\n        img = tf.image.random_brightness(img, CFG.bri)\n        img = dropout(img, DIM=dim, PROBABILITY = CFG.drop_prob, CT = CFG.drop_cnt, SZ = CFG.drop_size)\n        img = tf.clip_by_value(img, 0, 1)  if CFG.clip else img         \n        img = tf.reshape(img, [*dim, 3])\n        return img\n    \n    def augment_with_labels(img, label):    \n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\n\ndef build_dataset(paths, labels=None, batch_size=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\", drop_remainder=False):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    \n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n    ds = ds.cache(cache_dir) if cache else ds\n    ds = ds.repeat() if repeat else ds\n    if shuffle: \n        ds = ds.shuffle(shuffle, seed=CFG.seed)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-26T13:01:00.402867Z","iopub.execute_input":"2021-09-26T13:01:00.403218Z","iopub.status.idle":"2021-09-26T13:01:00.422345Z","shell.execute_reply.started":"2021-09-26T13:01:00.403181Z","shell.execute_reply":"2021-09-26T13:01:00.421538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Configs","metadata":{}},{"cell_type":"code","source":"BASE_DIRS = [\n    (512, '/kaggle/input/tf-petfinder-image-tpu-train'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    if len(paths)==0:\n        print('no model found for :',base_dir)\n    MODEL_CONFIGS.append([dim, paths])","metadata":{"execution":{"iopub.status.busy":"2021-09-26T13:01:00.423537Z","iopub.execute_input":"2021-09-26T13:01:00.423835Z","iopub.status.idle":"2021-09-26T13:01:00.437199Z","shell.execute_reply.started":"2021-09-26T13:01:00.423791Z","shell.execute_reply":"2021-09-26T13:01:00.436532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"print('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\nfor dim, model_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    if len(test_paths)<=8:\n        CFG.batch_size = 1\n    elif dim>=768:\n        CFG.batch_size = REPLICAS * 24\n    elif dim>=640:\n        CFG.batch_size = REPLICAS * 32\n    else:\n        CFG.batch_size = REPLICAS * 64\n    dtest = build_dataset(\n        test_paths, \n        batch_size=CFG.batch_size, repeat=True, \n        shuffle=False, augment=True if CFG.tta>1 else False, cache=False,\n        decode_fn=build_decoder(with_labels=False, target_size=[dim,dim]),\n        augment_fn=build_augmenter(with_labels=False, dim=[dim, dim])\n    )\n    for model_path in model_paths:\n        print(f'Model: {model_path}')\n        with strategy.scope():\n            print('Loading Model...')\n            model = tf.keras.models.load_model(model_path, compile=False)\n        print('Predicting...');\n        pred = model.predict(dtest, steps = CFG.tta*len(test_paths)/CFG.batch_size, verbose=1)\n        pred = pred[:CFG.tta*len(test_paths),:]\n        pred = np.mean(pred.reshape(CFG.tta, len(test_paths), -1), axis=0)\n        preds.append(pred)\n        print()\npreds = np.mean(preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T13:01:00.438436Z","iopub.execute_input":"2021-09-26T13:01:00.438807Z","iopub.status.idle":"2021-09-26T13:01:24.646638Z","shell.execute_reply.started":"2021-09-26T13:01:00.438773Z","shell.execute_reply":"2021-09-26T13:01:24.641995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"pred_df = pd.DataFrame({'Id':test_df.Id,\n                        'Pawpularity':preds.reshape(-1)})\nsub_df = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')\ndel sub_df['Pawpularity']\nsub_df = sub_df.merge(pred_df, on='Id', how='left')\nsub_df.to_csv('submission.csv',index=False)\nsub_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T13:01:24.648212Z","iopub.execute_input":"2021-09-26T13:01:24.648524Z","iopub.status.idle":"2021-09-26T13:01:24.678972Z","shell.execute_reply.started":"2021-09-26T13:01:24.648489Z","shell.execute_reply":"2021-09-26T13:01:24.67822Z"},"trusted":true},"execution_count":null,"outputs":[]}]}