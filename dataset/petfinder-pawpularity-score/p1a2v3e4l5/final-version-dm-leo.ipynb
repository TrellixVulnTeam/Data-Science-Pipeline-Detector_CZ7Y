{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.metrics import r2_score, mean_squared_error, accuracy_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Леонов, датамайнинг","metadata":{}},{"cell_type":"markdown","source":"### 1. Описание задачи","metadata":{}},{"cell_type":"markdown","source":"Ссылка на контест: https://www.kaggle.com/c/petfinder-pawpularity-score","metadata":{}},{"cell_type":"markdown","source":"**Суть задачи**\n\nЕсть сайт для поиска домашних животных, на котором размещены объявления с фотками и некоторой метаинфой о питомцах. На базе активности пользователей был разработан индекс популяроности данного животного **Pawpularity** $\\in [0 \\text{ (bad)},100 \\text{ (good)}]$. \n\n**Дано (features):** фотка и табличные данные про животное.\n\n**Цель (target):** предсказать **Pawpularity**.","metadata":{}},{"cell_type":"markdown","source":"Начнем с того, что загрузим и почистим данные.","metadata":{}},{"cell_type":"code","source":"table_path = '../input/petfinder-pawpularity-score/train.csv'\ntable_path_test = '../input/petfinder-pawpularity-score/test.csv'\nphoto_path = '../input/petfinder-pawpularity-score/train'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Про целевую переменную (Pawpularity)\n\n\n    The Pawpularity Score is derived from each pet profile's page view statistics at the listing pages, using an algorithm that normalizes the traffic data across different pages, platforms (web & mobile) and various metrics.\n    Duplicate clicks, crawler bot accesses and sponsored profiles are excluded from the analysis.\n    \n##### Про features (они все бинарные)\n\n\n    Focus - Pet stands out against uncluttered background, not too close / far.\n    \n    Eyes - Both eyes are facing front or near-front, with at least 1 eye / pupil decently clear.\n    \n    Face - Decently clear face, facing front or near-front.\n    \n    Near - Single pet taking up significant portion of photo (roughly over 50% of photo width or height).\n    \n    Action - Pet in the middle of an action (e.g., jumping).\n    \n    Accessory - Accompanying physical or digital accessory / prop (i.e. toy, digital sticker), excluding collar and leash.\n    \n    Group - More than 1 pet in the photo.\n    \n    Collage - Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).\n    \n    Human - Human in the photo.\n    \n    Occlusion - Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are considered occlusion.\n    \n    Info - Custom-added text or labels (i.e. pet name, description).\n    \n    Blur - Noticeably out of focus or noisy, especially for the pet’s eyes and face. For Blur entries, “Eyes” column is always set to 0.\n","metadata":{}},{"cell_type":"markdown","source":"Сразу отметим, что данных для такой задачи очень мало $(9912)$, также регрессия по фоткам всегда считалась нетривиальной задачей. По-хорошему, следует найти схожую задачу, взять предобученную сеть и уже ее применить (transfer learning), но к сожалению, на данный момент еще не хватает навыков реализовать этот сценарий, поэтому попробуем некоторые простые подходы и посмотрим, что выйдет.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(table_path)\ndf.shape # 12 фичей (не считая Id и Pawpularity)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# удалим экстремальные значения\n\nq1 = df.Pawpularity.quantile(0.01)\nq2 = df.Pawpularity.quantile(0.99)\n\ndf = df[~((df.Pawpularity <= q1) |(df.Pawpularity >= q2))]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().any().sum() # данные без пропусков","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Теперь про фотки","metadata":{}},{"cell_type":"code","source":"# считаем фотки\n\nimport cv2\nimport os\nfrom skimage import io\nfrom skimage.transform import resize\n\nX_photo = [] # в таком же порядке\n# расположены будут, как и в df расположена инфа о фотке\n\nfor img_id in df.Id:\n    \n    img = io.imread(photo_path+'/'+ str(img_id)+'.jpg',\n                    as_gray=True)# и превращаем в черное-белые  \n    \n    # пока будем просто ресайзить к одному размеру (28,28)\n    X_photo.append(cv2.resize(img,(28,28)))   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_photo[0]) # пример фотки","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.max(X_photo),np.min(X_photo) # черное-белые уже отнормированы","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Регрессия на числовых данных (в смысле, не фотки)","metadata":{}},{"cell_type":"markdown","source":"Сначала просто попробуем сделать Ridge-регрессию (делаем регуляризацию, потому что много коррелирующих признаков)","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True,\n           annot_kws={\"fontsize\":17},cmap=\"PuBu\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$$\\min_{w} || X w - y||_2^2 + \\alpha ||w||_2^2, \\; \\alpha \\geq 0 $$\n","metadata":{}},{"cell_type":"markdown","source":"Чтобы подобрать $\\alpha$ используем кросс-проверку, то есть разбиваем выборку на $k$ подмножества, каждое из которых будем использовать для проверки, а оставшиеся - для обучения. Получаем $k$ моделей, для которых можно посчитать среднюю ошибку - получаем некоторую объекивную оценку того, как модель работает при заданном $\\alpha$.\n\nLeave-one-out кросс-проверка (LOOCV) - частный крайний случай, когда мы строим модель на всех данных, кроме одного элемента выборки. Именно он по-умолчанию стоит в RidgeCV.\n","metadata":{}},{"cell_type":"code","source":"Xnames = [x for x in df.columns if x not in ('Id','Pawpularity')]\nynames = ['Pawpularity']\n\nX = df[Xnames]\ny = df[ynames]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,\n                                                    test_size=0.2,\n                                                    random_state=404)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RidgeCV(alphas=np.linspace(0.001,1000,1000))\nmodel.fit(X_train,np.array(y_train).ravel())\nmodel.alpha_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\nr2_score(y_test,y_pred), mean_squared_error(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получилось модель, чуть лучше чем константа (среднее)","metadata":{}},{"cell_type":"code","source":"y_pred_mean = np.ones(len(y_test)) * np.mean(y_test)[0]\n\nr2_score(y_test,y_pred_mean), mean_squared_error(y_test,y_pred_mean)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Регрессия на фотках (сверточная нейронная сеть)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_photo = np.array(X_photo)\ny = df[ynames]\nX_photo = X_photo.reshape(-1, 28, 28, 1) # нужно для keras\n\nX_train, X_test, y_train, y_test = train_test_split(X_photo,y,\n                                                    test_size=0.2,\n                                                    random_state=404)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential()\n\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3),\n                                 activation=\"relu\",\n                                 input_shape=(28, 28, 1)))\n\nmodel.add(tf.keras.layers.MaxPooling2D((2, 2)))\n\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), \n                                 activation=\"relu\"))\n\nmodel.add(tf.keras.layers.MaxPooling2D((2, 2)))\n\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), \n                                 activation=\"relu\"))\n\nmodel.add(tf.keras.layers.Flatten())\n\nmodel.add(tf.keras.layers.Dense(64, \n                                activation=\"relu\"))\n\nmodel.add(tf.keras.layers.Dense(1))\n\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='mse',\n             optimizer='adam')\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.fit(X_train,\n         y_train,\n         batch_size=64,\n         epochs=30,callbacks=[callback],\n         validation_data=(X_test, y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\nmean_squared_error(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MSE сверточной нейронной сети хуже, чем просто RidgeCV и даже хуже, чем константный прогноз (средним).","metadata":{}},{"cell_type":"markdown","source":"### 4. Классификация на числовых данных (10 классов)","metadata":{}},{"cell_type":"markdown","source":"Попробуем \"дискретизировать\" задачу: разобъем целевую переменную на группы.","metadata":{}},{"cell_type":"code","source":"def classify(x):\n    for i in range(10):\n        if x >= 0 + 10*i and x < 10 + 10*i:\n            return i\n    return 9 # если там есть 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df[Xnames]\ny = [classify(x) for x in df[ynames].values]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,\n                                                    test_size=0.2,\n                                                    random_state=404)\nnp.shape(X_train),np.shape(y_train),np.shape(X_test),np.shape(y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для классификации используем ансамбль деревьев: выборка разбивается на подвыборки, на каждой из которых обучается дерево, а потом результат усредняется.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Только четверть ответов угадывается правильно. Попробуем другие разбиения и найдет такое, при котором accuracy максимальное.","metadata":{}},{"cell_type":"markdown","source":"### 5. Бинарная классификация","metadata":{}},{"cell_type":"code","source":"classify = lambda x: 0 if x <= 50 else 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df[Xnames]\ny = [classify(x) for x in df[ynames].values]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,\n                                                    test_size=0.2,\n                                                    random_state=404)\nnp.shape(X_train),np.shape(y_train),np.shape(X_test),np.shape(y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Теперь построим еще две модели: отедельно для двух классов.","metadata":{}},{"cell_type":"code","source":"# классификацию для [0;50]\nclassify = lambda x: 0 if x <= 25 else 1\n\nX0 = df[df.Pawpularity <= 50][Xnames]\ny0 = [classify(x) for x in df[df.Pawpularity <= 50][ynames].values]\n\nX_train, X_test, y_train, y_test = train_test_split(X0,y0,\n                                                    test_size=0.2,\n                                                    random_state=404)\nnp.shape(X_train),np.shape(y_train),np.shape(X_test),np.shape(y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model0 = RandomForestClassifier()\nmodel0.fit(X_train,y_train)\ny_pred = model0.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Регрессия 0","metadata":{}},{"cell_type":"code","source":"# теперь регрессию для [0;25]\n\n# сильно урежем данные\ndf1 = df[df.Pawpularity <= 25]\nq1 = df1.Pawpularity.quantile(0.3)\nq2 = df1.Pawpularity.quantile(0.7)\ndf1 = df1[~((df1.Pawpularity <= q1) |(df1.Pawpularity >= q2))]\n\nX0 = df1[Xnames]\ny0 = df1[ynames]\n\nX_train, X_test, y_train, y_test = train_test_split(X0,y0,\n                                                    test_size=0.2,\n                                                    random_state=404)\nnp.shape(X_train),np.shape(y_train),np.shape(X_test),np.shape(y_test)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg0 = RidgeCV(alphas=np.linspace(0.001,1000,1000))\nreg0.fit(X_train,np.array(y_train).ravel())\nreg0.alpha_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = reg0.predict(X_test)\nr2_score(y_test,y_pred), mean_squared_error(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Регрессия 1","metadata":{}},{"cell_type":"code","source":"# теперь регрессию для (25;50]\n\n# сильно урежем данные\ndf1 = df[((df.Pawpularity > 25) & (df.Pawpularity <= 50))]\nq1 = df1.Pawpularity.quantile(0.15)\nq2 = df1.Pawpularity.quantile(0.85)\ndf1 = df1[~((df1.Pawpularity <= q1) |(df1.Pawpularity >= q2))]\n\nX0 = df1[Xnames]\ny0 = df1[ynames]\n\nX_train, X_test, y_train, y_test = train_test_split(X0,y0,\n                                                    test_size=0.2,\n                                                    random_state=404)\nnp.shape(X_train),np.shape(y_train),np.shape(X_test),np.shape(y_test)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg1 = RidgeCV(alphas=np.linspace(0.001,1000,1000))\nreg1.fit(X_train,np.array(y_train).ravel())\nreg1.alpha_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = reg1.predict(X_test)\nr2_score(y_test,y_pred), mean_squared_error(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"code","source":"# классификацию для (50;100]\nclassify = lambda x: 0 if x <= 75 else 1\n\nX0 = df[df.Pawpularity > 50][Xnames]\ny0 = [classify(x) for x in df[df.Pawpularity > 50][ynames].values]\n\nX_train, X_test, y_train, y_test = train_test_split(X0,y0,\n                                                    test_size=0.2,\n                                                    random_state=404)\nnp.shape(X_train),np.shape(y_train),np.shape(X_test),np.shape(y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = RandomForestClassifier()\nmodel1.fit(X_train,y_train)\ny_pred = model1.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Регрессия 2","metadata":{}},{"cell_type":"code","source":"# теперь регрессию для (50;75]\n\n# сильно урежем данные\ndf1 = df[((df.Pawpularity > 50) & (df.Pawpularity <= 75))]\nq1 = df1.Pawpularity.quantile(0.2)\nq2 = df1.Pawpularity.quantile(0.8)\ndf1 = df1[~((df1.Pawpularity <= q1) |(df1.Pawpularity >= q2))]\n\nX0 = df1[Xnames]\ny0 = df1[ynames]\n\nX_train, X_test, y_train, y_test = train_test_split(X0,y0,\n                                                    test_size=0.2,\n                                                    random_state=404)\nnp.shape(X_train),np.shape(y_train),np.shape(X_test),np.shape(y_test)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg2 = RidgeCV(alphas=np.linspace(0.001,1000,1000))\nreg2.fit(X_train,np.array(y_train).ravel())\nreg2.alpha_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = reg2.predict(X_test)\nr2_score(y_test,y_pred), mean_squared_error(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Регрессия 3","metadata":{}},{"cell_type":"code","source":"# теперь регрессию для (75;100]\n\n# сильно урежем данные\ndf1 = df[((df.Pawpularity > 75) & (df.Pawpularity <= 100))]\nq1 = df1.Pawpularity.quantile(0.01)\nq2 = df1.Pawpularity.quantile(0.99)\ndf1 = df1[~((df1.Pawpularity <= q1) |(df1.Pawpularity >= q2))]\n\nX0 = df1[Xnames]\ny0 = df1[ynames]\n\nX_train, X_test, y_train, y_test = train_test_split(X0,y0,\n                                                    test_size=0.2,\n                                                    random_state=404)\nnp.shape(X_train),np.shape(y_train),np.shape(X_test),np.shape(y_test)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg3 = RidgeCV(alphas=np.linspace(0.001,1000,1000))\nreg3.fit(X_train,np.array(y_train).ravel())\nreg3.alpha_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = reg3.predict(X_test)\nr2_score(y_test,y_pred), mean_squared_error(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В конце концов:\n\nСначала два раза применяем классификацию и в зависимости от того, что у нас получилось, применяем одну из четырех регрессий.\n","metadata":{}},{"cell_type":"code","source":"def fin_model(x):\n    \n    if model.predict(x) == 0:\n        if model0.predict(x) == 0:\n            return reg0.predict(x)\n        else:\n            return reg1.predict(x)\n            \n    else:\n        if model1.predict(x) == 0:\n            return reg2.predict(x)\n        else:\n            return reg3.predict(x)\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xnames = [x for x in df.columns if x not in ('Id','Pawpularity')]\nynames = ['Pawpularity']\n\nX = df[Xnames]\ny = df[ynames]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,\n                                                    test_size=0.2,\n                                                    random_state=404)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin_model(X_test.iloc[[0]])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = [fin_model(X_test.iloc[[i]]) for i in range(len(X_test))]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_error(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Вывод","metadata":{}},{"cell_type":"markdown","source":"Из всех представленных подходов самым лучшим с точки зрения MSE ялвяется RidgeCV, ее и будем считать итоговой моделью.","metadata":{}},{"cell_type":"code","source":"Xnames = [x for x in df.columns if x not in ('Id','Pawpularity')]\nynames = ['Pawpularity']\n\nX = df[Xnames]\ny = df[ynames]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,\n                                                    test_size=0.2,\n                                                    random_state=404)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RidgeCV(alphas=np.linspace(0.001,1000,1000))\nmodel.fit(X_train,np.array(y_train).ravel())\nmodel.alpha_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\nr2_score(y_test,y_pred), mean_squared_error(y_test,y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"# вывод для kaggle\nTrue_test_data = pd.read_csv(table_path_test)\nanswer = pd.DataFrame(model.predict(True_test_data.drop(['Id'],axis=1)),columns=['Pawpularity'])\npd.concat([True_test_data.Id,answer],axis=1).to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}