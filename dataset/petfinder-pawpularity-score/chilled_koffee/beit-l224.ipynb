{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timmmaster/')\nsys.path.append('../input/tez-lib/')\n!pip install GPUtil","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport timm\nimport torch.nn as nn\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\nimport gc\nfrom GPUtil import showUtilization as gpu_usage\nimport random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=999):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED']=str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic=True\n    \nseed_everything()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class args:\n    batch_size=16\n    image_size=224\n    epochs=20\n    mixup_alpha=0.2\n    cutmix_alpha=20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cutmixandmixup(x,z,y,prob):\n    #20% Mixup & 30% Cutmix Augmentation\n    if prob<0.2:\n        if args.mixup_alpha>0:\n            lam=np.random.beta(args.mixup_alpha,args.mixup_alpha)\n        else:\n            lam=1\n        batch_size=x.size()[0]\n        index=torch.randperm(batch_size).cuda()\n        mixed_x=lam*x+(1-lam)*x[index,:]\n        mixed_z=lam*z+(1-lam)*z[index,:]\n        y_a,y_b=y,y[index]\n        return mixed_x,mixed_z,y_a,y_b,lam\n    \n    \n    else:\n        image=None\n        dim=x.size()[1]\n        batch_size=x.size()[0]\n        index=torch.randperm(batch_size).cuda()\n        lam=torch.tensor([])\n        y_a,y_b=y,y[index]\n        \n        for i in range(len(batch_size)):\n            width=np.int_(np.round(np.random.beta(args.cutmix_alpha,args.cutmix_alpha)*dim))\n            height=np.int_(np.round(np.random.beta(args.cutmix_alpha,args.cutmix_alpha)*dim))\n            xx=np.random.randint(0,dim)\n            yy=np.random.randint(0,dim)\n            ya=max(0,y-height//2)\n            yb=min(dim,y+height//2)\n            xa=max(0,x-width//2)\n            xb=min(dim,x+width//2)\n            area=((yb-ya)*(xb-xa)/(dim*dim))\n            lam=torch.cat([lam,area])\n            one=x[i,:,ya:yb,0:xa]\n            two=x[index[i],:]\n            two=two[:,ya:yb,xa:xb]\n            three=x[i,:,ya:yb,xb:dim]\n            img=torch.cat([one,two,three],2)\n            img=torch.cat(x[i,:,0:ya,:],img,x[i,:,yb:dim,:],1)\n            img=img.unsqueeze(0)\n            if image is None:\n                image=img\n            else:\n                image=torch.cat([image,img])\n        lam=lam.unsqueeze(1)\n        mixed_z=(1-lam)*z+lam*z[index]\n        \n        return image,mixed_z,y_a,y_b,lam\n        \n    \n        \n\ndef mixup_loss(loss_fn,pred,y_a,y_b,lam):\n    return lam*loss_fn(pred,y_a)+(1-lam)*loss_fn(pred,y_b)\n\ndef cutmix_loss(loss_fn,pred,y_a,y_b,lam):\n    loss=[]\n    for i in range(len(pred)):\n        tmp_loss=lam[i]*loss_fn(pred[i],y_b[i])+(1-lam[i])*loss_fn(pred[i],y_a[i])\n        loss.append(tmp_loss)\n    return sum(loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularDataset:\n    def __init__(self,image_paths,dense_features,targets,augmentations):\n        self.image_paths=image_paths\n        self.dense_features=dense_features\n        self.targets=targets\n        self.augmentations=augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    \n    def __getitem__(self,item):\n        image=cv2.imread(self.image_paths[item])\n        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        \n        \n        if self.augmentations is not None:\n            augmented=self.augmentations(image=image)\n            image=augmented[\"image\"]\n            \n        image=np.transpose(image,(2,0,1)).astype(np.float32)\n        \n        \n        features=self.dense_features[item,:]\n        targets=self.targets[item]/100.\n        \n        return{\n            \"image\":torch.tensor(image,dtype=torch.float),\n            \"features\":torch.tensor(features,dtype=torch.float),\n            \"targets\":torch.tensor(targets,dtype=torch.float)\n        }\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass PawpularModel(tez.Model):\n    \n    def __init__(self):\n        super().__init__()\n    \n        self.model=timm.create_model(\"beit_large_patch16_224\",pretrained=True,in_chans=3)\n        self.model.head=nn.Linear(self.model.head.in_features,128)\n        self.dropout=nn.Dropout(0.2)\n        self.dense1=nn.Linear(128+12,64)\n        self.relu=nn.ReLU()\n        self.dense2=nn.Linear(64,1)\n        self.step_scheduler_after='epoch'\n        \n    def monitor_metrics(self,outputs,targets):\n        outputs=outputs.cpu().detach().numpy()\n        targets=targets.cpu().detach().numpy()\n        rmse=metrics.mean_squared_error(targets,outputs,squared=False)\n        return {'rmse': rmse}\n    \n    def fetch_scheduler(self):\n        sch=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optimizer,T_0=10,T_mult=1,eta_min=1e-6,last_epoch=-1)\n        return sch\n    \n    \n    def fetch_optimizer(self):\n        opt=torch.optim.Adam(self.parameters(),lr=1e-4)\n        return opt\n    \n    def forward(self,image,features,targets=None):\n        if((targets is not None) and (self._train_state==True)):\n            prob=torch.rand([1])\n            \n            if prob<0.7:\n                image,features,target_a,target_b,lam=cutmixandmixup(image,features,targets.view(-1,1),prob)\n                image=image.to(device='cuda',dtype=torch.float)\n                features=features.to(device='cuda',dtype=torch.float)\n                target_a=target_a.to(device='cuda',dtype=torch.float)\n                target_b=target_b.to(device='cuda',dtype=torch.float)\n            else:\n                image=image.to(device=\"cuda\",dtype=torch.float)\n                features=features.to(device=\"cuda\",dtype=torch.float)\n                targets=targets.to(device=\"cuda\",dtype=torch.float)\n        x=self.model(image)\n        x=self.dropout(x)\n        x=torch.cat([x,features],dim=1)\n        x=self.dense1(x)\n        x=self.relu(x)\n        x=self.dense2(x)\n        \n        if targets is not None:\n            loss_fn=nn.BCEWithLogitsLoss()\n            if self._train_state==True:\n                if prob<0.2:\n                    loss=mixup_loss(loss_fn,x,target_a,target_b,lam)\n                elif 0.2<prob<0.5:\n                    loss=cutmix_loss(loss_fn,x,target_a,target_b,lam)\n                else:\n                    loss=loss_fn(x,targets.view(-1,1))\n            else:\n                loss=loss_fn(x,targets.view(-1,1))\n            metrics=self.monitor_metrics(torch.sigmoid(x)*100,targets*100)\n            return x,loss,metrics\n        return x,0,{}\n                \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_aug=albumentations.Compose([\n\nalbumentations.RandomResizedCrop(args.image_size,args.image_size,p=1),\nalbumentations.HueSaturationValue(hue_shift_limit=0.2,sat_shift_limit=0.2,val_shift_limit=0.2,p=0.5),\nalbumentations.RandomBrightnessContrast(brightness_limit=(-0.1,0.1),contrast_limit=(-0.1,0.1),p=0.5),\nalbumentations.HorizontalFlip(p=0.5),\nalbumentations.VerticalFlip(p=0.5),\nalbumentations.GaussNoise(var_limit=5.0 / 255.0, p=0.50),\nalbumentations.Rotate(limit=180,p=0.7),\nalbumentations.ShiftScaleRotate(shift_limit=0.1,scale_limit=0.1,rotate_limit=45,p=0.5),\nalbumentations.CoarseDropout(max_holes=15,max_width=10,max_height=10,min_holes=6,p=0.5),\nalbumentations.Normalize(\n    mean=[0.485,0.456,0.406],\n    std=[0.229,0.224,0.225],\n    max_pixel_value=255.0,\n    p=1\n)\n\n],p=1)\n\nvalid_aug=albumentations.Compose([ albumentations.RandomResizedCrop(args.image_size,args.image_size,p=1), albumentations.Normalize( mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225], max_pixel_value=255.0, p=1 ),albumentations.HorizontalFlip(p=0.5) ],p=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_features = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold_ in range(5,10):\n    \n    \n    print(f'--- Fold {fold_} ---')\n    df=pd.read_csv('../input/creating-folds/train_10folds.csv')\n    df_train=df[df.kfold!=fold_].reset_index(drop=True)\n    df_valid=df[df.kfold==fold_].reset_index(drop=True)\n    train_img_paths=[f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n    valid_img_paths=[f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n    \n    train_dataset=PawpularDataset(\n        image_paths=train_img_paths,\n        dense_features=df_train[dense_features].values,\n        targets=df_train['Pawpularity'].values,\n        augmentations=train_aug\n    )\n\n    valid_dataset=PawpularDataset(\n        image_paths=valid_img_paths,\n        dense_features=df_valid[dense_features].values,\n        targets=df_valid['Pawpularity'].values,\n        augmentations=valid_aug\n    )\n\n\n    model=PawpularModel()\n\n    es=EarlyStopping(\n        monitor=\"valid_rmse\",\n        model_path=f\"model_f{fold_}.bin\",\n        patience=5,\n        mode=\"min\",\n        save_weights_only=True\n    )\n\n    model.fit(\n        train_dataset,\n        valid_dataset=valid_dataset,\n        train_bs=args.batch_size,\n        valid_bs=2*args.batch_size,\n        device=\"cuda\",\n        epochs=args.epochs,\n        callbacks=[es],\n        fp16=True,\n        n_jobs=-1\n    )\n    \n    del train_dataset,valid_dataset,model,df_train,df_valid,train_img_paths,valid_img_paths\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}