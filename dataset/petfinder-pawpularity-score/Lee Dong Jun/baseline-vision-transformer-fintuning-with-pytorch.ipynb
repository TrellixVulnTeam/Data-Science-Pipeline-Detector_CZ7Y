{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport gc\nsys.path.append(\"../input/pytorch-image-models\")\n\nimport time\nimport numpy as np\nimport pandas as pd\nfrom easydict import EasyDict as edict\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# image\nimport PIL\nfrom PIL import Image\nimport albumentations as albu\n\n# model validation\nimport sklearn\nfrom sklearn.model_selection import StratifiedKFold\n\n# model\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport timm\n\n# pytorch_lightening\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:55:33.123756Z","iopub.execute_input":"2021-10-14T07:55:33.12407Z","iopub.status.idle":"2021-10-14T07:55:33.134935Z","shell.execute_reply.started":"2021-10-14T07:55:33.124017Z","shell.execute_reply":"2021-10-14T07:55:33.133987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For notebook commit\nGET_CV = True\ntest = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\nif len(test)>8:\n    GET_CV = False\nelse:\n    print('this submission notebook will compute CV score, but commit notebook will not')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:55:33.902679Z","iopub.execute_input":"2021-10-14T07:55:33.9032Z","iopub.status.idle":"2021-10-14T07:55:33.923117Z","shell.execute_reply.started":"2021-10-14T07:55:33.903162Z","shell.execute_reply":"2021-10-14T07:55:33.922459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GET_CV = False","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:55:38.512689Z","iopub.execute_input":"2021-10-14T07:55:38.513666Z","iopub.status.idle":"2021-10-14T07:55:38.519485Z","shell.execute_reply.started":"2021-10-14T07:55:38.51359Z","shell.execute_reply":"2021-10-14T07:55:38.518632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if GET_CV:\n    df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\nelse:\n    df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:55:41.623749Z","iopub.execute_input":"2021-10-14T07:55:41.624014Z","iopub.status.idle":"2021-10-14T07:55:41.634074Z","shell.execute_reply.started":"2021-10-14T07:55:41.623984Z","shell.execute_reply":"2021-10-14T07:55:41.633092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Model Config","metadata":{}},{"cell_type":"code","source":"__C = edict()\ncfg = __C\n# model\ncfg.model = edict()\ncfg.model.name = 'vit_base_patch16_224'\ncfg.model.weight = '../input/vit-base-models-pretrained-pytorch/jx_vit_base_p16_224-80ecf9dd.pth'\n\n# optimizer\ncfg.optim = edict()\ncfg.optim.name = 'torch.optim.AdamW'\ncfg.optim.lr = 2e-5\ncfg.optim.max_epochs = 20\n\n# lr_schedule\ncfg.lr_sched = edict()\ncfg.lr_sched.name = 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'\ncfg.lr_sched.params = {'eta_min':0.0001, 'T_0':20}\n\n# dataset\ncfg.trainloader = edict()\ncfg.trainloader.batch_size = 32\ncfg.trainloader.drop_last = True\ncfg.trainloader.num_workers = 4\ncfg.trainloader.pin_memory = False\ncfg.trainloader.shuffle = True\n\ncfg.valloader = edict()\ncfg.valloader.batch_size = 16\ncfg.valloader.drop_last = True\ncfg.valloader.num_workers = 4\ncfg.valloader.pin_memory = False\ncfg.valloader.shuffle = False\n\n# data transform and augmentation\ncfg.transform = edict()\ncfg.transform.img_size = 224\ncfg.transform.normalize_mean = [.5, .5, .5]\ncfg.transform.normalize_std = [.5, .5, .5]\n\n# data directory\ncfg.data = edict()\nif GET_CV:\n    cfg.data.df_dir = '../input/petfinder-pawpularity-score/train.csv'\nelse:\n    cfg.data.df_dir = '../input/petfinder-pawpularity-score/test.csv'\n\nif GET_CV:    \n    cfg.data.image_dir = '../input/petfinder-pawpularity-score/train'\nelse:\n    cfg.data.image_dir = '../input/petfinder-pawpularity-score/test'","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:55:48.033662Z","iopub.execute_input":"2021-10-14T07:55:48.033951Z","iopub.status.idle":"2021-10-14T07:55:48.044816Z","shell.execute_reply.started":"2021-10-14T07:55:48.03392Z","shell.execute_reply":"2021-10-14T07:55:48.044124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Pipeline","metadata":{}},{"cell_type":"code","source":"def build_transform(cfg):\n    transforms = torchvision.transforms.Compose([\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize(cfg.transform.normalize_mean,\n                                         cfg.transform.normalize_std),\n        torchvision.transforms.Resize(size = (cfg.transform.img_size,cfg.transform.img_size))\n        ])\n    return transforms","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:55:50.162717Z","iopub.execute_input":"2021-10-14T07:55:50.163269Z","iopub.status.idle":"2021-10-14T07:55:50.16809Z","shell.execute_reply.started":"2021-10-14T07:55:50.163231Z","shell.execute_reply":"2021-10-14T07:55:50.16728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, df, data_dir, transforms):\n        self.df = df\n        self.df['Pawpularity'] /= 100.0\n        self.data_dir = data_dir\n        self.transforms = transforms\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = os.path.join(self.data_dir, self.df['Id'][index])+'.jpg'\n        img = Image.open(img_path)\n        img = self.transforms(img)\n        label = torch.tensor(self.df['Pawpularity'][index], dtype = torch.float32).reshape(1)\n        return img, label\n    \nclass TestDataset(torch.utils.data.Dataset):\n    def __init__(self, df, data_dir, transform):\n        self.df = df\n        self.data_dir = data_dir\n        self.transforms = transforms\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, index):\n        img_path = os.path.join(self.data_dir, self.df['Id'][index])+'.jpg'\n        img = Image.open(img_path)\n        img = self.transforms(img)\n        return img\n    \nclass Dataloader(LightningDataModule):\n    def __init__(self, cfg, train_df, val_df):\n        super().__init__()\n        self.cfg = cfg\n        self.train_df = train_df\n        self.val_df = val_df\n    def _create_dataset(self, train = True):\n        if train:\n            return Dataset(self.train_df, self.cfg.data.image_dir, build_transform(self.cfg))\n        else:\n            return Dataset(self.val_df, self.cfg.data.image_dir, build_transform(self.cfg))\n    \n    def train_dataloader(self):\n        dataset = self._create_dataset(train=True)\n        return torch.utils.data.DataLoader(dataset, **self.cfg.trainloader)\n    def val_dataloader(self):\n        dataset = self._create_dataset(train = False)\n        return torch.utils.data.DataLoader(dataset, **self.cfg.valloader)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:55:52.452734Z","iopub.execute_input":"2021-10-14T07:55:52.453264Z","iopub.status.idle":"2021-10-14T07:55:52.467728Z","shell.execute_reply.started":"2021-10-14T07:55:52.453227Z","shell.execute_reply":"2021-10-14T07:55:52.467005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Vision Transformer model","metadata":{}},{"cell_type":"code","source":"def RMSELoss(yhat,y):\n    return torch.sqrt(torch.mean((yhat-y)**2))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:55:54.630766Z","iopub.execute_input":"2021-10-14T07:55:54.631021Z","iopub.status.idle":"2021-10-14T07:55:54.635585Z","shell.execute_reply.started":"2021-10-14T07:55:54.630993Z","shell.execute_reply":"2021-10-14T07:55:54.634582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Identity(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, x):\n        return x\n\nclass ViT_model(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.backbone = timm.create_model(cfg.model.name, pretrained=False)\n        self.backbone.load_state_dict(torch.load(cfg.model.weight))\n        for param in self.backbone.parameters():\n            param.requires_grad = False\n        self.backbone.head = nn.Linear(768, 1)\n        self.sigmoid = nn.Sigmoid()\n        self.criterion = nn.BCELoss()\n    \n    def forward(self, input):\n        x = self.backbone(input)\n        x = self.sigmoid(x)\n        return x\n    \n    def _step(self, batch):\n        img, target = batch\n        pred = self(img)\n        loss = self.criterion(pred, target)\n        return pred, target, loss\n    \n    def training_step(self, batch, batch_idx):\n        pred, target, loss = self._step(batch)\n        metric = RMSELoss(pred, target)\n        tensorboard_log = {'train_loss':loss, 'train_rmse':metric}\n        return {'loss':loss, 'rmse':metric, 'log':tensorboard_log}\n    \n    def validation_step(self, batch, batch_idx):\n        with torch.no_grad():\n            pred, target, loss = self._step(batch)\n            rmse = RMSELoss(pred*100.0, target*100.0)\n        return {'val_loss': loss, 'val_rmse': rmse}\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        avg_rmse = torch.stack([x['val_rmse'] for x in outputs]).mean()\n        print(f\"Epoch {self.current_epoch} loss:{avg_loss} rmse:{avg_rmse}\")\n        self.log('val_rmse', avg_rmse)\n        tensorboard_logs = {'val_loss': avg_loss, 'val_rmse': avg_rmse}\n        return {'val_loss': avg_loss,\n                'val_rmse': avg_rmse,\n                'log': tensorboard_logs}\n            \n    def configure_optimizers(self):\n        optimizer = eval(self.cfg.optim.name)(self.parameters(), lr = self.cfg.optim.lr)\n        schedule = eval(self.cfg.lr_sched.name)(optimizer = optimizer, **self.cfg.lr_sched.params)\n        return [optimizer], [schedule]","metadata":{"execution":{"iopub.status.busy":"2021-10-14T07:55:56.503612Z","iopub.execute_input":"2021-10-14T07:55:56.504061Z","iopub.status.idle":"2021-10-14T07:55:56.520142Z","shell.execute_reply.started":"2021-10-14T07:55:56.504012Z","shell.execute_reply":"2021-10-14T07:55:56.51934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training with Pytorch Lightning","metadata":{}},{"cell_type":"code","source":"# train model and compute cv score\nif GET_CV:    \n    kfold = StratifiedKFold(n_splits = 5, shuffle = True)\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(df[\"Id\"], df[\"Pawpularity\"])):\n        print('fold {} training start'.format(fold+1))\n        start = time.time()\n        # train_test_split\n        train_df = df.loc[train_idx].reset_index(drop=True)\n        val_df = df.loc[val_idx].reset_index(drop=True)\n        # define datamodule\n        dataloader = Dataloader(cfg, train_df, val_df)\n        # define model\n        model = ViT_model(cfg)\n        # define callbacks\n        earystopping = EarlyStopping(monitor=\"val_rmse\")\n        lr_monitor = callbacks.LearningRateMonitor()\n        loss_checkpoint = callbacks.ModelCheckpoint(\n            filename = None,\n            monitor=\"val_rmse\",\n            save_top_k=1,\n            mode=\"min\",\n            save_last=False,\n            )\n        logger = TensorBoardLogger(cfg.model.name)\n\n        trainer = pl.Trainer(\n            logger=logger,\n            max_epochs=cfg.optim.max_epochs,\n            callbacks=[lr_monitor, loss_checkpoint, earystopping],\n            gpus = 1)\n        trainer.fit(model, datamodule = dataloader)\n    \n    elapse = time.time() -start\n    print('fold {} complete -- {} seconds elapsed'.format(fold + 1, elapse))\nelse:\n    print('This Notebook is for commit, not for computing CV score')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T03:05:27.574172Z","iopub.execute_input":"2021-10-14T03:05:27.57461Z","iopub.status.idle":"2021-10-14T03:05:27.58546Z","shell.execute_reply.started":"2021-10-14T03:05:27.574576Z","shell.execute_reply":"2021-10-14T03:05:27.584529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Inference & Submission","metadata":{}},{"cell_type":"code","source":"# inference on test set\nif not GET_CV:\n    transforms = build_transform(cfg)\n    dataset = TestDataset(df,cfg.data.image_dir, transforms)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size = 128)\n    pawpularity = []\n    models = [ViT_model(cfg) for i in range(5)]\n    # load pretrained weights\n    weights_1 = torch.load('../input/finetuned-pawpularity-vit/epoch19-step4939.ckpt')['state_dict']\n    weights_2 = torch.load('../input/finetuned-pawpularity-vit/epoch19-step4939 (1).ckpt')['state_dict']\n    weights_3 = torch.load('../input/finetuned-pawpularity-vit/epoch19-step4939 (2).ckpt')['state_dict']\n    weights_4 = torch.load('../input/finetuned-pawpularity-vit/epoch19-step4939 (3).ckpt')['state_dict']\n    weights_5 = torch.load('../input/finetuned-pawpularity-vit/epoch19-step4939 (4).ckpt')['state_dict']\n    weights = [weights_1, weights_2, weights_3, weights_4, weights_5]\n    # load pretrained weights to model\n    for i, (model, weight) in enumerate(zip(models, weights)):\n        model.load_state_dict(weight)\n        model = model.eval()\n        models[i] = model.cuda()\n    # inference by averaging 5 outputs\n    for batch_idx, batch in enumerate(dataloader):\n        pred = torch.zeros(batch.shape[0], 1).cuda()\n        for model in models:\n            with torch.no_grad():\n                pred += model(batch.cuda())\n        pred = pred / 5.0\n        pred *= 100.0\n        pawpularity.append(pred)\n        # memory efficiency\n        torch.cuda.empty_cache()\n        del batch\n        gc.collect()\n        print(f'{64*(batch_idx+1)} image processed')\n    pawpularity = np.concatenate([tensor.cpu().numpy().reshape(-1,) for tensor in pawpularity])\n    df['Pawpularity'] = pawpularity\n    submission = df[['Id','Pawpularity']]\n    submission['Pawpularity'] = submission['Pawpularity'].astype(float)\n    submission.to_csv('submission.csv')\n    print('submission complete')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T08:20:32.423855Z","iopub.execute_input":"2021-10-14T08:20:32.424129Z","iopub.status.idle":"2021-10-14T08:29:32.882825Z","shell.execute_reply.started":"2021-10-14T08:20:32.424099Z","shell.execute_reply":"2021-10-14T08:29:32.881995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}