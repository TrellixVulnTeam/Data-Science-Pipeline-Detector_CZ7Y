{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#There's an Error when submmitting to the competition  ----------- Notebook Threw Exception\nimport sys \nsys.path.append(\"../input/notebookd97ba6b497/\")","metadata":{"execution":{"iopub.status.busy":"2021-10-16T07:16:32.245066Z","iopub.execute_input":"2021-10-16T07:16:32.245353Z","iopub.status.idle":"2021-10-16T07:16:32.343581Z","shell.execute_reply.started":"2021-10-16T07:16:32.245277Z","shell.execute_reply":"2021-10-16T07:16:32.342871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# coding=utf-8\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms, models\nfrom PIL import Image\nimport pandas as pd\nimport re\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-16T07:16:32.345403Z","iopub.execute_input":"2021-10-16T07:16:32.345756Z","iopub.status.idle":"2021-10-16T07:16:36.882591Z","shell.execute_reply.started":"2021-10-16T07:16:32.345698Z","shell.execute_reply":"2021-10-16T07:16:36.881877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 2  # 训练次数\nbatch_size = 32  # 批处理大小\nnum_workers = 0  # 多线程的数目\nuse_gpu = torch.cuda.is_available()\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nroot = '../input/petfinder-pawpularity-score/'\nmodel_root = '../input/notebookd97ba6b497/pic_net_model.pt'\n# set the path\ntrain_pic_path = root + 'train'\ntest_pic_path = root + 'test'\ntrain_csv_path = root + 'train.csv'\ntest_csv_path = root + 'test.csv'","metadata":{"execution":{"iopub.status.busy":"2021-10-16T07:16:36.883791Z","iopub.execute_input":"2021-10-16T07:16:36.884055Z","iopub.status.idle":"2021-10-16T07:16:36.944509Z","shell.execute_reply.started":"2021-10-16T07:16:36.884022Z","shell.execute_reply":"2021-10-16T07:16:36.943808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FineTuneResnet50(nn.Module):\n    def __init__(self, num_class=10):\n        super(FineTuneResnet50, self).__init__()\n        self.num_class = num_class\n        resnet50_net = models.resnet50(pretrained=False)\n        self.features = nn.Sequential(*list(resnet50_net.children())[:-1])\n        self.classifier = nn.Linear(2048, self.num_class)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-16T07:16:36.947006Z","iopub.execute_input":"2021-10-16T07:16:36.947465Z","iopub.status.idle":"2021-10-16T07:16:36.955854Z","shell.execute_reply.started":"2021-10-16T07:16:36.947424Z","shell.execute_reply":"2021-10-16T07:16:36.955137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self):\n        super(RMSELoss, self).__init__()\n\n    def forward(self, x, y):\n        criterion = nn.MSELoss()\n        loss = torch.sqrt(criterion(x, y))\n        return loss","metadata":{"execution":{"iopub.status.busy":"2021-10-16T07:16:36.957001Z","iopub.execute_input":"2021-10-16T07:16:36.957666Z","iopub.status.idle":"2021-10-16T07:16:36.967242Z","shell.execute_reply.started":"2021-10-16T07:16:36.957617Z","shell.execute_reply":"2021-10-16T07:16:36.966441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PicSet(Dataset):\n    def __init__(self, root, train=False):\n        # 所有图片的绝对路径\n        self.train=train\n        self.imgs = os.listdir(root)\n        self.root = root\n        self.transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        self.csv_data = pd.read_csv(root + '.csv')\n\n\n    def __getitem__(self, index):\n        img_path = self.root + '/'+self.csv_data['Id'][index] + '.jpg'\n        pil_img = Image.open(img_path)\n        if self.transforms:\n            data = self.transforms(pil_img)\n        else:\n            pil_img = np.asarray(pil_img)\n            data = torch.from_numpy(pil_img)\n        if self.train:\n            label = torch.tensor(self.csv_data['Pawpularity'][index]).to(torch.float32)\n            return {'pic': data, 'label': label}\n        else:\n            return {'pic': data}\n\n\n    def __len__(self):\n        return len(self.imgs)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T07:16:36.969949Z","iopub.execute_input":"2021-10-16T07:16:36.970154Z","iopub.status.idle":"2021-10-16T07:16:36.981212Z","shell.execute_reply.started":"2021-10-16T07:16:36.970124Z","shell.execute_reply":"2021-10-16T07:16:36.98046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_pic(train_path, test_path):\n    train_dataset = PicSet(train_path,train=True)\n    pic_num = len(train_dataset)\n    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset,\n                                                               [int(pic_num * 0.9), pic_num - int(pic_num * 0.9)])\n    # print('train:', len(train_dataset), 'val:', len(val_dataset))\n\n    train_loader = torch.utils.data.DataLoader(train_dataset,\n                                               batch_size=batch_size,\n                                               shuffle=True,\n                                               num_workers=num_workers)\n\n    val_loader = torch.utils.data.DataLoader(val_dataset,\n                                             batch_size=batch_size,\n                                             shuffle=False,\n                                             num_workers=num_workers)\n\n    test_dataset = PicSet(test_path)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n                                              num_workers=num_workers)\n    return train_loader, val_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2021-10-16T07:16:36.982332Z","iopub.execute_input":"2021-10-16T07:16:36.982778Z","iopub.status.idle":"2021-10-16T07:16:36.993993Z","shell.execute_reply.started":"2021-10-16T07:16:36.982745Z","shell.execute_reply":"2021-10-16T07:16:36.993304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    train_loader, val_loader, test_loader = load_pic(train_pic_path, test_pic_path)\n\n    test_df = pd.read_csv(test_csv_path)\n    test_score = []\n\n    pic_net = FineTuneResnet50(num_class=1).to(device)\n    \n    pic_net.load_state_dict(torch.load(model_root))\n\n\n    criterion = RMSELoss()\n    optimizer_PIC = optim.Adam(pic_net.parameters(), lr=0.0001)\n\n    train_losses = []\n    val_losses = []\n    for epoch in range(epochs):\n        each_train_losses = []\n        each_val_losses = []\n\n        pic_net.train()\n\n        with tqdm(total=len(train_loader)) as t:\n            for data in train_loader:\n\n                pic_score = pic_net(data['pic'].to(device))\n\n                total_score = pic_score\n\n                loss = criterion(total_score, data['label'].to(device).view(-1, 1))\n\n                each_train_losses.append(loss.item())\n\n                optimizer_PIC.zero_grad()\n\n                loss.backward()\n\n                optimizer_PIC.step()\n\n                t.set_description(f'Epoch [{epoch+1}/{epochs}]')\n                t.set_postfix(loss=loss.item())\n                t.update(1)\n\n        pic_net.eval()\n\n        for data in val_loader:\n            \n            pic_score = pic_net(data['pic'].to(device))\n                \n            # total_score = (pic_score + data_score) / 2\n            total_score = pic_score\n            \n            loss = criterion(total_score, data['label'].to(device).view(-1, 1))\n\n            each_val_losses.append(loss.item())\n\n        val_losses.append(np.mean(each_val_losses))\n        train_losses.append(np.mean(each_train_losses))\n\n        # print('--------------Epoch %d --------------' % (epoch+1))\n        print('Epoch: ', epoch+1, ', training loss:', np.mean(each_train_losses), ', validate loss: ',\n              np.mean(each_val_losses))\n\n    torch.save(pic_net.state_dict(), 'pic_net_model.pt')\n    \n    test_score = []\n\n    for data in test_loader:\n        \n        pic_score = pic_net(data['pic'].to(device))\n        \n        pic_score = np.array(pic_score.cpu().detach().numpy())\n\n        test_score.extend(list(map(float, np.mean(pic_score, axis=1))))\n    \n\n    submission = pd.DataFrame({\"Id\": test_df.Id.values, \"Pawpularity\": test_score})\n    submission.to_csv(\"submission.csv\", index=False)\n#     print(submission)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T07:16:36.99534Z","iopub.execute_input":"2021-10-16T07:16:36.995684Z","iopub.status.idle":"2021-10-16T07:24:00.388847Z","shell.execute_reply.started":"2021-10-16T07:16:36.995628Z","shell.execute_reply":"2021-10-16T07:24:00.388133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T07:24:00.390251Z","iopub.execute_input":"2021-10-16T07:24:00.390507Z","iopub.status.idle":"2021-10-16T07:24:00.409533Z","shell.execute_reply.started":"2021-10-16T07:24:00.390474Z","shell.execute_reply":"2021-10-16T07:24:00.408912Z"},"trusted":true},"execution_count":null,"outputs":[]}]}