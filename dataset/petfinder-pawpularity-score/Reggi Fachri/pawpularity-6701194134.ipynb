{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-29T01:02:19.745748Z","iopub.execute_input":"2021-11-29T01:02:19.746077Z","iopub.status.idle":"2021-11-29T01:02:22.319255Z","shell.execute_reply.started":"2021-11-29T01:02:19.746042Z","shell.execute_reply":"2021-11-29T01:02:22.317267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_metadata = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\ndf_test_metadata = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\ndf_train_metadata.head","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:02:22.323504Z","iopub.execute_input":"2021-11-29T01:02:22.323786Z","iopub.status.idle":"2021-11-29T01:02:22.358513Z","shell.execute_reply.started":"2021-11-29T01:02:22.323755Z","shell.execute_reply":"2021-11-29T01:02:22.357614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport tensorflow as tf\nimport cv2\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\ntrain_image = df_train_metadata.copy()\ntest_image = df_test_metadata.copy()\n\ntrain_image[\"file_path\"] = df_train_metadata[\"Id\"].apply(lambda x: \"../input/petfinder-pawpularity-score/train/\" + x + \".jpg\")\ntest_image[\"file_path\"] = df_test_metadata[\"Id\"].apply(lambda x: \"../input/petfinder-pawpularity-score/test/\" + x + \".jpg\")\n\n\n\nplt.figure(figsize=(20, 20))\nrow, col = 5, 4\nfor i in range(row * col):\n    plt.subplot(row, col, i+1)\n    image = cv2.imread(train_image.loc[i, 'file_path'])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    target = train_image.loc[i, 'Pawpularity']\n    plt.imshow(image)\n    plt.title(f\"No: {i}\" f\"   Pawpularity: {target}\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:02:22.359941Z","iopub.execute_input":"2021-11-29T01:02:22.360493Z","iopub.status.idle":"2021-11-29T01:02:26.625692Z","shell.execute_reply.started":"2021-11-29T01:02:22.360442Z","shell.execute_reply":"2021-11-29T01:02:26.624664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_features_train = pd.read_csv('../input/image-features-train/image_features_train.csv')\nimage_features_test = pd.read_csv('../input/image-features-test/image_features_test.csv')\n\\\n\ndf_train = pd.concat([df_train_metadata['Pawpularity'], df_train_metadata.loc[:,'Subject Focus':'Blur'],image_features_train.loc[:,'centroid_pr_x':'kurtosis_pr_y']], axis=1)\ndf_test = pd.concat([df_test_metadata.loc[:,'Subject Focus':'Blur'],image_features_test.loc[:,'centroid_pr_x':'kurtosis_pr_y']], axis=1)\n\ndf_test.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:02:26.627861Z","iopub.execute_input":"2021-11-29T01:02:26.62843Z","iopub.status.idle":"2021-11-29T01:02:26.690235Z","shell.execute_reply.started":"2021-11-29T01:02:26.628386Z","shell.execute_reply":"2021-11-29T01:02:26.689182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from skfeature.function.similarity_based import fisher_score, reliefF, trace_ratio\n# from skfeature.function.statistical_based import f_score, chi_square, gini_index\n# from skfeature.function.information_theoretical_based import FCBF, JMI\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\n\n# #ambil kolom untuk label kontinu\nlabel_kontinu = np.asarray(df_train['Pawpularity'])\n\n# # ambil kolom untuk features\nfeatures_train = np.asarray(df_train.loc[:, 'Subject Focus':'kurtosis_pr_y'])\nfeatures_test = np.asarray(df_test.loc[:, 'Subject Focus':'kurtosis_pr_y'])\n# #melakukan label encoding label diskrit\n# # encoder = preprocessing.LabelEncoder().fit(label_diskrit)\n# # transformed_label_diskrit = encoder.transform(label_diskrit)\n# # print(transformed_label_diskrit)\n\n# melakukan feature scaling\nscaler = preprocessing.MinMaxScaler(feature_range=(0, 10)).fit(features_train)\nscaled_feature_train = scaler.transform(features_train)\nscaled_features_test = scaler.transform(features_test)\nprint(scaled_feature_train)\n\n# # bentuk awal method dan parameter gini-index terdapat X dan y\n# # dimana X adalah fitur dan y adalah label\n# # MIM.mim(X, y)\n# # ranked_index = fisher_score.fisher_score(scaled_feature, transformed_label_diskrit, mode='raw')\n# # print(\"\\nfisher score raw\")\n# # print(ranked_index)\n\n# # ranked_index = fisher_score.fisher_score(scaled_feature, transformed_label_diskrit, mode='rank')\n# # print(\"\\nfisher score rank\")\n# # print(ranked_index)\n\n# ranked_index = JMI.jmi(scaled_feature_train, label_kontinu, mode='index')\n# print(\"\\nJMI\")\n# print(ranked_index)\n\n\n# # menampilkan fitur yang sudah diurutkan berdasarkan seleksi fitur\n# result_train = scaled_feature_train[:, ranked_index[:]]\n# print(result_train)\n# result_test = scaled_features_test[:, ranked_index[:]]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:02:26.691747Z","iopub.execute_input":"2021-11-29T01:02:26.692299Z","iopub.status.idle":"2021-11-29T01:02:26.706443Z","shell.execute_reply.started":"2021-11-29T01:02:26.69225Z","shell.execute_reply":"2021-11-29T01:02:26.705153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ranked_index = [19, 18, 17, 14, 12, 11, 6, 3, 13, 2, 15, 8, 16, 5, 7, 4, 0, 1, 10, 9]\nprint(\"\\nMIM\")\nprint(ranked_index)\n\n\n# menampilkan fitur yang sudah diurutkan berdasarkan seleksi fitur\nresult_train = scaled_feature_train[:, ranked_index[:]]\nprint(result_train)\nresult_test = scaled_features_test[:, ranked_index[:]]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:02:26.708273Z","iopub.execute_input":"2021-11-29T01:02:26.70853Z","iopub.status.idle":"2021-11-29T01:02:26.72103Z","shell.execute_reply.started":"2021-11-29T01:02:26.708503Z","shell.execute_reply":"2021-11-29T01:02:26.7199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(predict, actual):\n    predict = np.array(predict)\n    actual = np.array(actual)\n\n    distance = predict - actual\n\n    square_distance = distance ** 2\n\n    mean_square_distance = square_distance.mean()\n\n    score = np.sqrt(mean_square_distance)\n\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:02:26.7235Z","iopub.execute_input":"2021-11-29T01:02:26.72383Z","iopub.status.idle":"2021-11-29T01:02:26.732666Z","shell.execute_reply.started":"2021-11-29T01:02:26.723788Z","shell.execute_reply":"2021-11-29T01:02:26.731821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import make_scorer\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport xgboost as xgb\n\njumlah_fitur = range(1,scaled_feature_train.shape[1]+1)\nscores = []\nscore = 1000\nbest_score = 1000\nbest_feature_number = 0\n\n#Mencoba optimasi hyerparameter untuk setiap kombinasi/jumlah fitur\nfor jumlah_fitur_terbaik in jumlah_fitur:\n    #print(jumlah_fitur_terbaik)\n    selected_features = result_train[:,0:jumlah_fitur_terbaik]\n    #split data training dan data testing\n    X_train, X_test, y_train, y_test = train_test_split(selected_features, label_kontinu, test_size=0.3, random_state=0)\n\n    regressor = DecisionTreeRegressor()\n    #regressor = KNeighborsRegressor()\n    #regressor = SVR()\n    #regressor = GradientBoostingRegressor()\n    #regressor = xgb.XGBRegressor()\n    \n    # optimasi hyperparameter\n    param_grid = [\n    #{'n_neighbors':[3,5,7,9,11,13,15], 'metric':['euclidean','manhattan','chebyshev','minkowski','wminkowski','seuclidean','mahalanobis']}\n    #{'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n    #{'n_estimators': [50, 100, 150, 200], 'learning_rate': [0.5, 1, 1.5, 2], 'subsample': [0.6, 0.8, 1.0], 'max_depth': [5, 10, 15, 20]}\n    {'max_depth':[5, 10, 15], 'min_samples_split':[0.1, 1.0, 10], 'min_samples_leaf':[0.1, 0.5, 5]}\n    #{'n_estimators': [50, 100, 150, 200],'learning_rate': [0.1,0.2,0.3],}\n    #{'max_depth': [3, 5, 6, 10, 15, 20], 'learning_rate': [0.01, 0.1, 0.2, 0.3], 'subsample': np.arange(0.5, 1.0, 0.1), 'colsample_bytree': np.arange(0.4, 1.0, 0.1), 'colsample_bylevel': np.arange(0.4, 1.0, 0.1), 'n_estimators': [100, 500, 1000]}\n    ]\n    \n    #menentukan prioritas scoring menggunakan apa (accuracy/precision/recall, dll)\n    metric = make_scorer(rmse, greater_is_better = False)\n\n    model = GridSearchCV(regressor, param_grid, scoring=metric, cv=5, refit = True, verbose = 3) \n    # fitting the model for grid search \n    model.fit(X_train, y_train)\n\n    # print best parameter after tuning \n    print(model.best_params_) \n      \n    # print how our model looks after hyper-parameter tuning \n    print(model.best_estimator_)\n\n    #model_predictions = model.predict(X_test) \n\n    #model.fit(X_train, y_train)\n    score = abs(model.score(X_test, y_test))\n    scores.append(score)\n\n    #menentukan model terbaik berdasarkan score terbaik menggunakan kombinasi jumlah fitur dan optimasi hyperparameter\n    if(best_score > score):\n      best_score = score\n      best_model = model\n      best_feature_number = jumlah_fitur_terbaik\n      best_parameter = model.best_params_\n      \n      #menyimpan best_X_test dengan jumlah fitur terbaik\n      best_X_test = X_test\n\n\nplt.figure()\nplt.xlabel('jumlah_fitur_terbaik')\nplt.ylabel('score')\nplt.scatter(jumlah_fitur, scores)\nplt.grid()\n\nprint(scores);\nprint('Jumlah fitur terbaik adalah: ',best_feature_number)\nprint('Score terbaik adalah: ',best_score)\nprint('Parameter terbaik adalah: ',best_parameter)\n\nfinal_predictions = best_model.predict(best_X_test) \n  \n# print classification report \n# from sklearn.metrics import classification_report\n# print(classification_report(y_test, final_predictions)) \n\n# plot confusion matrix\n# from sklearn.metrics import plot_confusion_matrix\n# plot_confusion_matrix(best_model, best_X_test, y_test)  \n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:02:26.734348Z","iopub.execute_input":"2021-11-29T01:02:26.734703Z","iopub.status.idle":"2021-11-29T01:03:07.13956Z","shell.execute_reply.started":"2021-11-29T01:02:26.734658Z","shell.execute_reply":"2021-11-29T01:03:07.138694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#isi jawaban plot regresi dt\nfrom sklearn.metrics import r2_score\n\nfig, ax = plt.subplots()\nax.text(1, 9.5,'$R^2=$'+str(round(r2_score(y_test, final_predictions),4)), fontsize=12, verticalalignment='top', multialignment='center')\nax.text(1, 19,'$MSE=$'+str(round(rmse(y_test, final_predictions),4)), fontsize=12, verticalalignment='top', multialignment='center')\n\nax.set_xlim(xmin=1)\nax.set_ylim(ymin=1)\nax.set_xlim(xmax=100)\nax.set_ylim(ymax=100)\n\nax.set_xlabel('Actual Value', fontsize=14)\nax.set_ylabel('Predicted Value', fontsize=14)\nax.scatter(y_test, final_predictions, s=50, c=y_test, cmap='viridis')\n\nlims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n]\n\n# now plot both limits against eachother\nax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\nax.set_aspect('equal')\nax.set_xlim(lims)\nax.set_ylim(lims)\nax.grid(True, which='both')\n\nxvalue = np.linspace(1,10,10)\nlsigma = ax.fill_between(xvalue, xvalue+1, xvalue-1, color='blue', alpha=0.3)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:03:07.140951Z","iopub.execute_input":"2021-11-29T01:03:07.141197Z","iopub.status.idle":"2021-11-29T01:03:07.405666Z","shell.execute_reply.started":"2021-11-29T01:03:07.141167Z","shell.execute_reply":"2021-11-29T01:03:07.404798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_test = np.asarray(df_test.loc[:, \"Subject Focus\":\"kurtosis_pr_y\"])\nscaler = preprocessing.MinMaxScaler(feature_range=(0, 1)).fit(features_test)\nfeatures_test = scaler.transform(features_test)\n\nresult_test = features_test[:, ranked_index[:]]\nselected_features_kaggle_test = result_test[:, 0:best_feature_number]\n\nfinal_predictions_kaggle = best_model.predict(selected_features_kaggle_test) \ndata_test = np.array(df_test_metadata.Id)\n# print(len(final_predictions_kaggle))\n# print(features_test)\nfeatures_test = np.asarray(df_test.loc[:, \"Subject Focus\":\"kurtosis_pr_y\"])\nscaler = preprocessing.MinMaxScaler(feature_range=(0, 1)).fit(features_test)\nfeatures_test = scaler.transform(features_test)\n\nresult_test = features_test[:, ranked_index[:]]\nselected_features_kaggle_test = result_test[:, 0:best_feature_number]\n\nfinal_predictions_kaggle = best_model.predict(selected_features_kaggle_test) \ndata_test = np.array(df_test_metadata.Id)\n# print(len(final_predictions_kaggle))\n# print(features_test)\n# print(result_test)\n# print(data_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:03:07.408483Z","iopub.execute_input":"2021-11-29T01:03:07.408849Z","iopub.status.idle":"2021-11-29T01:03:07.420221Z","shell.execute_reply.started":"2021-11-29T01:03:07.408795Z","shell.execute_reply":"2021-11-29T01:03:07.419288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#generate file prediksi\nselected_features_kaggle_test = result_test[:, 0:best_feature_number]\nfinal_predictions_kaggle = best_model.predict(selected_features_kaggle_test) \nfinal_predictions_kaggle\n\ndf_hasil = pd.DataFrame({\"Id\":df_test_metadata.Id,\"Pawpularity\":final_predictions_kaggle})\n\ndf_hasil.to_csv('submission.csv', index=False)\ndf_hasil.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T01:03:07.421757Z","iopub.execute_input":"2021-11-29T01:03:07.42255Z","iopub.status.idle":"2021-11-29T01:03:07.443081Z","shell.execute_reply.started":"2021-11-29T01:03:07.422504Z","shell.execute_reply":"2021-11-29T01:03:07.442455Z"},"trusted":true},"execution_count":null,"outputs":[]}]}