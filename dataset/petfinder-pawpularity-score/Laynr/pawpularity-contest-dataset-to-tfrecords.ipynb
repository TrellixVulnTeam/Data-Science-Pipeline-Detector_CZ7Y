{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom io import BytesIO\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.python.lib.io import file_io\n\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T22:35:36.434183Z","iopub.execute_input":"2021-11-24T22:35:36.434743Z","iopub.status.idle":"2021-11-24T22:35:40.975467Z","shell.execute_reply.started":"2021-11-24T22:35:36.434702Z","shell.execute_reply":"2021-11-24T22:35:40.974524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path() # you can list the bucket with \"!gsutil ls $GCS_DS_PATH\"","metadata":{"execution":{"iopub.status.busy":"2021-11-24T22:35:40.977373Z","iopub.execute_input":"2021-11-24T22:35:40.977716Z","iopub.status.idle":"2021-11-24T22:35:41.525492Z","shell.execute_reply.started":"2021-11-24T22:35:40.977672Z","shell.execute_reply":"2021-11-24T22:35:41.524684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get handles\ndata_dir  = GCS_DS_PATH\ntest_dir  = data_dir + '/test/*.jpg'\ntrain_dir = data_dir + '/train/*.jpg'\n\ntest_images = !gsutil ls $test_dir\ntrain_images = !gsutil ls $train_dir\n\ntest_labels = pd.read_csv(data_dir + '/test.csv') \ntrain_labels = pd.read_csv(data_dir + '/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T22:35:41.52674Z","iopub.execute_input":"2021-11-24T22:35:41.526977Z","iopub.status.idle":"2021-11-24T22:36:00.508703Z","shell.execute_reply.started":"2021-11-24T22:35:41.526945Z","shell.execute_reply":"2021-11-24T22:36:00.50798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.tensorflow.org/tutorials/load_data/tfrecord\n# The following functions can be used to convert a value to a type compatible with tf.train.Example.\n\ndef _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float / double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","metadata":{"execution":{"iopub.status.busy":"2021-11-24T22:36:00.518835Z","iopub.execute_input":"2021-11-24T22:36:00.519334Z","iopub.status.idle":"2021-11-24T22:36:00.531708Z","shell.execute_reply.started":"2021-11-24T22:36:00.519297Z","shell.execute_reply":"2021-11-24T22:36:00.53106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_labels.columns)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T22:36:00.532673Z","iopub.execute_input":"2021-11-24T22:36:00.533049Z","iopub.status.idle":"2021-11-24T22:36:00.544006Z","shell.execute_reply.started":"2021-11-24T22:36:00.533012Z","shell.execute_reply":"2021-11-24T22:36:00.543227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# split into train validate\ntrain, validate = train_test_split(train_labels, test_size=0.2)\n\ndatasets = {'test': test_labels, 'train': train, 'validate': validate}\n\n# make tfrecords\nfor key, df in datasets.items():\n    record_file = f'{key}.tfrecords'\n    with tf.io.TFRecordWriter(record_file) as writer:\n        for index, row in df.iterrows():\n            \n            # image\n            img_id = row['Id']\n            image_path = data_dir + f'/{key}/{img_id}.jpg'\n            if key == 'validate':\n                image_path = data_dir + f'/train/{img_id}.jpg'\n            image_string = (BytesIO(file_io.read_file_to_string(image_path, binary_mode=True))).read()\n            image_shape = tf.io.decode_jpeg(image_string).shape\n            \n            feature = {\n              'height': _int64_feature(image_shape[0]),\n              'width': _int64_feature(image_shape[1]),\n              'depth': _int64_feature(image_shape[2]),\n              'image_raw': _bytes_feature(image_string),\n            }\n            \n            feature['Subject Focus'] = _int64_feature(row['Subject Focus'])\n            feature['Eyes'] = _int64_feature(row['Eyes'])\n            feature['Face'] = _int64_feature(row['Face'])\n            feature['Near'] = _int64_feature(row['Near'])\n            feature['Action'] = _int64_feature(row['Action'])\n            feature['Accessory'] = _int64_feature(row['Accessory'])\n            feature['Group'] = _int64_feature(row['Group'])\n            feature['Collage'] = _int64_feature(row['Collage'])\n            feature['Human'] = _int64_feature(row['Human'])\n            feature['Occlusion'] = _int64_feature(row['Occlusion'])\n            feature['Info'] = _int64_feature(row['Info'])\n            feature['Blur'] = _int64_feature(row['Blur'])\n            \n            if key == 'train' or key == 'validate':\n                feature['Pawpularity'] = _float_feature(row['Pawpularity'])\n\n            tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n            writer.write(tf_example.SerializeToString())","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}