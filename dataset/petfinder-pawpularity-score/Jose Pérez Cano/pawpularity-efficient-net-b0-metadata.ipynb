{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Basic libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Neural network libraries\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Sequential\nimport tensorflow.keras.layers.experimental.preprocessing as preprocessing\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Reading images and creating video libraries\nimport cv2\nimport os\n\n# Forest libraries\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt, inf, pi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-27T10:55:50.420163Z","iopub.execute_input":"2021-09-27T10:55:50.42094Z","iopub.status.idle":"2021-09-27T10:55:53.418319Z","shell.execute_reply.started":"2021-09-27T10:55:50.420897Z","shell.execute_reply":"2021-09-27T10:55:53.417498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntrain = train.set_index('Id')\ntargets = train['Pawpularity']\ntrain = train.drop('Pawpularity', axis=1)\npreds = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\npreds = preds.set_index('Id')\ntest = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest = test.set_index('Id')","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:55:53.419993Z","iopub.execute_input":"2021-09-27T10:55:53.420275Z","iopub.status.idle":"2021-09-27T10:55:53.454035Z","shell.execute_reply.started":"2021-09-27T10:55:53.420241Z","shell.execute_reply":"2021-09-27T10:55:53.453371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# specify your image path\ndef load_imgs(idx, train=True):\n    if train:\n        image_path = os.path.join(\n            '../input/petfinder-pawpularity-score/train/', idx+'.jpg'\n        )\n    else:\n        image_path = os.path.join(\n            '../input/petfinder-pawpularity-score/test/', idx+'.jpg'\n        )\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:55:53.455275Z","iopub.execute_input":"2021-09-27T10:55:53.455595Z","iopub.status.idle":"2021-09-27T10:55:53.461882Z","shell.execute_reply.started":"2021-09-27T10:55:53.455558Z","shell.execute_reply":"2021-09-27T10:55:53.461234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(load_imgs('0007de18844b0dbbb5e1f607da0606e0'))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:55:53.70227Z","iopub.execute_input":"2021-09-27T10:55:53.702751Z","iopub.status.idle":"2021-09-27T10:55:53.929744Z","shell.execute_reply.started":"2021-09-27T10:55:53.702718Z","shell.execute_reply":"2021-09-27T10:55:53.929067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels=None, batch_size=256, \n                 dim=(512,512), n_channels=3, shuffle=True, \n                 is_train=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.is_train = (labels is not None)\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        list_IDs_temp = self.list_IDs[index*self.batch_size:(index+1)*self.batch_size]\n\n        X = self.__data_generation(list_IDs_temp)\n        # Generate data\n        if self.is_train:\n            X2 = train.loc[list_IDs_temp]\n            y = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n            return ((np.array(X), np.array(X2)), np.array(y))\n        else:\n            X2 = test.loc[list_IDs_temp]\n            return ((np.array(X), np.array(X2)), np.zeros((self.batch_size,))) # TF somehow needs target for test when predicting\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels), dtype='uint8')\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            idx = str(ID)\n            img = load_imgs(idx, train=self.is_train)\n            img = cv2.resize(img, dsize=self.dim, interpolation=cv2.INTER_LINEAR)\n            img = np.array(img, dtype='uint8') \n            X[i,] = img\n        \n        return X","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:55:54.368512Z","iopub.execute_input":"2021-09-27T10:55:54.369069Z","iopub.status.idle":"2021-09-27T10:55:54.384063Z","shell.execute_reply.started":"2021-09-27T10:55:54.369031Z","shell.execute_reply":"2021-09-27T10:55:54.38288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(np.array(targets.index), targets,\n                                                 test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:57:46.22486Z","iopub.execute_input":"2021-09-27T10:57:46.225666Z","iopub.status.idle":"2021-09-27T10:57:46.235377Z","shell.execute_reply.started":"2021-09-27T10:57:46.225628Z","shell.execute_reply":"2021-09-27T10:57:46.234545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dim = (512,512)\nbatch_size = 8\nX_train = X_train[0:(len(X_train) - len(X_train)%batch_size)]\nX_val = X_val[0:(len(X_val)- len(X_val)%batch_size)]\ny_train = y_train[0:(len(y_train)- len(y_train)%batch_size)]\ny_val = y_val[0:(len(y_val)- len(y_val)%batch_size)]\n\ntrain_dataset = DataGenerator(X_train, y_train, batch_size=batch_size, dim=dim)\nval_dataset = DataGenerator(X_val, y_val, batch_size=batch_size, dim=dim)\ntest_dataset = DataGenerator(np.array(preds.index), batch_size=1, dim=dim)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T11:01:34.851391Z","iopub.execute_input":"2021-09-27T11:01:34.852293Z","iopub.status.idle":"2021-09-27T11:01:34.861344Z","shell.execute_reply.started":"2021-09-27T11:01:34.852227Z","shell.execute_reply":"2021-09-27T11:01:34.860406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet &> /dev/null","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:35:02.63719Z","iopub.execute_input":"2021-09-27T10:35:02.637715Z","iopub.status.idle":"2021-09-27T10:35:11.08792Z","shell.execute_reply.started":"2021-09-27T10:35:02.637663Z","shell.execute_reply":"2021-09-27T10:35:11.086967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"!mkdir model\n!mkdir model/variables\n!cp ../input/weights/saved_model.pb model\n!cp ../input/weights/variables.data-00000-of-00001 model/variables\n!cp ../input/weights/variables.index model/variables\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:35:11.089817Z","iopub.execute_input":"2021-09-27T10:35:11.090129Z","iopub.status.idle":"2021-09-27T10:35:11.097239Z","shell.execute_reply.started":"2021-09-27T10:35:11.090088Z","shell.execute_reply":"2021-09-27T10:35:11.096401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = train_dataset.__getitem__(0)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:35:11.101741Z","iopub.execute_input":"2021-09-27T10:35:11.102083Z","iopub.status.idle":"2021-09-27T10:35:12.380616Z","shell.execute_reply.started":"2021-09-27T10:35:11.101957Z","shell.execute_reply":"2021-09-27T10:35:12.379837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(a[0][0][0])","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:35:39.997547Z","iopub.execute_input":"2021-09-27T10:35:39.997919Z","iopub.status.idle":"2021-09-27T10:35:40.248177Z","shell.execute_reply.started":"2021-09-27T10:35:39.997882Z","shell.execute_reply":"2021-09-27T10:35:40.247519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(tf.image.flip_left_right(a[0][0][0]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:40:26.447527Z","iopub.execute_input":"2021-09-27T10:40:26.448234Z","iopub.status.idle":"2021-09-27T10:40:26.669923Z","shell.execute_reply.started":"2021-09-27T10:40:26.448195Z","shell.execute_reply":"2021-09-27T10:40:26.669249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.tfkeras as efn\n\ni = 7\nwith tf.device('/gpu:0'):\n    def newLayer(inp, neurons, drop):\n        x = layers.BatchNormalization()(inp)\n        x = layers.Dense(neurons)(x)\n        x = layers.Dropout(drop)(x)\n        return layers.Activation('relu')(x)\n    \n    def augmentation(img):\n        img = tf.cast(img, tf.float32) \n        return (img,\n                tf.image.flip_left_right(img))\n    \n    def effNet(imgs):\n        out = []\n        eff = efn.EfficientNetB0(include_top=False, pooling='avg')\n        for img in imgs:\n            out.append(eff(img))\n        return layers.concatenate(out, axis=1)\n    \n    def build_model(inp):\n        X = inp[0]\n        x1 = augmentation(X)\n        x1 = effNet(x1)\n        x1 = layers.Dense(128)(x1)\n        x1 = layers.Dropout(0.1)(x1)\n        x2 = inp[1]\n        x = layers.concatenate([x1, x2], axis=1)\n        x = layers.Dense(64, activation='relu')(x)\n        x = layers.Dense(1)(x)\n        return tf.clip_by_value(x, 1, 100)\n\n    def old_model(inp):\n        X = inp[0]\n        x = efn.EfficientNetB0(include_top=False, pooling='avg')(X)\n        return layers.Dense(1, activation='sigmoid')(x)\n    \n    optimizers = []\n    initial_learning_rate = 0.01\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate,\n        decay_steps=100,\n        decay_rate=0.99,\n        staircase=True)\n    optimizers.append(('exponential',(tf.keras.optimizers.SGD(learning_rate=lr_schedule)))) # 19.28\n    optimizers.append(('adam', tf.keras.optimizers.Adam(learning_rate=0.0005))) # 19.52\n    optimizers.append(('adagrad', keras.optimizers.Adagrad(lr=0.01))) # 19.39\n    optimizers.append(('adadelta', keras.optimizers.Adadelta(lr=1.0, rho=0.95))) # 19.40\n    optimizers.append(('rmsprop', keras.optimizers.RMSprop(lr=0.001, rho=0.9))) # 20.02\n    \n    histories = []\n    for name, optimizer in optimizers:\n        earlyStopping = EarlyStopping(patience=3, min_delta=0.01, \n                                      verbose=1, restore_best_weights=False,\n                                      baseline=None)\n\n        checkpoint_path = \"model_\"+name+\"_\"+str(i)\n        checkpoint_dir = os.path.dirname(checkpoint_path)\n        # model = tf.keras.models.load_model(checkpoint_path)\n\n        # Create a callback that saves the model's weights\n        cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                     save_weights_only=False,\n                                                     save_best_only=True,\n                                                     verbose=1)\n    \n        inp_images = layers.Input(shape=(*dim, 3))\n        inp_tabular = layers.Input(shape=(train.shape[1],))\n        inp = (inp_images, inp_tabular)\n        model = keras.Model(inputs=inp, outputs=build_model(inp))\n        model.compile(\n            optimizer=optimizer, \n            loss='mse',\n            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n            )\n\n        history = model.fit(train_dataset, validation_data=val_dataset,\n                            epochs=100, callbacks=[earlyStopping, cp_callback])\n        histories.append((history, name))","metadata":{"execution":{"iopub.status.busy":"2021-09-27T11:04:02.739766Z","iopub.execute_input":"2021-09-27T11:04:02.7401Z","iopub.status.idle":"2021-09-27T11:04:34.263586Z","shell.execute_reply.started":"2021-09-27T11:04:02.740069Z","shell.execute_reply":"2021-09-27T11:04:34.260943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,len(histories), figsize=(20,3))\n# Defining custom 'xlim' and 'ylim' values.\ncustom_ylim = (0, 0.24)\n\n# Setting the values for all axes.\nplt.setp(ax, ylim=custom_ylim)\nfor k, history in enumerate(histories):\n    ax[k].plot(history[0].history[\"root_mean_squared_error\"])\n    ax[k].plot(history[0].history[\"val_root_mean_squared_error\"])\n    ax[k].title.set_text(history[1])\n    ax[k].legend(['train', 'val'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:13:22.005339Z","iopub.execute_input":"2021-09-26T14:13:22.006139Z","iopub.status.idle":"2021-09-26T14:13:22.699507Z","shell.execute_reply.started":"2021-09-26T14:13:22.006103Z","shell.execute_reply":"2021-09-26T14:13:22.698765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_path = '../input/modelspawpularity/'\nmodels = ['model_exponential_6', 'model_adam_6', 'model_adadelta_6', 'model_adagrad_6', 'model_rmsprop_6']\n# models = [models_path + model for model in models]\n# labels_train = np.zeros((X_train.shape[0], 1))\nlabels_val = np.zeros((X_val.shape[0], 1))\nlabels_test = np.zeros((test.shape[0], 1))\nfor name in models:\n    print(name)\n    model = tf.keras.models.load_model(name)\n    # labels_train += model.predict(train_dataset) * 100\n    labels_val += model.predict(val_dataset) * 100\n    labels_test += model.predict(test_dataset, batch_size=1) * 100\n# labels_train /= len(models)\nlabels_val /= len(models)\nlabels_test /= len(models)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:14:54.995768Z","iopub.execute_input":"2021-09-26T15:14:54.996038Z","iopub.status.idle":"2021-09-26T15:15:57.122286Z","shell.execute_reply.started":"2021-09-26T15:14:54.995995Z","shell.execute_reply":"2021-09-26T15:15:57.121512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = sqrt(mean_squared_error(y_val * 100, labels_val))\nprint('Error (ensemble):', error)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:32:12.954757Z","iopub.execute_input":"2021-09-26T14:32:12.955414Z","iopub.status.idle":"2021-09-26T14:32:12.961995Z","shell.execute_reply.started":"2021-09-26T14:32:12.955374Z","shell.execute_reply":"2021-09-26T14:32:12.96114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds['Pawpularity'] = labels_test\npreds.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:16:52.8536Z","iopub.execute_input":"2021-09-26T15:16:52.854297Z","iopub.status.idle":"2021-09-26T15:16:52.861668Z","shell.execute_reply.started":"2021-09-26T15:16:52.854259Z","shell.execute_reply":"2021-09-26T15:16:52.860951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"X_train = train.loc[list(X_train)]\nX_val = train.loc[list(X_val)]\ny_train = targets.loc[list(X_train.index)]\ny_val = targets.loc[list(X_val.index)]\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:32:25.732934Z","iopub.execute_input":"2021-09-26T14:32:25.733675Z","iopub.status.idle":"2021-09-26T14:32:25.761082Z","shell.execute_reply.started":"2021-09-26T14:32:25.733637Z","shell.execute_reply":"2021-09-26T14:32:25.760394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"X_train['label'] = labels_train\nX_val['label'] = labels_val\ntest['label'] = labels_test\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:32:28.736322Z","iopub.execute_input":"2021-09-26T14:32:28.737037Z","iopub.status.idle":"2021-09-26T14:32:28.745139Z","shell.execute_reply.started":"2021-09-26T14:32:28.736985Z","shell.execute_reply":"2021-09-26T14:32:28.742697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"n_estimators = np.linspace(100, 1000, 10)\nmax_depths = range(1,20,2)\nbest_model = (None, None)\nmin_error = inf\nfor n in n_estimators:\n    print('estimators:', n)\n    for d in max_depths:\n        print('    depth:', d)\n        rf = RandomForestRegressor(n_estimators=int(n), max_features='sqrt',\n                                  max_depth=d)\n        rf.fit(X_train, y_train)\n        pred = rf.predict(X_val)\n        error = sqrt(mean_squared_error(y_val, pred))\n        if error < min_error:\n            best_model = (n, d)\n            min_error = error\n        print('        Error:', error)\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"print('Best error:', min_error)\nprint('Best n_estimator:', best_model[0])\nprint('Best depth:', best_model[1])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:36:41.400157Z","iopub.execute_input":"2021-09-26T14:36:41.400413Z","iopub.status.idle":"2021-09-26T14:36:41.408649Z","shell.execute_reply.started":"2021-09-26T14:36:41.400378Z","shell.execute_reply":"2021-09-26T14:36:41.407727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"n_estimators = np.linspace(100, 1000, 10)\nlearning_rates = np.logspace(-1, -4, 10)\nbest_model = (None, None)\nmin_error = inf\nfor n in n_estimators:\n    print('estimators:', n)\n    for l in learning_rates:\n        print('    learning_rate:', l)\n        xgb = XGBRegressor(n_estimators=int(n), learning_rate=l)\n        xgb.fit(X_train, y_train)\n        pred = xgb.predict(X_val)\n        error = sqrt(mean_squared_error(y_val, pred))\n        if error < min_error:\n            best_model = (n, l)\n            min_error = error\n        print('        Error:', error)\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"print('Best error:', min_error)\nprint('Best n_estimator:', best_model[0])\nprint('Best learning rate:', best_model[1])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:43:19.417873Z","iopub.execute_input":"2021-09-26T14:43:19.418211Z","iopub.status.idle":"2021-09-26T14:43:19.42741Z","shell.execute_reply.started":"2021-09-26T14:43:19.418173Z","shell.execute_reply":"2021-09-26T14:43:19.426712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"n_estimators = np.linspace(100, 1000, 10)\nlearning_rates = np.logspace(-1, -4, 10)\nbest_model = (None, None, None)\nmin_error = inf\nfor n in n_estimators:\n    print('estimators:', n)\n    for l in learning_rates:\n        print('    learning_rate:', l)\n        for d in max_depths:\n            print('        depth:', d)\n            lgbm = LGBMRegressor(n_estimators=int(n), learning_rate=l, max_depth=d)\n            lgbm.fit(X_train, y_train)\n            pred = lgbm.predict(X_val)\n            error = sqrt(mean_squared_error(y_val, pred))\n            if error < min_error:\n                best_model = (n, l, d)\n                min_error = error\n            print('            Error:', error)\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"print('Best error:', min_error)\nprint('Best n_estimator:', best_model[0])\nprint('Best learning rate:', best_model[1])\nprint('Best depth:', best_model[2])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:59:21.280599Z","iopub.execute_input":"2021-09-26T14:59:21.282339Z","iopub.status.idle":"2021-09-26T14:59:21.290757Z","shell.execute_reply.started":"2021-09-26T14:59:21.282308Z","shell.execute_reply":"2021-09-26T14:59:21.290012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"n_estimators = np.linspace(100, 1000, 10)\nlearning_rates = np.logspace(-1, -4, 10)\nbest_model = (None, None)\nmin_error = inf\nfor n in n_estimators:\n    print('estimators:', n)\n    for l in learning_rates:\n        print('    learning_rate:', l)\n        cat = CatBoostRegressor(n_estimators=int(n), learning_rate=l,\n                               verbose=0)\n        cat.fit(X_train, y_train)\n        pred = cat.predict(X_val)\n        error = sqrt(mean_squared_error(y_val, pred))\n        if error < min_error:\n            best_model = (n, l)\n            min_error = error\n        print('        Error:', error)\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"print('Best error:', min_error)\nprint('Best n_estimator:', best_model[0])\nprint('Best learning rate:', best_model[1])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:46:24.916765Z","iopub.execute_input":"2021-09-26T14:46:24.917455Z","iopub.status.idle":"2021-09-26T14:46:24.924409Z","shell.execute_reply.started":"2021-09-26T14:46:24.917414Z","shell.execute_reply":"2021-09-26T14:46:24.923404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"train = pd.concat([X_train,X_val])\ntargets = pd.concat([y_train,y_val])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-25T17:53:46.214659Z","iopub.execute_input":"2021-09-25T17:53:46.21534Z","iopub.status.idle":"2021-09-25T17:53:46.223851Z","shell.execute_reply.started":"2021-09-25T17:53:46.215308Z","shell.execute_reply":"2021-09-25T17:53:46.222965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"from sklearn.ensemble import StackingRegressor, VotingRegressor\n\nX_train, X_val, y_train, y_val = train_test_split(train, targets, \n                                                 random_state=1, test_size=0.2)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:00:41.875711Z","iopub.execute_input":"2021-09-26T15:00:41.875993Z","iopub.status.idle":"2021-09-26T15:00:41.888503Z","shell.execute_reply.started":"2021-09-26T15:00:41.875964Z","shell.execute_reply":"2021-09-26T15:00:41.887588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"stacking = StackingRegressor(\n    estimators=[\n        ('rf', RandomForestRegressor(n_estimators=800, max_features='sqrt',\n                                    max_depth=7)),\n        #('xgb', XGBRegressor(n_estimators=700, learning_rate=0.004641588833612782)),\n        ('lgbm', LGBMRegressor(n_estimators=1000, learning_rate=0.001, max_depth=9)),\n        ('cat', CatBoostRegressor(n_estimators=500, learning_rate=0.0021544346900318843,\n                                 verbose=0))\n    ],\n    final_estimator=RandomForestRegressor(n_estimators=800, max_features='sqrt',\n                                    max_depth=7)\n)\nstacking.fit(X_train, y_train)\npred = stacking.predict(X_val)\nprint('Error:', sqrt(mean_squared_error(y_val, pred)))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:00:42.707769Z","iopub.execute_input":"2021-09-26T15:00:42.708048Z","iopub.status.idle":"2021-09-26T15:01:09.846109Z","shell.execute_reply.started":"2021-09-26T15:00:42.708002Z","shell.execute_reply":"2021-09-26T15:01:09.84528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"voting = VotingRegressor(\n    estimators=[\n        #('rf', RandomForestRegressor(n_estimators=800, max_features='sqrt',\n                                    #max_depth=7)),\n        ('xgb', XGBRegressor(n_estimators=700, learning_rate=0.004641588833612782)),\n        ('lgbm', LGBMRegressor(n_estimators=1000, learning_rate=0.001, max_depth=9)),\n        ('cat', CatBoostRegressor(n_estimators=500, learning_rate=0.0021544346900318843,\n                                 verbose=0))\n    ]\n)\nvoting.fit(X_train, y_train)\npred = voting.predict(X_val)\nprint('Error:', sqrt(mean_squared_error(y_val, pred)))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:01:24.897627Z","iopub.execute_input":"2021-09-26T15:01:24.897881Z","iopub.status.idle":"2021-09-26T15:01:30.506284Z","shell.execute_reply.started":"2021-09-26T15:01:24.897855Z","shell.execute_reply":"2021-09-26T15:01:30.504614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_=\"\"\"stacking.fit(train, targets)\npreds['Pawpularity'] = stacking.predict(test)\npreds.to_csv('submission.csv')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-25T17:59:04.864222Z","iopub.execute_input":"2021-09-25T17:59:04.864498Z","iopub.status.idle":"2021-09-25T17:59:29.6854Z","shell.execute_reply.started":"2021-09-25T17:59:04.864469Z","shell.execute_reply":"2021-09-25T17:59:29.68469Z"},"trusted":true},"execution_count":null,"outputs":[]}]}