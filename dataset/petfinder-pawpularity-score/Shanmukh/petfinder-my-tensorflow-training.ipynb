{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center style = \"font-family: 'Lucida Console', 'Courier New', monospace;\">\n    <img src = \"https://www.bargainmarket.com.au/images/banner-pets-dog-cat-boarding.png\" width=600 height = 400>\n    <h1 style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\">PetFinder.my - Pawpularity Contest üê∂üê±</h1>\n</center>\n\n<br>\n<h2 style = \"font-family: Consolas\">What is PetFinder.my‚ùì</h2>\n<p style = \"font-family : Lucida Sans Typewriter\">\n<a href = \"https://petfinder.my/\">PetFinder.my</a> is Malaysia‚Äôs leading animal welfare platform, featuring over 180,000 animals with 54,000 happily adopted. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.\n</p>\n\n<br>\n<h2 style = \"font-family: Consolas\">What should we doüìù</h2>\n<p style = \"font-family : Lucida Sans Typewriter\">\nIn this competition, you‚Äôll analyze raw images and metadata to predict the ‚ÄúPawpularity‚Äù of pet photos. You'll train and test your model on PetFinder.my's thousands of pet profiles.</p>\n\n<br>\n<h2 style = \"font-family: Consolas\">Data InformationüíΩ</h2>\n<p style = \"font-family : Lucida Sans Typewriter\">Check <a href = \"https://www.kaggle.com/c/petfinder-pawpularity-score/data\">competition page</a> for details</p>\n\n<h2 style = \"font-family : Comic Sans MS\">Let's dive in ‚¨áÔ∏è</h2>","metadata":{}},{"cell_type":"markdown","source":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Librariesüìö</h1></center>","metadata":{}},{"cell_type":"code","source":"!/opt/conda/bin/python3.7 -m pip install --upgrade pip\n! pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:31:34.59937Z","iopub.execute_input":"2021-11-28T05:31:34.599885Z","iopub.status.idle":"2021-11-28T05:32:04.308824Z","shell.execute_reply.started":"2021-11-28T05:31:34.599789Z","shell.execute_reply":"2021-11-28T05:32:04.307857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##--------------------------\n# Import necessary libraries\n##--------------------------\nimport os\n\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nimport numpy as np\n\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nimport efficientnet.tfkeras as efn\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nfrom kaggle_datasets import KaggleDatasets\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:32:04.310664Z","iopub.execute_input":"2021-11-28T05:32:04.310951Z","iopub.status.idle":"2021-11-28T05:32:11.32915Z","shell.execute_reply.started":"2021-11-28T05:32:04.31092Z","shell.execute_reply":"2021-11-28T05:32:11.328215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Checking TPU accessüíª</h1></center>","metadata":{}},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:32:11.3305Z","iopub.execute_input":"2021-11-28T05:32:11.330855Z","iopub.status.idle":"2021-11-28T05:32:17.284481Z","shell.execute_reply.started":"2021-11-28T05:32:11.330807Z","shell.execute_reply":"2021-11-28T05:32:17.283519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Initializationsüé¨</h1></center>","metadata":{}},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"petfinder-pawpularity-score\")\nprint(GCS_DS_PATH)\n\nTRAIN_PATH = GCS_DS_PATH + \"/train/\"\nTEST_PATH = GCS_DS_PATH + \"/TEST/\"\n\nTRAIN_P = \"../input/petfinder-pawpularity-score/train\"\nTEST_P = \"../input/petfinder-pawpularity-score/test\"\n\ntrain_df = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntest_df = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n\nTRAIN_NS = os.listdir(TRAIN_P) \nTEST_NS = os.listdir(TEST_P)\nTRAIN_PS = [os.path.join(TRAIN_P,f) for f in TRAIN_NS]\nTEST_PS = [os.path.join(TEST_P,f) for f in TEST_NS]\n\nHEIGHT, WIDTH = 512, 512\nCHANNELS = 3\nSEED = 2021\nNUM_CLASSES = 10","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:32:17.286951Z","iopub.execute_input":"2021-11-28T05:32:17.28745Z","iopub.status.idle":"2021-11-28T05:32:17.986245Z","shell.execute_reply.started":"2021-11-28T05:32:17.287404Z","shell.execute_reply":"2021-11-28T05:32:17.985349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Data Visualizationüìä</h1></center>","metadata":{}},{"cell_type":"code","source":"##------------------------------\n# Display Random Training Images\n##------------------------------\n\nrand_ls = np.random.randint(9000, size=(9))\nfig,ax = plt.subplots(nrows=3,ncols=3,figsize=(18,10))\nfor count,i in enumerate(rand_ls):\n    r,c = count//3, count%3\n    ax[r,c].imshow(np.asarray(Image.open(TRAIN_PS[i])))\n    ax[r,c].axis(\"off\")\n    label = train_df[train_df[\"Id\"] == TRAIN_NS[i].split(\".\")[0]][\"Pawpularity\"].values[0]\n    ax[r,c].set_title(f\"Pawpularity Score : {label}\",fontsize=15, fontfamily=\"monospace\", fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:32:17.987564Z","iopub.execute_input":"2021-11-28T05:32:17.988339Z","iopub.status.idle":"2021-11-28T05:32:20.494444Z","shell.execute_reply.started":"2021-11-28T05:32:17.988296Z","shell.execute_reply":"2021-11-28T05:32:20.493817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##--------------------------------\n# Height, Width of Training Images\n##--------------------------------\ntrain_h, train_w = [], []\n\nfor path in TRAIN_PS:\n    im = Image.open(path)\n    w,h = im.size\n    train_h.append(h)\n    train_w.append(w)\n\n'''plt.figure(figsize=(10,10))\nsns.jointplot(x=train_w, y=train_h,kind=\"kde\")\nplt.xlabel(\"Width of Image\")\nplt.ylabel(\"Height of Image\")'''\nprint(f\"Mean Height : {sum(train_h)/len(train_h)} | Mean Width : {sum(train_w)/len(train_w)}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:34:58.231189Z","iopub.execute_input":"2021-11-28T05:34:58.231975Z","iopub.status.idle":"2021-11-28T05:34:58.240289Z","shell.execute_reply.started":"2021-11-28T05:34:58.231926Z","shell.execute_reply":"2021-11-28T05:34:58.239318Z"},"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##---------------------------\n# Metadata of Training images\n# Pandas Profiling\n##---------------------------\ntrain_df[\"Width\"] = train_w\ntrain_df[\"Height\"] = train_h\n\ntrain_report = ProfileReport(train_df,title=\"Metadata of Training images\")\n#train_report.to_file(\"./train_metadata.html\")\ntrain_report","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:33:21.701115Z","iopub.execute_input":"2021-11-28T05:33:21.701341Z","iopub.status.idle":"2021-11-28T05:33:57.820652Z","shell.execute_reply.started":"2021-11-28T05:33:21.701315Z","shell.execute_reply":"2021-11-28T05:33:57.819842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Data Preprocessingüß∞</h1></center>","metadata":{}},{"cell_type":"code","source":"##----------------------\n#Preprocessing Functions\n##----------------------\n\ndef process_img(filepath,label):\n    image = tf.io.read_file(filepath)\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n    image = tf.image.convert_image_dtype(image, tf.float32) \n    image = tf.image.resize(image, [HEIGHT,WIDTH])\n    return image,label\n\n\ndef data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n            \n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) \n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) \n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) \n        \n    \n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        \n    \n    if p_crop > .7:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.8)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.9)\n    elif p_crop > .4:\n        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n    \n    image = tf.image.resize(image, [HEIGHT,WIDTH])\n    return image,label\n\ndef get_dataset(filenames,labels, training=True):\n    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))\n    dataset = dataset.map(process_img,num_parallel_calls=AUTO)\n    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)\n    dataset = dataset.cache()\n    dataset = dataset.repeat()\n    if training:\n        dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:33:57.822204Z","iopub.execute_input":"2021-11-28T05:33:57.822469Z","iopub.status.idle":"2021-11-28T05:33:57.842538Z","shell.execute_reply.started":"2021-11-28T05:33:57.822439Z","shell.execute_reply":"2021-11-28T05:33:57.841805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_ls = tf.io.gfile.glob(TRAIN_PATH + \"*.jpg\" )\nfiles_df = pd.DataFrame(files_ls, columns = [\"filepath\"])\n\nbin_ranges = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\nbin_names = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\ntrain_df[\"label\"] = pd.cut(np.array(train_df[\"Pawpularity\"]),bins=bin_ranges,labels=bin_names)\n\nreal_labels = np.array(train_df[\"Pawpularity\"])\npaw_values = []\nfor i in bin_names:\n    val = list(train_df[train_df[\"label\"] == i][\"Pawpularity\"])\n    paw_values.append(sum(val)/len(val))\n\npseudo_labels = np.array(train_df[\"label\"])\n                       \n'''onehot_labels = np.zeros((len(labels), NUM_CLASSES))\nfor i in range(len(pseudo_labels)):\n    onehot_labels[i][pseudo_labels[i]] = 1'''\n    \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:33:57.843815Z","iopub.execute_input":"2021-11-28T05:33:57.844213Z","iopub.status.idle":"2021-11-28T05:33:58.8075Z","shell.execute_reply.started":"2021-11-28T05:33:57.844172Z","shell.execute_reply":"2021-11-28T05:33:58.806656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Setting Up Training Processüç≥</h1></center>","metadata":{}},{"cell_type":"code","source":"def create_model():\n    \n    pretrained = efn.EfficientNetB7(include_top=False, weights='noisy-student',input_shape=[HEIGHT,WIDTH, CHANNELS])\n    '''pretrained = tf.keras.applications.DenseNet121(weights= \"imagenet\",\n                                                   include_top=False,\n                                                   input_shape=(HEIGHT,WIDTH,CHANNELS),pooling=None)'''        \n    x = pretrained.output\n    x = tf.keras.layers.GlobalAveragePooling2D() (x)\n    x = tf.keras.layers.Dense(512, activation = \"relu\") (x)\n    x = tf.keras.layers.Dropout(0.3) (x)\n    x = tf.keras.layers.Dense(256, activation=\"relu\") (x)\n    x = tf.keras.layers.Dropout(0.3) (x)\n    #outputs = tf.keras.layers.Dense(NUM_CLASSES,activation=\"softmax\", dtype='float32')(x)\n    outputs = tf.keras.layers.Dense(1, dtype='float32')(x)\n        \n    model = tf.keras.Model(pretrained.input, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:33:58.809754Z","iopub.execute_input":"2021-11-28T05:33:58.810005Z","iopub.status.idle":"2021-11-28T05:33:58.819551Z","shell.execute_reply.started":"2021-11-28T05:33:58.809977Z","shell.execute_reply":"2021-11-28T05:33:58.818843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\n\ndef compile_model(model, lr=0.001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    #loss = tf.keras.losses.CategoricalCrossentropy()\n    loss = tf.keras.losses.MeanSquaredError()\n   \n    metrics = [tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n    '''\n    tfa.metrics.F1Score(num_classes = NUM_CLASSES,average = \"macro\", name = \"f1_score\"),\n    tf.keras.metrics.CategoricalAccuracy(name='acc')\n    '''\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:33:58.821528Z","iopub.execute_input":"2021-11-28T05:33:58.821795Z","iopub.status.idle":"2021-11-28T05:33:58.956362Z","shell.execute_reply.started":"2021-11-28T05:33:58.821756Z","shell.execute_reply":"2021-11-28T05:33:58.955478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"METRIC = \"val_rmse\"\n\ndef create_callbacks(kfold,metric = METRIC):\n    \n    cpk_path = f'./best_model_{kfold}.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor= metric,\n        mode='min',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor= metric,\n        mode='min',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor= metric,\n        mode='min',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:33:58.958134Z","iopub.execute_input":"2021-11-28T05:33:58.958434Z","iopub.status.idle":"2021-11-28T05:33:58.966496Z","shell.execute_reply.started":"2021-11-28T05:33:58.958397Z","shell.execute_reply":"2021-11-28T05:33:58.965391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Trainingüí°</h1></center>","metadata":{}},{"cell_type":"code","source":"EPOCHS = 10\nVERBOSE = 1\nN_SPLITS = 10\nBATCH_SIZE = 32\n\nkfold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\nhistory = {}\n\n\nfor fold,(tID,vID) in enumerate(kfold.split(files_ls,pseudo_labels)):\n    tFiles, tLabels = list(files_df.iloc[tID][\"filepath\"]),real_labels[tID]  #, onehot_labels[tID]\n    vFiles, vLabels = list(files_df.iloc[vID][\"filepath\"]), real_labels[vID]  #, onehot_labels[vID]\n    print(\"Number of Training Images: \",len(tID))\n    print(\"Number of Validation Images: \",len(vID))\n    \n    STEPS_PER_EPOCH  = len(tID)//BATCH_SIZE\n    VALID_STEPS = len(vID)//BATCH_SIZE\n    \n    tf.keras.backend.clear_session()\n    \n    train_ds = get_dataset(tFiles,tLabels, training = True)\n    val_ds = get_dataset(vFiles, vLabels, training = False)\n    \n    with strategy.scope():\n        model = create_model()\n        model = compile_model(model, lr=0.0001)\n        callbacks = create_callbacks(kfold = fold)\n    \n        print(\"------------------Fold - \",fold+1,\" --------------------------\")\n        history[fold] = model.fit(\n                            train_ds,\n                            epochs=EPOCHS,\n                            callbacks=callbacks,\n                            validation_data = val_ds,\n                            verbose=VERBOSE,\n                            steps_per_epoch = STEPS_PER_EPOCH,\n                            validation_steps=VALID_STEPS\n                           )","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-28T05:33:58.96818Z","iopub.execute_input":"2021-11-28T05:33:58.968804Z","iopub.status.idle":"2021-11-28T05:34:30.330573Z","shell.execute_reply.started":"2021-11-28T05:33:58.96876Z","shell.execute_reply":"2021-11-28T05:34:30.32722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">How did the Training goüìú</h1></center>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8*N_SPLITS,24))\n\nfor i in range(N_SPLITS):\n    acc = history[i].history['rmse']\n    val_acc = history[i].history['val_rmse']\n    loss = history[i].history['loss']\n    val_loss = history[i].history['val_loss']\n    epochs_range = range(len(history[i].history['val_loss'])) \n    \n    plt.subplot(N_SPLITS, 2,i*2+1)\n    plt.plot(epochs_range, acc, label='Training RMSE')\n    plt.plot(epochs_range, val_acc, label='Validation  RMSE')\n    plt.legend(loc='lower right')\n    plt.title(f'FOLD:{str(i)} Training and Validation  RMSE')\n    \n    plt.subplot(N_SPLITS, 2, i*2+2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title(f'FOLD:{str(i)} Training and Validation Loss')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:34:30.333308Z","iopub.status.idle":"2021-11-28T05:34:30.334562Z","shell.execute_reply.started":"2021-11-28T05:34:30.334314Z","shell.execute_reply":"2021-11-28T05:34:30.334367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}