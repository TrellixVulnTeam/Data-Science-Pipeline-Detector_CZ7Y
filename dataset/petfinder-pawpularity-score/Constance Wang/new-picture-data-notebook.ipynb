{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"For Picture Data, make sure notebook is running in GPU.","metadata":{}},{"cell_type":"code","source":"# repeat import from metadata\nimport sklearn\nimport sklearn.linear_model as linear_model\nfrom sklearn import model_selection\nimport pandas as pd\nimport numpy as np\n\n# pytorch\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\n\n# preprocessing\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:30:03.181491Z","iopub.execute_input":"2021-12-13T04:30:03.181769Z","iopub.status.idle":"2021-12-13T04:30:03.190092Z","shell.execute_reply.started":"2021-12-13T04:30:03.181738Z","shell.execute_reply":"2021-12-13T04:30:03.189388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create a custom dataset","metadata":{}},{"cell_type":"code","source":"img_size = 128\n\ndef getImagePath(split, img_id):\n    return '../input/petfinder-pawpularity-score/' + split + '/' + img_id + '.jpg'\n\n# ids is train_data['Id'], converted to numpy array\ndef getRawImages(split, ids):\n    images = []\n    for index in tqdm(range(ids.size)):\n        img_id = ids[index]\n        img_path = getImagePath(split, img_id)\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (img_size, img_size), interpolation = cv2.INTER_AREA)\n        img = img.astype(np.float32)\n        images.append(img)\n    return images\n\nclass PetImageDataset(Dataset):\n    def __init__(self, images, labels=None, transforms=None, split=\"train\"):\n        self.images = images\n        self.labels = labels\n        self.transforms = transforms\n        self.split = split\n        if torch.cuda.is_available():\n            device = 'cuda'\n        else:\n            device = 'cpu'\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, index):\n        img = self.images[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        if self.split == 'train':\n            score = self.labels[index]\n            return img, score\n        else:\n            return img","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:41:58.056463Z","iopub.execute_input":"2021-12-13T04:41:58.056785Z","iopub.status.idle":"2021-12-13T04:41:58.070639Z","shell.execute_reply.started":"2021-12-13T04:41:58.056745Z","shell.execute_reply":"2021-12-13T04:41:58.069873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Image Preprocessing\n\nBecause our image dataset is very small, with 9912 images, we want to augment the dataset by doing some image transformations.","metadata":{}},{"cell_type":"code","source":"# Training data has the possibility of being augmented by horizontal flip, etc. Pawpularity label remains the same\ndef getTrainTransforms():\n    return A.Compose([\n                        A.HorizontalFlip(p=0.5),\n#                         A.augmentations.geometric.rotate.Rotate(limit=5, p=0.5),\n                        A.Normalize(\n                                mean=[0.485, 0.456, 0.406], # for DATASET, not for individual image\n                                std=[0.229, 0.224, 0.225], \n                            ),\n                        ToTensorV2()\n                    ])\n\n# Do NOT do image augmentation on test and validation training sets, only resize and normalize.\ndef getValidationTestTransforms():\n    return A.Compose([\n                        A.Normalize(\n                            mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225],\n                        ),\n                        ToTensorV2(),\n                    ])","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:30:03.206159Z","iopub.execute_input":"2021-12-13T04:30:03.206615Z","iopub.status.idle":"2021-12-13T04:30:03.216363Z","shell.execute_reply.started":"2021-12-13T04:30:03.206536Z","shell.execute_reply":"2021-12-13T04:30:03.215633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Load Training, Validation, and Test Data","metadata":{}},{"cell_type":"code","source":"# Fetch images outside of dataset so that dataloader doesn't have to do fetching every time and cause training to be very slow\n\n# Repeated code from metadata. Could be removed-----------------\nrandom_state = 131\n\ninput_path = '../input/petfinder-pawpularity-score/'\ntrain_data = pd.read_csv(input_path + 'train.csv')\ntest_data = pd.read_csv(input_path + 'test.csv')\n\n# end of repeated code------------------------------------------\n\n# Get image lists for train, val, and test\ntrain_val_raw_images = getRawImages(\"train\", train_data['Id'].values)\ntrain_raw_images, val_raw_images, y_train, y_val = sklearn.model_selection.train_test_split(train_val_raw_images, train_data[\"Pawpularity\"].values.astype(np.float32), test_size = 0.2, random_state=random_state)\ntest_raw_images = getRawImages(\"test\", test_data['Id'].values)\n\n# Now set up dataloader\n\ntrain_img_data = PetImageDataset(images=train_raw_images, labels=y_train, split='train', transforms=getTrainTransforms())\nval_img_data = PetImageDataset(images=val_raw_images, labels=y_val, split='train', transforms=getValidationTestTransforms())","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:30:03.217724Z","iopub.execute_input":"2021-12-13T04:30:03.218126Z","iopub.status.idle":"2021-12-13T04:32:13.189273Z","shell.execute_reply.started":"2021-12-13T04:30:03.218088Z","shell.execute_reply":"2021-12-13T04:32:13.188583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### CNN Models","metadata":{}},{"cell_type":"markdown","source":"##### Baseline CNN model\nVery simple model to see how CNN is working, make sure data is loaded correctly.","metadata":{}},{"cell_type":"code","source":"class CNN(torch.nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv_1 = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.max_pool2d = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n        self.linear_1 = torch.nn.Linear(img_size // 2 * img_size // 2 * 32, 128)\n        self.linear_2 = torch.nn.Linear(128, 1)\n        self.dropout = torch.nn.Dropout(p=0.5)\n        self.relu = torch.nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.conv_1(x))\n        x = self.max_pool2d(x)\n        x = x.reshape(x.size(0), -1)\n        x = self.relu(self.linear_1(x))\n        x = self.dropout(x)\n        x = self.linear_2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:32:13.191581Z","iopub.execute_input":"2021-12-13T04:32:13.192404Z","iopub.status.idle":"2021-12-13T04:32:13.200625Z","shell.execute_reply.started":"2021-12-13T04:32:13.192364Z","shell.execute_reply":"2021-12-13T04:32:13.199964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### More Complex CNN Model\nWe tried adding more layers to see if the error would improve. The MSE error after the ideal number of epochs usually stayed around 21-25, either the same or worst than the median prediction. This is the final result after some tuning, which is only marginally better than the simple CNN model.\n\nThe architecture of the model was inspired by AlexNet.","metadata":{}},{"cell_type":"code","source":"class ComplexCNN(torch.nn.Module):\n    def __init__(self):\n        super(ComplexCNN, self).__init__()\n        self.conv_1 = torch.nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1)\n        self.conv_2 = torch.nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.max_pool2d_big = torch.nn.MaxPool2d(kernel_size=4, stride=4)\n        self.max_pool2d = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv_3 = torch.nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.linear_1 = torch.nn.Linear(img_size // 16 * img_size // 16 * 16, 128)\n        self.linear_2 = torch.nn.Linear(128, 128)\n        self.linear_3 = torch.nn.Linear(128, 1)\n        self.dropout = torch.nn.Dropout(p=0.5)\n        self.relu = torch.nn.ReLU()\n        self.sigmoid = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.relu(self.conv_1(x)) # 128 x 128 x 8\n        x = self.max_pool2d_big(x) # 32 x 32 x 16\n        x = self.relu(self.conv_2(x)) # 32 x 32 x 16\n        x = self.max_pool2d(x)\n        x = self.relu(self.conv_3(x)) # 16 x 16 x 16\n        x = self.relu(self.conv_3(x))\n        x = self.relu(self.conv_3(x))\n        x = self.max_pool2d(x) # 8 x 8 x 16\n        x = x.reshape(x.size(0), -1)\n        x = self.relu(self.linear_1(x))\n        x = self.dropout(x)\n        x = self.linear_2(x)\n        x = self.dropout(x)\n        x = self.linear_3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:32:13.201789Z","iopub.execute_input":"2021-12-13T04:32:13.202107Z","iopub.status.idle":"2021-12-13T04:32:13.215684Z","shell.execute_reply.started":"2021-12-13T04:32:13.202069Z","shell.execute_reply":"2021-12-13T04:32:13.214879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train the model","metadata":{}},{"cell_type":"code","source":"epochs = 100\nbatch_size = 32\nmodel = ComplexCNN() # Can change to complex CNN\n\ncriterion = torch.nn.MSELoss()\nmse_loss = torch.nn.MSELoss()\n\ntrain_loader = torch.utils.data.DataLoader(train_img_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n# No need to shuffle, we just want to iterate through the whole validation set\nval_loader = torch.utils.data.DataLoader(val_img_data, shuffle=False, batch_size=len(val_img_data), pin_memory=True, num_workers=2)\n\ntrain_loss = []\nval_loss = []\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\n    \noptimizer = Adam(model.parameters(), lr=1e-3)\n\ndef getError(loader, model):\n    with torch.no_grad():\n        for index, (x, y) in enumerate(val_loader, 0):\n            if torch.cuda.is_available():\n                x = x.cuda()\n                y = y.cuda()\n            y_pred = model(x)\n            error = criterion(y_pred, y)\n            error = error.cpu()\n            return error\n\nfor epoch in tqdm(range(epochs)):\n    running_loss = 0\n    for i, (batch_x_train, batch_y_train) in enumerate(train_loader, 0):\n        if torch.cuda.is_available():\n            batch_x_train = batch_x_train.cuda()\n            batch_y_train = batch_y_train.cuda()\n        optimizer.zero_grad()\n\n        y_predicted = model(batch_x_train)\n        y_predicted = y_predicted.to(torch.float32)\n        \n        loss = criterion(y_predicted, batch_y_train)\n        running_loss += loss.detach().cpu() * len(batch_x_train)\n        loss.backward()\n        optimizer.step()\n    running_loss /= len(train_img_data)\n    \n    if (epoch + 1) % 5 == 0:\n        loss_test = getError(val_loader, model)\n        train_loss.append(running_loss)\n        val_loss.append(loss_test)\n        print(f'epoch: {epoch+1}, loss: {np.sqrt(running_loss ):.4f}, test_loss: {np.sqrt(loss_test):.4f}' )","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:32:13.216925Z","iopub.execute_input":"2021-12-13T04:32:13.217452Z","iopub.status.idle":"2021-12-13T04:39:23.473878Z","shell.execute_reply.started":"2021-12-13T04:32:13.217415Z","shell.execute_reply":"2021-12-13T04:39:23.471275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,5))\nplt.title(\"Training and Validation Loss\")\nplt.plot(val_loss,label=\"val\")\nplt.plot(train_loss,label=\"train\")\nplt.xlabel(\"iterations (every 5 epochs)\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:40:13.181312Z","iopub.execute_input":"2021-12-13T04:40:13.18182Z","iopub.status.idle":"2021-12-13T04:40:13.506385Z","shell.execute_reply.started":"2021-12-13T04:40:13.181768Z","shell.execute_reply":"2021-12-13T04:40:13.501709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install torchsummary\n# from torchsummary import summary\n\n# summary(model, input_size=(3, img_size, img_size))","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:42:04.899747Z","iopub.execute_input":"2021-12-13T04:42:04.900027Z","iopub.status.idle":"2021-12-13T04:42:12.167887Z","shell.execute_reply.started":"2021-12-13T04:42:04.899998Z","shell.execute_reply":"2021-12-13T04:42:12.167075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now load and evaluate model on test image data\ntest_img_data = PetImageDataset(images=test_raw_images, split='test', transforms=getValidationTestTransforms())\ntest_loader = torch.utils.data.DataLoader(test_img_data, shuffle=False, batch_size=len(test_img_data))\n\nfinal_result = []\n\nfor index, (x) in enumerate(test_loader, 0):\n    if torch.cuda.is_available():\n        x = x.cuda()\n    final_result = model(x).cpu().detach().numpy().reshape(-1)\n\n# submit\nsubmission = pd.DataFrame({\n        \"Id\":  test_data['Id'],\n        \"Pawpularity\": final_result\n    })\nsubmission.to_csv('../working/submission.csv', index=False)\n\nfinal_result","metadata":{"execution":{"iopub.status.busy":"2021-12-13T04:39:23.483125Z","iopub.status.idle":"2021-12-13T04:39:23.483893Z","shell.execute_reply.started":"2021-12-13T04:39:23.483612Z","shell.execute_reply":"2021-12-13T04:39:23.483642Z"},"trusted":true},"execution_count":null,"outputs":[]}]}