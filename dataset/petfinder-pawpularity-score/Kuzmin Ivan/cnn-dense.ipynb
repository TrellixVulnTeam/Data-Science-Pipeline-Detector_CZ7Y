{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-20T10:06:30.878985Z","iopub.execute_input":"2021-12-20T10:06:30.879453Z","iopub.status.idle":"2021-12-20T10:06:30.992763Z","shell.execute_reply.started":"2021-12-20T10:06:30.879301Z","shell.execute_reply":"2021-12-20T10:06:30.991118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport glob\nimport random\nimport cv2\nimport pickle\npd.set_option('display.max_columns', None)\n\n# Image Aug\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# Machine Learning\nfrom xgboost import XGBRegressor\n\n# Deep Learning\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()\n\n# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:30.996362Z","iopub.execute_input":"2021-12-20T10:06:30.996961Z","iopub.status.idle":"2021-12-20T10:06:39.597824Z","shell.execute_reply.started":"2021-12-20T10:06:30.996904Z","shell.execute_reply":"2021-12-20T10:06:39.595734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAIN","metadata":{}},{"cell_type":"code","source":"csv_dir = '../input/petfinder-pawpularity-score'\ntrain_dir = '../input/petfinder-pawpularity-score/train'\ntest_dir = '../input/petfinder-pawpularity-score/test'\n\ntrain_file_path = '../input/train-5folds/train_5folds.csv'\ntest_file_path = os.path.join(csv_dir, 'test.csv')\nsample_sub_file_path = os.path.join(csv_dir, 'sample_submission.csv')\n\nprint(f'Train file: {train_file_path}')\nprint(f'Train file: {sample_sub_file_path}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.599834Z","iopub.execute_input":"2021-12-20T10:06:39.601032Z","iopub.status.idle":"2021-12-20T10:06:39.611285Z","shell.execute_reply.started":"2021-12-20T10:06:39.600985Z","shell.execute_reply":"2021-12-20T10:06:39.609377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(train_file_path)\ntest_df = pd.read_csv(sample_sub_file_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.613762Z","iopub.execute_input":"2021-12-20T10:06:39.614092Z","iopub.status.idle":"2021-12-20T10:06:39.665025Z","shell.execute_reply.started":"2021-12-20T10:06:39.614022Z","shell.execute_reply":"2021-12-20T10:06:39.664126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def return_filpath(name, folder):\n    path = os.path.join(folder, f'{name}.jpg')\n    return path","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.666699Z","iopub.execute_input":"2021-12-20T10:06:39.666998Z","iopub.status.idle":"2021-12-20T10:06:39.672999Z","shell.execute_reply.started":"2021-12-20T10:06:39.66696Z","shell.execute_reply":"2021-12-20T10:06:39.671764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['image_path'] = train_df['Id'].apply(lambda x: return_filpath(x, train_dir))\ntest_df['image_path'] = test_df['Id'].apply(lambda x: return_filpath(x, folder=test_dir))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.675064Z","iopub.execute_input":"2021-12-20T10:06:39.675844Z","iopub.status.idle":"2021-12-20T10:06:39.719083Z","shell.execute_reply.started":"2021-12-20T10:06:39.6758Z","shell.execute_reply":"2021-12-20T10:06:39.718109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.722223Z","iopub.execute_input":"2021-12-20T10:06:39.722465Z","iopub.status.idle":"2021-12-20T10:06:39.771801Z","shell.execute_reply.started":"2021-12-20T10:06:39.722422Z","shell.execute_reply":"2021-12-20T10:06:39.770635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = ['Pawpularity']\nnot_features = ['Id', 'kfold', 'image_path', 'Pawpularity']\ncols = list(train_df.columns)\nfeatures = [feat for feat in cols if feat not in not_features]\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.776408Z","iopub.execute_input":"2021-12-20T10:06:39.779186Z","iopub.status.idle":"2021-12-20T10:06:39.792251Z","shell.execute_reply.started":"2021-12-20T10:06:39.77914Z","shell.execute_reply":"2021-12-20T10:06:39.790887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_FOLDS = [0, 1, 2, 3, 4]","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.796264Z","iopub.execute_input":"2021-12-20T10:06:39.797316Z","iopub.status.idle":"2021-12-20T10:06:39.811324Z","shell.execute_reply.started":"2021-12-20T10:06:39.797247Z","shell.execute_reply":"2021-12-20T10:06:39.809774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'model': 'vit_large_patch32_384',\n    'dense_features': features,\n    'pretrained': True,\n    'inp_channels': 3,\n    'im_size': 384,\n    'device': device,\n    'lr': 1e-5,\n    'weight_decay': 1e-6,\n    'batch_size': 32,\n    'num_workers' : 0,\n    'epochs': 10,\n    'out_features': 1,\n    'dropout': 0.2,\n    'num_fold': len(TRAIN_FOLDS),\n    'mixup': False,\n    'mixup_alpha': 1.0,\n    'scheduler_name': 'CosineAnnealingWarmRestarts',\n    'T_0': 5,\n    'T_max': 5,\n    'T_mult': 1,\n    'min_lr': 1e-7,\n    'max_lr': 1e-4\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.8206Z","iopub.execute_input":"2021-12-20T10:06:39.82086Z","iopub.status.idle":"2021-12-20T10:06:39.842504Z","shell.execute_reply.started":"2021-12-20T10:06:39.820833Z","shell.execute_reply":"2021-12-20T10:06:39.839216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_transforms(DIM = params['im_size']):\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM,DIM),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.Rotate(limit=180, p=0.7),\n            albumentations.ShiftScaleRotate(\n                shift_limit = 0.1, scale_limit=0.1, rotate_limit=45, p=0.5\n            ),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, sat_shift_limit=0.2,\n                val_shift_limit=0.2, p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1, 0.1),\n                contrast_limit=(-0.1, 0.1), p=0.5\n            ),\n            ToTensorV2(p=1.0),\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.84479Z","iopub.execute_input":"2021-12-20T10:06:39.845189Z","iopub.status.idle":"2021-12-20T10:06:39.870289Z","shell.execute_reply.started":"2021-12-20T10:06:39.845145Z","shell.execute_reply":"2021-12-20T10:06:39.868874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mixup_data(x, z, y, params):\n    if params['mixup_alpha'] > 0:\n        lam = np.random.beta(\n            params['mixup_alpha'], params['mixup_alpha']\n        )\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if params['device'].type == 'cuda':\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    mixed_z = lam * z + (1 - lam) * z[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, mixed_z, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.872939Z","iopub.execute_input":"2021-12-20T10:06:39.873703Z","iopub.status.idle":"2021-12-20T10:06:39.901275Z","shell.execute_reply.started":"2021-12-20T10:06:39.873645Z","shell.execute_reply":"2021-12-20T10:06:39.899792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_valid_transforms(DIM = params['im_size']):\n    return albumentations.Compose(\n        [\n          albumentations.Resize(DIM,DIM),\n          albumentations.Normalize(\n              mean=[0.485, 0.456, 0.406],\n              std=[0.229, 0.224, 0.225],\n          ),\n          ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.904009Z","iopub.execute_input":"2021-12-20T10:06:39.906517Z","iopub.status.idle":"2021-12-20T10:06:39.922472Z","shell.execute_reply.started":"2021-12-20T10:06:39.905703Z","shell.execute_reply":"2021-12-20T10:06:39.920621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CuteDataset(Dataset):\n    def __init__(self, images_filepaths, dense_features, targets, transform=None):\n        self.images_filepaths = images_filepaths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        \n        dense = self.dense_features[idx, :]\n        label = torch.tensor(self.targets[idx]).float()\n        return image, dense, label","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.925209Z","iopub.execute_input":"2021-12-20T10:06:39.925773Z","iopub.status.idle":"2021-12-20T10:06:39.946826Z","shell.execute_reply.started":"2021-12-20T10:06:39.925716Z","shell.execute_reply":"2021-12-20T10:06:39.942864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def usr_rmse_score(output, target):\n    y_pred = torch.sigmoid(output).cpu()\n    y_pred = y_pred.detach().numpy()*100\n    target = target.cpu()*100\n    \n    return mean_squared_error(target, y_pred, squared=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.949922Z","iopub.execute_input":"2021-12-20T10:06:39.950774Z","iopub.status.idle":"2021-12-20T10:06:39.967387Z","shell.execute_reply.started":"2021-12-20T10:06:39.950726Z","shell.execute_reply":"2021-12-20T10:06:39.96633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"],\n                    float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.969146Z","iopub.execute_input":"2021-12-20T10:06:39.969572Z","iopub.status.idle":"2021-12-20T10:06:39.98938Z","shell.execute_reply.started":"2021-12-20T10:06:39.969425Z","shell.execute_reply":"2021-12-20T10:06:39.987796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scheduler(optimizer, scheduler_params=params):\n    if scheduler_params['scheduler_name'] == 'CosineAnnealingWarmRestarts':\n        scheduler = CosineAnnealingWarmRestarts(\n            optimizer,\n            T_0=scheduler_params['T_0'],\n            eta_min=scheduler_params['min_lr'],\n            last_epoch=-1\n        )\n    elif scheduler_params['scheduler_name'] == 'OneCycleLR':\n        scheduler = OneCycleLR(\n            optimizer,\n            max_lr=scheduler_params['max_lr'],\n            steps_per_epoch=int(((scheduler_params['num_fold']-1) * train_df.shape[0]) / (scheduler_params['num_fold'] * scheduler_params['batch_size'])) + 1,\n            epochs=scheduler_params['epochs'],\n        )\n\n    elif scheduler_params['scheduler_name'] == 'CosineAnnealingLR':\n        scheduler = CosineAnnealingLR(\n            optimizer,\n            T_max=scheduler_params['T_max'],\n            eta_min=scheduler_params['min_lr'],\n            last_epoch=-1\n        )\n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:39.992844Z","iopub.execute_input":"2021-12-20T10:06:39.994627Z","iopub.status.idle":"2021-12-20T10:06:40.017092Z","shell.execute_reply.started":"2021-12-20T10:06:39.994582Z","shell.execute_reply":"2021-12-20T10:06:40.01255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetNet(nn.Module):\n    def __init__(self, model_name=params['model'], out_features=params['out_features'], inp_channels=params['inp_channels'],\n                 pretrained=params['pretrained'], num_dense=len(params['dense_features'])):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, 128)\n        self.fc = nn.Sequential(\n            nn.Linear(128 + num_dense, 64),\n            nn.ReLU(),\n            nn.Linear(64, out_features)\n        )\n        self.dropout = nn.Dropout(params['dropout'])\n    \n    def forward(self, image, dense):\n        embeddings = self.model(image)\n        x = self.dropout(embeddings)\n        x = torch.cat([x, dense], dim=1)\n        output = self.fc(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.019178Z","iopub.execute_input":"2021-12-20T10:06:40.019896Z","iopub.status.idle":"2021-12-20T10:06:40.037783Z","shell.execute_reply.started":"2021-12-20T10:06:40.019851Z","shell.execute_reply":"2021-12-20T10:06:40.036627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler=None):\n    metric_monitor = MetricMonitor()\n    model.train()\n    stream = tqdm(train_loader)\n    \n    for i, (images, dense, target) in enumerate(stream, start=1):\n        if params['mixup']:\n            images, dense, target_a, target_b, lam = mixup_data(images, dense, target.view(-1, 1), params)\n            images = images.to(params['device'], dtype=torch.float)\n            dense = dense.to(params['device'], dtype=torch.float)\n            target_a = target_a.to(params['device'], dtype=torch.float)\n            target_b = target_b.to(params['device'], dtype=torch.float)\n        else:\n            images = images.to(params['device'], non_blocking=True)\n            dense = dense.to(params['device'], non_blocking=True)\n            target = target.to(params['device'], non_blocking=True).float().view(-1, 1)\n            \n        output = model(images, dense)\n        \n        if params['mixup']:\n            loss = mixup_criterion(criterion, output, target_a, target_b, lam)\n        else:\n            loss = criterion(output, target)\n            \n        rmse_score = usr_rmse_score(output, target)\n        metric_monitor.update('Loss', loss.item())\n        metric_monitor.update('RMSE', rmse_score)\n        loss.backward()\n        optimizer.step()\n            \n        if scheduler is not None:\n            scheduler.step()\n        \n        optimizer.zero_grad()\n        stream.set_description(f\"Epoch: {epoch:02}. Train. {metric_monitor}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.040148Z","iopub.execute_input":"2021-12-20T10:06:40.041407Z","iopub.status.idle":"2021-12-20T10:06:40.070372Z","shell.execute_reply.started":"2021-12-20T10:06:40.041366Z","shell.execute_reply":"2021-12-20T10:06:40.067684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate_fn(val_loader, model, criterion, epoch, params):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(val_loader)\n    final_targets = []\n    final_outputs = []\n    with torch.no_grad():\n        for i, (images, dense, target) in enumerate(stream, start=1):\n            images = images.to(params['device'], non_blocking=True)\n            dense = dense.to(params['device'], non_blocking=True)\n            target = target.to(params['device'], non_blocking=True).float().view(-1, 1)\n            output = model(images, dense)\n            loss = criterion(output, target)\n            rmse_score = usr_rmse_score(output, target)\n            metric_monitor.update('Loss', loss.item())\n            metric_monitor.update('RMSE', rmse_score)\n            stream.set_description(f\"Epoch: {epoch:02}. Valid. {metric_monitor}\")\n            \n            targets = (target.detach().cpu().numpy()*100).tolist()\n            outputs = (torch.sigmoid(output).detach().cpu().numpy()*100).tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(outputs)\n    return final_outputs, final_targets","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.074788Z","iopub.execute_input":"2021-12-20T10:06:40.075145Z","iopub.status.idle":"2021-12-20T10:06:40.102131Z","shell.execute_reply.started":"2021-12-20T10:06:40.075102Z","shell.execute_reply":"2021-12-20T10:06:40.098164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_models_of_each_fold = []\nrmse_tracker = []","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.103951Z","iopub.execute_input":"2021-12-20T10:06:40.104821Z","iopub.status.idle":"2021-12-20T10:06:40.114034Z","shell.execute_reply.started":"2021-12-20T10:06:40.104759Z","shell.execute_reply":"2021-12-20T10:06:40.112557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfor fold in TRAIN_FOLDS:\n    print(''.join(['#']*50))\n    print(f\"{''.join(['=']*15)} TRAINING FOLD: {fold+1}/{train_df['kfold'].nunique()} {''.join(['=']*15)}\")\n    # Data Split to train and Validation\n    train = train_df[train_df['kfold'] != fold]\n    valid = train_df[train_df['kfold'] == fold]\n    \n    X_train = train['image_path']\n    X_train_dense = train[params['dense_features']]\n    y_train = train['Pawpularity']/100\n    X_valid = valid['image_path']\n    X_valid_dense = valid[params['dense_features']]\n    y_valid = valid['Pawpularity']/100\n    \n    # Pytorch Dataset Creation\n    train_dataset = CuteDataset(\n        images_filepaths=X_train.values,\n        dense_features=X_train_dense.values,\n        targets=y_train.values,\n        transform=get_train_transforms()\n    )\n\n    valid_dataset = CuteDataset(\n        images_filepaths=X_valid.values,\n        dense_features=X_valid_dense.values,\n        targets=y_valid.values,\n        transform=get_valid_transforms()\n    )\n    \n    # Pytorch Dataloader creation\n    train_loader = DataLoader(\n        train_dataset, batch_size=params['batch_size'], shuffle=True,\n        num_workers=params['num_workers'], pin_memory=True\n        )\n\n    val_loader = DataLoader(\n        valid_dataset, batch_size=params['batch_size'], shuffle=False,\n        num_workers=params['num_workers'], pin_memory=True\n        )\n    \n    # Model, cost function and optimizer instancing\n    model = PetNet()\n    model = model.to(params['device'])\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'],\n                                  weight_decay=params['weight_decay'],\n                                  amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n    \n    # Training and Validation Loop\n    best_rmse = np.inf\n    best_epoch = np.inf\n    best_model_name = None\n    for epoch in range(1, params['epochs'] + 1):\n        train_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler)\n        predictions, valid_targets = validate_fn(val_loader, model, criterion, epoch, params)\n        rmse = round(mean_squared_error(valid_targets, predictions, squared=False), 3)\n        if rmse < best_rmse:\n            best_rmse = rmse\n            best_epoch = epoch\n            if best_model_name is not None:\n                os.remove(best_model_name)\n            torch.save(model.state_dict(),\n                       f\"{params['model']}_{epoch}_epoch_f{fold+1}_{rmse}_rmse.pth\")\n            best_model_name = f\"{params['model']}_{epoch}_epoch_f{fold+1}_{rmse}_rmse.pth\"\n\n    # Print summary of this fold\n    print('')\n    print(f'The best RMSE: {best_rmse} for fold {fold+1} was achieved on epoch: {best_epoch}.')\n    print(f'The Best saved model is: {best_model_name}')\n    best_models_of_each_fold.append(best_model_name)\n    rmse_tracker.append(best_rmse)\n    print(''.join(['#']*50))\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n\nprint('')\nprint(f'Average RMSE of all folds: {round(np.mean(rmse_tracker), 4)}')\n'''","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.116558Z","iopub.execute_input":"2021-12-20T10:06:40.117014Z","iopub.status.idle":"2021-12-20T10:06:40.145087Z","shell.execute_reply.started":"2021-12-20T10:06:40.116972Z","shell.execute_reply":"2021-12-20T10:06:40.137728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, name in enumerate(best_models_of_each_fold):\n    print(f'Best model of fold {i+1}: {name}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.146487Z","iopub.execute_input":"2021-12-20T10:06:40.147098Z","iopub.status.idle":"2021-12-20T10:06:40.15938Z","shell.execute_reply.started":"2021-12-20T10:06:40.147054Z","shell.execute_reply":"2021-12-20T10:06:40.158098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEST","metadata":{}},{"cell_type":"code","source":"csv_dir = '../input/petfinder-pawpularity-score'\ntest_dir = '../input/petfinder-pawpularity-score/test'\nmodels_dir = '../input/pawpularity-contest-models/swin_large_patch4_window12_384_2'\n\ntest_file_path = os.path.join(csv_dir, 'test.csv')\nsample_sub_file_path = os.path.join(csv_dir, 'sample_submission.csv')\nprint(f'Test file: {test_file_path}')\nprint(f'Models path: {models_dir}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.164614Z","iopub.execute_input":"2021-12-20T10:06:40.165401Z","iopub.status.idle":"2021-12-20T10:06:40.178848Z","shell.execute_reply.started":"2021-12-20T10:06:40.165358Z","shell.execute_reply":"2021-12-20T10:06:40.177567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(test_file_path)\nsample_df = pd.read_csv(sample_sub_file_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.180994Z","iopub.execute_input":"2021-12-20T10:06:40.182722Z","iopub.status.idle":"2021-12-20T10:06:40.206794Z","shell.execute_reply.started":"2021-12-20T10:06:40.18268Z","shell.execute_reply":"2021-12-20T10:06:40.20581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['image_path'] = test_df['Id'].apply(lambda x: return_filpath(x, folder=test_dir))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.212376Z","iopub.execute_input":"2021-12-20T10:06:40.215405Z","iopub.status.idle":"2021-12-20T10:06:40.226147Z","shell.execute_reply.started":"2021-12-20T10:06:40.215366Z","shell.execute_reply":"2021-12-20T10:06:40.22474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.231813Z","iopub.execute_input":"2021-12-20T10:06:40.233711Z","iopub.status.idle":"2021-12-20T10:06:40.263843Z","shell.execute_reply.started":"2021-12-20T10:06:40.233667Z","shell.execute_reply":"2021-12-20T10:06:40.262694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'model': 'swin_large_patch4_window12_384',\n    'dense_features': ['Subject Focus', 'Eyes', 'Face', 'Near',\n                       'Action', 'Accessory', 'Group', 'Collage',\n                       'Human', 'Occlusion', 'Info', 'Blur'],\n    'pretrained': False,\n    'dropout' : 0.2,\n    'inp_channels': 3,\n    'im_size': 384,\n    'device': device,\n    'batch_size': 16,\n    'num_workers' : 2,\n    'out_features': 1,\n    'debug': False\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.271329Z","iopub.execute_input":"2021-12-20T10:06:40.271695Z","iopub.status.idle":"2021-12-20T10:06:40.286484Z","shell.execute_reply.started":"2021-12-20T10:06:40.271656Z","shell.execute_reply":"2021-12-20T10:06:40.28156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if params['debug']:\n    test_df = test_df.sample(frac=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.290161Z","iopub.execute_input":"2021-12-20T10:06:40.292316Z","iopub.status.idle":"2021-12-20T10:06:40.303673Z","shell.execute_reply.started":"2021-12-20T10:06:40.291345Z","shell.execute_reply":"2021-12-20T10:06:40.30253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_transforms(DIM = params['im_size']):\n    return albumentations.Compose(\n        [\n          albumentations.Resize(DIM,DIM),\n          albumentations.Normalize(\n              mean=[0.485, 0.456, 0.406],\n              std=[0.229, 0.224, 0.225],\n          ),\n          ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.309934Z","iopub.execute_input":"2021-12-20T10:06:40.311087Z","iopub.status.idle":"2021-12-20T10:06:40.322933Z","shell.execute_reply.started":"2021-12-20T10:06:40.311029Z","shell.execute_reply":"2021-12-20T10:06:40.3216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Model","metadata":{}},{"cell_type":"code","source":"class PetNet(nn.Module):\n    def __init__(self, model_name=params['model'], out_features=params['out_features'], inp_channels=params['inp_channels'],\n                 pretrained=params['pretrained'], num_dense=len(params['dense_features'])):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, 128)\n        self.fc = nn.Sequential(\n            nn.Linear(128 + num_dense, 64),\n            nn.ReLU(),\n            nn.Linear(64, out_features)\n        )\n        self.dropout = nn.Dropout(params['dropout'])\n    \n    def forward(self, image, dense):\n        embeddings = self.model(image)\n        x = self.dropout(embeddings)\n        x = torch.cat([x, dense], dim=1)\n        output = self.fc(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.326114Z","iopub.execute_input":"2021-12-20T10:06:40.327621Z","iopub.status.idle":"2021-12-20T10:06:40.349175Z","shell.execute_reply.started":"2021-12-20T10:06:40.327576Z","shell.execute_reply":"2021-12-20T10:06:40.348017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Prediction","metadata":{}},{"cell_type":"code","source":"for model_name in glob.glob(models_dir + '/*.pth'):\n    model = PetNet()\n    model.load_state_dict(torch.load(model_name))\n    model = model.to(params['device'])\n    model.eval()\n    test_dataset = CuteDataset(\n        images_filepaths = test_df['image_path'].values,\n        dense_features = test_df[params['dense_features']].values,\n        targets = sample_df['Pawpularity'].values,\n        transform = get_test_transforms()\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=params['batch_size'],\n        shuffle=False, num_workers=params['num_workers'],\n        pin_memory=True\n    )\n\n    temp_preds = None\n    with torch.no_grad():\n        for (images, dense, target) in tqdm(test_loader, desc=f'Predicting. '):\n            images = images.to(params['device'], non_blocking=True)\n            dense = dense.to(params['device'], non_blocking=True)\n            predictions = torch.sigmoid(model(images, dense)).to('cpu').numpy()*100\n            \n            if temp_preds is None:\n                temp_preds = predictions\n            else:\n                temp_preds = np.vstack((temp_preds, predictions))\n\n    test_df[model_name.split('/')[-1].split('_')[-3]] = temp_preds\ndisplay(test_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:06:40.354892Z","iopub.execute_input":"2021-12-20T10:06:40.359724Z","iopub.status.idle":"2021-12-20T10:09:08.55375Z","shell.execute_reply.started":"2021-12-20T10:06:40.359685Z","shell.execute_reply":"2021-12-20T10:09:08.552211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_features = []\nfor model_name in glob.glob(models_dir + '/*.pth'):\n    dense_features.append(model_name.split('/')[-1].split('_')[-3])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:08.556832Z","iopub.execute_input":"2021-12-20T10:09:08.557896Z","iopub.status.idle":"2021-12-20T10:09:08.56687Z","shell.execute_reply.started":"2021-12-20T10:09:08.557812Z","shell.execute_reply":"2021-12-20T10:09:08.565894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"test_pred_all = None\nfor regressor_name in glob.glob(models_dir + '/*.bin'):\n    model = XGBRegressor()\n    model.load_model(regressor_name)\n    test_pred = model.predict(test_df[dense_features].values)\n    \n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n        \ntest_pred_all /= (len(glob.glob(models_dir + '/*.bin')))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-20T10:09:08.569069Z","iopub.execute_input":"2021-12-20T10:09:08.569561Z","iopub.status.idle":"2021-12-20T10:09:10.81307Z","shell.execute_reply.started":"2021-12-20T10:09:08.569506Z","shell.execute_reply":"2021-12-20T10:09:10.810971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame()\nsub_df['Id'] = test_df['Id']\nsub_df['Pawpularity'] = test_pred_all","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:10.814895Z","iopub.execute_input":"2021-12-20T10:09:10.815366Z","iopub.status.idle":"2021-12-20T10:09:10.825881Z","shell.execute_reply.started":"2021-12-20T10:09:10.81532Z","shell.execute_reply":"2021-12-20T10:09:10.824689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:10.827691Z","iopub.execute_input":"2021-12-20T10:09:10.828515Z","iopub.status.idle":"2021-12-20T10:09:10.84607Z","shell.execute_reply.started":"2021-12-20T10:09:10.828424Z","shell.execute_reply":"2021-12-20T10:09:10.844712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:10.848058Z","iopub.execute_input":"2021-12-20T10:09:10.848416Z","iopub.status.idle":"2021-12-20T10:09:10.86269Z","shell.execute_reply.started":"2021-12-20T10:09:10.848371Z","shell.execute_reply":"2021-12-20T10:09:10.86148Z"},"trusted":true},"execution_count":null,"outputs":[]}]}