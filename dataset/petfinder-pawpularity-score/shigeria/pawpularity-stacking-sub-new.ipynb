{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mkdir -p /tmp/pip/cache/\n!cp ../input/pyroppl-152/pyro_ppl-1.5.2-py3-none-any.whl /tmp/pip/cache/\n!cp ../input/pyroppl-152/pyro_api-0.1.2-py3-none-any.whl /tmp/pip/cache/\n!pip install --no-index --find-links /tmp/pip/cache/ pyro-ppl==1.5.2","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:20.681016Z","iopub.execute_input":"2022-01-04T21:24:20.681782Z","iopub.status.idle":"2022-01-04T21:24:31.684171Z","shell.execute_reply.started":"2022-01-04T21:24:20.68168Z","shell.execute_reply":"2022-01-04T21:24:31.683312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -R '/kaggle/input/yolov5/torch/root/.cache/torch' '/root/.cache/torch'\n!cp -R '/kaggle/input/yolov5/ultralytics/root/.config/Ultralytics' '/root/.config/Ultralytics'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/timmmaster/\")\nsys.path.append(\"../input/ttach-kaggle/ttach/\")\nsys.path.append(\"../input/pythonbox/\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:31.687156Z","iopub.execute_input":"2022-01-04T21:24:31.687636Z","iopub.status.idle":"2022-01-04T21:24:31.691642Z","shell.execute_reply.started":"2022-01-04T21:24:31.687602Z","shell.execute_reply":"2022-01-04T21:24:31.690846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\nimport gc\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom box import Box\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\nimport math\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule\n\nfrom sklearn.linear_model import Ridge\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nimport yaml\nfrom sklearn.preprocessing import normalize\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:31.693273Z","iopub.execute_input":"2022-01-04T21:24:31.693615Z","iopub.status.idle":"2022-01-04T21:24:42.59178Z","shell.execute_reply.started":"2022-01-04T21:24:31.693576Z","shell.execute_reply":"2022-01-04T21:24:42.59102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore')\n\n#general\nimport pickle\nfrom tqdm.auto import tqdm\nfrom collections import defaultdict\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport gc\nimport cv2\nimport imageio\nfrom itertools import product\ngc.enable()\nimport glob\npd.set_option('display.max_columns', None) \nfrom PIL import Image\n\n# visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# augmentation\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# deep learning\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n# metrics\nfrom sklearn.metrics import mean_squared_error\n\n# cv\nfrom sklearn.model_selection import KFold\n\nimport glob, re","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:42.59514Z","iopub.execute_input":"2022-01-04T21:24:42.595356Z","iopub.status.idle":"2022-01-04T21:24:43.618735Z","shell.execute_reply.started":"2022-01-04T21:24:42.595324Z","shell.execute_reply":"2022-01-04T21:24:43.618001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\nimport fastai","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport albumentations\nimport imageio\nimport itertools\n\nimport random\n\nimport torchvision.transforms as T\nfrom torchvision.io import read_image\n\nimport timm\nimport cv2\n\nfrom torch.cuda.amp import autocast, GradScaler\n\n# CatBoost\nimport catboost as cb\nfrom catboost import CatBoost, Pool\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:43.621193Z","iopub.execute_input":"2022-01-04T21:24:43.621459Z","iopub.status.idle":"2022-01-04T21:24:43.668902Z","shell.execute_reply.started":"2022-01-04T21:24:43.621424Z","shell.execute_reply":"2022-01-04T21:24:43.667207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cuml, pickle\nfrom cuml.svm import SVR\nprint('RAPIDS version',cuml.__version__,'\\n')\n\nLOAD_SVR_FROM_PATH = None\nLOAD_GPR_FROM_PATH = None","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:43.67038Z","iopub.execute_input":"2022-01-04T21:24:43.671073Z","iopub.status.idle":"2022-01-04T21:24:45.263548Z","shell.execute_reply.started":"2022-01-04T21:24:43.67103Z","shell.execute_reply":"2022-01-04T21:24:45.262756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smoke_test = ('CI' in os.environ)  # ignore; used to check code integrity in the Pyro repo\n# assert pyro.__version__.startswith('1.6.0')\ndevice = torch.device('cuda:0')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:45.264722Z","iopub.execute_input":"2022-01-04T21:24:45.265167Z","iopub.status.idle":"2022-01-04T21:24:45.269905Z","shell.execute_reply.started":"2022-01-04T21:24:45.265127Z","shell.execute_reply":"2022-01-04T21:24:45.269118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pyro\nimport pyro.contrib.gp as gp\n\n# reference: https://pyro.ai/examples/gp.html\ndef train_GPR(embeddings, target, gpr_path, emb_path, y_path):\n    \"\"\"\n    GPR training: The GPR model takes in the embeddings and the label/target of the samples\n        embeddings: numpy array of shape(N, D)\n        target: numpy array of shape (N, )\n        \n        gpr_path: the location to save the gpr model\n        emb_path: the location to save the transformer oof embedding\n        y_path: the location to save the original label/target\n    \"\"\"\n    pyro.set_rng_seed(0)\n    pyro.clear_param_store()\n    no_steps = 300\n    ls = 70.\n    var = 420.\n    noise = 1.\n\n    X = torch.tensor(embeddings, dtype=torch.float32).to(device)\n    y = torch.tensor(target, dtype=torch.float32).to(device)\n    kernel = gp.kernels.RBF(input_dim=X.shape[1], variance=torch.tensor(var),\n                        lengthscale=torch.tensor(ls)).to(device)\n\n    gpr = gp.models.GPRegression(X, y, kernel, noise=torch.tensor(noise)).to(device)\n\n    optimizer = torch.optim.Adam(gpr.parameters(), lr=0.0005)\n    loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n    losses = []\n    num_steps = no_steps if not smoke_test else 2\n    for i in tqdm(range(num_steps)):\n        optimizer.zero_grad()\n        loss = loss_fn(gpr.model, gpr.guide)\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n    \n    with torch.no_grad():\n        mean, cov = gpr(X, full_cov=True, noiseless=False)\n    \n    gpr_prediction = mean.cpu().numpy()\n    \n    print(\"Saving gpr model, embeddings, and target\")\n    save_gpr_model(gpr, embeddings, y, gpr_path, emb_path, y_path)\n    \n    del gpr, kernel\n    torch.cuda.empty_cache()\n    gc.collect()\n    return gpr_prediction\n\n\ndef save_gpr_model(gpr, embedding, y, gpr_path, embedding_path, y_path):\n    \"\"\"\n    To save the gpr model, embeddings and the original label required to perform inference for new test points.\n        gpr: pyro gpr model\n        embedding: transformer oof embedding\n        y: original label/target\n        \n        gpr_path: the filepath to save the gpr model\n        embedding_path: the filepath to save the transformer oof embedding\n        y_path: the filepath to save the original label/target\n        \n    \"\"\"    \n    torch.save(gpr.state_dict(), gpr_path)\n    np.save(embedding_path, embedding)\n    np.save(y_path, y.cpu())\n    print(\"Finished saving gpr weights at: {}\".format(gpr_path))\n    print(\"Finished saving embeddings at: {}\".format(embedding_path))\n    print(\"Finished saving embeddings label/target at: {}\".format(y_path))\n\ndef get_pyro_emb_preds(embedding_path, y_new_path, gpr_model_path, test_embedding, is_normalize=False):\n    pyro.clear_param_store()\n\n    emb_train = np.load(embedding_path, allow_pickle=True)\n    emb_train = np.vstack(emb_train)\n    if is_normalize:\n        X = torch.tensor(normalize(emb_train), dtype=torch.float32).cuda()\n    else:\n        X = torch.tensor((emb_train), dtype=torch.float32).cuda()\n        \n    y_new =  torch.tensor(np.load(y_new_path), dtype=torch.float32).cuda()\n \n    emb_test = np.vstack(test_embedding)\n    if is_normalize:\n        X_test = torch.tensor(normalize(emb_test), dtype=torch.float32).cuda()\n    else:\n        X_test = torch.tensor((emb_test), dtype=torch.float32).cuda()\n        \n    kernel = gp.kernels.RBF(input_dim=X.shape[1], variance=torch.tensor(420.),\n                    lengthscale=torch.tensor(70.)).cuda()\n    gpr = gp.models.GPRegression(X, y_new, kernel, noise=torch.tensor(1.)).cuda()\n    gpr.load_state_dict(torch.load(gpr_model_path, map_location='cuda:0'))\n    \n    with torch.no_grad():\n        mean, cov = gpr(X_test, full_cov=True, noiseless=False)\n    mean = np.array(mean.cpu())\n    \n    del gpr, kernel\n    torch.cuda.empty_cache()\n    gc.collect()\n    return mean","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:45.271468Z","iopub.execute_input":"2022-01-04T21:24:45.272039Z","iopub.status.idle":"2022-01-04T21:24:45.608625Z","shell.execute_reply.started":"2022-01-04T21:24:45.272Z","shell.execute_reply":"2022-01-04T21:24:45.607881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    model_name = \"swint_large224\"\n    data_dir = \"../input/petfinder-pawpularity-score/\"\n    model_dirs = \"../input/pawpularity-swin-new-exp1/\"\n    output_dir = \".\"\n    img_train_dir = os.path.join(data_dir, \"train\")\n    img_test_dir = os.path.join(data_dir, \"test\")\n    random_seed = 555\n    tta_times = 6 # 1: no TTA\n    tta_beta = 1 / tta_times\n    model_path = \"swin_large_patch4_window7_224_in22k\"\n    pretrained = False\n    n_fold = 5\n    inp_channels = 3\n    im_size =  224\n    batch_size = 8\n    num_workers = 0 # >0: OS Error\n    out_features = 0\n    dropout = 0\n    scheduler_name = \"OneCycleLR\" #OneCycleLR","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config2:\n    model_name = \"swint_large224\"\n    data_dir = \"../input/petfinder-pawpularity-score/\"\n    model_dirs = \"../input/pawpularity-swin-new-exp4/\"\n    output_dir = \".\"\n    img_train_dir = os.path.join(data_dir, \"train\")\n    img_test_dir = os.path.join(data_dir, \"test\")\n    random_seed = 555\n    tta_times = 6 # 1: no TTA\n    tta_beta = 1 / tta_times\n    model_path = \"swin_large_patch4_window7_224\"\n    pretrained = False\n    n_fold = 5\n    inp_channels = 3\n    im_size =  224\n    batch_size = 8\n    num_workers = 0 # >0: OS Error\n    out_features = 0\n    dropout = 0\n    scheduler_name = \"OneCycleLR\" #OneCycleLR","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:26:32.131149Z","iopub.execute_input":"2022-01-04T21:26:32.131779Z","iopub.status.idle":"2022-01-04T21:26:32.138351Z","shell.execute_reply.started":"2022-01-04T21:26:32.131739Z","shell.execute_reply":"2022-01-04T21:26:32.137459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config3:\n    model_name = \"swint_large224\"\n    data_dir = \"../input/petfinder-pawpularity-score/\"\n    model_dirs = \"../input/pawpularity-swin-new-exp3/\"\n    output_dir = \".\"\n    img_train_dir = os.path.join(data_dir, \"train\")\n    img_test_dir = os.path.join(data_dir, \"test\")\n    random_seed = 555\n    tta_times = 6 # 1: no TTA\n    tta_beta = 1 / tta_times\n    model_path = \"swin_large_patch4_window7_224\"\n    pretrained = False\n    n_fold = 5\n    inp_channels = 3\n    im_size = 224\n    batch_size = 8\n    num_workers = 0 # >0: OS Error\n    out_features = 0\n    dropout = 0\n    scheduler_name = \"OneCycleLR\" #OneCycleLR","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=Config.random_seed):\n    os.environ['PYTHONSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic =True\n    torch.backends.cudnn.benchmark =True\n\nseed_everything()\n# device optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:45.61904Z","iopub.execute_input":"2022-01-04T21:24:45.619658Z","iopub.status.idle":"2022-01-04T21:24:45.635447Z","shell.execute_reply.started":"2022-01-04T21:24:45.619621Z","shell.execute_reply":"2022-01-04T21:24:45.634681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\ndef get_train_transforms(epoch, dim = Config.im_size):\n    return A.Compose(\n        [             \n            # resize like Resize in fastai\n            A.SmallestMaxSize(max_size=dim, p=1.0),\n            A.CenterCrop(height=dim, width=dim, p=1.0),\n            #A.HorizontalFlip(p = 0.5),\n            #A.geometric.transforms.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=1.0)\n        ]\n  )\n\ndef get_tta_transforms(epoch, dim = Config.im_size):\n    return A.Compose(\n        [             \n            # resize like Resize in fastai\n            A.SmallestMaxSize(max_size=dim, p=1.0),\n            A.CenterCrop(height=dim, width=dim, p=1.0),\n            A.HorizontalFlip(p = 0.5),\n            A.geometric.transforms.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=1.0)\n        ]\n  )","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:45.637112Z","iopub.execute_input":"2022-01-04T21:24:45.637841Z","iopub.status.idle":"2022-01-04T21:24:45.643839Z","shell.execute_reply.started":"2022-01-04T21:24:45.637801Z","shell.execute_reply":"2022-01-04T21:24:45.64301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetDataset(Dataset):\n    def __init__(self, image_filepaths, targets, transform=None):\n        self.image_filepaths = image_filepaths\n        self.targets = targets\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.image_filepaths[idx]\n        with open(image_filepath, 'rb') as f:\n            image = Image.open(f)\n            image_rgb = image.convert('RGB')\n        image = np.array(image_rgb)\n\n        if self.transform is not None:\n            image = self.transform(image = image)[\"image\"]\n        \n        image = image / 255 # convert to 0-1\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        target = self.targets[idx]\n\n        image = torch.tensor(image, dtype = torch.float)\n        target = torch.tensor(target, dtype = torch.float)\n        return image, target","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:45.646695Z","iopub.execute_input":"2022-01-04T21:24:45.647477Z","iopub.status.idle":"2022-01-04T21:24:45.656392Z","shell.execute_reply.started":"2022-01-04T21:24:45.647437Z","shell.execute_reply":"2022-01-04T21:24:45.655712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"],\n                    float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )\n    \ndef usr_rmse_score(output, target):\n    y_pred = torch.sigmoid(output).cpu()\n    y_pred = y_pred.detach().numpy()*100\n    target = target.cpu()*100\n    \n    return mean_squared_error(target, y_pred, squared=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:45.657442Z","iopub.execute_input":"2022-01-04T21:24:45.660647Z","iopub.status.idle":"2022-01-04T21:24:45.67062Z","shell.execute_reply.started":"2022-01-04T21:24:45.659712Z","shell.execute_reply":"2022-01-04T21:24:45.669813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetNet(nn.Module):\n    def __init__(\n        self,\n        model_name = Config.model_path,\n        out_features = Config.out_features,\n        inp_channels=Config.inp_channels,\n        pretrained=Config.pretrained\n    ):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), \n            nn.Linear(self.model.num_features, 1)\n        )\n\n    def extract_features(self, x):\n        f = self.model(x)\n        return f\n\n    def forward(self, x):\n        f = self.extract_features(x)\n        out = self.fc(f)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:45.674678Z","iopub.execute_input":"2022-01-04T21:24:45.67542Z","iopub.status.idle":"2022-01-04T21:24:45.68329Z","shell.execute_reply.started":"2022-01-04T21:24:45.675385Z","shell.execute_reply":"2022-01-04T21:24:45.682492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = timm.create_model('swin_large_patch4_window7_224', pretrained=False, in_chans=3, num_classes=0)\n        self.fc = self.fc = nn.Sequential(\n            nn.Dropout(0.5), \n            nn.Linear(self.backbone.num_features, 1)\n        )\n\n    def extract_features(self, x):\n        f = self.backbone(x)\n        return f\n\n    def forward(self, x):\n        f = self.extract_features(x)\n        out = self.fc(f)\n        return out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_train_dir = os.path.join(Config.data_dir, 'train')\ndef return_imgfilepath(name, folder=img_train_dir):\n    path = os.path.join(folder, f'{name}.jpg')\n    return path\n\ntrain_file_path = os.path.join(Config.data_dir, 'train.csv')\ntrain_df = pd.read_csv(train_file_path)\n\n# set image filepath\ntrain_df['file_path'] = train_df['Id'].apply(lambda x: return_imgfilepath(x))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:28:41.475223Z","iopub.execute_input":"2022-01-04T21:28:41.475507Z","iopub.status.idle":"2022-01-04T21:28:41.533185Z","shell.execute_reply.started":"2022-01-04T21:28:41.475479Z","shell.execute_reply":"2022-01-04T21:28:41.532446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = train_df['Id'].values\ntrain_filepaths = train_df['file_path'].values\ntargets = train_df['Pawpularity'].values\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\ntarget_bins = pd.cut(targets/100, bins=num_bins, labels=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:28:42.236911Z","iopub.execute_input":"2022-01-04T21:28:42.237324Z","iopub.status.idle":"2022-01-04T21:28:42.243877Z","shell.execute_reply.started":"2022-01-04T21:28:42.23729Z","shell.execute_reply":"2022-01-04T21:28:42.242945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_file_path = os.path.join(Config.data_dir, 'test.csv')\ntest_df = pd.read_csv(test_file_path)\ntest_df['file_path'] = test_df['Id'].apply(lambda x: return_imgfilepath(x, folder=Config.img_test_dir))\ntarget = 'Pawpularity'\ntest_filepaths = test_df['file_path'].values","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:28:42.945381Z","iopub.execute_input":"2022-01-04T21:28:42.945958Z","iopub.status.idle":"2022-01-04T21:28:42.956253Z","shell.execute_reply.started":"2022-01-04T21:28:42.94592Z","shell.execute_reply":"2022-01-04T21:28:42.955414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_final_predictions = [] #classifier\nsuper_final_predictions2 = [] #SVR\nsuper_final_predictions3 = [] #GPR\n\nskf = StratifiedKFold(n_splits = Config.n_fold, shuffle=True, random_state=Config.random_seed)\nfor i_fold, (train_idx, valid_idx) in enumerate(skf.split(train_filepaths, target_bins)):\n    print(f'=== fold {i_fold}: training ===')\n    \"\"\"\n    separate train/valid data \n    \"\"\"\n    X_train_paths = train_filepaths[train_idx]\n    y_train = targets[train_idx]\n    X_valid_paths = train_filepaths[valid_idx]\n    y_valid = targets[valid_idx]\n    valid_ids = ids[valid_idx]\n    \"\"\"\n    prepare dataset\n    \"\"\"\n    train_dataset = PetDataset(\n      image_filepaths = X_train_paths,\n      targets = y_train / 100,\n      transform = get_train_transforms(0)\n    )\n    train_loader = DataLoader(\n      train_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    valid_dataset = PetDataset(\n      image_filepaths = X_valid_paths,\n      targets = y_valid / 100,\n      transform = get_tta_transforms(0)\n    )\n    valid_loader = DataLoader(\n      valid_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    test_dataset = PetDataset(\n      image_filepaths = test_filepaths,\n      targets = np.zeros(len(test_filepaths)),\n      transform = get_tta_transforms(0)\n    )\n    test_loader = DataLoader(\n      test_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    \"\"\"\n    instantiate model, cost function and optimizer\n    \"\"\"\n    model = PetNet()\n    model.load_state_dict(torch.load(Config.model_dirs+Config.model_path+f\"_fold{i_fold}.pth\"))\n    model = model.to(device)\n    model.eval()\n    criterion = nn.BCEWithLogitsLoss()\n    \n    LOAD_SVR_FROM_PATH = \"../input/paws-svr-gpr-new-2/\"\n    LOAD_GPR_FROM_PATH = \"../input/paws-svr-gpr-new-2/\"\n    name = f\"SVR_fold_{i_fold}.pkl\"\n    ##################\n    # LOAD RAPIDS SVR \n    print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n    clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n    print('Predicting test...')\n    final_test_predictions_all = []\n    final_test_predictions_all2 = []\n    final_test_predictions_all3 = []\n    for _ in range(5):\n        final_test_predictions = []\n        embed_test = np.array([]).reshape((0,1536))\n        stream = tqdm(test_loader)\n        for i, (images, target) in enumerate(stream, start = 1):\n            images = images.to(device, non_blocking = True).float()\n            target = target.to(device, non_blocking = True).float().view(-1, 1)\n            with torch.no_grad():\n                output = model(images)\n                emb = model.extract_features(images)\n            embed_test = np.concatenate([embed_test, emb.tolist()])\n            pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n            final_test_predictions.extend(pred)\n        final_test_predictions2 = clf.predict(normalize(embed_test))\n        final_test_predictions3 = get_pyro_emb_preds(LOAD_GPR_FROM_PATH+f'notebook_embeddings_f{i_fold}.npy', LOAD_GPR_FROM_PATH+f'notebook_y_f{i_fold}.npy', \n                                                     LOAD_GPR_FROM_PATH+f'notebook_gpr_f{i_fold}', normalize(embed_test))\n        final_test_predictions_all.append(final_test_predictions)\n        final_test_predictions_all2.append(final_test_predictions2)\n        final_test_predictions_all3.append(final_test_predictions3)\n    final_test_predictions_all = np.mean(final_test_predictions_all, axis=0)\n    final_test_predictions_all2 = np.mean(final_test_predictions_all2, axis=0)\n    final_test_predictions_all3 = np.mean(final_test_predictions_all3, axis=0)\n    super_final_predictions.append(final_test_predictions_all)\n    super_final_predictions2.append(final_test_predictions_all2)\n    super_final_predictions3.append(final_test_predictions_all3)\n    ##################\n    \n    del model, clf\n    del train_loader, train_dataset\n    del test_loader, test_dataset\n    del valid_loader, valid_dataset\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_final_predictions_2 = [] #classifier\nsuper_final_predictions2_2 = [] #SVR\nsuper_final_predictions3_2 = [] #GPR\n\nskf = StratifiedKFold(n_splits = Config.n_fold, shuffle=True, random_state=Config.random_seed)\nfor i_fold, (train_idx, valid_idx) in enumerate(skf.split(train_filepaths, target_bins)):\n    print(f'=== fold {i_fold}: training ===')\n    \"\"\"\n    separate train/valid data \n    \"\"\"\n    X_train_paths = train_filepaths[train_idx]\n    y_train = targets[train_idx]\n    X_valid_paths = train_filepaths[valid_idx]\n    y_valid = targets[valid_idx]\n    valid_ids = ids[valid_idx]\n    \"\"\"\n    prepare dataset\n    \"\"\"\n    train_dataset = PetDataset(\n      image_filepaths = X_train_paths,\n      targets = y_train / 100,\n      transform = get_train_transforms(0)\n    )\n    train_loader = DataLoader(\n      train_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    valid_dataset = PetDataset(\n      image_filepaths = X_valid_paths,\n      targets = y_valid / 100,\n      transform = get_tta_transforms(0)\n    )\n    valid_loader = DataLoader(\n      valid_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    test_dataset = PetDataset(\n      image_filepaths = test_filepaths,\n      targets = np.zeros(len(test_filepaths)),\n      transform = get_tta_transforms(0)\n    )\n    test_loader = DataLoader(\n      test_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    \"\"\"\n    instantiate model, cost function and optimizer\n    \"\"\"\n    model = PetNet()\n    model.load_state_dict(torch.load(Config2.model_dirs+Config2.model_path+f\"_fold{i_fold}.pth\"))\n    model = model.to(device)\n    model.eval()\n    criterion = nn.BCEWithLogitsLoss()\n    \n    LOAD_SVR_FROM_PATH = \"../input/paws-svr-gpr-new-5/\"\n    LOAD_GPR_FROM_PATH = \"../input/paws-svr-gpr-new-5/\"\n    name = f\"SVR_fold_{i_fold}.pkl\"\n    ##################\n    # LOAD RAPIDS SVR \n    print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n    clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n    print('Predicting test...')\n    final_test_predictions_all = []\n    final_test_predictions_all2 = []\n    final_test_predictions_all3 = []\n    for _ in range(5):\n        final_test_predictions = []\n        embed_test = np.array([]).reshape((0,1536))\n        stream = tqdm(test_loader)\n        for i, (images, target) in enumerate(stream, start = 1):\n            images = images.to(device, non_blocking = True).float()\n            target = target.to(device, non_blocking = True).float().view(-1, 1)\n            with torch.no_grad():\n                output = model(images)\n                emb = model.extract_features(images)\n            embed_test = np.concatenate([embed_test, emb.tolist()])\n            pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n            final_test_predictions.extend(pred)\n        final_test_predictions2 = clf.predict(normalize(embed_test))\n        final_test_predictions3 = get_pyro_emb_preds(LOAD_GPR_FROM_PATH+f'notebook_embeddings_f{i_fold}.npy', LOAD_GPR_FROM_PATH+f'notebook_y_f{i_fold}.npy', \n                                                     LOAD_GPR_FROM_PATH+f'notebook_gpr_f{i_fold}', normalize(embed_test))\n        final_test_predictions_all.append(final_test_predictions)\n        final_test_predictions_all2.append(final_test_predictions2)\n        final_test_predictions_all3.append(final_test_predictions3)\n    final_test_predictions_all = np.mean(final_test_predictions_all, axis=0)\n    final_test_predictions_all2 = np.mean(final_test_predictions_all2, axis=0)\n    final_test_predictions_all3 = np.mean(final_test_predictions_all3, axis=0)\n    super_final_predictions_2.append(final_test_predictions_all)\n    super_final_predictions2_2.append(final_test_predictions_all2)\n    super_final_predictions3_2.append(final_test_predictions_all3)\n    ##################\n    \n    del model, clf\n    del train_loader, train_dataset\n    del test_loader, test_dataset\n    del valid_loader, valid_dataset\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_final_predictions_3 = [] #classifier\nsuper_final_predictions2_3 = [] #SVR\nsuper_final_predictions3_3 = [] #GPR\n\nskf = StratifiedKFold(n_splits = Config.n_fold, shuffle=True, random_state=Config.random_seed)\nfor i_fold, (train_idx, valid_idx) in enumerate(skf.split(train_filepaths, target_bins)):\n    print(f'=== fold {i_fold}: training ===')\n    \"\"\"\n    separate train/valid data \n    \"\"\"\n    X_train_paths = train_filepaths[train_idx]\n    y_train = targets[train_idx]\n    X_valid_paths = train_filepaths[valid_idx]\n    y_valid = targets[valid_idx]\n    valid_ids = ids[valid_idx]\n    \"\"\"\n    prepare dataset\n    \"\"\"\n    train_dataset = PetDataset(\n      image_filepaths = X_train_paths,\n      targets = y_train / 100,\n      transform = get_train_transforms(0)\n    )\n    train_loader = DataLoader(\n      train_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    valid_dataset = PetDataset(\n      image_filepaths = X_valid_paths,\n      targets = y_valid / 100,\n      transform = get_tta_transforms(0)\n    )\n    valid_loader = DataLoader(\n      valid_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    test_dataset = PetDataset(\n      image_filepaths = test_filepaths,\n      targets = np.zeros(len(test_filepaths)),\n      transform = get_tta_transforms(0)\n    )\n    test_loader = DataLoader(\n      test_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    \"\"\"\n    instantiate model, cost function and optimizer\n    \"\"\"\n    model = PetNet()\n    model.load_state_dict(torch.load(Config3.model_dirs+Config3.model_path+f\"_fold{i_fold}.pth\"))\n    model = model.to(device)\n    model.eval()\n    criterion = nn.BCEWithLogitsLoss()\n    \n    LOAD_SVR_FROM_PATH = \"../input/paws-svr-gpr-new-4/\"\n    LOAD_GPR_FROM_PATH = \"../input/paws-svr-gpr-new-4/\"\n    name = f\"SVR_fold_{i_fold}.pkl\"\n    ##################\n    # LOAD RAPIDS SVR \n    print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n    clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n    print('Predicting test...')\n    final_test_predictions_all = []\n    final_test_predictions_all2 = []\n    final_test_predictions_all3 = []\n    for _ in range(5):\n        final_test_predictions = []\n        embed_test = np.array([]).reshape((0,1536))\n        stream = tqdm(test_loader)\n        for i, (images, target) in enumerate(stream, start = 1):\n            images = images.to(device, non_blocking = True).float()\n            target = target.to(device, non_blocking = True).float().view(-1, 1)\n            with torch.no_grad():\n                output = model(images)\n                emb = model.extract_features(images)\n            embed_test = np.concatenate([embed_test, emb.tolist()])\n            pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n            final_test_predictions.extend(pred)\n        final_test_predictions2 = clf.predict(normalize(embed_test))\n        final_test_predictions3 = get_pyro_emb_preds(LOAD_GPR_FROM_PATH+f'notebook_embeddings_f{i_fold}.npy', LOAD_GPR_FROM_PATH+f'notebook_y_f{i_fold}.npy', \n                                                     LOAD_GPR_FROM_PATH+f'notebook_gpr_f{i_fold}', normalize(embed_test))\n        final_test_predictions_all.append(final_test_predictions)\n        final_test_predictions_all2.append(final_test_predictions2)\n        final_test_predictions_all3.append(final_test_predictions3)\n    final_test_predictions_all = np.mean(final_test_predictions_all, axis=0)\n    final_test_predictions_all2 = np.mean(final_test_predictions_all2, axis=0)\n    final_test_predictions_all3 = np.mean(final_test_predictions_all3, axis=0)\n    super_final_predictions_3.append(final_test_predictions_all)\n    super_final_predictions2_3.append(final_test_predictions_all2)\n    super_final_predictions3_3.append(final_test_predictions_all3)\n    ##################\n    \n    del model, clf\n    del train_loader, train_dataset\n    del test_loader, test_dataset\n    del valid_loader, valid_dataset\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_final_preds = []\ndf = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ndf['Path'] = df['Id'].map(lambda x:'../input/petfinder-pawpularity-score/train/'+str(x)+'.jpg')\n\ndf_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\ndf_test['Path'] = df_test['Id'].map(lambda x:'../input/petfinder-pawpularity-score/test/'+str(x)+'.jpg')\n\ndf_test['norm_score'] = 0.01\n\nskf = StratifiedKFold(\n    n_splits=5, shuffle=True, random_state=555\n)\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(df)))))\ndf['norm_score'] = df['Pawpularity']/100\ndf['bins'] = pd.cut(df['norm_score'].values, bins=num_bins, labels=False)\n\nfor fold_, (train_idx, val_idx) in enumerate(skf.split(df[\"Id\"], df[\"bins\"])):\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n        \n    df_train = df.loc[train_idx].reset_index(drop=True)\n    df_val = df.loc[val_idx].reset_index(drop=True)\n    \n    df['is_valid'] = df.index.map(lambda x: x in val_idx)\n    dls = ImageDataLoaders.from_df(df,\n                               valid_col='is_valid',\n                               seed=555,\n                               fn_col='Path',\n                               label_col='norm_score',\n                               y_block=RegressionBlock,\n                               bs=8,\n                               shuffle=False,\n                               num_workers=8,\n                               item_tfms=Resize(224),\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()]))\n    model = PetModel()\n    learn = Learner(dls, model, loss_func=BCEWithLogitsLossFlat(), metrics=[AccumMetric(func=petfinder_rmse)])\n    learn.model.load_state_dict(torch.load(f\"../input/pawpularity-swin-l-fork/fold_{fold_}.pth\")['model']) # Loading trained model weights\n    learn.model.eval()\n    learn.model.cuda()\n\n    ##################\n    # TEST PREDICTIONS\n    print('Predicting test...')\n    \n    test_dl = dls.test_dl(df_test)\n    preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n    super_final_preds.append(preds)\n    ##################\n    \n    ##################\n    # COMPUTE RSME\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_l = {'max_depth': 2,\n 'objective': 'regression',\n 'metric': 'rmse',\n 'learning_rate': 0.05,\n 'seed': 999,\n 'feature_pre_filter': False,\n 'lambda_l1': 0.29742200421119536,\n 'lambda_l2': 5.720025931478957,\n 'num_leaves': 3,\n 'feature_fraction': 0.748,\n 'bagging_fraction': 0.8840460329244646,\n 'bagging_freq': 4,\n 'min_child_samples': 100}\n\nparams_r = {\"alpha\": 10, \"random_state\": 999}\n\nparams_cat = {\n        'loss_function' : 'RMSE',\n        'eval_metric' : 'RMSE',\n        'iterations' : 1000,\n        'grow_policy' : 'SymmetricTree',\n        'random_state' : 42,\n        'depth': 4,\n        'learning_rate': 0.01943558754716122,\n        'random_strength': 97,\n        'bagging_temperature': 2.9049665973532472,\n        'od_type': 'Iter',\n        'od_wait': 45}","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:46.299361Z","iopub.status.idle":"2022-01-04T21:24:46.299869Z","shell.execute_reply.started":"2022-01-04T21:24:46.29961Z","shell.execute_reply":"2022-01-04T21:24:46.299635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_labels(df):\n    df[['cat', 'dog', 'neither']] = 0\n    ohe = []\n    for idx, path in zip(itertools.count(), df['path'].values):\n        img = imageio.imread(path)\n        result = yolov5(img)\n        labels = result.pandas().xyxy[0]['name'].values\n        found_label = False\n        for label in labels:\n            if label == 'cat':\n                ohe.append([1,0,0])\n                found_label = True\n                break\n            elif label == 'dog':\n                ohe.append([0,1,0])\n                found_label = True\n                break\n        if not found_label:\n            ohe.append([0,0,1])\n            \n    df[['cat', 'dog', 'neither']] = ohe\n    return df\n\nyolov5 = torch.hub.load('ultralytics/yolov5', 'yolov5x6')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.read_csv(\"../input/pawpularity-for-post-process-v2/paws_for_post_process_v3.csv\")\ny_train = X_train.Pawpularity.values\nkfold_array = X_train.kfold.values\nX_train.drop([\"Id\", \"kfold\", \"Pawpularity\"], axis=1, inplace=True)\n\nX_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\nsuper_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\nsuper_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\nsuper_final_predictions3 = np.mean(np.column_stack(super_final_predictions3), axis=1)\nsuper_final_predictions_2 = np.mean(np.column_stack(super_final_predictions_2), axis=1)\nsuper_final_predictions2_2 = np.mean(np.column_stack(super_final_predictions2_2), axis=1)\nsuper_final_predictions3_2 = np.mean(np.column_stack(super_final_predictions3_2), axis=1)\nsuper_final_predictions_3 = np.mean(np.column_stack(super_final_predictions_3), axis=1)\nsuper_final_predictions2_3 = np.mean(np.column_stack(super_final_predictions2_3), axis=1)\nsuper_final_predictions3_3 = np.mean(np.column_stack(super_final_predictions3_3), axis=1)\nsuper_final_preds = np.mean(np.hstack(super_final_preds), axis=1) * 100\nX_test[\"preds1\"] = super_final_predictions\nX_test[\"preds2\"] = super_final_predictions2\nX_test[\"preds3\"] = super_final_predictions3\nX_test[\"preds1_2\"] = super_final_predictions_2\nX_test[\"preds2_2\"] = super_final_predictions2_2\nX_test[\"preds3_2\"] = super_final_predictions3_2\nX_test[\"preds1_3\"] = super_final_predictions_3\nX_test[\"preds2_3\"] = super_final_predictions2_3\nX_test[\"preds3_3\"] = super_final_predictions3_3\nX_test[\"preds\"] = super_final_preds\nX_test['path'] = X_test['Id'].map(lambda x:f'../input/petfinder-pawpularity-score/test/{str(x)}'+'.jpg')\nX_test = add_labels(X_test)\nX_test = X_test.drop([\"Id\", \"path\"], axis=1)\n\ndel yolov5\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:46.301679Z","iopub.status.idle":"2022-01-04T21:24:46.302338Z","shell.execute_reply.started":"2022-01-04T21:24:46.302078Z","shell.execute_reply":"2022-01-04T21:24:46.302103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds_l = []\nmodels_l = []\noof_train_l = np.zeros((len(X_train)))\ny_preds_cat = []\nmodels_cat = []\noof_train_cat = np.zeros((len(X_train)))\ny_preds_r = []\nmodels_r = []\noof_train_r = np.zeros((len(X_train)))\nfor fold_ in range(10):\n    train_index = np.nonzero(kfold_array != fold_)[0]\n    valid_index = np.nonzero(kfold_array == fold_)[0]\n    X_tr = X_train.iloc[train_index, :]\n    y_tr = y_train[train_index]\n    X_val = X_train.iloc[valid_index, :]\n    y_val = y_train[valid_index]\n    categorical_cols = [\"Subject Focus\", \"Eyes\", \"Face\", \"Near\", \"Action\", \"Accessory\", \"Group\", \"Collage\", \"Human\", \"Occlusion\", \"Info\", \"Blur\", \n                        \"cat\", \"dog\", \"neither\"]\n    lgb_train = lgb.Dataset(X_tr, y_tr, categorical_feature=categorical_cols)\n    lgb_eval = lgb.Dataset(\n        X_val, y_val, reference=lgb_train, categorical_feature=categorical_cols\n    )\n    model_l = lgb.train(\n        params_l,\n        lgb_train,\n        valid_sets=[lgb_train, lgb_eval],\n        verbose_eval=30,\n        num_boost_round=1000,\n        early_stopping_rounds=50,\n    )\n    oof_train_l[valid_index] = model_l.predict(X_val, num_iteration=model_l.best_iteration)\n    y_pred_l = model_l.predict(X_test, num_iteration=model_l.best_iteration)\n    y_preds_l.append(y_pred_l)\n    models_l.append(model_l)\n    model_cat = cb.CatBoostRegressor(**params_cat)\n    model_cat.fit(\n        X_tr,\n        y_tr,\n        eval_set=[(X_val, y_val)],\n        early_stopping_rounds=100,\n        cat_features=categorical_cols,\n        verbose=False,\n    )\n    oof_train_cat[valid_index] = model_cat.predict(X_val)\n    y_pred_cat = model_cat.predict(X_test)\n    y_preds_cat.append(y_pred_cat)\n    models_cat.append(model_cat)\n    model_r = Ridge(**params_r)\n    model_r.fit(X_tr, y_tr)\n    oof_train_r[valid_index] = model_r.predict(X_val)\n    y_pred_r = model_r.predict(X_test)\n    y_preds_r.append(y_pred_r)\n    models_r.append(model_r)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:46.303527Z","iopub.status.idle":"2022-01-04T21:24:46.304296Z","shell.execute_reply.started":"2022-01-04T21:24:46.304038Z","shell.execute_reply":"2022-01-04T21:24:46.304064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mean_squared_error(oof_train_l, y_train, squared=False))\ny_sub_l = sum(y_preds_l) / len(y_preds_l)\n\nprint(mean_squared_error(oof_train_cat, y_train, squared=False))\ny_sub_cat = sum(y_preds_cat) / len(y_preds_cat)\n\nprint(mean_squared_error(oof_train_r, y_train, squared=False))\ny_sub_r = sum(y_preds_r) / len(y_preds_r)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:46.305397Z","iopub.status.idle":"2022-01-04T21:24:46.306071Z","shell.execute_reply.started":"2022-01-04T21:24:46.305818Z","shell.execute_reply":"2022-01-04T21:24:46.305849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\ndf_test[\"Pawpularity\"] = y_sub_cat * 0.67 + y_sub_r * 0.33\ndf_test = df_test[[\"Id\", \"Pawpularity\"]]\ndf_test.to_csv(\"submission.csv\", index=False)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:24:46.307518Z","iopub.status.idle":"2022-01-04T21:24:46.308391Z","shell.execute_reply.started":"2022-01-04T21:24:46.308124Z","shell.execute_reply":"2022-01-04T21:24:46.30815Z"},"trusted":true},"execution_count":null,"outputs":[]}]}