{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\n\nimport albumentations\nimport pandas as pd\nimport numpy as np\n\nimport gc\nfrom glob import glob\nimport pickle\nimport json\nimport subprocess\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, RepeatedStratifiedKFold\n\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches, text, patheffects\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.optimize import minimize\nimport seaborn as sns\n\nimport cv2\nfrom tqdm import tqdm\n\nimport ast","metadata":{"id":"xymr0lBQVDcq","execution":{"iopub.status.busy":"2022-01-13T23:23:48.432421Z","iopub.execute_input":"2022-01-13T23:23:48.433002Z","iopub.status.idle":"2022-01-13T23:23:48.441104Z","shell.execute_reply.started":"2022-01-13T23:23:48.432967Z","shell.execute_reply":"2022-01-13T23:23:48.440185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --no-index --find-links ../input/timmset2 tez\n# !pip install --no-index --find-links ../input/timmset2 timm\n!pip install --no-index --find-links ../input/timmset2 pytorch-lightning","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-13T17:00:44.85002Z","iopub.execute_input":"2022-01-13T17:00:44.850403Z","iopub.status.idle":"2022-01-13T17:00:54.670391Z","shell.execute_reply.started":"2022-01-13T17:00:44.85037Z","shell.execute_reply":"2022-01-13T17:00:54.669322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append('../input/timmset2/pytorch-image-models')\nimport timm\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule","metadata":{"execution":{"iopub.status.busy":"2022-01-13T17:00:54.671923Z","iopub.execute_input":"2022-01-13T17:00:54.67222Z","iopub.status.idle":"2022-01-13T17:01:04.785308Z","shell.execute_reply.started":"2022-01-13T17:00:54.672159Z","shell.execute_reply":"2022-01-13T17:01:04.78423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --find-links ../input/yetanotherefficientdetpytorch webcolors","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:45:53.856395Z","iopub.execute_input":"2022-01-12T08:45:53.856671Z","iopub.status.idle":"2022-01-12T08:46:01.504204Z","shell.execute_reply.started":"2022-01-12T08:45:53.856635Z","shell.execute_reply":"2022-01-12T08:46:01.503339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir('/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:46:01.507571Z","iopub.execute_input":"2022-01-12T08:46:01.507811Z","iopub.status.idle":"2022-01-12T08:46:01.511817Z","shell.execute_reply.started":"2022-01-12T08:46:01.507783Z","shell.execute_reply":"2022-01-12T08:46:01.511106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append('../input/yetanotherefficientdetpytorch')\nsys.path.append('../input/yetanotherefficientdetpytorch/Yet-Another-EfficientDet-Pytorch')\n# os.chdir('./yetanotherefficientdetpytorch/Yet-Another-EfficientDet-Pytorch')\n# sys.path.append('.')\n# from backbone import EfficientDetBackbon\nfrom efficientdet.utils import BBoxTransform, ClipBoxes\nfrom utils.utils import preprocess, invert_affine, postprocess, STANDARD_COLORS, standard_to_bgr, get_index_label, plot_one_box\nfrom torch.backends import cudnn\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:46:01.514177Z","iopub.execute_input":"2022-01-12T08:46:01.514752Z","iopub.status.idle":"2022-01-12T08:46:01.648505Z","shell.execute_reply.started":"2022-01-12T08:46:01.514715Z","shell.execute_reply":"2022-01-12T08:46:01.647806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientdet.model import BiFPN, Regressor, Classifier, EfficientNet\nfrom efficientdet.utils import Anchors\n\n\nclass EfficientDetBackbone(nn.Module):\n    def __init__(self, num_classes=80, compound_coef=0, load_weights=False, **kwargs):\n        super(EfficientDetBackbone, self).__init__()\n        self.compound_coef = compound_coef\n\n        self.backbone_compound_coef = [0, 1, 2, 3, 4, 5, 6, 6, 7]\n        self.fpn_num_filters = [64, 88, 112, 160, 224, 288, 384, 384, 384]\n        self.fpn_cell_repeats = [3, 4, 5, 6, 7, 7, 8, 8, 8]\n        self.input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]\n        self.box_class_repeats = [3, 3, 3, 4, 4, 4, 5, 5, 5]\n        self.pyramid_levels = [5, 5, 5, 5, 5, 5, 5, 5, 6]\n        self.anchor_scale = [4., 4., 4., 4., 4., 4., 4., 5., 4.]\n        self.aspect_ratios = kwargs.get('ratios', [(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)])\n        self.num_scales = len(kwargs.get('scales', [2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]))\n        conv_channel_coef = {\n            # the channels of P3/P4/P5.\n            0: [40, 112, 320],\n            1: [40, 112, 320],\n            2: [48, 120, 352],\n            3: [48, 136, 384],\n            4: [56, 160, 448],\n            5: [64, 176, 512],\n            6: [72, 200, 576],\n            7: [72, 200, 576],\n            8: [80, 224, 640],\n        }\n\n        num_anchors = len(self.aspect_ratios) * self.num_scales\n\n        self.bifpn = nn.Sequential(\n            *[BiFPN(self.fpn_num_filters[self.compound_coef],\n                    conv_channel_coef[compound_coef],\n                    True if _ == 0 else False,\n                    attention=True if compound_coef < 6 else False,\n                    use_p8=compound_coef > 7)\n              for _ in range(self.fpn_cell_repeats[compound_coef])])\n\n        self.num_classes = num_classes\n        self.regressor = Regressor(in_channels=self.fpn_num_filters[self.compound_coef], num_anchors=num_anchors,\n                                   num_layers=self.box_class_repeats[self.compound_coef],\n                                   pyramid_levels=self.pyramid_levels[self.compound_coef])\n        self.classifier = Classifier(in_channels=self.fpn_num_filters[self.compound_coef], num_anchors=num_anchors,\n                                     num_classes=num_classes,\n                                     num_layers=self.box_class_repeats[self.compound_coef],\n                                     pyramid_levels=self.pyramid_levels[self.compound_coef])\n\n        self.anchors = Anchors(anchor_scale=self.anchor_scale[compound_coef],\n                               pyramid_levels=(torch.arange(self.pyramid_levels[self.compound_coef]) + 3).tolist(),\n                               **kwargs)\n\n        self.backbone_net = EfficientNet(self.backbone_compound_coef[compound_coef], load_weights)\n\n    def freeze_bn(self):\n        for m in self.modules():\n            if isinstance(m, nn.BatchNorm2d):\n                m.eval()\n\n    def forward(self, inputs):\n        max_size = inputs.shape[-1]\n\n        _, p3, p4, p5 = self.backbone_net(inputs)\n\n        features = (p3, p4, p5)\n        features = self.bifpn(features)\n\n        regression = self.regressor(features)\n        classification = self.classifier(features)\n        anchors = self.anchors(inputs, inputs.dtype)\n\n        return features, regression, classification, anchors\n\n    def init_backbone(self, path):\n        state_dict = torch.load(path)\n        try:\n            ret = self.load_state_dict(state_dict, strict=False)\n            print(ret)\n        except RuntimeError as e:\n            print('Ignoring ' + str(e) + '\"')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:46:01.650064Z","iopub.execute_input":"2022-01-12T08:46:01.650539Z","iopub.status.idle":"2022-01-12T08:46:01.735146Z","shell.execute_reply.started":"2022-01-12T08:46:01.650502Z","shell.execute_reply":"2022-01-12T08:46:01.734457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --find-links ../input/monaiset monai\nimport monai.transforms as mT","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:46:01.736263Z","iopub.execute_input":"2022-01-12T08:46:01.736524Z","iopub.status.idle":"2022-01-12T08:46:11.842429Z","shell.execute_reply.started":"2022-01-12T08:46:01.736489Z","shell.execute_reply":"2022-01-12T08:46:11.841532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global IMG_SIZE, BATCH_SIZE, MODEL_NAME\n# Constants\nIMG_SIZE = 224\nCHANNELS = 3\nQ = 30\nSEED = 2051\n\n# BATCH_SIZE = 8\nBATCH_SIZE = 32\n\nREPETE_NUMBER = 3\nLR = 0.000005\nWD = 0.0000005\nEPOCHS = 100\nEARRY_STOP = 3\n\n\nMODEL_NAME = \"model\"\n\nOPT_NAME = 'torch.optim.AdamW'\nOPT_PARAMS = {'lr': 1e-5}\n\nSCH_NAME = 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'\nSCH_PARAMS = {\n  'T_0': 20,\n  'eta_min': 1e-4,\n  }\nTRAINER = {\n  'gpus': 1,\n  'accumulate_grad_batches': 1,\n  'progress_bar_refresh_rate': 1,\n  'fast_dev_run': False,\n  'num_sanity_val_steps': 0,\n  'resume_from_checkpoint': None,\n  }\nTRN_LOADER = {\n  'batch_size': BATCH_SIZE,\n  'shuffle': True,\n  'num_workers': 4,\n  'pin_memory': False,\n  'drop_last': True,\n  }\nVAL_LOADER = {\n  'batch_size': BATCH_SIZE,\n  'shuffle': False,\n  'num_workers': 4,\n  'pin_memory': False,\n  'drop_last': False\n  }\nLOSS = 'nn.BCEWithLogitsLoss'\n\nGRADCAM_BATCH_SIZE = 16\n\n\nMD_NAME = 'nb019-v001'\n\nSVR_PATH = '.'\n# SVR_PATH = '../input/nb019-svr'\nSVR_RATIO = 0.4","metadata":{"id":"wKkCBCV7VDc6","execution":{"iopub.status.busy":"2022-01-13T17:01:04.882755Z","iopub.execute_input":"2022-01-13T17:01:04.883064Z","iopub.status.idle":"2022-01-13T17:01:04.891926Z","shell.execute_reply.started":"2022-01-13T17:01:04.883025Z","shell.execute_reply":"2022-01-13T17:01:04.891064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Val\nfrom tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n\ndef get_result(folder_names):\n    val_result = pd.DataFrame()\n\n    model_names = []\n    model_vals = []\n\n    for folder_name in folder_names:\n        paths = glob(f'{folder_name}/version_*')\n        for path in paths:\n            print(path)\n            e_path = glob(f'{path}/events*')[0]\n            event_acc = EventAccumulator(path, size_guidance={'scalars': 0})\n            event_acc.Reload()\n\n            scalars = {}\n            for tag in event_acc.Tags()['scalars']:\n                events = event_acc.Scalars(tag)\n                scalars[tag] = [event.value for event in events]\n\n            model_names.append(path)\n            model_vals.append(min(scalars['val_loss']))\n\n    val_result['name'] = model_names\n    val_result['val'] = model_vals\n    return val_result","metadata":{"id":"V5HunQHhPt8A","execution":{"iopub.status.busy":"2022-01-13T23:23:54.426622Z","iopub.execute_input":"2022-01-13T23:23:54.426908Z","iopub.status.idle":"2022-01-13T23:23:54.435312Z","shell.execute_reply.started":"2022-01-13T23:23:54.426875Z","shell.execute_reply":"2022-01-13T23:23:54.434622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# folder_names = [\n#     '../input/nb021nc-v001',\n#     '../input/nb021nc-v002',\n#     '../input/nb021nc-v004',\n    \n# ]\n# result_normal = get_result(folder_names)\n# # result_normal = result_normal.sort_values('val')\n# # result_normal = result_normal[:6]\n\n# # Bad\n# result_normal = result_normal.drop(2)\n# result_normal = result_normal.drop(3)\n# result_normal = result_normal.drop(10)\n# result_normal = result_normal.drop(13)\n# result_normal = result_normal.drop(14)\n\n# # Little Bad\n# result_normal = result_normal.drop(1)\n# result_normal = result_normal.drop(7)\n# result_normal = result_normal.drop(12)\n\n# result_normal","metadata":{"execution":{"iopub.status.busy":"2022-01-13T23:23:54.629783Z","iopub.execute_input":"2022-01-13T23:23:54.63067Z","iopub.status.idle":"2022-01-13T23:23:54.634752Z","shell.execute_reply.started":"2022-01-13T23:23:54.630635Z","shell.execute_reply":"2022-01-13T23:23:54.634187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_names = [\n#     '../input/nb021nc-v001',\n#     '../input/nb021nc-v002',\n    '../input/nb021nc-v004',\n    '../input/nb021nc-v006',\n    \n]\nresult_normal = get_result(folder_names)\n# result_normal = result_normal.sort_values('val')\n# result_normal = result_normal[:6]\n\nresult_normal","metadata":{"execution":{"iopub.status.busy":"2022-01-13T23:24:21.40855Z","iopub.execute_input":"2022-01-13T23:24:21.408849Z","iopub.status.idle":"2022-01-13T23:24:21.473111Z","shell.execute_reply.started":"2022-01-13T23:24:21.408819Z","shell.execute_reply":"2022-01-13T23:24:21.47258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result_normal = pd.DataFrame()\n\n# model_names = []\n# model_vals = []\n\n# paths = [\n#     '../input/nb019-v005/version_3',\n#     '../input/nb019-v016/version_3',\n#     '../input/nb021-v013/version_0',\n#     '../input/nb021-v013/version_1',\n#     '../input/nb021-v013/version_4',\n#     '../input/nb021-v013/version_5',\n# ]\n# for path in paths:\n#     print(path)\n#     e_path = glob(f'{path}/events*')[0]\n#     event_acc = EventAccumulator(path, size_guidance={'scalars': 0})\n#     event_acc.Reload()\n\n#     scalars = {}\n#     for tag in event_acc.Tags()['scalars']:\n#         events = event_acc.Scalars(tag)\n#         scalars[tag] = [event.value for event in events]\n\n#     model_names.append(path)\n#     model_vals.append(min(scalars['val_loss']))\n\n# result_normal['name'] = model_names\n# result_normal['val'] = model_vals\n# result_normal\n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T17:19:22.229409Z","iopub.execute_input":"2022-01-13T17:19:22.22969Z","iopub.status.idle":"2022-01-13T17:19:22.233899Z","shell.execute_reply.started":"2022-01-13T17:19:22.229651Z","shell.execute_reply":"2022-01-13T17:19:22.233093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result_normal['nb'] = result_normal['name'].str.split('/', expand=True)[2]\n# result_normal.groupby('nb')['val'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T23:24:04.231524Z","iopub.execute_input":"2022-01-13T23:24:04.231999Z","iopub.status.idle":"2022-01-13T23:24:04.266116Z","shell.execute_reply.started":"2022-01-13T23:24:04.231968Z","shell.execute_reply":"2022-01-13T23:24:04.265286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_names = [\n#     '../input/nb021nc-v005',\n    '../input/nb021nc-v007',\n]\nresult_xcit = get_result(folder_names)\nresult_xcit = result_xcit.sort_values('val')\n# result_xcit = result_xcit[:4]\n# result_xcit = result_xcit.drop(0)\nresult_xcit","metadata":{"execution":{"iopub.status.busy":"2022-01-13T23:28:51.055005Z","iopub.execute_input":"2022-01-13T23:28:51.055976Z","iopub.status.idle":"2022-01-13T23:28:51.094816Z","shell.execute_reply.started":"2022-01-13T23:28:51.055931Z","shell.execute_reply":"2022-01-13T23:28:51.094157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_names = [  \n    '../input/nb021nc-v003',\n]\nresult_nfnet = get_result(folder_names)\n# result_nfnet = result_nfnet.sort_values('val')\n# result_nfnet = result_nfnet[:3]\n# result_nfnet = result_nfnet.drop(0)\nresult_nfnet","metadata":{"execution":{"iopub.status.busy":"2022-01-13T17:20:04.557665Z","iopub.execute_input":"2022-01-13T17:20:04.558362Z","iopub.status.idle":"2022-01-13T17:20:04.587956Z","shell.execute_reply.started":"2022-01-13T17:20:04.55832Z","shell.execute_reply":"2022-01-13T17:20:04.587278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('normal')\nprint(result_normal['val'].describe())\nprint('\\nxcit')\nprint(result_xcit['val'].describe())\nprint('\\nnfnet')\nprint(result_nfnet['val'].describe())","metadata":{"execution":{"iopub.status.busy":"2022-01-13T17:22:51.980914Z","iopub.execute_input":"2022-01-13T17:22:51.981195Z","iopub.status.idle":"2022-01-13T17:22:51.999492Z","shell.execute_reply.started":"2022-01-13T17:22:51.981152Z","shell.execute_reply":"2022-01-13T17:22:51.99865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\nimport seaborn as sns\n\npaths = result_normal['name'].tolist()\npaths.extend(result_xcit['name'].tolist())\npaths.extend(result_nfnet['name'].tolist())\n\nfor path in paths:\n    print(path)\n    e_path = glob(f'{path}/events*')[0]\n    event_acc = EventAccumulator(path + '/', size_guidance={'scalars': 0})\n    event_acc.Reload()\n\n    scalars = {}\n    for tag in event_acc.Tags()['scalars']:\n        events = event_acc.Scalars(tag)\n        scalars[tag] = [event.value for event in events]\n    sns.set()\n\n    plt.figure(figsize=(8, 3))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(len(scalars['lr-AdamW'])), scalars['lr-AdamW'])\n    plt.xlabel('epoch')\n    plt.ylabel('lr')\n    plt.title('adamw lr')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(range(len(scalars['train_loss'])), scalars['train_loss'], label='train_loss')\n    plt.plot(range(len(scalars['val_loss'])), scalars['val_loss'], label='val_loss')\n    plt.legend()\n    plt.ylabel('rmse')\n    plt.xlabel('epoch')\n    plt.title('train/val rmse')\n    plt.show()\n    print('best_val_loss', min(scalars['val_loss']))\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T22:56:27.234133Z","iopub.execute_input":"2022-01-12T22:56:27.235221Z","iopub.status.idle":"2022-01-12T22:56:33.08142Z","shell.execute_reply.started":"2022-01-12T22:56:27.235173Z","shell.execute_reply":"2022-01-12T22:56:33.080454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transform_value(train, field, width, height):\n    classes = np.array(field['classes'])\n    animal_indexes = np.where((classes == 16) | (classes == 17))[0]\n    minimum_crop = min(width, height)\n    if len(animal_indexes) == 0:\n        return {'cx': width / 2, 'cy': height / 2, 'ms': minimum_crop, 'msx': minimum_crop, 'msy': minimum_crop}\n\n    box = np.array(field['boxes']).astype(np.int)\n    box = box[animal_indexes]\n\n    width_x = (box[:, 2].max() - box[:, 0].min())\n    width_y = (box[:, 3].max() - box[:, 1].min())\n \n    center_x = (box[:, 0].min()) + (width_x / 2)\n    center_y = (box[:, 1].min()) + (width_y / 2)\n\n    min_size = max(width_x, width_y)\n    min_size = np.clip(min_size, 100, minimum_crop)\n    min_size_x = np.clip(width_x, 100, width)\n    min_size_y = np.clip(width_y, 100, height)\n\n    return {'cx': center_x, 'cy': center_y, 'ms': min_size, 'msx': min_size_x, 'msy': min_size_y}\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:13:14.527983Z","iopub.execute_input":"2022-01-12T19:13:14.528777Z","iopub.status.idle":"2022-01-12T19:13:14.538953Z","shell.execute_reply.started":"2022-01-12T19:13:14.528724Z","shell.execute_reply":"2022-01-12T19:13:14.537744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def str_to_list(colum_str):\n    string = colum_str.split(\"array(\")[1]\n    string = string.split(']')[0:-1]\n    string = ']'.join(string)\n    string += ']'\n    return ast.literal_eval(string)\n    \ndef fields_to_dict(field_text):\n    field = field_text\n    field = field[1:-1]\n\n    field = field.split('),')\n\n    boxes = field[1]\n    score = field[0]\n    classes = field[2]\n\n    boxes = str_to_list(boxes)\n    score = str_to_list(score)\n    classes = str_to_list(classes)\n    return {'boxes': boxes, 'score': score, 'classes': classes}\n\ndef set_boxes_info(df):\n    df['cx'] = 0\n    df['cy'] = 0\n    df['ms'] = 0\n    df['msx'] = 0\n    df['msy'] = 0\n    for index in df.index:\n        min_ms = min([df.loc[index, 'width'], df.loc[index, 'height']])\n        result = get_transform_value(False,df.loc[index, 'fields'], df.loc[index, 'width'], df.loc[index, 'height'])\n        cx = result['cx']\n        cy = result['cy']\n        ms = result['ms']\n        msx = result['msx']\n        msy = result['msy']\n\n        df.loc[index, ['cx', 'cy', 'ms', 'msx', 'msy']] = [cx, cy, ms, msx, msy]","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:13:14.731181Z","iopub.execute_input":"2022-01-12T19:13:14.732093Z","iopub.status.idle":"2022-01-12T19:13:14.742055Z","shell.execute_reply.started":"2022-01-12T19:13:14.732052Z","shell.execute_reply":"2022-01-12T19:13:14.741026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CPU or GPU\n# for colab\nDATA_DIR = '../input/petfinder-pawpularity-score'\n\n# # Use only GPU\nIMG_PATH = DATA_DIR","metadata":{"id":"HB-n_bYvdI3i","execution":{"iopub.status.busy":"2022-01-12T19:13:15.978833Z","iopub.execute_input":"2022-01-12T19:13:15.980219Z","iopub.status.idle":"2022-01-12T19:13:15.98521Z","shell.execute_reply.started":"2022-01-12T19:13:15.980141Z","shell.execute_reply":"2022-01-12T19:13:15.984183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=pd.read_csv(f'{DATA_DIR}/test.csv')\ntest_df['image_path'] = f'{IMG_PATH}/test/' + test_df['Id'] + '.jpg'","metadata":{"id":"pN5P8n6rVDdJ","execution":{"iopub.status.busy":"2022-01-12T08:49:42.333028Z","iopub.execute_input":"2022-01-12T08:49:42.333636Z","iopub.status.idle":"2022-01-12T08:49:42.391131Z","shell.execute_reply.started":"2022-01-12T08:49:42.333603Z","shell.execute_reply":"2022-01-12T08:49:42.390432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"dense_features = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur',\n    'Persons', 'Cats', 'Dogs', 'Animals',\n]","metadata":{"id":"ShH4jFTk19vc","execution":{"iopub.status.busy":"2022-01-12T08:47:40.444508Z","iopub.execute_input":"2022-01-12T08:47:40.444807Z","iopub.status.idle":"2022-01-12T08:47:40.449118Z","shell.execute_reply.started":"2022-01-12T08:47:40.444762Z","shell.execute_reply":"2022-01-12T08:47:40.448182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\ndef get_default_transforms():\n    transform = {\n        \"train\": T.Compose([\n          # T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n          T.RandomHorizontalFlip(),\n          T.RandomVerticalFlip(),\n          T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n\n          T.ConvertImageDtype(torch.float),\n          T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n        ]),\n        \"val\": T.Compose([\n          T.RandomHorizontalFlip(),\n\n          T.ConvertImageDtype(torch.float),\n          T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n        ]),\n    }\n    return transform","metadata":{"id":"bqTE3rrQL5NP","execution":{"iopub.status.busy":"2022-01-12T08:47:40.450905Z","iopub.execute_input":"2022-01-12T08:47:40.451435Z","iopub.status.idle":"2022-01-12T08:47:40.460429Z","shell.execute_reply.started":"2022-01-12T08:47:40.451397Z","shell.execute_reply":"2022-01-12T08:47:40.459611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"15iduP6cisv3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetfinderDataset(Dataset):\n    def __init__(self, df, train=True):\n        self._X = df[\"Id\"].values\n        self._y = None\n        self._train = train\n        self._image_path = df[\"image_path\"].values\n        # self._dense_features = df[dense_features].values\n\n        self._fields = df['fields'].values\n        self._cats = df['Cats'].values\n        self._dogs = df['Dogs'].values\n        self._animalss = df['Animals'].values\n\n        self._width = df['width'].values\n        self._height = df['height'].values\n\n        self._cx = df['cx'].values\n        self._cy = df['cy'].values\n        \n        self._ms = df['ms'].values\n        self._msx = df['msx'].values\n        self._msy = df['msy'].values\n\n        if \"Pawpularity\" in df.keys():\n            self._y = df[\"Pawpularity\"].values\n\n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        image_path = self._image_path[idx]\n        image = read_image(image_path)\n\n        # Procese of get box\n        field = self._fields[idx]\n        width = self._width[idx]\n        height = self._height[idx]\n\n        image_size = min(width,height)\n\n        cx = self._cx[idx]\n        cy = self._cy[idx]\n        ms = self._ms[idx]\n        # Set msx and msy as big as possible, then crop\n        msx = self._msx[idx]\n        msy = self._msy[idx]\n     \n        if self._train:\n            transfomer = mT.Compose([          \n                T.RandomRotation(degrees=(-45, 45)),\n                T.RandomPerspective(distortion_scale=0.3, p=0.4),\n\n                mT.SpatialCrop(roi_center=[cy, cx], roi_size=[msy, msx]),\n                mT.Resize([IMG_SIZE, IMG_SIZE]),\n            ])\n        else:            \n            # TTA\n            if self._animalss[idx] > 1:\n                if torch.rand(1)[0] > 0.7:\n                    # Add columns by each crop\n                    classes = np.array(field['classes'])\n                    animal_indexes = np.where((classes == 16) | (classes == 17))[0]\n                    \n                    box = np.array(field['boxes']).astype(np.int)\n                    box = box[animal_indexes]\n                    animal_i = torch.randint(0, len(box), (1,))[0]\n                    \n                    msx = (box[animal_i, 2] - box[animal_i, 0])\n                    msy = (box[animal_i, 3] - box[animal_i, 1])\n\n                    cx = (box[animal_i, 0]) + (msx / 2)\n                    cy = (box[animal_i, 1]) + (msy / 2)\n                    \n                    ms = max(msx, msy)\n            \n            swift_rand = torch.rand(3)\n            \n            ms += (ms * (swift_rand[0] - 0.3) * 0.1)\n            msx += (msx * (swift_rand[0] - 0.3) * 0.1)\n            msy += (msy * (swift_rand[0] - 0.3) * 0.1)\n            \n            cx += (msx * (swift_rand[1] - 0.5) * 0.1)\n            cy += (msy * (swift_rand[2] - 0.5) * 0.1)\n            cx = np.clip(cx, 0, width)\n            cy = np.clip(cy, 0, height)\n            \n            ms = np.clip(ms, 100, image_size)\n            msx = ms\n            msy = ms  \n\n            transfomer = mT.Compose([\n                mT.SpatialCrop(roi_center=[cy, cx], roi_size=[msy, msx]),\n                mT.Resize([IMG_SIZE, IMG_SIZE]),\n            ])\n          \n        try:\n            image = transfomer(image)\n        except:\n            print(\"error\")\n            transfomer = mT.Compose([\n                mT.RandSpatialCrop(ms*0.99),\n                mT.Resize([IMG_SIZE, IMG_SIZE]),\n            ])\n            image = transfomer(image)\n\n        if self._y is not None:\n            label = self._y[idx]\n            return {\"image\": image, \"label\": label}\n        return {\"image\": image}\n\nclass PetfinderDataModule(LightningDataModule):\n    def __init__(\n        self,\n        train_df,\n        val_df,\n    ):\n        super().__init__()\n        self._train_df = train_df\n        self._val_df = val_df\n\n    def __create_dataset(self, train=True):\n        return (\n          PetfinderDataset(self._train_df, train)  if train else PetfinderDataset(self._val_df, train)\n        )\n\n    def train_dataloader(self):\n        dataset = self.__create_dataset(True)\n        return DataLoader(dataset, **TRN_LOADER)\n\n    def val_dataloader(self):\n        dataset = self.__create_dataset(False)\n        return DataLoader(dataset, **VAL_LOADER)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:47:40.463296Z","iopub.execute_input":"2022-01-12T08:47:40.463696Z","iopub.status.idle":"2022-01-12T08:47:40.49318Z","shell.execute_reply.started":"2022-01-12T08:47:40.463662Z","shell.execute_reply":"2022-01-12T08:47:40.492405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularModel(pl.LightningModule):\n    def __init__(self, model_name, model_type):\n        super().__init__()\n        self.__build_model(model_name, model_type)\n        self._criterion = eval(LOSS)()\n        self.transform = get_default_transforms()\n\n    def __build_model(self, model_name, model_type):\n        if model_type=='nb019':\n            self.base = timm.create_model(\n                model_name, pretrained=False, num_classes=0, in_chans=3\n            )\n            num_features = self.base.num_features\n            self.fc = nn.Sequential(\n                nn.Dropout(0.1),\n                nn.LazyLinear(1)\n            )\n        elif model_type=='onlyresize':\n            self.base = timm.create_model(\n                model_name, pretrained=False, num_classes=0, in_chans=3\n            )\n            num_features = self.base.num_features\n            self.fc = nn.Sequential(\n                nn.Dropout(0.1),\n                nn.LazyLinear(1)\n            )\n            \n        elif model_type=='ensemble':\n            self.base = timm.create_model(\n                model_name, pretrained=False, num_classes=0, in_chans=3\n            )\n            num_features = self.base.num_features\n            self.fc = nn.Sequential(\n                nn.Dropout(0.1),\n                nn.Linear(num_features, 128),\n                nn.Softmax(128, 10),\n            )\n\n    def forward(self, image):\n        f = self.base(image)\n        out = self.fc(f)\n        return out\n    def training_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'train')\n        return {'loss': loss, 'pred': pred, 'labels': labels}\n        \n    def validation_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'val')\n        return {'pred': pred, 'labels': labels}\n    \n    def test_step(self, batch, batch_idx):\n        # For transform, set mode val\n        loss, pred, labels = self.__share_step(batch, 'val')\n        return {'pred': pred, 'labels': labels}\n    \n    def __share_step(self, batch, mode):\n        images, labels = batch['image'], batch['label']\n        labels = labels / 100.0\n        images = self.transform[mode](images)\n        \n        if torch.rand(1)[0] < 0.5 and mode == 'train':\n            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n            logits = self.forward(mix_images).squeeze(1)\n            loss = self._criterion(logits, target_a) * lam + \\\n                (1 - lam) * self._criterion(logits, target_b)\n        else:\n            logits = self.forward(images).squeeze(1)\n            loss = self._criterion(logits, labels)\n        \n        pred = logits.sigmoid().detach().cpu() * 100.\n        labels = labels.detach().cpu() * 100.\n        return loss, pred, labels\n        \n    def training_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'train')\n\n    def validation_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'val')\n        \n    def test_epoch_end(self, outputs):\n        result = self.__share_epoch_end(outputs, 'test')\n        \n    def __share_epoch_end(self, outputs, mode):\n        preds = []\n        labels = []\n        for out in outputs:\n            pred, label = out['pred'], out['labels']\n            preds.append(pred)\n            labels.append(label)\n        preds = torch.cat(preds)\n        labels = torch.cat(labels)\n        metrics = torch.sqrt(((labels - preds) ** 2).mean())\n        self.log(f'{mode}_loss', metrics)\n        \n    def predict_step(self, batch, batch_idx):\n        # For transform, set mode val\n        images = self.transform['val'](batch['image'])\n        logits = self.forward(images)  .squeeze(1)   \n        pred = logits.sigmoid().detach().cpu() * 100.\n        return {'pred': pred}\n    def on_predict_epoch_end(self, outputs):\n        preds = []\n        for out in outputs[0]:\n            preds.append(out['pred'])\n        result = torch.cat(preds)\n\n    def configure_optimizers(self):\n        optimizer = eval(OPT_NAME)(\n          self.parameters(), **OPT_PARAMS\n        )\n        scheduler = eval(SCH_NAME)(\n          optimizer,\n          **SCH_PARAMS\n        )\n        return [optimizer], [scheduler]\n\n    ","metadata":{"id":"x3hH31dYcwJJ","execution":{"iopub.status.busy":"2022-01-12T08:47:40.4948Z","iopub.execute_input":"2022-01-12T08:47:40.495337Z","iopub.status.idle":"2022-01-12T08:47:40.522252Z","shell.execute_reply.started":"2022-01-12T08:47:40.4953Z","shell.execute_reply":"2022-01-12T08:47:40.521507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(\n  max_epochs= EPOCHS,\n  callbacks=[],\n  **TRAINER\n)","metadata":{"id":"GtiwM7z3FrEl","outputId":"6ec173a8-f7b4-4d49-f5aa-886de833cb70","execution":{"iopub.status.busy":"2022-01-12T08:47:40.787113Z","iopub.execute_input":"2022-01-12T08:47:40.787865Z","iopub.status.idle":"2022-01-12T08:47:40.803328Z","shell.execute_reply.started":"2022-01-12T08:47:40.787824Z","shell.execute_reply":"2022-01-12T08:47:40.802518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_paths(model_name, model_type, paths, df):\n    versions_paths = []\n    versions_preds = []\n    versions_clf_preds = []\n    \n    datamodule = PetfinderDataModule(df, df)\n    if model_type ==  'onlyresize':\n        datamodule = OnlyresizeDataModule(df, df)\n    val_dl = datamodule.val_dataloader()\n    \n    features = df[dense_features].values\n    \n    model = PawpularModel(model_name, model_type)\n    model = model.cuda().eval()\n    \n    for path in paths:\n        model.load_state_dict(torch.load(f'{path}/checkpoints/best_loss.ckpt')['state_dict'])\n        model = model.cuda().eval()\n        \n        s_preds = trainer.predict(model, val_dl)\n        preds = np.array([])\n        for row in s_preds:\n            preds = np.concatenate((preds, row['pred']), axis=0)\n        train_features = np.concatenate((preds[:, np.newaxis], features), axis=1)\n\n        # For no svr\n        clf_preds = [0]\n    \n        versions_paths.append(path)\n        versions_preds.append(preds)\n        versions_clf_preds.append(clf_preds)\n    return {'paths': versions_paths, 'preds': np.float32(versions_preds), 'clf_preds': np.float32(versions_clf_preds)}","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:47:40.806369Z","iopub.execute_input":"2022-01-12T08:47:40.806825Z","iopub.status.idle":"2022-01-12T08:47:40.816245Z","shell.execute_reply.started":"2022-01-12T08:47:40.806787Z","shell.execute_reply":"2022-01-12T08:47:40.815526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normal_predict(df):\n    model_name = 'swin_large_patch4_window7_224'\n    model_type = 'nb019'\n    \n    paths = result_normal['name']\n\n    IMG_SIZE = 224\n    BATCH_SIZE = 32\n    \n    return predict_paths(model_name, model_type, paths, df)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:13:30.694629Z","iopub.execute_input":"2022-01-12T08:13:30.695363Z","iopub.status.idle":"2022-01-12T08:13:30.705278Z","shell.execute_reply.started":"2022-01-12T08:13:30.695322Z","shell.execute_reply":"2022-01-12T08:13:30.704533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def xcit_predict(df):\n    model_name = 'xcit_large_24_p8_224_dist'\n    model_type = 'nb019'\n    \n    paths = result_xcit['name']\n    \n    IMG_SIZE = 384\n    BATCH_SIZE = 16\n    return predict_paths(model_name, model_type, paths, df)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:13:30.706728Z","iopub.execute_input":"2022-01-12T08:13:30.707212Z","iopub.status.idle":"2022-01-12T08:13:30.714282Z","shell.execute_reply.started":"2022-01-12T08:13:30.707175Z","shell.execute_reply":"2022-01-12T08:13:30.713563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nfnet_predict(df):\n    model_name = 'dm_nfnet_f1'\n    model_type = 'nb019'\n    \n    paths = result_nfnet['name']\n    \n    IMG_SIZE = 320\n    BATCH_SIZE = 16\n    return predict_paths(model_name, model_type, paths, df)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:13:30.715724Z","iopub.execute_input":"2022-01-12T08:13:30.716236Z","iopub.status.idle":"2022-01-12T08:13:30.723173Z","shell.execute_reply.started":"2022-01-12T08:13:30.716198Z","shell.execute_reply":"2022-01-12T08:13:30.722435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nfnet2_predict(df):\n    model_name = 'dm_nfnet_f2'\n    model_type = 'nb019'\n    \n    paths = [\"../input/nb021nc-v008\"]\n    \n    IMG_SIZE = 352\n    BATCH_SIZE = 16\n    return predict_paths(model_name, model_type, paths, df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multiple_ratio(preds):\n    y_pred = np.zeros(len(preds[0]))\n    best_ratios = np.array([1.0/len(preds) for i in range(len(preds))])\n\n    for i, ratio in enumerate(best_ratios):\n        y_pred += (preds[i] * ratio)\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:13:30.72448Z","iopub.execute_input":"2022-01-12T08:13:30.725216Z","iopub.status.idle":"2022-01-12T08:13:30.732381Z","shell.execute_reply.started":"2022-01-12T08:13:30.725177Z","shell.execute_reply":"2022-01-12T08:13:30.731618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compound_coef = 8\nforce_input_size = None  # set None to use default size\n# img_path = train_df.loc[14, 'image_path']\n\n# replace this part with your project's anchor config\nanchor_ratios = [(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)]\nanchor_scales = [2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]\n\nthreshold = 0.2\niou_threshold = 0.2\n\nuse_cuda = True\nuse_float16 = False\ncudnn.fastest = True\ncudnn.benchmark = True\n\nobj_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n            'fire hydrant', '', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n            'cow', 'elephant', 'bear', 'zebra', 'giraffe', '', 'backpack', 'umbrella', '', '', 'handbag', 'tie',\n            'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n            'skateboard', 'surfboard', 'tennis racket', 'bottle', '', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n            'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',\n            'cake', 'chair', 'couch', 'potted plant', 'bed', '', 'dining table', '', '', 'toilet', '', 'tv',\n            'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n            'refrigerator', '', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n            'toothbrush']\n\n\ncolor_list = standard_to_bgr(STANDARD_COLORS)\n# tf bilinear interpolation is different from any other's, just make do\ninput_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]\ninput_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n\ndetect_model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n                             ratios=anchor_ratios, scales=anchor_scales)\ndetect_model.load_state_dict(torch.load(f'../input/yetanotherefficientdetpytorch/weights/efficientdet-d{compound_coef}.pth', map_location='cuda'))\ndetect_model.requires_grad_(False)\ndetect_model.eval()\n\nif use_cuda:\n    detect_model = detect_model.cuda()\nif use_float16:\n    detect_model = detect_model.half()\n\nregressBoxes = BBoxTransform()\nclipBoxes = ClipBoxes()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:47:40.819516Z","iopub.execute_input":"2022-01-12T08:47:40.81977Z","iopub.status.idle":"2022-01-12T08:47:42.164254Z","shell.execute_reply.started":"2022-01-12T08:47:40.819745Z","shell.execute_reply":"2022-01-12T08:47:42.163565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_hwf(df):\n    # Object detec to train_confirm\n    df['width'] = 0\n    df['height'] = 0\n    df['fields'] = ''\n    \n    df['Persons'] = 0\n    df['Cats'] = 0\n    df['Dogs'] = 0\n    df['Animals'] = 0\n\n    for index in tqdm(df.index):\n        img_path = df.loc[index, 'image_path']\n        ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)\n        df.loc[index, 'width'] = framed_metas[0][2]\n        df.loc[index, 'height'] = framed_metas[0][3]\n    \n\n        if use_cuda:\n            x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n        else:\n            x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n\n        x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n\n        features, regression, classification, anchors = detect_model(x)\n\n        out = postprocess(x,\n            anchors, regression, classification,\n            regressBoxes, clipBoxes,\n            threshold, iou_threshold)\n        out = invert_affine(framed_metas, out)[0]\n        out['boxes'] = out.pop('rois')\n        out['classes'] = out.pop('class_ids')\n        out['scores'] = out['scores']\n\n        df.loc[index, 'fields'] = str(out)\n\n        df.loc[index, 'Persons'] = out['classes'].tolist().count(0)\n        df.loc[index, 'Cats'] = out['classes'].tolist().count(16)\n        df.loc[index, 'Dogs'] = out['classes'].tolist().count(17)\n        df.loc[index, 'Animals'] = df.loc[index, 'Cats'] + df.loc[index, 'Dogs']","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:59:48.69864Z","iopub.execute_input":"2022-01-12T08:59:48.698965Z","iopub.status.idle":"2022-01-12T08:59:48.719518Z","shell.execute_reply.started":"2022-01-12T08:59:48.698932Z","shell.execute_reply":"2022-01-12T08:59:48.718364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV Using Confirm","metadata":{}},{"cell_type":"code","source":"# train_df=pd.read_csv(f'../input/petfinder2-detected-info/train.csv')\n# train_df['image_path'] = f'{IMG_PATH}/train/' + train_df['Id'] + '.jpg'\n# train_df['fields'] = train_df['fields'].apply(fields_to_dict)\n# set_boxes_info(train_df)\n# train_df['Animals'] = train_df['Cats'] + train_df['Dogs']\n\n# confirm_index = []\n# with open('../input/val-index/val_index.pkl', 'rb') as web:\n#     confirm_index = pickle.load(web)\n# train_confirm = train_df.iloc[confirm_index]\n# train_df = train_df.drop(confirm_index)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:13:20.162822Z","iopub.execute_input":"2022-01-12T19:13:20.163671Z","iopub.status.idle":"2022-01-12T19:13:40.485904Z","shell.execute_reply.started":"2022-01-12T19:13:20.163616Z","shell.execute_reply":"2022-01-12T19:13:40.485077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_confirm['Pawpularity'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:13:45.008949Z","iopub.execute_input":"2022-01-12T19:13:45.009268Z","iopub.status.idle":"2022-01-12T19:13:45.022374Z","shell.execute_reply.started":"2022-01-12T19:13:45.009238Z","shell.execute_reply":"2022-01-12T19:13:45.021427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# normal_result = normal_predict(train_confirm)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T07:31:47.395713Z","iopub.execute_input":"2022-01-07T07:31:47.395985Z","iopub.status.idle":"2022-01-07T07:45:30.064078Z","shell.execute_reply.started":"2022-01-07T07:31:47.395953Z","shell.execute_reply":"2022-01-07T07:45:30.06315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(len(normal_result['preds'])):\n#     apply_index = [False for i in range(len(normal_result['preds']))]\n#     apply_index[i] = True\n\n#     preds = multiple_ratio(normal_result['preds'][apply_index])\n#     # preds = multiple_ratio(normal_preds_array)\n#     train_confirm['preds'] = preds\n#     print(normal_result['paths'][i])\n#     print(preds.mean(), preds.std(), np.sqrt(mean_squared_error(train_confirm['Pawpularity'], preds)))\n\n#     # Cats CV\n#     specific_data = train_confirm[(train_confirm['Cats']) > 0]\n#     print(len(specific_data))\n#     print(np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n\n#     # Dogs CV\n#     specific_data = train_confirm[(train_confirm['Dogs']) > 0]\n#     print(len(specific_data))\n#     print(np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))","metadata":{"execution":{"iopub.status.busy":"2022-01-07T07:45:30.094667Z","iopub.execute_input":"2022-01-07T07:45:30.09541Z","iopub.status.idle":"2022-01-07T07:45:30.197522Z","shell.execute_reply.started":"2022-01-07T07:45:30.095332Z","shell.execute_reply":"2022-01-07T07:45:30.19672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds = multiple_ratio(normal_result['preds'])\n# train_confirm['preds'] = preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(preds.mean(), preds.std(), np.sqrt(mean_squared_error(train_confirm['Pawpularity'], preds)))\n# # Cats CV\n# specific_data = train_confirm[(train_confirm['Cats']) > 0]\n# print(\"Cats\", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n# # Dogs CV\n# specific_data = train_confirm[(train_confirm['Dogs']) > 0]\n# print(\"Dogs\", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n\n# print(\"Animals\")\n# for i in range(8):\n#     specific_data = train_confirm[train_confirm['Animals'] == i]\n#     print(i, len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# one_animal = train_confirm[train_confirm['Animals']==1]\n\n# specific_data = one_animal[one_animal['width'] > one_animal['height']]\n# print(\"width > height\", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n# print()\n\n# specific_data = one_animal[one_animal['width'] < one_animal['height']]\n# print(\"width < height\", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n# print()\n\n# specific_data = one_animal[one_animal['width'] > (one_animal['height'] * 1.3)]\n# print(\"width> height * 1.3 \", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n# print()\n# specific_data = one_animal[(one_animal['width'] * 1.3) < one_animal['height']]\n# print(\"width * 1.3 < height\", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n# print()\n\n# specific_data = one_animal[one_animal['width'] > (one_animal['height'] * 1.5)]\n# print(\"width> height * 1.5 \", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n# print()\n# specific_data = one_animal[(one_animal['width'] * 1.5) < one_animal['height']]\n# print(\"width * 1.5 < height\", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n# print()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ##time\n# xcit_result = xcit_predict(train_confirm) \n# xcit_preds = multiple_ratio(xcit_result['preds'])\n\n# print(xcit_preds.mean(), xcit_preds.std(), np.sqrt(mean_squared_error(train_confirm['Pawpularity'], xcit_preds)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ##time\n# nfnet_result = nfnet_predict(train_confirm) \n# nfnet_preds = multiple_ratio(nfnet_result['preds'])\n\n# print(nfnet_preds.mean(), nfnet_preds.std(), np.sqrt(mean_squared_error(train_confirm['Pawpularity'], nfnet_preds)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_confirm.loc[:, 'preds'] = (train_confirm.loc[:, 'preds'] * 0.6) + (xcit_preds * 0.2) + (nfnet_preds * 0.2)\n# preds = train_confirm['preds']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(preds.mean(), preds.std(), np.sqrt(mean_squared_error(train_confirm['Pawpularity'], preds)))\n# # Cats CV\n# specific_data = train_confirm[(train_confirm['Cats']) > 0]\n# print(\"Cats\", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n# # Dogs CV\n# specific_data = train_confirm[(train_confirm['Dogs']) > 0]\n# print(\"Dogs\", len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))\n\n# print(\"Animals\")\n# for i in range(8):\n#     specific_data = train_confirm[train_confirm['Animals'] == i]\n#     print(i, len(specific_data), np.sqrt(mean_squared_error(specific_data['Pawpularity'], specific_data['preds'])))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"# Object detect\nadd_hwf(test_df)\n# I mustn't connect to below code","metadata":{"execution":{"iopub.status.busy":"2021-12-27T22:13:38.647363Z","iopub.execute_input":"2021-12-27T22:13:38.648057Z","iopub.status.idle":"2021-12-27T22:13:43.178381Z","shell.execute_reply.started":"2021-12-27T22:13:38.648011Z","shell.execute_reply":"2021-12-27T22:13:43.177714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['fields'] = test_df['fields'].apply(fields_to_dict)\nset_boxes_info(test_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Normal no svr\nnormal_result = normal_predict(test_df)\nnormal_preds = multiple_ratio(normal_result['preds'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xcit_result = xcit_predict(test_df) \nxcit_preds = multiple_ratio(xcit_result['preds'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nfnet_result = nfnet_predict(test_df) \nnfnet_preds = multiple_ratio(nfnet_result['preds'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nfnet2_result = nfnet2_predict(test_df) \nnfnet2_preds = multiple_ratio(nfnet2_result['preds'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.loc[:, 'preds'] = (normal_preds * 0.55) + (xcit_preds * 0.3) +  (nfnet_preds * 0.1) + (nfnet2_preds * 0.05)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Pawpularity'] = test_df['preds']\ntest_df = test_df[[\"Id\", \"Pawpularity\"]]\ntest_df.to_csv(\"submission.csv\", index=False)","metadata":{"id":"TmynbFQYVDdc","execution":{"iopub.status.busy":"2021-12-27T22:22:01.993563Z","iopub.execute_input":"2021-12-27T22:22:01.994197Z","iopub.status.idle":"2021-12-27T22:22:02.011113Z","shell.execute_reply.started":"2021-12-27T22:22:01.994157Z","shell.execute_reply":"2021-12-27T22:22:02.010348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2021-12-27T22:22:02.796911Z","iopub.execute_input":"2021-12-27T22:22:02.797496Z","iopub.status.idle":"2021-12-27T22:22:02.807537Z","shell.execute_reply.started":"2021-12-27T22:22:02.797455Z","shell.execute_reply":"2021-12-27T22:22:02.806388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}