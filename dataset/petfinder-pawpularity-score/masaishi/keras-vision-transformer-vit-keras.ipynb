{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I started to learn about machine learning few months ago.\nThus, this notebook may have some wrong points.\nIf you find these or some advices, please comment to tell me; it will help me to learn data science.\n\n---\n\nI used Vision Transformer at keras.\n\nThis is article.\n[An Image is Worth 16x16 Words: Transformes For Image Recognition at Scale. ](https://arxiv.org/pdf/2010.11929.pdf)\n\nI used [vit-keras](https://github.com/faustomorales/vit-keras) library to use that.\n\n<br />\n\nFor submit, I can't connect internet, so I save vit_b16 and use from dataset.\n```\nbase_model = vit.vit_b16(\n    image_size=IMG_SIZE,\n    activation='sigmoid',\n    pretrained=True,\n    include_top=False,\n    pretrained_top=False,\n)\nbase_model.save_model('base_model.h5')\n```\n\nThis predictions are made by ensemble of 3 Transfer Learning predictions and 3 Fine tuning predictions.","metadata":{"id":"gwJQIPKN91xv"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport gc\nimport sys\nimport datetime\n\nimport pickle\n\nimport subprocess\nimport json\nimport datetime\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, RepeatedStratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport tensorflow.experimental.numpy as tnp\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nimport tensorflow_addons as tfa\n\nimport seaborn as sns\nfrom scipy.optimize import minimize\n","metadata":{"id":"xymr0lBQVDcq","execution":{"iopub.status.busy":"2021-11-20T18:37:52.500696Z","iopub.execute_input":"2021-11-20T18:37:52.501356Z","iopub.status.idle":"2021-11-20T18:37:58.641996Z","shell.execute_reply.started":"2021-11-20T18:37:52.501312Z","shell.execute_reply":"2021-11-20T18:37:58.641088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install vit-keras\n!pip install ../input/vit-keras/validators-0.18.2-py3-none-any.whl\n!pip install ../input/vit-keras/vit_keras-0.1.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:37:58.644824Z","iopub.execute_input":"2021-11-20T18:37:58.645104Z","iopub.status.idle":"2021-11-20T18:38:54.569325Z","shell.execute_reply.started":"2021-11-20T18:37:58.645068Z","shell.execute_reply":"2021-11-20T18:38:54.568536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vit_keras import vit, utils","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:38:54.572371Z","iopub.execute_input":"2021-11-20T18:38:54.57269Z","iopub.status.idle":"2021-11-20T18:38:54.854622Z","shell.execute_reply.started":"2021-11-20T18:38:54.572652Z","shell.execute_reply":"2021-11-20T18:38:54.853905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"G88GvDcYVDc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Constants\nIMG_SIZE = 384\nCHANNELS = 3\nBATCH_SIZE = 32\nQ = 30\nEPOCHS = 17\nREPETE_NUMBER = 1\nLR = 0.001\nWD = 0.0001\nEARRY_STOP = 5\n\nF_EPOCHS = 4\nF_BATCH_SIZE = 8\nF_LR = 0.000002\nF_WD = 0.0000002\n\n\nDATA_DIR = '../input/petfinder-pawpularity-score'\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE  ","metadata":{"id":"wKkCBCV7VDc6","execution":{"iopub.status.busy":"2021-11-20T18:38:57.013486Z","iopub.execute_input":"2021-11-20T18:38:57.013843Z","iopub.status.idle":"2021-11-20T18:38:57.022731Z","shell.execute_reply.started":"2021-11-20T18:38:57.0138Z","shell.execute_reply":"2021-11-20T18:38:57.02184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare train and test\nTRAIN_FILENAMES = tf.io.gfile.glob(DATA_DIR + '/train/*')\nTEST_FILENAMES = tf.io.gfile.glob(DATA_DIR + '/test/*')\n\nTRAIN_FILENAMES.sort()\nTEST_FILENAMES.sort()\n\ntrain_df=pd.read_csv(f'{DATA_DIR}/train.csv', usecols=['Id', 'Pawpularity'])\ntest_df=pd.read_csv(f'{DATA_DIR}/test.csv', usecols=['Id'])\n\ntrain_df['file_path'] = TRAIN_FILENAMES\ntest_df['file_path'] = TEST_FILENAMES\n\ntrain_df['target_value'] = train_df['Pawpularity']\ntrain_df['stratify_label'] = pd.qcut(train_df['Pawpularity'], q = Q, labels = range(Q))","metadata":{"id":"pN5P8n6rVDdJ","execution":{"iopub.status.busy":"2021-11-20T10:22:01.184446Z","iopub.execute_input":"2021-11-20T10:22:01.184764Z","iopub.status.idle":"2021-11-20T10:22:02.762543Z","shell.execute_reply.started":"2021-11-20T10:22:01.18471Z","shell.execute_reply":"2021-11-20T10:22:02.761788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confirm_index = []\nwith open('../input/val-index/val_index.pkl', 'rb') as web:\n    confirm_index = pickle.load(web)\ntrain_confirm = train_df.iloc[confirm_index]\ntrain_df = train_df.drop(confirm_index)","metadata":{"id":"MPrdrfl0VDdO","execution":{"iopub.status.busy":"2021-11-20T10:22:02.763929Z","iopub.execute_input":"2021-11-20T10:22:02.764182Z","iopub.status.idle":"2021-11-20T10:22:02.784275Z","shell.execute_reply.started":"2021-11-20T10:22:02.764148Z","shell.execute_reply":"2021-11-20T10:22:02.783664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/rsmits/effnet-b2-feature-models-catboost#SET-TPU-/-GPU\n\ndef build_augmenter(is_labelled):\n    def augment(img):\n        # Only use basic augmentations...too much augmentation hurts performance\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.95, 1.05)\n        img = tf.image.random_brightness(img, 0.05)\n        img = tf.image.random_contrast(img, 0.95, 1.05)\n        img = tf.image.random_hue(img, 0.05)\n        \n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if is_labelled else augment\n\ndef build_decoder(is_labelled):\n    def decode(path):\n        # Read Image\n        file_bytes = tf.io.read_file(path)\n        img = tf.image.decode_jpeg(file_bytes, channels = CHANNELS)\n        \n        # Normalize and Resize\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n        \n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), label\n    \n    return decode_with_labels if is_labelled else decode\n\ndef create_dataset(df, batch_size = BATCH_SIZE, is_labelled = False, augment = False, repeat = False, shuffle = False):\n    decode_fn = build_decoder(is_labelled)\n    augmenter_fn = build_augmenter(is_labelled)\n    \n    # Create Dataset\n    if is_labelled:\n        dataset = tf.data.Dataset.from_tensor_slices((df['file_path'].values, df['target_value'].values))\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices((df['file_path'].values))\n    dataset = dataset.map(decode_fn, num_parallel_calls = AUTOTUNE)\n    dataset = dataset.map(augmenter_fn, num_parallel_calls = AUTOTUNE) if augment else dataset\n    dataset = dataset.repeat() if repeat else dataset\n    dataset = dataset.shuffle(1024, reshuffle_each_iteration = True) if shuffle else dataset\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(AUTOTUNE)\n    \n    return dataset","metadata":{"id":"rl3E6p6VVDdS","execution":{"iopub.status.busy":"2021-11-20T10:22:02.78541Z","iopub.execute_input":"2021-11-20T10:22:02.785669Z","iopub.status.idle":"2021-11-20T10:22:02.798089Z","shell.execute_reply.started":"2021-11-20T10:22:02.785636Z","shell.execute_reply":"2021-11-20T10:22:02.797256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"yrgEpvmit2gq","outputId":"727e8e7d-021a-4166-bf9b-7f6bdd01ef9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set Callbacks\ndef model_checkpoint(kind, fold):\n    return ModelCheckpoint(f'{kind}{fold:03}.h5',\n              verbose = 1, \n              monitor = 'val_root_mean_squared_error', \n              mode = 'min', \n              save_weights_only=False,\n              save_best_only = True)\ndef early_stopping():\n    return EarlyStopping(\n        monitor='val_root_mean_squared_error',\n        min_delta=0.0,\n        patience=EARRY_STOP,\n    )","metadata":{"id":"gQOEFS_1VDdT","execution":{"iopub.status.busy":"2021-11-20T11:05:39.467253Z","iopub.execute_input":"2021-11-20T11:05:39.467519Z","iopub.status.idle":"2021-11-20T11:05:39.472999Z","shell.execute_reply.started":"2021-11-20T11:05:39.467478Z","shell.execute_reply":"2021-11-20T11:05:39.471902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# OOF RMSE Placeholder\nall_val_rmse = []\n\n# Stratified Training\n# kfold = StratifiedKFold(n_splits = FEATURE_FOLDS, shuffle = True, random_state = SEED)\nkfold = RepeatedStratifiedKFold(n_splits = 5, n_repeats=REPETE_NUMBER)\n\nfor fold, (train_index, val_index) in enumerate(kfold.split(train_df.index, train_df['stratify_label'])):\n    print(f'\\n===== Fold {fold}\\n')\n\n    # Pre model.fit cleanup\n    tf.keras.backend.clear_session()\n    gc.collect()\n\n    # Create Model\n    base_model = keras.models.load_model('../input/nb013-v005-output/base_model.h5')\n    base_model.trainable=False\n    \n    x = base_model.output\n\n    prediction = tf.keras.layers.Dense(128, activation=tfa.activations.rrelu)(x)\n    prediction = tf.keras.layers.Dense(1, activation=tfa.activations.rrelu)(prediction)\n    \n    model = keras.Model(inputs = base_model.input, outputs = prediction)\n\n    model.compile(\n        optimizer = tfa.optimizers.AdamW(\n            learning_rate=LR, weight_decay=WD\n        ),\n        loss = tf.keras.losses.MeanSquaredError(),\n        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n    )\n\n    # Create TF Datasets\n    trn = train_df.iloc[train_index]\n    val = train_df.iloc[val_index]\n    \n    # training_dataset = create_dataset(small_trn, batch_size = BATCH_SIZE, is_labelled = True, augment = True, repeat = True, shuffle = True)\n    training_dataset = create_dataset(trn, batch_size = BATCH_SIZE, is_labelled = True, augment = True, repeat = True, shuffle = True)\n    validation_dataset = create_dataset(val, batch_size = BATCH_SIZE, is_labelled = True, augment = False, repeat = True, shuffle = False)\n\n    # Transfer Learning\n    model.fit(training_dataset,\n      epochs = EPOCHS,\n      steps_per_epoch = trn.shape[0] // BATCH_SIZE,\n      validation_steps = val.shape[0] // BATCH_SIZE,\n      callbacks = [model_checkpoint(\"t\", fold), early_stopping()],\n      validation_data = validation_dataset,\n      verbose = 1\n    )\n\n    # Fine tuning\n    training_dataset = create_dataset(trn, batch_size = F_BATCH_SIZE, is_labelled = True, augment = True, repeat = True, shuffle = True)\n    model.load_weights(f't{fold:03}.h5')\n    model.trainable = True\n    model.compile(\n        optimizer = tfa.optimizers.AdamW(\n            learning_rate=F_LR, weight_decay=F_WD\n        ),\n        loss = tf.keras.losses.MeanSquaredError(),\n        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n    )\n    \n    history = model.fit(training_dataset,\n      epochs = F_EPOCHS,\n      steps_per_epoch = trn.shape[0] // F_BATCH_SIZE,\n      validation_steps = val.shape[0] // F_BATCH_SIZE,\n      callbacks = [model_checkpoint(\"f\", fold), early_stopping()],\n      validation_data = validation_dataset,\n      verbose = 1\n    )\n\n    # Validation Information\n    best_val_rmse = min(history.history['val_root_mean_squared_error'])\n    all_val_rmse.append(best_val_rmse)\n    print(f'\\nValidation RMSE: {best_val_rmse}\\n')\n\n# Summary\nprint(f'Final Mean RMSE for {REPETE_NUMBER*5} Fold CV Training: {np.mean(all_val_rmse)}')","metadata":{"id":"LXIr51sDVDdW","outputId":"5bfd9d70-3ef0-411a-e645-ffff7df1880c","execution":{"iopub.status.busy":"2021-11-20T11:05:40.663389Z","iopub.execute_input":"2021-11-20T11:05:40.663625Z","iopub.status.idle":"2021-11-20T11:21:14.8513Z","shell.execute_reply.started":"2021-11-20T11:05:40.663598Z","shell.execute_reply":"2021-11-20T11:21:14.850418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file_name in os.listdir(f'./'):\n    if 't' in file_name and '.h5' in file_name:\n        model.load_weights(f'{file_name}')\n        head_input = keras.layers.Input(model.layers[-2].input_shape[1:])\n        head_model = head_input\n\n        for layer in model.layers[-2:]:\n            head_model = layer(head_model)\n\n        head_model = keras.Model(inputs=head_input, outputs=head_model)\n        head_model.compile(\n            optimizer = tfa.optimizers.AdamW(\n                learning_rate=F_LR, weight_decay=F_WD\n            ),\n            loss = tf.keras.losses.MeanSquaredError(),\n            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n        )\n\n        head_model.save(f'h{file_name}')","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:27:19.114468Z","iopub.execute_input":"2021-11-20T11:27:19.115088Z","iopub.status.idle":"2021-11-20T11:27:19.478739Z","shell.execute_reply.started":"2021-11-20T11:27:19.115049Z","shell.execute_reply":"2021-11-20T11:27:19.478005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confirm_dataset = create_dataset(train_confirm, batch_size = BATCH_SIZE, is_labelled = True, augment = False, repeat = False, shuffle = False)\npredictions = []","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:22:41.215538Z","iopub.execute_input":"2021-11-20T11:22:41.215818Z","iopub.status.idle":"2021-11-20T11:22:41.238991Z","shell.execute_reply.started":"2021-11-20T11:22:41.215782Z","shell.execute_reply":"2021-11-20T11:22:41.238326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = keras.models.load_model('../input/nb013-v005-output/base_model.h5')\nbase_output = base_model.predict(confirm_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:22:42.223881Z","iopub.execute_input":"2021-11-20T11:22:42.224102Z","iopub.status.idle":"2021-11-20T11:24:12.784459Z","shell.execute_reply.started":"2021-11-20T11:22:42.224076Z","shell.execute_reply":"2021-11-20T11:24:12.78361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head_models = []\nfor i in range(REPETE_NUMBER*5):\n    head_models.append(keras.models.load_model(f'ht{i:03}.h5'))\nfor head_model in head_models:\n    predictions.append(np.array(head_model.predict(base_output)))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:28:24.350666Z","iopub.execute_input":"2021-11-20T11:28:24.351269Z","iopub.status.idle":"2021-11-20T11:28:24.530656Z","shell.execute_reply.started":"2021-11-20T11:28:24.351227Z","shell.execute_reply":"2021-11-20T11:28:24.529964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_models = []\nfor i in range(REPETE_NUMBER*5):\n    trained_models.append(keras.models.load_model(f'f{i:03}.h5'))\nfor trained_model in trained_models:\n    predictions.append(np.array(trained_model.predict(confirm_dataset)))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:28:45.07161Z","iopub.execute_input":"2021-11-20T11:28:45.072345Z","iopub.status.idle":"2021-11-20T11:29:38.204477Z","shell.execute_reply.started":"2021-11-20T11:28:45.072306Z","shell.execute_reply":"2021-11-20T11:29:38.203705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, prediction in enumerate(predictions):\n    print(i, prediction.mean(), prediction.std(), np.sqrt(mean_squared_error(train_confirm['Pawpularity'], prediction)))","metadata":{"id":"yKqFS8SICv9s","execution":{"iopub.status.busy":"2021-11-20T11:29:38.206375Z","iopub.execute_input":"2021-11-20T11:29:38.206628Z","iopub.status.idle":"2021-11-20T11:29:38.216345Z","shell.execute_reply.started":"2021-11-20T11:29:38.206596Z","shell.execute_reply":"2021-11-20T11:29:38.215555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For measuring similarity\nscore_table = []\nfor prediction1 in predictions:\n    temp_line = []\n    for prediction2 in predictions:\n        temp_line.append(np.sqrt(mean_squared_error(prediction1, prediction2)))\n    score_table.append(temp_line)\nsns.heatmap(score_table)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:29:38.217921Z","iopub.execute_input":"2021-11-20T11:29:38.218994Z","iopub.status.idle":"2021-11-20T11:29:38.476767Z","shell.execute_reply.started":"2021-11-20T11:29:38.218955Z","shell.execute_reply":"2021-11-20T11:29:38.476089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fine tuning may get more good grade. Thus, I set high ratio of ensemble.\n\nTransfer learning ones (ht) 4 : Fine tuning ones (f) 6","metadata":{}},{"cell_type":"code","source":"ratio_bet_htf = [0.4, 0.6]\nbest_ratios = []\nfor one_ratio in ratio_bet_htf:\n    for i in range(REPETE_NUMBER*5):\n        best_ratios.append(1.0 * one_ratio / (REPETE_NUMBER * 5))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:47:22.072614Z","iopub.execute_input":"2021-11-20T18:47:22.072917Z","iopub.status.idle":"2021-11-20T18:47:22.079644Z","shell.execute_reply.started":"2021-11-20T18:47:22.072877Z","shell.execute_reply":"2021-11-20T18:47:22.078916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_ratios","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:47:45.563181Z","iopub.execute_input":"2021-11-20T18:47:45.563658Z","iopub.status.idle":"2021-11-20T18:47:45.570295Z","shell.execute_reply.started":"2021-11-20T18:47:45.563623Z","shell.execute_reply":"2021-11-20T18:47:45.569502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.zeros((train_confirm.shape[0], 1))\nfor i, ratio in enumerate(best_ratios):\n    y_pred += (predictions[i] * ratio)\nprint(y_pred.mean(), y_pred.std(), np.sqrt(mean_squared_error(train_confirm['Pawpularity'], y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:48:10.844252Z","iopub.execute_input":"2021-11-20T18:48:10.844511Z","iopub.status.idle":"2021-11-20T18:48:10.851383Z","shell.execute_reply.started":"2021-11-20T18:48:10.844482Z","shell.execute_reply":"2021-11-20T18:48:10.850617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_dataset = create_dataset(test_df, batch_size = BATCH_SIZE, is_labelled = False, augment = False, repeat = False, shuffle = False)\npredictions = []","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:32:24.986406Z","iopub.execute_input":"2021-11-20T11:32:24.986939Z","iopub.status.idle":"2021-11-20T11:32:25.008137Z","shell.execute_reply.started":"2021-11-20T11:32:24.986902Z","shell.execute_reply":"2021-11-20T11:32:25.007467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_output = base_model.predict(sub_dataset)\nfor head_model in head_models:\n    predictions.append(np.array(head_model.predict(base_output)))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:32:25.388077Z","iopub.execute_input":"2021-11-20T11:32:25.388329Z","iopub.status.idle":"2021-11-20T11:32:28.239994Z","shell.execute_reply.started":"2021-11-20T11:32:25.3883Z","shell.execute_reply":"2021-11-20T11:32:28.239032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for trained_model in trained_models:\n    predictions.append(np.array(trained_model.predict(sub_dataset)))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:32:28.241944Z","iopub.execute_input":"2021-11-20T11:32:28.242529Z","iopub.status.idle":"2021-11-20T11:32:32.563204Z","shell.execute_reply.started":"2021-11-20T11:32:28.242484Z","shell.execute_reply":"2021-11-20T11:32:32.558988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.zeros((test_df.shape[0], 1))\n\nfor i, ratio in enumerate(best_ratios):\n    y_pred += (predictions[i] * ratio)\nprint(y_pred.mean(), y_pred.std())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Pawpularity'] = y_pred\ntest_df = test_df[[\"Id\", \"Pawpularity\"]]\ntest_df.to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{},"execution_count":null,"outputs":[]}]}