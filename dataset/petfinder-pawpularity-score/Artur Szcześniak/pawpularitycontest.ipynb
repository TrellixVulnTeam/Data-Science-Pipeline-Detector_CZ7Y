{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports and definitions","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\nfrom torchvision.io import read_image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport os\nimport cProfile\nimport pstats\nfrom pstats import SortKey\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:04:31.604065Z","iopub.execute_input":"2022-01-17T18:04:31.604914Z","iopub.status.idle":"2022-01-17T18:04:33.327004Z","shell.execute_reply.started":"2022-01-17T18:04:31.604807Z","shell.execute_reply":"2022-01-17T18:04:33.326071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_image(im, final_size, destination, index):\n    bg = (127, 127, 127)\n    w, h = im.size\n    if w == h:\n        image = im.resize(final_size)\n        image.save(os.path.join(destination, index + \".jpg\"))\n    elif w > h:\n        image = Image.new(im.mode, (w, w), bg)\n        image.paste(im, (0, (w - h) // 2))\n        image = image.resize(final_size)\n        image.save(os.path.join(destination, index + \".jpg\"))\n    elif h > w:\n        image = Image.new(im.mode, (h, h), bg)\n        image.paste(im, ((h - w) // 2, 0))\n        image = image.resize(final_size)\n        image.save(os.path.join(destination, index + \".jpg\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:04:33.33077Z","iopub.execute_input":"2022-01-17T18:04:33.330996Z","iopub.status.idle":"2022-01-17T18:04:33.338255Z","shell.execute_reply.started":"2022-01-17T18:04:33.330971Z","shell.execute_reply":"2022-01-17T18:04:33.337599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_images(labels_csv, source, destination, final_size):\n    print(\"Starting image preprocessing...\")\n    if not os.path.isdir(destination):\n        os.mkdir(destination)\n    df = pd.read_csv(labels_csv)\n    indexes = df['Id']\n    i = 0\n    n = len(indexes)\n    t0 = datetime.now()\n    processed = 0\n    skipped = 0\n    for index in indexes:\n        try:\n            if (i + 1) % (n // 10) == 0:\n                print(f\"Checking image {i + 1}/{n}\")\n        except ZeroDivisionError:\n            pass\n        if os.path.isfile(os.path.join(destination, index + \".jpg\")):\n            with Image.open(os.path.join(destination, index + \".jpg\")) as dst_im:\n                if dst_im.size == final_size:\n                    skipped += 1\n                    pass\n                else:\n                    with Image.open(os.path.join(source, index + \".jpg\")) as src_im:\n                        process_image(src_im, final_size, destination, index)\n                        processed += 1\n        else:\n            with Image.open(os.path.join(source, index + \".jpg\")) as src_im:\n                process_image(src_im, final_size, destination, index)\n                processed += 1\n        i += 1\n    print(f\"Image preprocessing took {datetime.now() - t0}, processed {processed} images, skipped {skipped}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:04:33.339531Z","iopub.execute_input":"2022-01-17T18:04:33.33998Z","iopub.status.idle":"2022-01-17T18:04:33.351739Z","shell.execute_reply.started":"2022-01-17T18:04:33.339943Z","shell.execute_reply":"2022-01-17T18:04:33.351116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularityDataset(Dataset):\n    def __init__(self, csv, img_dir, tr_test, split=0.8, transformations=None):\n        self.transformations = transformations\n        self.img_dir = img_dir\n        self.df = pd.read_csv(csv)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)\n        if tr_test == 'train':\n            self.df = self.df.truncate(after=np.floor(len(self.df) * split))\n        else:\n            self.df = self.df.truncate(before=np.floor(len(self.df) * split))\n        self.targets = self.df['Pawpularity']\n        self.targets = self.targets.to_numpy(dtype='float32')\n        self.indexes = self.df['Id']\n        self.metadata = self.df.drop(columns=['Pawpularity', 'Id'])\n        self.metadata = self.metadata.to_numpy(dtype=\"float32\")\n\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, item):\n        img_path = os.path.join(self.img_dir, self.indexes.iloc[item])\n        image = read_image(img_path + \".jpg\")\n        if self.transformations:\n            image = self.transformations(image)\n        image = image.type(torch.float32)\n        image = (image - torch.mean(image)) / torch.std(image)\n        metadata = torch.from_numpy(self.metadata[item])\n        target = torch.tensor(self.targets[item].reshape(-1))\n        data = (image, metadata)\n        return data, target","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:04:33.355053Z","iopub.execute_input":"2022-01-17T18:04:33.355582Z","iopub.status.idle":"2022-01-17T18:04:33.367312Z","shell.execute_reply.started":"2022-01-17T18:04:33.355557Z","shell.execute_reply":"2022-01-17T18:04:33.366502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularityModel(nn.Module):\n\n    def __init__(self, img_size):\n        super(PawpularityModel, self).__init__()\n        self.image_cnn = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d(2),\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(2),\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding='same'),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(2),\n            nn.Flatten()\n        )\n        self.metadata_ann = nn.Sequential(\n            nn.Linear(12, 512),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Dropout()\n        )\n        self.dense = nn.Sequential(\n            nn.Linear(img_size[0] * img_size[1] * 2 + 512, 4096),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(4096, 1024),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(1024, 1)\n        )\n\n    def forward(self, X):\n        image, metadata = X\n        image, metadata = image.to(device), metadata.to(device)\n        ann_out = self.metadata_ann(metadata)\n        cnn_out = self.image_cnn(image)\n        dense_input = torch.cat((cnn_out, ann_out), dim=1)\n        out = self.dense(dense_input)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:04:33.368674Z","iopub.execute_input":"2022-01-17T18:04:33.368942Z","iopub.status.idle":"2022-01-17T18:04:33.386971Z","shell.execute_reply.started":"2022-01-17T18:04:33.368907Z","shell.execute_reply":"2022-01-17T18:04:33.386293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, device, criterion, optimizer, train_batches, test_batches,\n          baseline_rmse, train_loader, test_loader, epochs):\n    train_losses = []\n    test_losses = []\n    epochs = epochs\n    t0 = datetime.now()\n    print(\"Starting training...\")\n    for epoch in range(epochs):\n        print(f\"Starting epoch {epoch + 1}.\")\n        model.train()\n        train_loss = []\n        batch = 0\n        for inputs, targets in train_loader:\n            batch += 1\n            targets = targets.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            loss.backward()\n            optimizer.step()\n\n            train_loss.append(loss.item())\n            if batch % (train_batches // 10) == 0:\n                print(f\"Processed train batch {batch}/{int(np.ceil(train_batches))}\")\n\n        train_losses.append(np.mean(train_loss))\n\n        batch = 0\n        model.eval()\n        test_loss = []\n        for inputs, targets in test_loader:\n            batch += 1\n            targets = targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            test_loss.append(loss.item())\n            if batch % (test_batches // 10) == 0:\n                print(f\"Processed test batch {batch}/{int(np.ceil(test_batches))}\")\n\n        test_losses.append(np.mean(test_loss))\n        dt = datetime.now() - t0\n        train_epoch_loss = train_losses[-1]\n        test_epoch_loss = test_losses[-1]\n        print(f\"Epoch:          {epoch + 1}/{epochs}\\n\"\n              f\"Train loss:     {train_epoch_loss:.4f} (root {np.sqrt(train_epoch_loss):.4f})\\n\"\n              f\"Baseline diff:  {np.sqrt(train_epoch_loss) - baseline_rmse:.4f}\\n\"\n              f\"Test loss:      {test_epoch_loss:.4f} (root {np.sqrt(test_epoch_loss):.4f})\\n\"\n              f\"Baseline diff:  {np.sqrt(test_epoch_loss) - baseline_rmse:.4f}\\n\"\n              f\"Total duration: {dt}\")\n\n    plt.plot(train_losses, label=\"Train losses\")\n    plt.plot(test_losses, label=\"Test losses\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:04:33.388261Z","iopub.execute_input":"2022-01-17T18:04:33.388759Z","iopub.status.idle":"2022-01-17T18:04:33.402351Z","shell.execute_reply.started":"2022-01-17T18:04:33.388723Z","shell.execute_reply":"2022-01-17T18:04:33.401595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grade(model, device, train_batches, test_batches, baseline_rmse, train_loader, test_loader):\n    print(\"Starting grading...\")\n    with torch.no_grad():\n        train_outputs = []\n        train_targets = []\n        model.train()\n        batch = 0\n        for inputs, targets in train_loader:\n            batch += 1\n            if batch % (train_batches // 10) == 0:\n                print(f\"Grading training batch {batch}/{int(np.ceil(train_batches))}...\")\n            targets = targets.to(device)\n            outputs = model(inputs).cpu().numpy().flatten().tolist()\n            train_targets += targets.cpu().numpy().flatten().tolist()\n            train_outputs += outputs\n\n        train_outputs = np.array(train_outputs)\n        train_targets = np.array(train_targets)\n        train_diff = train_targets - train_outputs\n        plt.hist(train_diff, bins=range(-75, 75), label=\"Train diff\", color='blue')\n        plt.show()\n\n        train_rmse = np.sqrt(((train_targets - train_outputs) ** 2).mean())\n\n        test_outputs = []\n        test_targets = []\n        model.eval()\n        batch = 0\n        for inputs, targets in test_loader:\n            batch += 1\n            if batch % (test_batches // 10) == 0:\n                print(f\"Grading test batch {batch}/{int(np.ceil(test_batches))}...\")\n            targets = targets.to(device)\n            outputs = model(inputs).cpu().numpy().flatten().tolist()\n            test_targets += targets.cpu().numpy().flatten().tolist()\n            test_outputs += outputs\n\n        test_outputs = np.array(test_outputs)\n        test_targets = np.array(test_targets)\n        test_diff = test_targets - test_outputs\n        plt.hist(test_diff, bins=range(-75, 75), label=\"Test diff\", color='orange')\n        plt.show()\n\n        test_rmse = np.sqrt(((test_targets - test_outputs) ** 2).mean())\n        print(f\"Train RMSE: {train_rmse:.4f}, baseline diff: {train_rmse - baseline_rmse:.4f}\\n\"\n              f\"Test RMSE:  {test_rmse:.4f}, baseline diff: {test_rmse - baseline_rmse:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:04:33.403538Z","iopub.execute_input":"2022-01-17T18:04:33.403933Z","iopub.status.idle":"2022-01-17T18:04:33.418475Z","shell.execute_reply.started":"2022-01-17T18:04:33.403899Z","shell.execute_reply":"2022-01-17T18:04:33.417544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image preprocessing","metadata":{}},{"cell_type":"code","source":"img_size = (128, 128)\npreprocess_images('/kaggle/input/petfinder-pawpularity-score/train.csv', '/kaggle/input/petfinder-pawpularity-score/train', 'train-post', img_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:04:33.421359Z","iopub.execute_input":"2022-01-17T18:04:33.422927Z","iopub.status.idle":"2022-01-17T18:08:50.518995Z","shell.execute_reply.started":"2022-01-17T18:04:33.422882Z","shell.execute_reply":"2022-01-17T18:08:50.518186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Datasets instantiation","metadata":{}},{"cell_type":"code","source":"train_dataset = PawpularityDataset(csv='/kaggle/input/petfinder-pawpularity-score/train.csv',\n                                   img_dir='train-post',\n                                   tr_test='train',\n                                   transformations=None)\n\ntest_dataset = PawpularityDataset(csv='/kaggle/input/petfinder-pawpularity-score/train.csv',\n                                  img_dir='train-post',\n                                  tr_test='test')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:08:50.520381Z","iopub.execute_input":"2022-01-17T18:08:50.520802Z","iopub.status.idle":"2022-01-17T18:08:50.561105Z","shell.execute_reply.started":"2022-01-17T18:08:50.520743Z","shell.execute_reply":"2022-01-17T18:08:50.560432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training parameters","metadata":{}},{"cell_type":"code","source":"batch_sz = 96\nbaseline_rmse = 20.59095133915306\ntrain_batches = train_dataset.__len__() / batch_sz\ntest_batches = test_dataset.__len__() / batch_sz\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_sz, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_sz, shuffle=False)\n\nmodel = PawpularityModel(img_size)\ndevice = torch.device(\"cuda:0\")\nmodel.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-6)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:08:50.563455Z","iopub.execute_input":"2022-01-17T18:08:50.563694Z","iopub.status.idle":"2022-01-17T18:08:55.111144Z","shell.execute_reply.started":"2022-01-17T18:08:50.563661Z","shell.execute_reply":"2022-01-17T18:08:55.110338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training run","metadata":{}},{"cell_type":"code","source":"train(model, device, criterion, optimizer, train_batches, test_batches, baseline_rmse, train_loader, test_loader, epochs=50)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:08:55.112448Z","iopub.execute_input":"2022-01-17T18:08:55.112692Z","iopub.status.idle":"2022-01-17T18:29:45.391079Z","shell.execute_reply.started":"2022-01-17T18:08:55.112659Z","shell.execute_reply":"2022-01-17T18:29:45.390381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Grading","metadata":{}},{"cell_type":"code","source":"grade(model, device, train_batches, test_batches, baseline_rmse, train_loader, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:29:45.392436Z","iopub.execute_input":"2022-01-17T18:29:45.392867Z","iopub.status.idle":"2022-01-17T18:29:59.094843Z","shell.execute_reply.started":"2022-01-17T18:29:45.392827Z","shell.execute_reply":"2022-01-17T18:29:59.093955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create submission","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    preprocess_images('/kaggle/input/petfinder-pawpularity-score/test.csv', '/kaggle/input/petfinder-pawpularity-score/test', 'test-post', img_size)\n    submission = pd.DataFrame(columns=['Id', 'Pawpularity'])\n    df = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\n    metadata_df = df.drop(columns=['Id'])\n    metadata = metadata_df.to_numpy(dtype=\"float32\")\n    indexes = df['Id']\n    ids = []\n    pawpularities = []\n    i = 0\n    for index in indexes:\n        ids.append(index)\n        image = read_image(os.path.join('test-post', index + \".jpg\"))\n        image = image.type(torch.float32)\n        image = (image - torch.mean(image)) / torch.std(image)\n        image = image.reshape(1, 3, img_size[0], img_size[1])\n        md = metadata[i]\n        md = md.reshape(1, 12)\n        md = torch.from_numpy(md)\n        data = (image, md)\n        output = model(data).cpu().item()\n        pawpularities.append(output)\n        i += 1\n\n    submission['Id'] = ids\n    submission['Pawpularity'] = pawpularities\n    submission.to_csv('submission.csv', index=False)\n    print(\"Saved submission.\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:29:59.096577Z","iopub.execute_input":"2022-01-17T18:29:59.097104Z","iopub.status.idle":"2022-01-17T18:29:59.252178Z","shell.execute_reply.started":"2022-01-17T18:29:59.097063Z","shell.execute_reply":"2022-01-17T18:29:59.250629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:29:59.253579Z","iopub.execute_input":"2022-01-17T18:29:59.25387Z","iopub.status.idle":"2022-01-17T18:29:59.961469Z","shell.execute_reply.started":"2022-01-17T18:29:59.253832Z","shell.execute_reply":"2022-01-17T18:29:59.960508Z"},"trusted":true},"execution_count":null,"outputs":[]}]}