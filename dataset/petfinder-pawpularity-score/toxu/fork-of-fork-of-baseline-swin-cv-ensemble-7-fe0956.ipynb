{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Shiro","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:31.733139Z","iopub.execute_input":"2021-12-27T06:39:31.733655Z","iopub.status.idle":"2021-12-27T06:39:31.740122Z","shell.execute_reply.started":"2021-12-27T06:39:31.733608Z","shell.execute_reply":"2021-12-27T06:39:31.738934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2 \nimport torch\nfrom tqdm import tqdm\nfrom torch.cuda.amp import GradScaler, autocast\nprint(torch.__version__)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:31.742383Z","iopub.execute_input":"2021-12-27T06:39:31.743365Z","iopub.status.idle":"2021-12-27T06:39:33.61601Z","shell.execute_reply.started":"2021-12-27T06:39:31.743312Z","shell.execute_reply":"2021-12-27T06:39:33.614801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:33.617492Z","iopub.execute_input":"2021-12-27T06:39:33.618368Z","iopub.status.idle":"2021-12-27T06:39:33.625464Z","shell.execute_reply.started":"2021-12-27T06:39:33.618321Z","shell.execute_reply":"2021-12-27T06:39:33.624442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nSEED = 42\nimport random\ndef seed_everything(seed_value):\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    \n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:33.62725Z","iopub.execute_input":"2021-12-27T06:39:33.627681Z","iopub.status.idle":"2021-12-27T06:39:40.225584Z","shell.execute_reply.started":"2021-12-27T06:39:33.627584Z","shell.execute_reply":"2021-12-27T06:39:40.224204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:40.229936Z","iopub.execute_input":"2021-12-27T06:39:40.230453Z","iopub.status.idle":"2021-12-27T06:39:40.250842Z","shell.execute_reply.started":"2021-12-27T06:39:40.230371Z","shell.execute_reply":"2021-12-27T06:39:40.249876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"old_folder = \"../input/petfinder-pawpularity-score/test\"\ndf_test[\"path\"] = df_test.Id.apply(lambda x: os.path.join(old_folder, x+\".jpg\"))","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:40.253278Z","iopub.execute_input":"2021-12-27T06:39:40.253965Z","iopub.status.idle":"2021-12-27T06:39:40.267654Z","shell.execute_reply.started":"2021-12-27T06:39:40.25392Z","shell.execute_reply":"2021-12-27T06:39:40.26665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\n\n\nclass PetNet(torch.nn.Module):\n    def __init__(self, backbone, dim, num_classes=101, output=\"classification\", one_hot=False):\n        \"\"\"\n        In the constructor we instantiate two nn.Linear modules and assign them as\n        member variables.\n        \"\"\"\n        super(PetNet, self).__init__()\n        \n        self.type = output\n        self.backbone = backbone\n        self.one_hot = one_hot\n        if one_hot:\n            dim = dim + 12\n        self.last_layer = nn.Linear(dim, num_classes)\n        self.r = torch.arange(num_classes).unsqueeze(0)\n        \n    def to_device(self, device):\n        self.r = self.r.to(device)\n    def forward(self, x, x2=None):\n        \"\"\"\n        In the forward function we accept a Tensor of input data and we must return\n        a Tensor of output data. We can use Modules defined in the constructor as\n        well as arbitrary operators on Tensors.\n        \"\"\"\n        features = self.backbone(x)\n        #print(len(features),features[0].shape, features[1].shape)\n        #print(features.shape)\n        if type(features) == tuple:\n            features = features[0]\n        #print(features.shape, x2.shape)\n        if self.one_hot:\n            features = torch.cat((features, x2), dim=-1)\n            \n        #print(features.shape)\n        output_proba = self.last_layer(features)\n        \n        # if self.type == \"regression\":\n        #     output = nn.functional.softmax(output_proba, dim=1)\n        #     #print(output)\n            \n        #     output = (self.r * output).sum(1)\n        #     return output, output_proba\n        #     #print(output.shape)\n            \n        #print(output_proba.shape)\n        return output_proba","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:40.269342Z","iopub.execute_input":"2021-12-27T06:39:40.270366Z","iopub.status.idle":"2021-12-27T06:39:40.285498Z","shell.execute_reply.started":"2021-12-27T06:39:40.270321Z","shell.execute_reply":"2021-12-27T06:39:40.284329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluation     segment  \ndef inference_fn(model, dataloader, cfg):\n    t=tqdm(dataloader, disable=not cfg.verbose)\n     \n    y_preds = []\n    model.eval()\n    device = cfg.device\n    with torch.no_grad():\n        for i, batch in enumerate(t):\n            \n            if len(batch) == 2:\n                inputs, indices = batch\n                inputs2 = None\n            else:\n                inputs, inputs2, indices = batch\n                inputs2 = inputs2.to(cfg.device, dtype=torch.float) \n\n            inputs = inputs.to(device, dtype=torch.float)\n\n            with autocast(cfg.use_apex_val):\n                outputs = model(inputs, x2=inputs2)\n                if type(outputs) == tuple:\n                    outputs = outputs[0]    \n           \n            if cfg.mode == \"classification\":\n                y_preds.append( torch.nn.functional.softmax(outputs, dim=1).cpu().detach().numpy())\n            else:\n                y_preds.append( outputs.cpu().detach().numpy())\n    return np.concatenate(y_preds).astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:40.287209Z","iopub.execute_input":"2021-12-27T06:39:40.288674Z","iopub.status.idle":"2021-12-27T06:39:40.30381Z","shell.execute_reply.started":"2021-12-27T06:39:40.28863Z","shell.execute_reply":"2021-12-27T06:39:40.302484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport os\nimport pandas as pd \nimport cv2 \nfrom torchvision import transforms as pth_transforms\nfrom tqdm import tqdm\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n\nclass PetDataset(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, data,one_hot=False,resize=224):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.data = data[\"path\"].values.tolist()\n        self.one_hot = one_hot\n        if one_hot: # 12 feature\n            self.data2 = data[['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n                               'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']].values \n        self.transform = pth_transforms.Compose([ \n                                                 pth_transforms.ToPILImage(),\n                                                 pth_transforms.Resize((resize, resize)), \n                                                 #pth_transforms.CenterCrop(224), \n                                                 pth_transforms.ToTensor(), \n                                                 pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), \n                                             ]) \n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.data[idx])\n        #img = cv2.resize(img, (224,224))\n        img = self.transform(img)\n        if self.one_hot:\n            return img, self.data2[idx], idx\n        return img, idx\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:40.307825Z","iopub.execute_input":"2021-12-27T06:39:40.308061Z","iopub.status.idle":"2021-12-27T06:39:40.323158Z","shell.execute_reply.started":"2021-12-27T06:39:40.308026Z","shell.execute_reply":"2021-12-27T06:39:40.322139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config(object):\n    def __init__(self):\n        self.epochs = 100\n        self.lr = 1e-4\n        self.wd = 1e-5\n        self.accumulation = 1\n        self.batch_size=32\n        self.use_apex = True\n        self.use_apex_val = False\n        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n        self.num_classes = 101\n        self.model_name = \"cait_m36_384\" #\"cait_m36_384\"#'swin_large_patch4_window12_384_in22k'\n        self.kfold=5\n        self.resize = 384\n        self.one_hot= True\n        self.mode = \"classification\"\n        self.verbose = True\n        self.verbose_val = True\n        self.smoothing = 0.1\n        # optimizer \n        self.patience = 5\n        self.factor = 0.5\ncfg = Config()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:40.324613Z","iopub.execute_input":"2021-12-27T06:39:40.32524Z","iopub.status.idle":"2021-12-27T06:39:40.338907Z","shell.execute_reply.started":"2021-12-27T06:39:40.325194Z","shell.execute_reply":"2021-12-27T06:39:40.337938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"backbone = timm.create_model(cfg.model_name, pretrained=False)\nbackbone.head = nn.Identity()\nbackbone.head_dist = nn.Identity()\nmodel = PetNet(backbone, dim=768, num_classes=cfg.num_classes, output=cfg.mode, one_hot=cfg.one_hot)\n\nmodel = model.to(cfg.device)\nmodel.to_device(cfg.device)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:40.34066Z","iopub.execute_input":"2021-12-27T06:39:40.341253Z","iopub.status.idle":"2021-12-27T06:39:51.877251Z","shell.execute_reply.started":"2021-12-27T06:39:40.341078Z","shell.execute_reply":"2021-12-27T06:39:51.876164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = PetDataset(data=df_test, one_hot=cfg.one_hot, resize=cfg.resize)#PetDataset(data=new_images,  resize=224)\ntest_dataloader = DataLoader(test_dataset, num_workers=2, batch_size=cfg.batch_size, shuffle=False)\npreds_avg = np.zeros((len(df_test),))\nfor i in range(cfg.kfold):\n    ckpt_name = f\"../input/petfinder-cait-m36-384/cait_m36_384-best-petfinders-classification-fold{i}.pth\"\n    \n    model.load_state_dict(torch.load(ckpt_name, map_location=\"cpu\"))\n    #model = model.to(cfg.device)\n    #model.to_device(cfg.device)\n    preds = inference_fn(model, test_dataloader, cfg)\n    #preds_max = np.argmax(preds, axis=1)\n    preds_mean = (preds * np.array(range(cfg.num_classes)).reshape(1,-1)).sum(1)\n    preds_avg += preds_mean\n\npreds_cait_384 = preds_avg / cfg.kfold","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:39:51.878732Z","iopub.execute_input":"2021-12-27T06:39:51.880127Z","iopub.status.idle":"2021-12-27T06:41:01.399854Z","shell.execute_reply.started":"2021-12-27T06:39:51.880081Z","shell.execute_reply":"2021-12-27T06:41:01.398828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config(object):\n    def __init__(self):\n        self.epochs = 100\n        self.lr = 1e-4\n        self.wd = 1e-5\n        self.accumulation = 1\n        self.batch_size=16\n        self.use_apex = True\n        self.use_apex_val = False\n        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n        self.num_classes = 101\n        self.model_name = \"cait_m48_448\" #\"cait_m36_384\"#'swin_large_patch4_window12_384_in22k'\n        self.kfold=5\n        self.resize = 448\n        self.one_hot= True\n        self.mode = \"classification\"\n        self.verbose = True\n        self.verbose_val = True\n        self.smoothing = 0.1\n        # optimizer \n        self.patience = 5\n        self.factor = 0.5\ncfg = Config()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:41:01.40343Z","iopub.execute_input":"2021-12-27T06:41:01.403904Z","iopub.status.idle":"2021-12-27T06:41:01.414516Z","shell.execute_reply.started":"2021-12-27T06:41:01.403869Z","shell.execute_reply":"2021-12-27T06:41:01.413141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"backbone = timm.create_model(cfg.model_name, pretrained=False)\nbackbone.head = nn.Identity()\nbackbone.head_dist = nn.Identity()\nmodel = PetNet(backbone, dim=768, num_classes=cfg.num_classes, output=cfg.mode, one_hot=cfg.one_hot)\n\nmodel = model.to(cfg.device)\nmodel.to_device(cfg.device)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:41:01.422076Z","iopub.execute_input":"2021-12-27T06:41:01.422411Z","iopub.status.idle":"2021-12-27T06:41:09.203426Z","shell.execute_reply.started":"2021-12-27T06:41:01.42238Z","shell.execute_reply":"2021-12-27T06:41:09.202253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = PetDataset(data=df_test, one_hot=cfg.one_hot, resize=cfg.resize)#PetDataset(data=new_images,  resize=224)\ntest_dataloader = DataLoader(test_dataset, num_workers=2, batch_size=cfg.batch_size, shuffle=False)\npreds_avg = np.zeros((len(df_test),))\nfor i in range(cfg.kfold):\n    ckpt_name = f\"../input/petfindertransformers/cait_m48_448-adam-aug-mixup-one-hot-newfolds/cait_m48_448-best-petfinders-classification-fold{i}.pth\"\n    \n    model.load_state_dict(torch.load(ckpt_name, map_location=\"cpu\"))\n    #model = model.to(cfg.device)\n    #model.to_device(cfg.device)\n    preds = inference_fn(model, test_dataloader, cfg)\n    #preds_max = np.argmax(preds, axis=1)\n    preds_mean = (preds * np.array(range(cfg.num_classes)).reshape(1,-1)).sum(1)\n    preds_avg += preds_mean\n\npreds_cait_448 = preds_avg / cfg.kfold","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:41:09.20567Z","iopub.execute_input":"2021-12-27T06:41:09.206005Z","iopub.status.idle":"2021-12-27T06:42:37.510273Z","shell.execute_reply.started":"2021-12-27T06:41:09.205955Z","shell.execute_reply":"2021-12-27T06:42:37.508305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\nmodel = model.to(\"cpu\")\ndel model\n\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:42:37.512475Z","iopub.execute_input":"2021-12-27T06:42:37.51317Z","iopub.status.idle":"2021-12-27T06:42:38.620497Z","shell.execute_reply.started":"2021-12-27T06:42:37.51312Z","shell.execute_reply":"2021-12-27T06:42:38.61945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tony","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:42:38.62216Z","iopub.execute_input":"2021-12-27T06:42:38.622639Z","iopub.status.idle":"2021-12-27T06:42:38.628398Z","shell.execute_reply.started":"2021-12-27T06:42:38.622596Z","shell.execute_reply":"2021-12-27T06:42:38.627406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/vit-keras-dataset')\n!pip install -q /kaggle/input/validators0182-dataset/validators-0.18.2-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:42:38.629932Z","iopub.execute_input":"2021-12-27T06:42:38.630576Z","iopub.status.idle":"2021-12-27T06:43:09.91982Z","shell.execute_reply.started":"2021-12-27T06:42:38.63053Z","shell.execute_reply":"2021-12-27T06:43:09.91865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/swintransformertf')\nfrom swintransformer import SwinTransformer","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:43:09.922201Z","iopub.execute_input":"2021-12-27T06:43:09.922582Z","iopub.status.idle":"2021-12-27T06:43:11.082778Z","shell.execute_reply.started":"2021-12-27T06:43:09.922536Z","shell.execute_reply":"2021-12-27T06:43:11.081769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport re\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport joblib\nfrom typing import Optional, Tuple\nimport warnings\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow_addons as tfa\n# import efficientnet.tfkeras as efnB\nfrom vit_keras import vit, utils, visualize, layers\nfrom scipy.signal import get_window\n\nfrom tensorflow.keras.losses import mean_squared_error\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n\nimport tensorflow_hub as hub\n\nfrom tqdm.notebook import tqdm\n\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:43:11.08448Z","iopub.execute_input":"2021-12-27T06:43:11.084851Z","iopub.status.idle":"2021-12-27T06:43:12.742897Z","shell.execute_reply.started":"2021-12-27T06:43:11.084807Z","shell.execute_reply":"2021-12-27T06:43:12.741808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\nstrategy = tf.distribute.get_strategy()\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\n# Model Params\nKFOLDS = 5\nFOLD = 0\n\nBATCH_SIZE = 16\nAUG = False","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:43:12.744613Z","iopub.execute_input":"2021-12-27T06:43:12.744991Z","iopub.status.idle":"2021-12-27T06:43:12.783517Z","shell.execute_reply.started":"2021-12-27T06:43:12.744934Z","shell.execute_reply":"2021-12-27T06:43:12.782495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/petfinder-pawpularity-score'\n\ndf = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ndf['image_path'] = BASE_PATH + '/train/' + df.Id + '.jpg'\n\ntest_df  = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest_df['image_path'] = BASE_PATH + '/test/' + test_df.Id + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:43:12.785496Z","iopub.execute_input":"2021-12-27T06:43:12.786153Z","iopub.status.idle":"2021-12-27T06:43:12.838274Z","shell.execute_reply.started":"2021-12-27T06:43:12.786111Z","shell.execute_reply":"2021-12-27T06:43:12.837309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntest_df2 = pd.DataFrame()\n \nfor i in range(len(test_df)):\n    a = test_df.loc[i]\n    d = pd.DataFrame(a).T\n    test_df2 = test_df2.append([d]*850)  #每行复制24倍\ntest_df = test_df2\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:43:12.839998Z","iopub.execute_input":"2021-12-27T06:43:12.840803Z","iopub.status.idle":"2021-12-27T06:43:12.853652Z","shell.execute_reply.started":"2021-12-27T06:43:12.840744Z","shell.execute_reply":"2021-12-27T06:43:12.852199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_func(filename, image_size):\n    img = tf.io.read_file(filename)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.keras.preprocessing.image.smart_resize(img, [image_size, image_size], interpolation='bilinear')\n    \n    img = tf.cast(img, tf.float32)\n    img = tf.keras.applications.imagenet_utils.preprocess_input(img, mode=\"torch\")\n    \n    img = tf.reshape(img, [image_size, image_size, 3])\n    return img\n\n\ndef get_dataset(files, image_size, batch_size=BATCH_SIZE, aug=False):\n    \n    # ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = tf.data.Dataset.from_tensor_slices(files)\n    ds = ds.cache()\n    \n    ds = ds.map(lambda x: parse_func(x, image_size), num_parallel_calls=AUTO)\n    \n    \"\"\"\n    if aug:\n        ds = ds.map(augment, num_parallel_calls=AUTO)\n    \"\"\"\n    \n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:43:12.856278Z","iopub.execute_input":"2021-12-27T06:43:12.856681Z","iopub.status.idle":"2021-12-27T06:43:12.868062Z","shell.execute_reply.started":"2021-12-27T06:43:12.85662Z","shell.execute_reply":"2021-12-27T06:43:12.866777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    inp = tf.keras.layers.Input(shape=[384, 384, 3])\n    base = SwinTransformer('swin_large_384', include_top=False, pretrained=False, use_tpu=False)\n    \n    features = base(inp)\n    x = tf.keras.layers.Dropout(0.3)(features)\n    x = tf.keras.layers.Dense(32, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.Model(inputs=inp, outputs=[x, features])\n\n    opt = tf.optimizers.Adam(learning_rate=1e-4)\n    \n    model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:43:12.869914Z","iopub.execute_input":"2021-12-27T06:43:12.870567Z","iopub.status.idle":"2021-12-27T06:43:12.885104Z","shell.execute_reply.started":"2021-12-27T06:43:12.870506Z","shell.execute_reply":"2021-12-27T06:43:12.883827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom glob import glob\n\nBASE_DIRS = [\n    (384, '/kaggle/input/petfinder-baseline-swt-174358-tfio', '/kaggle/input/petfinder-baseline-swt-174358-svr-all'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    # svr_paths = sorted(glob(os.path.join(svr_dir, 'svr-fold*.h5')))\n    svr_default_paths = [os.path.join(svr_dir, f'svr-fold{i}.h5') for i in range(5)]\n    svr_2_paths = [os.path.join(svr_dir, f'svr-fold-2-{i}.h5') for i in range(5)]\n    svr_20_paths = [os.path.join(svr_dir, f'svr-fold-20-{i}.h5') for i in range(5)]\n    \n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_default_paths, svr_2_paths, svr_20_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\npreds_svr_2 = []\npreds_svr_20 = []\nfor dim, model_paths, svr_default_paths, svr_2_paths, svr_20_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_default_path, svr_2_path, svr_20_path in zip(model_paths, svr_default_paths, svr_2_paths, svr_20_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        # svr default\n        svr = joblib.load(svr_default_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        # svr 2\n        svr = joblib.load(svr_2_path)\n        pred_svr_2 = np.expand_dims(svr.predict(features), 1)\n        # svr 20\n        svr = joblib.load(svr_20_path)\n        pred_svr_20 = np.expand_dims(svr.predict(features), 1)\n        \n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        pred_svr_2 = pred_svr_2[:len(test_paths), :]\n        pred_svr_20 = pred_svr_20[:len(test_paths), :]\n        \n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        preds_svr_2.append(pred_svr_2) # denormalizing from [0-1] to [0-100]\n        preds_svr_20.append(pred_svr_20) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_384 = np.mean(preds, axis=0)\npreds_384_svr = np.mean(preds_svr, axis=0)\npreds_384_svr_2 = np.mean(preds_svr_2, axis=0)\npreds_384_svr_20 = np.mean(preds_svr_20, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:44:55.583892Z","iopub.execute_input":"2021-12-27T06:44:55.584278Z","iopub.status.idle":"2021-12-27T06:48:03.257537Z","shell.execute_reply.started":"2021-12-27T06:44:55.584236Z","shell.execute_reply":"2021-12-27T06:48:03.256424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\nBASE_DIRS = [\n    (384, '/kaggle/input/petfinder-baseline-swt-173328-soft', '/kaggle/input/petfinder-baseline-swt-173328-svr-all'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    # svr_paths = sorted(glob(os.path.join(svr_dir, 'svr-fold*.h5')))\n    svr_default_paths = [os.path.join(svr_dir, f'svr-fold{i}.h5') for i in range(5)]\n    svr_2_paths = [os.path.join(svr_dir, f'svr-fold-2-{i}.h5') for i in range(5)]\n    svr_20_paths = [os.path.join(svr_dir, f'svr-fold-20-{i}.h5') for i in range(5)]\n    \n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_default_paths, svr_2_paths, svr_20_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\npreds_svr_2 = []\npreds_svr_20 = []\nfor dim, model_paths, svr_default_paths, svr_2_paths, svr_20_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_default_path, svr_2_path, svr_20_path in zip(model_paths, svr_default_paths, svr_2_paths, svr_20_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        # svr default\n        svr = joblib.load(svr_default_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        # svr 2\n        svr = joblib.load(svr_2_path)\n        pred_svr_2 = np.expand_dims(svr.predict(features), 1)\n        # svr 20\n        svr = joblib.load(svr_20_path)\n        pred_svr_20 = np.expand_dims(svr.predict(features), 1)\n        \n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        pred_svr_2 = pred_svr_2[:len(test_paths), :]\n        pred_svr_20 = pred_svr_20[:len(test_paths), :]\n        \n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        preds_svr_2.append(pred_svr_2) # denormalizing from [0-1] to [0-100]\n        preds_svr_20.append(pred_svr_20) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_384_soft = np.mean(preds, axis=0)\npreds_384_soft_svr = np.mean(preds_svr, axis=0)\npreds_384_soft_svr_2 = np.mean(preds_svr_2, axis=0)\npreds_384_soft_svr_20 = np.mean(preds_svr_20, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:48:25.684357Z","iopub.execute_input":"2021-12-27T06:48:25.684658Z","iopub.status.idle":"2021-12-27T06:51:36.021888Z","shell.execute_reply.started":"2021-12-27T06:48:25.684626Z","shell.execute_reply":"2021-12-27T06:51:36.020773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\nBASE_DIRS = [\n    (384, '/kaggle/input/petfinder-baseline-swt1k-174402-tfio', '/kaggle/input/petfinder-baseline-swt-174402-svr-all'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    # svr_paths = sorted(glob(os.path.join(svr_dir, 'svr-fold*.h5')))\n    svr_default_paths = [os.path.join(svr_dir, f'svr-fold{i}.h5') for i in range(5)]\n    svr_2_paths = [os.path.join(svr_dir, f'svr-fold-2-{i}.h5') for i in range(5)]\n    svr_20_paths = [os.path.join(svr_dir, f'svr-fold-20-{i}.h5') for i in range(5)]\n    \n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_default_paths, svr_2_paths, svr_20_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\npreds_svr_2 = []\npreds_svr_20 = []\nfor dim, model_paths, svr_default_paths, svr_2_paths, svr_20_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_default_path, svr_2_path, svr_20_path in zip(model_paths, svr_default_paths, svr_2_paths, svr_20_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        # svr default\n        svr = joblib.load(svr_default_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        # svr 2\n        svr = joblib.load(svr_2_path)\n        pred_svr_2 = np.expand_dims(svr.predict(features), 1)\n        # svr 20\n        svr = joblib.load(svr_20_path)\n        pred_svr_20 = np.expand_dims(svr.predict(features), 1)\n        \n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        pred_svr_2 = pred_svr_2[:len(test_paths), :]\n        pred_svr_20 = pred_svr_20[:len(test_paths), :]\n        \n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        preds_svr_2.append(pred_svr_2) # denormalizing from [0-1] to [0-100]\n        preds_svr_20.append(pred_svr_20) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_384_1k = np.mean(preds, axis=0)\npreds_384_1k_svr = np.mean(preds_svr, axis=0)\npreds_384_1k_svr_2 = np.mean(preds_svr_2, axis=0)\npreds_384_1k_svr_20 = np.mean(preds_svr_20, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:53:24.462128Z","iopub.execute_input":"2021-12-27T06:53:24.462416Z","iopub.status.idle":"2021-12-27T06:56:29.956655Z","shell.execute_reply.started":"2021-12-27T06:53:24.462388Z","shell.execute_reply":"2021-12-27T06:56:29.955625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom glob import glob\n\nBASE_DIRS = [\n    (384, '/kaggle/input/petfinder-baseline-swt1k-173756-soft', '/kaggle/input/petfinder-baseline-swt1k-173756-svr2'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    svr_paths = sorted(glob(os.path.join(svr_dir, '*h5')))\n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\nfor dim, model_paths, svr_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_path in zip(model_paths, svr_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        svr = joblib.load(svr_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_384_1k_soft = np.mean(preds, axis=0)\npreds_384_1k_soft_svr = np.mean(preds_svr, axis=0)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:52:12.277937Z","iopub.status.idle":"2021-12-27T06:52:12.278375Z","shell.execute_reply.started":"2021-12-27T06:52:12.278147Z","shell.execute_reply":"2021-12-27T06:52:12.278177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ndef build_model():\n    inp = tf.keras.layers.Input(shape=[384, 384, 3])\n    base = SwinTransformer('swin_base_384', include_top=False, pretrained=False, use_tpu=False)\n    \n    features = base(inp)\n    x = tf.keras.layers.Dropout(0.3)(features)\n    x = tf.keras.layers.Dense(32, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.Model(inputs=inp, outputs=[x, features])\n\n    opt = tf.optimizers.Adam(learning_rate=1e-4)\n    \n    model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())\n\n    return model\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:58:29.001126Z","iopub.execute_input":"2021-12-27T06:58:29.001833Z","iopub.status.idle":"2021-12-27T06:58:29.012103Z","shell.execute_reply.started":"2021-12-27T06:58:29.001787Z","shell.execute_reply":"2021-12-27T06:58:29.010883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom glob import glob\n\nBASE_DIRS = [\n    (384, '/kaggle/input/petfinder-baseline-swt-base384-175904-tfio', '/kaggle/input/petfinder-baseline-swt-base384-175904-svr2'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    svr_paths = sorted(glob(os.path.join(svr_dir, '*h5')))\n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\nfor dim, model_paths, svr_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_path in zip(model_paths, svr_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        svr = joblib.load(svr_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_384_base = np.mean(preds, axis=0)\npreds_384_base_svr = np.mean(preds_svr, axis=0)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-27T06:58:29.014873Z","iopub.execute_input":"2021-12-27T06:58:29.015449Z","iopub.status.idle":"2021-12-27T07:01:02.461818Z","shell.execute_reply.started":"2021-12-27T06:58:29.015402Z","shell.execute_reply":"2021-12-27T07:01:02.460618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom glob import glob\n\nBASE_DIRS = [\n    (384, '/kaggle/input/petfinder-baseline-swt-base384-175108-soft', '/kaggle/input/petfinder-baseline-swt-base384-175108-svr2'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    svr_paths = sorted(glob(os.path.join(svr_dir, '*h5')))\n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\nfor dim, model_paths, svr_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_path in zip(model_paths, svr_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        svr = joblib.load(svr_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_384_base_soft = np.mean(preds, axis=0)\npreds_384_base_soft_svr = np.mean(preds_svr, axis=0)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:01:02.463817Z","iopub.execute_input":"2021-12-27T07:01:02.464949Z","iopub.status.idle":"2021-12-27T07:01:02.476337Z","shell.execute_reply.started":"2021-12-27T07:01:02.4649Z","shell.execute_reply":"2021-12-27T07:01:02.475041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    inp = tf.keras.layers.Input(shape=[224, 224, 3])\n    base = SwinTransformer('swin_large_224', include_top=False, pretrained=False, use_tpu=False)\n    features = base(inp)\n    x = tf.keras.layers.Dropout(0.3)(features)\n    x = tf.keras.layers.Dense(32, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.Model(inputs=inp, outputs=[x, features])\n\n    opt = tf.optimizers.Adam(learning_rate=1e-4)\n    \n    model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:01:02.478307Z","iopub.execute_input":"2021-12-27T07:01:02.479439Z","iopub.status.idle":"2021-12-27T07:01:02.493254Z","shell.execute_reply.started":"2021-12-27T07:01:02.479392Z","shell.execute_reply":"2021-12-27T07:01:02.492108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\nBASE_DIRS = [\n    (224, '/kaggle/input/petfinder-baseline-swt224-175702-tfio', '/kaggle/input/petfinder-baseline-swt224-175702-svr-all'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    # svr_paths = sorted(glob(os.path.join(svr_dir, 'svr-fold*.h5')))\n    svr_default_paths = [os.path.join(svr_dir, f'svr-fold{i}.h5') for i in range(5)]\n    svr_2_paths = [os.path.join(svr_dir, f'svr-fold-2-{i}.h5') for i in range(5)]\n    svr_20_paths = [os.path.join(svr_dir, f'svr-fold-20-{i}.h5') for i in range(5)]\n    \n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_default_paths, svr_2_paths, svr_20_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\npreds_svr_2 = []\npreds_svr_20 = []\nfor dim, model_paths, svr_default_paths, svr_2_paths, svr_20_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_default_path, svr_2_path, svr_20_path in zip(model_paths, svr_default_paths, svr_2_paths, svr_20_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        # svr default\n        svr = joblib.load(svr_default_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        # svr 2\n        svr = joblib.load(svr_2_path)\n        pred_svr_2 = np.expand_dims(svr.predict(features), 1)\n        # svr 20\n        svr = joblib.load(svr_20_path)\n        pred_svr_20 = np.expand_dims(svr.predict(features), 1)\n        \n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        pred_svr_2 = pred_svr_2[:len(test_paths), :]\n        pred_svr_20 = pred_svr_20[:len(test_paths), :]\n        \n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        preds_svr_2.append(pred_svr_2) # denormalizing from [0-1] to [0-100]\n        preds_svr_20.append(pred_svr_20) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_224 = np.mean(preds, axis=0)\npreds_224_svr = np.mean(preds_svr, axis=0)\npreds_224_svr_2 = np.mean(preds_svr_2, axis=0)\npreds_224_svr_20 = np.mean(preds_svr_20, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:01:02.497307Z","iopub.execute_input":"2021-12-27T07:01:02.497772Z","iopub.status.idle":"2021-12-27T07:03:59.941111Z","shell.execute_reply.started":"2021-12-27T07:01:02.497694Z","shell.execute_reply":"2021-12-27T07:03:59.939884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom glob import glob\n\nBASE_DIRS = [\n    (224, '/kaggle/input/petfinder-baseline-swt224-174820-soft', '/kaggle/input/petfinder-baseline-swt224-174820-svr2'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    svr_paths = sorted(glob(os.path.join(svr_dir, '*h5')))\n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\nfor dim, model_paths, svr_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_path in zip(model_paths, svr_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        svr = joblib.load(svr_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_224_soft = np.mean(preds, axis=0)\npreds_224_soft_svr = np.mean(preds_svr, axis=0)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:03:59.943854Z","iopub.execute_input":"2021-12-27T07:03:59.944741Z","iopub.status.idle":"2021-12-27T07:03:59.965615Z","shell.execute_reply.started":"2021-12-27T07:03:59.944664Z","shell.execute_reply":"2021-12-27T07:03:59.964437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_func(filename, image_size):\n    img = tf.io.read_file(filename)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.keras.preprocessing.image.smart_resize(img, [image_size, image_size], interpolation='bilinear')\n    \n    img = tf.cast(img, tf.float32)\n    img = vit.preprocess_inputs(img)\n    \n    img = tf.reshape(img, [image_size, image_size, 3])\n    return img\n\n\ndef get_dataset(files, image_size, batch_size=BATCH_SIZE, aug=False):\n    \n    # ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = tf.data.Dataset.from_tensor_slices(files)\n    ds = ds.cache()\n    \n    ds = ds.map(lambda x: parse_func(x, image_size), num_parallel_calls=AUTO)\n    \n    \"\"\"\n    if aug:\n        ds = ds.map(augment, num_parallel_calls=AUTO)\n    \"\"\"\n    \n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:03:59.96752Z","iopub.execute_input":"2021-12-27T07:03:59.968215Z","iopub.status.idle":"2021-12-27T07:03:59.979943Z","shell.execute_reply.started":"2021-12-27T07:03:59.968066Z","shell.execute_reply":"2021-12-27T07:03:59.97842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    inp = tf.keras.layers.Input(shape=[384, 384, 3])\n    base = getattr(vit, 'vit_l16')(image_size=384, include_top=False, pretrained_top=False, pretrained=False, weights='imagenet21k+imagenet2012')\n    features = base(inp)\n    x = tf.keras.layers.Dropout(0.3)(features)\n    x = tf.keras.layers.Dense(32, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.Model(inputs=inp, outputs=[x, features])\n\n    opt = tf.optimizers.Adam(learning_rate=1e-4)\n    \n    model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:03:59.98249Z","iopub.execute_input":"2021-12-27T07:03:59.983486Z","iopub.status.idle":"2021-12-27T07:03:59.996821Z","shell.execute_reply.started":"2021-12-27T07:03:59.983441Z","shell.execute_reply":"2021-12-27T07:03:59.995112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\nBASE_DIRS = [\n    (384, '/kaggle/input/petfinder-baseline-vit-176180-tfio', '/kaggle/input/petfinder-baseline-swt-176180-svr-all'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    # svr_paths = sorted(glob(os.path.join(svr_dir, 'svr-fold*.h5')))\n    svr_default_paths = [os.path.join(svr_dir, f'svr-fold{i}.h5') for i in range(5)]\n    svr_2_paths = [os.path.join(svr_dir, f'svr-fold-2-{i}.h5') for i in range(5)]\n    svr_20_paths = [os.path.join(svr_dir, f'svr-fold-20-{i}.h5') for i in range(5)]\n    \n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_default_paths, svr_2_paths, svr_20_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\npreds_svr_2 = []\npreds_svr_20 = []\nfor dim, model_paths, svr_default_paths, svr_2_paths, svr_20_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_default_path, svr_2_path, svr_20_path in zip(model_paths, svr_default_paths, svr_2_paths, svr_20_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        # svr default\n        svr = joblib.load(svr_default_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        # svr 2\n        svr = joblib.load(svr_2_path)\n        pred_svr_2 = np.expand_dims(svr.predict(features), 1)\n        # svr 20\n        svr = joblib.load(svr_20_path)\n        pred_svr_20 = np.expand_dims(svr.predict(features), 1)\n        \n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        pred_svr_2 = pred_svr_2[:len(test_paths), :]\n        pred_svr_20 = pred_svr_20[:len(test_paths), :]\n        \n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        preds_svr_2.append(pred_svr_2) # denormalizing from [0-1] to [0-100]\n        preds_svr_20.append(pred_svr_20) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_vit_384 = np.mean(preds, axis=0)\npreds_vit_384_svr = np.mean(preds_svr, axis=0)\npreds_vit_384_svr_2 = np.mean(preds_svr_2, axis=0)\npreds_vit_384_svr_20 = np.mean(preds_svr_20, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:03:59.998862Z","iopub.execute_input":"2021-12-27T07:03:59.999373Z","iopub.status.idle":"2021-12-27T07:06:42.000726Z","shell.execute_reply.started":"2021-12-27T07:03:59.99931Z","shell.execute_reply":"2021-12-27T07:06:41.999619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom glob import glob\n\nBASE_DIRS = [\n    (384, '/kaggle/input/petfinder-baseline-vit-175046-soft', '/kaggle/input/petfinder-baseline-vit-175046-svr2'),\n]\n\nMODEL_CONFIGS = []\nfor dim, base_dir, svr_dir in  BASE_DIRS:\n    paths = sorted(glob(os.path.join(base_dir, '*h5')))\n    svr_paths = sorted(glob(os.path.join(svr_dir, '*h5')))\n    if len(paths)==0:\n        print('no model found for :',base_dir)\n        \n    MODEL_CONFIGS.append([dim, paths, svr_paths])\n\nprint('='*35)\nprint('### Inference')\nprint('='*35)\npreds=[]\npreds_svr = []\nfor dim, model_paths, svr_paths in tqdm(MODEL_CONFIGS):\n    test_paths = test_df.image_path.tolist()\n    dtest = get_dataset(test_paths, dim)\n    \n    for model_path, svr_path in zip(model_paths, svr_paths):\n        print(f'Model: {model_path}')\n        \n        with strategy.scope():\n            model = build_model()\n            model.load_weights(model_path)\n            # model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n            \n        print('Predicting...');\n        pred, features = model.predict(dtest, verbose=1)\n        \n        svr = joblib.load(svr_path)\n        pred_svr = np.expand_dims(svr.predict(features), 1)\n        \n        pred = pred[:len(test_paths),:]\n        pred_svr = pred_svr[:len(test_paths), :]\n        \n        preds.append(pred*100.0) # denormalizing from [0-1] to [0-100]\n        preds_svr.append(pred_svr) # denormalizing from [0-1] to [0-100]\n        print()\n        \npreds_vit_384_soft = np.mean(preds, axis=0)\npreds_vit_384_soft_svr = np.mean(preds_svr, axis=0)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:06:42.00277Z","iopub.execute_input":"2021-12-27T07:06:42.003764Z","iopub.status.idle":"2021-12-27T07:06:42.014864Z","shell.execute_reply.started":"2021-12-27T07:06:42.003703Z","shell.execute_reply":"2021-12-27T07:06:42.013433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ncolumns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n\nfeatures = np.stack([\n    np.squeeze(preds_384),\n    np.squeeze(preds_384_svr),\n    np.squeeze(preds_384_svr_2),\n    np.squeeze(preds_384_svr_20),\n    \n    np.squeeze(preds_384_soft),\n    np.squeeze(preds_384_soft_svr),\n    np.squeeze(preds_384_soft_svr_2),\n    np.squeeze(preds_384_soft_svr_20),\n    \n    np.squeeze(preds_384_1k),\n    np.squeeze(preds_384_1k_svr),\n    np.squeeze(preds_384_1k_svr_2),\n    np.squeeze(preds_384_1k_svr_20),\n    \n    # np.squeeze(preds_384_1k_soft),\n    # np.squeeze(preds_384_1k_soft_svr),\n    \n    np.squeeze(preds_224),\n    np.squeeze(preds_224_svr),\n    np.squeeze(preds_224_svr_2),\n    np.squeeze(preds_224_svr_20),\n    \n    # np.squeeze(preds_224_soft),\n    # np.squeeze(preds_224_soft_svr),\n    \n    # np.squeeze(preds_384_base),\n    # np.squeeze(preds_384_base_svr),\n    \n    # np.squeeze(preds_384_base_soft),\n    # np.squeeze(preds_384_base_soft_svr),\n    \n    np.squeeze(preds_vit_384),\n    np.squeeze(preds_vit_384_svr),\n    np.squeeze(preds_vit_384_svr_2),\n    np.squeeze(preds_vit_384_svr_20),\n\n    # np.squeeze(preds_vit_384_soft),\n    # np.squeeze(preds_vit_384_soft_svr),\n    \n    np.squeeze(preds_cait_384), \n    np.squeeze(preds_cait_448), \n\n    ], axis=1)\n\nfeatures = np.concatenate([features, test_df[columns].values], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:06:42.017057Z","iopub.execute_input":"2021-12-27T07:06:42.018054Z","iopub.status.idle":"2021-12-27T07:06:42.035388Z","shell.execute_reply.started":"2021-12-27T07:06:42.017964Z","shell.execute_reply":"2021-12-27T07:06:42.033872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_head = joblib.load('../input/petfinder-final-lr-170275/final-lr-170275.h5')\npreds = lr_head.predict(features)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:06:42.037544Z","iopub.execute_input":"2021-12-27T07:06:42.038225Z","iopub.status.idle":"2021-12-27T07:06:42.062395Z","shell.execute_reply.started":"2021-12-27T07:06:42.03803Z","shell.execute_reply":"2021-12-27T07:06:42.061351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = pd.DataFrame({'Id':test_df.Id,\n                        'Pawpularity':preds.reshape(-1)})\nsub_df = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')\ndel sub_df['Pawpularity']\nsub_df = sub_df.merge(pred_df, on='Id', how='left')\nsub_df.to_csv('submission.csv',index=False)\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:06:42.06399Z","iopub.execute_input":"2021-12-27T07:06:42.065167Z","iopub.status.idle":"2021-12-27T07:06:42.110349Z","shell.execute_reply.started":"2021-12-27T07:06:42.065105Z","shell.execute_reply":"2021-12-27T07:06:42.10913Z"},"trusted":true},"execution_count":null,"outputs":[]}]}