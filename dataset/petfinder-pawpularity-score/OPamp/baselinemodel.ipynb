{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CNNと表を組み合わせて考えられないか？\n\nMobileNetとニューラルネットワークを最後の層で結合することで問題の解答を実現する試み","metadata":{}},{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:20:56.19514Z","iopub.execute_input":"2021-10-06T09:20:56.19554Z","iopub.status.idle":"2021-10-06T09:21:04.169051Z","shell.execute_reply.started":"2021-10-06T09:20:56.195491Z","shell.execute_reply":"2021-10-06T09:21:04.168105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport random\nimport time\nimport warnings\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport transformers as T\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport torchvision.models as models\nimport timm\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed = 2021\nseed_torch(seed)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:21:04.172937Z","iopub.execute_input":"2021-10-06T09:21:04.173188Z","iopub.status.idle":"2021-10-06T09:21:10.354973Z","shell.execute_reply.started":"2021-10-06T09:21:04.173147Z","shell.execute_reply":"2021-10-06T09:21:10.354085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\ntest_df = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:21:10.35643Z","iopub.execute_input":"2021-10-06T09:21:10.356687Z","iopub.status.idle":"2021-10-06T09:21:10.398814Z","shell.execute_reply.started":"2021-10-06T09:21:10.356647Z","shell.execute_reply":"2021-10-06T09:21:10.398032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelの構築\nResNetを基礎として利用","metadata":{}},{"cell_type":"code","source":"class Create_Model(nn.Module):\n    def __init__(self):\n        super(Create_Model,self).__init__()\n        self.swin = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True,num_classes=0, in_chans=3)\n        num_features = self.swin.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features, 1)\n        )\n    def forward(self,x,xx):\n        x = self.swin(x)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:21:10.400649Z","iopub.execute_input":"2021-10-06T09:21:10.400875Z","iopub.status.idle":"2021-10-06T09:21:10.409653Z","shell.execute_reply.started":"2021-10-06T09:21:10.400849Z","shell.execute_reply":"2021-10-06T09:21:10.408634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torchvision.models as models\nclass Pawpularity_Net(nn.Module):\n    def __init__(self):\n        super(Pawpularity_Net , self).__init__()\n        self.model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True,num_classes=0, in_chans=3)\n        num_features = self.model.num_features\n        #self.model   = nn.Sequential(*list(model.children())[:-1])\n        #self.layer_1 = nn.Linear(12,100)\n        #self.bn1     = nn.BatchNorm1d(100)\n        #self.layer_2 = nn.Linear(100,100)\n        #self.bn2     = nn.BatchNorm1d(100)\n        #self.layer_3 = nn.Linear(2148 , 500)\n        #self.bn3     = nn.BatchNorm1d(500)\n        self.last_layer = nn.Linear(num_features, 1)\n    \n    def forward(self,x1,x2):\n        x1 = self.model(x1)\n        #x1 = x1.view(x1.shape[0],-1)\n        #x2 = F.relu(self.layer_1(x2))\n        #x2 = F.relu(self.layer_2(x2))\n        #x = torch.cat([x1,x2],dim = 1)\n        #x = F.relu(self.layer_3(x))\n        #x = self.last_layer(x)\n        x = self.last_layer(F.relu(x1))\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:21:10.411426Z","iopub.execute_input":"2021-10-06T09:21:10.411849Z","iopub.status.idle":"2021-10-06T09:21:10.420009Z","shell.execute_reply.started":"2021-10-06T09:21:10.411809Z","shell.execute_reply":"2021-10-06T09:21:10.419106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\nfrom PIL import Image \nimport torchvision.transforms as T\nfrom tqdm import tqdm\n\ndef get_transforms(key):\n    transforms = {'train':T.Compose([\n                            T.RandomHorizontalFlip(),\n                            T.RandomVerticalFlip(),\n                            T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                            T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                            T.Resize(256),\n                            T.CenterCrop(224),\n                            T.ToTensor(),\n                            T.Normalize(\n                                mean=[0.485, 0.456, 0.406],\n                                std=[0.229, 0.224, 0.225])\n                            ]),\n                           'val':T.Compose([\n                            T.Resize(256),\n                            T.CenterCrop(224),\n                            T.ToTensor(),\n                            T.Normalize(\n                                mean=[0.485, 0.456, 0.406],\n                                std=[0.229, 0.224, 0.225])\n                            ])}\n    \n    return transforms[key]\n\n\n\n        \nclass CustomDataSet(Dataset):\n    def __init__(self,df,img_pth,is_test=False,now = 'val'):\n        self.img_list =  torch.load(img_pth)\n        self.table_list = df[df.columns[1:13]]\n        self.label_list = df[df.columns[-1]].to_list()\n        self.preprocess = get_transforms(now)\n        self.is_test = is_test\n        \n\n            \n    def __getitem__(self,idx):\n        \n        #if self.is_test is not True:\n        #    path = \"/kaggle/input/petfinder-pawpularity-score/train/\"+self.img_list[idx]+'.jpg'\n        #else:\n        #    path = \"/kaggle/input/petfinder-pawpularity-score/test/\"+self.img_list[idx]+'.jpg'\n        t1 = time.time()\n        #img = Image.open(path).convert('RGB')\n        img = self.img_list[idx]\n        t2 = time.time()\n        #print(f'読み出し:{t2 - t1}')\n        read_time = t2 - t1\n        t1 = time.time()\n        \n        #img = self.preprocess(img)\n        t2 = time.time()\n        \n        \n        #print(f'変換:{t2 - t1}')\n        trans_time = t2 - t1\n        \n        t1 = time.time()\n        tbl = torch.tensor(list(self.table_list.iloc[idx])).to(torch.float32)\n        t2 = time.time()\n        \n        tbl_time = t2 - t1\n        \n        #print(f'テーブル変換:{t2 - t1}')\n        t1 = time.time()\n        label = torch.tensor(self.label_list[idx]/100).to(torch.float32)\n        t2 = time.time()\n        #print(f'ラベル:{t2 - t1}')\n        label_time = t2 - t1\n        \n        sum_time = read_time + trans_time + tbl_time + label_time\n        \n        #print(f'画像読み出し：{read_time/sum_time*100} 画像変換:{trans_time/sum_time*100} テーブル変換:{tbl_time/sum_time*100} ラベル変換:{label_time/sum_time*100} 合計時間:{sum_time}')\n        \n        if self.is_test is not True:\n            return img,tbl,label\n        else:\n            return img,tbl\n    def __len__(self):\n        return len(self.img_list)\n\n    def __del__(self):\n        del self.img_list \n        del self.table_list\n        del self.label_list\n        del self.preprocess\n        del self.is_test \n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:21:10.421763Z","iopub.execute_input":"2021-10-06T09:21:10.422307Z","iopub.status.idle":"2021-10-06T09:21:10.442209Z","shell.execute_reply.started":"2021-10-06T09:21:10.422266Z","shell.execute_reply":"2021-10-06T09:21:10.441378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_list(img_list,types='train'):\n    preprocess = get_transforms('val')\n    print('make dataset...')\n    tensor_block = [preprocess(Image.open(f\"/kaggle/input/petfinder-pawpularity-score/{types}/\"+img_list[i]+'.jpg').convert('RGB')) for i in range(len(img_list))]\n    \n    return tensor_block\n    \n            ","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:21:10.443584Z","iopub.execute_input":"2021-10-06T09:21:10.443956Z","iopub.status.idle":"2021-10-06T09:21:10.456208Z","shell.execute_reply.started":"2021-10-06T09:21:10.443917Z","shell.execute_reply":"2021-10-06T09:21:10.455194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLD_NUM = 5","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:21:10.457783Z","iopub.execute_input":"2021-10-06T09:21:10.458147Z","iopub.status.idle":"2021-10-06T09:21:10.465003Z","shell.execute_reply.started":"2021-10-06T09:21:10.458051Z","shell.execute_reply":"2021-10-06T09:21:10.464099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 損失関数をMSELossからnn.BCEWithLogitsLossに変更\n最強らしい","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.model_selection import KFold\nimport torch.optim as opt\nimport numpy as np\nimport time\nimport gc\n\nkf = KFold(n_splits=FOLD_NUM, random_state=None, shuffle=False)\n\nBATCH_SIZE = 96\nEPOCH = 50\nDEVICE = 'cuda'\nSTOP_NUM = 3\ncriterion_mse = nn.MSELoss()\ncriterion_bce = nn.BCEWithLogitsLoss()\n\nval_dataset = None\ntrain_dataset = None\ntrain_loader = None\nval_loader = None\ndel train_dataset\ndel val_dataset\ndel train_loader\ndel val_loader\n\ngc.collect()\n\nfor k,(train_index, test_index) in enumerate(kf.split(train_df['Id'])):\n    print(f\"========={k+1}-FOLD=========\")\n    model = Create_Model().to(DEVICE)\n    val_dataset = None\n    train_dataset = None\n    train_loader = None\n    val_loader = None\n    \n    train_dataset = CustomDataSet(train_df.loc[train_index],f\"../input/petfinder-fold-dataset/{k+1}_fold_train.pth\")\n    val_dataset = CustomDataSet(train_df.loc[test_index],f\"../input/petfinder-fold-dataset/{k+1}_fold_val.pth\")\n    train_loader = DataLoader(train_dataset,batch_size = BATCH_SIZE,shuffle = True,num_workers = 8)\n    val_loader = DataLoader(val_dataset,batch_size = BATCH_SIZE,shuffle = False,num_workers = 8)\n   \n\n    \n    optimizer = opt.AdamW(params = model.parameters(),lr = 1e-5)\n    scheduler = opt.lr_scheduler.CosineAnnealingWarmRestarts(optimizer , 100 , eta_min=1e-4)\n    best_loss = 99999\n    stop_counter = 0\n    \n    for e in range(EPOCH):\n        model.train()\n        train_total_loss = 0\n        train_score = 0\n        counter = 0\n        \n        for n,(img,tbl,label) in enumerate(train_loader):\n            img = img.to(DEVICE)\n            tbl = tbl.to(DEVICE)\n            label = label.to(DEVICE)\n            optimizer.zero_grad()\n            \n            output = model(img,tbl)[:,0]\n            \n            loss = criterion_bce(output , label)\n            score = criterion_mse(F.sigmoid(output)*100 , label*100).detach()\n            \n            \n            train_total_loss = (train_total_loss * n + loss.detach().item())/(n+1)\n            train_score =  (train_score * counter + score.item()*output.shape[0])/(counter + output.shape[0])\n            \n            counter += output.shape[0]\n            loss.backward()\n            optimizer.step()\n            print('\\rTRAIN EPOCH[{:03}/{:03}] ITR[{:04}/{:04}] LOSS:{:.5} SCORE:{:.5}'.format(e+1,EPOCH,n+1,len(train_loader),train_total_loss,np.sqrt(train_score)),end = \"\")\n        scheduler.step()\n        print()\n        val_total_loss = 0\n        val_score = 0\n        counter = 0\n        model.eval()\n        with torch.no_grad():\n            for n,(img,tbl,label) in enumerate(val_loader):\n                img = img.to(DEVICE)\n                tbl = tbl.to(DEVICE)\n                label = label.to(DEVICE)\n            \n                output = model(img,tbl)[:,0]\n\n                loss = criterion_bce(output , label)\n                score = criterion_mse(F.sigmoid(output)*100 , label*100).detach()\n                \n                \n                val_total_loss = (val_total_loss * n + loss.item())/(n+1)\n                \n                val_score =  (val_score * counter + score.item()*output.shape[0])/(counter + output.shape[0])\n                \n                counter += output.shape[0]\n                print('\\rVAL   EPOCH[{:03}/{:03}] ITR[{:04}/{:04}] LOSS:{:.5} SCORE:{:.5}'.format(e+1,EPOCH,n+1,len(val_loader),val_total_loss,np.sqrt(val_score)),end = \"\")\n        print()\n        if(best_loss > val_total_loss):\n            best_loss = val_total_loss\n            model_path = f'{k+1}-fold.pth'\n            torch.save(model.state_dict(), model_path)\n            stop_counter = 0\n        else:\n            stop_counter += 1\n        if stop_counter >= STOP_NUM:\n            break\n    \n    del train_dataset\n    del val_dataset\n    del train_loader\n    del val_loader\n    \n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:25:53.393262Z","iopub.execute_input":"2021-10-06T09:25:53.393736Z","iopub.status.idle":"2021-10-06T09:36:08.99803Z","shell.execute_reply.started":"2021-10-06T09:25:53.393694Z","shell.execute_reply":"2021-10-06T09:36:08.995334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\nprint(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\nprint(\" ------------------------------------ \")\nfor var_name in dir():\n    if not var_name.startswith(\"_\"):\n        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.265357Z","iopub.status.idle":"2021-10-06T09:23:29.265669Z","shell.execute_reply.started":"2021-10-06T09:23:29.26551Z","shell.execute_reply":"2021-10-06T09:23:29.26553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = None\nval_dataset = None","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.26679Z","iopub.status.idle":"2021-10-06T09:23:29.267207Z","shell.execute_reply.started":"2021-10-06T09:23:29.266987Z","shell.execute_reply":"2021-10-06T09:23:29.26701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntest_dataset = CustomDataSet(test_df,is_test = True)\ntest_loader = DataLoader(test_dataset,batch_size = 2,shuffle = False)\nwith torch.no_grad():\n    fold_output = [[] for x in range(FOLD_NUM)]\n    for k in range(FOLD_NUM):\n        model = Pawpularity_Net().to(DEVICE)\n        model_path = f'{k+1}-fold.pth'\n        model.load_state_dict(torch.load(model_path))\n        for n,(img,tbl) in enumerate(test_loader):\n            img = img.to(DEVICE)\n            tbl = tbl.to(DEVICE)\n            output = model(img,tbl).cpu()[:,0]\n            fold_output[k].append(F.sigmoid(output)*100)\n            print('\\r TEST FOLD[{:02}/{:02}]  ITR[{:03}/{:03}]'.format(k+1,FOLD_NUM,n+1,len(test_loader)),end = \"\")\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.268858Z","iopub.status.idle":"2021-10-06T09:23:29.269463Z","shell.execute_reply.started":"2021-10-06T09:23:29.269195Z","shell.execute_reply":"2021-10-06T09:23:29.269222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfor k in range(len(fold_output)):\n    fold_output[k] = torch.cat(fold_output[k],dim = 0).numpy()\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.270483Z","iopub.status.idle":"2021-10-06T09:23:29.271351Z","shell.execute_reply.started":"2021-10-06T09:23:29.271071Z","shell.execute_reply":"2021-10-06T09:23:29.271098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#list(np.mean(np.array(fold_output),axis = 0))","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.272437Z","iopub.status.idle":"2021-10-06T09:23:29.27334Z","shell.execute_reply.started":"2021-10-06T09:23:29.273036Z","shell.execute_reply":"2021-10-06T09:23:29.273063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_result = pd.DataFrame({f'Pawpularity_{i}':fold_output[i] for i in range(len(fold_output))})","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.274433Z","iopub.status.idle":"2021-10-06T09:23:29.275275Z","shell.execute_reply.started":"2021-10-06T09:23:29.274999Z","shell.execute_reply":"2021-10-06T09:23:29.275025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_result","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.276373Z","iopub.status.idle":"2021-10-06T09:23:29.277127Z","shell.execute_reply.started":"2021-10-06T09:23:29.27687Z","shell.execute_reply":"2021-10-06T09:23:29.276896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_sub = pd.concat([train_df['Id'] , df_result],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.278282Z","iopub.status.idle":"2021-10-06T09:23:29.27908Z","shell.execute_reply.started":"2021-10-06T09:23:29.278817Z","shell.execute_reply":"2021-10-06T09:23:29.278843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.280309Z","iopub.status.idle":"2021-10-06T09:23:29.281211Z","shell.execute_reply.started":"2021-10-06T09:23:29.280913Z","shell.execute_reply":"2021-10-06T09:23:29.28094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainデータに対する予測結果を出力","metadata":{}},{"cell_type":"code","source":"\"\"\"\nfrom sklearn.model_selection import KFold\nimport torch.optim as opt\nimport numpy as np\n\n\nkf = KFold(n_splits=FOLD_NUM, random_state=None, shuffle=False)\n\nBATCH_SIZE = 256\nEPOCH = 5\nDEVICE = 'cuda'\n\n\ntest_dataset = CustomDataSet(train_df)\ntest_loader = DataLoader(test_dataset,batch_size = BATCH_SIZE,shuffle = False,num_workers=2)\nwith torch.no_grad():\n    fold_output = [[] for x in range(FOLD_NUM)]\n    for k in range(FOLD_NUM):\n        model = Pawpularity_Net().to(DEVICE)\n        model_path = f'../input/bceleaningresult/{k+1}-fold.pth'\n        model.load_state_dict(torch.load(model_path))\n        for n,(img,tbl,label) in enumerate(test_loader):\n            img = img.to(DEVICE)\n            tbl = tbl.to(DEVICE)\n            output = model(img,tbl).cpu()[:,0]\n            fold_output[k].append(F.sigmoid(output)*100)\n            print('\\r TEST FOLD[{:02}/{:02}]  ITR[{:03}/{:03}]'.format(k+1,FOLD_NUM,n+1,len(test_loader)),end = \"\")\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.282391Z","iopub.status.idle":"2021-10-06T09:23:29.283131Z","shell.execute_reply.started":"2021-10-06T09:23:29.28288Z","shell.execute_reply":"2021-10-06T09:23:29.282905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DatasetLoaderの速度確認","metadata":{}},{"cell_type":"code","source":"\"\"\"\nfrom sklearn.model_selection import KFold\nimport torch.optim as opt\nimport numpy as np\nfrom tqdm import tqdm\nimport time\n\nFOLD_NUM = 5\nBATCH_SIZE = 32\nEPOCH = 5\nDEVICE = 'cuda'\nkf = KFold(n_splits=FOLD_NUM, random_state=None, shuffle=False)\n\n\ncriterion_mse = nn.MSELoss(reduction = 'mean' )\ncriterion_bce = nn.BCEWithLogitsLoss()\n\nfor k,(train_index, test_index) in enumerate(kf.split(train_df['Id'])):\n    train_dataset = CustomDataSet(train_df.loc[train_index])\n    train_loader = DataLoader(train_dataset,batch_size = BATCH_SIZE,shuffle = True,num_workers=2)\n    print(f\"========={k}-FOLD=========len:{len(train_loader)}\")\n    print(f\"Datanum:{BATCH_SIZE*len(train_loader)}\")\n    start = time.time()\n    for n,(img,tbl,label) in enumerate(tqdm(train_loader)):\n        pass\n    end = time.time()\n    print(end -start)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.284364Z","iopub.status.idle":"2021-10-06T09:23:29.285238Z","shell.execute_reply.started":"2021-10-06T09:23:29.284935Z","shell.execute_reply":"2021-10-06T09:23:29.284962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.load(\"../input/petfinder-fold-dataset/1_fold_train.pth\")","metadata":{"execution":{"iopub.status.busy":"2021-10-06T09:23:29.286397Z","iopub.status.idle":"2021-10-06T09:23:29.287314Z","shell.execute_reply.started":"2021-10-06T09:23:29.287039Z","shell.execute_reply":"2021-10-06T09:23:29.287065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}