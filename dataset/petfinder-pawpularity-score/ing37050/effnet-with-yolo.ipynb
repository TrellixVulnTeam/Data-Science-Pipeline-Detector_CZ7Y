{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Any comments or advice would be appreciated :)","metadata":{}},{"cell_type":"markdown","source":"## Using Effnet with YOLO (Keras)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as tfl\nfrom tensorflow.keras import regularizers\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.cluster import KMeans\n\nimport os\nfrom multiprocessing import cpu_count\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import pearsonr\nfrom PIL import Image\n\nimport glob\nimport sys\nimport cv2\nimport imageio\nimport joblib\nimport math\nimport warnings\nimport torch\nimport imagehash\nfrom sklearn.cluster import KMeans\nfrom collections import Counter\nfrom skimage.color import rgb2lab, deltaE_cie76\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntqdm.pandas()\nnp.random.seed(0)\ntf.random.set_seed(0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T02:45:35.497445Z","iopub.execute_input":"2021-12-22T02:45:35.497918Z","iopub.status.idle":"2021-12-22T02:45:44.317621Z","shell.execute_reply.started":"2021-12-22T02:45:35.497825Z","shell.execute_reply":"2021-12-22T02:45:44.316764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the original file\n# train = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\n# train['path'] = '../input/petfinder-pawpularity-score/train/' + train['Id'] + '.jpg'\n# train.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:13:24.811326Z","iopub.execute_input":"2021-12-21T17:13:24.811615Z","iopub.status.idle":"2021-12-21T17:13:24.874908Z","shell.execute_reply.started":"2021-12-21T17:13:24.811585Z","shell.execute_reply":"2021-12-21T17:13:24.874199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\ntest['path'] = '../input/petfinder-pawpularity-score/test/' + test['Id'] + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:21:54.936386Z","iopub.execute_input":"2021-12-21T17:21:54.937284Z","iopub.status.idle":"2021-12-21T17:21:54.947433Z","shell.execute_reply.started":"2021-12-21T17:21:54.93724Z","shell.execute_reply":"2021-12-21T17:21:54.946585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature pre-extracted file - to save time. (R,G,B columns are not used in this notebook)\ntrain = pd.read_csv('../input/train-final/train_final.csv')\ntrain = train.drop('Unnamed: 0', axis=1)\ntrain['path'] = '../input/petfinder-pawpularity-score/train/' + train['Id'] + '.jpg'\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:21:55.243726Z","iopub.execute_input":"2021-12-21T17:21:55.244396Z","iopub.status.idle":"2021-12-21T17:21:55.322931Z","shell.execute_reply.started":"2021-12-21T17:21:55.244358Z","shell.execute_reply":"2021-12-21T17:21:55.321943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### YOLOv5 \n- get more meta data from the images","metadata":{}},{"cell_type":"code","source":"# importing yolov5 without internet \n!mkdir /root/.config/Ultralytics/\n!cp ../input/yolo-arial/Arial.ttf /root/.config/Ultralytics/Arial.ttf\nyolov5x6_model = torch.hub.load('../input/d/nilavanakilan/yolov5/', 'custom', source='local', force_reload=True, path='../input/ultralyticsyolov5aweights/yolov5x6.pt')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:14:20.013732Z","iopub.execute_input":"2021-12-21T17:14:20.014436Z","iopub.status.idle":"2021-12-21T17:14:34.116407Z","shell.execute_reply.started":"2021-12-21T17:14:20.014399Z","shell.execute_reply":"2021-12-21T17:14:34.115604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get Image Info\ndef get_image_info(file_path, plot=False):\n    # Read Image\n    image = imageio.imread(file_path)\n    h, w, c = image.shape\n    \n    if plot: # Debug Plots\n        fig, ax = plt.subplots(1, 2, figsize=(8,8))\n        ax[0].set_title('Pets detected in Image', size=16)\n        ax[0].imshow(image)\n        \n    # Get YOLOV5 results using Test Time Augmentation for better result\n    results = yolov5x6_model(image, augment=True)\n    \n    # Mask for pixels containing pets, initially all set to zero\n    pet_pixels = np.zeros(shape=[h, w], dtype=np.uint8)\n    \n    # Dictionary to Save Image Info\n    h, w, _ = image.shape\n    image_info = { \n        'n_pets': 0, # Number of pets in the image\n        'labels': [], # Label assigned to found objects\n        'thresholds': [], # confidence score\n        'coords': [], # coordinates of bounding boxes\n        'x_min': 0, # minimum x coordinate of pet bounding box\n        'x_max': w - 1, # maximum x coordinate of pet bounding box\n        'y_min': 0, # minimum y coordinate of pet bounding box\n        'y_max': h - 1, # maximum x coordinate of pet bounding box\n    }\n    \n    # Save found pets to draw bounding boxes\n    pets_found = []\n    \n    # Save info for each pet\n    for x1, y1, x2, y2, treshold, label in results.xyxy[0].cpu().detach().numpy():\n        label = results.names[int(label)]\n        if label in ['cat', 'dog']:\n            image_info['n_pets'] += 1\n            image_info['labels'].append(label)\n            image_info['thresholds'].append(treshold)\n            image_info['coords'].append(tuple([x1, y1, x2, y2]))\n            image_info['x_min'] = max(x1, image_info['x_min'])\n            image_info['x_max'] = min(x2, image_info['x_max'])\n            image_info['y_min'] = max(y1, image_info['y_min'])\n            image_info['y_max'] = min(y2, image_info['y_max'])\n            \n            # Set pixels containing pets to 1\n            pet_pixels[int(y1):int(y2), int(x1):int(x2)] = 1\n            \n            # Add found pet\n            pets_found.append([x1, x2, y1, y2, label])\n\n    if plot:\n        for x1, x2, y1, y2, label in pets_found:\n            c = 'red' if label == 'dog' else 'blue'\n            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor=c, facecolor='none')\n            # Add the patch to the Axes\n            ax[0].add_patch(rect)\n            ax[0].text(max(25, (x2+x1)/2), max(25, y1-h*0.02), label, c=c, ha='center', size=14)\n                \n    # Add Pet Ratio in Image\n    image_info['pet_ratio'] = pet_pixels.sum() / (h*w)\n\n    if plot:\n        # Show pet pixels\n        ax[1].set_title('Pixels Containing Pets', size=16)\n        ax[1].imshow(pet_pixels)\n        plt.show()\n        \n    return image_info","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:22:03.29701Z","iopub.execute_input":"2021-12-21T17:22:03.29726Z","iopub.status.idle":"2021-12-21T17:22:03.313364Z","shell.execute_reply.started":"2021-12-21T17:22:03.297233Z","shell.execute_reply":"2021-12-21T17:22:03.312577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Image Info train\n# IMAGES_INFO = {\n#     'n_pets': [],\n#     'label': [],\n#     'coords': [],\n#     'x_min': [],\n#     'x_max': [],\n#     'y_min': [],\n#     'y_max': [],\n#     'pet_ratio': [],\n# }\n\n\n# for idx, file_path in enumerate(tqdm(train['path'])):\n#     image_info = get_image_info(file_path, plot=False)\n    \n#     IMAGES_INFO['n_pets'].append(image_info['n_pets'])\n#     IMAGES_INFO['coords'].append(image_info['coords'])\n#     IMAGES_INFO['x_min'].append(image_info['x_min'])\n#     IMAGES_INFO['x_max'].append(image_info['x_max'])\n#     IMAGES_INFO['y_min'].append(image_info['y_min'])\n#     IMAGES_INFO['y_max'].append(image_info['y_max'])\n#     IMAGES_INFO['pet_ratio'].append(image_info['pet_ratio'])\n    \n#     # Not Every Image can be Correctly Classified\n#     labels = image_info['labels']\n#     if len(set(labels)) == 1: # unanimous label\n#         IMAGES_INFO['label'].append(labels[0])\n#     elif len(set(labels)) > 1: # Get label with highest confidence\n#         IMAGES_INFO['label'].append(labels[0])\n#     else: # unknown label, yolo could not find pet\n#         IMAGES_INFO['label'].append('unknown')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:22:03.888708Z","iopub.execute_input":"2021-12-21T17:22:03.89088Z","iopub.status.idle":"2021-12-21T17:22:03.896651Z","shell.execute_reply.started":"2021-12-21T17:22:03.890841Z","shell.execute_reply":"2021-12-21T17:22:03.89576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Add Image Info to Train\n# for k, v in IMAGES_INFO.items():\n#     train[k] = v","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:22:05.14219Z","iopub.execute_input":"2021-12-21T17:22:05.142747Z","iopub.status.idle":"2021-12-21T17:22:05.146366Z","shell.execute_reply.started":"2021-12-21T17:22:05.142709Z","shell.execute_reply":"2021-12-21T17:22:05.145571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Info test\nIMAGES_INFO = {\n    'n_pets': [],\n    'label': [],\n    'coords': [],\n    'x_min': [],\n    'x_max': [],\n    'y_min': [],\n    'y_max': [],\n    'pet_ratio': [],\n}\n\n\nfor idx, file_path in enumerate(tqdm(test['path'])):\n    image_info = get_image_info(file_path, plot=False)\n    \n    IMAGES_INFO['n_pets'].append(image_info['n_pets'])\n    IMAGES_INFO['coords'].append(image_info['coords'])\n    IMAGES_INFO['x_min'].append(image_info['x_min'])\n    IMAGES_INFO['x_max'].append(image_info['x_max'])\n    IMAGES_INFO['y_min'].append(image_info['y_min'])\n    IMAGES_INFO['y_max'].append(image_info['y_max'])\n    IMAGES_INFO['pet_ratio'].append(image_info['pet_ratio'])\n    \n    # Not Every Image can be Correctly Classified\n    labels = image_info['labels']\n    if len(set(labels)) == 1: # unanimous label\n        IMAGES_INFO['label'].append(labels[0])\n    elif len(set(labels)) > 1: # Get label with highest confidence\n        IMAGES_INFO['label'].append(labels[0])\n    else: # unknown label, yolo could not find pet\n        IMAGES_INFO['label'].append('unknown')\n\n# Add Image Info to Train\nfor k, v in IMAGES_INFO.items():\n    test[k] = v","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:22:06.53604Z","iopub.execute_input":"2021-12-21T17:22:06.536299Z","iopub.status.idle":"2021-12-21T17:22:07.6532Z","shell.execute_reply.started":"2021-12-21T17:22:06.536271Z","shell.execute_reply":"2021-12-21T17:22:07.652481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess data","metadata":{}},{"cell_type":"code","source":"# to process label column\ntrain = pd.get_dummies(train, prefix='label', columns=['label'])\ntest = pd.get_dummies(test, prefix='label', columns=['label'])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:22:09.240296Z","iopub.execute_input":"2021-12-21T17:22:09.241076Z","iopub.status.idle":"2021-12-21T17:22:09.257038Z","shell.execute_reply.started":"2021-12-21T17:22:09.241027Z","shell.execute_reply":"2021-12-21T17:22:09.256313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make the number of columns same for the train and test data (test data only has 'unknown' column)\n\ndef make_columns(df):\n    for i in range(3):\n        if 'label_cat' not in df.columns:\n            df['label_cat']=0\n\n        elif 'label_dog' not in df.columns:\n            df['label_dog']=0\n\n        elif 'label_unknown' not in df.columns:\n            df['label_unknown']=0\n        \n    return df\n\ntrain = make_columns(train)\ntest = make_columns(test)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:23:47.040343Z","iopub.execute_input":"2021-12-21T17:23:47.04065Z","iopub.status.idle":"2021-12-21T17:23:47.048047Z","shell.execute_reply.started":"2021-12-21T17:23:47.040617Z","shell.execute_reply":"2021-12-21T17:23:47.047369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply MinMaxScaler\ntrain_columns = train.drop(['Id', 'path', 'coords', 'Pawpularity', 'R', 'G', 'B'], axis=1).columns \ntest_columns = test.drop(['Id', 'path', 'coords'], axis=1).columns\n\nminMaxScaler = MinMaxScaler()\n\ntrain_final = pd.DataFrame()\ntrain_final[train_columns] = pd.DataFrame(minMaxScaler.fit_transform(train.drop(['Id', 'path', 'coords', 'Pawpularity', 'R', 'G', 'B'], axis=1)))\n\ntest_final = pd.DataFrame()\ntest_final[test_columns] = pd.DataFrame(minMaxScaler.transform(test.drop(['Id', 'path', 'coords'], axis=1)))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:26:45.924065Z","iopub.execute_input":"2021-12-21T17:26:45.924317Z","iopub.status.idle":"2021-12-21T17:26:45.961489Z","shell.execute_reply.started":"2021-12-21T17:26:45.924288Z","shell.execute_reply":"2021-12-21T17:26:45.960527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_final[['Id', 'path', 'Pawpularity']] = train[['Id', 'path', 'Pawpularity']]\n# train_final[['Id', 'path']] = train[['Id', 'path']]\ntest_final[['Id', 'path']] = test[['Id', 'path']]","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:26:59.11623Z","iopub.execute_input":"2021-12-21T17:26:59.116509Z","iopub.status.idle":"2021-12-21T17:26:59.127724Z","shell.execute_reply.started":"2021-12-21T17:26:59.116478Z","shell.execute_reply":"2021-12-21T17:26:59.126909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split dataset\ntrain, val= train_test_split(train_final, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:27:34.994152Z","iopub.execute_input":"2021-12-21T17:27:34.994486Z","iopub.status.idle":"2021-12-21T17:27:35.006182Z","shell.execute_reply.started":"2021-12-21T17:27:34.994455Z","shell.execute_reply":"2021-12-21T17:27:35.005422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[['Pawpularity']].join(train.drop('Pawpularity', axis=1))\nval = val[['Pawpularity']].join(val.drop('Pawpularity', axis=1))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:30:13.91896Z","iopub.execute_input":"2021-12-21T17:30:13.919236Z","iopub.status.idle":"2021-12-21T17:30:13.936113Z","shell.execute_reply.started":"2021-12-21T17:30:13.919208Z","shell.execute_reply":"2021-12-21T17:30:13.935379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_data(path, meta, augment=False, label=True):\n    img = tf.io.decode_jpeg(tf.io.read_file(path), channels=3)\n    img = tf.cast(img, dtype=tf.float32)\n#     img = tf.image.central_crop(img, 1.0)\n    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = keras.applications.efficientnet.preprocess_input(img)\n#     img = img / 255.\n    img = tf.cast(img, dtype=tf.float64)\n    \n    if augment:\n        img = tf.image.random_flip_left_right(img)\n#         img = tf.image.random_brightness(img, 0.1)\n        img = tf.image.random_saturation(img, 0.95, 1.05)\n        img = tf.image.random_contrast(img, 0.95, 1.05)\n        \n    if label:\n        return (img, meta[1:]), meta[0]\n    return (img, meta), 0","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:30:27.894019Z","iopub.execute_input":"2021-12-21T17:30:27.894275Z","iopub.status.idle":"2021-12-21T17:30:27.901715Z","shell.execute_reply.started":"2021-12-21T17:30:27.894246Z","shell.execute_reply":"2021-12-21T17:30:27.900953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 299\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2021-12-21T19:09:56.977944Z","iopub.execute_input":"2021-12-21T19:09:56.978266Z","iopub.status.idle":"2021-12-21T19:09:56.986386Z","shell.execute_reply.started":"2021-12-21T19:09:56.97823Z","shell.execute_reply":"2021-12-21T19:09:56.985545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_ds = tf.data.Dataset.from_tensor_slices((train['path'], train.drop(['path', 'Id'], axis=1).astype(float))).map(lambda x,y: process_data(x, y, True)).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n# val_ds = tf.data.Dataset.from_tensor_slices((val['path'], val.drop(['path', 'Id'], axis=1).astype(float))).map(process_data).batch(BATCH_SIZE).prefetch(AUTOTUNE)\ntest_ds = tf.data.Dataset.from_tensor_slices((test_final['path'], test_final.drop(['path','Id'], axis=1).astype(float))).map(lambda x,y: process_data(x, y, False, False)).batch(BATCH_SIZE).prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T19:09:57.350902Z","iopub.execute_input":"2021-12-21T19:09:57.351186Z","iopub.status.idle":"2021-12-21T19:09:57.511295Z","shell.execute_reply.started":"2021-12-21T19:09:57.351155Z","shell.execute_reply":"2021-12-21T19:09:57.510477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modeling\n- Use effnetB7\n- Use metadata by concatenating\n- Use skip connection","metadata":{}},{"cell_type":"code","source":"eff_model = keras.models.load_model('../input/d/ekaterinadranitsyna/keras-applications-models/EfficientNetB7.h5')\neff_model.trainable = False\n\ndef get_model():\n    img_input = tfl.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    meta_input = tfl.Input(shape=(21,))\n\n    X = eff_model(img_input)\n    X = tfl.BatchNormalization()(X)\n# kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)\n    con = tfl.concatenate([X, meta_input])\n#     con= tfl.BatchNormalization()(con)\n    con = tfl.Dropout(0.4)(con)  \n\n    skip = tfl.Dense(64,  \n                     kernel_initializer=tf.keras.initializers.GlorotUniform(),\n                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(con)\n    \n    X = tfl.Dense(256, activation='relu', \n                  kernel_initializer=tf.keras.initializers.GlorotUniform(),\n                 kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(con)\n    X = tfl.Dropout(0.4)(X)  \n    \n    X = tfl.Dense(256, activation='relu', \n                  kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(X)\n    X = tfl.Dropout(0.4)(X)\n    \n    X = tfl.Dense(64,  \n                  kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(X)\n\n\n    X = tfl.Add()([X, skip])\n    X= tfl.BatchNormalization()(X)\n    X = tfl.Activation('relu')(X)\n#     X = tfl.Dropout(0.4)(X)\n    \n#     X = tfl.Dense(16, activation='relu')(X)\n#     X = tfl.Dropout(0.4)(X)\n\n\n    \n\n    out = tfl.Dense(1)(X)\n\n    model = keras.Model(inputs=[img_input, meta_input], outputs=out)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-21T19:04:17.556951Z","iopub.execute_input":"2021-12-21T19:04:17.557213Z","iopub.status.idle":"2021-12-21T19:04:28.78036Z","shell.execute_reply.started":"2021-12-21T19:04:17.557184Z","shell.execute_reply":"2021-12-21T19:04:28.779585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T19:04:28.78206Z","iopub.execute_input":"2021-12-21T19:04:28.782426Z","iopub.status.idle":"2021-12-21T19:04:31.041517Z","shell.execute_reply.started":"2021-12-21T19:04:28.782389Z","shell.execute_reply":"2021-12-21T19:04:31.040761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T19:04:31.042833Z","iopub.execute_input":"2021-12-21T19:04:31.043078Z","iopub.status.idle":"2021-12-21T19:04:31.482776Z","shell.execute_reply.started":"2021-12-21T19:04:31.043045Z","shell.execute_reply":"2021-12-21T19:04:31.481876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# early_stop = keras.callbacks.EarlyStopping(\n#         patience=3,\n#         restore_best_weights=True)\n\n# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n#     initial_learning_rate=1e-3,\n#     decay_steps=100,\n#     decay_rate=0.96,\n#     staircase=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T19:08:00.802412Z","iopub.execute_input":"2021-12-21T19:08:00.80303Z","iopub.status.idle":"2021-12-21T19:08:00.808022Z","shell.execute_reply.started":"2021-12-21T19:08:00.802991Z","shell.execute_reply":"2021-12-21T19:08:00.807267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = get_model()\n\n# model.compile(keras.optimizers.Adam(learning_rate=lr_schedule), \n#             loss='mse', \n#             metrics=[keras.metrics.RootMeanSquaredError()])\n\n# history = model.fit(train_ds,\n#                validation_data=val_ds,\n#                epochs=20,\n#                workers=-1,\n#                callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T19:27:04.92985Z","iopub.execute_input":"2021-12-21T19:27:04.930115Z","iopub.status.idle":"2021-12-21T19:27:04.933877Z","shell.execute_reply.started":"2021-12-21T19:27:04.930087Z","shell.execute_reply":"2021-12-21T19:27:04.932815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 5\nfold = KFold(k,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:25:01.343611Z","iopub.execute_input":"2021-11-17T04:25:01.344707Z","iopub.status.idle":"2021-11-17T04:25:01.350656Z","shell.execute_reply.started":"2021-11-17T04:25:01.344643Z","shell.execute_reply":"2021-11-17T04:25:01.349248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nhistories = []\n\nfor i, (t_ids, v_ids) in enumerate(fold.split(train)):\n    \n    keras.backend.clear_session()\n\n    print(\"\\n\\n===========================================================================================\\n\")\n    train_ds = tf.data.Dataset.from_tensor_slices((train.iloc[t_ids]['path'], train.iloc[t_ids].drop(['path', 'Id'], axis=1).astype(float)))\\\n    .map(lambda x,y: process_data(x, y, True)).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    \n    val_ds = tf.data.Dataset.from_tensor_slices((train.iloc[v_ids]['path'], train.iloc[v_ids].drop(['path', 'Id'], axis=1).astype(float)))\\\n    .map(process_data).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    \n    model = get_model()\n    \n    early_stop = keras.callbacks.EarlyStopping(\n        patience=3,\n        restore_best_weights=True)\n\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=1e-3,\n        decay_steps=1000,\n        decay_rate=0.96,\n        staircase=True)\n    \n    model.compile(keras.optimizers.Adam(learning_rate=lr_schedule), \n            loss='mse', \n            metrics=[keras.metrics.RootMeanSquaredError()])\n    \n    history = model.fit(train_ds,\n                   validation_data=val_ds,\n                   epochs=20,\n                   callbacks=[early_stop])\n    \n    models.append(model)\n    histories.append(history)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T02:12:01.492371Z","iopub.status.idle":"2021-11-11T02:12:01.498485Z","shell.execute_reply.started":"2021-11-11T02:12:01.492887Z","shell.execute_reply":"2021-11-11T02:12:01.492913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds = model.predict(test_ds)\npreds = models[0].predict(test_ds)/k\n\nfor i in range(1,k):\n    preds += models[i].predict(test_ds)/k","metadata":{"execution":{"iopub.status.busy":"2021-11-17T15:37:32.997462Z","iopub.execute_input":"2021-11-17T15:37:32.998162Z","iopub.status.idle":"2021-11-17T15:37:37.700999Z","shell.execute_reply.started":"2021-11-17T15:37:32.998126Z","shell.execute_reply":"2021-11-17T15:37:37.700195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2021-11-17T15:37:37.704624Z","iopub.execute_input":"2021-11-17T15:37:37.704838Z","iopub.status.idle":"2021-11-17T15:37:37.710233Z","shell.execute_reply.started":"2021-11-17T15:37:37.704812Z","shell.execute_reply":"2021-11-17T15:37:37.709541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Pawpularity'] = preds\ntest[['Id', 'Pawpularity']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T15:37:46.705023Z","iopub.execute_input":"2021-11-17T15:37:46.705289Z","iopub.status.idle":"2021-11-17T15:37:46.716554Z","shell.execute_reply.started":"2021-11-17T15:37:46.705259Z","shell.execute_reply":"2021-11-17T15:37:46.715837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}