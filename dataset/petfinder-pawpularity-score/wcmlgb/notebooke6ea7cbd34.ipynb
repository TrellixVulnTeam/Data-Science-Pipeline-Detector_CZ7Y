{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/3rd-party/timm-0.4.12-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:08:25.961256Z","iopub.execute_input":"2021-11-29T09:08:25.961695Z","iopub.status.idle":"2021-11-29T09:08:54.935377Z","shell.execute_reply.started":"2021-11-29T09:08:25.961571Z","shell.execute_reply":"2021-11-29T09:08:54.934522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm, torch, random, os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport torch.nn as nn\nimport torchvision.transforms as transforms\n\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:09:03.681781Z","iopub.execute_input":"2021-11-29T09:09:03.682409Z","iopub.status.idle":"2021-11-29T09:09:09.799029Z","shell.execute_reply.started":"2021-11-29T09:09:03.682365Z","shell.execute_reply":"2021-11-29T09:09:09.79823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    apex=False\n    debug=False\n    print_freq=10\n    num_workers=4\n    size=512\n    model_name='tf_efficientnet_b8'\n    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n    epochs=3\n    T_max=3 # CosineAnnealingLR\n    T_0=3 # CosineAnnealingWarmRestarts\n    lr=1e-4\n    min_lr=1e-6\n    batch_size=24\n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    seed=42\n    target_size=1\n    target_col='Pawpularity'\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]\n    train=True\n    grad_cam=True","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:09:13.52132Z","iopub.execute_input":"2021-11-29T09:09:13.52223Z","iopub.status.idle":"2021-11-29T09:09:13.528162Z","shell.execute_reply.started":"2021-11-29T09:09:13.52219Z","shell.execute_reply":"2021-11-29T09:09:13.527486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=pd.read_csv('../input/petfinder-pawpularity-score/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:09:16.689119Z","iopub.execute_input":"2021-11-29T09:09:16.689656Z","iopub.status.idle":"2021-11-29T09:09:16.706543Z","shell.execute_reply.started":"2021-11-29T09:09:16.689617Z","shell.execute_reply":"2021-11-29T09:09:16.705833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_file_path(image_id):\n    return f'../input/petfinder-pawpularity-score/test/{image_id}.jpg'\ntest['file_path'] = test['Id'].apply(get_image_file_path)\n\nfeature_cols = [col for col in test.columns if col not in ['Id', 'Pawpularity', 'file_path']]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:09:18.015801Z","iopub.execute_input":"2021-11-29T09:09:18.016058Z","iopub.status.idle":"2021-11-29T09:09:18.029739Z","shell.execute_reply.started":"2021-11-29T09:09:18.016027Z","shell.execute_reply":"2021-11-29T09:09:18.028986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class test_data(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n        self.file_name = df['file_path'].values\n        self.meta = df[feature_cols].values\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        file_path = self.file_name[index]\n        image = Image.open(file_path).convert('RGB')\n        meta = self.meta[index, :]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, meta\n\nget_transforms = transforms.Compose([\n    transforms.Resize((CFG.size, CFG.size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225],\n    )\n])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:09:19.745357Z","iopub.execute_input":"2021-11-29T09:09:19.74611Z","iopub.status.idle":"2021-11-29T09:09:19.755811Z","shell.execute_reply.started":"2021-11-29T09:09:19.74607Z","shell.execute_reply":"2021-11-29T09:09:19.754969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class custom_model(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model('tf_efficientnet_b8', pretrained=pretrained)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.dropout = nn.Dropout(p=0.3)\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(self.n_features+12, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3)\n        )\n\n        self.fc2 = nn.Sequential(\n            nn.Linear(1024, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3)\n        )\n\n        self.fc3 = nn.Linear(256, self.cfg.target_size)\n\n    def image_feature(self, image):\n        feature = self.model(image)\n        return feature\n\n    def forward(self, image, meta):\n        feature = self.image_feature(image)\n        feature = self.dropout(feature)\n        ensembled_feature = torch.cat([feature, meta], dim=1)  # features = (bs, embedding_size + 12)\n\n        ensembled_feature = self.fc1(ensembled_feature)\n        ensembled_feature = self.fc2(ensembled_feature)\n\n        output = self.fc3(ensembled_feature)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:09:26.898954Z","iopub.execute_input":"2021-11-29T09:09:26.899238Z","iopub.status.idle":"2021-11-29T09:09:26.910089Z","shell.execute_reply.started":"2021-11-29T09:09:26.899208Z","shell.execute_reply":"2021-11-29T09:09:26.908976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:09:43.440747Z","iopub.execute_input":"2021-11-29T09:09:43.441097Z","iopub.status.idle":"2021-11-29T09:09:43.450216Z","shell.execute_reply.started":"2021-11-29T09:09:43.441054Z","shell.execute_reply":"2021-11-29T09:09:43.449369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer(model, device, test_loader):\n    model.to(device)\n    model.eval()\n    y = []\n\n    with torch.no_grad():\n        for images, meta in test_loader:\n            images = images.to(device)\n            meta = meta.to(device)\n            y_preds = model(images, meta)\n            y.append(y_preds)\n    return y","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:09:46.256386Z","iopub.execute_input":"2021-11-29T09:09:46.257061Z","iopub.status.idle":"2021-11-29T09:09:46.263561Z","shell.execute_reply.started":"2021-11-29T09:09:46.257026Z","shell.execute_reply":"2021-11-29T09:09:46.261504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the model\nmodel_path = '../input/trained-model/tf_efficientnet_b8_fold4_best.pth'\nmodel_infer = custom_model(CFG, pretrained=False)\nmodel_infer.load_state_dict(torch.load(model_path))\nmodel_infer.eval()\n\n#\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ntestset = test_data(test, transform=get_transforms)\ntestloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=0)\n\nypred_test = infer(model_infer, device, testloader)\n\nsubmission_transfer_nn = pd.DataFrame()\nsubmission_transfer_nn['Id'] = test['Id']\n\ny_sub = []\nfor i in range(len(ypred_test)):\n    y_sub.append(ypred_test[i].view(-1).to('cpu').item())\n\nsubmission_transfer_nn['Pawpularity'] = y_sub\n\nsubmission_transfer_nn","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:09:48.979035Z","iopub.execute_input":"2021-11-29T09:09:48.979735Z","iopub.status.idle":"2021-11-29T09:10:05.866126Z","shell.execute_reply.started":"2021-11-29T09:09:48.979697Z","shell.execute_reply":"2021-11-29T09:10:05.865403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_transfer_nn.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T09:10:22.711972Z","iopub.execute_input":"2021-11-29T09:10:22.712474Z","iopub.status.idle":"2021-11-29T09:10:22.720039Z","shell.execute_reply.started":"2021-11-29T09:10:22.712413Z","shell.execute_reply":"2021-11-29T09:10:22.719113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}