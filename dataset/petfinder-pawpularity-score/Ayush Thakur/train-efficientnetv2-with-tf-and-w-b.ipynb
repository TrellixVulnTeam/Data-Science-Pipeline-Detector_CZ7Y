{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üê∂ Introduction\n\nIn this competition, the task is to predict the \"Pawpularity Score\" given an input image. The score range from 0-100 and thus can be formulated as classification problem or regression problem. \n\n# üêï About this kernel\n\nThis kernel fine-tunes an EfficientNetv2 model using TensorFlow and uses Weights and Biases (W&B) for efficient experiment tracking. Meta-data is also used for training. \n\nIn the past, I have created multiple training kernels that use Weights and Biases but this kernel introduces some useful W&B best-practices (framework agnostic) that you can easily incorporate in your own pipeline with slight to no modification. \n\nIn particular, this kernel introduces:\n\n1. Use of hash value (random string) for efficient grouping of experiments in the W&B UI. ‚úîÔ∏è \n2. Fine-tuning of EfficientNetv2 hosted on TensorFlow Hub. \n3. Use of Albumentations with TensorFlow for data augmentation. \n4. Track metrics using W&B Experiment Tracking. ‚úîÔ∏è \n4. Keep track of the model and `oof.csv` file using W&B Artifacts.‚úîÔ∏è \n5. Save the trained model as Kaggle dataset to be used for inference.\n6. Visualize model perforance using W&B Tables. ‚úîÔ∏è \n7. Manually log LB Score to Weights and Biases. ‚úîÔ∏è \n\nThe bullet points marked with ‚úîÔ∏è are specific to Weights and Biases and can be incorporated in your own workflow. ","metadata":{}},{"cell_type":"markdown","source":"# ü¶Æ Imports and Setups\n\n* Install the latest version of W&B. \n* Generate random string as hash value.\n* Import important libraries.\n* Loging to W&B using your W&B API access token.","metadata":{}},{"cell_type":"code","source":"!pip install -q --upgrade wandb","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:24:43.591488Z","iopub.execute_input":"2021-10-08T14:24:43.592139Z","iopub.status.idle":"2021-10-08T14:24:55.584742Z","shell.execute_reply.started":"2021-10-08T14:24:43.592046Z","shell.execute_reply":"2021-10-08T14:24:55.583897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ‚ùì Why is this useful?\n\nüôã In Kaggle we usually train model using K-fold strategy. If you are using W&B for experiment tracking you can see aggregated training metrics for each fold if you pass in `group=some-name` argument to `wandb.init()`. In the context of Kaggle, where we keep trying new experiments, tweak hyperparameters, change model definition, etc. regularly, deciding on this `some-name` can be tricky and prone to human error (usual error is to forget renaming for a new experiment). \n\nBy using a randomly generated hash-value you can group one experiment under one group-name and name the model as well as any generated file with that name. This is an unique identifier about your experiment. \n\n‚ö†Ô∏è Run this cell at the start of the notebook.","metadata":{}},{"cell_type":"code","source":"import string\nimport random\ndef id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n\nHASH_NAME = id_generator(size=12)\nprint(HASH_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:24:57.075666Z","iopub.execute_input":"2021-10-08T14:24:57.075951Z","iopub.status.idle":"2021-10-08T14:24:57.086073Z","shell.execute_reply.started":"2021-10-08T14:24:57.0759Z","shell.execute_reply":"2021-10-08T14:24:57.085344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each experiments are grouped together using the hash-value. \n\n![img](https://i.imgur.com/a7atecz.png)","metadata":{}},{"cell_type":"code","source":"import os\n# Close TF debug logs\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nimport gc\nimport sys\nimport time\nimport json\nimport wandb\nprint(\"W&B version: \", wandb.__version__)\n\nimport signal\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom wandb.keras import WandbCallback\n\n# For deep learning\nimport tensorflow as tf\nprint(\"TF version: \", tf.__version__)\nimport tensorflow_hub as hub\nprint('Hub version:', hub.__version__)\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import regularizers\nimport tensorflow_addons as tfa\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\n\n# Sklearn for spliting the dataset\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Imports for augmentations. \nfrom albumentations import Compose, RandomResizedCrop, Cutout, Rotate, HorizontalFlip, VerticalFlip, RandomBrightnessContrast, ShiftScaleRotate, CenterCrop, Resize, Normalize","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-10-08T14:24:58.34061Z","iopub.execute_input":"2021-10-08T14:24:58.341193Z","iopub.status.idle":"2021-10-08T14:25:05.387081Z","shell.execute_reply.started":"2021-10-08T14:24:58.341157Z","shell.execute_reply":"2021-10-08T14:25:05.38631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ‚ùì Why is this useful?\n\nüôã In case a cell with initialized W&B run is KeyboardInterrupted, this function will close the W&B run. If you use a Python script to train your model, W&B will close automatically if you interrupt the training process. ","metadata":{}},{"cell_type":"code","source":"def wandbKeyboardInterruptHandler(signal, frame):\n    print(\"KeyboardInterrupt (ID: {}) has been caught. Cleaning up...\".format(signal))\n    wandb.finish()\n    sys.exit()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:05.391054Z","iopub.execute_input":"2021-10-08T14:25:05.392627Z","iopub.status.idle":"2021-10-08T14:25:05.397764Z","shell.execute_reply.started":"2021-10-08T14:25:05.391542Z","shell.execute_reply":"2021-10-08T14:25:05.397103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Utils for EfficientNetV2","metadata":{}},{"cell_type":"code","source":"# For efficientnet class of models\ndef get_hub_url_and_isize(model_name, ckpt_type, hub_type):\n  if ckpt_type == '1k':\n    ckpt_type = ''  # json doesn't support empty string\n  else:\n    ckpt_type = '-' + ckpt_type  # add '-' as prefix\n  \n  hub_url_map = {\n    'efficientnetv2-b0': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0/{hub_type}',\n    'efficientnetv2-b1': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1/{hub_type}',\n    'efficientnetv2-b2': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2/{hub_type}',\n    'efficientnetv2-b3': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3/{hub_type}',\n    'efficientnetv2-s':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s/{hub_type}',\n    'efficientnetv2-m':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m/{hub_type}',\n    'efficientnetv2-l':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l/{hub_type}',\n\n    'efficientnetv2-b0-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0-21k/{hub_type}',\n    'efficientnetv2-b1-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1-21k/{hub_type}',\n    'efficientnetv2-b2-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2-21k/{hub_type}',\n    'efficientnetv2-b3-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3-21k/{hub_type}',\n    'efficientnetv2-s-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k/{hub_type}',\n    'efficientnetv2-m-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k/{hub_type}',\n    'efficientnetv2-l-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k/{hub_type}',\n    'efficientnetv2-xl-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-xl-21k/{hub_type}',\n\n    'efficientnetv2-b0-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0-21k-ft1k/{hub_type}',\n    'efficientnetv2-b1-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1-21k-ft1k/{hub_type}',\n    'efficientnetv2-b2-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2-21k-ft1k/{hub_type}',\n    'efficientnetv2-b3-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3-21k-ft1k/{hub_type}',\n    'efficientnetv2-s-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k-ft1k/{hub_type}',\n    'efficientnetv2-m-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k-ft1k/{hub_type}',\n    'efficientnetv2-l-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k-ft1k/{hub_type}',\n    'efficientnetv2-xl-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-xl-21k-ft1k/{hub_type}',\n      \n    # efficientnetv1\n    'efficientnet_b0': f'https://tfhub.dev/tensorflow/efficientnet/b0/{hub_type}/1',\n    'efficientnet_b1': f'https://tfhub.dev/tensorflow/efficientnet/b1/{hub_type}/1',\n    'efficientnet_b2': f'https://tfhub.dev/tensorflow/efficientnet/b2/{hub_type}/1',\n    'efficientnet_b3': f'https://tfhub.dev/tensorflow/efficientnet/b3/{hub_type}/1',\n    'efficientnet_b4': f'https://tfhub.dev/tensorflow/efficientnet/b4/{hub_type}/1',\n    'efficientnet_b5': f'https://tfhub.dev/tensorflow/efficientnet/b5/{hub_type}/1',\n    'efficientnet_b6': f'https://tfhub.dev/tensorflow/efficientnet/b6/{hub_type}/1',\n    'efficientnet_b7': f'https://tfhub.dev/tensorflow/efficientnet/b7/{hub_type}/1',\n  }\n  \n  image_size_map = {\n    'efficientnetv2-b0': 224,\n    'efficientnetv2-b1': 240,\n    'efficientnetv2-b2': 260,\n    'efficientnetv2-b3': 300,\n    'efficientnetv2-s':  384,\n    'efficientnetv2-m':  480,\n    'efficientnetv2-l':  480,\n    'efficientnetv2-xl':  512,\n  \n    'efficientnet_b0': 224,\n    'efficientnet_b1': 240,\n    'efficientnet_b2': 260,\n    'efficientnet_b3': 300,\n    'efficientnet_b4': 380,\n    'efficientnet_b5': 456,\n    'efficientnet_b6': 528,\n    'efficientnet_b7': 600,\n  }\n  \n  hub_url = hub_url_map.get(model_name + ckpt_type)\n  image_size = image_size_map.get(model_name, 224)\n  return hub_url, image_size","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:05.778536Z","iopub.execute_input":"2021-10-08T14:25:05.779046Z","iopub.status.idle":"2021-10-08T14:25:05.794038Z","shell.execute_reply.started":"2021-10-08T14:25:05.77901Z","shell.execute_reply":"2021-10-08T14:25:05.793166Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:05.950586Z","iopub.execute_input":"2021-10-08T14:25:05.951286Z","iopub.status.idle":"2021-10-08T14:25:07.572673Z","shell.execute_reply.started":"2021-10-08T14:25:05.951247Z","shell.execute_reply":"2021-10-08T14:25:07.571333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Login to Weights and Biases\n\nIf you are using Kaggle kernel to train your model and commit the kernel, it's best to use Kaggle User Secrets. Put in your W&B Access token with the label `wandb_api`. \n\nIf you Quick Save your kernel you can simply use `wandb.login()`.\n\nIf you are using a local system (where the runtime is not volatile) you just need to call `wandb.login()` once. ","metadata":{}},{"cell_type":"code","source":"try:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=secret_value_0)\n    anony=None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:07.574313Z","iopub.execute_input":"2021-10-08T14:25:07.574556Z","iopub.status.idle":"2021-10-08T14:25:08.818827Z","shell.execute_reply.started":"2021-10-08T14:25:07.57452Z","shell.execute_reply":"2021-10-08T14:25:08.818041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  üêï‚Äçü¶∫Hyperparameters\n\nSave your hyperparameters as a dictionary so that you can log the same to W&B. ","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = '../input/petfinder-pawpularity-score/train/'\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nCONFIG = dict (\n    seed = 42,\n    loss = 'mse', # binary_crossentropy\n    num_labels = 1,\n    num_folds = 5,\n    train_val_split = 0.2,\n    img_width = 224,\n    img_height = 224,\n    batch_size = 16,\n    epochs = 1, # FOR FULL TRAINING INCREASE EPOCHS TO ATLEAST 20.\n    learning_rate = 1e-5,\n    hash_name = HASH_NAME\n)\n\n# Model configs\nCONFIG['model_type'] = 'efficientnetv2-b0'\nCONFIG['ckpt_type'] = '1k'   # '21k', '21k-ft1k', '1k'\nCONFIG['hub_type'] = 'feature-vector' # \nhub_url, image_size = get_hub_url_and_isize(CONFIG['model_type'], CONFIG['ckpt_type'], CONFIG['hub_type'])\nprint(hub_url)\n\nCONFIG['group'] = f'{HASH_NAME}-Regression'\nCONFIG['model_name'] = f'{HASH_NAME}-model'\nCONFIG['img_width'] = image_size\nCONFIG['img_height'] = image_size\nCONFIG['do_fine_tuning'] = True\n\n# Set the random seeds\ndef seed_everything(SEED):\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n    np.random.seed(SEED)\n    tf.random.set_seed(SEED)\n    \nseed_everything(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:08.82072Z","iopub.execute_input":"2021-10-08T14:25:08.821023Z","iopub.status.idle":"2021-10-08T14:25:08.833674Z","shell.execute_reply.started":"2021-10-08T14:25:08.820984Z","shell.execute_reply":"2021-10-08T14:25:08.832799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üê± Build Input Pipeline","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\nprint(f'Number of train images: {len(df)}')\n\n# Add path\ndf['img_path'] = df['Id'].apply(lambda x: f'{TRAIN_PATH}{x}.jpg')\n\n# Min-max scaling (For regression)\ncolumn = 'Pawpularity'\ndf[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())   \n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:08.836598Z","iopub.execute_input":"2021-10-08T14:25:08.836813Z","iopub.status.idle":"2021-10-08T14:25:08.916829Z","shell.execute_reply.started":"2021-10-08T14:25:08.836789Z","shell.execute_reply":"2021-10-08T14:25:08.91604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FEATURES = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:08.918697Z","iopub.execute_input":"2021-10-08T14:25:08.919266Z","iopub.status.idle":"2021-10-08T14:25:08.923905Z","shell.execute_reply.started":"2021-10-08T14:25:08.919223Z","shell.execute_reply":"2021-10-08T14:25:08.923099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_folds(data, num_splits):\n    data[\"kfold\"] = -1\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n\n    data.loc[:, \"bins\"] = pd.cut(data[\"Pawpularity\"], bins=num_bins, labels=False)\n\n    kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n    \n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'kfold'] = f\n    \n    data = data.drop(\"bins\", axis=1)\n\n    return data\n\ndf = create_folds(df, num_splits=CONFIG['num_folds'])\ndf.to_csv('five_fold_classification.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:08.988124Z","iopub.execute_input":"2021-10-08T14:25:08.988336Z","iopub.status.idle":"2021-10-08T14:25:09.105146Z","shell.execute_reply.started":"2021-10-08T14:25:08.988311Z","shell.execute_reply":"2021-10-08T14:25:09.104442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üêà Dataloader","metadata":{}},{"cell_type":"code","source":"# Apply training augmentation\ntrain_transforms = Compose([\n            Resize(CONFIG['img_height'], CONFIG['img_width'], p=1),\n            Rotate(limit=20),\n            Cutout(num_holes=8, max_h_size=30, max_w_size=30, p=1.0),\n            HorizontalFlip(p=0.7),\n            VerticalFlip(p=0.4),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0,\n                p=1.0,\n            ),\n        ])\n\n# Apply validation augmentation\nvalid_transforms = Compose([\n            Resize(CONFIG['img_height'], CONFIG['img_width'], p=1),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0,\n                p=1.0,\n            ),\n        ])\n\ndef aug_train_fn(image):\n    data = {\"image\":image}\n    aug_data = train_transforms(**data)\n    aug_img = aug_data[\"image\"]\n\n    return aug_img.astype(np.float32) \n\ndef aug_valid_fn(image):\n    data = {\"image\":image}\n    aug_data = valid_transforms(**data)\n    aug_img = aug_data[\"image\"]\n\n    return aug_img.astype(np.float32) \n\ndef train_augmentations(inputs, label):\n    image = inputs['image']\n    aug_img = tf.numpy_function(func=aug_train_fn, inp=[image], Tout=tf.float32)\n    aug_img.set_shape((CONFIG['img_height'], CONFIG['img_width'], 3))\n\n    return {'image': aug_img, 'features': inputs['features']}, label\n\ndef valid_augmentations(inputs, label):\n    image = inputs['image']\n    aug_img = tf.numpy_function(func=aug_valid_fn, inp=[image], Tout=tf.float32)\n    aug_img.set_shape((CONFIG['img_height'], CONFIG['img_width'], 3))\n\n    return {'image': aug_img, 'features': inputs['features']}, label","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:09.295239Z","iopub.execute_input":"2021-10-08T14:25:09.295518Z","iopub.status.idle":"2021-10-08T14:25:09.311171Z","shell.execute_reply.started":"2021-10-08T14:25:09.295488Z","shell.execute_reply":"2021-10-08T14:25:09.310282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef load_resize(df_dict):\n    # Load image\n    img = tf.io.read_file(df_dict['img_path'])\n    img = tf.image.decode_jpeg(img, channels=3)\n    \n    # Parse features\n    features = {key: df_dict[key] for key in FEATURES}\n    features = features.values()\n    \n    # Parse label\n    label = df_dict['Pawpularity']\n    label = tf.cast(label, tf.float32)\n    \n    return {'image': img, 'features': features}, label","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:09.505637Z","iopub.execute_input":"2021-10-08T14:25:09.505897Z","iopub.status.idle":"2021-10-08T14:25:09.517Z","shell.execute_reply.started":"2021-10-08T14:25:09.505869Z","shell.execute_reply":"2021-10-08T14:25:09.51622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ndef get_dataloaders(train_df, valid_df):\n    # Train Loader\n    trainloader = tf.data.Dataset.from_tensor_slices(dict(train_df))\n    # Valid Loader\n    validloader = tf.data.Dataset.from_tensor_slices(dict(valid_df))\n\n    trainloader = (\n        trainloader\n        .shuffle(1024)\n        .map(load_resize, num_parallel_calls=AUTOTUNE)\n        .map(train_augmentations, num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n\n    validloader = (\n        validloader\n        .map(load_resize, num_parallel_calls=AUTOTUNE)\n        .map(valid_augmentations, num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n    \n    return trainloader, validloader","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:09.680873Z","iopub.execute_input":"2021-10-08T14:25:09.683185Z","iopub.status.idle":"2021-10-08T14:25:09.693449Z","shell.execute_reply.started":"2021-10-08T14:25:09.683114Z","shell.execute_reply":"2021-10-08T14:25:09.692776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_batch(image_batch):\n  plt.figure(figsize=(20,20))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.axis('off')\n\n#sanity check\n# Prepare dataloaders\ntrain_df = df.loc[df.kfold != 0].reset_index(drop=True)\nvalid_df = df.loc[df.kfold == 0].reset_index(drop=True)\n\ntrainloader, validloader = get_dataloaders(train_df, valid_df)\ninputs, labels = next(iter(validloader))\n\n# show_batch(imgs)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:25:10.429386Z","iopub.execute_input":"2021-10-08T14:25:10.429652Z","iopub.status.idle":"2021-10-08T14:25:10.981442Z","shell.execute_reply.started":"2021-10-08T14:25:10.429622Z","shell.execute_reply":"2021-10-08T14:25:10.980611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üêï Model","metadata":{}},{"cell_type":"code","source":"def get_model():\n    # Setup backbone model\n    base_model = hub.KerasLayer(hub_url, trainable=CONFIG['do_fine_tuning'])\n\n    # Inputs\n    image_inputs = layers.Input((CONFIG['img_height'], CONFIG['img_width'], 3), name='image')\n    feature_inputs = layers.Input((len(FEATURES)), name='features')\n    \n    # Get image features\n    img_features = base_model(image_inputs)\n    img_features = layers.Dense(64, activation='selu', \n                               kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n                               bias_regularizer=regularizers.l2(1e-4), \n                               activity_regularizer=regularizers.l2(1e-5))(img_features)\n    \n    # Get metadata features\n    features = layers.Dense(64, activation='selu',\n                            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n                            bias_regularizer=regularizers.l2(1e-4),\n                            activity_regularizer=regularizers.l2(1e-5))(feature_inputs)\n    \n    # Concat features\n    concat_features = layers.concatenate([img_features, features])\n    \n    x = layers.Dropout(0.5)(concat_features)\n    x = layers.Dense(64, activation='selu', \n                     kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n                     bias_regularizer=regularizers.l2(1e-4),\n                     activity_regularizer=regularizers.l2(1e-5))(x)\n    \n    outputs = layers.Dense(1, activation='sigmoid', \n                           kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n                           bias_regularizer=regularizers.l2(1e-4),\n                           activity_regularizer=regularizers.l2(1e-5))(x)\n    \n    return models.Model([image_inputs, feature_inputs], outputs)\n\ntf.keras.backend.clear_session()\nmodel = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:37:09.819304Z","iopub.execute_input":"2021-10-08T14:37:09.819584Z","iopub.status.idle":"2021-10-08T14:42:28.267117Z","shell.execute_reply.started":"2021-10-08T14:37:09.819555Z","shell.execute_reply":"2021-10-08T14:42:28.266337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üê∂ Callbacks","metadata":{}},{"cell_type":"code","source":"# Callbacks\nearlystopper = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=2, verbose=0, mode='min',\n    restore_best_weights=True\n)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=1, min_lr=CONFIG['learning_rate'])","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:43:40.78324Z","iopub.execute_input":"2021-10-08T14:43:40.78351Z","iopub.status.idle":"2021-10-08T14:43:40.790862Z","shell.execute_reply.started":"2021-10-08T14:43:40.783481Z","shell.execute_reply":"2021-10-08T14:43:40.788917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# üêï‚Äçü¶∫ Train\n\n‚ö†Ô∏è For demonstration purposes I am training the model for 1 epochs. ","metadata":{}},{"cell_type":"code","source":"def get_predictions(model, validloader, valid_df):\n    y_pred = []\n    for image_batch, label_batch in validloader:\n        preds = model.predict(image_batch)\n        y_pred.extend(preds)\n        \n    valid_df['preds'] = y_pred\n    \n    return valid_df ","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:43:44.430107Z","iopub.execute_input":"2021-10-08T14:43:44.430768Z","iopub.status.idle":"2021-10-08T14:43:44.435364Z","shell.execute_reply.started":"2021-10-08T14:43:44.430728Z","shell.execute_reply":"2021-10-08T14:43:44.434341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:43:45.708314Z","iopub.execute_input":"2021-10-08T14:43:45.70883Z","iopub.status.idle":"2021-10-08T14:43:45.713814Z","shell.execute_reply.started":"2021-10-08T14:43:45.708798Z","shell.execute_reply":"2021-10-08T14:43:45.71297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In case we interrupt the kernel\nsignal.signal(signal.SIGINT, wandbKeyboardInterruptHandler)\n\nfor fold in range(CONFIG['num_folds']):\n    print('FOLD: ', fold)\n    # Prepare train and valid df\n    train_df = df.loc[df.kfold != fold].reset_index(drop=True)\n    valid_df = df.loc[df.kfold == fold].reset_index(drop=True)\n\n    # Prepare dataloaders\n    trainloader, validloader = get_dataloaders(train_df, valid_df)\n\n    # Initialize model\n    tf.keras.backend.clear_session()\n    model = get_model()\n\n    # Compile model\n    optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG['learning_rate'])\n    model.compile(optimizer, \n                  loss='binary_crossentropy', \n                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\n    # Update CONFIG dict with the name of the model.\n    print('Training configuration: ', CONFIG)\n\n    # Initialize W&B run\n    run = wandb.init(project='petfinder-train', \n                     config=CONFIG,\n                     group=CONFIG['group'], \n                     job_type='train',\n                     tags=['effnetv2', f'{HASH_NAME}'],\n                     name=f'{HASH_NAME}-fold-{fold}')\n\n    # Train\n    _ = model.fit(trainloader, \n                  epochs=CONFIG['epochs'],\n                  validation_data=validloader,\n                  callbacks=[WandbCallback(),\n                             earlystopper,\n                             reduce_lr])\n\n\n    # Evaluate\n    loss, rsme = model.evaluate(validloader)\n    wandb.log({'Val RSME': rsme})\n\n    # Save model\n    model_name = CONFIG['model_name']\n    MODEL_PATH = f'models/{model_name}'\n    os.makedirs(MODEL_PATH, exist_ok=True)\n    count_models = len(os.listdir(MODEL_PATH))\n\n    model.save(f'{MODEL_PATH}/{model_name}_{count_models}')\n\n    # Get Prediction on validation set\n    _oof_df = get_predictions(model, validloader, valid_df)\n    oof_df = pd.concat([oof_df, _oof_df])\n\n    # Close W&B run\n    run.finish()\n\n    del model, trainloader, validloader, _oof_df\n    _ = gc.collect()\n\n# Save oof as csv file\noof_df.to_csv('oof_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T14:44:45.920901Z","iopub.execute_input":"2021-10-08T14:44:45.921193Z","iopub.status.idle":"2021-10-08T15:23:31.524808Z","shell.execute_reply.started":"2021-10-08T14:44:45.921164Z","shell.execute_reply":"2021-10-08T15:23:31.524028Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üêà Compute CV Score and Save Model and OOF File as W&B Artifacts","metadata":{}},{"cell_type":"code","source":"# Initialize W&B run\nrun = wandb.init(project='petfinder-train', \n                 config=CONFIG,\n                 group=CONFIG['group'], \n                 job_type='eval',\n                 name=f'{HASH_NAME}-eval')\n\n# Compute CV score\noof_df_copy = oof_df.copy()\ndef correct_preds(row):\n    return row.preds[0]\n\noof_df_copy['preds'] = oof_df_copy.apply(lambda row: correct_preds(row), axis=1)\n\nmetric = tf.keras.metrics.RootMeanSquaredError()\nmetric.update_state(oof_df_copy.Pawpularity.values, oof_df_copy.preds.values)\nprint(f'CV Score: {metric.result().numpy()}')\n\nwandb.log({\"CV Score\": metric.result().numpy()})\n\n# Log oof.csv as artifacts\nmodel_artifacts = wandb.Artifact(f'{HASH_NAME}', type='model', metadata={'hash_name': HASH_NAME})\n# Add oof_preds.csv\nmodel_artifacts.add_file('oof_preds.csv')\n# Add trained models\nmodel_artifacts.add_dir('models/')\nwandb.log_artifact(model_artifacts)\n\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T15:31:17.748494Z","iopub.execute_input":"2021-10-08T15:31:17.74876Z","iopub.status.idle":"2021-10-08T15:31:32.869093Z","shell.execute_reply.started":"2021-10-08T15:31:17.748725Z","shell.execute_reply":"2021-10-08T15:31:32.868403Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This way you can track which experiment trained which model and the corresponding `oof_preds.csv` file. \n\n![img](https://i.imgur.com/gOz1LNj.png)","metadata":{}},{"cell_type":"markdown","source":"# üê± Save the model as Kaggle dataset\n\n","metadata":{}},{"cell_type":"code","source":"# Copy Kaggle API token to ~/.kaggle\n! mkdir -p /root/.kaggle/\n! cp ../input/apitoken/kaggle.json /root/.kaggle/kaggle.json\n\n# Initialize dataset creation\n! kaggle datasets init -p models/\n\n!ls models/\n\n%cat models/dataset-metadata.json","metadata":{"execution":{"iopub.status.busy":"2021-10-08T16:56:49.725554Z","iopub.execute_input":"2021-10-08T16:56:49.726262Z","iopub.status.idle":"2021-10-08T16:56:53.739151Z","shell.execute_reply.started":"2021-10-08T16:56:49.726207Z","shell.execute_reply":"2021-10-08T16:56:53.738231Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n  \n# Opening JSON file\nwith open('models/dataset-metadata.json', 'r') as openfile:\n    # Reading from json file\n    json_object = json.load(openfile)\n\n    json_object['title'] = f'Petfinder {HASH_NAME}'\n    json_object['id'] = f'petfinder-{HASH_NAME}'\n\nwith open(\"models/dataset-metadata.json\", \"w\") as outfile:\n    json.dump(json_object, outfile, indent=2)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T17:07:01.24315Z","iopub.execute_input":"2021-10-08T17:07:01.243422Z","iopub.status.idle":"2021-10-08T17:07:01.253485Z","shell.execute_reply.started":"2021-10-08T17:07:01.243391Z","shell.execute_reply":"2021-10-08T17:07:01.252729Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets create -p models/ --dir-mode zip\n# ! kaggle datasets version -p /kaggle/tmp/hpa_512x512_dataset -m \"add rgb images\"  --dir-mode tar","metadata":{"execution":{"iopub.status.busy":"2021-10-08T17:07:08.994707Z","iopub.execute_input":"2021-10-08T17:07:08.99549Z","iopub.status.idle":"2021-10-08T17:07:10.133211Z","shell.execute_reply.started":"2021-10-08T17:07:08.995442Z","shell.execute_reply":"2021-10-08T17:07:10.132252Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DESP = \"efficientnetv2-b0_trained_with_metadata\"\n!kaggle datasets version -p models -m {DESP} --dir-mode zip","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üêï Analysis of Model Performance","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.set(style='dark')\n\nplt.figure(figsize=(10*2,6*2))\n\n# Prediction Plot\nplt.subplot(2, 2, 1)\nsns.kdeplot(x=oof_df_copy.Pawpularity.values, color='b',shade=True);\nsns.kdeplot(x=oof_df_copy.preds.values, color='r',shade=True);\nplt.grid('ON')\nplt.xlabel(oof_df_copy.Pawpularity.values);plt.ylabel('freq');plt.title('KDE')\nplt.legend(['train', 'oof'])\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T17:08:07.876294Z","iopub.execute_input":"2021-10-08T17:08:07.876602Z","iopub.status.idle":"2021-10-08T17:08:08.527286Z","shell.execute_reply.started":"2021-10-08T17:08:07.876566Z","shell.execute_reply":"2021-10-08T17:08:08.526351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Update LB Score\n\nUse the trained model to run inference using a different kernel. Once you get the LB score, use the cell code below to log the LB score to the <HASH_NAME>-eval W&B run name. \n\n![img](https://i.imgur.com/c7CAlBH.gif)","metadata":{}},{"cell_type":"code","source":"import wandb\napi = wandb.Api()\n\nrun = api.run(\"ayut/petfinder-train/3sopqxw1\")\nrun.summary[\"LB Score\"] = 0.22954 # This is just representative number.\nrun.summary.update()","metadata":{},"execution_count":null,"outputs":[]}]}