{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\n\nimport pylab as pl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-07T17:53:31.888129Z","iopub.execute_input":"2021-11-07T17:53:31.888845Z","iopub.status.idle":"2021-11-07T17:53:31.893299Z","shell.execute_reply.started":"2021-11-07T17:53:31.888808Z","shell.execute_reply":"2021-11-07T17:53:31.892446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RES = [224, 224]\nMETA_SHAPE = []\nBATCH_SIZE = 64\nFOLDS = 5\nEPOCHS = 10\nAUGMENT = True\nSEED = 2022","metadata":{"execution":{"iopub.status.busy":"2021-11-07T17:53:31.8988Z","iopub.execute_input":"2021-11-07T17:53:31.899439Z","iopub.status.idle":"2021-11-07T17:53:31.90724Z","shell.execute_reply.started":"2021-11-07T17:53:31.8994Z","shell.execute_reply":"2021-11-07T17:53:31.906314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu\ndef mixup(inputs, label, PROBABILITY=0.5):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with mixup applied\n    DIM = RES[0]\n    CLASSES = 1\n    \n    image = inputs['image_inp']\n    \n    batch_size = BATCH_SIZE\n    \n    imgs = []; labs = []\n    for j in range(batch_size):\n        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n        # CHOOSE RANDOM\n        k = tf.cast( tf.random.uniform([],0,batch_size),tf.int32)\n        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n        # MAKE MIXUP IMAGE\n        img1 = image[j,]\n        img2 = image[k,]\n        imgs.append((1-a)*img1 + a*img2)\n        \n        lab1 = label[j,]\n        lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(BATCH_SIZE,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(BATCH_SIZE,CLASSES))\n    return ({ 'image_inp': image2, 'meta_inp': inputs['meta_inp'] }, label2)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T17:53:31.908779Z","iopub.execute_input":"2021-11-07T17:53:31.909554Z","iopub.status.idle":"2021-11-07T17:53:31.920968Z","shell.execute_reply.started":"2021-11-07T17:53:31.909479Z","shell.execute_reply":"2021-11-07T17:53:31.920184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_base_path = \"../input/petfinder-pawpularity-score/train/\"\ntrain_csv = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntrain_data = np.array(train_csv)\n\nfor datum in train_data:\n    datum[0] = train_base_path+datum[0]+\".jpg\"\n    \ntrain_images = train_data[:,0]\ntrain_meta = train_data[:,1:-1].astype(np.float32)\ntrain_labels = train_data[:,-1].astype(np.float32) / 100.\n\nFOLD_SIZE = train_images.shape[0] // FOLDS\nprint(f\"Fold size: {FOLD_SIZE}\")\ntrain_datasets = []\nval_datasets = []\n\ndef augment(image):\n    return image\n\ndef preprocess(inputs, labels):\n    filename = inputs['image_inp']\n    image = tf.io.read_file(filename)\n    image = tf.io.decode_jpeg(image)\n    #image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.cast(image, tf.float32)\n    image = tf.image.resize(image, RES)\n\n    if AUGMENT:\n        #image = tf.image.random_flip_left_right(image, SEED)\n        #image = tf.image.random_flip_up_down(image, SEED)\n        image = tf.image.random_hue(image, 0.05, SEED)\n        image = tf.image.random_contrast(image, 0.95, 1.05, SEED)\n        image = tf.image.random_brightness(image, 0.05, SEED)\n\n    return ({ 'image_inp': image, 'meta_inp': inputs['meta_inp'] }, labels)\n\ndef preprocess_val(inputs, labels):\n    filename = inputs['image_inp']\n    image = tf.io.read_file(filename)\n    image = tf.io.decode_jpeg(image)\n    #image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.cast(image, tf.float32)\n    image = tf.image.resize(image, RES)\n\n    return ({ 'image_inp': image, 'meta_inp': inputs['meta_inp'] }, labels)\n\ntotal_trainset = tf.data.Dataset.from_tensor_slices(\n        (\n            { 'image_inp': train_images, 'meta_inp': train_meta },\n            { 'output': train_labels }\n        )\n    ).map(preprocess).shuffle(256).batch(BATCH_SIZE)\n\n# Returns train, val\ndef extract_validation_set(data, fold):\n    return np.concatenate((data[:fold*FOLD_SIZE], data[(fold+1)*FOLD_SIZE:]), axis=0), data[fold*FOLD_SIZE:(fold+1)*FOLD_SIZE]\n\nfor f in range(FOLDS):\n    train_images_fold, val_images_fold = extract_validation_set(train_images, f)\n    train_meta_fold, val_meta_fold = extract_validation_set(train_meta, f)\n    train_labels_fold, val_labels_fold = extract_validation_set(train_labels, f)\n\n    META_SHAPE = train_meta[0].shape\n\n    train_datasets.append(\n        tf.data.Dataset.from_tensor_slices(\n            (\n                { 'image_inp': train_images_fold, 'meta_inp': train_meta_fold },\n                train_labels_fold\n            )\n        ).map(preprocess).shuffle(256).batch(BATCH_SIZE, drop_remainder=True).map(mixup)\n    )\n    \n    val_datasets.append(\n        tf.data.Dataset.from_tensor_slices(\n            (\n                { 'image_inp': val_images_fold, 'meta_inp': val_meta_fold },\n                val_labels_fold\n            )\n        ).map(preprocess_val).shuffle(256).batch(BATCH_SIZE)\n    )","metadata":{"execution":{"iopub.status.busy":"2021-11-07T17:53:31.94229Z","iopub.execute_input":"2021-11-07T17:53:31.942477Z","iopub.status.idle":"2021-11-07T17:53:39.307609Z","shell.execute_reply.started":"2021-11-07T17:53:31.942455Z","shell.execute_reply":"2021-11-07T17:53:39.306834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_base_path = \"../input/petfinder-pawpularity-score/test/\"\ntest_csv = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\ntest_ids = list(test_csv['Id'])\ntest_meta = np.array(test_csv.drop('Id', axis=1)).astype(np.float32)\n\ndef test_preprocess(input_dict):\n    filepath = input_dict['image_inp']\n    image = tf.io.read_file(filepath)\n    image = tf.io.decode_jpeg(image)\n    image = tf.cast(image, tf.float32)\n    image = tf.image.resize(image, RES[:2])\n    \n    return { 'image_inp': image, 'meta_inp': input_dict['meta_inp'] }\n\ntest_files = [test_base_path+s+\".jpg\" for s in test_ids]\ntest_dataset = tf.data.Dataset.from_tensor_slices({ 'image_inp': test_files, 'meta_inp': test_meta }).map(test_preprocess).batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T17:53:39.310342Z","iopub.execute_input":"2021-11-07T17:53:39.310876Z","iopub.status.idle":"2021-11-07T17:53:39.333675Z","shell.execute_reply.started":"2021-11-07T17:53:39.310835Z","shell.execute_reply":"2021-11-07T17:53:39.333037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RES = [RES[0], RES[1], 3]\ndef get_model():\n    image_inp = keras.Input(RES, name=\"image_inp\")\n    meta_inp = keras.Input(META_SHAPE, name=\"meta_inp\")\n    \n    backbone = keras.applications.EfficientNetB0(weights=\"../input/keras-applications-models/EfficientNetB0.h5\",\n                                                 include_top=False, input_shape=RES, pooling='avg')\n    for layer in backbone.layers:\n        if isinstance(layer, layers.BatchNormalization):\n            layer.trainable = False\n        else:\n            layer.trainable = True\n    \n    x = backbone(image_inp)\n    x = layers.Dropout(0.2)(x)\n    x = tf.concat([x, meta_inp], axis=-1)\n    x = layers.Dense(128, activation='gelu')(x)\n    x = layers.Dense(1, activation='sigmoid', name=\"output\")(x)\n    \n    return keras.Model(inputs=[image_inp, meta_inp], outputs=x)\n\nget_model()\n\ndef metric(labels, logits):\n    las = labels * 100.\n    los = logits * 100.\n    mse = tf.math.reduce_mean(tf.math.square((las - los)))\n    rmse = tf.math.sqrt(mse)\n    \n    return rmse\n\ndef get_lr_callback():\n    lr_start   = 0.0005\n    lr_max     = 0.000125 * BATCH_SIZE\n    lr_min     = 0.0001\n    lr_ramp_ep = 4\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n    return lr_callback","metadata":{"execution":{"iopub.status.busy":"2021-11-07T17:53:39.335133Z","iopub.execute_input":"2021-11-07T17:53:39.335605Z","iopub.status.idle":"2021-11-07T17:53:41.780935Z","shell.execute_reply.started":"2021-11-07T17:53:39.33557Z","shell.execute_reply":"2021-11-07T17:53:41.780189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_predictions = []\n\nopt = keras.optimizers.Adam(learning_rate=1e-4)\n\nfor fold, (train_dataset, val_dataset) in enumerate(zip(train_datasets, val_datasets)):\n    keras.backend.clear_session()\n    model = get_model()\n    \n    model.compile(optimizer=opt, loss=keras.losses.BinaryCrossentropy(), metrics=metric)\n    print(f\"TRAINING FOLD: {fold+1}\")\n    model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n    fold_predictions = model.predict(test_dataset) * 100.\n    all_predictions.append(fold_predictions)\n    \nfinal_predictions = np.mean(all_predictions, axis=0)\nprint(final_predictions.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T17:53:41.783836Z","iopub.execute_input":"2021-11-07T17:53:41.784282Z","iopub.status.idle":"2021-11-07T18:05:48.840499Z","shell.execute_reply.started":"2021-11-07T17:53:41.784234Z","shell.execute_reply":"2021-11-07T18:05:48.839175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_dict = { 'Id': test_ids, 'Pawpularity': final_predictions[:,0] }\nprint(sub_dict)\nsubmission = pd.DataFrame.from_dict(sub_dict)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T18:05:48.841501Z","iopub.status.idle":"2021-11-07T18:05:48.8424Z","shell.execute_reply.started":"2021-11-07T18:05:48.842142Z","shell.execute_reply":"2021-11-07T18:05:48.842167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-07T18:05:48.843768Z","iopub.status.idle":"2021-11-07T18:05:48.844414Z","shell.execute_reply.started":"2021-11-07T18:05:48.844166Z","shell.execute_reply":"2021-11-07T18:05:48.844191Z"},"trusted":true},"execution_count":null,"outputs":[]}]}