{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hello\nThis notebook is for PetFinder.my competition.\n\nI'll use tensorflow for training data.\n\nFirst import train and test data for process.","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# set parameters\nproc_img_width = 224\nproc_img_height = 224\n\n# load csv data\ntrain_data = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\n\n# set image path\ntrain_img_path = '../input/petfinder-pawpularity-score/train'","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:48:19.129969Z","iopub.execute_input":"2021-10-14T02:48:19.131345Z","iopub.status.idle":"2021-10-14T02:48:19.174744Z","shell.execute_reply.started":"2021-10-14T02:48:19.131303Z","shell.execute_reply":"2021-10-14T02:48:19.173939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process Image\nResize all image as predefined size (proc_img_width x proc_img_height).\n\nAlso make image batch for train and test data.","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm, trange\nimport numpy as np\nimport tensorflow as tf\n\ntrain_ids = train_data['Id'][:]\ntrain_label = train_data['Pawpularity'][:]\n\n# train_imgs = []\n# for i in trange(len(train_ids)):\n#     path = os.path.join(train_img_path, train_ids[i] + '.jpg')\n#     image = tf.image.decode_jpeg(tf.io.read_file(path), channels = 3)\n#     image = tf.cast(tf.image.resize_with_pad(image, proc_img_width, proc_img_height), dtype = tf.int32)\n#     train_imgs.append(image)\n# train_imgs = np.array(train_imgs)\n\nprint(train_ids.shape, train_label.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:48:19.176123Z","iopub.execute_input":"2021-10-14T02:48:19.177805Z","iopub.status.idle":"2021-10-14T02:48:25.101833Z","shell.execute_reply.started":"2021-10-14T02:48:19.177769Z","shell.execute_reply":"2021-10-14T02:48:25.100894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Test Data\n\nPrepare test data with feature and train_data.","metadata":{}},{"cell_type":"code","source":"total_cnt = train_ids.shape[0]\nprint(total_cnt)\n\nsplit_rate = 0.9\n\ntrain_label_re = np.array(train_label).reshape(-1, 1)\n\ntrain_id = np.array(train_ids[:(int)(total_cnt * split_rate)])\nval_id = np.array(train_ids[(int)(total_cnt * split_rate):])\ntrain_pawp = train_label_re[:(int)(total_cnt * split_rate)]\nval_pawp = train_label_re[(int)(total_cnt * split_rate):]\n\nprint(train_id.shape, train_pawp.shape)\nprint(val_id.shape, val_pawp.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:48:25.104878Z","iopub.execute_input":"2021-10-14T02:48:25.105173Z","iopub.status.idle":"2021-10-14T02:48:25.115665Z","shell.execute_reply.started":"2021-10-14T02:48:25.10513Z","shell.execute_reply":"2021-10-14T02:48:25.114534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train with NN\n\nTrain data with simple neural network.\n\nFirst load pretrained image classification model (EfficientNet B0)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras import *\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0\n\npre_train_model = load_model('../input/keras-applications-models/EfficientNetB0.h5')\npre_train_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:48:25.117573Z","iopub.execute_input":"2021-10-14T02:48:25.117853Z","iopub.status.idle":"2021-10-14T02:48:28.054692Z","shell.execute_reply.started":"2021-10-14T02:48:25.117821Z","shell.execute_reply":"2021-10-14T02:48:28.053767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And then define model network.","metadata":{}},{"cell_type":"code","source":"input1 = Input(shape = (proc_img_width, proc_img_height, 3))\n# input2 = Input(shape = (train_other_fe.shape[1],))\n\nmodel_feat1 = layers.experimental.preprocessing.RandomFlip(mode = 'horizontal')(input1)\n\nmodel_feat1 = pre_train_model(model_feat1)\n\nmodel_feat1 = BatchNormalization()(model_feat1)\nmodel_feat1 = Dropout(0.2)(model_feat1)\nmodel_feat1 = Dense(32, activation = \"relu\")(model_feat1)\n\n# model_feat1 = Dense(8, activation = \"relu\", kernel_initializer = \"normal\")(model_feat1)\n\n# model_feat2 = Dense(8, activation = \"relu\", kernel_initializer = \"normal\")(input2)\n# model_feat2 = Dense(8, activation = \"relu\", kernel_initializer = \"normal\")(model_feat2)\n\n# model_feat = add([model_feat1, model_feat2])\n\n# model_feat = Dense(16, activation = \"relu\", kernel_initializer = \"normal\")(model_feat1)\nmodel_feat = Dense(1)(model_feat1)\n\n# model = Model(inputs = [input1, input2], outputs = model_feat)\nmodel = Model(inputs = input1, outputs = model_feat)\n\n# gradually decrease learning rate\nlr_schedule = schedules.ExponentialDecay(\n    initial_learning_rate = 1e-3,\n    decay_steps = 100,\n    decay_rate = 0.96,\n    staircase = True)\n\n# compile model network\nmodel.compile(optimizer = Adam(learning_rate = lr_schedule),\n             loss = losses.MeanSquaredError(),\n             metrics = [metrics.RootMeanSquaredError()])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:48:28.056211Z","iopub.execute_input":"2021-10-14T02:48:28.056496Z","iopub.status.idle":"2021-10-14T02:48:28.853278Z","shell.execute_reply.started":"2021-10-14T02:48:28.056459Z","shell.execute_reply":"2021-10-14T02:48:28.852337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Start training.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import *\nfrom sklearn.utils import shuffle\n\nclass DataGenerator(Sequence):\n    def __init__(self, id_data, pawp_data, batch_size = 128, shuffle = True):\n        'Initialization'\n        self.id_data = id_data\n        self.pawp_data = pawp_data\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(self.pawp_data.shape[0] / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        id_batch = self.id_data[index * self.batch_size : (index + 1) * self.batch_size]\n        pawp_data = self.pawp_data[index * self.batch_size : (index + 1) * self.batch_size]\n\n        # make image batch\n        img_batch = []\n        for i in range(self.batch_size):\n            path = os.path.join(train_img_path, id_batch[i] + '.jpg')\n            image = tf.image.decode_jpeg(tf.io.read_file(path), channels = 3)\n            image = tf.cast(tf.image.resize_with_pad(image, proc_img_width, proc_img_height), dtype = tf.int32)\n            img_batch.append(image)\n            \n            # release buffer\n            del path\n            del image\n        img_batch = np.array(img_batch).astype(np.float32)\n        \n        # release buffer\n        del id_batch\n\n        # return [img_batch.astype(np.float32), feat_batch.astype(np.float32)], pawp_data\n        return img_batch, pawp_data\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            self.id_data, self.pawp_data = shuffle(self.id_data, self.pawp_data)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:48:28.854346Z","iopub.execute_input":"2021-10-14T02:48:28.854641Z","iopub.status.idle":"2021-10-14T02:48:29.52411Z","shell.execute_reply.started":"2021-10-14T02:48:28.854612Z","shell.execute_reply":"2021-10-14T02:48:29.523301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import *\n\n# define callback for best result training\nearly_stop = EarlyStopping(\n    monitor = 'val_loss', patience = 5, restore_best_weights = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:48:29.525145Z","iopub.execute_input":"2021-10-14T02:48:29.525384Z","iopub.status.idle":"2021-10-14T02:48:29.529994Z","shell.execute_reply.started":"2021-10-14T02:48:29.52536Z","shell.execute_reply":"2021-10-14T02:48:29.529231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = DataGenerator(train_id, train_pawp, shuffle = False)\nval_gen = DataGenerator(val_id, val_pawp, shuffle = False)\n\nhistory = model.fit(train_gen, epochs = 1, validation_data = val_gen,\n                    # use_multiprocessing = True, workers = -1)\n                    use_multiprocessing = True, workers = -1,\n                    callbacks = [early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:48:29.531433Z","iopub.execute_input":"2021-10-14T02:48:29.531948Z","iopub.status.idle":"2021-10-14T02:57:54.334378Z","shell.execute_reply.started":"2021-10-14T02:48:29.531917Z","shell.execute_reply":"2021-10-14T02:57:54.333314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show Train Result\n\nShow trained result as graph.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nrmse = history.history['root_mean_squared_error']\nval_rmse = history.history['val_root_mean_squared_error']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(rmse) + 1)\n\nplt.plot(epochs, rmse, 'bo', label='Training rmse')\nplt.plot(epochs, val_rmse, 'b', label='Validation rmse')\nplt.title('Training and validation rmse')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:57:54.336422Z","iopub.execute_input":"2021-10-14T02:57:54.336767Z","iopub.status.idle":"2021-10-14T02:57:54.801233Z","shell.execute_reply.started":"2021-10-14T02:57:54.336724Z","shell.execute_reply":"2021-10-14T02:57:54.800292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clear Buffer\n\nClear all buffer for reduce memory.","metadata":{}},{"cell_type":"code","source":"del train_data\ndel train_img_path\n\ndel train_ids\ndel train_label\n\ndel train_label_re\ndel train_id\ndel val_id\ndel train_pawp\ndel val_pawp\n\ndel train_gen\ndel val_gen\ndel history","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:58:48.558014Z","iopub.execute_input":"2021-10-14T02:58:48.558323Z","iopub.status.idle":"2021-10-14T02:58:48.587743Z","shell.execute_reply.started":"2021-10-14T02:58:48.558294Z","shell.execute_reply":"2021-10-14T02:58:48.586947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation & Submit\n\nEvaluation with trained model and save result as csv.","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest_img_path = '../input/petfinder-pawpularity-score/test'\n\ntest_ids = test_data['Id'][:]\n\ntest_imgs = []\nfor i in trange(len(test_ids)):\n    path = os.path.join(test_img_path, test_ids[i] + '.jpg')\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels = 3)\n    image = tf.cast(tf.image.resize_with_pad(image, proc_img_width, proc_img_height), dtype = tf.int32)\n    test_imgs.append(image)\ntest_imgs = np.array(test_imgs)\n\nprint(test_imgs.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:57:54.812211Z","iopub.execute_input":"2021-10-14T02:57:54.812531Z","iopub.status.idle":"2021-10-14T02:57:54.908361Z","shell.execute_reply.started":"2021-10-14T02:57:54.812491Z","shell.execute_reply":"2021-10-14T02:57:54.907777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"commit_x1 = np.array(test_imgs)\n# commit_x2 = np.array(test_other_feat).astype(np.float32)\n\n# predictions = model.predict([commit_x1, commit_x2]).reshape(commit_x1.shape[0],)\npredictions = model.predict(commit_x1).reshape(commit_x1.shape[0],)\nsubmission_df = pd.DataFrame()\n\nsubmission_df['Id'] = test_ids\nsubmission_df['Pawpularity'] = predictions\nsubmission_df.to_csv('submission.csv',index = False)\n\n# show result\nprint(submission_df.head(10))\n\nprint('Finished')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:57:54.909383Z","iopub.execute_input":"2021-10-14T02:57:54.91011Z","iopub.status.idle":"2021-10-14T02:57:56.617922Z","shell.execute_reply.started":"2021-10-14T02:57:54.910055Z","shell.execute_reply":"2021-10-14T02:57:56.617278Z"},"trusted":true},"execution_count":null,"outputs":[]}]}