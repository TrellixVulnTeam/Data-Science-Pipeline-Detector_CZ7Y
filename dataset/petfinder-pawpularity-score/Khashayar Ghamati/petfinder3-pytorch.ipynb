{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! mkdir ../working/cached\n# ! mkdir /kaggle/working/output","metadata":{"execution":{"iopub.status.busy":"2022-06-01T17:27:42.569836Z","iopub.execute_input":"2022-06-01T17:27:42.57012Z","iopub.status.idle":"2022-06-01T17:27:43.366764Z","shell.execute_reply.started":"2022-06-01T17:27:42.57009Z","shell.execute_reply":"2022-06-01T17:27:43.365835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\nfrom tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nimport numpy as np","metadata":{"id":"Jib5coQMKc0I","execution":{"iopub.status.busy":"2022-06-01T17:27:21.528203Z","iopub.execute_input":"2022-06-01T17:27:21.528499Z","iopub.status.idle":"2022-06-01T17:27:27.880442Z","shell.execute_reply.started":"2022-06-01T17:27:21.528464Z","shell.execute_reply":"2022-06-01T17:27:27.879728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = '../input/petfinder-pawpularity-score/'\ntrain_metadata = pd.read_csv(base_path+'train.csv')\ntest_metadata = pd.read_csv(base_path+'test.csv')","metadata":{"id":"0DAjVW5HKjpt","execution":{"iopub.status.busy":"2022-06-01T17:27:27.882189Z","iopub.execute_input":"2022-06-01T17:27:27.882619Z","iopub.status.idle":"2022-06-01T17:27:27.936846Z","shell.execute_reply.started":"2022-06-01T17:27:27.882577Z","shell.execute_reply":"2022-06-01T17:27:27.93572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport os\n\n\nnrows = 4\nncols = 4\n\npic_index = 0\n\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\ntrain_images_fnames = os.listdir(base_path+'train')\n\npic_index+=8\n\nnext_image_pix = [os.path.join(base_path+'train', fname) \n                for fname in train_images_fnames[ pic_index-8:pic_index] \n               ]\n\nfor i, img_path in enumerate(next_image_pix):\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off')\n\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n\nplt.show()","metadata":{"id":"9cswOen6Kvbl","outputId":"2f2657eb-be3c-4189-f348-c70fb218ac41","execution":{"iopub.status.busy":"2022-06-01T17:27:27.938194Z","iopub.execute_input":"2022-06-01T17:27:27.93843Z","iopub.status.idle":"2022-06-01T17:27:29.95086Z","shell.execute_reply.started":"2022-06-01T17:27:27.938397Z","shell.execute_reply":"2022-06-01T17:27:29.950236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_image_format(item):\n    return f\"{item}.jpg\"\n\ntrain_image_names = list(train_metadata['Id'].apply(add_image_format))\ntest_image_names = list(test_metadata['Id'].apply(add_image_format))","metadata":{"id":"hT8qDLlvaTek","execution":{"iopub.status.busy":"2022-06-01T17:27:29.952334Z","iopub.execute_input":"2022-06-01T17:27:29.953012Z","iopub.status.idle":"2022-06-01T17:27:29.967593Z","shell.execute_reply.started":"2022-06-01T17:27:29.952969Z","shell.execute_reply":"2022-06-01T17:27:29.966648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_metadata['filename'] = train_image_names\ntest_metadata['filename'] = test_image_names\nX = train_metadata.drop(['Id'], axis=1) \ny = train_metadata['Pawpularity']\nX_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.1, random_state=42)\n\n\nnumber_of_items_in_batch = 50\ntotal_batch_data_size = 20\n\ndata_X_train_batches = X_train#[X_train[i:i + number_of_items_in_batch] for i in range(0, len(X_train), total_batch_data_size)]\ndata_y_train_batches = y_train#[y_train[i:i + number_of_items_in_batch] for i in range(0, len(y_train), total_batch_data_size)]\ndata_X_dev_batches = X_dev#[X_dev[i:i + number_of_items_in_batch] for i in range(0, len(X_dev), total_batch_data_size)]\ndata_y_dev_batches = y_dev#[y_dev[i:i + number_of_items_in_batch] for i in range(0, len(y_dev), total_batch_data_size)]\n\nX_test_data_ID = test_metadata['Id']\nX_test_data = test_metadata.drop(['Id'], axis=1)","metadata":{"id":"xLm0_7c6ab3B","execution":{"iopub.status.busy":"2022-06-01T17:27:29.968712Z","iopub.execute_input":"2022-06-01T17:27:29.969301Z","iopub.status.idle":"2022-06-01T17:27:29.993489Z","shell.execute_reply.started":"2022-06-01T17:27:29.969256Z","shell.execute_reply":"2022-06-01T17:27:29.992735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nclass DataLoader:\n    \n    def prepare(self, batch_data_index=0, path='train'):\n        self.batch_data_index = batch_data_index\n        self.make_data(path)\n\n    def get_images(self, data, path):\n        npz_paths = []\n        if type(self.batch_data_index) == str:\n            _data_in_loop = data[:]['filename'] if path == 'train' else data['filename']\n        else:\n            _data_in_loop = data[self.batch_data_index]['filename'] if path == 'train' else data['filename']\n        for i in _data_in_loop:\n            pic_bgr_arr = cv2.imread(f'{base_path}{path}/{i}')\n            resized = cv2.resize(pic_bgr_arr, (80, 80), interpolation = cv2.INTER_AREA)\n            pic_rgb_arr = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n\n            npz_file_name = f\"../working/cached/{i.split('.')[0]}.npz\"\n            npz_paths.append(npz_file_name)\n            np.savez_compressed(npz_file_name, pic=pic_rgb_arr/255)\n        return npz_paths\n\n    def get_X_y(self, df, is_test=False):\n        X_pic, X_stats = [], []\n        y = []\n\n        for index, record in df.iterrows():\n            loaded_npz = np.load(record['NPZ_Path'])\n\n            pic = loaded_npz['pic']\n            X_pic.append(pic)\n\n            if not is_test:\n                stats = record.drop(['Pawpularity', 'filename', 'NPZ_Path'])\n                X_stats.append(stats)\n                y.append(record['Pawpularity'])\n            else:\n                stats = record.drop(['filename', 'NPZ_Path'])\n                X_stats.append(stats)\n\n\n        X_pic, X_stats = np.array(X_pic), np.array(X_stats)\n        if not is_test:\n            y = np.array(y)\n            return (X_pic, X_stats), y\n        else:\n            return (X_pic, X_stats)\n\n    def make_data(self, path):\n        if path == 'test':\n            NPZ_Pathes = self.get_images(X_test_data, path)\n            X_test_data['NPZ_Path'] = NPZ_Pathes\n            (self.test_images, self.test_meta) = self.get_X_y(X_test_data, True)\n        else:\n            trained_data = self.get_images(data_X_train_batches, path)\n            deved_data = self.get_images(data_X_dev_batches, path)\n\n            if type(self.batch_data_index) == str:\n                data_X_train_batches['NPZ_Path'] = trained_data\n                data_X_dev_batches['NPZ_Path'] = deved_data  \n                (self.train_images, self.train_meta), self.y_train = self.get_X_y(data_X_train_batches)\n                (self.dev_images, self.dev_meta), self.y_dev = self.get_X_y(data_X_train_batches)\n            else:\n                data_X_train_batches[self.batch_data_index]['NPZ_Path'] = trained_data\n                data_X_dev_batches[self.batch_data_index]['NPZ_Path'] = deved_data\n                (self.train_images, self.train_meta), self.y_train = self.get_X_y(data_X_train_batches[self.batch_data_index])\n                (self.dev_images, self.dev_meta), self.y_dev = self.get_X_y(data_X_train_batches[self.batch_data_index])\n\n\n\n    def get_dev_data(self):\n        return (np.asarray(self.dev_images).astype('float32'), np.asarray(self.dev_meta).astype('float32')), np.asarray(self.y_dev).astype('float32')\n\n    def get_train_data(self):\n        return (np.asarray(self.train_images).astype('float32'), np.asarray(self.train_meta).astype('float32')), np.asarray(self.y_train).astype('float32')\n\n    def get_test_data(self):\n        return (np.asarray(self.test_images).astype('float32'), np.asarray(self.test_meta).astype('float32'))\n","metadata":{"id":"U1JOCh7AbdUk","execution":{"iopub.status.busy":"2022-06-01T17:27:48.278179Z","iopub.execute_input":"2022-06-01T17:27:48.278656Z","iopub.status.idle":"2022-06-01T17:27:48.296779Z","shell.execute_reply.started":"2022-06-01T17:27:48.2786Z","shell.execute_reply":"2022-06-01T17:27:48.295639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = DataLoader()\ndata.prepare(path='test')\n(test_images, test_meta) = data.get_test_data()\ntest_images.shape, test_meta.shape\n","metadata":{"id":"hKwFaNzDobsd","outputId":"d48dd401-81e8-4a3a-94d8-a837a138d419","execution":{"iopub.status.busy":"2022-06-01T17:27:48.32268Z","iopub.execute_input":"2022-06-01T17:27:48.323304Z","iopub.status.idle":"2022-06-01T17:27:48.540205Z","shell.execute_reply.started":"2022-06-01T17:27:48.323259Z","shell.execute_reply":"2022-06-01T17:27:48.539321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create a network for metadata","metadata":{"id":"YiJSS425u5-Z"}},{"cell_type":"code","source":"input_meta = tf.keras.layers.Input(shape=(12,))\nmeta_d = tf.keras.layers.Dense(50, activation='relu')(input_meta)\nmeta_d = tf.keras.layers.Dense(20, activation='relu')(meta_d)\nmeta_d = tf.keras.layers.Dense(12, activation='relu')(meta_d)\nmeta_model = tf.keras.Model(inputs=input_meta, outputs=meta_d)","metadata":{"id":"dsC4Chf6sBuS","execution":{"iopub.status.busy":"2022-06-01T17:27:52.672979Z","iopub.execute_input":"2022-06-01T17:27:52.673265Z","iopub.status.idle":"2022-06-01T17:27:52.79477Z","shell.execute_reply.started":"2022-06-01T17:27:52.673229Z","shell.execute_reply":"2022-06-01T17:27:52.793937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create CNN","metadata":{"id":"Ae936Fsvv-3v"}},{"cell_type":"code","source":"def identity_block(X, f, filters, training=True, initializer=random_uniform):\n    \"\"\"\n    Implementation of the identity block as defined in Figure 4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    training -- True: Behave in training mode\n                False: Behave in inference mode\n    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n    \n    Returns:\n    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n    \"\"\"\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n    X = Activation('relu')(X)\n    \n    ### START CODE HERE\n    ## Second component of main path (≈3 lines)\n    ## Set the padding = 'same'\n    X = Conv2D(filters = F2, kernel_size = (f,f), strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training)\n    X = Activation('relu')(X) \n\n    ## Third component of main path (≈2 lines)\n    ## Set the padding = 'valid'\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training = training) \n    \n    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X) \n    ### END CODE HERE\n\n    return X","metadata":{"id":"xELeZBM-we0M","execution":{"iopub.status.busy":"2022-06-01T17:27:55.237919Z","iopub.execute_input":"2022-06-01T17:27:55.238546Z","iopub.status.idle":"2022-06-01T17:27:55.246677Z","shell.execute_reply.started":"2022-06-01T17:27:55.238506Z","shell.execute_reply":"2022-06-01T17:27:55.246077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n    \"\"\"\n    Implementation of the convolutional block as defined in Figure 4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    s -- Integer, specifying the stride to be used\n    training -- True: Behave in training mode\n                False: Behave in inference mode\n    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n                   also called Xavier uniform initializer.\n    \n    Returns:\n    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    \n    # First component of main path glorot_uniform(seed=0)\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X, training=training)\n    X = Activation('relu')(X)\n\n    ### START CODE HERE\n    \n    ## Second component of main path (≈3 lines)\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X) \n    X = BatchNormalization(axis = 3)(X, training=training)\n    X = Activation('relu')(X) \n    \n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X) \n    X = BatchNormalization(axis = 3)(X, training=training)\n    X = Activation('relu')(X) \n\n    ## Third component of main path (≈2 lines)\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)  \n    X = BatchNormalization(axis = 3)(X, training=training) \n    \n    ##### SHORTCUT PATH ##### (≈2 lines)\n    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)  \n    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n    \n    ### END CODE HERE\n\n    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","metadata":{"id":"-0tDj-RnwrSj","execution":{"iopub.status.busy":"2022-06-01T17:27:55.586582Z","iopub.execute_input":"2022-06-01T17:27:55.587046Z","iopub.status.idle":"2022-06-01T17:27:55.597676Z","shell.execute_reply.started":"2022-06-01T17:27:55.587004Z","shell.execute_reply":"2022-06-01T17:27:55.596859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ResNet50(input_shape = (110, 110, 3), classes = 6):\n    \"\"\"\n    Stage-wise implementation of the architecture of the popular ResNet50:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n\n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n   \n    # Normalizing data\n    #_input = tf.keras.layers.Rescaling(1./255)(X_input)\n    \n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(224, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [200, 200, 256], s = 1)\n    X = identity_block(X, 3, [200, 200, 256])\n    X = identity_block(X, 3, [200, 200, 256])\n\n    ### START CODE HERE\n    \n    ## Stage 3 (≈4 lines)\n    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2) \n    X = identity_block(X, 3, [128,128,512]) \n    X = identity_block(X, 3, [128,128,512]) \n    X = identity_block(X, 3, [128,128,512]) \n    \n    ## Stage 4 (≈6 lines)\n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2) \n    X = identity_block(X, 3, [256, 256, 1024]) \n    X = identity_block(X, 3, [256, 256, 1024]) \n    X = identity_block(X, 3, [256, 256, 1024]) \n    X = identity_block(X, 3, [256, 256, 1024]) \n    X = identity_block(X, 3, [256, 256, 1024])\n\n    ## Stage 5 (≈3 lines)\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)  \n    X = identity_block(X, 3, [512, 512, 2048])  \n    X = identity_block(X, 3, [512, 512, 2048]) \n\n    ## AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n    X = AveragePooling2D(pool_size=(2, 2))(X)    \n    \n    ### END CODE HERE\n\n    # output layer\n    X = Flatten()(X)\n    # X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X)\n\n    return model","metadata":{"id":"4TIWt6EKwtA8","execution":{"iopub.status.busy":"2022-06-01T17:27:55.846254Z","iopub.execute_input":"2022-06-01T17:27:55.846525Z","iopub.status.idle":"2022-06-01T17:27:55.860308Z","shell.execute_reply.started":"2022-06-01T17:27:55.846491Z","shell.execute_reply":"2022-06-01T17:27:55.859172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model = ResNet50(input_shape = (80, 80, 3), classes = 1)","metadata":{"id":"TIXux8RsvnjJ","execution":{"iopub.status.busy":"2022-06-01T17:27:56.183829Z","iopub.execute_input":"2022-06-01T17:27:56.184629Z","iopub.status.idle":"2022-06-01T17:27:57.384936Z","shell.execute_reply.started":"2022-06-01T17:27:56.184588Z","shell.execute_reply":"2022-06-01T17:27:57.383653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined = tf.keras.layers.concatenate([cnn_model.output, meta_model.output])","metadata":{"id":"Nl4qgmpjw_O4","execution":{"iopub.status.busy":"2022-06-01T17:27:59.034031Z","iopub.execute_input":"2022-06-01T17:27:59.034728Z","iopub.status.idle":"2022-06-01T17:27:59.044698Z","shell.execute_reply.started":"2022-06-01T17:27:59.03468Z","shell.execute_reply":"2022-06-01T17:27:59.043984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = Dense(len(train_image_names)+12, activation='relu')(combined)\nX = Dropout(0.2)(X)\nX = Dense(50, activation='relu')(X)\nX = Dense(50, activation='relu')(X)\nX = Dense(50, activation='relu')(X)\nX = Dense(10, activation='relu')(X)\nX = Dense(1, activation='linear')(X)\nfinal_model = Model(inputs=[cnn_model.input, meta_model.input], outputs=X)","metadata":{"id":"wOLuLFpZxg_k","execution":{"iopub.status.busy":"2022-06-01T17:28:00.43791Z","iopub.execute_input":"2022-06-01T17:28:00.438385Z","iopub.status.idle":"2022-06-01T17:28:00.657986Z","shell.execute_reply.started":"2022-06-01T17:28:00.43835Z","shell.execute_reply":"2022-06-01T17:28:00.657158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class LearningRateReducerCb(tf.keras.callbacks.Callback):\n\n#     def on_epoch_end(self, epoch, logs={}):\n#         old_lr = self.model.optimizer.lr.read_value()\n#         new_lr = old_lr * 0.99\n#         print(\"\\nEpoch: {}. Reducing Learning Rate from {} to {}\".format(epoch, old_lr, new_lr))\n#         self.model.optimizer.lr.assign(new_lr)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T17:28:02.848227Z","iopub.execute_input":"2022-06-01T17:28:02.849183Z","iopub.status.idle":"2022-06-01T17:28:02.853632Z","shell.execute_reply.started":"2022-06-01T17:28:02.849135Z","shell.execute_reply":"2022-06-01T17:28:02.853025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model.compile(optimizer='adam', loss='mse',\n    metrics=[tf.keras.metrics.RootMeanSquaredError()])","metadata":{"id":"jVqx-32byWcH","execution":{"iopub.status.busy":"2022-06-01T17:28:03.707126Z","iopub.execute_input":"2022-06-01T17:28:03.707681Z","iopub.status.idle":"2022-06-01T17:28:03.727793Z","shell.execute_reply.started":"2022-06-01T17:28:03.707623Z","shell.execute_reply":"2022-06-01T17:28:03.726955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tf.keras.utils.plot_model(final_model, show_shapes=True, show_layer_names=False)","metadata":{"id":"SeltLEfRy9uT","execution":{"iopub.status.busy":"2022-06-01T17:28:04.678548Z","iopub.execute_input":"2022-06-01T17:28:04.678864Z","iopub.status.idle":"2022-06-01T17:28:04.682881Z","shell.execute_reply.started":"2022-06-01T17:28:04.678829Z","shell.execute_reply":"2022-06-01T17:28:04.682074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = DataLoader()\n\n\ndata.prepare(batch_data_index='all')\n\n(train_images, train_meta), y_train = data.get_train_data()\n(dev_images, dev_meta), y_dev = data.get_dev_data()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T17:28:05.167912Z","iopub.execute_input":"2022-06-01T17:28:05.168202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#history = final_model.fit(x=[train_images, train_meta], y=y_train, validation_data=([dev_images, dev_meta], y_dev), verbose=1, epochs=80, callbacks=[LearningRateReducerCb()])\nhistory = final_model.fit(x=[train_images, train_meta], y=y_train, validation_data=([dev_images, dev_meta], y_dev), verbose=1, epochs=80)","metadata":{"id":"bxmUheSAsXZL","outputId":"d87c522c-30f5-4df8-ade5-1444857d3a16","execution":{"iopub.status.busy":"2022-06-01T16:43:25.357333Z","iopub.execute_input":"2022-06-01T16:43:25.357931Z","iopub.status.idle":"2022-06-01T17:19:53.878096Z","shell.execute_reply.started":"2022-06-01T16:43:25.357892Z","shell.execute_reply":"2022-06-01T17:19:53.877281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import json\n# path = '/kaggle/working/output/h.txt'\n# # if os.path.exists(path):\n# # history = json.load(open(path, 'r'))[0]\n# # else:\n# histories = [i.history for i in histories]\n# json.dump(histories, open(path, 'w'))\n","metadata":{"id":"gqjtlouZ5lXR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# acc = []\n# val_acc = []\n# loss = []\n# val_loss = []\n\n\n# acc += history.history['root_mean_squared_error']\n# val_acc += history.history['val_root_mean_squared_error']\n# loss += history.history['loss']\n# val_loss += history.history['val_loss']\n\n# epochs = range(len(acc))\n\n# plt.plot(epochs, acc, 'r', label='Training accuracy')\n# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n# plt.title('Training and validation accuracy')\n# plt.legend(loc=0)\n# plt.figure()\n\n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:34:34.540384Z","iopub.execute_input":"2022-06-01T16:34:34.540853Z","iopub.status.idle":"2022-06-01T16:34:34.741357Z","shell.execute_reply.started":"2022-06-01T16:34:34.540802Z","shell.execute_reply":"2022-06-01T16:34:34.740624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = []\nval_acc = []\nloss = []\nval_loss = []\n\n\nacc += history.history['root_mean_squared_error']\nval_acc += history.history['val_root_mean_squared_error']\nloss += history.history['loss']\nval_loss += history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T17:26:51.474642Z","iopub.execute_input":"2022-06-01T17:26:51.475105Z","iopub.status.idle":"2022-06-01T17:26:51.566411Z","shell.execute_reply.started":"2022-06-01T17:26:51.474985Z","shell.execute_reply":"2022-06-01T17:26:51.565563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = final_model.predict([test_images, test_meta]).flatten()\ntest_predictions.shape","metadata":{"id":"UQrLFL3ktJHB","outputId":"6fe28f2e-0b46-48f5-8e4b-7dd3cf3bcb6f","execution":{"iopub.status.busy":"2022-06-01T17:27:13.328733Z","iopub.execute_input":"2022-06-01T17:27:13.328998Z","iopub.status.idle":"2022-06-01T17:27:13.341393Z","shell.execute_reply.started":"2022-06-01T17:27:13.328968Z","shell.execute_reply":"2022-06-01T17:27:13.340605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_result = pd.concat([X_test_data_ID, pd.Series(test_predictions)], axis=1)\npredicted_result.columns=['Id', \"Pawpularity\"]","metadata":{"id":"D6iPaKem_jGA","outputId":"4fb92dcc-44ac-443d-993d-5399aa94f228","execution":{"iopub.status.busy":"2022-06-01T17:19:55.118027Z","iopub.execute_input":"2022-06-01T17:19:55.11829Z","iopub.status.idle":"2022-06-01T17:19:55.125145Z","shell.execute_reply.started":"2022-06-01T17:19:55.118253Z","shell.execute_reply":"2022-06-01T17:19:55.123309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_result","metadata":{"execution":{"iopub.status.busy":"2022-06-01T17:19:55.126656Z","iopub.execute_input":"2022-06-01T17:19:55.126935Z","iopub.status.idle":"2022-06-01T17:19:55.140703Z","shell.execute_reply.started":"2022-06-01T17:19:55.126898Z","shell.execute_reply":"2022-06-01T17:19:55.139977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicted_result","metadata":{"id":"IyGPlxU9_nBA","outputId":"3ad14134-f699-4b81-a291-040789f2ed0c","execution":{"iopub.status.busy":"2022-06-01T15:16:26.925342Z","iopub.execute_input":"2022-06-01T15:16:26.926292Z","iopub.status.idle":"2022-06-01T15:16:26.955334Z","shell.execute_reply.started":"2022-06-01T15:16:26.92624Z","shell.execute_reply":"2022-06-01T15:16:26.95202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_result.to_csv('submission.csv', index=False)","metadata":{"id":"_uZwukYBEujJ","execution":{"iopub.status.busy":"2022-06-01T15:47:49.633424Z","iopub.execute_input":"2022-06-01T15:47:49.633675Z","iopub.status.idle":"2022-06-01T15:47:49.643603Z","shell.execute_reply.started":"2022-06-01T15:47:49.633649Z","shell.execute_reply":"2022-06-01T15:47:49.64281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_model.save(f'/kaggle/working/output/final_model_2.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T15:10:41.240712Z","iopub.execute_input":"2022-06-01T15:10:41.241382Z","iopub.status.idle":"2022-06-01T15:10:41.245592Z","shell.execute_reply.started":"2022-06-01T15:10:41.241348Z","shell.execute_reply":"2022-06-01T15:10:41.244808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! rm -r /kaggle/working/cached","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:25:48.737298Z","iopub.execute_input":"2022-06-01T13:25:48.737628Z","iopub.status.idle":"2022-06-01T13:25:49.417495Z","shell.execute_reply.started":"2022-06-01T13:25:48.737539Z","shell.execute_reply":"2022-06-01T13:25:49.416713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}