{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version 1.7\n!pip install timm\n!pip install nb_black\n%load_ext nb_black","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:27:59.506322Z","iopub.execute_input":"2021-09-28T12:27:59.506595Z","iopub.status.idle":"2021-09-28T12:29:17.49972Z","shell.execute_reply.started":"2021-09-28T12:27:59.506567Z","shell.execute_reply":"2021-09-28T12:29:17.49886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"ggplot\")\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.distributed.parallel_loader as pl\n\nimport timm\n\nimport gc\nimport os\nimport time\nimport random\nfrom datetime import datetime\n\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nfrom sklearn import model_selection, metrics\nfrom sklearn.model_selection import StratifiedKFold\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:17.502454Z","iopub.execute_input":"2021-09-28T12:29:17.502775Z","iopub.status.idle":"2021-09-28T12:29:20.960738Z","shell.execute_reply.started":"2021-09-28T12:29:17.50273Z","shell.execute_reply":"2021-09-28T12:29:20.959913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLD = 0","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:20.962061Z","iopub.execute_input":"2021-09-28T12:29:20.962392Z","iopub.status.idle":"2021-09-28T12:29:20.970221Z","shell.execute_reply.started":"2021-09-28T12:29:20.962359Z","shell.execute_reply":"2021-09-28T12:29:20.9694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For parallelization in TPUs\nos.environ[\"XLA_USE_BF16\"] = \"1\"\nos.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\"","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:20.9725Z","iopub.execute_input":"2021-09-28T12:29:20.972974Z","iopub.status.idle":"2021-09-28T12:29:21.027902Z","shell.execute_reply.started":"2021-09-28T12:29:20.972933Z","shell.execute_reply":"2021-09-28T12:29:21.026941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results\n    \n    Arguments:\n        seed {int} -- Number of the seed\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(28)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.029676Z","iopub.execute_input":"2021-09-28T12:29:21.030138Z","iopub.status.idle":"2021-09-28T12:29:21.050751Z","shell.execute_reply.started":"2021-09-28T12:29:21.030097Z","shell.execute_reply":"2021-09-28T12:29:21.049938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# general global variables\nDATA_PATH = \"../input/petfinder-pawpularity-score\"\nTRAIN_PATH = \"../input/petfinder-pawpularity-score/train\"\nTEST_PATH = \"../input/petfinder-pawpularity-score/test\"\nMODEL_PATH = (\n    \"../input/vit-base-models-pretrained-pytorch/jx_vit_base_p16_224-80ecf9dd.pth\"\n)\nBASE_DIR = \"../input/petfinder-pawpularity-score\"\nIMG_DIR = \"train\"\n\n# model specific global variables\nIMG_SIZE = 384\nBATCH_SIZE = 16\nLR = 4e-05\nGAMMA = 0.7\nN_EPOCHS = 4\n\n\nclass TrainConfig:\n    batch_size = BATCH_SIZE\n    num_workers = 4\n    epochs = N_EPOCHS\n    lr = LR\n    img_size = IMG_SIZE","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.052434Z","iopub.execute_input":"2021-09-28T12:29:21.052762Z","iopub.status.idle":"2021-09-28T12:29:21.074022Z","shell.execute_reply.started":"2021-09-28T12:29:21.052711Z","shell.execute_reply":"2021-09-28T12:29:21.073166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.075583Z","iopub.execute_input":"2021-09-28T12:29:21.076062Z","iopub.status.idle":"2021-09-28T12:29:21.157036Z","shell.execute_reply.started":"2021-09-28T12:29:21.076011Z","shell.execute_reply":"2021-09-28T12:29:21.156142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_FOLDS = 5\ntrain_df[\"kfold\"] = -1\nskf = StratifiedKFold(n_splits=N_FOLDS)\ntrain_df[\"groups\"] = pd.cut(train_df[\"Pawpularity\"], bins=10, labels=False)\ntarget = train_df[\"groups\"]\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(target, target)):\n    train_df.loc[val_idx, 'kfold'] = fold\ntrain_df = train_df.drop([\"groups\"], axis=1)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.15838Z","iopub.execute_input":"2021-09-28T12:29:21.158651Z","iopub.status.idle":"2021-09-28T12:29:21.21462Z","shell.execute_reply.started":"2021-09-28T12:29:21.158615Z","shell.execute_reply":"2021-09-28T12:29:21.213841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = train_df[train_df[\"kfold\"] == FOLD]\ntrain_df = train_df[train_df[\"kfold\"] != FOLD]\n\ntrain_df = train_df.drop([\"kfold\"], axis=1)\nval_df = val_df.drop([\"kfold\"], axis=1)\n\nprint(f\"Train Size: {train_df.shape}\")\nprint(f\"Validation Size: {val_df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.21575Z","iopub.execute_input":"2021-09-28T12:29:21.216029Z","iopub.status.idle":"2021-09-28T12:29:21.240879Z","shell.execute_reply.started":"2021-09-28T12:29:21.215999Z","shell.execute_reply":"2021-09-28T12:29:21.240255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_augs():\n    return A.Compose(\n        [\n            A.RandomResizedCrop(TrainConfig.img_size, TrainConfig.img_size),\n            A.OneOf(\n                [\n                    A.HueSaturationValue(\n                        hue_shift_limit=0.2,\n                        sat_shift_limit=0.2,\n                        val_shift_limit=0.2,\n                        p=0.9,\n                    ),\n                    A.RandomBrightnessContrast(\n                        brightness_limit=0.2, contrast_limit=0.2, p=0.9\n                    ),\n                ],\n                p=0.9,\n            ),\n            A.ToGray(p=0.01),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n            ToTensorV2(p=1.0),\n        ],\n        p=1.0,\n    )\n\n\ndef get_valid_augs():\n    return A.Compose(\n        [\n            A.Resize(height=TrainConfig.img_size, width=TrainConfig.img_size, p=1.0),\n            ToTensorV2(p=1.0),\n        ],\n        p=1.0,\n    )","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.24307Z","iopub.execute_input":"2021-09-28T12:29:21.243661Z","iopub.status.idle":"2021-09-28T12:29:21.282758Z","shell.execute_reply.started":"2021-09-28T12:29:21.243627Z","shell.execute_reply":"2021-09-28T12:29:21.281912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetFinderDataset(Dataset):\n    def __init__(self, df, augs=None):\n        self.df = df\n        self.augs = augs\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        image = self._load_image(self.df[\"Id\"].iloc[index])\n\n        # Apply image augmentations if available\n        if self.augs:\n            image = self.augs(image=image)[\"image\"]\n\n        return image, self.df[\"Pawpularity\"].iloc[index]\n\n    def _load_image(self, image_id):\n        image = cv2.imread(f\"{BASE_DIR}/{IMG_DIR}/{image_id}.jpg\", cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        return image","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.283855Z","iopub.execute_input":"2021-09-28T12:29:21.284072Z","iopub.status.idle":"2021-09-28T12:29:21.309897Z","shell.execute_reply.started":"2021-09-28T12:29:21.284046Z","shell.execute_reply":"2021-09-28T12:29:21.309157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = PetFinderDataset(df=train_df, augs=get_train_augs())\nvalid_dataset = PetFinderDataset(df=val_df, augs=get_valid_augs())\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=TrainConfig.batch_size,\n    pin_memory=False,\n    num_workers=TrainConfig.num_workers,\n)\n\nvalid_loader = DataLoader(\n    valid_dataset,\n    batch_size=TrainConfig.batch_size,\n    pin_memory=False,\n    num_workers=TrainConfig.num_workers,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.310942Z","iopub.execute_input":"2021-09-28T12:29:21.311564Z","iopub.status.idle":"2021-09-28T12:29:21.334247Z","shell.execute_reply.started":"2021-09-28T12:29:21.311533Z","shell.execute_reply":"2021-09-28T12:29:21.333436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Available Vision Transformer Models: \")\ntimm.list_models(\"vit*\")","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.335396Z","iopub.execute_input":"2021-09-28T12:29:21.335629Z","iopub.status.idle":"2021-09-28T12:29:21.350232Z","shell.execute_reply.started":"2021-09-28T12:29:21.335604Z","shell.execute_reply":"2021-09-28T12:29:21.349319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ViT(nn.Module):\n    def __init__(self, pretrained=False):\n\n        super(ViT, self).__init__()\n\n        self.model = timm.create_model(\"vit_base_patch32_384\", pretrained=pretrained)\n        self.model.head = nn.Linear(self.model.head.in_features, 1)\n\n    def forward(self, x):\n        return self.model(x)\n\n    def train_one_epoch(self, train_loader, criterion, optimizer, device):\n        # keep track of training loss\n        epoch_loss = 0.0\n\n        ###################\n        # train the model #\n        ###################\n        self.model.train()\n        for i, (data, target) in enumerate(train_loader):\n            # move tensors to GPU if CUDA is available\n            if device.type == \"cuda\":\n                data, target = data.cuda(), target.cuda()\n            elif device.type == \"xla\":\n                data = data.to(device, dtype=torch.float32)\n                target = target.to(device, dtype=torch.int64)\n\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = self.forward(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # update training loss\n            epoch_loss += loss\n\n            # perform a single optimization step (parameter update)\n            if device.type == \"xla\":\n                xm.optimizer_step(optimizer)\n\n                if i % 100 == 0:\n                    xm.master_print(f\"\\tBATCH {i+1}/{len(train_loader)} - LOSS: {loss}\")\n\n            else:\n                optimizer.step()\n\n        return epoch_loss / len(train_loader)\n\n    def validate_one_epoch(self, valid_loader, criterion, device):\n        # keep track of validation loss\n        valid_loss = 0.0\n\n        ######################\n        # validate the model #\n        ######################\n        self.model.eval()\n        for data, target in valid_loader:\n            # move tensors to GPU if CUDA is available\n            if device.type == \"cuda\":\n                data, target = data.cuda(), target.cuda()\n            elif device.type == \"xla\":\n                data = data.to(device, dtype=torch.float32)\n                target = target.to(device, dtype=torch.int64)\n\n            with torch.no_grad():\n                # forward pass: compute predicted outputs by passing inputs to the model\n                output = self.model(data)\n                # calculate the batch loss\n                loss = criterion(output, target)\n                # update average validation loss\n                valid_loss += loss\n\n        return valid_loss / len(valid_loader)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.352839Z","iopub.execute_input":"2021-09-28T12:29:21.353266Z","iopub.status.idle":"2021-09-28T12:29:21.407864Z","shell.execute_reply.started":"2021-09-28T12:29:21.353234Z","shell.execute_reply":"2021-09-28T12:29:21.406952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_tpu(\n    model, epochs, device, criterion, optimizer, train_loader, valid_loader=None\n):\n\n    valid_loss_min = np.Inf  # track change in validation loss\n\n    # keeping track of losses as it happen\n    train_losses = []\n    valid_losses = []\n\n    for epoch in range(1, epochs + 1):\n        gc.collect()\n        para_train_loader = pl.ParallelLoader(train_loader, [device])\n\n        xm.master_print(f\"{'='*50}\")\n        xm.master_print(f\"EPOCH {epoch} - TRAINING...\")\n        train_loss = model.train_one_epoch(\n            para_train_loader.per_device_loader(device), criterion, optimizer, device\n        )\n        xm.master_print(\n            f\"\\n\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}\\n\"\n        )\n        train_losses.append(train_loss)\n        gc.collect()\n\n        if valid_loader is not None:\n            gc.collect()\n            para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n            xm.master_print(f\"EPOCH {epoch} - VALIDATING...\")\n            valid_loss = model.validate_one_epoch(\n                para_valid_loader.per_device_loader(device), criterion, device\n            )\n            xm.master_print(f\"\\t[VALID] LOSS: {valid_loss}\\n\")\n            valid_losses.append(valid_loss)\n            gc.collect()\n\n            # log to wandb\n#             wandb.log(\n#                 {\n#                     \"Train Loss\": train_loss,\n#                     \"Validation Loss\": valid_loss,\n#                 }\n#             )\n\n            # save model if validation loss has decreased\n            if valid_loss <= valid_loss_min and epoch != 1:\n                xm.master_print(\n                    \"Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...\".format(\n                        valid_loss_min, valid_loss\n                    )\n                )\n            #                 xm.save(model.state_dict(), 'best_model.pth')\n\n            valid_loss_min = valid_loss\n\n    return {\n        \"train_loss\": train_losses,\n        \"valid_losses\": valid_losses,\n    }","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.409156Z","iopub.execute_input":"2021-09-28T12:29:21.409485Z","iopub.status.idle":"2021-09-28T12:29:21.448676Z","shell.execute_reply.started":"2021-09-28T12:29:21.409452Z","shell.execute_reply":"2021-09-28T12:29:21.447794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ViT(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:21.449895Z","iopub.execute_input":"2021-09-28T12:29:21.450202Z","iopub.status.idle":"2021-09-28T12:29:33.110747Z","shell.execute_reply.started":"2021-09-28T12:29:21.450171Z","shell.execute_reply":"2021-09-28T12:29:33.109946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\n# wandb.watch(model)\nprint(f\"The model has {count_parameters(model):,} trainable parameters\")","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:33.11219Z","iopub.execute_input":"2021-09-28T12:29:33.112723Z","iopub.status.idle":"2021-09-28T12:29:33.128425Z","shell.execute_reply.started":"2021-09-28T12:29:33.112684Z","shell.execute_reply":"2021-09-28T12:29:33.127264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self, eps=1e-6):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        self.eps = eps\n\n    def forward(self, yhat, y):\n        loss = torch.sqrt(self.mse(yhat, y.float()) + self.eps)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:33.129732Z","iopub.execute_input":"2021-09-28T12:29:33.129975Z","iopub.status.idle":"2021-09-28T12:29:33.145904Z","shell.execute_reply.started":"2021-09-28T12:29:33.129949Z","shell.execute_reply":"2021-09-28T12:29:33.14494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _run():\n    train_dataset = PetFinderDataset(df=train_df, augs=get_train_augs())\n    valid_dataset = PetFinderDataset(df=val_df, augs=get_valid_augs())\n\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True,\n    )\n\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n        valid_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False,\n    )\n\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=TrainConfig.batch_size,\n        pin_memory=False,\n        num_workers=TrainConfig.num_workers,\n    )\n\n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=TrainConfig.batch_size,\n        pin_memory=False,\n        num_workers=TrainConfig.num_workers,\n    )\n\n#     criterion = nn.CrossEntropyLoss()\n    criterion = RMSELoss()\n    device = xm.xla_device()\n    model.to(device)\n\n    lr = LR * xm.xrt_world_size()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    xm.master_print(f\"INITIALIZING TRAINING ON {xm.xrt_world_size()} TPU CORES\")\n    start_time = datetime.now()\n    xm.master_print(f\"Start Time: {start_time}\")\n\n    logs = fit_tpu(\n        model=model,\n        epochs=N_EPOCHS,\n        device=device,\n        criterion=criterion,\n        optimizer=optimizer,\n        train_loader=train_loader,\n        valid_loader=valid_loader,\n    )\n\n    xm.master_print(f\"Execution time: {datetime.now() - start_time}\")\n\n    xm.master_print(\"Saving Model\")\n    xm.save(\n        model.state_dict(), f'model_5e_{datetime.now().strftime(\"%Y%m%d-%H%M\")}.pth'\n    )","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:33.147081Z","iopub.execute_input":"2021-09-28T12:29:33.147496Z","iopub.status.idle":"2021-09-28T12:29:33.193663Z","shell.execute_reply.started":"2021-09-28T12:29:33.147466Z","shell.execute_reply":"2021-09-28T12:29:33.192883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_run()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T12:29:33.19489Z","iopub.execute_input":"2021-09-28T12:29:33.195117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}