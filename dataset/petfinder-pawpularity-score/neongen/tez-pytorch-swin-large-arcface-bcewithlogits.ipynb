{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Changes\n- Classification\n- Custom loss (ArcFace + BCEWithLogits)\n- Custom Architecture\n- Backbone: swin_large_patch4_window12_384_in22k\n\n**I hope you find it helpful :) !**","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/tez-lib/\")\nsys.path.append(\"../input/timmmaster/\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.093588,"end_time":"2021-09-23T15:47:28.583643","exception":false,"start_time":"2021-09-23T15:47:28.490055","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:46.956755Z","iopub.execute_input":"2021-10-11T14:34:46.957074Z","iopub.status.idle":"2021-10-11T14:34:47.061615Z","shell.execute_reply.started":"2021-10-11T14:34:46.956993Z","shell.execute_reply":"2021-10-11T14:34:47.06077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torchvision.io import read_image\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom sklearn.preprocessing import StandardScaler\nimport math","metadata":{"papermill":{"duration":7.952676,"end_time":"2021-09-23T15:47:36.545018","exception":false,"start_time":"2021-09-23T15:47:28.592342","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:47.066044Z","iopub.execute_input":"2021-10-11T14:34:47.066685Z","iopub.status.idle":"2021-10-11T14:34:55.692716Z","shell.execute_reply.started":"2021-10-11T14:34:47.066643Z","shell.execute_reply":"2021-10-11T14:34:55.691887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=2021):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T14:34:55.696248Z","iopub.execute_input":"2021-10-11T14:34:55.696457Z","iopub.status.idle":"2021-10-11T14:34:55.705396Z","shell.execute_reply.started":"2021-10-11T14:34:55.696433Z","shell.execute_reply":"2021-10-11T14:34:55.704529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class args:\n    batch_size = 8\n    image_size = 384\n    coeff = 0.2\n    epochs = 20\n    learning_rate = 1e-4\n    fold = 0","metadata":{"papermill":{"duration":0.014205,"end_time":"2021-09-23T15:47:36.567331","exception":false,"start_time":"2021-09-23T15:47:36.553126","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:55.707552Z","iopub.execute_input":"2021-10-11T14:34:55.707854Z","iopub.status.idle":"2021-10-11T14:34:55.713908Z","shell.execute_reply.started":"2021-10-11T14:34:55.707819Z","shell.execute_reply":"2021-10-11T14:34:55.713228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item] / 100.\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }","metadata":{"papermill":{"duration":0.019847,"end_time":"2021-09-23T15:47:36.595083","exception":false,"start_time":"2021-09-23T15:47:36.575236","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:55.714994Z","iopub.execute_input":"2021-10-11T14:34:55.715325Z","iopub.status.idle":"2021-10-11T14:34:55.725766Z","shell.execute_reply.started":"2021-10-11T14:34:55.715291Z","shell.execute_reply":"2021-10-11T14:34:55.724715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcFaceLoss(nn.modules.Module):\n    def __init__(self, s=30.0, m=0.5):\n        super().__init__()\n        self.crit = nn.BCEWithLogitsLoss()\n        self.s = s\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, logits, labels):\n        logits = logits.float()\n        cosine = logits\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n\n        output = (labels * phi) + ((1.0 - labels) * cosine)\n        output *= self.s\n        loss = self.crit(output, labels)\n        return loss / 2\n    \nclass ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        stdv = 1. / math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n\n    def forward(self, features):\n        cosine = F.linear(F.normalize(features), F.normalize(self.weight))\n        return cosine","metadata":{"execution":{"iopub.status.busy":"2021-10-11T14:34:55.726946Z","iopub.execute_input":"2021-10-11T14:34:55.727302Z","iopub.status.idle":"2021-10-11T14:34:55.74037Z","shell.execute_reply.started":"2021-10-11T14:34:55.727268Z","shell.execute_reply":"2021-10-11T14:34:55.739678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularModel(tez.Model):\n    def __init__(self):\n        super().__init__()\n\n        self.model = timm.create_model(\"swin_large_patch4_window12_384_in22k\", pretrained=True, in_chans=3)\n        in_features = self.model.head.in_features\n        self.model.head = nn.Identity()\n        self.neck = nn.Sequential(\n            nn.BatchNorm1d(in_features),\n            nn.Linear(in_features, 512, bias=False),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(512),\n            nn.Linear(512, 512, bias=False),\n            nn.BatchNorm1d(512)\n        )\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Sequential(\n            nn.Linear(in_features, 512, bias=False),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, 1)\n        )\n        self.arc_margin_product = ArcMarginProduct(512, 1)\n        \n        self.step_scheduler_after = \"epoch\"\n\n    def monitor_metrics(self, outputs, targets):\n        outputs = outputs.cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        rmse = metrics.mean_squared_error(targets, outputs, squared=False)\n        return {\"rmse\": rmse}\n\n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n        return sch\n\n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=args.learning_rate)\n        return opt\n\n    def forward(self, image, features, targets=None):\n\n        x = self.model(image)\n        x = self.dropout(x)\n        x_ = self.neck(x)\n        x_ = self.arc_margin_product(x_)\n        x = self.out(x)\n        \n        if targets is not None:\n            loss_classification = nn.BCEWithLogitsLoss()(x, targets.view(-1, 1))\n            loss_metric = ArcFaceLoss()(x_, targets.view(-1, 1))\n            coeff = args.coeff\n            loss =  loss_classification * (1 - coeff) + loss_metric * coeff\n            \n            metrics = self.monitor_metrics(torch.sigmoid(x) * 100, targets * 100)\n            return x, loss, metrics\n        return x, 0, {}","metadata":{"papermill":{"duration":0.020353,"end_time":"2021-09-23T15:47:36.623166","exception":false,"start_time":"2021-09-23T15:47:36.602813","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:55.741578Z","iopub.execute_input":"2021-10-11T14:34:55.742444Z","iopub.status.idle":"2021-10-11T14:34:55.759563Z","shell.execute_reply.started":"2021-10-11T14:34:55.742408Z","shell.execute_reply":"2021-10-11T14:34:55.758812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.RandomResizedCrop(args.image_size, args.image_size, p=0.5),\n        albumentations.HorizontalFlip(p=0.5),\n        albumentations.VerticalFlip(p=0.5),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","metadata":{"papermill":{"duration":0.017942,"end_time":"2021-09-23T15:47:36.648904","exception":false,"start_time":"2021-09-23T15:47:36.630962","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:55.762326Z","iopub.execute_input":"2021-10-11T14:34:55.762558Z","iopub.status.idle":"2021-10-11T14:34:55.77329Z","shell.execute_reply.started":"2021-10-11T14:34:55.762531Z","shell.execute_reply":"2021-10-11T14:34:55.772617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/same-old-creating-folds/train_10folds.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-11T14:34:55.776022Z","iopub.execute_input":"2021-10-11T14:34:55.776805Z","iopub.status.idle":"2021-10-11T14:34:55.820098Z","shell.execute_reply.started":"2021-10-11T14:34:55.776768Z","shell.execute_reply":"2021-10-11T14:34:55.819399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_features = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n]","metadata":{"execution":{"iopub.status.busy":"2021-10-11T14:34:55.822176Z","iopub.execute_input":"2021-10-11T14:34:55.822368Z","iopub.status.idle":"2021-10-11T14:34:55.829984Z","shell.execute_reply.started":"2021-10-11T14:34:55.822345Z","shell.execute_reply":"2021-10-11T14:34:55.829222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df[df.kfold != args.fold].reset_index(drop=True)\ndf_valid = df[df.kfold == args.fold].reset_index(drop=True)","metadata":{"papermill":{"duration":0.06482,"end_time":"2021-09-23T15:47:36.721942","exception":false,"start_time":"2021-09-23T15:47:36.657122","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:55.833459Z","iopub.execute_input":"2021-10-11T14:34:55.833644Z","iopub.status.idle":"2021-10-11T14:34:55.859478Z","shell.execute_reply.started":"2021-10-11T14:34:55.833623Z","shell.execute_reply":"2021-10-11T14:34:55.858786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\nvalid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]","metadata":{"papermill":{"duration":0.018697,"end_time":"2021-09-23T15:47:36.748479","exception":false,"start_time":"2021-09-23T15:47:36.729782","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:55.860535Z","iopub.execute_input":"2021-10-11T14:34:55.860771Z","iopub.status.idle":"2021-10-11T14:34:55.869062Z","shell.execute_reply.started":"2021-10-11T14:34:55.86074Z","shell.execute_reply":"2021-10-11T14:34:55.868211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = PawpularDataset(\n    image_paths=train_img_paths,\n    dense_features=df_train[dense_features].values,\n    targets=df_train.Pawpularity.values,\n    augmentations=train_aug,\n)\n\nvalid_dataset = PawpularDataset(\n    image_paths=valid_img_paths,\n    dense_features=df_valid[dense_features].values,\n    targets=df_valid.Pawpularity.values,\n    augmentations=valid_aug,\n)\n","metadata":{"papermill":{"duration":0.016149,"end_time":"2021-09-23T15:47:36.772704","exception":false,"start_time":"2021-09-23T15:47:36.756555","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:55.870609Z","iopub.execute_input":"2021-10-11T14:34:55.870885Z","iopub.status.idle":"2021-10-11T14:34:55.879965Z","shell.execute_reply.started":"2021-10-11T14:34:55.870853Z","shell.execute_reply":"2021-10-11T14:34:55.879264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PawpularModel()\n\nes = EarlyStopping(\n    monitor=\"valid_rmse\",\n    model_path=f\"model_f{args.fold}.bin\",\n    patience=3,\n    mode=\"min\",\n    save_weights_only=True,\n)\n\nmodel.fit(\n    train_dataset,\n    valid_dataset=valid_dataset,\n    train_bs=args.batch_size,\n    valid_bs=2*args.batch_size,\n    device=\"cuda\",\n    epochs=args.epochs,\n    callbacks=[es],\n    fp16=True\n)","metadata":{"papermill":{"duration":650.468568,"end_time":"2021-09-23T15:58:27.24912","exception":false,"start_time":"2021-09-23T15:47:36.780552","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T14:34:55.881326Z","iopub.execute_input":"2021-10-11T14:34:55.881687Z","iopub.status.idle":"2021-10-11T14:35:38.06214Z","shell.execute_reply.started":"2021-10-11T14:34:55.881575Z","shell.execute_reply":"2021-10-11T14:35:38.059998Z"},"trusted":true},"execution_count":null,"outputs":[]}]}