{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport cv2\nimport gc\nimport seaborn as sns\nimport albumentations as A\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\n\nsys.path.append(\"../input/efficientnet\")\n\nfrom  efficientnet_pytorch import EfficientNet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-04T11:36:53.917251Z","iopub.execute_input":"2021-12-04T11:36:53.917631Z","iopub.status.idle":"2021-12-04T11:36:57.870938Z","shell.execute_reply.started":"2021-12-04T11:36:53.917534Z","shell.execute_reply":"2021-12-04T11:36:57.870049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1.  This kernel is an attempt to understand the behaviour of the traiing baseline model.[https://www.kaggle.com/narendra/pawpularity-baseline-submission]\n2. Training Data of scores is similar to gausssian, which has some classes are underrepresented with Pawpularity <=10 and >60\n3. During baseline training there will be a chance that model could be more biased to the higher representation images like around (20-40), due to more sampling.\n4. As a result images with higher scores might be pulled down and lower scores can be pushed up which can significantly change the distribution of model to the expected.","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:57.872405Z","iopub.execute_input":"2021-12-04T11:36:57.872732Z","iopub.status.idle":"2021-12-04T11:36:57.881283Z","shell.execute_reply.started":"2021-12-04T11:36:57.8727Z","shell.execute_reply":"2021-12-04T11:36:57.878052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything():\n    np.random.seed(10)\n    random.seed(10)\n    torch.manual_seed(10)\n\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:57.882661Z","iopub.execute_input":"2021-12-04T11:36:57.883022Z","iopub.status.idle":"2021-12-04T11:36:57.899073Z","shell.execute_reply.started":"2021-12-04T11:36:57.882985Z","shell.execute_reply":"2021-12-04T11:36:57.897783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_folder=\"../input/pawpularity-resize-256/resized\"\ntrain_df=pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\nprint(train_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:57.903195Z","iopub.execute_input":"2021-12-04T11:36:57.903681Z","iopub.status.idle":"2021-12-04T11:36:57.948348Z","shell.execute_reply.started":"2021-12-04T11:36:57.903637Z","shell.execute_reply":"2021-12-04T11:36:57.94769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['bin_num'] = train_df.Pawpularity.apply(lambda x: min(9, x//10))\ntrain_df['score'] = train_df.Pawpularity/100\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:57.949319Z","iopub.execute_input":"2021-12-04T11:36:57.950064Z","iopub.status.idle":"2021-12-04T11:36:57.986057Z","shell.execute_reply.started":"2021-12-04T11:36:57.950026Z","shell.execute_reply":"2021-12-04T11:36:57.985467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def kfold(train_df, k=5):\n    image_ids=train_df.Id.values\n    bins=train_df.bin_num.unique()\n    train_df=train_df.sample(frac=1.0, random_state=22)\n    fold_map={}\n    \n    for bin_num in bins:\n        image_ids=train_df[train_df.bin_num == bin_num].Id.values\n        num_images=len(image_ids)\n        slice_length=num_images//k\n        for i in range(0, num_images, slice_length):\n            fold_num=min(i//slice_length, k-1)\n            for j in range(i, i+slice_length):\n                if j >= num_images:\n                    break\n                fold_map[ image_ids[j] ] = fold_num\n    \n    df=train_df.copy()\n    df['fold'] = df['Id'].apply(lambda x: fold_map[x])\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:57.986934Z","iopub.execute_input":"2021-12-04T11:36:57.987663Z","iopub.status.idle":"2021-12-04T11:36:57.994623Z","shell.execute_reply.started":"2021-12-04T11:36:57.987628Z","shell.execute_reply":"2021-12-04T11:36:57.993761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformations","metadata":{}},{"cell_type":"code","source":"train_transform=A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(p=0.7, limit=(-20, 20), border_mode=2),\n    A.RGBShift(p=1.0, r_shift_limit=(-15, 15),\n               g_shift_limit=(-15, 15),\n               b_shift_limit=(-15, 15)\n              ),\n    A.RandomBrightnessContrast(p=1.0),\n    A.CoarseDropout(p=1.0,min_holes=5, max_holes=10,\n                    min_width=8, max_width=12,\n                    min_height=8, max_height=12),\n    \n    A.Normalize(p=1.0)\n])\nval_transform = A.Compose([A.Normalize(p=1.0)])","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:57.996065Z","iopub.execute_input":"2021-12-04T11:36:57.996546Z","iopub.status.idle":"2021-12-04T11:36:58.009964Z","shell.execute_reply.started":"2021-12-04T11:36:57.996501Z","shell.execute_reply":"2021-12-04T11:36:58.009187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Images","metadata":{}},{"cell_type":"code","source":"def read_image(image_name, phase):\n    filepath=os.path.join(train_folder, \"{}.jpg\".format(image_name))\n    img=cv2.imread(filepath)\n    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    if phase!='eval':\n        img=train_transform(image = img)['image']\n    else:\n        img=val_transform(image = img)['image']\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:58.01147Z","iopub.execute_input":"2021-12-04T11:36:58.011792Z","iopub.status.idle":"2021-12-04T11:36:58.032053Z","shell.execute_reply.started":"2021-12-04T11:36:58.01175Z","shell.execute_reply":"2021-12-04T11:36:58.031372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class Baseline(nn.Module):\n    def __init__(self):\n        super(Baseline, self).__init__()\n        self.efficient_net=EfficientNet.from_pretrained('efficientnet-b0', include_top=True)\n        self.avg_pooling=nn.AdaptiveAvgPool2d(1)\n        \n        self.fc=nn.Sequential(\n            nn.BatchNorm1d(1280),\n            nn.Linear(1280, 512),\n            nn.SiLU(),\n            nn.Dropout(0.2),\n            \n            nn.BatchNorm1d(512),\n            nn.Linear(512, 1)\n        )\n    def forward(self, x):\n        batch_size=x.size(0)\n        x=self.efficient_net.extract_features(x)\n        x=self.avg_pooling(x).view(batch_size, -1)\n        x=self.fc(x)\n        x=torch.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:58.033297Z","iopub.execute_input":"2021-12-04T11:36:58.033752Z","iopub.status.idle":"2021-12-04T11:36:58.047035Z","shell.execute_reply.started":"2021-12-04T11:36:58.03371Z","shell.execute_reply":"2021-12-04T11:36:58.046051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset and dataloaders","metadata":{}},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, image_ids, scores, phase):\n        self.image_ids=image_ids\n        self.scores=scores\n        self.phase=phase\n    def __getitem__(self, idx):\n        image_name = self.image_ids[idx]\n        score=self.scores[idx]\n        img=read_image(image_name, self.phase)\n        \n        X=torch.tensor(img, dtype=torch.float32).transpose(0, 2)\n        y=torch.tensor(score, dtype=torch.float32)\n        return (X, y)\n        \n    def __len__(self):\n        return len(self.image_ids)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:58.048985Z","iopub.execute_input":"2021-12-04T11:36:58.049531Z","iopub.status.idle":"2021-12-04T11:36:58.062388Z","shell.execute_reply.started":"2021-12-04T11:36:58.049477Z","shell.execute_reply":"2021-12-04T11:36:58.061408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataloaders(fold_num, df):\n    BATCH_SIZE=64\n    \n    train_image_ids=df[df.fold!=fold_num].Id.values\n    train_scores=df[df.fold!=fold_num].score.values\n    \n    val_image_ids=df[df.fold==fold_num].Id.values\n    val_scores=df[df.fold==fold_num].score.values\n    \n    train_dataset=Dataset(train_image_ids, train_scores, phase='train')\n    val_dataset=Dataset(val_image_ids, val_scores, phase='eval')\n    \n    train_dataloader=torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_dataloader=torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n    \n    return (train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:39:07.054395Z","iopub.execute_input":"2021-12-04T11:39:07.055214Z","iopub.status.idle":"2021-12-04T11:39:07.061391Z","shell.execute_reply.started":"2021-12-04T11:39:07.055172Z","shell.execute_reply":"2021-12-04T11:39:07.060534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training","metadata":{}},{"cell_type":"code","source":"def rmse(y, yhat):\n    yerr=torch.abs(y-yhat)\n    rmse_loss=torch.sqrt( torch.mean( yerr**2 ) )\n    return rmse_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:58.081789Z","iopub.execute_input":"2021-12-04T11:36:58.082247Z","iopub.status.idle":"2021-12-04T11:36:58.093813Z","shell.execute_reply.started":"2021-12-04T11:36:58.082217Z","shell.execute_reply":"2021-12-04T11:36:58.093044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(val_dataloader, model):\n    model.eval()\n    eval_loss = 0\n    for it, (X, y) in enumerate(val_dataloader):\n        X=X.to(device)\n        y=y.to(device)\n        \n        with torch.no_grad():\n            yhat=model(X)\n            rmse_loss=rmse(y, yhat)\n            eval_loss+=rmse_loss\n    eval_loss/=len(val_dataloader)\n    return eval_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:36:58.094758Z","iopub.execute_input":"2021-12-04T11:36:58.095673Z","iopub.status.idle":"2021-12-04T11:36:58.106889Z","shell.execute_reply.started":"2021-12-04T11:36:58.09563Z","shell.execute_reply":"2021-12-04T11:36:58.106038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=torch.load(\"../input/pawpularity-baseline/model1.pth\", map_location=device)\nmodel=model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:37:33.662427Z","iopub.execute_input":"2021-12-04T11:37:33.662743Z","iopub.status.idle":"2021-12-04T11:37:33.942682Z","shell.execute_reply.started":"2021-12-04T11:37:33.662713Z","shell.execute_reply":"2021-12-04T11:37:33.941696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fold_df=kfold(train_df)\nval_df=train_fold_df[train_fold_df.fold==0].copy()\n\nval_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:38:32.338214Z","iopub.execute_input":"2021-12-04T11:38:32.338547Z","iopub.status.idle":"2021-12-04T11:38:32.382064Z","shell.execute_reply.started":"2021-12-04T11:38:32.338487Z","shell.execute_reply":"2021-12-04T11:38:32.381248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nval_image_ids=val_df.Id.values\nval_scores=val_df.score.values\nval_dataset=Dataset(val_image_ids, val_scores, phase='eval')\n\nval_dataloader=torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:42:34.295025Z","iopub.execute_input":"2021-12-04T11:42:34.29532Z","iopub.status.idle":"2021-12-04T11:42:34.300653Z","shell.execute_reply.started":"2021-12-04T11:42:34.295283Z","shell.execute_reply":"2021-12-04T11:42:34.299686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yval=[]\nmodel.eval()\nfor it, (X, _) in enumerate(val_dataloader):\n    if it%10 == 0:\n        print(it*64)\n    with torch.no_grad():\n        yhat=model(X)\n        yhat=yhat.view(-1).tolist()\n        yval+=yhat\nprint(len(yval))","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:43:12.193914Z","iopub.execute_input":"2021-12-04T11:43:12.19419Z","iopub.status.idle":"2021-12-04T11:47:09.322565Z","shell.execute_reply.started":"2021-12-04T11:43:12.19416Z","shell.execute_reply":"2021-12-04T11:47:09.321627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df['pred_score'] = yval\nval_df['pred_bin'] = val_df['pred_score'].apply(lambda x: min(9, (100*x)//10))\n\nval_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:48:04.181346Z","iopub.execute_input":"2021-12-04T11:48:04.181705Z","iopub.status.idle":"2021-12-04T11:48:04.204428Z","shell.execute_reply.started":"2021-12-04T11:48:04.181665Z","shell.execute_reply":"2021-12-04T11:48:04.203862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title(\"Score (Vs) Predicted Score\")\nsns.kdeplot(data=val_df[['score', 'pred_score']], fill=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-04T11:55:57.636697Z","iopub.execute_input":"2021-12-04T11:55:57.636998Z","iopub.status.idle":"2021-12-04T11:55:57.874733Z","shell.execute_reply.started":"2021-12-04T11:55:57.636964Z","shell.execute_reply":"2021-12-04T11:55:57.873746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. We can see the predicted model is more biased to the middle region with higher peak.","metadata":{}},{"cell_type":"markdown","source":"# lets check the distributions","metadata":{}},{"cell_type":"code","source":"_, ax=plt.subplots(nrows=2, ncols=1)\nsns.countplot(x=val_df.bin_num, ax=ax[0])\nsns.countplot(x=val_df.pred_bin, ax=ax[1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-04T12:14:19.438078Z","iopub.execute_input":"2021-12-04T12:14:19.438353Z","iopub.status.idle":"2021-12-04T12:14:19.734251Z","shell.execute_reply.started":"2021-12-04T12:14:19.438323Z","shell.execute_reply":"2021-12-04T12:14:19.733415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17, 5))\nsns.countplot(data=val_df, x='bin_num', hue='pred_bin')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-04T12:10:39.671902Z","iopub.execute_input":"2021-12-04T12:10:39.672178Z","iopub.status.idle":"2021-12-04T12:10:40.137389Z","shell.execute_reply.started":"2021-12-04T12:10:39.672148Z","shell.execute_reply":"2021-12-04T12:10:40.136486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Model ignored the training images below pawpularity score<10\n2. As expected there are spikes with predicted classes 2,3,4.","metadata":{}},{"cell_type":"markdown","source":"Furthur Improvements.\n\n1. Use classfication or distance representation to penalize samples that is predicted far away from original.\n2. Reduce the bias of overrepresented samples.\n3. using GAN's to increase the underrepresented samples.\n4. Training is overfitting , have to use better augmentations or auxilary tasks, to improve representations","metadata":{}}]}