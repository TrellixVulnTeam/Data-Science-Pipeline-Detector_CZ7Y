{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-3monthsold/pytorch-image-models-master 2')\nsys.path.append('../input/convnext')\nfrom timm import create_model\n#from timm.data.mixup import Mixup\nfrom fastai.vision.all import *\n#from fastai.callback.hook import *\nimport models.convnext\nimport models.convnext_isotropic\nimport timm\nfrom timm.models.registry import register_model\nimport utils\nimport fastai\n\nprint(\"Torch version:\", torch.__version__)\nprint(\"Timm version:\", timm.__version__)\nprint(\"Fast-ai version:\", fastai.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-14T14:16:39.820206Z","iopub.execute_input":"2022-01-14T14:16:39.820534Z","iopub.status.idle":"2022-01-14T14:16:44.676414Z","shell.execute_reply.started":"2022-01-14T14:16:39.820451Z","shell.execute_reply":"2022-01-14T14:16:44.675654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/albumentation-file/albumentations-1.0.3-py3-none-any.whl\n!pip install ../input/madgrad-file/madgrad-1.1-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:16:44.678243Z","iopub.execute_input":"2022-01-14T14:16:44.678507Z","iopub.status.idle":"2022-01-14T14:17:40.810596Z","shell.execute_reply.started":"2022-01-14T14:16:44.678468Z","shell.execute_reply":"2022-01-14T14:17:40.809784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import typing as tp\nsys.path.append(\"../input/volo-package\")\nfrom volo.models import volo_d1, volo_d2, volo_d3, volo_d4, volo_d5  # register models to timm\nfrom volo.utils import load_pretrained_weights as volo_load_weights","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:40.812213Z","iopub.execute_input":"2022-01-14T14:17:40.812479Z","iopub.status.idle":"2022-01-14T14:17:40.872082Z","shell.execute_reply.started":"2022-01-14T14:17:40.81244Z","shell.execute_reply":"2022-01-14T14:17:40.871319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from madgrad import MADGRAD\nfrom radam import Over9000\n\ndef WrapperMADGRAD(param_groups,**kwargs):\n    return OptimWrapper(param_groups,MADGRAD)\n\ndef WrapperOver9000(param_groups,**kwargs):\n    return OptimWrapper(param_groups,Over9000)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:40.874307Z","iopub.execute_input":"2022-01-14T14:17:40.87458Z","iopub.status.idle":"2022-01-14T14:17:40.897643Z","shell.execute_reply.started":"2022-01-14T14:17:40.874543Z","shell.execute_reply":"2022-01-14T14:17:40.896948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=999):\n    set_seed(seed, reproducible=True)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.use_deterministic_algorithms = True\n\n    \ndef petfinder_rmse(preds, target):\n    return 100 * torch.sqrt(F.mse_loss(F.sigmoid(preds.flatten()), target))\n\n    \nseed_everything(seed=365)\n\n# # Cant use internet, and timm library wants to find pretrained weights (downloads if not in specific directory)\n#     # so we make the directory\n# if not os.path.exists('/root/cache/torch/hub/checkpoints/'):\n#     os.makedirs('/root/.cache/torch/hub/checkpoints/')\n# !cp '../input/swin-transformer/swin_large_patch4_window7_224_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window7_224_22kto1k.pth'\n# !cp '../input/swin-transformer/swin_large_patch4_window7_224_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window7_224_22kto1k.pth'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-14T14:17:40.900042Z","iopub.execute_input":"2022-01-14T14:17:40.900683Z","iopub.status.idle":"2022-01-14T14:17:40.907192Z","shell.execute_reply.started":"2022-01-14T14:17:40.900638Z","shell.execute_reply":"2022-01-14T14:17:40.906393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass VoloModel(nn.Module):\n    \n    def __init__(self, \n                 base_name: str, \n                 dims_head: tp.List[int],\n                 pretrained=True, \n                 in_channels: int=3, \n                 image_size: int=224,\n                 drop_path_rate: float=0.1\n    ):\n        \"\"\"Initialize\"\"\"\n        self.base_name = base_name\n        super().__init__()\n        model_name = base_name.split(\"-\")[0]\n        assert timm.is_model(model_name), \"you can use only models in timm.\"\n        \n        if model_name[:4] == \"volo\":\n            base_model = timm.create_model(\n                model_name, img_size=image_size,\n                mix_token=False, \n                return_dense=False, \n                drop_path_rate=0.3, # 0.4,  0.1\n            )\n            in_features = base_model.head.in_features\n            if pretrained:\n                volo_load_weights(base_model, VOLO_CHECHPOINTS[base_name], strict=False)\n            \n            if in_channels != 3:\n                # # change input channel\n                # # I follow the manner used in timm.\n                first_conv = base_model.patch_embed.conv[0]\n                w_t = first_conv.weight.data  # shape: (out_ch, 3, 7, 7)\n                if in_channels == 1:\n                    new_w_t = w_t.sum(axis=1, keepdims=True)  # shape: (out_ch, 1, 7, 7)\n                else:\n                    n_repeats = (in_channels + 3 - 1) // 3\n                    new_w_t = w_t.repeat((1, n_repeats, 1, 1))\n                    new_w_t = new_w_t[:, :in_channels]\n                    new_w_t = new_w_t * 3 / in_channels  # shape: (out_ch, in_channels, 7, 7)\n\n                first_conv.weight.data = new_w_t\n        else:\n            base_model = timm.create_model(\n                base_name, pretrained=pretrained, in_chans=in_channels)\n            in_features = base_model.num_features\n            print(\"load imagenet pretrained:\", pretrained)\n            \n        base_model.reset_classifier(num_classes=0)\n        self.backbone = base_model\n        print(f\"{base_name}: {in_features}\")\n        \n        # # prepare head clasifier\n        if dims_head[0] is None:\n            dims_head[0] = in_features\n\n        layers_list = []\n        for i in range(len(dims_head) - 2):\n            in_dim, out_dim = dims_head[i: i + 2]\n            layers_list.extend([\n                nn.Linear(in_dim, out_dim),\n                nn.ReLU(), nn.Dropout(0.5),])\n        layers_list.append(\n            nn.Linear(dims_head[-2], dims_head[-1]))\n        self.head = nn.Sequential(*layers_list)\n\n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        h = self.backbone(x)\n        h = self.head(h)\n        return h\n    \n    \n########\nfrom radam import Over9000\n\ndef WrapperOver9000(param_groups,**kwargs):\n    return OptimWrapper(param_groups, Over9000)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-14T14:17:40.908877Z","iopub.execute_input":"2022-01-14T14:17:40.909402Z","iopub.status.idle":"2022-01-14T14:17:40.926307Z","shell.execute_reply.started":"2022-01-14T14:17:40.909363Z","shell.execute_reply":"2022-01-14T14:17:40.925529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImgClassifier(nn.Module):\n    def __init__(self, model_arch, n_class=1, in_channels=3,pretrained_path=''):\n        super().__init__()\n        self.model = timm.create_model(model_arch,in_chans=in_channels, pretrained=False)\n        self.model=self.load_pretrain(self.model,pretrained_path)\n        num_ftrs = self.model.head.in_features\n        self.model.head = nn.Linear(num_ftrs, n_class)\n    def load_pretrain(self,model,pretrained_path):\n        checkpoint = torch.load(pretrained_path, map_location='cpu')\n        print(\"Load ckpt from %s\" % pretrained_path)\n        checkpoint_model = checkpoint['model']\n        state_dict = model.state_dict()\n        for k in ['head.weight', 'head.bias']:\n            if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n                print(f\"Removing key {k} from pretrained checkpoint\")\n                del checkpoint_model[k]\n        utils.load_state_dict(model, checkpoint_model, prefix='')\n        return model\n    def forward(self, x):\n        x = self.model(x)\n        x=x.flatten()\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:40.927589Z","iopub.execute_input":"2022-01-14T14:17:40.928145Z","iopub.status.idle":"2022-01-14T14:17:40.938856Z","shell.execute_reply.started":"2022-01-14T14:17:40.928101Z","shell.execute_reply":"2022-01-14T14:17:40.938071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicImageModel(nn.Module):\n    \n    def __init__(self, \n                 base_name: str, \n                 dims_head: tp.List[int],\n                 pretrained=True, \n                 in_channels: int=3, \n                 image_size: int=224,\n                 drop_path_rate: float=0.1\n    ):\n        \"\"\"Initialize\"\"\"\n        self.base_name = base_name\n        super().__init__()\n        model_name = base_name.split(\"-\")[0]\n        assert timm.is_model(model_name), \"you can use only models in timm.\"\n        \n        if model_name[:4] == \"volo\":\n            base_model = timm.create_model(\n                model_name, img_size=image_size,\n                mix_token=False, \n                return_dense=False, \n                drop_path_rate=0.3, # 0.4,  0.1\n            )\n            in_features = base_model.head.in_features\n            if pretrained:\n                volo_load_weights(base_model, VOLO_CHECHPOINTS[base_name], strict=False)\n            \n            if in_channels != 3:\n                # # change input channel\n                # # I follow the manner used in timm.\n                first_conv = base_model.patch_embed.conv[0]\n                w_t = first_conv.weight.data  # shape: (out_ch, 3, 7, 7)\n                if in_channels == 1:\n                    new_w_t = w_t.sum(axis=1, keepdims=True)  # shape: (out_ch, 1, 7, 7)\n                else:\n                    n_repeats = (in_channels + 3 - 1) // 3\n                    new_w_t = w_t.repeat((1, n_repeats, 1, 1))\n                    new_w_t = new_w_t[:, :in_channels]\n                    new_w_t = new_w_t * 3 / in_channels  # shape: (out_ch, in_channels, 7, 7)\n\n                first_conv.weight.data = new_w_t\n        else:\n            base_model = timm.create_model(\n                base_name, pretrained=pretrained, in_chans=in_channels)\n            in_features = base_model.num_features\n            print(\"load imagenet pretrained:\", pretrained)\n            \n        base_model.reset_classifier(num_classes=0)\n        self.backbone = base_model\n        print(f\"{base_name}: {in_features}\")\n        \n        # # prepare head clasifier\n        if dims_head[0] is None:\n            dims_head[0] = in_features\n\n        layers_list = []\n        for i in range(len(dims_head) - 2):\n            in_dim, out_dim = dims_head[i: i + 2]\n            layers_list.extend([\n                nn.Linear(in_dim, out_dim),\n                nn.ReLU(), nn.Dropout(0.5),])\n        layers_list.append(\n            nn.Linear(dims_head[-2], dims_head[-1]))\n        self.head = nn.Sequential(*layers_list)\n\n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        h = self.backbone(x)\n        h = self.head(h)\n        return h","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-14T14:17:40.940177Z","iopub.execute_input":"2022-01-14T14:17:40.940635Z","iopub.status.idle":"2022-01-14T14:17:40.955781Z","shell.execute_reply.started":"2022-01-14T14:17:40.940599Z","shell.execute_reply":"2022-01-14T14:17:40.955148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VoloModel(nn.Module):\n    \n    def __init__(self, \n                 base_name: str, \n                 dims_head: tp.List[int],\n                 pretrained=True, \n                 in_channels: int=3, \n                 image_size: int=224,\n                 drop_path_rate: float=0.1\n    ):\n        \"\"\"Initialize\"\"\"\n        self.base_name = base_name\n        super().__init__()\n        model_name = base_name.split(\"-\")[0]\n        assert timm.is_model(model_name), \"you can use only models in timm.\"\n        \n        if model_name[:4] == \"volo\":\n            base_model = timm.create_model(\n                model_name, img_size=image_size,\n                mix_token=False, \n                return_dense=False, \n                drop_path_rate=0.3, # 0.4,  0.1\n            )\n            in_features = base_model.head.in_features\n            if pretrained:\n                volo_load_weights(base_model, VOLO_CHECHPOINTS[base_name], strict=False)\n            \n            if in_channels != 3:\n                # # change input channel\n                # # I follow the manner used in timm.\n                first_conv = base_model.patch_embed.conv[0]\n                w_t = first_conv.weight.data  # shape: (out_ch, 3, 7, 7)\n                if in_channels == 1:\n                    new_w_t = w_t.sum(axis=1, keepdims=True)  # shape: (out_ch, 1, 7, 7)\n                else:\n                    n_repeats = (in_channels + 3 - 1) // 3\n                    new_w_t = w_t.repeat((1, n_repeats, 1, 1))\n                    new_w_t = new_w_t[:, :in_channels]\n                    new_w_t = new_w_t * 3 / in_channels  # shape: (out_ch, in_channels, 7, 7)\n\n                first_conv.weight.data = new_w_t\n        else:\n            base_model = timm.create_model(\n                base_name, pretrained=pretrained, in_chans=in_channels)\n            in_features = base_model.num_features\n            print(\"load imagenet pretrained:\", pretrained)\n            \n        base_model.reset_classifier(num_classes=0)\n        self.backbone = base_model\n        print(f\"{base_name}: {in_features}\")\n        \n        # # prepare head clasifier\n        if dims_head[0] is None:\n            dims_head[0] = in_features\n\n        layers_list = []\n        for i in range(len(dims_head) - 2):\n            in_dim, out_dim = dims_head[i: i + 2]\n            layers_list.extend([\n                nn.Linear(in_dim, out_dim),\n                nn.ReLU(), nn.Dropout(0.5),])\n        layers_list.append(\n            nn.Linear(dims_head[-2], dims_head[-1]))\n        self.head = nn.Sequential(*layers_list)\n\n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        h = self.backbone(x)\n        h = self.head(h)\n        return h","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-14T14:17:40.957209Z","iopub.execute_input":"2022-01-14T14:17:40.957651Z","iopub.status.idle":"2022-01-14T14:17:40.972979Z","shell.execute_reply.started":"2022-01-14T14:17:40.957614Z","shell.execute_reply":"2022-01-14T14:17:40.972248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AlbumentationsTransform(RandTransform):\n\t\"A transform handler for multiple `Albumentation` transforms\"\n\tsplit_idx, order = None, 2\n\n\tdef __init__(self, train_aug, valid_aug):\n\t\tstore_attr()\n\n\tdef before_call(self, b, split_idx):\n\t\tself.idx = split_idx\n\n\tdef encodes(self, img: PILImage):\n\t\tif self.idx == 0:\n\t\t\taug_img = self.train_aug(image=np.array(img))['image']\n\t\telse:\n\t\t\taug_img = self.valid_aug(image=np.array(img))['image']\nimport random\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport albumentations as A\n\n\ndef visualize(image):\n\tplt.figure(figsize=(10, 10))\n\tplt.axis('off')\n\tplt.imshow(image)\n\n\n\n\ndef train_aug():\n\treturn A.Compose([\n\t\tA.Resize(384, 384),\n\t\tA.SomeOf([A.RandomContrast((0.6, 0.3)), A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20),\n\t\t          A.RandomBrightness(limit=[0.6, 0.3]), A.Flip(), A.Rotate(limit=45), A.Equalize(), A.Sharpen(),\n\t\t          A.Solarize(196), A.Posterize(), A.Affine(translate_percent=[0.1, 0.1])], n=3)\n\t])\n\n\ndef valid_aug():\n\treturn A.Compose([\n\t\tA.Resize(384, 384),\n\n\t])\n\n\nclass AlbumentationsTransform(RandTransform):\n\t\"A transform handler for multiple `Albumentation` transforms\"\n\tsplit_idx, order = None, 2\n\n\tdef __init__(self, train_aug, valid_aug):\n\t\tstore_attr()\n\n\tdef before_call(self, b, split_idx):\n\t\tself.idx = split_idx\n\n\tdef encodes(self, img: PILImage):\n\t\tif self.idx == 0:\n\t\t\taug_img = self.train_aug(image=np.array(img))['image']\n\t\telse:\n\t\t\taug_img = self.valid_aug(image=np.array(img))['image']\n\t\treturn PILImage.create(aug_img)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-14T14:17:40.977148Z","iopub.execute_input":"2022-01-14T14:17:40.977712Z","iopub.status.idle":"2022-01-14T14:17:42.290465Z","shell.execute_reply.started":"2022-01-14T14:17:40.977654Z","shell.execute_reply":"2022-01-14T14:17:42.289709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Final RMSE: 17.233747032380457\n#Ensemble Weights: [0.35205359 0.18218062 0.19627086 0.27224672]\n#Models: ['Ioa-384', 'Siti-224', 'Edrickv4-224', 'Volo-d2-384']\n#Sum of weights: 1.002751786932252\n\n########\n# Final RMSE: 17.215003972534888\n# Ensemble Weights: [0.32042124 0.15301671 0.15904355 0.19359245 0.18038215]\n# Models: ['Ioa-384', 'Siti-224', 'Edrickv4-224', 'Volo-d4-448']\n# Sum of weights: 1.0064561020267702","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:42.29166Z","iopub.execute_input":"2022-01-14T14:17:42.29195Z","iopub.status.idle":"2022-01-14T14:17:42.296167Z","shell.execute_reply.started":"2022-01-14T14:17:42.291886Z","shell.execute_reply":"2022-01-14T14:17:42.295529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### calc CV score using OOF\nfrom sklearn.metrics import mean_squared_error\n\nmodel_names = ['Ioa-384', 'Siti-224', 'Edrickv4-224', 'Volo-d2-384', 'Volo-d4-224'] # 'Volo-d4-224'\nprint(model_names)\n\noof1 = pd.read_csv('../input/exp03-swinl384-5kf-cv1746/train_with_oof_seed_365.csv')\noof1['Id'] = oof1['path'].apply(lambda s: s.split('/')[-1].split('.')[0])  \noof1 = oof1.sort_values(by='Id')\nprint(\"Model 1 RMSE (no TTA):\", mean_squared_error(oof1[\"oof\"], oof1[\"Pawpularity\"], squared=False).round(5) )\n\n\noof2 = pd.read_csv('../input/fastai-mixup-lb01794/train_with_oof.csv')\noof2['Id'] = oof2['path'].apply(lambda s: s.split('/')[-1].split('.')[0])  \noof2 = oof2.sort_values(by='Id')\nprint(\"Model 2 RMSE (no TTA):\", mean_squared_error(oof2[\"oof\"], oof2[\"Pawpularity\"], squared=False).round(5) )\n\n\n# oof3 = pd.read_csv('../input/edrick-swin224-5kf-cv1761-lb1784/train_with_oof.csv')\noof3 = pd.read_csv('../input/convnext-oof-384/train_with_oof.csv')\noof3['Id'] = oof3['path'].apply(lambda s: s.split('/')[-1].split('.')[0])  \noof3 = oof3.sort_values(by='Id')\nprint(\"Model 3 RMSE (no TTA):\", mean_squared_error(oof3[\"oof\"], oof3[\"Pawpularity\"], squared=False).round(5) )\n\n\n# oof4 = pd.read_csv('../input/pet-swinl-224-mixup-seed-3407/train_with_oof_seed_3407.csv')\noof4 = pd.read_csv('../input/best-volo-d2-weight/volo_oof.csv')\noof4['Id'] = oof4['path'].apply(lambda s: s.split('/')[-1].split('.')[0])  \noof4 = oof4.sort_values(by='Id')\nprint(\"Model 4 RMSE (no TTA):\", mean_squared_error(oof4[\"oof\"], oof4[\"Pawpularity\"], squared=False).round(5) )\n#print(\"Model 4 RMSE (with TTA):\", mean_squared_error(oof4[\"oof_tta\"], oof4[\"Pawpularity\"], squared=False).round(5) )\n\n\noof5 = pd.read_csv('../input/biet-petfinder/train_with_oof.csv')\noof5['Id'] = oof5['path'].apply(lambda s: s.split('/')[-1].split('.')[0])  \noof5 = oof5.sort_values(by='Id')\nprint(\"Model 5 RMSE (no TTA):\", mean_squared_error(oof5[\"oof\"], oof5[\"Pawpularity\"], squared=False).round(5) )\n\n\ntgt = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntgt = tgt.sort_values(by='Id')\ntgt = tgt[tgt.Id.isin(oof2.Id.tolist())]['Pawpularity']\nprint('-'*20)\n\n#################\np = (oof1[\"oof\"].values + oof2[\"oof\"].values)/2\n# p = (oof2[\"oof\"].values + oof3[\"oof\"].values)/2\nprint('\\navg ens 2M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\np = 0.6 * oof1[\"oof\"].values + 0.4 * oof2[\"oof\"].values\n# p = 0.4 * oof2[\"oof\"].values + 0.6 * oof3[\"oof\"].values\nprint('weighted ens 2M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\nprint('-'*20)\np = (oof1[\"oof\"].values + oof2[\"oof\"].values + oof3[\"oof\"].values)/3\nprint('\\navg ens 3M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\n# p = 0.4 * oof1[\"oof\"].values + 0.3 * oof2[\"oof\"].values + 0.3 * oof3[\"oof\"].values\n# print('weighted ens 3M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\n# p = 0.5 * oof1[\"oof\"].values + 0.3 * oof2[\"oof\"].values + 0.2 * oof3[\"oof\"].values\n# print('weighted ens 3M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\n# p = 0.5 * oof1[\"oof\"].values + 0.2 * oof2[\"oof\"].values + 0.3 * oof3[\"oof\"].values\n# print('weighted ens 3M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\n\nprint('-'*20)\np = (oof1[\"oof\"].values + oof2[\"oof\"].values + oof3[\"oof\"].values + oof4[\"oof\"].values)/4\nprint('\\navg ens 4M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\np = 0.5 * oof1[\"oof\"].values + 0.15 * oof2[\"oof\"].values + 0.2 * oof3[\"oof\"].values + 0.15 * oof4[\"oof\"].values\nprint('weighted ens 4M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\np = 0.5 * oof1[\"oof\"].values + 0.1 * oof2[\"oof\"].values + 0.2 * oof3[\"oof\"].values + 0.2 * oof4[\"oof\"].values\nprint('weighted ens 4M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\np = 0.342 * oof1[\"oof\"].values + 0.1774 * oof2[\"oof\"].values + 0.19489 * oof3[\"oof\"].values + 0.2975 * oof4[\"oof\"].values\nprint('weighted ens 4M RMSE (no TTA):', mean_squared_error(p, tgt, squared=False).round(5) )\n\n\np = 0.2 * oof1[\"oof\"].values + 0.2 * oof2[\"oof\"].values + 0.2 * oof3[\"oof\"].values + 0.2 * oof4[\"oof\"].values + 0.2 * oof5[\"oof\"].values\nprint('avg ens 5M RMSE:', mean_squared_error(p, tgt, squared=False).round(5) )\n\np = 0.4 * oof1[\"oof\"].values + 0.1 * oof2[\"oof\"].values + 0.2 * oof3[\"oof\"].values + 0.2 * oof4[\"oof\"].values + 0.1 * oof5[\"oof\"].values\nprint('weighted ens 5M RMSE:', mean_squared_error(p, tgt, squared=False).round(5) )\n\nw = [0.28180586,0.13010029,0.28598953,0.16734793,0.18953224]\np = (w[0]*oof1[\"oof\"].values + w[1] * oof2[\"oof\"].values + w[2] * oof3[\"oof\"].values + w[3] * oof4[\"oof\"].values + w[4] * oof5[\"oof\"].values) -2.3280542645433115\n\nprint('Ridge weights ens 5M RMSE:', mean_squared_error(p, tgt, squared=False).round(5) )\n","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:42.29815Z","iopub.execute_input":"2022-01-14T14:17:42.298568Z","iopub.status.idle":"2022-01-14T14:17:42.708621Z","shell.execute_reply.started":"2022-01-14T14:17:42.29853Z","shell.execute_reply":"2022-01-14T14:17:42.707712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:42.710094Z","iopub.execute_input":"2022-01-14T14:17:42.710339Z","iopub.status.idle":"2022-01-14T14:17:42.717976Z","shell.execute_reply.started":"2022-01-14T14:17:42.710304Z","shell.execute_reply":"2022-01-14T14:17:42.717216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:42.719221Z","iopub.execute_input":"2022-01-14T14:17:42.719471Z","iopub.status.idle":"2022-01-14T14:17:42.727115Z","shell.execute_reply.started":"2022-01-14T14:17:42.719435Z","shell.execute_reply":"2022-01-14T14:17:42.726197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del tgt, oof1, oof2, oof3, oof4, oof5, p\ngc.collect();","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:42.729127Z","iopub.execute_input":"2022-01-14T14:17:42.729425Z","iopub.status.idle":"2022-01-14T14:17:42.882037Z","shell.execute_reply.started":"2022-01-14T14:17:42.729389Z","shell.execute_reply":"2022-01-14T14:17:42.881264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# ## Edrick's LB 17.80\n# def inf_run_1(fold):\n#     learn = load_learner(fname=Path(f'../input/fastai-mixup/model_fold_{fold}.pkl'), cpu=False)\n#     print(f'Device: {learn.dls.device} ')\n#     test_dl = learn.dls.test_dl(test)\n#     preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n#     return preds\n\n\n## Ioa CV 17.46\ndef inf_run_1(fold):\n    learn = load_learner(fname=Path(f'../input/exp03-swinl384-5kf-cv1746/model_fold_{fold}.pkl'), cpu=False)\n    learn = learn.to_fp16()\n    #print(f'Device: {learn.dls.device} ')\n    test_dl = learn.dls.test_dl(test)\n    #preds, _ = learn.tta(dl=test_dl, n=3, beta=0.3) ## \n    #preds, _ = learn.tta(dl=test_dl, n=5, beta=0.6)  # beta 0.6 CV 17.419\n    preds, _ = learn.tta(dl=test_dl, n=3, beta=0.)\n    return preds.numpy()[:,0] \n\n\n\n## siti's CV 17.55/17.63 -- LB 17.74\ndef inf_run_2(fold):\n    learn = load_learner(fname=Path(f'../input/fastai-mixup-lb01794/model_fold_{fold}.pkl'), cpu=False) \n    learn = learn.to_fp16()\n    #print(f'Device: {learn.dls.device} ')\n    test_dl = learn.dls.test_dl(test)\n    #preds, _ = learn.tta(dl=test_dl, n=5, beta=0.38) ## best n, beta \n    ##preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n    preds, _ = learn.tta(dl=test_dl, n=3, beta=0.)\n    return preds.numpy()[:,0] \n\n\n# # ## Edrick's LB 17.84\n# def inf_run_3(fold):\n#     learn = load_learner(fname=Path(f'../input/edrick-swin224-5kf-cv1761-lb1784/model_fold_{fold}.pkl'), cpu=False)\n#     #print(f'Device: {learn.dls.device} ')\n#     test_dl = learn.dls.test_dl(test)\n#     preds, _ = learn.tta(dl=test_dl, n=5, beta=0.5)  ## TODO find best n, beta \n#     return preds\n\n\n# ## ConvNext CV 17.6\ndef inf_run_3(fold):\n    if True:\n        learn = load_learner(fname=Path(f'../input/convnet384/ConvNext384/model_fold_{fold}.pkl'), cpu=False)\n    else:\n        learn = load_learner(fname=Path(f'../input/fastai-mixup-convnextlarge-3-4/model_fold_{fold}.pkl'), cpu=False)\n    learn = learn.to_fp16()\n    #print(f'Device: {learn.dls.device} ')\n    test_dl = learn.dls.test_dl(test)\n    #preds, _ = learn.tta(dl=test_dl, n=5, beta=0.6)  ## #beta 0.6 17.257\n    preds, _ = learn.tta(dl=test_dl, n=3, beta=0.) \n    return preds.numpy() \n\n\n# ## Mrigr Volo-d2 \ndef inf_run_4(fold):\n    learn = load_learner(fname=Path(f'../input/best-volo-d2-weight/model_fold_{fold}.pkl'), cpu=False)\n    learn = learn.to_fp16()\n    #print(f'Device: {learn.dls.device} ')\n    test_dl = learn.dls.test_dl(test)\n    # preds, _ = learn.tta(dl=test_dl, n=5, beta=0.5)  ## \n    preds, _ = learn.tta(dl=test_dl, n=3, beta=0.)\n    return preds.numpy()[:,0] \n\n\n\n# ## Ioa Volo-d4 224 CV 17.66\ndef inf_run_5(fold):\n    learn = load_learner(fname=Path(f'../input/biet-petfinder/model_fold_{fold}.pkl'), cpu=False)\n    learn = learn.to_fp16()\n    #print(f'Device: {learn.dls.device} ')\n    test_dl = learn.dls.test_dl(test)\n    #     preds, _ = learn.tta(dl=test_dl, n=5, beta=0.1)  ## \n    preds, _ = learn.tta(dl=test_dl, n=3, beta=0.)\n    return preds.numpy()[:,0] \n\n\n# # ## Mrigrenda Volo-d2 \n# def inf_run_5(fold):\n#     learn = load_learner(fname=Path(f'../input/volo-d2-weight/model_fold_{fold}.pkl'), cpu=False)\n#     learn = learn.to_fp16()\n#     #print(f'Device: {learn.dls.device} ')\n#     test_dl = learn.dls.test_dl(test)\n#     preds, _ = learn.tta(dl=test_dl, n=5, beta=0.4)  ## \n#     return preds.numpy()[:,0] \n\n\n\n# # ## Ioa Swin224 seed3407\n# def inf_run_4(fold):\n#     learn = load_learner(fname=Path(f'../input/pet-swinl-224-mixup-seed-3407/model_fold_{fold}.pkl'), cpu=False)\n#     learn = learn.to_fp16()\n#     #print(f'Device: {learn.dls.device} ')\n#     test_dl = learn.dls.test_dl(test)\n#     preds, _ = learn.tta(dl=test_dl, n=5, beta=0.4)  ## \n#     return preds.numpy()[:,0] \n\n\n###################################\n\n# # ## Mithil 384 10kf CV 17.44 ?\n# def inf_run_5(fold):\n#     learn = load_learner(fname=Path(f'../input/fastai-384-pred/swin_large_patch4_window12_384/model_fold_{fold}.pkl'), cpu=False)\n#     learn = learn.to_fp16()\n#     #print(f'Device: {learn.dls.device} ')\n#     test_dl = learn.dls.test_dl(test)\n#     #preds, _ = learn.tta(dl=test_dl, n=5, beta=0.4)  ## \n#     preds, _ = learn.get_preds(dl=test_dl) # \n#     return preds.numpy()[:,0] \n\n\n# # ## Mithil 224 10kf CV 17.46 ?\n### ......\n","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:42.883532Z","iopub.execute_input":"2022-01-14T14:17:42.883788Z","iopub.status.idle":"2022-01-14T14:17:42.900271Z","shell.execute_reply.started":"2022-01-14T14:17:42.883751Z","shell.execute_reply":"2022-01-14T14:17:42.899554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\nsubmission['Pawpularity'] = 0\n\ntest = submission.copy()\ntest['path'] = test['Id'].apply(lambda x: '../input/petfinder-pawpularity-score/test/' + x + '.jpg')\ntest","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:42.902029Z","iopub.execute_input":"2022-01-14T14:17:42.902514Z","iopub.status.idle":"2022-01-14T14:17:42.928987Z","shell.execute_reply.started":"2022-01-14T14:17:42.902474Z","shell.execute_reply":"2022-01-14T14:17:42.928269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(5):\n# for fold in [1,2,3,4]:\n    \n    print(f'Inference fold: {fold} ')\n\n    test[f'preds1_{fold}'] = inf_run_1(fold) # preds.numpy()[:,0] ","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:17:42.930185Z","iopub.execute_input":"2022-01-14T14:17:42.930409Z","iopub.status.idle":"2022-01-14T14:18:43.344819Z","shell.execute_reply.started":"2022-01-14T14:17:42.930377Z","shell.execute_reply":"2022-01-14T14:18:43.34407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(5):\n# for fold in [1,2,3,4]:\n    \n    print(f'Inference fold: {fold} ')\n    \n    test[f'preds2_{fold}'] = inf_run_2(fold)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:18:43.346298Z","iopub.execute_input":"2022-01-14T14:18:43.346803Z","iopub.status.idle":"2022-01-14T14:19:27.030718Z","shell.execute_reply.started":"2022-01-14T14:18:43.34676Z","shell.execute_reply":"2022-01-14T14:19:27.029959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(5):\n# for fold in [1,2,3,4]:\n    \n    print(f'Inference fold: {fold} ')\n    \n    test[f'preds3_{fold}'] = inf_run_3(fold) ","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:20:25.045493Z","iopub.execute_input":"2022-01-14T14:20:25.046226Z","iopub.status.idle":"2022-01-14T14:21:33.909581Z","shell.execute_reply.started":"2022-01-14T14:20:25.046185Z","shell.execute_reply":"2022-01-14T14:21:33.908728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(5):\n# for fold in [1,2,3,4]:\n    \n    print(f'Inference fold: {fold} ')\n    \n    test[f'preds4_{fold}'] = inf_run_4(fold) ","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:21:38.766719Z","iopub.execute_input":"2022-01-14T14:21:38.767379Z","iopub.status.idle":"2022-01-14T14:22:07.14857Z","shell.execute_reply.started":"2022-01-14T14:21:38.767337Z","shell.execute_reply":"2022-01-14T14:22:07.147716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(5):\n# for fold in [1,2,3,4]:\n    \n    print(f'Inference fold: {fold} ')\n    \n    test[f'preds5_{fold}'] = inf_run_5(fold) ","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:22:07.150642Z","iopub.execute_input":"2022-01-14T14:22:07.151478Z","iopub.status.idle":"2022-01-14T14:23:01.362562Z","shell.execute_reply.started":"2022-01-14T14:22:07.151433Z","shell.execute_reply":"2022-01-14T14:23:01.361744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:23:01.364Z","iopub.execute_input":"2022-01-14T14:23:01.364261Z","iopub.status.idle":"2022-01-14T14:23:01.39567Z","shell.execute_reply.started":"2022-01-14T14:23:01.364224Z","shell.execute_reply":"2022-01-14T14:23:01.394918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p1 = test[['preds1_' + str(i) for i in range(5) ]].mean(axis=1)\np2 = test[['preds2_' + str(i) for i in range(5) ]].mean(axis=1)\np3 = test[['preds3_' + str(i) for i in range(5) ]].mean(axis=1)\np4 = test[['preds4_' + str(i) for i in range(5) ]].mean(axis=1)\np5 = test[['preds5_' + str(i) for i in range(5) ]].mean(axis=1)\n\n# p1 = test[['preds1_' + str(i) for i in [1,2,3,4] ]].mean(axis=1)\n# p2 = test[['preds2_' + str(i) for i in [1,2,3,4] ]].mean(axis=1)\n# p3 = test[['preds3_' + str(i) for i in [1,2,3,4] ]].mean(axis=1)\n# p4 = test[['preds4_' + str(i) for i in [1,2,3,4] ]].mean(axis=1)\n# p5 = test[['preds5_' + str(i) for i in [1,2,3,4] ]].mean(axis=1)\n\nassert (len(p1)==len(p2)==len(p3)==len(p4)), \"Error: Check shapes!!\"","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:23:07.282033Z","iopub.execute_input":"2022-01-14T14:23:07.282763Z","iopub.status.idle":"2022-01-14T14:23:07.298698Z","shell.execute_reply.started":"2022-01-14T14:23:07.282713Z","shell.execute_reply":"2022-01-14T14:23:07.298022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# w = [0.35205359 ,0.18218062, 0.19627086, 0.27224672]\n\nw = [0.3137313,0.13160744,0.20586328,0.20454176,0.19065228]\nsum(w)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:23:08.200117Z","iopub.execute_input":"2022-01-14T14:23:08.201005Z","iopub.status.idle":"2022-01-14T14:23:08.207666Z","shell.execute_reply.started":"2022-01-14T14:23:08.200955Z","shell.execute_reply":"2022-01-14T14:23:08.206848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p1","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:23:20.747005Z","iopub.execute_input":"2022-01-14T14:23:20.747606Z","iopub.status.idle":"2022-01-14T14:23:20.758824Z","shell.execute_reply.started":"2022-01-14T14:23:20.747566Z","shell.execute_reply":"2022-01-14T14:23:20.757923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission['Pawpularity'] = test[['preds_' + str(i) for i in range(5)]].mean(axis=1)\n# submission['Pawpularity'] = 0.5*p1 + 0.1*p2 + 0.2*p3 + 0.2*p4\n\nsubmission['Pawpularity'] = w[0]*p1 + w[1]*p2 + w[2]*p3 + w[3]*p4 + w[4]*p5 \n\nsubmission['Pawpularity'] = submission['Pawpularity'] * 100\nsubmission['Pawpularity'] = submission['Pawpularity'] -2.3280542645433115\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:24:32.104709Z","iopub.execute_input":"2022-01-14T14:24:32.105572Z","iopub.status.idle":"2022-01-14T14:24:32.121724Z","shell.execute_reply.started":"2022-01-14T14:24:32.10553Z","shell.execute_reply":"2022-01-14T14:24:32.120794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission['Pawpularity'].hist(bins=50)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:19:27.516492Z","iopub.status.idle":"2022-01-14T14:19:27.517125Z","shell.execute_reply.started":"2022-01-14T14:19:27.516891Z","shell.execute_reply":"2022-01-14T14:19:27.516928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}