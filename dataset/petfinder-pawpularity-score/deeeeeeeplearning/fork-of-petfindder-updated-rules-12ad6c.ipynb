{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master/')\nfrom timm import create_model\nfrom fastai.vision.all import *\nset_seed(999, reproducible=True)\nBATCH_SIZE = 16\nN_FOLDS = 5\ndataset_path = Path('../input/petfinder-pawpularity-score/')\ndataset_path.ls()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:29:42.43525Z","iopub.execute_input":"2021-12-03T04:29:42.43601Z","iopub.status.idle":"2021-12-03T04:29:50.066489Z","shell.execute_reply.started":"2021-12-03T04:29:42.435972Z","shell.execute_reply":"2021-12-03T04:29:50.065752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Fast.ai with SVR head! ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:48:26.393994Z","iopub.execute_input":"2021-12-03T04:48:26.394464Z","iopub.status.idle":"2021-12-03T04:48:26.399778Z","shell.execute_reply.started":"2021-12-03T04:48:26.394423Z","shell.execute_reply":"2021-12-03T04:48:26.399101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(dataset_path/'train.csv')\ntrain_df['path'] = train_df['Id'].map(lambda x:str(dataset_path/'train'/x)+'.jpg')#映射为图片地址\ntrain_df = train_df.drop(columns=['Id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df['norm_score'] = train_df['Pawpularity']/100\ntrain_df.head()\nnum_bins = int(np.floor(1+3.3*np.log2(len(train_df))))\nnum_bins#分为44个等级\ntrain_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)#指定多个区间！pd.cut\ntrain_df['bins'].hist()\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)#分层采样 各类别样本的比例与原始数据集中相同\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):#index当做X  bins当做y 标签\n    train_df.iloc[train_index, -1] =i #第i折 \n    \ntrain_df['fold'] = train_df['fold'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:48:27.953178Z","iopub.execute_input":"2021-12-03T04:48:27.953692Z","iopub.status.idle":"2021-12-03T04:48:28.141208Z","shell.execute_reply.started":"2021-12-03T04:48:27.953648Z","shell.execute_reply":"2021-12-03T04:48:28.140469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(dataset_path/'test.csv')\n\ntest_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path/'test'/x)+'.jpg')\ntest_df = test_df.drop(columns=['Id'])\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:34:13.616631Z","iopub.execute_input":"2021-12-03T04:34:13.617419Z","iopub.status.idle":"2021-12-03T04:34:13.657595Z","shell.execute_reply.started":"2021-12-03T04:34:13.617369Z","shell.execute_reply":"2021-12-03T04:34:13.656814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(torch.sigmoid(input.flatten()), target))","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:51:13.313259Z","iopub.execute_input":"2021-12-03T04:51:13.313521Z","iopub.status.idle":"2021-12-03T04:51:13.320177Z","shell.execute_reply.started":"2021-12-03T04:51:13.313492Z","shell.execute_reply":"2021-12-03T04:51:13.31937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 检测猫狗","metadata":{}},{"cell_type":"code","source":"!mkdir /root/.config/Ultralytics/\n!cp ../input/arial-front/Arial.ttf -r  /root/.config/Ultralytics/\n!mkdir /root/.cache/torch/\n!mkdir /root/.cache/torch/hub/\n!cp ../input/swin-ck/ultralytics_yolov5_master -r /root/.cache/torch/hub/\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:29:09.503814Z","iopub.execute_input":"2021-12-03T04:29:09.50445Z","iopub.status.idle":"2021-12-03T04:29:19.463552Z","shell.execute_reply.started":"2021-12-03T04:29:09.504362Z","shell.execute_reply":"2021-12-03T04:29:19.462491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolov5x6_model = torch.hub.load('ultralytics/yolov5', 'yolov5x6')\n# Get Image Info\ndef get_image_info(file_path, plot=True):\n    # Read Image\n    image = imageio.imread(file_path)\n    h, w, c = image.shape\n    \n    if plot: # Debug Plots\n        fig, ax = plt.subplots(1, 2, figsize=(8,8))\n        ax[0].set_title('Pets detected in Image', size=16)\n        ax[0].imshow(image)\n        \n    # Get YOLOV5 results using Test Time Augmentation for better result\n    results = yolov5x6_model(image, augment=True)\n    \n    # Mask for pixels containing pets, initially all set to zero\n    pet_pixels = np.zeros(shape=[h, w], dtype=np.uint8)\n    \n    # Dictionary to Save Image Info\n    h, w, _ = image.shape\n    image_info = { \n        'n_pets': 0, # Number of pets in the image\n        'labels': [], # Label assigned to found objects\n        'thresholds': [], # confidence score\n        'coords': [], # coordinates of bounding boxes\n        'x_min': 0, # minimum x coordinate of pet bounding box\n        'x_max': w - 1, # maximum x coordinate of pet bounding box\n        'y_min': 0, # minimum y coordinate of pet bounding box\n        'y_max': h - 1, # maximum x coordinate of pet bounding box\n    }\n    \n    # Save found pets to draw bounding boxes\n    pets_found = []\n    \n    # Save info for each pet\n    for x1, y1, x2, y2, treshold, label in results.xyxy[0].cpu().detach().numpy():\n        label = results.names[int(label)]\n        if label in ['cat', 'dog']:\n            image_info['n_pets'] += 1\n            image_info['labels'].append(label)\n            image_info['thresholds'].append(treshold)\n            image_info['coords'].append(tuple([x1, y1, x2, y2]))\n            image_info['x_min'] = max(x1, image_info['x_min'])\n            image_info['x_max'] = min(x2, image_info['x_max'])\n            image_info['y_min'] = max(y1, image_info['y_min'])\n            image_info['y_max'] = min(y2, image_info['y_max'])\n            \n            # Set pixels containing pets to 1\n            pet_pixels[int(y1):int(y2), int(x1):int(x2)] = 1\n            \n            # Add found pet\n            pets_found.append([x1, x2, y1, y2, label])\n\n    if plot:\n        for x1, x2, y1, y2, label in pets_found:\n            c = 'red' if label == 'dog' else 'blue'\n            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor=c, facecolor='none')\n            # Add the patch to the Axes\n            ax[0].add_patch(rect)\n            ax[0].text(max(25, (x2+x1)/2), max(25, y1-h*0.02), label, c=c, ha='center', size=14)\n                \n    # Add Pet Ratio in Image\n    image_info['pet_ratio'] = pet_pixels.sum() / (h*w)\n\n    if plot:\n        # Show pet pixels\n        ax[1].set_title('Pixels Containing Pets', size=16)\n        ax[1].imshow(pet_pixels)\n        plt.show()\n        \n    return image_info","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:32:36.042249Z","iopub.execute_input":"2021-12-03T04:32:36.042898Z","iopub.status.idle":"2021-12-03T04:32:37.682586Z","shell.execute_reply.started":"2021-12-03T04:32:36.042839Z","shell.execute_reply":"2021-12-03T04:32:37.681858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport imageio\n# Image Info\ndef detection_dog_cat(train_df):\n    IMAGES_INFO = {\n    'n_pets': [],\n    'label': [],\n    'coords': [],\n    'x_min': [],\n    'x_max': [],\n    'y_min': [],\n    'y_max': [],\n    'pet_ratio': [],\n    }\n\n\n    for idx, file_path in enumerate(tqdm(train_df['path'])):#对train_df进行检测！\n        image_info = get_image_info(file_path, plot=False)\n    \n        IMAGES_INFO['n_pets'].append(image_info['n_pets'])\n        IMAGES_INFO['coords'].append(image_info['coords'])\n        IMAGES_INFO['x_min'].append(image_info['x_min'])\n        IMAGES_INFO['x_max'].append(image_info['x_max'])\n        IMAGES_INFO['y_min'].append(image_info['y_min'])\n        IMAGES_INFO['y_max'].append(image_info['y_max'])\n        IMAGES_INFO['pet_ratio'].append(image_info['pet_ratio'])\n    \n    # Not Every Image can be Correctly Classified\n        labels = image_info['labels']\n        if len(set(labels)) == 1: # unanimous label\n            IMAGES_INFO['label'].append(labels[0])\n        elif len(set(labels)) > 1: # Get label with highest confidence\n            IMAGES_INFO['label'].append(labels[0])\n        else: # unknown label, yolo could not find pet\n            IMAGES_INFO['label'].append('unknown')\n        \n    for k, v in IMAGES_INFO.items():#写入dataframe\n        train_df[k] = v\n    return 0\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:33:54.513603Z","iopub.execute_input":"2021-12-03T04:33:54.514014Z","iopub.status.idle":"2021-12-03T04:33:54.61103Z","shell.execute_reply.started":"2021-12-03T04:33:54.513972Z","shell.execute_reply":"2021-12-03T04:33:54.610295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detection_dog_cat(test_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:34:17.761761Z","iopub.execute_input":"2021-12-03T04:34:17.762435Z","iopub.status.idle":"2021-12-03T04:34:24.451373Z","shell.execute_reply.started":"2021-12-03T04:34:17.762395Z","shell.execute_reply":"2021-12-03T04:34:24.450696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:35:05.180535Z","iopub.execute_input":"2021-12-03T04:35:05.180813Z","iopub.status.idle":"2021-12-03T04:35:05.191773Z","shell.execute_reply.started":"2021-12-03T04:35:05.180783Z","shell.execute_reply":"2021-12-03T04:35:05.190939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Cat']=0\ntest_df.loc[test_df['label']=='cat','Cat']=1\ntest_df['Dog']=0\ntest_df.loc[test_df['label']=='dog','Dog']=1\nfeatures_list=['Subject Focus','Eyes','Face','Near','Action', 'Accessory','Group','Collage','Human','Occlusion','Info','Blur','n_pets','Cat','Dog']\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nparams = {\n    'model': 'swin_large_patch4_window7_224',\n    'pretrained': True,\n    'inp_channels': 3,\n    'out_features': 1,\n    'dropout': 0,\n}\nclass PetNet(nn.Module):\n    def __init__(self, model_name=params['model'], out_features=params['out_features'], inp_channels=params['inp_channels'],\n                 pretrained=params['pretrained']):\n        super().__init__()\n        self.model = create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, 256)\n        self.fc = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, out_features)\n        )\n        self.dropout = nn.Dropout(params['dropout'])\n    \n    def forward(self, image):\n        embeddings = self.model(image)\n        #x = self.dropout(embeddings)\n        x=embeddings\n        output = self.fc(x)\n        x = torch.cat([embeddings, output], dim=1)\n        return x\n    \ndef get_learner(fold_num):\n    data = get_data(fold_num)\n    \n    model = PetNet()\n#     model = nn.DataParallel(model)\n#     model = model.cuda()\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse).to_fp16()\n    \n    return learn","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:36:47.681768Z","iopub.execute_input":"2021-12-03T04:36:47.682337Z","iopub.status.idle":"2021-12-03T04:36:47.691942Z","shell.execute_reply.started":"2021-12-03T04:36:47.6823Z","shell.execute_reply":"2021-12-03T04:36:47.691183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv(dataset_path/'sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = []\nimport gc\ndir_pt='../input/swin-ck/224_64_lrs'\ndir_head='../input/swin-ck/SVR'\nfor i in range(N_FOLDS):\n    print(f'Fold {i} results')\n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=999, #seed\n                               fn_col='path', #filename/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()]))\n    \n    learn = load_learner('{}/model_fold_{}.pkl'.format(dir_pt,i),cpu=False)\n    learn.model=learn.model.module\n    learn.loss_func=None\n    learn = learn.to_fp32()\n#########################    \n    test_dl = dls.test_dl(test_df)\n    \n    preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n    \n    embds=pd.DataFrame(preds[:,:-1])\n    features=test_df[features_list].reset_index(drop=True)\n    X_train=pd.concat([features, embds], axis=1) \n    clf = pickle.load(open('{}/head_{}.pkl'.format(dir_head,i), \"rb\"))\n    f=nn.Sigmoid()\n    y0=f(preds[:,-1])\n    y1=clf.predict(X_train)\n    y=(y0*100+y1)/2\n\n    all_preds.append(y.view(-1))\n\n    del learn\n\n    torch.cuda.empty_cache()\n\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T04:53:17.806141Z","iopub.execute_input":"2021-12-03T04:53:17.806836Z","iopub.status.idle":"2021-12-03T04:54:57.991776Z","shell.execute_reply.started":"2021-12-03T04:53:17.806796Z","shell.execute_reply":"2021-12-03T04:54:57.991026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv(dataset_path/'sample_submission.csv')\npreds = np.mean(np.stack(all_preds), axis=0)\nsample_df['Pawpularity'] = preds\nsample_df.to_csv('submission.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df.to_csv('submission.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]}]}