{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Get GPU Info","metadata":{"id":"BINjp9x4_S1v"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"7JFphgy7-Bnh","outputId":"9726f4ca-f7a2-45c7-8faa-de794e82430d","execution":{"iopub.status.busy":"2022-01-03T13:57:53.364432Z","iopub.execute_input":"2022-01-03T13:57:53.364958Z","iopub.status.idle":"2022-01-03T13:57:54.251734Z","shell.execute_reply.started":"2022-01-03T13:57:53.364869Z","shell.execute_reply":"2022-01-03T13:57:54.250624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Installations","metadata":{"id":"6I-oEtuP_kQ4","_kg_hide-input":false,"_kg_hide-output":false}},{"cell_type":"code","source":"!pip install -qq timm\n!pip install -qq albumentations==1.0.3\n!pip install -qq ttach","metadata":{"id":"9iIVyfJS_Vmb","_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-03T13:57:54.254475Z","iopub.execute_input":"2022-01-03T13:57:54.255085Z","iopub.status.idle":"2022-01-03T13:58:23.697428Z","shell.execute_reply.started":"2022-01-03T13:57:54.255036Z","shell.execute_reply":"2022-01-03T13:58:23.696128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"OOStUXXcAgDa"}},{"cell_type":"code","source":"# General\nfrom tqdm.auto import tqdm\nfrom collections import defaultdict\nimport pandas as pd\nimport numpy as np\nimport os\nimport random\nimport time\nimport gc\nimport cv2\nfrom PIL import Image\nimport glob\ngc.enable()\npd.set_option('display.max_columns', None)\n\n# Visialisation\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Image Aug\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# Deep Learning\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.nn import BCEWithLogitsLoss\n#Metrics\nfrom sklearn.metrics import mean_squared_error\n","metadata":{"id":"fewdVIGwAfpU","outputId":"68c049ba-a995-4305-9788-ee9e6e6fb14e","execution":{"iopub.status.busy":"2022-01-03T13:58:23.700698Z","iopub.execute_input":"2022-01-03T13:58:23.701027Z","iopub.status.idle":"2022-01-03T13:58:31.366743Z","shell.execute_reply.started":"2022-01-03T13:58:23.700982Z","shell.execute_reply":"2022-01-03T13:58:31.3656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import psutil\nfrom memory_profiler import profile","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.368892Z","iopub.execute_input":"2022-01-03T13:58:31.369602Z","iopub.status.idle":"2022-01-03T13:58:31.379732Z","shell.execute_reply.started":"2022-01-03T13:58:31.369551Z","shell.execute_reply":"2022-01-03T13:58:31.378703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## set device","metadata":{}},{"cell_type":"code","source":"# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.383424Z","iopub.execute_input":"2022-01-03T13:58:31.383844Z","iopub.status.idle":"2022-01-03T13:58:31.440198Z","shell.execute_reply.started":"2022-01-03T13:58:31.383804Z","shell.execute_reply":"2022-01-03T13:58:31.438532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## set seed","metadata":{}},{"cell_type":"code","source":"# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.442604Z","iopub.execute_input":"2022-01-03T13:58:31.442972Z","iopub.status.idle":"2022-01-03T13:58:31.454406Z","shell.execute_reply.started":"2022-01-03T13:58:31.442917Z","shell.execute_reply":"2022-01-03T13:58:31.453251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ignore warnings","metadata":{}},{"cell_type":"code","source":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# dont display warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.455834Z","iopub.execute_input":"2022-01-03T13:58:31.457037Z","iopub.status.idle":"2022-01-03T13:58:31.465841Z","shell.execute_reply.started":"2022-01-03T13:58:31.456973Z","shell.execute_reply":"2022-01-03T13:58:31.464827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def petfinder_rmse(input,target):\n    score = 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.467595Z","iopub.execute_input":"2022-01-03T13:58:31.468028Z","iopub.status.idle":"2022-01-03T13:58:31.476926Z","shell.execute_reply.started":"2022-01-03T13:58:31.467985Z","shell.execute_reply":"2022-01-03T13:58:31.47591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_memory():\n    mem = psutil.virtual_memory() \n    print(f\"Memory Total:{mem.total}. Used:{mem.used}. Available:{mem.available}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.479125Z","iopub.execute_input":"2022-01-03T13:58:31.479549Z","iopub.status.idle":"2022-01-03T13:58:31.487809Z","shell.execute_reply.started":"2022-01-03T13:58:31.479494Z","shell.execute_reply":"2022-01-03T13:58:31.48683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mem_details = []\n\ndef memory_ckpt():\n    mem_details.append(psutil.virtual_memory()[3])\n    mem_used_step = mem_details[-1] - mem_details[-2] if len(mem_details) > 1 else 0\n    mem_used_total = mem_details[-1] - mem_details[0] if len(mem_details) > 1 else 0\n\n    if mem_used_step > 50000000:\n        print('Mem Warning, High memory usage step:', round(mem_used_step/1073741824, 2), ' GB\\n')\n    elif mem_used_step < -50000000:\n        print('Mem Note, High memory release step:', round(mem_used_step/1073741824, 2), ' GB\\n')\n\n    if mem_used_total > 6000000000:\n        print('Mem Warning, High memory usage cumulatively by the code in the kernel:', round(mem_used_total/1073741824,2), ' GB\\n')\n        print('Total Memory used at start of kernel before line 1:', round(mem_details[0]/1073741824,2), ' GB\\n')\n        print('Total Memory used as of this step:', round(mem_details[-1]/1073741824,2), ' GB\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{}},{"cell_type":"code","source":"# TRAIN_FOLDS = [0, 1 ,2 ,3, 4]\n# N_FOLDS = 5\n\n# TRAIN_FOLDS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n# N_FOLDS = 10\nTRAIN_FOLDS = [0, 1]\nN_FOLDS = 10","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.489691Z","iopub.execute_input":"2022-01-03T13:58:31.490064Z","iopub.status.idle":"2022-01-03T13:58:31.499959Z","shell.execute_reply.started":"2022-01-03T13:58:31.490009Z","shell.execute_reply":"2022-01-03T13:58:31.49893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'model': 'swin_large_patch4_window7_224_in22k',\n    'dense_features': ['is_cat','n_pets','pet_ratio'],\n    'pretrained': True,\n    'inp_channels': 3,\n    'im_size': 224,\n    'device': device,\n    'lr': 2e-5,\n    'weight_decay': 1e-6,\n    'batch_size': 32,\n    'num_workers' : 2,\n#     'epochs': 8,\n    'epochs': 2,\n    'out_features': 1,\n    'dropout': 0.5,\n    'num_fold': N_FOLDS,\n#     'mixup': True,\n    'mixup': False,\n    'mixup_alpha': 1.0,\n    'scheduler_name': 'CosineAnnealingWarmRestarts',\n    'T_0': 5,\n    'T_max': 5,\n    'T_mult': 1,\n    'min_lr': 1e-6,\n    'max_lr': 3e-5,\n    'patience': 2\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.501936Z","iopub.execute_input":"2022-01-03T13:58:31.502382Z","iopub.status.idle":"2022-01-03T13:58:31.511209Z","shell.execute_reply.started":"2022-01-03T13:58:31.502341Z","shell.execute_reply":"2022-01-03T13:58:31.510032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"csv_dir = '../input/petfinder-pawpularity-score'\ntrain_dir = '../input/petfinder-pawpularity-score/train'\n# test_dir = '../input/petfinder-pawpularity-score/test'\n\ntrain_file_path = '../input/make-new-csv/train_add_f.csv'\nsample_sub_file_path = os.path.join(csv_dir, 'sample_submission.csv')\n\nprint(f'Train file: {train_file_path}')\nprint(f'Train file: {sample_sub_file_path}')","metadata":{"id":"cscftms-CyMn","outputId":"150ac493-d079-4950-85b5-b69f1f3ea8bd","execution":{"iopub.status.busy":"2022-01-03T13:58:31.513309Z","iopub.execute_input":"2022-01-03T13:58:31.513761Z","iopub.status.idle":"2022-01-03T13:58:31.524896Z","shell.execute_reply.started":"2022-01-03T13:58:31.513718Z","shell.execute_reply":"2022-01-03T13:58:31.523646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(train_file_path)\n# test_df = pd.read_csv(sample_sub_file_path)","metadata":{"id":"B1aBWdnoDWWX","execution":{"iopub.status.busy":"2022-01-03T13:58:31.526835Z","iopub.execute_input":"2022-01-03T13:58:31.527505Z","iopub.status.idle":"2022-01-03T13:58:31.575651Z","shell.execute_reply.started":"2022-01-03T13:58:31.527462Z","shell.execute_reply":"2022-01-03T13:58:31.574714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# delete NaN\ntrain_df = train_df.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.581328Z","iopub.execute_input":"2022-01-03T13:58:31.581609Z","iopub.status.idle":"2022-01-03T13:58:31.612501Z","shell.execute_reply.started":"2022-01-03T13:58:31.581549Z","shell.execute_reply":"2022-01-03T13:58:31.6115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"pet_ratio\"] = train_df[\"pet_ratio\"].astype('float32')","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.61401Z","iopub.execute_input":"2022-01-03T13:58:31.614377Z","iopub.status.idle":"2022-01-03T13:58:31.624984Z","shell.execute_reply.started":"2022-01-03T13:58:31.614336Z","shell.execute_reply":"2022-01-03T13:58:31.623495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def return_filpath(name, folder=train_dir):\n    path = os.path.join(folder, f'{name}.jpg')\n    return path","metadata":{"id":"vy3X2yUODZP1","execution":{"iopub.status.busy":"2022-01-03T13:58:31.627032Z","iopub.execute_input":"2022-01-03T13:58:31.627694Z","iopub.status.idle":"2022-01-03T13:58:31.634126Z","shell.execute_reply.started":"2022-01-03T13:58:31.6276Z","shell.execute_reply":"2022-01-03T13:58:31.632649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['image_path'] = train_df['Id'].apply(lambda x: return_filpath(x))","metadata":{"id":"4cQlB9XUD31w","execution":{"iopub.status.busy":"2022-01-03T13:58:31.636248Z","iopub.execute_input":"2022-01-03T13:58:31.637189Z","iopub.status.idle":"2022-01-03T13:58:31.672454Z","shell.execute_reply.started":"2022-01-03T13:58:31.637145Z","shell.execute_reply":"2022-01-03T13:58:31.671501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set fold","metadata":{}},{"cell_type":"code","source":"#Sturges' rule\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\ntrain_df['bins'] = pd.cut(train_df['Pawpularity'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:31.674211Z","iopub.execute_input":"2022-01-03T13:58:31.6746Z","iopub.status.idle":"2022-01-03T13:58:32.122806Z","shell.execute_reply.started":"2022-01-03T13:58:31.67456Z","shell.execute_reply":"2022-01-03T13:58:32.121869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=RANDOM_SEED, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['kfold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:32.12486Z","iopub.execute_input":"2022-01-03T13:58:32.125854Z","iopub.status.idle":"2022-01-03T13:58:32.411947Z","shell.execute_reply.started":"2022-01-03T13:58:32.12581Z","shell.execute_reply":"2022-01-03T13:58:32.411003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = ['Pawpularity']\ndrop_features = ['Id', 'bins', 'fold',\n                 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory','Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\ntrain_df = train_df.drop(columns=drop_features)\ncols = list(train_df.columns)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:32.413456Z","iopub.execute_input":"2022-01-03T13:58:32.414517Z","iopub.status.idle":"2022-01-03T13:58:32.426118Z","shell.execute_reply.started":"2022-01-03T13:58:32.414471Z","shell.execute_reply":"2022-01-03T13:58:32.42515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:32.427999Z","iopub.execute_input":"2022-01-03T13:58:32.428341Z","iopub.status.idle":"2022-01-03T13:58:32.448641Z","shell.execute_reply.started":"2022-01-03T13:58:32.428299Z","shell.execute_reply":"2022-01-03T13:58:32.447676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Train Augmentations","metadata":{"id":"ocxEJDymG9-9"}},{"cell_type":"code","source":"def get_train_transforms(DIM = params['im_size']):\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM,DIM),\n#             albumentations.Normalize(\n#                 mean=[0.51876384, 0.48398507, 0.44618937],\n#                 std=[0.26810414, 0.26382494, 0.26581845],\n#             ),\n            ToTensorV2(p=1.0),\n        ]\n    )","metadata":{"id":"VAgcHrtSG53X","execution":{"iopub.status.busy":"2022-01-03T13:58:32.450474Z","iopub.execute_input":"2022-01-03T13:58:32.450822Z","iopub.status.idle":"2022-01-03T13:58:32.456832Z","shell.execute_reply.started":"2022-01-03T13:58:32.450779Z","shell.execute_reply":"2022-01-03T13:58:32.45571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Mixup","metadata":{"id":"_7Jgmmh0HCI-"}},{"cell_type":"code","source":"def mixup_data(x, z, y, params):\n    if params['mixup_alpha'] > 0:\n        lam = np.random.beta(\n            params['mixup_alpha'], params['mixup_alpha']\n        )\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if params['device'].type == 'cuda':\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    mixed_z = lam * z + (1 - lam) * z[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, mixed_z, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","metadata":{"id":"cSI6LYDxHCoy","execution":{"iopub.status.busy":"2022-01-03T13:58:32.458744Z","iopub.execute_input":"2022-01-03T13:58:32.459231Z","iopub.status.idle":"2022-01-03T13:58:32.472654Z","shell.execute_reply.started":"2022-01-03T13:58:32.459188Z","shell.execute_reply":"2022-01-03T13:58:32.471653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Valid Augmentations","metadata":{"id":"GkfBqo6cHHCZ"}},{"cell_type":"code","source":"def get_valid_transforms(DIM = params['im_size']):\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM,DIM),\n#             albumentations.Normalize(\n#                 mean=[0.51876384, 0.48398507, 0.44618937],\n#                 std=[0.26810414, 0.26382494, 0.26581845],\n#             ),\n            ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"id":"vyYpi2CJHHZr","execution":{"iopub.status.busy":"2022-01-03T13:58:32.474575Z","iopub.execute_input":"2022-01-03T13:58:32.475483Z","iopub.status.idle":"2022-01-03T13:58:32.482127Z","shell.execute_reply.started":"2022-01-03T13:58:32.47544Z","shell.execute_reply":"2022-01-03T13:58:32.481072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"1XzssvuYHNI0"}},{"cell_type":"code","source":"class CuteDataset(Dataset):\n    def __init__(self, images_filepaths, dense_features, targets, transform=None):\n        self.images_filepaths = images_filepaths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        \n        image = torch.tensor(image, dtype=torch.int32)\n        dense = self.dense_features[idx, :]\n        label = self.targets[idx]\n\n        return image, dense, label","metadata":{"id":"7b4_Zu73HK62","execution":{"iopub.status.busy":"2022-01-03T13:58:32.485083Z","iopub.execute_input":"2022-01-03T13:58:32.486034Z","iopub.status.idle":"2022-01-03T13:58:32.496495Z","shell.execute_reply.started":"2022-01-03T13:58:32.485989Z","shell.execute_reply":"2022-01-03T13:58:32.495442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Visualize Some Examples","metadata":{"id":"z4LHNKAcTsi7"}},{"cell_type":"code","source":"X_train = train_df['image_path']\nX_train_dense = train_df[params['dense_features']]\ny_train = train_df['Pawpularity']\ntrain_dataset = CuteDataset(\n    images_filepaths=X_train.values,\n    dense_features=X_train_dense.values,\n    targets=y_train.values,\n    transform=get_train_transforms()\n)","metadata":{"id":"-WJ54a68TxVS","execution":{"iopub.status.busy":"2022-01-03T13:58:32.498051Z","iopub.execute_input":"2022-01-03T13:58:32.498604Z","iopub.status.idle":"2022-01-03T13:58:32.509618Z","shell.execute_reply.started":"2022-01-03T13:58:32.498561Z","shell.execute_reply":"2022-01-03T13:58:32.508605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{"id":"GMHo2KKAHw-3"}},{"cell_type":"code","source":"def usr_rmse_score(output, target):\n    y_pred = torch.sigmoid(output).cpu()\n    y_pred = y_pred.detach().numpy()*100\n    target = target.cpu()*100\n    \n    return mean_squared_error(target, y_pred, squared=False)","metadata":{"id":"nHiDAFprHtD-","execution":{"iopub.status.busy":"2022-01-03T13:58:38.680949Z","iopub.execute_input":"2022-01-03T13:58:38.68136Z","iopub.status.idle":"2022-01-03T13:58:38.703483Z","shell.execute_reply.started":"2022-01-03T13:58:38.681308Z","shell.execute_reply":"2022-01-03T13:58:38.702372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scheduler(optimizer, scheduler_params=params):\n    if scheduler_params['scheduler_name'] == 'CosineAnnealingWarmRestarts':\n        scheduler = CosineAnnealingWarmRestarts(\n            optimizer,\n            T_0=scheduler_params['T_0'],\n            eta_min=scheduler_params['min_lr'],\n            last_epoch=-1\n        )\n    elif scheduler_params['scheduler_name'] == 'OneCycleLR':\n        scheduler = OneCycleLR(\n            optimizer,\n            max_lr=scheduler_params['max_lr'],\n            steps_per_epoch=int(((scheduler_params['num_fold']-1) * train_df.shape[0]) / (scheduler_params['num_fold'] * scheduler_params['batch_size'])) + 1,\n            epochs=scheduler_params['epochs'],\n        )\n\n    elif scheduler_params['scheduler_name'] == 'CosineAnnealingLR':\n        scheduler = CosineAnnealingLR(\n            optimizer,\n            T_max=scheduler_params['T_max'],\n            eta_min=scheduler_params['min_lr'],\n            last_epoch=-1\n        )\n    return scheduler","metadata":{"id":"ikY8Rw2vI3fx","execution":{"iopub.status.busy":"2022-01-03T13:58:38.707335Z","iopub.execute_input":"2022-01-03T13:58:38.707618Z","iopub.status.idle":"2022-01-03T13:58:38.719354Z","shell.execute_reply.started":"2022-01-03T13:58:38.707589Z","shell.execute_reply":"2022-01-03T13:58:38.718139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{}},{"cell_type":"code","source":"from torch.nn.modules.loss import _WeightedLoss\n\nclass SmoothBCEwLogits(_WeightedLoss):\n    def __init__(self, weight = None, reduction = 'mean', smoothing = 0.0, pos_weight = None):\n        super().__init__(weight=weight, reduction=reduction)\n        self.smoothing = smoothing\n        self.weight = weight\n        self.reduction = reduction\n        self.pos_weight = pos_weight\n\n    @staticmethod\n    def _smooth(targets, n_labels, smoothing = 0.0):\n        assert 0 <= smoothing < 1\n        with torch.no_grad(): targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n        return targets\n\n    def forward(self, inputs, targets):\n        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1), self.smoothing)\n        loss = F.binary_cross_entropy_with_logits(inputs, targets, self.weight, pos_weight = self.pos_weight)\n        del targets\n        if  self.reduction == 'sum': loss = loss.sum()\n        elif  self.reduction == 'mean': loss = loss.mean()  \n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:38.722659Z","iopub.execute_input":"2022-01-03T13:58:38.722958Z","iopub.status.idle":"2022-01-03T13:58:38.734759Z","shell.execute_reply.started":"2022-01-03T13:58:38.722902Z","shell.execute_reply":"2022-01-03T13:58:38.733724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class PetNet(nn.Module):\n    def __init__(self, model_name=params['model'], out_features=params['out_features'], inp_channels=params['inp_channels'],\n                 pretrained=params['pretrained'], num_dense=len(params['dense_features'])):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, 128)\n        self.fc = nn.Sequential(\n            nn.Linear(128 + num_dense, 64),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(64, out_features)\n        )\n        self.dropout = nn.Dropout(params['dropout'])\n    \n    def forward(self, image, dense):\n        embeddings = self.model(image)\n        x = self.dropout(embeddings)\n        x = torch.cat([x, dense], dim=1)\n        output = self.fc(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:38.749748Z","iopub.execute_input":"2022-01-03T13:58:38.750889Z","iopub.status.idle":"2022-01-03T13:58:38.763053Z","shell.execute_reply.started":"2022-01-03T13:58:38.750849Z","shell.execute_reply":"2022-01-03T13:58:38.761998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and Validation Functions","metadata":{"id":"4t9QFMaWL8UB"}},{"cell_type":"markdown","source":"## 1. Train Function","metadata":{"id":"ICwkAc81L-gl"}},{"cell_type":"code","source":"def train_mixup_fn(train_loader, model, criterion, optimizer, epoch, params, loss_train_tracker, scheduler=None):\n    model.train()\n    stream = tqdm(train_loader)\n    loss = None\n    \n    for i, (images, dense, target) in enumerate(stream, start=1):\n        if loss is not None:\n            del loss\n\n        images, dense, target_a, target_b, lam = mixup_data(images, dense, target.view(-1, 1), params)\n        images = images.to(params['device'], dtype=torch.float32)\n        dense = dense.to(params['device'], dtype=torch.float32)\n        target_a = target_a.to(params['device'], dtype=torch.float32)\n        target_b = target_b.to(params['device'], dtype=torch.float32)\n            \n        output = model(images, dense)\n        \n        loss = mixup_criterion(criterion, output, target_a, target_b, lam)\n                \n        rmse_score = usr_rmse_score(output, target)\n        \n        loss.backward()\n        optimizer.step()\n            \n        if scheduler is not None:\n            scheduler.step()\n        \n        optimizer.zero_grad()\n        \n        stream.set_description(f\"Epoch:{epoch:02}. Train Loss:{loss.item():.4f}. RMSE:{rmse_score:.4f}\")\n        del images, dense, target_a, target_b, lam\n    \n    print(f\"Fold: {fold}. Epoch: {epoch}. Train Loss. {loss:.4f}. Train RMSE. {rmse_score:.4f}.\")\n    del loss, stream, rmse_score\n            ","metadata":{"id":"lPx4HwTbL3_N","execution":{"iopub.status.busy":"2022-01-03T13:58:38.76477Z","iopub.execute_input":"2022-01-03T13:58:38.765938Z","iopub.status.idle":"2022-01-03T13:58:38.779093Z","shell.execute_reply.started":"2022-01-03T13:58:38.76588Z","shell.execute_reply":"2022-01-03T13:58:38.778094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, epoch, params, loss_train_tracker, scheduler=None):\n    model.train()\n    stream = tqdm(train_loader)\n    loss = None\n    images = None\n    dense = None\n    target = None\n    \n    for i, (images, dense, target) in enumerate(stream, start=1):\n        if loss is not None:\n            del loss\n        print(\" \")\n        print(\"load data\")\n        check_memory()\n        images = images.to(params['device'], dtype=torch.float32)\n        dense = dense.to(params['device'], dtype=torch.float32)\n        target = target.to(params['device'], dtype=torch.float32).view(-1, 1)\n        output = model(images, dense)\n        \n        loss = criterion(output, target)\n        rmse_score = usr_rmse_score(output, target)\n        \n        loss.backward()\n        optimizer.step()\n            \n        if scheduler is not None:\n            scheduler.step()\n        \n        optimizer.zero_grad()\n        stream.set_description(f\"Epoch:{epoch:02}. Train Loss:{loss.item():.4f}. RMSE:{rmse_score:.4f}\")\n        del images, dense, target, output\n    \n    print(f\"Fold: {fold}. Epoch: {epoch}. Train Loss. {loss:.4f}. Train RMSE. {rmse_score:.4f}.\")\n    del loss, stream, rmse_score","metadata":{"execution":{"iopub.status.busy":"2022-01-03T13:58:38.780769Z","iopub.execute_input":"2022-01-03T13:58:38.781798Z","iopub.status.idle":"2022-01-03T13:58:38.795489Z","shell.execute_reply.started":"2022-01-03T13:58:38.781754Z","shell.execute_reply":"2022-01-03T13:58:38.79438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Validate Function","metadata":{"id":"wKVjdmIbMrN4"}},{"cell_type":"code","source":"def validate_fn(valid_loader, model, criterion, epoch, params):\n    model.eval()\n    print(\"stream\")\n    check_memory()\n    stream = tqdm(valid_loader)\n    final_targets = []\n    final_outputs = []\n    loss = None\n    \n    with torch.no_grad():\n        for i, (images, dense, target) in enumerate(stream, start=1):\n            if loss is not None:\n                del loss\n\n            images = images.to(params['device'], dtype=torch.float32)\n            dense = dense.to(params['device'], dtype=torch.float32)\n            target = target.to(params['device'], dtype=torch.float32).view(-1, 1)\n\n            output = model(images, dense)\n            loss = criterion(output, target)\n            rmse_score = usr_rmse_score(output, target)\n            stream.set_description(f\"Epoch: {epoch:02}. Valid Loss:{loss.item():.4f}. RMSE:{rmse_score:.4f}\")\n            \n            targets = (target.detach().cpu().numpy()*100).tolist()\n            outputs = (torch.sigmoid(output).detach().cpu().numpy()*100).tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(outputs)    \n\n    print(f\"Fold: {fold}. Epoch: {epoch}. Valid Loss. {loss:.4f}. Valid RMSE. {rmse_score:.4f}.\")\n    del loss, stream, rmse_score, output, targets, outputs\n\n    return final_outputs, final_targets","metadata":{"id":"d07oClh-MnzD","execution":{"iopub.status.busy":"2022-01-03T13:58:38.797133Z","iopub.execute_input":"2022-01-03T13:58:38.797741Z","iopub.status.idle":"2022-01-03T13:58:38.812447Z","shell.execute_reply.started":"2022-01-03T13:58:38.797701Z","shell.execute_reply":"2022-01-03T13:58:38.811097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nfrom pympler.tracker import SummaryTracker\ntracker = SummaryTracker()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\nprint(\" ------------------------------------ \")\nfor var_name in dir():\n    if not var_name.startswith(\"_\"):\n        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tot_mem = round(torch.cuda.get_device_properties(0).total_memory/(1024*1024*1024),1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run","metadata":{"id":"dlPu51_fMysB"}},{"cell_type":"code","source":"for fold in TRAIN_FOLDS:\n    print(f\"---Train fold:{fold}.---\")\n    # Data Split to train and Validation\n    train = train_df[train_df['kfold'] != fold]\n    valid = train_df[train_df['kfold'] == fold]\n    \n    X_train = train['image_path']\n    X_train_dense = train[params['dense_features']]\n    y_train = train['Pawpularity']/100\n \n    # Pytorch Dataset Creation\n    train_dataset = CuteDataset(\n        images_filepaths=X_train.values,\n        dense_features=X_train_dense.values,\n        targets=y_train.values,\n        transform=get_train_transforms()\n    )\n    \n    # Pytorch Dataloader creation\n    train_loader = DataLoader(\n        train_dataset, batch_size=params['batch_size'], shuffle=True,\n        num_workers=params['num_workers'], pin_memory=True\n    )\n    \n    # set valid data\n    X_valid = valid['image_path']\n    X_valid_dense = valid[params['dense_features']]\n    y_valid = valid['Pawpularity']/100\n\n    valid_dataset = CuteDataset(\n        images_filepaths=X_valid.values,\n        dense_features=X_valid_dense.values,\n        targets=y_valid.values,\n        transform=get_valid_transforms()\n    )\n    valid_loader = DataLoader(\n        valid_dataset, batch_size=params['batch_size'], shuffle=False,\n        num_workers=params['num_workers'], pin_memory=True\n    )\n    \n    # Model, cost function and optimizer instancing\n    model = PetNet()\n    model = model.to(params['device'])\n    criterion = SmoothBCEwLogits()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'],\n                                  weight_decay=params['weight_decay'],\n                                  amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n    \n    # Training and Validation Loop\n    best_rmse = np.inf\n    best_epoch = np.inf\n    best_model_name = None\n    early_stop_cnt = 0\n    print(f\"Start Training\")\n    print(f\"Fold:{fold} is trained.\")\n    \n    # Train & Valid Loop\n    for epoch in range(1, params['epochs'] + 1):\n        print(f\"Start Training. Fold:{fold}. Epoch:{epoch}\")\n        \n        # Check Early Stopping\n        if early_stop_cnt >= params['patience']:\n            print(f\"Early stoppping. Fold:{fold} Epoch:{epoch}.\")\n            continue\n\n        # measure elapsed time\n        torch.cuda.synchronize()\n        start = time.time()\n        print(f\"Before Train.\")\n        check_memory()\n        if params['mixup']:\n            train_mixup_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler)\n        else:\n            train_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler)\n        print(f\"After Train. Before valid\")\n        check_memory()\n        predictions, valid_targets = validate_fn(valid_loader, model, criterion, epoch, params)\n        \n        print(f\"After valid.\")\n        check_memory()\n        rmse = round(mean_squared_error(valid_targets, predictions, squared=False), 5)\n        print(f\"After Scoring.\")\n        check_memory()\n\n        if rmse < best_rmse:\n            early_stop_cnt = 0\n            best_rmse = rmse\n            best_epoch = epoch\n            if best_model_name is not None:\n                os.remove(best_model_name)\n            torch.save(model.state_dict(),\n                       f\"{params['model']}_{epoch}_epoch_f{fold+1}_{rmse}_rmse.pth\")\n            best_model_name = f\"{params['model']}_{epoch}_epoch_f{fold+1}_{rmse}_rmse.pth\"\n        else:\n            early_stop_cnt += 1\n            \n        torch.cuda.synchronize()\n        elapsed_time = time.time() - start\n        \n        print(f\"Epoch:{epoch}. Elapsed_time: {elapsed_time/60:.2f} minutes.\")\n        print(f\"Pred RSME rmse :{rmse}\")\n        print(f\"Pred values MAX:{max(predictions)}, MIN:{min(predictions)}\")\n        print(f\"Precision is not improved:{early_stop_cnt} times. Patience:{params['patience']}\")\n        \n        #memory check function\n        res_mem = round(torch.cuda.memory_reserved(0)/(1024*1024*1024),1)\n        print(\"Reserved GPU memory: \",res_mem)\n        memory_ckpt()\n        \n    # Print summary of this fold\n    print('')\n    print(f'The best RMSE: {best_rmse} for fold {fold+1} was achieved on epoch: {best_epoch}.')\n    print(f'The Best saved model is: {best_model_name}')\n    \n    # check memory before and after del\n    print(f'before delete and gc collect and cuda empty cache')\n    check_memory()\n\n    del model\n    del train, X_train, X_train_dense, y_train, train_dataset, train_loader\n    del valid, X_valid, X_valid_dense, y_valid, valid_dataset, valid_loader\n    del predictions, valid_targets, elapsed_time\n    \n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    print(f'after delete and gc collect and cuda empty cache')\n    check_memory()\n\n    print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n    print(\" ------------------------------------ \")\n    for var_name in dir():\n        if not var_name.startswith(\"_\"):\n            print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))\n        \n    print(f\"---Trained fold:{fold}.---\")","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-03T13:58:38.814309Z","iopub.execute_input":"2022-01-03T13:58:38.814823Z","iopub.status.idle":"2022-01-03T14:09:21.41317Z","shell.execute_reply.started":"2022-01-03T13:58:38.814771Z","shell.execute_reply":"2022-01-03T14:09:21.410921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\nprint(\" ------------------------------------ \")\nfor var_name in dir():\n    if not var_name.startswith(\"_\"):\n        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}