{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/timmmaster/\")\n\n\n\nimport os\nimport math\nimport cv2\nimport timm\nimport torch\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch.optim as optim\nimport albumentations\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom typing import List, Optional\nfrom dataclasses import dataclass\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils import data as torch_data\nfrom catalyst import dl\nfrom catalyst.data import ToTensor\nfrom catalyst.contrib.nn import BatchScheduler\nfrom catalyst.utils.torch import set_optimizer_momentum\nfrom sklearn.model_selection import StratifiedKFold, train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-30T13:23:28.136541Z","iopub.execute_input":"2021-09-30T13:23:28.136804Z","iopub.status.idle":"2021-09-30T13:23:39.914879Z","shell.execute_reply.started":"2021-09-30T13:23:28.136719Z","shell.execute_reply":"2021-09-30T13:23:39.914061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img align=\"left\" src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/25383/logos/header.png?t=2021-08-31-18-49-29\" data-canonical-src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/25383/logos/header.png?t=2021-08-31-18-49-29\" width=\"1350\" />\n","metadata":{}},{"cell_type":"markdown","source":"1. [EDA](#1)\n    * [Pawpularity](#1.1)\n    * [Additional Characteristics](#1.2)\n    * [Image for each charecteristic](#1.3)\n2. [Train](#2)\n3. [Inference](#3)\n4. [References](#4)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n## 1. EDA","metadata":{}},{"cell_type":"code","source":"def set_seed(seed: int):\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\n@dataclass\nclass CFG:\n    image_size: int = 256\n    vflip_p: float = 0.01\n    fold: int = 0\n    lr: float = 5e-4\n    reg_dropout: float = 0.1\n    batch_size: int = 64\n    reg_epochs: int = 5\n    seed: int = 2809\n        \ncfg = CFG()\nset_seed(cfg.seed)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:23:39.916788Z","iopub.execute_input":"2021-09-30T13:23:39.917Z","iopub.status.idle":"2021-09-30T13:23:39.928819Z","shell.execute_reply.started":"2021-09-30T13:23:39.916969Z","shell.execute_reply":"2021-09-30T13:23:39.928151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/same-old-creating-folds/train_10folds.csv\")\n\ndf_train = df[df.kfold != cfg.fold].reset_index(drop=True)\ndf_valid = df[df.kfold == cfg.fold].reset_index(drop=True)\n\ncharacteristics = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n]\n\ntrain_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\nvalid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:23:39.929946Z","iopub.execute_input":"2021-09-30T13:23:39.930331Z","iopub.status.idle":"2021-09-30T13:23:39.994349Z","shell.execute_reply.started":"2021-09-30T13:23:39.930295Z","shell.execute_reply":"2021-09-30T13:23:39.993626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n### Pawpularity\nThe Pawpularity Score is derived from each pet profile's page view statistics at the listing pages, using an algorithm that normalizes the traffic data across different pages, platforms (web & mobile) and various metrics.","metadata":{}},{"cell_type":"code","source":"def get_center(x):\n    hist, bins = np.histogram(x, bins=128)\n    a = hist.argmax()\n    return (bins[a + 1] + bins[a]) / 2","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:32:10.091079Z","iopub.execute_input":"2021-09-30T13:32:10.091707Z","iopub.status.idle":"2021-09-30T13:32:10.096881Z","shell.execute_reply.started":"2021-09-30T13:32:10.091657Z","shell.execute_reply":"2021-09-30T13:32:10.095756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = ff.create_distplot([df_train.Pawpularity.values, df_valid.Pawpularity.values], ['Train', 'Valid'])\nfig.update_layout(\n    title=\"Pawpularity Distribution\",\n    xaxis_title=\"Pawpularity\",\n    yaxis_title=\"Density\")\nCX = get_center(df.Pawpularity.values)\nLNX = CX\nRNX = 100 - CX\nfig.add_vline(get_center(df.Pawpularity.values), line_width=3, line_color=\"red\")\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-30T13:32:10.944459Z","iopub.execute_input":"2021-09-30T13:32:10.944744Z","iopub.status.idle":"2021-09-30T13:32:11.170332Z","shell.execute_reply.started":"2021-09-30T13:32:10.944709Z","shell.execute_reply":"2021-09-30T13:32:11.169651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def norm(x, center=CX, lscale=LNX, rscale=RNX):\n    x = x.copy().astype(np.float64)\n    x -= center\n    x[x <= 0] /= lscale\n    x[x > 0] /= rscale\n    return x\n\ndef inorm(x, center=CX, lscale=LNX, rscale=RNX):\n    x = x.copy().astype(np.float64)\n    x[x <= 0] *= lscale\n    x[x > 0] *= rscale\n    return x + center","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:32:11.65119Z","iopub.execute_input":"2021-09-30T13:32:11.651728Z","iopub.status.idle":"2021-09-30T13:32:11.657977Z","shell.execute_reply.started":"2021-09-30T13:32:11.651675Z","shell.execute_reply":"2021-09-30T13:32:11.656908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = ff.create_distplot([norm(df_train.Pawpularity.values), norm(df_valid.Pawpularity.values)], ['Train', 'Valid'], bin_size=0.01)\nfig.update_layout(\n    title=\"Pawpularity Distribution\",\n    xaxis_title=\"Pawpularity\",\n    yaxis_title=\"Density\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:32:13.444479Z","iopub.execute_input":"2021-09-30T13:32:13.44504Z","iopub.status.idle":"2021-09-30T13:32:13.67949Z","shell.execute_reply.started":"2021-09-30T13:32:13.445Z","shell.execute_reply":"2021-09-30T13:32:13.67874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_c = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'Pawpularity'\n]\nfig = fig = px.imshow(df[_c].corr())\nfig.update_layout(\n    title=\"Characteristics - Pawpularity Correlation\")\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-30T13:32:41.947182Z","iopub.execute_input":"2021-09-30T13:32:41.947441Z","iopub.status.idle":"2021-09-30T13:32:42.556878Z","shell.execute_reply.started":"2021-09-30T13:32:41.947413Z","shell.execute_reply":"2021-09-30T13:32:42.556026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.2\"></a>\n### Additional Characteristics\n* Focus - Pet stands out against uncluttered background, not too close / far.\n* Eyes - Both eyes are facing front or near-front, with at least 1 eye / pupil decently clear.\n* Face - Decently clear face, facing front or near-front.\n* Near - Single pet taking up significant portion of photo (roughly over 50% of photo width or height).\n* Action - Pet in the middle of an action (e.g., jumping).\n* Accessory - Accompanying physical or digital accessory / prop (i.e. toy, digital sticker), excluding collar and leash.\n* Group - More than 1 pet in the photo.\n* Collage - Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).\n* Human - Human in the photo.\n* Occlusion - Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are considered occlusion.\n* Info - Custom-added text or labels (i.e. pet name, description).\n* Blur - Noticeably out of focus or noisy, especially for the pet’s eyes and face. For Blur entries, “Eyes” column is always set to 0.\n","metadata":{}},{"cell_type":"code","source":"widths = np.array([10 for _ in characteristics])\n\ndata = {\n    \"Positive\": df[characteristics].values.sum(0),\n    \"Negative\": len(df) -  df[characteristics].values.sum(0)\n}\n\nfig = go.Figure()\nfor key in data:\n    fig.add_trace(go.Bar(\n        name=key,\n        y=data[key],\n        x=np.cumsum(widths)-widths,\n        width=widths,\n        offset=0,\n        customdata=np.transpose([characteristics, data[key]]),\n        texttemplate=\"%{customdata[0]}<br>%{customdata[1]}\",\n        textposition=\"inside\",\n        textangle=0,\n        textfont_color=\"white\",\n        hovertemplate=\"<br>\".join([\n            \"characteristic: %{customdata[0]}\",\n            \"Total Num.: %{customdata[1]}\",\n        ])\n    ))\n\nfig.update_xaxes(\n    tickvals=np.cumsum(widths)-widths/2,\n    ticktext= [\"%s\" % (l) for l in characteristics]\n)\n\nfig.update_xaxes(range=[0,sum(widths)])\nfig.update_yaxes(range=[0,len(df)])\n\nfig.update_layout(\n    title_text=\"Characteristic Pos./Neg. Disttribution\",\n    barmode=\"stack\",\n    uniformtext=dict(mode=\"hide\", minsize=10),\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:32:43.54334Z","iopub.execute_input":"2021-09-30T13:32:43.544204Z","iopub.status.idle":"2021-09-30T13:32:43.625492Z","shell.execute_reply.started":"2021-09-30T13:32:43.54416Z","shell.execute_reply":"2021-09-30T13:32:43.624496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.3\"></a>\n### Image for each charecteristic","metadata":{}},{"cell_type":"code","source":"def visualize_img_characteristic(characteristic):\n    neg = [cv2.cvtColor(\n        cv2.imread(f\"../input/petfinder-pawpularity-score/train/{idx}.jpg\"), \n        cv2.COLOR_BGR2RGB) for idx in df.loc[df[characteristic] == 0, 'Id'].sample(1)]\n    pos = [cv2.cvtColor(\n        cv2.imread(f\"../input/petfinder-pawpularity-score/train/{idx}.jpg\"), \n        cv2.COLOR_BGR2RGB) for idx in df.loc[df[characteristic] == 1, 'Id'].sample(1)]\n\n    fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n\n    for p, n in zip(pos, neg):\n        axs[0].imshow(p)\n        axs[0].set_title('1')\n        axs[0].axis('off')\n    \n    \n        axs[1].imshow(n)\n        axs[1].set_title('0')\n        axs[1].axis('off')\n    fig.suptitle(characteristic)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:32:46.367371Z","iopub.execute_input":"2021-09-30T13:32:46.36814Z","iopub.status.idle":"2021-09-30T13:32:46.376781Z","shell.execute_reply.started":"2021-09-30T13:32:46.368102Z","shell.execute_reply":"2021-09-30T13:32:46.375844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for c in characteristics:\n    visualize_img_characteristic(c)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:32:48.802451Z","iopub.execute_input":"2021-09-30T13:32:48.802756Z","iopub.status.idle":"2021-09-30T13:32:53.998502Z","shell.execute_reply.started":"2021-09-30T13:32:48.802723Z","shell.execute_reply":"2021-09-30T13:32:53.997606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n## 2. Train","metadata":{}},{"cell_type":"code","source":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, image_paths: List[str], targets: np.ndarray, augmentations: albumentations.Compose):\n        self.image_paths = image_paths\n        self.targets = norm(targets)\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, index):\n        image = cv2.imread(self.image_paths[index])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = torch.tensor(np.transpose(image, (2, 0, 1)).astype(np.float32), dtype=torch.float)\n        \n        y = torch.tensor(self.targets[index], dtype=torch.float)\n        return {\"features\": image, \"targets\": y}","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:33:11.843132Z","iopub.execute_input":"2021-09-30T13:33:11.843529Z","iopub.status.idle":"2021-09-30T13:33:11.851627Z","shell.execute_reply.started":"2021-09-30T13:33:11.843477Z","shell.execute_reply":"2021-09-30T13:33:11.850679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegModel(nn.Module):\n    def __init__(self, base_model: nn.Module, config: CFG):\n        super().__init__()\n        self.model = base_model\n        self.model.classifier = nn.Sequential(\n                    nn.Dropout(config.reg_dropout),\n                    nn.Linear(in_features=self.model.classifier.in_features, out_features=1, bias=False)\n        )\n    \n    def forward(self, x):\n        out = self.model(x)\n        return out[:, 0]","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:33:12.855123Z","iopub.execute_input":"2021-09-30T13:33:12.855384Z","iopub.status.idle":"2021-09-30T13:33:12.861785Z","shell.execute_reply.started":"2021-09-30T13:33:12.855355Z","shell.execute_reply":"2021-09-30T13:33:12.860892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CosineHardRestartWarmupBatchShedulerWrapper(BatchScheduler):\n    def __init__(self, optimizer: optim.Optimizer, \n                       num_warmup_steps: int, \n                       num_training_steps: int, \n                       num_cycles: int = 1,\n                       last_itter: int = -1,\n                       gamma: float = 0.9,\n                       verbose: bool = False):\n        self.__num_warmup_steps = num_warmup_steps\n        self.__num_training_steps = num_training_steps\n        self.__num_cycles = num_cycles\n        self.__gamma = gamma\n        self.__steps_per_epoch = (num_training_steps - num_warmup_steps) // (num_cycles)\n        self.total_groups = len(optimizer.param_groups)\n        super().__init__(optimizer, last_itter, verbose)\n        \n    def get_momentum(self):\n        return [] * self.total_groups\n    \n    \n    def get_lr(self):\n        return [lr * self._form_function(self._step_count) * self.__gamma ** (self._step_count // self.__steps_per_epoch) for lr in self.base_lrs]\n    \n    def _form_function(self, count):\n        if count < self.__num_warmup_steps:\n            return float(count) / float(max(1, self.__num_warmup_steps))\n        progress = float(count - self.__num_warmup_steps) / float(max(1, self.__num_training_steps - self.__num_warmup_steps))\n\n        if progress >= 1.0:\n            return 0\n        return max(0, 0.5 * (1.0 + math.cos(math.pi * ((float(self.__num_cycles) * progress) % 1.0))))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:33:13.726458Z","iopub.execute_input":"2021-09-30T13:33:13.726749Z","iopub.status.idle":"2021-09-30T13:33:13.737541Z","shell.execute_reply.started":"2021-09-30T13:33:13.726716Z","shell.execute_reply":"2021-09-30T13:33:13.736819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_aug = albumentations.Compose(\n    [\n        albumentations.Resize(cfg.image_size, cfg.image_size, p=1),\n        albumentations.augmentations.transforms.HorizontalFlip(p=cfg.vflip_p),\n        albumentations.Normalize(),\n    ],\n    p=1.0,\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(cfg.image_size, cfg.image_size, p=1),\n        albumentations.Normalize(),\n    ],\n    p=1.0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:33:14.470397Z","iopub.execute_input":"2021-09-30T13:33:14.471306Z","iopub.status.idle":"2021-09-30T13:33:14.478029Z","shell.execute_reply.started":"2021-09-30T13:33:14.471256Z","shell.execute_reply":"2021-09-30T13:33:14.477126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_dataset = DataRetriever(train_img_paths, df_train.loc[:, 'Pawpularity'].values, train_aug)\nvl_dataset = DataRetriever(valid_img_paths, df_valid.loc[:, 'Pawpularity'].values, valid_aug)\n\ntr_loader = DataLoader(tr_dataset, batch_size=cfg.batch_size, num_workers=8)\nvl_loader = DataLoader(vl_dataset, batch_size=cfg.batch_size, num_workers=8)\nloaders = {\"train\": tr_loader, \"valid\": vl_loader}","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:33:15.488516Z","iopub.execute_input":"2021-09-30T13:33:15.48882Z","iopub.status.idle":"2021-09-30T13:33:15.498655Z","shell.execute_reply.started":"2021-09-30T13:33:15.488786Z","shell.execute_reply":"2021-09-30T13:33:15.497761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained=False, in_chans=3)\nbase_model.load_state_dict(torch.load('../input/timms-effb0/tf_efficientnet_b0_ns-c0e6a31c.pth'))\n\nreg_model = RegModel(base_model, cfg)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(reg_model.parameters(), lr=cfg.lr)\nscheduler = CosineHardRestartWarmupBatchShedulerWrapper(\n                                    optimizer, \n                                    num_warmup_steps=len(tr_loader), \n                                    num_training_steps=len(tr_loader) * cfg.reg_epochs,\n                                    num_cycles=cfg.reg_epochs - 1\n)\n\nmodel_parameters = filter(lambda p: p.requires_grad, reg_model.parameters())\nprint(\"Total N params\",sum([np.prod(p.size()) for p in model_parameters]))\n\nrunner = dl.SupervisedRunner()\n# model training\nrunner.train(\n    model=reg_model,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    loaders=loaders,\n    num_epochs=cfg.reg_epochs,\n    logdir=\"./logs_reg\",\n    valid_loader=\"valid\",\n    valid_metric=\"loss\",\n    minimize_valid_metric=True,\n    verbose=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:33:16.993307Z","iopub.execute_input":"2021-09-30T13:33:16.993562Z","iopub.status.idle":"2021-09-30T13:42:10.87665Z","shell.execute_reply.started":"2021-09-30T13:33:16.993532Z","shell.execute_reply":"2021-09-30T13:42:10.875794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_metrics = pd.read_csv('./logs_reg/logs/valid.csv')\ntrain_metrics = pd.read_csv('./logs_reg/logs/train.csv')\n\nfig = px.line(\n    pd.DataFrame(\n        {\n        'Epoch': train_metrics.step,\n        'Valid RMSE': np.sqrt(valid_metrics.loss.values),\n        'Train RMSE': np.sqrt(train_metrics.loss.values)\n        }\n    ),\n    x='Epoch',\n    y=['Valid RMSE', 'Train RMSE'],\n    title='Train/Valid RMSE'\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:47:30.124891Z","iopub.execute_input":"2021-09-30T13:47:30.125667Z","iopub.status.idle":"2021-09-30T13:47:30.220818Z","shell.execute_reply.started":"2021-09-30T13:47:30.125622Z","shell.execute_reply":"2021-09-30T13:47:30.220129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_model.load_state_dict(torch.load('logs_reg/checkpoints/best_full.pth')['model_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:47:36.337187Z","iopub.execute_input":"2021-09-30T13:47:36.337993Z","iopub.status.idle":"2021-09-30T13:47:36.491048Z","shell.execute_reply.started":"2021-09-30T13:47:36.337949Z","shell.execute_reply":"2021-09-30T13:47:36.490201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_model.eval()\nvalid_pred = []\nvalid_target = []\n\nwith torch.no_grad():\n    for x in tqdm(vl_loader):\n        valid_pred.extend(reg_model(x['features'].to('cuda')).cpu().numpy().tolist())\n        valid_target.extend(x['targets'].numpy().tolist())\n        \nfig = ff.create_distplot([inorm(np.array(valid_pred)), inorm(np.array(valid_target))], ['Predicted', 'Target'])\nfig.update_layout(\n    title=\"Pawpularity Distribution\",\n    xaxis_title=\"Pawpularity\",\n    yaxis_title=\"Density\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:47:56.502482Z","iopub.execute_input":"2021-09-30T13:47:56.502768Z","iopub.status.idle":"2021-09-30T13:48:07.351075Z","shell.execute_reply.started":"2021-09-30T13:47:56.502736Z","shell.execute_reply":"2021-09-30T13:48:07.350189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_model.eval()\npred = []\ntarget = []\n\nwith torch.no_grad():\n    for x in tqdm(tr_loader):\n        pred.extend(reg_model(x['features'].to('cuda')).cpu().numpy().tolist())\n        target.extend(x['targets'].numpy().tolist())\n        \nfig = ff.create_distplot([inorm(np.array(pred)), inorm(np.array(target))], ['Predicted', 'Target'])\nfig.update_layout(\n    title=\"Pawpularity Distribution\",\n    xaxis_title=\"Pawpularity\",\n    yaxis_title=\"Density\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:48:21.5898Z","iopub.execute_input":"2021-09-30T13:48:21.590396Z","iopub.status.idle":"2021-09-30T13:49:48.011069Z","shell.execute_reply.started":"2021-09-30T13:48:21.590359Z","shell.execute_reply":"2021-09-30T13:49:48.010167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n## 3. Inference","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\ntest_img_paths = [f\"../input/petfinder-pawpularity-score/test/{x}.jpg\" for x in df_test[\"Id\"].values]\n\ntest_dataset = DataRetriever(\n    image_paths=test_img_paths,\n    targets=np.ones(len(test_img_paths)),\n    augmentations=valid_aug,\n)\n\nreg_model.eval()\nfinal_test_predictions = []\n\nwith torch.no_grad():\n    for x in tqdm(DataLoader(test_dataset, batch_size=cfg.batch_size, num_workers=8)):\n        final_test_predictions.extend(reg_model(x['features'].to('cuda')).cpu().numpy().tolist())\n\nfinal_test_predictions = inorm(np.array(final_test_predictions))\nfinal_test_predictions[final_test_predictions < 0] = 0\nfinal_test_predictions[final_test_predictions > 100] = 100\ndf_test[\"Pawpularity\"] = final_test_predictions\ndf_test = df_test[[\"Id\", \"Pawpularity\"]]\ndf_test.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T09:50:41.88652Z","iopub.execute_input":"2021-09-26T09:50:41.887106Z","iopub.status.idle":"2021-09-26T09:50:42.409067Z","shell.execute_reply.started":"2021-09-26T09:50:41.887068Z","shell.execute_reply":"2021-09-26T09:50:42.408289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n## References\n* [same old creating folds](https://www.kaggle.com/abhishek/same-old-creating-folds)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}