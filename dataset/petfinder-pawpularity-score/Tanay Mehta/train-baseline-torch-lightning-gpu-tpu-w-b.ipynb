{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"alert alert-info\">\n    <h2 align='center'>üêæ PyTorch Lightning Training Baseline for GPU & TPU + W&B Tracking üöÑ</h1>\n</div>\n\n<p style='text-align: center'>\n    To run the model on TPU, un-comment and run the below cell and change the <code>gpus=1</code> argument to <code>tpu_cores=1</code> or <code>tpu_cores=8</code> in the <code>Trainer</code> class.\n</p>","metadata":{}},{"cell_type":"markdown","source":"<h1 style='color: #fc0362; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 24px'>If you liked this notebook, kindly leave an upvote ‚¨ÜÔ∏è</h1>","metadata":{}},{"cell_type":"code","source":"# ! curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n# ! python pytorch-xla-env-setup.py --version 1.7 --apt-packages libomp5 libopenblas-dev","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-09T03:31:48.256859Z","iopub.execute_input":"2021-10-09T03:31:48.257205Z","iopub.status.idle":"2021-10-09T03:31:48.28068Z","shell.execute_reply.started":"2021-10-09T03:31:48.257122Z","shell.execute_reply":"2021-10-09T03:31:48.279824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>1. Installation & Imports</h1>","metadata":{}},{"cell_type":"code","source":"%%sh\npip install -q pytorch-lightning==1.1.8\npip install -q timm\npip install -q albumentations\npip install -q --upgrade wandb","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-09T03:31:48.583904Z","iopub.execute_input":"2021-10-09T03:31:48.584213Z","iopub.status.idle":"2021-10-09T03:32:44.05758Z","shell.execute_reply.started":"2021-10-09T03:31:48.584186Z","shell.execute_reply":"2021-10-09T03:32:44.056569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport timm\nimport torch\nimport transformers\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nimport os\nimport cv2\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nimport wandb\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\nfrom albumentations.pytorch import ToTensorV2\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-09T03:32:44.06015Z","iopub.execute_input":"2021-10-09T03:32:44.06083Z","iopub.status.idle":"2021-10-09T03:32:52.330883Z","shell.execute_reply.started":"2021-10-09T03:32:44.060752Z","shell.execute_reply":"2021-10-09T03:32:52.329766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\"/></center><br>\n<p style=\"text-align:center\">WandB is a developer tool for companies turn deep learning research projects into deployed software by helping teams track their models, visualize model performance and easily automate training and improving models.\nWe will use their tools to log hyperparameters and output metrics from your runs, then visualize and compare results and quickly share findings with your colleagues.<br><br></p>\n\n![img](https://i.imgur.com/BGgfZj3.png)","metadata":{}},{"cell_type":"markdown","source":"To login to W&B, you can use below snippet.\n\n```python\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\nwandb.login(key=wb_key)\n```\nMake sure you have your W&B key stored as `WANDB_API_KEY` under Add-ons -> Secrets\n\nYou can view [this](https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases) notebook to learn more about W&B tracking.\n\nIf you don't want to login to W&B, the kernel will still work and log everything to W&B in anonymous mode.","metadata":{}},{"cell_type":"code","source":"Config = dict(\n    NFOLDS = 5,\n    EPOCHS = 5,\n    LR = 2e-4,\n    IMG_SIZE = (224, 224),\n    MODEL_NAME = 'tf_efficientnet_b6_ns',\n    DR_RATE = 0.35,\n    NUM_LABELS = 1,\n    TRAIN_BS = 32,\n    VALID_BS = 16,\n    min_lr = 1e-6,\n    T_max = 20,\n    T_0 = 25,\n    NUM_WORKERS = 4,\n    infra = \"Kaggle\",\n    competition = 'petfinder',\n    _wandb_kernel = 'tanaym',\n    wandb = False\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T03:32:52.332531Z","iopub.execute_input":"2021-10-09T03:32:52.332946Z","iopub.status.idle":"2021-10-09T03:32:52.344124Z","shell.execute_reply.started":"2021-10-09T03:32:52.332839Z","shell.execute_reply":"2021-10-09T03:32:52.340174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a W&B Logger\nwandb_logger = WandbLogger(project='pytorchlightning', group='vision', job_type='train', anonymous='allow', config=Config)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T03:39:31.06047Z","iopub.execute_input":"2021-10-09T03:39:31.060778Z","iopub.status.idle":"2021-10-09T03:39:31.066378Z","shell.execute_reply.started":"2021-10-09T03:39:31.060749Z","shell.execute_reply":"2021-10-09T03:39:31.065235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>2. Dataset Class</h1>","metadata":{}},{"cell_type":"code","source":"class PetfinderData(Dataset):\n    def __init__(self, df, is_test=False, augments=None):\n        self.df = df\n        self.is_test = is_test\n        self.augments = augments\n        \n        self.images, self.meta_features, self.targets = self._process_df(self.df)\n    \n    def __getitem__(self, index):\n        img = self.images[index]\n        meta_feats = self.meta_features[index]\n        meta_feats = torch.tensor(meta_feats, dtype=torch.float32)\n        \n        img = cv2.imread(img)\n        img = img[:, :, ::-1]\n        img = cv2.resize(img, Config['IMG_SIZE'])\n        \n        if self.augments:\n            img = self.augments(image=img)['image']\n        \n        if not self.is_test:\n            target = torch.tensor(self.targets[index], dtype=torch.float32)\n            return img, meta_feats, target\n        else:\n            return img, meta_feats\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def _process_df(self, df):\n        TRAIN = \"../input/petfinder-pawpularity-score/train\"\n        TEST = \"../input/petfinder-pawpularity-score/test\"\n        \n        if not self.is_test:\n            df['Id'] = df['Id'].apply(lambda x: os.path.join(TRAIN, x+\".jpg\"))\n        else:\n            df['Id'] = df['Id'].apply(lambda x: os.path.join(TEST, x+\".jpg\"))\n            \n        meta_features = df.drop(['Id', 'Pawpularity'], axis=1).values\n        \n        return df['Id'].tolist(), meta_features, df['Pawpularity'].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T03:39:31.94457Z","iopub.execute_input":"2021-10-09T03:39:31.945342Z","iopub.status.idle":"2021-10-09T03:39:31.95906Z","shell.execute_reply.started":"2021-10-09T03:39:31.945304Z","shell.execute_reply":"2021-10-09T03:39:31.957799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>3. Augmentations</h1>","metadata":{}},{"cell_type":"code","source":"class Augments:\n    \"\"\"\n    Contains Train, Validation Augments\n    \"\"\"\n    train_augments = Compose([\n        Resize(*Config['IMG_SIZE'], p=1.0),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        Normalize(\n            mean=[0.485, 0.456, 0.406], \n            std=[0.229, 0.224, 0.225], \n            max_pixel_value=255.0, \n            p=1.0\n        ),\n        ToTensorV2(p=1.0),\n    ],p=1.)\n    \n    valid_augments = Compose([\n        Resize(*Config['IMG_SIZE'], p=1.0),\n        Normalize(\n            mean=[0.485, 0.456, 0.406], \n            std=[0.229, 0.224, 0.225], \n            max_pixel_value=255.0, \n            p=1.0\n        ),\n        ToTensorV2(p=1.0),\n    ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T03:39:33.074441Z","iopub.execute_input":"2021-10-09T03:39:33.075054Z","iopub.status.idle":"2021-10-09T03:39:33.083219Z","shell.execute_reply.started":"2021-10-09T03:39:33.075024Z","shell.execute_reply":"2021-10-09T03:39:33.081675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>4. Pytorch Lightning Model Class</h1>","metadata":{}},{"cell_type":"code","source":"class PetFinderModel(pl.LightningModule):\n    def __init__(self, pretrained=True):\n        super(PetFinderModel, self).__init__()\n        self.model = timm.create_model(Config['MODEL_NAME'], pretrained=pretrained)\n        \n        self.n_features = self.model.classifier.in_features\n        self.model.reset_classifier(0)\n        self.fc = nn.Linear(self.n_features + 12, Config['NUM_LABELS'])\n        \n        self.train_loss = nn.MSELoss()\n        self.valid_loss = nn.MSELoss()\n\n    def forward(self, images, meta):\n        features = self.model(images)\n        features = torch.cat([features, meta], dim=1)\n        output = self.fc(features)\n        return output\n    \n    def training_step(self, batch, batch_idx):\n        imgs = batch[0]\n        meta = batch[1]\n        target = batch[2]\n        \n        out = self(imgs, meta)\n        train_loss = torch.sqrt(self.train_loss(out, target))\n        \n        logs = {'train_loss': train_loss}\n        \n        return {'loss': train_loss, 'log': logs}\n    \n    def validation_step(self, batch, batch_idx):\n        imgs = batch[0]\n        meta = batch[1]\n        target = batch[2]\n        \n        out = self(imgs, meta)\n        valid_loss = torch.sqrt(self.valid_loss(out, target))\n        \n        return {'val_loss': valid_loss}\n    \n    def validation_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        logs = {'val_loss': avg_loss}\n        \n        print(f\"val_loss: {avg_loss}\")\n        return {'avg_val_loss': avg_loss, 'log': logs}\n    \n    def configure_optimizers(self):\n        opt = torch.optim.Adam(self.parameters(), lr=Config['LR'])\n        sch = torch.optim.lr_scheduler.CosineAnnealingLR(\n            opt, \n            T_max=Config['T_max'],\n            eta_min=Config['min_lr']\n        )\n        \n        return [opt], [sch]","metadata":{"execution":{"iopub.status.busy":"2021-10-09T03:39:34.070664Z","iopub.execute_input":"2021-10-09T03:39:34.071219Z","iopub.status.idle":"2021-10-09T03:39:34.086888Z","shell.execute_reply.started":"2021-10-09T03:39:34.071186Z","shell.execute_reply":"2021-10-09T03:39:34.085677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center' style='color: #8532a8; font-family: Segoe UI; font-size: 1.5em; font-weight: 300; font-size: 32px'>5. KFolds Model Training</h1>","metadata":{}},{"cell_type":"code","source":"# Run the Kfolds training loop\nkf = StratifiedKFold(n_splits=Config['NFOLDS'])\ntrain_file = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\n\nfor fold_, (train_idx, valid_idx) in enumerate(kf.split(X=train_file, y=train_file['Pawpularity'])):\n    print(f\"{'='*20} Fold: {fold_} {'='*20}\")\n    \n    train_df = train_file.loc[train_idx]\n    valid_df = train_file.loc[valid_idx]\n    \n    train_set = PetfinderData(\n        train_df,\n        augments = Augments.train_augments\n    )\n\n    valid_set = PetfinderData(\n        valid_df,\n        augments = Augments.valid_augments\n    )\n    \n    train = DataLoader(\n        train_set,\n        batch_size=Config['TRAIN_BS'],\n        shuffle=True,\n        num_workers=Config['NUM_WORKERS'],\n        pin_memory=True\n    )\n    valid = DataLoader(\n        valid_set,\n        batch_size=Config['VALID_BS'],\n        shuffle=False,\n        num_workers=Config['NUM_WORKERS']\n    )\n    \n    checkpoint_callback = ModelCheckpoint(\n        monitor=\"val_loss\",\n        dirpath=\"./\",\n        filename=f\"fold_{fold_}_{Config['MODEL_NAME']}\",\n        save_top_k=1,\n        mode=\"min\",\n    )\n    \n    model = PetFinderModel()\n    trainer = pl.Trainer(\n        max_epochs=Config['EPOCHS'], \n        gpus=1, \n        callbacks=[checkpoint_callback], \n        logger= wandb_logger\n    )\n    trainer.fit(model, train, valid)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T03:39:35.503974Z","iopub.execute_input":"2021-10-09T03:39:35.504579Z","iopub.status.idle":"2021-10-09T05:18:49.027349Z","shell.execute_reply.started":"2021-10-09T03:39:35.504534Z","shell.execute_reply":"2021-10-09T05:18:49.026246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [View the Complete Dashboard Here üéØ](https://wandb.ai/anony-mouse-138818/pytorchlightning/runs/1mgcybd2?apiKey=9c1b4ff53762c75e39d283f5434cc5552455b179)","metadata":{}},{"cell_type":"markdown","source":"![](https://imgur.com/XyvhYFZ.gif)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}