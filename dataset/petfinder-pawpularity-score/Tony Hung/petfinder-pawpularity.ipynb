{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"xrWxMEkjGCyv","outputId":"8e62d093-ec18-4ada-8250-31796cfc47eb","execution":{"iopub.status.busy":"2022-03-18T21:38:29.056128Z","iopub.execute_input":"2022-03-18T21:38:29.056392Z","iopub.status.idle":"2022-03-18T21:38:29.060393Z","shell.execute_reply.started":"2022-03-18T21:38:29.056363Z","shell.execute_reply":"2022-03-18T21:38:29.059281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade --force-reinstall kaggle\n# !pip install wandb\n# !pip install timm\n# !pip install albumentations\n","metadata":{"id":"-QALS2DOG804","outputId":"f59cebc2-b1f1-4143-d3fa-e4a0c14dd1a7","execution":{"iopub.status.busy":"2022-03-18T21:38:29.061977Z","iopub.execute_input":"2022-03-18T21:38:29.062425Z","iopub.status.idle":"2022-03-18T21:38:29.070799Z","shell.execute_reply.started":"2022-03-18T21:38:29.062388Z","shell.execute_reply":"2022-03-18T21:38:29.070011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm --no-index --find-links=file:../input/petfinderpawpularitypackages/timm\n!pip install albumentations --no-index --find-links=../input/petfinderpawpularitypackages/albumentations","metadata":{"execution":{"iopub.status.busy":"2022-03-18T21:38:29.072032Z","iopub.execute_input":"2022-03-18T21:38:29.072408Z","iopub.status.idle":"2022-03-18T21:38:44.185249Z","shell.execute_reply.started":"2022-03-18T21:38:29.072307Z","shell.execute_reply":"2022-03-18T21:38:44.184439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run only to download dataset\n\n# !rm -rf /content/drive/MyDrive/Kaggle\\ Datasets/petfinder-pawpularity-score\n# %cd /content\n# !mkdir -p ~/.kaggle/ && cp /content/drive/MyDrive/Kaggle/kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n# !mkdir -p /content/drive/MyDrive/Kaggle\\ Datasets/petfinder-pawpularity-score\n# %cd /content/drive/MyDrive/Kaggle Datasets/petfinder-pawpularity-score\n# !kaggle competitions download -c petfinder-pawpularity-score\n# !unzip petfinder-pawpularity-score.zip\n# !rm petfinder-pawpularity-score.zip\n# %cd /content","metadata":{"id":"ZGQLtZc4GLli","execution":{"iopub.status.busy":"2022-03-18T21:38:44.186992Z","iopub.execute_input":"2022-03-18T21:38:44.187287Z","iopub.status.idle":"2022-03-18T21:38:44.191444Z","shell.execute_reply.started":"2022-03-18T21:38:44.187249Z","shell.execute_reply":"2022-03-18T21:38:44.190742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nBASE_DIR = \"/kaggle/input/petfinder-pawpularity-score/\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2022-03-18T21:38:44.194097Z","iopub.execute_input":"2022-03-18T21:38:44.194357Z","iopub.status.idle":"2022-03-18T21:38:44.202042Z","shell.execute_reply.started":"2022-03-18T21:38:44.194323Z","shell.execute_reply":"2022-03-18T21:38:44.201297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(f'{BASE_DIR}train.csv')\ntrain_df.head() ","metadata":{"id":"fTZK6oOrKOlL","outputId":"37e15f39-f30c-4f7c-dcde-2fa549d3578c","execution":{"iopub.status.busy":"2022-03-18T21:38:44.2034Z","iopub.execute_input":"2022-03-18T21:38:44.204087Z","iopub.status.idle":"2022-03-18T21:38:44.238631Z","shell.execute_reply.started":"2022-03-18T21:38:44.204051Z","shell.execute_reply":"2022-03-18T21:38:44.237904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(f'{BASE_DIR}test.csv')\n# test_df.head()","metadata":{"id":"Ymuy21_o4fh3","outputId":"f1f7077b-63e6-4ba5-926a-59a259277c23","execution":{"iopub.status.busy":"2022-03-18T21:38:44.239906Z","iopub.execute_input":"2022-03-18T21:38:44.240149Z","iopub.status.idle":"2022-03-18T21:38:44.257155Z","shell.execute_reply.started":"2022-03-18T21:38:44.240118Z","shell.execute_reply":"2022-03-18T21:38:44.256507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 96\nBATCH_SIZE = 32\nEPOCHS= 10\nDROPOUT = 0.3","metadata":{"id":"GVSAuGI1kWyP","execution":{"iopub.status.busy":"2022-03-18T21:38:44.258446Z","iopub.execute_input":"2022-03-18T21:38:44.258747Z","iopub.status.idle":"2022-03-18T21:38:44.262899Z","shell.execute_reply.started":"2022-03-18T21:38:44.258711Z","shell.execute_reply":"2022-03-18T21:38:44.261881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations\n\ntrain_aug = albumentations.Compose(\n    [\n        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n        albumentations.HueSaturationValue(\n            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n        ),\n        albumentations.RandomBrightnessContrast(\n            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n        ),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ]\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ]\n)","metadata":{"id":"cgiBDDoFkPmn","execution":{"iopub.status.busy":"2022-03-18T21:38:44.264117Z","iopub.execute_input":"2022-03-18T21:38:44.264818Z","iopub.status.idle":"2022-03-18T21:38:44.274133Z","shell.execute_reply.started":"2022-03-18T21:38:44.264782Z","shell.execute_reply":"2022-03-18T21:38:44.273372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.io import read_image\nfrom skimage import io, transform\nimport os\nfrom PIL import Image\nimport cv2\nimport numpy as np\n\nclass PetDataset(Dataset):    \n    def __init__(self, annotations_path, csv_name, transforms=None, nrows=len(train_df)):\n        self.annotations_path = annotations_path\n        self.csv_name = csv_name\n\n        self.transforms = transforms\n        self.img_labels = pd.read_csv(f'{annotations_path}/{csv_name}.csv', nrows= nrows)\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        row = self.img_labels.iloc[idx]\n        img_path = os.path.join(self.annotations_path, f'{self.csv_name}/{row[\"Id\"]}.jpg')\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transforms is not None:\n            transforms = self.transforms(image=image)\n            image = transforms[\"image\"]\n\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n\n        image = torch.tensor(image, dtype=torch.float)\n        if self.csv_name != \"test\":\n            target = torch.tensor(row[\"Pawpularity\"], dtype=torch.float)\n            return (image, target)\n        else:\n            return image\n    \ntrain_dataset = PetDataset(BASE_DIR, \"train\", train_aug)\ntrain_dl = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n","metadata":{"id":"WHoP7dhfRmXf","execution":{"iopub.status.busy":"2022-03-18T21:38:44.275454Z","iopub.execute_input":"2022-03-18T21:38:44.27585Z","iopub.status.idle":"2022-03-18T21:38:44.30425Z","shell.execute_reply.started":"2022-03-18T21:38:44.275816Z","shell.execute_reply":"2022-03-18T21:38:44.303632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for (img, target) in train_dl:\n#     print(img.shape, target.shape)\n#     break\n\n# for (img) in test_dl:\n#     print(img.shape)\n#     break","metadata":{"id":"AahJ8G-EeLtf","outputId":"1faf71d8-2fde-4c8a-c0c8-2c6aa6e5a903","execution":{"iopub.status.busy":"2022-03-18T21:38:44.305337Z","iopub.execute_input":"2022-03-18T21:38:44.305588Z","iopub.status.idle":"2022-03-18T21:38:44.309419Z","shell.execute_reply.started":"2022-03-18T21:38:44.30553Z","shell.execute_reply":"2022-03-18T21:38:44.30855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # img, target = next(iter(train_dl))\n# # img, target\n# import matplotlib.pyplot as plt\n\n# (train_features, train_labels) = next(iter(train_dl))\n# print(f\"Feature batch shape: {train_features.size()}\")\n# print(f\"Labels batch shape: {train_labels.size()}\")\n# img_source = train_features[0]\n# # img_source = img_source.reshape(3, 96, 96)\n\n# print(img_source.shape)\n# plt.imshow(img_source.permute(1, 2, 0)  )\n","metadata":{"id":"0adli3fBUxuU","outputId":"b808522d-964c-4ac7-860c-13f8e1bf5164","execution":{"iopub.status.busy":"2022-03-18T21:38:44.310478Z","iopub.execute_input":"2022-03-18T21:38:44.311324Z","iopub.status.idle":"2022-03-18T21:38:44.318891Z","shell.execute_reply.started":"2022-03-18T21:38:44.31129Z","shell.execute_reply":"2022-03-18T21:38:44.317944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nclass Model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n\n        self.model = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained=False, in_chans=3)\n        self.model.load_state_dict(torch.load(\"../input/timm-pretrained-efficientnet/efficientnet/tf_efficientnet_b0_ns-c0e6a31c.pth\", map_location=device))\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 64)\n        self.dropout = nn.Dropout(DROPOUT)\n        self.dense = nn.Linear(64, 1)\n\n    def forward(self, image, targets=None):\n        x = self.model(image)\n        x = self.dropout(x)\n        x = self.dense(x)\n\n        return x, targets","metadata":{"id":"1kpcZxsBez2G","execution":{"iopub.status.busy":"2022-03-18T21:38:44.321449Z","iopub.execute_input":"2022-03-18T21:38:44.322207Z","iopub.status.idle":"2022-03-18T21:38:44.329869Z","shell.execute_reply.started":"2022-03-18T21:38:44.322171Z","shell.execute_reply":"2022-03-18T21:38:44.329068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model()\nmodel = model.to(device)\n# model","metadata":{"id":"68gtvxGjVL1h","outputId":"96926f8e-db4e-47d1-f68e-1179c2601385","execution":{"iopub.status.busy":"2022-03-18T21:38:44.334083Z","iopub.execute_input":"2022-03-18T21:38:44.334279Z","iopub.status.idle":"2022-03-18T21:38:44.522558Z","shell.execute_reply.started":"2022-03-18T21:38:44.334257Z","shell.execute_reply":"2022-03-18T21:38:44.521837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nimport torch.optim as optim\nfrom torchvision.transforms import transforms\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport math\nimport time\nfrom sklearn.metrics import r2_score\nfrom termcolor import cprint\nimport warnings\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)\n\n# validation_size= 0.2\n# train_dataset = PetDataset(BASE_DIR, \"train\", train_aug, nrows=BATCH_SIZE)\n# print(len(train_dataset))\n# num_train = len(train_dataset)\n# indices = list(range(num_train))\n# split = int(np.floor(validation_size * num_train))\n# np.random.shuffle(indices)\n\n# train_idx, valid_idx = indices[split:], indices[:split]\n# train_sampler = SubsetRandomSampler(train_idx)\n# valid_sampler = SubsetRandomSampler(valid_idx)\n\n# train_dl = DataLoader(train_dataset, shuffle=False, batch_size = BATCH_SIZE, sampler=train_sampler)\n# val_dl = DataLoader(train_dataset, shuffle=False, batch_size = BATCH_SIZE, sampler=valid_sampler)\n\n# EPOCHS = 1\ncriterion = nn.MSELoss()\noptm = optim.Adam(model.parameters(), lr = 1e-4)\n\ntrain_step_loss, val_step_loss = [], []\ntrain_loss, val_loss = [], []\nval_best_loss = np.inf\n\nfor epoch in range(EPOCHS):\n    start_time = time.time()\n    print(f\"Epoch {epoch + 1} : \")\n    epoch_loss = 0.0\n    model.train()\n    for (img, target) in train_dl:\n        optm.zero_grad()\n        img = img.float().to(device)\n        target = target.float().to(device)\n        output, _ = model(img)\n        loss = criterion(output, target)\n        epoch_loss += loss.item()\n        train_step_loss.append(loss.item())\n#         print(f\"Loss: {'%.4f'%(loss.item())}\")\n        loss.backward()\n        optm.step()\n\n# train_loss.append(epoch_loss)\n# model.eval()\n# val_ep_loss = 0.0\n# with torch.no_grad():\n#     for (img, target) in val_dl:\n#         img = img.float().to(device)\n#         target = target.float().to(device)\n#         output, _ = model(img, target)\n#         loss = criterion(output, target)\n#         val_step_loss.append(loss.item())\n#         val_ep_loss += loss.item()\n\n\n# print(f\"validation data --> loss : {'%.4f'%(val_ep_loss)}\")\n# val_loss.append(val_ep_loss)\n ","metadata":{"id":"KxWkR0_LXLao","outputId":"20f9b0ff-f5a4-4311-cfd5-1beb6beff056","execution":{"iopub.status.busy":"2022-03-18T21:38:44.525848Z","iopub.execute_input":"2022-03-18T21:38:44.526043Z","iopub.status.idle":"2022-03-18T21:40:53.404456Z","shell.execute_reply.started":"2022-03-18T21:38:44.526019Z","shell.execute_reply":"2022-03-18T21:40:53.403728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test dataset\ntest_dataset = PetDataset(BASE_DIR, \"test\", valid_aug)\ntest_dl = DataLoader(test_dataset, shuffle=False, batch_size=1)\n\nmodel.eval()\npreds = []\n\nwith torch.no_grad():\n    for (idx, img) in enumerate(test_dl):\n        img = img.float().to(device)\n        output, _ = model(img)\n        preds.extend(output.ravel().tolist())\n","metadata":{"id":"Bh3PkoFKKvni","execution":{"iopub.status.busy":"2022-03-18T21:40:53.406016Z","iopub.execute_input":"2022-03-18T21:40:53.406274Z","iopub.status.idle":"2022-03-18T21:40:53.558888Z","shell.execute_reply.started":"2022-03-18T21:40:53.406241Z","shell.execute_reply":"2022-03-18T21:40:53.558187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(f'{BASE_DIR}test.csv')\ntest_df['Pawpularity'] = preds\ntest_df  = test_df[[\"Id\", \"Pawpularity\"]]\ntest_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T21:40:53.560226Z","iopub.execute_input":"2022-03-18T21:40:53.560471Z","iopub.status.idle":"2022-03-18T21:40:53.577428Z","shell.execute_reply.started":"2022-03-18T21:40:53.560439Z","shell.execute_reply":"2022-03-18T21:40:53.576744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df","metadata":{"id":"LpRii-4FhLtP","execution":{"iopub.status.busy":"2022-03-18T21:42:36.250826Z","iopub.execute_input":"2022-03-18T21:42:36.251106Z","iopub.status.idle":"2022-03-18T21:42:36.261277Z","shell.execute_reply.started":"2022-03-18T21:42:36.251077Z","shell.execute_reply":"2022-03-18T21:42:36.260472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.read_csv(\"submission.csv\")","metadata":{"id":"7tMw2bOUjIgc","execution":{"iopub.status.busy":"2022-03-18T21:40:53.578825Z","iopub.execute_input":"2022-03-18T21:40:53.579083Z","iopub.status.idle":"2022-03-18T21:40:53.582845Z","shell.execute_reply.started":"2022-03-18T21:40:53.579048Z","shell.execute_reply":"2022-03-18T21:40:53.582075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}