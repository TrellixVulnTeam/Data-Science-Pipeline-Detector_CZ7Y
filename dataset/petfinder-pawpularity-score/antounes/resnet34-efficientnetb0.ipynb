{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transfer Learning for Image Regression - EfficientNet","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nimport csv\nimport os\nfrom fastai.vision.all import *\n\nconfig = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=2, \n                                  inter_op_parallelism_threads=2, \n                                  allow_soft_placement=True) # TensorFlow config\npd.options.mode.chained_assignment = None # Pandas config","metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:25:38.669688Z","iopub.execute_input":"2022-01-01T20:25:38.670019Z","iopub.status.idle":"2022-01-01T20:25:45.093817Z","shell.execute_reply.started":"2022-01-01T20:25:38.669927Z","shell.execute_reply":"2022-01-01T20:25:45.093081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 224, 224, 3 # Input dimensions for EfficientNet\nBATCH_SIZE = 128\n\ndef read_and_decode(filename, reshape_dims):\n    # Read an image file to a tensor as a sequence of bytes\n    image = tf.io.read_file(filename)\n    # Convert the tensor to a 3D uint8 tensor\n    image = tf.image.decode_jpeg(image, channels=IMG_CHANNELS)\n    # Convert 3D uint8 tensor with values in [0, 1]\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    # Resize the image to the desired size\n    return tf.image.resize(image, reshape_dims)\n    \ndef decode_csv(csv_row):\n    record_defaults = ['Id', 'Pawpularity']\n    filename, pawpularity = tf.io.decode_csv(csv_row, record_defaults)\n    pawpularity = tf.convert_to_tensor(np.float(pawpularity), dtype=tf.float32)\n    image = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n    return image, pawpularity\n\ndef show_image(filename):\n    image = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n    plt.imshow(image);\n    plt.axis('off');\n\ndef training_plot(metrics, history):\n    f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n    for idx, metric in enumerate(metrics):\n        ax[idx].plot(history.history[metric], ls='dashed')\n        ax[idx].set_xlabel('Epochs')\n        ax[idx].set_ylabel(metric)\n        ax[idx].plot(history.history['val_'+metric]);\n        ax[idx].legend(['train_'+metric, 'val_'+metric])\n","metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:25:45.095821Z","iopub.execute_input":"2022-01-01T20:25:45.096087Z","iopub.status.idle":"2022-01-01T20:25:45.106525Z","shell.execute_reply.started":"2022-01-01T20:25:45.096051Z","shell.execute_reply":"2022-01-01T20:25:45.105805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get the data","metadata":{}},{"cell_type":"code","source":"path = \"../input/petfinder-pawpularity-score/\"\n\ndata = pd.read_csv(path+\"/train.csv\") # Dataset for images\ndata['Id'] = data['Id'].apply(lambda x: path+'train/'+x+'.jpg')\nx, y = data.drop([\"Id\", \"Pawpularity\"], axis=1), data[\"Pawpularity\"]","metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:25:45.107771Z","iopub.execute_input":"2022-01-01T20:25:45.109224Z","iopub.status.idle":"2022-01-01T20:25:45.160168Z","shell.execute_reply.started":"2022-01-01T20:25:45.109195Z","shell.execute_reply":"2022-01-01T20:25:45.159561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preliminary pet classification","metadata":{}},{"cell_type":"code","source":"# Load a train a ResNet34 model for distinguishing between cats and dogs\n# Following work will be carried out for each type of pet\n\n#resnet_path = untar_data(URLs.PETS)/'images'\n\n#def is_cat(x): return x[0].isupper()\n\n#dls = ImageDataLoaders.from_name_func(\n#    path, get_image_files(resnet_path), valid_pct=0.2, seed=42, label_func=is_cat, item_tfms=Resize(224))\n\n#learn = cnn_learner(dls, resnet34, metrics=error_rate)\n#learn.fine_tune(1)\n\n# Export fine-tuned Resnet 34\n#torch.save(learn, '/kaggle/working/resnet34.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:25:45.161393Z","iopub.execute_input":"2022-01-01T20:25:45.161634Z","iopub.status.idle":"2022-01-01T20:25:45.166016Z","shell.execute_reply.started":"2022-01-01T20:25:45.161601Z","shell.execute_reply":"2022-01-01T20:25:45.165329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_cat(x): return x[0].isupper()\nlearner = torch.load('../input/resnet34trainedcatsimages/resnet34.pkl')\ndata['Is cat']= data['Id'].apply(lambda x: eval(learner.predict(x)[0]))\n\n#cats = data.loc[data['Is cat']==True]\n#dogs = data.loc[data['Is cat']==False]","metadata":{"execution":{"iopub.status.busy":"2022-01-01T20:26:34.340302Z","iopub.execute_input":"2022-01-01T20:26:34.341039Z","iopub.status.idle":"2022-01-01T20:26:46.222306Z","shell.execute_reply.started":"2022-01-01T20:26:34.341Z","shell.execute_reply":"2022-01-01T20:26:46.22081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pawpularity distribution by pet type\n\ncats['Pawpularity'].hist(label='Cats', alpha=0.3)\ndogs['Pawpularity'].hist(label='Dogs', alpha=0.3)\nplt.title('Pawpularity score distribution by pet type')\nplt.xlabel('Pawpularity score')\nplt.ylabel('Count')\nplt.legend(loc='upper right')\nplt.grid(False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A trial with only cats\n\nx, y = cats[cats['Pawpularity']<99].drop([\"Id\", \"Pawpularity\"], axis=1), cats[cats['Pawpularity']<99][\"Pawpularity\"]\n\n# Create training, validation and test sets for tabular and image data\n# First: test set is created by keeping apart 20% of the dataset\n# Second: validation set is created by keeping apart 20% of the remaining dataset\n# Third: Training set consists of the remaining samples after test and validation set creation\n\nsssplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2) # Use stratified sampling\nfor train_index, val_index in sssplit.split(x, y):\n    train_img_tmp = cats[cats['Pawpularity']<99].iloc[train_index]\n    val_img = cats.iloc[val_index][['Id', 'Pawpularity']]\n    \nsssplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\nfor train_index, test_index in sssplit.split(train_img_tmp, train_img_tmp['Pawpularity']):\n    train_img = train_img_tmp.iloc[train_index][['Id', 'Pawpularity']]\n    test_img = train_img_tmp.iloc[test_index][['Id', 'Pawpularity']]\n    \n    \n# Export image sets for futher loading and processing\ntrain_img.to_csv('/kaggle/working/training_img.csv', header=False, index=False)\nval_img.to_csv('/kaggle/working/val_img.csv', header=False, index=False)\ntest_img.to_csv('/kaggle/working/test_img.csv', header=False, index=False)\n\ntrain_dataset = tf.data.TextLineDataset(\n    '/kaggle/working/training_img.csv').map(decode_csv).batch(BATCH_SIZE)\n\nval_dataset = tf.data.TextLineDataset(\n    '/kaggle/working/val_img.csv').map(decode_csv).batch(BATCH_SIZE)\n\ntest_dataset = tf.data.TextLineDataset(\n    '/kaggle/working/test_img.csv').map(decode_csv).batch(BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build and train EfficientNet model for transfer learning","metadata":{}},{"cell_type":"code","source":"# Keeping EfficientNet architecture and retraining top layers for our purpose only\n\nimg_augmentation = tf.keras.models.Sequential([\n    tf.keras.layers.RandomRotation(0.2),\n    tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n    tf.keras.layers.RandomContrast(0.1),\n    tf.keras.layers.RandomZoom(0.2)\n])\n\ninputs = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\nx = img_augmentation(inputs)\nmodel = tf.keras.applications.EfficientNetB7(\n    include_top=False, input_tensor=inputs,\n    weights='../input/efficientnet-pretrain-weights/noisystudent/noisy.student.notop-b7.h5') # Use imagenet pre-trained weights\n\n# freeze pre-trained noisy student weights\nmodel.trainable = False\n\n# rebuild top layer for regression\n# 1 unit dense layer with no activation function\nx = tf.keras.layers.GlobalAveragePooling2D()(model.output)\nx = tf.keras.layers.BatchNormalization()(x)\noutputs = tf.keras.layers.Dense(1, activation=None)(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.summary())\ntf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile model\n\nmodel = tf.keras.models.Model(inputs, outputs, name='EfficientNet')\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n              loss=tf.keras.losses.MeanSquaredError(),\n              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\n# Train model\nhistory = model.fit(train_dataset, epochs=5, validation_data=val_dataset, batch_size=BATCH_SIZE)\n\n# Plot results\ntraining_plot(['loss', 'root_mean_squared_error'], history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compute predictions and build submission process","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\nsample_submission['Id'] = sample_submission['Id'].apply(lambda x: '../input/petfinder-pawpularity-score/test/'+x+'.jpg')\nsample_submission.to_csv('/kaggle/working/sample_submission.csv', index=False, header=False)\nsample_submission = tf.data.TextLineDataset(\n    './sample_submission.csv'\n).map(decode_csv).batch(BATCH_SIZE)\n\n# Make predictions with our model\nsample_prediction = model.predict(sample_submission)\n\n# Format predictions to output for submission\nsubmission_output = pd.concat(\n    [pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv').drop('Pawpularity', axis=1),\n    pd.DataFrame(sample_prediction)],\n    axis=1\n)\nsubmission_output.columns = [['Id', 'Pawpularity']]\n\n# Output submission file to csv\nsubmission_output.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}