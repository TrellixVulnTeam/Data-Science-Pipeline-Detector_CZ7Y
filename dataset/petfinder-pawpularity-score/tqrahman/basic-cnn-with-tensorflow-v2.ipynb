{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Creating a Baseline Tensorflow Model to Predict Pet Popularity","metadata":{}},{"cell_type":"markdown","source":"V2 Updates:\n* made CNN deeper\n* tweaked parameters\n* added some image augmentation to the model\n* added some documentation","metadata":{}},{"cell_type":"markdown","source":"Sources:\n* https://www.kaggle.com/ekaterinadranitsyna/pretrained-feature-model-keras \n    * used it to load data and convert it to TF Datasets\n* removed the Transfer Learning part for simplicity\n* converted Sequential API -> Functional API","metadata":{}},{"cell_type":"code","source":"# Imports\n\nimport os\nfrom tqdm.notebook import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-19T21:33:56.284801Z","iopub.execute_input":"2021-10-19T21:33:56.285121Z","iopub.status.idle":"2021-10-19T21:34:01.420342Z","shell.execute_reply.started":"2021-10-19T21:33:56.285088Z","shell.execute_reply":"2021-10-19T21:34:01.419581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the path\n\nPATH = \"../input/petfinder-pawpularity-score/\"","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:01.422118Z","iopub.execute_input":"2021-10-19T21:34:01.422367Z","iopub.status.idle":"2021-10-19T21:34:01.42649Z","shell.execute_reply.started":"2021-10-19T21:34:01.422334Z","shell.execute_reply":"2021-10-19T21:34:01.42557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading in data\n\ntrain = pd.read_csv(\"\".join([PATH,\"train.csv\"]))\ntest = pd.read_csv(\"\".join([PATH,\"test.csv\"]))\nsubmission = pd.read_csv(\"\".join([PATH,\"sample_submission.csv\"]))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:01.428126Z","iopub.execute_input":"2021-10-19T21:34:01.428688Z","iopub.status.idle":"2021-10-19T21:34:01.489545Z","shell.execute_reply.started":"2021-10-19T21:34:01.428649Z","shell.execute_reply":"2021-10-19T21:34:01.488775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the first few rows\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:01.49276Z","iopub.execute_input":"2021-10-19T21:34:01.493599Z","iopub.status.idle":"2021-10-19T21:34:01.519405Z","shell.execute_reply.started":"2021-10-19T21:34:01.49356Z","shell.execute_reply":"2021-10-19T21:34:01.518643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the shape\n\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:01.52083Z","iopub.execute_input":"2021-10-19T21:34:01.52116Z","iopub.status.idle":"2021-10-19T21:34:01.52658Z","shell.execute_reply.started":"2021-10-19T21:34:01.521125Z","shell.execute_reply":"2021-10-19T21:34:01.525768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the info of the data\n\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:01.528199Z","iopub.execute_input":"2021-10-19T21:34:01.528823Z","iopub.status.idle":"2021-10-19T21:34:01.550098Z","shell.execute_reply.started":"2021-10-19T21:34:01.528787Z","shell.execute_reply":"2021-10-19T21:34:01.549212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the file path of each image\n\ntrain[\"path\"] = train[\"Id\"].apply(lambda x: \"../input/petfinder-pawpularity-score/train/\" + x + \".jpg\")\ntest[\"path\"] = test[\"Id\"].apply(lambda x: \"../input/petfinder-pawpularity-score/test/\" + x + \".jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:01.551406Z","iopub.execute_input":"2021-10-19T21:34:01.552201Z","iopub.status.idle":"2021-10-19T21:34:01.565433Z","shell.execute_reply.started":"2021-10-19T21:34:01.55216Z","shell.execute_reply":"2021-10-19T21:34:01.564754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Functions reading and converting data into Tensorflow datasets\n# source: https://www.kaggle.com/ekaterinadranitsyna/pretrained-feature-model-kera\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 64\nIMG_SIZE = 224\ntarget = 'Pawpularity'\nseed = 0\n\ndef set_seed(seed=seed):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef id_to_path(img_id: str, dir: str):\n    \"\"\"Function returns a path to an image file.\n    :param img_id: Image Id\n    :param dir: Path to the directory with images\n    :return: Image file path\n    \"\"\"\n    return os.path.join(dir, f'{img_id}.jpg')\n\n\n@tf.function\ndef get_image(path: str) -> tf.Tensor:\n    \"\"\"Function loads image from a file and preprocesses it.\n    :param path: Path to image file\n    :return: Tensor with preprocessed image\n    \"\"\"\n    print(f\"IMAGE PROCESSING {str}\")\n    ## Decoding the image\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n\n    ## Resizing image\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.int32)\n\n    return image\n\n\n@tf.function\ndef process_dataset(path: str, label: int) -> tuple:\n    \"\"\"Function returns preprocessed image and label.\n    :param path: Path to image file\n    :param label: Class label\n    :return: tf.Tensor with preprocessed image, numeric label\n    \"\"\"\n    return get_image(path), label\n\n\n@tf.function\ndef get_dataset(x, y=None) -> tf.data.Dataset:\n    \"\"\"Function creates batched optimized dataset for the model\n    out of an array of file paths and (optionally) class labels.\n    :param x: Input data for the model (array of file paths)\n    :param y: Target values for the model (array of class indexes)\n    :return TensorFlow Dataset object\n    \"\"\"\n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        return ds.map(process_dataset, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses and metrics\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    rmse = hist.history['root_mean_squared_error']\n    val_rmse = hist.history['val_root_mean_squared_error']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(loss) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n\n    ax1.plot(x_axis, loss, 'bo', label='Training')\n    ax1.plot(x_axis, val_loss, 'ro', label='Validation', alpha=0.3)\n    ax1.set_title('MSE Loss')\n    ax1.legend()\n\n    ax2.plot(x_axis, rmse, 'bo', label='Training')\n    ax2.plot(x_axis, val_rmse, 'ro', label='Validation', alpha=0.3)\n    ax2.set_title('Root Mean Squared Error')\n    ax2.set_xlabel('Epochs')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:01.567779Z","iopub.execute_input":"2021-10-19T21:34:01.568065Z","iopub.status.idle":"2021-10-19T21:34:01.588165Z","shell.execute_reply.started":"2021-10-19T21:34:01.568031Z","shell.execute_reply":"2021-10-19T21:34:01.587228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting train into train and validation sets\n\ntrain_subset, valid_subset = train_test_split(\n    train[['path', target]],\n    test_size=.2, shuffle=True, random_state=0\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:01.589252Z","iopub.execute_input":"2021-10-19T21:34:01.589973Z","iopub.status.idle":"2021-10-19T21:34:01.607346Z","shell.execute_reply.started":"2021-10-19T21:34:01.589937Z","shell.execute_reply":"2021-10-19T21:34:01.606578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating TensorFlow datasets\n\ntrain_ds = get_dataset(x=train_subset['path'], y=train_subset[target])\nvalid_ds = get_dataset(x=valid_subset['path'], y=valid_subset[target])\ntest_ds = get_dataset(x=test['path'])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:01.61041Z","iopub.execute_input":"2021-10-19T21:34:01.610771Z","iopub.status.idle":"2021-10-19T21:34:03.720435Z","shell.execute_reply.started":"2021-10-19T21:34:01.610739Z","shell.execute_reply":"2021-10-19T21:34:03.719718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the model\n\ndef get_model():\n    \n    ## Setting the Inputs\n    inputs = keras.Input(shape=(224, 224, 3))\n    x = inputs\n    \n    ## Preprocessing Layers\n    \n    ### Rescaling\n    x = keras.layers.experimental.preprocessing.Rescaling(1./255)(x)\n    \n    ## Data Augmentation\n    x = keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\")(x)\n    x = keras.layers.experimental.preprocessing.RandomRotation(0.2)(x)\n    x = keras.layers.experimental.preprocessing.RandomTranslation(0.2,0.2)(x)\n    \n    ## Convolutional Layers\n    \n    ### First CNN layer\n    x = keras.layers.Conv2D(filters=96, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.MaxPool2D(2)(x)\n\n    ### Second CNN layer\n    x = keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.MaxPool2D(2)(x)\n    \n    ### Third CNN layer\n    x = keras.layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.MaxPool2D(2)(x)\n\n    ## Flattening the layer\n    x = keras.layers.Flatten()(x)\n    \n    ## Fully Connected (Dense) Layers\n    \n    ### First Fully Connected layer w/ Dropout\n    x = keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.Dropout(0.2)(x)\n    \n    ## Output layer\n    output = keras.layers.Dense(1)(x)\n\n    ## Returning the model\n    return keras.Model(inputs=inputs, outputs=output)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:50:36.213496Z","iopub.execute_input":"2021-10-19T21:50:36.213861Z","iopub.status.idle":"2021-10-19T21:50:36.230173Z","shell.execute_reply.started":"2021-10-19T21:50:36.213825Z","shell.execute_reply":"2021-10-19T21:50:36.2278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\n\ndef compile_and_fit(model):\n    \n    # Creating an exponential decay for learning rate\n\n    LEARNING_RATE = 1e-2\n    DECAY_STEPS = 100\n    DECAY_RATE = 0.99\n\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=LEARNING_RATE,\n        decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n        staircase=True\n    )\n    \n    # Creating an early stopper\n\n    early_stop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss', patience=5, restore_best_weights=True\n    )\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n        loss=tf.keras.losses.MeanSquaredError(),\n        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n    )\n    \n    history = model.fit(\n        train_ds, \n        validation_data=valid_ds,\n        epochs=50,\n        use_multiprocessing=True, workers=-1,\n        callbacks=[early_stop]\n    )\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:03.757317Z","iopub.execute_input":"2021-10-19T21:34:03.757901Z","iopub.status.idle":"2021-10-19T21:34:03.766333Z","shell.execute_reply.started":"2021-10-19T21:34:03.757864Z","shell.execute_reply":"2021-10-19T21:34:03.765546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Applying K-Fold\n\n# from sklearn.model_selection import KFold\n# from sklearn.metrics import mean_squared_error\n\n# kf = KFold(5)\n\n# scores = []\n\n# for train_index, valid_index in kf.split(train_subset):\n#     print(\"TRAIN:\", train_index, \"TEST:\", valid_index)\n    \n#     X_train, X_valid = train_subset.iloc[train_index], train_subset.iloc[valid_index]\n    \n#     train_ds = get_dataset(x=X_train['path'], y=X_train[target])\n#     valid_ds = get_dataset(x=X_valid['path'], y=X_valid[target])\n    \n#     model = get_model()\n    \n#     model, history = compile_and_fit(model)\n    \n#     predictions = model.predict(valid_ds, use_multiprocessing=True, workers=os.cpu_count())\n    \n#     rmse = mean_squared_error(X_valid[target], predictions, squared=False)\n#     print(rmse)\n    \n#     scores.append(rmse)\n\n# # Printing the results of K-Fold\n\n# print(f\"Mean: {np.mean(scores)}, Std: {np.std(scores)}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:34:03.767303Z","iopub.execute_input":"2021-10-19T21:34:03.769623Z","iopub.status.idle":"2021-10-19T21:34:03.776897Z","shell.execute_reply.started":"2021-10-19T21:34:03.769585Z","shell.execute_reply":"2021-10-19T21:34:03.776055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the model\n\nkeras.backend.clear_session()\n\nmodel = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:50:42.127714Z","iopub.execute_input":"2021-10-19T21:50:42.128177Z","iopub.status.idle":"2021-10-19T21:50:42.328146Z","shell.execute_reply.started":"2021-10-19T21:50:42.12814Z","shell.execute_reply":"2021-10-19T21:50:42.327447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\n\nmodel, history = compile_and_fit(model)\n# predictions = model.predict(valid_ds, use_multiprocessing=True, workers=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2021-10-19T21:50:45.514677Z","iopub.execute_input":"2021-10-19T21:50:45.515533Z","iopub.status.idle":"2021-10-19T22:02:26.23642Z","shell.execute_reply.started":"2021-10-19T21:50:45.515484Z","shell.execute_reply":"2021-10-19T22:02:26.235716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting accuracy and loss of model\n\nplot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T22:02:50.668112Z","iopub.execute_input":"2021-10-19T22:02:50.66838Z","iopub.status.idle":"2021-10-19T22:02:51.082232Z","shell.execute_reply.started":"2021-10-19T22:02:50.668353Z","shell.execute_reply":"2021-10-19T22:02:51.081566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# Using the model to predict on the test data\n\ntest[target] = model.predict(\n    test_ds, use_multiprocessing=True, workers=os.cpu_count()\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T22:54:28.058555Z","iopub.status.idle":"2021-10-18T22:54:28.059301Z","shell.execute_reply.started":"2021-10-18T22:54:28.059028Z","shell.execute_reply":"2021-10-18T22:54:28.059052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the submission file\n\ntest[['Id', target]].to_csv('submission.csv', index=False)\ntest[['Id', target]].head()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T22:54:28.060616Z","iopub.status.idle":"2021-10-18T22:54:28.061393Z","shell.execute_reply.started":"2021-10-18T22:54:28.061112Z","shell.execute_reply":"2021-10-18T22:54:28.061139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To-Do's\n* save model\n* remove Duplicate images\n* augment the data more\n* add Transfer Learning\n* add meta data","metadata":{}}]}