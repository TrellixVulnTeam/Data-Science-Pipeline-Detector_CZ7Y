{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#### 安装依赖环境包\n!pip install python-box timm pytorch-lightning==1.4.0 grad-cam ttach","metadata":{"execution":{"iopub.status.busy":"2021-10-26T08:11:42.515936Z","iopub.execute_input":"2021-10-26T08:11:42.516655Z","iopub.status.idle":"2021-10-26T08:12:10.768965Z","shell.execute_reply.started":"2021-10-26T08:11:42.516545Z","shell.execute_reply":"2021-10-26T08:12:10.76775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### 基于Regression NN Head的多模态特征融合\n\n\n#### 基于RAPIDS SVR Head的多模态特征融合\n\n#### 对两种方法进行结果融合\n\n#### 基于XGBOOST的多模态融合方案\n\n#### 基于backbone的融合发方案\n\n### mixup\n#########################################################################\n#########################################################################\nimport torch\nimport numpy as np\n\n### 融合两张图片\ndef mixup_data(x, y, alpha=1.0, use_cuda=True):\n\n    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0.:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1.\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index,:]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n### mixup损失\ndef mixup_criterion(y_a, y_b, lam):\n    return lambda criterion, pred: lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n\n##具体使用\n############################################################\n### your data and target\ndata, target = data.to(self.device), target.to(self.device)\n\n\ndata, target_a, target_b, lam = mixup_data(data, target, 0.4, True)\n\nloss1 = self.loss_func(outputs, target_a)\nloss2 = self.loss_func(outputs, target_b)\nloss = lam * loss1 + (1 - lam) * loss2\n###########################################################\n\n#########################################################################\n#########################################################################\n\n### cutmix\n#########################################################################\n#########################################################################\n\nimport numpy as np\n\n\ndef rand_bbox(size, lam):\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.int(W * cut_rat)\n    cut_h = np.int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\nlam = np.random.beta(1.0, 1.0)\nrand_index = torch.randperm(data.size()[0]).to(self.device)\ntarget_a = target\ntarget_b = target[rand_index]\nbbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\ndata[:, :, bbx1:bbx2, bby1:bby2] = data[rand_index, :, bbx1:bbx2, bby1:bby2]\n# adjust lambda to exactly match pixel ratio\nlam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n# compute output\ndata = torch.autograd.Variable(data, requires_grad=True)\ntarget_a_var = torch.autograd.Variable(target_a)\ntarget_b_var = torch.autograd.Variable(target_b)\n\nloss1 = self.loss_func(outputs, target_a_var)\nloss2 = self.loss_func(outputs, target_b_var)\nloss = lam * loss1 + (1 - lam) * loss2\n\n#########################################################################\n#########################################################################\n\n### AutoAug\n##具体使用可以参照我的github\nhttps://github.com/whut2962575697/image_classification/tree/master/common/autoaugment\n\n### fp16\nfrom torch.cuda.amp import autocast as autocast, GradScaler\nscaler = GradScaler()\nfor _ in range(trainer.epochs):\n    for batch in trainer.train_dl:\n        self.optim.zero_grad()\n        with autocast():\n            ###\n            # your model forward\n            #...\n            ###\n        scaler.scale(loss).backward()\n        scaler.step(self.optim)\n        scaler.update()\n\n\n### data prefetch\nfrom prefetch_generator import BackgroundGenerator\n\nclass DataLoaderX(DataLoader):\n\n    def __iter__(self):\n        return BackgroundGenerator(super().__iter__())\n## 将Pytorch 官方Dataloder换成DataLoaderX\n\n### \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### 导入所需模块\n\nimport os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom box import Box\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\nfrom pytorch_grad_cam import GradCAMPlusPlus\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule\n\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-10-26T08:15:23.767421Z","iopub.execute_input":"2021-10-26T08:15:23.767762Z","iopub.status.idle":"2021-10-26T08:15:31.516108Z","shell.execute_reply.started":"2021-10-26T08:15:23.767729Z","shell.execute_reply":"2021-10-26T08:15:31.51498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### 配置文件\n\nconfig = {'seed': 2021,\n          'root': '/kaggle/input/petfinder-pawpularity-score/', \n          'n_splits': 5,\n          'epoch': 20,\n          'trainer': {\n              'gpus': 1,\n              'accumulate_grad_batches': 1,\n              'progress_bar_refresh_rate': 1,\n              'fast_dev_run': False,\n              'num_sanity_val_steps': 0,\n              'resume_from_checkpoint': None,\n          },\n          'transform':{\n              'name': 'get_default_transforms',\n              'image_size': 224\n          },\n          'train_loader':{\n              'batch_size': 64,\n              'shuffle': True,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': True,\n          },\n          'val_loader': {\n              'batch_size': 64,\n              'shuffle': False,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': False\n         },\n          'model':{\n              'name': 'swin_tiny_patch4_window7_224',\n              'output_dim': 1\n          },\n          'optimizer':{\n              'name': 'optim.AdamW',\n              'params':{\n                  'lr': 1e-5\n              },\n          },\n          'scheduler':{\n              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n              'params':{\n                  'T_0': 20,\n                  'eta_min': 1e-4,\n              }\n          },\n          'loss': 'nn.BCEWithLogitsLoss',\n}\n\nconfig = Box(config)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-26T08:15:46.749768Z","iopub.execute_input":"2021-10-26T08:15:46.750474Z","iopub.status.idle":"2021-10-26T08:15:46.761666Z","shell.execute_reply.started":"2021-10-26T08:15:46.750437Z","shell.execute_reply":"2021-10-26T08:15:46.760438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(config)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T08:15:58.01243Z","iopub.execute_input":"2021-10-26T08:15:58.012783Z","iopub.status.idle":"2021-10-26T08:15:58.018709Z","shell.execute_reply.started":"2021-10-26T08:15:58.012744Z","shell.execute_reply":"2021-10-26T08:15:58.017699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"code","source":"class PetfinderDataset(Dataset):\n    def __init__(self, df, image_size=224):\n        self._X = df[\"Id\"].values\n        self._y = None\n        if \"Pawpularity\" in df.keys():\n            self._y = df[\"Pawpularity\"].values\n        self._transform = T.Resize([image_size, image_size])\n\n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        image_path = self._X[idx]\n        image = read_image(image_path)\n        image = self._transform(image)\n        if self._y is not None:\n            label = self._y[idx]\n            return image, label\n        return image\n\nclass PetfinderDataModule(LightningDataModule):\n    def __init__(\n        self,\n        train_df,\n        val_df,\n        cfg,\n    ):\n        super().__init__()\n        self._train_df = train_df\n        self._val_df = val_df\n        self._cfg = cfg\n\n    def __create_dataset(self, train=True):\n        return (\n            PetfinderDataset(self._train_df, self._cfg.transform.image_size)\n            if train\n            else PetfinderDataset(self._val_df, self._cfg.transform.image_size)\n        )\n\n    def train_dataloader(self):\n        dataset = self.__create_dataset(True)\n        return DataLoader(dataset, **self._cfg.train_loader)\n\n    def val_dataloader(self):\n        dataset = self.__create_dataset(False)\n        return DataLoader(dataset, **self._cfg.val_loader)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T08:16:01.018033Z","iopub.execute_input":"2021-10-26T08:16:01.018352Z","iopub.status.idle":"2021-10-26T08:16:01.030951Z","shell.execute_reply.started":"2021-10-26T08:16:01.018322Z","shell.execute_reply":"2021-10-26T08:16:01.029982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## visualize data","metadata":{}},{"cell_type":"code","source":"torch.autograd.set_detect_anomaly(True)\nseed_everything(config.seed)\n\ndf = pd.read_csv(os.path.join(config.root, \"train.csv\"))\ndf[\"Id\"] = df[\"Id\"].apply(lambda x: os.path.join(config.root, \"train\", x + \".jpg\"))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-26T08:16:05.554431Z","iopub.execute_input":"2021-10-26T08:16:05.555037Z","iopub.status.idle":"2021-10-26T08:16:05.651962Z","shell.execute_reply.started":"2021-10-26T08:16:05.554981Z","shell.execute_reply":"2021-10-26T08:16:05.651025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_dataloader = PetfinderDataModule(df, df, config).val_dataloader()\nimages, labels = iter(sample_dataloader).next()\n\nplt.figure(figsize=(12, 12))\nfor it, (image, label) in enumerate(zip(images[:16], labels[:16])):\n    plt.subplot(4, 4, it+1)\n    plt.imshow(image.permute(1, 2, 0))\n    plt.axis('off')\n    plt.title(f'Pawpularity: {int(label)}')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T08:16:09.184069Z","iopub.execute_input":"2021-10-26T08:16:09.184361Z","iopub.status.idle":"2021-10-26T08:16:13.350731Z","shell.execute_reply.started":"2021-10-26T08:16:09.184331Z","shell.execute_reply":"2021-10-26T08:16:13.349608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## augmentation","metadata":{}},{"cell_type":"code","source":"IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\ndef get_default_transforms():\n    transform = {\n        \"train\": T.Compose(\n            [\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n        \"val\": T.Compose(\n            [\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n    }\n    return transform\n","metadata":{"execution":{"iopub.status.busy":"2021-10-26T08:16:19.960737Z","iopub.execute_input":"2021-10-26T08:16:19.961091Z","iopub.status.idle":"2021-10-26T08:16:19.969261Z","shell.execute_reply.started":"2021-10-26T08:16:19.961058Z","shell.execute_reply":"2021-10-26T08:16:19.968127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n    assert alpha > 0, \"alpha should be larger than 0\"\n    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n\n    lam = np.random.beta(alpha, alpha)\n    rand_index = torch.randperm(x.size()[0])\n    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n    target_a, target_b = y, y[rand_index]\n    return mixed_x, target_a, target_b, lam\n\nclass Model(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.__build_model()\n        self._criterion = eval(self.cfg.loss)()\n        self.transform = get_default_transforms()\n        self.save_hyperparameters(cfg)\n\n    def __build_model(self):\n        self.backbone = create_model(\n            self.cfg.model.name, pretrained=True, num_classes=0, in_chans=3\n        )\n        num_features = self.backbone.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)\n        )\n\n    def forward(self, x):\n        f = self.backbone(x)\n        out = self.fc(f)\n        return out\n\n    def training_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'train')\n        return {'loss': loss, 'pred': pred, 'labels': labels}\n        \n    def validation_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'val')\n        return {'pred': pred, 'labels': labels}\n    \n    def __share_step(self, batch, mode):\n        images, labels = batch\n        labels = labels.float() / 100.0\n        images = self.transform[mode](images)\n        \n        if torch.rand(1)[0] < 0.5 and mode == 'train':\n            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n            logits = self.forward(mix_images).squeeze(1)\n            loss = self._criterion(logits, target_a) * lam + \\\n                (1 - lam) * self._criterion(logits, target_b)\n        else:\n            logits = self.forward(images).squeeze(1)\n            loss = self._criterion(logits, labels)\n        \n        pred = logits.sigmoid().detach().cpu() * 100.\n        labels = labels.detach().cpu() * 100.\n        return loss, pred, labels\n        \n    def training_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'train')\n\n    def validation_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'val')    \n        \n    def __share_epoch_end(self, outputs, mode):\n        preds = []\n        labels = []\n        for out in outputs:\n            pred, label = out['pred'], out['labels']\n            preds.append(pred)\n            labels.append(label)\n        preds = torch.cat(preds)\n        labels = torch.cat(labels)\n        metrics = torch.sqrt(((labels - preds) ** 2).mean())\n        self.log(f'{mode}_loss', metrics)\n    \n    def check_gradcam(self, dataloader, target_layer, target_category, reshape_transform=None):\n        cam = GradCAMPlusPlus(\n            model=self,\n            target_layer=target_layer, \n            use_cuda=self.cfg.trainer.gpus, \n            reshape_transform=reshape_transform)\n        \n        org_images, labels = iter(dataloader).next()\n        cam.batch_size = len(org_images)\n        images = self.transform['val'](org_images)\n        images = images.to(self.device)\n        logits = self.forward(images).squeeze(1)\n        pred = logits.sigmoid().detach().cpu().numpy() * 100\n        labels = labels.cpu().numpy()\n        \n        grayscale_cam = cam(input_tensor=images, target_category=target_category, eigen_smooth=True)\n        org_images = org_images.detach().cpu().numpy().transpose(0, 2, 3, 1) / 255.\n        return org_images, grayscale_cam, pred, labels\n\n    def configure_optimizers(self):\n        optimizer = eval(self.cfg.optimizer.name)(\n            self.parameters(), **self.cfg.optimizer.params\n        )\n        scheduler = eval(self.cfg.scheduler.name)(\n            optimizer,\n            **self.cfg.scheduler.params\n        )\n        return [optimizer], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2021-10-26T08:17:47.053181Z","iopub.execute_input":"2021-10-26T08:17:47.053507Z","iopub.status.idle":"2021-10-26T08:17:47.082984Z","shell.execute_reply.started":"2021-10-26T08:17:47.053476Z","shell.execute_reply":"2021-10-26T08:17:47.08204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(\n    n_splits=config.n_splits, shuffle=True, random_state=config.seed\n)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df[\"Id\"], df[\"Pawpularity\"])):\n    train_df = df.loc[train_idx].reset_index(drop=True)\n    val_df = df.loc[val_idx].reset_index(drop=True)\n    datamodule = PetfinderDataModule(train_df, val_df, config)\n    model = Model(config)\n    earystopping = EarlyStopping(monitor=\"val_loss\")\n    lr_monitor = callbacks.LearningRateMonitor()\n    loss_checkpoint = callbacks.ModelCheckpoint(\n        filename=\"best_loss\",\n        monitor=\"val_loss\",\n        save_top_k=1,\n        mode=\"min\",\n        save_last=False,\n    )\n    logger = TensorBoardLogger(config.model.name)\n    \n    trainer = pl.Trainer(\n        logger=logger,\n        max_epochs=config.epoch,\n        callbacks=[lr_monitor, loss_checkpoint, earystopping],\n        **config.trainer,\n    )\n    trainer.fit(model, datamodule=datamodule)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T08:17:54.520833Z","iopub.execute_input":"2021-10-26T08:17:54.521641Z","iopub.status.idle":"2021-10-26T12:14:22.066176Z","shell.execute_reply.started":"2021-10-26T08:17:54.521607Z","shell.execute_reply":"2021-10-26T12:14:22.064924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# class activation map","metadata":{}},{"cell_type":"code","source":"# gradcam reshape_transform for vit\ndef reshape_transform(tensor, height=7, width=7):\n    result = tensor.reshape(tensor.size(0),\n                            height, width, tensor.size(2))\n\n    # like in CNNs.\n    result = result.permute(0, 3, 1, 2)\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:15:50.351343Z","iopub.execute_input":"2021-10-26T12:15:50.351703Z","iopub.status.idle":"2021-10-26T12:15:50.358222Z","shell.execute_reply.started":"2021-10-26T12:15:50.351672Z","shell.execute_reply":"2021-10-26T12:15:50.357104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(config) \nmodel.load_state_dict(torch.load(f'{config.model.name}/default/version_0/checkpoints/best_loss.ckpt')['state_dict'])\nmodel = model.cuda().eval()\nconfig.val_loader.batch_size = 16\ndatamodule = PetfinderDataModule(train_df, val_df, config)\nimages, grayscale_cams, preds, labels = model.check_gradcam(\n                                            datamodule.val_dataloader(), \n                                            target_layer=model.backbone.layers[-1].blocks[-1].norm1,\n                                            target_category=None,\n                                            reshape_transform=reshape_transform)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:49:22.576656Z","iopub.execute_input":"2021-10-26T12:49:22.576978Z","iopub.status.idle":"2021-10-26T12:49:27.028654Z","shell.execute_reply.started":"2021-10-26T12:49:22.576944Z","shell.execute_reply":"2021-10-26T12:49:27.027063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor it, (image, grayscale_cam, pred, label) in enumerate(zip(images, grayscale_cams, preds, labels)):\n    plt.subplot(4, 4, it + 1)\n    visualization = show_cam_on_image(image, grayscale_cam)\n    plt.imshow(visualization)\n    plt.title(f'pred: {pred:.1f} label: {label}')\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:49:52.247841Z","iopub.execute_input":"2021-10-26T12:49:52.248295Z","iopub.status.idle":"2021-10-26T12:49:53.608097Z","shell.execute_reply.started":"2021-10-26T12:49:52.248246Z","shell.execute_reply":"2021-10-26T12:49:53.607036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualize result","metadata":{}},{"cell_type":"code","source":"from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n\npath = glob(f'./{config.model.name}/default/version_0/events*')[0]\nevent_acc = EventAccumulator(path, size_guidance={'scalars': 0})\nevent_acc.Reload()\n\nscalars = {}\nfor tag in event_acc.Tags()['scalars']:\n    events = event_acc.Scalars(tag)\n    scalars[tag] = [event.value for event in events]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\n\nplt.figure(figsize=(16, 6))\nplt.subplot(1, 2, 1)\nplt.plot(range(len(scalars['lr-AdamW'])), scalars['lr-AdamW'])\nplt.xlabel('epoch')\nplt.ylabel('lr')\nplt.title('adamw lr')\n\nplt.subplot(1, 2, 2)\nplt.plot(range(len(scalars['train_loss'])), scalars['train_loss'], label='train_loss')\nplt.plot(range(len(scalars['val_loss'])), scalars['val_loss'], label='val_loss')\nplt.legend()\nplt.ylabel('rmse')\nplt.xlabel('epoch')\nplt.title('train/val rmse')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('best_val_loss', min(scalars['val_loss']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### test submit #########\n\nimport os\nfrom tqdm import tqdm\nimport pandas as pd\n\n\nclass TestPawpularityDataset(Dataset):\n    def __init__(self, root_dir, transforms=None):\n        self.root_dir = root_dir\n        self.file_names = os.listdir(self.root_dir)\n        self._transform = transforms\n        \n    def __len__(self):\n        return len(self.file_names)\n    \n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.file_names[index])\n        img = read_image(img_path)\n        img = self._transform(img)\n        \n#         if self.transforms:\n#             img = self.transforms(image=img)[\"image\"]\n            \n        return img, self.file_names[index].strip('.jpg')\n    \ndef load_param(model, model_path):\n        param_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n        if 'state_dict' in param_dict.keys():\n            param_dict = param_dict['state_dict']\n\n        \n        start_with_module = False\n        for k in param_dict.keys():\n            if k.startswith('module.'):\n                start_with_module = True\n                break\n        if start_with_module:\n            param_dict = {k[7:] : v for k, v in param_dict.items() }\n  \n        print('ignore_param:')\n        print([k for k, v in param_dict.items() if k not in model.state_dict() or model.state_dict()[k].size() != v.size()])\n        print('unload_param:')\n        print([k for k, v in model.state_dict().items() if k not in param_dict.keys() or param_dict[k].size() != v.size()] )\n\n        param_dict = {k: v for k, v in param_dict.items() if k in model.state_dict() and model.state_dict()[k].size() == v.size()}\n        for i in param_dict:\n            model.state_dict()[i].copy_(param_dict[i])\n        return model\n\n_transforms = T.Compose(\n            [\n                T.Resize([224, 224]),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ])\ntest_dataset = TestPawpularityDataset('../input/petfinder-pawpularity-score/train', transforms=_transforms)\n\ntest_loader = DataLoader(test_dataset, batch_size=8,num_workers=4, shuffle=False, pin_memory=True)\noutputs_list = list()\nfilenames_list = list()\n\n# model = load_param(model, './RMSE20.5880_epoch4.bin')\n# model=model.eval()\nfor data, filenames in tqdm(test_loader):\n    data = data.to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), dtype=torch.float)\n    with torch.no_grad(): \n        logits = model(data)\n        outputs = logits.sigmoid().detach().cpu() * 100.\n#     print(outputs.shape)\n    outputs_list.append(outputs[:, 0])\n    filenames_list.extend(filenames)\noutputs_list = torch.cat(outputs_list, 0)\noutputs_list = list(np.round(outputs_list.cpu().numpy(), 2))\nprint(outputs_list, filenames_list)\ndataframe = pd.DataFrame({'Id':filenames_list,'Pawpularity':outputs_list})\ndataframe.to_csv(\"submission.csv\",index=False,sep=',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:39:43.137031Z","iopub.execute_input":"2021-10-26T12:39:43.137776Z","iopub.status.idle":"2021-10-26T12:39:44.083656Z","shell.execute_reply.started":"2021-10-26T12:39:43.137738Z","shell.execute_reply":"2021-10-26T12:39:44.082536Z"},"trusted":true},"execution_count":null,"outputs":[]}]}