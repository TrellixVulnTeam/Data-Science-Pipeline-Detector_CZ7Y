{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-02T17:10:00.437389Z","iopub.execute_input":"2021-10-02T17:10:00.438307Z","iopub.status.idle":"2021-10-02T17:10:06.529593Z","shell.execute_reply.started":"2021-10-02T17:10:00.438212Z","shell.execute_reply":"2021-10-02T17:10:06.517652Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\nsample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:10:06.557285Z","iopub.execute_input":"2021-10-02T17:10:06.557487Z","iopub.status.idle":"2021-10-02T17:10:06.589226Z","shell.execute_reply.started":"2021-10-02T17:10:06.557463Z","shell.execute_reply":"2021-10-02T17:10:06.588508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:10:06.590341Z","iopub.execute_input":"2021-10-02T17:10:06.590648Z","iopub.status.idle":"2021-10-02T17:10:06.629903Z","shell.execute_reply.started":"2021-10-02T17:10:06.590612Z","shell.execute_reply":"2021-10-02T17:10:06.629122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:10:06.631559Z","iopub.execute_input":"2021-10-02T17:10:06.631866Z","iopub.status.idle":"2021-10-02T17:10:06.651211Z","shell.execute_reply.started":"2021-10-02T17:10:06.631833Z","shell.execute_reply":"2021-10-02T17:10:06.650438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def kfold_split(df:pd.DataFrame, n_splits:int, shuffle:bool, random_state:int):\n    \n    from sklearn.model_selection import StratifiedKFold\n    \n    df['kfold'] = -1\n    df = df.sample(frac=1).reset_index(drop=True)\n    \n    kf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n    \n    for fold, (train_idx,valid_idx) in enumerate(kf.split(X=df,y=df.Pawpularity.values)):\n        \n        df.loc[valid_idx,'kfold'] = fold\n        \n    return df ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:10:12.689057Z","iopub.execute_input":"2021-10-02T17:10:12.689309Z","iopub.status.idle":"2021-10-02T17:10:12.695767Z","shell.execute_reply.started":"2021-10-02T17:10:12.689283Z","shell.execute_reply":"2021-10-02T17:10:12.694928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = kfold_split(df=train_df, n_splits=5, shuffle=True, random_state=42)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:10:13.076619Z","iopub.execute_input":"2021-10-02T17:10:13.07687Z","iopub.status.idle":"2021-10-02T17:10:13.850183Z","shell.execute_reply.started":"2021-10-02T17:10:13.076844Z","shell.execute_reply":"2021-10-02T17:10:13.849306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nimport catboost as ctb\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\n\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef objective(trial,model,df):\n    \n    x_train = df[df.kfold != 0].reset_index(drop=True)\n    x_test  = df[df.kfold  == 0].reset_index(drop=True)\n\n\n    y_train = x_train.Pawpularity\n    y_test = x_test.Pawpularity\n\n    x_train = x_train.drop(columns=['Id','Pawpularity','kfold'])\n    x_test  = x_test.drop(columns=['Id','Pawpularity','kfold'])\n    \n    if model == \"catboost\":\n      \n        param = {\n\n            'iterations': trial.suggest_int(\"iterations\",100,2000),\n            'learning_rate': trial.suggest_float(\"learning_rate\",1e-2,0.25, log=True),\n            'subsample': trial.suggest_float(\"subsample\",0.1,1.0),\n            'depth':trial.suggest_int(\"depth\",5,9),\n            'bagging_temperature':trial.suggest_int(\"bagging_temperature\",0,5)\n\n        }\n\n        catboost_regressor = ctb.CatBoostRegressor(**param,random_state = 42,verbose=0)\n\n        catboost_regressor.fit(x_train,y_train,eval_set=[(x_test,y_test)])\n\n        preds = catboost_regressor.predict(x_test)\n        rmse = metrics.mean_squared_error(y_test,preds)\n\n        return rmse\n    \n    if model == \"xgboost\":\n        \n        param = {\n\n            'reg_lambda': trial.suggest_loguniform(\"reg_lambda\",1e-8,100.0),\n            'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8,100.0),\n            'learning_rate': trial.suggest_float(\"learning_rate\",1e-2,0.25, log=True),\n            'subsample': trial.suggest_float(\"subsample\",0.1,1.0),\n            'max_depth':trial.suggest_int(\"max_depth\",1,7),\n            'colsample_bytree':trial.suggest_float(\"colsample_bytree\",0.1,1.0)\n\n        }\n        \n        xgboost_regressor = XGBRegressor(**param,random_state=42,tree_method=\"gpu_hist\",gpu_id=1,predictor=\"gpu_predictor\")\n        xgboost_regressor.fit(x_train,y_train,eval_set=[(x_test,y_test)])\n        print(\"buradasÄ±n\")\n        preds = xgboost_regressor.predict(x_test)\n        rmse  = metrics.mean_squared_error(y_test,preds)\n        \n        return rmse\n    \n    \n    if model ==\"lightgbm\":\n\n        param = {\n            'boosting_type': 'gbdt',\n            'objective': 'regression',\n            'metric': {'rmse'},\n            'n_estimators': trial.suggest_int(\"n_estimators\", 64, 8192),\n            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-3, 0.25, log=True),\n            'num_leaves': trial.suggest_int(\"num_leaves\", 4, 16),\n            'max_depth': trial.suggest_int(\"max_depth\", 4, 16),\n            'feature_fraction': trial.suggest_float(\"feature_fraction\", 0.1, 1.0),\n            'lambda_l1': trial.suggest_loguniform(\"lambda_l1\", 1e-8, 100.0),\n            'lambda_l2': trial.suggest_loguniform(\"lambda_l2\", 1e-8, 100.0),\n            'seed': 42,\n            'deterministic': True,\n            'verbose':-1,\n        }\n\n        lgb_train = lgb.Dataset(x_train,y_train)\n        lgb_val   = lgb.Dataset(x_test,y_test)\n\n        model=lgb.train(\n            param,\n            lgb_train,\n            num_boost_round=5000,\n            valid_sets=(lgb_train, lgb_val),\n            early_stopping_rounds=100,\n            verbose_eval=False\n            \n        )\n        \n        preds = model.predict(x_test)\n        rmse = metrics.mean_squared_error(y_test,preds)\n        \n        return rmse   ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:10:24.979066Z","iopub.execute_input":"2021-10-02T17:10:24.979327Z","iopub.status.idle":"2021-10-02T17:10:27.595461Z","shell.execute_reply.started":"2021-10-02T17:10:24.9793Z","shell.execute_reply":"2021-10-02T17:10:27.594719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\n\n\ndef optimize(model,n_trials):\n\n    optimizer_func = partial(objective,model=model,df=train_df)\n\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(optimizer_func,n_trials=n_trials)\n\n    return study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:10:29.389404Z","iopub.execute_input":"2021-10-02T17:10:29.389678Z","iopub.status.idle":"2021-10-02T17:10:29.39483Z","shell.execute_reply.started":"2021-10-02T17:10:29.389649Z","shell.execute_reply":"2021-10-02T17:10:29.393823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_best_params = optimize(model=\"lightgbm\",n_trials=100)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:11:25.702743Z","iopub.execute_input":"2021-10-02T17:11:25.704258Z","iopub.status.idle":"2021-10-02T17:11:58.561259Z","shell.execute_reply.started":"2021-10-02T17:11:25.704213Z","shell.execute_reply":"2021-10-02T17:11:58.560669Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catboost_best_params = optimize(model=\"catboost\",n_trials=100)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:11:58.564581Z","iopub.execute_input":"2021-10-02T17:11:58.566168Z","iopub.status.idle":"2021-10-02T17:15:42.991263Z","shell.execute_reply.started":"2021-10-02T17:11:58.566135Z","shell.execute_reply":"2021-10-02T17:15:42.990536Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgboost_best_params = optimize(model=\"xgboost\",n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:10:36.844768Z","iopub.execute_input":"2021-10-02T17:10:36.845501Z","iopub.status.idle":"2021-10-02T17:10:47.863898Z","shell.execute_reply.started":"2021-10-02T17:10:36.845464Z","shell.execute_reply":"2021-10-02T17:10:47.863376Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_fold_with_best_params(df,test_df,fold,model,params):\n    \n    fold_predictions = []\n    \n    for fold_idx in range(fold):\n\n        x_train = df[df.kfold != fold_idx].reset_index(drop=True)\n        x_valid  = df[df.kfold  == fold_idx].reset_index(drop=True)\n\n\n        y_train = x_train.Pawpularity\n        y_valid = x_valid.Pawpularity\n\n        x_train = x_train.drop(columns=['Id','Pawpularity','kfold'])\n        x_valid  = x_valid.drop(columns=['Id','Pawpularity','kfold'])\n\n\n        x_test = test_df.drop(columns=['Id'])\n\n        if model == \"catboost\":\n\n            catboost_regressor = ctb.CatBoostRegressor(**params,random_state = 42,verbose=0)\n            catboost_regressor.fit(x_train,y_train,eval_set=[(x_valid,y_valid)])\n\n            valid_preds = catboost_regressor.predict(x_valid)\n            rmse = np.sqrt(metrics.mean_squared_error(y_valid,valid_preds))\n\n            print(f\"RMSE of {model} for the fold {fold_idx} : {rmse}\")\n\n            test_preds = catboost_regressor.predict(x_test)\n\n            fold_predictions.append(test_preds)\n        \n        elif model ==\"xgboost\":\n            \n            xgboost_regressor = XGBRegressor(**params,random_state=42,tree_method=\"gpu_hist\",gpu_id=1,predictor=\"gpu_predictor\")\n            xgboost_regressor.fit(x_train,y_train,eval_set=[(x_valid,y_valid)])\n            \n            valid_preds = xgboost_regressor.predict(x_valid)\n            rmse = np.sqrt(metrics.mean_squared_error(y_valid,valid_preds))\n\n            print(f\"RMSE of {model} for the fold {fold_idx} : {rmse}\")\n            \n            test_preds = xgboost_regressor.predict(x_test)\n            \n            fold_predictions.append(test_preds)\n        \n        elif model==\"lightgbm\":\n            \n            lgb_train = lgb.Dataset(x_train,y_train)\n            lgb_val   = lgb.Dataset(x_valid,y_valid)\n\n            model=lgb.train(\n                params,\n                lgb_train,\n                num_boost_round=5000,\n                verbose_eval=False\n\n            )\n            \n            valid_preds = model.predict(x_valid)\n            rmse = np.sqrt(metrics.mean_squared_error(y_valid,valid_preds))\n\n            print(f\"RMSE of {model} for the fold {fold_idx} : {rmse}\")\n            \n            test_preds = model.predict(x_test)\n            fold_predictions.append(test_preds)\n        \n    final_predictions = np.mean(np.column_stack(fold_predictions), axis=1)\n       \n    return final_predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:20:30.597833Z","iopub.execute_input":"2021-10-02T17:20:30.59818Z","iopub.status.idle":"2021-10-02T17:20:30.614369Z","shell.execute_reply.started":"2021-10-02T17:20:30.598151Z","shell.execute_reply":"2021-10-02T17:20:30.613614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_predictions = []\n\nfor model,param in zip(['catboost','xgboost','lightgbm'],[catboost_best_params,xgboost_best_params,lgb_best_params]):\n    \n    preds =  fit_fold_with_best_params(df=train_df,test_df=test_df,fold=5,model=model,params=param)\n    \n    model_predictions.append(preds)   ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:22:43.13205Z","iopub.execute_input":"2021-10-02T17:22:43.132369Z","iopub.status.idle":"2021-10-02T17:22:58.271679Z","shell.execute_reply.started":"2021-10-02T17:22:43.132337Z","shell.execute_reply":"2021-10-02T17:22:58.27095Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last = np.mean(np.column_stack(model_predictions), axis=1)\n ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:24:00.964794Z","iopub.execute_input":"2021-10-02T17:24:00.96536Z","iopub.status.idle":"2021-10-02T17:24:00.972052Z","shell.execute_reply.started":"2021-10-02T17:24:00.96532Z","shell.execute_reply":"2021-10-02T17:24:00.971292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = test_df['Id'].values\n\nsubmission = pd.DataFrame({'Id':ids,\n                            'Pawpularity':last})","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:25:37.196394Z","iopub.execute_input":"2021-10-02T17:25:37.196659Z","iopub.status.idle":"2021-10-02T17:25:37.202023Z","shell.execute_reply.started":"2021-10-02T17:25:37.196629Z","shell.execute_reply":"2021-10-02T17:25:37.201113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T17:25:55.96563Z","iopub.execute_input":"2021-10-02T17:25:55.965933Z","iopub.status.idle":"2021-10-02T17:25:55.973684Z","shell.execute_reply.started":"2021-10-02T17:25:55.965888Z","shell.execute_reply":"2021-10-02T17:25:55.972861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}