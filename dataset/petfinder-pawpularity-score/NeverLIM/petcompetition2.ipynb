{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r ../input/petnets/timm-0.4.12-py3-none-any.whl /kaggle/working\n!pip install -qq ./timm-0.4.12-py3-none-any.whl\n!cp -r ../input/petnets/model_swin.py /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2021-10-13T01:51:45.303013Z","iopub.execute_input":"2021-10-13T01:51:45.303605Z","iopub.status.idle":"2021-10-13T01:52:15.167025Z","shell.execute_reply.started":"2021-10-13T01:51:45.303518Z","shell.execute_reply":"2021-10-13T01:52:15.166064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import model_swin","metadata":{"execution":{"iopub.status.busy":"2021-10-13T01:52:15.169216Z","iopub.execute_input":"2021-10-13T01:52:15.1695Z","iopub.status.idle":"2021-10-13T01:52:20.365714Z","shell.execute_reply.started":"2021-10-13T01:52:15.169464Z","shell.execute_reply":"2021-10-13T01:52:20.364944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport os\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nimport torch\nimport csv\nfrom tqdm import tqdm\nimport pandas as pd\n\n\nclass MyData(Dataset):\n\n    def __init__(self, photo_root, labels_root=None, is_train=True, use_meta=False, transforms_input=None):\n        self.photo_root = photo_root  # path of data\n        self.labels_root = labels_root  # root of train.csv/test.csv\n        self.is_train = is_train  # 当前是否处于训练状态\n        # self.use_meta = use_meta\n        self.transforms = transforms_input  # 预处理方式\n\n        self.df = pd.read_csv(labels_root)\n\n    def __getitem__(self, index):\n        # img = Image.open()\n        # img_label\n        # return img,img_label\n        path = os.path.join(self.photo_root, self.df['Id'][index]) + '.jpg'\n        img = Image.open(path)\n        if self.transforms is not None:\n            img = self.transforms(img)\n\n        if self.is_train:\n            label = torch.as_tensor(self.df['Pawpularity'][index]).reshape(1)\n            return img, label\n        else:\n            return img\n\n    def __len__(self):\n        # length of dataset\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T01:52:20.36698Z","iopub.execute_input":"2021-10-13T01:52:20.367269Z","iopub.status.idle":"2021-10-13T01:52:20.377679Z","shell.execute_reply.started":"2021-10-13T01:52:20.367215Z","shell.execute_reply":"2021-10-13T01:52:20.376705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# ensemble\n# 混合精度训练\nimport math\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, Subset, ConcatDataset\nfrom torchvision import transforms\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom torch.utils.tensorboard import SummaryWriter\n# import data_new\nfrom tqdm import tqdm\n\nfrom torch.cuda.amp import GradScaler, autocast\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, Subset, ConcatDataset\nfrom torchvision import transforms\nfrom torch.optim import AdamW\nfrom torch.utils.tensorboard import SummaryWriter\nimport math\nimport random\nfrom tqdm import tqdm\nfrom sklearn.model_selection import KFold\n\nMY_DATA_MEAN = [0.5155, 0.4858, 0.4506]\nMY_DATA_STD = [0.2693, 0.2650, 0.2666]\nIMAGENET_MEAN = [0.485, 0.456, 0.406]\nIMAGENET_STD = [0.229, 0.224, 0.225]\n\n\n# class TraindataSet(Dataset):\n#     def __init__(self, train_features, train_labels):\n#         self.x_data = train_features\n#         self.y_data = train_labels\n#         self.len = len(train_labels)\n#\n#     def __getitem__(self, index):\n#         return self.x_data[index], self.y_data[index]\n#\n#     def __len__(self):\n#         return self.len\nclass MySubset(Dataset):\n    r\"\"\"\n    Subset of a dataset at specified indices.\n\n    Args:\n        dataset (Dataset): The whole Dataset\n        indices (sequence): Indices in the whole set selected for subset\n    \"\"\"\n\n    def __init__(self, dataset, indices, transforms_input) -> None:\n        self.dataset = dataset\n        self.indices = indices\n        self.transforms = transforms_input\n\n    def __getitem__(self, idx):\n        img, label = self.dataset[self.indices[idx]]\n        img = self.transforms(img)\n        return img, label\n\n    def __len__(self):\n        return len(self.indices)\n\n\n# 训练函数\ndef train(pretrain_dir, train_data, test_data, k_num, epochs, lr, weight_decay,\n          batch_size, device):\n    train_loss_rmse, test_loss_mean = 0.0, 0.0  # 存储train_loss,test_loss\n    test_loss_min = 100.0\n    dataloader_train = DataLoader(train_data, batch_size, shuffle=True)\n    dataloader_test = DataLoader(test_data, batch_size)\n\n    # model\n#     net = model_swin.SwinTransformer()\n#     net = model_swin.SwinTransformer(embed_dim=192, depths=[2, 2, 18, 2], num_heads=[6, 12, 24, 48], \n#                           num_classes=1000)  # 实例化模型large\n    net = model_swin.SwinTransformer(embed_dim=96, \n                                     depths=[2, 2, 18, 2],\n                                     num_heads=[3, 6, 12, 24])  # 实例化模型small\n    # net = model_swin.SwinTransformer(embed_dim=96, depths=[2, 2, 18, 2],\n    #                                  num_heads=[3, 6, 12, 24], drop_rate=0.1,\n    #                                  attn_drop_rate=0.1, drop_path_rate=0.1)  # 实例化模型\n    checkpoint = torch.load(pretrain_dir, map_location='cpu')\n    net.load_state_dict(checkpoint['model'], strict=False)\n    in_features = net.head.in_features\n#     net.head = nn.Sequential(nn.Dropout(0.3), nn.Linear(in_features=in_features, out_features=1))\n    net.head = nn.Linear(in_features=in_features, out_features=1)\n    net.to(device)\n\n    # 这里使用了AdamW优化算法\n    # optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    eps = 1e-8\n    betas = (0.9, 0.999)\n    # weight_decay = 0.05\n    optimizer = AdamW(net.parameters(), eps=eps, betas=betas, lr=lr, weight_decay=weight_decay)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, eta_min=1e-7)\n    # loss_fn_train = nn.BCELoss()\n    loss_fn_train = nn.BCEWithLogitsLoss()\n    loss_fn_test = nn.MSELoss()\n    sigmoid = nn.Sigmoid()\n\n    scaler = GradScaler()\n\n    writer = SummaryWriter('logs')\n    for epoch in range(epochs):\n        train_step = 0\n        test_step = 0\n        '''loss of train'''\n        total_train_rmse = 0.0\n        '''loss of test'''\n        total_test_loss = 0.0\n\n        net.train()\n        print(\"-----epoch:{}/{} of fold:{}-----\".format(epoch + 1, epochs, k_num))\n#         for img, labels in tqdm(dataloader_train):\n        for img, labels in dataloader_train:\n            img = img.to(device)\n            labels = (labels / 100).to(device)\n            optimizer.zero_grad()\n            with autocast():\n                outputs = net(img)\n                loss = loss_fn_train(outputs, labels)\n                outputs = sigmoid(outputs)\n                loss_r = nn.functional.mse_loss(outputs * 100, labels * 100)\n            scaler.scale(loss).backward()\n            # loss.backward()\n            scaler.step(optimizer)\n            # optimizer.step()\n            scheduler.step()\n            scaler.update()\n\n            #             outputs = net(img)\n            #             loss = loss_fn_train(outputs, labels)\n            #             outputs = sigmoid(outputs)\n            #             loss_r = nn.functional.mse_loss(outputs*100, labels*100)\n            #             loss.backward()\n            #             optimizer.step()\n\n            train_step += 1\n            total_train_rmse += loss_r.item()\n\n            if train_step % 20 == 0:\n                print('fold:{}, epoch:{}, train step = {}, loss={}'.format(k_num, epoch + 1, train_step, loss.item()))\n\n        net.eval()\n\n        with torch.no_grad():\n#             for img, labels in tqdm(dataloader_test):\n            for img, labels in dataloader_test:\n                img = img.to(device)\n                labels = labels.to(device)\n\n                outputs = net(img)\n                outputs = sigmoid(outputs)\n                loss = loss_fn_test(outputs * 100, labels)\n                test_step += 1\n                total_test_loss += loss.item()\n\n        train_loss_rmse = math.sqrt(total_train_rmse / train_step)\n        test_loss_mean = math.sqrt(total_test_loss / test_step)\n        print(\"-----epoch:{}/{} of fold:{} finished-----\".format(epoch + 1, epochs, k_num))\n        print('train_loss_rmse={}'.format(train_loss_rmse))\n        print('test_loss_mean={}'.format(test_loss_mean))\n        writer.add_scalar('train_loss_rmse of fold:{}'.format(k_num), train_loss_rmse, epoch)\n        writer.add_scalar('test_loss of fold:{}'.format(k_num), total_test_loss, epoch)\n\n#         torch.save(net.state_dict(), 'net{}_of_fold_{}.pth'.format(epoch + 1, k_num))\n        if test_loss_mean<test_loss_min:\n            test_loss_min = test_loss_mean\n            torch.save(net.state_dict(), 'net_of_fold_{}.pth'.format(k_num))\n            print(\"model is saved successfully\")\n            print('current val loss={}'.format(test_loss_min))\n    writer.close()\n\n    net = None\n    optimizer = None\n    #     torch.cuda.empty_cache()\n\n    return train_loss_rmse, test_loss_min\n\n\ndef k_fold(k, X_train, pretrain_dir,\n           transforms_train,\n           transforms_test,\n           device, num_epochs=3,\n           learning_rate=0.001,\n           weight_decay=0.05,\n           batch_size=5):\n    train_loss_rmse_sum, valid_loss_sum = 0, 0\n    # train_acc_sum, valid_acc_sum = 0, 0\n    kf = KFold(n_splits=k, shuffle=True, random_state=2)\n    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n        data_train = MySubset(X_train, train_index, transforms_train)\n        data_val = MySubset(X_train, test_index, transforms_test)\n\n        # 每份数据进行训练,体现步骤三####\n        train_ls_rmse, valid_ls = train(pretrain_dir, data_train, data_val, i+1, num_epochs,\n                                                  learning_rate, weight_decay, batch_size, device=device)\n\n        print('*' * 25, '第', i + 1, '折', '*' * 25)\n#         print('train_loss_rmse:{:.6f}'.format(train_ls_rmse),\n#               'valid loss:{:.6f}'.format(valid_ls))\n        print('valid loss:{:.6f}'.format(valid_ls))\n\n        train_loss_rmse_sum += train_ls_rmse\n        valid_loss_sum += valid_ls\n    print('#' * 10, '最终k折交叉验证结果', '#' * 10)\n    # 体现步骤四\n#     print('train_loss_rmse:{:.4f}'.format(train_loss_rmse_sum / k),\n#           'valid_loss_sum:{:.4f}'.format(valid_loss_sum / k))\n    print('valid_loss_sum:{:.4f}'.format(valid_loss_sum / k))\n\ndef main(parser_data):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"using device:{}\".format(device))\n\n    '''setting of transform'''\n    data_transform = transforms.Compose(\n        [transforms.RandomResizedCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.RandomVerticalFlip(),\n         transforms.ToTensor(),\n         transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)]\n    )\n    \n    data_transform2 = transforms.Compose(\n        [transforms.RandomResizedCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n         transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n         transforms.ToTensor(),\n         transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)]\n    )\n\n    test_transform = transforms.Compose(\n        [transforms.Resize([224, 224]),\n         #          transforms.CenterCrop(224),\n         transforms.ToTensor(),\n         transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)]\n    )\n    '''divide data of train_data and test_data'''\n    data_path = parser_data.img_path\n    label_path = parser_data.labels_path\n    train_data = MyData(photo_root=data_path, labels_root=label_path)\n\n    k_fold(parser_data.fold, train_data, parser_data.pretrain_dir,\n           transforms_train=data_transform,\n           transforms_test=test_transform,\n           device=device, num_epochs=parser_data.epochs, learning_rate=parser_data.lr,\n           batch_size=parser_data.batch_size)  # 交叉验证\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T01:52:20.380072Z","iopub.execute_input":"2021-10-13T01:52:20.380397Z","iopub.status.idle":"2021-10-13T01:52:21.365213Z","shell.execute_reply.started":"2021-10-13T01:52:20.38035Z","shell.execute_reply":"2021-10-13T01:52:21.364528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_kaggle(): \n    import argparse\n\n    parser = argparse.ArgumentParser(\n        description=__doc__)\n\n    # 训练数据集的目录\n    parser.add_argument('--img_path', default='../input/petfinder-pawpularity-score/train', help='dataset')\n    # 训练数据集labels目录\n    parser.add_argument('--labels_path', default='../input/petfinder-pawpularity-score/train.csv', help='labels')\n    # pretrained\n    parser.add_argument('--pretrain_dir', default='../input/petnets/swin_small_patch4_window7_224.pth', help='path where to save')\n    # fold\n    parser.add_argument('--fold', default=10, type=int, metavar='N')\n    # 训练的总epoch数\n    parser.add_argument('--epochs', default=10, type=int, metavar='N',\n                        help='number of total epochs to run')\n    # 训练的batch size\n    parser.add_argument('--batch_size', default=64, type=int, metavar='N',\n                        help='batch size when training.')\n    # lr\n    parser.add_argument('--lr', default=1e-4, type=float, metavar='N',\n                        help='learning_rate')\n\n    args = parser.parse_args(args=[])\n    print(args)\n\n    main(args)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T01:52:21.368208Z","iopub.execute_input":"2021-10-13T01:52:21.368423Z","iopub.status.idle":"2021-10-13T01:52:21.376289Z","shell.execute_reply.started":"2021-10-13T01:52:21.368398Z","shell.execute_reply":"2021-10-13T01:52:21.375458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_kaggle()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T01:52:21.377946Z","iopub.execute_input":"2021-10-13T01:52:21.378243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}