{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Convolutional Neural Network and Random Forest on Evaluating Pet Pawpularity (PetFinder.my)\nIn this notebook, I will build a Convolution Neural Network and a Random Forest to predict pet popularity from images and metadata.","metadata":{}},{"cell_type":"markdown","source":"## Basic Imports","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting images\nimport cv2 # used for downloading and resizing images\n\n# libraries for CNN\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\n\n# libraries for RF\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-12-27T19:14:11.666453Z","iopub.execute_input":"2021-12-27T19:14:11.666717Z","iopub.status.idle":"2021-12-27T19:14:20.682452Z","shell.execute_reply.started":"2021-12-27T19:14:11.666636Z","shell.execute_reply":"2021-12-27T19:14:20.681736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Handling\nFirst I will import the data from the csv files.","metadata":{}},{"cell_type":"code","source":"metadata_train = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\nmetadata_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:14:20.684282Z","iopub.execute_input":"2021-12-27T19:14:20.684541Z","iopub.status.idle":"2021-12-27T19:14:20.724825Z","shell.execute_reply.started":"2021-12-27T19:14:20.684505Z","shell.execute_reply":"2021-12-27T19:14:20.724123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:14:20.727716Z","iopub.execute_input":"2021-12-27T19:14:20.727936Z","iopub.status.idle":"2021-12-27T19:14:20.749601Z","shell.execute_reply.started":"2021-12-27T19:14:20.727911Z","shell.execute_reply":"2021-12-27T19:14:20.748949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll then import the image data.","metadata":{}},{"cell_type":"code","source":"train_filenames = os.listdir(\"../input/petfinder-pawpularity-score/train\")\ntest_filenames = os.listdir(\"../input/petfinder-pawpularity-score/test\")\n\ntrain_str = \"../input/petfinder-pawpularity-score/train/\"\ntest_str = \"../input/petfinder-pawpularity-score/test/\"\n\ntrain_size = metadata_train.size//metadata_train.iloc[0,:].size\ntest_size = metadata_test.size//metadata_test.iloc[0,:].size\n\nimages_train = np.ndarray((train_size, 28, 28, 3)) # resizing all images to 28 x 28 (3 channels)\nimages_test = np.ndarray((test_size, 28, 28, 3))\n\nindex = 0\nfor train_file in train_filenames:\n    img = cv2.imread(train_str + train_file)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, dsize=(28, 28), interpolation=cv2.INTER_NEAREST)\n    images_train[index] = img\n    if ((index+1)%100 == 0):\n        print(f\"{index+1} completed in train\")\n    index += 1\n\nindex = 0\nfor test_file in test_filenames:\n    img = cv2.imread(test_str + test_file)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, dsize=(28, 28), interpolation=cv2.INTER_NEAREST)\n    images_test[index] = img\n    print(f\"{index+1} completed in test\")\n    index += 1","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-27T19:14:20.751039Z","iopub.execute_input":"2021-12-27T19:14:20.75167Z","iopub.status.idle":"2021-12-27T19:16:36.979571Z","shell.execute_reply.started":"2021-12-27T19:14:20.751632Z","shell.execute_reply":"2021-12-27T19:16:36.978812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then I will split the training data into training and validation data.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_metadata = metadata_train.iloc[:, 1:13]\ny_train = metadata_train[\"Pawpularity\"]\nmetadata_training, metadata_valid, y_training, y_valid = train_test_split(X_metadata, y_train, test_size = 0.2, shuffle = False)\nimages_training, images_valid, _, _2 = train_test_split(images_train, y_train, test_size = 0.2, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:16:36.981121Z","iopub.execute_input":"2021-12-27T19:16:36.981549Z","iopub.status.idle":"2021-12-27T19:16:37.050317Z","shell.execute_reply.started":"2021-12-27T19:16:36.981507Z","shell.execute_reply":"2021-12-27T19:16:37.049546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display a few images\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images_training[i].astype(\"uint8\"))\n    plt.title(y_training[i])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:16:37.05171Z","iopub.execute_input":"2021-12-27T19:16:37.051984Z","iopub.status.idle":"2021-12-27T19:16:37.488881Z","shell.execute_reply.started":"2021-12-27T19:16:37.05195Z","shell.execute_reply":"2021-12-27T19:16:37.488212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the Convolutional Neural Network\nFirst, I will train the convolutional neural network. The architecture is shown below.","metadata":{}},{"cell_type":"code","source":"# building the model\ncnn_model = keras.Sequential([\n    layers.BatchNormalization(input_shape=[28, 28, 3], axis=1),\n    layers.Conv2D(filters=16, kernel_size=3, activation='relu'),\n    layers.Dropout(0.2),\n    layers.BatchNormalization(axis=1),\n    layers.Conv2D(filters=32, kernel_size=5, activation='relu'),\n    layers.Dropout(0.2),\n    layers.BatchNormalization(axis=1),\n    layers.Conv2D(filters=64, kernel_size=7, activation='relu'),\n    layers.Dropout(0.2),\n    layers.BatchNormalization(axis=1),\n    layers.Conv2D(filters=64, kernel_size=7, activation='relu'),\n    layers.MaxPool2D(),\n    layers.BatchNormalization(axis=1),\n    layers.Flatten(),\n    layers.Dense(units=1024, activation='relu'),\n    layers.Dense(units=1, activation='relu'),\n])\n\n# compiling the model with 'adam' optimizer,\n# \"mean_squared_error\" loss, and RootMeanSquaredError metric\ncnn_model.compile(\n    optimizer='adam',\n    loss='mean_squared_error',\n    metrics=[keras.metrics.RootMeanSquaredError()]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:16:37.490205Z","iopub.execute_input":"2021-12-27T19:16:37.490604Z","iopub.status.idle":"2021-12-27T19:16:40.21202Z","shell.execute_reply.started":"2021-12-27T19:16:37.490567Z","shell.execute_reply":"2021-12-27T19:16:40.210496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(cnn_model, show_shapes=True, show_layer_names=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:16:40.213658Z","iopub.execute_input":"2021-12-27T19:16:40.214145Z","iopub.status.idle":"2021-12-27T19:16:41.036852Z","shell.execute_reply.started":"2021-12-27T19:16:40.214057Z","shell.execute_reply":"2021-12-27T19:16:41.036033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fitting the model with Early Stopping\ncallback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n\nhistory = cnn_model.fit(\n    images_training, y_training,\n    batch_size = 16,\n    validation_data = (images_valid, y_valid),\n    epochs=100,\n    callbacks=[callback]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:16:41.038551Z","iopub.execute_input":"2021-12-27T19:16:41.040252Z","iopub.status.idle":"2021-12-27T19:17:47.173712Z","shell.execute_reply.started":"2021-12-27T19:16:41.040209Z","shell.execute_reply":"2021-12-27T19:17:47.17298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions from the convolutional neural network\npredictions_cnn = cnn_model.predict(images_test)\npredictions_cnn","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:18:47.134605Z","iopub.execute_input":"2021-12-27T19:18:47.134881Z","iopub.status.idle":"2021-12-27T19:18:47.356292Z","shell.execute_reply.started":"2021-12-27T19:18:47.134848Z","shell.execute_reply":"2021-12-27T19:18:47.355607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the Random Forest\nNext, I will train the random forest.","metadata":{}},{"cell_type":"code","source":"# creating the RandomForestRegressor model with 100 estimators and 4 jobs (for faster processing)\nrf_model = RandomForestRegressor(n_estimators = 100, n_jobs = 4, random_state = 0)\nrf_model.fit(metadata_training, y_training)\n\nimport math\npredictions_rf_valid = rf_model.predict(metadata_valid)\nprint(\"Random Forest error: \" + str(math.sqrt(mean_squared_error(y_valid, predictions_rf_valid))))","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:18:59.628294Z","iopub.execute_input":"2021-12-27T19:18:59.629027Z","iopub.status.idle":"2021-12-27T19:19:00.19005Z","shell.execute_reply.started":"2021-12-27T19:18:59.628989Z","shell.execute_reply":"2021-12-27T19:19:00.18838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_rf = rf_model.predict(metadata_test.iloc[:, 1:13])","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:19:05.271595Z","iopub.execute_input":"2021-12-27T19:19:05.271866Z","iopub.status.idle":"2021-12-27T19:19:05.383165Z","shell.execute_reply.started":"2021-12-27T19:19:05.271835Z","shell.execute_reply":"2021-12-27T19:19:05.38241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_rf = np.resize(predictions_rf, (test_size,1))\npredictions_rf","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:19:08.196645Z","iopub.execute_input":"2021-12-27T19:19:08.197218Z","iopub.status.idle":"2021-12-27T19:19:08.204603Z","shell.execute_reply.started":"2021-12-27T19:19:08.197179Z","shell.execute_reply":"2021-12-27T19:19:08.20374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Combining the Models\nHere I will combine the results of the two trained models with a 80:20 weighted ratio.","metadata":{}},{"cell_type":"code","source":"final_predictions = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\nfinal_predictions[\"Pawpularity\"] = 0.8*predictions_cnn + 0.2*predictions_rf\nfinal_predictions = final_predictions.iloc[:, 0:14:13]\nfinal_predictions.to_csv(\"submission.csv\", index = False)\nprint(final_predictions)\nprint(\"Final submission created!\")","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:19:12.920378Z","iopub.execute_input":"2021-12-27T19:19:12.920941Z","iopub.status.idle":"2021-12-27T19:19:12.936536Z","shell.execute_reply.started":"2021-12-27T19:19:12.920902Z","shell.execute_reply":"2021-12-27T19:19:12.935777Z"},"trusted":true},"execution_count":null,"outputs":[]}]}