{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-23T03:48:58.031325Z","iopub.execute_input":"2021-12-23T03:48:58.031544Z","iopub.status.idle":"2021-12-23T03:49:00.768181Z","shell.execute_reply.started":"2021-12-23T03:48:58.031516Z","shell.execute_reply":"2021-12-23T03:49:00.767423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\n#images\nimport cv2\n\n#modeling\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.client import device_lib\n\n#visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:00.771085Z","iopub.execute_input":"2021-12-23T03:49:00.771304Z","iopub.status.idle":"2021-12-23T03:49:00.779058Z","shell.execute_reply.started":"2021-12-23T03:49:00.771276Z","shell.execute_reply":"2021-12-23T03:49:00.778142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check to see\ntf.config.get_visible_devices()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:00.780666Z","iopub.execute_input":"2021-12-23T03:49:00.78102Z","iopub.status.idle":"2021-12-23T03:49:00.790555Z","shell.execute_reply.started":"2021-12-23T03:49:00.78098Z","shell.execute_reply":"2021-12-23T03:49:00.789655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/petfinder-pawpularity-score/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/petfinder-pawpularity-score/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:00.792001Z","iopub.execute_input":"2021-12-23T03:49:00.792362Z","iopub.status.idle":"2021-12-23T03:49:00.825406Z","shell.execute_reply.started":"2021-12-23T03:49:00.792257Z","shell.execute_reply":"2021-12-23T03:49:00.824672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Modify the Id such that each Id is the full image path. In the form\ndef train_id_to_path(x):\n    return '/kaggle/input/petfinder-pawpularity-score/train/' + x + \".jpg\"\ndef test_id_to_path(x):\n    return '/kaggle/input/petfinder-pawpularity-score/test/' + x + \".jpg\"\n\n\n#Read in the data and drop unnecessary columns\ntrain = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\ntrain = train.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\n\ntest = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\ntest = test.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\n\n#Add the .jpg extensions to the image file name ids\ntrain[\"img_path\"] = train[\"Id\"].apply(train_id_to_path)\ntest[\"img_path\"] = test[\"Id\"].apply(test_id_to_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:00.826659Z","iopub.execute_input":"2021-12-23T03:49:00.826901Z","iopub.status.idle":"2021-12-23T03:49:00.858045Z","shell.execute_reply.started":"2021-12-23T03:49:00.826868Z","shell.execute_reply":"2021-12-23T03:49:00.857387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['two_bin_pawp'] = pd.qcut(train['Pawpularity'], q=2, labels=False)\ntrain = train.astype({\"two_bin_pawp\": str})\n\ntrain['four_bin_pawp'] = pd.qcut(train['Pawpularity'], q=4, labels=False)\ntrain = train.astype({\"four_bin_pawp\": str})\n\ntrain['ten_bin_pawp'] = pd.qcut(train['Pawpularity'], q=10, labels=False)\ntrain = train.astype({\"ten_bin_pawp\": str})","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:00.859281Z","iopub.execute_input":"2021-12-23T03:49:00.859538Z","iopub.status.idle":"2021-12-23T03:49:00.909076Z","shell.execute_reply.started":"2021-12-23T03:49:00.859502Z","shell.execute_reply":"2021-12-23T03:49:00.90844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train2bin_stats = train.groupby('two_bin_pawp')\ntrain2bin_stats.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:00.910233Z","iopub.execute_input":"2021-12-23T03:49:00.910465Z","iopub.status.idle":"2021-12-23T03:49:00.939435Z","shell.execute_reply.started":"2021-12-23T03:49:00.910432Z","shell.execute_reply":"2021-12-23T03:49:00.93863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:00.940884Z","iopub.execute_input":"2021-12-23T03:49:00.941137Z","iopub.status.idle":"2021-12-23T03:49:00.95356Z","shell.execute_reply.started":"2021-12-23T03:49:00.941103Z","shell.execute_reply":"2021-12-23T03:49:00.952731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set the size image you want to use\nimage_height = 128\nimage_width = 128\n\n#define a function that accepts an image url and outputs an eager tensor\ndef path_to_eagertensor(image_path):\n    raw = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(raw, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    #image = tf.image.resize_with_pad(image, image_height, image_width) #optional with padding to retain original dimensions\n    image = tf.image.resize(image, (image_height, image_width))\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:00.954776Z","iopub.execute_input":"2021-12-23T03:49:00.954967Z","iopub.status.idle":"2021-12-23T03:49:00.961849Z","shell.execute_reply.started":"2021-12-23T03:49:00.954943Z","shell.execute_reply":"2021-12-23T03:49:00.960884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"og_example_image = plt.imread('../input/petfinder-pawpularity-score/train/0007de18844b0dbbb5e1f607da0606e0.jpg') \nprint(og_example_image.shape)\n\n#then plt.imshow() can display it for you\nplt.imshow(og_example_image)\nplt.title('First Training Image') \nplt.axis('off') #turns off the gridlines\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:00.963594Z","iopub.execute_input":"2021-12-23T03:49:00.964256Z","iopub.status.idle":"2021-12-23T03:49:01.119705Z","shell.execute_reply.started":"2021-12-23T03:49:00.964204Z","shell.execute_reply":"2021-12-23T03:49:01.118885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_image = path_to_eagertensor('../input/petfinder-pawpularity-score/train/0007de18844b0dbbb5e1f607da0606e0.jpg')\n#show the type \nprint('type: ', type(example_image),'\\n shape: ',example_image.shape)\nplt.imshow(example_image)\nplt.title('First Training Image - with preprocessing done by path_to_eagertensor()') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:01.121048Z","iopub.execute_input":"2021-12-23T03:49:01.121312Z","iopub.status.idle":"2021-12-23T03:49:01.33368Z","shell.execute_reply.started":"2021-12-23T03:49:01.121277Z","shell.execute_reply":"2021-12-23T03:49:01.333011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get all the images in the training folder and put their tensors in a list\nX = []\nfor img in train['img_path']:\n    new_img_tensor = path_to_eagertensor(img)\n    X.append(new_img_tensor)\n    \nprint(type(X),len(X))\nX = np.array(X)\nprint(type(X),X.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:01.334899Z","iopub.execute_input":"2021-12-23T03:49:01.335151Z","iopub.status.idle":"2021-12-23T03:49:52.37674Z","shell.execute_reply.started":"2021-12-23T03:49:01.335116Z","shell.execute_reply":"2021-12-23T03:49:52.375912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(X[:1])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:52.378123Z","iopub.execute_input":"2021-12-23T03:49:52.378587Z","iopub.status.idle":"2021-12-23T03:49:52.382526Z","shell.execute_reply.started":"2021-12-23T03:49:52.378545Z","shell.execute_reply":"2021-12-23T03:49:52.381555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get all the images in the test folder and put their tensors in a list\nX_submission = []\nfor img in test['img_path']:\n    new_img_tensor = path_to_eagertensor(img)\n    X_submission.append(new_img_tensor)\n    \nprint(type(X_submission),len(X_submission))\nX_submission = np.array(X_submission)\nprint(type(X_submission),X_submission.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:52.38382Z","iopub.execute_input":"2021-12-23T03:49:52.384238Z","iopub.status.idle":"2021-12-23T03:49:52.480179Z","shell.execute_reply.started":"2021-12-23T03:49:52.384182Z","shell.execute_reply":"2021-12-23T03:49:52.479457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y = train['two_bin_pawp']\ny = train[\"four_bin_pawp\"]\nprint(y[:5])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:52.485165Z","iopub.execute_input":"2021-12-23T03:49:52.48552Z","iopub.status.idle":"2021-12-23T03:49:52.49062Z","shell.execute_reply.started":"2021-12-23T03:49:52.48549Z","shell.execute_reply":"2021-12-23T03:49:52.489776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:52.49223Z","iopub.execute_input":"2021-12-23T03:49:52.492724Z","iopub.status.idle":"2021-12-23T03:49:53.042407Z","shell.execute_reply.started":"2021-12-23T03:49:52.492686Z","shell.execute_reply":"2021-12-23T03:49:53.041566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_test[:5])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:53.043945Z","iopub.execute_input":"2021-12-23T03:49:53.044301Z","iopub.status.idle":"2021-12-23T03:49:53.050201Z","shell.execute_reply.started":"2021-12-23T03:49:53.044263Z","shell.execute_reply":"2021-12-23T03:49:53.049192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_train[:5])","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:53.051646Z","iopub.execute_input":"2021-12-23T03:49:53.051967Z","iopub.status.idle":"2021-12-23T03:49:53.062261Z","shell.execute_reply.started":"2021-12-23T03:49:53.051927Z","shell.execute_reply":"2021-12-23T03:49:53.06118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Conv1D, MaxPooling1D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:53.063927Z","iopub.execute_input":"2021-12-23T03:49:53.064361Z","iopub.status.idle":"2021-12-23T03:49:53.070448Z","shell.execute_reply.started":"2021-12-23T03:49:53.064325Z","shell.execute_reply":"2021-12-23T03:49:53.06852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n# num_classes = 2\n\n# # TODO: Conv1\nmodel.add(Conv2D(filters=32, kernel_size=7,padding=\"same\",activation=\"relu\",input_shape=(128, 128, 3)))\nmodel.add(MaxPooling2D(pool_size=7, strides=2, padding=\"valid\"))\n# # # TODO: Conv2\nmodel.add(Conv2D(filters=16, kernel_size=5,padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=7, strides=2, padding=\"valid\"))\n\n# # # TODO: Conv3\nmodel.add(Conv2D(filters=5, kernel_size=3,padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=7, strides=2, padding=\"valid\"))\n# # TODO: Flatten the layer\nmodel.add(Flatten())\n\n# # TODO: Add the intermediate fully connected layers (Dense in keras)\nmodel.add(Dense(64, activation='relu'))\n\nmodel.add(Dropout(0.5))\n# # TODO: Add the final fully connected layer with the softmax activation function\nmodel.add(Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:53.071579Z","iopub.execute_input":"2021-12-23T03:49:53.07224Z","iopub.status.idle":"2021-12-23T03:49:53.133911Z","shell.execute_reply.started":"2021-12-23T03:49:53.072178Z","shell.execute_reply":"2021-12-23T03:49:53.13325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:53.134877Z","iopub.execute_input":"2021-12-23T03:49:53.135106Z","iopub.status.idle":"2021-12-23T03:49:53.144877Z","shell.execute_reply.started":"2021-12-23T03:49:53.135072Z","shell.execute_reply":"2021-12-23T03:49:53.144023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for two categories\n# def convert2onehot(labels):\n#   result = []\n#   for label in labels:\n# #         print(label)\n#         if label == '1':\n# #             print(\"label 1\")\n#             result.append([1, 0])\n#         else:\n# #             print(\"label 0\")\n#             result.append([0, 1])\n#   return np.array(result)\n\n# x_train_array = np.array(x_train)\n# x_test_array = np.array(x_test)\n# y_train_onehot = convert2onehot(y_train)\n# y_test_onehot = convert2onehot(y_test)\n# print(y_train[:5])\n# print(y_train_onehot[:5])\n# print(x_train_array[:5])\n\n#for 4 categories \ndef convert2onehot_4(labels):\n  result = []\n  for label in labels:\n#         print(label)\n        if label == '0':\n#             print(\"label 1\")\n            result.append([1, 0, 0, 0])\n        elif label == '1':\n            result.append([0,1,0,0])\n        elif label == '2':\n            result.append([0,0,1,0])\n        else:\n#             print(\"label 0\")\n            result.append([0,0,0,1])\n  return np.array(result)\nx_train_array = np.array(x_train)\nx_test_array = np.array(x_test)\ny_train_onehot = convert2onehot_4(y_train)\ny_test_onehot = convert2onehot_4(y_test)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:53.146122Z","iopub.execute_input":"2021-12-23T03:49:53.146407Z","iopub.status.idle":"2021-12-23T03:49:53.707236Z","shell.execute_reply.started":"2021-12-23T03:49:53.14637Z","shell.execute_reply":"2021-12-23T03:49:53.70635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) \n# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) ","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:53.711167Z","iopub.execute_input":"2021-12-23T03:49:53.712708Z","iopub.status.idle":"2021-12-23T03:49:53.731042Z","shell.execute_reply.started":"2021-12-23T03:49:53.712665Z","shell.execute_reply":"2021-12-23T03:49:53.730373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train_array.shape, y_train_onehot.shape,x_test_array.shape, y_test_onehot.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:53.735082Z","iopub.execute_input":"2021-12-23T03:49:53.739625Z","iopub.status.idle":"2021-12-23T03:49:53.751105Z","shell.execute_reply.started":"2021-12-23T03:49:53.739586Z","shell.execute_reply":"2021-12-23T03:49:53.750361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train_array, y_train_onehot, batch_size=16, epochs=3, validation_data=(x_test_array, y_test_onehot))","metadata":{"execution":{"iopub.status.busy":"2021-12-23T03:49:53.752096Z","iopub.execute_input":"2021-12-23T03:49:53.754338Z","iopub.status.idle":"2021-12-23T03:50:17.543498Z","shell.execute_reply.started":"2021-12-23T03:49:53.754298Z","shell.execute_reply":"2021-12-23T03:50:17.542622Z"},"trusted":true},"execution_count":null,"outputs":[]}]}