{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ******Let us first view couple of images to understad what is in it","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom time import sleep\nimport itertools\nimport cv2\nimport os\nimport numpy as np\nimport os\nimport ipywidgets as widgets\nfrom IPython.display import display","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:54:23.094592Z","iopub.execute_input":"2021-10-13T15:54:23.094857Z","iopub.status.idle":"2021-10-13T15:54:23.288223Z","shell.execute_reply.started":"2021-10-13T15:54:23.094828Z","shell.execute_reply":"2021-10-13T15:54:23.287445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a useful function\ndef get_image(f_path):\n    '''\n    Returns the image from a path\n    '''\n    img_labs = ['jpg','png']\n    if any(x in img_labs for x in f_path.split('.')):\n        file = os.path.join(folder,f_path)\n        image = open(file,'rb').read()\n        return image\n    \n# Do the actual work here\nfolder = '../input/petfinder-pawpularity-score/train'\nfiles  = os.listdir(folder)\nsample_files = files[0:18]","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:54:25.238306Z","iopub.execute_input":"2021-10-13T15:54:25.238571Z","iopub.status.idle":"2021-10-13T15:54:25.251237Z","shell.execute_reply.started":"2021-10-13T15:54:25.238535Z","shell.execute_reply":"2021-10-13T15:54:25.250445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = [get_image(x) for x in sample_files]\nchildren = [widgets.Image(value = img) for img in images if str(type(img)) != '<class \\'NoneType\\'>']\nlabels = ['{}'.format(i) for i in range(len(children))]\n\n# Customize your layout here:\nbox_layout = widgets.Layout(\n    display='flex',\n    flex_flow='column',\n    align_items='stretch',\n    border='solid',\n    width='50%')\n\n# Create the widget\ntab = widgets.Tab()\ntab.children = children\n\n# Label em'!\nfor i in range(len(children)):\n    tab.set_title(i,labels[i])\n\ndisplay(tab)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:54:36.758689Z","iopub.execute_input":"2021-10-13T15:54:36.758995Z","iopub.status.idle":"2021-10-13T15:54:37.029658Z","shell.execute_reply.started":"2021-10-13T15:54:36.758943Z","shell.execute_reply":"2021-10-13T15:54:37.028994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:54:41.581681Z","iopub.execute_input":"2021-10-13T15:54:41.581943Z","iopub.status.idle":"2021-10-13T15:54:41.61894Z","shell.execute_reply.started":"2021-10-13T15:54:41.581915Z","shell.execute_reply":"2021-10-13T15:54:41.618286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We are creating a function for transforming and augmenting the image\n\nYou can see the tutorial below\n\nhttps://www.tensorflow.org/tutorials/load_data/images","metadata":{}},{"cell_type":"code","source":"#Generating file name with proper extension\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndf_train['FileName'] = df_train['Id']+\".jpg\"\n\ndef augmentData(df,img_width,img_height,x_col,y_col,batch_size):\n    datagen = ImageDataGenerator(rescale = 1./255, horizontal_flip = True,\n                                   fill_mode = \"nearest\", zoom_range = 0.2,\n                                   width_shift_range = 0.2, height_shift_range=0.2,\n                                   rotation_range=30,validation_split=0.20)\n    \n    #Creating training generator and validation generator\n    train_generator = datagen.flow_from_dataframe(dataframe=df, directory=\"../input/petfinder-pawpularity-score/train/\", \n                                              x_col=x_col, y_col=y_col, \n                                              class_mode=\"raw\", target_size=(img_width, img_height), \n                                              batch_size=batch_size,shuffle=True)\n    \n    validation_generator = datagen.flow_from_dataframe(dataframe=df, directory=\"../input/petfinder-pawpularity-score/train/\", \n                                              x_col=x_col, y_col=y_col, \n                                              class_mode=\"raw\", target_size=(img_width, img_height), \n                                              batch_size=batch_size,subset='validation',shuffle=True)\n    return train_generator,validation_generator\n\n#We are using the function to augment and generate and each time you call the function it is going to shuffle\n#the data for generator which can also used for cross validation\ntrain_generator,validation_generator = augmentData(df_train,100,100,\"FileName\",\"Pawpularity\",64)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:54:43.672123Z","iopub.execute_input":"2021-10-13T15:54:43.672673Z","iopub.status.idle":"2021-10-13T15:54:51.254378Z","shell.execute_reply.started":"2021-10-13T15:54:43.672638Z","shell.execute_reply":"2021-10-13T15:54:51.253544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let us view some sample Images which are augmented**\n\nThis will help us understand the variety of images ","metadata":{}},{"cell_type":"code","source":"# generate samples and plot\nfrom matplotlib import pyplot\nbatch=next(train_generator)  # returns the next batch of images and labels \nprint(batch[0].shape) # batch[0] is the images, batch[1] are the labels\nimg=batch[0][0]   # this is the first image  batch[0][1] would be the next image\nprint (img.shape)\nplt.imshow(img) ","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:54:54.351751Z","iopub.execute_input":"2021-10-13T15:54:54.352274Z","iopub.status.idle":"2021-10-13T15:54:55.593812Z","shell.execute_reply.started":"2021-10-13T15:54:54.352236Z","shell.execute_reply":"2021-10-13T15:54:55.593168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First I am going to start with res net and do transfer learning for regression to start with\n\n![](https://www.researchgate.net/publication/322621180/figure/fig2/AS:584852684410885@1516451154473/The-representation-of-model-architecture-image-for-ResNet-152-VGG-19-and-two-layered.png)","metadata":{}},{"cell_type":"code","source":"#We are going to use resnet for transfer learning and for regression task\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import datasets, layers, models, losses, Model\n#Construct resnet model\ndef resNet_152(height,width,fc_layer_nodes):\n    base_model = tf.keras.applications.ResNet152(weights = '../input/resnet152-weight-file/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top = False, input_shape = (height,width,3))\n    #Freeze weights\n    for layer in base_model.layers:\n        layer.trainable = False\n    x = layers.Flatten()(base_model.output)\n    x = layers.Dense(fc_layer_nodes, activation='relu')(x)\n    prediction = layers.Dense(1)(x)\n    resNet_152_regression = Model(inputs = base_model.input, outputs = prediction)\n    return resNet_152_regression\n\nresNet_152_head_regression = resNet_152(32,32,1000)\nresNet_152_head_regression.compile(optimizer='adam', loss=losses.mean_squared_error, metrics=['mse'])\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n#Since resnet will accept 32*32 in top layer hence we need to adjust the generators\ntrain_generator,validation_generator = augmentData(df_train,32,32,\"FileName\",\"Pawpularity\",64)\n\nhistory = resNet_152_head_regression.fit(train_generator,steps_per_epoch=100,epochs=15,validation_data= validation_generator,callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:55:23.724191Z","iopub.execute_input":"2021-10-13T15:55:23.724453Z","iopub.status.idle":"2021-10-13T16:18:16.704391Z","shell.execute_reply.started":"2021-10-13T15:55:23.724425Z","shell.execute_reply":"2021-10-13T16:18:16.703547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model Loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T16:18:46.599838Z","iopub.execute_input":"2021-10-13T16:18:46.600545Z","iopub.status.idle":"2021-10-13T16:18:47.030281Z","shell.execute_reply.started":"2021-10-13T16:18:46.600502Z","shell.execute_reply":"2021-10-13T16:18:47.029311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef preprocessImagePrediction(imagePath,width,height):\n    image = tf.keras.preprocessing.image.load_img(imagePath, target_size=(width,height))\n    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n    input_arr = np.array([input_arr])  \n    return input_arr\n\nprediction = resNet_152_head_regression.predict(preprocessImagePrediction('../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg',32,32))","metadata":{"execution":{"iopub.status.busy":"2021-10-13T16:18:54.801289Z","iopub.execute_input":"2021-10-13T16:18:54.801569Z","iopub.status.idle":"2021-10-13T16:18:57.161142Z","shell.execute_reply.started":"2021-10-13T16:18:54.80154Z","shell.execute_reply":"2021-10-13T16:18:57.160309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = []\nimport os\n# assign directory\ndirectory = '../input/petfinder-pawpularity-score/test'\n \n# iterate over files in\n# that directory\nfor filename in os.listdir(directory):\n    f = os.path.join(directory, filename)\n    # checking if it is a file\n    prediction = resNet_152_head_regression.predict(preprocessImagePrediction(f,32,32))\n    result.append(round(prediction[0][0],2))","metadata":{"execution":{"iopub.status.busy":"2021-10-13T16:19:09.154368Z","iopub.execute_input":"2021-10-13T16:19:09.154654Z","iopub.status.idle":"2021-10-13T16:19:09.605256Z","shell.execute_reply.started":"2021-10-13T16:19:09.154626Z","shell.execute_reply":"2021-10-13T16:19:09.604481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_10thOct_2021 = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')[['Id','Pawpularity']]","metadata":{"execution":{"iopub.status.busy":"2021-10-13T16:19:16.232822Z","iopub.execute_input":"2021-10-13T16:19:16.233465Z","iopub.status.idle":"2021-10-13T16:19:16.253091Z","shell.execute_reply.started":"2021-10-13T16:19:16.233425Z","shell.execute_reply":"2021-10-13T16:19:16.252434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_10thOct_2021['Pawpularity'] = result","metadata":{"execution":{"iopub.status.busy":"2021-10-13T16:19:18.608804Z","iopub.execute_input":"2021-10-13T16:19:18.609641Z","iopub.status.idle":"2021-10-13T16:19:18.615904Z","shell.execute_reply.started":"2021-10-13T16:19:18.609591Z","shell.execute_reply":"2021-10-13T16:19:18.615084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_10thOct_2021.to_csv('./submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T16:19:47.161044Z","iopub.execute_input":"2021-10-13T16:19:47.161743Z","iopub.status.idle":"2021-10-13T16:19:47.169733Z","shell.execute_reply.started":"2021-10-13T16:19:47.161708Z","shell.execute_reply":"2021-10-13T16:19:47.168927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resNet_152_head_regression.save('./resnet152')","metadata":{"execution":{"iopub.status.busy":"2021-10-13T16:20:15.915188Z","iopub.execute_input":"2021-10-13T16:20:15.915448Z","iopub.status.idle":"2021-10-13T16:21:24.131431Z","shell.execute_reply.started":"2021-10-13T16:20:15.91542Z","shell.execute_reply":"2021-10-13T16:21:24.130637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import model_from_json","metadata":{"execution":{"iopub.status.busy":"2021-10-13T16:35:16.358614Z","iopub.execute_input":"2021-10-13T16:35:16.359175Z","iopub.status.idle":"2021-10-13T16:35:16.363036Z","shell.execute_reply.started":"2021-10-13T16:35:16.359137Z","shell.execute_reply":"2021-10-13T16:35:16.36218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# serialize model to JSON\nmodel_json = resNet_152_head_regression.to_json()\nwith open(\"resNet_152_head_regression.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nresNet_152_head_regression.save_weights(\"resNet_152_head_regression.h5\")\nprint(\"Saved model to disk\")","metadata":{"execution":{"iopub.status.busy":"2021-10-13T16:35:59.270808Z","iopub.execute_input":"2021-10-13T16:35:59.2711Z","iopub.status.idle":"2021-10-13T16:36:00.405345Z","shell.execute_reply.started":"2021-10-13T16:35:59.271069Z","shell.execute_reply":"2021-10-13T16:36:00.403807Z"},"trusted":true},"execution_count":null,"outputs":[]}]}