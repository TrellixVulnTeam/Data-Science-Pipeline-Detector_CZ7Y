{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom time import sleep\nimport itertools\nimport cv2\nimport os\nimport numpy as np\nimport os\nimport ipywidgets as widgets\nfrom IPython.display import display","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:21:35.264794Z","iopub.execute_input":"2021-12-15T14:21:35.265114Z","iopub.status.idle":"2021-12-15T14:21:35.487306Z","shell.execute_reply.started":"2021-12-15T14:21:35.265082Z","shell.execute_reply":"2021-12-15T14:21:35.486457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We are going to try MobileNet for regression task","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom time import sleep\nimport itertools\nimport cv2\nimport os\nimport numpy as np\nimport os\nimport ipywidgets as widgets\nfrom IPython.display import display","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:21:44.568944Z","iopub.execute_input":"2021-12-15T14:21:44.569653Z","iopub.status.idle":"2021-12-15T14:21:44.575371Z","shell.execute_reply.started":"2021-12-15T14:21:44.569614Z","shell.execute_reply":"2021-12-15T14:21:44.573474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a useful function\ndef get_image(f_path):\n    '''\n    Returns the image from a path\n    '''\n    img_labs = ['jpg','png']\n    if any(x in img_labs for x in f_path.split('.')):\n        file = os.path.join(folder,f_path)\n        image = open(file,'rb').read()\n        return image\n    \n# Do the actual work here\nfolder = '../input/petfinder-pawpularity-score/train'\nfiles  = os.listdir(folder)\nsample_files = files[0:18]","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:25:32.823823Z","iopub.execute_input":"2021-12-15T14:25:32.824329Z","iopub.status.idle":"2021-12-15T14:25:32.839729Z","shell.execute_reply.started":"2021-12-15T14:25:32.824292Z","shell.execute_reply":"2021-12-15T14:25:32.838796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = [get_image(x) for x in sample_files]\nchildren = [widgets.Image(value = img) for img in images if str(type(img)) != '<class \\'NoneType\\'>']\nlabels = ['{}'.format(i) for i in range(len(children))]\n\n# Customize your layout here:\nbox_layout = widgets.Layout(\n    display='flex',\n    flex_flow='column',\n    align_items='stretch',\n    border='solid',\n    width='50%')\n\n# Create the widget\ntab = widgets.Tab()\ntab.children = children\n\n# Label em'!\nfor i in range(len(children)):\n    tab.set_title(i,labels[i])\n\ndisplay(tab)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:25:38.014095Z","iopub.execute_input":"2021-12-15T14:25:38.014739Z","iopub.status.idle":"2021-12-15T14:25:38.262856Z","shell.execute_reply.started":"2021-12-15T14:25:38.014678Z","shell.execute_reply":"2021-12-15T14:25:38.262019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:25:50.134801Z","iopub.execute_input":"2021-12-15T14:25:50.135461Z","iopub.status.idle":"2021-12-15T14:25:50.174651Z","shell.execute_reply.started":"2021-12-15T14:25:50.13541Z","shell.execute_reply":"2021-12-15T14:25:50.173683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We are creating a function for transforming and augmenting the image","metadata":{}},{"cell_type":"markdown","source":"You can see the tutorial below\n\nhttps://www.tensorflow.org/tutorials/load_data/images","metadata":{}},{"cell_type":"code","source":"#Generating file name with proper extension\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndf_train['FileName'] = df_train['Id']+\".jpg\"\ndf_train['Normal_y'] = df_train['Pawpularity']/100\n\ndef augmentData(df,img_width,img_height,x_col,y_col,batch_size):\n    datagen = ImageDataGenerator(rescale = 1./255, horizontal_flip = True,\n                                   fill_mode = \"nearest\", zoom_range = 0.2,\n                                   width_shift_range = 0.2, height_shift_range=0.2,\n                                   rotation_range=30,validation_split=0.20)\n    \n    #Creating training generator and validation generator\n    train_generator = datagen.flow_from_dataframe(dataframe=df, directory=\"../input/petfinder-pawpularity-score/train/\", \n                                              x_col=x_col, y_col=y_col, \n                                              class_mode=\"raw\", target_size=(img_width, img_height), \n                                              batch_size=batch_size,shuffle=True)\n    \n    validation_generator = datagen.flow_from_dataframe(dataframe=df, directory=\"../input/petfinder-pawpularity-score/train/\", \n                                              x_col=x_col, y_col=y_col, \n                                              class_mode=\"raw\", target_size=(img_width, img_height), \n                                              batch_size=batch_size,subset='validation',shuffle=True)\n    return train_generator,validation_generator\n\n#We are using the function to augment and generate and each time you call the function it is going to shuffle\n#the data for generator which can also used for cross validation\ntrain_generator,validation_generator = augmentData(df_train,100,100,\"FileName\",\"Normal_y\",64)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:44:55.840774Z","iopub.execute_input":"2021-12-15T14:44:55.841306Z","iopub.status.idle":"2021-12-15T14:44:59.078885Z","shell.execute_reply.started":"2021-12-15T14:44:55.841269Z","shell.execute_reply":"2021-12-15T14:44:59.078002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let us view some sample Images which are augmented\n\nThis will help us understand the variety of images","metadata":{}},{"cell_type":"code","source":"# generate samples and plot\nfrom matplotlib import pyplot\nbatch=next(train_generator)  # returns the next batch of images and labels \nprint(batch[0].shape) # batch[0] is the images, batch[1] are the labels\nimg=batch[0][0]   # this is the first image  batch[0][1] would be the next image\nprint (img.shape)\nplt.imshow(img) ","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:45:05.443858Z","iopub.execute_input":"2021-12-15T14:45:05.444604Z","iopub.status.idle":"2021-12-15T14:45:06.874075Z","shell.execute_reply.started":"2021-12-15T14:45:05.444565Z","shell.execute_reply":"2021-12-15T14:45:06.872887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1400/1*Voah8cvrs7gnTDf6acRvDw.png)","metadata":{}},{"cell_type":"markdown","source":"**Depthwise convolution is the channel-wise DK×DK spatial convolution. Suppose in the figure above, we have 5 channels, then we will have 5 DK×DK spatial convolution.\n\n**Pointwise convolution actually is the 1×1 convolution to change the dimension.**","metadata":{}},{"cell_type":"code","source":"#We are going to use resnet for transfer learning and for regression task\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import datasets, layers, models, losses, Model\n#Construct resnet model\ndef mobileNetV2(height,width):\n    base_model = tf.keras.applications.MobileNetV2(input_shape=(height,width,3),\n                                               include_top=False,\n                                               weights='imagenet')\n    #Freeze weights\n    for layer in base_model.layers:\n        layer.trainable = False\n    x = layers.Flatten()(base_model.output)\n    x = layers.Dense(1000, activation='relu')(x)\n    x = layers.Dense(100, activation='relu')(x)\n    prediction = layers.Dense(1,activation='sigmoid')(x)\n    mobNet_v2_regression = Model(inputs = base_model.input, outputs = prediction)\n    return mobNet_classification\n\nmobNet_classification = mobileNetV2(160,160)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:53:41.361592Z","iopub.execute_input":"2021-12-15T14:53:41.362253Z","iopub.status.idle":"2021-12-15T14:53:42.389558Z","shell.execute_reply.started":"2021-12-15T14:53:41.362207Z","shell.execute_reply":"2021-12-15T14:53:42.388732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we are using binary accuracy since the pawpularity score is normalized","metadata":{}},{"cell_type":"code","source":"loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nmobNet_classification = mobileNetV2(160,160)\nmobNet_classification.compile(optimizer='adam', loss=loss_fn, metrics=[tf.keras.metrics.BinaryCrossentropy(\n    name=\"binary_crossentropy\", dtype=None)])\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n#Since resnet will accept 160*160 in top layer hence we need to adjust the generators\ntrain_generator,validation_generator = augmentData(df_train,160,160,\"FileName\",\"Normal_y\",64)\n\nhistory = mobNet_classification.fit(train_generator,steps_per_epoch=100,epochs=15,validation_data= validation_generator,callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:59:16.16574Z","iopub.execute_input":"2021-12-15T14:59:16.166331Z","iopub.status.idle":"2021-12-15T15:42:25.6328Z","shell.execute_reply.started":"2021-12-15T14:59:16.166274Z","shell.execute_reply":"2021-12-15T15:42:25.631956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model Loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T15:44:04.682728Z","iopub.execute_input":"2021-12-15T15:44:04.683584Z","iopub.status.idle":"2021-12-15T15:44:04.932332Z","shell.execute_reply.started":"2021-12-15T15:44:04.683528Z","shell.execute_reply":"2021-12-15T15:44:04.931517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is preprocessing before prediction\nimport numpy as np\ndef preprocessImagePrediction(imagePath,width,height):\n    image = tf.keras.preprocessing.image.load_img(imagePath, target_size=(width,height))\n    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n    input_arr = np.array([input_arr])  \n    return input_arr","metadata":{"execution":{"iopub.status.busy":"2021-12-15T15:44:19.962942Z","iopub.execute_input":"2021-12-15T15:44:19.963245Z","iopub.status.idle":"2021-12-15T15:44:19.969922Z","shell.execute_reply.started":"2021-12-15T15:44:19.963215Z","shell.execute_reply":"2021-12-15T15:44:19.968942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = mobNet_classification.predict(preprocessImagePrediction('../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg',160,160))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T15:44:33.335998Z","iopub.execute_input":"2021-12-15T15:44:33.337194Z","iopub.status.idle":"2021-12-15T15:44:34.380388Z","shell.execute_reply.started":"2021-12-15T15:44:33.337115Z","shell.execute_reply":"2021-12-15T15:44:34.379248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction","metadata":{"execution":{"iopub.status.busy":"2021-12-15T15:44:39.058143Z","iopub.execute_input":"2021-12-15T15:44:39.05844Z","iopub.status.idle":"2021-12-15T15:44:39.06526Z","shell.execute_reply.started":"2021-12-15T15:44:39.058407Z","shell.execute_reply":"2021-12-15T15:44:39.064396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import model_from_json","metadata":{"execution":{"iopub.status.busy":"2021-12-15T15:44:48.179237Z","iopub.execute_input":"2021-12-15T15:44:48.179716Z","iopub.status.idle":"2021-12-15T15:44:48.187471Z","shell.execute_reply.started":"2021-12-15T15:44:48.17965Z","shell.execute_reply":"2021-12-15T15:44:48.186202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# serialize model to JSON\nmodel_json = mobNet_classification.to_json()\nwith open(\"mobNet_classification.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmobNet_classification.save_weights(\"mobNet_classification.h5\")\nprint(\"Saved model to disk\")","metadata":{"execution":{"iopub.status.busy":"2021-12-15T15:45:24.997317Z","iopub.execute_input":"2021-12-15T15:45:24.997592Z","iopub.status.idle":"2021-12-15T15:45:25.625844Z","shell.execute_reply.started":"2021-12-15T15:45:24.997561Z","shell.execute_reply":"2021-12-15T15:45:25.624918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}