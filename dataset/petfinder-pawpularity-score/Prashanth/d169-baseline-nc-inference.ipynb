{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Library Imports","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from time import time\nnotebook_start_time = time()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:23.008249Z","iopub.execute_input":"2021-10-12T17:11:23.009159Z","iopub.status.idle":"2021-10-12T17:11:23.106439Z","shell.execute_reply.started":"2021-10-12T17:11:23.00889Z","shell.execute_reply":"2021-10-12T17:11:23.105517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport re\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader as DL\nfrom torch.nn.utils import weight_norm as WN\nfrom torchvision import models, transforms\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:23.108572Z","iopub.execute_input":"2021-10-12T17:11:23.108951Z","iopub.status.idle":"2021-10-12T17:11:29.069335Z","shell.execute_reply.started":"2021-10-12T17:11:23.108908Z","shell.execute_reply":"2021-10-12T17:11:29.06817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Constants and Utilities","metadata":{}},{"cell_type":"code","source":"SEED = 49\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nPATH = \"../input/petfinder-pawpularity-score\"\nPRETRAINED_WEIGHTS_PATH = \"../input/pretrained-model-weights-all\"\nTRAINED_ANN_WEIGHTS_PATH = \"../input/d169-baseline-nc-train\"\n\nMODEL_NAME = \"densenet169\"\nFEATURE_LENGTH = 1664\nNUM_FOLDS = len([name for name in os.listdir(TRAINED_ANN_WEIGHTS_PATH) if name[-2:] == \"pt\"])\n\nIMAGE_SIZE = 224\nTRANSFORM = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize([0.485, 0.456, 0.406],\n                                                     [0.229, 0.224, 0.225]),\n                                ])\n\nsc_y = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:29.073328Z","iopub.execute_input":"2021-10-12T17:11:29.073699Z","iopub.status.idle":"2021-10-12T17:11:29.141035Z","shell.execute_reply.started":"2021-10-12T17:11:29.073654Z","shell.execute_reply":"2021-10-12T17:11:29.140085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def breaker(num=50, char=\"*\") -> None:\n    print(\"\\n\" + num*char + \"\\n\")\n\n\ndef head(x, no_of_ele=5) -> None:\n    print(x[:no_of_ele])\n\n\ndef get_filenames_and_targets(path: str) -> tuple:\n    df = pd.read_csv(os.path.join(path, \"train.csv\"), engine=\"python\")\n    filenames = df.iloc[:, 0].copy().values\n    targets  = df.iloc[:, -1].copy().values\n    return filenames, targets\n\n\ndef get_filenames(path: str) -> np.ndarray:\n    df = pd.read_csv(os.path.join(path, \"test.csv\"), engine=\"python\")\n    filenames  = df[\"Id\"].copy().values\n    return filenames\n\n\ndef get_image(path: str, name: str, size: int) -> np.ndarray:\n    image = cv2.imread(os.path.join(path, name + \".jpg\"), cv2.IMREAD_COLOR)\n    image = cv2.cvtColor(src=image, code=cv2.COLOR_BGR2RGB)\n    image = cv2.resize(src=image, dsize=(size, size), interpolation=cv2.INTER_AREA)\n    return image\n\n\ndef make_submission(path: str, y_pred: np.ndarray) -> None:\n    submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"), engine=\"python\")\n    submission[\"Pawpularity\"] = y_pred\n    submission.to_csv(\"./submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:29.143899Z","iopub.execute_input":"2021-10-12T17:11:29.144236Z","iopub.status.idle":"2021-10-12T17:11:29.157006Z","shell.execute_reply.started":"2021-10-12T17:11:29.144194Z","shell.execute_reply":"2021-10-12T17:11:29.155913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Templates","metadata":{}},{"cell_type":"code","source":"class ImageDS(Dataset):\n    def __init__(self, base_path=None, filenames=None, image_size=None, transform=None):\n        self.base_path = base_path\n        self.filenames = filenames\n        self.image_size = image_size\n        self.transform = transform\n    \n    def __len__(self):\n        return self.filenames.shape[0]\n    \n    def __getitem__(self, idx):\n        image = get_image(self.base_path, self.filenames[idx], self.image_size)\n        return self.transform(image)\n\n    \nclass FeatureDS(Dataset):\n    def __init__(self, features=None):\n        self.features = features\n    \n    def __len__(self):\n        return self.features.shape[0]\n    \n    def __getitem__(self, idx):\n        return torch.FloatTensor(self.features[idx])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:29.158791Z","iopub.execute_input":"2021-10-12T17:11:29.159406Z","iopub.status.idle":"2021-10-12T17:11:29.174776Z","shell.execute_reply.started":"2021-10-12T17:11:29.159363Z","shell.execute_reply":"2021-10-12T17:11:29.173644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Models","metadata":{}},{"cell_type":"code","source":"def build_models(IL: int, pretrained: bool, seed: int):\n\n    class ImageModel(nn.Module):\n        def __init__(self, pretrained=False):\n            super(ImageModel, self).__init__()\n\n            self.features = models.densenet169(pretrained=pretrained, progress=True)\n            if pretrained:\n                self.freeze()\n            self.features = nn.Sequential(*[*self.features.children()][:-1])\n            self.features.add_module(\"Adaptive Average Pool\", nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n            self.features.add_module(\"Flatten\", nn.Flatten())\n\n        def freeze(self):\n            for params in self.parameters():\n                    params.requires_grad = False\n\n        def forward(self, x):\n            return self.features(x)\n    \n    torch.manual_seed(seed)\n    vision_model = ImageModel(pretrained=pretrained)\n    \n    \n    class ANN(nn.Module):\n        def __init__(self, IL=None):\n            super(ANN, self).__init__()\n\n            self.predictor = nn.Sequential()\n            self.predictor.add_module(\"BN\", nn.BatchNorm1d(num_features=IL, eps=1e-5))\n            self.predictor.add_module(\"FC\", WN(nn.Linear(in_features=IL, out_features=1)))\n\n        def get_optimizer(self, lr=1e-3, wd=0):\n            params = [p for p in self.parameters() if p.requires_grad]\n            return optim.Adam(params, lr=lr, weight_decay=wd)\n\n        def get_plateau_scheduler(self, optimizer=None, patience=5, eps=1e-8):\n            return optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=patience, eps=eps, verbose=True)\n\n        def forward(self, x1, x2=None):\n            if x2 is not None:\n                return self.predictor(x1), self.predictor(x2)\n            else:\n                return self.predictor(x1)\n    \n    torch.manual_seed(seed)\n    ann_model = ANN(IL=IL)\n    \n    return vision_model, ann_model","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:49.809987Z","iopub.execute_input":"2021-10-12T17:11:49.810275Z","iopub.status.idle":"2021-10-12T17:11:49.827552Z","shell.execute_reply.started":"2021-10-12T17:11:49.810247Z","shell.execute_reply":"2021-10-12T17:11:49.826549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Getter and Predict Helper","metadata":{}},{"cell_type":"code","source":"def get_features(model=None, dataloader=None, feature_length=None, path=None):\n    model.load_state_dict(torch.load(path, map_location=DEVICE))\n    model.to(DEVICE)\n    model.eval()\n\n    features = torch.zeros(1, feature_length).to(DEVICE)\n    for X in dataloader:\n        X = X.to(DEVICE)\n        with torch.no_grad():\n            output = model(X)\n        features = torch.cat((features, output.view(-1, feature_length)), dim=0)\n    \n    return features[1:].detach().cpu().numpy()\n\n\ndef predict_batch(model=None, dataloader=None, mode=\"test\", path=None):\n    model.load_state_dict(torch.load(path, map_location=DEVICE)[\"model_state_dict\"])\n    model.to(DEVICE)\n    model.eval()\n\n    y_pred = torch.zeros(1, 1).to(DEVICE)\n    if re.match(r\"valid\", mode, re.IGNORECASE):\n        for X, _ in dataloader:\n            X = X.to(DEVICE)\n            with torch.no_grad():\n                output = model(X)\n            y_pred = torch.cat((y_pred, output.view(-1, 1)), dim=0)\n    elif re.match(r\"test\", mode, re.IGNORECASE):\n        for X in dataloader:\n            X = X.to(DEVICE)\n            with torch.no_grad():\n                output = model(X)\n            y_pred = torch.cat((y_pred, output.view(-1, 1)), dim=0)\n    \n    return y_pred[1:].detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:50.129431Z","iopub.execute_input":"2021-10-12T17:11:50.130058Z","iopub.status.idle":"2021-10-12T17:11:50.145901Z","shell.execute_reply.started":"2021-10-12T17:11:50.130026Z","shell.execute_reply":"2021-10-12T17:11:50.144816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Submission","metadata":{}},{"cell_type":"code","source":"def submit():\n    ts_filenames = get_filenames(PATH)\n    filenames, targets = get_filenames_and_targets(PATH)\n    \n    VisionModel, ANNModel = build_models(IL=FEATURE_LENGTH, pretrained=False, seed=SEED)\n    \n    ts_image_data_setup = ImageDS(base_path=os.path.join(PATH, \"test\"), \n                                  filenames=ts_filenames, \n                                  image_size=IMAGE_SIZE, \n                                  transform=TRANSFORM)\n    ts_image_data = DL(ts_image_data_setup, batch_size=64, shuffle=False)\n    ts_features = get_features(model=VisionModel, dataloader=ts_image_data, \n                               feature_length=FEATURE_LENGTH, \n                               path=os.path.join(PRETRAINED_WEIGHTS_PATH, \"{}_state.pt\".format(MODEL_NAME)))\n    \n    breaker()\n    print(\"Making Predictions on Test Features ...\")\n    breaker()\n    \n    fold = 1\n    final_y_pred = np.zeros((len(ts_filenames), 1))\n    for tr_idx, va_idx in KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED).split(filenames):\n        print(\"Processing Fold {} ...\".format(fold))\n        \n        tr_targets = targets[tr_idx]\n        tr_targets = tr_targets.reshape(-1, 1)\n        tr_targets = sc_y.fit_transform(tr_targets)\n    \n        ts_feature_data_setup = FeatureDS(features=ts_features)\n        ts_feature_data = DL(ts_feature_data_setup, batch_size=512, shuffle=False)\n\n        y_pred = predict_batch(model=ANNModel, dataloader=ts_feature_data, mode=\"test\",\n                               path=os.path.join(TRAINED_ANN_WEIGHTS_PATH, \"Fold_{}_state.pt\".format(fold)))\n        y_pred = sc_y.inverse_transform(y_pred)\n        \n        final_y_pred += y_pred\n        fold += 1\n    \n    final_y_pred = final_y_pred / NUM_FOLDS\n    \n    breaker()\n    print(\"Generating Submission File ...\")\n    make_submission(PATH, final_y_pred)\n    breaker()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:50.45715Z","iopub.execute_input":"2021-10-12T17:11:50.458078Z","iopub.status.idle":"2021-10-12T17:11:50.470406Z","shell.execute_reply.started":"2021-10-12T17:11:50.458041Z","shell.execute_reply":"2021-10-12T17:11:50.469216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:50.664952Z","iopub.execute_input":"2021-10-12T17:11:50.665702Z","iopub.status.idle":"2021-10-12T17:11:51.916799Z","shell.execute_reply.started":"2021-10-12T17:11:50.665671Z","shell.execute_reply":"2021-10-12T17:11:51.914951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breaker()\nprint(\"Notebook Run Time : {:.2f} minutes\".format((time()-notebook_start_time)/60))\nbreaker()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:11:51.919073Z","iopub.execute_input":"2021-10-12T17:11:51.919703Z","iopub.status.idle":"2021-10-12T17:11:51.927346Z","shell.execute_reply.started":"2021-10-12T17:11:51.919645Z","shell.execute_reply":"2021-10-12T17:11:51.926212Z"},"trusted":true},"execution_count":null,"outputs":[]}]}