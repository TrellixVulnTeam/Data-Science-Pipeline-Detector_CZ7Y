{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nimport cv2\nfrom scipy.stats import stats\nimport matplotlib.image as mpimg\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.client import device_lib\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\n\ndef train_id_to_path(x):\n    return '../input/petfinder-pawpularity-score/train/' + x + \".jpg\"\n\n\ndef test_id_to_path(x):\n    return '../input/petfinder-pawpularity-score/test/' + x + \".jpg\"\n\n\nimage_height = 128\nimage_width = 128\n\n\n# define a function that accepts an image url and outputs an eager tensor\ndef path_to_eagertensor(image_path):\n    raw = tf.io.read_file(image_path)\n\n    image = tf.image.decode_jpeg(raw, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    # image = tf.image.resize_with_pad(image, image_height, image_width) #optional with padding to retain original dimensions\n    image = tf.image.resize(image, (image_height, image_width))\n    return image\n\n\ndef main():\n    tf.config.get_visible_devices()\n    if 'GPU' in str(device_lib.list_local_devices()):\n        config = tf.compat.v1.ConfigProto(device_count={'GPU': 0})\n        sess = tf.compat.v1.Session(config=config)\n\n    np.random.seed(1)\n    # Training settings\n    use_cuda = True  # Switch to False if you only want to use your CPU\n\n\n    # get the data\n    train = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\n    test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n    meta = train.drop(['Id', 'Pawpularity'], axis=1)\n    train[\"img_path\"] = train[\"Id\"].apply(train_id_to_path)\n    test[\"img_path\"] = test[\"Id\"].apply(test_id_to_path)\n    train['ten_bin_pawp'] = pd.qcut(train['Pawpularity'], q=10, labels=False)\n    train = train.astype({\"ten_bin_pawp\": str})\n    train10bin_stats = train.groupby('ten_bin_pawp')\n    # print(train10bin_stats.describe())\n    # print(train.head())\n\n    X = []\n    B = []\n    for img in train['img_path']:\n        new_img_tensor = path_to_eagertensor(img)\n\n        #pca for rgb image, reference from Iqbal Hussain\n        image = cv2.cvtColor(new_img_tensor.numpy(), cv2.COLOR_BGR2RGB)\n        blue, green, red = cv2.split(image)\n        df_blue = blue / 255\n        df_green = green / 255\n        df_red = red / 255\n        pca_b = PCA(n_components=75)\n        pca_b.fit(df_blue)\n        trans_pca_b = pca_b.transform(df_blue)\n        pca_g = PCA(n_components=75)\n        pca_g.fit(df_green)\n        trans_pca_g = pca_g.transform(df_green)\n        pca_r = PCA(n_components=75)\n        pca_r.fit(df_red)\n        trans_pca_r = pca_r.transform(df_red)\n        b_arr = pca_b.inverse_transform(trans_pca_b)\n        g_arr = pca_g.inverse_transform(trans_pca_g)\n        r_arr = pca_r.inverse_transform(trans_pca_r)\n        img_reduced = (cv2.merge((b_arr, g_arr, r_arr)))\n\n        # l=new_img_tensor.numpy().flatten()\n        # B.append(l)\n        X.append(img_reduced)\n\n    print(type(X), len(X))\n    X = np.array(X)\n    print(type(X), X.shape)\n\n    y = train['Pawpularity']\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7)\n    # x_train, x_test, y_train, y_test = train_test_split(meta, y, test_size=0.1, random_state=7)\n\n    X_submission = []\n    for img in test['img_path']:\n        new_img_tensor = path_to_eagertensor(img)\n        X_submission.append(new_img_tensor)\n\n    #print(type(X_submission), len(X_submission))\n    X_submission = np.array(X_submission)\n\n    # for logistic regression with image data\n    # clf = LogisticRegression(random_state=1,max_iter=200).fit(x_train, y_train)\n    # c=clf.predict(x_test)\n\n    # for logistic regression with meta data\n    # clf = LogisticRegression(random_state=1,max_iter=1000).fit(x_train, y_train)\n    # c=clf.predict(x_test)\n\n    # for random forest ensemble\n    # regr = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=20, max_features=\"sqrt\",max_samples=5000)\n    # regr.fit(x_train, y_train)\n    # c=regr.predict(x_test)\n\n    # for random forest ensemble with only metadata\n    \"\"\"regr = RandomForestRegressor(max_depth=8, random_state=0, n_estimators=100,max_features=\"sqrt\",max_samples=5000)\n    regr.fit(x_train, y_train)\n    c=regr.predict(x_test)\n\n    rms = mean_squared_error(y_test, c, squared=False)\n    print(rms)\n    scores = cross_val_score(regr,meta, y, cv=5,scoring=\"neg_root_mean_squared_error\")\n    print(scores)\"\"\"\n\n    x_traint, x_testt, y_traint, y_testt = train_test_split(x_train, y_train, test_size=0.11, random_state=7)\n\n    inputs = tf.keras.Input(shape=(image_height, image_width, 3))\n\n    x = inputs\n\n    x = tf.keras.layers.Conv2D(filters=16, kernel_size=(7, 7),  padding='valid',\n                               kernel_initializer='he_normal',  activation='relu')(x)\n    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5), padding='same', activation='relu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3),  padding='same',\n                               kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation='relu')(x)\n    #x = tf.keras.layers.BatchNormalization()(x)\n    #x = tf.keras.layers.Dropout(0.25)(x)\n    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same',\n                               kernel_regularizer=l2(0.0003), activation='relu')(x)\n    \"\"\"x = tf.keras.layers.BatchNormalization()(x)\"\"\"\n\n    #x = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3),kernel_regularizer=l2(0.0002), activation='relu')(x)\n    #x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n\n    output = tf.keras.layers.Dense(1)(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=output)\n    print(model.summary())\n\n    model.compile(\n        loss='mse',\n        optimizer='Adam',\n        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])\n\n    data_augmentation = ImageDataGenerator(\n        rotation_range=15,\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.1,\n        horizontal_flip=True,\n        fill_mode=\"nearest\")\n    cnnmodel = model.fit(\n        data_augmentation.flow(x_traint, y_traint, batch_size=32),\n        validation_data=(x_testt, y_testt),\n        steps_per_epoch=len(x_traint) // 32,\n        epochs=30\n    )\n\n    #print(cnnmodel.history[\"val_rmse\"])\n\n    cnn_pred = model.predict(x_test)\n    rms = mean_squared_error(y_test, cnn_pred, squared=False)\n    print(rms)\n\n    cnn_pred = model.predict(X_submission)\n    cnn = pd.DataFrame()\n    cnn['Id'] = test['Id']\n    cnn['Pawpularity'] = cnn_pred\n    cnn.to_csv('submission.csv', index=False)\n\nif __name__ == '__main__':\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-13T11:19:21.940196Z","iopub.execute_input":"2021-12-13T11:19:21.940587Z","iopub.status.idle":"2021-12-13T11:42:11.840077Z","shell.execute_reply.started":"2021-12-13T11:19:21.940497Z","shell.execute_reply":"2021-12-13T11:42:11.838652Z"},"trusted":true},"execution_count":null,"outputs":[]}]}