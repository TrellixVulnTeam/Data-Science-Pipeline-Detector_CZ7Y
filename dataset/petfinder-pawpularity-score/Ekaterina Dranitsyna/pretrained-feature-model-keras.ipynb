{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pretrained Image Model to Predict Pet Popularity","metadata":{}},{"cell_type":"markdown","source":"Pretrained **EfficientNetB0 model from Keras applications** is fine-tuned with small learning rate and used to extract features from images resized to 224 x 224. Popularity score is estimated based solely on images. Tabular data is ignored. Since image quality affects the target value only horizontal flip is used for data augmentation.","metadata":{}},{"cell_type":"code","source":"import os\nimport random\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-14T13:25:14.912322Z","iopub.execute_input":"2021-10-14T13:25:14.912916Z","iopub.status.idle":"2021-10-14T13:25:14.918539Z","shell.execute_reply.started":"2021-10-14T13:25:14.912878Z","shell.execute_reply":"2021-10-14T13:25:14.917831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tabular data file paths\nTRAIN_DATA_PATH = '../input/petfinder-pawpularity-score/train.csv'\nTEST_DATA_PATH = '../input/petfinder-pawpularity-score/test.csv'\n\n# Image data directories\nTRAIN_DIRECTORY = '../input/petfinder-pawpularity-score/train'\nTEST_DIRECTORY = '../input/petfinder-pawpularity-score/test'","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:14.925131Z","iopub.execute_input":"2021-10-14T13:25:14.926053Z","iopub.status.idle":"2021-10-14T13:25:14.930742Z","shell.execute_reply.started":"2021-10-14T13:25:14.926025Z","shell.execute_reply":"2021-10-14T13:25:14.92975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameters for processing tabular data\nTARGET_NAME = 'Pawpularity'\nVAL_SIZE = 0.15\nSEED = 5","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:14.93258Z","iopub.execute_input":"2021-10-14T13:25:14.933357Z","iopub.status.idle":"2021-10-14T13:25:14.940672Z","shell.execute_reply.started":"2021-10-14T13:25:14.933323Z","shell.execute_reply":"2021-10-14T13:25:14.939928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TensorFlow settings and training parameters\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 224\nBATCH_SIZE = 64\nDROPOUT_RATE = 0.2\nLEARNING_RATE = 1e-4\nDECAY_STEPS = 200\nDECAY_RATE = 0.96\nEPOCHS = 500\nPATIENCE = 3","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:14.943553Z","iopub.execute_input":"2021-10-14T13:25:14.943855Z","iopub.status.idle":"2021-10-14T13:25:14.950406Z","shell.execute_reply.started":"2021-10-14T13:25:14.943789Z","shell.execute_reply":"2021-10-14T13:25:14.949599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pretrained image classification model EfficientNetB4\n# from tf.keras.applications with global average pooling as a final layer.\n# In this notebook the model is loaded from a public dataset on Kaggle\n# at https://www.kaggle.com/ekaterinadranitsyna/keras-applications-models\nIMG_MODEL = '../input/keras-applications-models/EfficientNetB0.h5'","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:14.9519Z","iopub.execute_input":"2021-10-14T13:25:14.952174Z","iopub.status.idle":"2021-10-14T13:25:14.960262Z","shell.execute_reply.started":"2021-10-14T13:25:14.952141Z","shell.execute_reply":"2021-10-14T13:25:14.959435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=42):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef id_to_path(img_id: str, dir: str):\n    \"\"\"Function returns a path to an image file.\n    :param img_id: Image Id\n    :param dir: Path to the directory with images\n    :return: Image file path\n    \"\"\"\n    return os.path.join(dir, f'{img_id}.jpg')\n\n\n@tf.function\ndef get_image(path: str) -> tf.Tensor:\n    \"\"\"Function loads image from a file and preprocesses it.\n    :param path: Path to image file\n    :return: Tensor with preprocessed image\n    \"\"\"\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.int32)\n    return tf.keras.applications.efficientnet.preprocess_input(image)\n\n\n@tf.function\ndef process_dataset(path: str, label: int) -> tuple:\n    \"\"\"Function returns preprocessed image and label.\n    :param path: Path to image file\n    :param label: Class label\n    :return: tf.Tensor with preprocessed image, numeric label\n    \"\"\"\n    return get_image(path), label\n\n\n@tf.function\ndef get_dataset(x, y=None) -> tf.data.Dataset:\n    \"\"\"Function creates batched optimized dataset for the model\n    out of an array of file paths and (optionally) class labels.\n    :param x: Input data for the model (array of file paths)\n    :param y: Target values for the model (array of class indexes)\n    :return TensorFlow Dataset object\n    \"\"\"\n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        return ds.map(process_dataset, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses and metrics\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    rmse = hist.history['root_mean_squared_error']\n    val_rmse = hist.history['val_root_mean_squared_error']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(loss) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n\n    ax1.plot(x_axis, loss, 'bo', label='Training')\n    ax1.plot(x_axis, val_loss, 'ro', label='Validation')\n    ax1.set_title('MSE Loss')\n    ax1.legend()\n\n    ax2.plot(x_axis, rmse, 'bo', label='Training')\n    ax2.plot(x_axis, val_rmse, 'ro', label='Validation')\n    ax2.set_title('Root Mean Squared Error')\n    ax2.set_xlabel('Epochs')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:14.963338Z","iopub.execute_input":"2021-10-14T13:25:14.963544Z","iopub.status.idle":"2021-10-14T13:25:14.989336Z","shell.execute_reply.started":"2021-10-14T13:25:14.963516Z","shell.execute_reply":"2021-10-14T13:25:14.988584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Processing","metadata":{}},{"cell_type":"code","source":"set_seed(SEED)\nset_display()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:14.991026Z","iopub.execute_input":"2021-10-14T13:25:14.991343Z","iopub.status.idle":"2021-10-14T13:25:15.029817Z","shell.execute_reply.started":"2021-10-14T13:25:14.991308Z","shell.execute_reply":"2021-10-14T13:25:15.028935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train data set\ndata_train = pd.read_csv(TRAIN_DATA_PATH)\nprint(f'Train data shape: {data_train.shape}')\ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:15.031422Z","iopub.execute_input":"2021-10-14T13:25:15.031781Z","iopub.status.idle":"2021-10-14T13:25:15.072085Z","shell.execute_reply.started":"2021-10-14T13:25:15.031745Z","shell.execute_reply":"2021-10-14T13:25:15.071208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data set\ndata_test = pd.read_csv(TEST_DATA_PATH)\nprint(f'Test data shape: {data_test.shape}')\ndata_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:15.073516Z","iopub.execute_input":"2021-10-14T13:25:15.073789Z","iopub.status.idle":"2021-10-14T13:25:15.09367Z","shell.execute_reply.started":"2021-10-14T13:25:15.073744Z","shell.execute_reply":"2021-10-14T13:25:15.092991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reconstruct the paths to train and test images.\ndata_train['path'] = data_train['Id'].apply(\n    lambda x: id_to_path(x, TRAIN_DIRECTORY))\ndata_test['path'] = data_test['Id'].apply(\n    lambda x: id_to_path(x, TEST_DIRECTORY))\n\n# Keep a portion of the labeled data for validation.\ntrain_subset, valid_subset = train_test_split(\n    data_train[['path', TARGET_NAME]],\n    test_size=VAL_SIZE, shuffle=True, random_state=SEED\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:15.094905Z","iopub.execute_input":"2021-10-14T13:25:15.095309Z","iopub.status.idle":"2021-10-14T13:25:15.12958Z","shell.execute_reply.started":"2021-10-14T13:25:15.095275Z","shell.execute_reply":"2021-10-14T13:25:15.128949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create TensorFlow datasets\ntrain_ds = get_dataset(x=train_subset['path'], y=train_subset[TARGET_NAME])\nvalid_ds = get_dataset(x=valid_subset['path'], y=valid_subset[TARGET_NAME])\ntest_ds = get_dataset(x=data_test['path'])","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:15.130836Z","iopub.execute_input":"2021-10-14T13:25:15.131081Z","iopub.status.idle":"2021-10-14T13:25:15.494904Z","shell.execute_reply.started":"2021-10-14T13:25:15.13105Z","shell.execute_reply":"2021-10-14T13:25:15.494162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pretrained image classification model\nfeature_model = tf.keras.models.load_model(IMG_MODEL)\n\n# Make top layers trainable with the exception of BatchNormalization.\nfeature_model.trainable = False\nfor layer in feature_model.layers[-20:]:\n    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n        layer.trainable = True","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:15.497365Z","iopub.execute_input":"2021-10-14T13:25:15.497837Z","iopub.status.idle":"2021-10-14T13:25:17.740101Z","shell.execute_reply.started":"2021-10-14T13:25:15.497717Z","shell.execute_reply":"2021-10-14T13:25:17.739334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This model takes in 224 x 224 images, applies random horizontal flip\n# (only in the train mode), passes image arrays through pretrained\n# feature extraction model and applies batch normalization, dropout\n# and activations to get the target score.\nimage_model = tf.keras.models.Sequential(\n    [\n        tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n        feature_model,\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(DROPOUT_RATE, name='top_dropout'),\n        tf.keras.layers.Dense(32, activation='relu'),\n        tf.keras.layers.Dense(1, name='score')\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:17.743427Z","iopub.execute_input":"2021-10-14T13:25:17.743655Z","iopub.status.idle":"2021-10-14T13:25:18.351721Z","shell.execute_reply.started":"2021-10-14T13:25:17.743627Z","shell.execute_reply":"2021-10-14T13:25:18.35101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To gradually decrease learning rate\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=LEARNING_RATE,\n    decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n    staircase=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:18.353039Z","iopub.execute_input":"2021-10-14T13:25:18.353292Z","iopub.status.idle":"2021-10-14T13:25:18.359373Z","shell.execute_reply.started":"2021-10-14T13:25:18.353259Z","shell.execute_reply":"2021-10-14T13:25:18.358736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nimage_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n                    loss=tf.keras.losses.MeanSquaredError(),\n                    metrics=[tf.keras.metrics.RootMeanSquaredError()])","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:18.362381Z","iopub.execute_input":"2021-10-14T13:25:18.362646Z","iopub.status.idle":"2021-10-14T13:25:18.384181Z","shell.execute_reply.started":"2021-10-14T13:25:18.362611Z","shell.execute_reply":"2021-10-14T13:25:18.383579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:18.385412Z","iopub.execute_input":"2021-10-14T13:25:18.385664Z","iopub.status.idle":"2021-10-14T13:25:18.405296Z","shell.execute_reply.started":"2021-10-14T13:25:18.385634Z","shell.execute_reply":"2021-10-14T13:25:18.40453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To monitor validation loss and stop the training.\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=PATIENCE, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:25:18.406641Z","iopub.execute_input":"2021-10-14T13:25:18.406881Z","iopub.status.idle":"2021-10-14T13:25:18.411441Z","shell.execute_reply.started":"2021-10-14T13:25:18.40685Z","shell.execute_reply":"2021-10-14T13:25:18.41069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = image_model.fit(train_ds, validation_data=valid_ds,\n                          epochs=EPOCHS, callbacks=[early_stop],\n                          use_multiprocessing=True, workers=-1)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:30:12.932275Z","iopub.execute_input":"2021-10-14T13:30:12.932948Z","iopub.status.idle":"2021-10-14T13:30:46.954722Z","shell.execute_reply.started":"2021-10-14T13:30:12.932911Z","shell.execute_reply":"2021-10-14T13:30:46.953971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_mse, val_rmse = image_model.evaluate(valid_ds)\nprint(f'Validation MSE = {val_mse}\\nValidation RMSE = {val_rmse}')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:30:46.956631Z","iopub.execute_input":"2021-10-14T13:30:46.956881Z","iopub.status.idle":"2021-10-14T13:30:51.92019Z","shell.execute_reply.started":"2021-10-14T13:30:46.956848Z","shell.execute_reply":"2021-10-14T13:30:51.919149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:30:54.1613Z","iopub.execute_input":"2021-10-14T13:30:54.161841Z","iopub.status.idle":"2021-10-14T13:30:54.565878Z","shell.execute_reply.started":"2021-10-14T13:30:54.161807Z","shell.execute_reply":"2021-10-14T13:30:54.565235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_model.save_weights('img_model_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:31:42.493443Z","iopub.execute_input":"2021-10-14T13:31:42.493696Z","iopub.status.idle":"2021-10-14T13:31:42.689312Z","shell.execute_reply.started":"2021-10-14T13:31:42.493668Z","shell.execute_reply":"2021-10-14T13:31:42.688585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# Predict popularity score for the test\ndata_test[TARGET_NAME] = image_model.predict(\n    test_ds, use_multiprocessing=True, workers=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:31:45.098505Z","iopub.execute_input":"2021-10-14T13:31:45.09905Z","iopub.status.idle":"2021-10-14T13:31:46.509724Z","shell.execute_reply.started":"2021-10-14T13:31:45.099017Z","shell.execute_reply":"2021-10-14T13:31:46.508948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test[['Id', TARGET_NAME]].to_csv('submission.csv', index=False)\ndata_test[['Id', TARGET_NAME]].head()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T13:31:47.315168Z","iopub.execute_input":"2021-10-14T13:31:47.315846Z","iopub.status.idle":"2021-10-14T13:31:47.33247Z","shell.execute_reply.started":"2021-10-14T13:31:47.315813Z","shell.execute_reply":"2021-10-14T13:31:47.331694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}