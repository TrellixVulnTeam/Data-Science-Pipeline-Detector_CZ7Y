{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n## Understanding Pawpular Model\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-12T04:28:56.641126Z","iopub.execute_input":"2021-11-12T04:28:56.641445Z","iopub.status.idle":"2021-11-12T04:28:56.659715Z","shell.execute_reply.started":"2021-11-12T04:28:56.641364Z","shell.execute_reply":"2021-11-12T04:28:56.659074Z"}}},{"cell_type":"markdown","source":"### Pawpular model was first written by Abhisek Thakur.\n### Later I copied the model from Manyu Li (who orginally got it from Chris Deotte)\n\n### Link: https://www.kaggle.com/manyuli/rapids-svr-boost-17-8-pro?scriptVersionId=77613696","metadata":{}},{"cell_type":"markdown","source":"## Goal of this notebook: explain the Pawpular model code","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"# !pip install tez\n# !pip install timm","metadata":{"execution":{"iopub.status.busy":"2021-11-12T08:10:56.782131Z","iopub.execute_input":"2021-11-12T08:10:56.784328Z","iopub.status.idle":"2021-11-12T08:10:56.794031Z","shell.execute_reply.started":"2021-11-12T08:10:56.784177Z","shell.execute_reply":"2021-11-12T08:10:56.793424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# based on the post here: https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/275094\n\nimport sys\nsys.path.append(\"../input/tez-lib/\")\nsys.path.append(\"../input/timmmaster/\")\n\nimport tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport timm\nimport torch.nn as nn\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\nimport math\n\nclass args:\n    batch_size = 16\n    image_size = 384\n    \ndef sigmoid(x):\n    return 1 / (1 + math.exp(-x))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-12T05:59:18.399Z","iopub.execute_input":"2021-11-12T05:59:18.399337Z","iopub.status.idle":"2021-11-12T05:59:24.13241Z","shell.execute_reply.started":"2021-11-12T05:59:18.399302Z","shell.execute_reply":"2021-11-12T05:59:24.131442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pawpular Model","metadata":{}},{"cell_type":"code","source":"class PawpularDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }\n    \nclass PawpularModel(tez.Model):\n    def __init__(self, model_name):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n        self.model.head = nn.Linear(self.model.head.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(140, 64)\n        self.dense2 = nn.Linear(64, 1)\n\n    def forward(self, image, features, targets=None):\n        x1 = self.model(image)\n        x = self.dropout(x1)\n        x = torch.cat([x, features], dim=1)\n        x = self.dense1(x)\n        x = self.dense2(x)\n        \n        x = torch.cat([x, x1, features], dim=1)\n        return x, 0, {}\n    \n\ntest_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n        albumentations.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n        albumentations.RandomBrightnessContrast(p=0.5),\n        \n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T06:46:13.358881Z","iopub.execute_input":"2021-11-12T06:46:13.360005Z","iopub.status.idle":"2021-11-12T06:46:13.382138Z","shell.execute_reply.started":"2021-11-12T06:46:13.359949Z","shell.execute_reply":"2021-11-12T06:46:13.381245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Line by line Pawpular model","metadata":{}},{"cell_type":"code","source":"# Line 1\nclass PawpularModel(tez.Model):","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The first line we are defining a model class and notice instead of PawpularModel(), we are using PawpularModel(tez.Model). \n## This is because we want to inherit from tez.Model instead of nn.Module.\n## Note that nn.Module is base class for all neural network modules.","metadata":{}},{"cell_type":"code","source":"# Line 2 and 3\ndef __init__(self, model_name):\n        super().__init__()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The 2nd line - \"\\_\\_init\\_\\_\" is a reserved method in Python classes. The word 'self' is used to represent the instance of a class.\n## The 3rd line - super() has two use cases:\n### 1. allows us to avoid using base class explicitly 2. working with multiple inheritance (check reference 4 for examples)","metadata":{}},{"cell_type":"code","source":"# Line 4\nself.model = timm.create_model(model_name, pretrained=False, in_chans=3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The 4th line uses timm.create_model - \\'timm\\' is a deep-learning library created by Ross Wightman.\n## Quote from documentation - \\\" The create_model function is what is used to create hundreds of models inside timm. It also expects a bunch of **kwargs such as features_only and out_indices and passing these two **kwargs to the create_model function creates a feature extractor  instead.\\\"\n\n## You might be wondering what's \\\" in_chans = 3\\\" - this means 3- channel images or RGB. Each pixel is made up of three channels, with each channel representing a colour.","metadata":{}},{"cell_type":"code","source":"# Line 5\n self.model.head = nn.Linear(self.model.head.in_features, 128)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## What is nn.Linear? More importantly why self.model.head? \n## nn.Linear applies a linear transformation to the incoming data: $$ y = xA^T + b $$","metadata":{}},{"cell_type":"markdown","source":"## Let's understand self.model.head by adding print statements before and after\n## The output from print statements will be\n## Linear(in_features=1536, out_features=1000, bias=True) \n## Linear(in_features=1536, out_features=128, bias=True) \n## Essentially timm.create_model generates multiple models and \\\".head\\\" selects the first of those.","metadata":{}},{"cell_type":"code","source":"# Lines 6,7, and 8\nself.dropout = nn.Dropout(0.1)\nself.dense1 = nn.Linear(140, 64)\nself.dense2 = nn.Linear(64, 1)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T07:15:51.05015Z","iopub.execute_input":"2021-11-12T07:15:51.050426Z","iopub.status.idle":"2021-11-12T07:15:51.236468Z","shell.execute_reply.started":"2021-11-12T07:15:51.050398Z","shell.execute_reply":"2021-11-12T07:15:51.235484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Line 6 is dropout - drops some data and is an effective technique for regularization\n## Please see reference 7 for more info.\n## Line 7 is the first dense layer and 140 is sum of 128 (output of previous layer) + dense features (12) (140 explanation thanks to Harshit Mehta (https://www.kaggle.com/harshit92))","metadata":{}},{"cell_type":"code","source":"# forward block\ndef forward(self, image, features, targets=None):\n    x1 = self.model(image)\n    x = self.dropout(x1)\n    x = torch.cat([x, features], dim=1)\n    x = self.dense1(x)\n    x = self.dense2(x)\n\n    x = torch.cat([x, x1, features], dim=1)\n    return x, 0, {}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## In the forward pass block, we define how data flows from one layer to another inside the network.\n## torch.cat concatenates the given sequence of seq tensors in the given dimension.\n## dim = 1 means by column and dim = 0 is by row","metadata":{}},{"cell_type":"markdown","source":"# References:\n## 1. https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n## 2. https://github.com/abhishekkrthakur/tez\n## 3. https://www.tutorialspoint.com/What-is-difference-between-self-and-init-methods-in-python-Class\n## 4. https://www.programiz.com/python-programming/methods/built-in/super\n## 5. https://fastai.github.io/timmdocs/\n## 6. https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n## 7. https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n## 8. https://pytorch.org/docs/stable/generated/torch.cat.html","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}