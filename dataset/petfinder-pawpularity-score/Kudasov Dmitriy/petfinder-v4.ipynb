{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# n = 0\n# for dirname, _, filenames in os.walk('/kaggle/input/'):\n#     for filename in filenames:\n#         if dirname == '/kaggle/input/petfinder-pawpularity-score/test' or dirname == '/kaggle/input/petfinder-pawpularity-score/train':\n#             break\n#         else:\n#             print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-02T10:12:53.000869Z","iopub.execute_input":"2021-10-02T10:12:53.001504Z","iopub.status.idle":"2021-10-02T10:12:53.093276Z","shell.execute_reply.started":"2021-10-02T10:12:53.001406Z","shell.execute_reply":"2021-10-02T10:12:53.092367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdsd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb.init(project='PetFinder', entity='kudasov_dmitriy')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:12:53.095152Z","iopub.execute_input":"2021-10-02T10:12:53.095425Z","iopub.status.idle":"2021-10-02T10:13:10.795715Z","shell.execute_reply.started":"2021-10-02T10:12:53.095391Z","shell.execute_reply":"2021-10-02T10:13:10.794878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/timm-folder/\")","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:10.799744Z","iopub.execute_input":"2021-10-02T10:13:10.800165Z","iopub.status.idle":"2021-10-02T10:13:10.808153Z","shell.execute_reply.started":"2021-10-02T10:13:10.800124Z","shell.execute_reply":"2021-10-02T10:13:10.807494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\nTEST = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')\nSUB = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:10.816679Z","iopub.execute_input":"2021-10-02T10:13:10.817072Z","iopub.status.idle":"2021-10-02T10:13:10.873291Z","shell.execute_reply.started":"2021-10-02T10:13:10.817036Z","shell.execute_reply":"2021-10-02T10:13:10.87257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\n\nfrom tqdm.notebook import tqdm\n\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\n\nimport albumentations\nimport albumentations.pytorch\n\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.metrics import f1_score\n\nimport cv2\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:10.877229Z","iopub.execute_input":"2021-10-02T10:13:10.879118Z","iopub.status.idle":"2021-10-02T10:13:16.822387Z","shell.execute_reply.started":"2021-10-02T10:13:10.879076Z","shell.execute_reply":"2021-10-02T10:13:16.821695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sq = 10000000000\n# min_width = 0\n# min_height = 0\n# min_path = ''\n# scale = []\n# from PIL import Image\n# for i in tqdm(range(len(TRAIN['Id']))):\n#     path = '../input/petfinder-pawpularity-score/train/'+ TRAIN['Id'][i] + '.jpg'\n#     im = Image.open(path)\n#     (width, height) = im.size\n#     scale.append(width / height) \n#     if sq > width*height:\n#         sq = width*height\n#         min_width = width\n#         min_height = height\n#         min_path = path\n\n# print(f'Plosh - {sq}' + ' | ' + f'Min_width {min_width}' + ' | ' + f'Min_height {min_height}')\n# print(min_path)\n# print(sum(scale) / len(scale))","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:16.823664Z","iopub.execute_input":"2021-10-02T10:13:16.82391Z","iopub.status.idle":"2021-10-02T10:13:16.830441Z","shell.execute_reply.started":"2021-10-02T10:13:16.823877Z","shell.execute_reply":"2021-10-02T10:13:16.828569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x = cv2.imread('../input/dataset/train/train_images/1.jpg',cv2.IMREAD_COLOR)\nimg = Image.open('../input/petfinder-pawpularity-score/train/4388dabf50790924baa7fec88b192b02.jpg')\n# x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\nimg = img.resize((380, 380), Image.ANTIALIAS)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:16.831781Z","iopub.execute_input":"2021-10-02T10:13:16.832299Z","iopub.status.idle":"2021-10-02T10:13:16.864588Z","shell.execute_reply.started":"2021-10-02T10:13:16.832154Z","shell.execute_reply":"2021-10-02T10:13:16.859493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib import colors, cm, pyplot as plt\n\nimg=img \nplt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:16.868525Z","iopub.execute_input":"2021-10-02T10:13:16.868788Z","iopub.status.idle":"2021-10-02T10:13:17.262423Z","shell.execute_reply.started":"2021-10-02T10:13:16.868759Z","shell.execute_reply":"2021-10-02T10:13:17.26178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = Image.open('../input/petfinder-pawpularity-score/train/4388dabf50790924baa7fec88b192b02.jpg')\nimage = image.resize((380, 380), Image.ANTIALIAS)\n\nimage = np.asarray(image)\n# input_tensor[0] = input_tensor[0] / 255.0\n# input_tensor[1] = input_tensor[1] / 255.0\n# input_tensor[2] = input_tensor[2] / 255.0\npreprocess = albumentations.Compose([\n#     albumentations.CenterCrop(380, 380),\n#     albumentations.Transpose(p=0.5),\n#     albumentations.HorizontalFlip(p=0.5),\n#     albumentations.VerticalFlip(p=0.5),\n#     albumentations.ShiftScaleRotate(p=0.5),\n    albumentations.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225],\n    ),\n    albumentations.pytorch.transforms.ToTensorV2()\n])\ninput_tensor = preprocess(image = image)\n\nplt.imshow(input_tensor['image'].numpy().transpose())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.263836Z","iopub.execute_input":"2021-10-02T10:13:17.264273Z","iopub.status.idle":"2021-10-02T10:13:17.666888Z","shell.execute_reply.started":"2021-10-02T10:13:17.264239Z","shell.execute_reply":"2021-10-02T10:13:17.666209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\nTRAIN['path'] = TRAIN['Id'].apply(lambda x: \n                            str('../input/petfinder-pawpularity-score' \n                                + '/train/'\n                                + str(x)\n                               + '.jpg'))\n\nTEST = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\nTEST['path'] = TEST['Id'].apply(lambda x: \n                            str('../input/petfinder-pawpularity-score' \n                                + '/test/'\n                                + str(x) \n                               + '.jpg'))","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.669904Z","iopub.execute_input":"2021-10-02T10:13:17.670101Z","iopub.status.idle":"2021-10-02T10:13:17.711569Z","shell.execute_reply.started":"2021-10-02T10:13:17.670077Z","shell.execute_reply":"2021-10-02T10:13:17.71094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.712557Z","iopub.execute_input":"2021-10-02T10:13:17.713049Z","iopub.status.idle":"2021-10-02T10:13:17.720607Z","shell.execute_reply.started":"2021-10-02T10:13:17.71302Z","shell.execute_reply":"2021-10-02T10:13:17.719888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN = pd.concat((TRAIN, TRAIN.sample(8)), axis = 0).reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.722011Z","iopub.execute_input":"2021-10-02T10:13:17.722261Z","iopub.status.idle":"2021-10-02T10:13:17.735559Z","shell.execute_reply.started":"2021-10-02T10:13:17.722229Z","shell.execute_reply":"2021-10-02T10:13:17.734964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, annotations_file, img_path, transform=None, target_transform=None):\n        self.img_labels = annotations_file\n        self.img_path = img_path\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        \n        image = Image.open(self.img_path[idx])\n        \n        (width, height) = image.size\n           \n        mult = 380 / min(width, height)\n\n        new_width = int(round(mult*width,0))\n        new_height = int(round(mult*height,0))\n\n        image = image.resize((new_width, new_height), Image.ANTIALIAS)\n\n        image_num = np.asarray(image)\n\n        preprocess = albumentations.Compose([\n            albumentations.CenterCrop(380, 380),\n#             albumentations.Transpose(p=0.5),\n#             albumentations.HorizontalFlip(p=0.5),\n#             albumentations.VerticalFlip(p=0.5),\n#             albumentations.ShiftScaleRotate(p=0.5),\n#             albumentations.ColorJitter(brightness=0.2,\n#                                        contrast=0.2,\n#                                        saturation=0.2,\n#                                        hue=0.2,\n#                                        always_apply=False,\n#                                        p=0.5),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            albumentations.pytorch.transforms.ToTensorV2()\n        ])\n\n        \n        image = preprocess(image = image_num)\n        \n        label = self.img_labels[idx]\n        label = torch.tensor(label)\n            \n        return image['image'], label ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.736784Z","iopub.execute_input":"2021-10-02T10:13:17.737035Z","iopub.status.idle":"2021-10-02T10:13:17.74719Z","shell.execute_reply.started":"2021-10-02T10:13:17.737005Z","shell.execute_reply":"2021-10-02T10:13:17.746412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for featur, datas, targ in test_dataloader:\n#     print(featur.shape, datas.shape, targ.shape)\n#     break","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.748674Z","iopub.execute_input":"2021-10-02T10:13:17.748998Z","iopub.status.idle":"2021-10-02T10:13:17.758113Z","shell.execute_reply.started":"2021-10-02T10:13:17.748967Z","shell.execute_reply":"2021-10-02T10:13:17.757408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with torch.no_grad():\n#     pred = model(featur.to(device = device), datas.to(device = device))","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.75945Z","iopub.execute_input":"2021-10-02T10:13:17.759753Z","iopub.status.idle":"2021-10-02T10:13:17.766991Z","shell.execute_reply.started":"2021-10-02T10:13:17.75972Z","shell.execute_reply":"2021-10-02T10:13:17.766311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.768206Z","iopub.execute_input":"2021-10-02T10:13:17.76846Z","iopub.status.idle":"2021-10-02T10:13:17.775291Z","shell.execute_reply.started":"2021-10-02T10:13:17.768428Z","shell.execute_reply":"2021-10-02T10:13:17.77457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# criterion = torch.nn.MSELoss()\n# torch.sqrt(criterion(pred, targ.to(device = device)))","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.776714Z","iopub.execute_input":"2021-10-02T10:13:17.776988Z","iopub.status.idle":"2021-10-02T10:13:17.784137Z","shell.execute_reply.started":"2021-10-02T10:13:17.776954Z","shell.execute_reply":"2021-10-02T10:13:17.783407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.786489Z","iopub.execute_input":"2021-10-02T10:13:17.787119Z","iopub.status.idle":"2021-10-02T10:13:17.800197Z","shell.execute_reply.started":"2021-10-02T10:13:17.787069Z","shell.execute_reply":"2021-10-02T10:13:17.799329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.801453Z","iopub.execute_input":"2021-10-02T10:13:17.80178Z","iopub.status.idle":"2021-10-02T10:13:17.939286Z","shell.execute_reply.started":"2021-10-02T10:13:17.801749Z","shell.execute_reply":"2021-10-02T10:13:17.938501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.940715Z","iopub.execute_input":"2021-10-02T10:13:17.941014Z","iopub.status.idle":"2021-10-02T10:13:17.993919Z","shell.execute_reply.started":"2021-10-02T10:13:17.940979Z","shell.execute_reply":"2021-10-02T10:13:17.99306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:17.995269Z","iopub.execute_input":"2021-10-02T10:13:17.995526Z","iopub.status.idle":"2021-10-02T10:13:18.78693Z","shell.execute_reply.started":"2021-10-02T10:13:17.995494Z","shell.execute_reply":"2021-10-02T10:13:18.78351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class MyModel(nn.Module):\n#     def __init__(self):\n#         super(MyModel, self).__init__()\n#         self.cnn = timm.create_model(model_name='tf_efficientnet_b4_ns', pretrained=True)\n#         self.cnn.drop_rate = 0.4\n#         self.cnn.classifier = nn.Sequential(\n#             nn.Dropout(p=0.5, inplace=False),\n#             nn.Linear(in_features = 1792, out_features = 30))    \n        \n#         self.fc1 = nn.Linear(30 + 12, 60)\n#         self.fc2 = nn.Linear(60, 1)\n        \n#     def forward(self, image, data):\n#         x1 = self.cnn(image)\n#         x2 = data\n        \n#         x = torch.cat((x1, x2), dim=1)\n#         x = nn.functional.relu(self.fc1(x))\n#         x = self.fc2(x)\n#         return x\n        \nmodel = timm.create_model(model_name='tf_efficientnet_b4_ns', pretrained=True)\nmodel.drop_rate = 0.4\nmodel.classifier = nn.Sequential(\n            nn.Linear(in_features = 1792, out_features = 1))\n\n# model.load_state_dict(torch.load('../input/pet-eff-b4/efficientnet_b4.pt'))\nmodel.to(device = device)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:18.79101Z","iopub.execute_input":"2021-10-02T10:13:18.791563Z","iopub.status.idle":"2021-10-02T10:13:25.583221Z","shell.execute_reply.started":"2021-10-02T10:13:18.791532Z","shell.execute_reply":"2021-10-02T10:13:25.582528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:25.5845Z","iopub.execute_input":"2021-10-02T10:13:25.584955Z","iopub.status.idle":"2021-10-02T10:13:25.589872Z","shell.execute_reply.started":"2021-10-02T10:13:25.584917Z","shell.execute_reply":"2021-10-02T10:13:25.589151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, batch_size, n_epochs):\n    \n    best_result = {'epoch':0, 'valid_loss': 1000, 'train_loss': 1000}\n    \n    # to track the training loss as the model trains\n    train_losses = []\n    # to track the validation loss as the model trains\n    valid_losses = []\n    # to track the average training loss per epoch as the model trains\n    avg_train_losses = []\n    # to track the average validation loss per epoch as the model trains\n    avg_valid_losses = [] \n\n    \n    \n    for epoch in tqdm(range(1, n_epochs + 1)):\n\n        ###################\n        # train the model #\n        ###################\n        wandb.watch(model)\n        model.train() # prep model for training\n        for batch, (image, target) in enumerate(train_dataloader, 1):\n            # clear the gradients of all optimized variables\n            image = image.to(device=device)\n            target = target.to(device=device)\n            \n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(image)\n            # calculate the loss\n            loss = criterion(output.squeeze(), target.float())\n            loss = loss\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # record training loss\n            train_losses.append(loss.item())\n            \n            if batch % 2000 == 0:\n                print(f'{batch / 100 * 100} batches done')\n            \n            del image\n            del output\n            del target\n            torch.cuda.empty_cache()\n            \n        ######################    \n        # validate the model #\n        ######################\n        model.eval() # prep model for evaluation\n\n        for image, target in test_dataloader:\n            image = image.to(device=device)\n            target = target.to(device=device)\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(image)\n            # calculate the loss\n            loss = criterion(output.squeeze(), target.float())\n            # record validation loss\n            valid_losses.append(loss.item())\n            \n\n            del image\n            del output\n            del target\n            torch.cuda.empty_cache()\n        \n\n        # print training/validation statistics \n        # calculate average loss over an epoch\n        train_loss = np.average(train_losses)\n        valid_loss = np.average(valid_losses)\n#         f1_glob_f = np.average(f1_glob)\n        avg_train_losses.append(train_loss)\n        avg_valid_losses.append(valid_loss)\n#         av_f1_glob.append(f1_glob_f)\n        \n        if best_result['valid_loss'] > valid_loss:\n            best_result['valid_loss'] = valid_loss\n            best_result['train_loss'] = train_loss\n            best_result['epoch'] = epoch\n            torch.save(model.state_dict(), 'checkpoint.pt')\n        \n        scheduler.step(valid_loss)\n        \n        epoch_len = len(str(n_epochs))\n        \n#         wandb.log(\n#             {\n#         \"Train_loss\": train_loss,\n#         \"Val Loss\": valid_loss,\n#         \"Test Accuracy\": 100. * correct / len(test_dataloader.dataset)\n#             })\n        print(\n            f\"Train_loss - {train_loss} | \" + \n            f\"Val Loss - {valid_loss}\"\n        )\n        wandb.log({\"train_loss\": train_loss, 'valid_loss': valid_loss})\n            # clear lists to track next epoch\n        train_losses = []\n        valid_losses = []\n        \n    model.load_state_dict(torch.load('checkpoint.pt'))\n\n    return  model, avg_train_losses, avg_valid_losses, best_result","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:25.591193Z","iopub.execute_input":"2021-10-02T10:13:25.59162Z","iopub.status.idle":"2021-10-02T10:13:25.608098Z","shell.execute_reply.started":"2021-10-02T10:13:25.591567Z","shell.execute_reply":"2021-10-02T10:13:25.607356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = wandb.config\nconfig.learning_rate = 1e-4\nconfig.weight_decay = 1e-6\nconfig.n_epochs = 4\nconfig.batch_size = 4\nconfig.loss = 'MSELoss'\nconfig.model = 'tf_efficientnet_b4_ns'\nconfig.optim = 'ReduceLROnPlateau'\nconfig.factor = 0.2\nconfig.patience = 5\nconfig.eps = 1e-6\nconfig.CenterCrop = 380\nconfig.Normalize_mean = 0.456\nconfig.Normalize_std = 0.224\n\nbatch_size = 4\nn_epochs = 4\n\nX = TRAIN.drop(['Id','Pawpularity', 'index'], axis = 1)\ny = TRAIN['Pawpularity']\n\nskf = KFold(n_splits=5, shuffle=True)\nskf.get_n_splits(X, y)\n\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr= 1e-4, weight_decay = 1e-6)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5, eps=1e-6)\n\nfor train_index, test_index in skf.split(X, y):\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n\n    train_loader = CustomImageDataset(y_train.values ,X_train['path'].values)\n    test_loader = CustomImageDataset(y_test.values ,X_test['path'].values)\n\n    train_dataloader = DataLoader(train_loader, \n                                  batch_size=batch_size, \n                                  shuffle=True, \n                                  num_workers = 4, \n                                  pin_memory=True)\n    test_dataloader = DataLoader(test_loader, \n                                 batch_size=batch_size, \n                                 shuffle=True, \n                                 num_workers = 4, \n                                 pin_memory=True)\n\n\n\n    model, train_loss, valid_loss, best_result = train_model(model,\n                                                             batch_size = batch_size, \n                                                             n_epochs = n_epochs)\n    del train_dataloader\n    del test_dataloader\n    del train_loader\n    del test_loader\n    torch.cuda.empty_cache()\n    \n    \n    \n# checkpoint = {'model': MyModel(),\n#           'state_dict': model.state_dict(),\n#           'optimizer' : optimizer.state_dict()}\n\n# torch.save(checkpoint, 'Pet_eff_b4.pth')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:13:25.609521Z","iopub.execute_input":"2021-10-02T10:13:25.609887Z","iopub.status.idle":"2021-10-02T14:15:21.611243Z","shell.execute_reply.started":"2021-10-02T10:13:25.609854Z","shell.execute_reply":"2021-10-02T14:15:21.610439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdsd","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:15:21.612949Z","iopub.execute_input":"2021-10-02T14:15:21.613468Z","iopub.status.idle":"2021-10-02T14:15:22.179075Z","shell.execute_reply.started":"2021-10-02T14:15:21.61343Z","shell.execute_reply":"2021-10-02T14:15:22.177699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset_test(Dataset):\n    def __init__(self, img_path, add_data, transform=None, target_transform=None):\n        self.img_path = img_path\n        self.add_data = add_data\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_path)\n\n    def __getitem__(self, idx):\n        \n        image = Image.open(self.img_path[idx])\n        \n        (width, height) = image.size\n           \n        mult = 380 / min(width, height)\n\n        new_width = int(round(mult*width,0))\n        new_height = int(round(mult*height,0))\n\n        image = image.resize((new_width, new_height), Image.ANTIALIAS)\n\n        image_num = np.asarray(image)\n\n        preprocess = albumentations.Compose([\n            albumentations.CenterCrop(380, 380),\n#             albumentations.Transpose(p=0.5),\n#             albumentations.HorizontalFlip(p=0.5),\n#             albumentations.VerticalFlip(p=0.5),\n#             albumentations.ShiftScaleRotate(p=0.5),\n#             albumentations.ColorJitter(brightness=0.2,\n#                                        contrast=0.2,\n#                                        saturation=0.2,\n#                                        hue=0.2,\n#                                        always_apply=False,\n#                                        p=0.5),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            albumentations.pytorch.transforms.ToTensorV2()\n        ])\n\n        \n        image = preprocess(image = image_num)\n        \n        add_data = self.add_data[idx]\n        add_data = torch.tensor(add_data)\n            \n        return image['image'], add_data","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:25:33.92538Z","iopub.execute_input":"2021-10-02T14:25:33.925655Z","iopub.status.idle":"2021-10-02T14:25:33.938016Z","shell.execute_reply.started":"2021-10-02T14:25:33.925613Z","shell.execute_reply":"2021-10-02T14:25:33.936937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 1    \n    \ntest_loader = CustomImageDataset_test(TEST['path'].values, TEST.drop(['path', 'Id'], axis = 1).values)\ntest_dataloader = DataLoader(test_loader, batch_size=batch_size, num_workers = 4, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:15:22.182414Z","iopub.status.idle":"2021-10-02T14:15:22.183066Z","shell.execute_reply.started":"2021-10-02T14:15:22.182825Z","shell.execute_reply":"2021-10-02T14:15:22.182848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n    \nfinal_targets = []\nfinal_outputs = []\n    \nwith torch.no_grad():\n        \n    for image, data in tqdm(test_dataloader, position=0, leave=True, desc='Evaluating'):\n        \n        image = image.to(device=device)\n        data = data.to(device=device)\n            \n        output = model(image, data)\n            \n        final_outputs.extend(output.cpu().numpy().tolist())\n        del image\n        del output\n        torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:15:22.184279Z","iopub.status.idle":"2021-10-02T14:15:22.184926Z","shell.execute_reply.started":"2021-10-02T14:15:22.18469Z","shell.execute_reply":"2021-10-02T14:15:22.184713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = final_outputs","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:15:22.186103Z","iopub.status.idle":"2021-10-02T14:15:22.18674Z","shell.execute_reply.started":"2021-10-02T14:15:22.186474Z","shell.execute_reply":"2021-10-02T14:15:22.186496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:15:22.193143Z","iopub.status.idle":"2021-10-02T14:15:22.193784Z","shell.execute_reply.started":"2021-10-02T14:15:22.193516Z","shell.execute_reply":"2021-10-02T14:15:22.193537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(res, columns = ['Pawpularity'])\nsubmission = pd.concat([SUB['Id'], submission], axis=1) \nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:15:22.194905Z","iopub.status.idle":"2021-10-02T14:15:22.195495Z","shell.execute_reply.started":"2021-10-02T14:15:22.195268Z","shell.execute_reply":"2021-10-02T14:15:22.19529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T14:15:22.196624Z","iopub.status.idle":"2021-10-02T14:15:22.197236Z","shell.execute_reply.started":"2021-10-02T14:15:22.197008Z","shell.execute_reply":"2021-10-02T14:15:22.19703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}