{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/gradcam131/grad-cam-1.3.1/\")\nsys.path.append(\"../input/ttach-kaggle/\")\nsys.path.append(\"../input/timmmaster/\")\nsys.path.append(\"../input/bbbbox/\")\nsys.path.append(\"../input/pytorchlighting/\")\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:25:15.151447Z","iopub.execute_input":"2021-12-02T16:25:15.151813Z","iopub.status.idle":"2021-12-02T16:25:15.186457Z","shell.execute_reply.started":"2021-12-02T16:25:15.151722Z","shell.execute_reply":"2021-12-02T16:25:15.185528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom box import Box\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset\nfrom pytorch_grad_cam import GradCAMPlusPlus\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule\n\n\nwarnings.filterwarnings(\"ignore\")\n\nconfig = {'seed': 2021,\n          'root': '../input/petfinder-pawpularity-score/',\n          'n_splits': 10,\n          'epoch': 20,\n          'trainer': {\n              'gpus': 1,\n              'accumulate_grad_batches': 1,\n              'progress_bar_refresh_rate': 1,\n              'fast_dev_run': False,\n              'num_sanity_val_steps': 0,\n              'resume_from_checkpoint': None,\n          },\n          'transform':{\n              'name': 'get_default_transforms',\n              'image_size': 224\n          },\n          'train_loader':{\n              'batch_size': 64,\n              'shuffle': True,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': True,\n          },\n          'val_loader': {\n              'batch_size': 64,\n              'shuffle': False,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': False\n         },\n          'test_loader': {\n              'batch_size': 64,\n              'shuffle': False,\n              'num_workers': 4,\n              'pin_memory': False,\n              'drop_last': False\n         },\n          'model':{\n              'name': 'swin_tiny_patch4_window7_224',\n              'output_dim': 1\n          },\n          'optimizer':{\n              'name': 'optim.AdamW',\n              'params':{\n                  'lr': 1e-5\n              },\n          },\n          'scheduler':{\n              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n              'params':{\n                  'T_0': 20,\n                  'eta_min': 1e-4,\n              }\n          },\n          'loss': 'nn.BCEWithLogitsLoss',\n}\nfinal_predictions = []\nconfig = Box(config)\n\nclass PetfinderDataset(Dataset):\n    def __init__(self, df, image_size=224):\n        self._X = df[\"Id\"].values\n        self._y = None\n        if \"Pawpularity\" in df.keys():\n            self._y = df[\"Pawpularity\"].values\n        self._transform = T.Resize([image_size, image_size])\n\n    def __len__(self):\n        return len(self._X)\n\n    def __getitem__(self, idx):\n        image_path = self._X[idx]\n        image = read_image(image_path)\n        image = self._transform(image)\n        if self._y is not None:\n            label = self._y[idx]\n            return image, label\n        return image\n\nclass PetfinderDataModule(LightningDataModule):\n    def __init__(\n        self,\n        train_df,\n        val_df,\n        test_df,\n        cfg,\n    ):\n        super().__init__()\n        self._train_df = train_df\n        self._val_df = val_df\n        self._test_df = test_df\n        self._cfg = cfg\n\n    def __create_dataset(self, train=False,val=False,test=True):\n        if train:\n            return PetfinderDataset(self._train_df, self._cfg.transform.image_size)\n        if val:\n            return PetfinderDataset(self._val_df, self._cfg.transform.image_size)\n        if test:\n            return PetfinderDataset(self._test_df, self._cfg.transform.image_size)\n\n    def train_dataloader(self):\n        dataset = self.__create_dataset(True)\n        return DataLoader(dataset, **self._cfg.train_loader)\n\n    def val_dataloader(self):\n        dataset = self.__create_dataset(False)\n        return DataLoader(dataset, **self._cfg.val_loader)\n    def test_dataloader(self):\n        dataset = self.__create_dataset(False)\n        return DataLoader(dataset, **self._cfg.test_loader)\n\ntorch.autograd.set_detect_anomaly(True)\nseed_everything(config.seed)\n\n\nIMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\n\ndef get_default_transforms():\n    transform = {\n        \"train\": T.Compose(\n            [\n                T.RandomHorizontalFlip(),\n                T.RandomVerticalFlip(),\n                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n        \"val\": T.Compose(\n            [\n                T.ConvertImageDtype(torch.float),\n                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n            ]\n        ),\n    }\n    return transform\n\n\ndef mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n    assert alpha > 0, \"alpha should be larger than 0\"\n    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n\n    lam = np.random.beta(alpha, alpha)\n    rand_index = torch.randperm(x.size()[0])\n    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n    target_a, target_b = y, y[rand_index]\n    return mixed_x, target_a, target_b, lam\nfinal_predictions_pre =[]\n\nclass Model(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.__build_model()\n        self._criterion = eval(self.cfg.loss)()\n        self.transform = get_default_transforms()\n        self.save_hyperparameters(cfg)\n\n    def __build_model(self):\n        self.backbone = create_model(\n            self.cfg.model.name, pretrained=False, num_classes=0, in_chans=3\n        )\n        num_features = self.backbone.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features, self.cfg.model.output_dim)\n        )\n\n    def forward(self, x):\n        f = self.backbone(x)\n        out = self.fc(f)\n        return out\n\n    def training_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'train')\n        return {'loss': loss, 'pred': pred, 'labels': labels}\n\n    def validation_step(self, batch, batch_idx):\n        loss, pred, labels = self.__share_step(batch, 'val')\n        return {'pred': pred, 'labels': labels}\n\n    def test_step(self, batch, batch_idx):\n        images = self.transform[\"val\"](batch)\n        logits = self.forward(images).squeeze(1)\n        pred = logits.sigmoid().detach().cpu() * 100.\n        final_predictions.append(pred)\n        return pred\n\n    def __share_step(self, batch, mode):\n        images, labels = batch\n        labels = labels.float() / 100.0\n        images = self.transform[mode](images)\n\n        if torch.rand(1)[0] < 0.5 and mode == 'train':\n            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n            logits = self.forward(mix_images).squeeze(1)\n            loss = self._criterion(logits, target_a) * lam + \\\n                   (1 - lam) * self._criterion(logits, target_b)\n        else:\n            logits = self.forward(images).squeeze(1)\n            loss = self._criterion(logits, labels)\n\n        pred = logits.sigmoid().detach().cpu() * 100.\n        labels = labels.detach().cpu() * 100.\n        return loss, pred, labels\n\n    def training_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'train')\n\n    def validation_epoch_end(self, outputs):\n        self.__share_epoch_end(outputs, 'val')\n\n    def __share_epoch_end(self, outputs, mode):\n        preds = []\n        labels = []\n        for out in outputs:\n            pred, label = out['pred'], out['labels']\n            preds.append(pred)\n            labels.append(label)\n        preds = torch.cat(preds)\n        labels = torch.cat(labels)\n        metrics = torch.sqrt(((labels - preds) ** 2).mean())\n        self.log(f'{mode}_loss', metrics)\n\n    def check_gradcam(self, dataloader, target_layer, target_category, reshape_transform=None):\n        cam = GradCAMPlusPlus(\n            model=self,\n            target_layer=target_layer,\n            use_cuda=self.cfg.trainer.gpus,\n            reshape_transform=reshape_transform)\n\n        org_images, labels = iter(dataloader).next()\n        cam.batch_size = len(org_images)\n        images = self.transform['val'](org_images)\n        images = images.to(self.device)\n        logits = self.forward(images).squeeze(1)\n        pred = logits.sigmoid().detach().cpu().numpy() * 100\n        labels = labels.cpu().numpy()\n\n        grayscale_cam = cam(input_tensor=images, target_category=target_category, eigen_smooth=True)\n        org_images = org_images.detach().cpu().numpy().transpose(0, 2, 3, 1) / 255.\n        return org_images, grayscale_cam, pred, labels\n\n    def configure_optimizers(self):\n        optimizer = eval(self.cfg.optimizer.name)(\n            self.parameters(), **self.cfg.optimizer.params\n        )\n        scheduler = eval(self.cfg.scheduler.name)(\n            optimizer,\n            **self.cfg.scheduler.params\n        )\n        return [optimizer], [scheduler]\n\n\nskf = StratifiedKFold(\n    n_splits=config.n_splits, shuffle=True, random_state=config.seed\n)\ndf = pd.read_csv(os.path.join(config.root, \"test.csv\"))\ndf[\"Id\"] = df[\"Id\"].apply(lambda x: os.path.join(config.root, \"test\", x + \".jpg\"))\nfor fold in range(10):\n    print(fold)\n    datamodule = PetfinderDataModule(train_df=None, val_df=None, test_df=df,cfg=config)\n    checkpoint_dir = '../input/swint224/model_f'+str(fold)+'.ckpt'\n    checkpoint = torch.load(checkpoint_dir)\n    model_infer = Model(config)\n    trainer = pl.Trainer()\n    trainer.test(model_infer,ckpt_path=checkpoint_dir,datamodule=datamodule)\nfinal_predictions = np.mean(np.column_stack(final_predictions),axis=1)\ndf[\"Pawpularity\"] = final_predictions\ndf = df[[\"Id\",\"Pawpularity\"]]\ndf.to_csv(\"submission.csv\",index=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-02T16:25:15.401507Z","iopub.execute_input":"2021-12-02T16:25:15.401793Z","iopub.status.idle":"2021-12-02T16:26:38.616681Z","shell.execute_reply.started":"2021-12-02T16:25:15.401761Z","shell.execute_reply":"2021-12-02T16:26:38.615013Z"},"trusted":true},"execution_count":null,"outputs":[]}]}