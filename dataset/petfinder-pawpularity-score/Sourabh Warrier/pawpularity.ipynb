{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n#@author sourabhwarrier 2022\n#   IMPORTS BEGIN\nimport pickle\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom random import random, shuffle\n#import matplotlib.pyplot as plt\nfrom tensorflow.keras import layers, Model, utils, optimizers\nimport tensorflow as tf\n#   IMPORTS END\n\n#   PREPROCESSOR STAGE BEGIN\ndims = (128,128)\ncolor = 1\nmtype = \"CNN\"\ncolorflag = \"color\" if color else \"gray\"\ndef imgage_tensor(filepath,dims):\n    if colorflag == \"gray\":   \n        image = cv2.cvtColor(cv2.resize(cv2.imread(filepath),dims),cv2.COLOR_BGR2GRAY)\n    else:\n        image = cv2.resize(cv2.imread(filepath),dims)\n    img_data = np.array(image)    \n    return img_data\n\n#def build_train_tensor(dims,ftype):\n#    meta = pd.read_csv(\"/kaggle/input/petfinder-pawpularity-score/{}.csv\".format(ftype))\n#    data_tensor = []\n#    size = meta.shape[0]\n#    for i in range(size):\n#        try:\n#            img_data = imgage_tensor(\"/kaggle/input/petfinder-pawpularity-score/{}/{}.jpg\".format(ftype,meta.iloc[i][0]),dims = dims)\n#            pawpularity = float(meta.iloc[i][13])\n#            #metadata = np.array([meta.iloc[i][1],meta.iloc[i][2],meta.iloc[i][3],meta.iloc[i][4],meta.iloc[i][5],meta.iloc[i][6],meta.iloc[i][7],meta.iloc[i][8],meta.iloc[i][9],meta.iloc[i][10],meta.iloc[i][11],meta.iloc[i][12]])\n#            data_tensor.append((img_data/255,pawpularity/100))\n#            if i%100 == 1:\n#               print(\"processed images : {}\".format(i-1))\n#        except:\n#            pass\n#    shuffle(data_tensor)\n#    return data_tensor\n\ndef build_test_tensor(dims,ftype):\n    meta = pd.read_csv(\"/kaggle/input/petfinder-pawpularity-score/{}.csv\".format(ftype))\n    data_tensor = []\n    size = meta.shape[0]\n    for i in range(size):\n        try:\n            Id = str(meta.iloc[i][0])\n            img_data = imgage_tensor(\"/kaggle/input/petfinder-pawpularity-score/{}/{}.jpg\".format(ftype,meta.iloc[i][0]),dims = dims)\n            data_tensor.append((Id,img_data/255))\n            if i%100 == 1:\n                print(\"processed images : {}\".format(i-1))\n        except:\n            pass\n    return data_tensor\ntry:\n    #with open('{}_train_tensor_{}.pickle'.format(colorflag,str(dims[0])), 'rb') as handle:\n    #    train_tensor = pickle.load(handle)\n    with open('{}_test_tensor_{}.pickle'.format(colorflag,str(dims[0])), 'rb') as handle:\n        test_tensor = pickle.load(handle)\n    #with open('{}_final_test_tensor_{}.pickle'.format(colorflag,str(dims[0])), 'rb') as handle:\n    #    final_test_tensor = pickle.load(handle)\n    print(\"tensors found : will skip preprocessing stage\")\nexcept FileNotFoundError:\n    print(\"tensors not found : starting preprocessing\")\n    #data_tensor = build_train_tensor(dims,\"train\")\n    test_tensor = build_test_tensor(dims,\"test\")\n    #train_tensor,final_test_tensor = data_tensor[:7212],data_tensor[7212:]\n    #with open('{}_train_tensor_{}.pickle'.format(colorflag,str(dims[0])), 'wb') as handle:\n    #    pickle.dump(train_tensor, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    with open('{}_test_tensor_{}.pickle'.format(colorflag,str(dims[0])), 'wb') as handle:\n        pickle.dump(test_tensor, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    #with open('{}_final_test_tensor_{}.pickle'.format(colorflag,str(dims[0])), 'wb') as handle:\n    #    pickle.dump(final_test_tensor, handle, protocol=pickle.HIGHEST_PROTOCOL)\n#   PREPROCESSOR STAGE END\n\n#   MODEL TRAIN BEGIN\ntry:\n    if mtype == \"DNN\":\n        model = tf.keras.models.load_model('dnmodel{}{}.h5'.format(colorflag,dims[0]))\n    else:\n        model = tf.keras.models.load_model('/kaggle/input/pawpularity-cnn/cnnmodel{}{}.h5'.format(colorflag,dims[0]))\n    print(\"model found : will skip to predictions\")\nexcept:\n    print(\"model not found : will train first and then predict\")\n    initializer = tf.keras.initializers.GlorotNormal()\n    if mtype == \"DNN\":\n        model = tf.keras.Sequential([\n            tf.keras.layers.Flatten(input_shape=(dims[0], dims[0],3)),\n            #tf.keras.layers.Dense(2048, activation='relu',kernel_initializer=initializer),\n            tf.keras.layers.Dense(256, activation='relu',kernel_initializer=initializer),\n            tf.keras.layers.Dense(128, activation='relu',kernel_initializer=initializer),\n            tf.keras.layers.Dense(64, activation='relu',kernel_initializer=initializer),\n            tf.keras.layers.Dense(64, activation='relu',kernel_initializer=initializer),\n            tf.keras.layers.Dense(32, activation='relu',kernel_initializer=initializer),\n            tf.keras.layers.Dense(1)\n        ])\n    else:\n        model = tf.keras.Sequential()\n        #model.add(Dense(256, activation='relu', input_dim=366))\n        model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape = (dims[0], dims[0],3)))\n        #model.add(Conv2D(128, (3, 3), activation='relu'))\n        #model.add(Conv2D(64, (3, 3), init='uniform'))\n\n        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n        model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n        model.add(tf.keras.layers.Flatten())\n\n        model.add(tf.keras.layers.Dense(128, activation='relu'))\n        model.add(tf.keras.layers.Dropout(0.1))\n\n        model.add(tf.keras.layers.Dense(64, activation='relu'))\n        model.add(tf.keras.layers.Dropout(0.1))\n        model.add(tf.keras.layers.Dense(32, activation='relu'))\n\n        model.add(tf.keras.layers.Dense(1, activation='linear'))\n\n    x_train,y_train = np.array([x[0] for x in train_tensor]),np.array([x[1] for x in train_tensor])\n    x_final_test,y_final_test = np.array([x[0] for x in final_test_tensor]),np.array([x[1] for x in final_test_tensor])\n    opt = optimizers.Adam(learning_rate=0.000001)\n    model.compile(optimizer = opt, loss = 'MSE',metrics=[tf.keras.metrics.RootMeanSquaredError()])\n    model.fit(x_train, y_train, epochs = 50,validation_split = 0.15)\n    if mtype == \"DNN\":\n        model.save('dnnmodel{}{}.h5'.format(colorflag,dims[0]))\n    else:\n        model.save('cnnmodel{}{}.h5'.format(colorflag,dims[0]))\n#   MODEL TRAIN END\n\n#   PREDICTIONS BEGIN\n#model.evaluate(x_final_test,y_final_test)\nIds,x_test = np.array([x[0] for x in test_tensor]),np.array([x[1] for x in test_tensor])\npredictions = [round(float(x[0])*100,2) for x in model.predict(x_test)]\nsubmission = pd.DataFrame({'Id':Ids,'Pawpularity':predictions})\nsubmission.to_csv(\"submission.csv\",index=False)\nprint(submission)\n#   PREDICTIONS END\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-06T18:18:31.614303Z","iopub.execute_input":"2022-01-06T18:18:31.614613Z","iopub.status.idle":"2022-01-06T18:18:38.324739Z","shell.execute_reply.started":"2022-01-06T18:18:31.614579Z","shell.execute_reply":"2022-01-06T18:18:38.323883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}