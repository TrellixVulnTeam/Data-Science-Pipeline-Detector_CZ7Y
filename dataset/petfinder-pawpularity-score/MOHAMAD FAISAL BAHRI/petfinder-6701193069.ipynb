{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import classification_report, make_scorer, r2_score, mean_squared_error\n#from skfeature.function.similarity_based import fisher_score, reliefF, trace_ratio\n#from skfeature.function.statistical_based import f_score, chi_square, gini_index\n#from skfeature.function.information_theoretical_based import FCBF, JMI\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.svm import SVC, SVR\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import AdaBoostRegressor\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-30T10:15:14.084451Z","iopub.execute_input":"2021-11-30T10:15:14.084771Z","iopub.status.idle":"2021-11-30T10:15:14.092081Z","shell.execute_reply.started":"2021-11-30T10:15:14.084709Z","shell.execute_reply":"2021-11-30T10:15:14.091254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_train_metadata = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')\ndf_test_metadata = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:15:14.095353Z","iopub.execute_input":"2021-11-30T10:15:14.095829Z","iopub.status.idle":"2021-11-30T10:15:14.129573Z","shell.execute_reply.started":"2021-11-30T10:15:14.095787Z","shell.execute_reply":"2021-11-30T10:15:14.128941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport cv2\nimport missingno as msno\n\ntrain_image = df_train_metadata.copy()\ntest_image = df_test_metadata.copy()\n\ntrain_image[\"file_path\"] = df_train_metadata[\"Id\"].apply(lambda x: \"/kaggle/input/petfinder-pawpularity-score/train/\" + x + \".jpg\")\ntest_image[\"file_path\"] = df_test_metadata[\"Id\"].apply(lambda x: \"/kaggle/input/petfinder-pawpularity-score/test/\" + x + \".jpg\")\n\nplt.figure(figsize=(20, 20))\nrow, col = 5, 4\nfor i in range(row * col):\n    plt.subplot(row, col, i+1)\n    image = cv2.imread(train_image.loc[i, 'file_path'])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    target = train_image.loc[i, 'Pawpularity']\n    plt.imshow(image)\n    plt.title(f\"No: {i}\" f\"   Pawpularity: {target}\")\nplt.show()\n\n# def preprocess(image_url):\n#   image_string = tf.io.read_file(image_url)\n#   image = tf.image.decode_jpeg(image_string, channels=3)\n#   image = tf.cast(image, tf.float32) / 255.0\n#   image = tf.image.central_crop(image, 1.0)\n#   image = tf.image.resize(image, (128, 128))\n#   return image\n\n# x_train_image=[]\n# for i in train_image['file_path']:\n#     x1=preprocess(i)\n#     x_train_image.append(x1)\n\n#x_train_image = pd.DataFrame(x_train_image)\n\n#print(x_train_image)\n#x_train_image.to_csv('image_features.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:15:14.130783Z","iopub.execute_input":"2021-11-30T10:15:14.131701Z","iopub.status.idle":"2021-11-30T10:15:18.54531Z","shell.execute_reply.started":"2021-11-30T10:15:14.131653Z","shell.execute_reply":"2021-11-30T10:15:18.544208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n#Here is the business:\ndef image_statistics(Z):\n    #Input: Z, a 2D array, hopefully containing some sort of peak\n    #Output: cx,cy,sx,sy,skx,sky,kx,ky\n    #cx and cy are the coordinates of the centroid\n    #sx and sy are the stardard deviation in the x and y directions\n    #skx and sky are the skewness in the x and y directions\n    #kx and ky are the Kurtosis in the x and y directions\n    #Note: this is not the excess kurtosis. For a normal distribution\n    #you expect the kurtosis will be 3.0. Just subtract 3 to get the\n    #excess kurtosis.\n    import numpy as np\n\n    h,w = np.shape(Z)\n\n    x = range(w)\n    y = range(h)\n\n\n    #calculate projections along the x and y axes\n    yp = np.sum(Z,axis=1)\n    xp = np.sum(Z,axis=0)\n\n    #centroid\n    cx = np.sum(x*xp)/np.sum(xp)\n    cy = np.sum(y*yp)/np.sum(yp)\n\n    #standard deviation\n    x2 = (x-cx)**2\n    y2 = (y-cy)**2\n\n    sx = np.sqrt( np.sum(x2*xp)/np.sum(xp) )\n    sy = np.sqrt( np.sum(y2*yp)/np.sum(yp) )\n\n    #skewness\n    x3 = (x-cx)**3\n    y3 = (y-cy)**3\n\n    skx = np.sum(xp*x3)/(np.sum(xp) * sx**3)\n    sky = np.sum(yp*y3)/(np.sum(yp) * sy**3)\n\n    #Kurtosis\n    x4 = (x-cx)**4\n    y4 = (y-cy)**4\n    kx = np.sum(xp*x4)/(np.sum(xp) * sx**4)\n    ky = np.sum(yp*y4)/(np.sum(yp) * sy**4)\n\n\n    return cx,cy,sx,sy,skx,sky,kx,ky\n\n#We can check that the result is the same if we use the full 2D data array\ndef image_statistics_2D(Z):\n    h,w = np.shape(Z)\n\n    x = range(w)\n    y = range(h)\n\n    X,Y = np.meshgrid(x,y)\n\n    #Centroid (mean)\n    cx = np.sum(Z*X)/np.sum(Z)\n    cy = np.sum(Z*Y)/np.sum(Z)\n\n    ###Standard deviation\n    x2 = (range(w) - cx)**2\n    y2 = (range(h) - cy)**2\n\n    X2,Y2 = np.meshgrid(x2,y2)\n\n    #Find the variance\n    vx = np.sum(Z*X2)/np.sum(Z)\n    vy = np.sum(Z*Y2)/np.sum(Z)\n\n    #SD is the sqrt of the variance\n    sx,sy = np.sqrt(vx),np.sqrt(vy)\n\n    ###Skewness\n    x3 = (range(w) - cx)**3\n    y3 = (range(h) - cy)**3\n\n    X3,Y3 = np.meshgrid(x3,y3)\n\n    #Find the thid central moment\n    m3x = np.sum(Z*X3)/np.sum(Z)\n    m3y = np.sum(Z*Y3)/np.sum(Z)\n\n    #Skewness is the third central moment divided by SD cubed\n    skx = m3x/sx**3\n    sky = m3y/sy**3\n\n    ###Kurtosis\n    x4 = (range(w) - cx)**4\n    y4 = (range(h) - cy)**4\n\n    X4,Y4 = np.meshgrid(x4,y4)\n\n    #Find the fourth central moment\n    m4x = np.sum(Z*X4)/np.sum(Z)\n    m4y = np.sum(Z*Y4)/np.sum(Z)\n\n    #Kurtosis is the fourth central moment divided by SD to the fourth power\n    kx = m4x/sx**4\n    ky = m4y/sy**4\n\n    return cx,cy,sx,sy,skx,sky,kx,ky\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:15:18.546682Z","iopub.execute_input":"2021-11-30T10:15:18.547566Z","iopub.status.idle":"2021-11-30T10:15:18.574341Z","shell.execute_reply.started":"2021-11-30T10:15:18.547523Z","shell.execute_reply":"2021-11-30T10:15:18.573591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.io import imread, imshow\n\n#df_label = pd.DataFrame(columns=['Label'])\n\nimage_features_train = pd.DataFrame(\n    columns=[\n             'centroid_pr_x','centroid_pr_y','stddev_pr_x','stddev_pr_y','skewness_pr_x','skewness_pr_y','kurtosis_pr_x','kurtosis_pr_y'\n                ])\n\nfor i in train_image[\"file_path\"]:\n    #print('image1:',df_train['image_1'][i])\n    image = cv2.imread(i)\n    #print('/content/drive/MyDrive/NDSC/training_img/{}'.format(df_train['image_1'][i]))\n    #print(image1)\n    #imshow(image);\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    #Calculate the image statistics using the projection method\n    stats_pr = image_statistics(gray_image)\n    print(stats_pr)\n    #Confirm that they are the same by using a 2D calculation\n    #stats_2d = image_statistics_2D(gray_image)\n    baris = [\n             stats_pr[0], stats_pr[1], stats_pr[2], stats_pr[3], stats_pr[4], stats_pr[5], stats_pr[6], stats_pr[7]\n            ]\n    \n    image_features_train.loc[len(image_features_train.index)] = baris\n\nimage_features_train.to_csv ('/kaggle/working/image_features_train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:15:18.576081Z","iopub.execute_input":"2021-11-30T10:15:18.576698Z","iopub.status.idle":"2021-11-30T10:18:16.118596Z","shell.execute_reply.started":"2021-11-30T10:15:18.576663Z","shell.execute_reply":"2021-11-30T10:18:16.117631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.io import imread, imshow\n\n#df_label = pd.DataFrame(columns=['Label'])\n\nimage_features_test = pd.DataFrame(\n    columns=[\n             'centroid_pr_x','centroid_pr_y','stddev_pr_x','stddev_pr_y','skewness_pr_x','skewness_pr_y','kurtosis_pr_x','kurtosis_pr_y'\n                ])\n\nfor i in test_image[\"file_path\"]:\n    #print('image1:',df_train['image_1'][i])\n    image = cv2.imread(i)\n    #print('/content/drive/MyDrive/NDSC/training_img/{}'.format(df_train['image_1'][i]))\n    #print(image1)\n    #imshow(image);\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    #Calculate the image statistics using the projection method\n    stats_pr = image_statistics(gray_image)\n    print(stats_pr)\n    #Confirm that they are the same by using a 2D calculation\n    #stats_2d = image_statistics_2D(gray_image)\n    baris = [\n             stats_pr[0], stats_pr[1], stats_pr[2], stats_pr[3], stats_pr[4], stats_pr[5], stats_pr[6], stats_pr[7]\n            ]\n    \n    image_features_test.loc[len(image_features_test.index)] = baris\n\nimage_features_test.to_csv('/kaggle/working/image_features_test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:18:16.120013Z","iopub.execute_input":"2021-11-30T10:18:16.12034Z","iopub.status.idle":"2021-11-30T10:18:16.162375Z","shell.execute_reply.started":"2021-11-30T10:18:16.120294Z","shell.execute_reply":"2021-11-30T10:18:16.161535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_features_train = pd.read_csv('/kaggle/working/image_features_train.csv')\nimage_features_test = pd.read_csv('/kaggle/working/image_features_test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:18:16.163765Z","iopub.execute_input":"2021-11-30T10:18:16.164907Z","iopub.status.idle":"2021-11-30T10:18:16.192937Z","shell.execute_reply.started":"2021-11-30T10:18:16.164857Z","shell.execute_reply":"2021-11-30T10:18:16.192042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.concat([df_train_metadata['Pawpularity'], df_train_metadata.loc[:,'Subject Focus':'Blur'],image_features_train.loc[:,'centroid_pr_x':'kurtosis_pr_y']], axis=1)\ndf_test = pd.concat([df_test_metadata.loc[:,'Subject Focus':'Blur'],image_features_test.loc[:,'centroid_pr_x':'kurtosis_pr_y']], axis=1)\n\ndf_test.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:18:16.194044Z","iopub.execute_input":"2021-11-30T10:18:16.19437Z","iopub.status.idle":"2021-11-30T10:18:16.224209Z","shell.execute_reply.started":"2021-11-30T10:18:16.19434Z","shell.execute_reply":"2021-11-30T10:18:16.223566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlabel = np.asarray(df_train['Pawpularity'])\nfeatures = np.asarray(df_train.loc[:, 'Subject Focus':'kurtosis_pr_y'])\n\nscaler = preprocessing.MinMaxScaler(feature_range=(0,10)).fit(features)\nscaled_feature = scaler.transform(features)\n\nranked_index = [12, 8, 13, 14, 15, 16, 17, 18, 19, 10,  9,  1,  6,  2,  3,  7, 11,  5,  4,  0,  0]\n\nresult = scaled_feature[:, ranked_index[:]]\n\nprint(\"\\nJMI\")\nprint(ranked_index)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:20:08.421487Z","iopub.execute_input":"2021-11-30T10:20:08.422282Z","iopub.status.idle":"2021-11-30T10:20:08.434568Z","shell.execute_reply.started":"2021-11-30T10:20:08.422242Z","shell.execute_reply":"2021-11-30T10:20:08.433655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(predict, actual):\n    predict = np.array(predict)\n    actual = np.array(actual)\n\n    distance = predict - actual\n\n    square_distance = distance ** 2\n\n    mean_square_distance = square_distance.mean()\n\n    score = np.sqrt(mean_square_distance)\n\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:20:17.782952Z","iopub.execute_input":"2021-11-30T10:20:17.783563Z","iopub.status.idle":"2021-11-30T10:20:17.788669Z","shell.execute_reply.started":"2021-11-30T10:20:17.783528Z","shell.execute_reply":"2021-11-30T10:20:17.788052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import make_scorer\n\njumlah_fitur = range(1,scaled_feature.shape[1]+1)\nscores = []\nscore = 1000\nbest_score = 1000\nbest_feature_number = 0\n\n#Mencoba optimasi hyperparameter untuk setiap kombinasi/jumlah fitur\nfor jumlah_fitur_terbaik in jumlah_fitur:\n    #print(jumlah_fitur_terbaik)\n    selected_features = result[:,0:jumlah_fitur_terbaik]\n    #split data training dan data testing\n    X_train, X_test, y_train, y_test = train_test_split(selected_features, label, test_size=0.3, random_state=0)\n\n    regressor = KNeighborsRegressor()\n    \n    # optimasi hyperparameter\n    param_grid = [\n    {'n_neighbors':[3,5,7,9,11,13,15], 'metric':['euclidean','manhattan','chebyshev','minkowski','wminkowski','seuclidean','mahalanobis']}\n    #{'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n    #{'n_estimators': [50, 100, 150, 200], 'criterion':['gini', 'entropy'], 'max_depth':[5, 10, 15], 'min_samples_split':[0.1, 1.0, 10], 'min_samples_leaf':[0.1, 0.5, 5]}\n    #{'criterion':['gini', 'entropy'], 'max_depth':[5, 10, 15], 'min_samples_split':[0.1, 1.0, 10], 'min_samples_leaf':[0.1, 0.5, 5]}\n    #{'n_estimators': [50, 100, 150, 200],'learning_rate': [0.1,0.2,0.3],}\n    ]\n    \n    #menentukan prioritas scoring menggunakan apa (accuracy/precision/recall, dll)\n    metric = make_scorer(mean_squared_error, greater_is_better=False)\n\n    model = GridSearchCV(regressor, param_grid, scoring=metric, cv=5, refit = True, verbose = 3)\n\n    # fitting the model for grid search \n    model.fit(X_train, y_train)\n\n    # print best parameter after tuning \n    print(model.best_params_) \n      \n    # print how our model looks after hyper-parameter tuning \n    print(model.best_estimator_)\n\n    #model_predictions = model.predict(X_test) \n\n    #model.fit(X_train, y_train)\n    score = abs(model.score(X_test, y_test))\n    scores.append(score)\n\n    #menentukan model terbaik berdasarkan score terbaik menggunakan kombinasi jumlah fitur dan optimasi hyperparameter\n    if(best_score > score):\n      best_score = score\n      best_model = model\n      best_feature_number = jumlah_fitur_terbaik\n      best_parameter = model.best_params_\n      \n      #menyimpan best_X_test dengan jumlah fitur terbaik\n      best_X_test = X_test\n\n\nplt.figure()\nplt.xlabel('jumlah_fitur_terbaik')\nplt.ylabel('score')\nplt.scatter(jumlah_fitur, scores)\nplt.grid()\n\nprint(scores);\nprint('Jumlah fitur terbaik : ',best_feature_number)\nprint('Score terbaik : ',best_score)\nprint('Parameter terbaik : ',best_parameter)\n\nfinal_predictions = best_model.predict(best_X_test) ","metadata":{"execution":{"iopub.status.busy":"2021-11-30T10:21:04.190572Z","iopub.execute_input":"2021-11-30T10:21:04.190906Z","iopub.status.idle":"2021-11-30T10:26:06.647498Z","shell.execute_reply.started":"2021-11-30T10:21:04.190871Z","shell.execute_reply":"2021-11-30T10:26:06.646688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nfig, ax = plt.subplots()\nax.text(1, 9.5,'$R^2=$'+str(round(r2_score(y_test, final_predictions),4)), fontsize=12, verticalalignment='top', multialignment='center')\nax.text(1, 9,'$MSE=$'+str(round(rmse(y_test, final_predictions),4)), fontsize=12, verticalalignment='top', multialignment='center')\n\nax.set_xlim(xmin=1)\nax.set_ylim(ymin=1)\nax.set_xlim(xmax=100)\nax.set_ylim(ymax=100)\n\nax.set_xlabel('Actual Value', fontsize=14)\nax.set_ylabel('Predicted Value', fontsize=14)\nax.scatter(y_test, final_predictions, s=100, c=y_test, cmap='viridis')\n\nlims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n]\n\n# now plot both limits against eachother\nax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\nax.set_aspect('equal')\nax.set_xlim(lims)\nax.set_ylim(lims)\nax.grid(True, which='both')\n\nxvalue = np.linspace(1,10,10)\nlsigma = ax.fill_between(xvalue, xvalue+1, xvalue-1, color='blue', alpha=0.3)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T11:47:58.840638Z","iopub.execute_input":"2021-11-30T11:47:58.840935Z","iopub.status.idle":"2021-11-30T11:47:59.132591Z","shell.execute_reply.started":"2021-11-30T11:47:58.840904Z","shell.execute_reply":"2021-11-30T11:47:59.131622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_test = np.asarray(df_test.loc[:, \"Subject Focus\":\"kurtosis_pr_y\"])\nscaler = preprocessing.MinMaxScaler(feature_range=(0, 1)).fit(features_test)\nfeatures_test = scaler.transform(features_test)\n\nresult_test = features_test[:, ranked_index[:]]\nselected_features_kaggle_test = result_test[:, 0:best_feature_number]\n\nfinal_predictions_kaggle = best_model.predict(selected_features_kaggle_test) \ndata_test = np.array(df_test_metadata.Id)\n# print(len(final_predictions_kaggle))\n# print(features_test)\n# print(result_test)\n# print(data_test)\n\ndf_hasil = pd.DataFrame({\"Id\":data_test,\"Pawpularity\":final_predictions_kaggle})\n\ndf_hasil.to_csv('submission.csv', index=False)\ndf_hasil.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T11:48:04.825624Z","iopub.execute_input":"2021-11-30T11:48:04.82607Z","iopub.status.idle":"2021-11-30T11:48:04.844584Z","shell.execute_reply.started":"2021-11-30T11:48:04.826039Z","shell.execute_reply":"2021-11-30T11:48:04.843408Z"},"trusted":true},"execution_count":null,"outputs":[]}]}