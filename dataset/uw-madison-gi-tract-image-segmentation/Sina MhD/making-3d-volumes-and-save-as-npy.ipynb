{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Why 3D volumes?\n\nBecause a 3d model like 3D unet can make use of 3D information and learn volumetric information.\n\nHere I show how to make 3D volumes out of this dataset. The dataset is also saved at the end and can be directly used. \n","metadata":{}},{"cell_type":"code","source":"# Importing required libraries\nimport numpy as np\nimport os\nimport time\nimport glob\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-06-16T04:43:04.859877Z","iopub.execute_input":"2022-06-16T04:43:04.861243Z","iopub.status.idle":"2022-06-16T04:43:04.866938Z","shell.execute_reply.started":"2022-06-16T04:43:04.861201Z","shell.execute_reply":"2022-06-16T04:43:04.866007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking a look at the dataset\ndf_train = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\nprint(df_train.shape)\ndf_train.head(4)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T04:47:11.025049Z","iopub.execute_input":"2022-06-16T04:47:11.025479Z","iopub.status.idle":"2022-06-16T04:47:11.581329Z","shell.execute_reply.started":"2022-06-16T04:47:11.025441Z","shell.execute_reply":"2022-06-16T04:47:11.580425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Annotation information is in segmentation column","metadata":{}},{"cell_type":"code","source":"#unique ids\nids = np.unique(df_train[df_train['segmentation'].isna()==False]['id'].str.split('_day').apply(lambda x : x[0]).apply(lambda x: x.split('case')[1]).to_list())\nprint(ids.shape)\nprint(ids[:10])","metadata":{"execution":{"iopub.status.busy":"2022-06-16T04:47:27.389203Z","iopub.execute_input":"2022-06-16T04:47:27.38958Z","iopub.status.idle":"2022-06-16T04:47:27.602025Z","shell.execute_reply.started":"2022-06-16T04:47:27.38955Z","shell.execute_reply":"2022-06-16T04:47:27.601071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, there are 85 cases, where each of them has multiple sessions of a patient","metadata":{}},{"cell_type":"code","source":"# takin a look at a slice of one sample and its mask\ntrain_path = '../input/uw-madison-gi-tract-image-segmentation/train'\ncase= 154\nday =16\nslice_num=75\nmask_path = df_train[df_train['id'] == f'case{case}_day{day}_slice_{str(slice_num).zfill(4)}']\nimage_path = glob.glob(f'{train_path}/case{case}/case{case}_day{day}/scans/slice_{str(slice_num).zfill(4)}_*.png')[0]\nimage = plt.imread(image_path)\n\ndef rle_decode(mask_rle, shape):\n    h, w = shape\n    img = np.zeros((h * w,), dtype=np.float32)\n    for i in range(3):\n        mask = mask_rle[i]\n        if mask==mask:\n            s = np.array(mask.split(), dtype=int)\n            starts = s[0::2] - 1\n            lengths = s[1::2]\n            ends = starts + lengths\n            for lo, hi in zip(starts, ends):\n                img[lo : hi] = i+1\n    return img.reshape(shape).astype(np.uint8)\n\nmask = rle_decode(mask_path.segmentation.values, image.shape)\n\nfig, ax = plt.subplots(1,3,figsize=(10,6))\nax[0].imshow(image)\nax[1].imshow(mask)\nax[2].imshow(image,'gray')\nax[2].imshow(mask, alpha=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T04:54:46.568671Z","iopub.execute_input":"2022-06-16T04:54:46.569104Z","iopub.status.idle":"2022-06-16T04:54:46.985285Z","shell.execute_reply.started":"2022-06-16T04:54:46.569066Z","shell.execute_reply":"2022-06-16T04:54:46.984379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Here, we make the 3d volumes, save the volume inputs with _x.npy suffix and the segmentation volumes with _y.npy**","metadata":{}},{"cell_type":"code","source":"# Make 3d volumes\nos.makedirs('./3d_volumes_masks', exist_ok=True)\nfor root, dirs, files in sorted(os.walk(train_path)):\n    if len(files)>10:\n        dim1 = np.int32(sorted(files)[0].split('_')[3])\n        dim2 = np.int32(sorted(files)[0].split('_')[2])\n        image_3d= np.zeros((dim1,dim2,len(files))).astype(np.float32)\n        label_3d = np.zeros((dim1,dim2,len(files))).astype(np.uint8)\n        file_name = root.split('/')[5]\n        for i, image_path in enumerate(sorted(files)):\n            slice_num = image_path.split('_')[1]\n            image = Image.open(os.path.join(root,image_path))\n            image_3d[:,:,i] = image\n            label_path = df_train[df_train['id'] == f\"{file_name}_slice_{str(slice_num).zfill(4)}\"]\n            label_3d[:,:,i] = rle_decode(label_path.segmentation.values, (dim1, dim2))\n        np.save(os.path.join('./3d_volumes_masks/', file_name+'_x'), image_3d, allow_pickle=True)\n        np.save(os.path.join('./3d_volumes_masks/', file_name+'_y'), label_3d, allow_pickle=True)\n        print(file_name , 'saved with', len(files), 'slices')","metadata":{"execution":{"iopub.status.busy":"2022-06-16T05:01:14.576348Z","iopub.execute_input":"2022-06-16T05:01:14.576771Z","iopub.status.idle":"2022-06-16T05:03:53.70316Z","shell.execute_reply.started":"2022-06-16T05:01:14.576721Z","shell.execute_reply":"2022-06-16T05:03:53.701513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's it, now we have 3D X and y both ready in npy format","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}