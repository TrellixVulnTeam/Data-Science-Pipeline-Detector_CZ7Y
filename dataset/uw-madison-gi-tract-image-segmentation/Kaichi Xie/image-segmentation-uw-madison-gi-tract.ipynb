{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"\\n... IMPORTS STARTING ...\\n\")\n\nimport os\nos.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t– TENSORFLOW VERSION: {tf.__version__}\");\"\"\nimport logging\n\n#import tensorflow_hub as tfhub; print(f\"\\t\\t– TENSORFLOW HUB VERSION: {tfhub.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t– TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t– NUMPY VERSION: {np.__version__}\");\nimport sklearn; print(f\"\\t\\t– SKLEARN VERSION: {sklearn.__version__}\");\nfrom sklearn.preprocessing import RobustScaler, PolynomialFeatures\nfrom pandarallel import pandarallel; pandarallel.initialize();\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold, train_test_split\n\n# # RAPIDS\n# import cudf, cupy, cuml\n# from cuml.neighbors import NearestNeighbors\n# from cuml.manifold import TSNE, UMAP\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom datetime import datetime\nfrom glob import glob\n#import warnings\nimport requests\nimport hashlib\nimport IPython\nimport sklearn\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport json\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.patches import Rectangle\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image, ImageEnhance\nimport matplotlib; print(f\"\\t\\t– MATPLOTLIB VERSION: {matplotlib.__version__}\");\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')\nimport plotly\nimport PIL\nimport cv2\n\nimport plotly.io as pio\nprint(pio.renderers)\n\ndef seed_it_all(seed=7):\n    \"\"\" Attempt to be Reproducible \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \ntf.get_logger().setLevel('ERROR')\n    \nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n\nprint(\"\\n... SEEDING FOR DETERMINISTIC BEHAVIOUR ...\\n\")\nseed_it_all()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:35.925451Z","iopub.execute_input":"2022-05-31T04:43:35.92598Z","iopub.status.idle":"2022-05-31T04:43:35.945905Z","shell.execute_reply.started":"2022-05-31T04:43:35.925941Z","shell.execute_reply":"2022-05-31T04:43:35.945119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:35.947733Z","iopub.execute_input":"2022-05-31T04:43:35.94842Z","iopub.status.idle":"2022-05-31T04:43:36.670648Z","shell.execute_reply.started":"2022-05-31T04:43:35.948374Z","shell.execute_reply":"2022-05-31T04:43:36.669756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\n... ACCELERATOR SETUP STARTING ...\\n\")\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \nexcept ValueError:\n    TPU = None\n\nif TPU:\n    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    print(f\"\\n... RUNNING ON CPU/GPU ...\")\n    physical_devices = tf.config.list_physical_devices('GPU')\n    try:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    except:\n        # Invalid device or cannot modify virtual devices once initialized.\n        pass\n    \n    # Yield the default distribution strategy in Tensorflow\n    #   --> Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\n# What Is a Replica?\n#    --> A single Cloud TPU device consists of FOUR chips, each of which has TWO TPU cores. \n#    --> Therefore, for efficient utilization of Cloud TPU, a program should make use of each of the EIGHT (4x2) cores. \n#    --> Each replica is essentially a copy of the training graph that is run on each core and \n#        trains a mini-batch containing 1/8th of the overall batch size\nN_REPLICAS = strategy.num_replicas_in_sync\n    \nprint(f\"... # OF REPLICAS: {N_REPLICAS} ...\\n\")\n\nprint(f\"\\n... ACCELERATOR SETUP COMPLTED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:36.672621Z","iopub.execute_input":"2022-05-31T04:43:36.673053Z","iopub.status.idle":"2022-05-31T04:43:36.691422Z","shell.execute_reply.started":"2022-05-31T04:43:36.673013Z","shell.execute_reply":"2022-05-31T04:43:36.690492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... DATA ACCESS SETUP STARTED ...\\n\")\n\nif TPU:\n    # Google Cloud Dataset path to training and validation images\n    DATA_DIR = KaggleDatasets().get_gcs_path('uw-madison-gi-tract-image-segmentation')\n    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n    load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\nelse:\n    # Local path to training and validation images\n    DATA_DIR = \"../input/uw-madison-gi-tract-image-segmentation\"\n    save_locally = None\n    load_locally = None\n\nprint(f\"\\n... DATA DIRECTORY PATH IS:\\n\\t--> {DATA_DIR}\")\n\nprint(f\"\\n... IMMEDIATE CONTENTS OF DATA DIRECTORY IS:\")\nfor file in tf.io.gfile.glob(os.path.join(DATA_DIR, \"*\")): print(f\"\\t--> {file}\")\n\nprint(\"\\n\\n... DATA ACCESS SETUP COMPLETED ...\\n\")\n#'gs://kds-5cfbc058b17caa8a1bd8982b1193f1c5381f45c742948f2a940c250d/train/**/*.png'","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:36.692962Z","iopub.execute_input":"2022-05-31T04:43:36.693426Z","iopub.status.idle":"2022-05-31T04:43:36.709841Z","shell.execute_reply.started":"2022-05-31T04:43:36.693384Z","shell.execute_reply":"2022-05-31T04:43:36.708991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\n... XLA OPTIMIZATIONS STARTING ...\\n\")\n\nprint(f\"\\n... CONFIGURE JIT (JUST IN TIME) COMPILATION ...\\n\")\n# enable XLA optmizations (10% speedup when using @tf.function calls)\ntf.config.optimizer.set_jit(False)\n\nprint(f\"\\n... XLA OPTIMIZATIONS COMPLETED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:36.71219Z","iopub.execute_input":"2022-05-31T04:43:36.712741Z","iopub.status.idle":"2022-05-31T04:43:36.720183Z","shell.execute_reply.started":"2022-05-31T04:43:36.7127Z","shell.execute_reply":"2022-05-31T04:43:36.719324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... Basic Data Set up Starting ... \")\nTRAIN_DIR = os.path.join(DATA_DIR, \"train\")\nTRAIN_CSV_DIR = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV_DIR)\n#all_training_images = tf.io.gfile.glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"))\nprint(\"\\n... ORIGINAL TRAINING DATAFRAME... \\n\")\ndisplay(train_df)\n\n# Test cases and submission csv check\nTEST_DIR = os.path.join(DATA_DIR, \"test\")\nprint(TEST_DIR)\nSS_CSV   = os.path.join(DATA_DIR, \"sample_submission.csv\")\nss_df = pd.read_csv(SS_CSV)\n\nall_test_images = glob(os.path.join(TEST_DIR, \"**\", \"*.png\"), recursive=True)\nprint(\"Test images in total: \", len(all_test_images))\nprint(\"\\n\\n\\n... ORIGINAL SUBMISSION DATAFRAME... \\n\")\ndisplay(ss_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:36.722076Z","iopub.execute_input":"2022-05-31T04:43:36.722746Z","iopub.status.idle":"2022-05-31T04:43:37.034881Z","shell.execute_reply.started":"2022-05-31T04:43:36.722706Z","shell.execute_reply":"2022-05-31T04:43:37.033925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_all_training_images(df, is_tf = True):\n    if(is_tf):\n        df[\"case_#\"] = df[\"id\"].apply(lambda x : x.split(\"_\")[0])\n        df[\"day_#\"] = df[\"id\"].apply(lambda x : x.split(\"_\")[1])\n        df_tf = pd.DataFrame({\"case_#\" : df[\"case_#\"], \"day_#\":df[\"day_#\"]})\n        df_tf = df_tf.drop_duplicates(subset=[\"case_#\", \"day_#\"]).reset_index(drop=True)\n        df_tf[\"case#_day#\"] = df[\"case_#\"]+\"_\"+df[\"day_#\"]\n        all_image_path = df_tf[\"case#_day#\"].apply(lambda x : tf.io.gfile.glob(os.path.join(TRAIN_DIR, x.split(\"_\")[0], x, \"scans\", \"*.png\")))\n        all_train_image_path = []\n        for paths in all_image_path:\n            all_train_image_path = all_train_image_path + paths\n        \n    else:\n        all_train_image_path = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n    return all_train_image_path\n\nall_training_images = get_all_training_images(train_df.copy(), is_tf = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:37.036303Z","iopub.execute_input":"2022-05-31T04:43:37.036678Z","iopub.status.idle":"2022-05-31T04:43:37.766662Z","shell.execute_reply.started":"2022-05-31T04:43:37.036639Z","shell.execute_reply":"2022-05-31T04:43:37.765893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"...There are in total : \", len(all_training_images), \" images\")\nprint(\"...One of Image file paths :  \\n\", all_training_images[10000])","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:37.767941Z","iopub.execute_input":"2022-05-31T04:43:37.768215Z","iopub.status.idle":"2022-05-31T04:43:37.774347Z","shell.execute_reply.started":"2022-05-31T04:43:37.768182Z","shell.execute_reply":"2022-05-31T04:43:37.773541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For debugging purposes when the test set hasn't been substituted we will know\nDEBUG=len(all_test_images)==0\n\n\n\nif DEBUG:\n    TEST_DIR = TRAIN_DIR\n    all_test_images = all_training_images\n    first_50_cases = train_df.id.apply(lambda x: x.split(\"_\", 1)[0]).unique()[:50]\n    ss_df = train_df[train_df.id.apply(lambda x: x.split(\"_\", 1)[0]).isin(first_50_cases)]\n    ss_df = ss_df[[\"id\", \"class\"]]\n    ss_df[\"predicted\"] = \"\"\n    \n    print(\"\\n\\n\\n... DEBUG SUBMISSION DATAFRAME... \\n\")\n    display(ss_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:37.775866Z","iopub.execute_input":"2022-05-31T04:43:37.776645Z","iopub.status.idle":"2022-05-31T04:43:37.912821Z","shell.execute_reply.started":"2022-05-31T04:43:37.776456Z","shell.execute_reply":"2022-05-31T04:43:37.912053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\nsf_classes = [\"lb\", \"sb\", \"st\"]\nSF2LF = {_sf:_lf for _sf,_lf in zip(sf_classes, classes)}\nLF2SF = {_lf:_sf for _sf,_lf in zip(sf_classes, classes)}","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:37.913981Z","iopub.execute_input":"2022-05-31T04:43:37.914697Z","iopub.status.idle":"2022-05-31T04:43:37.920366Z","shell.execute_reply.started":"2022-05-31T04:43:37.914657Z","shell.execute_reply":"2022-05-31T04:43:37.919573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def separateKeyWords(df):\n    df[\"case_id_str\"] = df[\"id\"].apply(lambda x : x.split(\"_\")[0])\n    df[\"case_id\"] = df[\"case_id_str\"].apply(lambda x : int(x[4:]))\n    df[\"day_num_str\"] = df[\"id\"].apply(lambda x : x.split(\"_\")[1])\n    df[\"slice_id_str\"] = df[\"id\"].apply(lambda x : x.split(\"_\",2)[-1])\n    return df\n\ndef set_up_img_file_path(df, img_files_paths):\n    # correct path: '../input/uw-madison-gi-tract-image-segmentation/train/case36/case36_day14/scans/slice_0006_266_266_1.50_1.50.png'\n    #gs://kds-5cfbc058b17caa8a1bd8982b1193f1c5381f45c742948f2a940c250d/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png\n    identifier = [x.rsplit(\"/\",3)[1] +\"_\"+ x.rsplit(\"/\",1)[1].rsplit(\"_\", 4)[0] for x in img_files_paths]\n    _tmp_merge_df = pd.DataFrame({\"id\" : identifier, \"img_file_path\" : img_files_paths})\n    #display(_tmp_merge_df)\n    df = df.merge(_tmp_merge_df, on = \"id\")\n    return df\n\ndef process_segmentation(df):\n    # Merge three rows which corresponding to three types of segmentations into one row\n    large_bowel_df = df[df[\"class\"] == \"large_bowel\"][[\"id\", \"segmentation\"]].rename(columns = {\"segmentation\" : \"large_bowel_seg_rle\"})\n    small_bowel_df = df[df[\"class\"] == \"small_bowel\"][[\"id\", \"segmentation\"]].rename(columns = {\"segmentation\" : \"small_bowel_seg_rle\"})\n    stomach_df = df[df[\"class\"] == \"stomach\"][[\"id\", \"segmentation\"]].rename(columns = {\"segmentation\" : \"stomach_seg_rle\"})\n    df = df.merge(large_bowel_df, on = \"id\", how = \"left\")\n    df = df.merge(small_bowel_df, on = \"id\", how = \"left\")\n    df = df.merge(stomach_df, on = \"id\", how = \"left\")\n    df = df.drop_duplicates(subset=[\"id\",]).reset_index(drop=True)\n    df[\"large_bowel_seg_flag\"] = df[\"large_bowel_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"small_bowel_seg_flag\"] = df[\"small_bowel_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"stomach_seg_flag\"] = df[\"stomach_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df.drop([\"class\",\"segmentation\"], axis = 1, inplace = True)\n    return df\n\ndef get_height_and_width(df):\n    df[\"slice_h\"] = df[\"img_file_path\"].apply(lambda x : int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"slice_w\"] = df[\"img_file_path\"].apply(lambda x : int(x[:-4].rsplit(\"_\",4)[2]))\n    df[\"px_spacing_h\"] = df[\"img_file_path\"].apply(lambda x : float(x[:-4].rsplit(\"_\",4)[3]))\n    df[\"px_spacing_w\"] = df[\"img_file_path\"].apply(lambda x : float(x[:-4].rsplit(\"_\",4)[4]))\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:37.923707Z","iopub.execute_input":"2022-05-31T04:43:37.924048Z","iopub.status.idle":"2022-05-31T04:43:37.942159Z","shell.execute_reply.started":"2022-05-31T04:43:37.92401Z","shell.execute_reply":"2022-05-31T04:43:37.941393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_first_stage_preprocessing(df, img_files_paths, is_submitting = False):\n# 276_276_1.63_1.63.png.\n#These four numbers are slice height / width (integers in pixels) and heigh/width pixel spacing (floating points in mm).\n#The first two: the resolution of the slide. The last two: the physical size of each pixel.\n    df = separateKeyWords(df)\n    if not is_submitting:\n        df = process_segmentation(df)\n    df = set_up_img_file_path(df, img_files_paths)\n    df = get_height_and_width(df)\n    # 8. Reorder columns to the a new ordering (drops class and segmentation as no longer necessary)\n    new_col_order = [\"id\", \"img_file_path\",\n                     \"large_bowel_seg_rle\", \"large_bowel_seg_flag\",\n                     \"small_bowel_seg_rle\", \"small_bowel_seg_flag\", \n                     \"stomach_seg_rle\", \"stomach_seg_flag\",\n                     \"slice_h\", \"slice_w\", \"px_spacing_h\", \n                     \"px_spacing_w\", \"case_id_str\", \"case_id\", \n                     \"day_num_str\", \"day_num\", \"slice_id\", \"predicted\"]\n    if is_submitting: new_col_order.insert(1, \"class\")\n    new_col_order = [_c for _c in new_col_order if _c in df.columns]\n    df = df[new_col_order]\n    return df\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:37.943315Z","iopub.execute_input":"2022-05-31T04:43:37.943892Z","iopub.status.idle":"2022-05-31T04:43:37.954546Z","shell.execute_reply.started":"2022-05-31T04:43:37.943849Z","shell.execute_reply":"2022-05-31T04:43:37.953747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_second_stage_preprocessing(train_df):\n    N_FOLDS = 8\n    gkf = GroupKFold(n_splits=N_FOLDS) \n    \n    remove_ids = [\"case7_day0\", \"case81_day30\"]\n    for _id in remove_ids:\n        train_df = train_df[~train_df.id.str.contains(_id)].reset_index(drop=True)\n    \n    # train_df = train_df[train_df.n_segs>0].reset_index(drop=True)\n    train_df[\"which_segs\"] = train_df.large_bowel_seg_flag.astype(int).astype(str)+\\\n                             train_df.small_bowel_seg_flag.astype(int).astype(str)+\\\n                             train_df.stomach_seg_flag.astype(int).astype(str)\n    \n    \"\"\"\n    Test train val split\n    Total 38496\n    \n    Get train 60% = 26,947\n        val 20% = 5774\n        test 20% = 5774\n    \"\"\"\n    train_df, test_df = np.split(train_df.sample(frac=1), [int(.9*len(train_df))])\n    \n    for train_idxs, val_idxs in gkf.split(train_df[\"id\"], train_df[\"which_segs\"], train_df[\"case_id\"]):\n        sub_train_df=train_df.iloc[train_idxs]\n        N_TRAIN = len(sub_train_df)\n        sub_train_df=sub_train_df.sample(N_TRAIN).reset_index(drop=True)\n\n        sub_val_df=train_df.iloc[val_idxs]\n        N_VAL = len(sub_val_df)\n        sub_val_df=sub_val_df.sample(N_VAL).reset_index(drop=True)\n\n        break\n\n    # Fix the way we handled nan\n    sub_train_df.large_bowel_seg_rle.fillna(\"\", inplace=True)\n    sub_train_df.small_bowel_seg_rle.fillna(\"\", inplace=True)\n    sub_train_df.stomach_seg_rle.fillna(\"\", inplace=True)\n    \n    # Fix the way we handled nan\n    sub_val_df.large_bowel_seg_rle.fillna(\"\", inplace=True)\n    sub_val_df.small_bowel_seg_rle.fillna(\"\", inplace=True)\n    sub_val_df.stomach_seg_rle.fillna(\"\", inplace=True)\n    \n    test_df.large_bowel_seg_rle.fillna(\"\", inplace=True)\n    test_df.small_bowel_seg_rle.fillna(\"\", inplace=True)\n    test_df.stomach_seg_rle.fillna(\"\", inplace=True)\n\n    print(\"\\nFOLD 1: TRAIN DF\\n\\n\")\n    display(sub_train_df.head())\n\n    print(\"\\n\\n\\n\\nFOLD 1: VAL DF\\n\\n\")\n    display(sub_val_df.head())\n    \n    print(\"\\n\\n\\n TEST DF\\n\\n\")\n    display(test_df.head())\n    \n    return sub_train_df, sub_val_df, test_df","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:37.955717Z","iopub.execute_input":"2022-05-31T04:43:37.956264Z","iopub.status.idle":"2022-05-31T04:43:37.96982Z","shell.execute_reply.started":"2022-05-31T04:43:37.956227Z","shell.execute_reply":"2022-05-31T04:43:37.969073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_after_first_stage = data_first_stage_preprocessing(train_df.copy(), all_training_images)\nss_df = data_first_stage_preprocessing(ss_df, all_test_images, is_submitting =True)\ndisplay(ss_df)\ndisplay(train_df_after_first_stage.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:37.971153Z","iopub.execute_input":"2022-05-31T04:43:37.971495Z","iopub.status.idle":"2022-05-31T04:43:39.623006Z","shell.execute_reply.started":"2022-05-31T04:43:37.971461Z","shell.execute_reply":"2022-05-31T04:43:39.622291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_preprocessed, val_df, test_df = data_second_stage_preprocessing(train_df_after_first_stage)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:39.624491Z","iopub.execute_input":"2022-05-31T04:43:39.624962Z","iopub.status.idle":"2022-05-31T04:43:39.911894Z","shell.execute_reply.started":"2022-05-31T04:43:39.624923Z","shell.execute_reply":"2022-05-31T04:43:39.911192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total = len(train_df_after_first_stage)\nprint(\"\\n ...Training set ratio to the total examples :    \", \"%.2f\"%(len(train_df_preprocessed)/total),\"\\n\")\nprint(\"\\n ...Validation set ratio to the total examples :    \", \"%.2f\"%(len(val_df)/total), \"\\n\")\nprint(\"\\n ...Test set ratio to the total examples :    \", \"%.2f\"%(len(test_df)/total), \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:39.913089Z","iopub.execute_input":"2022-05-31T04:43:39.91377Z","iopub.status.idle":"2022-05-31T04:43:39.922144Z","shell.execute_reply.started":"2022-05-31T04:43:39.913731Z","shell.execute_reply":"2022-05-31T04:43:39.921372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nTF Functions:\n1 load mask as a tensorflow object\n1 for decode rln\n\"\"\"\n\nIMAGE_SHAPE = SEG_SHAPE = (256,256)\ndef rle_encode(img):\n    \"\"\" TBD\n    \n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n    \n    Returns: \n        run length as string formated\n    \"\"\"\n    \n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef tf_load_mask(rle_strs, root_shape, style=\"multiclass\"):\n    \"\"\" \n    Pure tensorflow function to load multiple rles into an RGB array based on output style \n    For now, I am doing multiclass \n    \"\"\"\n    tf_masks = [tf.cast(tf.image.resize(tf.expand_dims(rle_decode_tf(rle_str, root_shape), axis=-1), \\\n                                        size=(tf.constant(SEG_SHAPE[0]), tf.constant(SEG_SHAPE[1])), \\\n                                        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR), tf.uint8) for rle_str in rle_strs]\n    if style==\"multiclass\": # stack for each class\n        return tf.concat(tf_masks, axis=-1)\n    else:        \n        _tf_masks = tf.zeros((*SEG_SHAPE, 1), dtype=tf.uint8)\n        _tf_masks = tf_masks[2]*tf.constant(3, dtype=tf.uint8) # small bowel = 3\n        _tf_masks = tf.where(tf_masks[1]==tf.constant(1, dtype=tf.uint8), tf.constant(2, dtype=tf.uint8), _tf_masks) # small bowel = 2\n        _tf_masks = tf.where(tf_masks[0]==tf.constant(1, dtype=tf.uint8), tf.constant(1, dtype=tf.uint8), _tf_masks) # large bowel = 1\n        return _tf_masks\n    \n    \ndef tf_load_image(path):\n    \"\"\" Load an image with the correct shape using only TF\n    \n    Args:\n        path (tf.string): Path to the image to be loaded\n        resize_to (tuple, optional): Size to reshape image\n    \n    Returns:\n        3 channel tf.Constant image ready for training/inference\n    \n    \"\"\"\n    img_bytes = tf.io.read_file(path)\n    img = tf.image.decode_png(img_bytes, channels=3, dtype=tf.uint16)\n    # img = 255.*(img/tf.constant(32767, dtype=tf.uint16))\n    img = 255.*(img/tf.reduce_max(img)) # Normalization\n    img = tf.image.resize(img, (tf.constant(IMAGE_SHAPE[0]), tf.constant(IMAGE_SHAPE[1])))\n    return img\n# Try show the an image with the original function and with normalization with tensorflow function\n\n\ndef rle_decode_tf(mask_rle, shape):\n    \"\"\" Pure tensorflow RLE decoding function for easy pipelining\n    \n    Args:\n        mask_rle (str): The Run Length Encoded mask\n        shape (tuple): The shape of the mask we are decoding\n    \n    Returns:\n        A 1D tf.constant representing the decoded mask\n        If mask_rle == \"\", return zeros tf.constant with shape\n    \"\"\"\n    \n    shape = tf.convert_to_tensor(shape, tf.int64)\n    size = tf.math.reduce_prod(shape)\n    \n    # Split string\n    s = tf.strings.split(mask_rle)\n    s = tf.strings.to_number(s, tf.int64)\n    \n    # Get starts and lengths\n    starts = s[::2] - 1\n    lens = s[1::2]\n    \n    # Make ones to be scattered\n    total_ones = tf.reduce_sum(lens)\n    ones = tf.ones([total_ones], tf.uint8)\n    \n    # Make scattering indices\n    r = tf.range(total_ones)\n    lens_cum = tf.math.cumsum(lens)\n    s = tf.searchsorted(lens_cum, r, 'right')\n    idx = r + tf.gather(starts - tf.pad(lens_cum[:-1], [(1, 0)]), s)\n    \n    # Scatter ones into flattened mask\n    mask_flat = tf.scatter_nd(tf.expand_dims(idx, 1), ones, [size])\n    \n    # Reshape into mask\n    return tf.reshape(mask_flat, shape)\n    #return tf.transpose(tf.reshape(mask_flat,(shape[1],shape[0])))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:39.923614Z","iopub.execute_input":"2022-05-31T04:43:39.923932Z","iopub.status.idle":"2022-05-31T04:43:39.945076Z","shell.execute_reply.started":"2022-05-31T04:43:39.923899Z","shell.execute_reply":"2022-05-31T04:43:39.944351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nVisualization tools\n\"\"\"\ndef showRandomSlices(num):\n    row = (num // 5) + 1\n    col = 5\n    n = np.random.randint(low=0, high=len(all_training_images), size=num)\n    plt.figure(figsize = (20,10))\n    for i in range(num):\n        plt.subplot(row,col,i+1)\n        img = cv2.imread(all_training_images[n[i]],0)\n        img = (img/img.max()).astype(np.float32) \n        #cv2.normalize(img,  img, 0, 255, cv2.NORM_MINMAX)\n        #tf_img = tf.constant(img)\n        #img = tf.image.per_image_standardization(tf_img)\n        plt.imshow(img)\n        plt.axis(False)\n    plt.tight_layout()\n    plt.show()\n\n\ndef get_overlay(img, mask, _alpha=0.999, _beta=0.45, _gamma=0):\n    \n    # Normalize to be between 0-1 (float32)\n    img = (img/img.max()).astype(np.float32)\n    \n    # Make mask RGB and float32\n    if len(mask.shape)==2:\n        mask_rgb = np.zeros_like(img, dtype=np.float32)\n        mask_rgb[..., 2] = np.where(mask==3, 1.0, 0.0)\n        mask_rgb[..., 1] = np.where(mask==2, 1.0, 0.0)\n        mask_rgb[..., 0] = np.where(mask==1, 1.0, 0.0)\n    else:\n        mask_rgb=mask.astype(np.float32)\n    \n    # overlay\n    seg_overlay = cv2.addWeighted(src1=img, alpha=_alpha, \n                                  src2=mask_rgb, beta=_beta, gamma=_gamma)\n    return seg_overlay\n\n\n\ndef plot_image_with_mask(img, gt_mask): #pred_mask\n    \"\"\"\n    To visualize results after training\n    * need modification\n    \"\"\"\n    gt_overlay = get_overlay(img, gt_mask)\n    #pred_overlay = get_overlay(img, pred_mask)\n    #miss_overlay = get_miss_overlay(gt_mask, pred_mask)\n    \n    plt.figure(figsize=(10,6))\n    #[\"Original\", \"Prediction Mask\", \"Ground-Truth Mask\", \"Miss Mask\"]\n    descriptions = [\"Ground-Truth Mask\"]\n    \n    for i, (_desc, _img) in enumerate(zip(descriptions, [gt_overlay,])):        \n        plt.subplot(1,2,i+1)\n        plt.imshow(_img)\n        plt.title(f\"{_desc} Image\", fontweight=\"bold\")        \n        plt.axis(False)\n        \n        if i in [1,2]:\n            handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n            labels = [\"Large Bowel Segmentation Map\", \"Small Bowel Segmentation Map\", \"Stomach Segmentation Map\"]\n            plt.legend(handles,labels)\n        \"\"\" \n        elif i==3:\n            handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.0,0.8,0.0), (0.8,0.0,0.0), (0.0, 0.0, 0.0)]]\n            labels = [\"Agreement\", \"Disagreement\", \"Background\"]\n            plt.legend(handles,labels)\n        \"\"\"\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:39.947528Z","iopub.execute_input":"2022-05-31T04:43:39.948278Z","iopub.status.idle":"2022-05-31T04:43:39.965033Z","shell.execute_reply.started":"2022-05-31T04:43:39.948227Z","shell.execute_reply":"2022-05-31T04:43:39.964225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nVisualization:\n\"\"\"\nif DEBUG:\n    tdf = train_df_preprocessed\n    all_labeled = tdf[tdf[\"which_segs\"] == \"111\"].iloc[:4]\n    \n    all_labeled_ds = tf.data.Dataset.from_tensor_slices( (all_labeled[\"img_file_path\"],\\\n                                                 (all_labeled.large_bowel_seg_rle, all_labeled.small_bowel_seg_rle, all_labeled.stomach_seg_rle),\\\n                                                 (all_labeled.slice_w,all_labeled.slice_h) ) )\n    all_labeled_ds = all_labeled_ds.map(lambda x,y,z: (tf_load_image(x),tf.cast(tf_load_mask(y,z, style = \"multiclass\"), tf.float32 )))\n    plt.figure(figsize=(15,9))\n    i = 1\n    for img, mask in all_labeled_ds:\n        _mask = mask.numpy().squeeze().astype(np.float32)\n        gt_overlay = get_overlay(img.numpy().astype(np.int32), _mask)\n        plt.subplot(2,2,i)\n        i+=1\n        plt.imshow(gt_overlay)\n        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n        labels = [\"Large Bowel Segmentation Map\", \"Small Bowel Segmentation Map\", \"Stomach Segmentation Map\"]\n        plt.legend(handles,labels)\n        plt.axis(False)\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:39.966484Z","iopub.execute_input":"2022-05-31T04:43:39.96682Z","iopub.status.idle":"2022-05-31T04:43:41.47904Z","shell.execute_reply.started":"2022-05-31T04:43:39.966783Z","shell.execute_reply":"2022-05-31T04:43:41.478402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_batch(img_batch, mask_batch):\n    \"\"\" Pipeline augmentation \n        - Right-Left Flipping (1/3 probability)\n        - Rotation (2/3 probability)\n        - Translation (2/3 probability)\n    \"\"\"\n    # Simple augmentation\n    if tf.random.uniform([])<=tf.constant(0.3333):\n        img_batch = tf.image.flip_left_right(img_batch)\n        mask_batch = tf.image.flip_left_right(mask_batch)\n    # Random rotation\n    if tf.random.uniform([])<=tf.constant(0.6666):\n        degree_rot = tf.random.uniform([BATCH_SIZE,], minval=tf.constant(-0.4), maxval=tf.constant(0.4))\n        img_batch = tfa.image.rotate(img_batch, degree_rot, interpolation=\"bilinear\")\n        mask_batch = tfa.image.rotate(mask_batch, degree_rot, interpolation=\"nearest\")  \n    # Random translation\n    if tf.random.uniform([])<=tf.constant(0.6666):\n        _t_mag = tf.random.uniform([BATCH_SIZE,2], minval=tf.constant(-30.0), maxval=tf.constant(30.0))\n        img_batch = tfa.image.translate(img_batch, translations=_t_mag, interpolation=\"bilinear\")\n        mask_batch = tfa.image.translate(mask_batch, translations=_t_mag, interpolation=\"nearest\")\n        \n    return img_batch, mask_batch\n\ndef add_sample_weights(image_batch, mask_batch, _multiplier=1.5, _exp=0.25):\n    \"\"\"\n    Incorporate class weighting as a third term in tf.data.Dataset\n        \n        BACKGROUND TRAINING DATA PIXEL COUNT (%)  : %98.3326\n        LARGE BOWEL TRAINING DATA PIXEL COUNT (%) : %0.6883\n        SMALL BOWEL TRAINING DATA PIXEL COUNT (%) : %0.6301\n        STOMACH TRAINING DATA PIXEL COUNT (%)     : %0.3490\n\n    \"\"\"    \n    # Add class weighting\n    likelihood = tf.constant([0.983326, 0.06883, 0.06301, 0.03490])\n    class_weights = tf.constant(_multiplier)*((tf.constant(1.0)-likelihood)**_exp)\n    \n    # Create an image of `sample_weights` by using the label at each pixel as an index into the `class weights`\n    #sample_weights_batch = tf.gather(class_weights, indices=tf.cast(mask_batch, tf.int32))\n    \n    \"\"\"\n    for each channel set up sample weight\n    \"\"\"\n    height, width, channels = mask.shape\n    output_mask = tf.zeros((height, width, 1))\n    for c in range(channels): # shoudl be [0:3]\n        _class_weights = [class_weights[0], class_weights[c+1]]\n        output_mask = tf.concat([output_mask, tf.expand_dims(tf.gather(_class_weights, indices = tf.cast(mask[...,c], tf.int32) ), -1)], -1)\n    sample_weights_batch = output_mask[...,1:]\n    return image_batch, mask_batch, sample_weights_batch\n\ndef model_preprocessing_train(img_batch, mask_batch):\n    \"\"\" Model specific preprocessing for DeepLabV3 (training)\"\"\"\n    img_batch = img_batch/tf.constant(127.5)-tf.constant(1.0)\n    return img_batch, mask_batch\n    \ndef model_preprocessing_test(img_batch):\n    \"\"\" Model specific preprocessing for DeepLabV3 (testing)\"\"\"    \n    img_batch = img_batch/tf.constant(127.5)-tf.constant(1.0)\n    return img_batch\n\ndef convert_2_float32_train(img_batch, mask_batch, sample_weights_batch):\n    return tf.cast(img_batch, tf.float32), tf.cast(mask_batch, tf.float32), tf.cast(sample_weights_batch, tf.float32)\n\ndef convert_2_float32_val(img_batch, mask_batch):\n    return tf.cast(img_batch, tf.float32), tf.cast(mask_batch, tf.float32)\n\n# Hyperparameters\nBATCH_SIZE = 24\nSHUFFLE_BUFFER = max(BATCH_SIZE*25, 500)\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Whether or not to train?\n\nDO_TRAIN= False\nSTYLE = \"multiclass\"\nAUTOTUNE = tf.data.AUTOTUNE\nif not DEBUG: DO_TRAIN=False\n    # DEBUG    -> True: on my own; False : submit\n    # DO_TRAIN -> \n    \n# train_df_preprocessed : the dataframe that has been cleaned and preprocessed\n# val_df : same structure as the training df but different examples\n    \nif DEBUG:\n    train_ds = tf.data.Dataset.from_tensor_slices((train_df_preprocessed.img_file_path,\\\n                                                   (train_df_preprocessed.large_bowel_seg_rle, train_df_preprocessed.small_bowel_seg_rle, train_df_preprocessed.stomach_seg_rle),\\\n                                                   (train_df_preprocessed.slice_w,train_df_preprocessed.slice_h)))\n    \n    val_ds = tf.data.Dataset.from_tensor_slices((val_df.img_file_path,\\\n                                                 (val_df.large_bowel_seg_rle, val_df.small_bowel_seg_rle, val_df.stomach_seg_rle),\\\n                                                 (val_df.slice_w,val_df.slice_h)))\n\n    \n    # Images are normalized within \"tf_load_image\"\n    # Masks are created as stacks of multiple classes -> \"multilabel\"\n    train_ds = train_ds.map(lambda x,y,z: (tf_load_image(x), tf_load_mask(y,z,style=STYLE)), num_parallel_calls=AUTOTUNE)\n    \n    val_ds = val_ds.map(lambda x,y,z: (tf_load_image(x), tf_load_mask(y,z,style=STYLE)), num_parallel_calls=AUTOTUNE)\n\n    train_ds = train_ds.shuffle(SHUFFLE_BUFFER)\\\n                       .batch(BATCH_SIZE, drop_remainder=True)\\\n                       .map(augment_batch, num_parallel_calls=AUTOTUNE)\\\n                       .map(model_preprocessing_train, num_parallel_calls=AUTOTUNE)\\\n                       .map(add_sample_weights, num_parallel_calls=AUTOTUNE)\\\n                       .map(convert_2_float32_train)\\\n                       .prefetch(AUTOTUNE)    \n    # .map(model_preprocessing_train, num_parallel_calls=AUTOTUNE)\\\n    \n    # we only shuffle the validation a little because we don't want \n    # drop_remainder to hit the same images over and over...\n    val_ds = val_ds.shuffle(SHUFFLE_BUFFER//5)\\\n                   .batch(BATCH_SIZE, drop_remainder=True)\\\n                   .map(model_preprocessing_train, num_parallel_calls=AUTOTUNE)\\\n                   .map(convert_2_float32_val)\\\n                   .prefetch(AUTOTUNE)\n    \n    #.map(model_preprocessing_train, num_parallel_calls=AUTOTUNE)\\\n    \n    \n    \"\"\"\n    for _img_batch, _mask_batch in val_ds.take(1):\n        print(_img_batch.shape, _mask_batch.shape)\n        _img=_img_batch[0]\n        _mask=_mask_batch[0]\n        plt.figure(figsize=(15,5))\n        plt.subplot(1,2,1)\n        plt.imshow(tf.cast(_mask, tf.float32))\n\n        plt.subplot(1,2,2)\n        plt.imshow(tf.cast((_img+1)*127.5, tf.uint8))\n\n        plt.tight_layout()\n        plt.show()\"\"\"\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:41.4801Z","iopub.execute_input":"2022-05-31T04:43:41.48049Z","iopub.status.idle":"2022-05-31T04:43:43.921093Z","shell.execute_reply.started":"2022-05-31T04:43:41.48031Z","shell.execute_reply":"2022-05-31T04:43:43.920388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = tf.data.Dataset.from_tensor_slices((test_df.img_file_path,\\\n                                                 (test_df.large_bowel_seg_rle, test_df.small_bowel_seg_rle, test_df.stomach_seg_rle),\\\n                                                 (test_df.slice_w, test_df.slice_h)))\ntest_ds = test_ds.map(lambda x,y,z: (tf_load_image(x), tf_load_mask(y,z,style=STYLE)), num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)\\\n                 .map(model_preprocessing_train, num_parallel_calls=AUTOTUNE)\\\n                 .prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:43.922448Z","iopub.execute_input":"2022-05-31T04:43:43.922702Z","iopub.status.idle":"2022-05-31T04:43:44.169574Z","shell.execute_reply.started":"2022-05-31T04:43:43.922666Z","shell.execute_reply":"2022-05-31T04:43:44.168852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train Dataset:\", train_ds)\nprint(\"Val Dataset:\", val_ds)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:44.170908Z","iopub.execute_input":"2022-05-31T04:43:44.171156Z","iopub.status.idle":"2022-05-31T04:43:44.177554Z","shell.execute_reply.started":"2022-05-31T04:43:44.171124Z","shell.execute_reply":"2022-05-31T04:43:44.176847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We only need every third row (hence the iloc[::3])\nsubmission_ds = tf.data.Dataset.from_tensor_slices(ss_df.iloc[::3].img_file_path.tolist())\nsubmission_ds = submission_ds.map(lambda x: tf_load_image(x), num_parallel_calls=AUTOTUNE)\n# This should be deterministic... i.e. the order of images will match the order of IDs\nsubmission_ds = submission_ds.batch(BATCH_SIZE)\\\n                    .map(model_preprocessing_test, num_parallel_calls=AUTOTUNE)\\\n                    .prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:44.178964Z","iopub.execute_input":"2022-05-31T04:43:44.179405Z","iopub.status.idle":"2022-05-31T04:43:44.331744Z","shell.execute_reply.started":"2022-05-31T04:43:44.179364Z","shell.execute_reply":"2022-05-31T04:43:44.331016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Model Building***","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D, UpSampling2D, Reshape, Dense\nfrom tensorflow.keras.models import Model\n\ndef SqueezeAndExcite(inputs, ratio=8):\n    init = inputs\n    filters = init.shape[-1]\n    se_shape = (1, 1, filters)\n\n    se = GlobalAveragePooling2D()(init)\n    se = Reshape(se_shape)(se)\n    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n    x = init * se\n    return x\n\ndef ASPP(aspp_input):\n    \"\"\"\n    Atrous(Dilated) pyramid pooling\n    \"\"\"\n    shape = aspp_input.shape\n    #Image Pooling\n    y1 = AveragePooling2D(pool_size = (shape[1], shape[2]))(aspp_input)\n    y1 = Conv2D(256, 1, padding=\"same\", use_bias=False)(y1)\n    y1 = BatchNormalization()(y1)\n    y1 = Activation(\"relu\")(y1)\n    y1 = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y1)\n\n    \"\"\" 1x1 conv \"\"\"\n    y2 = Conv2D(256, 1, padding=\"same\", use_bias=False)(aspp_input)\n    y2 = BatchNormalization()(y2)\n    y2 = Activation(\"relu\")(y2)\n\n    \"\"\" 3x3 conv rate=6 \"\"\"\n    y3 = Conv2D(256, 3, padding=\"same\", use_bias=False, dilation_rate=6)(aspp_input)\n    y3 = BatchNormalization()(y3)\n    y3 = Activation(\"relu\")(y3)\n\n    \"\"\" 3x3 conv rate=12 \"\"\"\n    y4 = Conv2D(256, 3, padding=\"same\", use_bias=False, dilation_rate=12)(aspp_input)\n    y4 = BatchNormalization()(y4)\n    y4 = Activation(\"relu\")(y4)\n\n    \"\"\" 3x3 conv rate=18 \"\"\"\n    y5 = Conv2D(256, 3, padding=\"same\", use_bias=False, dilation_rate=18)(aspp_input)\n    y5 = BatchNormalization()(y5)\n    y5 = Activation(\"relu\")(y5)\n\n    y = Concatenate()([y1, y2, y3, y4, y5])\n    y = Conv2D(256, 1, padding=\"same\", use_bias=False)(y)\n    y = BatchNormalization()(y)\n    y = Activation(\"relu\")(y)\n\n    return y\n    \n    \ndef Deeplabv3_plus(img_h, img_w,\n                   backbone,\n                   low_feat_layer, high_feat_layer,\n                   n_classes,\n                   weights = \"imagenet\",\n                   dropout = 0.3):\n    \"\"\" Input \"\"\"\n    _input = Input((img_h, img_w, 3))\n    \n    \"\"\"Encoder\"\"\"\n    encoder = backbone(weights = weights, include_top = False, input_tensor = _input)\n    # Take high level features from the backbone model\n    image_features = encoder.get_layer(high_feat_layer).output\n    #Put high level features through dilated average pooling\n    x_a = ASPP(image_features)\n    x_a = UpSampling2D((4,4), interpolation = \"bilinear\")(x_a)\n    \n    #Get low level features from backbone model\n    x_b = encoder.get_layer(low_feat_layer).output\n    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n    x_b = BatchNormalization()(x_b)\n    x_b = Activation('relu')(x_b)\n\n    x = Concatenate()([x_a, x_b])\n    x = SqueezeAndExcite(x)\n\n    x = Conv2D(filters=256, kernel_size=3, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters=256, kernel_size=3, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SqueezeAndExcite(x)\n\n    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n    x = Conv2D(n_classes, kernel_size =(1,1), padding = \"same\")(x)\n    x = Activation(\"sigmoid\")(x)\n\n    model = Model(_input, x)\n    return model\n ","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:44.333106Z","iopub.execute_input":"2022-05-31T04:43:44.333349Z","iopub.status.idle":"2022-05-31T04:43:44.355835Z","shell.execute_reply.started":"2022-05-31T04:43:44.333301Z","shell.execute_reply":"2022-05-31T04:43:44.354629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_H, IMG_W = IMAGE_SHAPE\nBACKBONE = tf.keras.applications.ResNet50\nLOW_FEAT_LAYER = \"conv2_block2_out\"\nHIGH_FEAT_LAYER = \"conv4_block6_out\"\nDO_TRAIN = False\n#We can add addtional weights, but I will stick with the \"imagenet\" for now\n# For now, I am trying to do \"multilabel\"\nif STYLE==\"multiclass\":\n    N_CLASSES = len(classes) # n_classses+background\nelse: \n    N_CLASSES = len(classes) # n_classses (binary so background is 0 in each channel)\n\nMODEL_INSPECT = \"summary\"\nSUB_NODEBUG_MODEL_WT_PATH = \"../input/2021-5-30-trained-resnet50-256x256x3-multiclass/resnet50_256x256x3_multiclass\"\nWEIGHT_PATH = \"../input/tf-keras-pretrained-model-weights/No Top/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n\nif DO_TRAIN:\n    deeplabv3plus = Deeplabv3_plus(IMG_H, IMG_W,\n                   BACKBONE,\n                   LOW_FEAT_LAYER, HIGH_FEAT_LAYER,\n                   n_classes = N_CLASSES, weights = WEIGHT_PATH)\n    if MODEL_INSPECT==\"plot\":\n        display(tf.keras.utils.plot_model(deeplabv3plus))\n    elif MODEL_INSPECT==\"summary\":\n        print(deeplabv3plus.summary())\nelse:\n    deeplabv3plus = tf.keras.models.load_model(SUB_NODEBUG_MODEL_WT_PATH, compile=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:44.357267Z","iopub.execute_input":"2022-05-31T04:43:44.357716Z","iopub.status.idle":"2022-05-31T04:43:54.221626Z","shell.execute_reply.started":"2022-05-31T04:43:44.357657Z","shell.execute_reply":"2022-05-31T04:43:54.220747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TRANINING THE MODEL**","metadata":{}},{"cell_type":"markdown","source":"**Setting up evaluation metrics**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import backend as K\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    smooth = 0.0001\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_multilabel(y_true, y_pred, numLabels = N_CLASSES):\n    dice=0\n    for index in range(numLabels):\n        dice += dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index])\n    return dice/numLabels\n\ndef dice_loss(y_true, y_pred):\n    return (1 - dice_coef_multilabel(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:54.222975Z","iopub.execute_input":"2022-05-31T04:43:54.22324Z","iopub.status.idle":"2022-05-31T04:43:54.232976Z","shell.execute_reply.started":"2022-05-31T04:43:54.223205Z","shell.execute_reply":"2022-05-31T04:43:54.232202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"# Custom Callback To Include in Callbacks List At Training Time\nfrom tensorflow.keras.metrics import Accuracy, Recall, Precision, MeanIoU\nclass GarbageCollectorCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        gc.collect()\n        tf.keras.backend.clear_session()\n        \ndef plot_history(_history, fold_num=\"1\", metrics=(\"acc\",)):\n    \"\"\" TBD \"\"\"\n    fig = px.line(_history.history, \n                  x=range(len(_history.history[\"loss\"])), \n                  y=[\"loss\", \"val_loss\"],\n                  labels={\"value\":\"Loss (log-axis)\", \"x\":\"Epoch #\"},\n                  title=f\"<b>FOLD {fold_num} MODEL - LOSS</b>\", log_y=True\n                  )\n    fig.show()\n\n    for _m in metrics:\n        fig = px.line(_history.history, \n                      x=range(len(_history.history[_m])), \n                      y=[_m, f\"val_{_m}\"],\n                      labels={\"value\":f\"{_m} (log-axis)\", \"x\":\"Epoch #\"},\n                      title=f\"<b>FOLD {fold_num} MODEL - {_m}</b>\", log_y=True)\n        fig.show()    \n\nN_EPOCH = 10\nif DO_TRAIN:\n    OPTIMIZER = tf.keras.optimizers.Adam(0.0006666)\n    if STYLE==\"multiclass\":\n        LOSS = tf.keras.losses.SparseCategoricalCrossentropy()\n    else:\n        LOSS = tfa.losses.SigmoidFocalCrossEntropy()\n        \n    METRICS = [\"acc\"]\n               \n\n    _lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.75, \n                                                  patience=2, verbose=1, mode=\"min\")\n    _es_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",  patience=4, \n                                              verbose=1, mode=\"min\",\n                                              restore_best_weights=True)\n    _ckpt_cb = tf.keras.callbacks.ModelCheckpoint(f'./resnet50_{IMAGE_SHAPE[0]}x{IMAGE_SHAPE[1]}x3_{STYLE}', \n                                                  monitor='val_loss', mode=\"min\",\n                                                  save_best_only=True, options=save_locally)\n    _gc_cb = GarbageCollectorCallback()\n    CB_LIST = [_es_cb, _ckpt_cb, _lr_cb, _gc_cb]\n\n    deeplabv3plus.compile(optimizer=OPTIMIZER, loss=dice_loss, metrics=[Accuracy(), dice_coef_multilabel])\n    history = deeplabv3plus.fit(train_ds, validation_data=val_ds, epochs=N_EPOCH, callbacks=CB_LIST)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:54.234792Z","iopub.execute_input":"2022-05-31T04:43:54.235118Z","iopub.status.idle":"2022-05-31T04:43:54.249258Z","shell.execute_reply.started":"2022-05-31T04:43:54.23507Z","shell.execute_reply":"2022-05-31T04:43:54.248372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_overlay(img, mask, _alpha=0.999, _beta=0.45, _gamma=0):\n    \n    # Normalize to be between 0-1 (float32)\n    img = (img/img.max()).astype(np.float32)\n    \n    # Make mask RGB and float32\n    if len(mask.shape)==2:\n        mask_rgb = np.zeros_like(img, dtype=np.float32)\n        mask_rgb[..., 2] = np.where(mask==3, 1.0, 0.0)\n        mask_rgb[..., 1] = np.where(mask==2, 1.0, 0.0)\n        mask_rgb[..., 0] = np.where(mask==1, 1.0, 0.0)\n    else:\n        mask_rgb=mask.astype(np.float32)\n    \n    # overlay\n    seg_overlay = cv2.addWeighted(src1=img, alpha=_alpha, \n                                  src2=mask_rgb, beta=_beta, gamma=_gamma)\n    return seg_overlay\n\ndef get_miss_overlay(gt_mask, pred_mask, _alpha=0.9, _beta=0.25, _gamma=0):\n    \n    # Make mask RGB and float32\n    miss_rgb = np.zeros((*pred_mask.shape[:2],3), dtype=np.float32)\n    if len(pred_mask.shape)==2:\n        miss_rgb[..., 1] = np.where((gt_mask==pred_mask)&(gt_mask!=0), 0.8, 0.0)\n        miss_rgb[..., 0] = np.where((gt_mask!=pred_mask), 0.8, 0.0)\n    else:\n        miss_rgb = np.where((gt_mask==pred_mask)&(gt_mask!=0.0), (0.0,0.8,0.0), (0.0,0.0,0.0))\n        miss_rgb = np.where((gt_mask!=pred_mask), (0.8,0.0,0.0), miss_rgb)\n        \n    return miss_rgb\n\ndef plot_preds(img, pred_mask, gt_mask):\n    gt_overlay = get_overlay(img, gt_mask)\n    pred_overlay = get_overlay(img, pred_mask)\n    #miss_overlay = get_miss_overlay(gt_mask, pred_mask)\n    \n    miss_overlay_lb = get_miss_overlay(gt_mask[...,0].squeeze().astype(np.float32), pred_mask[...,0].squeeze().astype(np.float32))\n    miss_overlay_sb = get_miss_overlay(gt_mask[...,1].squeeze().astype(np.float32), pred_mask[...,1].squeeze().astype(np.float32))\n    miss_overlay_st = get_miss_overlay(gt_mask[...,2].squeeze().astype(np.float32), pred_mask[...,2].squeeze().astype(np.float32))\n    \n    plt.figure(figsize=(27,17))\n    \n    for i, (_desc, _img) in enumerate(zip([\"Prediction Mask\", \"Ground-Truth Mask\", \"Miss Mask Large Bowel\", \"Miss Mask Small Bowel\", \"Miss Mask Stomach\"],\n                                          [pred_overlay, gt_overlay, miss_overlay_lb, miss_overlay_sb, miss_overlay_st])):        \n        plt.subplot(1,5,i+1)\n        plt.imshow(_img)\n        plt.title(f\"{_desc} Image\", fontweight=\"bold\")        \n        plt.axis(False)\n        \n        if i in [0,1]:\n            handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n            labels = [\"Large Bowel Segmentation Map\", \"Small Bowel Segmentation Map\", \"Stomach Segmentation Map\"]\n            plt.legend(handles,labels)\n        elif i in [2,3,4]:\n            handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.0,0.8,0.0), (0.8,0.0,0.0), (0.0, 0.0, 0.0)]]\n            labels = [\"Agreement\", \"Disagreement\", \"Background\"]\n            plt.legend(handles,labels)\n    plt.tight_layout()\n    plt.show()\n\n    \"\"\"\n    if DEBUG:\n    for img_batch, mask_batch in val_ds.take(1):\n        pred_batch = deeplabv3plus(img_batch)\n        \n        if STYLE==\"multiclass\":\n            pred_batch = np.where(pred_batch>=0.5, 1.0, 0.0)\n        else:\n            pred_batch = np.argmax(pred_batch, axis=-1)\n\n        img_batch = ((img_batch+1)*127.5).numpy().astype(np.int32)\n        mask_batch = mask_batch.numpy().squeeze().astype(np.float32)\n        break\n\n    for _img, _pred, _mask in zip(img_batch, pred_batch, mask_batch):\n        plot_preds(_img, _pred, _mask)\"\"\"\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:54.250948Z","iopub.execute_input":"2022-05-31T04:43:54.251225Z","iopub.status.idle":"2022-05-31T04:43:54.283057Z","shell.execute_reply.started":"2022-05-31T04:43:54.25119Z","shell.execute_reply":"2022-05-31T04:43:54.282377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_2_rle(pred_arr, root_shape):\n    \n    # Get correct size pred array based on initial slice size\n    lb_mask = cv2.resize(pred_arr[...,0], root_shape, interpolation=cv2.INTER_NEAREST)\n    sb_mask = cv2.resize(pred_arr[...,1], root_shape, interpolation=cv2.INTER_NEAREST)\n    st_mask = cv2.resize(pred_arr[...,2], root_shape, interpolation=cv2.INTER_NEAREST)\n    # Get individual segmentation masks\n    #lb_mask = np.where(pred_arr_lb==1,1,0)\n    #sb_mask = np.where(pred_arr_sb==1,1,0)\n    #st_mask = np.where(pred_arr_st==3,1,0)\n    return rle_encode(lb_mask), rle_encode(sb_mask), rle_encode(st_mask)\n\nN_TEST = int(np.ceil((len(ss_df)//3)/BATCH_SIZE))\n\nprint(\"\\n\\n\\n\\n\\n\\n \", \"............NOW WE START PREDICTING.................\", \"\\n\\n\\n\\n\\n\\n\\n\")\n\n# Loop over batches and get prediction\nfor i, img_batch in tqdm(enumerate(submission_ds), total=N_TEST):\n    # Cleanup every so often\n    if i%100==0:\n        gc.collect(); gc.collect(); tf.keras.backend.clear_session(); gc.collect()    \n    #print(img_batch.shape)\n    \n    # Get predictions\n    pred_batch = deeplabv3plus(img_batch, training=False).numpy()\n    pred_batch = np.where(pred_batch>=0.5, 1.0, 0.0)\n    #pred_batch = tf.argmax(deeplabv3plus(img_batch, training=False), axis=-1).numpy()\n    \n    # Loop over prediction and determine submission dataframe index (3*individual-count because of reduced inference size)\n    for j, _pred in enumerate(pred_batch):\n        df_idx = 3*(i*BATCH_SIZE+j)\n        pred_rles = pred_2_rle(_pred, (ss_df.iloc[df_idx][\"slice_h\"], ss_df.iloc[df_idx][\"slice_w\"]))\n        # Loop over rles and assign the correct row of the submission dataframe\n        for k,pred_rle in enumerate(pred_rles):\n            ss_df.loc[df_idx+k, \"predicted\"] = pred_rle","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:43:54.286993Z","iopub.execute_input":"2022-05-31T04:43:54.287188Z","iopub.status.idle":"2022-05-31T04:49:51.986395Z","shell.execute_reply.started":"2022-05-31T04:43:54.287165Z","shell.execute_reply":"2022-05-31T04:49:51.98558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fix_empty_slices(_row):\n    identifier = _row[\"id\"]\n    slice_id = identifier.split(\"_\",3)[3]\n    if int(slice_id) in remove_seg_slices[_row[\"class\"]]:\n        _row[\"predicted\"] = \"\"\n    return _row\n\ndef is_isolated(_row):\n    return (_row[\"predicted\"]!=\"\" and _row[\"prev_predicted\"]==\"\" and _row[\"next_predicted\"]==\"\")\n\ndef fix_nc_slices(_row):\n    if _row[\"seg_isolated\"]:\n        _row[\"predicted\"] = \"\"\n    return _row\n\n# No segmentation exists at these slices\nremove_seg_slices = {\n     \"large_bowel\": [1, 138, 139, 140, 141, 142, 143, 144],\n    \"small_bowel\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 138, 139, 140, 141, 142, 143, 144],\n    \"stomach\": [1, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144],\n}\n\n# Heuristic processing\nss_df = ss_df.apply(fix_empty_slices, axis=1)\n\nss_df[\"prev_predicted\"] = ss_df.shift(3, fill_value=\"\")[\"predicted\"]\nss_df[\"next_predicted\"] = ss_df.shift(-3, fill_value=\"\")[\"predicted\"]\nss_df[\"seg_isolated\"] = ss_df.apply(is_isolated, axis=1)\nss_df = ss_df.apply(fix_nc_slices, axis=1)\n\n# Submit\nss_df = ss_df[[\"id\", \"class\", \"predicted\"]]\nss_df.to_csv(\"submission.csv\", index=False)\ndisplay(ss_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T04:49:51.987913Z","iopub.execute_input":"2022-05-31T04:49:51.988597Z","iopub.status.idle":"2022-05-31T04:50:03.956964Z","shell.execute_reply.started":"2022-05-31T04:49:51.988545Z","shell.execute_reply":"2022-05-31T04:50:03.956178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}