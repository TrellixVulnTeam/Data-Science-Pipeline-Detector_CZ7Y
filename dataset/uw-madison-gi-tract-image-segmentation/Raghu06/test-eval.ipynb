{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries and setup","metadata":{}},{"cell_type":"code","source":"\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport gc\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nfrom datetime import datetime\nimport json,itertools\nfrom typing import Optional\nfrom glob import glob\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\nimport random\n\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\nfrom keras.models import load_model, save_model\nfrom matplotlib.patches import Rectangle\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T09:14:32.319179Z","iopub.execute_input":"2022-06-26T09:14:32.320217Z","iopub.status.idle":"2022-06-26T09:14:34.906577Z","shell.execute_reply.started":"2022-06-26T09:14:32.320098Z","shell.execute_reply":"2022-06-26T09:14:34.905561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reproducibility**","metadata":{}},{"cell_type":"code","source":"# Set random seeds\ndef set_seed(seed=0):\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\nset_seed(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:34.907981Z","iopub.execute_input":"2022-06-26T09:14:34.908828Z","iopub.status.idle":"2022-06-26T09:14:34.915287Z","shell.execute_reply.started":"2022-06-26T09:14:34.908777Z","shell.execute_reply":"2022-06-26T09:14:34.914244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\n... ACCELERATOR SETUP STARTING ...\\n\")\n\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \nexcept ValueError:\n    TPU = None\n\nif TPU:\n    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    print(f\"\\n... RUNNING ON CPU/GPU ...\")\n    strategy = tf.distribute.get_strategy() \n\nN_REPLICAS = strategy.num_replicas_in_sync\nprint(f\"... # OF REPLICAS: {N_REPLICAS} ...\\n\")\nprint(f\"\\n... ACCELERATOR SETUP COMPLTED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:34.916773Z","iopub.execute_input":"2022-06-26T09:14:34.917512Z","iopub.status.idle":"2022-06-26T09:14:34.93175Z","shell.execute_reply.started":"2022-06-26T09:14:34.91746Z","shell.execute_reply":"2022-06-26T09:14:34.930934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Config**","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 30\nEPOCHS = 1\nn_splits = 5\nfold_selected = 2   \nIMAGE_WIDTH = 256\nIMAGE_HEIGHT = 256","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:34.93409Z","iopub.execute_input":"2022-06-26T09:14:34.934629Z","iopub.status.idle":"2022-06-26T09:14:34.943157Z","shell.execute_reply.started":"2022-06-26T09:14:34.934592Z","shell.execute_reply":"2022-06-26T09:14:34.942306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"To import dataset in kaggle click on + Add data in top right corner -> go to competitions and choose the uw-madison-gi-tract-image-segmentation datset","metadata":{}},{"cell_type":"code","source":"print(\"\\n... DATA ACCESS SETUP STARTED ...\\n\")\n\nDATA_DIR = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\nsave_locally = None\nload_locally = None\n\n# if TPU:\n#     # Google Cloud Dataset path to training and validation images\n#     DATA_DIR = KaggleDatasets().get_gcs_path('uw-madison-gi-tract-image-segmentation')\n#     save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n#     load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n# else:\n#     DATA_DIR = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\n#     save_locally = None\n#     load_locally = None","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:34.944406Z","iopub.execute_input":"2022-06-26T09:14:34.945224Z","iopub.status.idle":"2022-06-26T09:14:34.958061Z","shell.execute_reply.started":"2022-06-26T09:14:34.945187Z","shell.execute_reply":"2022-06-26T09:14:34.956659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train set**","metadata":{}},{"cell_type":"code","source":"TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV)\nprint(train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:34.959978Z","iopub.execute_input":"2022-06-26T09:14:34.961323Z","iopub.status.idle":"2022-06-26T09:14:35.295391Z","shell.execute_reply.started":"2022-06-26T09:14:34.96127Z","shell.execute_reply":"2022-06-26T09:14:35.294571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test set**","metadata":{}},{"cell_type":"code","source":"TEST_CSV = os.path.join(DATA_DIR, 'sample_submission.csv')\ntest_df = pd.read_csv(TEST_CSV)\n\nif len(test_df)==0:\n    DEBUG=True\n    test_df = train_df[115488-300:]\n    #test_df[\"segmentation\"]=''\n    #test_df=test_df.rename(columns={\"segmentation\":\"prediction\"})\nelse:\n    DEBUG=False\n\nsubmission=test_df.copy()\nsubmission[\"segmentation\"]=''\nsubmission=submission.rename(columns={\"segmentation\":\"prediction\"})\nprint(test_df.head())\nprint(submission.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:35.296609Z","iopub.execute_input":"2022-06-26T09:14:35.297266Z","iopub.status.idle":"2022-06-26T09:14:35.316323Z","shell.execute_reply.started":"2022-06-26T09:14:35.29723Z","shell.execute_reply":"2022-06-26T09:14:35.314989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocessing(df, subset=\"train\"):\n    df[\"case\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\n    df[\"day\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\n    df[\"slice\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n    if (subset==\"train\") or (DEBUG):\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/train\"\n    else:\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/test\"\n    \n    all_images = glob(os.path.join(DIR, \"**\", \"*.png\"), recursive=True)\n    x = all_images[0].rsplit(\"/\", 4)[0] \n\n    path_partial_list = []\n    for i in range(0, df.shape[0]):\n        path_partial_list.append(os.path.join(x,\n                              \"case\"+str(df[\"case\"].values[i]),\n                              \"case\"+str(df[\"case\"].values[i])+\"_\"+ \"day\"+str(df[\"day\"].values[i]),\n                              \"scans\",\n                              \"slice_\"+str(df[\"slice\"].values[i])))\n    df[\"path_partial\"] = path_partial_list\n    path_partial_list = []\n    for i in range(0, len(all_images)):\n        path_partial_list.append(str(all_images[i].rsplit(\"_\",4)[0]))\n\n    tmp_df = pd.DataFrame()\n    tmp_df['path_partial'] = path_partial_list\n    tmp_df['path'] = all_images\n\n    df = df.merge(tmp_df, on=\"path_partial\").drop(columns=[\"path_partial\"])\n    df[\"width\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"height\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n    del x, path_partial_list, tmp_df\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:35.317843Z","iopub.execute_input":"2022-06-26T09:14:35.319084Z","iopub.status.idle":"2022-06-26T09:14:35.343284Z","shell.execute_reply.started":"2022-06-26T09:14:35.319024Z","shell.execute_reply":"2022-06-26T09:14:35.341971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def restructure(df, subset=\"train\"):\n    # RESTRUCTURE  DATAFRAME\n    df_out = pd.DataFrame({'id': df['id'][::3]})\n\n    if True:\n        df_out['large_bowel'] = df['segmentation'][::3].values\n        df_out['small_bowel'] = df['segmentation'][1::3].values\n        df_out['stomach'] = df['segmentation'][2::3].values\n\n    df_out['path'] = df['path'][::3].values\n    df_out['case'] = df['case'][::3].values\n    df_out['day'] = df['day'][::3].values\n    df_out['slice'] = df['slice'][::3].values\n    df_out['width'] = df['width'][::3].values\n    df_out['height'] = df['height'][::3].values\n\n    df_out=df_out.reset_index(drop=True)\n    df_out=df_out.fillna('')\n    if subset==\"train\":\n        df_out['count'] = np.sum(df_out.iloc[:,1:4]!='',axis=1).values\n    \n    return df_out","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:35.345305Z","iopub.execute_input":"2022-06-26T09:14:35.34612Z","iopub.status.idle":"2022-06-26T09:14:35.36335Z","shell.execute_reply.started":"2022-06-26T09:14:35.346068Z","shell.execute_reply":"2022-06-26T09:14:35.36197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\ntrain_df = train_df[:115488-300]\ntrain_df = preprocessing(train_df, subset=\"train\")\nprint(train_df.shape)\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:35.365323Z","iopub.execute_input":"2022-06-26T09:14:35.365998Z","iopub.status.idle":"2022-06-26T09:14:40.453755Z","shell.execute_reply.started":"2022-06-26T09:14:35.365835Z","shell.execute_reply":"2022-06-26T09:14:40.452656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=preprocessing(test_df, subset=\"test\")\nprint(test_df.shape)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:40.454945Z","iopub.execute_input":"2022-06-26T09:14:40.455248Z","iopub.status.idle":"2022-06-26T09:14:41.354856Z","shell.execute_reply.started":"2022-06-26T09:14:40.455218Z","shell.execute_reply":"2022-06-26T09:14:41.353665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=restructure(train_df, subset=\"train\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.356427Z","iopub.execute_input":"2022-06-26T09:14:41.356821Z","iopub.status.idle":"2022-06-26T09:14:41.445534Z","shell.execute_reply.started":"2022-06-26T09:14:41.356787Z","shell.execute_reply":"2022-06-26T09:14:41.444514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=restructure(test_df, subset=\"test\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.449604Z","iopub.execute_input":"2022-06-26T09:14:41.449998Z","iopub.status.idle":"2022-06-26T09:14:41.476956Z","shell.execute_reply.started":"2022-06-26T09:14:41.449964Z","shell.execute_reply":"2022-06-26T09:14:41.475947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove mislabeled training data\nprint(train_df.shape, test_df.shape)\ntrain_df = train_df[(train_df['case']!=7)|(train_df['day']!=0)].reset_index(drop=True)\ntrain_df = train_df[(train_df['case']!=81)|(train_df['day']!=30)].reset_index(drop=True)\nprint(train_df.shape, test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.478388Z","iopub.execute_input":"2022-06-26T09:14:41.479024Z","iopub.status.idle":"2022-06-26T09:14:41.518088Z","shell.execute_reply.started":"2022-06-26T09:14:41.478991Z","shell.execute_reply":"2022-06-26T09:14:41.517143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Garbage collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.519448Z","iopub.execute_input":"2022-06-26T09:14:41.520547Z","iopub.status.idle":"2022-06-26T09:14:41.707086Z","shell.execute_reply.started":"2022-06-26T09:14:41.520506Z","shell.execute_reply":"2022-06-26T09:14:41.706042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape, test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.708399Z","iopub.execute_input":"2022-06-26T09:14:41.708704Z","iopub.status.idle":"2022-06-26T09:14:41.717748Z","shell.execute_reply.started":"2022-06-26T09:14:41.708673Z","shell.execute_reply":"2022-06-26T09:14:41.716934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = np.array(mask_rle.split(), dtype=int)   \n    starts = s[0::2] - 1 # Every even value is the start, every odd value is the \"run\" length\n    lengths = s[1::2]\n    ends = starts + lengths\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color    \n    return img.reshape(shape)    ","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.719162Z","iopub.execute_input":"2022-06-26T09:14:41.719972Z","iopub.status.idle":"2022-06-26T09:14:41.731211Z","shell.execute_reply.started":"2022-06-26T09:14:41.719919Z","shell.execute_reply":"2022-06-26T09:14:41.730107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run length encoding\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.732351Z","iopub.execute_input":"2022-06-26T09:14:41.732663Z","iopub.status.idle":"2022-06-26T09:14:41.746187Z","shell.execute_reply.started":"2022-06-26T09:14:41.732632Z","shell.execute_reply":"2022-06-26T09:14:41.745228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metrics\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n    return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + dice_loss(tf.cast(y_true, tf.float32), y_pred)\n\ndef tversky(y_true, y_pred):\n    smooth = 1\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\ndef focal_tversky(y_true,y_pred):\n    pt_1 = tversky(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1-pt_1), gamma)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.74766Z","iopub.execute_input":"2022-06-26T09:14:41.748203Z","iopub.status.idle":"2022-06-26T09:14:41.76329Z","shell.execute_reply.started":"2022-06-26T09:14:41.74817Z","shell.execute_reply":"2022-06-26T09:14:41.762283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, batch_size = BATCH_SIZE, subset=\"train\", shuffle=False, width=IMAGE_WIDTH, height=IMAGE_HEIGHT):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(df))\n        self.width=width\n        self.height=height\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index):\n        X = np.empty((self.batch_size,self.width,self.height,3))\n        y = np.empty((self.batch_size,self.width,self.height,3))\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i, img_path in enumerate(self.df['path'].iloc[indexes]):\n            w=self.df['width'].iloc[indexes[i]]\n            h=self.df['height'].iloc[indexes[i]]\n            img = self.__load_grayscale(img_path)\n            X[i,] =img  \n            if self.subset == 'train':\n                for k,j in enumerate([\"large_bowel\",\"small_bowel\",\"stomach\"]):\n                    rles = self.df[j].iloc[indexes[i]]\n                    mask = rle_decode(rles, shape=(h, w, 1))\n                    mask = cv2.resize(mask, (self.width, self.height))\n                    y[i,:,:,k] = mask\n        if self.subset == 'train':\n            return X,y\n        else: \n            return X\n        \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n        dsize = (self.width, self.height)\n        img = cv2.resize(img, dsize)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n        return img","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.764535Z","iopub.execute_input":"2022-06-26T09:14:41.76511Z","iopub.status.idle":"2022-06-26T09:14:41.848424Z","shell.execute_reply.started":"2022-06-26T09:14:41.765073Z","shell.execute_reply":"2022-06-26T09:14:41.847569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_grayscale(img_path):\n    img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n    print(img.shape)\n    print(img.max())\n    dsize = (img.shape[0]-img.shape[0]%32, img.shape[1]-img.shape[1]%32)\n    img = cv2.resize(img, dsize)\n    img = img.astype(np.float32)\n    print(img.max())\n    img = img / 255.\n    img = np.tile(np.expand_dims(img, axis=-1),3)\n    print(img.shape)\n    print(img.max())\n    return img\n\nimg = load_grayscale(train_df['path'].iloc[14])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.84967Z","iopub.execute_input":"2022-06-26T09:14:41.851224Z","iopub.status.idle":"2022-06-26T09:14:41.874047Z","shell.execute_reply.started":"2022-06-26T09:14:41.851061Z","shell.execute_reply":"2022-06-26T09:14:41.872584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"def open_gray16(_path, normalize=True, to_rgb=False):\n    if normalize:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/255., axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/255.\n    else:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.875325Z","iopub.execute_input":"2022-06-26T09:14:41.875658Z","iopub.status.idle":"2022-06-26T09:14:41.883766Z","shell.execute_reply.started":"2022-06-26T09:14:41.875612Z","shell.execute_reply":"2022-06-26T09:14:41.882631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def examine_id(DEMO_ID, seg_masks=False):\n  demo_ex = train_df[train_df.id==DEMO_ID].squeeze()\n  display(demo_ex.to_frame())\n\n  print(f\"\\n\\n...IMAGE ...\\n\")\n  plt.figure(figsize=(6,6))\n  plt.imshow(open_gray16(demo_ex.path), cmap=\"gray\")\n  plt.title(f\"Original Grayscale Image For ID: {demo_ex.id}\", fontweight=\"bold\")\n  plt.axis(False)\n  plt.show()\n\n  if(seg_masks):\n    print(f\"\\n\\n... 3 SEGMENTATION MASKS ...\\n\")\n\n    plt.figure(figsize=(14,7))\n    for i, _seg_type in enumerate([\"large_bowel\", \"small_bowel\", \"stomach\"]):\n        if pd.isna(demo_ex[f\"{_seg_type}\"]): continue\n        plt.subplot(1,3,i+1)\n        s = demo_ex[f\"{_seg_type}\"]\n        plt.imshow(rle_decode(demo_ex[f\"{_seg_type}\"], shape=(demo_ex.height, demo_ex.width), color=1))\n        plt.title(f\"RLE Encoding For {_seg_type} Segmentation\", fontweight=\"bold\")\n        plt.axis(False)\n    plt.tight_layout()\n    plt.show()\n\n  print(f\"\\n\\n...IMAGE WITH AN RGB SEGMENTATION MASK OVERLAY ...\\n\")\n\n  _img = open_gray16(demo_ex.path, to_rgb=True)\n  _img = ((_img-_img.min())/(_img.max()-_img.min())).astype(np.float32)\n  _seg_rgb = np.stack([rle_decode(demo_ex[f\"{_seg_type}\"], shape=(demo_ex.height, demo_ex.width), color=1) if not pd.isna(demo_ex[f\"{_seg_type}\"]) else np.zeros((demo_ex.height, demo_ex.width)) for _seg_type in [\"large_bowel\", \"small_bowel\", \"stomach\"]], axis=-1).astype(np.float32)\n  seg_overlay = cv2.addWeighted(src1=_img, alpha=0.99, src2=_seg_rgb, beta=0.33, gamma=0.0)\n\n  plt.figure(figsize=(6,6))\n  plt.imshow(seg_overlay)\n  plt.title(f\"Segmentation Overlay For ID: {demo_ex.id}\", fontweight=\"bold\")\n  handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n  labels = [\"Large Bowel Segmentation Map\", \"Small Bowel Segmentation Map\", \"Stomach Segmentation Map\"]\n  plt.legend(handles,labels)\n  plt.axis(False)\n  plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.885699Z","iopub.execute_input":"2022-06-26T09:14:41.886658Z","iopub.status.idle":"2022-06-26T09:14:41.911448Z","shell.execute_reply.started":"2022-06-26T09:14:41.886602Z","shell.execute_reply":"2022-06-26T09:14:41.910143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... SINGLE ID EXPLORATION ...\\n\\n\")\nDEMO_ID = \"case123_day20_slice_0082\"\nexamine_id(DEMO_ID, seg_masks=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.913225Z","iopub.execute_input":"2022-06-26T09:14:41.914033Z","iopub.status.idle":"2022-06-26T09:14:42.751113Z","shell.execute_reply.started":"2022-06-26T09:14:41.913979Z","shell.execute_reply":"2022-06-26T09:14:42.749953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation","metadata":{}},{"cell_type":"code","source":"# Group by case id\nskf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\nfor fold, (_, val_idx) in enumerate(skf.split(X=train_df, y=train_df['count'], groups=train_df['case']), 1):\n    train_df.loc[val_idx, 'fold'] = fold\n\ntrain_df['fold'] = train_df['fold'].astype(np.uint8)\n\ntrain_ids = train_df[train_df[\"fold\"]!=fold_selected].index\nvalid_ids = train_df[train_df[\"fold\"]==fold_selected].index\n\nX_train = train_df[train_df.index.isin(train_ids)]\nX_valid = train_df[train_df.index.isin(valid_ids)]\n\ntrain_df.groupby('fold').size()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:42.752729Z","iopub.execute_input":"2022-06-26T09:14:42.753992Z","iopub.status.idle":"2022-06-26T09:14:42.961399Z","shell.execute_reply.started":"2022-06-26T09:14:42.753938Z","shell.execute_reply":"2022-06-26T09:14:42.960264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fold sizes\ntrain_df.groupby(['fold','count'])['id'].count()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:42.962752Z","iopub.execute_input":"2022-06-26T09:14:42.963102Z","iopub.status.idle":"2022-06-26T09:14:42.980841Z","shell.execute_reply.started":"2022-06-26T09:14:42.96307Z","shell.execute_reply":"2022-06-26T09:14:42.979863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"! pip install segmentation-models","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-26T09:14:42.982195Z","iopub.execute_input":"2022-06-26T09:14:42.982515Z","iopub.status.idle":"2022-06-26T09:14:54.703823Z","shell.execute_reply.started":"2022-06-26T09:14:42.982483Z","shell.execute_reply":"2022-06-26T09:14:54.702634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install git+https://github.com/qubvel/segmentation_models","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-26T09:14:54.705309Z","iopub.execute_input":"2022-06-26T09:14:54.705648Z","iopub.status.idle":"2022-06-26T09:15:10.758789Z","shell.execute_reply.started":"2022-06-26T09:14:54.705615Z","shell.execute_reply":"2022-06-26T09:15:10.757727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')\nsm.framework()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:15:10.761196Z","iopub.execute_input":"2022-06-26T09:15:10.761721Z","iopub.status.idle":"2022-06-26T09:15:10.847324Z","shell.execute_reply.started":"2022-06-26T09:15:10.761666Z","shell.execute_reply":"2022-06-26T09:15:10.846262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data generators \ntrain_generator = DataGenerator(X_train, shuffle=True)\nval_generator = DataGenerator(X_valid)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:15:10.848761Z","iopub.execute_input":"2022-06-26T09:15:10.849127Z","iopub.status.idle":"2022-06-26T09:15:10.855779Z","shell.execute_reply.started":"2022-06-26T09:15:10.849094Z","shell.execute_reply":"2022-06-26T09:15:10.85462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"!pwd\n!ls\n!cd ./288-no-freeze\n!ls","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:15:10.858051Z","iopub.execute_input":"2022-06-26T09:15:10.858632Z","iopub.status.idle":"2022-06-26T09:15:13.887048Z","shell.execute_reply.started":"2022-06-26T09:15:10.85858Z","shell.execute_reply":"2022-06-26T09:15:13.885113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_objects = custom_objects={\n    'dice_coef': dice_coef,\n    'iou_coef': iou_coef,\n    'bce_dice_loss': bce_dice_loss,\n    'tversky' : tversky,\n    'focal_tversky': focal_tversky\n}\n\n\n#model1 = load_model('../input/final-model/1/UNET_model', custom_objects=custom_objects)\n#model2 = load_model('../input/final-model/2/2/UNET_model', custom_objects=custom_objects)\n#model3 = load_model('../input/final-model/3/UNET_model', custom_objects=custom_objects)\n#model4 = load_model('../input/final-model/4/4/UNET_model', custom_objects=custom_objects)\n#model5 = load_model('../input/final-model/5/UNET_model', custom_objects=custom_objects)\n#model6 = load_model('../input/final-model/6/UNET_model', custom_objects=custom_objects)\n#model7 = load_model('../input/final-model/7/UNET_model', custom_objects=custom_objects)\n#model9 = load_model('../input/final-model/9/9/UNET_model', custom_objects=custom_objects)\n#model11 = load_model('../input/new-model-1/11/UNET_model', custom_objects=custom_objects)\nmodel12 = load_model('../input/new-model-1/12/12/UNET_model', custom_objects=custom_objects)\n#model3_2 = load_model('../input/new-model-1/3_2/UNET_model', custom_objects=custom_objects)\n#model13 = load_model('../input/new-model-2/13/UNET_model', custom_objects=custom_objects)\n#model14 = load_model('../input/new-model-2/14/UNET_model', custom_objects=custom_objects)\n#model15 = load_model('../input/new-model-2/15/15/UNET_model', custom_objects=custom_objects)\n#model16 = load_model('../input/new-model-2/16/16/UNET_model', custom_objects=custom_objects)\n#model17 = load_model('../input/new-model-2/17/UNET_model', custom_objects=custom_objects)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:15:13.892508Z","iopub.execute_input":"2022-06-26T09:15:13.893467Z","iopub.status.idle":"2022-06-26T09:17:57.999852Z","shell.execute_reply.started":"2022-06-26T09:15:13.89341Z","shell.execute_reply":"2022-06-26T09:17:57.998785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preview predictions**","metadata":{}},{"cell_type":"code","source":"pred_batches = DataGenerator(test_df, batch_size = 1, subset=\"train\", shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:24:28.398279Z","iopub.execute_input":"2022-06-26T09:24:28.399907Z","iopub.status.idle":"2022-06-26T09:24:28.411932Z","shell.execute_reply.started":"2022-06-26T09:24:28.399817Z","shell.execute_reply":"2022-06-26T09:24:28.409038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model12.evaluate(pred_batches,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:24:28.60778Z","iopub.execute_input":"2022-06-26T09:24:28.609328Z","iopub.status.idle":"2022-06-26T09:24:55.87918Z","shell.execute_reply.started":"2022-06-26T09:24:28.609268Z","shell.execute_reply":"2022-06-26T09:24:55.877734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model12.predict_generator(pred_batches,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:28:27.859163Z","iopub.execute_input":"2022-06-26T09:28:27.860061Z","iopub.status.idle":"2022-06-26T09:28:54.340628Z","shell.execute_reply.started":"2022-06-26T09:28:27.860009Z","shell.execute_reply":"2022-06-26T09:28:54.339365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nThreshold = 0.5\n# Visualizing\nfig = plt.figure(figsize=(10, 25))\ngs = gridspec.GridSpec(nrows=8, ncols=3)\ncolors = ['yellow','green','red']\nlabels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\npatches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3= mpl.colors.ListedColormap(colors[2])\n\n# for j in range(16):\nfor i in range(8):\n    images, mask = pred_batches[i + 72]\n    sample_img=images[0,:,:,0]\n    mask1=mask[0,:,:,0]\n    mask2=mask[0,:,:,1]\n    mask3=mask[0,:,:,2]\n\n    pre=preds[i + 72]\n    predict1=pre[:,:,0]\n    predict2=pre[:,:,1]\n    predict3=pre[:,:,2]\n\n    predict1= (predict1 > Threshold).astype(np.float32)\n    predict2= (predict2 > Threshold).astype(np.float32)\n    predict3= (predict3 > Threshold).astype(np.float32)\n\n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img, cmap='bone')\n    ax0.set_title(\"Image\", fontsize=12, y=1.01)\n    #--------------------------\n    ax1 = fig.add_subplot(gs[i, 1])\n    ax1.set_title(\"Mask\", fontsize=12,  y=1.01)\n    l0 = ax1.imshow(sample_img, cmap='bone')\n    l1 = ax1.imshow(np.ma.masked_where(mask1== False,  mask1),cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(mask2== False,  mask2),cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(mask3== False,  mask3),cmap=cmap3, alpha=1)\n    #--------------------------\n    ax2 = fig.add_subplot(gs[i, 2])\n    ax2.set_title(\"Predict\", fontsize=12, y=1.01)\n    l0 = ax2.imshow(sample_img, cmap='bone')\n    l1 = ax2.imshow(np.ma.masked_where(predict1== False,  predict1),cmap=cmap1, alpha=1)\n    l2 = ax2.imshow(np.ma.masked_where(predict2== False,  predict2),cmap=cmap2, alpha=1)\n    l3 = ax2.imshow(np.ma.masked_where(predict3== False,  predict3),cmap=cmap3, alpha=1)\n\n\n    _ = [ax.set_axis_off() for ax in [ax0,ax1,ax2]]\n    colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]\n    plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 12,title='Mask Labels', title_fontsize=12, edgecolor=\"black\",  facecolor='#c5c6c7')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:28:54.342376Z","iopub.execute_input":"2022-06-26T09:28:54.342866Z","iopub.status.idle":"2022-06-26T09:28:56.804253Z","shell.execute_reply.started":"2022-06-26T09:28:54.342812Z","shell.execute_reply":"2022-06-26T09:28:56.803167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test set predictions","metadata":{}},{"cell_type":"markdown","source":"**Save predictions**","metadata":{}}]}