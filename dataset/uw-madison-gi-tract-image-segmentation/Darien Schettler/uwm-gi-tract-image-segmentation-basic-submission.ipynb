{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<br>\n\n<br><center><img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/27923/logos/header.png?t=2021-06-02-20-30-25\" width=100%></center>\n\n<h2 style=\"text-align: center; font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: underline; text-transform: none; letter-spacing: 2px; color: teal; background-color: #ffffff;\">UWM - GI Tract Image Segmentation Challenge<br><br>Explore Basic Submissions<br></h2>\n<h5 style=\"text-align: center; font-family: Verdana; font-size: 12px; font-style: normal; font-weight: bold; text-decoration: None; text-transform: none; letter-spacing: 1px; color: black; background-color: #ffffff;\">CREATED BY: DARIEN SCHETTLER</h5>\n\n<br>\n\n---\n\n<br>\n\n<center><div class=\"alert alert-block alert-warning\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 18px;\">üëè &nbsp; IF YOU FORK THIS OR FIND THIS HELPFUL &nbsp; üëè</b><br><br><b style=\"font-size: 22px; color: darkorange\">PLEASE UPVOTE!</b><br><br>This was a lot of work for me and while it may seem silly, it makes me feel appreciated when others like my work. üòÖ\n</div></center>\n\n\n","metadata":{}},{"cell_type":"code","source":"print(\"\\n... IMPORTS STARTING ...\\n\")\n\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t‚Äì TENSORFLOW VERSION: {tf.__version__}\");\nimport tensorflow_hub as tfhub; print(f\"\\t\\t‚Äì TENSORFLOW HUB VERSION: {tfhub.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t‚Äì TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t‚Äì NUMPY VERSION: {np.__version__}\");\nimport sklearn; print(f\"\\t\\t‚Äì SKLEARN VERSION: {sklearn.__version__}\");\nfrom sklearn.preprocessing import RobustScaler, PolynomialFeatures\nfrom pandarallel import pandarallel; pandarallel.initialize();\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom scipy.spatial import cKDTree\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom datetime import datetime\nfrom glob import glob\nimport warnings\nimport requests\nimport hashlib\nimport imageio\nimport IPython\nimport sklearn\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport json\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.patches import Rectangle\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image, ImageEnhance\nimport matplotlib; print(f\"\\t\\t‚Äì MATPLOTLIB VERSION: {matplotlib.__version__}\");\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')\nimport plotly\nimport PIL\nimport cv2\n    \nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:24:28.567038Z","iopub.execute_input":"2022-05-02T19:24:28.56734Z","iopub.status.idle":"2022-05-02T19:24:36.999435Z","shell.execute_reply.started":"2022-05-02T19:24:28.567306Z","shell.execute_reply":"2022-05-02T19:24:36.998504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... BASIC DATA SETUP STARTING ...\\n\\n\")\n\n# Open the training dataframe and display the initial dataframe\nDATA_DIR = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\nTRAIN_DIR = os.path.join(DATA_DIR, \"train\")\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV)\n\n# Get all training images\nall_train_images = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n\nprint(\"\\n... ORIGINAL TRAINING DATAFRAME... \\n\")\ndisplay(train_df)\n\nTEST_DIR = os.path.join(DATA_DIR, \"test\")\nSS_CSV   = os.path.join(DATA_DIR, \"sample_submission.csv\")\nss_df = pd.read_csv(SS_CSV)\n\n# Get all testing images if there are any\nall_test_images = glob(os.path.join(TEST_DIR, \"**\", \"*.png\"), recursive=True)\n\n# For debugging purposes when the test set hasn't been substituted we will know\nDEBUG=len(ss_df)==0\n\nif DEBUG:\n    TEST_DIR = TRAIN_DIR\n    all_test_images = all_train_images\n    ss_df = train_df.iloc[:10]\n    ss_df = ss_df[[\"id\", \"class\"]]\n    ss_df[\"predicted\"] = \"\"\n    \n\nprint(\"\\n\\n\\n... ORIGINAL SUBMISSION DATAFRAME... \\n\")    \ndisplay(ss_df)\n\nSF2LF = {\"lb\":\"Large Bowel\",\"sb\":\"Small Bowel\",\"st\":\"Stomach\"}\nLF2SF = {v:k for k,v in SF2LF.items()}\nprint(f\"\\n\\n\\n... ARE WE DEBUGGING: {DEBUG}... \\n\")\n\nprint(\"\\n... BASIC DATA SETUP FINISHED ...\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:24:37.001517Z","iopub.execute_input":"2022-05-02T19:24:37.001828Z","iopub.status.idle":"2022-05-02T19:24:46.023584Z","shell.execute_reply.started":"2022-05-02T19:24:37.001787Z","shell.execute_reply":"2022-05-02T19:24:46.022943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_filepath_from_partial_identifier(_ident, file_list):\n    return [x for x in file_list if _ident in x][0]\n\ndef df_preprocessing(df, globbed_file_list, is_test=False):\n    \"\"\" The preprocessing steps applied to get column information \"\"\"\n    # 1. Get Case-ID as a column (str and int)\n    df[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\n    df[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n    # 2. Get Day as a column\n    df[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\n    df[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n    # 3. Get Slice Identifier as a column\n    df[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\n    # 4. Get full file paths for the representative scans\n    df[\"_partial_ident\"] = (globbed_file_list[0].rsplit(\"/\", 4)[0]+\"/\"+ # /kaggle/input/uw-madison-gi-tract-image-segmentation/train/\n                           df[\"case_id_str\"]+\"/\"+ # .../case###/\n                           df[\"case_id_str\"]+\"_\"+df[\"day_num_str\"]+ # .../case###_day##/\n                           \"/scans/\"+df[\"slice_id\"]) # .../slice_#### \n    _tmp_merge_df = pd.DataFrame({\"_partial_ident\":[x.rsplit(\"_\",4)[0] for x in globbed_file_list], \"f_path\":globbed_file_list})\n    df = df.merge(_tmp_merge_df, on=\"_partial_ident\").drop(columns=[\"_partial_ident\"])\n\n    # 5. Get slice dimensions from filepath (int in pixels)\n    df[\"slice_h\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"slice_w\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n\n    # 6. Pixel spacing from filepath (float in mm)\n    df[\"px_spacing_h\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[3]))\n    df[\"px_spacing_w\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[4]))\n\n    if not is_test:\n        # 7. Merge 3 Rows Into A Single Row (As This/Segmentation-RLE Is The Only Unique Information Across Those Rows)\n        l_bowel_df = df[df[\"class\"]==\"large_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"lb_seg_rle\"})\n        s_bowel_df = df[df[\"class\"]==\"small_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"sb_seg_rle\"})\n        stomach_df = df[df[\"class\"]==\"stomach\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"st_seg_rle\"})\n        df = df.merge(l_bowel_df, on=\"id\", how=\"left\")\n        df = df.merge(s_bowel_df, on=\"id\", how=\"left\")\n        df = df.merge(stomach_df, on=\"id\", how=\"left\")\n        df = df.drop_duplicates(subset=[\"id\",]).reset_index(drop=True)\n        df[\"lb_seg_flag\"] = df[\"lb_seg_rle\"].apply(lambda x: not pd.isna(x))\n        df[\"sb_seg_flag\"] = df[\"sb_seg_rle\"].apply(lambda x: not pd.isna(x))\n        df[\"st_seg_flag\"] = df[\"st_seg_rle\"].apply(lambda x: not pd.isna(x))\n        df[\"n_segs\"] = df[\"lb_seg_flag\"].astype(int)+df[\"sb_seg_flag\"].astype(int)+df[\"st_seg_flag\"].astype(int)\n\n    # 8. Reorder columns to the a new ordering (drops class and segmentation as no longer necessary)\n    new_col_order = [\"id\", \"f_path\", \"n_segs\",\n                     \"lb_seg_rle\", \"lb_seg_flag\",\n                     \"sb_seg_rle\", \"sb_seg_flag\", \n                     \"st_seg_rle\", \"st_seg_flag\",\n                     \"slice_h\", \"slice_w\", \"px_spacing_h\", \n                     \"px_spacing_w\", \"case_id_str\", \"case_id\", \n                     \"day_num_str\", \"day_num\", \"slice_id\",]\n    if is_test: new_col_order.insert(1, \"class\")\n    new_col_order = [_c for _c in new_col_order if _c in df.columns]\n    df = df[new_col_order]\n    \n    return df\n\ntrain_df = df_preprocessing(train_df, all_train_images)\nss_df = df_preprocessing(ss_df, all_test_images, is_test=True)\n\ndisplay(train_df)\ndisplay(ss_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:24:46.024904Z","iopub.execute_input":"2022-05-02T19:24:46.025176Z","iopub.status.idle":"2022-05-02T19:24:47.729136Z","shell.execute_reply.started":"2022-05-02T19:24:46.025118Z","shell.execute_reply":"2022-05-02T19:24:47.728567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns: \n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    # Split the string by space, then convert it into a integer array\n    s = np.array(mask_rle.split(), dtype=int)\n\n    # Every even value is the start, every odd value is the \"run\" length\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n\n    # The image image is actually flattened since RLE is a 1D \"run\"\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n\n    # The color here is actually just any integer you want!\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n        \n    # Don't forget to change the image back to the original shape\n    return img.reshape(shape)\n\n# https://www.kaggle.com/namgalielei/which-reshape-is-used-in-rle\ndef rle_decode_top_to_bot_first(mask_rle, shape):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns:\n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape((shape[1], shape[0]), order='F').T  # Reshape from top -> bottom first\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    \"\"\" TBD\n    \n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n    \n    Returns: \n        run length as string formated\n    \"\"\"\n    \n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef open_gray16(_path, normalize=True, to_rgb=False):\n    \"\"\" Helper to open files \"\"\"\n    if normalize:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535., axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535.\n    else:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)\n        \ndef fix_empty_slices(_row):\n    if int(_row[\"slice_id\"].rsplit(\"_\", 1)[-1]) in remove_seg_slices[_row[\"class\"]]:\n        _row[\"predicted\"] = \"\"\n    return _row\n\ndef is_isolated(_row):\n    return (_row[\"predicted\"]!=\"\" and _row[\"prev_predicted\"]==\"\" and _row[\"next_predicted\"]==\"\")\n\ndef fix_nc_slices(_row):\n    if _row[\"seg_isolated\"]:\n        _row[\"predicted\"] = \"\"\n    return _row\n\nremove_seg_slices = {\n    \"large_bowel\": [1, 138, 139, 140, 141, 142, 143, 144],\n    \"small_bowel\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 138, 139, 140, 141, 142, 143, 144],\n    \"stomach\": [1, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144],\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:28:02.93405Z","iopub.execute_input":"2022-05-02T19:28:02.934339Z","iopub.status.idle":"2022-05-02T19:28:02.952021Z","shell.execute_reply.started":"2022-05-02T19:28:02.934308Z","shell.execute_reply":"2022-05-02T19:28:02.95142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **I HAVE REDUCED IT TO 5 BASIC PATHS**\n\n* **`'all_random'`**\n    * Predict masks/rle as completely random scattering of 0s and 1s\n* **`'all_zeros'`**\n    * Predict masks/rle as all zeros (black --> rle=\"\")\n* **`'all_ones'`**\n    * Predict masks/rle as all ones (white --> rle=\"1 [numer-of-pixels]\")\n* **`'basic_random'`**\n    * Predict masks/rle by sampling similar examples from the training dataset\n* **`'smart_random'`**\n    * Predict masks/rle by sampling similar examples from the training dataset\n    * Also apply basic heuristics to the final output to try to improve    ","metadata":{}},{"cell_type":"code","source":"SUBMISSION_STYLE = \"all_ones\" # ['smart_random', 'basic_random', 'all_random', all_zeros', 'all_ones']\n\nif SUBMISSION_STYLE==\"all_zeros\":\n    ss_df[\"predicted\"] = \"\"\nelif SUBMISSION_STYLE==\"all_ones\":\n    ss_df[\"predicted\"] = \"1 \"+(ss_df[\"slice_w\"]*ss_df[\"slice_h\"]).astype(str)\nelif SUBMISSION_STYLE==\"all_random\":\n    ss_df[\"predicted\"] = ss_df.apply(lambda row: rle_encode(np.where(np.random.random((row[\"slice_w\"], row[\"slice_h\"]))>0.5, 1.0, 0.0)), axis=1)\nelse:\n    \n    \n    # 1. Remove broken masks\n    remove_ids = [\"case7_day0\", \"case81_day30\"]\n    for _id in remove_ids:\n        train_df = train_df[~train_df.id.str.contains(_id)].reset_index(drop=True)\n\n    # 2. Get existing training data mappings to align with known metadata\n    slice_px_map = {}\n    for _, row in train_df.groupby([\"slice_h\", \"slice_w\", \"px_spacing_h\", \"px_spacing_w\", \"slice_id\"])[[\"lb_seg_rle\", \"sb_seg_rle\", \"st_seg_rle\"]].first().reset_index().iterrows():\n        slice_px_map[f\"{row['slice_h']}-{row['slice_w']}-{row['px_spacing_h']}-{row['px_spacing_w']}-{row['slice_id']}-large_bowel\"] = row[\"lb_seg_rle\"]\n        slice_px_map[f\"{row['slice_h']}-{row['slice_w']}-{row['px_spacing_h']}-{row['px_spacing_w']}-{row['slice_id']}-small_bowel\"] = row[\"sb_seg_rle\"]\n        slice_px_map[f\"{row['slice_h']}-{row['slice_w']}-{row['px_spacing_h']}-{row['px_spacing_w']}-{row['slice_id']}-stomach\"] = row[\"st_seg_rle\"]\n    \n    # 3. Create a lookup and assign the prediction RLE\n    ss_df[\"ident\"] = ss_df['slice_h'].astype(str)+\"-\"+ss_df['slice_w'].astype(str)+\"-\"+ss_df['px_spacing_h'].astype(str)+\"-\"+ss_df['px_spacing_w'].astype(str)+\"-\"+ss_df['slice_id'].astype(str)+\"-\"+ss_df[\"class\"].astype(str)\n    ss_df[\"predicted\"] = ss_df[\"ident\"].map(slice_px_map)\n    ss_df[\"predicted\"] = ss_df[\"predicted\"].apply(lambda x: \"\" if x==None else x)\n\n    \n    # 4. If we want some additional post processing we do that here\n    if SUBMISSION_STYLE==\"smart_random\":\n        \n        # 4a. Remove RLE masks from areas where no mask should exist\n        ss_df = ss_df.apply(fix_empty_slices, axis=1)\n        \n        # 4b. Remove non-contiguous masks that do not align with known patterns\n        ss_df[\"prev_predicted\"] = ss_df.shift(3, fill_value=\"\")[\"predicted\"]\n        ss_df[\"next_predicted\"] = ss_df.shift(-3, fill_value=\"\")[\"predicted\"]\n        ss_df[\"seg_isolated\"] = ss_df.apply(is_isolated, axis=1)\n        ss_df = ss_df.apply(fix_nc_slices, axis=1)\n        \n# 5. Reduce number of columns and save        \nss_df = ss_df[[\"id\", \"class\", \"predicted\"]]\nss_df.to_csv(\"submission.csv\", index=False)\ndisplay(ss_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:35:40.2877Z","iopub.execute_input":"2022-05-02T19:35:40.287976Z","iopub.status.idle":"2022-05-02T19:35:40.475008Z","shell.execute_reply.started":"2022-05-02T19:35:40.287945Z","shell.execute_reply":"2022-05-02T19:35:40.474207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}