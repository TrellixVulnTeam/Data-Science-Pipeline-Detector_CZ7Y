{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installs","metadata":{}},{"cell_type":"code","source":"!cd ../input/gi-seg-downloads && \\\npip install -q efficientnet_pytorch-0.6.3.tar.gz pretrainedmodels-0.7.4.tar.gz timm-0.4.12-py3-none-any.whl  segmentation_models_pytorch-0.2.1-py3-none-any.whl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import Callable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nimport os\nimport albumentations as A\nimport cupy as cp\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport segmentation_models_pytorch as smp\nimport torch\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Paths & Settings","metadata":{}},{"cell_type":"code","source":"KAGGLE_DIR = Path(\"/\") / \"kaggle\"\nINPUT_DIR = KAGGLE_DIR / \"input\"\nOUTPUT_DIR = KAGGLE_DIR / \"working\"\n\nINPUT_DATA_DIR = INPUT_DIR / \"uw-madison-gi-tract-image-segmentation\"\nINPUT_DATA_NPY_DIR = INPUT_DIR / \"uw-madison-gi-tract-image-segmentation-masks\"\n\nIMG_SIZE = 356\nCROP_SIZE = 320\nUSE_AUGS = True\nBATCH_SIZE = 32\nNUM_WORKERS = 2\nENCODER_NAME = \"efficientnet-b3\"\nGPUS = 1\nCHANNELS = 5\nDEVICE = \"cuda\"\nTHR = 0.45\n\nDEBUG = False # Debug complete pipeline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"transforms_val = A.Compose([\n    A.CenterCrop(CROP_SIZE, CROP_SIZE, p=1),\n    ToTensorV2(transpose_mask=True)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UWDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n\n    def resize(self, img, interp):\n        return cv2.resize(\n            img, (IMG_SIZE, IMG_SIZE), interpolation=interp)\n\n    def load_slice(self, img_file, diff):\n        slice_num = os.path.basename(img_file).split('_')[1]\n        filename = (\n            img_file.replace(\n                'slice_' + slice_num,\n                'slice_' + str(int(slice_num) + diff).zfill(4)))\n        if os.path.exists(filename):\n            return cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n        return None\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n\n        # read 5 slices into one image\n        imgs = [self.load_slice(row[\"image_path\"], i) for i in range(-2, 3)]\n        if imgs[3] is None:\n            imgs[3] = imgs[2]\n        if imgs[4] is None:\n            imgs[4] = imgs[3]\n        if imgs[1] is None:\n            imgs[1] = imgs[2]\n        if imgs[0] is None:\n            imgs[0] = imgs[1]\n        image = np.stack(imgs, axis=2)\n        image = image.astype(np.float32)\n        h, w = image.shape[:2]\n        max_val = image.max()\n        if max_val != 0:\n            image /= max_val\n        image = self.resize(image, cv2.INTER_AREA)\n        id_ = row[\"id\"]\n\n        if self.transforms:\n            data = self.transforms(image=image)\n            image = data[\"image\"]\n        r = {\n            'image': image,\n            'id': id_,\n            'h': h,\n            'w': w\n        }\n        return r","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Test Data","metadata":{}},{"cell_type":"code","source":"def extract_metadata_from_id(df):\n    df[[\"case\", \"day\", \"slice\"]] = df[\"id\"].str.split(\"_\", n=2, expand=True)\n\n    df[\"case\"] = df[\"case\"].str.replace(\"case\", \"\").astype(int)\n    df[\"day\"] = df[\"day\"].str.replace(\"day\", \"\").astype(int)\n    df[\"slice\"] = df[\"slice\"].str.replace(\"slice_\", \"\").astype(int)\n\n    return df\n\n\ndef extract_metadata_from_path(path_df):\n    path_df[[\"parent\", \"case_day\", \"scans\", \"file_name\"]] = path_df[\"image_path\"].str.rsplit(\"/\", n=3, expand=True)\n\n    path_df[[\"case\", \"day\"]] = path_df[\"case_day\"].str.split(\"_\", expand=True)\n    path_df[\"case\"] = path_df[\"case\"].str.replace(\"case\", \"\")\n    path_df[\"day\"] = path_df[\"day\"].str.replace(\"day\", \"\")\n\n    path_df[[\"slice\", \"width\", \"height\", \"spacing\", \"spacing_\"]] = (\n        path_df[\"file_name\"].str.replace(\"slice_\", \"\").str.replace(\".png\", \"\").str.split(\"_\", expand=True)\n    )\n    path_df = path_df.drop(columns=[\"parent\", \"case_day\", \"scans\", \"file_name\", \"spacing_\"])\n\n    numeric_cols = [\"case\", \"day\", \"slice\", \"width\", \"height\", \"spacing\"]\n    path_df[numeric_cols] = path_df[numeric_cols].apply(pd.to_numeric)\n\n    return path_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv(INPUT_DATA_DIR / \"sample_submission.csv\")\ntest_set_hidden = not bool(len(sub_df))\n\nif test_set_hidden:\n    test_df = pd.read_csv(INPUT_DATA_DIR / \"train.csv\")[: 1000 * 3]\n    test_df = test_df.drop(columns=[\"class\", \"segmentation\"]).drop_duplicates()\n    image_paths = [str(path) for path in (INPUT_DATA_DIR / \"train\").rglob(\"*.png\")]\nelse:\n    test_df = sub_df.drop(columns=[\"class\", \"predicted\"]).drop_duplicates()\n    image_paths = [str(path) for path in (INPUT_DATA_DIR / \"test\").rglob(\"*.png\")]\n\ntest_df = extract_metadata_from_id(test_df)\n\npath_df = pd.DataFrame(image_paths, columns=[\"image_path\"])\npath_df = extract_metadata_from_path(path_df)\n\ntest_df = test_df.merge(path_df, on=[\"case\", \"day\", \"slice\"], how=\"left\")\n\nprint(len(test_df))\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save Test DataFrame","metadata":{}},{"cell_type":"code","source":"test_df.to_csv(\"test_preprocessed.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"td = UWDataset(test_df, transforms=transforms_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"td[0]['image'].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"td[0]['id'],td[0]['h'],td[0]['w']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls ../input/exp01017/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_pths = [\n    '../input/exp01017/expexp010-bestloss-fold0-7.ckpt'\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model = smp.Unet(\n        encoder_name=ENCODER_NAME,   \n        encoder_weights=None,\n        in_channels=CHANNELS,                  \n        classes=3,        \n        activation=None,\n        decoder_use_batchnorm=True,\n        decoder_attention_type='scse'\n    )\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(path):\n    model = build_model()\n    state = torch.load(path)['state_dict']\n    nstate = {}\n    for k,v in state.items():\n        nstate[k[4:]] = v\n    model.load_state_dict(nstate)\n    model.to(DEVICE)\n    model.eval()\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run inference","metadata":{}},{"cell_type":"code","source":"def mask2rle(mask):\n    \"\"\"\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    \"\"\"\n    mask = cp.array(mask)\n    pixels = mask.flatten()\n    pad = cp.array([0])\n    pixels = cp.concatenate([pad, pixels, pad])\n    runs = cp.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n\n    return \" \".join(str(x) for x in runs)\n\ndef pad_mask(mask):\n    # pad image to conf.image_size\n    padded = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=mask.dtype)\n    dh = IMG_SIZE - mask.shape[0]\n    dw = IMG_SIZE - mask.shape[1]\n\n    top = dh//2\n    left = dw//2\n    padded[top:top + mask.shape[0], left:left + mask.shape[1], :] = mask\n    return padded\n\ndef resize_mask(mask, height, width):\n    # print(mask.shape)  # (356, 356, 3)\n    msk = np.zeros((height, width, 3), dtype=mask.dtype)\n    msk[:,:,0] = cv2.resize(mask[:,:,0], (width, height), interpolation=cv2.INTER_NEAREST)\n    msk[:,:,1] = cv2.resize(mask[:,:,1], (width, height), interpolation=cv2.INTER_NEAREST)\n    msk[:,:,2] = cv2.resize(mask[:,:,2], (width, height), interpolation=cv2.INTER_NEAREST)\n    return msk\n\ndef masks2rles(masks, ids, heights, widths):\n    pred_strings = []\n    pred_ids = []\n    pred_classes = []\n\n    for idx in range(masks.shape[0]):\n        mask = pad_mask(masks[idx])  # crop_size to img_size\n        mask = resize_mask(mask, heights[idx].item(), widths[idx].item()) # img_size to ori_size\n        rle = [None] * 3\n        for midx in [0, 1, 2]:\n            rle[midx] = mask2rle(mask[..., midx])\n\n        pred_strings.extend(rle)\n        pred_ids.extend([ids[idx]] * len(rle))\n        pred_classes.extend([\"large_bowel\", \"small_bowel\", \"stomach\"])\n\n    return pred_strings, pred_ids, pred_classes\n\n\n@torch.no_grad()\ndef infer(model_paths, thr):\n    \n    test_set = UWDataset(test_df, transforms=transforms_val)\n    test_dataloader = DataLoader(test_set,\n                              batch_size=BATCH_SIZE,\n                              num_workers=NUM_WORKERS, pin_memory=False, drop_last=False)\n    \n    pred_strings = []\n    pred_ids = []\n    pred_classes = []\n\n    # for imgs, ids, heights, widths in tqdm(test_dataloader):\n    for r in tqdm(test_dataloader):\n        imgs, ids, heights, widths = r['image'], r['id'], r['h'], r['w']\n        imgs = imgs.to(DEVICE, dtype=torch.float)\n        size = imgs.size()\n\n        masks = []\n        masks = torch.zeros((size[0], 3, size[2], size[3]), device=DEVICE, dtype=torch.float32)\n\n        for path in model_paths:\n            model = load_model(path)\n            out = model(imgs)\n            out = torch.nn.Sigmoid()(out)\n            masks += out / len(model_paths)\n\n        masks = (masks.permute((0, 2, 3, 1)) > thr).to(torch.uint8).cpu().detach().numpy()  # shape: (n, h, w, c)\n\n        result = masks2rles(masks, ids, heights, widths)\n        pred_strings.extend(result[0])\n        pred_ids.extend(result[1])\n        pred_classes.extend(result[2])\n\n    pred_df = pd.DataFrame({\"id\": pred_ids, \"class\": pred_classes, \"predicted\": pred_strings})\n\n    return pred_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = infer(model_pths, THR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = np.zeros((100, 200, 2));a.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b = np.zeros((200, 300));b.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = cv2.resize(b, (100, 200));c.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit","metadata":{}},{"cell_type":"code","source":"if not test_set_hidden:\n    sub_df = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv\")\n    del sub_df[\"predicted\"]\nelse:\n    sub_df = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/train.csv\")[: 1000 * 3]\n    del sub_df[\"segmentation\"]\n\nsub_df = sub_df.merge(pred_df, on=[\"id\", \"class\"])\nsub_df.to_csv(\"submission.csv\", index=False)\ndisplay(sub_df.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ","metadata":{}}]}