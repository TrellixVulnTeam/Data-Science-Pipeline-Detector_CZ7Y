{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-07T13:15:46.340808Z","iopub.execute_input":"2022-06-07T13:15:46.341349Z","iopub.status.idle":"2022-06-07T13:15:46.380487Z","shell.execute_reply.started":"2022-06-07T13:15:46.341243Z","shell.execute_reply":"2022-06-07T13:15:46.378988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q timm\n!pip install -q tqdm\n!pip install -q pytorch-lightning","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:15:46.383345Z","iopub.execute_input":"2022-06-07T13:15:46.384365Z","iopub.status.idle":"2022-06-07T13:16:22.460064Z","shell.execute_reply.started":"2022-06-07T13:15:46.384306Z","shell.execute_reply":"2022-06-07T13:16:22.458929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nfrom tqdm.notebook import tqdm\nimport pytorch_lightning as pl\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\n\nimport torchvision\nfrom torchvision.utils import make_grid\nfrom torchvision import transforms\n\nimport cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\n\n# Sklearn\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:16:22.461926Z","iopub.execute_input":"2022-06-07T13:16:22.462544Z","iopub.status.idle":"2022-06-07T13:16:33.837703Z","shell.execute_reply.started":"2022-06-07T13:16:22.462493Z","shell.execute_reply":"2022-06-07T13:16:33.836873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH  = '../input/uw-madison-gi-tract-image-segmentation'\ndf = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:16:33.839523Z","iopub.execute_input":"2022-06-07T13:16:33.840567Z","iopub.status.idle":"2022-06-07T13:16:34.431135Z","shell.execute_reply.started":"2022-06-07T13:16:33.840528Z","shell.execute_reply":"2022-06-07T13:16:34.4302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    seed          = 101\n    debug         = False # set debug=False for Full Training\n    exp_name      = 'Baselinev2'\n    comment       = 'unet-efficientnet_b1-224x224-aug2-split2'\n    model_name    = 'Unet'\n    backbone      = 'efficientnet-b1'\n    train_bs      = 128\n    valid_bs      = train_bs*2\n    img_size      = [224, 224]\n    epochs        = 15\n    lr            = 2e-3\n    scheduler     = 'CosineAnnealingLR'\n    min_lr        = 1e-6\n    T_max         = int(30000/train_bs*epochs)+50\n    T_0           = 25\n    warmup_epochs = 0\n    wd            = 1e-6\n    n_accumulate  = max(1, 32//train_bs)\n    n_fold        = 5\n    num_classes   = 3\n    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:16:34.432349Z","iopub.execute_input":"2022-06-07T13:16:34.432801Z","iopub.status.idle":"2022-06-07T13:16:34.4412Z","shell.execute_reply.started":"2022-06-07T13:16:34.432768Z","shell.execute_reply":"2022-06-07T13:16:34.440151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\n\nids = OrderedDict()\nids[\"case\"] = []\nids[\"day\"] = []\nids[\"slice\"] = []\n\n\nfor index, row in df.iterrows():\n    splitted_id_row = row[\"id\"].split(\"_\")\n    case = int(splitted_id_row[0].strip(\"case\"))\n    day  = int(splitted_id_row[1].strip(\"day\"))\n    patch_slice = int(splitted_id_row[3])\n    ids[\"case\"].append(case)\n    ids[\"day\"].append(day)\n    ids[\"slice\"].append(patch_slice)\n    \ndf[\"case\"] = ids[\"case\"]\ndf[\"day\"] = ids[\"day\"]\ndf[\"slice\"] = ids[\"slice\"]\n\ndf[\"height\"]= \"\"\ndf[\"width\"] = \"\"\ndf[\"file_path\"] = \"\"\n\n\ndf['segmentation'] = df.segmentation.fillna('')\ndf['rle_len'] = df.segmentation.map(len) # length of each rle mask\ndf['empty'] = (df.rle_len==0) # empty masks\n\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:16:34.442486Z","iopub.execute_input":"2022-06-07T13:16:34.442859Z","iopub.status.idle":"2022-06-07T13:16:40.858443Z","shell.execute_reply.started":"2022-06-07T13:16:34.442828Z","shell.execute_reply":"2022-06-07T13:16:40.857388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['empty'].value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:16:40.859802Z","iopub.execute_input":"2022-06-07T13:16:40.860285Z","iopub.status.idle":"2022-06-07T13:16:41.095139Z","shell.execute_reply.started":"2022-06-07T13:16:40.860232Z","shell.execute_reply":"2022-06-07T13:16:41.094008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img = OrderedDict()\ntrain_img[\"case\"] = []\ntrain_img[\"day\"] = []\ntrain_img[\"slice\"] = []\ntrain_img[\"slice\"] = []\ntrain_img[\"height\"] = []\ntrain_img[\"width\"] = []\ntrain_img[\"file_path\"] = []\n\nfor dirname, _, filenames in os.walk('../input/uw-madison-gi-tract-image-segmentation'):\n    for filename in filenames:\n        if \"train\" in dirname and \"png\" in filename:\n            test = os.path.join(dirname, filename)\n            splitted_path = test.split(\"/\")\n            case_day = splitted_path[-3]\n            case = int(case_day.split(\"_\")[0].strip(\"case\"))\n            day  = int(case_day.split(\"_\")[1].strip(\"day\"))\n            \n            train_img[\"file_path\"].append(os.path.join(dirname, filename))\n            \n            filename = splitted_path[-1].strip(\".png\").split('_')\n            patch_slice = int(filename[1])\n            height = int(filename[2])\n            width  = int(filename[3])\n            \n            train_img[\"case\"].append(case)\n            train_img[\"day\"].append(day)\n            train_img[\"slice\"].append(patch_slice)\n            train_img[\"height\"].append(height)\n            train_img[\"width\"].append(width)\n\ntrain_img_df = pd.DataFrame(train_img)\ntrain_img_df","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:16:41.096528Z","iopub.execute_input":"2022-06-07T13:16:41.096931Z","iopub.status.idle":"2022-06-07T13:16:46.893578Z","shell.execute_reply.started":"2022-06-07T13:16:41.096899Z","shell.execute_reply":"2022-06-07T13:16:46.892454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, row in tqdm(df.iterrows()):\n    case = row[\"case\"]\n    day = row[\"day\"]\n    patch_slice = row[\"slice\"]\n    res = train_img_df.query('case==@case and day ==@day and slice==@patch_slice')\n    df.at[index,'height']    = res.iloc[0][\"height\"]\n    df.at[index,'width']     = res.iloc[0][\"width\"]\n    df.at[index,'file_path'] = res.iloc[0][\"file_path\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:16:46.897308Z","iopub.execute_input":"2022-06-07T13:16:46.897688Z","iopub.status.idle":"2022-06-07T13:23:49.880286Z","shell.execute_reply.started":"2022-06-07T13:16:46.897656Z","shell.execute_reply":"2022-06-07T13:23:49.879365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:23:49.881728Z","iopub.execute_input":"2022-06-07T13:23:49.882053Z","iopub.status.idle":"2022-06-07T13:23:49.908203Z","shell.execute_reply.started":"2022-06-07T13:23:49.882025Z","shell.execute_reply":"2022-06-07T13:23:49.907352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility\n## Mask","metadata":{}},{"cell_type":"code","source":"def id2mask(id_):\n    idf = df[df['id']==id_]\n    wh = idf[['height','width']].iloc[0]\n    shape = (wh.height, wh.width, 3)\n    mask = np.zeros(shape, dtype=np.uint8)\n    for i, class_ in enumerate(['large_bowel', 'small_bowel', 'stomach']):\n        cdf = idf[idf['class']==class_]\n        rle = cdf.segmentation.squeeze()\n        if len(cdf) and not pd.isna(rle):\n            mask[..., i] = rle_decode(rle, shape[:2])\n    return mask\n\ndef rgb2gray(mask):\n    pad_mask = np.pad(mask, pad_width=[(0,0),(0,0),(1,0)])\n    gray_mask = pad_mask.argmax(-1)\n    return gray_mask\n\ndef gray2rgb(mask):\n    rgb_mask = tf.keras.utils.to_categorical(mask, num_classes=4)\n    return rgb_mask[..., 1:].astype(mask.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:23:49.909493Z","iopub.execute_input":"2022-06-07T13:23:49.909801Z","iopub.status.idle":"2022-06-07T13:23:49.920202Z","shell.execute_reply.started":"2022-06-07T13:23:49.909774Z","shell.execute_reply":"2022-06-07T13:23:49.918803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ref: https://www.kaggle.com/code/awsaf49/uwmgi-unet-train-pytorch#%F0%9F%93%92-Notebooks\n\ndef load_img(path):\n    im = Image.open(path)\n    im = np.array(im).astype(np.float32)\n    return im\n\ndef load_msk(path):\n    msk = np.load(path)\n    msk = msk.astype('float32')\n    msk*=255.0\n    return msk\n    \n\ndef show_img(img, mask=None):\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    plt.imshow(img)#, cmap='bone')\n    \n    if mask is not None:\n        plt.imshow(mask*255, alpha=0.5)\n        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n        labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n        plt.legend(handles,labels)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:23:49.921602Z","iopub.execute_input":"2022-06-07T13:23:49.922254Z","iopub.status.idle":"2022-06-07T13:23:49.937283Z","shell.execute_reply.started":"2022-06-07T13:23:49.922217Z","shell.execute_reply":"2022-06-07T13:23:49.936507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RLE","metadata":{}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:23:49.938283Z","iopub.execute_input":"2022-06-07T13:23:49.938836Z","iopub.status.idle":"2022-06-07T13:23:49.952461Z","shell.execute_reply.started":"2022-06-07T13:23:49.938797Z","shell.execute_reply":"2022-06-07T13:23:49.951542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:23:49.953597Z","iopub.execute_input":"2022-06-07T13:23:49.954438Z","iopub.status.idle":"2022-06-07T13:23:49.98611Z","shell.execute_reply.started":"2022-06-07T13:23:49.954401Z","shell.execute_reply":"2022-06-07T13:23:49.985152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Mask Dataset","metadata":{}},{"cell_type":"code","source":"for index, row in tqdm(df.iterrows()):\n    idx = row[\"id\"]\n    file_path = row[\"file_path\"]\n    dest_path = \"./train_masks/\"\n    os.makedirs(os.path.join(dest_path,\"/\".join(file_path.split(\"/\")[5:-1])), exist_ok = True)\n    \n    mask_name = os.path.basename(file_path).replace(\".png\",\".mask.npy\")\n    dest_mask_path = os.path.join(dest_path,\"/\".join(file_path.split(\"/\")[5:-1]))\n    \n    mask_path = os.path.join(dest_mask_path,mask_name)\n    \n    if not os.path.exists(mask_path):\n        mask_data = id2mask(idx)\n        np.save(mask_path,mask_data)\n        \n    df.at[index,'mask_path'] = mask_path","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:23:49.988186Z","iopub.execute_input":"2022-06-07T13:23:49.988834Z","iopub.status.idle":"2022-06-07T13:38:32.104917Z","shell.execute_reply.started":"2022-06-07T13:23:49.988799Z","shell.execute_reply":"2022-06-07T13:38:32.103444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = df.query(\"empty == False\")\nfile_path,mask_path =  test.iloc[10][\"file_path\"], test.iloc[10][\"mask_path\"]\n\n\nim = Image.open(file_path)\nim = np.array(im).astype(np.float32)\n#im = load_img(file_path)\n#mask = load_msk(mask_path)\nmask = np.load(mask_path)\nshow_img(im,mask)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:38:32.107664Z","iopub.execute_input":"2022-06-07T13:38:32.108988Z","iopub.status.idle":"2022-06-07T13:38:32.384896Z","shell.execute_reply.started":"2022-06-07T13:38:32.108923Z","shell.execute_reply":"2022-06-07T13:38:32.384168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('./train_processed.csv',index=False,encoding='utf-8')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:38:32.386497Z","iopub.execute_input":"2022-06-07T13:38:32.387203Z","iopub.status.idle":"2022-06-07T13:38:34.910334Z","shell.execute_reply.started":"2022-06-07T13:38:32.387153Z","shell.execute_reply":"2022-06-07T13:38:34.909435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = df.query(\"empty == False\")\nfile_path,mask_path =  test.iloc[10][\"file_path\"], test.iloc[10][\"mask_path\"]\n\n\nim = Image.open(file_path)\nim = np.array(im).astype(np.float32)\nmask = np.load(mask_path)\nshow_img(im,mask)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T13:38:34.911575Z","iopub.execute_input":"2022-06-07T13:38:34.912412Z","iopub.status.idle":"2022-06-07T13:38:35.064622Z","shell.execute_reply.started":"2022-06-07T13:38:34.912365Z","shell.execute_reply":"2022-06-07T13:38:35.063489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}