{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook makes TFRecord files to train the models running on TPU.\nThe contents of the TFRecord files are as follows:\n\n| Name | Type | Description |\n| --- | --- | --- |\n| id | bytes | sample ID taken from the 'id' column in 'train.csv', utf-8 encoded. |\n| case number | int64 | case number taken from 'id' at caseNNN |\n| day number | int64 | day number taken from 'id' at dayNN |\n| slice number | int64 | slice number taken from 'id' at slice_NNNN |\n| image | bytes | numpy save image bytes read from the associated file. | \n| mask | bytes | PNG format mask bytes generated from the 'segmentation' column in 'train.csv' |\n| fold | int64 | fold number that this sample belongs to |\n| height | int64 | slice height taken from the file name |\n| width | int64 | slice width taken from the file name |\n| space height | float32 | pixel spacing height taken from the file name |\n| space width | float32 | pixel spacing width taken from the file name |\n| large bowel dice coef | float32 | how well the model predicted for large bowel |\n| small bowel dice coef | float32 | how well the model predicted for small bowel |\n| stomach dice coef | float32 | how well the model predicted for stomach |\n| slice count | int64 | number of slices for case/day |\n\nI would like to:\n* put as much information as possible.\n* put the original size of images and masks, so it's possible to try various processing (e.g. resizing or padding) for the training. \n\n# Reference\n\n* [AW-Madison: EDA & In Depth Mask Exploration](https://www.kaggle.com/code/andradaolteanu/aw-madison-eda-in-depth-mask-exploration)\n\n# Preparation","metadata":{}},{"cell_type":"code","source":"DEBUG = False","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:20.332771Z","iopub.execute_input":"2022-06-17T20:35:20.335309Z","iopub.status.idle":"2022-06-17T20:35:20.381652Z","shell.execute_reply.started":"2022-06-17T20:35:20.335046Z","shell.execute_reply":"2022-06-17T20:35:20.380245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport os\nimport glob\nfrom sklearn.model_selection import StratifiedGroupKFold\nimport matplotlib.pyplot as plt\nimport cv2\nfrom io import BytesIO\n\nprint(tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-17T20:35:20.408203Z","iopub.execute_input":"2022-06-17T20:35:20.408965Z","iopub.status.idle":"2022-06-17T20:35:28.662886Z","shell.execute_reply.started":"2022-06-17T20:35:20.408893Z","shell.execute_reply":"2022-06-17T20:35:28.661872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TFREC_FILES = 15\nN_FOLDS = 5","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:28.665059Z","iopub.execute_input":"2022-06-17T20:35:28.66574Z","iopub.status.idle":"2022-06-17T20:35:28.671183Z","shell.execute_reply.started":"2022-06-17T20:35:28.66568Z","shell.execute_reply":"2022-06-17T20:35:28.670207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_SRC = 'uw-madison-gi-tract-image-segmentation'\nDATA_DIR = os.path.join('..', 'input', DATA_SRC)\nTRAIN_DIR = os.path.join(DATA_DIR, 'train')\nANAL_DIR = 'uwmgi-image-segmentation-pred-analysis'\nANAL_FILE = 'analysis_V32.csv'\nANAL_PATH = os.path.join('..', 'input', ANAL_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:28.672925Z","iopub.execute_input":"2022-06-17T20:35:28.67356Z","iopub.status.idle":"2022-06-17T20:35:28.688458Z","shell.execute_reply.started":"2022-06-17T20:35:28.673512Z","shell.execute_reply":"2022-06-17T20:35:28.68771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataFrame","metadata":{}},{"cell_type":"code","source":"train_csv_path = os.path.join(DATA_DIR, 'train.csv')\ntrain_df = pd.read_csv(train_csv_path)\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:28.690987Z","iopub.execute_input":"2022-06-17T20:35:28.691548Z","iopub.status.idle":"2022-06-17T20:35:29.320638Z","shell.execute_reply.started":"2022-06-17T20:35:28.691508Z","shell.execute_reply":"2022-06-17T20:35:29.318094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_unstack_df = \\\n    train_df \\\n        .set_index(['id', 'class']) \\\n        .unstack() \\\n        .reset_index()\ntrain_unstack_df.columns = \\\n    ['id', 'large_bowel', 'small_bowel', 'stomach']\n\ntrain_unstack_df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:29.322061Z","iopub.execute_input":"2022-06-17T20:35:29.322587Z","iopub.status.idle":"2022-06-17T20:35:29.500418Z","shell.execute_reply.started":"2022-06-17T20:35:29.322539Z","shell.execute_reply":"2022-06-17T20:35:29.499073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_unstack_df[['case_no', 'day_no', 'slice_no']] = \\\n    train_unstack_df['id'] \\\n        .str \\\n        .extract(r'case(\\d\\d*)_day(\\d\\d*)_slice_(\\d\\d*)')\n\ntrain_unstack_df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:29.501539Z","iopub.execute_input":"2022-06-17T20:35:29.501798Z","iopub.status.idle":"2022-06-17T20:35:29.631805Z","shell.execute_reply.started":"2022-06-17T20:35:29.50177Z","shell.execute_reply":"2022-06-17T20:35:29.630952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform() gets a Series of 'slice_no' for each group.\n# Series.iloc[-1] returns the last element.\n#\n# https://stackoverflow.com/questions/56288949/\n# how-to-access-the-last-element-in-a-pandas-series\ntrain_unstack_df['slice_count'] = \\\n    train_unstack_df \\\n        .groupby(['case_no', 'day_no']) \\\n        ['slice_no'] \\\n        .transform(lambda x: x.iloc[-1])\n\ntrain_unstack_df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:29.633411Z","iopub.execute_input":"2022-06-17T20:35:29.633923Z","iopub.status.idle":"2022-06-17T20:35:29.706247Z","shell.execute_reply.started":"2022-06-17T20:35:29.633879Z","shell.execute_reply":"2022-06-17T20:35:29.705386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path_pattern = os.path.join(TRAIN_DIR, '**', '*.png')\nfile_paths = glob.glob(file_path_pattern, recursive=True)\nfile_info_df = pd.DataFrame({\"file_path\": file_paths})\n\nfile_info_df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:29.707816Z","iopub.execute_input":"2022-06-17T20:35:29.708304Z","iopub.status.idle":"2022-06-17T20:35:34.187392Z","shell.execute_reply.started":"2022-06-17T20:35:29.70826Z","shell.execute_reply":"2022-06-17T20:35:34.185987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_info_df['id'] = file_info_df['file_path'] \\\n    .str \\\n    .replace(\n        pat=r'^.*/(case\\d\\d*)_(day\\d\\d*)/scans/(slice_\\d\\d*)_.*$',\n        repl=r'\\1_\\2_\\3', regex=True)\n\nfile_name_info_df = file_info_df['file_path'] \\\n    .str \\\n    .extract(\n        r'slice_\\d\\d*_(\\d\\d*)_(\\d\\d*)_(\\d\\d*\\.\\d\\d*)_(\\d\\d*\\.\\d\\d*)') \\\n    .rename(columns={\n        0: 'height', 1: 'width', 2: 'space_h', 3: 'space_w'})\n\nfile_info_df = pd.concat([file_info_df, file_name_info_df], axis=1)\n\nfile_info_df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:34.189284Z","iopub.execute_input":"2022-06-17T20:35:34.190044Z","iopub.status.idle":"2022-06-17T20:35:34.608276Z","shell.execute_reply.started":"2022-06-17T20:35:34.18999Z","shell.execute_reply":"2022-06-17T20:35:34.607413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anal_csv_path = os.path.join(ANAL_PATH, ANAL_FILE)\nanal_df = pd.read_csv(anal_csv_path) \\\n    [['id', 'large_bowel_dice_coef',\n      'small_bowel_dice_coef', 'stomach_dice_coef']]\n\nanal_df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:34.612081Z","iopub.execute_input":"2022-06-17T20:35:34.612457Z","iopub.status.idle":"2022-06-17T20:35:34.74314Z","shell.execute_reply.started":"2022-06-17T20:35:34.612426Z","shell.execute_reply":"2022-06-17T20:35:34.742263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_df = pd.merge(\n    train_unstack_df,\n    pd.merge(file_info_df, anal_df, how='inner', on='id'),\n    how='inner', on='id')\ntrain_data_df = train_data_df.fillna('')\n\ntrain_data_df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:34.744207Z","iopub.execute_input":"2022-06-17T20:35:34.74442Z","iopub.status.idle":"2022-06-17T20:35:35.010797Z","shell.execute_reply.started":"2022-06-17T20:35:34.744394Z","shell.execute_reply":"2022-06-17T20:35:35.009375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Folds","metadata":{}},{"cell_type":"code","source":"def has_mask(row):\n    return \\\n        len(row['large_bowel']) > 0 or \\\n        len(row['small_bowel']) > 0 or \\\n        len(row['stomach']) > 0 \n\ntrain_data_df['has_mask'] = train_data_df.apply(has_mask, axis=1)\n\ntrain_data_df['has_mask']","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:35.011915Z","iopub.execute_input":"2022-06-17T20:35:35.012141Z","iopub.status.idle":"2022-06-17T20:35:35.890243Z","shell.execute_reply.started":"2022-06-17T20:35:35.012114Z","shell.execute_reply":"2022-06-17T20:35:35.889226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgkf = StratifiedGroupKFold(\n    n_splits=N_FOLDS, shuffle=True, random_state=53)\ntrain_data_len = len(train_data_df)\nfold_X = np.arange(train_data_len)\nfold_y = train_data_df['has_mask']\nfold_groups = train_data_df['case_no']\nfold_data = np.empty(train_data_len)\n\nfor fold_idx, (_, val_idx) in \\\n        enumerate(sgkf.split(fold_X, fold_y, fold_groups)):\n    fold_data[val_idx] = fold_idx\n    \ntrain_data_df['fold'] = fold_data.astype(np.int32)\n\ntrain_data_df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:35.89191Z","iopub.execute_input":"2022-06-17T20:35:35.892222Z","iopub.status.idle":"2022-06-17T20:35:36.128235Z","shell.execute_reply.started":"2022-06-17T20:35:35.892189Z","shell.execute_reply":"2022-06-17T20:35:36.127169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_df.groupby(['fold', 'has_mask'])['id'].count()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:36.129735Z","iopub.execute_input":"2022-06-17T20:35:36.130044Z","iopub.status.idle":"2022-06-17T20:35:36.152271Z","shell.execute_reply.started":"2022-06-17T20:35:36.130004Z","shell.execute_reply":"2022-06-17T20:35:36.151574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_df.to_csv('train_data.csv', index=False)\n\n!head train_data.csv","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:36.153667Z","iopub.execute_input":"2022-06-17T20:35:36.153955Z","iopub.status.idle":"2022-06-17T20:35:38.422834Z","shell.execute_reply.started":"2022-06-17T20:35:36.153916Z","shell.execute_reply":"2022-06-17T20:35:38.421675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image/Mask","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/andradaolteanu/aw-madison-eda-in-depth-mask-exploration\ndef read_cv2_image(path):\n    '''Reads and converts the image.\n    path: the full complete path to the .png file'''\n\n    # Read image in a corresponding manner\n    # convert int16 -> float32\n    image = cv2.imread(path, cv2.IMREAD_UNCHANGED).astype('float32')\n    # Scale to [0, 255]\n    image = cv2.normalize(image, None, alpha = 0, beta = 255, \n                        norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n    image = image.astype(np.uint8)\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:38.424547Z","iopub.execute_input":"2022-06-17T20:35:38.424867Z","iopub.status.idle":"2022-06-17T20:35:38.432288Z","shell.execute_reply.started":"2022-06-17T20:35:38.424832Z","shell.execute_reply":"2022-06-17T20:35:38.43134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_image(file_path):\n    image_cv2 = read_cv2_image(file_path)\n    image_cv2_flatten = image_cv2.flatten()\n    with BytesIO() as f:\n        np.save(f, image_cv2_flatten)\n        image_bytes = f.getvalue()\n    tf_image_bytes = tf.constant(image_bytes)\n    return tf_image_bytes","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:38.434034Z","iopub.execute_input":"2022-06-17T20:35:38.43469Z","iopub.status.idle":"2022-06-17T20:35:38.454974Z","shell.execute_reply.started":"2022-06-17T20:35:38.43461Z","shell.execute_reply":"2022-06-17T20:35:38.453252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_zero_mask(height, width):\n    return tf.zeros([height, width, 1], dtype=tf.uint8)\n\ndef make_non_zero_mask(rle, height, width):\n    rle_splits = tf.strings.split(rle, sep=' ')\n    rle_nums = tf.strings.to_number(rle_splits, out_type=tf.int32)\n    # For example, '1 3 10 5'\n    # starts = [1 10]\n    # lengths = [3 5]\n    starts = rle_nums[0::2]\n    lengths = rle_nums[1::2]\n    # sl_stack = [[1 10]\n    #             [3 5]]\n    sl_stack = tf.stack([starts, lengths])\n    # starts_lengths = [[1 3]   <-- 1st pair of start and length\n    #                   [10 5]] <-- 2nd pair of start and length\n    starts_lengths = tf.transpose(sl_stack)\n    range_length = height * width\n    \n    def _make_bool_mask(start_length):\n        start = start_length[0]\n        length = start_length[1]\n        end = start + length\n        # range_values = [0 1 2 ... range_length-1]\n        range_values = tf.range(range_length, dtype=tf.int32)\n        # range_mask = [False ... False True ... True False ... False]\n        #                 0             start    end-1\n        range_mask = tf.math.logical_and(\n            start <= range_values, range_values < end)\n        return range_mask\n    \n    bool_masks = tf.map_fn(\n        fn=_make_bool_mask, elems=starts_lengths, dtype=tf.bool)\n    bool_mask = tf.reduce_any(bool_masks, axis=0)\n    ui8_one = tf.ones([], dtype=tf.uint8)\n    ui8_zero = tf.zeros([], dtype=tf.uint8)\n    mask = tf.where(bool_mask, ui8_one, ui8_zero)\n    mask = tf.reshape(mask, [height, width, 1])\n    return mask\n\ndef make_one_mask(rle, height, width):\n    return tf.cond(\n        tf.strings.length(rle) == 0,\n        lambda: make_zero_mask(height, width),\n        lambda: make_non_zero_mask(rle, height, width))\n\ndef make_mask(large_bowel, small_bowel, stomach, height, width):\n    large_bowel_mask = make_one_mask(large_bowel, height, width)\n    small_bowel_mask = make_one_mask(small_bowel, height, width)\n    stomach_mask = make_one_mask(stomach, height, width)\n    mask = tf.concat(\n        [large_bowel_mask, small_bowel_mask, stomach_mask],\n        axis=2)\n    mask_bytes = tf.io.encode_png(mask)\n    return mask_bytes","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:38.457046Z","iopub.execute_input":"2022-06-17T20:35:38.457418Z","iopub.status.idle":"2022-06-17T20:35:38.477929Z","shell.execute_reply.started":"2022-06-17T20:35:38.457366Z","shell.execute_reply":"2022-06-17T20:35:38.476579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TFRecords","metadata":{}},{"cell_type":"code","source":"def _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        # BytesList won't unpack a string from an EagerTensor.\n        value = value.numpy() \n    elif isinstance(value, str):\n        # string needs to be encoded to bytes.\n        value = value.encode('utf-8')\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _float32_feature(value):\n    \"\"\"Returns an float32_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:38.479384Z","iopub.execute_input":"2022-06-17T20:35:38.480043Z","iopub.status.idle":"2022-06-17T20:35:38.501158Z","shell.execute_reply.started":"2022-06-17T20:35:38.480003Z","shell.execute_reply":"2022-06-17T20:35:38.500381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def serialize_example(row):\n    sample_id = row['id']\n    case_no = int(row['case_no'])\n    day_no = int(row['day_no'])\n    slice_no = int(row['slice_no'])\n    height = int(row['height'])\n    width = int(row['width'])\n    space_h = float(row['space_h'])\n    space_w = float(row['space_w'])\n    large_bowel_dice_coef = float(row['large_bowel_dice_coef'])\n    small_bowel_dice_coef = float(row['small_bowel_dice_coef'])\n    stomach_dice_coef = float(row['stomach_dice_coef'])\n    slice_count = int(row['slice_count'])\n    \n    image_bytes = read_image(row['file_path'])\n    mask_bytes = make_mask(\n        row['large_bowel'], row['small_bowel'], row['stomach'],\n        height, width)\n    \n    feature = {\n        'id': _bytes_feature(sample_id.encode('utf-8')),\n        'case_no': _int64_feature(case_no),\n        'day_no': _int64_feature(day_no),\n        'slice_no': _int64_feature(slice_no),\n        'image': _bytes_feature(image_bytes),\n        'mask': _bytes_feature(mask_bytes),\n        'fold' : _int64_feature(row['fold']),\n        'height': _int64_feature(height),\n        'width': _int64_feature(width),\n        'space_h': _float32_feature(space_h),\n        'space_w': _float32_feature(space_w),\n        'large_bowel_dice_coef': _float32_feature(large_bowel_dice_coef),\n        'small_bowel_dice_coef': _float32_feature(small_bowel_dice_coef),\n        'stomach_dice_coef': _float32_feature(stomach_dice_coef),\n        'slice_count': _int64_feature(slice_count),\n    }\n    \n    example_proto = tf.train.Example(\n        features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:38.502611Z","iopub.execute_input":"2022-06-17T20:35:38.502913Z","iopub.status.idle":"2022-06-17T20:35:38.527372Z","shell.execute_reply.started":"2022-06-17T20:35:38.502879Z","shell.execute_reply":"2022-06-17T20:35:38.526157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_df = train_data_df.head(300) if DEBUG else train_data_df\n\nlen(train_data_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:38.528879Z","iopub.execute_input":"2022-06-17T20:35:38.529244Z","iopub.status.idle":"2022-06-17T20:35:38.558966Z","shell.execute_reply.started":"2022-06-17T20:35:38.529196Z","shell.execute_reply":"2022-06-17T20:35:38.557972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_data_per_tfrec = \\\n    (len(train_data_df) + NUM_TFREC_FILES - 1) // NUM_TFREC_FILES\n\nn_data_per_tfrec","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:38.560446Z","iopub.execute_input":"2022-06-17T20:35:38.560993Z","iopub.status.idle":"2022-06-17T20:35:38.583686Z","shell.execute_reply.started":"2022-06-17T20:35:38.560897Z","shell.execute_reply":"2022-06-17T20:35:38.582985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remaining_item_count = len(train_data_df)\ntfrec_i = 0\ntfrec_data_iter = train_data_df.iterrows()\nwhile 0 < remaining_item_count:\n    tfrec_item_count = min(n_data_per_tfrec, remaining_item_count)\n    tfrec_file_name = \"{0:02d}-{1:03d}.tfrec\".format(tfrec_i, tfrec_item_count)\n    print(\"Writing {0}...\".format(tfrec_file_name))\n    with tf.io.TFRecordWriter(tfrec_file_name) as writer:\n        for tfrec_item_i in range(tfrec_item_count):\n            if tfrec_item_i % 100 == 0:\n                print(tfrec_item_i, \", \", end='')\n            _, row = next(tfrec_data_iter)\n            example = serialize_example(row)\n            writer.write(example)\n    print()\n    remaining_item_count -= tfrec_item_count\n    tfrec_i += 1","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:35:38.585049Z","iopub.execute_input":"2022-06-17T20:35:38.585465Z","iopub.status.idle":"2022-06-17T20:36:14.385073Z","shell.execute_reply.started":"2022-06-17T20:35:38.585413Z","shell.execute_reply":"2022-06-17T20:36:14.384191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:36:14.386472Z","iopub.execute_input":"2022-06-17T20:36:14.38732Z","iopub.status.idle":"2022-06-17T20:36:15.173411Z","shell.execute_reply.started":"2022-06-17T20:36:14.387278Z","shell.execute_reply":"2022-06-17T20:36:15.172336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Verify TFRecords","metadata":{}},{"cell_type":"code","source":"def decode_image(image_bytes, height, width):\n    image_raw_bytes = tf.io.decode_raw(image_bytes, out_type=tf.uint8)\n    image_len = height * width\n    image_bytes = image_raw_bytes[-image_len: ]\n    image = tf.reshape(image_bytes, [width, height, 1])\n    return image\n\ndef decode_mask(mask_bytes):\n    mask_png = tf.image.decode_png(mask_bytes)\n    mask_float = tf.cast(mask_png, dtype=tf.float32)\n    return mask_float\n\ndef read_tfrecord(example):\n    TFREC_FORMAT = {\n        'id': tf.io.FixedLenFeature([], tf.string),\n        'case_no': tf.io.FixedLenFeature([], tf.int64),\n        'day_no': tf.io.FixedLenFeature([], tf.int64),\n        'slice_no': tf.io.FixedLenFeature([], tf.int64),\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'mask': tf.io.FixedLenFeature([], tf.string),\n        'fold': tf.io.FixedLenFeature([], tf.int64),\n        'height': tf.io.FixedLenFeature([], tf.int64),\n        'width': tf.io.FixedLenFeature([], tf.int64),\n        'space_h': tf.io.FixedLenFeature([], tf.float32),\n        'space_w': tf.io.FixedLenFeature([], tf.float32),\n        'large_bowel_dice_coef': tf.io.FixedLenFeature([], tf.float32),\n        'small_bowel_dice_coef': tf.io.FixedLenFeature([], tf.float32),\n        'stomach_dice_coef': tf.io.FixedLenFeature([], tf.float32),\n        'slice_count': tf.io.FixedLenFeature([], tf.int64),\n    }\n    \n    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n    sample_id = example['id']\n    case_no = example['case_no']\n    day_no = example['day_no']\n    slice_no = example['slice_no']\n    mask = decode_mask(example['mask'])\n    fold = example['fold']\n    height = example['height']\n    width = example['width']\n    space_h = example['space_h']\n    space_w = example['space_w']\n    image = decode_image(example['image'], height, width)\n    large_bowel_dice_coef = example['large_bowel_dice_coef']\n    small_bowel_dice_coef = example['small_bowel_dice_coef']\n    stomach_dice_coef = example['stomach_dice_coef']\n    slice_count = example['slice_count']\n    return \\\n        sample_id, case_no, day_no, slice_no, \\\n        image, mask, fold, height, width, space_h, space_w, \\\n        large_bowel_dice_coef, small_bowel_dice_coef, \\\n        stomach_dice_coef, slice_count\n\ndef load_dataset(filenames):\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=None)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=None)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:36:15.175923Z","iopub.execute_input":"2022-06-17T20:36:15.17631Z","iopub.status.idle":"2022-06-17T20:36:15.195733Z","shell.execute_reply.started":"2022-06-17T20:36:15.176262Z","shell.execute_reply":"2022-06-17T20:36:15.194422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfrec_file_names = sorted(tf.io.gfile.glob('*.tfrec'))\ntfrec_ds = load_dataset(tfrec_file_names)\n\ntfrec_ds","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:36:15.19748Z","iopub.execute_input":"2022-06-17T20:36:15.197952Z","iopub.status.idle":"2022-06-17T20:36:15.66985Z","shell.execute_reply.started":"2022-06-17T20:36:15.197916Z","shell.execute_reply":"2022-06-17T20:36:15.669147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_image_mask(ax, image, mask, title):\n    ax.imshow(image, cmap='gray')\n    ax.imshow(mask, alpha=0.5)\n    ax.set_title(title)\n\ndef draw_tfrec_images(nrows, ncols, figsize):\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n    tfrec_ds_iter = iter(tfrec_ds.skip(100))\n    for row in range(nrows):\n        for col in range(ncols):\n            tfrec_data = next(tfrec_ds_iter)\n            sample_id = tfrec_data[0].numpy().decode('utf-8')\n            image = tfrec_data[4]\n            mask = tfrec_data[5]\n            title = sample_id\n            draw_image_mask(axes[row, col], image, mask, title)\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:36:15.670893Z","iopub.execute_input":"2022-06-17T20:36:15.671442Z","iopub.status.idle":"2022-06-17T20:36:15.681693Z","shell.execute_reply.started":"2022-06-17T20:36:15.6714Z","shell.execute_reply":"2022-06-17T20:36:15.680745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_tfrec_images(3, 4, (12, 10))","metadata":{"execution":{"iopub.status.busy":"2022-06-17T20:36:15.685485Z","iopub.execute_input":"2022-06-17T20:36:15.685791Z","iopub.status.idle":"2022-06-17T20:36:18.559498Z","shell.execute_reply.started":"2022-06-17T20:36:15.685758Z","shell.execute_reply":"2022-06-17T20:36:18.558689Z"},"trusted":true},"execution_count":null,"outputs":[]}]}