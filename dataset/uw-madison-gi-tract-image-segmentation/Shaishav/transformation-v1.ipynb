{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shutil\nfrom pathlib import Path\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom tqdm.notebook import tqdm\nimport imageio\nimport ast\n\n\ndef load_mask(row):\n    shape = (row.height, row.width, 3)\n    mask = np.zeros(shape, dtype=np.uint8)\n\n    for i, rle in enumerate(row.segmentation):\n        if rle:\n            mask[..., i] = rle_decode(rle, shape[:2])\n\n    return mask * 255\n\n\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape):\n    \"\"\"\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n    \"\"\"\n    s = np.asarray(mask_rle.split(), dtype=int)\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\n\ndef save_array(file_path, array):\n    file_path = Path(file_path)\n    file_path.parent.mkdir(parents=True, exist_ok=True)\n    np.save(file_path, array)\n\n\n\ndef load_image(path):\n    image = cv2.imread(path,cv2.IMREAD_UNCHANGED)\n    #image = image.astype(\"uint\")  # original is uint16\n    #image /= image.max()\n    return image\n\n\ndef load_images(paths):\n    images = [load_image(path) for path in ast.literal_eval(paths)]\n    images = np.stack(images, axis=-1)    \n    \n    return images\n\n\ndef load_mask(path):\n    mask = np.load(path)\n    #mask = mask.astype(\"float32\")\n    #mask /= 255.0\n    return mask\n    \n    \ndef show_image(image, mask=None):\n    plt.imshow(image, cmap=\"bone\")\n\n    if mask is not None:\n        plt.imshow(mask, alpha=0.5)\n\n        handles = [\n            Rectangle((0, 0), 1, 1, color=_c) for _c in [(0.667, 0.0, 0.0), (0.0, 0.667, 0.0), (0.0, 0.0, 0.667)]\n        ]\n        labels = [\"Stomach\", \"Large Bowel\", \"Small Bowel\"]\n\n        plt.legend(handles, labels)\n\n    plt.axis(\"off\")\n    \n\ndef show_grid(train_df, nrows, ncols):\n    fig, _ = plt.subplots(figsize=(5 * ncols, 5 * nrows))\n\n    train_df_sampled = train_df[~train_df[\"empty\"]].sample(n=nrows * ncols)\n    for i, row in enumerate(train_df_sampled.itertuples()):\n\n        #image = load_images(row.image_paths)\n        image = load_image(row.image_path)\n\n        mask = load_mask(row.mask_path)\n\n        plt.subplot(nrows, ncols, i + 1)\n        plt.tight_layout()\n        plt.title(row.id)\n\n        show_image(image, mask)\n        \ndef try_tranform(train_df,nrows,tranform,image_flag = 1,mask_flag = 1,albumentation = 0):\n    fig, _ = plt.subplots(figsize=(5 * 2, 5 * nrows))\n\n    train_df_sampled = train_df[~train_df[\"empty\"]].sample(n=nrows)\n    counter = 1\n    for i, row in enumerate(train_df_sampled.itertuples()):\n\n        #image = load_images(row.image_paths)\n        image = load_image(row.image_path)\n\n        mask = load_mask(row.mask_path)\n\n        plt.subplot(nrows, ncols, counter)\n        plt.tight_layout()\n        plt.title(row.id+' Original 2.5D')\n\n        show_image(image, mask)\n        counter+=1\n\n\n\n        plt.subplot(nrows, ncols, counter)\n        plt.tight_layout()\n        plt.title(row.id+' After Transformation')\n        \n        if albumentation == 1:\n            transformed = transform(image=image, mask=mask)\n            show_image(transformed['image'], transformed['mask'])\n        else:\n            \n        \n            if image_flag == 1:\n                transformed_image = transform(image)\n            else:\n                transformed_image = image\n\n            if mask_flag == 1:\n                transformed_mask = transform(mask)\n            else:\n                transformed_mask = mask\n            \n            show_image(transformed_image, transformed_mask)\n        \n        counter+=1\n    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-01T10:19:07.09599Z","iopub.execute_input":"2022-06-01T10:19:07.096431Z","iopub.status.idle":"2022-06-01T10:19:07.124044Z","shell.execute_reply.started":"2022-06-01T10:19:07.096396Z","shell.execute_reply":"2022-06-01T10:19:07.123074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KAGGLE_DIR = Path(\"/\") / \"kaggle\"\nINPUT_DIR = KAGGLE_DIR / \"input\"\nOUTPUT_DIR = KAGGLE_DIR / \"working\"\n\nINPUT_DATA_DIR = INPUT_DIR / \"uw-madison-gi-tract-image-segmentation\"\nN_SPLITS = 5\nRANDOM_SEED = 2022\n\n# For 2.5D Data\nCHANNELS = 3\nSTRIDE = 2\n\nOUTPUT_DATA_DIR = OUTPUT_DIR / INPUT_DATA_DIR.stem\nOUTPUT_DATA_DIR.mkdir(exist_ok=True)\n\nDEBUG = True","metadata":{"execution":{"iopub.status.busy":"2022-06-01T09:41:01.032407Z","iopub.execute_input":"2022-06-01T09:41:01.032738Z","iopub.status.idle":"2022-06-01T09:41:01.040533Z","shell.execute_reply.started":"2022-06-01T09:41:01.032699Z","shell.execute_reply":"2022-06-01T09:41:01.039408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(INPUT_DIR / 'uw-madison-gi-tract-image-segmentation-masks'/'train_preprocessed.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T09:41:01.043124Z","iopub.execute_input":"2022-06-01T09:41:01.043794Z","iopub.status.idle":"2022-06-01T09:41:02.103929Z","shell.execute_reply.started":"2022-06-01T09:41:01.04374Z","shell.execute_reply":"2022-06-01T09:41:02.102955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nrows = 2\nncols = 2\nshow_grid(df, nrows, ncols)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T09:41:02.105766Z","iopub.execute_input":"2022-06-01T09:41:02.106188Z","iopub.status.idle":"2022-06-01T09:41:03.111287Z","shell.execute_reply.started":"2022-06-01T09:41:02.106153Z","shell.execute_reply":"2022-06-01T09:41:03.11038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install monai","metadata":{"execution":{"iopub.status.busy":"2022-06-01T09:41:03.259524Z","iopub.execute_input":"2022-06-01T09:41:03.260462Z","iopub.status.idle":"2022-06-01T09:41:17.420909Z","shell.execute_reply.started":"2022-06-01T09:41:03.260424Z","shell.execute_reply":"2022-06-01T09:41:17.419968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import (\n    AddChanneld,\n    LoadImage,\n    LoadImaged,\n    Orientationd,\n    Rand3DElasticd,\n    RandAffined,\n    Spacingd,\n)\nfrom monai.config import print_config\nfrom monai.apps import download_and_extract\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tempfile\nimport shutil\nimport os\nimport glob","metadata":{"execution":{"iopub.status.busy":"2022-06-01T09:41:17.422843Z","iopub.execute_input":"2022-06-01T09:41:17.423203Z","iopub.status.idle":"2022-06-01T09:41:26.28353Z","shell.execute_reply.started":"2022-06-01T09:41:17.423168Z","shell.execute_reply":"2022-06-01T09:41:26.282349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import Callable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\n\nimport albumentations as A\n#import cupy as cp\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport seaborn as sns\n#import segmentation_models_pytorch as smp\nimport torch\nfrom albumentations.pytorch import ToTensorV2\nfrom monai.metrics.utils import get_mask_edges\nfrom monai.metrics.utils import get_surface_distance\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom torchmetrics import Metric\nfrom torchmetrics import MetricCollection\nfrom torch.utils.data import DataLoader\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-06-01T09:41:26.285007Z","iopub.execute_input":"2022-06-01T09:41:26.285976Z","iopub.status.idle":"2022-06-01T09:41:28.631722Z","shell.execute_reply.started":"2022-06-01T09:41:26.285939Z","shell.execute_reply":"2022-06-01T09:41:28.630573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import RandGaussianNoise\n\ntransform = RandGaussianNoise(std = 200,mean =0 ,prob=1)\n\ntry_tranform(df,nrows,transform,image_flag = 1,mask_flag = 0)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T09:53:23.87106Z","iopub.execute_input":"2022-06-01T09:53:23.871498Z","iopub.status.idle":"2022-06-01T09:53:25.063564Z","shell.execute_reply.started":"2022-06-01T09:53:23.871459Z","shell.execute_reply":"2022-06-01T09:53:25.06252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import ShiftIntensity\n\ntransform = ShiftIntensity(offset = 0.5)\n\ntry_tranform(df,nrows,transform,image_flag = 1,mask_flag = 0)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:18:49.142268Z","iopub.execute_input":"2022-06-01T05:18:49.143174Z","iopub.status.idle":"2022-06-01T05:18:50.307453Z","shell.execute_reply.started":"2022-06-01T05:18:49.143127Z","shell.execute_reply":"2022-06-01T05:18:50.306441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import NormalizeIntensity\n\ntransform = NormalizeIntensity()\n\ntry_tranform(df,nrows,transform,image_flag = 1,mask_flag = 0)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:18:50.310128Z","iopub.execute_input":"2022-06-01T05:18:50.310485Z","iopub.status.idle":"2022-06-01T05:18:51.136176Z","shell.execute_reply.started":"2022-06-01T05:18:50.310454Z","shell.execute_reply":"2022-06-01T05:18:51.135226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import RandHistogramShift\n\ntransform = RandHistogramShift(num_control_points=10, prob=0.05)\n\ntry_tranform(df,nrows,transform,image_flag =1 ,mask_flag = 1)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:18:51.137402Z","iopub.execute_input":"2022-06-01T05:18:51.137728Z","iopub.status.idle":"2022-06-01T05:18:51.963421Z","shell.execute_reply.started":"2022-06-01T05:18:51.137698Z","shell.execute_reply":"2022-06-01T05:18:51.962338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import RandStdShiftIntensity\n\ntransform = RandStdShiftIntensity(100)\n\ntry_tranform(df,nrows,transform,image_flag =1 ,mask_flag = 0)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:18:51.965208Z","iopub.execute_input":"2022-06-01T05:18:51.96571Z","iopub.status.idle":"2022-06-01T05:18:52.718736Z","shell.execute_reply.started":"2022-06-01T05:18:51.965671Z","shell.execute_reply":"2022-06-01T05:18:52.717782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import CropForeground\n\ndef threshold_at_one(x):\n    # threshold at 1\n    return x > 200\ntransform = CropForeground(select_fn=threshold_at_one, margin=0)\n\ntry_tranform(df,nrows,transform,image_flag =1 ,mask_flag = 0)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:18:52.71983Z","iopub.execute_input":"2022-06-01T05:18:52.720135Z","iopub.status.idle":"2022-06-01T05:18:53.588819Z","shell.execute_reply.started":"2022-06-01T05:18:52.720106Z","shell.execute_reply":"2022-06-01T05:18:53.587843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import RandSpatialCrop\n\ntransform = RandSpatialCrop(roi_size=1)\n\ntry_tranform(df,nrows,transform,image_flag =1 ,mask_flag = 0)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:18:53.590237Z","iopub.execute_input":"2022-06-01T05:18:53.591364Z","iopub.status.idle":"2022-06-01T05:18:54.436681Z","shell.execute_reply.started":"2022-06-01T05:18:53.591318Z","shell.execute_reply":"2022-06-01T05:18:54.435472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import Rand2DElastic\nimport albumentations as A\n\ntransform = A.Compose([\n    A.RandomCrop(width=256, height=256),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n])\n\n\ntry_tranform(df,nrows,transform,image_flag =1 ,mask_flag = 0,albumentation=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:18:54.438173Z","iopub.execute_input":"2022-06-01T05:18:54.438618Z","iopub.status.idle":"2022-06-01T05:18:55.356162Z","shell.execute_reply.started":"2022-06-01T05:18:54.438574Z","shell.execute_reply":"2022-06-01T05:18:55.355026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from monai.transforms import Rand2DElastic\n# import albumentations as A\n\n# transform = A.Compose([\n#     A.augmentations.transforms.CLAHE(clip_limit=4.0,tile_grid_size=(8, 8),p=1)\n# ])\n\n\n# try_tranform(df,nrows,transform,image_flag =1 ,mask_flag = 0,albumentation=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:17:11.669553Z","iopub.execute_input":"2022-06-01T10:17:11.66996Z","iopub.status.idle":"2022-06-01T10:17:12.181904Z","shell.execute_reply.started":"2022-06-01T10:17:11.669925Z","shell.execute_reply":"2022-06-01T10:17:12.180382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import HistogramNormalize\n\ntransform = HistogramNormalize()\n\ntry_tranform(df,nrows,transform,image_flag =1 ,mask_flag = 0)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:22:50.882375Z","iopub.execute_input":"2022-06-01T05:22:50.882987Z","iopub.status.idle":"2022-06-01T05:22:51.795676Z","shell.execute_reply.started":"2022-06-01T05:22:50.882945Z","shell.execute_reply":"2022-06-01T05:22:51.794524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom monai.transforms import Rand2DElastic\nimport albumentations as A\n\ntransform = A.Compose([\n    A.augmentations.transforms.RandomBrightnessContrast(brightness_limit=[0,0,0], contrast_limit=[0,0,0], p=1)\n])\n\n\ntry_tranform(df,nrows,transform,image_flag =1 ,mask_flag = 0,albumentation=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:05:48.650126Z","iopub.execute_input":"2022-06-01T10:05:48.650578Z","iopub.status.idle":"2022-06-01T10:05:49.829212Z","shell.execute_reply.started":"2022-06-01T10:05:48.650542Z","shell.execute_reply":"2022-06-01T10:05:49.828328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from monai.transforms import Rand2DElastic\nimport albumentations as A\n\ntransform = A.Compose([\n    A.augmentations.transforms.GaussNoise(var_limit=(0.001, 0.02), mean=0, per_channel=False, p=1.0)\n])\n\n\ntry_tranform(df,nrows,transform,image_flag =1 ,mask_flag = 0,albumentation=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T05:21:04.244922Z","iopub.execute_input":"2022-06-01T05:21:04.245448Z","iopub.status.idle":"2022-06-01T05:21:05.095598Z","shell.execute_reply.started":"2022-06-01T05:21:04.245406Z","shell.execute_reply":"2022-06-01T05:21:05.09467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}