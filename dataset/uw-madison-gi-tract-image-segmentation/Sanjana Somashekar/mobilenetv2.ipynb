{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport gc\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nfrom datetime import datetime\nimport json,itertools\nfrom typing import Optional\nfrom glob import glob\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\nimport random\n\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, LearningRateScheduler\nfrom tensorflow.keras.models import load_model, save_model\nfrom matplotlib.patches import Rectangle\n\nfrom tensorflow.keras.layers import Conv2D, Activation, BatchNormalization\nfrom tensorflow.keras.layers import UpSampling2D, Input, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import plot_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-26T17:26:42.371045Z","iopub.execute_input":"2022-06-26T17:26:42.371545Z","iopub.status.idle":"2022-06-26T17:26:48.202931Z","shell.execute_reply.started":"2022-06-26T17:26:42.371423Z","shell.execute_reply":"2022-06-26T17:26:48.20196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random seeds\ndef set_seed(seed=0):\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\nset_seed(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.204711Z","iopub.execute_input":"2022-06-26T17:26:48.205583Z","iopub.status.idle":"2022-06-26T17:26:48.213307Z","shell.execute_reply.started":"2022-06-26T17:26:48.205545Z","shell.execute_reply":"2022-06-26T17:26:48.211826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GPU Setup:","metadata":{}},{"cell_type":"code","source":"print(f\"\\n... ACCELERATOR SETUP STARTING ...\\n\")\n\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \nexcept ValueError:\n    TPU = None\n\nif TPU:\n    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    print(f\"\\n... RUNNING ON CPU/GPU ...\")\n    strategy = tf.distribute.get_strategy() \n\nN_REPLICAS = strategy.num_replicas_in_sync\nprint(f\"... # OF REPLICAS: {N_REPLICAS} ...\\n\")\nprint(f\"\\n... ACCELERATOR SETUP COMPLTED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.214361Z","iopub.execute_input":"2022-06-26T17:26:48.214712Z","iopub.status.idle":"2022-06-26T17:26:48.236038Z","shell.execute_reply.started":"2022-06-26T17:26:48.214676Z","shell.execute_reply":"2022-06-26T17:26:48.235001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Required Constants Declared:","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 16\nEPOCHS = 30\nn_splits = 5\nfold_selected = 2   \nIMAGE_WIDTH = 224 #256\nIMAGE_HEIGHT = 224 #256","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.239316Z","iopub.execute_input":"2022-06-26T17:26:48.239566Z","iopub.status.idle":"2022-06-26T17:26:48.244333Z","shell.execute_reply.started":"2022-06-26T17:26:48.239543Z","shell.execute_reply":"2022-06-26T17:26:48.243195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Supplementary Functions: Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocessing(df, subset=\"train\"):\n    df[\"case\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\n    df[\"day\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\n    df[\"slice\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n    if (subset==\"train\") or (DEBUG):\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/train\"\n    else:\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/test\"\n    \n    all_images = glob(os.path.join(DIR, \"**\", \"*.png\"), recursive=True)\n    x = all_images[0].rsplit(\"/\", 4)[0] \n\n    path_partial_list = []\n    for i in range(0, df.shape[0]):\n        path_partial_list.append(os.path.join(x,\n                              \"case\"+str(df[\"case\"].values[i]),\n                              \"case\"+str(df[\"case\"].values[i])+\"_\"+ \"day\"+str(df[\"day\"].values[i]),\n                              \"scans\",\n                              \"slice_\"+str(df[\"slice\"].values[i])))\n    df[\"path_partial\"] = path_partial_list\n    path_partial_list = []\n    for i in range(0, len(all_images)):\n        path_partial_list.append(str(all_images[i].rsplit(\"_\",4)[0]))\n\n    tmp_df = pd.DataFrame()\n    tmp_df['path_partial'] = path_partial_list\n    tmp_df['path'] = all_images\n\n    df = df.merge(tmp_df, on=\"path_partial\").drop(columns=[\"path_partial\"])\n    df[\"width\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"height\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n    del x, path_partial_list, tmp_df\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.246537Z","iopub.execute_input":"2022-06-26T17:26:48.247361Z","iopub.status.idle":"2022-06-26T17:26:48.262902Z","shell.execute_reply.started":"2022-06-26T17:26:48.247325Z","shell.execute_reply":"2022-06-26T17:26:48.262014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def restructure(df, subset=\"train\"):\n    # RESTRUCTURE  DATAFRAME\n    df_out = pd.DataFrame({'id': df['id'][::3]})\n\n    if subset==\"train\":\n        df_out['large_bowel'] = df['segmentation'][::3].values\n        df_out['small_bowel'] = df['segmentation'][1::3].values\n        df_out['stomach'] = df['segmentation'][2::3].values\n\n    df_out['path'] = df['path'][::3].values\n    df_out['case'] = df['case'][::3].values\n    df_out['day'] = df['day'][::3].values\n    df_out['slice'] = df['slice'][::3].values\n    df_out['width'] = df['width'][::3].values\n    df_out['height'] = df['height'][::3].values\n\n    df_out=df_out.reset_index(drop=True)\n    df_out=df_out.fillna('')\n    if subset==\"train\":\n        df_out['count'] = np.sum(df_out.iloc[:,1:4]!='',axis=1).values\n    \n    return df_out","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.264568Z","iopub.execute_input":"2022-06-26T17:26:48.265311Z","iopub.status.idle":"2022-06-26T17:26:48.275309Z","shell.execute_reply.started":"2022-06-26T17:26:48.265277Z","shell.execute_reply":"2022-06-26T17:26:48.274354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Supplementary Functions : RLE Encoding and Decoding","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = np.array(mask_rle.split(), dtype=int)   \n    starts = s[0::2] - 1 # Every even value is the start, every odd value is the \"run\" length\n    lengths = s[1::2]\n    ends = starts + lengths\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color    \n    return img.reshape(shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.276371Z","iopub.execute_input":"2022-06-26T17:26:48.277097Z","iopub.status.idle":"2022-06-26T17:26:48.287733Z","shell.execute_reply.started":"2022-06-26T17:26:48.277064Z","shell.execute_reply":"2022-06-26T17:26:48.28687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run length encoding\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.289012Z","iopub.execute_input":"2022-06-26T17:26:48.289688Z","iopub.status.idle":"2022-06-26T17:26:48.297587Z","shell.execute_reply.started":"2022-06-26T17:26:48.289653Z","shell.execute_reply":"2022-06-26T17:26:48.296702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Definition of Metrics:","metadata":{}},{"cell_type":"code","source":"# Metrics\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n    return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + dice_loss(tf.cast(y_true, tf.float32), y_pred)\n\n#Keras\nALPHA = 0.5 # < 0.5 penalises FP more, > 0.5 penalises FN more\nCE_RATIO = 0.5 #weighted contribution of modified CE loss compared to Dice loss\n\ndef Combo_loss(targets, inputs, eps=1e-9):\n    targets = K.flatten(targets)\n    inputs = K.flatten(inputs)\n    smooth = eps\n    \n    intersection = K.sum(targets * inputs)\n    dice = (2. * intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n    inputs = K.clip(inputs, eps, 1.0 - eps)\n    out = - (ALPHA * ((targets * K.log(inputs)) + ((1 - ALPHA) * (1.0 - targets) * K.log(1.0 - inputs))))\n    weighted_ce = K.mean(out, axis=-1)\n    combo = (CE_RATIO * weighted_ce) - ((1 - CE_RATIO) * dice)\n    \n    return combo\n\n#Keras\nALPHA = 0.5\nBETA = 0.5\nGAMMA = 1\n\ndef FocalTverskyLoss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):\n    \n        #flatten label and prediction tensors\n        inputs = K.flatten(inputs)\n        targets = K.flatten(targets)\n        \n        #True Positives, False Positives & False Negatives\n        TP = K.sum((inputs * targets))\n        FP = K.sum(((1-targets) * inputs))\n        FN = K.sum((targets * (1-inputs)))\n               \n        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n        FocalTversky = K.pow((1 - Tversky), gamma)\n        \n        return FocalTversky","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.300874Z","iopub.execute_input":"2022-06-26T17:26:48.301313Z","iopub.status.idle":"2022-06-26T17:26:48.319254Z","shell.execute_reply.started":"2022-06-26T17:26:48.301289Z","shell.execute_reply":"2022-06-26T17:26:48.318372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Generator Wrapper Function:","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, batch_size = BATCH_SIZE, subset=\"train\", shuffle=False, width=IMAGE_WIDTH, height=IMAGE_HEIGHT):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(df))\n        self.width=width\n        self.height=height\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index):\n        X = np.empty((self.batch_size,self.width,self.height,3))\n        y = np.empty((self.batch_size,self.width,self.height,3))\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i, img_path in enumerate(self.df['path'].iloc[indexes]):\n            w=self.df['width'].iloc[indexes[i]]\n            h=self.df['height'].iloc[indexes[i]]\n            img = self.__load_grayscale(img_path)\n            X[i,] =img  \n            if self.subset == 'train':\n                for k,j in enumerate([\"large_bowel\",\"small_bowel\",\"stomach\"]):\n                    rles = self.df[j].iloc[indexes[i]]\n                    mask = rle_decode(rles, shape=(h, w, 1))\n                    mask = cv2.resize(mask, (self.width, self.height))\n                    y[i,:,:,k] = mask\n        if self.subset == 'train':\n            return X,y\n        else: \n            return X\n        \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n        dsize = (self.width, self.height)\n        img = cv2.resize(img, dsize)\n        #img = img.astype(np.float32) / 255.\n        img = ((img-img.min())/(img.max()-img.min())).astype(np.float32)\n        img = np.expand_dims(img, axis=-1)\n        return img","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.324642Z","iopub.execute_input":"2022-06-26T17:26:48.325357Z","iopub.status.idle":"2022-06-26T17:26:48.340366Z","shell.execute_reply.started":"2022-06-26T17:26:48.325322Z","shell.execute_reply":"2022-06-26T17:26:48.339422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def open_gray16(_path, normalize=True, to_rgb=False):\n    if normalize:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/255., axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/255.\n    else:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.341675Z","iopub.execute_input":"2022-06-26T17:26:48.342695Z","iopub.status.idle":"2022-06-26T17:26:48.351351Z","shell.execute_reply.started":"2022-06-26T17:26:48.342643Z","shell.execute_reply":"2022-06-26T17:26:48.35037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Setup:","metadata":{}},{"cell_type":"code","source":"print(\"\\n... DATA ACCESS SETUP STARTED ...\\n\")\n\nDATA_DIR = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\nsave_locally = None\nload_locally = None\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.352736Z","iopub.execute_input":"2022-06-26T17:26:48.353595Z","iopub.status.idle":"2022-06-26T17:26:48.362994Z","shell.execute_reply.started":"2022-06-26T17:26:48.353559Z","shell.execute_reply":"2022-06-26T17:26:48.361934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV)\nprint(train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.364379Z","iopub.execute_input":"2022-06-26T17:26:48.364958Z","iopub.status.idle":"2022-06-26T17:26:48.869827Z","shell.execute_reply.started":"2022-06-26T17:26:48.364922Z","shell.execute_reply":"2022-06-26T17:26:48.868848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Data Definition:","metadata":{}},{"cell_type":"code","source":"TEST_CSV = os.path.join(DATA_DIR, 'sample_submission.csv')\ntest_df = pd.read_csv(TEST_CSV)\ntest_split = 300\nseparate_test = True\nif len(test_df)==0:\n    DEBUG=True\n    test_df = train_df[-test_split:]\n    test_df_disp = test_df.copy()\n    y_test = test_df_disp[\"segmentation\"]\n    submission=test_df.copy()\n    submission['prediction'] = ''\n    if separate_test == True:\n        train_df = train_df[:-test_split]\nelse:\n    DEBUG=False\n\nprint(submission.head())\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.871289Z","iopub.execute_input":"2022-06-26T17:26:48.8719Z","iopub.status.idle":"2022-06-26T17:26:48.901509Z","shell.execute_reply.started":"2022-06-26T17:26:48.871863Z","shell.execute_reply":"2022-06-26T17:26:48.900483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing Data:","metadata":{}},{"cell_type":"code","source":"train_df = preprocessing(train_df, subset=\"train\")\ntrain_df = restructure(train_df, subset=\"train\")\n# Remove mislabeled training data\ntrain_df = train_df[(train_df['case']!=7)|(train_df['day']!=0)].reset_index(drop=True)\ntrain_df = train_df[(train_df['case']!=81)|(train_df['day']!=30)].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:48.903168Z","iopub.execute_input":"2022-06-26T17:26:48.903554Z","iopub.status.idle":"2022-06-26T17:26:56.651192Z","shell.execute_reply.started":"2022-06-26T17:26:48.903517Z","shell.execute_reply":"2022-06-26T17:26:56.650223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df_pred = preprocessing(test_df, subset=\"test\")\ntest_df_pred = restructure(test_df_pred, subset=\"test\")\n\ntest_df_disp = preprocessing(test_df_disp, subset=\"train\")\ntest_df_disp=restructure(test_df_disp, subset=\"train\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:56.652891Z","iopub.execute_input":"2022-06-26T17:26:56.653268Z","iopub.status.idle":"2022-06-26T17:26:58.108123Z","shell.execute_reply.started":"2022-06-26T17:26:56.653231Z","shell.execute_reply":"2022-06-26T17:26:58.107176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Garbage collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:58.109664Z","iopub.execute_input":"2022-06-26T17:26:58.110235Z","iopub.status.idle":"2022-06-26T17:26:58.261551Z","shell.execute_reply.started":"2022-06-26T17:26:58.110201Z","shell.execute_reply":"2022-06-26T17:26:58.260487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape, test_df_pred.shape, test_df_disp.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:58.263345Z","iopub.execute_input":"2022-06-26T17:26:58.263783Z","iopub.status.idle":"2022-06-26T17:26:58.272364Z","shell.execute_reply.started":"2022-06-26T17:26:58.263748Z","shell.execute_reply":"2022-06-26T17:26:58.271479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA Display:","metadata":{}},{"cell_type":"code","source":"def examine_id(DEMO_ID, seg_masks=False):\n  demo_ex = train_df[train_df.id==DEMO_ID].squeeze()\n  display(demo_ex.to_frame())\n\n  print(f\"\\n\\n...IMAGE ...\\n\")\n  plt.figure(figsize=(6,6))\n  plt.imshow(open_gray16(demo_ex.path), cmap=\"gray\")\n  plt.title(f\"Original Grayscale Image For ID: {demo_ex.id}\", fontweight=\"bold\")\n  plt.axis(False)\n  plt.show()\n\n  if(seg_masks):\n    print(f\"\\n\\n... 3 SEGMENTATION MASKS ...\\n\")\n\n    plt.figure(figsize=(14,7))\n    for i, _seg_type in enumerate([\"large_bowel\", \"small_bowel\", \"stomach\"]):\n        if pd.isna(demo_ex[f\"{_seg_type}\"]): continue\n        plt.subplot(1,3,i+1)\n        s = demo_ex[f\"{_seg_type}\"]\n        plt.imshow(rle_decode(demo_ex[f\"{_seg_type}\"], shape=(demo_ex.height, demo_ex.width), color=1))\n        plt.title(f\"RLE Encoding For {_seg_type} Segmentation\", fontweight=\"bold\")\n        plt.axis(False)\n    plt.tight_layout()\n    plt.show()\n\n  print(f\"\\n\\n...IMAGE WITH AN RGB SEGMENTATION MASK OVERLAY ...\\n\")\n\n  _img = open_gray16(demo_ex.path, to_rgb=True)\n  _img = ((_img-_img.min())/(_img.max()-_img.min())).astype(np.float32)\n  _seg_rgb = np.stack([rle_decode(demo_ex[f\"{_seg_type}\"], shape=(demo_ex.height, demo_ex.width), color=1) if not pd.isna(demo_ex[f\"{_seg_type}\"]) else np.zeros((demo_ex.height, demo_ex.width)) for _seg_type in [\"large_bowel\", \"small_bowel\", \"stomach\"]], axis=-1).astype(np.float32)\n  seg_overlay = cv2.addWeighted(src1=_img, alpha=0.99, src2=_seg_rgb, beta=0.33, gamma=0.0)\n\n  plt.figure(figsize=(6,6))\n  plt.imshow(seg_overlay)\n  plt.title(f\"Segmentation Overlay For ID: {demo_ex.id}\", fontweight=\"bold\")\n  handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n  labels = [\"Large Bowel Segmentation Map\", \"Small Bowel Segmentation Map\", \"Stomach Segmentation Map\"]\n  plt.legend(handles,labels)\n  plt.axis(False)\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:58.273995Z","iopub.execute_input":"2022-06-26T17:26:58.274564Z","iopub.status.idle":"2022-06-26T17:26:58.29028Z","shell.execute_reply.started":"2022-06-26T17:26:58.27453Z","shell.execute_reply":"2022-06-26T17:26:58.289409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... SINGLE ID EXPLORATION ...\\n\\n\")\nDEMO_ID = \"case123_day20_slice_0082\"\nexamine_id(DEMO_ID, seg_masks=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:58.293205Z","iopub.execute_input":"2022-06-26T17:26:58.293983Z","iopub.status.idle":"2022-06-26T17:26:58.980246Z","shell.execute_reply.started":"2022-06-26T17:26:58.293956Z","shell.execute_reply":"2022-06-26T17:26:58.979371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Grouping:","metadata":{}},{"cell_type":"code","source":"# Group by case id\nskf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\nfor fold, (_, val_idx) in enumerate(skf.split(X=train_df, y=train_df['count'], groups=train_df['case']), 1):\n    train_df.loc[val_idx, 'fold'] = fold\n\ntrain_df['fold'] = train_df['fold'].astype(np.uint8)\n\ntrain_ids = train_df[train_df[\"fold\"]!=fold_selected].index\nvalid_ids = train_df[train_df[\"fold\"]==fold_selected].index\n\nX_train = train_df[train_df.index.isin(train_ids)]\nX_valid = train_df[train_df.index.isin(valid_ids)]\n\nprint(train_df.groupby('fold').size())\nprint(X_train.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:58.981838Z","iopub.execute_input":"2022-06-26T17:26:58.982512Z","iopub.status.idle":"2022-06-26T17:26:59.151023Z","shell.execute_reply.started":"2022-06-26T17:26:58.982473Z","shell.execute_reply":"2022-06-26T17:26:59.150098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fold sizes\ntrain_df.groupby(['fold','count'])['id'].count()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:59.154112Z","iopub.execute_input":"2022-06-26T17:26:59.154375Z","iopub.status.idle":"2022-06-26T17:26:59.169421Z","shell.execute_reply.started":"2022-06-26T17:26:59.154351Z","shell.execute_reply":"2022-06-26T17:26:59.168516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install segmentation-models","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:26:59.170889Z","iopub.execute_input":"2022-06-26T17:26:59.171243Z","iopub.status.idle":"2022-06-26T17:27:11.996867Z","shell.execute_reply.started":"2022-06-26T17:26:59.171209Z","shell.execute_reply":"2022-06-26T17:27:11.995595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')\nsm.framework()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:27:11.999316Z","iopub.execute_input":"2022-06-26T17:27:11.999747Z","iopub.status.idle":"2022-06-26T17:27:12.186489Z","shell.execute_reply.started":"2022-06-26T17:27:11.9997Z","shell.execute_reply":"2022-06-26T17:27:12.185523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Definition: UNet with Pretrained MobileNetV2","metadata":{}},{"cell_type":"code","source":"def model_def():\n    inputs = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), name=\"input_image\")\n    ## Change channel size? OR change tensor size above?\n    ## Add preprocessing layer here\n    encoder = MobileNetV2(input_tensor=inputs, weights=\"imagenet\", include_top=False, alpha=0.35)\n    encoder.trainable = False ## Are we supposed to use a trained base? Yes\n    skip_connection_names = [\"input_image\", \"block_1_expand_relu\", \"block_3_expand_relu\", \"block_6_expand_relu\"]\n    encoder_output = encoder.get_layer(\"block_13_expand_relu\").output\n    \n    f = [16, 32, 48, 64]\n    x = encoder_output\n    for i in range(1, len(skip_connection_names)+1, 1):\n        x_skip = encoder.get_layer(skip_connection_names[-i]).output\n        x = UpSampling2D((2, 2))(x)\n        x = Concatenate()([x, x_skip])\n        \n        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        \n        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        \n    x = Conv2D(3, (1, 1), padding=\"same\")(x)\n    x = Activation(\"sigmoid\")(x) #Tanh gives between -1 to 1, same as our preprocessing // Sigmoid, as output masks will be between 0 to 1\n    \n    model = Model(inputs, x)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:27:12.188199Z","iopub.execute_input":"2022-06-26T17:27:12.188579Z","iopub.status.idle":"2022-06-26T17:27:12.199389Z","shell.execute_reply.started":"2022-06-26T17:27:12.188543Z","shell.execute_reply":"2022-06-26T17:27:12.198364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data generators \ntrain_generator = DataGenerator(X_train, shuffle=True)\nval_generator = DataGenerator(X_valid)\ntrain_generator","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:27:12.201035Z","iopub.execute_input":"2022-06-26T17:27:12.201725Z","iopub.status.idle":"2022-06-26T17:27:12.222349Z","shell.execute_reply.started":"2022-06-26T17:27:12.201686Z","shell.execute_reply":"2022-06-26T17:27:12.221241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Creation, Compilation, Training:","metadata":{}},{"cell_type":"code","source":"model = model_def()\nopt = tf.keras.optimizers.Nadam(1e-4)\nmetrics=[dice_coef,iou_coef]\n#loss=bce_dice_loss\n#loss=Combo_loss\nloss = FocalTverskyLoss\n#model.summary()\n#plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:27:12.224268Z","iopub.execute_input":"2022-06-26T17:27:12.224637Z","iopub.status.idle":"2022-06-26T17:27:16.528846Z","shell.execute_reply.started":"2022-06-26T17:27:12.2246Z","shell.execute_reply":"2022-06-26T17:27:16.52793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=opt, loss=loss, metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:27:16.534428Z","iopub.execute_input":"2022-06-26T17:27:16.534732Z","iopub.status.idle":"2022-06-26T17:27:16.551199Z","shell.execute_reply.started":"2022-06-26T17:27:16.534706Z","shell.execute_reply":"2022-06-26T17:27:16.550275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    'Mobilenet_model.keras',\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    save_weights_only=False,\n    mode='auto',\n)\n\nearly_stopping = EarlyStopping(\n    patience=5,\n    min_delta=0.0001,\n    restore_best_weights=True,\n)\n\ndef scheduler(epoch, lr):\n   if epoch < 10:\n     return lr\n   else:\n     return lr * tf.math.exp(-0.1)\nlr_scheduler = LearningRateScheduler(scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:27:16.553128Z","iopub.execute_input":"2022-06-26T17:27:16.553647Z","iopub.status.idle":"2022-06-26T17:27:16.561073Z","shell.execute_reply.started":"2022-06-26T17:27:16.55355Z","shell.execute_reply":"2022-06-26T17:27:16.559833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint, early_stopping],\n    #callbacks=[checkpoint, early_stopping, lr_scheduler],\n    use_multiprocessing=False,\n    workers=4,\n    epochs=EPOCHS\n    #epochs = 1\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:27:16.562785Z","iopub.execute_input":"2022-06-26T17:27:16.563363Z","iopub.status.idle":"2022-06-26T17:54:11.546611Z","shell.execute_reply.started":"2022-06-26T17:27:16.563325Z","shell.execute_reply":"2022-06-26T17:54:11.545511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Results:","metadata":{}},{"cell_type":"code","source":"# History\nhist_df = pd.DataFrame(history.history)\nhist_df.to_csv('history.csv')\n\n# PLOT TRAINING\nplt.figure(figsize=(15,5))\nplt.subplot(1,3,1)\nplt.plot(range(history.epoch[-1]+1),history.history['loss'],label='Train_Loss')\nplt.plot(range(history.epoch[-1]+1),history.history['val_loss'],label='Val_loss')\nplt.title('LOSS'); plt.xlabel('Epoch'); plt.ylabel('loss');plt.legend();\n\nplt.subplot(1,3,2)\nplt.plot(range(history.epoch[-1]+1),history.history['dice_coef'],label='Train_dice_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['val_dice_coef'],label='Val_dice_coef')\nplt.title('DICE'); plt.xlabel('Epoch'); plt.ylabel('dice_coef');plt.legend(); \n\nplt.subplot(1,3,3)\nplt.plot(range(history.epoch[-1]+1),history.history['iou_coef'],label='Train_iou_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['val_iou_coef'],label='Val_iou_coef')\nplt.title('IOU'); plt.xlabel('Epoch'); plt.ylabel('iou_coef');plt.legend();\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:54:11.547947Z","iopub.execute_input":"2022-06-26T17:54:11.548342Z","iopub.status.idle":"2022-06-26T17:54:39.694997Z","shell.execute_reply.started":"2022-06-26T17:54:11.548303Z","shell.execute_reply":"2022-06-26T17:54:39.694064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_objects = custom_objects={\n    'dice_coef': dice_coef,\n    'iou_coef': iou_coef,\n    #'bce_dice_loss': bce_dice_loss\n    #'Combo_loss' : Combo_loss\n    'FocalTverskyLoss' : FocalTverskyLoss\n}\nmodel = load_model('./Mobilenet_model.keras', custom_objects=custom_objects)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:54:39.696478Z","iopub.execute_input":"2022-06-26T17:54:39.697063Z","iopub.status.idle":"2022-06-26T17:54:40.721343Z","shell.execute_reply.started":"2022-06-26T17:54:39.697027Z","shell.execute_reply":"2022-06-26T17:54:40.720375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mask Prediction Visualisation on Test Dataset","metadata":{}},{"cell_type":"code","source":"num_img = 8\nstart = 63\npred_batches = DataGenerator(test_df_disp.iloc[start:start+num_img,:], batch_size = 1, subset=\"train\", shuffle=False)\nprint(\"Prediction Scores: Loss, Dice_coef, IOU_coef:\",model.evaluate(pred_batches, verbose = 1))\npreds = model.predict_generator(pred_batches,verbose=1)\n\nThreshold = 0.5\n# Visualizing\nfig = plt.figure(figsize=(10, 25))\ngs = gridspec.GridSpec(nrows=8, ncols=3)\ncolors = ['yellow','green','red']\nlabels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\npatches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3= mpl.colors.ListedColormap(colors[2])\n\nfor i in range(num_img):\n    images, mask = pred_batches[i]\n    sample_img=images[0,:,:,0]\n    mask1=mask[0,:,:,0]\n    mask2=mask[0,:,:,1]\n    mask3=mask[0,:,:,2]\n    \n    pre=preds[i]\n    predict1=pre[:,:,0]\n    predict2=pre[:,:,1]\n    predict3=pre[:,:,2]\n    \n    predict1= (predict1 > Threshold).astype(np.float32)\n    predict2= (predict2 > Threshold).astype(np.float32)\n    predict3= (predict3 > Threshold).astype(np.float32)\n    \n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img, cmap='bone')\n    ax0.set_title(\"Image\", fontsize=12, y=1.01)\n    #--------------------------\n    ax1 = fig.add_subplot(gs[i, 1])\n    ax1.set_title(\"Mask\", fontsize=12,  y=1.01)\n    l0 = ax1.imshow(sample_img, cmap='bone')\n    l1 = ax1.imshow(np.ma.masked_where(mask1== False,  mask1),cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(mask2== False,  mask2),cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(mask3== False,  mask3),cmap=cmap3, alpha=1)\n    #--------------------------\n    ax2 = fig.add_subplot(gs[i, 2])\n    ax2.set_title(\"Predict\", fontsize=12, y=1.01)\n    l0 = ax2.imshow(sample_img, cmap='bone')\n    l1 = ax2.imshow(np.ma.masked_where(predict1== False,  predict1),cmap=cmap1, alpha=1)\n    l2 = ax2.imshow(np.ma.masked_where(predict2== False,  predict2),cmap=cmap2, alpha=1)\n    l3 = ax2.imshow(np.ma.masked_where(predict3== False,  predict3),cmap=cmap3, alpha=1)\n   \n\n    _ = [ax.set_axis_off() for ax in [ax0,ax1,ax2]]\n    colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]\n    plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 12,title='Mask Labels', title_fontsize=12, edgecolor=\"black\",  facecolor='#c5c6c7')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:54:40.722985Z","iopub.execute_input":"2022-06-26T17:54:40.723365Z","iopub.status.idle":"2022-06-26T17:54:44.303885Z","shell.execute_reply.started":"2022-06-26T17:54:40.723328Z","shell.execute_reply":"2022-06-26T17:54:44.303053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Prediction:","metadata":{}},{"cell_type":"code","source":"#test = test_df_pred.iloc[start:start+num_img,:]\ntest = test_df_pred.copy()\nprint(test.shape)\nprint(\"Prediction Scores: Loss, Dice_coef, IOU_coef:\",model.evaluate(pred_batches, verbose = 1))\npred_batches = DataGenerator(test, batch_size = BATCH_SIZE, subset=\"test\", shuffle=False)\nnum_batches = int(len(test)/BATCH_SIZE)\n\nfor i in range(num_batches):\n    # Predict\n    preds = model.predict(pred_batches[i],verbose=0)  \n    \n    # Rle encode\n    for j in range(BATCH_SIZE):\n        \n        for k in range(3):\n            pred_img = cv2.resize(preds[j,:,:,k], (test.loc[i*BATCH_SIZE+j,\"width\"], test.loc[i*BATCH_SIZE+j,\"height\"]), interpolation=cv2.INTER_NEAREST) # resize probabilities to original shape\n            pred_img = (pred_img>0.5).astype(dtype='uint8')    # classify\n            rle_out = rle_encode(pred_img)\n            #print(rle_out)\n            submission.loc[3*(i*BATCH_SIZE+j)+k,'prediction'] = rle_out","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:54:44.305418Z","iopub.execute_input":"2022-06-26T17:54:44.305995Z","iopub.status.idle":"2022-06-26T17:54:46.623404Z","shell.execute_reply.started":"2022-06-26T17:54:44.30595Z","shell.execute_reply":"2022-06-26T17:54:46.622351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Kaggle Submission Requirement","metadata":{}},{"cell_type":"code","source":"sub_disp = submission.copy()\nsubmission.to_csv('submission.csv',index=False)\nsubmission.sample(20)\nprint(submission.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:54:46.625232Z","iopub.execute_input":"2022-06-26T17:54:46.625679Z","iopub.status.idle":"2022-06-26T17:54:46.645205Z","shell.execute_reply.started":"2022-06-26T17:54:46.625637Z","shell.execute_reply":"2022-06-26T17:54:46.644175Z"},"trusted":true},"execution_count":null,"outputs":[]}]}