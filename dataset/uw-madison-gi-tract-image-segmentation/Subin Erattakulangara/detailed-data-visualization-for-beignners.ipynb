{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Please upvote my notebook if you liked the contents**","metadata":{}},{"cell_type":"markdown","source":"## Load the libraries","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom skimage import color\nimport seaborn as sns\nfrom glob import glob\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-20T02:32:23.952163Z","iopub.execute_input":"2022-04-20T02:32:23.952516Z","iopub.status.idle":"2022-04-20T02:32:23.958066Z","shell.execute_reply.started":"2022-04-20T02:32:23.952478Z","shell.execute_reply":"2022-04-20T02:32:23.957094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the data\n\n* CSV data available is arranged in the following format.\n    1. ID\n    2. Class\n    3. Segmentation\n* Here we tried taking a peek into some samples from the data.\n* The data have some values having Nan so it need be cleaned before using.\n* The image sizes are embedded in the file names so we have to extract it out.","metadata":{}},{"cell_type":"code","source":"root_dir = Path('../input/uw-madison-gi-tract-image-segmentation')\ntrain_dir = root_dir / 'train'\ndf_train = pd.read_csv(root_dir / 'train.csv')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T02:32:26.948138Z","iopub.execute_input":"2022-04-20T02:32:26.948797Z","iopub.status.idle":"2022-04-20T02:32:27.282129Z","shell.execute_reply.started":"2022-04-20T02:32:26.948753Z","shell.execute_reply":"2022-04-20T02:32:27.281563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking number of data instances\n* we have same number of samples for\n    1. large bowel\n    2. small bowel\n    3. Stomach\n* No data cleaning is needed since we have same number of samples for all the classses\n* Note : no need to use any class weightage.","metadata":{}},{"cell_type":"code","source":"df_train['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T02:32:33.617307Z","iopub.execute_input":"2022-04-20T02:32:33.618014Z","iopub.status.idle":"2022-04-20T02:32:33.640442Z","shell.execute_reply.started":"2022-04-20T02:32:33.617979Z","shell.execute_reply":"2022-04-20T02:32:33.639411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating metadata for training\n* Why we have to create extra metadata\n    1. we need to extract cases to match with the segmentation masks\n    2. Need to extract the days from file names\n    3. Slice number is also embedded in the filename\n    \n**Example**\n\nsample file name from csv : case123_day20_slice_0002\n* case number : 123\n* day : 20\n* slice : 002\n\nSample scaned file name : ../input/uw-madison-gi-tract-image-segmentation/train/case101/case101_day20/scans/slice_0001_266_266_1.50_1.50.png\n\n**Parameters needed**\n* case number\n* day\n* slice number\n\n**So we need to extract all these details from the train.csv file to generate the file name**","metadata":{}},{"cell_type":"code","source":"#Generate the list of images\nimages_list = glob('../input/uw-madison-gi-tract-image-segmentation/train/*/*/scans/*.png')\n\n#extract details from the path\nimages_metadata = pd.DataFrame({'Path':images_list})\n\n#split the path to get individual parameters\npath_split = images_metadata['Path'].str.split('/',n=7,expand=True)\n\n#we need to extract [5] and [7]\nimages_metadata['CaseNum_Day'] = path_split[5]\nimages_metadata['SliceNum'] = path_split[7]\n\n#Resplitting to extract case, day, slice, height and width\ncase_split = images_metadata['CaseNum_Day'].str.split('_',n=2, expand=True)\nimages_metadata['Case'] = case_split[0].str[4:].astype(int)\nimages_metadata['Day'] = case_split[1].str[3:].astype(int)\n\n#Resplitting to extract slice, height and width\nfileName_split = images_metadata['SliceNum'].str.split('_',n=6, expand=True)\nimages_metadata['Slice'] = fileName_split[1].astype(int)\nimages_metadata['Height'] = fileName_split[2].astype(int)\nimages_metadata['Width'] = fileName_split[3].astype(int)\n\nimages_metadata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T02:32:46.575933Z","iopub.execute_input":"2022-04-20T02:32:46.576224Z","iopub.status.idle":"2022-04-20T02:32:47.783834Z","shell.execute_reply.started":"2022-04-20T02:32:46.576193Z","shell.execute_reply":"2022-04-20T02:32:47.782931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unique values from the metadata\n\n* There are 85 cases with 35 different dates\n* 4 types of heights and widths","metadata":{"execution":{"iopub.status.busy":"2022-04-19T17:56:28.723966Z","iopub.status.idle":"2022-04-19T17:56:28.725869Z","shell.execute_reply.started":"2022-04-19T17:56:28.725543Z","shell.execute_reply":"2022-04-19T17:56:28.725578Z"}}},{"cell_type":"code","source":"print('Unique case numbers ',len(images_metadata['Case'].unique()))\nprint('Unique Days ',len(images_metadata['Day'].unique()))\nprint('Unique Heights ',len(images_metadata['Height'].unique()))\nprint('Unique Widths ',len(images_metadata['Width'].unique()))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T02:32:52.09583Z","iopub.execute_input":"2022-04-20T02:32:52.096105Z","iopub.status.idle":"2022-04-20T02:32:52.105337Z","shell.execute_reply.started":"2022-04-20T02:32:52.096076Z","shell.execute_reply":"2022-04-20T02:32:52.104694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing the MRI samples\n1. pixel values in MRI are not in range of 0 -255\n2. So we need to normalize the values to visualize it properly\n3. we can use np.interp for normalizing the values","metadata":{}},{"cell_type":"code","source":"#plotting random samples\nplt.subplots(figsize=(12,16))\nfor i in range(12):\n    index = np.random.randint(0, images_metadata.shape[0])\n    image = np.array(Image.open(images_metadata.loc[index, 'Path']))\n    \n    plt.subplot(4,3,i+1)\n    title = (images_metadata.loc[index, 'CaseNum_Day'] + \n           '_Slice_' + str(images_metadata.loc[index, 'Slice']))\n    plt.title(title)\n    plt.imshow(np.interp(image, [np.min(image), np.max(image)], [0,255]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T02:33:35.915941Z","iopub.execute_input":"2022-04-20T02:33:35.91624Z","iopub.status.idle":"2022-04-20T02:33:37.79103Z","shell.execute_reply.started":"2022-04-20T02:33:35.916208Z","shell.execute_reply":"2022-04-20T02:33:37.790136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing the Masks\n* The masks provided are in the RLE format encoded in the train.csv file\n* we need to parse the format to create the masks\n* [Notebook1](http:/https://www.kaggle.com/code/abhishek123maurya/1-visualization-and-decoding-rle/) and [Notebook2](http:/https://www.kaggle.com/code/subinek/2-understanding-plotting-rle-bounding-boxes/edit/) helped in providing the essential code.\n* I would reccoment saving [Notebook2](http:/https://www.kaggle.com/code/subinek/2-understanding-plotting-rle-bounding-boxes/edit/) for your future challenges and notebooks","metadata":{}},{"cell_type":"code","source":"#Helper functions\n\n# Extract mask data from the train.csv file and load all non null values\nmask_encoding = df_train[df_train['segmentation'].notnull()]\n\n#convert it into a list index\nmask_index = list(mask_encoding.index)\n\n#function for getting pixel location\ndef get_pixel_loc(rle_string, img_shape):\n    rle = [int(i) for i in rle_string.split(' ')]\n    pairs = list(zip(rle[0::2],rle[1::2]))\n    p_loc = []     #   Pixel Locations\n\n    for start, length in pairs:\n        for p_pos in range(start, start + length):\n            p_loc.append((p_pos % img_shape[1], p_pos // img_shape[0]))\n    return p_loc\n\n#function for getting the mask\ndef get_mask(mask, img_shape):\n    canvas = np.zeros(img_shape).T\n    canvas[tuple(zip(*mask))] = 1\n    return canvas.T\n\n#applying the mask\ndef apply_mask(image, mask, img_shape):\n    image = image / image.max()\n    image = np.dstack((image, get_mask(mask, img_shape), get_mask(mask, img_shape)))\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-04-20T02:33:45.812907Z","iopub.execute_input":"2022-04-20T02:33:45.813525Z","iopub.status.idle":"2022-04-20T02:33:45.843017Z","shell.execute_reply.started":"2022-04-20T02:33:45.813485Z","shell.execute_reply":"2022-04-20T02:33:45.842124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting random masks from the dataset\nfor i in range(5):\n    index = mask_index[np.random.randint(0,len(mask_index) - 1)]\n    curr_id = mask_encoding.loc[index, 'id']\n    class_of_scan = mask_encoding.loc[index, 'class']\n\n    splits = curr_id.split('_')\n    x = images_metadata[(images_metadata['Case']==int(splits[0][4:]))\n                      &(images_metadata['Day']==int(splits[1][3:]))\n                      &(images_metadata['Slice']==int(splits[3]))]\n\n    image = np.array(Image.open(x['Path'].values[0]))\n    k = image.shape\n    rle_string = mask_encoding.loc[index, 'segmentation']\n    p_loc = get_pixel_loc(rle_string, k)\n\n\n    fig, ax = plt.subplots(1,3, figsize=(12,16))\n    ax[0].set_title('Image')\n    ax[0].imshow(image)\n\n    ax[1].set_title('Mask')\n    ax[1].imshow(get_mask(p_loc, k))\n\n    ax[2].set_title(f'{class_of_scan} Segmented')\n    ax[2].imshow(apply_mask(image, p_loc, k))\n    plt.show()\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-20T02:33:58.891875Z","iopub.execute_input":"2022-04-20T02:33:58.892152Z","iopub.status.idle":"2022-04-20T02:34:00.877888Z","shell.execute_reply.started":"2022-04-20T02:33:58.892123Z","shell.execute_reply":"2022-04-20T02:34:00.877255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Thank you for reviewing my notebook**","metadata":{}}]}