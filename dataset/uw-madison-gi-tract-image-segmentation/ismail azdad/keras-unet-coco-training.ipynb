{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip --quiet install pycocotools","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:00.267212Z","iopub.execute_input":"2022-06-06T11:08:00.267532Z","iopub.status.idle":"2022-06-06T11:08:11.264371Z","shell.execute_reply.started":"2022-06-06T11:08:00.267504Z","shell.execute_reply":"2022-06-06T11:08:11.263227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pycocotools\nfrom pycocotools import mask\nimport json\nimport numpy as np\nimport pycocotools.mask as mask_util\nfrom skimage import measure\nimport os\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nimport cv2\nimport random\nfrom itertools import groupby\nimport itertools\nimport pandas as pd\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom glob import glob\n# from google.colab.patches import cv2_imshow\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl\nfrom pycocotools.coco import COCO\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.metrics import *","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:11.267024Z","iopub.execute_input":"2022-06-06T11:08:11.267427Z","iopub.status.idle":"2022-06-06T11:08:11.279945Z","shell.execute_reply.started":"2022-06-06T11:08:11.267369Z","shell.execute_reply":"2022-06-06T11:08:11.278754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_json_tmp = '../input/keras-prepare-coco-analyse/tmp_json.json'\npath_json_train = '../input/keras-prepare-coco-analyse/train_json.json'\npath_json_test = '../input/keras-prepare-coco-analyse/test_json.json'","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:14:29.259259Z","iopub.execute_input":"2022-06-06T11:14:29.259657Z","iopub.status.idle":"2022-06-06T11:14:29.264205Z","shell.execute_reply.started":"2022-06-06T11:14:29.259613Z","shell.execute_reply":"2022-06-06T11:14:29.263524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_json = json.load(open(path_json_tmp, 'r'))\ntrain_json = json.load(open(path_json_train, 'r'))\ntest_json = json.load(open(path_json_test, 'r'))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:11.281162Z","iopub.execute_input":"2022-06-06T11:08:11.281386Z","iopub.status.idle":"2022-06-06T11:08:16.655006Z","shell.execute_reply.started":"2022-06-06T11:08:11.28136Z","shell.execute_reply":"2022-06-06T11:08:16.654102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coco_train = COCO(path_json_train)\ncatIds_train = coco_train.getCatIds() \nimgIds_train = coco_train.getImgIds() \nimgDict_train = coco_train.loadImgs(imgIds_train) \nprint(len(imgIds_train) , len(catIds_train))\n\ncoco_val = COCO(path_json_test)\ncatIds_val = coco_val.getCatIds()\nimgIds_val = coco_val.getImgIds()\nimgDict_val = coco_val.loadImgs(imgIds_val)\nprint(len(imgIds_val) , len(catIds_val))\n\n\ncoco = COCO(path_json_tmp)\ncatIDs = coco.getCatIds()\ncats = coco.loadCats(catIDs)\nimgIds = coco.getImgIds() \nimgDict = coco_train.loadImgs(imgIds) \nprint(len(imgIds) , len(cats))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:16.65748Z","iopub.execute_input":"2022-06-06T11:08:16.657811Z","iopub.status.idle":"2022-06-06T11:08:21.054548Z","shell.execute_reply.started":"2022-06-06T11:08:16.657766Z","shell.execute_reply":"2022-06-06T11:08:21.05356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nms=[cat['name'] for cat in cats]\nprint(len(nms),'categories: \\n{}\\n'.format(' '.join(nms)))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:21.055643Z","iopub.execute_input":"2022-06-06T11:08:21.055897Z","iopub.status.idle":"2022-06-06T11:08:21.06203Z","shell.execute_reply.started":"2022-06-06T11:08:21.055861Z","shell.execute_reply":"2022-06-06T11:08:21.061132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getClassName(classID, cats):\n    for i in range(len(cats)):\n        if cats[i]['id']==classID:\n            return cats[i]['name']\n    return \"None\"\n\nprint('The class name is', getClassName(0, cats))\nprint('The class name is', getClassName(1, cats))\nprint('The class name is', getClassName(2, cats))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:21.063347Z","iopub.execute_input":"2022-06-06T11:08:21.063889Z","iopub.status.idle":"2022-06-06T11:08:21.075733Z","shell.execute_reply.started":"2022-06-06T11:08:21.063834Z","shell.execute_reply":"2022-06-06T11:08:21.075047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load and display image\nplt.figure(figsize=(10,10)) \nimport skimage.io as io \nimg = coco_train.loadImgs(imgIds_train[np.random.randint(0,len(imgIds_train))])[0] \nI = io.imread(img['file_name'])/255.0\n\n# Or use url to load image\nplt.axis('off') \nplt.imshow(I) \nplt.show( )","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:21.077165Z","iopub.execute_input":"2022-06-06T11:08:21.077388Z","iopub.status.idle":"2022-06-06T11:08:21.377857Z","shell.execute_reply.started":"2022-06-06T11:08:21.077361Z","shell.execute_reply":"2022-06-06T11:08:21.377192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:21.379108Z","iopub.execute_input":"2022-06-06T11:08:21.379501Z","iopub.status.idle":"2022-06-06T11:08:21.384564Z","shell.execute_reply.started":"2022-06-06T11:08:21.379451Z","shell.execute_reply":"2022-06-06T11:08:21.383997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs = coco_train.loadImgs(imgIds_train[0:2])\n_, axs = plt.subplots(len(imgs), 2, figsize=(40, 15 * len(imgs)))\nfor img, ax in zip(imgs, axs):\n    print(img['file_id'])\n    I = Image.open(img['file_name'])\n    I = Image.fromarray(\n        np.array(Image.open(img['file_name'])).astype(\"uint16\"))\n    annIds = coco_train.getAnnIds(imgIds=[img['id']])\n    anns = coco_train.loadAnns(annIds)\n    ax[0].imshow(I)\n    ax[1].imshow(I)\n    plt.sca(ax[1])\n    coco.showAnns(anns, draw_bbox=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:21.401649Z","iopub.execute_input":"2022-06-06T11:08:21.402094Z","iopub.status.idle":"2022-06-06T11:08:23.942077Z","shell.execute_reply.started":"2022-06-06T11:08:21.402044Z","shell.execute_reply":"2022-06-06T11:08:23.94134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### GENERATE A SEGMENTATION MASK ####\nfilterClasses =  ['small_bowel', 'large_bowel', 'stomach']\nmask = np.zeros((img['height'],img['width']))\nfor i in range(len(anns)):\n    className = getClassName(anns[i]['category_id'], cats)\n    pixel_value = filterClasses.index(className)+1\n    mask = np.maximum(coco_train.annToMask(anns[i])*pixel_value, mask)\nplt.imshow(mask)\n\nprint('Unique pixel values in the mask are:', np.unique(mask))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:23.943258Z","iopub.execute_input":"2022-06-06T11:08:23.943737Z","iopub.status.idle":"2022-06-06T11:08:24.136767Z","shell.execute_reply.started":"2022-06-06T11:08:23.943686Z","shell.execute_reply":"2022-06-06T11:08:24.135884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### GENERATE BINARY MASK ####\n\nmask = np.zeros((img['height'],img['width']))\nfor i in range(len(anns)):\n    mask = np.maximum(coco_train.annToMask(anns[i]), mask)\nplt.imshow(mask)\n\nprint('Unique pixel values in the mask are:', np.unique(mask))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:08:24.13791Z","iopub.execute_input":"2022-06-06T11:08:24.138127Z","iopub.status.idle":"2022-06-06T11:08:24.323058Z","shell.execute_reply.started":"2022-06-06T11:08:24.1381Z","shell.execute_reply":"2022-06-06T11:08:24.322127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filterDataset( classes=None, json_file=None):    \n    # initialize COCO api for instance annotations\n    annFile = json_file\n    coco = COCO(annFile)\n    \n    images = []\n    if classes!=None:\n        # iterate for each individual class in the list\n        for className in classes:\n            # get all images containing given categories\n            catIds = coco.getCatIds(catNms=className)\n            imgIds = coco.getImgIds(catIds=catIds)\n            images += coco.loadImgs(imgIds)\n    \n    else:\n        imgIds = coco.getImgIds()\n        images = coco.loadImgs(imgIds)\n    \n    # Now, filter out the repeated images\n    unique_images = []\n    for i in range(len(images)):\n        if images[i] not in unique_images:\n            unique_images.append(images[i])\n            \n    random.shuffle(unique_images)\n    dataset_size = len(unique_images)\n    \n    return unique_images, dataset_size, coco\n","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:09:19.705993Z","iopub.execute_input":"2022-06-06T11:09:19.706427Z","iopub.status.idle":"2022-06-06T11:09:19.717161Z","shell.execute_reply.started":"2022-06-06T11:09:19.706383Z","shell.execute_reply":"2022-06-06T11:09:19.716137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['small_bowel', 'large_bowel', 'stomach']","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:10:10.684531Z","iopub.execute_input":"2022-06-06T11:10:10.684886Z","iopub.status.idle":"2022-06-06T11:10:10.691044Z","shell.execute_reply.started":"2022-06-06T11:10:10.684821Z","shell.execute_reply":"2022-06-06T11:10:10.689216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_tmp, dataset_size_tmp, coco = filterDataset( classes,  path_json_tmp)\nimages_train, dataset_size_train, coco_train = filterDataset( classes,  path_json_train)\nimages_test, dataset_size_test, coco_val = filterDataset( classes,  path_json_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:10:11.957383Z","iopub.execute_input":"2022-06-06T11:10:11.957764Z","iopub.status.idle":"2022-06-06T11:11:16.29642Z","shell.execute_reply.started":"2022-06-06T11:10:11.957728Z","shell.execute_reply":"2022-06-06T11:11:16.295123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use image size 128 for better results \nimage_size = 128 \nepochs = 10\nbatch_size = 8\ninput_image_size = (128,128)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:11:16.298724Z","iopub.execute_input":"2022-06-06T11:11:16.29922Z","iopub.status.idle":"2022-06-06T11:11:16.304958Z","shell.execute_reply.started":"2022-06-06T11:11:16.299166Z","shell.execute_reply":"2022-06-06T11:11:16.304026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGeneratorFromCocoJson(tf.keras.utils.Sequence):\n  # function getting info dataset from json coco\n  # Batch size\n  # subset train or test for annotations\n  # image_list to develop...\n  # classes classe wanted\n  # input image size tuple (X,X)\n  # annFile path to annoted coco json file file\n    def __init__(self, batch_size=batch_size, subset=\"train\", image_list=[], classes=[], input_image_size=(128, 128), annFile='', shuffle=False):\n\n        super().__init__()\n        self.subset = subset\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(image_list))\n        self.image_list = image_list\n        self.classes = classes\n        self.input_image_size = (input_image_size)\n        self.dataset_size = len(image_list)\n        self.coco = COCO(annFile)\n        catIds = self.coco.getCatIds(catNms=self.classes)\n        self.catIds = catIds\n        self.cats = self.coco.loadCats(catIDs)\n        self.imgIds = self.coco.getImgIds()\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(len(self.image_list)/self.batch_size)\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def getClassName(self, classID, cats):\n        for i in range(len(cats)):\n            if cats[i]['id'] == classID:\n                return cats[i]['name']\n        return None\n\n    def getNormalMask(self, image_id, catIds):\n        annIds = self.coco.getAnnIds(image_id, catIds=catIds, iscrowd=None)\n        anns = self.coco.loadAnns(annIds)\n        cats = self.coco.loadCats(catIds)\n        train_mask = np.zeros(self.input_image_size, dtype=np.uint8)\n        for a in range(len(anns)):\n            className = self.getClassName(anns[a]['category_id'], cats)\n            pixel_value = self.classes.index(className)+1\n            new_mask = cv2.resize(self.coco.annToMask(\n                anns[a])*pixel_value, self.input_image_size)\n            train_mask = np.maximum(new_mask, train_mask)\n            # train_mask = new_mask / 255.0\n        return train_mask\n\n    def getLevelsMask(self, image_id):\n        # for each category , we get the x mask and add it to mask list\n        res = []\n        mask = np.zeros((self.input_image_size))\n        for j, categorie in enumerate(self.catIds):\n            annIds = coco.getAnnIds(image_id, catIds=categorie, iscrowd=None)\n            anns = coco.loadAnns(annIds)\n            mask = self.getNormalMask(image_id, categorie)\n            res.append(mask)\n        return res\n\n    def getImage(self, file_path):\n        train_img = cv2.imread(file_path, cv2.IMREAD_ANYDEPTH)\n        train_img = cv2.resize(train_img, (self.input_image_size))\n        train_img = train_img.astype(np.float32) / 255.\n        if (len(train_img.shape) == 3 and train_img.shape[2] == 3):\n            return train_img\n        else:\n            stacked_img = np.stack((train_img,)*3, axis=-1)\n            return stacked_img\n\n    def get_image_Infos_by_path_id(self, node):\n        for dict in self.image_list:\n            if dict['file_name'] == node:\n                return dict\n\n    def __getitem__(self, index):\n        X = np.empty((self.batch_size, 128, 128, 3))\n        y = np.empty((self.batch_size, 128, 128, 3))\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        for i in range(len(indexes)):\n            value = indexes[i]\n            img_info = self.image_list[value]\n            w = img_info['height']\n            h = img_info['width']\n            X[i, ] = self.getImage(img_info['file_name'])\n            mask_train = self.getLevelsMask(img_info['id'])\n            for j in self.catIds:\n                y[i, :, :, j] = mask_train[j]\n                y[i, :, :, j] = mask_train[j]\n                y[i, :, :, j] = mask_train[j]\n\n        X = np.array(X)\n        y = np.array(y)\n\n        if self.subset == 'train':\n            return X, y\n        else:\n            return X","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:11:16.306318Z","iopub.execute_input":"2022-06-06T11:11:16.306559Z","iopub.status.idle":"2022-06-06T11:11:16.33579Z","shell.execute_reply.started":"2022-06-06T11:11:16.306531Z","shell.execute_reply":"2022-06-06T11:11:16.3349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_generator_class = DataGeneratorFromCocoJson(\n    batch_size, \"train\", images_tmp, classes, input_image_size, path_json_tmp, shuffle=False)\ntest_generator_class = DataGeneratorFromCocoJson(\n    batch_size, \"train\", images_test, classes, input_image_size, path_json_test, shuffle=False)\ntrain_generator_class = DataGeneratorFromCocoJson(\n    batch_size, \"train\", images_train, classes, input_image_size, path_json_train, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:14:32.448721Z","iopub.execute_input":"2022-06-06T11:14:32.449554Z","iopub.status.idle":"2022-06-06T11:14:37.462051Z","shell.execute_reply.started":"2022-06-06T11:14:32.449512Z","shell.execute_reply":"2022-06-06T11:14:37.461212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = tmp_generator_class.__getitem__(1)\n\nfig = plt.figure(figsize=(50, 40))\ngs = gridspec.GridSpec(nrows=len(X), ncols=2)\ncolors = ['yellow', 'green', 'red']\nlabels = [\"Small Bowel\", \"Large Bowel\", \"Stomach\"]\npatches = [mpatches.Patch(\n    color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3 = mpl.colors.ListedColormap(colors[2])\nflag = False\nfor i in range(0, 8):\n\n    images, mask = X[i], y[i]\n    sample_img = images/255.\n    mask1 = mask[:, :, 0]\n    mask2 = mask[:, :, 1]\n    mask3 = mask[:, :, 2]\n\n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img[:, :, 0], cmap='gray')\n\n    ax1 = fig.add_subplot(gs[i, 1])\n    if(flag == False):\n        flag = True\n        ax0.set_title(\"Image\", fontsize=15, weight='bold', y=1.02)\n        ax1.set_title(\"Mask\", fontsize=15, weight='bold', y=1.02)\n        plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4, fontsize=14,\n                   title='Mask Labels', title_fontsize=14, edgecolor=\"black\",  facecolor='#c5c6c7')\n\n    l0 = ax1.imshow(sample_img[:, :, 0], cmap='gray')\n    l1 = ax1.imshow(np.ma.masked_where(\n        mask1 == False,  mask1), cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(\n        mask2 == False,  mask2), cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(\n        mask3 == False,  mask3), cmap=cmap3, alpha=1)\n    _ = [ax.set_axis_off() for ax in [ax0, ax1]]\n\n    colors = [im.cmap(im.norm(1)) for im in [l1, l2, l3]]\nplt.subplots_adjust(left=0.11, bottom=0.08, right=0.3,\n                    top=0.92, wspace=0.01, hspace=0.08)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:14:45.170352Z","iopub.execute_input":"2022-06-06T11:14:45.170676Z","iopub.status.idle":"2022-06-06T11:14:47.170062Z","shell.execute_reply.started":"2022-06-06T11:14:45.170643Z","shell.execute_reply":"2022-06-06T11:14:47.169161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install --quiet segmentation-models","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install --quiet  git+https: // github.com/qubvel/segmentation_models","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')\nsm.framework()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:15:40.854597Z","iopub.execute_input":"2022-06-06T11:15:40.854919Z","iopub.status.idle":"2022-06-06T11:15:40.885738Z","shell.execute_reply.started":"2022-06-06T11:15:40.854885Z","shell.execute_reply":"2022-06-06T11:15:40.884524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\nfrom keras.losses import binary_crossentropy\n\n# Metrics\ndice_loss_fun = sm.losses.DiceLoss()\nbce_loss_fun = sm.losses.BinaryCELoss()\n\n\ndef bce_dice_loss(y_true, y_pred):\n    dice_loss = dice_loss_fun(y_true, y_pred)\n    bce_loss = bce_loss_fun(y_true, y_pred)\n    return 0.5 * dice_loss + 0.5 * bce_loss\n\n# https://www.kaggle.com/code/ammarnassanalhajali/uwmgi-unet-keras-train-with-eda\n\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    coef = (2. * intersection + smooth) \\\n        / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return coef","metadata":{"execution":{"iopub.status.busy":"2022-06-06T11:15:35.78292Z","iopub.execute_input":"2022-06-06T11:15:35.784048Z","iopub.status.idle":"2022-06-06T11:15:35.823141Z","shell.execute_reply.started":"2022-06-06T11:15:35.783996Z","shell.execute_reply":"2022-06-06T11:15:35.821851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models.utils import set_trainable\n\nmodel = Unet('efficientnetb7', input_shape=(128, 128, 3), classes=3,\n             activation='sigmoid', encoder_weights='imagenet')\nmodel.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = dataset_size_train // batch_size\nvalidation_steps = dataset_size_test // batch_size","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n\ntb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n\ncheckpoint = ModelCheckpoint(\n    'UNET_model',\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    save_weights_only=False,\n    mode='auto',\n)\n\nreduce_lr = ReduceLROnPlateau(\n    factor=0.2, monitor='val_loss', verbose=1, patience=5, min_lr=0.001)\n# reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n\nearly_stopping = EarlyStopping(monitor='loss', min_delta=0.0001, patience=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator_class,\n    validation_data=test_generator_class,\n\n    validation_steps=validation_steps,\n    steps_per_epoch=steps_per_epoch,\n    epochs=epochs,\n\n    callbacks=[tb_callback, reduce_lr,\n               early_stopping, checkpoint],\n\n    batch_size=batch_size,\n    workers=4,\n    use_multiprocessing=False\n\n)\n","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n# summarize history for IOU\nplt.plot(history.history['dice_coef'])\nplt.plot(history.history['val_dice_coef'])\nplt.title('dice_coef iou')\nplt.ylabel('iou')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./model.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('./model.h5',\n                    custom_objects={'dice_coef': dice_coef, 'bce_dice_loss': bce_dice_loss})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator_class = DataGeneratorFromCocoJson(\n    batch_size, \"train\", images_test, classes, input_image_size, path_json_test, shuffle=True)\nimg_s, mask_s = test_generator_class.__getitem__(0)\npreds = model.predict(img_s)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 25))\ngs = gridspec.GridSpec(nrows=len(img_s), ncols=3)\ncolors = ['yellow', 'green', 'red']\nlabels = [\"Small Bowel\", \"Large Bowel\", \"Stomach\"]\npatches = [mpatches.Patch(\n    color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3 = mpl.colors.ListedColormap(colors[2])\nflag = False\nfor i in range(0, 7):\n\n    images, mask = img_s[i], mask_s[i]\n    sample_img = images/255.\n    mask1 = mask[:, :, 0]\n    mask2 = mask[:, :, 1]\n    mask3 = mask[:, :, 2]\n\n    pre = preds[i]\n    predict1 = pre[:, :, 0]\n    predict1 = (predict1 > 0.8).astype(np.float32)\n    predict1 = np.array(predict1)\n    predict2 = pre[:, :, 1]\n    predict3 = pre[:, :, 2]\n\n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img[:, :, 0], cmap='gray')\n\n    ax1 = fig.add_subplot(gs[i, 1])\n    ax2 = fig.add_subplot(gs[i, 2])\n    if(flag == False):\n        flag = True\n        ax0.set_title(\"Image\", fontsize=15, weight='bold', y=1.02)\n        ax1.set_title(\"Mask\", fontsize=15, weight='bold', y=1.02)\n        ax2.set_title(\"predicted Mask\", fontsize=15, weight='bold', y=1.02)\n        plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4, fontsize=14,\n                   title='Mask Labels', title_fontsize=14, edgecolor=\"black\",  facecolor='#c5c6c7')\n\n    l0 = ax1.imshow(sample_img[:, :, 0], cmap='gray')\n    l1 = ax1.imshow(np.ma.masked_where(\n        mask1 == False,  mask1), cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(\n        mask2 == False,  mask2), cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(\n        mask3 == False,  mask3), cmap=cmap3, alpha=1)\n\n    l0 = ax2.imshow(sample_img[:, :, 0], cmap='gray')\n    l1 = ax2.imshow(np.ma.masked_where(\n        predict1 == False,  predict1), cmap=cmap1, alpha=1)\n    l2 = ax2.imshow(np.ma.masked_where(\n        predict2 == False,  predict2), cmap=cmap2, alpha=1)\n    l3 = ax2.imshow(np.ma.masked_where(\n        predict3 == False,  predict3), cmap=cmap3, alpha=1)\n    _ = [ax.set_axis_off() for ax in [ax0, ax1]]\n\n    colors = [im.cmap(im.norm(1)) for im in [l1, l2, l3]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run-length encoding\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n\n    return ' '.join(str(x) for x in runs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_test, dataset_size_test, coco_val = filterDataset( classes,  path_json_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame.from_records(images_test)\nsubmission_df.insert(5, 'prediction', np.nan)\nsubmission_df.insert(3, 'class_name', np.nan)\nsubmission_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ntest_generator_class = DataGeneratorFromCocoJson(\n    1, 'test', images_test, classes, input_image_size, path_json_test, shuffle = True)\ngc.collect()\nLOGITS = model.predict(test_generator_class, verbose=1)\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame.from_records(images_test) \nsubmission_df.insert(5,'prediction', np.nan)\nsubmission_df.insert(3,'class_name', np.nan)\nsubmission_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbs = []\nsbs = []\nsts = []\nfor index, row in tqdm(submission_df.iterrows(), total=submission_df.shape[0]):\n    root_shape = (submission_df.iloc[index][\"height\"],\n                  submission_df.iloc[index][\"width\"])\n    pred_arr = np.round(cv2.resize(\n        LOGITS[index, :, :, 0], root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n    lbs.append(rle_encode(pred_arr))\n    pred_arr = np.round(cv2.resize(\n        LOGITS[index, :, :, 1], root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n    sbs.append(rle_encode(pred_arr))\n    pred_arr = np.round(cv2.resize(\n        LOGITS[index, :, :, 2], root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n    sts.append(rle_encode(pred_arr))\ndel LOGITS\ngc.collect()    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\nclasses = []\nrles = []\nfor index, row in tqdm(submission_df.iterrows(), total=submission_df.shape[0]):\n    ids.extend([row['file_id']] * 3)\n    classes.extend(['large_bowel', 'small_bowel', 'stomach'])\n    rles.extend([lbs[index], sbs[index], sts[index]])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame()\nsubmission_df['id'] = ids\nsubmission_df['class'] = classes\nsubmission_df['predicted'] = rles\n# submission_df = submission_df.reset_index(drop=True)\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.sample(10)","metadata":{},"execution_count":null,"outputs":[]}]}