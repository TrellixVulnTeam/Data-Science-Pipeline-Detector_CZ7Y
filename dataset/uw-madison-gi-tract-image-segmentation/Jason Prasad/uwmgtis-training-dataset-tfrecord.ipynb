{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook creates a *train.csv* and a number of `TFRecord`s. Each record corresponds to a grouped fold. The fold respects the cases available in the training PNGs (i.e. `GroupKFold`). The *train.csv* has the information about the training examples, as well as, the fold each belongs to. The records are available in the following dataset:\n\n[UWMGTIS Training Dataset](https://www.kaggle.com/datasets/jasonprasad/uwmgtis-training-dataset)","metadata":{}},{"cell_type":"code","source":"import glob\nimport math\nimport os\nimport random\n\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom IPython.display import HTML\nfrom sklearn.model_selection import GroupKFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-20T13:00:38.227947Z","iopub.execute_input":"2022-05-20T13:00:38.228284Z","iopub.status.idle":"2022-05-20T13:00:38.234082Z","shell.execute_reply.started":"2022-05-20T13:00:38.228243Z","shell.execute_reply":"2022-05-20T13:00:38.233345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\nN_SPLITS = 16  # Works out to be > ~100MB per TFRecord\nOUTPUT_SHAPE = (224, 224)\nSEED = 42\nTRAIN_DIR = f\"{DATA_DIR}/train\"\nTRAIN_CSV = f\"{DATA_DIR}/train.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:12:19.476519Z","iopub.execute_input":"2022-05-20T12:12:19.476738Z","iopub.status.idle":"2022-05-20T12:12:19.482069Z","shell.execute_reply.started":"2022-05-20T12:12:19.476712Z","shell.execute_reply":"2022-05-20T12:12:19.481091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The shuffle for the GroupKFold adds randomness\nos.environ['PYTHONHASHSEED'] = str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:12:19.483348Z","iopub.execute_input":"2022-05-20T12:12:19.483649Z","iopub.status.idle":"2022-05-20T12:12:19.493566Z","shell.execute_reply.started":"2022-05-20T12:12:19.483615Z","shell.execute_reply":"2022-05-20T12:12:19.492662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the image DataFrame\n\nThe image `DataFrame` is constructed by reading all of the *.png* paths available in the train directory. The `DataFrame` will contain the case, day, slice, filepath, and pixel dimensions. The filepath is all that is necessary to create the image `tf.data.Dataset`, whereas the other attributes are used to decode the segmentation masks.","metadata":{}},{"cell_type":"code","source":"def parse_int(s):\n    i = j = 0\n    while i < len(s):\n        while j < len(s) and s[j].isdigit():\n            j += 1\n        if i < j:\n            return int(s[i:j])\n        i = j = j + 1\n    return math.nan\n\ndef extract_image_info(path):\n    case_day, fname = path.rsplit(\"/\", maxsplit=3)[1::2]\n    case, day = case_day.split(\"_\")\n    slice, height, width = fname.split(\"_\", maxsplit=4)[1:4]\n    info = [f\"{case}_{day}_slice_{slice}\"]\n    numeric_info = [case, day, slice, height, width]\n    info.extend([parse_int(info) for info in numeric_info])\n    return info\n    \ndef create_image_df(path):\n    paths = glob.glob(f\"{TRAIN_DIR}/**/*.png\", recursive=True)\n    df = pd.DataFrame({\"path\": paths})\n    info_cols = [\"id\", \"case\", \"day\", \"slice\", \"height\", \"width\"]\n    df[info_cols] = df.apply(\n        lambda row: extract_image_info(row.path), \n        axis=1,\n        result_type=\"expand\"\n    )\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:12:19.495927Z","iopub.execute_input":"2022-05-20T12:12:19.496277Z","iopub.status.idle":"2022-05-20T12:12:19.510138Z","shell.execute_reply.started":"2022-05-20T12:12:19.496232Z","shell.execute_reply":"2022-05-20T12:12:19.509454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df = create_image_df(TRAIN_DIR)\nimage_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:12:19.511526Z","iopub.execute_input":"2022-05-20T12:12:19.512549Z","iopub.status.idle":"2022-05-20T12:12:30.351687Z","shell.execute_reply.started":"2022-05-20T12:12:19.512505Z","shell.execute_reply":"2022-05-20T12:12:30.349919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the mask DataFrame","metadata":{}},{"cell_type":"markdown","source":"The mask`DataFrame` is constructed by manipulating the *train.csv*. The *class/segmentation* structure is flattened for easier access later on.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(TRAIN_CSV)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:13:35.468264Z","iopub.execute_input":"2022-05-20T12:13:35.468698Z","iopub.status.idle":"2022-05-20T12:13:36.053398Z","shell.execute_reply.started":"2022-05-20T12:13:35.468657Z","shell.execute_reply":"2022-05-20T12:13:36.052523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I took the `unstack` logic from [UWMGI Image Segmentation Make TFRecords](https://www.kaggle.com/code/tt195361/uwmgi-image-segmentation-make-tfrecords)","metadata":{}},{"cell_type":"code","source":"def create_mask_df(df):\n    df = (\n        df.set_index([\"id\", \"class\"])\n        .unstack()\n        .reset_index()\n    )\n    df.columns = \"id\", \"lb_seg\", \"sb_seg\", \"s_seg\"\n    df.fillna(\"\", inplace=True)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:13:37.437314Z","iopub.execute_input":"2022-05-20T12:13:37.43786Z","iopub.status.idle":"2022-05-20T12:13:37.442952Z","shell.execute_reply.started":"2022-05-20T12:13:37.437826Z","shell.execute_reply":"2022-05-20T12:13:37.441975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_df = create_mask_df(df)\nmask_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:13:37.886826Z","iopub.execute_input":"2022-05-20T12:13:37.887144Z","iopub.status.idle":"2022-05-20T12:13:38.101069Z","shell.execute_reply.started":"2022-05-20T12:13:37.887103Z","shell.execute_reply":"2022-05-20T12:13:38.099795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Join the image and mask DataFrames and create K-folds\n\nThe image and mask `DataFrames` are joined so that the may be split into K-folds, as well as, to relate the pixel dimensions to the segmentation masks.","metadata":{}},{"cell_type":"code","source":"df = image_df.merge(mask_df, on=\"id\", how=\"left\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:13:39.463221Z","iopub.execute_input":"2022-05-20T12:13:39.464654Z","iopub.status.idle":"2022-05-20T12:13:39.547488Z","shell.execute_reply.started":"2022-05-20T12:13:39.464586Z","shell.execute_reply":"2022-05-20T12:13:39.54627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.sample(frac=1).reset_index(drop=True)\ngroups = X[\"case\"]","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-05-20T12:13:40.546146Z","iopub.execute_input":"2022-05-20T12:13:40.546506Z","iopub.status.idle":"2022-05-20T12:13:40.587746Z","shell.execute_reply.started":"2022-05-20T12:13:40.546469Z","shell.execute_reply":"2022-05-20T12:13:40.586905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = GroupKFold(n_splits=N_SPLITS).split(X=X, groups=groups)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:13:41.625346Z","iopub.execute_input":"2022-05-20T12:13:41.625689Z","iopub.status.idle":"2022-05-20T12:13:41.631019Z","shell.execute_reply.started":"2022-05-20T12:13:41.625654Z","shell.execute_reply":"2022-05-20T12:13:41.629868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[\"fold\"] = -1\nfor fold, (_, test_indices) in enumerate(folds):\n    X.loc[test_indices, \"fold\"] = fold","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:13:42.670734Z","iopub.execute_input":"2022-05-20T12:13:42.671112Z","iopub.status.idle":"2022-05-20T12:13:42.703465Z","shell.execute_reply.started":"2022-05-20T12:13:42.671067Z","shell.execute_reply":"2022-05-20T12:13:42.70216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.to_csv(\"train.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:13:43.487385Z","iopub.execute_input":"2022-05-20T12:13:43.48772Z","iopub.status.idle":"2022-05-20T12:13:44.794646Z","shell.execute_reply.started":"2022-05-20T12:13:43.487687Z","shell.execute_reply":"2022-05-20T12:13:44.793563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating TF dataset for images and masks\n\nThe following helpers were taken from [UWMGIT - DeepLabV3+ - End-to-End Pipeline [TF]](https://www.kaggle.com/code/dschettler8845/uwmgit-deeplabv3-end-to-end-pipeline-tf#helper_functions) with slight modifications. Assumptions that were made: to use resizing with padding to minimize distortion, as well as, to use nearest neighbor in resizing to preserve the `dtype`.","metadata":{}},{"cell_type":"code","source":"def tf_rle_decode(mask_rle, orig_shape, output_shape):\n    shape = tf.convert_to_tensor(orig_shape, tf.int64)\n    size = tf.math.reduce_prod(shape)\n    \n    # Split string\n    s = tf.strings.split(mask_rle)\n    s = tf.strings.to_number(s, tf.int64)\n    \n    # Get starts and lengths\n    starts = s[::2] - 1\n    lens = s[1::2]\n    \n    # Make ones to be scattered\n    total_ones = tf.reduce_sum(lens)\n    ones = tf.ones([total_ones], tf.uint8)\n    \n    # Make scattering indices\n    r = tf.range(total_ones)\n    lens_cum = tf.math.cumsum(lens)\n    s = tf.searchsorted(lens_cum, r, \"right\")\n    idx = r + tf.gather(starts - tf.pad(lens_cum[:-1], [(1, 0)]), s)\n    \n    # Scatter ones into flattened mask\n    mask_flat = tf.scatter_nd(tf.expand_dims(idx, 1), ones, [size])\n    \n    # Reshape and resize into mask\n    mask = tf.reshape(mask_flat, orig_shape)\n    mask = tf.expand_dims(mask, axis=-1)\n    mask = tf.image.resize_with_pad(\n        mask,\n        *output_shape,\n        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n    )\n    return tf.cast(mask, tf.uint8)\n\ndef tf_load_image(path, output_shape):\n    \"\"\" Load an image with the resized output shape using only TF\n    \n    Args:\n        path (string): Path to the image to be loaded\n        output_shape (tuple, optional): Shape to resize image\n    \n    Returns:\n        3 channel tf.Constant image ready for training/inference\n    \n    \"\"\"\n    raw = tf.io.read_file(path)\n    img = tf.image.decode_png(raw, channels=3, dtype=tf.uint16)\n    img = tf.image.resize_with_pad(\n        img, \n        *output_shape,\n        tf.image.ResizeMethod.NEAREST_NEIGHBOR\n    )\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:13:45.475332Z","iopub.execute_input":"2022-05-20T12:13:45.475691Z","iopub.status.idle":"2022-05-20T12:13:45.49192Z","shell.execute_reply.started":"2022-05-20T12:13:45.475654Z","shell.execute_reply":"2022-05-20T12:13:45.490212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assemble_masks(lb_seg, sb_seg, s_seg, height, width, output_shape):\n    orig_shape = (width, height)  # this ordering is important to decode the rle correctly!\n    masks = [\n        tf_rle_decode(lb_seg, orig_shape, output_shape),\n        tf_rle_decode(sb_seg, orig_shape, output_shape),\n        tf_rle_decode(s_seg, orig_shape, output_shape),\n    ]\n    return tf.concat(masks, axis=-1)\n    \ndef make_dataset(df, output_shape=OUTPUT_SHAPE):\n    id_ds = tf.data.Dataset.from_tensor_slices(df.id)\n    image_ds = tf.data.Dataset.from_tensor_slices(df.path)\n    image_ds = image_ds.map(\n        lambda path: tf_load_image(path, output_shape),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    mask_ds = tf.data.Dataset.from_tensor_slices((\n        df.lb_seg, \n        df.sb_seg, \n        df.s_seg, \n        df.height,\n        df.width\n    ))\n    mask_ds = mask_ds.map(\n        lambda *args: assemble_masks(*args, output_shape),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    \n    return tf.data.Dataset.zip((id_ds, image_ds, mask_ds))\n\ndef show_example(ds):\n    for example in ds:\n        id, img, mask = example\n        if tf.reduce_sum(mask) > 0:\n            break\n    _, ax = plt.subplots(figsize=(6, 6))\n    ax.set_title(id.numpy().decode())\n    ax.imshow(tf.keras.utils.array_to_img(img), cmap=\"gray\")\n    ax.imshow(tf.keras.utils.array_to_img(mask), cmap=\"hot\", alpha=0.5)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:27:15.719014Z","iopub.execute_input":"2022-05-20T12:27:15.719337Z","iopub.status.idle":"2022-05-20T12:27:15.733078Z","shell.execute_reply.started":"2022-05-20T12:27:15.719307Z","shell.execute_reply":"2022-05-20T12:27:15.732194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_fold = 0\nexample_ds = make_dataset(X[X.fold == example_fold])\nshow_example(example_ds)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:27:16.273712Z","iopub.execute_input":"2022-05-20T12:27:16.274004Z","iopub.status.idle":"2022-05-20T12:27:18.038891Z","shell.execute_reply.started":"2022-05-20T12:27:16.273972Z","shell.execute_reply":"2022-05-20T12:27:18.037751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Persisting dataset with TFRecord","metadata":{}},{"cell_type":"code","source":"def bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef encode_example(id, image, mask):\n    return id, tf.io.encode_png(image), tf.io.encode_png(mask)\n\ndef serialize_example(id, image, mask):\n    features = tf.train.Features(feature={\n        \"id\": bytes_feature(id),\n        \"image\": bytes_feature(image),\n        \"mask\": bytes_feature(mask),\n    })\n    \n    example_proto = tf.train.Example(features=features)\n    return example_proto.SerializeToString()\n\ndef write_records(ds, fold, n_splits=N_SPLITS, output_shape=OUTPUT_SHAPE):\n    h, w = output_shape\n    path = f\"uwmgtis-{h}-{w}.tfrecord-{fold:04d}-of-{n_splits:04d}\"\n    with tf.io.TFRecordWriter(path) as writer:\n        for id, image, mask in ds.as_numpy_iterator():\n            example = serialize_example(id, image, mask)\n            writer.write(example)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:21:05.598537Z","iopub.execute_input":"2022-05-20T12:21:05.59887Z","iopub.status.idle":"2022-05-20T12:21:05.611312Z","shell.execute_reply.started":"2022-05-20T12:21:05.59884Z","shell.execute_reply":"2022-05-20T12:21:05.609985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(N_SPLITS):\n    fold_ds = make_dataset(X[X.fold == fold])\n    encoded_fold_ds = fold_ds.map(encode_example, num_parallel_calls=tf.data.AUTOTUNE)\n    write_records(encoded_fold_ds, fold)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading an example TFRecord","metadata":{}},{"cell_type":"code","source":"def parse_example(example):\n    features = {\n        \"id\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"mask\": tf.io.FixedLenFeature([], tf.string),\n    }\n    \n    example = tf.io.parse_single_example(example, features)\n    image = tf.image.decode_png(example[\"image\"], channels=3, dtype=tf.uint16)\n    mask = tf.image.decode_png(example[\"mask\"], channels=3, dtype=tf.uint8)\n    return example[\"id\"], image, mask","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:22:51.93746Z","iopub.execute_input":"2022-05-20T12:22:51.937973Z","iopub.status.idle":"2022-05-20T12:22:51.945163Z","shell.execute_reply.started":"2022-05-20T12:22:51.937924Z","shell.execute_reply":"2022-05-20T12:22:51.943901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_record = \"uwmgtis-224-224.tfrecord-0000-of-0016\"\nrecord_ds = tf.data.TFRecordDataset(example_record)\nrecord_ds = record_ds.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\nshow_example(record_ds)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T12:27:32.193886Z","iopub.execute_input":"2022-05-20T12:27:32.194264Z","iopub.status.idle":"2022-05-20T12:27:32.478534Z","shell.execute_reply.started":"2022-05-20T12:27:32.194232Z","shell.execute_reply":"2022-05-20T12:27:32.477719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the *id* persisted in the records we can retrieve specific slices. In the following case we are using it to animate the scans and masks.","metadata":{}},{"cell_type":"code","source":"case36_day8 = filter(\n    lambda x: x[0].decode().startswith(\"case36_day8\"), \n    record_ds.as_numpy_iterator()\n)\ncase36_day8 = list(case36_day8)\ncase36_day8.sort(key=lambda x: x[0])","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(6, 6))\n\nims = []\nfor _, img, mask in case36_day8:\n    im = ax.imshow(tf.keras.utils.array_to_img(img), cmap=\"gray\")\n    im2 = ax.imshow(tf.keras.utils.array_to_img(mask), cmap=\"hot\", alpha=0.5)\n    ims.append([im, im2])\n\nani = animation.ArtistAnimation(fig, ims)\nplt.close()\nHTML(ani.to_jshtml())","metadata":{"execution":{"iopub.status.busy":"2022-05-20T13:00:42.778217Z","iopub.execute_input":"2022-05-20T13:00:42.778539Z","iopub.status.idle":"2022-05-20T13:01:03.930013Z","shell.execute_reply.started":"2022-05-20T13:00:42.778505Z","shell.execute_reply":"2022-05-20T13:01:03.928889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}