{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 入力形式に対応したデータセットを作る\n- case2 ~ case133までを学習用、case134以降を評価用に使う","metadata":{}},{"cell_type":"markdown","source":"https://github.com/akshaykvnit/pl-sem-seg/blob/master/pl_training.ipynb","metadata":{}},{"cell_type":"code","source":"EPOCHS = 1\nTHRESHOLD = 0.99999\nINPUT_SIZE = (360, 360)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:12:45.936663Z","iopub.execute_input":"2022-06-13T12:12:45.937191Z","iopub.status.idle":"2022-06-13T12:12:45.966741Z","shell.execute_reply.started":"2022-06-13T12:12:45.937111Z","shell.execute_reply":"2022-06-13T12:12:45.965989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom glob import glob\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torchvision.models.segmentation import lraspp_mobilenet_v3_large, fcn_resnet50\n\nimport pytorch_lightning as pl\n\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:12:45.968258Z","iopub.execute_input":"2022-06-13T12:12:45.968515Z","iopub.status.idle":"2022-06-13T12:12:55.226387Z","shell.execute_reply.started":"2022-06-13T12:12:45.968481Z","shell.execute_reply":"2022-06-13T12:12:55.225653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_file_id(file_name):\n    parts = file_name.split(\"_\")\n    case = parts[0].split(\"/\")[-1]\n    day = parts[1].split(\"/\")[0]\n    slice = \"slice_\" + parts[2]\n    return case, day, slice\n\ndef get_file_dict(file_names):\n    file_dict = {}\n    for file_name in file_names:\n        case, day, slice = get_file_id(file_name)\n        file_id = \"{}_{}_{}\".format(case, day, slice)\n        file_dict[file_id] = file_name\n    return file_dict\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:12:55.227768Z","iopub.execute_input":"2022-06-13T12:12:55.228012Z","iopub.status.idle":"2022-06-13T12:12:55.237173Z","shell.execute_reply.started":"2022-06-13T12:12:55.227979Z","shell.execute_reply":"2022-06-13T12:12:55.236417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle3_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string list formated\n    '''\n    results = []\n    for i in range(3):\n        pixels = img[i].flatten()\n        pixels = np.concatenate([[0], pixels, [0]])\n        runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n        runs[1::2] -= runs[::2]\n        results.append(' '.join(str(x) for x in runs))\n    return results\n\ndef rle3_decode(mask_rle3, shape, input_size):\n    '''\n    mask_rle3: run-length as string list formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    masks = []\n    for mask_rle in mask_rle3:\n        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n        mask_rle = str(mask_rle)\n        if mask_rle != 'nan':\n            s = mask_rle.split()\n            starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n            starts -= 1\n            ends = starts + lengths\n            for lo, hi in zip(starts, ends):\n                img[lo:hi] = 1\n        img = img.reshape(shape)\n        masks.append(img)\n    stacked = np.stack(masks).transpose(2, 1, 0)\n    res_img = ImageOps.mirror(Image.fromarray(stacked)).rotate(90)\n    res_img = res_img.resize(input_size)\n    \n    return np.asarray(res_img)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:12:55.239253Z","iopub.execute_input":"2022-06-13T12:12:55.239662Z","iopub.status.idle":"2022-06-13T12:12:55.252336Z","shell.execute_reply.started":"2022-06-13T12:12:55.239625Z","shell.execute_reply":"2022-06-13T12:12:55.251563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(pd_table, input_size, mode):\n    dataset = []\n    # CSVファイルを順に処理\n    for colum_num in range(0, len(pd_table), 3):\n        table = pd_table[colum_num:colum_num+3]\n        assert(len(table['id'].unique())==1)\n        assert(list(table['class']) == ['large_bowel', 'small_bowel', 'stomach'])\n        file_id, rle_str_list = list(table['id'])[0], list(table['segmentation'])\n\n        file_name = file_dict[file_id]\n        case_id = int(file_id.split('_')[0][4:])\n        \n        if (mode == 'train' and case_id < 134) or (mode == 'test' and case_id >= 134):\n            data = {}\n            data[\"file_name\"] = file_name\n            data[\"mask\"] = rle_str_list\n            dataset.append(data)\n\n    return dataset\n\n\n\nclass MyDataset(Dataset):\n    def __init__(self, pd_table, input_size, mode='train'):\n        super().__init__()\n        self.pd_table = pd_table\n        self.input_size = input_size\n        self.mode = mode\n        self.data = create_dataset(pd_table, input_size, mode)\n        self.len = len(self.data)\n        \n    def __len__(self):\n        return self.len\n    \n    def __getitem__(self, index):\n        file_name = self.data[index][\"file_name\"]\n        shape = (int(file_name.split('_')[3]), int(file_name.split('_')[4]))\n        image = np.asarray(Image.open(file_name).resize(self.input_size)).astype(np.float32)[:, :, np.newaxis].transpose(2,1,0)\n        mask = rle3_decode(self.data[index][\"mask\"], shape, self.input_size).astype(np.float32).transpose(2,1,0)\n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:12:55.253565Z","iopub.execute_input":"2022-06-13T12:12:55.256783Z","iopub.status.idle":"2022-06-13T12:12:55.27064Z","shell.execute_reply.started":"2022-06-13T12:12:55.256743Z","shell.execute_reply":"2022-06-13T12:12:55.269673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = \"/kaggle/input/uw-madison-gi-tract-image-segmentation/\"\npd_table = pd.read_csv(\"{}train.csv\".format(root_dir))\n\nfile_names = glob(\"{}train/*/*/scans/*.png\".format(root_dir))\nfile_dict = get_file_dict(file_names)\n\ntrain_dataset = MyDataset(pd_table, INPUT_SIZE)\nvalid_dataset = MyDataset(pd_table, INPUT_SIZE, mode='test')\n\nn_cpu = os.cpu_count()\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=n_cpu)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=n_cpu)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:12:55.272157Z","iopub.execute_input":"2022-06-13T12:12:55.272449Z","iopub.status.idle":"2022-06-13T12:13:16.670476Z","shell.execute_reply.started":"2022-06-13T12:12:55.272413Z","shell.execute_reply":"2022-06-13T12:13:16.669574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"---\\ntrain\")\nimage, mask = train_dataset[81]\nplt.subplot(1,2,1)\nplt.imshow(image.transpose(2,1,0))\nplt.subplot(1,2,2)\nplt.imshow(mask.transpose(2,1,0))\nplt.show()\n\nprint(\"---\\nvalid\")\nimage, mask = valid_dataset[62]\nplt.subplot(1,2,1)\nplt.imshow(image.transpose(2,1,0))\nplt.subplot(1,2,2)\nplt.imshow(mask.transpose(2,1,0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:13:16.67165Z","iopub.execute_input":"2022-06-13T12:13:16.672281Z","iopub.status.idle":"2022-06-13T12:13:17.266334Z","shell.execute_reply.started":"2022-06-13T12:13:16.672234Z","shell.execute_reply":"2022-06-13T12:13:17.265691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T15:08:53.529321Z","iopub.execute_input":"2022-05-28T15:08:53.529751Z","iopub.status.idle":"2022-05-28T15:08:53.946427Z","shell.execute_reply.started":"2022-05-28T15:08:53.52972Z","shell.execute_reply":"2022-05-28T15:08:53.94522Z"}}},{"cell_type":"code","source":"class SegModel(pl.LightningModule):\n    def __init__(self):\n        super(SegModel, self).__init__()\n        self.batch_size = 16\n        self.learning_rate = 1e-4\n        self.net = fcn_resnet50(num_classes=3, pretrained_backbone=False)\n        self.sigmoid = nn.Sigmoid()\n        #self.net.backbone['0'][0] = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        self.net.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # fcn_resnet50\n        #self.transform = transforms.Compose([\n            #transforms.ToTensor(),\n            #transforms.Normalize(mean = [0.35675976, 0.37380189, 0.3764753], std = [0.32064945, 0.32098866, 0.32325324])\n        #])\n        self.trainset = train_dataset\n        self.testset = valid_dataset\n        \n    def forward(self, x):\n        return self.sigmoid(self.net(x)['out'])\n    \n    def training_step(self, batch, batch_nb) :\n        img, mask = batch\n        img = img.float()\n        mask = mask.float()\n        out = self.forward(img)\n        #print('mask', mask)\n        #print('out', out)\n        loss_val = F.cross_entropy(out, mask)\n#         print(loss.shape)\n        return {'loss' : loss_val}\n    \n    def configure_optimizers(self):\n        opt = torch.optim.Adam(self.net.parameters(), lr = self.learning_rate)\n        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max = 10)\n        return [opt], [sch]\n    \n    def train_dataloader(self):\n        return DataLoader(self.trainset, batch_size = self.batch_size, shuffle = True)\n    \n    def test_dataloader(self):\n        return DataLoader(self.testset, batch_size = 1, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:13:17.267657Z","iopub.execute_input":"2022-06-13T12:13:17.268427Z","iopub.status.idle":"2022-06-13T12:13:17.279644Z","shell.execute_reply.started":"2022-06-13T12:13:17.268385Z","shell.execute_reply":"2022-06-13T12:13:17.278827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SegModel()\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(dirpath = '/',save_last = True, verbose = True, monitor = 'loss', mode = 'min')\ntrainer = pl.Trainer(gpus = 1, max_epochs= EPOCHS, checkpoint_callback = checkpoint_callback)\ntrainer.fit(model)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:13:17.283459Z","iopub.execute_input":"2022-06-13T12:13:17.284095Z","iopub.status.idle":"2022-06-13T12:49:53.109851Z","shell.execute_reply.started":"2022-06-13T12:13:17.284055Z","shell.execute_reply":"2022-06-13T12:49:53.109034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glob('/kaggle/working/lightning_logs/version_0/checkpoints/*.ckpt')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:49:53.111052Z","iopub.execute_input":"2022-06-13T12:49:53.113143Z","iopub.status.idle":"2022-06-13T12:49:53.122931Z","shell.execute_reply.started":"2022-06-13T12:49:53.11309Z","shell.execute_reply":"2022-06-13T12:49:53.121891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SegModel()\nckpt_file = glob('/kaggle/working/lightning_logs/version_0/checkpoints/*.ckpt')[-1]\ncheckpoint = torch.load(ckpt_file, map_location = lambda storage, loc : storage)\nmodel.load_state_dict(checkpoint['state_dict'])\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:49:53.124228Z","iopub.execute_input":"2022-06-13T12:49:53.124591Z","iopub.status.idle":"2022-06-13T12:49:53.926896Z","shell.execute_reply.started":"2022-06-13T12:49:53.124546Z","shell.execute_reply":"2022-06-13T12:49:53.926215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 推論","metadata":{}},{"cell_type":"code","source":"print(\"---\\ntest\")\nimage, mask = train_dataset[81]\nplt.subplot(1,4,1)\nplt.imshow(image.transpose(2,1,0))\n\npredict = model(torch.tensor(image).unsqueeze(0))\nresult = predict.cpu().detach().numpy().squeeze().transpose(2,1,0)\nplt.subplot(1,4,2)\nplt.imshow(result)\n\nplt.subplot(1,4,3)\nplt.imshow((result>THRESHOLD).astype(np.float32))\n\nplt.subplot(1,4,4)\nplt.imshow(mask.transpose(2,1,0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:49:53.928034Z","iopub.execute_input":"2022-06-13T12:49:53.928862Z","iopub.status.idle":"2022-06-13T12:49:55.947761Z","shell.execute_reply.started":"2022-06-13T12:49:53.928822Z","shell.execute_reply":"2022-06-13T12:49:55.947105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 提出用データ生成","metadata":{}},{"cell_type":"code","source":"sub_df = pd.read_csv('{}sample_submission.csv'.format(root_dir))\nif not len(sub_df):\n    debug = True\n    test_fnames = glob(\"{}train/*/*/scans/*.png\".format(root_dir))\nelse:\n    debug = False\n    test_fnames = glob(\"{}test/*/*/scans/*.png\".format(root_dir))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:51:15.917674Z","iopub.execute_input":"2022-06-13T12:51:15.918068Z","iopub.status.idle":"2022-06-13T12:51:16.590403Z","shell.execute_reply.started":"2022-06-13T12:51:15.918027Z","shell.execute_reply":"2022-06-13T12:51:16.589621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_ids, pred_classes, pred_strings = [], [], []\nfor test_fname in test_fnames:\n    case, day, slice = get_file_id(test_fname)\n    shape = (int(test_fname.split('_')[3]), int(test_fname.split('_')[4]))\n    file_id = \"{}_{}_{}\".format(case, day, slice)\n    image = np.asarray(Image.open(test_fname).resize(INPUT_SIZE)).astype(np.float32)[:, :, np.newaxis].transpose(2,1,0)\n    predict = model(torch.tensor(image).unsqueeze(0))\n    resized = Image.fromarray((predict.cpu().detach().numpy().squeeze().transpose(2,1,0)).astype(np.uint8)).resize(shape)\n    result = (np.asarray(resized)>THRESHOLD).astype(np.float32).transpose(2,1,0)\n    rle_results = rle3_encode(result)\n    for cls, rle_result in zip(['large_bowel', 'small_bowel', 'stomach'], rle_results):\n        pred_ids.append(file_id)\n        pred_classes.append(cls)\n        pred_strings.append(rle_result)\n\npred_df = pd.DataFrame({\n    \"id\":pred_ids,\n    \"class\":pred_classes,\n    \"predicted\":pred_strings\n})\n\nif not debug:\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n    del sub_df['predicted']\nelse:\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n    del sub_df['segmentation']\n    \nsub_df = sub_df.merge(pred_df, on=['id','class'])\nsub_df.to_csv('submission.csv',index=False)\ndisplay(sub_df.head(5))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T12:51:26.455866Z","iopub.execute_input":"2022-06-13T12:51:26.456535Z"},"trusted":true},"execution_count":null,"outputs":[]}]}