{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! ls ../input/segmentation-pytorchmodel/segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:25:31.470479Z","iopub.execute_input":"2022-06-23T19:25:31.470921Z","iopub.status.idle":"2022-06-23T19:25:32.187182Z","shell.execute_reply.started":"2022-06-23T19:25:31.47083Z","shell.execute_reply":"2022-06-23T19:25:32.186178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r ../input/segmentation-pytorchmodel/segmentation_models_pytorch/efficientnet_pytorch-0.6.3/ /tmp/st\n!cp -r ../input/segmentation-pytorchmodel/segmentation_models_pytorch/pretrainedmodels-0.7.4/ /tmp/st","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:25:32.189462Z","iopub.execute_input":"2022-06-23T19:25:32.189938Z","iopub.status.idle":"2022-06-23T19:25:33.930519Z","shell.execute_reply.started":"2022-06-23T19:25:32.189897Z","shell.execute_reply":"2022-06-23T19:25:33.92925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /tmp/st/efficientnet_pytorch-0.6.3/","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:25:33.936013Z","iopub.execute_input":"2022-06-23T19:25:33.938004Z","iopub.status.idle":"2022-06-23T19:26:06.496076Z","shell.execute_reply.started":"2022-06-23T19:25:33.937942Z","shell.execute_reply":"2022-06-23T19:26:06.495055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /tmp/st/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:26:06.497319Z","iopub.execute_input":"2022-06-23T19:26:06.497671Z","iopub.status.idle":"2022-06-23T19:26:37.638504Z","shell.execute_reply.started":"2022-06-23T19:26:06.497636Z","shell.execute_reply":"2022-06-23T19:26:37.637504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation_models_pytorch --no-index --find-links=../input/segmentation-pytorchmodel/segmentation_models_pytorch\n","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:26:37.642252Z","iopub.execute_input":"2022-06-23T19:26:37.642997Z","iopub.status.idle":"2022-06-23T19:26:48.079748Z","shell.execute_reply.started":"2022-06-23T19:26:37.642951Z","shell.execute_reply":"2022-06-23T19:26:48.078742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install monai --no-index --find-links ../input/monai-uwmadison/monai monai","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:26:48.081556Z","iopub.execute_input":"2022-06-23T19:26:48.081962Z","iopub.status.idle":"2022-06-23T19:26:58.66428Z","shell.execute_reply.started":"2022-06-23T19:26:48.081922Z","shell.execute_reply":"2022-06-23T19:26:58.663294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import libraries\n# Operating system libraries\nfrom glob import glob\nimport os\nimport time\nimport copy\nimport monai\nimport gc\nimport cupy as cp\n\n# linear algebra and data processing\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\n\n# visualization\nimport cv2\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom matplotlib import animation, rc\nrc('animation', html='jshtml')\nimport seaborn as sns\n\n# Progress bars to know cell progress in pandas apply\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm_notebook\ntqdm_notebook.pandas()\n\n# PyTorch deep learning semantic segmentation\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\n# Albumentations for image augmentations\nimport albumentations as A","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:26:58.668269Z","iopub.execute_input":"2022-06-23T19:26:58.668598Z","iopub.status.idle":"2022-06-23T19:27:10.008201Z","shell.execute_reply.started":"2022-06-23T19:26:58.668567Z","shell.execute_reply":"2022-06-23T19:27:10.007121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.isdir('test_updated'):\n    os.makedirs('test_updated')\ncase_day_all = glob('../input/uw-madison-gi-tract-image-segmentation/test/*/*')\nclahe_transform_6 = A.Compose([A.CLAHE(clip_limit=6,p=1.0)])\n\nfor case_day in case_day_all:\n    print(case_day)\n    case, day = (case_day.split('/')[-1]).split('_')\n    if not os.path.isdir('./test_updated/'+case):\n        os.makedirs('./test_updated/'+case)\n    if not os.path.isdir('./test_updated/'+case+'/'+case+'_'+day):\n        os.makedirs('./test_updated/'+case+'/'+case+'_'+day)\n    if not os.path.isdir('./test_updated/'+case+'/'+case+'_'+day+'/scans'):\n        os.makedirs('./test_updated/'+case+'/'+case+'_'+day+'/scans')\n\n    images = glob('../input/uw-madison-gi-tract-image-segmentation/test/'+case+'/'+case+'_'+day+'/scans/*')\n    max_pixel = 0\n    for image in images:\n        image = cv2.imread(image,cv2.IMREAD_UNCHANGED)\n        if image.max() > max_pixel:\n            max_pixel = image.max()\n    #print(\"Max Pixel Value:\",max_pixel)\n    NormalizeIntensity = monai.transforms.NormalizeIntensity(subtrahend=0, divisor=max_pixel/255)\n    #HistogramNormalize = monai.transforms.HistogramNormalize(num_bins=64)\n    for image in images:\n        image_path = image.split('/')[-1]\n        image = cv2.imread(image,cv2.IMREAD_UNCHANGED)\n        image[image>12000] = 12000\n        image_normalized = NormalizeIntensity.__call__(image)\n        data = clahe_transform_6(image=image_normalized)\n        image_clahe = data['image']\n        #image_histogram_normalized = HistogramNormalize.__call__(image_normalized)\n        cv2.imwrite('./test_updated/'+case+'/'+case+'_'+day+'/scans'+'/'+image_path, image_clahe)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:27:10.0095Z","iopub.execute_input":"2022-06-23T19:27:10.010464Z","iopub.status.idle":"2022-06-23T19:27:10.02333Z","shell.execute_reply.started":"2022-06-23T19:27:10.010426Z","shell.execute_reply":"2022-06-23T19:27:10.02261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_FOLDER = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\n# df_train = pd.read_csv(os.path.join(DATASET_FOLDER, \"train.csv\"))\n# display(df_train.head())\nTRAIN_DIR = \"../input/normalized-dataset/Final Normalized Data\"\nTRAIN_CSV = os.path.join(DATASET_FOLDER, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV)\n\ndf_pred = pd.read_csv(os.path.join(DATASET_FOLDER, \"sample_submission.csv\"))\nWITH_SUBMISSION = not df_pred.empty","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:27:10.024773Z","iopub.execute_input":"2022-06-23T19:27:10.025644Z","iopub.status.idle":"2022-06-23T19:27:10.543397Z","shell.execute_reply.started":"2022-06-23T19:27:10.025605Z","shell.execute_reply":"2022-06-23T19:27:10.542644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    \"\"\" TBD\n\n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n\n    Returns: \n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    # Split the string by space, then convert it into a integer array\n    s = np.array(mask_rle.split(), dtype=int)\n\n    # Every even value is the start, every odd value is the \"run\" length\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n\n    # The image is actually flattened since RLE is a 1D \"run\"\n    if len(shape) == 3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n\n    # The color here is actually just any integer you want!\n    for lo, hi in zip(starts, ends):\n        img[lo: hi] = color\n\n    # Don't forget to change the image back to the original shape\n    return img.reshape(shape)\n\n\n# https://www.kaggle.com/namgalielei/which-reshape-is-used-in-rle\ndef rle_decode_top_to_bot_first(mask_rle, shape):\n    \"\"\" TBD\n\n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n\n    Returns:\n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape((shape[1], shape[0]), order='F').T  # Reshape from top -> bottom first\n\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    \"\"\" TBD\n\n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n\n    Returns: \n        run length as string formated\n    \"\"\"\n\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef load_json_to_dict(json_path):\n    \"\"\" tbd \"\"\"\n    with open(json_path) as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef tf_load_png(img_path):\n    return tf.image.decode_png(tf.io.read_file(img_path), channels=3)\n\n\ndef open_gray16(_path, normalize=True, to_rgb=False):\n    \"\"\" Helper to open files \"\"\"\n    if normalize:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH) / 65535., axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH) / 65535.\n    else:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)\n\n\ndef load_img(path):\n\n    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n    img = np.tile(img[..., None], [1, 1, 3])  # gray to rgb\n    img = img.astype('float32')  # original is uint16\n    mx = np.max(img)\n    if mx:\n        img /= mx  # scale image to [0, 1]\n    return img\n\n\ndef load_msk(path):\n    msk = np.load(path)\n    msk = msk.astype('float32')\n    return msk","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:27:10.544868Z","iopub.execute_input":"2022-06-23T19:27:10.545255Z","iopub.status.idle":"2022-06-23T19:27:10.566544Z","shell.execute_reply.started":"2022-06-23T19:27:10.545217Z","shell.execute_reply":"2022-06-23T19:27:10.565525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class constants:\n    num_classes   = 3\n    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:27:10.570175Z","iopub.execute_input":"2022-06-23T19:27:10.570873Z","iopub.status.idle":"2022-06-23T19:27:10.638371Z","shell.execute_reply.started":"2022-06-23T19:27:10.570836Z","shell.execute_reply":"2022-06-23T19:27:10.637111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_metadata(row):\n    data = row['id'].split('_')\n    case = int(data[0].replace('case',''))\n    day = int(data[1].replace('day',''))\n    slice_ = int(data[-1])\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row\n\ndef path2info(row):\n    path = row['image_path']\n    data = path.split('/')\n    slice_ = int(data[-1].split('_')[1])\n    case = int(data[-3].split('_')[0].replace('case',''))\n    day = int(data[-3].split('_')[1].replace('day',''))\n    width = int(data[-1].split('_')[2])\n    height = int(data[-1].split('_')[3])\n    row['height'] = height\n    row['width'] = width\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n#     row['id'] = f'case{case}_day{day}_slice_{slice_}'\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:27:10.640117Z","iopub.execute_input":"2022-06-23T19:27:10.640556Z","iopub.status.idle":"2022-06-23T19:27:10.652101Z","shell.execute_reply.started":"2022-06-23T19:27:10.640516Z","shell.execute_reply":"2022-06-23T19:27:10.651147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\nif not len(sub_df):\n    debug = True\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n    sub_df = sub_df.drop(columns=['class','segmentation']).drop_duplicates()\nelse:\n    debug = False\n    sub_df = sub_df.drop(columns=['class','predicted']).drop_duplicates()\nsub_df = sub_df.progress_apply(get_metadata,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:27:10.653402Z","iopub.execute_input":"2022-06-23T19:27:10.653846Z","iopub.status.idle":"2022-06-23T19:27:13.149368Z","shell.execute_reply.started":"2022-06-23T19:27:10.653811Z","shell.execute_reply":"2022-06-23T19:27:13.148594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/train/**/*png',recursive=True)\n#     paths = sorted(paths)\nelse:\n    paths = glob(f'./test_updated/**/*png',recursive=True)\n#     paths = sorted(paths)\npath_df = pd.DataFrame(paths, columns=['image_path'])\npath_df = path_df.progress_apply(path2info, axis=1)\npath_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:27:13.15069Z","iopub.execute_input":"2022-06-23T19:27:13.151191Z","iopub.status.idle":"2022-06-23T19:28:52.129042Z","shell.execute_reply.started":"2022-06-23T19:27:13.151152Z","shell.execute_reply":"2022-06-23T19:28:52.12813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred = sub_df.merge(path_df, on=['case','day','slice'], how='left')\ndf_pred.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:28:52.130441Z","iopub.execute_input":"2022-06-23T19:28:52.130832Z","iopub.status.idle":"2022-06-23T19:28:52.162212Z","shell.execute_reply.started":"2022-06-23T19:28:52.130795Z","shell.execute_reply":"2022-06-23T19:28:52.161245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sfolder = \"test\" if WITH_SUBMISSION else \"train\"\n# ls_images = glob(os.path.join(DATASET_FOLDER, sfolder, \"**\", \"*.png\"), recursive=True)\n# ls_images = [p.replace(DATASET_FOLDER + os.path.sep, \"\") for p in ls_images]\n# case_day = [os.path.dirname(p).split(os.path.sep)[-2] for p in ls_images]\n# df_pred = pd.DataFrame({'Case_Day': case_day, 'image_path': ls_images})\n\n# if not WITH_SUBMISSION:\n#     df_pred = df_pred[df_pred[\"Case_Day\"].str.startswith(\"case123_day\")]\n# display(df_pred.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-20T09:57:50.920378Z","iopub.execute_input":"2022-06-20T09:57:50.920769Z","iopub.status.idle":"2022-06-20T09:58:00.780086Z","shell.execute_reply.started":"2022-06-20T09:57:50.920738Z","shell.execute_reply":"2022-06-20T09:58:00.779306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_pred['image_path']=DATASET_FOLDER+\"/\"+df_pred['image_path']\n# df_pred[\"slice_h\"] = df_pred[\"image_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[1]))\n# df_pred[\"slice_w\"] = df_pred[\"image_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[2]))\n# df_pred[\"slice_id\"] = df_pred[\"image_path\"].apply(lambda x: x.split(\"_\", 3)[2])\n# df_pred['id']=df_pred[\"Case_Day\"]+\"_slice_\"+df_pred[\"slice_id\"]\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T09:58:00.781754Z","iopub.execute_input":"2022-06-20T09:58:00.782128Z","iopub.status.idle":"2022-06-20T09:58:00.797081Z","shell.execute_reply.started":"2022-06-20T09:58:00.782094Z","shell.execute_reply":"2022-06-20T09:58:00.796135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_pred['case'] = df_pred['Case_Day'].apply(lambda x:x.split('_')[0])\n# df_pred['day'] = df_pred['Case_Day'].apply(lambda x:x.split('_')[1])\n# df_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-20T09:58:23.285385Z","iopub.execute_input":"2022-06-20T09:58:23.285761Z","iopub.status.idle":"2022-06-20T09:58:23.310877Z","shell.execute_reply.started":"2022-06-20T09:58:23.285732Z","shell.execute_reply":"2022-06-20T09:58:23.30987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BuildDataset(torch.utils.data.Dataset):\n    def __init__(self, df, label=False, transforms=None):\n        self.df         = df\n        self.label      = label\n        self.img_paths  = df['image_path'].tolist()\n        self.ids        = df['id'].tolist()\n        if 'msk_path' in df.columns:\n            self.msk_paths  = df['mask_path'].tolist()\n        else:\n            self.msk_paths = None\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path  = self.img_paths[index]\n        id_       = self.ids[index]\n        img = []\n        img = load_img(img_path)\n        h, w = img.shape[:2]\n        if self.label:\n            msk_path = self.msk_paths[index]\n            msk = load_msk(msk_path)\n            if self.transforms:\n                data = self.transforms(image=img, mask=msk)\n                img  = data['image']\n                msk  = data['mask']\n            img = np.transpose(img, (2, 0, 1))\n            msk = np.transpose(msk, (2, 0, 1))\n            return torch.tensor(img), torch.tensor(msk)\n        else:\n            if self.transforms:\n                data = self.transforms(image=img)\n                img  = data['image']\n            img = np.transpose(img, (2, 0, 1))\n            return torch.tensor(img), id_, h, w","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:28:52.163743Z","iopub.execute_input":"2022-06-23T19:28:52.164116Z","iopub.status.idle":"2022-06-23T19:28:52.177405Z","shell.execute_reply.started":"2022-06-23T19:28:52.164079Z","shell.execute_reply":"2022-06-23T19:28:52.176711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class BuildDataset(torch.utils.data.Dataset):\n#     def __init__(self, df, label=True, transforms=None,_style = 'multilabel'):\n#         self.df         = df\n#         self.label      = label\n#         self.transforms = transforms\n        \n#     def __len__(self):\n#         return len(self.df)\n    \n#     def __getitem__(self, index):\n#         img_path=self.df['image_path'].iloc[index]\n#         img = []\n#         img = load_img(img_path)\n#         data = self.transforms(image=img)\n#         img  = data['image']\n#         img = np.transpose(img, (2, 0, 1))\n#         return img_path,torch.tensor(img)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:28:52.180763Z","iopub.execute_input":"2022-06-23T19:28:52.181121Z","iopub.status.idle":"2022-06-23T19:28:52.189252Z","shell.execute_reply.started":"2022-06-23T19:28:52.181094Z","shell.execute_reply":"2022-06-23T19:28:52.188397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n\n    IMAGE_SHAPE = SEG_SHAPE = (256,256)\n    submission_transforms = {\n        \"test\": A.Compose([\n            A.Resize(*IMAGE_SHAPE, interpolation=cv2.INTER_NEAREST)\n            ], p=1.0)\n    }\n    \nelse:\n    \n    IMAGE_SHAPE = SEG_SHAPE = (256,256)\n    submission_transforms = {\n        \"test\": A.Compose([\n            A.Resize(*IMAGE_SHAPE, interpolation=cv2.INTER_NEAREST),\n            \n         ], p=1.0)\n    }","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:28:52.190566Z","iopub.execute_input":"2022-06-23T19:28:52.191131Z","iopub.status.idle":"2022-06-23T19:28:52.199018Z","shell.execute_reply.started":"2022-06-23T19:28:52.191092Z","shell.execute_reply":"2022-06-23T19:28:52.198024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = BuildDataset(df_pred, transforms=submission_transforms['test'])\ntest_loader  = DataLoader(test_dataset, batch_size=32,num_workers=2, shuffle=False, pin_memory=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:28:52.200872Z","iopub.execute_input":"2022-06-23T19:28:52.201379Z","iopub.status.idle":"2022-06-23T19:28:52.210716Z","shell.execute_reply.started":"2022-06-23T19:28:52.201339Z","shell.execute_reply":"2022-06-23T19:28:52.209898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load(\"../input/unet-plusplus-normmodel/unetPlusPlusNorm_v2\")","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:28:52.212497Z","iopub.execute_input":"2022-06-23T19:28:52.212783Z","iopub.status.idle":"2022-06-23T19:29:00.31436Z","shell.execute_reply.started":"2022-06-23T19:28:52.212748Z","shell.execute_reply":"2022-06-23T19:29:00.31339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def path_to_shape(path):\n    #return 300,300\n    return int(path[:-4].rsplit(\"_\", 4)[1]),int(path[:-4].rsplit(\"_\", 4)[2])","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:29:00.316332Z","iopub.execute_input":"2022-06-23T19:29:00.3168Z","iopub.status.idle":"2022-06-23T19:29:00.322456Z","shell.execute_reply.started":"2022-06-23T19:29:00.316753Z","shell.execute_reply":"2022-06-23T19:29:00.321512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reshape_to_original(paths,masks):\n    masks=masks.numpy()\n    df=pd.dataframe()\n    for i in range(0,masks.shape[0]):\n        mask=masks[i]\n        \n        for j in range(0,mask.shape[0]):\n            channel=mask[j]\n            re_size_mask=A.Resize(*path_to_shape(paths[i]), interpolation=cv2.INTER_NEAREST,always_apply=True)\n            channel=re_size_mask(image=channel)\n            channel=channel['image']\n            if(j==0):\n                resized_mask=channel\n            else:\n                resized_mask=cv2.merge((resized_mask, channel))\n        print(resized_mask.shape)\n        \n        out_df=image_to_submission(path[i],resized_mask)\n        df.append(out_df,inplace=True)\n        \n    return 0\n","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:29:00.324176Z","iopub.execute_input":"2022-06-23T19:29:00.324925Z","iopub.status.idle":"2022-06-23T19:29:00.333646Z","shell.execute_reply.started":"2022-06-23T19:29:00.324829Z","shell.execute_reply":"2022-06-23T19:29:00.332944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef infer(model_paths, _d_loader, num_log=1, thr=0.5):\n    msks = []; imgs = [];\n    pred_strings = []; pred_ids = []; pred_classes = [];\n    for idx, (img, ids, heights, widths) in enumerate(tqdm(test_loader, total=len(test_loader), desc='Infer ')):\n        img = img.to(constants.device, dtype=torch.float) # .squeeze(0)\n        size = img.size()\n        msk = []\n        msk = torch.zeros((size[0], 3, size[2], size[3]), device=constants.device, dtype=torch.float32)\n        for path in model_paths:\n            model = torch.load(path)\n            out   = model(img) # .squeeze(0) # removing batch axis\n            out   = nn.Sigmoid()(out) # removing channel axis\n            msk+=out/len(model_paths)\n        msk = (msk.permute((0,2,3,1))>thr).to(torch.uint8).cpu().detach().numpy() # shape: (n, h, w, c)\n        result = masks2rles(msk, ids, heights, widths)\n        pred_strings.extend(result[0])\n        pred_ids.extend(result[1])\n        pred_classes.extend(result[2])\n        if idx<num_log:\n            img = img.permute((0,2,3,1)).cpu().detach().numpy()\n            imgs.append(img[:10])\n            msks.append(msk[:10])\n        #del img, msk, out, model, result\n        gc.collect()\n        torch.cuda.empty_cache()\n    return pred_strings, pred_ids, pred_classes, imgs, msks","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:29:00.33637Z","iopub.execute_input":"2022-06-23T19:29:00.336725Z","iopub.status.idle":"2022-06-23T19:29:00.350914Z","shell.execute_reply.started":"2022-06-23T19:29:00.336672Z","shell.execute_reply":"2022-06-23T19:29:00.350119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @torch.no_grad()\n# def infer(df_pred,model_path=\"../input/effnet-v7/Effnet_b7v_07\", device=\"cuda\", thr=0.5):\n#     test_dataset = BuildDataset(df_pred, transforms=submission_transforms['test'])\n#     test_loader  = DataLoader(test_dataset, batch_size=32,num_workers=2, shuffle=False, pin_memory=False)\n    \n#     pred_strings = []\n#     pred_ids = []\n#     pred_classes = []\n\n#     for idx, (paths, imgs) in enumerate(tqdm(test_loader, total=len(test_loader), desc='Infer ')):\n#         size_3d = imgs.size()\n#         imgs = imgs.to(constants.device, dtype=torch.float)\n#         masks_3d = torch.zeros((size_3d[0],size_3d[1], size_3d[2], size_3d[3]), device=device, dtype=torch.float32)\n#         model = torch.load(model_path)\n#         out_3d = model(imgs)\n#         out_3d = torch.nn.Sigmoid()(out_3d)\n#         masks_3d += out_3d / 1\n\n#         # Remove batch dim\n#         masks_3d = torch.squeeze(masks_3d) \n        \n#         ######\n# #         1. Mask to original shape -> to result(mask RLE ) -> return DF same as submission\n# #     2. append DF to main df ( merge dfs of different batches into one)\n    \n        \n        \n        \n        \n#         #######\n#         masks = (masks_3d.permute((0, 2, 3, 1)) > thr).to(torch.uint8).cpu().detach().numpy()\n        \n#         # shape: (n, h, w, c)\n#         result = masks2rles(masks, paths, height=256, width=256)\n#         pred_strings.extend(result[0])\n#         pred_ids.extend(result[1])\n#         pred_classes.extend(result[2])\n        \n#     pred_df = pd.DataFrame({\"id\": pred_ids, \"class\": pred_classes, \"predicted\": pred_strings})\n\n#     return pred_df","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:16:41.062321Z","iopub.execute_input":"2022-06-21T09:16:41.06268Z","iopub.status.idle":"2022-06-21T09:16:41.06745Z","shell.execute_reply.started":"2022-06-21T09:16:41.062649Z","shell.execute_reply":"2022-06-21T09:16:41.066694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def masks2rles(msks, ids, heights, widths):\n    pred_strings = []; pred_ids = []; pred_classes = [];\n    for idx in range(msks.shape[0]):\n        height = heights[idx].item()\n        width = widths[idx].item()\n        left = (width - msks[idx].shape[0])//2\n        right = left\n        top = (height - msks[idx].shape[1])//2\n        bottom = top\n        msk = cv2.copyMakeBorder(msks[idx], top, bottom, left, right, cv2.BORDER_CONSTANT, 0)\n        rle = [None]*3\n        for midx in [0, 1, 2]:\n            rle[midx] = mask2rle(msk[...,midx])\n        pred_strings.extend(rle)\n        pred_ids.extend([ids[idx]]*len(rle))\n        pred_classes.extend(['large_bowel', 'small_bowel', 'stomach'])\n    return pred_strings, pred_ids, pred_classes","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:29:00.352696Z","iopub.execute_input":"2022-06-23T19:29:00.353413Z","iopub.status.idle":"2022-06-23T19:29:00.363521Z","shell.execute_reply.started":"2022-06-23T19:29:00.353376Z","shell.execute_reply":"2022-06-23T19:29:00.362735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mask2rle(msk, thr=0.5):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    msk    = cp.array(msk)\n    pixels = msk.flatten()\n    pad    = cp.array([0])\n    pixels = cp.concatenate([pad, pixels, pad])\n    runs   = cp.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:29:00.365178Z","iopub.execute_input":"2022-06-23T19:29:00.365642Z","iopub.status.idle":"2022-06-23T19:29:00.375738Z","shell.execute_reply.started":"2022-06-23T19:29:00.365576Z","shell.execute_reply":"2022-06-23T19:29:00.37484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_strings, pred_ids, pred_classes, imgs, msks =infer(['../input/unet-plusplus-normmodel/unetPlusPlusNorm_v2'], test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:29:00.377401Z","iopub.execute_input":"2022-06-23T19:29:00.377947Z","iopub.status.idle":"2022-06-23T19:29:40.900775Z","shell.execute_reply.started":"2022-06-23T19:29:00.377911Z","shell.execute_reply":"2022-06-23T19:29:40.899757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = pd.DataFrame({\n    \"id\":pred_ids,\n    \"class\":pred_classes,\n    \"predicted\":pred_strings\n})","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:29:40.902784Z","iopub.execute_input":"2022-06-23T19:29:40.903387Z","iopub.status.idle":"2022-06-23T19:29:40.910727Z","shell.execute_reply.started":"2022-06-23T19:29:40.903347Z","shell.execute_reply":"2022-06-23T19:29:40.909907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not debug:\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n    del sub_df['predicted']\nelse:\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n    del sub_df['segmentation']\n    \nsub_df = sub_df.merge(pred_df, on=['id','class'])\nsub_df.to_csv('submission.csv',index=False)\ndisplay(sub_df.head(5))","metadata":{"execution":{"iopub.status.busy":"2022-06-23T19:29:40.912362Z","iopub.execute_input":"2022-06-23T19:29:40.912828Z","iopub.status.idle":"2022-06-23T19:29:41.223258Z","shell.execute_reply.started":"2022-06-23T19:29:40.912789Z","shell.execute_reply":"2022-06-23T19:29:41.222507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_idsList = []\n# for i in range(len(pred_df)):\n#     sub_ids = (\"_\").join(pred_df['id'][i].split(os.sep)[6:7] + pred_df['id'][i].split(os.sep)[6:10][-1].split(\"_\")[:2])\n#     sub_idsList.append(sub_ids)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:17:32.593194Z","iopub.execute_input":"2022-06-21T09:17:32.593452Z","iopub.status.idle":"2022-06-21T09:17:32.599328Z","shell.execute_reply.started":"2022-06-21T09:17:32.593428Z","shell.execute_reply":"2022-06-21T09:17:32.59853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_df[\"Testid\"] = sub_idsList\n# first_column = pred_df.pop('Testid')\n# pred_df.insert(0, 'Testid', first_column)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:17:32.600661Z","iopub.execute_input":"2022-06-21T09:17:32.601469Z","iopub.status.idle":"2022-06-21T09:17:32.605218Z","shell.execute_reply.started":"2022-06-21T09:17:32.601428Z","shell.execute_reply":"2022-06-21T09:17:32.604502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_df.drop('id', axis=1, inplace=True)\n# pred_df.rename(columns = {'Testid':'id'}, inplace = True)\n# pred_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:17:32.606427Z","iopub.execute_input":"2022-06-21T09:17:32.607235Z","iopub.status.idle":"2022-06-21T09:17:32.615114Z","shell.execute_reply.started":"2022-06-21T09:17:32.607197Z","shell.execute_reply":"2022-06-21T09:17:32.6143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T06:38:43.331069Z","iopub.execute_input":"2022-06-20T06:38:43.331914Z","iopub.status.idle":"2022-06-20T06:38:43.340966Z","shell.execute_reply.started":"2022-06-20T06:38:43.33186Z","shell.execute_reply":"2022-06-20T06:38:43.340064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n# del sub_df['predicted']\n\n# sub_df = sub_df.merge(pred_df, on=['id', 'class'])\n# sub_df = sub_df.fillna('')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T06:38:43.342216Z","iopub.execute_input":"2022-06-20T06:38:43.343125Z","iopub.status.idle":"2022-06-20T06:38:43.361081Z","shell.execute_reply.started":"2022-06-20T06:38:43.343074Z","shell.execute_reply":"2022-06-20T06:38:43.360286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T06:38:43.362305Z","iopub.execute_input":"2022-06-20T06:38:43.363052Z","iopub.status.idle":"2022-06-20T06:38:43.369937Z","shell.execute_reply.started":"2022-06-20T06:38:43.363014Z","shell.execute_reply":"2022-06-20T06:38:43.369087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n\n# empty_df = pd.DataFrame(columns=['id','class','predicted'])\n# empty_df.to_csv('submission.csv',index=False)\n\n# if len(pred_df) != len(sub_df):\n#     print(wrong)\n\n# sample_sub_length = len(sub_df)\n# actual_length = len(pred_df)\n\n# del sub_df['predicted']\n# sub_df = sub_df.merge(pred_df, on=['id','class'],how='left')\n# sub_df = sub_df.fillna('')\n# sub_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T06:38:43.371298Z","iopub.execute_input":"2022-06-20T06:38:43.372106Z","iopub.status.idle":"2022-06-20T06:38:43.37652Z","shell.execute_reply.started":"2022-06-20T06:38:43.372067Z","shell.execute_reply":"2022-06-20T06:38:43.375719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}