{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pycocotools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T17:48:20.440123Z","iopub.execute_input":"2022-04-21T17:48:20.440576Z","iopub.status.idle":"2022-04-21T17:48:30.671014Z","shell.execute_reply.started":"2022-04-21T17:48:20.440528Z","shell.execute_reply":"2022-04-21T17:48:30.669842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction\n\nIn this visualization, we use pycocotools to decode the RLEs. To do so, we first convert the segmentation to COCO compatible RLE, then we use maskUtils in pycocotools to encode-decode RLEs to masks. This can be useful if you are converting data to COCO format. \nIn addition, we also visualize all annotated classes overlayed on the single slice for better understanding of the dataset.\n\nReferences:\n\n1. https://www.kaggle.com/code/fabiendaniel/image-with-masks-quick-overview\n2. https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/mask.py","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom glob import glob\nimport pycocotools.mask as maskUtils","metadata":{"execution":{"iopub.status.busy":"2022-04-21T17:48:30.673349Z","iopub.execute_input":"2022-04-21T17:48:30.673734Z","iopub.status.idle":"2022-04-21T17:48:30.68056Z","shell.execute_reply.started":"2022-04-21T17:48:30.673683Z","shell.execute_reply":"2022-04-21T17:48:30.679487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some Basic Statistics of Dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\nprint('=> Shape of the train dataframe {}'.format(train_df.shape))\nprint('=> Number of unique classes = {}'.format(train_df['class'].nunique()))\nprint('=> Unique classes = {}'.format(train_df['class'].unique()))\nprint('=> Unique ids = {}'.format(train_df.id.nunique()))\nfor cat in train_df['class'].unique():\n    print('=> Number of {} in train = {}'.format(cat,sum(train_df['class'] == cat)))\nlist_images = glob('../input/uw-madison-gi-tract-image-segmentation/train/*/*/scans/*.png')    \nprint('=> Number of images in train set = {}'.format(len(list_images)))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T17:48:30.682471Z","iopub.execute_input":"2022-04-21T17:48:30.682844Z","iopub.status.idle":"2022-04-21T17:48:31.736162Z","shell.execute_reply.started":"2022-04-21T17:48:30.682799Z","shell.execute_reply":"2022-04-21T17:48:31.735361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_properties = pd.DataFrame([(c, c.split('/')[-3], c.split('/')[-1]) for c in list_images], columns = ['file_path', 'case_day', 'file'])\nimage_properties['slice'] = image_properties['file'].apply(lambda x: f\"slice_{x.split('_')[1]}\")\nimage_properties['height'] = image_properties['file'].apply(lambda x: int(x.split('_')[2]))\nimage_properties['width']  = image_properties['file'].apply(lambda x: int(x.split('_')[3]))\nimage_properties['id']= image_properties['case_day'] + '_' + image_properties['slice']\ntrain_df_merged = pd.merge(train_df, image_properties, on='id', how='left')\nX = train_df_merged[train_df_merged['segmentation'].notnull()]\nprint('=> Images with Annotations : {}'.format(X.shape))\nX.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T17:48:31.737679Z","iopub.execute_input":"2022-04-21T17:48:31.737899Z","iopub.status.idle":"2022-04-21T17:48:32.093419Z","shell.execute_reply.started":"2022-04-21T17:48:31.737873Z","shell.execute_reply":"2022-04-21T17:48:32.092462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# COCO Compatiable RLE and Mask Generation\n\nRLE is a simple yet efficient format for storing binary masks. RLEfirst divides a vector (or vectorized image) into a series of piecewise constant regions and then for each piece simply stores the length of that piece. For example, given M=[0 0 1 1 1 0 1] the RLE counts would be [2 3 1 1], or for M=[1 1 1 1 1 1 0] the counts would be [0 6 1] (note that the odd counts are always the numbers of zeros). Instead of storing the counts directly, additional compression is achieved with a variable bitrate representation based on a common scheme called LEB128.","metadata":{}},{"cell_type":"code","source":"def get_mask(segmentation,height,width):\n    counts =list(map(int, segmentation.split()))\n    counts_01 = [counts[0]-1,counts[1]]\n    for i in range(2,len(counts)-1,2):\n        counts_01.append(counts[i] - (counts[i-1]+counts[i-2]))\n        counts_01.append(counts[i+1])\n    counts_01.append((height*width)- (counts[len(counts)-1]+counts[len(counts)-2]))\n    rle = maskUtils.frPyObjects([{'counts':counts_01,'size':[height,width]}], height,width)\n    m = maskUtils.decode(rle)\n    m = np.squeeze(m)\n    m = m.T \n    return m","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef plot_(image,masks,cols,cats):\n    fig, ax = plt.subplots(1,3, figsize=(12,16))\n    \n    ax[0].set_title('Image')\n    ax[0].imshow(image)\n\n    ax[1].set_title('Mask')\n    img = np.zeros( (masks[0].shape[0], masks[0].shape[1], 3) )\n    for mask in masks:\n          img[mask == 1] = 1\n    ax[1].imshow(img)\n\n    ax[2].set_title('overlays {}'.format(cats))\n    ax[2].imshow(image)\n    \n    for mask,col in zip(masks,cols):\n        img = np.ones( (mask.shape[0], mask.shape[1], 3) )\n        for i in range(3):\n            img[:,:,i] = col[i]\n        ax[2].imshow(np.dstack( (img, mask*0.5) ))\n        \n    plt.show()\n    \n\n\n\ncolor_dict = {\n    'large_bowel':[255,255,0], #yellow\n    'small_bowel':[255, 0, 0], #red\n    'stomach':[  0, 0, 255 ] #blue\n}\n\nfor i in range(0,10):\n#     image = np.array(Image.open(sample['whole_path']))\n    idx = np.random.randint(0,X.shape[0] - 1)\n    sample = X.iloc[idx]\n    slice_ids = X.index[X['id'] == sample['id']].tolist()\n    \n    masks = []\n    cols = []\n    cats = []\n    for id_ in slice_ids:\n        slice_ = train_df_merged.iloc[id_]\n        mask = get_mask(slice_['segmentation'],int(slice_['height']),int(slice_['width']))\n        masks.append(mask)\n        cols.append(color_dict[slice_['class']])\n        cats.append(slice_['class'])\n    image = np.array(Image.open(slice_['file_path']))\n    plot_(image,masks,cols,cats)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T17:51:53.371916Z","iopub.execute_input":"2022-04-21T17:51:53.372296Z","iopub.status.idle":"2022-04-21T17:51:58.643106Z","shell.execute_reply.started":"2022-04-21T17:51:53.372264Z","shell.execute_reply":"2022-04-21T17:51:58.642217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}