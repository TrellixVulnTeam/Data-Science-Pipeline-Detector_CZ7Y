{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [UW-Madison GI Tract Image Segmentation](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/)\n> Track healthy organs in medical scans to improve cancer treatment\n\n<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/27923/logos/header.png?t=2021-06-02-20-30-25\">","metadata":{}},{"cell_type":"code","source":"!pip install -q scikit-learn==1.0.0","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:25:46.358678Z","iopub.execute_input":"2022-05-06T09:25:46.35922Z","iopub.status.idle":"2022-05-06T09:25:59.383982Z","shell.execute_reply.started":"2022-05-06T09:25:46.359098Z","shell.execute_reply":"2022-05-06T09:25:59.382633Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference\nCheck this amazing notebook, [How To Create TFRecords](https://www.kaggle.com/cdeotte/how-to-create-tfrecords) by [Chris Deotte](https://www.kaggle.com/cdeotte)","metadata":{}},{"cell_type":"markdown","source":"# How to Create TFRecord","metadata":{}},{"cell_type":"code","source":"SEED  = 101\nFOLDS = 40\nIMAGE_SIZE = None\nCHANNELS = 3\nSTRIDE = 2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T09:25:59.38601Z","iopub.execute_input":"2022-05-06T09:25:59.386409Z","iopub.status.idle":"2022-05-06T09:25:59.391095Z","shell.execute_reply.started":"2022-05-06T09:25:59.386371Z","shell.execute_reply":"2022-05-06T09:25:59.3899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os, shutil\nfrom glob import glob\nfrom sklearn.cluster import KMeans\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\n# visualization\nimport cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:25:59.393502Z","iopub.execute_input":"2022-05-06T09:25:59.393955Z","iopub.status.idle":"2022-05-06T09:26:00.564516Z","shell.execute_reply.started":"2022-05-06T09:25:59.393891Z","shell.execute_reply":"2022-05-06T09:26:00.563544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility","metadata":{}},{"cell_type":"markdown","source":"## Mask","metadata":{}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = np.asarray(mask_rle.split(), dtype=int)\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:00.566021Z","iopub.execute_input":"2022-05-06T09:26:00.566305Z","iopub.status.idle":"2022-05-06T09:26:00.577841Z","shell.execute_reply.started":"2022-05-06T09:26:00.566276Z","shell.execute_reply":"2022-05-06T09:26:00.575368Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metadata","metadata":{}},{"cell_type":"code","source":"def get_metadata(row):\n    data = row['id'].split('_')\n    case = int(data[0].replace('case',''))\n    day = int(data[1].replace('day',''))\n    slice_ = int(data[-1])\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row\n\ndef path2info(row):\n    path = row['image_path']\n    data = path.split('/')\n    slice_ = int(data[-1].split('_')[1])\n    case = int(data[-3].split('_')[0].replace('case',''))\n    day = int(data[-3].split('_')[1].replace('day',''))\n    width = int(data[-1].split('_')[2])\n    height = int(data[-1].split('_')[3])\n    row['height'] = height\n    row['width'] = width\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:00.579531Z","iopub.execute_input":"2022-05-06T09:26:00.580347Z","iopub.status.idle":"2022-05-06T09:26:00.595693Z","shell.execute_reply.started":"2022-05-06T09:26:00.580264Z","shell.execute_reply":"2022-05-06T09:26:00.594602Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualization","metadata":{}},{"cell_type":"code","source":"def id2mask(id_):\n    idf = df[df['id']==id_]\n    shape = (idf.height.item(), idf.width.item(), 3)\n    mask = np.zeros(shape, dtype=np.uint8)\n    rles = idf.segmentation.squeeze()\n    for i, rle in enumerate(rles):\n        if not pd.isna(rle):\n            mask[..., i] = rle_decode(rle, shape[:2])\n    return mask\n\ndef rgb2gray(mask):\n    pad_mask = np.pad(mask, pad_width=[(0,0),(0,0),(1,0)])\n    gray_mask = pad_mask.argmax(-1)\n    return gray_mask\n\ndef gray2rgb(mask):\n    rgb_mask = tf.keras.utils.to_categorical(mask, num_classes=4)\n    return rgb_mask[..., 1:].astype(mask.dtype)\n\ndef load_img(path, size=IMAGE_SIZE):\n    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n    if size is not None:\n        img = cv2.resize(img, dsize=IMAGE_SIZE, interpolation=cv2.INTER_NEAREST)\n#     img = img.astype('float32') # original is uint16\n#     img = (img - img.min())/(img.max() - img.min())*255.0 # scale image to [0, 255]\n#     img = img.astype('uint8')\n    return img\n\ndef load_imgs(img_paths):\n    imgs = [None]*3\n    for i, img_path in enumerate(img_paths):\n        img = load_img(img_path)\n        imgs[i] = img\n    return np.stack(imgs,axis=-1)\n\ndef show_img(img, mask=None):\n#     plt.figure(figsize=(10,10))\n    plt.imshow(img, cmap='bone')\n    \n    if mask is not None:\n        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n        plt.imshow(mask, alpha=0.5)\n        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n        labels = [ \"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n        plt.legend(handles,labels)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:00.59712Z","iopub.execute_input":"2022-05-06T09:26:00.597431Z","iopub.status.idle":"2022-05-06T09:26:00.616795Z","shell.execute_reply.started":"2022-05-06T09:26:00.597397Z","shell.execute_reply":"2022-05-06T09:26:00.615476Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Meta Data","metadata":{}},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/uwmgi-mask-dataset/train.csv')\ndf['segmentation'] = df.segmentation.fillna('')\ndf['rle_len'] = df.segmentation.map(len) # length of each rle mask\n\ndf2 = df.groupby(['id'])['segmentation'].agg(list).to_frame().reset_index() # rle list of each id\ndf2 = df2.merge(df.groupby(['id'])['rle_len'].agg(sum).to_frame().reset_index()) # total length of all rles of each id\n\ndf = df.drop(columns=['segmentation', 'class', 'rle_len'])\ndf = df.groupby(['id']).head(1).reset_index(drop=True)\ndf = df.merge(df2, on=['id'])\ndf['empty'] = (df.rle_len==0) # empty masks","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:00.618731Z","iopub.execute_input":"2022-05-06T09:26:00.619109Z","iopub.status.idle":"2022-05-06T09:26:03.392471Z","shell.execute_reply.started":"2022-05-06T09:26:00.619074Z","shell.execute_reply":"2022-05-06T09:26:03.391603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove Faulty Cases","metadata":{}},{"cell_type":"code","source":"fault1 = 'case7_day0'\nfault2 = 'case81_day30'\ndf = df[~df['id'].str.contains(fault1) & ~df['id'].str.contains(fault2)].reset_index(drop=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:03.395552Z","iopub.execute_input":"2022-05-06T09:26:03.396276Z","iopub.status.idle":"2022-05-06T09:26:03.474971Z","shell.execute_reply.started":"2022-05-06T09:26:03.396225Z","shell.execute_reply":"2022-05-06T09:26:03.473743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.5D","metadata":{}},{"cell_type":"code","source":"for i in range(CHANNELS):\n    df[f'image_path_{i:02}'] = df.groupby(['case','day'])['image_path'].shift(-i*STRIDE).fillna(method=\"ffill\")\ndf['image_paths'] = df[[f'image_path_{i:02d}' for i in range(CHANNELS)]].values.tolist()\ndf.image_paths[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:03.476503Z","iopub.execute_input":"2022-05-06T09:26:03.477311Z","iopub.status.idle":"2022-05-06T09:26:03.563675Z","shell.execute_reply.started":"2022-05-06T09:26:03.477254Z","shell.execute_reply":"2022-05-06T09:26:03.562432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Data","metadata":{}},{"cell_type":"code","source":"row=1; col=4\nplt.figure(figsize=(5*col,5*row))\nfor i, id_ in enumerate(df[df['empty']==0].sample(frac=1.0)['id'].unique()[:row*col]):\n    img = load_imgs(df[df['id']==id_].squeeze().image_paths).astype('float32')\n    img/=img.max(axis=(0,1))\n    mask = id2mask(id_)*255\n    plt.subplot(row, col, i+1)\n    i+=1\n    show_img(img, mask=mask)\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:03.565231Z","iopub.execute_input":"2022-05-06T09:26:03.565633Z","iopub.status.idle":"2022-05-06T09:26:04.696693Z","shell.execute_reply.started":"2022-05-06T09:26:03.565596Z","shell.execute_reply":"2022-05-06T09:26:04.69565Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedGroupKFold\nskf = StratifiedGroupKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df, df['empty'], groups = df[\"case\"])):\n    df.loc[val_idx, 'fold'] = fold\ndisplay(df.groupby(['fold','empty'])['id'].count())","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:04.698312Z","iopub.execute_input":"2022-05-06T09:26:04.698692Z","iopub.status.idle":"2022-05-06T09:26:05.389949Z","shell.execute_reply.started":"2022-05-06T09:26:04.698655Z","shell.execute_reply":"2022-05-06T09:26:05.388322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TFRecord Data","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:05.391991Z","iopub.execute_input":"2022-05-06T09:26:05.392442Z","iopub.status.idle":"2022-05-06T09:26:11.695702Z","shell.execute_reply.started":"2022-05-06T09:26:05.392394Z","shell.execute_reply":"2022-05-06T09:26:11.694394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Writng TFRecord (Train)","metadata":{}},{"cell_type":"code","source":"def train_serialize_example(feature0, feature1, feature2, feature3, feature4,\n                           feature5, feature6, feature7, feature8):\n    feature = {\n      'image':_bytes_feature(feature0),\n      'id':_bytes_feature(feature1),\n      'case':_int64_feature(feature2),\n      'day':_int64_feature(feature3), \n      'slice':_int64_feature(feature4),\n      'height':_int64_feature(feature5),\n      'width':_int64_feature(feature6),\n      'empty':_int64_feature(feature7),\n      'mask':_bytes_feature(feature8),\n  }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:26:11.697267Z","iopub.execute_input":"2022-05-06T09:26:11.697607Z","iopub.status.idle":"2022-05-06T09:26:11.70523Z","shell.execute_reply.started":"2022-05-06T09:26:11.697568Z","shell.execute_reply":"2022-05-06T09:26:11.703943Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show=True\nos.makedirs('/tmp/uwmgi', exist_ok=True)\nfolds = df.fold.unique().tolist()\nfor fold in tqdm(folds): # create tfrecord for each fold\n    fold_df = df.query(\"fold==@fold\")\n    if show:\n        print(); print('Writing TFRecord of fold %i :'%(fold))  \n    with tf.io.TFRecordWriter('/tmp/uwmgi/train%.2i-%i.tfrec'%(fold,fold_df.shape[0])) as writer:\n        samples = fold_df.shape[0] # samples = 200\n        it = tqdm(range(samples)) if show else range(samples)\n        for k in it: # images in fold\n            row = fold_df.iloc[k,:]\n            image = load_imgs(row['image_paths'])\n            image_id = row['id']\n            case = row['case']\n            day = row['day']\n            slice_ = row['slice']\n            height = row['height']\n            width = row['width']\n            empty = row['empty']\n            mask = id2mask(image_id)*255 # [0, 1] => [0, 255]\n            example  = train_serialize_example(\n                image.tobytes(),\n                str.encode(image_id),\n                case,\n                day,\n                slice_,\n                height,\n                width,\n                empty,\n                mask.tobytes(),\n                )\n            writer.write(example)\n        if show:\n            filepath = '/tmp/uwmgi/train%.2i-%i.tfrec'%(fold,fold_df.shape[0])\n            filename = filepath.split('/')[-1]\n            filesize = os.path.getsize(filepath)/10**6\n            print(filename,':',np.around(filesize, 2),'MB')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-06T09:27:09.356752Z","iopub.execute_input":"2022-05-06T09:27:09.357213Z","iopub.status.idle":"2022-05-06T09:29:18.221898Z","shell.execute_reply.started":"2022-05-06T09:27:09.357171Z","shell.execute_reply":"2022-05-06T09:29:18.219669Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading TFRecord","metadata":{}},{"cell_type":"code","source":"import re, math\ndef decode_image(data, height, width, target_size=(224, 224)):\n    image = tf.io.decode_raw(data, out_type=tf.uint16)\n    image = tf.reshape(image, [height, width, 3]) # explicit size needed for TPU\n    image = tf.image.resize(image, target_size, method='nearest')\n    image = tf.cast(image,tf.float32) \n    image = image / tf.reduce_max(image)\n    return image\ndef decode_mask(data, height, width, target_size=(224, 224)):    \n    mask = tf.io.decode_raw(data, out_type=tf.uint8)\n    mask = tf.reshape(mask, [height, width, 3]) # explicit size needed for TPU  \n    mask = tf.image.resize(mask, target_size, method='nearest')\n    return mask\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"height\" : tf.io.FixedLenFeature([], tf.int64),\n        \"width\" : tf.io.FixedLenFeature([], tf.int64),\n        \"mask\" : tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    height = example['height']\n    width = example['width']\n    image = decode_image(example['image'], height, width)\n    mask = decode_mask(example['mask'], height, width)\n    return image, mask # returns a dataset of (image, label) pairs\n\ndef load_dataset(fileids, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(fileids, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(20, seed=SEED)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef count_data_items(fileids):\n    # the number of data items is written in the id of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(fileid).group(1)) for fileid in fileids]\n    return np.sum(n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-06T09:30:24.996666Z","iopub.execute_input":"2022-05-06T09:30:24.997162Z","iopub.status.idle":"2022-05-06T09:30:25.012264Z","shell.execute_reply.started":"2022-05-06T09:30:24.997122Z","shell.execute_reply":"2022-05-06T09:30:25.011193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper","metadata":{}},{"cell_type":"code","source":"def display_batch(batch, size=5):\n    imgs, tars = batch\n    plt.figure(figsize=(size*5, 5))\n    for img_idx in range(size):\n        plt.subplot(1, size, img_idx+1)\n        plt.imshow(imgs[img_idx,], cmap='bone')\n        plt.imshow(tars[img_idx,], alpha=0.5)\n        plt.xticks([])\n        plt.yticks([])\n    plt.tight_layout()\n    plt.show() ","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:30:27.000804Z","iopub.execute_input":"2022-05-06T09:30:27.001485Z","iopub.status.idle":"2022-05-06T09:30:27.006994Z","shell.execute_reply.started":"2022-05-06T09:30:27.001425Z","shell.execute_reply":"2022-05-06T09:30:27.006262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Total Images","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nAUTO = tf.data.experimental.AUTOTUNE\nTRAINING_FILENAMES = tf.io.gfile.glob('/tmp/uwmgi/train*.tfrec')\nTEST_FILENAMES     = tf.io.gfile.glob('/tmp/uwmgi/test*.tfrec')\nprint('There are %i train & %i test images'%(count_data_items(TRAINING_FILENAMES), count_data_items(TEST_FILENAMES)))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:30:29.546895Z","iopub.execute_input":"2022-05-06T09:30:29.547578Z","iopub.status.idle":"2022-05-06T09:30:29.559218Z","shell.execute_reply.started":"2022-05-06T09:30:29.547521Z","shell.execute_reply":"2022-05-06T09:30:29.558198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display Image from TFRecord","metadata":{}},{"cell_type":"code","source":"# DISPLAY TRAIN IMAGES\ntraining_dataset = get_training_dataset()\ntraining_dataset = training_dataset.unbatch().batch(20)\ntrain_batch = next(iter(training_dataset))\ndisplay_batch(train_batch, 5);","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:30:32.493042Z","iopub.execute_input":"2022-05-06T09:30:32.493431Z","iopub.status.idle":"2022-05-06T09:30:34.271047Z","shell.execute_reply.started":"2022-05-06T09:30:32.493398Z","shell.execute_reply":"2022-05-06T09:30:34.269976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = train_batch\nnp.unique(label.numpy(), return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:30:56.761856Z","iopub.execute_input":"2022-05-06T09:30:56.762328Z","iopub.status.idle":"2022-05-06T09:30:56.828196Z","shell.execute_reply.started":"2022-05-06T09:30:56.762289Z","shell.execute_reply":"2022-05-06T09:30:56.827208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compress Files","metadata":{}},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/tfrecord',\n                    'zip',\n                    '/tmp',\n                    'uwmgi')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T09:33:42.974797Z","iopub.execute_input":"2022-05-06T09:33:42.97538Z","iopub.status.idle":"2022-05-06T09:37:31.444671Z","shell.execute_reply.started":"2022-05-06T09:33:42.975336Z","shell.execute_reply":"2022-05-06T09:37:31.443126Z"},"trusted":true},"execution_count":null,"outputs":[]}]}