{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Configuration","metadata":{"tags":[]}},{"cell_type":"code","source":"import os\nfrom itertools import chain\n\nGRADIENT = os.path.exists('train')\nKAGGLE = os.path.exists('../input')\nmodel_name = 'resnet34-v1-20-epoch.pkl'\nSEED = 42\nVAL_PCT = 0.2\nINFER = True","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:33:33.039433Z","iopub.execute_input":"2022-05-16T07:33:33.040028Z","iopub.status.idle":"2022-05-16T07:33:33.044981Z","shell.execute_reply.started":"2022-05-16T07:33:33.039989Z","shell.execute_reply":"2022-05-16T07:33:33.044042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Libraries and Data","metadata":{"tags":[]}},{"cell_type":"code","source":"if KAGGLE:\n    !cp -r ../input/pytorch-segmentation-models-lib/ ./\n    !pip install -q ./pytorch-segmentation-models-lib/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4\n    !pip install -q ./pytorch-segmentation-models-lib/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3\n    !pip install -q ./pytorch-segmentation-models-lib/timm-0.4.12-py3-none-any.whl\n    !pip install -q ./pytorch-segmentation-models-lib/segmentation_models_pytorch-0.2.0-py3-none-any.whl","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-16T07:33:33.807997Z","iopub.execute_input":"2022-05-16T07:33:33.808845Z","iopub.status.idle":"2022-05-16T07:35:33.934171Z","shell.execute_reply.started":"2022-05-16T07:33:33.808789Z","shell.execute_reply":"2022-05-16T07:35:33.933288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\n\nimport gc","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-16T07:35:33.936834Z","iopub.execute_input":"2022-05-16T07:35:33.937143Z","iopub.status.idle":"2022-05-16T07:35:33.943784Z","shell.execute_reply.started":"2022-05-16T07:35:33.937101Z","shell.execute_reply":"2022-05-16T07:35:33.943072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if KAGGLE:\n    data_path = '../input/uw-madison-gi-tract-image-segmentation/'\n    model_name = '../input/uw-madison-models/' + model_name\nelif GRADIENT:\n    data_path = ''\n    model_name = 'models/' + model_name ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:33.945023Z","iopub.execute_input":"2022-05-16T07:35:33.945581Z","iopub.status.idle":"2022-05-16T07:35:33.955873Z","shell.execute_reply.started":"2022-05-16T07:35:33.945529Z","shell.execute_reply":"2022-05-16T07:35:33.95501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path(data_path+'train')\ntest_path = Path(data_path+'test')\ntrain = pd.read_csv(data_path+'train.csv', low_memory=False)\nsample_submission = pd.read_csv(data_path+'sample_submission.csv', low_memory=False)\nfnames = get_image_files(path)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-16T07:35:33.958266Z","iopub.execute_input":"2022-05-16T07:35:33.958612Z","iopub.status.idle":"2022-05-16T07:35:38.011467Z","shell.execute_reply.started":"2022-05-16T07:35:33.958577Z","shell.execute_reply":"2022-05-16T07:35:38.010738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{"tags":[]}},{"cell_type":"code","source":"# Extract case id from fname\ndef get_case_id(fname):\n    if KAGGLE: i = 5\n    elif GRADIENT: i = 2\n    return fname.parts[i] + '_' + fname.parts[i+2][:10]\n\ndef check_file(file_id, fname):\n    case_id, day, _, slice_no = file_id.split('_')\n    if case_id == fname.parts[1] and day == fname.parts[2].split('_')[1] and slice_no in fname.parts[-1]:\n        return True\n    return False\n\ndef get_file(file_id):\n    return fnames.filter(lambda f: check_file(not_null_train.id[0], f))[0]\n\n# https://www.kaggle.com/code/dschettler8845/uwm-gi-tract-image-segmentation-eda\ndef get_custom_df(df, fnames, root):\n    \n    df = df.copy()\n    \n    # 1. Get Case-ID as a column (str and int)\n    df[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\n    df[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n    # 2. Get Day as a column\n    df[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\n    df[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n    # 3. Get Slice Identifier as a column\n    df[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\n    # 4. Get full file paths for the representative scans\n    df[\"_partial_fname\"] = (root+'/'+ # /kaggle/input/uw-madison-gi-tract-image-segmentation/train/\n                          df[\"case_id_str\"]+\"/\"+ # .../case###/\n                          df[\"case_id_str\"]+\"_\"+df[\"day_num_str\"]+ # .../case###_day##/\n                          \"/scans/\"+df[\"slice_id\"]) # .../slice_####\n    \n    _tmp_merge_df = pd.DataFrame({\"_partial_fname\":[str(x).rsplit(\"_\",4)[0] for x in fnames], \"fname\": fnames})\n    df = df.merge(_tmp_merge_df, on=\"_partial_fname\").drop(columns=[\"_partial_fname\"])\n    \n    # Minor cleanup of our temporary workaround\n    del _tmp_merge_df; gc.collect(); gc.collect()\n    \n    # 5. Get slice dimensions from filepath (int in pixels)\n    df[\"slice_h\"] = df[\"fname\"].apply(lambda x: int(str(x)[:-4].rsplit(\"_\",4)[1]))\n    df[\"slice_w\"] = df[\"fname\"].apply(lambda x: int(str(x)[:-4].rsplit(\"_\",4)[2]))\n\n    # 6. Pixel spacing from filepath (float in mm)\n    df[\"px_spacing_h\"] = df[\"fname\"].apply(lambda x: float(str(x)[:-4].rsplit(\"_\",4)[3]))\n    df[\"px_spacing_w\"] = df[\"fname\"].apply(lambda x: float(str(x)[:-4].rsplit(\"_\",4)[4]))\n\n    # 7. Merge 3 Rows Into A Single Row (As This/Segmentation-RLE Is The Only Unique Information Across Those Rows)\n    l_bowel_train_df = df[df[\"class\"]==\"large_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"lb_seg_rle\"})\n    s_bowel_train_df = df[df[\"class\"]==\"small_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"sb_seg_rle\"})\n    stomach_train_df = df[df[\"class\"]==\"stomach\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"st_seg_rle\"})\n    df = df.merge(l_bowel_train_df, on=\"id\", how=\"left\")\n    df = df.merge(s_bowel_train_df, on=\"id\", how=\"left\")\n    df = df.merge(stomach_train_df, on=\"id\", how=\"left\")\n    df = df.drop_duplicates(subset=[\"id\",]).reset_index(drop=True)\n    df[\"lb_seg_flag\"] = df[\"lb_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"sb_seg_flag\"] = df[\"sb_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"st_seg_flag\"] = df[\"st_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"n_segs\"] = df[\"lb_seg_flag\"].astype(int)+df[\"sb_seg_flag\"].astype(int)+df[\"st_seg_flag\"].astype(int)\n\n    # 8. Reorder columns to the a new ordering (drops class and segmentation as no longer necessary)\n    df = df[[\"id\", \"fname\", \"n_segs\",\n             \"lb_seg_rle\", \"lb_seg_flag\",\n             \"sb_seg_rle\", \"sb_seg_flag\", \n             \"st_seg_rle\", \"st_seg_flag\",\n             \"slice_h\", \"slice_w\", \"px_spacing_h\", \n             \"px_spacing_w\", \"case_id_str\", \"case_id\", \n             \"day_num_str\", \"day_num\", \"slice_id\",]]\n\n    return df\n\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns: \n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    # Split the string by space, then convert it into a integer array\n    s = np.array(mask_rle.split(), dtype=int)\n\n    # Every even value is the start, every odd value is the \"run\" length\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n\n    # The image image is actually flattened since RLE is a 1D \"run\"\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n\n    # The color here is actually just any integer you want!\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n        \n    # Don't forget to change the image back to the original shape\n    return img.reshape(shape)\n\ndef get_image(row):\n    img = np.array(Image.open(row['fname']))\n    img = np.interp(img, [np.min(img), np.max(img)], [0,255])\n    return img\n    # return row['fname']\n                   \n\ndef get_mask(row):\n    mask = np.zeros((row['slice_w'], row['slice_h'], 3))\n    if row['lb_seg_flag']:\n        mask[..., 0] += rle_decode(row['lb_seg_rle'], shape=(row['slice_w'], row['slice_h']), color=255)\n    if row['sb_seg_flag']:\n        mask[..., 1] += rle_decode(row['sb_seg_rle'], shape=(row['slice_w'], row['slice_h']), color=255)\n    if row['st_seg_flag']:\n        mask[..., 2] += rle_decode(row['st_seg_rle'], shape=(row['slice_w'], row['slice_h']), color=255)\n        \n    return mask.astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:38.013036Z","iopub.execute_input":"2022-05-16T07:35:38.013304Z","iopub.status.idle":"2022-05-16T07:35:38.044478Z","shell.execute_reply.started":"2022-05-16T07:35:38.013268Z","shell.execute_reply":"2022-05-16T07:35:38.043181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Data","metadata":{}},{"cell_type":"code","source":"root = data_path+'test'\ntest_fnames = get_image_files(test_path)\n\nif not test_fnames:\n    test_fnames = fnames\n    root = data_path+'train'\n\ntest = pd.DataFrame({\n    'id': chain.from_iterable([[get_case_id(fname)]*3 for fname in test_fnames]),\n    'class': chain.from_iterable([['large_bowel', 'small_bowel', 'stomach'] for _ in test_fnames]),\n    'segmentation': chain.from_iterable([[np.nan]*3 for _ in test_fnames]),\n})\n\ntest = get_custom_df(test, test_fnames, root)\ntrain = get_custom_df(train, fnames, data_path+'train')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:38.04596Z","iopub.execute_input":"2022-05-16T07:35:38.046444Z","iopub.status.idle":"2022-05-16T07:35:42.558132Z","shell.execute_reply.started":"2022-05-16T07:35:38.046407Z","shell.execute_reply":"2022-05-16T07:35:42.557402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation Set","metadata":{}},{"cell_type":"code","source":"valid_pct = 0.2\nset_seed(SEED, True)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.559552Z","iopub.execute_input":"2022-05-16T07:35:42.5598Z","iopub.status.idle":"2022-05-16T07:35:42.564043Z","shell.execute_reply.started":"2022-05-16T07:35:42.559766Z","shell.execute_reply":"2022-05-16T07:35:42.563293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom validation","metadata":{}},{"cell_type":"code","source":"np.random.seed(SEED)\n\ncases = train.case_id.unique()\nn_cases = len(cases)\nrandom_cases = np.random.choice(cases, int(n_cases*valid_pct), replace=False)\n\ntrain['is_valid'] = False\ntrain.loc[train.case_id.isin(random_cases), 'is_valid'] = True\n\ndays = train.loc[~train['is_valid'], 'day_num'].unique()\nn_days = len(days)\nrandom_days = np.random.choice(days, int(n_days*valid_pct), replace=False)\n\ntrain.loc[train.case_id.isin(random_days), 'is_valid'] = True\n\ntrain['is_valid'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.565398Z","iopub.execute_input":"2022-05-16T07:35:42.565971Z","iopub.status.idle":"2022-05-16T07:35:42.586709Z","shell.execute_reply.started":"2022-05-16T07:35:42.565934Z","shell.execute_reply":"2022-05-16T07:35:42.586009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GroupValidation by Cases","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupShuffleSplit","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.58885Z","iopub.execute_input":"2022-05-16T07:35:42.589264Z","iopub.status.idle":"2022-05-16T07:35:42.593656Z","shell.execute_reply.started":"2022-05-16T07:35:42.589218Z","shell.execute_reply":"2022-05-16T07:35:42.59202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gss = GroupShuffleSplit(n_splits=1, test_size=valid_pct, random_state=SEED)\ntrain_idx, val_idx = [(train_idx, val_idx) for (train_idx, val_idx) in gss.split(train, train, train['case_id'])][0]\n\ntrain['is_valid'] = False\ntrain.loc[val_idx, 'is_valid'] = True\n\ntrain['is_valid'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.597603Z","iopub.execute_input":"2022-05-16T07:35:42.597971Z","iopub.status.idle":"2022-05-16T07:35:42.616357Z","shell.execute_reply.started":"2022-05-16T07:35:42.59794Z","shell.execute_reply":"2022-05-16T07:35:42.615614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Datablock API","metadata":{"tags":[]}},{"cell_type":"code","source":"@ToTensor\ndef encodes(self, o:PILMask): return o._tensor_cls(image2tensor(o))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.617416Z","iopub.execute_input":"2022-05-16T07:35:42.617804Z","iopub.status.idle":"2022-05-16T07:35:42.622349Z","shell.execute_reply.started":"2022-05-16T07:35:42.617767Z","shell.execute_reply":"2022-05-16T07:35:42.621477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@Normalize\ndef encodes(self, o:TensorMask): return o / 255\n\n@Normalize\ndef decodes(self, o:TensorMask): \n    f = to_cpu if o.device.type=='cpu' else noop\n    return f((o * 255).long())","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.623595Z","iopub.execute_input":"2022-05-16T07:35:42.624309Z","iopub.status.idle":"2022-05-16T07:35:42.631678Z","shell.execute_reply.started":"2022-05-16T07:35:42.624264Z","shell.execute_reply":"2022-05-16T07:35:42.630774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as mpatches\n\n@typedispatch\ndef show_batch(x:TensorImage, y:TensorMask, samples, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):\n    if figsize is None: figsize = (ncols*3, max_n//ncols * 3)\n    if ctxs is None: ctxs = get_grid(max_n, nrows=nrows, ncols=ncols, figsize=figsize)\n    for i,ctx in enumerate(ctxs): \n        x_i = x[i] / x[i].max()\n        show_image(x_i, ctx=ctx, cmap='gray', **kwargs)\n        show_image(y[i], ctx=ctx, cmap='Spectral_r', alpha=0.35, **kwargs)\n        red_patch = mpatches.Patch(color='red', label='lb')\n        green_patch = mpatches.Patch(color='green', label='sb')\n        blue_patch = mpatches.Patch(color='blue', label='st')\n        ctx.legend(handles=[red_patch, green_patch, blue_patch], fontsize=figsize[0]/2)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.63318Z","iopub.execute_input":"2022-05-16T07:35:42.63396Z","iopub.status.idle":"2022-05-16T07:35:42.644463Z","shell.execute_reply.started":"2022-05-16T07:35:42.63392Z","shell.execute_reply":"2022-05-16T07:35:42.643694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_aug_dls(aug=[], method='squish', bs=16, sample=False, show=True):\n    batch_tfms = [Normalize.from_stats(*imagenet_stats)]\n    if aug: batch_tfms = [*aug] + batch_tfms\n    \n    db = DataBlock((ImageBlock(cls=PILImageBW), MaskBlock),\n                    get_x=get_image,\n                   get_y=get_mask,\n                   splitter = ColSplitter(),\n                   item_tfms=[Resize(224, method=method)],\n                   batch_tfms=batch_tfms)\n    \n    if sample:\n        dev = train.sample(frac=0.2, random_state=SEED)\n    else:\n        dev = train\n        \n    dls = db.dataloaders(dev, bs=bs, shuffle=True)\n    dls.rng.seed(SEED)\n    \n    if show:\n        dls.show_batch(nrows=bs//4, ncols=4, max_n=bs, figsize=(12, 12))\n        \n    return dls, dev","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.645641Z","iopub.execute_input":"2022-05-16T07:35:42.646382Z","iopub.status.idle":"2022-05-16T07:35:42.657061Z","shell.execute_reply.started":"2022-05-16T07:35:42.646345Z","shell.execute_reply":"2022-05-16T07:35:42.656306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{"tags":[]}},{"cell_type":"code","source":"from scipy.spatial.distance import directed_hausdorff\n\ndef mod_acc(inp, targ):\n    targ = targ.squeeze(1)\n    mask = targ != 0\n    if mask.sum() == 0:\n        mask = targ == 0\n    return (torch.where(sigmoid(inp) > 0.5, 1, 0)[mask]==targ[mask]).float().mean().item()\n\ndef dice_coeff(inp, targ):\n    inp = np.where(inp.cpu().detach().numpy() > 0.5, 1, 0)\n    targ = targ.cpu().detach().numpy()\n    eps = 1e-5\n    I = (targ * inp).sum((2, 3))\n    U =  targ.sum((2,3)) + inp.sum((2, 3))\n    return ((2.*I+eps)/(U+eps)).mean((1, 0))\n\n# def dice_coeff(inp, targ):\n#     if torch.is_tensor(inp):\n#         inp = torch.where(sigmoid(inp) > 0.5, 1, 0).cpu().detach().numpy().astype(np.uint8)\n#     if torch.is_tensor(targ):\n#         targ = targ.cpu().detach().numpy().astype(np.uint8)\n#     # mask = targ == 1\n#     # I = (inp[mask] == targ[mask]).sum((2, 3))\n#     eps = 1e-5\n#     I = (targ & inp).sum((2, 3))\n#     # U = inp.sum((2, 3)) + targ.sum((2, 3))\n#     U = (targ | inp).sum((2, 3))\n#     return ((2*I)/(U+I+1) + (U==0)).mean((1, 0))\n\n# def dice_coeff2(inp, targ, thr=0.5, dim=(2,3), epsilon=0.001):\n#     targ = targ.to(torch.float32)\n#     inp = (inp>thr).to(torch.float32)\n#     inter = (targ*inp).sum(dim=dim)\n#     den = targ.sum(dim=dim) + inp.sum(dim=dim)\n#     dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n#     return dice\n\ndef hd_dist_per_slice(inp, targ):    \n    inp = np.argwhere(inp) / np.array(inp.shape)\n    targ = np.argwhere(targ) / np.array(targ.shape)\n    # if len(targ) == 0:\n    #     inp = 1 - inp\n    #     targ = 1 - targ\n    haussdorf_dist = 1 - directed_hausdorff(inp, targ, SEED)[0]\n    return haussdorf_dist if haussdorf_dist > 0 else 0\n\ndef hd_dist(inp, targ):\n    inp = np.where(inp.cpu().detach().numpy() > 0.5, 1, 0)\n    targ = targ.cpu().detach().numpy()\n    \n    return np.mean([np.mean([hd_dist_per_slice(inp[i, j], targ[i, j]) for j in range(3)]) for i in range(len(inp))])\n\ndef custom_metric(inp, targ):\n    hd_score_per_batch = hd_dist(inp, targ)\n    dice_score_per_batch = dice_coeff(inp, targ)\n        \n    return 0.4*dice_score_per_batch + 0.6*hd_score_per_batch\n\n\ndef custom_loss(inp, targ):\n    return nn.BCEWithLogitsLoss(inp, targ.float())","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-16T07:36:10.71164Z","iopub.execute_input":"2022-05-16T07:36:10.711942Z","iopub.status.idle":"2022-05-16T07:36:10.725482Z","shell.execute_reply.started":"2022-05-16T07:36:10.711912Z","shell.execute_reply":"2022-05-16T07:36:10.724776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# custom_metric(torch.zeros_like(y), torch.zeros_like(y))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.677665Z","iopub.execute_input":"2022-05-16T07:35:42.678335Z","iopub.status.idle":"2022-05-16T07:35:42.686365Z","shell.execute_reply.started":"2022-05-16T07:35:42.6783Z","shell.execute_reply":"2022-05-16T07:35:42.685598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss","metadata":{}},{"cell_type":"code","source":"class DiceBCEModule(Module):\n    def __init__(self, eps:float=1e-5, from_logits=True):\n        store_attr()\n        \n    def forward(self, inp:Tensor, targ:Tensor) -> Tensor:\n        if self.from_logits: \n            bce_loss = nn.BCEWithLogitsLoss()(inp, targ)\n            inp = torch.sigmoid(inp)\n        inp = inp.view(-1)\n        targ = targ.view(-1)\n        \n        intersection = (inp * targ).sum()                            \n        dice = (2.*intersection + self.eps)/(inp.sum() + targ.sum() + self.eps)  \n        \n        return 0.5*(1 - dice) + 0.5*bce_loss\n\n\nclass DiceBCELoss(BaseLoss):\n    def __init__(self, *args, eps:float=1e-5, from_logits=True, **kwargs):\n        super().__init__(DiceBCEModule, *args, eps=eps, from_logits=from_logits, flatten=False, is_2d=True, floatify=True, **kwargs)\n    \n    def decodes(self, x:Tensor) -> Tensor:\n        \"Converts model output to target format\"\n        return (x>self.thresh).long()\n\n    def activation(self, x:Tensor) -> Tensor:\n        \"`nn.BCEWithLogitsLoss`'s fused activation function applied to model output\"\n        return torch.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.687608Z","iopub.execute_input":"2022-05-16T07:35:42.688093Z","iopub.status.idle":"2022-05-16T07:35:42.699668Z","shell.execute_reply.started":"2022-05-16T07:35:42.688058Z","shell.execute_reply":"2022-05-16T07:35:42.698935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Learner","metadata":{"tags":[]}},{"cell_type":"code","source":"def splitter(model):\n    return [params(model.encoder), params(model.decoder)]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.700857Z","iopub.execute_input":"2022-05-16T07:35:42.701653Z","iopub.status.idle":"2022-05-16T07:35:42.71142Z","shell.execute_reply.started":"2022-05-16T07:35:42.70161Z","shell.execute_reply":"2022-05-16T07:35:42.710633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(encoder_name):\n    model = smp.Unet(\n        encoder_name=encoder_name,      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n        classes=3,        # model output channels (number of classes in your dataset)\n        activation=None,\n    )\n    model.to('cuda')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.712609Z","iopub.execute_input":"2022-05-16T07:35:42.713411Z","iopub.status.idle":"2022-05-16T07:35:42.719926Z","shell.execute_reply.started":"2022-05-16T07:35:42.713374Z","shell.execute_reply":"2022-05-16T07:35:42.719147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not INFER:\n    dls, dev = get_aug_dls(aug_transforms(), sample=False, bs=16, show=False)\n    unet = build_model('resnet34')\n    learn = Learner(dls, unet, metrics=[dice_coeff, hd_dist, custom_metric], loss_func=DiceBCELoss()).to_fp16()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-16T07:35:42.72127Z","iopub.execute_input":"2022-05-16T07:35:42.722009Z","iopub.status.idle":"2022-05-16T07:35:42.72882Z","shell.execute_reply.started":"2022-05-16T07:35:42.721972Z","shell.execute_reply":"2022-05-16T07:35:42.728145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"tags":[]}},{"cell_type":"code","source":"if not INFER:\n    learn.freeze()\n    learn.lr_find()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-16T07:35:42.73005Z","iopub.execute_input":"2022-05-16T07:35:42.730592Z","iopub.status.idle":"2022-05-16T07:35:42.736923Z","shell.execute_reply.started":"2022-05-16T07:35:42.730553Z","shell.execute_reply":"2022-05-16T07:35:42.736162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-3","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-16T07:35:42.738036Z","iopub.execute_input":"2022-05-16T07:35:42.738671Z","iopub.status.idle":"2022-05-16T07:35:42.745265Z","shell.execute_reply.started":"2022-05-16T07:35:42.738625Z","shell.execute_reply":"2022-05-16T07:35:42.744561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not INFER:\n    learn.fit_one_cycle(1, slice(lr))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-16T07:35:42.746598Z","iopub.execute_input":"2022-05-16T07:35:42.747379Z","iopub.status.idle":"2022-05-16T07:35:42.753655Z","shell.execute_reply.started":"2022-05-16T07:35:42.74734Z","shell.execute_reply":"2022-05-16T07:35:42.752908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not INFER:\n    learn.unfreeze()\n    learn.fit_one_cycle(10, slice(lr/400, lr/10))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.755905Z","iopub.execute_input":"2022-05-16T07:35:42.756844Z","iopub.status.idle":"2022-05-16T07:35:42.764705Z","shell.execute_reply.started":"2022-05-16T07:35:42.756798Z","shell.execute_reply":"2022-05-16T07:35:42.764054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show Results","metadata":{"tags":[]}},{"cell_type":"code","source":"if not INFER:\n    learn.show_results(max_n=16)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.767843Z","iopub.execute_input":"2022-05-16T07:35:42.769199Z","iopub.status.idle":"2022-05-16T07:35:42.7739Z","shell.execute_reply.started":"2022-05-16T07:35:42.769167Z","shell.execute_reply":"2022-05-16T07:35:42.773131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save Model","metadata":{}},{"cell_type":"code","source":"if not INFER:\n    learn.export(model_name)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:35:42.775314Z","iopub.execute_input":"2022-05-16T07:35:42.775691Z","iopub.status.idle":"2022-05-16T07:35:42.782257Z","shell.execute_reply.started":"2022-05-16T07:35:42.775654Z","shell.execute_reply":"2022-05-16T07:35:42.781572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test inference ","metadata":{"tags":[]}},{"cell_type":"code","source":"if INFER:\n    learn = load_learner(model_name)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:36:14.240177Z","iopub.execute_input":"2022-05-16T07:36:14.240786Z","iopub.status.idle":"2022-05-16T07:36:14.513659Z","shell.execute_reply.started":"2022-05-16T07:36:14.240746Z","shell.execute_reply":"2022-05-16T07:36:14.512936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# @torch.no_grad()\n# def get_preds(learn, dl, thresh=0.5):\n#     learn.model.eval()\n#     preds = []\n#     for b in tqdm(dl):\n#         b[0].to('cuda')\n#         b_preds = (sigmoid(learn.model(b[0])) > 0.5).permute(0, 2, 3, 1).cpu().detach().numpy().astype(np.uint8)\n#         preds.append(b_preds)\n#         torch.cuda.empty_cache()\n#         gc.collect()\n#     preds_arr = np.concatenate(preds)\n#     del preds; gc.collect()\n#     return preds_arr\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:36:15.945392Z","iopub.execute_input":"2022-05-16T07:36:15.946019Z","iopub.status.idle":"2022-05-16T07:36:15.952532Z","shell.execute_reply.started":"2022-05-16T07:36:15.94598Z","shell.execute_reply":"2022-05-16T07:36:15.951775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if INFER:\n    test_dl = learn.dls.test_dl(test, shuffle=False).to('cuda')\n    b = test_dl.one_batch()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:37:46.492671Z","iopub.execute_input":"2022-05-16T07:37:46.493261Z","iopub.status.idle":"2022-05-16T07:37:46.595342Z","shell.execute_reply.started":"2022-05-16T07:37:46.493204Z","shell.execute_reply":"2022-05-16T07:37:46.594575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if INFER:\n    learn.model = learn.model.cuda()\n    learn.model.eval()\n    test_preds = np.zeros((test.shape[0], b[0].shape[2], b[0].shape[3], b[0].shape[1]), dtype=np.uint8)\n    with torch.no_grad():\n        for i, b in enumerate(tqdm(test_dl)):\n            b[0].to('cuda')\n            b_preds = (sigmoid(learn.model(b[0])) > 0.5).permute(0, 2, 3, 1).cpu().detach().numpy().astype(np.uint8)\n            test_preds[i*16:i*16+16] = b_preds\n            torch.cuda.empty_cache()\n            gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T07:37:49.242541Z","iopub.execute_input":"2022-05-16T07:37:49.243199Z","iopub.status.idle":"2022-05-16T07:38:05.785021Z","shell.execute_reply.started":"2022-05-16T07:37:49.243161Z","shell.execute_reply":"2022-05-16T07:38:05.783863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if INFER:\n#     learn.model = learn.model.cuda()\n#     test_dl = learn.dls.test_dl(test, shuffle=False).to('cuda')\n#     test_preds = get_preds(learn, test_dl)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Source: https://www.kaggle.com/code/clemchris/gi-seg-pytorch-train-infer\n\ndef mask2rle(mask):\n    \"\"\"\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    \"\"\"\n    mask = np.array(mask)\n    pixels = mask.flatten()\n    pad = np.array([0])\n    pixels = np.concatenate([pad, pixels, pad])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n\n    return \" \".join(str(x) for x in runs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\ndef get_rle_masks(preds, df):\n    rle_masks = []\n    for pred, width, height in tqdm(zip(preds, df['slice_w'], df['slice_h'])):\n        upsized_mask = cv2.resize(pred, dsize=(height, width), interpolation=cv2.INTER_NEAREST)\n        for i in range(3):\n            rle_mask = mask2rle(upsized_mask[:, :, i])\n            rle_masks.append(rle_mask)\n    return rle_masks","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if INFER:\n    masks = get_rle_masks(test_preds, test)   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if INFER:\n    submission = pd.DataFrame({\n        'id': chain.from_iterable([[get_case_id(fname)]*3 for fname in test_fnames]),\n        'class': chain.from_iterable([['large_bowel', 'small_bowel', 'stomach'] for _ in test_fnames]),\n        'predicted': masks,\n    })\n    \n    if sample_submission.shape[0] > 0:\n        del sample_submission['predicted']\n        submission = sample_submission.merge(submission, on=['id', 'class'])\n    \n    submission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}