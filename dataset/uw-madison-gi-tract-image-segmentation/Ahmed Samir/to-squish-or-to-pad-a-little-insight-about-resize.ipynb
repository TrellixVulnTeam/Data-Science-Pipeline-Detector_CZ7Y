{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Motivation\n\nI noticed a discrepancy between my local validation and the public leaderboard, so I set out on a quest to find out where the problem was. \n\nIt turned out that I had made a problem while upsizing the predicted masks where I switched heights and widths. \n\nSo when I corrected that, I stumbled upon an insight.\n\n### Slices that have different heights and widths had different dice scores before and after upsizing, why?\n\nWell, it had to do something with the resize method I have used, which was padding. Let's take a look.","metadata":{}},{"cell_type":"markdown","source":"## Librarires and data","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\n\nfrom itertools import chain\nfrom fastai.vision.all import *\n\nGRADIENT = os.path.exists('train')\nKAGGLE = os.path.exists('../input')\nmodel_name = 'baseline-model'\nSEED = 42\n\nif KAGGLE:\n    data_path = '../input/uw-madison-gi-tract-image-segmentation/'\nelif GRADIENT:\n    data_path = ''\n    \npath = Path(data_path+'train')\ntest_path = Path(data_path+'test')\ntrain = pd.read_csv(data_path+'train.csv', low_memory=False)\nfnames = get_image_files(path)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:07:28.843517Z","iopub.execute_input":"2022-05-11T09:07:28.843778Z","iopub.status.idle":"2022-05-11T09:07:35.683876Z","shell.execute_reply.started":"2022-05-11T09:07:28.843751Z","shell.execute_reply":"2022-05-11T09:07:35.683139Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Some helper functions","metadata":{}},{"cell_type":"code","source":"# Extract case id from fname\ndef get_case_id(fname):\n    if KAGGLE: i = 5\n    elif GRADIENT: i = 2\n    return fname.parts[i] + '_' + fname.parts[i+2][:10]\n\ndef check_file(file_id, fname):\n    case_id, day, _, slice_no = file_id.split('_')\n    if case_id == fname.parts[1] and day == fname.parts[2].split('_')[1] and slice_no in fname.parts[-1]:\n        return True\n    return False\n\ndef get_file(file_id):\n    return fnames.filter(lambda f: check_file(not_null_train.id[0], f))[0]\n\n# https://www.kaggle.com/code/dschettler8845/uwm-gi-tract-image-segmentation-eda\ndef get_custom_df(df, fnames, root):\n    \n    df = df.copy()\n    \n    # 1. Get Case-ID as a column (str and int)\n    df[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\n    df[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n    # 2. Get Day as a column\n    df[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\n    df[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n    # 3. Get Slice Identifier as a column\n    df[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\n    # 4. Get full file paths for the representative scans\n    df[\"_partial_fname\"] = (root+'/'+ # /kaggle/input/uw-madison-gi-tract-image-segmentation/train/\n                          df[\"case_id_str\"]+\"/\"+ # .../case###/\n                          df[\"case_id_str\"]+\"_\"+df[\"day_num_str\"]+ # .../case###_day##/\n                          \"/scans/\"+df[\"slice_id\"]) # .../slice_####\n    \n    _tmp_merge_df = pd.DataFrame({\"_partial_fname\":[str(x).rsplit(\"_\",4)[0] for x in fnames], \"fname\": fnames})\n    df = df.merge(_tmp_merge_df, on=\"_partial_fname\").drop(columns=[\"_partial_fname\"])\n    \n    # Minor cleanup of our temporary workaround\n    del _tmp_merge_df; gc.collect(); gc.collect()\n    \n    # 5. Get slice dimensions from filepath (int in pixels)\n    df[\"slice_h\"] = df[\"fname\"].apply(lambda x: int(str(x)[:-4].rsplit(\"_\",4)[1]))\n    df[\"slice_w\"] = df[\"fname\"].apply(lambda x: int(str(x)[:-4].rsplit(\"_\",4)[2]))\n\n    # 6. Pixel spacing from filepath (float in mm)\n    df[\"px_spacing_h\"] = df[\"fname\"].apply(lambda x: float(str(x)[:-4].rsplit(\"_\",4)[3]))\n    df[\"px_spacing_w\"] = df[\"fname\"].apply(lambda x: float(str(x)[:-4].rsplit(\"_\",4)[4]))\n\n    # 7. Merge 3 Rows Into A Single Row (As This/Segmentation-RLE Is The Only Unique Information Across Those Rows)\n    l_bowel_train_df = df[df[\"class\"]==\"large_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"lb_seg_rle\"})\n    s_bowel_train_df = df[df[\"class\"]==\"small_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"sb_seg_rle\"})\n    stomach_train_df = df[df[\"class\"]==\"stomach\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"st_seg_rle\"})\n    df = df.merge(l_bowel_train_df, on=\"id\", how=\"left\")\n    df = df.merge(s_bowel_train_df, on=\"id\", how=\"left\")\n    df = df.merge(stomach_train_df, on=\"id\", how=\"left\")\n    df = df.drop_duplicates(subset=[\"id\",]).reset_index(drop=True)\n    df[\"lb_seg_flag\"] = df[\"lb_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"sb_seg_flag\"] = df[\"sb_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"st_seg_flag\"] = df[\"st_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"n_segs\"] = df[\"lb_seg_flag\"].astype(int)+df[\"sb_seg_flag\"].astype(int)+df[\"st_seg_flag\"].astype(int)\n\n    # 8. Reorder columns to the a new ordering (drops class and segmentation as no longer necessary)\n    df = df[[\"id\", \"fname\", \"n_segs\",\n             \"lb_seg_rle\", \"lb_seg_flag\",\n             \"sb_seg_rle\", \"sb_seg_flag\", \n             \"st_seg_rle\", \"st_seg_flag\",\n             \"slice_h\", \"slice_w\", \"px_spacing_h\", \n             \"px_spacing_w\", \"case_id_str\", \"case_id\", \n             \"day_num_str\", \"day_num\", \"slice_id\",]]\n\n    return df\n\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns: \n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    # Split the string by space, then convert it into a integer array\n    s = np.array(mask_rle.split(), dtype=int)\n\n    # Every even value is the start, every odd value is the \"run\" length\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n\n    # The image image is actually flattened since RLE is a 1D \"run\"\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n\n    # The color here is actually just any integer you want!\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n        \n    # Don't forget to change the image back to the original shape\n    return img.reshape(shape)\n\ndef get_image(row):\n    img = np.array(Image.open(row['fname']))\n    img = np.interp(img, [np.min(img), np.max(img)], [0,255])\n    return img\n    # return row['fname']\n                   \n\ndef get_mask(row):\n    mask = np.zeros((row['slice_w'], row['slice_h'], 3))\n    if row['lb_seg_flag']:\n        mask[..., 0] += rle_decode(row['lb_seg_rle'], shape=(row['slice_w'], row['slice_h']), color=255)\n    if row['sb_seg_flag']:\n        mask[..., 1] += rle_decode(row['sb_seg_rle'], shape=(row['slice_w'], row['slice_h']), color=255)\n    if row['st_seg_flag']:\n        mask[..., 2] += rle_decode(row['st_seg_rle'], shape=(row['slice_w'], row['slice_h']), color=255)\n        \n    return mask.astype(np.uint8)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:07:35.685653Z","iopub.execute_input":"2022-05-11T09:07:35.685922Z","iopub.status.idle":"2022-05-11T09:07:35.717956Z","shell.execute_reply.started":"2022-05-11T09:07:35.685891Z","shell.execute_reply":"2022-05-11T09:07:35.717238Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = data_path+'test'\ntest_fnames = get_image_files(test_path)\n\nif not test_fnames:\n    test_fnames = fnames\n    root = data_path+'train'\n\ntest = pd.DataFrame({\n    'id': chain.from_iterable([[get_case_id(fname)]*3 for fname in test_fnames]),\n    'class': chain.from_iterable([['large_bowel', 'small_bowel', 'stomach'] for _ in test_fnames]),\n    'segmentation': chain.from_iterable([[np.nan]*3 for _ in test_fnames]),\n})\n\ntest = get_custom_df(test, test_fnames, root)\ntrain = get_custom_df(train, fnames, data_path+'train')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:07:35.719323Z","iopub.execute_input":"2022-05-11T09:07:35.720281Z","iopub.status.idle":"2022-05-11T09:07:40.102159Z","shell.execute_reply.started":"2022-05-11T09:07:35.720205Z","shell.execute_reply":"2022-05-11T09:07:40.101398Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation Set","metadata":{}},{"cell_type":"code","source":"valid_pct = 0.2\n\nnp.random.seed(SEED)\n\ncases = train.case_id.unique()\nn_cases = len(cases)\nrandom_cases = np.random.choice(cases, int(n_cases*valid_pct), replace=False)\n\ntrain['is_valid'] = False\ntrain.loc[train.case_id.isin(random_cases), 'is_valid'] = True\n\ndays = train.loc[~train['is_valid'], 'day_num'].unique()\nn_days = len(days)\nrandom_days = np.random.choice(days, int(n_days*valid_pct), replace=False)\n\ntrain.loc[train.case_id.isin(random_days), 'is_valid'] = True","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:07:40.10397Z","iopub.execute_input":"2022-05-11T09:07:40.104225Z","iopub.status.idle":"2022-05-11T09:07:40.120934Z","shell.execute_reply.started":"2022-05-11T09:07:40.104191Z","shell.execute_reply":"2022-05-11T09:07:40.120084Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataloaders","metadata":{}},{"cell_type":"code","source":"@ToTensor\ndef encodes(self, o:PILMask): return o._tensor_cls(image2tensor(o))\n\n@Normalize\ndef encodes(self, o:TensorMask): return o / 255\n\n@Normalize\ndef decodes(self, o:TensorMask): \n    f = to_cpu if o.device.type=='cpu' else noop\n    return f((o * 255).long())\n\ndef get_aug_dls(aug=[], method='squish', sample=False, show=True):\n    batch_tfms = [Normalize.from_stats(*imagenet_stats)]\n    if aug: batch_tfms = [*aug] + batch_tfms\n    \n    db = DataBlock((ImageBlock(cls=PILImageBW), MaskBlock),\n                   get_x=get_image,\n                   get_y=get_mask,\n                   splitter = ColSplitter(),\n                   item_tfms=[Resize(160, method=method)],\n                   batch_tfms=batch_tfms\n            )\n    \n    if sample:\n        dev = train.sample(frac=0.2, random_state=SEED)\n        bs = 16\n    else:\n        dev = train\n        bs = 16\n        \n    dls = db.dataloaders(dev, bs=bs, shuffle=True)\n    dls.rng.seed(SEED)\n    \n    if show:\n        dls.show_batch(nrows=bs//4, ncols=4, max_n=bs, figsize=(12, 12))\n        \n    return dls, dev","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:07:40.122437Z","iopub.execute_input":"2022-05-11T09:07:40.123338Z","iopub.status.idle":"2022-05-11T09:07:40.13382Z","shell.execute_reply.started":"2022-05-11T09:07:40.123118Z","shell.execute_reply":"2022-05-11T09:07:40.133135Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as mpatches\n\n@typedispatch\ndef show_batch(x:TensorImage, y:TensorMask, samples, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):\n    if figsize is None: figsize = (ncols*3, max_n//ncols * 3)\n    if ctxs is None: ctxs = get_grid(max_n, nrows=nrows, ncols=ncols, figsize=figsize)\n    for i,ctx in enumerate(ctxs): \n        x_i = x[i] / x[i].max()\n        show_image(x_i, ctx=ctx, cmap='gray', **kwargs)\n        show_image(y[i], ctx=ctx, cmap='Spectral_r', alpha=0.35, **kwargs)\n        red_patch = mpatches.Patch(color='red', label='lb')\n        green_patch = mpatches.Patch(color='green', label='sb')\n        blue_patch = mpatches.Patch(color='blue', label='st')\n        ctx.legend(handles=[red_patch, green_patch, blue_patch], fontsize=figsize[0]/2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:07:40.134981Z","iopub.execute_input":"2022-05-11T09:07:40.135269Z","iopub.status.idle":"2022-05-11T09:07:40.147616Z","shell.execute_reply.started":"2022-05-11T09:07:40.135231Z","shell.execute_reply":"2022-05-11T09:07:40.146727Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"from scipy.spatial.distance import directed_hausdorff\n\ndef mod_acc(inp, targ):\n    targ = targ.squeeze(1)\n    mask = targ != 0\n    if mask.sum() == 0:\n        mask = targ == 0\n    return (torch.where(sigmoid(inp) > 0.5, 1, 0)[mask]==targ[mask]).float().mean().item()\n\ndef dice_coeff(inp, targ):\n    if torch.is_tensor(inp):\n        inp = torch.where(sigmoid(inp) > 0.5, 1, 0).cpu().detach().numpy().astype(np.uint8)\n    if torch.is_tensor(targ):\n        targ = targ.cpu().detach().numpy().astype(np.uint8)\n    # mask = targ == 1\n    # I = (inp[mask] == targ[mask]).sum((2, 3))\n    eps = 1e-5\n    I = (inp & targ).sum((2, 3))\n    U = inp.sum((2, 3)) + targ.sum((2, 3))\n    return ((2*I+eps)/(U+eps)).mean((1, 0))\n\n# def dice_coeff2(inp, targ, thr=0.5, dim=(2,3), epsilon=0.001):\n#     targ = targ.to(torch.float32)\n#     inp = (inp>thr).to(torch.float32)\n#     inter = (targ*inp).sum(dim=dim)\n#     den = targ.sum(dim=dim) + inp.sum(dim=dim)\n#     dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n#     return dice\n\ndef hd_dist_per_slice(inp, targ):\n    inp = torch.where(sigmoid(inp) > 0.5, 1, 0).cpu().detach().numpy()\n    targ = targ.cpu().detach().numpy()\n    inp = np.argwhere(inp) / np.array(inp.shape)\n    targ = np.argwhere(targ) / np.array(targ.shape)\n    # if len(targ) == 0:\n    #     inp = 1 - inp\n    #     targ = 1 - targ\n    haussdorf_dist = 1 - directed_hausdorff(inp, targ, SEED)[0]\n    return haussdorf_dist if haussdorf_dist > 0 else 0\n\ndef hd_dist(inp, targ):\n    return np.mean([np.mean([hd_dist_per_slice(inp[i, j], targ[i, j]) for j in range(3)]) for i in range(len(inp))])\n\ndef custom_metric(inp, targ):\n    hd_score_per_batch = hd_dist(inp, targ)\n    dice_score_per_batch = dice_coeff(inp, targ)\n        \n    return 0.4*dice_score_per_batch + 0.6*hd_score_per_batch\n\ndef custom_loss(inp, targ):\n    return nn.BCEWithLogitsLoss()(inp, targ.float())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:10:27.276753Z","iopub.execute_input":"2022-05-11T09:10:27.277042Z","iopub.status.idle":"2022-05-11T09:10:27.291464Z","shell.execute_reply.started":"2022-05-11T09:10:27.277009Z","shell.execute_reply":"2022-05-11T09:10:27.290454Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resizing with pad","metadata":{}},{"cell_type":"markdown","source":"## Create a datalaoder","metadata":{}},{"cell_type":"code","source":"dls, dev = get_aug_dls(sample=True, method='pad', show=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:10:11.499752Z","iopub.execute_input":"2022-05-11T09:10:11.500024Z","iopub.status.idle":"2022-05-11T09:10:11.586738Z","shell.execute_reply.started":"2022-05-11T09:10:11.499992Z","shell.execute_reply":"2022-05-11T09:10:11.586058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train a model ","metadata":{}},{"cell_type":"code","source":"set_seed(SEED, True)\nlearn = unet_learner(dls, resnet18, metrics=[mod_acc, dice_coeff, hd_dist, custom_metric], n_out=3, loss_func=custom_loss,\n                     self_attention=True, act_cls=Mish, opt_func=ranger).to_fp16()\nlearn.freeze()\nlearn.fit_flat_cos(1, slice(1e-3))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:10:30.705936Z","iopub.execute_input":"2022-05-11T09:10:30.706729Z","iopub.status.idle":"2022-05-11T09:13:04.836854Z","shell.execute_reply.started":"2022-05-11T09:10:30.706685Z","shell.execute_reply":"2022-05-11T09:13:04.836076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a new validation dl without any transformation","metadata":{}},{"cell_type":"code","source":"raw_dl = dls.valid.new(after_item=[ToTensor], after_batch=[], bs=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:13:04.838721Z","iopub.execute_input":"2022-05-11T09:13:04.839506Z","iopub.status.idle":"2022-05-11T09:13:04.845089Z","shell.execute_reply.started":"2022-05-11T09:13:04.839464Z","shell.execute_reply":"2022-05-11T09:13:04.844144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get all predictions","metadata":{}},{"cell_type":"code","source":"imgs, preds, targs = learn.get_preds(dl=dls.valid, with_input=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:13:04.846153Z","iopub.execute_input":"2022-05-11T09:13:04.846415Z","iopub.status.idle":"2022-05-11T09:13:35.637722Z","shell.execute_reply.started":"2022-05-11T09:13:04.846367Z","shell.execute_reply":"2022-05-11T09:13:35.636797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert predictions to numpy masks","metadata":{}},{"cell_type":"code","source":"preds_masks = (sigmoid(preds) > 0.5).permute(0, 2, 3, 1).cpu().detach().numpy().astype(np.uint8)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:13:35.64008Z","iopub.execute_input":"2022-05-11T09:13:35.640379Z","iopub.status.idle":"2022-05-11T09:13:36.513822Z","shell.execute_reply.started":"2022-05-11T09:13:35.640341Z","shell.execute_reply":"2022-05-11T09:13:36.513065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Upsize predicted masks ","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport cv2","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:13:37.796697Z","iopub.execute_input":"2022-05-11T09:13:37.798279Z","iopub.status.idle":"2022-05-11T09:13:37.961436Z","shell.execute_reply.started":"2022-05-11T09:13:37.798227Z","shell.execute_reply":"2022-05-11T09:13:37.960649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"before_dices = []\nafter_dices = []\norg_imgs = []\ninp_masks = []\ntarg_masks = []\nval = dev.query('is_valid')\nfor pred_mask, pred, targ, raw_b, width, height in tqdm(zip(preds_masks, preds, targs, raw_dl, val['slice_w'], val['slice_h'])):\n    upsized_mask = np.moveaxis(cv2.resize(pred_mask, dsize=(height, width), interpolation=cv2.INTER_NEAREST), -1, 0)\n    targ_mask = raw_b[1]\n    \n    before_dices.append(dice_coeff(pred[None, ...], targ[None, ...]))\n    after_dices.append(dice_coeff(upsized_mask[None, ...], targ_mask/255))\n    org_imgs.append(raw_b[0])\n    inp_masks.append(upsized_mask)\n    targ_masks.append(targ_mask)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-11T09:13:38.365302Z","iopub.execute_input":"2022-05-11T09:13:38.365948Z","iopub.status.idle":"2022-05-11T09:13:58.547987Z","shell.execute_reply.started":"2022-05-11T09:13:38.365905Z","shell.execute_reply":"2022-05-11T09:13:58.547027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compare score before and after resizing","metadata":{}},{"cell_type":"code","source":"np.mean(before_dices), np.mean(after_dices)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:13:58.550296Z","iopub.execute_input":"2022-05-11T09:13:58.55061Z","iopub.status.idle":"2022-05-11T09:13:58.559765Z","shell.execute_reply.started":"2022-05-11T09:13:58.550567Z","shell.execute_reply":"2022-05-11T09:13:58.559027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(before_dices, after_dices);","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:13:58.561154Z","iopub.execute_input":"2022-05-11T09:13:58.561535Z","iopub.status.idle":"2022-05-11T09:13:58.803846Z","shell.execute_reply.started":"2022-05-11T09:13:58.561497Z","shell.execute_reply":"2022-05-11T09:13:58.802962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### There you can see a little discrepancy where scores after upsizing tend to decrease. Let's take a look at some examples.","metadata":{}},{"cell_type":"markdown","source":"### Find masks with highest discrepancies between after and before scores","metadata":{}},{"cell_type":"code","source":"diff = np.array(before_dices) - np.array(after_dices)\ndiff_idx_sorted = np.argsort(diff)[::-1]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:14:34.406458Z","iopub.execute_input":"2022-05-11T09:14:34.406749Z","iopub.status.idle":"2022-05-11T09:14:34.411329Z","shell.execute_reply.started":"2022-05-11T09:14:34.406719Z","shell.execute_reply":"2022-05-11T09:14:34.410625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plt_before_after(idx):\n    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n    axes = axes.flatten()\n    \n    print(before_dices[idx], after_dices[idx], val.iloc[idx]['slice_w'], val.iloc[idx]['slice_h'])\n    \n    # plot image and target before upsize\n    decoded_small_img, decoded_small_mask = dls.decode((imgs[idx], targs[idx]))\n    show_image(decoded_small_img[0], cmap='gray', ctx=axes[0])\n    show_image(decoded_small_mask, cmap='Spectral_r', alpha=0.35, ctx=axes[0], title=\"Target (resized)\")\n    \n    # plot image and pred before upsize\n    show_image(decoded_small_img[0], cmap='gray', ctx=axes[1])\n    show_image(preds_masks[idx]*255, cmap='Spectral_r', alpha=0.35, ctx=axes[1], title=\"Prediction (resized)\")\n    \n    # plot image and target after upsize\n    show_image(org_imgs[idx][0], cmap='gray', ctx=axes[2])\n    show_image(targ_masks[idx][0], cmap='Spectral_r', alpha=0.35, ctx=axes[2], title=\"Target (original)\")\n    \n    # plot image and pred after upsize\n    show_image(org_imgs[idx][0], cmap='gray', ctx=axes[3])\n    show_image(np.moveaxis(inp_masks[idx], 0, -1)*255, cmap='Spectral_r', alpha=0.35, ctx=axes[3], title=\"Prediction (upsized)\")","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:14:35.410126Z","iopub.execute_input":"2022-05-11T09:14:35.410713Z","iopub.status.idle":"2022-05-11T09:14:35.419696Z","shell.execute_reply.started":"2022-05-11T09:14:35.410671Z","shell.execute_reply":"2022-05-11T09:14:35.419006Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt_before_after(diff_idx_sorted[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:15:20.233348Z","iopub.execute_input":"2022-05-11T09:15:20.234007Z","iopub.status.idle":"2022-05-11T09:15:20.657551Z","shell.execute_reply.started":"2022-05-11T09:15:20.233966Z","shell.execute_reply":"2022-05-11T09:15:20.656855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt_before_after(diff_idx_sorted[1])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:15:24.834501Z","iopub.execute_input":"2022-05-11T09:15:24.834803Z","iopub.status.idle":"2022-05-11T09:15:25.263639Z","shell.execute_reply.started":"2022-05-11T09:15:24.834769Z","shell.execute_reply":"2022-05-11T09:15:25.262938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt_before_after(diff_idx_sorted[2])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:15:28.55107Z","iopub.execute_input":"2022-05-11T09:15:28.551678Z","iopub.status.idle":"2022-05-11T09:15:28.975609Z","shell.execute_reply.started":"2022-05-11T09:15:28.551639Z","shell.execute_reply":"2022-05-11T09:15:28.974945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now let's fast forward to what would happend if we use squish","metadata":{}},{"cell_type":"code","source":"dls, dev = get_aug_dls(sample=True, method='squish', show=False)\n\nset_seed(SEED, True)\nlearn = unet_learner(dls, resnet18, metrics=[mod_acc, dice_coeff, hd_dist, custom_metric], n_out=3, loss_func=custom_loss,\n                     self_attention=True, act_cls=Mish, opt_func=ranger).to_fp16()\nlearn.freeze()\nlearn.fit_flat_cos(1, slice(1e-3))\n\nraw_dl = dls.valid.new(after_item=[ToTensor], after_batch=[], bs=1)\n\nimgs, preds, targs = learn.get_preds(dl=dls.valid, with_input=True)\n\npreds_masks = (sigmoid(preds) > 0.5).permute(0, 2, 3, 1).cpu().detach().numpy().astype(np.uint8)\n\nbefore_dices = []\nafter_dices = []\norg_imgs = []\ninp_masks = []\ntarg_masks = []\nval = dev.query('is_valid')\nfor pred_mask, pred, targ, raw_b, width, height in tqdm(zip(preds_masks, preds, targs, raw_dl, val['slice_w'], val['slice_h'])):\n    upsized_mask = np.moveaxis(cv2.resize(pred_mask, dsize=(height, width), interpolation=cv2.INTER_NEAREST), -1, 0)\n    targ_mask = raw_b[1]\n    \n    before_dices.append(dice_coeff(pred[None, ...], targ[None, ...]))\n    after_dices.append(dice_coeff(upsized_mask[None, ...], targ_mask/255))\n    org_imgs.append(raw_b[0])\n    inp_masks.append(upsized_mask)\n    targ_masks.append(targ_mask)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-11T09:18:15.286349Z","iopub.execute_input":"2022-05-11T09:18:15.286684Z","iopub.status.idle":"2022-05-11T09:21:31.245814Z","shell.execute_reply.started":"2022-05-11T09:18:15.28665Z","shell.execute_reply":"2022-05-11T09:21:31.244883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(before_dices), np.mean(after_dices)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:21:39.298816Z","iopub.execute_input":"2022-05-11T09:21:39.299137Z","iopub.status.idle":"2022-05-11T09:21:39.305703Z","shell.execute_reply.started":"2022-05-11T09:21:39.299078Z","shell.execute_reply":"2022-05-11T09:21:39.304779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(before_dices, after_dices);","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:21:40.689027Z","iopub.execute_input":"2022-05-11T09:21:40.689622Z","iopub.status.idle":"2022-05-11T09:21:40.895498Z","shell.execute_reply.started":"2022-05-11T09:21:40.68958Z","shell.execute_reply":"2022-05-11T09:21:40.894823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### And when we look at the predictions with the highest difference, we can see that they aren't as bad as before.","metadata":{}},{"cell_type":"code","source":"plt_before_after(diff_idx_sorted[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:21:43.545146Z","iopub.execute_input":"2022-05-11T09:21:43.545875Z","iopub.status.idle":"2022-05-11T09:21:43.978675Z","shell.execute_reply.started":"2022-05-11T09:21:43.545834Z","shell.execute_reply":"2022-05-11T09:21:43.977958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt_before_after(diff_idx_sorted[1])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:21:48.0598Z","iopub.execute_input":"2022-05-11T09:21:48.060391Z","iopub.status.idle":"2022-05-11T09:21:48.704255Z","shell.execute_reply.started":"2022-05-11T09:21:48.060351Z","shell.execute_reply":"2022-05-11T09:21:48.703475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt_before_after(diff_idx_sorted[2])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T09:21:55.27718Z","iopub.execute_input":"2022-05-11T09:21:55.277949Z","iopub.status.idle":"2022-05-11T09:21:55.711631Z","shell.execute_reply.started":"2022-05-11T09:21:55.27791Z","shell.execute_reply":"2022-05-11T09:21:55.710941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Thanks for reading.","metadata":{}}]}