{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **THIS IS NOT MY WORK**\n# **Please check out the original notebook by the awesome Darien Schettler!**\n\nhttps://www.kaggle.com/code/dschettler8845/uwm-gi-tract-image-segmentation-basic-submission","metadata":{}},{"cell_type":"markdown","source":"# To increase score from the original notebook, I changed the slice_px_map to include the slice_id\nWe need add slice_id to since it is a 3d map. Original was predicting on slices that have little to no 3 segments.","metadata":{}},{"cell_type":"markdown","source":"<br>\n\n<br><center><img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/27923/logos/header.png?t=2021-06-02-20-30-25\" width=100%></center>\n\n<h2 style=\"text-align: center; font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: underline; text-transform: none; letter-spacing: 2px; color: teal; background-color: #ffffff;\">UWM - GI Tract Image Segmentation Challenge</h2>\n<h5 style=\"text-align: center; font-family: Verdana; font-size: 12px; font-style: normal; font-weight: bold; text-decoration: None; text-transform: none; letter-spacing: 1px; color: black; background-color: #ffffff;\">CREATED BY: DARIEN SCHETTLER</h5>\n\n<br>\n\n---\n\n<br>\n\n<center><div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 18px;\">üõë &nbsp; WARNING:</b><br><br><b>THIS IS A WORK IN PROGRESS</b><br>\n</div></center>\n\n\n<center><div class=\"alert alert-block alert-warning\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 18px;\">üëè &nbsp; IF YOU FORK THIS OR FIND THIS HELPFUL &nbsp; üëè</b><br><br><b style=\"font-size: 22px; color: darkorange\">PLEASE UPVOTE!</b><br><br>This was a lot of work for me and while it may seem silly, it makes me feel appreciated when others like my work. üòÖ\n</div></center>\n\n\n","metadata":{}},{"cell_type":"code","source":"print(\"\\n... IMPORTS STARTING ...\\n\")\n\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t‚Äì TENSORFLOW VERSION: {tf.__version__}\");\nimport tensorflow_hub as tfhub; print(f\"\\t\\t‚Äì TENSORFLOW HUB VERSION: {tfhub.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t‚Äì TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t‚Äì NUMPY VERSION: {np.__version__}\");\nimport sklearn; print(f\"\\t\\t‚Äì SKLEARN VERSION: {sklearn.__version__}\");\nfrom sklearn.preprocessing import RobustScaler, PolynomialFeatures\nfrom pandarallel import pandarallel; pandarallel.initialize();\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom scipy.spatial import cKDTree\n\n# # RAPIDS\n# import cudf, cupy, cuml\n# from cuml.neighbors import NearestNeighbors\n# from cuml.manifold import TSNE, UMAP\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom datetime import datetime\nfrom glob import glob\nimport warnings\nimport requests\nimport hashlib\nimport imageio\nimport IPython\nimport sklearn\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport json\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.patches import Rectangle\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image, ImageEnhance\nimport matplotlib; print(f\"\\t\\t‚Äì MATPLOTLIB VERSION: {matplotlib.__version__}\");\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')\nimport plotly\nimport PIL\nimport cv2\n\nimport plotly.io as pio\nprint(pio.renderers)\n\ndef seed_it_all(seed=7):\n    \"\"\" Attempt to be Reproducible \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n    \nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:35:55.386715Z","iopub.execute_input":"2022-04-18T17:35:55.388318Z","iopub.status.idle":"2022-04-18T17:35:55.417817Z","shell.execute_reply.started":"2022-04-18T17:35:55.38825Z","shell.execute_reply":"2022-04-18T17:35:55.417141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... BASIC DATA SETUP STARTING ...\\n\\n\")\n\n# Open the training dataframe and display the initial dataframe\nDATA_DIR = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\nTRAIN_DIR = os.path.join(DATA_DIR, \"train\")\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV)\n\n# Get all training images\nall_train_images = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n\nprint(\"\\n... ORIGINAL TRAINING DATAFRAME... \\n\")\ndisplay(train_df)\n\nTEST_DIR = os.path.join(DATA_DIR, \"test\")\nSS_CSV   = os.path.join(DATA_DIR, \"sample_submission.csv\")\nss_df = pd.read_csv(SS_CSV)\n\n# Get all testing images if there are any\nall_test_images = glob(os.path.join(TEST_DIR, \"**\", \"*.png\"), recursive=True)\n\n# For debugging purposes when the test set hasn't been substituted we will know\nDEBUG=len(ss_df)==0\n\nif DEBUG:\n    TEST_DIR = TRAIN_DIR\n    all_test_images = all_train_images\n    ss_df = train_df.iloc[:10]\n    ss_df = ss_df[[\"id\", \"class\"]]\n    ss_df[\"predicted\"] = \"\"\n    \n\nprint(\"\\n\\n\\n... ORIGINAL SUBMISSION DATAFRAME... \\n\")    \ndisplay(ss_df)\n\nSF2LF = {\"lb\":\"Large Bowel\",\"sb\":\"Small Bowel\",\"st\":\"Stomach\"}\nLF2SF = {v:k for k,v in SF2LF.items()}\nprint(f\"\\n\\n\\n... ARE WE DEBUGGING: {DEBUG}... \\n\")\n\nprint(\"\\n... BASIC DATA SETUP FINISHED ...\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:35:55.419502Z","iopub.execute_input":"2022-04-18T17:35:55.419841Z","iopub.status.idle":"2022-04-18T17:35:56.840459Z","shell.execute_reply.started":"2022-04-18T17:35:55.419814Z","shell.execute_reply":"2022-04-18T17:35:56.839873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_filepath_from_partial_identifier(_ident, file_list):\n    return [x for x in file_list if _ident in x][0]\n\ndef df_preprocessing(df, globbed_file_list, is_test=False):\n    \"\"\" The preprocessing steps applied to get column information \"\"\"\n    # 1. Get Case-ID as a column (str and int)\n    df[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\n    df[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n    # 2. Get Day as a column\n    df[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\n    df[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n    # 3. Get Slice Identifier as a column\n    df[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\n    # 4. Get full file paths for the representative scans\n    df[\"_partial_ident\"] = (globbed_file_list[0].rsplit(\"/\", 4)[0]+\"/\"+ # /kaggle/input/uw-madison-gi-tract-image-segmentation/train/\n                           df[\"case_id_str\"]+\"/\"+ # .../case###/\n                           df[\"case_id_str\"]+\"_\"+df[\"day_num_str\"]+ # .../case###_day##/\n                           \"/scans/\"+df[\"slice_id\"]) # .../slice_#### \n    _tmp_merge_df = pd.DataFrame({\"_partial_ident\":[x.rsplit(\"_\",4)[0] for x in globbed_file_list], \"f_path\":globbed_file_list})\n    df = df.merge(_tmp_merge_df, on=\"_partial_ident\").drop(columns=[\"_partial_ident\"])\n\n    # 5. Get slice dimensions from filepath (int in pixels)\n    df[\"slice_h\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"slice_w\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n\n    # 6. Pixel spacing from filepath (float in mm)\n    df[\"px_spacing_h\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[3]))\n    df[\"px_spacing_w\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[4]))\n\n    if not is_test:\n        # 7. Merge 3 Rows Into A Single Row (As This/Segmentation-RLE Is The Only Unique Information Across Those Rows)\n        l_bowel_df = df[df[\"class\"]==\"large_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"lb_seg_rle\"})\n        s_bowel_df = df[df[\"class\"]==\"small_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"sb_seg_rle\"})\n        stomach_df = df[df[\"class\"]==\"stomach\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"st_seg_rle\"})\n        df = df.merge(l_bowel_df, on=\"id\", how=\"left\")\n        df = df.merge(s_bowel_df, on=\"id\", how=\"left\")\n        df = df.merge(stomach_df, on=\"id\", how=\"left\")\n        df = df.drop_duplicates(subset=[\"id\",]).reset_index(drop=True)\n        df[\"lb_seg_flag\"] = df[\"lb_seg_rle\"].apply(lambda x: not pd.isna(x))\n        df[\"sb_seg_flag\"] = df[\"sb_seg_rle\"].apply(lambda x: not pd.isna(x))\n        df[\"st_seg_flag\"] = df[\"st_seg_rle\"].apply(lambda x: not pd.isna(x))\n        df[\"n_segs\"] = df[\"lb_seg_flag\"].astype(int)+df[\"sb_seg_flag\"].astype(int)+df[\"st_seg_flag\"].astype(int)\n\n    # 8. Reorder columns to the a new ordering (drops class and segmentation as no longer necessary)\n    new_col_order = [\"id\", \"f_path\", \"n_segs\",\n                     \"lb_seg_rle\", \"lb_seg_flag\",\n                     \"sb_seg_rle\", \"sb_seg_flag\", \n                     \"st_seg_rle\", \"st_seg_flag\",\n                     \"slice_h\", \"slice_w\", \"px_spacing_h\", \n                     \"px_spacing_w\", \"case_id_str\", \"case_id\", \n                     \"day_num_str\", \"day_num\", \"slice_id\",]\n    if is_test: new_col_order.insert(1, \"class\")\n    new_col_order = [_c for _c in new_col_order if _c in df.columns]\n    df = df[new_col_order]\n    \n    return df\n\ntrain_df = df_preprocessing(train_df, all_train_images)\nss_df = df_preprocessing(ss_df, all_test_images, is_test=True)\n\ndisplay(train_df)\ndisplay(ss_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:35:56.841986Z","iopub.execute_input":"2022-04-18T17:35:56.84245Z","iopub.status.idle":"2022-04-18T17:35:58.859298Z","shell.execute_reply.started":"2022-04-18T17:35:56.842414Z","shell.execute_reply":"2022-04-18T17:35:58.858684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns: \n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    # Split the string by space, then convert it into a integer array\n    s = np.array(mask_rle.split(), dtype=int)\n\n    # Every even value is the start, every odd value is the \"run\" length\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n\n    # The image image is actually flattened since RLE is a 1D \"run\"\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n\n    # The color here is actually just any integer you want!\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n        \n    # Don't forget to change the image back to the original shape\n    return img.reshape(shape)\n\n# https://www.kaggle.com/namgalielei/which-reshape-is-used-in-rle\ndef rle_decode_top_to_bot_first(mask_rle, shape):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns:\n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape((shape[1], shape[0]), order='F').T  # Reshape from top -> bottom first\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    \"\"\" TBD\n    \n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n    \n    Returns: \n        run length as string formated\n    \"\"\"\n    \n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef open_gray16(_path, normalize=True, to_rgb=False):\n    \"\"\" Helper to open files \"\"\"\n    if normalize:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535., axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535.\n    else:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:35:58.880277Z","iopub.execute_input":"2022-04-18T17:35:58.880609Z","iopub.status.idle":"2022-04-18T17:35:58.898626Z","shell.execute_reply.started":"2022-04-18T17:35:58.880581Z","shell.execute_reply":"2022-04-18T17:35:58.897612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**For a dummy submission we will simply grab a valid RLE (with mask) from a similarily sized slice with similar pixel spacing**","metadata":{}},{"cell_type":"code","source":"slice_px_map = {}\nfor _, row in train_df[train_df.n_segs==3].groupby([\"slice_h\", \"slice_w\", \"px_spacing_h\", \"px_spacing_w\", \"slice_id\"])[[\"lb_seg_rle\", \"sb_seg_rle\", \"st_seg_rle\"]].first().reset_index().iterrows():\n    slice_px_map[f\"{row['slice_h']}-{row['slice_w']}-{row['px_spacing_h']}-{row['px_spacing_w']}-{row['slice_id']}-large_bowel\"] = row[\"lb_seg_rle\"]\n    slice_px_map[f\"{row['slice_h']}-{row['slice_w']}-{row['px_spacing_h']}-{row['px_spacing_w']}-{row['slice_id']}-small_bowel\"] = row[\"sb_seg_rle\"]\n    slice_px_map[f\"{row['slice_h']}-{row['slice_w']}-{row['px_spacing_h']}-{row['px_spacing_w']}-{row['slice_id']}-stomach\"] = row[\"st_seg_rle\"]\n    \nlist(slice_px_map.keys())[:15]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:35:58.899867Z","iopub.execute_input":"2022-04-18T17:35:58.900591Z","iopub.status.idle":"2022-04-18T17:35:58.967644Z","shell.execute_reply.started":"2022-04-18T17:35:58.900554Z","shell.execute_reply":"2022-04-18T17:35:58.967066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss_df[\"ident\"] = ss_df['slice_h'].astype(str)+\"-\"+ss_df['slice_w'].astype(str)+\"-\"+ss_df['px_spacing_h'].astype(str)+\"-\"+ss_df['px_spacing_w'].astype(str)+\"-\"+ss_df['slice_id'].astype(str)+'-'+ss_df[\"class\"].astype(str)\nss_df[\"predicted\"] = ss_df[\"ident\"].map(slice_px_map)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:35:58.968705Z","iopub.execute_input":"2022-04-18T17:35:58.969034Z","iopub.status.idle":"2022-04-18T17:35:58.979514Z","shell.execute_reply.started":"2022-04-18T17:35:58.968998Z","shell.execute_reply":"2022-04-18T17:35:58.978753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss_df = ss_df[[\"id\", \"class\", \"predicted\"]]\n\nss_df.to_csv(\"submission.csv\", index=False)\ndisplay(ss_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:35:58.980833Z","iopub.execute_input":"2022-04-18T17:35:58.981433Z","iopub.status.idle":"2022-04-18T17:35:59.000623Z","shell.execute_reply.started":"2022-04-18T17:35:58.981385Z","shell.execute_reply":"2022-04-18T17:35:58.999658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss_df[\"predicted\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:35:59.005389Z","iopub.execute_input":"2022-04-18T17:35:59.005918Z","iopub.status.idle":"2022-04-18T17:35:59.014416Z","shell.execute_reply.started":"2022-04-18T17:35:59.005868Z","shell.execute_reply":"2022-04-18T17:35:59.013572Z"},"trusted":true},"execution_count":null,"outputs":[]}]}