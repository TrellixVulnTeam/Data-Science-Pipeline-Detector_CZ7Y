{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as pltimg\nimport cv2\nfrom PIL import Image\nimport imageio\nfrom IPython.display import HTML","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:07.385624Z","iopub.execute_input":"2022-05-15T13:33:07.385934Z","iopub.status.idle":"2022-05-15T13:33:08.742482Z","shell.execute_reply.started":"2022-05-15T13:33:07.385853Z","shell.execute_reply":"2022-05-15T13:33:08.741565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Table of Contents\n\n\n\n\n* [Exploration](#section-one)\n\n\n* [Case](#case_section)\n    - [Case Selection](#case_selection)\n    - [Stacked Gif](#stacked_gif)\n    ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# Exploration","metadata":{}},{"cell_type":"code","source":"IMG_PATH = \"../input/uw-madison-gi-tract-image-segmentation/train/\"# folder are name as case\ntrain = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\ntest = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:33:08.74413Z","iopub.execute_input":"2022-05-15T13:33:08.744388Z","iopub.status.idle":"2022-05-15T13:33:09.325096Z","shell.execute_reply.started":"2022-05-15T13:33:08.744359Z","shell.execute_reply":"2022-05-15T13:33:09.324579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_pie(df, target_variable, figsize=(10, 10)):\n    print(df[target_variable].value_counts())\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.pie(df[target_variable].value_counts().values, labels=df[target_variable].value_counts().index, autopct='%1.2f%%', textprops={'fontsize': 10})\n    ax.axis('equal')\n    plt.title(target_variable)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:09.326125Z","iopub.execute_input":"2022-05-15T13:33:09.326342Z","iopub.status.idle":"2022-05-15T13:33:09.332618Z","shell.execute_reply.started":"2022-05-15T13:33:09.326315Z","shell.execute_reply":"2022-05-15T13:33:09.331792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# DATASET GLOBAL TRANSFORMATION\n\nitem_box = []\nfor item in train['id']:\n    items = str(item)\n    new_item = items.replace('_d', ' d').replace('_s', ' s')\n    clean = new_item.split()\n    item_box.append(clean)\n    \n\ncases = []\ndays = []\nslices = []\nfor item in item_box:\n    cases.append(item[0])\n    days.append(item[1])\n    slices.append(item[2])\n\nday_numbers = []\nfor item in days:\n    items = str(item)\n    new_item = items.replace('day', '')\n    day_numbers.append(int(new_item))\n    \nslice_numbers = []\nfor item in slices:\n    items = str(item)\n    new_item = items.replace('slice_', '')\n    slice_numbers.append(int(new_item))\n    \ncase_numbers = []\nfor item in cases:\n    items = str(item)\n    new_item = items.replace('case', '')\n    case_numbers.append(int(new_item))\n\n# I need to encode class\nstomach_class      = [1, 0, 0]\nlarge_bowel_class  = [0, 1, 0]\nsmall_bowel_class = [0, 0, 1]\n\nstomach_class_n      = 0\nlarge_bowel_class_n  = 1\nsmall_bowel_class_n  = 2\n\nencoded = []\nnumerical_encoded = []\n\nfor item in train['class']:\n    if str(item) == 'stomach':\n        encoded.append(stomach_class)\n        numerical_encoded.append(stomach_class_n)\n        \n    elif str(item) == 'large_bowel':\n        encoded.append(large_bowel_class)\n        numerical_encoded.append(large_bowel_class_n)\n        \n    elif str(item) == 'small_bowel':\n        encoded.append(small_bowel_class)\n        numerical_encoded.append(small_bowel_class_n)\n        \n    else:\n        print('somethings went wrong when encoding class')\n\n        \n        \n        \n# list to dataframes        \nclass_encode = pd.Series(encoded)\nclass_numerical_encode = pd.Series(numerical_encoded)\ncases = pd.Series(cases)\ncase_int = pd.Series(case_numbers)\ndays = pd.Series(days)\nday_number = pd.Series(day_numbers)\nslicing = pd.Series(slices)\nslice_number = pd.Series(slice_numbers)\n\ntrain['classencoded'] = class_encode\ntrain['classnumericalencoded'] = class_numerical_encode\ntrain['case'] = cases\ntrain['caseintegrer'] = case_int\ntrain['day'] = days\ntrain['daynumber'] = day_number\ntrain['slice'] = slicing\ntrain['slicenumber'] = slice_number\n\nprint(train.shape)\ntrain","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:33:09.334798Z","iopub.execute_input":"2022-05-15T13:33:09.335539Z","iopub.status.idle":"2022-05-15T13:33:10.615582Z","shell.execute_reply.started":"2022-05-15T13:33:09.335433Z","shell.execute_reply":"2022-05-15T13:33:10.614576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put Image in Dataset\n\n\ncases = train['case'].tolist()\ndays = train['day'].tolist()\nslices = train['slice'].tolist()\nscans = 'scans'\ncases = cases\npaths = []\nfiles_name = []\n\nfor i, item in enumerate(cases):\n    day = days[i]\n    folder_path = f'{IMG_PATH}{item}/{item}_{day}/{scans}/'\n    \n    arr = os.listdir(folder_path)\n    for file in arr:\n        if str(file[:int(len(str(slices[i])))]) == str(slices[i]):\n            img_path = f'{IMG_PATH}{item}/{item}_{day}/{scans}/{file}'\n            files_name.append(file)\n            paths.append(img_path)\n\nfiles = pd.Series(files_name)\npaths = pd.Series(paths)\n\ntrain['filename'] = files\ntrain['imagepath'] = paths\n\n\n# here all work but need some optimization\n\ndel cases\ndel days\ndel slices\ndel scans\ndel paths\ndel files_name\ndel files\n\ntrain.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-15T13:33:10.617318Z","iopub.execute_input":"2022-05-15T13:33:10.61791Z","iopub.status.idle":"2022-05-15T13:34:34.509752Z","shell.execute_reply.started":"2022-05-15T13:33:10.61787Z","shell.execute_reply":"2022-05-15T13:34:34.50879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"case_section\"></a>\n# Case\n","metadata":{}},{"cell_type":"code","source":"# I want to link segmentation organs by day then by slice and put mask on the same image with they're own segmentation and color\n# but first I need to check where are missing value and how many value is missing by case and also where in class\n\n\n\nplt.figure(figsize=(20, 20))\ncase = train.copy()\nprint(case['case'].value_counts(normalize=True).sort_values(ascending=False))\n#case['case'].value_counts(normalize=True).plot.pie();\n\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:34.512403Z","iopub.execute_input":"2022-05-15T13:34:34.512968Z","iopub.status.idle":"2022-05-15T13:34:34.625798Z","shell.execute_reply.started":"2022-05-15T13:34:34.512942Z","shell.execute_reply":"2022-05-15T13:34:34.624758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bigger case\ncase36 = case.loc[case['case'] == 'case36']#.set_index('daynumber')\n\n# Smaller Case\ncase116 = case.loc[case['case'] == 'case116'].set_index('daynumber')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:34.627276Z","iopub.execute_input":"2022-05-15T13:34:34.62755Z","iopub.status.idle":"2022-05-15T13:34:34.662784Z","shell.execute_reply.started":"2022-05-15T13:34:34.627528Z","shell.execute_reply":"2022-05-15T13:34:34.661823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"case_selection\"></a>\n# Case Selection","metadata":{}},{"cell_type":"code","source":"### Bigger Case\ncase36\n# % of missing value\n#print((case36.isna().sum() / case36.shape[0]).sort_values(ascending=False))\n\ncase36_class = case36['class'].to_list()\ncase36_nan_class = []\ncase36_nan_indexes = []\nfor i, item in enumerate(case36['segmentation']):\n    if str(item) == 'nan':\n        #print(case36_class[i])\n        case36_nan_class.append(case36_class[i])\n        \n\n#nan_class = pd.Series(case36_nan_class)\n\n#print(nan_class.value_counts(normalize=True).sort_values(ascending=False), '\\n\\n')\n#plt.figure(figsize=(8, 8))\n#plt.title(f'Case36:  % Missing Value')\n#nan_class.value_counts(normalize=True).sort_values(ascending=False).plot.pie();","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:34.664143Z","iopub.execute_input":"2022-05-15T13:34:34.664862Z","iopub.status.idle":"2022-05-15T13:34:34.672558Z","shell.execute_reply.started":"2022-05-15T13:34:34.664828Z","shell.execute_reply":"2022-05-15T13:34:34.671984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ","metadata":{"execution":{"iopub.status.busy":"2022-04-29T01:40:46.84555Z","iopub.execute_input":"2022-04-29T01:40:46.846558Z","iopub.status.idle":"2022-04-29T01:40:46.853068Z","shell.execute_reply.started":"2022-04-29T01:40:46.846516Z","shell.execute_reply":"2022-04-29T01:40:46.85248Z"}}},{"cell_type":"code","source":"pie = case36.drop(['id'], axis=1)\ncreate_pie(pie, 'class')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:34.673642Z","iopub.execute_input":"2022-05-15T13:34:34.674399Z","iopub.status.idle":"2022-05-15T13:34:35.050831Z","shell.execute_reply.started":"2022-05-15T13:34:34.674355Z","shell.execute_reply":"2022-05-15T13:34:35.049894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case36.shape","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:35.054283Z","iopub.execute_input":"2022-05-15T13:34:35.054631Z","iopub.status.idle":"2022-05-15T13:34:35.05987Z","shell.execute_reply.started":"2022-05-15T13:34:35.054603Z","shell.execute_reply":"2022-05-15T13:34:35.059047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case36_nanless = case36.copy()\ncase36_nanless.dropna(axis=0,inplace=True)\ncase36_nanless.shape","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:35.061362Z","iopub.execute_input":"2022-05-15T13:34:35.061599Z","iopub.status.idle":"2022-05-15T13:34:35.084774Z","shell.execute_reply.started":"2022-05-15T13:34:35.061567Z","shell.execute_reply":"2022-05-15T13:34:35.084233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(25, 6))\nplt.scatter(case36_nanless['slicenumber'], case36_nanless['daynumber']);\n\n#slicenumber\n#daynumber","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:35.086012Z","iopub.execute_input":"2022-05-15T13:34:35.086297Z","iopub.status.idle":"2022-05-15T13:34:35.247472Z","shell.execute_reply.started":"2022-05-15T13:34:35.086271Z","shell.execute_reply":"2022-05-15T13:34:35.246642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncase36_nanless_day6 = case36_nanless.copy()\ncase36_nanless_day6 = case36_nanless_day6.loc[case36_nanless_day6['daynumber'] == 6]\n\ncase36_nanless_day6\n\nplt.figure(figsize=(30, 6))\nplt.scatter(case36_nanless_day6['slicenumber'], case36_nanless_day6['classnumericalencoded']);\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:35.248622Z","iopub.execute_input":"2022-05-15T13:34:35.248874Z","iopub.status.idle":"2022-05-15T13:34:35.441047Z","shell.execute_reply.started":"2022-05-15T13:34:35.248851Z","shell.execute_reply":"2022-05-15T13:34:35.440283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here I have 2 Idea \n#\n# First:\n# category 0 can be on the first layer then disapear for the orther but still here,  meaning of this Idea all Data at this rate is correct and all Label are here\n\n# Second:\n# category 0 can be on the first layer and are not drawing and I keep data between 55 -> 61,    I don't like this Idea","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:35.44214Z","iopub.execute_input":"2022-05-15T13:34:35.442333Z","iopub.status.idle":"2022-05-15T13:34:35.447583Z","shell.execute_reply.started":"2022-05-15T13:34:35.442308Z","shell.execute_reply":"2022-05-15T13:34:35.446503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = pltimg.imread('../input/uw-madison-gi-tract-image-segmentation/train/case36/case36_day6/scans/slice_0056_266_266_1.50_1.50.png')\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef mask2rle(img):\n    \"\"\"\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formatted\n    \"\"\"\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef rle2mask(mask_rle: str, label=1, shape=img.shape):\n    \"\"\"\n    mask_rle: run-length as string formatted (start length)\n    shape: (height,width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n\n    \"\"\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = label\n    return img.reshape(shape)  # Needed to align to RLE direction","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:35.448895Z","iopub.execute_input":"2022-05-15T13:34:35.449119Z","iopub.status.idle":"2022-05-15T13:34:35.479162Z","shell.execute_reply.started":"2022-05-15T13:34:35.449091Z","shell.execute_reply":"2022-05-15T13:34:35.478654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case36_nanless_day6_slice56 = case36_nanless_day6.copy()\ncase36_nanless_day6_slice56 = case36_nanless_day6_slice56.loc[case36_nanless_day6_slice56['slicenumber'] == 56]\n\ncase36_nanless_day6_slice56\n\n\n\n","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:35.480288Z","iopub.execute_input":"2022-05-15T13:34:35.480601Z","iopub.status.idle":"2022-05-15T13:34:35.498175Z","shell.execute_reply.started":"2022-05-15T13:34:35.480575Z","shell.execute_reply":"2022-05-15T13:34:35.497407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncase36_nanless_day6_slice56_segmentation = case36_nanless_day6_slice56['segmentation'].tolist()\ncase36_nanless_day6_slice56_imgpath = case36_nanless_day6_slice56['imagepath'].tolist()\ncolumns = 3","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:35.499429Z","iopub.execute_input":"2022-05-15T13:34:35.499617Z","iopub.status.idle":"2022-05-15T13:34:35.506498Z","shell.execute_reply.started":"2022-05-15T13:34:35.499592Z","shell.execute_reply":"2022-05-15T13:34:35.505678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25, 25))\n\nfor i, mask in enumerate(case36_nanless_day6_slice56_segmentation):\n    \n    plt.subplot(int(len(case36_nanless_day6_slice56_segmentation) / columns + 1), columns, i + 1)\n    #rle2mask(mask_rle: str, label=1, shape=img.shape):\n    img = cv2.imread(f'{case36_nanless_day6_slice56_imgpath[i]}')\n    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    \n    # Now create a mask and create its inverse mask also\n    mask = rle2mask(str(mask), label=1, shape=gray.shape)\n    #mask_inv = cv2.bitwise_not(mask)\n\n    \n    \n    # Now black-out the area\n    #img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n    img1_bg = gray\n    #plt.figure(figsize=(28, 8))\n    #plt.imshow(img1_bg, cmap='gray')\n    \n    \n    # Take only region \n    img2_fg = cv2.bitwise_and(gray,gray,mask = mask)\n    #plt.figure(figsize=(28, 8))\n    #plt.imshow(img2_fg, cmap='gray')\n    \n    \n    #modify the main image\n    dst = cv2.add(img1_bg,img2_fg)\n\n    #plt.figure(figsize=(28, 8))\n    #plt.imshow(dst,cmap = \"mako\")\n    result = np.hstack((img1_bg,img2_fg))\n    plt.axis(\"off\")\n    plt.imshow(result, cmap='mako')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:35:04.400278Z","iopub.execute_input":"2022-05-15T13:35:04.400574Z","iopub.status.idle":"2022-05-15T13:35:04.702539Z","shell.execute_reply.started":"2022-05-15T13:35:04.400553Z","shell.execute_reply":"2022-05-15T13:35:04.701567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncase36_nanless_day6_rle = case36_nanless_day6['segmentation'].tolist()\ncase36_nanless_day6_imgpath = case36_nanless_day6['imagepath'].tolist()\ncase36_nanless_day6_class = case36_nanless_day6['class'].tolist()\n\nslices = case36_nanless_day6['slicenumber']\n\nlast_slice = [0]\n\nframes = []\npartial_frames = []\ncolumns = 3\nfor i, item in enumerate(slices):\n    #print(item)\n    if int(item) == int(last_slice[-1]) or int(item) == 0:\n        partial_frames.append(f'{case36_nanless_day6_class[i]}')\n        \n        \n    else:\n        if i > 0:\n            partial_frames.append(f'{case36_nanless_day6_class[i]:-<30}slice: {item}')\n            frames.append(partial_frames)\n            partial_frames = []\n            \n    last_slice.append(item)\n    \nframes # data distribution for day by slice for case 36\n#print(f'{col :-<50} {train[col].unique()}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:36.050804Z","iopub.execute_input":"2022-05-15T13:34:36.051087Z","iopub.status.idle":"2022-05-15T13:34:36.064279Z","shell.execute_reply.started":"2022-05-15T13:34:36.051057Z","shell.execute_reply":"2022-05-15T13:34:36.063873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize=(25, 400))\n#columns = 3\ncase36_nanless_day6_rle = case36_nanless_day6['segmentation'].tolist()\ncase36_nanless_day6_imgpath = case36_nanless_day6['imagepath'].tolist()\ncase36_nanless_day6_class = case36_nanless_day6['class'].tolist()\nslices = case36_nanless_day6['slicenumber']\n\nlast_slice = [0]\nframes = []\npartial_frames = []\n\nfor i, item in enumerate(slices):\n    #plt.subplot(int(len(case36_nanless_day6_rle) / columns + 1), columns, i + 1)\n    \n    color_img = cv2.imread(f'{case36_nanless_day6_imgpath[i]}')\n    gray = cv2.cvtColor(color_img,cv2.COLOR_BGR2GRAY)\n    \n    # Now create a mask \n    mask = rle2mask(str(case36_nanless_day6_rle[i]), label=1, shape=gray.shape)\n    \n    if int(item) == int(last_slice[-1]) or int(item) == 0:\n        foreground = cv2.bitwise_and(gray,gray,mask = mask)\n        partial_frames.append(foreground)\n        \n        \n    else:\n        if i > 0:\n            foreground = cv2.bitwise_and(gray,gray,mask = mask)\n            partial_frames.append(foreground)\n\n            frames.append(partial_frames)\n            partial_frames = []\n            \n    last_slice.append(item)\n    \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:36.065191Z","iopub.execute_input":"2022-05-15T13:34:36.065479Z","iopub.status.idle":"2022-05-15T13:34:36.935106Z","shell.execute_reply.started":"2022-05-15T13:34:36.065456Z","shell.execute_reply":"2022-05-15T13:34:36.934444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from frames create foreground frame\n\n\n#plt.figure(figsize=(25, 400))\n\nforeground_frames = []\ncolumns = 3\nfor i, item in enumerate(frames):\n    #plt.subplot(int(len(frames) / columns + 1), columns, i + 1)\n    #print(len(item))\n    if len(item) == 1:\n        #plt.imshow(item[0], cmap = 'mako')\n        foreground_frames.append(item[0])\n        \n    elif len(item) == 2:\n        foreground = item[0] + item[1]\n        #plt.imshow(foreground, cmap = 'mako')\n        foreground_frames.append(foreground)\n        \n    elif len(item) == 3:\n        foreground = item[0] + item[1]\n        foreground = foreground  + item[2]\n        #plt.imshow(foreground, cmap = 'mako')\n        foreground_frames.append(foreground)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:36.936033Z","iopub.execute_input":"2022-05-15T13:34:36.936216Z","iopub.status.idle":"2022-05-15T13:34:36.944561Z","shell.execute_reply.started":"2022-05-15T13:34:36.936188Z","shell.execute_reply":"2022-05-15T13:34:36.943606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_rle = train['segmentation'].tolist()\n#train_imgpath = train['imagepath'].tolist()\n#train_class = train['class'].tolist()\n#slices = train['slicenumber']\n#slices = slices[:3000]\n\n\ncase36_nanless_day6_rle     = case36_nanless_day6['segmentation'].tolist()\ncase36_nanless_day6_imgpath = case36_nanless_day6['imagepath'].tolist()\ncase36_nanless_day6_class   = case36_nanless_day6['class'].tolist()\nslices                      = case36_nanless_day6['slicenumber']\n\n\nlast_slice = [0]\n\n\nslice_image = []\nslice_numbers = []\nframes = []\npartial_frames = []\n\nforeground_frames = []\npartial_foreground_frames = []\n#plt.figure(figsize=(25, 25))\n\n\nr = [100,0,0]\ng = [0,100,0]\nb = [0,0,100]\n\n\n#SIZE = 128\nSIZE = 256\n\ncolumns = 3\nfor i, item in enumerate(slices):\n    # put color on mask\n    if str(case36_nanless_day6_class[i]) == \"stomach\":\n        color = r\n    elif str(case36_nanless_day6_class[i]) == \"large_bowel\":\n        color = g\n    elif str(case36_nanless_day6_class[i]) == \"small_bowel\":\n        color = b\n    else:\n        pass\n    \n    \n    \n    #plt.subplot(int(len(slices) / columns + 1), columns, i + 1)\n    # load images\n    color_img = cv2.imread(f'{case36_nanless_day6_imgpath[i]}', 1)\n    gray = pltimg.imread(f'{case36_nanless_day6_imgpath[i]}')\n\n    # Now create a mask and create its inverse mask also\n    mask = rle2mask(str(case36_nanless_day6_rle[i]), label=1, shape=gray.shape)\n    #foreground = cv2.bitwise_and(gray,gray,mask = mask)\n    foreground = cv2.bitwise_and(color_img,color_img,mask = mask)\n    \n    # resize our image with pillow library\n    p_mask = Image.fromarray(mask)\n    p_gray = Image.fromarray(color_img)\n    p_foreground = Image.fromarray(foreground)\n    \n    colored_mask = cv2.bitwise_and(color_img,color_img,mask = mask)\n    colored_mask[mask >= 1] = color\n    p_mask = Image.fromarray(colored_mask)\n    \n    new_size = (SIZE, SIZE)\n    \n    new_gray = color_img.copy()\n    new_gray = p_gray.resize(new_size)\n    \n    new_mask = colored_mask.copy()\n    new_mask = p_mask.resize(new_size)\n    \n    new_foreground = foreground.copy()\n    new_foreground = p_foreground.resize(new_size)\n    \n    \n    \n    # convert them into a numpy array\n    np_mask = np.array(new_mask)\n    np_gray = np.array(new_gray)\n    np_foreground = np.array(new_foreground)\n    \n    if int(item) == int(last_slice[-1]) or int(item) == 0:\n        #partial_frames.append(mask)\n        mask = np_mask.reshape(np_mask.shape[0], np_mask.shape[1], np_mask.shape[2])\n        partial_frames.append(np.array(mask))\n        \n        foreground = np_foreground.reshape(np_foreground.shape[0], np_foreground.shape[1], np_foreground.shape[2])\n        partial_foreground_frames.append(np.array(foreground))\n        \n        \n    else:\n        if i > 0:\n            mask = np_mask.reshape(np_mask.shape[0], np_mask.shape[1], np_mask.shape[2])\n            partial_frames.append(np.array(mask))\n            frames.append(partial_frames)\n            partial_frames = []\n        \n            foreground = np_foreground.reshape(np_foreground.shape[0], np_foreground.shape[1], np_foreground.shape[2])\n            foreground_frames.append(partial_foreground_frames)\n            partial_foreground_frames = []\n            \n            gray = np_gray.reshape(np_gray.shape[0], np_gray.shape[1], np_gray.shape[2])\n            slice_image.append(gray)\n            \n            slice_numbers.append(item)\n            \n    last_slice.append(item)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:36.945837Z","iopub.execute_input":"2022-05-15T13:34:36.946076Z","iopub.status.idle":"2022-05-15T13:34:38.622349Z","shell.execute_reply.started":"2022-05-15T13:34:36.946046Z","shell.execute_reply":"2022-05-15T13:34:38.621215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image = slice_image.copy()\ntrain_mask = frames.copy()\ntrain_number = slice_numbers.copy()\ntrain_foreground = foreground_frames.copy()\n\nprint(len(train_image))\nprint(len(train_mask))\nprint(len(train_number))\nprint(len(train_foreground))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:38.623643Z","iopub.execute_input":"2022-05-15T13:34:38.62383Z","iopub.status.idle":"2022-05-15T13:34:38.630144Z","shell.execute_reply.started":"2022-05-15T13:34:38.623808Z","shell.execute_reply":"2022-05-15T13:34:38.629402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_mask = []\n\n#plt.figure(figsize=(25, 25))\nfor i, mask in enumerate(train_mask):# and i <= 20:\n    #plt.subplot(int(len(train_image) / columns + 1), columns, i + 1)\n    \n    #print(len(mask))\n    \n    if len(mask) == 1:\n        dst = train_mask[i][0]\n        #plt.imshow(train_mask[i][0])\n        stacked_mask.append(np.array(dst))\n        \n    elif len(mask) == 2:\n        dst = cv2.add(train_mask[i][0],train_mask[i][1])\n        #plt.imshow(dst)\n        stacked_mask.append(np.array(dst))\n        \n    elif len(mask) == 3:\n        dst = cv2.add(train_mask[i][0],train_mask[i][1], train_mask[i][2])\n        #plt.imshow(dst)\n        stacked_mask.append(np.array(dst))\n        \nstacked_foreground = []\n\n#plt.figure(figsize=(25, 25))\nfor i, mask in enumerate(train_foreground):# and i <= 20:\n    #plt.subplot(int(len(train_image) / columns + 1), columns, i + 1)\n    \n    #print(len(mask))\n    \n    if len(mask) == 1:\n        dst = train_foreground[i][0]\n        #plt.imshow(train_mask[i][0])\n        stacked_foreground.append(np.array(dst))\n        \n    elif len(mask) == 2:\n        dst = cv2.add(train_foreground[i][0],train_foreground[i][1])\n        #plt.imshow(dst)\n        stacked_foreground.append(np.array(dst))\n        \n    elif len(mask) == 3:\n        dst = cv2.add(train_foreground[i][0],train_foreground[i][1], train_foreground[i][2])\n        #plt.imshow(dst)\n        stacked_foreground.append(np.array(dst))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:38.631045Z","iopub.execute_input":"2022-05-15T13:34:38.631357Z","iopub.status.idle":"2022-05-15T13:34:38.66015Z","shell.execute_reply.started":"2022-05-15T13:34:38.631323Z","shell.execute_reply":"2022-05-15T13:34:38.658949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain = train_image.copy()\ngif_frames = []\n\nfor i, image in enumerate(stacked_foreground):\n    img = train_image[i]\n    mask = stacked_mask[i]\n    foreground = stacked_foreground[i]\n    \n    \n    gray_mask = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    gray_foreground = cv2.cvtColor(foreground,cv2.COLOR_BGR2GRAY)\n    #np.expand_dims(gray)\n    gray_img = gray_img.reshape(gray_img.shape[0], gray_img.shape[1], 1)\n    gray_mask= gray_mask.reshape(gray_mask.shape[0], gray_mask.shape[1], 1)\n    gray_foreground= gray_foreground.reshape(gray_foreground.shape[0], gray_foreground.shape[1], 1)\n    '''print(gray_img.shape)\n    print(gray_mask.shape)\n    print(gray_foreground.shape)'''\n    \n    frames = np.hstack((gray_foreground, gray_img, gray_mask))\n    gif_frames.append(frames)\n    '''plt.imshow(frames)\n    plt.show()'''","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:38.661832Z","iopub.execute_input":"2022-05-15T13:34:38.662287Z","iopub.status.idle":"2022-05-15T13:34:38.682761Z","shell.execute_reply.started":"2022-05-15T13:34:38.662234Z","shell.execute_reply":"2022-05-15T13:34:38.682093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = []\nfor i, item in enumerate(gif_frames):\n    #print(len(item))\n    plt.axis(\"off\")\n    plt.imshow(item)\n    \n    # create file name and append it to a list\n    filename = f'{i}.png'\n    filenames.append(filename)\n    \n    # save frame\n    plt.savefig(filename)\n    plt.close()\n    \n    \n \n\n# build gif\nwith imageio.get_writer('stacked.gif', mode='I') as writer:\n    for filename in filenames:\n        image = imageio.imread(filename)\n        writer.append_data(image)\n        \n# Remove files\nfor filename in set(filenames):\n    os.remove(filename)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:37:08.600314Z","iopub.execute_input":"2022-05-15T13:37:08.601096Z","iopub.status.idle":"2022-05-15T13:37:14.318137Z","shell.execute_reply.started":"2022-05-15T13:37:08.60106Z","shell.execute_reply":"2022-05-15T13:37:14.317009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"stacked_gif\"></a>\n# Stacked Gif","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/subinium/how-to-use-matplotlib-animations-in-kaggle\n\n\nHTML('<img src=\"./stacked.gif\" />')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:37:19.325209Z","iopub.execute_input":"2022-05-15T13:37:19.325542Z","iopub.status.idle":"2022-05-15T13:37:19.330128Z","shell.execute_reply.started":"2022-05-15T13:37:19.32552Z","shell.execute_reply":"2022-05-15T13:37:19.329206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Smaller Case\ncase116\n(case116.isna().sum() / case116.shape[0]).sort_values(ascending=False)\n\n\n\ncase116_class = case116['class'].to_list()\ncase116_nan_class = []\ncase116_nan_indexes = []\nfor i, item in enumerate(case116['segmentation']):\n    if str(item) == 'nan':\n        #print(case36_class[i])\n        case116_nan_class.append(case116_class[i])\n        \n\nnan_class = pd.Series(case116_nan_class)\n\nprint(nan_class.value_counts(normalize=True).sort_values(ascending=False), '\\n\\n')\nplt.figure(figsize=(8, 8))\nplt.title(f'Case116:  % Missing Value')\nnan_class.value_counts(normalize=True).sort_values(ascending=False).plot.pie();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T13:34:46.797414Z","iopub.execute_input":"2022-05-15T13:34:46.79763Z","iopub.status.idle":"2022-05-15T13:34:46.926798Z","shell.execute_reply.started":"2022-05-15T13:34:46.797596Z","shell.execute_reply":"2022-05-15T13:34:46.925971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}