{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as pltimg\nimport cv2\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T21:30:52.276975Z","iopub.execute_input":"2022-04-26T21:30:52.278139Z","iopub.status.idle":"2022-04-26T21:30:52.28393Z","shell.execute_reply.started":"2022-04-26T21:30:52.278058Z","shell.execute_reply":"2022-04-26T21:30:52.282904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_PATH = \"../input/uw-madison-gi-tract-image-segmentation/train/\"# folder are name as case","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T21:30:52.355405Z","iopub.execute_input":"2022-04-26T21:30:52.3565Z","iopub.status.idle":"2022-04-26T21:30:52.360543Z","shell.execute_reply.started":"2022-04-26T21:30:52.356405Z","shell.execute_reply":"2022-04-26T21:30:52.359842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npd.set_option('display.max_column', 90)\npd.set_option('display.max_row', 200)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T21:30:52.425999Z","iopub.execute_input":"2022-04-26T21:30:52.426599Z","iopub.status.idle":"2022-04-26T21:30:52.43248Z","shell.execute_reply.started":"2022-04-26T21:30:52.426559Z","shell.execute_reply":"2022-04-26T21:30:52.4315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\ntest = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\nprint(train.shape)\nprint(train.dtypes.value_counts())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T21:30:52.489075Z","iopub.execute_input":"2022-04-26T21:30:52.489497Z","iopub.status.idle":"2022-04-26T21:30:52.903927Z","shell.execute_reply.started":"2022-04-26T21:30:52.489434Z","shell.execute_reply":"2022-04-26T21:30:52.90259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> Data Exploratory </h1>\n<ul>\n    <h2> Objectif:</h2>\n    <br>\n    <li><h3> understand our dataset</h3></li>\n    <br><h2>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If I understand what I need to do is: First Identify organs and Second put a binary mask on it   </h2><br>\n    <h2>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;So maybe I can use some of no segmentation part as testing Image   </h2><br>\n    <li><h3> thinking of basic model</h3></li>\n</ul>\n<br>\n<br>\n<h1> CheckList de base </h1>\n<br>\n<ul>\n    <h2>Annalyse de Forme:</h2>\n    <br>\n    <li><h3> variable Target:</h3></li>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;---> From Class --> segment organ</h3>\n    <li><h3> Nombre de ligne et de colonne:</h3></li>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--->115488 rows × 3 columns ----> with NaN value</h3>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--->columns created: case \tday \tslice \tfilename \timagepath \ttumor</h3>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--->rows deleted: no segmented image</h3>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--->33913 rows × 9 columns ----> after process value</h3><br>\n    <li><h3> Type de Variable:</h3></li>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--->object    3</h3>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;. . .dtype: int64</h3><br>\n    <li><h3> Annalyse des donnée manquantes:</h3></li>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--->segmentation    0.70635 % Missing Value</h3><br>\n</ul>\n<br>\n<br>\n<ul>\n    <h2> Annalyse de fond:</h2><br>\n    <li><h3> Visualisation de la Target</h3></li>\n    <li><h3> Signification des variables:</h3></li>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--->segmentation    ROI = organ position rle_encoded mask</h3>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--->class    Contain 3 Body Region</h3>\n    <ul>\n        <li>---> large_bowel    0.415327 %</li>\n        <li>---> small_bowel    0.330286 %</li>\n        <li>---> stomach        0.254386 %</li>\n        <li>---> * large_bowel    14085 segments</li>\n        <li>---> * small_bowel    11201 segments</li>\n        <li>---> * stomach         8627 segments</li>\n    </ul>\n    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--->id    Contain Case evolution througth day</h3><br><br>\n    <li><h3> Relation Variable / Target</h3></li>\n    <li><h3> Annalyse des donnée manquantes</h3></li>\n</ul>\n\n\n*     segmentation    0.70635\n*     id              0.00000\n*     class           0.00000\n  \n*     0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    0.70635 ----> no organs segmented\n*     1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    0.29365 ----> organ segmented\n\n\n\n<ul>\n    <li></li>\n    <li></li>\n    <li></li>\n</ul>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25, 25))\nsns.heatmap(train.isna(), cbar=False);","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:30:52.906108Z","iopub.execute_input":"2022-04-26T21:30:52.906821Z","iopub.status.idle":"2022-04-26T21:30:55.437332Z","shell.execute_reply.started":"2022-04-26T21:30:52.906736Z","shell.execute_reply":"2022-04-26T21:30:55.436699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train.isna().sum() / train.shape[0]).sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:30:55.438422Z","iopub.execute_input":"2022-04-26T21:30:55.438668Z","iopub.status.idle":"2022-04-26T21:30:55.467246Z","shell.execute_reply.started":"2022-04-26T21:30:55.438638Z","shell.execute_reply":"2022-04-26T21:30:55.466386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(28, 8))\ntrain['class'].value_counts(normalize=True).plot.pie();","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:30:55.47056Z","iopub.execute_input":"2022-04-26T21:30:55.470945Z","iopub.status.idle":"2022-04-26T21:30:55.608379Z","shell.execute_reply.started":"2022-04-26T21:30:55.470907Z","shell.execute_reply":"2022-04-26T21:30:55.607421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# DATASET GLOBAL TRANSFORMATION\n\nitem_box = []\nfor item in train['id']:\n    items = str(item)\n    new_item = items.replace('_d', ' d').replace('_s', ' s')\n    clean = new_item.split()\n    item_box.append(clean)\n    \n\ncases = []\ndays = []\nslices = []\nfor item in item_box:\n    cases.append(item[0])\n    days.append(item[1])\n    slices.append(item[2])\n\nday_numbers = []\nfor item in days:\n    items = str(item)\n    new_item = items.replace('day', '')\n    day_numbers.append(int(new_item))\n    \nslice_numbers = []\nfor item in slices:\n    items = str(item)\n    new_item = items.replace('slice_', '')\n    slice_numbers.append(int(new_item))\n    \ncase_numbers = []\nfor item in cases:\n    items = str(item)\n    new_item = items.replace('case', '')\n    case_numbers.append(int(new_item))\n\n# I need to encode class\nstomach_class      = [1, 0, 0]\nlarge_bowel_class  = [0, 1, 0]\nsmall_bowel_class = [0, 0, 1]\n\nstomach_class_n      = 0\nlarge_bowel_class_n  = 1\nsmall_bowel_class_n  = 2\n\nencoded = []\nnumerical_encoded = []\n\nfor item in train['class']:\n    if str(item) == 'stomach':\n        encoded.append(stomach_class)\n        numerical_encoded.append(stomach_class_n)\n        \n    elif str(item) == 'large_bowel':\n        encoded.append(large_bowel_class)\n        numerical_encoded.append(large_bowel_class_n)\n        \n    elif str(item) == 'small_bowel':\n        encoded.append(small_bowel_class)\n        numerical_encoded.append(small_bowel_class_n)\n        \n    else:\n        print('somethings went wrong when encoding class')\n\n        \n        \n        \n# list to dataframes        \nclass_encode = pd.Series(encoded)\nclass_numerical_encode = pd.Series(numerical_encoded)\ncases = pd.Series(cases)\ncase_int = pd.Series(case_numbers)\ndays = pd.Series(days)\nday_number = pd.Series(day_numbers)\nslicing = pd.Series(slices)\nslice_number = pd.Series(slice_numbers)\n\ntrain['classencoded'] = class_encode\ntrain['classnumericalencoded'] = class_numerical_encode\ntrain['case'] = cases\ntrain['caseintegrer'] = case_int\ntrain['day'] = days\ntrain['daynumber'] = day_number\ntrain['slice'] = slicing\ntrain['slicenumber'] = slice_number\n\nprint(train.shape)\ntrain","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T21:30:55.610039Z","iopub.execute_input":"2022-04-26T21:30:55.610364Z","iopub.status.idle":"2022-04-26T21:30:56.494788Z","shell.execute_reply.started":"2022-04-26T21:30:55.610322Z","shell.execute_reply":"2022-04-26T21:30:56.493867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i, col in enumerate(train.select_dtypes('int')):\n    plt.figure(figsize=(5, 5));\n    sns.distplot(train[col]);","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:04:25.878387Z","iopub.execute_input":"2022-04-26T22:04:25.878693Z","iopub.status.idle":"2022-04-26T22:04:28.678131Z","shell.execute_reply.started":"2022-04-26T22:04:25.878663Z","shell.execute_reply":"2022-04-26T22:04:28.676874Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(28, 8))\ntrain['case'].value_counts(normalize=True).plot.pie()\n\n#print(train['case'].value_counts(normalize=True).sort_values(ascending=False))","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-04-26T21:30:56.522865Z","iopub.execute_input":"2022-04-26T21:30:56.52309Z","iopub.status.idle":"2022-04-26T21:30:57.431233Z","shell.execute_reply.started":"2022-04-26T21:30:56.523064Z","shell.execute_reply":"2022-04-26T21:30:57.430616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"our Distribution of case seems to be homogenous","metadata":{}},{"cell_type":"markdown","source":"Now let's try to open up some images, and add ImagePaths to our dataframe\n\nIMG_PATH = \"../input/uw-madison-gi-tract-image-segmentation/train/\"\n\n\n    ---- train:\n    ---------- case101\n    ------------------ case101_day20\n    -------------------------------- scans\n    ------------------------------------- slice\n    ------------------------------------- slice\n    ------------------------------------- slice\n    ------------------------------------- ...\n","metadata":{}},{"cell_type":"code","source":"\ncases = train['case'].tolist()\ndays = train['day'].tolist()\nslices = train['slice'].tolist()\nscans = 'scans'\n\npaths = []\nfiles_name = []\n\nfor i, item in enumerate(cases):\n    day = days[i]\n    folder_path = f'{IMG_PATH}{item}/{item}_{day}/{scans}/'\n    \n    arr = os.listdir(folder_path)\n    for file in arr:\n        if str(file[:int(len(str(slices[i])))]) == str(slices[i]):\n            img_path = f'{IMG_PATH}{item}/{item}_{day}/{scans}/{file}'\n            files_name.append(file)\n            paths.append(img_path)\n\n\nfiles = pd.Series(files_name)\npaths = pd.Series(paths)\n\ntrain['filename'] = files\ntrain['imagepath'] = paths\n\n\n# here all work but need some optimization\n\ndel cases\ndel days\ndel slices\ndel scans\ndel paths\ndel files_name\ndel files\n\ntrain","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-26T21:30:57.432165Z","iopub.execute_input":"2022-04-26T21:30:57.432483Z","iopub.status.idle":"2022-04-26T21:31:59.389114Z","shell.execute_reply.started":"2022-04-26T21:30:57.432454Z","shell.execute_reply":"2022-04-26T21:31:59.388203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new thinking NaN mean no tumor ?    so if nan = 0 else = 1 ?      WRONG NaN mean NO SEGMENT\n#train.dropna(axis=0, subset=['segmentation'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:31:59.390269Z","iopub.execute_input":"2022-04-26T21:31:59.390577Z","iopub.status.idle":"2022-04-26T21:31:59.394605Z","shell.execute_reply.started":"2022-04-26T21:31:59.390536Z","shell.execute_reply":"2022-04-26T21:31:59.393685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create new column tumor  0 = NO Tumor          1 = !! Tumor\ncheck = train['segmentation'].tolist()\ntumors = []\n\nfor i, item in enumerate(check):\n    if str(item) == 'NaN' or str(item) == 'nan':\n        #print(0)\n        tumors.append('0')\n    else:\n        #print(1)\n        tumors.append('1')\n        \n        \ntumors = pd.Series(tumors)\ntrain['tumor'] = tumors\n\ndel tumors\n\ntrain","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-26T21:31:59.396668Z","iopub.execute_input":"2022-04-26T21:31:59.397216Z","iopub.status.idle":"2022-04-26T21:31:59.509565Z","shell.execute_reply.started":"2022-04-26T21:31:59.39718Z","shell.execute_reply":"2022-04-26T21:31:59.508747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train['tumor'].value_counts(normalize=True).sort_values(ascending=False))\n\nplt.figure(figsize=(28, 8))\ntrain['tumor'].value_counts(normalize=True).plot.pie();","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:31:59.511027Z","iopub.execute_input":"2022-04-26T21:31:59.51151Z","iopub.status.idle":"2022-04-26T21:31:59.616394Z","shell.execute_reply.started":"2022-04-26T21:31:59.511467Z","shell.execute_reply":"2022-04-26T21:31:59.615717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*  as we can see here we need some balance into our dataset because our proportion are 70% no tumor and 30% tumor ??\n*  I will keep thinking like it for now and focusing on 30% of tumor for now and see what I can found here","metadata":{}},{"cell_type":"code","source":"(train.isna().sum() / train.shape[0]).sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:31:59.618035Z","iopub.execute_input":"2022-04-26T21:31:59.618662Z","iopub.status.idle":"2022-04-26T21:31:59.700967Z","shell.execute_reply.started":"2022-04-26T21:31:59.618615Z","shell.execute_reply":"2022-04-26T21:31:59.700013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tumor_data = train.copy()\n\ntumor_data.dropna(axis=0,inplace=True)\ntumor_data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T21:31:59.702249Z","iopub.execute_input":"2022-04-26T21:31:59.702742Z","iopub.status.idle":"2022-04-26T21:31:59.906078Z","shell.execute_reply.started":"2022-04-26T21:31:59.702698Z","shell.execute_reply":"2022-04-26T21:31:59.905489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tumor_data['class'].value_counts(normalize=True).sort_values(ascending=False))\n\nplt.figure(figsize=(28, 8))\ntumor_data['class'].value_counts(normalize=True).plot.pie();","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:31:59.907157Z","iopub.execute_input":"2022-04-26T21:31:59.907541Z","iopub.status.idle":"2022-04-26T21:32:00.005325Z","shell.execute_reply.started":"2022-04-26T21:31:59.907499Z","shell.execute_reply":"2022-04-26T21:32:00.004276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I think I have maybe to much data for large_bowel","metadata":{}},{"cell_type":"code","source":"tumor = tumor_data['imagepath'].tolist()\nROI = tumor_data['segmentation'].tolist()\nfor i, item in enumerate(tumor[:1]):\n    img = pltimg.imread(f'{item}')\n    print(ROI[i])\n    plt.imshow(img, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:32:00.006855Z","iopub.execute_input":"2022-04-26T21:32:00.007761Z","iopub.status.idle":"2022-04-26T21:32:00.263511Z","shell.execute_reply.started":"2022-04-26T21:32:00.00763Z","shell.execute_reply":"2022-04-26T21:32:00.262524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef mask2rle(img):\n    \"\"\"\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formatted\n    \"\"\"\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef rle2mask(mask_rle: str, label=1, shape=img.shape):\n    \"\"\"\n    mask_rle: run-length as string formatted (start length)\n    shape: (height,width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n\n    \"\"\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = label\n    return img.reshape(shape)  # Needed to align to RLE direction","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:32:00.264982Z","iopub.execute_input":"2022-04-26T21:32:00.265287Z","iopub.status.idle":"2022-04-26T21:32:00.275535Z","shell.execute_reply.started":"2022-04-26T21:32:00.265249Z","shell.execute_reply":"2022-04-26T21:32:00.27438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Note that the image filenames include 4 numbers (ex. 276_276_1.63_1.63.png). These four numbers are slice height / width (integers in pixels) and heigh/width pixel spacing (floating points in mm). The first two defines the resolution of the slide. The last two record the physical size of each pixel.\n\n* slice_       276_ 276_ 1.63_ 1.63.png\n* slice_ 0065_ 266_ 266_ 1.50_ 1.50.png -----> slice height/width --> 266x266 px  px_size = 1.50x1.50 mm\n* on google : 1px = 0.2645833333 mm\n* slice_ 0065_ 266_ 266_ 1.50_ 1.50.png -----> slice height/width --> 266x266 px  px_size = 1.50x1.50 mm ---> 1.5 / 0.2645833333 = 5.669291339296919\n* the training annotations are provided as RLE-encoded masks, and the images are in 16-bit grayscale PNG format.","metadata":{}},{"cell_type":"code","source":"ratio = 1.5 / 0.2645833333\nprint(266 * ratio)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:32:00.276817Z","iopub.execute_input":"2022-04-26T21:32:00.277737Z","iopub.status.idle":"2022-04-26T21:32:00.292293Z","shell.execute_reply.started":"2022-04-26T21:32:00.277689Z","shell.execute_reply":"2022-04-26T21:32:00.291624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'mako', 'mako_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket', 'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'vlag', 'vlag_r', 'winter', 'winter_r'","metadata":{}},{"cell_type":"markdown","source":"so the next thing to do is to put large_bowel, small_bowel and stomach on the same image\n","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/zocainviken/organs-annalyze\n\nstomach_rle_masks = tumor_data['segmentation'].tolist()\nstomach_img_path = tumor_data['imagepath'].tolist()\nstomach_slices = tumor_data['slice'].tolist()\nstomach_slices = stomach_slices[:30]\nstomach_rle_masks = stomach_rle_masks[:30]\nstomach_img_path = stomach_img_path[:30]\n\ncolumns = 3\n\nplt.figure(figsize=(50, 50))\n\nfor i, mask in enumerate(stomach_rle_masks):\n    \n    plt.subplot(int(len(stomach_rle_masks) / columns + 1), columns, i + 1)\n    \n    color_img = cv2.imread(f'{stomach_img_path[i]}', 1)\n    gray = pltimg.imread(f'{stomach_img_path[i]}')\n\n    # Now create a mask and create its inverse mask also\n    mask = rle2mask(str(mask), label=1, shape=gray.shape)\n    mask_inv = cv2.bitwise_not(mask)\n    \n    foreground = cv2.bitwise_and(gray,gray,mask = mask)\n\n    # Now black-out the area \n    color_background = cv2.bitwise_and(color_img,color_img,mask = mask_inv)\n\n    # Put it in and modify the main image\n    color_img[mask >= 1] = [0,100,0]\n    plt.title(f'{stomach_slices[i]}')\n    plt.imshow(color_img)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:32:00.293406Z","iopub.execute_input":"2022-04-26T21:32:00.293795Z","iopub.status.idle":"2022-04-26T21:32:05.158537Z","shell.execute_reply.started":"2022-04-26T21:32:00.293765Z","shell.execute_reply":"2022-04-26T21:32:05.157846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tumor_data['class'].value_counts())\ntumor_data['class'].value_counts(normalize=True).plot.pie();","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:32:05.159928Z","iopub.execute_input":"2022-04-26T21:32:05.160294Z","iopub.status.idle":"2022-04-26T21:32:05.258998Z","shell.execute_reply.started":"2022-04-26T21:32:05.160263Z","shell.execute_reply":"2022-04-26T21:32:05.25577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tumor_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:32:05.264115Z","iopub.execute_input":"2022-04-26T21:32:05.264802Z","iopub.status.idle":"2022-04-26T21:32:05.277617Z","shell.execute_reply.started":"2022-04-26T21:32:05.264743Z","shell.execute_reply":"2022-04-26T21:32:05.276493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:32:05.279623Z","iopub.execute_input":"2022-04-26T21:32:05.280642Z","iopub.status.idle":"2022-04-26T21:32:05.321669Z","shell.execute_reply.started":"2022-04-26T21:32:05.28037Z","shell.execute_reply":"2022-04-26T21:32:05.320743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}