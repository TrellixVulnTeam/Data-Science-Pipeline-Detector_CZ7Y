{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This Notebook helps to create a dataset in the cocoformat and also has a visualization with with both coco and detectron API\n\nReference:\nhttps://www.kaggle.com/code/ammarnassanalhajali/k-fold-crossvalidation-coco-dataset-generator/notebook","metadata":{}},{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T14:33:24.841728Z","iopub.execute_input":"2022-04-21T14:33:24.84236Z","iopub.status.idle":"2022-04-21T14:33:24.869474Z","shell.execute_reply.started":"2022-04-21T14:33:24.842221Z","shell.execute_reply":"2022-04-21T14:33:24.868772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install pycocotools\n! pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:33:24.871151Z","iopub.execute_input":"2022-04-21T14:33:24.871635Z","iopub.status.idle":"2022-04-21T14:35:59.345982Z","shell.execute_reply.started":"2022-04-21T14:33:24.87159Z","shell.execute_reply":"2022-04-21T14:35:59.34485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport numpy as np\nimport pycocotools.mask as mask_util\nfrom skimage import measure\nimport os\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nimport cv2\nimport random\nfrom itertools import groupby\nimport itertools\nimport pandas as pd\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:35:59.347846Z","iopub.execute_input":"2022-04-21T14:35:59.348141Z","iopub.status.idle":"2022-04-21T14:36:00.935879Z","shell.execute_reply.started":"2022-04-21T14:35:59.34811Z","shell.execute_reply":"2022-04-21T14:36:00.935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\n# From https://newbedev.com/encode-numpy-array-using-uncompressed-rle-for-coco-dataset\ndef binary_mask_to_rle(binary_mask):\n    rle = {'counts': [], 'size': list(binary_mask.shape)}\n    counts = rle.get('counts')\n    for i, (value, elements) in enumerate(itertools.groupby(binary_mask.ravel(order='F'))):\n        if i == 0 and value == 1:\n            counts.append(0)\n        counts.append(len(list(elements)))\n    return rle\n\ndef create_coco_format_json(data_frame, classes, filepaths):\n    images = []\n    annotations = []\n    categories = []\n    count = 0\n    \n    # Additing categories\n    for idx, class_ in enumerate(classes):\n        categories.append(\n            { \n                \"id\": idx,\n                \"name\": class_\n            }\n        )\n\n    for filepath in tqdm(filepaths):\n        file_id = ('_'.join((filepath.split(\"/\")[-3] + \"_\" + filepath.split(\"/\")[-1]).split(\"_\")[:-4]))\n        height_slice = int(filepath.split(\"/\")[-1].split(\"_\")[3])\n        width_slice = int(filepath.split(\"/\")[-1].split(\"_\")[2])\n        ids = data_frame.index[data_frame['id'] == file_id].tolist()\n        file_name = '/'.join(filepath.split(\"/\")[4:])\n\n        if (len(ids) > 0):\n            # Adding images which has annotations\n            images.append(\n                {\n                    \"id\":file_id,\n                    \"width\":width_slice,\n                    \"height\":height_slice,\n                    \"file_name\": file_name\n                }\n            )\n            for idx in ids:\n                mk = rle_decode(data_frame.iloc[idx]['segmentation'], (height_slice, width_slice))\n                ys, xs = np.where(mk)\n                x1, x2 = min(xs), max(xs)\n                y1, y2 = min(ys), max(ys)              \n                contours,hierarchy = cv2.findContours(mk,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)\n                for id_, contour in enumerate(contours):\n                    mask_image = np.zeros((mk.shape[0], mk.shape[1], 3),  np.uint8)\n                    cv2.drawContours(mask_image, [contour], -1, (255,255,255), thickness=cv2.FILLED)\n                    mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n                    mask_image_bool = np.array(mask_image, dtype=bool).astype(np.uint8)\n                    ys, xs = np.where(mask_image_bool)\n                    x1, x2 = min(xs), max(xs)\n                    y1, y2 = min(ys), max(ys)\n                    enc =binary_mask_to_rle(mask_image_bool)\n                    seg = {\n                        'segmentation':enc, \n                        'bbox': [int(x1), int(y1), int(x2-x1+1), int(y2-y1+1)],\n                        'area': int(np.sum(mask_image_bool)),\n                        'image_id':file_id, \n                        'category_id':classes.index(data_frame.iloc[idx]['class']), \n                        'iscrowd':0, \n                        'id': count\n                    }\n                    annotations.append(seg)\n                    count +=1\n            \n    # creating the dataset\n    dataset_coco_format = {\n        \"categories\": categories,\n        \"images\": images,\n        \"annotations\": annotations,\n    }\n    \n    return dataset_coco_format","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:46:18.715962Z","iopub.execute_input":"2022-04-21T15:46:18.716615Z","iopub.status.idle":"2022-04-21T15:46:18.736399Z","shell.execute_reply.started":"2022-04-21T15:46:18.716567Z","shell.execute_reply":"2022-04-21T15:46:18.735362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the paths\ndataset_path = os.path.abspath(\"/kaggle/input/uw-madison-gi-tract-image-segmentation/\")\noutput_path = os.path.abspath(\"/kaggle/working/\")\ncsv_path = os.path.abspath(\"/kaggle/input/uw-madison-gi-tract-image-segmentation/train.csv\")\n\n# creating a dataframe\ndf = pd.read_csv(csv_path)\ndf_with_mask = df[df['segmentation'].notnull()] # Removing the slices which donot have any segmnatation\ndf_with_mask = df_with_mask.reset_index(drop=True)\n\n# Creation of train test split\ntrain_df, test_df = train_test_split(df_with_mask, test_size=0.2)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\nprint(train_df.head())\nprint(\"\\n \\nNumber of Train Images:{}\".format(len(train_df)))\nprint(\"Number of Test Images:{}\".format(len(test_df)))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:31:47.114695Z","iopub.execute_input":"2022-04-21T15:31:47.115126Z","iopub.status.idle":"2022-04-21T15:31:47.463581Z","shell.execute_reply.started":"2022-04-21T15:31:47.115096Z","shell.execute_reply":"2022-04-21T15:31:47.46267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['small_bowel', 'large_bowel', 'stomach']\n\nfilepaths = list()\nfor (dirpath, dirnames, filenames) in os.walk(dataset_path):\n    filepaths += [os.path.join(dirpath, file) for file in filenames if file.endswith(\".png\")]\n    \ntrain_json = create_coco_format_json(train_df, classes, filepaths)\ntest_json = create_coco_format_json(test_df, classes, filepaths)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:31:47.759171Z","iopub.execute_input":"2022-04-21T15:31:47.759465Z","iopub.status.idle":"2022-04-21T15:31:54.793669Z","shell.execute_reply.started":"2022-04-21T15:31:47.759429Z","shell.execute_reply":"2022-04-21T15:31:54.79265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the train and test json","metadata":{}},{"cell_type":"code","source":"# Code taken from: https://stackoverflow.com/a/65151218/12890869\ndef np_encoder(object):\n    if isinstance(object, np.generic):\n        return object.item()\n    \nwith open('train_json.json', 'w', encoding='utf-8') as f:\n    json.dump(train_json, f, ensure_ascii=True, indent=4, default=np_encoder)\n    \nwith open('test_json.json', 'w', encoding='utf-8') as f:\n    json.dump(test_json, f, ensure_ascii=True, indent=4, default=np_encoder)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:31:57.60118Z","iopub.execute_input":"2022-04-21T15:31:57.601486Z","iopub.status.idle":"2022-04-21T15:31:57.671677Z","shell.execute_reply.started":"2022-04-21T15:31:57.601456Z","shell.execute_reply":"2022-04-21T15:31:57.670609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization with Detectron2","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nimport matplotlib.pyplot as plt\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.utils.visualizer import ColorMode\n\nData_Resister_training=\"train\";\nData_Resister_testing=\"test\";\n\nif Data_Resister_training in DatasetCatalog.list():\n    DatasetCatalog.remove(Data_Resister_training)\nif Data_Resister_testing in DatasetCatalog.list():\n    DatasetCatalog.remove(Data_Resister_testing)\n\nregister_coco_instances(\n    Data_Resister_training,\n    {}, \n    os.path.join(output_path, \"train_json.json\"), \n    dataset_path)\n\nregister_coco_instances(\n    Data_Resister_testing,\n    {}, \n    os.path.join(output_path, \"test_json.json\"), \n    dataset_path)\n\nmetadata = MetadataCatalog.get(Data_Resister_training)\nmetadata = MetadataCatalog.get(Data_Resister_testing)\ndataset_train = DatasetCatalog.get(Data_Resister_training)\ndataset_test = DatasetCatalog.get(Data_Resister_testing)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:31:58.566761Z","iopub.execute_input":"2022-04-21T15:31:58.567117Z","iopub.status.idle":"2022-04-21T15:31:58.598594Z","shell.execute_reply.started":"2022-04-21T15:31:58.567074Z","shell.execute_reply":"2022-04-21T15:31:58.597892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nfor i, idx in enumerate(random.sample(range(0, len(dataset_train)), 4)):\n    d=dataset_train[idx]\n    gray_image = cv2.imread(d[\"file_name\"], cv2.IMREAD_ANYDEPTH)\n    gray_image = gray_image / gray_image.max()\n    img = np.repeat(gray_image[..., np.newaxis], 3, -1) * 255.0\n    v = Visualizer(img,\n                    metadata=metadata, \n                    scale=2,\n                    instance_mode=ColorMode.IMAGE_BW\n        )\n    out = v.draw_dataset_dict(d)\n    plt.subplot(2, 2, i+1)\n    plt.imshow(out.get_image())\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:32:00.011867Z","iopub.execute_input":"2022-04-21T15:32:00.012163Z","iopub.status.idle":"2022-04-21T15:32:00.935746Z","shell.execute_reply.started":"2022-04-21T15:32:00.012123Z","shell.execute_reply":"2022-04-21T15:32:00.934874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}