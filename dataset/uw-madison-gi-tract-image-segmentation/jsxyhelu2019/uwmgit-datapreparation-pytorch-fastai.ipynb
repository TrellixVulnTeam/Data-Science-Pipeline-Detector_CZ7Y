{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# STEP1：Import Libraries ","metadata":{}},{"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n#use fastai v2\nfrom fastai.vision.all import *  \nfrom tqdm import tqdm\nimport cv2\nimport  os\nimport  zipfile","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# STEP2：Utility","metadata":{}},{"cell_type":"code","source":"def rle_decode(rle, height, width , fill=255):\n    s = rle.split()\n    start, length = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    start -= 1\n    mask = np.zeros(height*width, dtype=np.uint8)\n    for i, l in zip(start, length):\n        mask[i:i+l] = fill\n    mask = mask.reshape(width,height).T\n    mask = np.ascontiguousarray(mask)\n    return mask\n\ndef rle2mask(rles, class_names, height, width, class_dict):\n    img = np.zeros(height*width, dtype=np.uint16)\n    for rle, class_name in zip(rles, class_names):\n        s = rle.split(' ')\n        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n        starts -= 1\n        ends = starts + lengths\n        for lo, hi in zip(starts, ends):\n            img[lo:hi] = class_dict[class_name]\n        \n    mask = img.reshape((width, height))\n    return mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The purpose of creating debug states is to save time\ndebug = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# STEP3：Data preparation","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:42:45.653899Z","iopub.execute_input":"2022-04-23T11:42:45.654632Z","iopub.status.idle":"2022-04-23T11:42:45.658318Z","shell.execute_reply.started":"2022-04-23T11:42:45.654583Z","shell.execute_reply":"2022-04-23T11:42:45.657344Z"}}},{"cell_type":"code","source":"ROOT_DIR = '../input/uw-madison-gi-tract-image-segmentation/'\nhome_path = Path(ROOT_DIR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_paths = glob.glob(ROOT_DIR+'train/*/*/*/*')\nfile_paths[:3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv(home_path / 'train.csv')\ntrain_csv = train_csv[train_csv['segmentation'].notnull()] #Remove empty line\ntrain_csv.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create table from train image (38496 images need 2 min 13 second)\nfile_csv = pd.DataFrame(columns=['id','filename','filepath'])\nfor idx, filepath in tqdm(enumerate(file_paths)):\n    case_day_str = filepath.split('/')[5]\n    filename = filepath.split('/')[-1]\n    slice_id = filename.split('_')[1]\n    slice_str = f'slice_{slice_id}'\n    idstr = case_day_str+'_'+slice_str\n    file_csv.loc[idx] = [idstr, filename,filepath]\n\nfile_csv.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge file_csv into train_csv\ntrain_csv = pd.merge(train_csv, file_csv, on=['id'])\ntrain_csv.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fill table with other parameters\ndef get_img_height(row):\n    return int(row.filename[:-4].split('_')[2])\ndef get_img_width(row):\n    return int(row.filename[:-4].split('_')[3])\ntrain_csv['img_height'] = train_csv.apply(lambda row: get_img_height(row), axis=1)\ntrain_csv['img_width'] = train_csv.apply(lambda row: get_img_width(row), axis=1)\ntrain_csv.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save csv  \ntrain_csv.to_csv('train_csv.csv')\n#load csv to save time\n#train_csv = pd.read_csv('../input/df-train-csv/df_train.csv')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create directories\nos.mkdir('train')\nos.mkdir('train/images')\nos.mkdir('train/labels')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the split identity\n#0: background\n#1: stomach\n#2: large_bowel\n#3: small_bowel\nclass2id = {class_name: idx+1 for idx, class_name in enumerate(train_csv['class'].unique())}\nid2class = {v:k for k, v in class2id.items()}\nid2class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make copies of “images” and “labels”\ngrouped = train_csv.groupby('id')\nfor name,group in grouped:\n    df_select = train_csv.groupby('id').get_group(name)\n    filepath = df_select.filepath.values[0]\n    image = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)\n    mask = rle2mask(df_select.segmentation.values,\n                df_select['class'].values,\n                df_select.img_height.values[0],\n                df_select.img_width.values[0],\n                class2id)\n    #cv2.imwrite(\"./images/\"+str(df_select.id.values),image)\n    imgPath = \"./train/images/\"+df_select.id.values[0]+\".png\"\n    mskPath = \"./train/labels/\"+df_select.id.values[0]+\"_mask.png\"\n    #print(strpath)\n    cv2.imwrite(imgPath,image)\n    cv2.imwrite(mskPath,mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#If under debug ,zip train images and labels\nstartdir = \"./train\"  #要压缩的文件夹路径，这里选择将input中的所有文件压缩\nfile_news = './' +'train.zip' # 压缩后文件夹的名字，这里压缩到kaggle之中的output文件之中，名称为result.zip\nz = zipfile.ZipFile(file_news,'w',zipfile.ZIP_DEFLATED) #参数一：文件夹名\nfor dirpath, dirnames, filenames in os.walk(startdir):\n    fpath = dirpath.replace(startdir,'') #这一句很重要，不replace的话，就从根目录开始复制\n    fpath = fpath and fpath + os.sep or ''#实现当前文件夹以及包含的所有文件的压缩\n    for filename in filenames:\n        z.write(os.path.join(dirpath, filename),fpath+filename)\nz.close()\nprint ('压缩成功')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# STEP4：TRAIN","metadata":{}},{"cell_type":"code","source":"#View the file in pair\n# train_path = Path('./train/')\n# fnames = get_image_files(train_path /'images')\n# lbl_names = get_image_files(train_path /'labels')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#View file details for images and lables and create mask methods\n# print (fnames[0],lbl_names[0])\n# get_mask = lambda o:'./train/labels/'+str(o.stem)+'_mask.png'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check out a pair of images and lables\n# img_fn = fnames[random.randint(0,len(fnames))]\n# im = PILImage.create(img_fn)\n# im.show(figsize=(5,5))\n# print(len(fnames))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mask_fn = get_mask(img_fn)\n# msk = PILMask.create(mask_fn)\n# msk.show(figsize=(5,5), alpha=1)\n# print(im.shape,msk.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make DataBlock\n# binary = DataBlock(blocks=(ImageBlock, MaskBlock( ['Background', 'stomach', 'large_bowel','small_bowel'])),    \n#                    get_items=get_image_files,   \n#                    splitter=RandomSplitter(),    \n#                    get_y=get_mask,               \n#                    item_tfms=Resize(128,ResizeMethod.Squish),       # Modify \"128\" may change results OR OOM\n#                    batch_tfms=[Normalize.from_stats(*imagenet_stats)])  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read the picture and display the sample\n# dls = binary.dataloaders(train_path /'images',bs=3)  # Modify \"bs=3\" may change train time OR OOM\n# dls.show_batch( vmin=0, vmax=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#You can try other options\n#pay attention to downloading the model first\n\n#model   : resnet34\n#metrics : DICEMulti\n\n#p = Path(\"/root/.cache/torch/hub/checkpoints\")\n#p.mkdir(parents=True)\n#!cp ../input/resnet34/resnet34-b627a593.pth /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n\n# learn = unet_learner(dls,models.resnet34,metrics=DiceMulti)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learn.lr_find()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Perform training, where better results can be obtained by adjusting lr\n# if debug:\n#     learn.fit_flat_cos(1)\n# else:\n#     learn.fit_flat_cos(12)\n\n# learn.recorder.plot_loss()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show result\n# learn.show_results(max_n=4, figsize=(12,6))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}