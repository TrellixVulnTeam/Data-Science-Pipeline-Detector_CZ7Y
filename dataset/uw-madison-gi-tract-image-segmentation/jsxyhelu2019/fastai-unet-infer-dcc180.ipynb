{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Configuration","metadata":{"tags":[]}},{"cell_type":"code","source":"import os\nfrom itertools import chain\n\nGRADIENT = os.path.exists('train')\nKAGGLE = os.path.exists('../input')\nmodel_name = '../input/fastai-unet-train-dcc180/resnet34-unetplusplus-valid_pct_1_20-epoch.pkl'\n\nSEED = 42\nVAL_PCT = 0.2\nINFER = True","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:04:36.623611Z","iopub.execute_input":"2022-06-14T06:04:36.62439Z","iopub.status.idle":"2022-06-14T06:04:36.650736Z","shell.execute_reply.started":"2022-06-14T06:04:36.624286Z","shell.execute_reply":"2022-06-14T06:04:36.650043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Libraries and Data","metadata":{"tags":[]}},{"cell_type":"code","source":"if KAGGLE:\n    !cp -r ../input/pytorch-segmentation-models-lib/ ./\n    !pip install -q ./pytorch-segmentation-models-lib/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4\n    !pip install -q ./pytorch-segmentation-models-lib/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3\n    !pip install -q ./pytorch-segmentation-models-lib/timm-0.4.12-py3-none-any.whl\n    !pip install -q ./pytorch-segmentation-models-lib/segmentation_models_pytorch-0.2.0-py3-none-any.whl","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-06-14T06:04:36.652478Z","iopub.execute_input":"2022-06-14T06:04:36.652948Z","iopub.status.idle":"2022-06-14T06:06:56.933946Z","shell.execute_reply.started":"2022-06-14T06:04:36.652912Z","shell.execute_reply":"2022-06-14T06:06:56.933013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\nimport gc\nimport segmentation_models_pytorch as smp","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-06-14T06:06:56.938996Z","iopub.execute_input":"2022-06-14T06:06:56.941055Z","iopub.status.idle":"2022-06-14T06:07:08.4136Z","shell.execute_reply.started":"2022-06-14T06:06:56.941009Z","shell.execute_reply":"2022-06-14T06:07:08.412732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if KAGGLE:\n    data_path = '../input/uw-madison-gi-tract-image-segmentation/'\nelif GRADIENT:\n    data_path = ''\n    model_name = 'models/' + model_name ","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:08.415185Z","iopub.execute_input":"2022-06-14T06:07:08.415744Z","iopub.status.idle":"2022-06-14T06:07:08.421954Z","shell.execute_reply.started":"2022-06-14T06:07:08.415698Z","shell.execute_reply":"2022-06-14T06:07:08.42079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path(data_path+'train')\ntest_path = Path(data_path+'test')\ntrain = pd.read_csv(data_path+'train.csv', low_memory=False)\nsample_submission = pd.read_csv(data_path+'sample_submission.csv', low_memory=False)\nfnames = get_image_files(path)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-06-14T06:07:08.428493Z","iopub.execute_input":"2022-06-14T06:07:08.430284Z","iopub.status.idle":"2022-06-14T06:07:15.287902Z","shell.execute_reply.started":"2022-06-14T06:07:08.43024Z","shell.execute_reply":"2022-06-14T06:07:15.286845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{"tags":[]}},{"cell_type":"code","source":"# Extract case id from fname\ndef get_case_id(fname):\n    if KAGGLE: i = 5\n    elif GRADIENT: i = 2\n    return fname.parts[i] + '_' + fname.parts[i+2][:10]\n\ndef check_file(file_id, fname):\n    case_id, day, _, slice_no = file_id.split('_')\n    if case_id == fname.parts[1] and day == fname.parts[2].split('_')[1] and slice_no in fname.parts[-1]:\n        return True\n    return False\n\ndef get_file(file_id):\n    return fnames.filter(lambda f: check_file(not_null_train.id[0], f))[0]\n\n# https://www.kaggle.com/code/dschettler8845/uwm-gi-tract-image-segmentation-eda\ndef get_custom_df(df, fnames, root):\n    \n    df = df.copy()\n    \n    # 1. Get Case-ID as a column (str and int)\n    df[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\n    df[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n    # 2. Get Day as a column\n    df[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\n    df[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n    # 3. Get Slice Identifier as a column\n    df[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\n    # 4. Get full file paths for the representative scans\n    df[\"_partial_fname\"] = (root+'/'+ # /kaggle/input/uw-madison-gi-tract-image-segmentation/train/\n                          df[\"case_id_str\"]+\"/\"+ # .../case###/\n                          df[\"case_id_str\"]+\"_\"+df[\"day_num_str\"]+ # .../case###_day##/\n                          \"/scans/\"+df[\"slice_id\"]) # .../slice_####\n    \n    _tmp_merge_df = pd.DataFrame({\"_partial_fname\":[str(x).rsplit(\"_\",4)[0] for x in fnames], \"fname\": fnames})\n    df = df.merge(_tmp_merge_df, on=\"_partial_fname\").drop(columns=[\"_partial_fname\"])\n    \n    # Minor cleanup of our temporary workaround\n    del _tmp_merge_df; gc.collect(); gc.collect()\n    \n    # 5. Get slice dimensions from filepath (int in pixels)\n    df[\"slice_h\"] = df[\"fname\"].apply(lambda x: int(str(x)[:-4].rsplit(\"_\",4)[1]))\n    df[\"slice_w\"] = df[\"fname\"].apply(lambda x: int(str(x)[:-4].rsplit(\"_\",4)[2]))\n\n    # 6. Pixel spacing from filepath (float in mm)\n    df[\"px_spacing_h\"] = df[\"fname\"].apply(lambda x: float(str(x)[:-4].rsplit(\"_\",4)[3]))\n    df[\"px_spacing_w\"] = df[\"fname\"].apply(lambda x: float(str(x)[:-4].rsplit(\"_\",4)[4]))\n\n    # 7. Merge 3 Rows Into A Single Row (As This/Segmentation-RLE Is The Only Unique Information Across Those Rows)\n    l_bowel_train_df = df[df[\"class\"]==\"large_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"lb_seg_rle\"})\n    s_bowel_train_df = df[df[\"class\"]==\"small_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"sb_seg_rle\"})\n    stomach_train_df = df[df[\"class\"]==\"stomach\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"st_seg_rle\"})\n    df = df.merge(l_bowel_train_df, on=\"id\", how=\"left\")\n    df = df.merge(s_bowel_train_df, on=\"id\", how=\"left\")\n    df = df.merge(stomach_train_df, on=\"id\", how=\"left\")\n    df = df.drop_duplicates(subset=[\"id\",]).reset_index(drop=True)\n    df[\"lb_seg_flag\"] = df[\"lb_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"sb_seg_flag\"] = df[\"sb_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"st_seg_flag\"] = df[\"st_seg_rle\"].apply(lambda x: not pd.isna(x))\n    df[\"n_segs\"] = df[\"lb_seg_flag\"].astype(int)+df[\"sb_seg_flag\"].astype(int)+df[\"st_seg_flag\"].astype(int)\n\n    # 8. Reorder columns to the a new ordering (drops class and segmentation as no longer necessary)\n    df = df[[\"id\", \"fname\", \"n_segs\",\n             \"lb_seg_rle\", \"lb_seg_flag\",\n             \"sb_seg_rle\", \"sb_seg_flag\", \n             \"st_seg_rle\", \"st_seg_flag\",\n             \"slice_h\", \"slice_w\", \"px_spacing_h\", \n             \"px_spacing_w\", \"case_id_str\", \"case_id\", \n             \"day_num_str\", \"day_num\", \"slice_id\",]]\n\n    return df\n\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns: \n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    # Split the string by space, then convert it into a integer array\n    s = np.array(mask_rle.split(), dtype=int)\n\n    # Every even value is the start, every odd value is the \"run\" length\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n\n    # The image image is actually flattened since RLE is a 1D \"run\"\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n\n    # The color here is actually just any integer you want!\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n        \n    # Don't forget to change the image back to the original shape\n    return img.reshape(shape)\n\ndef get_image(row):\n    img = np.array(Image.open(row['fname']))\n    img = np.interp(img, [np.min(img), np.max(img)], [0,255])\n    return img\n \ndef get_25D_image(row):\n    imgs = np.zeros((row['slice_w'], row['slice_h'], len(row['fnames'])))\n        \n    for i, fname in enumerate(row['fnames']):\n        img = load_image(fname)\n        imgs[..., i] += img\n    return imgs.astype(np.uint8)                 \n\ndef get_mask(row):\n    mask = np.zeros((row['slice_w'], row['slice_h'], 3))\n    if row['lb_seg_flag']:\n        mask[..., 0] += rle_decode(row['lb_seg_rle'], shape=(row['slice_w'], row['slice_h']), color=255)\n    if row['sb_seg_flag']:\n        mask[..., 1] += rle_decode(row['sb_seg_rle'], shape=(row['slice_w'], row['slice_h']), color=255)\n    if row['st_seg_flag']:\n        mask[..., 2] += rle_decode(row['st_seg_rle'], shape=(row['slice_w'], row['slice_h']), color=255)    \n    return mask.astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:15.292387Z","iopub.execute_input":"2022-06-14T06:07:15.292653Z","iopub.status.idle":"2022-06-14T06:07:15.368575Z","shell.execute_reply.started":"2022-06-14T06:07:15.292617Z","shell.execute_reply":"2022-06-14T06:07:15.367743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Data","metadata":{}},{"cell_type":"code","source":"root = data_path+'test'\ntest_fnames = get_image_files(test_path)\n\nif not test_fnames:\n    test_fnames = fnames\n    root = data_path+'train'\n\ntest = pd.DataFrame({\n    'id': chain.from_iterable([[get_case_id(fname)]*3 for fname in test_fnames]),\n    'class': chain.from_iterable([['large_bowel', 'small_bowel', 'stomach'] for _ in test_fnames]),\n    'segmentation': chain.from_iterable([[np.nan]*3 for _ in test_fnames]),\n})\n\ntest = get_custom_df(test, test_fnames, root)\ntrain = get_custom_df(train, fnames, data_path+'train')","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:15.370466Z","iopub.execute_input":"2022-06-14T06:07:15.371251Z","iopub.status.idle":"2022-06-14T06:07:23.028561Z","shell.execute_reply.started":"2022-06-14T06:07:15.371209Z","shell.execute_reply":"2022-06-14T06:07:23.027776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation Set","metadata":{}},{"cell_type":"code","source":"valid_pct = 0.2\nset_seed(SEED, True)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.032949Z","iopub.execute_input":"2022-06-14T06:07:23.035263Z","iopub.status.idle":"2022-06-14T06:07:23.040215Z","shell.execute_reply.started":"2022-06-14T06:07:23.035217Z","shell.execute_reply":"2022-06-14T06:07:23.039334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channels = 3\nstride = 2\nfor j, i in enumerate(range(-1*(channels-channels//2-1), channels//2+1)):\n    method = 'ffill'\n    if i <= 0: method = 'bfill'\n    train[f'fname_{j:02}'] = train.groupby(['case_id', 'day_num'])['fname'].shift(stride*-i).fillna(method=method)\n    test[f'fname_{j:02}'] = test.groupby(['case_id', 'day_num'])['fname'].shift(stride*-i).fillna(method=method)\n    \ntrain['fnames'] = train[[f'fname_{j:02d}' for j in range(channels)]].values.tolist()\ntest['fnames'] = test[[f'fname_{j:02d}' for j in range(channels)]].values.tolist()\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.041487Z","iopub.execute_input":"2022-06-14T06:07:23.041922Z","iopub.status.idle":"2022-06-14T06:07:23.294367Z","shell.execute_reply.started":"2022-06-14T06:07:23.04187Z","shell.execute_reply":"2022-06-14T06:07:23.293399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom validation","metadata":{}},{"cell_type":"code","source":"np.random.seed(SEED)\n\ncases = train.case_id.unique()\nn_cases = len(cases)\nrandom_cases = np.random.choice(cases, int(n_cases*valid_pct), replace=False)\n\ntrain['is_valid'] = False\ntrain.loc[train.case_id.isin(random_cases), 'is_valid'] = True\n\ndays = train.loc[~train['is_valid'], 'day_num'].unique()\nn_days = len(days)\nrandom_days = np.random.choice(days, int(n_days*valid_pct), replace=False)\n\ntrain.loc[train.case_id.isin(random_days), 'is_valid'] = True\n\ntrain['is_valid'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.295969Z","iopub.execute_input":"2022-06-14T06:07:23.296383Z","iopub.status.idle":"2022-06-14T06:07:23.320113Z","shell.execute_reply.started":"2022-06-14T06:07:23.296344Z","shell.execute_reply":"2022-06-14T06:07:23.318758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GroupValidation by Cases","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupShuffleSplit","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.32146Z","iopub.execute_input":"2022-06-14T06:07:23.321893Z","iopub.status.idle":"2022-06-14T06:07:23.326466Z","shell.execute_reply.started":"2022-06-14T06:07:23.321844Z","shell.execute_reply":"2022-06-14T06:07:23.325554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gss = GroupShuffleSplit(n_splits=1, test_size=valid_pct, random_state=SEED)\ntrain_idx, val_idx = [(train_idx, val_idx) for (train_idx, val_idx) in gss.split(train, train, train['case_id'])][0]\n\ntrain['is_valid'] = False\ntrain.loc[val_idx, 'is_valid'] = True\n\ntrain['is_valid'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.328267Z","iopub.execute_input":"2022-06-14T06:07:23.328567Z","iopub.status.idle":"2022-06-14T06:07:23.357088Z","shell.execute_reply.started":"2022-06-14T06:07:23.328528Z","shell.execute_reply":"2022-06-14T06:07:23.356324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Datablock API","metadata":{"tags":[]}},{"cell_type":"code","source":"@ToTensor\ndef encodes(self, o:PILMask): return o._tensor_cls(image2tensor(o))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.361043Z","iopub.execute_input":"2022-06-14T06:07:23.363323Z","iopub.status.idle":"2022-06-14T06:07:23.369727Z","shell.execute_reply.started":"2022-06-14T06:07:23.363283Z","shell.execute_reply":"2022-06-14T06:07:23.368942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@Normalize\ndef encodes(self, o:TensorMask): return o / 255\n\n@Normalize\ndef decodes(self, o:TensorMask): \n    f = to_cpu if o.device.type=='cpu' else noop\n    return f((o * 255).long())","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.378422Z","iopub.execute_input":"2022-06-14T06:07:23.38099Z","iopub.status.idle":"2022-06-14T06:07:23.39044Z","shell.execute_reply.started":"2022-06-14T06:07:23.380948Z","shell.execute_reply":"2022-06-14T06:07:23.38943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as mpatches\n\n@typedispatch\ndef show_batch(x:TensorImage, y:TensorMask, samples, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):\n    if figsize is None: figsize = (ncols*3, max_n//ncols * 3)\n    if ctxs is None: ctxs = get_grid(max_n, nrows=nrows, ncols=ncols, figsize=figsize)\n    for i,ctx in enumerate(ctxs): \n        x_i = x[i] / x[i].max()\n        show_image(x_i, ctx=ctx, cmap='gray', **kwargs)\n        show_image(y[i], ctx=ctx, cmap='Spectral_r', alpha=0.35, **kwargs)\n        red_patch = mpatches.Patch(color='red', label='lb')\n        green_patch = mpatches.Patch(color='green', label='sb')\n        blue_patch = mpatches.Patch(color='blue', label='st')\n        ctx.legend(handles=[red_patch, green_patch, blue_patch], fontsize=figsize[0]/2)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.395264Z","iopub.execute_input":"2022-06-14T06:07:23.39777Z","iopub.status.idle":"2022-06-14T06:07:23.412023Z","shell.execute_reply.started":"2022-06-14T06:07:23.397723Z","shell.execute_reply":"2022-06-14T06:07:23.411216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_aug_dls(aug=[], method='squish', bs=16, sample=False, show=True):\n    batch_tfms = [Normalize.from_stats(*imagenet_stats)]\n    if aug: batch_tfms = [*aug] + batch_tfms\n    \n    db = DataBlock((ImageBlock(cls=PILImageBW), MaskBlock),\n                    get_x=get_image,\n                   get_y=get_mask,\n                   splitter = ColSplitter(),\n                   item_tfms=[Resize(224, method=method)],\n                   batch_tfms=batch_tfms)\n    \n    if sample:\n        dev = train.sample(frac=0.2, random_state=SEED)\n    else:\n        dev = train\n        \n    dls = db.dataloaders(dev, bs=bs, shuffle=True)\n    dls.rng.seed(SEED)\n    \n    if show:\n        dls.show_batch(nrows=bs//4, ncols=4, max_n=bs, figsize=(12, 12))\n        \n    return dls, dev","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.417029Z","iopub.execute_input":"2022-06-14T06:07:23.418362Z","iopub.status.idle":"2022-06-14T06:07:23.43201Z","shell.execute_reply.started":"2022-06-14T06:07:23.418315Z","shell.execute_reply":"2022-06-14T06:07:23.431052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{"tags":[]}},{"cell_type":"code","source":"from scipy.spatial.distance import directed_hausdorff\n\ndef mod_acc(inp, targ):\n    targ = targ.squeeze(1)\n    mask = targ != 0\n    if mask.sum() == 0:\n        mask = targ == 0\n    return (torch.where(sigmoid(inp) > 0.5, 1, 0)[mask]==targ[mask]).float().mean().item()\n\ndef dice_coeff(inp, targ):\n    inp = np.where(inp.cpu().detach().numpy() > 0.5, 1, 0)\n    targ = targ.cpu().detach().numpy()\n    eps = 1e-5\n    I = (targ * inp).sum((2, 3))\n    U =  targ.sum((2,3)) + inp.sum((2, 3))\n    return ((2.*I+eps)/(U+eps)).mean((1, 0))\n\n# def dice_coeff(inp, targ):\n#     if torch.is_tensor(inp):\n#         inp = torch.where(sigmoid(inp) > 0.5, 1, 0).cpu().detach().numpy().astype(np.uint8)\n#     if torch.is_tensor(targ):\n#         targ = targ.cpu().detach().numpy().astype(np.uint8)\n#     # mask = targ == 1\n#     # I = (inp[mask] == targ[mask]).sum((2, 3))\n#     eps = 1e-5\n#     I = (targ & inp).sum((2, 3))\n#     # U = inp.sum((2, 3)) + targ.sum((2, 3))\n#     U = (targ | inp).sum((2, 3))\n#     return ((2*I)/(U+I+1) + (U==0)).mean((1, 0))\n\n# def dice_coeff2(inp, targ, thr=0.5, dim=(2,3), epsilon=0.001):\n#     targ = targ.to(torch.float32)\n#     inp = (inp>thr).to(torch.float32)\n#     inter = (targ*inp).sum(dim=dim)\n#     den = targ.sum(dim=dim) + inp.sum(dim=dim)\n#     dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n#     return dice\n\ndef hd_dist_per_slice(inp, targ):    \n    inp = np.argwhere(inp) / np.array(inp.shape)\n    targ = np.argwhere(targ) / np.array(targ.shape)\n    # if len(targ) == 0:\n    #     inp = 1 - inp\n    #     targ = 1 - targ\n    haussdorf_dist = 1 - directed_hausdorff(inp, targ, SEED)[0]\n    return haussdorf_dist if haussdorf_dist > 0 else 0\n\ndef hd_dist(inp, targ):\n    inp = np.where(inp.cpu().detach().numpy() > 0.5, 1, 0)\n    targ = targ.cpu().detach().numpy()\n    \n    return np.mean([np.mean([hd_dist_per_slice(inp[i, j], targ[i, j]) for j in range(3)]) for i in range(len(inp))])\n\ndef custom_metric(inp, targ):\n    hd_score_per_batch = hd_dist(inp, targ)\n    dice_score_per_batch = dice_coeff(inp, targ)\n        \n    return 0.4*dice_score_per_batch + 0.6*hd_score_per_batch\n\n\ndef custom_loss(inp, targ):\n    return nn.BCEWithLogitsLoss(inp, targ.float())","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-06-14T06:07:23.436698Z","iopub.execute_input":"2022-06-14T06:07:23.439411Z","iopub.status.idle":"2022-06-14T06:07:23.463357Z","shell.execute_reply.started":"2022-06-14T06:07:23.439369Z","shell.execute_reply":"2022-06-14T06:07:23.462371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# custom_metric(torch.zeros_like(y), torch.zeros_like(y))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.465056Z","iopub.execute_input":"2022-06-14T06:07:23.465599Z","iopub.status.idle":"2022-06-14T06:07:23.477568Z","shell.execute_reply.started":"2022-06-14T06:07:23.465558Z","shell.execute_reply":"2022-06-14T06:07:23.476502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss","metadata":{}},{"cell_type":"code","source":"class DiceBCEModule(Module):\n    def __init__(self, eps:float=1e-5, from_logits=True):\n        store_attr()\n        \n    def forward(self, inp:Tensor, targ:Tensor) -> Tensor:\n        if self.from_logits: \n            bce_loss = nn.BCEWithLogitsLoss()(inp, targ)\n            inp = torch.sigmoid(inp)\n        inp = inp.view(-1)\n        targ = targ.view(-1)\n        \n        intersection = (inp * targ).sum()                            \n        dice = (2.*intersection + self.eps)/(inp.sum() + targ.sum() + self.eps)  \n        \n        return 0.5*(1 - dice) + 0.5*bce_loss\n\n\nclass DiceBCELoss(BaseLoss):\n    def __init__(self, *args, eps:float=1e-5, from_logits=True, **kwargs):\n        super().__init__(DiceBCEModule, *args, eps=eps, from_logits=from_logits, flatten=False, is_2d=True, floatify=True, **kwargs)\n    \n    def decodes(self, x:Tensor) -> Tensor:\n        \"Converts model output to target format\"\n        return (x>self.thresh).long()\n\n    def activation(self, x:Tensor) -> Tensor:\n        \"`nn.BCEWithLogitsLoss`'s fused activation function applied to model output\"\n        return torch.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.479118Z","iopub.execute_input":"2022-06-14T06:07:23.479542Z","iopub.status.idle":"2022-06-14T06:07:23.496081Z","shell.execute_reply.started":"2022-06-14T06:07:23.479502Z","shell.execute_reply":"2022-06-14T06:07:23.495155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Learner","metadata":{"tags":[]}},{"cell_type":"code","source":"def splitter(model):\n    return [params(model.encoder), params(model.decoder)]","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.497503Z","iopub.execute_input":"2022-06-14T06:07:23.497943Z","iopub.status.idle":"2022-06-14T06:07:23.509956Z","shell.execute_reply.started":"2022-06-14T06:07:23.49789Z","shell.execute_reply":"2022-06-14T06:07:23.508882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(encoder_name):\n    model = smp.UnetPlusPlus(\n        encoder_name=encoder_name,      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n        classes=3,        # model output channels (number of classes in your dataset)\n        activation=None,\n    )\n    model.to('cuda')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.511307Z","iopub.execute_input":"2022-06-14T06:07:23.51201Z","iopub.status.idle":"2022-06-14T06:07:23.523593Z","shell.execute_reply.started":"2022-06-14T06:07:23.511961Z","shell.execute_reply":"2022-06-14T06:07:23.522583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not INFER:\n    dls, dev = get_aug_dls(aug_transforms(), sample=False, bs=16, show=False)\n    unet = build_model('resnet50')\n    learn = Learner(dls, unet, metrics=[dice_coeff, hd_dist, custom_metric], loss_func=DiceBCELoss()).to_fp16()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-06-14T06:07:23.524938Z","iopub.execute_input":"2022-06-14T06:07:23.525994Z","iopub.status.idle":"2022-06-14T06:07:23.533588Z","shell.execute_reply.started":"2022-06-14T06:07:23.525949Z","shell.execute_reply":"2022-06-14T06:07:23.532571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"tags":[]}},{"cell_type":"code","source":"if not INFER:\n    learn.freeze()\n    learn.lr_find()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-06-14T06:07:23.535189Z","iopub.execute_input":"2022-06-14T06:07:23.535649Z","iopub.status.idle":"2022-06-14T06:07:23.547422Z","shell.execute_reply.started":"2022-06-14T06:07:23.535587Z","shell.execute_reply":"2022-06-14T06:07:23.546187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-3","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-06-14T06:07:23.549305Z","iopub.execute_input":"2022-06-14T06:07:23.549701Z","iopub.status.idle":"2022-06-14T06:07:23.556656Z","shell.execute_reply.started":"2022-06-14T06:07:23.54966Z","shell.execute_reply":"2022-06-14T06:07:23.555559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not INFER:\n    learn.fit_one_cycle(1, slice(lr))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-06-14T06:07:23.558683Z","iopub.execute_input":"2022-06-14T06:07:23.559057Z","iopub.status.idle":"2022-06-14T06:07:23.568338Z","shell.execute_reply.started":"2022-06-14T06:07:23.559019Z","shell.execute_reply":"2022-06-14T06:07:23.567056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not INFER:\n    learn.unfreeze()\n    learn.fit_one_cycle(10, slice(lr/400, lr/10))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.57004Z","iopub.execute_input":"2022-06-14T06:07:23.570449Z","iopub.status.idle":"2022-06-14T06:07:23.578833Z","shell.execute_reply.started":"2022-06-14T06:07:23.570407Z","shell.execute_reply":"2022-06-14T06:07:23.577514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show Results","metadata":{"tags":[]}},{"cell_type":"code","source":"# if not INFER:\n#     learn.show_results(max_n=16)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.580699Z","iopub.execute_input":"2022-06-14T06:07:23.580997Z","iopub.status.idle":"2022-06-14T06:07:23.590148Z","shell.execute_reply.started":"2022-06-14T06:07:23.58096Z","shell.execute_reply":"2022-06-14T06:07:23.588615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save Model","metadata":{}},{"cell_type":"markdown","source":"## Test inference ","metadata":{"tags":[]}},{"cell_type":"code","source":"if INFER:\n    learn = load_learner(model_name)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:23.59204Z","iopub.execute_input":"2022-06-14T06:07:23.592408Z","iopub.status.idle":"2022-06-14T06:07:25.359188Z","shell.execute_reply.started":"2022-06-14T06:07:23.592359Z","shell.execute_reply":"2022-06-14T06:07:25.357728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n@torch.no_grad()\ndef get_preds(learn, dl, thresh=0.5):\n    learn.model.eval()\n    preds = []\n    for b in tqdm(dl):\n        b[0].to('cuda')\n        b_preds = (sigmoid(learn.model(b[0])) > 0.5).permute(0, 2, 3, 1).cpu().detach().numpy().astype(np.uint8)\n        preds.append(b_preds)\n        torch.cuda.empty_cache()\n        gc.collect()\n    preds_arr = np.concatenate(preds)\n    del preds; gc.collect()\n    return preds_arr\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:25.363126Z","iopub.execute_input":"2022-06-14T06:07:25.365611Z","iopub.status.idle":"2022-06-14T06:07:25.375679Z","shell.execute_reply.started":"2022-06-14T06:07:25.365566Z","shell.execute_reply":"2022-06-14T06:07:25.374928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if INFER:\n    test_dl = learn.dls.test_dl(test, shuffle=False).to('cuda')\n    b = test_dl.one_batch()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:07:25.37962Z","iopub.execute_input":"2022-06-14T06:07:25.382237Z","iopub.status.idle":"2022-06-14T06:07:33.099248Z","shell.execute_reply.started":"2022-06-14T06:07:25.382194Z","shell.execute_reply":"2022-06-14T06:07:33.09846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if INFER:\n    learn.model = learn.model.cuda()\n    learn.model.eval()\n    test_preds = np.zeros((test.shape[0], b[0].shape[2], b[0].shape[3], b[0].shape[1]), dtype=np.uint8)\n    with torch.no_grad():\n        for i, b in enumerate(tqdm(test_dl)):\n            b[0].to('cuda')\n            b_preds = (sigmoid(learn.model(b[0])) > 0.5).permute(0, 2, 3, 1).cpu().detach().numpy().astype(np.uint8)\n            test_preds[i*16:i*16+16] = b_preds\n            torch.cuda.empty_cache()\n            gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:16:34.94822Z","iopub.execute_input":"2022-06-14T06:16:34.948515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if INFER:\n#     learn.model = learn.model.cuda()\n#     test_dl = learn.dls.test_dl(test, shuffle=False).to('cuda')\n#     test_preds = get_preds(learn, test_dl)\n  ","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:10:31.534884Z","iopub.status.idle":"2022-06-14T06:10:31.537279Z","shell.execute_reply.started":"2022-06-14T06:10:31.537016Z","shell.execute_reply":"2022-06-14T06:10:31.537043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Source: https://www.kaggle.com/code/clemchris/gi-seg-pytorch-train-infer\n\ndef mask2rle(mask):\n    \"\"\"\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    \"\"\"\n    mask = np.array(mask)\n    pixels = mask.flatten()\n    pad = np.array([0])\n    pixels = np.concatenate([pad, pixels, pad])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n\n    return \" \".join(str(x) for x in runs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\ndef get_rle_masks(preds, df):\n    rle_masks = []\n    for pred, width, height in tqdm(zip(preds, df['slice_w'], df['slice_h'])):\n        upsized_mask = cv2.resize(pred, dsize=(height, width), interpolation=cv2.INTER_NEAREST)\n        for i in range(3):\n            rle_mask = mask2rle(upsized_mask[:, :, i])\n            rle_masks.append(rle_mask)\n    return rle_masks","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:10:31.546305Z","iopub.status.idle":"2022-06-14T06:10:31.546986Z","shell.execute_reply.started":"2022-06-14T06:10:31.546715Z","shell.execute_reply":"2022-06-14T06:10:31.546741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if INFER:\n    masks = get_rle_masks(test_preds, test)   ","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:10:31.552178Z","iopub.status.idle":"2022-06-14T06:10:31.552878Z","shell.execute_reply.started":"2022-06-14T06:10:31.552599Z","shell.execute_reply":"2022-06-14T06:10:31.552624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if INFER:\n    submission = pd.DataFrame({\n        'id': chain.from_iterable([[get_case_id(fname)]*3 for fname in test_fnames]),\n        'class': chain.from_iterable([['large_bowel', 'small_bowel', 'stomach'] for _ in test_fnames]),\n        'predicted': masks,\n    })\n    \n    if sample_submission.shape[0] > 0:\n        del sample_submission['predicted']\n        submission = sample_submission.merge(submission, on=['id', 'class'])\n    \n    submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:10:31.554105Z","iopub.status.idle":"2022-06-14T06:10:31.554759Z","shell.execute_reply.started":"2022-06-14T06:10:31.554505Z","shell.execute_reply":"2022-06-14T06:10:31.554529Z"},"trusted":true},"execution_count":null,"outputs":[]}]}