{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing\n\n- segmentation-models\n\n    Used for creating segmentation model\n\n# Documentation\nhttps://github.com/qubvel/segmentation_models","metadata":{}},{"cell_type":"code","source":"!pip install segmentation_models","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:11.269346Z","iopub.execute_input":"2022-05-14T16:58:11.269673Z","iopub.status.idle":"2022-05-14T16:58:23.10612Z","shell.execute_reply.started":"2022-05-14T16:58:11.269589Z","shell.execute_reply":"2022-05-14T16:58:23.105176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:23.108572Z","iopub.execute_input":"2022-05-14T16:58:23.109029Z","iopub.status.idle":"2022-05-14T16:58:27.803964Z","shell.execute_reply.started":"2022-05-14T16:58:23.108921Z","shell.execute_reply":"2022-05-14T16:58:27.803234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = \"../input/uw-madison-gi-tract-image-segmentation\"\nTRAIN_IMAGES_PATH = os.path.join(BASE_PATH, \"train\")\nTRAIN_CSV_PATH = os.path.join(BASE_PATH, \"train.csv\")\nTEST_PATH = os.path.join(BASE_PATH, \"test\")","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:27.806221Z","iopub.execute_input":"2022-05-14T16:58:27.80664Z","iopub.status.idle":"2022-05-14T16:58:27.811657Z","shell.execute_reply.started":"2022-05-14T16:58:27.806604Z","shell.execute_reply":"2022-05-14T16:58:27.810841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data_augmentation = tf.keras.Sequential(\n    [\n        tf.keras.layers.RandomContrast(0.1),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:27.814167Z","iopub.execute_input":"2022-05-14T16:58:27.81448Z","iopub.status.idle":"2022-05-14T16:58:31.552353Z","shell.execute_reply.started":"2022-05-14T16:58:27.814444Z","shell.execute_reply":"2022-05-14T16:58:31.550544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Generator\n\nThis will load the dataset and apply transformation based on requirements","metadata":{}},{"cell_type":"code","source":"class Dataset(tf.keras.utils.Sequence):\n    def __init__(self, path, augmentation=True, batch_size=4, shuffle=True, size=(256, 256), csv_path=None):\n        self.path = path\n        self.size = size\n        self.augmentation = augmentation\n        self.load_images_paths()\n        \n        # Our classes\n        self.classes = [\"background\",\"large_bowel\", \"small_bowel\", \"stomach\"]\n\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        \n        self.keys = list(self.images.keys())\n        self.n = len(self.keys)\n        self.indexes = np.array(list(range(self.n)))\n        \n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n        if csv_path:\n            self.csv_path = csv_path\n            self.load_csv()\n    \n    def load_images_paths(self):\n        '''Loading All Slices paths only\n        '''\n        self.images = {}\n        for c1 in os.listdir(self.path):\n            path1 = os.path.join(self.path, c1)\n            for c2 in os.listdir(path1):\n                path2 = os.path.join(path1, c2, \"scans\")\n                for c3 in os.listdir(path2):\n                    path3 = os.path.join(path2, c3)\n                    self.images[f\"{c2}_{self.get_slice_name(c3)}\"] = {\"path\": path3,\n                                                                     \"class\": [],\n                                                                     \"segmentation\": [],\n                                                                     \"size\": (0 , 0)}\n\n    def get_slice_name(self, image_name):\n        image_name = image_name.split(\"_\")\n        return f\"{image_name[0]}_{image_name[1]}\"\n\n    def load_csv(self):\n        '''Load CSV for output labels\n        '''\n        self.csv_data = pd.read_csv(self.csv_path).values\n        \n        for v in self.csv_data:\n            self.images[v[0]][\"class\"].append(v[1])\n            self.images[v[0]][\"segmentation\"].append(v[2])\n    \n    def decode_segmentation(self, idx):\n        '''Convert CSV Labels to segmenation images\n        '''\n        values_list = self.images[idx][\"segmentation\"]\n        labels = self.images[idx][\"class\"]\n        size = self.images[idx][\"size\"]\n        \n        image = np.zeros(size[0] * size[1], dtype=np.uint8)\n        \n        for values, lbl in zip(values_list, labels):\n            if not type(values) == str:\n                continue\n            \n            lbl_id = self.classes.index(lbl)\n            values = values.split()\n            starts, lengths = [np.asarray(x, dtype=int) for x in (values[0:][::2], values[1:][::2])]\n            starts -= 1\n            ends = starts + lengths\n            for lo, hi in zip(starts, ends):\n                image[lo: hi] = lbl_id\n\n        result = image.reshape(size)\n        return result\n\n    def load_image(self, idx):\n        filename = self.images[idx][\"path\"]\n        img = cv2.imread(filename, cv2.CV_16UC1)\n        self.images[idx][\"size\"] = img.shape\n        return img\n    \n    def normalize(self, img):\n        '''Normalize input images\n        '''\n        return (img-np.min(img)) / (np.max(img)-np.min(img))\n    \n    def padding(self, img, seg):\n        '''Padd images to make them same size'''\n        h, w = img.shape\n        size = np.max([h, w])\n        new_img = np.zeros((size, size))\n        new_seg = np.zeros((size, size), dtype=\"uint8\")\n\n        pady = (size-h)//2\n        padx = (size-w)//2\n\n        new_img[pady:pady+h, padx:padx+w] = img\n        new_seg[pady:pady+h, padx:padx+w] = seg\n\n        return new_img, new_seg\n\n    def mask_resize(self, seg):\n        '''resize mask\n        class labels are in the form of one hot encoding, but the are inside image pixels.\n        '''\n        labels = np.unique(seg)\n        \n        new_seg = np.zeros((self.size[0], self.size[1], 4))\n        for l in labels:\n            if l == 0:\n                continue\n            temp_seg = seg.copy()\n            temp_seg[temp_seg != l] = 0\n            temp_seg[temp_seg == l] = 1\n            temp_seg = cv2.resize(temp_seg, (self.size))\n            new_seg[:, :, l] = temp_seg\n        return new_seg\n        \n    def preprocess(self, img, seg):\n        img, seg = self.padding(img, seg)\n        img = cv2.resize(img, (self.size))\n        img = self.normalize(img)\n        img2 = np.zeros((img.shape[0], img.shape[1], 3))\n        img2[:, :, 0] = img\n        img2[:, :, 1] = img\n        img2[:, :, 2] = img\n        seg = self.mask_resize(seg)\n        return img2, seg\n\n    def get_single_samples(self, idx):\n        idx = self.keys[idx]\n        img = self.load_image(idx)\n        seg = self.decode_segmentation(idx)\n        return img, seg\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.keys)\n\n    def __get_data(self, batches):\n        # Generates data containing batch_size samples\n    \n        X_batch = [] # input list\n        y_batch = [] # output list\n\n        for indx in batches: # loop to create new batch\n            keys = self.keys[indx]\n            img = self.load_image(keys)\n            seg = self.decode_segmentation(keys)\n            img, seg = self.preprocess(img, seg)\n#             img = input_data_augmentation(img)\n#             seg = seg_data_augmentation(seg)\n            X_batch.append(img)\n            y_batch.append(seg)\n\n        return np.array(X_batch, dtype=\"float32\"), np.array(y_batch, dtype=\"float32\")\n\n    def __getitem__(self, index):\n        # get name of the files for current batch\n        batches = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n        # load images from file name\n        return self.__get_data(batches)\n    \n    def __call__(self):\n        for i in self.indexes:\n            yield self.__getitem__(i)\n\n    def __len__(self):\n        return self.n // self.batch_size","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:31.553919Z","iopub.execute_input":"2022-05-14T16:58:31.554161Z","iopub.status.idle":"2022-05-14T16:58:31.591466Z","shell.execute_reply.started":"2022-05-14T16:58:31.554127Z","shell.execute_reply":"2022-05-14T16:58:31.59077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = Dataset(path=TRAIN_IMAGES_PATH, csv_path=TRAIN_CSV_PATH, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:31.594246Z","iopub.execute_input":"2022-05-14T16:58:31.594756Z","iopub.status.idle":"2022-05-14T16:58:35.306686Z","shell.execute_reply.started":"2022-05-14T16:58:31.594717Z","shell.execute_reply":"2022-05-14T16:58:35.305894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preview Dataset","metadata":{}},{"cell_type":"code","source":"images, segms = next(iter(train_data))\nfor img, seg in zip(images, segms):\n    img2 = img.copy()\n    img2 = (img2-np.min(img2))/(np.max(img2)-np.min(img2))\n    img2 = np.array(img2*255, dtype=\"uint8\")\n    # Class 1 shown as Red\n    img2[seg[:, :, 1] == 1] = (255, 0, 0)\n    # Class 2 shown as Green\n    img2[seg[:, :, 2] == 1] = (0, 255, 0)\n    # Class 3 shown as Blue\n    img2[seg[:, :, 3] == 1] = (0, 0, 255)\n    \n    plt.figure(figsize=(10, 10))\n    \n    all_imgs = [img,\n#                 seg[:, :, 1],\n#                 seg[:, :, 2],\n#                 seg[:, :, 3],\n                img2]\n\n    for indx, data in enumerate(all_imgs):\n        plt.subplot(1,len(all_imgs), indx+1)\n        plt.imshow(data)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:35.308149Z","iopub.execute_input":"2022-05-14T16:58:35.308456Z","iopub.status.idle":"2022-05-14T16:58:37.884673Z","shell.execute_reply.started":"2022-05-14T16:58:35.308419Z","shell.execute_reply":"2022-05-14T16:58:37.883985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation model","metadata":{}},{"cell_type":"code","source":"import segmentation_models as sm\nimport tensorflow.keras as keras\n# or from tensorflow import keras\nsm.set_framework('tf.keras')\n\nsm.framework()\n# keras.backend.set_image_data_format('channels_last')\n# or keras.backend.set_image_data_format('channels_first')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:37.885726Z","iopub.execute_input":"2022-05-14T16:58:37.886087Z","iopub.status.idle":"2022-05-14T16:58:38.588115Z","shell.execute_reply.started":"2022-05-14T16:58:37.886052Z","shell.execute_reply":"2022-05-14T16:58:38.587392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialize Models Parameters","metadata":{}},{"cell_type":"code","source":"# define optomizer\nLR = 1e-4\noptim = keras.optimizers.Adam(LR)\n\nn_classes = 4\n# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\ndice_loss = sm.losses.DiceLoss()\nfocal_loss = sm.losses.CategoricalFocalLoss()\ntotal_loss = dice_loss + (1 * focal_loss)\n\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n\nmodel = sm.FPN('efficientnetb3', classes=n_classes, activation='softmax')\n\n# compile keras model with defined optimozer, loss and metrics\nmodel.compile(optim, total_loss, metrics)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:01:41.224797Z","iopub.execute_input":"2022-05-14T17:01:41.225074Z","iopub.status.idle":"2022-05-14T17:01:43.968244Z","shell.execute_reply.started":"2022-05-14T17:01:41.225045Z","shell.execute_reply":"2022-05-14T17:01:43.967476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_weights(\"model.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:43.009791Z","iopub.execute_input":"2022-05-14T16:58:43.010056Z","iopub.status.idle":"2022-05-14T16:58:43.014318Z","shell.execute_reply.started":"2022-05-14T16:58:43.010022Z","shell.execute_reply":"2022-05-14T16:58:43.01356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model\n\n- Require GPU (otherwise it will take 7 Hours for 1 epoch)\n    - Kaggle proive 30 Hours of GPU (18 Minute with Kaggel GPU for each epoch)","metadata":{}},{"cell_type":"code","source":"model.fit(train_data,\n          epochs=30,\n          verbose=2,\n          callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath='model_FPN_{epoch:02d}.h5', save_weights_only=True),\n                     tf.keras.callbacks.ModelCheckpoint(filepath='model_FPN_.h5', save_weights_onlu=True)])","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:01:55.082876Z","iopub.execute_input":"2022-05-14T17:01:55.083292Z","iopub.status.idle":"2022-05-14T17:02:11.006334Z","shell.execute_reply.started":"2022-05-14T17:01:55.083256Z","shell.execute_reply":"2022-05-14T17:02:11.00508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}