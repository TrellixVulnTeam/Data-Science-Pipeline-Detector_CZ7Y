{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/segmentation-models-pytorch/segmentation_models.pytorch-master\")\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nsys.path.append(\"../input/pretrainedmodels/pretrainedmodels-0.7.4\")\nsys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch-master\")","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:45:51.933554Z","iopub.execute_input":"2022-04-19T13:45:51.93396Z","iopub.status.idle":"2022-04-19T13:45:51.968837Z","shell.execute_reply.started":"2022-04-19T13:45:51.933873Z","shell.execute_reply":"2022-04-19T13:45:51.967765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport gc\ngc.enable()\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom PIL import Image\nimport cv2\nimport albumentations as A\nimport time\nimport os\nfrom tqdm.notebook import tqdm\nimport segmentation_models_pytorch as smp\nfrom torch.cuda import amp\nscaler = amp.GradScaler()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:45:52.158986Z","iopub.execute_input":"2022-04-19T13:45:52.159221Z","iopub.status.idle":"2022-04-19T13:46:00.300583Z","shell.execute_reply.started":"2022-04-19T13:45:52.159192Z","shell.execute_reply":"2022-04-19T13:46:00.299516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input')","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:46:00.30393Z","iopub.execute_input":"2022-04-19T13:46:00.304254Z","iopub.status.idle":"2022-04-19T13:46:00.316365Z","shell.execute_reply.started":"2022-04-19T13:46:00.304206Z","shell.execute_reply":"2022-04-19T13:46:00.315236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv\")\nDEBUG = False\nif df.shape[0] == 0:\n    DEBUG = True\nif DEBUG == True:\n    df = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/train.csv\")\n    df.pop('segmentation')\n    df['predicted'] = \"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:46:00.318058Z","iopub.execute_input":"2022-04-19T13:46:00.318479Z","iopub.status.idle":"2022-04-19T13:46:00.83936Z","shell.execute_reply.started":"2022-04-19T13:46:00.318436Z","shell.execute_reply":"2022-04-19T13:46:00.838411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\ndf[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n# 2. Get Day as a column\ndf[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\ndf[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n# 3. Get Slice Identifier as a column\ndf[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\nif DEBUG:\n    TRAIN_DIR = '../input/uw-madison-gi-tract-image-segmentation/train'\nelse:\n    TRAIN_DIR = '../input/uw-madison-gi-tract-image-segmentation/test'\n# Get all training images\nall_train_images = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n\n# 4. Get full file paths for the representative scans\n# df[\"_partial_ident\"] = (+ \"\\\\\" + +\"\\\\\"+ \n#                        + \"\\\\scans\\\\\"+df[\"slice_id\"]) \n\np = []\nx = all_train_images[0].rsplit(\"/\", 4)[0]\nfor i in range(0, df.shape[0]):\n    p.append(os.path.join(x, df[\"case_id_str\"].values[i], df[\"case_id_str\"].values[i]+\"_\"+df[\"day_num_str\"].values[i], \"scans\", df[\"slice_id\"].values[i]))\ndf[\"_partial_ident\"] = p\n\np = []\nfor i in range(0, len(all_train_images)):\n    p.append(str(all_train_images[i].rsplit(\"_\",4)[0]))\n    \n_tmp_merge_df = pd.DataFrame()\n_tmp_merge_df['_partial_ident'] = p\n_tmp_merge_df['f_path'] = all_train_images\n\n\ndf = df.merge(_tmp_merge_df, on=\"_partial_ident\").drop(columns=[\"_partial_ident\"])\n\n# 5. Get slice dimensions from filepath (int in pixels)\ndf[\"slice_h\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\ndf[\"slice_w\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n\n# 6. Pixel spacing from filepath (float in mm)\ndf[\"px_spacing_h\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[3]))\ndf[\"px_spacing_w\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[4]))\n\ndf1 = df[df.index % 3 == 0]\ndf2 = df[df.index % 3 == 1]\ndf3 = df[df.index % 3 == 2]\ndf = df1.copy()\ndf.pop('class')\ngc.collect()\n\ndel x, df1, df2, df3, _tmp_merge_df\ngc.collect()\ndf = df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:46:00.842336Z","iopub.execute_input":"2022-04-19T13:46:00.84273Z","iopub.status.idle":"2022-04-19T13:46:10.70072Z","shell.execute_reply.started":"2022-04-19T13:46:00.842686Z","shell.execute_reply":"2022-04-19T13:46:10.699742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (df.shape)\nif DEBUG:\n    df = df.sample(frac=0.05).reset_index(drop=True)\nprint (df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:46:10.703976Z","iopub.execute_input":"2022-04-19T13:46:10.704608Z","iopub.status.idle":"2022-04-19T13:46:10.720688Z","shell.execute_reply.started":"2022-04-19T13:46:10.70454Z","shell.execute_reply":"2022-04-19T13:46:10.719712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TractDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.image_path = df['f_path']\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        \n        _img = self.open_gray16(self.image_path[idx])\n        _img = ((_img-_img.min())/(_img.max()-_img.min())).astype(np.float32)\n        img = (_img * 255.0).astype('uint8')\n        \n        if self.transform is not None:\n            aug = self.transform(image=img)\n            img = aug['image']\n            \n        img = img / 255.0\n        img = np.transpose(img, (2, 0, 1))\n        \n        return torch.tensor(img, dtype=torch.float)\n    \n    def open_gray16(self, _path, normalize=True, to_rgb=True):\n        \"\"\" Helper to open files \"\"\"\n        if normalize:\n            if to_rgb:\n                return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535., axis=-1), 3)\n            else:\n                return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535.\n        else:\n            if to_rgb:\n                return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n            else:\n                return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:46:10.722119Z","iopub.execute_input":"2022-04-19T13:46:10.722467Z","iopub.status.idle":"2022-04-19T13:46:10.734972Z","shell.execute_reply.started":"2022-04-19T13:46:10.722434Z","shell.execute_reply":"2022-04-19T13:46:10.733784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_epoch(loader):\n    model.eval()\n    LOGITS = []\n    \n    with torch.no_grad():\n        \n        for (data) in tqdm(loader):\n            \n            data = data.to(CFG['device'])\n            \n            output = model(data)\n            \n            LOGITS.append(torch.round(torch.sigmoid(output.cpu())).numpy().astype('uint8'))\n            \n    return LOGITS","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:46:10.736924Z","iopub.execute_input":"2022-04-19T13:46:10.737539Z","iopub.status.idle":"2022-04-19T13:46:10.750024Z","shell.execute_reply.started":"2022-04-19T13:46:10.737493Z","shell.execute_reply":"2022-04-19T13:46:10.74907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(img):\n    \"\"\" TBD\n    \n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n    \n    Returns: \n        run length as string formated\n    \"\"\"\n    \n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:46:10.752846Z","iopub.execute_input":"2022-04-19T13:46:10.753416Z","iopub.status.idle":"2022-04-19T13:46:10.761872Z","shell.execute_reply.started":"2022-04-19T13:46:10.753372Z","shell.execute_reply":"2022-04-19T13:46:10.760828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG = {\n    'fold' : 0, \n    'batch_size' : 16,\n    'image_size' : 256,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    'init_lr' : 1e-3,\n    'warmup_factor' : 10,\n    'warmup_epo' : 4,\n    'n_epochs' : 30,\n    'num_workers' : 4,\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:46:10.76392Z","iopub.execute_input":"2022-04-19T13:46:10.765033Z","iopub.status.idle":"2022-04-19T13:46:10.775358Z","shell.execute_reply.started":"2022-04-19T13:46:10.765Z","shell.execute_reply":"2022-04-19T13:46:10.774373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = smp.Unet('efficientnet-b1', encoder_weights=None, classes=3, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])\nmodel = model.to(CFG['device'])\nmodel_file = f'../input/effb1-unet/best_fold_{CFG[\"fold\"]}.pth'\nmodel.load_state_dict(torch.load(model_file))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:46:10.790281Z","iopub.execute_input":"2022-04-19T13:46:10.791168Z","iopub.status.idle":"2022-04-19T13:46:14.793832Z","shell.execute_reply.started":"2022-04-19T13:46:10.791125Z","shell.execute_reply":"2022-04-19T13:46:14.792864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_test = A.Compose([A.Resize(CFG['image_size'], CFG['image_size'], interpolation=cv2.INTER_NEAREST)])\ntest_set = TractDataset(df.reset_index(drop=True), transform_test)\ntest_loader = DataLoader(test_set, batch_size=CFG['batch_size'], shuffle=False) \n\nLOGITS = test_epoch(test_loader)\ndel test_set, test_loader\ngc.collect()\nLOGITS = np.vstack(LOGITS)\ndf = df[['id', 'slice_h', 'slice_w']]\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbs = []\nsbs = []\nsts = []\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    root_shape = (df.iloc[index][\"slice_h\"], df.iloc[index][\"slice_w\"])\n    pred_arr = np.round(cv2.resize(LOGITS[index, 0, :, :], root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n    lbs.append(rle_encode(pred_arr))\n    pred_arr = np.round(cv2.resize(LOGITS[index, 1, :, :], root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n    sbs.append(rle_encode(pred_arr))\n    pred_arr = np.round(cv2.resize(LOGITS[index, 2, :, :], root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n    sts.append(rle_encode(pred_arr))\ndel LOGITS\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:50:37.681102Z","iopub.execute_input":"2022-04-19T13:50:37.681511Z","iopub.status.idle":"2022-04-19T13:50:41.056851Z","shell.execute_reply.started":"2022-04-19T13:50:37.681477Z","shell.execute_reply":"2022-04-19T13:50:41.055577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[['id']]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:50:46.360972Z","iopub.execute_input":"2022-04-19T13:50:46.361708Z","iopub.status.idle":"2022-04-19T13:50:46.369864Z","shell.execute_reply.started":"2022-04-19T13:50:46.361673Z","shell.execute_reply":"2022-04-19T13:50:46.368717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\nclasses = []\nrles = []\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    ids.extend([row['id']] * 3)\n    classes.extend(['large_bowel', 'small_bowel', 'stomach'])\n    rles.extend([lbs[index], sbs[index], sts[index]])","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:50:47.785622Z","iopub.execute_input":"2022-04-19T13:50:47.786231Z","iopub.status.idle":"2022-04-19T13:50:48.169616Z","shell.execute_reply.started":"2022-04-19T13:50:47.786178Z","shell.execute_reply":"2022-04-19T13:50:48.168816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['id'] = ids\ndf['class'] = classes\ndf['predicted'] = rles\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:50:50.436166Z","iopub.execute_input":"2022-04-19T13:50:50.436831Z","iopub.status.idle":"2022-04-19T13:50:50.502489Z","shell.execute_reply.started":"2022-04-19T13:50:50.436778Z","shell.execute_reply":"2022-04-19T13:50:50.501461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T13:50:51.120893Z","iopub.execute_input":"2022-04-19T13:50:51.121294Z","iopub.status.idle":"2022-04-19T13:50:51.140235Z","shell.execute_reply.started":"2022-04-19T13:50:51.12126Z","shell.execute_reply":"2022-04-19T13:50:51.139076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}