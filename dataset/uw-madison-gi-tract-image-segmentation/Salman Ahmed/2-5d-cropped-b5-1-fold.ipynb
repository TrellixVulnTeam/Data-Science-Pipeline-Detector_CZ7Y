{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/segmentation-models-pytorch/segmentation_models.pytorch-master\")\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nsys.path.append(\"../input/pretrainedmodels/pretrainedmodels-0.7.4\")\nsys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch-master\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:33:05.705944Z","iopub.execute_input":"2022-06-07T05:33:05.706658Z","iopub.status.idle":"2022-06-07T05:33:05.737451Z","shell.execute_reply.started":"2022-06-07T05:33:05.706547Z","shell.execute_reply":"2022-06-07T05:33:05.73676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport gc\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom PIL import Image\nimport cv2\nimport albumentations as A\nimport time\nimport os\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nimport segmentation_models_pytorch as smp\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numba\nimport numpy as np\nfrom math import sqrt\nfrom scipy.spatial.distance import directed_hausdorff\nfrom scipy.ndimage import convolve\nfrom scipy.ndimage.morphology import distance_transform_edt as edt\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import KFold\nimport math","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:33:07.488753Z","iopub.execute_input":"2022-06-07T05:33:07.489039Z","iopub.status.idle":"2022-06-07T05:33:15.625378Z","shell.execute_reply.started":"2022-06-07T05:33:07.488986Z","shell.execute_reply":"2022-06-07T05:33:15.624528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_nd_df_test(df, WINDOW_SIZE=12, base_path_image=\"\", base_path_mask=\"\"):\n    IMG, MSK, STM, SML, LRG, SH, SW, F, ID, CASE, DAY = [], [], [], [], [], [], [], [], [], [], []\n    cases = df['case_id'].unique()\n    for eachC in cases:\n        xdf = df[df['case_id'] == eachC].reset_index(drop=True)\n        days = xdf['day_num'].unique()\n        for eachD in days:\n            xxdf = xdf[xdf['day_num'] == eachD].reset_index(drop=True)\n\n            for i in range(0, xxdf.shape[0]):\n                check = xxdf[i:i + WINDOW_SIZE]\n                if check.shape[0] != WINDOW_SIZE:\n                    break\n                else:\n                    id = check['id'].values[2]\n                    img = check['f_path'].values.tolist()\n                    msk = img[2]\n                    stm = [None, None, None, None, None]\n                    sml = [None, None, None, None, None]\n                    lrg = [None, None, None, None, None]\n                    slice_h = check['slice_h'].values.tolist()\n                    slice_w = check['slice_w'].values.tolist()\n                    case_id = check['case_id'].values.tolist()\n                    day_num = check['day_num'].values.tolist()\n                    fold = -1\n                    IMG.append(img)\n                    MSK.append(msk)\n                    STM.append(stm)\n                    SML.append(sml)\n                    LRG.append(lrg)\n                    SH.append(slice_h)\n                    SW.append(slice_w)\n                    F.append(fold)\n                    ID.append(id)\n                    CASE.append(case_id[0])\n                    DAY.append(day_num[0])\n\n    nndf = pd.DataFrame()\n    nndf[\"id\"] = ID\n    nndf[\"case_id\"] = CASE\n    nndf[\"day_num\"] = DAY\n    nndf[\"nd_images\"] = IMG\n    nndf[\"nd_masks\"] = MSK\n    nndf[\"stomach_rles\"] = STM\n    nndf[\"small_rles\"] = SML\n    nndf[\"large_rles\"] = LRG\n    nndf[\"slices_h\"] = SH\n    nndf[\"slices_w\"] = SW\n    nndf[\"fold\"] = F\n    return nndf\n\n\ndef get_1d_transformations(img_size):\n    data_transforms = {\n        \"train\": A.Compose([\n                    A.Resize(img_size, img_size, interpolation=cv2.INTER_NEAREST),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n            A.OneOf([\n                A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n            ], p=0.25),\n            A.CoarseDropout(max_holes=8, max_height=img_size // 20, max_width=img_size // 20,\n                            min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n        ], p=1.0),\n\n        \"valid\": A.Compose([A.Resize(img_size, img_size, interpolation=cv2.INTER_NEAREST)], p=1.0)\n    }\n    return data_transforms\n\n\ndef get_prepare_df(filename, sep = '\\\\', TRAIN_DIR = '../train'):\n\n    df = pd.read_csv(filename)\n\n    df[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\n    df[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n    # 2. Get Day as a column\n    df[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\n    df[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n    # 3. Get Slice Identifier as a column\n    df[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\n    # Get all training images\n    all_train_images = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n\n    p = []\n    x = all_train_images[0].rsplit(sep, 4)[0]\n    for i in range(0, df.shape[0]):\n        p.append(os.path.join(x, df[\"case_id_str\"].values[i],\n                              df[\"case_id_str\"].values[i] + \"_\" + df[\"day_num_str\"].values[i], \"scans\",\n                              df[\"slice_id\"].values[i]))\n    df[\"_partial_ident\"] = p\n\n    p = []\n    for i in range(0, len(all_train_images)):\n        p.append(str(all_train_images[i].rsplit(\"_\", 4)[0]))\n\n    _tmp_merge_df = pd.DataFrame()\n    _tmp_merge_df['_partial_ident'] = p\n    _tmp_merge_df['f_path'] = all_train_images\n\n    df = df.merge(_tmp_merge_df, on=\"_partial_ident\").drop(columns=[\"_partial_ident\"])\n\n    # 5. Get slice dimensions from filepath (int in pixels)\n    df[\"slice_h\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[1]))\n    df[\"slice_w\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[2]))\n\n    # 6. Pixel spacing from filepath (float in mm)\n    df[\"px_spacing_h\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\", 4)[3]))\n    df[\"px_spacing_w\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\", 4)[4]))\n\n    df1 = df[df.index % 3 == 0]\n    df2 = df[df.index % 3 == 1]\n    df3 = df[df.index % 3 == 2]\n    df = df1.copy()\n    df.pop('class')\n    gc.collect()\n\n    del df1, df2, df3\n    gc.collect()\n    df = df.reset_index(drop=True)\n    return df\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    \"\"\" TBD\n\n    Args:\n        img (np.array):\n            - 1 indicating mask\n            - 0 indicating background\n\n    Returns:\n        run length as string formated\n    \"\"\"\n\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef open_gray16(_path, normalize_f=True, normalize=False, to_rgb=False):\n    \"\"\" Helper to open competition specific files from path\n\n    Args:\n        _path (str): Path to the image on the LOCAL file system\n        normalize (bool, optional): Whether or not to coerce image to be between 0-1\n        to_rgb (bool, optional): Whether or not to tile the grayscale image to produce a pseudo RGB image\n\n    Returns:\n        The image as a numpy array\n    \"\"\"\n    if normalize_f:\n        img = cv2.imread(_path, cv2.IMREAD_UNCHANGED)\n        img = img.astype('float32')  # original is uint16\n        img = (img - img.min()) / (img.max() - img.min()) * 255.0  # scale image to [0, 255]\n        img = img.astype('uint8')\n        if to_rgb:\n            return np.tile(np.expand_dims(img, axis=-1), 3)\n        else:\n            return np.tile(np.expand_dims(img, axis=-1), 1)\n    elif normalize:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH) / 65535., axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH) / 65535.\n    else:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:33:19.684834Z","iopub.execute_input":"2022-06-07T05:33:19.685145Z","iopub.status.idle":"2022-06-07T05:33:19.728574Z","shell.execute_reply.started":"2022-06-07T05:33:19.685105Z","shell.execute_reply":"2022-06-07T05:33:19.727643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_1d_model(model_type='unet', encoder_name='timm-efficientnet-b4', encoder_weights='noisy-student',\n                 in_channels=1, classes=3, activation=None):\n\n    if model_type == 'unet':\n        model = smp.Unet(encoder_name=encoder_name, encoder_weights=encoder_weights,\n                         in_channels=in_channels, classes=classes, activation=activation)\n    elif model_type == 'fpn':\n        model = smp.FPN(encoder_name=encoder_name, encoder_weights=encoder_weights,\n                        in_channels=in_channels, classes=classes, activation=activation)\n    elif model_type == 'unetplusplus':\n        model = smp.UnetPlusPlus(encoder_name=encoder_name, encoder_weights=encoder_weights,\n                                 in_channels=in_channels, classes=classes, activation=activation)\n    elif model_type == 'linknet':\n        model = smp.Linknet(encoder_name=encoder_name, encoder_weights=encoder_weights,\n                            in_channels=in_channels, classes=classes, activation=activation)\n    elif model_type == 'deeplabv3':\n        model = smp.DeepLabV3(encoder_name=encoder_name, encoder_weights=encoder_weights,\n                              in_channels=in_channels, classes=classes, activation=activation)\n    elif model_type == 'deeplabv3plus':\n        model = smp.DeepLabV3Plus(encoder_name=encoder_name, encoder_weights=encoder_weights,\n                                  in_channels=in_channels, classes=classes, activation=activation)\n    elif model_type == 'pspnet':\n        model = smp.PSPNet(encoder_name=encoder_name, encoder_weights=encoder_weights,\n                           in_channels=in_channels, classes=classes, activation=activation)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:33:21.039255Z","iopub.execute_input":"2022-06-07T05:33:21.039526Z","iopub.status.idle":"2022-06-07T05:33:21.051103Z","shell.execute_reply.started":"2022-06-07T05:33:21.039495Z","shell.execute_reply":"2022-06-07T05:33:21.050077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv\")\nDEBUG = False\nif df.shape[0] == 0:\n    DEBUG = True","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:33:27.137897Z","iopub.execute_input":"2022-06-07T05:33:27.13826Z","iopub.status.idle":"2022-06-07T05:33:27.152494Z","shell.execute_reply.started":"2022-06-07T05:33:27.138227Z","shell.execute_reply":"2022-06-07T05:33:27.151816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG = {\n    'fold': 0,\n    'bs': 1,\n    'n_workers': 2,\n    'init_lr': 1e-3,\n    'warmup_factor': 10,\n    'warmup_epochs': 2,\n    'n_epochs': 50,\n    'img_size': 384,\n    'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    'debug': DEBUG,\n    'loss_name': 'dice',\n    'model_type': 'unet',\n    'encoder_name': 'timm-efficientnet-b4',\n    'in_channels': 5,\n    'num_classes': 3,\n    }","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:40:18.118539Z","iopub.execute_input":"2022-06-07T05:40:18.119392Z","iopub.status.idle":"2022-06-07T05:40:18.128565Z","shell.execute_reply.started":"2022-06-07T05:40:18.119344Z","shell.execute_reply":"2022-06-07T05:40:18.127601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_get_mask(img, tol=15):\n    mask = img>tol\n    return np.ix_(mask.any(1),mask.any(0))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:36:40.670899Z","iopub.execute_input":"2022-06-07T05:36:40.671531Z","iopub.status.idle":"2022-06-07T05:36:40.677444Z","shell.execute_reply.started":"2022-06-07T05:36:40.671491Z","shell.execute_reply":"2022-06-07T05:36:40.676176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TractDatasetNSeg(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.image_path = df['nd_images']\n        self.sh = df['slices_h']\n        self.sw = df['slices_w']\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n\n        img_paths = self.image_path[idx]\n        slack = []\n        for j in range(0, len(img_paths)):\n            slack.append(open_gray16(img_paths[j], to_rgb=False)[:, :, 0])\n            \n        slack = np.stack(slack)\n        slack = np.transpose(slack, (1, 2, 0))\n        m = crop_get_mask(slack[:, :, 2], 15)\n#         print (m[0].shape, m[1].shape)\n        img = slack[m]\n        prev_shape = (img.shape[0], img.shape[1])\n        \n        \n        if self.transform is not None:\n            aug = self.transform(image=img)\n            img = aug['image']\n        img = img / img.max()\n        img = np.transpose(img, (2, 0, 1))\n        return torch.tensor(img, dtype=torch.float), [self.sh[idx][2], self.sw[idx][2], m, prev_shape[0], prev_shape[1]]","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:36:40.907595Z","iopub.execute_input":"2022-06-07T05:36:40.908101Z","iopub.status.idle":"2022-06-07T05:36:40.920683Z","shell.execute_reply.started":"2022-06-07T05:36:40.908057Z","shell.execute_reply":"2022-06-07T05:36:40.91967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_1d_epoch(model, loader, device):\n\n    model.eval()\n    activation = nn.Sigmoid()\n    stomach = []\n    smalltract = []\n    largetract = []\n    with torch.no_grad():\n        for (data, xd) in tqdm(loader, total=len(loader)):\n            data = data.to(device)\n            output = model(data)\n            output = activation(output)\n            output = (output > 0.5).to(torch.float32).cpu().numpy()\n            sh, sw, m, prev_shape0, prev_shape1 = xd\n            prev_shape = (int(prev_shape1[0]), int(prev_shape0[0]))\n            m = [m[0][0].numpy(), m[1][0].numpy()]\n            for idx in range(0, len(sh)):\n                root_shape = (int(sw[idx]), int(sh[idx]), 1)\n                xpred_arr = np.round(cv2.resize(output[idx, 0, :, :].astype('uint8'), prev_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n                pred_arr = np.zeros(shape=root_shape)\n                pred_arr[m] = xpred_arr[:, :, np.newaxis]\n#                 print (prev_shape, root_shape, pred_arr[m].shape, xpred_arr.shape)\n                stomach.append(rle_encode(pred_arr[:, :, 0]))\n                xpred_arr = np.round(cv2.resize(output[idx, 1, :, :].astype('uint8'), prev_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n                pred_arr = np.zeros(shape=root_shape)\n                pred_arr[m] = xpred_arr[:, :, np.newaxis]\n                smalltract.append(rle_encode(pred_arr[:, :, 0]))\n                xpred_arr = np.round(cv2.resize(output[idx, 2, :, :].astype('uint8'), prev_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n                pred_arr = np.zeros(shape=root_shape)\n                pred_arr[m] = xpred_arr[:, :, np.newaxis]\n                largetract.append(rle_encode(pred_arr[:, :, 0]))\n            \n    return stomach, smalltract, largetract","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:34:40.260531Z","iopub.execute_input":"2022-06-07T05:34:40.260792Z","iopub.status.idle":"2022-06-07T05:34:40.274586Z","shell.execute_reply.started":"2022-06-07T05:34:40.260762Z","shell.execute_reply":"2022-06-07T05:34:40.273864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_1d_model(model_type=CFG['model_type'], encoder_name=CFG['encoder_name'], encoder_weights=None,\n                 in_channels=CFG['in_channels'], classes=CFG['num_classes'], activation=None).to(CFG['device'])","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:35:58.611313Z","iopub.execute_input":"2022-06-07T05:35:58.611581Z","iopub.status.idle":"2022-06-07T05:36:02.177102Z","shell.execute_reply.started":"2022-06-07T05:35:58.611551Z","shell.execute_reply":"2022-06-07T05:36:02.176246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_file = f'../input/unet-2-5d-2folds-384-50-epochs/2_5d_v1_crop_best_fold_0.pth'\nmodel.load_state_dict(torch.load(model_file))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:36:02.179637Z","iopub.execute_input":"2022-06-07T05:36:02.179845Z","iopub.status.idle":"2022-06-07T05:36:03.578789Z","shell.execute_reply.started":"2022-06-07T05:36:02.17982Z","shell.execute_reply":"2022-06-07T05:36:03.578066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = get_1d_transformations(CFG['img_size'])\nif CFG['debug']:\n    tr_csv_f = \"../input/uw-madison-gi-tract-image-segmentation/train.csv\"\n    df = get_prepare_df(tr_csv_f, sep='/', TRAIN_DIR = '../input/uw-madison-gi-tract-image-segmentation/train')\n    df = df[df['case_id'] == 30].reset_index(drop=True)\n    pdf = prepare_nd_df_test(df, WINDOW_SIZE=CFG['in_channels'])\n    test_set = TractDatasetNSeg(pdf.reset_index(drop=True), transforms[\"valid\"])\nelse:\n    tr_csv_f = \"../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv\"\n    df = get_prepare_df(tr_csv_f, sep='/', TRAIN_DIR = '../input/uw-madison-gi-tract-image-segmentation/test')\n    pdf = prepare_nd_df_test(df, WINDOW_SIZE=CFG['in_channels'])\n    test_set = TractDatasetNSeg(pdf.reset_index(drop=True), transforms[\"valid\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:40:21.208886Z","iopub.execute_input":"2022-06-07T05:40:21.209159Z","iopub.status.idle":"2022-06-07T05:40:36.643198Z","shell.execute_reply.started":"2022-06-07T05:40:21.209123Z","shell.execute_reply":"2022-06-07T05:40:36.642408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(test_set, batch_size=CFG['bs'], shuffle=False, num_workers=CFG['n_workers'])","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:40:36.644973Z","iopub.execute_input":"2022-06-07T05:40:36.645279Z","iopub.status.idle":"2022-06-07T05:40:36.649288Z","shell.execute_reply.started":"2022-06-07T05:40:36.645233Z","shell.execute_reply":"2022-06-07T05:40:36.648477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stomach, smalltract, largetract = test_1d_epoch(model, test_loader, CFG['device'])","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:40:36.650706Z","iopub.execute_input":"2022-06-07T05:40:36.651167Z","iopub.status.idle":"2022-06-07T05:40:55.115968Z","shell.execute_reply.started":"2022-06-07T05:40:36.651126Z","shell.execute_reply":"2022-06-07T05:40:55.115081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\nclasses = []\nrles = []\npids = pdf['id'].values\nix = 0\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    ids.extend([row['id']] * 3)\n    classes.extend(['large_bowel', 'small_bowel', 'stomach'])\n    if row['id'] in pids:\n        rles.extend([largetract[ix], smalltract[ix], stomach[ix]])\n        ix += 1\n    else:\n        v = np.zeros(shape = (row['slice_w'], row['slice_h']))\n        v = rle_encode(v)\n        rles.extend([v, v, v])\ngc.collect()\ndel largetract, smalltract, stomach\ngc.collect()\n\nxxdf = pd.DataFrame()\nxxdf['id'] = ids\nxxdf['class'] = classes\nxxdf['predicted'] = rles\nxxdf.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T05:40:55.118209Z","iopub.execute_input":"2022-06-07T05:40:55.118427Z","iopub.status.idle":"2022-06-07T05:40:55.646449Z","shell.execute_reply.started":"2022-06-07T05:40:55.118401Z","shell.execute_reply":"2022-06-07T05:40:55.645553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-20T19:17:47.806776Z","iopub.execute_input":"2022-05-20T19:17:47.807261Z","iopub.status.idle":"2022-05-20T19:17:47.828032Z","shell.execute_reply.started":"2022-05-20T19:17:47.807221Z","shell.execute_reply":"2022-05-20T19:17:47.827389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}