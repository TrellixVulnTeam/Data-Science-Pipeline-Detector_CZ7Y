{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Searching for duplicate files**\n\n## **Author: [Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan/)**\n## **CEO, [Moad Computer](http://www.moad.computer/)**\n\nAn example implementation of duplicate file detection using Python. This could be used as the backbone for a de-duplicated file system.","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import os, hashlib\nfrom glob import glob\nfrom tqdm.notebook import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute file hashes\nThe file hashes are computed for a specified chunk size using either SHA256 or Blake cryptographic functions using the [hashlib python library](https://docs.python.org/3/library/hashlib.html).","metadata":{}},{"cell_type":"code","source":"class FileHash():\n  def __init__(self, \n               chunk_size:int=4096, \n               crypto:str='blake2b')->None:\n    self.chunk_size = chunk_size\n    self.crypto = crypto\n  def file_hash(self, fname:str)->str:\n    _hash_fn = getattr(hashlib, self.crypto)()\n    with open(fname, 'rb') as f:\n      for _chunk in iter(lambda: f.read(self.chunk_size), b''):\n        _hash_fn.update(_chunk)\n    return _hash_fn.hexdigest()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detect file duplicates\nCreates a dictionary output with the cryptographic hash as the key and a list of files that share that specific cryptographic hash as the value.","metadata":{}},{"cell_type":"code","source":"class FileDedup(FileHash):\n  def __init__(self,\n               crypto:str='blake2b', \n               chunk_size:int=2048):\n    super().__init__()\n    self.crypto = crypto\n    self.chunk_size = chunk_size\n  def __call__(self,\n               file_list:list)->dict:\n    file_compare = {}\n    for f in tqdm(file_list):\n      try:\n        file_compare[self.file_hash(f)].append(f)\n      except KeyError:    \n        file_compare[self.file_hash(f)] = [f]\n    return file_compare","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dedup_dict = FileDedup(crypto='blake2b', chunk_size=4096)(\n               glob(\n                    '../input/uw-madison-gi-tract-image-segmentation/**/*.png', \n                    recursive=True\n                   )\n                 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing for duplicates in original dataset\nFinding the duplicate files can be performed by simply iterating over all the keys in the file comparison dictionary, looking for values with a list size of more than 1.","metadata":{}},{"cell_type":"code","source":"def find_duplicates(dedup_dict):\n  num_dup = 0  \n  for i, k in tqdm(enumerate(dedup_dict)):\n    if len(dedup_dict[k])>1:\n      print('\\n', dedup_dict[k], '\\n ')\n      num_dup += 1\n  print(f'Number of files with duplicates: {num_dup}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"find_duplicates(dedup_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create some duplicate files","metadata":{}},{"cell_type":"code","source":"!cp -r ../input/uw-madison-gi-tract-image-segmentation/train/case101/ ./","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing duplicate detection on the synthetic file list","metadata":{}},{"cell_type":"code","source":"file_list = glob(\n              '../input/uw-madison-gi-tract-image-segmentation/**/*.png', \n              recursive=True\n              )\nprint(len(file_list))\nfile_list.extend(glob('./case101/**/*.png', recursive=True))\nprint(len(file_list))\ndedup_dict = FileDedup(crypto='blake2b', chunk_size=4096)(file_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"find_duplicates(dedup_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}