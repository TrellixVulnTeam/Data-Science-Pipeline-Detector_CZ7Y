{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### There is a sequence in the images provided and I thought it will be interesting to visualize annotations of each case per day by viewing the slices provided as a short video which one can control. It will also help to analyse the quality of prediction on validation data once rendered correctly. ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T20:01:27.474233Z","iopub.execute_input":"2022-04-27T20:01:27.474708Z","iopub.status.idle":"2022-04-27T20:01:27.478419Z","shell.execute_reply.started":"2022-04-27T20:01:27.474675Z","shell.execute_reply":"2022-04-27T20:01:27.477733Z"}}},{"cell_type":"markdown","source":"# **Import Packages**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib import animation\nfrom matplotlib.patches import Rectangle\nimport os\nimport glob\nfrom IPython import display\nimport matplotlib.widgets\nimport cv2\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:18:53.669936Z","iopub.execute_input":"2022-04-27T20:18:53.670238Z","iopub.status.idle":"2022-04-27T20:18:53.889242Z","shell.execute_reply.started":"2022-04-27T20:18:53.670158Z","shell.execute_reply":"2022-04-27T20:18:53.888629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Training Data**","metadata":{}},{"cell_type":"code","source":"root = \"../input/uw-madison-gi-tract-image-segmentation/\"\ntrain = pd.read_csv(root + \"train.csv\").\\\n           replace({\"large_bowel\":\"lb\",\"small_bowel\":\"sb\",\"stomach\":\"st\"}).\\\n           set_index(['id','class']).unstack()['segmentation'].\\\n           reset_index().\\\n           rename_axis(None, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:18:53.89039Z","iopub.execute_input":"2022-04-27T20:18:53.893772Z","iopub.status.idle":"2022-04-27T20:18:54.674254Z","shell.execute_reply.started":"2022-04-27T20:18:53.8937Z","shell.execute_reply":"2022-04-27T20:18:54.673334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Process Training Data**","metadata":{}},{"cell_type":"code","source":"# Process Image MetaData\n\nimage_files = glob.glob(root + \"train/**/*.png\", recursive=True)\nimage_files_df = pd.DataFrame({\"path\":image_files})\nimage_files_df[\"files_cleaned\"] = image_files_df[\"path\"].map(lambda x: x.lstrip(\"../input/uw-madison-gi-tract-image-segmentation\"))\nimage_files_df[['case','case_day','scans','slice']] = image_files_df['files_cleaned'].str.split('/', -1, expand=True)\nimage_files_df = image_files_df.drop([\"files_cleaned\",\"scans\"],axis = 1)\nimage_files_df[[\"slice\",\"slice_id\",\"image_meta\"]] = image_files_df['slice'].str.split('_', 2, expand=True)\nimage_files_df['id'] = image_files_df[\"case_day\"]+ \"_\" + image_files_df[\"slice\"] + \"_\" + image_files_df[\"slice_id\"]\nimage_files_df[\"image_meta\"] = image_files_df[\"image_meta\"].map(lambda x: x.rstrip(\".png\"))\nimage_files_df[['height','width','ht_pxl','wd_pxl']] = image_files_df[\"image_meta\"].str.split('_', -1, expand=True)\nimage_files_df['height'] = image_files_df['height'].astype(int)\nimage_files_df['width'] = image_files_df['width'].astype(int)\nimage_files_df['ht_pxl'] = image_files_df['ht_pxl'].astype(float)\nimage_files_df['wd_pxl'] = image_files_df['wd_pxl'].astype(float)\nimage_files_df = image_files_df[['path','id','height','width','ht_pxl','wd_pxl']].drop_duplicates()\n\n# Process Train Data\n\ntrain_processed = train.copy()\ntrain_processed[['case','day','slice_name','slice']] = train_processed['id'].str.split('_', -1, expand=True)\ntrain_processed = train_processed.drop([\"slice_name\"], axis = 1)\ntrain_processed[\"case\"] = train_processed[\"case\"].map(lambda x: x.lstrip('case'))\ntrain_processed[\"day\"] = train_processed[\"day\"].map(lambda x: x.lstrip('day'))\n\n# Final Train Data\ntrain_final = pd.merge(train_processed,image_files_df,how = \"left\", on = [\"id\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:18:54.67553Z","iopub.execute_input":"2022-04-27T20:18:54.675851Z","iopub.status.idle":"2022-04-27T20:18:59.670201Z","shell.execute_reply.started":"2022-04-27T20:18:54.675811Z","shell.execute_reply":"2022-04-27T20:18:59.669392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Helper Functions**\n\nExcellent helper functions were provided in this [notebook](https://www.kaggle.com/code/dschettler8845/uwm-gi-tract-image-segmentation-eda) which I have reused here","metadata":{}},{"cell_type":"code","source":"def case_function(case_id,data):\n    return data[data[\"id\"] == case_id].squeeze()\n\ndef rle_decode(mask_rle, shape, color=1):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns: \n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    # Split the string by space, then convert it into a integer array\n    s = np.array(mask_rle.split(), dtype=int)\n\n    # Every even value is the start, every odd value is the \"run\" length\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n\n    # The image image is actually flattened since RLE is a 1D \"run\"\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n\n    # The color here is actually just any integer you want!\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n        \n    # Don't forget to change the image back to the original shape\n    return img.reshape(shape)\n\ndef open_gray16(_path, normalize=True, to_rgb=False):\n    \"\"\" Helper to open files \"\"\"\n    if normalize:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535., axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535.\n    else:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)\n\ndef overlay_plot(case_data,data):\n    img = open_gray16(case_data[\"path\"], to_rgb=True)\n    img = ((img-img.min())/(img.max()-img.min())).astype(np.float32)\n    seg_rgb = np.stack(\n        [rle_decode(case_data[f\"{_seg_type}\"], \n                shape=(case_data[\"width\"], case_data[\"height\"]), color=1) if not pd.isna(case_data[f\"{_seg_type}\"]) else np.zeros((case_data[\"width\"], case_data[\"height\"])) for _seg_type in [\"lb\", \"sb\", \"st\"]], axis=-1).astype(np.float32)\n    seg_overlay = cv2.addWeighted(src1=img, alpha=0.99, \n                              src2=seg_rgb, beta=0.33, gamma=0.0)\n    return seg_overlay","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:18:59.67186Z","iopub.execute_input":"2022-04-27T20:18:59.672122Z","iopub.status.idle":"2022-04-27T20:18:59.686027Z","shell.execute_reply.started":"2022-04-27T20:18:59.672095Z","shell.execute_reply":"2022-04-27T20:18:59.685225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Image GIF Generator**","metadata":{}},{"cell_type":"code","source":"def scan_as_gif(data,case_id,day,fps):\n    rel_cases = data[data[\"id\"].str.contains(f\"case{case_id}_day{day}\")][\"id\"].tolist()\n\n    frames = []\n    for i in rel_cases:\n        case_data = case_function(i,train_final)\n        seg_overlay = overlay_plot(case_data,train_final)\n        frames.append(seg_overlay)\n\n    plt.figure(figsize=(8,8))\n    patch = plt.imshow(frames[0]) \n    plt.title(f\"Segmentation Overlay For ID: {case_function(rel_cases[0],train_final)['id']}\", fontweight=\"bold\")\n    handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n    labels = [\"Large Bowel Segment\", \"Small Bowel Segmentat\", \"Stomach Segment\"]\n    plt.legend(handles,labels)\n    plt.axis(False)\n\n    def animate(i):\n        plt.title(f\"Segmentation Overlay For ID: {case_function(rel_cases[i],train_final)['id']}\", fontweight=\"bold\")\n        patch.set_data(frames[i])\n\n    anim = animation.FuncAnimation(plt.gcf(), \n                                       animate, \n                                       frames = len(frames), \n                                       interval=15)\n    video = anim.to_jshtml(fps = fps)\n    html = display.HTML(video)\n    return display.display(html)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:18:59.687293Z","iopub.execute_input":"2022-04-27T20:18:59.688201Z","iopub.status.idle":"2022-04-27T20:18:59.70486Z","shell.execute_reply.started":"2022-04-27T20:18:59.688146Z","shell.execute_reply":"2022-04-27T20:18:59.70403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Rendering**","metadata":{}},{"cell_type":"code","source":"scan_as_gif(data = train_final,\n            case_id = 101,\n            day = 20,\n            fps = 8\n           )\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:18:59.706198Z","iopub.execute_input":"2022-04-27T20:18:59.706686Z","iopub.status.idle":"2022-04-27T20:19:22.167567Z","shell.execute_reply.started":"2022-04-27T20:18:59.706623Z","shell.execute_reply":"2022-04-27T20:19:22.166853Z"},"trusted":true},"execution_count":null,"outputs":[]}]}