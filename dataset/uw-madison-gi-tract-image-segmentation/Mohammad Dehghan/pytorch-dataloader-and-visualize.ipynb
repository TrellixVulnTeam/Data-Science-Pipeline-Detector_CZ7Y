{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-15T20:45:17.079779Z","iopub.execute_input":"2022-04-15T20:45:17.080232Z","iopub.status.idle":"2022-04-15T20:45:17.084911Z","shell.execute_reply.started":"2022-04-15T20:45:17.080181Z","shell.execute_reply":"2022-04-15T20:45:17.083754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom PIL import Image as Img\nimport random\nfrom skimage import color\nimport glob\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:17.08602Z","iopub.execute_input":"2022-04-15T20:45:17.086223Z","iopub.status.idle":"2022-04-15T20:45:17.101175Z","shell.execute_reply.started":"2022-04-15T20:45:17.086197Z","shell.execute_reply":"2022-04-15T20:45:17.100019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_dir = '/kaggle/input/uw-madison-gi-tract-image-segmentation/'\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:17.10231Z","iopub.execute_input":"2022-04-15T20:45:17.10258Z","iopub.status.idle":"2022-04-15T20:45:17.112205Z","shell.execute_reply.started":"2022-04-15T20:45:17.102546Z","shell.execute_reply":"2022-04-15T20:45:17.111365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: I got this idea from https://www.kaggle.com/code/fabiendaniel/image-with-masks-quick-overview","metadata":{}},{"cell_type":"code","source":"\n\ndf_train = pd.read_csv(main_dir + 'train.csv')\n\n# name = df_train[200]\n\n# target = name.split('/')[-3] + '_slice_' + name.split('/')[-1].split('_')[1]\n# # print(name.split('/')[-3] + '_slice_' + name.split('/')[-1].split('_')[1])\n# # print(df_train.index[df_train['id']==target].tolist())\n# mask = decode_rle_mask(str(df_train.index[df_train['id']==target].tolist()[1]), (266,266))\n\ndf_train.sample(5)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:17.11329Z","iopub.execute_input":"2022-04-15T20:45:17.113552Z","iopub.status.idle":"2022-04-15T20:45:17.432229Z","shell.execute_reply.started":"2022-04-15T20:45:17.113521Z","shell.execute_reply":"2022-04-15T20:45:17.431478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nlist_images = glob('../input/uw-madison-gi-tract-image-segmentation/train/*/*/scans/*.png')\n# print(list_images[0])\n\nimage_properties = pd.DataFrame([(c, c.split('/')[-3], c.split('/')[-1]) for c in list_images], columns = ['whole_path', 'case_day', 'file'])\n\nimage_properties.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:17.434505Z","iopub.execute_input":"2022-04-15T20:45:17.434723Z","iopub.status.idle":"2022-04-15T20:45:17.866035Z","shell.execute_reply.started":"2022-04-15T20:45:17.434696Z","shell.execute_reply":"2022-04-15T20:45:17.864662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_properties['slice'] = image_properties['file'].apply(lambda x: f\"slice_{x.split('_')[1]}\")\nimage_properties.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:17.867448Z","iopub.execute_input":"2022-04-15T20:45:17.867775Z","iopub.status.idle":"2022-04-15T20:45:17.923902Z","shell.execute_reply.started":"2022-04-15T20:45:17.867733Z","shell.execute_reply":"2022-04-15T20:45:17.923227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_properties['height'] = image_properties['file'].apply(lambda x: int(x.split('_')[2]))\nimage_properties['width']  = image_properties['file'].apply(lambda x: int(x.split('_')[3]))\nimage_properties.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:17.92493Z","iopub.execute_input":"2022-04-15T20:45:17.925558Z","iopub.status.idle":"2022-04-15T20:45:18.049198Z","shell.execute_reply.started":"2022-04-15T20:45:17.925514Z","shell.execute_reply":"2022-04-15T20:45:18.048101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_properties['id']= image_properties['case_day'] + '_' + image_properties['slice']\nimage_properties.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:18.050584Z","iopub.execute_input":"2022-04-15T20:45:18.050957Z","iopub.status.idle":"2022-04-15T20:45:18.098508Z","shell.execute_reply.started":"2022-04-15T20:45:18.050916Z","shell.execute_reply":"2022-04-15T20:45:18.097715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.merge(df_train, image_properties, on='id', how='left')\ndf_train.sample(3)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:18.099928Z","iopub.execute_input":"2022-04-15T20:45:18.100417Z","iopub.status.idle":"2022-04-15T20:45:18.204136Z","shell.execute_reply.started":"2022-04-15T20:45:18.100378Z","shell.execute_reply":"2022-04-15T20:45:18.203534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualize some of the data","metadata":{}},{"cell_type":"code","source":"nx, ny = 6, 2\nfig, axes = plt.subplots(ny, nx, figsize=(24, 9))\nimages = random.choices(list_images, k=nx*ny)\n# print(images[0])\nfor num, img in enumerate(images):\n    i = num % nx\n    j = num // nx\n    image = Img.open(img)\n    image = np.array(image)\n#     iar_shp = np.array(image).shape\n    axes[j, i].axis('off')\n#     axes[j, i].set_title(str(img.parent).strip('/scans').split('/')[-1], color='red')\n    axes[j, i].imshow(image / image.max())\n    \nplt.subplots_adjust(wspace=0.05, hspace=0.05)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:18.205282Z","iopub.execute_input":"2022-04-15T20:45:18.205746Z","iopub.status.idle":"2022-04-15T20:45:19.231121Z","shell.execute_reply.started":"2022-04-15T20:45:18.205704Z","shell.execute_reply":"2022-04-15T20:45:19.230544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_decode(rle, height, width , fill=255):\n    s = rle.split()\n    start, length = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    start -= 1\n    mask = np.zeros(height*width, dtype=np.uint8)\n    for i, l in zip(start, length):\n        mask[i:i+l] = fill\n    mask = mask.reshape(width,height).T\n    mask = np.ascontiguousarray(mask)\n    return mask","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:19.232144Z","iopub.execute_input":"2022-04-15T20:45:19.232749Z","iopub.status.idle":"2022-04-15T20:45:19.239039Z","shell.execute_reply.started":"2022-04-15T20:45:19.232712Z","shell.execute_reply":"2022-04-15T20:45:19.238406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train[df_train['segmentation'].notnull()]\n\nnx, ny = 3, 4\nfig, axes = plt.subplots(ny, nx, figsize=(20, 15))\n\n\nfor i in range(ny):\n    print(random.randint(0, X.shape[0]))\n    sample = X.iloc[random.randint(0, X.shape[0])]\n#     print(sample.head())\n#     height, width = 255, 255\n    mask = rle_decode(sample['segmentation'], sample['height'], sample['width'], 255)\n#     mask = decode_rle_mask(sample['segmentation'], [sample['height'], sample['width']])\n    mask = (mask / 255).astype(int).T\n\n    if i == 0 : axes[i, 0].set_title(\"mask\", color='red')\n    axes[i, 0].set_ylabel(sample['id'])\n    axes[i, 0].imshow(mask)\n    image = Img.open(sample['whole_path'])\n    if i == 0 : axes[i, 1].set_title(\"image\", color='red')\n    axes[i, 1].imshow(np.array(image))\n\n    result_image = color.label2rgb(mask, np.array(image) / np.array(image).max())\n    if i == 0 : axes[i, 2].set_title(\"mask_image overlay\", color='red')\n    axes[i, 2].imshow(result_image)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:19.240168Z","iopub.execute_input":"2022-04-15T20:45:19.240564Z","iopub.status.idle":"2022-04-15T20:45:21.238214Z","shell.execute_reply.started":"2022-04-15T20:45:19.240524Z","shell.execute_reply":"2022-04-15T20:45:21.237587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PyTorch dataLoader","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python3\n# encoding: utf-8\n\n\nclass UW_Madison(Dataset):\n\n    def __init__(self, patients_dataframe, crop_size=None, modes=None, train=True):\n        self.patients_dataframe = patients_dataframe\n\n        self.modes = modes\n        self.train = train\n        self.crop_size = crop_size\n\n    def __len__(self):\n        return len(self.patients_dir)\n\n    def __getitem__(self, index):\n        sample = X.iloc[index]\n        mask = rle_decode(sample['segmentation'], sample['height'], sample['width'], 255)\n        mask = (mask / 255).astype(int).T\n        image = Img.open(sample['whole_path'])\n\n\n#         patient_dir = self.patients_dir[index]\n#         image = cv2.imread(patient_dir)\n\n        return image, mask\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:21.239441Z","iopub.execute_input":"2022-04-15T20:45:21.239891Z","iopub.status.idle":"2022-04-15T20:45:21.24704Z","shell.execute_reply.started":"2022-04-15T20:45:21.239844Z","shell.execute_reply":"2022-04-15T20:45:21.246389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patients_dataframe = df_train[df_train['segmentation'].notnull()]\n\ndata_loader = UW_Madison(patients_dataframe)\n\nfig , axes = plt.subplots(1, 3, figsize=(20, 15))\nimport numpy as np\nimage , mask = data_loader[0]\n# print(np.unique(mask))\naxes[0].imshow(np.array(image))\naxes[0].set_title('image')\n\naxes[1].imshow(mask)\naxes[1].set_title('mask')\n\nmerged_image = color.label2rgb(mask, np.array(image) / np.array(image).max())\naxes[2].set_title('merged_image')\naxes[2].imshow(merged_image)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T20:45:21.248185Z","iopub.execute_input":"2022-04-15T20:45:21.24862Z","iopub.status.idle":"2022-04-15T20:45:21.894152Z","shell.execute_reply.started":"2022-04-15T20:45:21.248571Z","shell.execute_reply":"2022-04-15T20:45:21.893379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Next version:\n\n    1. adding data_augmentation\n    2. training loop","metadata":{}}]}