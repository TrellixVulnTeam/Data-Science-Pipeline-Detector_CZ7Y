{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ“– Overview","metadata":{}},{"cell_type":"markdown","source":"We commonly work with predictions from the final layer of a neural network in deep learning tasks. In some circumstances, the outputs of intermediate layers may also be of relevance (especially in **semantic segmentations tasks**). It may be difficult to extract intermediate characteristics from the network, whether we wish to extract data embeddings or evaluate what prior layers have learned.\n\nThis Notebook demonstrates how to use PyTorch's forward hook feature to harvest intermediate activations from any layer of a deep learning model. The simplicity and ability to extract features without having to run the inference twice is a significant benefit of this method, which only requires a single forward pass through the model to save many outputs.","metadata":{}},{"cell_type":"markdown","source":"# ðŸ“– Why are intermediate features necessary?","metadata":{}},{"cell_type":"markdown","source":"Many applications benefit from the extraction of intermediate activations (also known as features). The outputs of intermediate CNN layers are commonly used to demonstrate the learning process and illustrate visual features discriminated by the model on different layers in computer vision challenges. Another common application is extracting intermediate outputs to build image or text embeddings, which can be used to detect duplicate items, include as input characteristics in a traditional ML model, show data clusters, and more. The outputs of intermediary layers can also be utilized to compress data into a smaller-sized vector carrying the data representation when dealing with Encoder-Decoder architectures. Intermediate activations can be useful in a variety of other situations. So let's talk about how to get them!","metadata":{}},{"cell_type":"markdown","source":"# ðŸ“– How to extract intermediate features?","metadata":{}},{"cell_type":"markdown","source":"To extract activations from intermediate layers, we'll need to create a forward hook in our neural network for the layers we're interested in and use inference to store the relevant outputs.\n","metadata":{}},{"cell_type":"markdown","source":"# ðŸ“– Model","metadata":{}},{"cell_type":"markdown","source":"To extract anything from a neural network, we must first put it up, correct? We create a basic Efficientnet b0 model with a two-node output layer in the cell below. The model is instantiated with the timm library, however feature extraction will work with any neural network constructed in PyTorch.\n\nWe also print out our network's architecture. As you can see, our image passes through numerous intermediary layers during a forward pass before becoming a two-number output. The names of the layers should be written down since they will be required by a feature extraction algorithm.","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# pytorch\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# timm\n!pip install timm\nimport timm\n\n# augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport cv2\nimport os\nfrom glob import glob\n\ndevice = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:13:45.848381Z","iopub.execute_input":"2022-05-24T19:13:45.850687Z","iopub.status.idle":"2022-05-24T19:14:09.34582Z","shell.execute_reply.started":"2022-05-24T19:13:45.848999Z","shell.execute_reply":"2022-05-24T19:14:09.344972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model    = timm.create_model(model_name = 'efficientnet_b0', pretrained = True)\nmodel.fc = nn.Linear(512, 2)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:14:09.348155Z","iopub.execute_input":"2022-05-24T19:14:09.348485Z","iopub.status.idle":"2022-05-24T19:14:10.281347Z","shell.execute_reply.started":"2022-05-24T19:14:09.348438Z","shell.execute_reply":"2022-05-24T19:14:10.280733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“– Feature extraction","metadata":{}},{"cell_type":"markdown","source":"Feature extraction may be implemented in two easy steps:\n\n1. Registering a forward hook on a certain network layer.\n2. To extract features from that layer, use put model in inference.\n\nTo begin, we must create a helper function that will add a hook. When a forward or backward call to a certain layer is made, a hook is just a command that is executed. This [site](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/) will tell you all you need to know about hooks.\n\nWe're looking for a forward hook that just replicates the layer outputs, delivers them to the CPU, and stores them to a dictionary object called features in our setup.\n\nIn the cell below, the hook is defined. The dictionary key under which we will keep our intermediate activations is specified by the name parameter in get features().","metadata":{}},{"cell_type":"code","source":"def get_features(name):\n    def hook(model, input, output):\n        features[name] = output.detach()\n    return hook","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:14:10.282596Z","iopub.execute_input":"2022-05-24T19:14:10.283024Z","iopub.status.idle":"2022-05-24T19:14:10.287451Z","shell.execute_reply.started":"2022-05-24T19:14:10.282981Z","shell.execute_reply":"2022-05-24T19:14:10.286633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We may use the .register forward hook() method to register a hook after the helper function has been created. Any layer of the neural network can be used as a hook.\n\nBecause we're using a CNN, collecting features from the final convolutional layer might be beneficial for obtaining Â embeddings. As a result, we're registering a hook for the (global pool) outputs. We could also use model.layer1[1].act2 to extract features from an earlier layer and put them in the features dictionary under a different name. We can technically register many hooks (one for each layer of interest) with this technique, but for the sake of this example, we'll simply maintain one.","metadata":{}},{"cell_type":"code","source":"model.global_pool.register_forward_hook(get_features('feats'))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:14:10.289831Z","iopub.execute_input":"2022-05-24T19:14:10.290132Z","iopub.status.idle":"2022-05-24T19:14:10.302415Z","shell.execute_reply.started":"2022-05-24T19:14:10.290091Z","shell.execute_reply":"2022-05-24T19:14:10.301667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We're all set to extract features now! The good thing about hooks is that we can now conduct inference as normal while simultaneously receiving many outputs:\n\n1. the last layer's outputs\n2. each layer's outputs using a registered hook\n\nWhen we run the model, the feature extraction happens automatically during the forward pass (inputs). We only need to put the following in our inference loop to save intermediate features and concatenate them across batches:\n\n* Make a placeholder list called **Feat = []**. All batch intermediate outputs will be stored in this list.\n\n* Make a placeholder dict with **features = {}** This dictionary will be used to store intermediate outputs from each batch.\n\n* Extract batch features to **features** iteratively, send them to the CPU, and add them to the **Feat** list.\n","metadata":{}},{"cell_type":"code","source":"# # placeholders\n# PREDS = []\n# FEATS = []\n\n# # placeholder for batch features\n# features = {}\n\n# # loop through batches\n# for idx, inputs in enumerate(test_dataloader):\n\n#     # move to device\n#     inputs = inputs.to(device)\n       \n#     # forward pass [with feature extraction]\n#     preds = model(inputs)\n    \n#     # add feats and preds to lists\n#     PREDS.append(preds.detach().cpu().numpy())\n#     FEATS.append(features['feats'].cpu().numpy())\n\n#     # early stop\n#     if idx == 9:\n#         break","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:14:10.693839Z","iopub.status.idle":"2022-05-24T19:14:10.694644Z","shell.execute_reply.started":"2022-05-24T19:14:10.694304Z","shell.execute_reply":"2022-05-24T19:14:10.694359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thanks for your attention","metadata":{}}]}