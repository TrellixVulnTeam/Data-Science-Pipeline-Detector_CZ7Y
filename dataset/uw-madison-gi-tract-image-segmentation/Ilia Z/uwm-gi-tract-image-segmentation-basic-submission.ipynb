{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom glob import glob\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-05-12T14:09:41.303919Z","iopub.execute_input":"2022-05-12T14:09:41.304701Z","iopub.status.idle":"2022-05-12T14:09:41.309673Z","shell.execute_reply.started":"2022-05-12T14:09:41.304631Z","shell.execute_reply":"2022-05-12T14:09:41.308897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... BASIC DATA SETUP STARTING ...\\n\\n\")\n\n# Open the training dataframe and display the initial dataframe\nDATA_DIR = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\nTRAIN_DIR = os.path.join(DATA_DIR, \"train\")\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV)\n\n# Get all training images\nall_train_images = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n\nprint(\"\\n... ORIGINAL TRAINING DATAFRAME... \\n\")\ndisplay(train_df)\n\nTEST_DIR = os.path.join(DATA_DIR, \"test\")\nSS_CSV   = os.path.join(DATA_DIR, \"sample_submission.csv\")\nss_df = pd.read_csv(SS_CSV)\n\n# Get all testing images if there are any\nall_test_images = glob(os.path.join(TEST_DIR, \"**\", \"*.png\"), recursive=True)\n\n# For debugging purposes when the test set hasn't been substituted we will know\nDEBUG=len(ss_df)==0\n\nif DEBUG:\n    TEST_DIR = TRAIN_DIR\n    all_test_images = all_train_images\n    ss_df = train_df.iloc[:10]\n    ss_df = ss_df[[\"id\", \"class\"]]\n    ss_df[\"predicted\"] = \"\"\n    \n\nprint(\"\\n\\n\\n... ORIGINAL SUBMISSION DATAFRAME... \\n\")    \ndisplay(ss_df)\n\nSF2LF = {\"lb\":\"Large Bowel\",\"sb\":\"Small Bowel\",\"st\":\"Stomach\"}\nLF2SF = {v:k for k,v in SF2LF.items()}\nprint(f\"\\n\\n\\n... ARE WE DEBUGGING: {DEBUG}... \\n\")\n\nprint(\"\\n... BASIC DATA SETUP FINISHED ...\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-12T14:09:41.503591Z","iopub.execute_input":"2022-05-12T14:09:41.503896Z","iopub.status.idle":"2022-05-12T14:09:47.704111Z","shell.execute_reply.started":"2022-05-12T14:09:41.503863Z","shell.execute_reply":"2022-05-12T14:09:47.70346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_filepath_from_partial_identifier(_ident, file_list):\n    return [x for x in file_list if _ident in x][0]\n\ndef df_preprocessing(df, globbed_file_list, is_test=False):\n    \"\"\" The preprocessing steps applied to get column information \"\"\"\n    # 1. Get Case-ID as a column (str and int)\n    df[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\n    df[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n    # 2. Get Day as a column\n    df[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\n    df[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n    # 3. Get Slice Identifier as a column\n    df[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\n    # 4. Get full file paths for the representative scans\n    df[\"_partial_ident\"] = (globbed_file_list[0].rsplit(\"/\", 4)[0]+\"/\"+ # /kaggle/input/uw-madison-gi-tract-image-segmentation/train/\n                           df[\"case_id_str\"]+\"/\"+ # .../case###/\n                           df[\"case_id_str\"]+\"_\"+df[\"day_num_str\"]+ # .../case###_day##/\n                           \"/scans/\"+df[\"slice_id\"]) # .../slice_#### \n    _tmp_merge_df = pd.DataFrame({\"_partial_ident\":[x.rsplit(\"_\",4)[0] for x in globbed_file_list], \"f_path\":globbed_file_list})\n    df = df.merge(_tmp_merge_df, on=\"_partial_ident\").drop(columns=[\"_partial_ident\"])\n\n    # 5. Get slice dimensions from filepath (int in pixels)\n    df[\"slice_h\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"slice_w\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n\n    # 6. Pixel spacing from filepath (float in mm)\n    df[\"px_spacing_h\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[3]))\n    df[\"px_spacing_w\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[4]))\n\n    if not is_test:\n        # 7. Merge 3 Rows Into A Single Row (As This/Segmentation-RLE Is The Only Unique Information Across Those Rows)\n        l_bowel_df = df[df[\"class\"]==\"large_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"lb_seg_rle\"})\n        s_bowel_df = df[df[\"class\"]==\"small_bowel\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"sb_seg_rle\"})\n        stomach_df = df[df[\"class\"]==\"stomach\"][[\"id\", \"segmentation\"]].rename(columns={\"segmentation\":\"st_seg_rle\"})\n        df = df.merge(l_bowel_df, on=\"id\", how=\"left\")\n        df = df.merge(s_bowel_df, on=\"id\", how=\"left\")\n        df = df.merge(stomach_df, on=\"id\", how=\"left\")\n        df = df.drop_duplicates(subset=[\"id\",]).reset_index(drop=True)\n        df[\"lb_seg_flag\"] = df[\"lb_seg_rle\"].apply(lambda x: not pd.isna(x))\n        df[\"sb_seg_flag\"] = df[\"sb_seg_rle\"].apply(lambda x: not pd.isna(x))\n        df[\"st_seg_flag\"] = df[\"st_seg_rle\"].apply(lambda x: not pd.isna(x))\n        df[\"n_segs\"] = df[\"lb_seg_flag\"].astype(int)+df[\"sb_seg_flag\"].astype(int)+df[\"st_seg_flag\"].astype(int)\n\n    # 8. Reorder columns to the a new ordering (drops class and segmentation as no longer necessary)\n    new_col_order = [\"id\", \"f_path\", \"n_segs\",\n                     \"lb_seg_rle\", \"lb_seg_flag\",\n                     \"sb_seg_rle\", \"sb_seg_flag\", \n                     \"st_seg_rle\", \"st_seg_flag\",\n                     \"slice_h\", \"slice_w\", \"px_spacing_h\", \n                     \"px_spacing_w\", \"case_id_str\", \"case_id\", \n                     \"day_num_str\", \"day_num\", \"slice_id\",]\n    if is_test: new_col_order.insert(1, \"class\")\n    new_col_order = [_c for _c in new_col_order if _c in df.columns]\n    df = df[new_col_order]\n    \n    return df\n\ntrain_df = df_preprocessing(train_df, all_train_images)\nss_df = df_preprocessing(ss_df, all_test_images, is_test=True)\n\ndisplay(train_df)\ndisplay(ss_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T14:10:00.901752Z","iopub.execute_input":"2022-05-12T14:10:00.902423Z","iopub.status.idle":"2022-05-12T14:10:02.997135Z","shell.execute_reply.started":"2022-05-12T14:10:00.902369Z","shell.execute_reply":"2022-05-12T14:10:02.996321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns: \n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    # Split the string by space, then convert it into a integer array\n    s = np.array(mask_rle.split(), dtype=int)\n\n    # Every even value is the start, every odd value is the \"run\" length\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n\n    # The image image is actually flattened since RLE is a 1D \"run\"\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n\n    # The color here is actually just any integer you want!\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n        \n    # Don't forget to change the image back to the original shape\n    return img.reshape(shape)\n\n# https://www.kaggle.com/namgalielei/which-reshape-is-used-in-rle\ndef rle_decode_top_to_bot_first(mask_rle, shape):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns:\n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape((shape[1], shape[0]), order='F').T  # Reshape from top -> bottom first\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    \"\"\" TBD\n    \n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n    \n    Returns: \n        run length as string formated\n    \"\"\"\n    \n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef open_gray16(_path, normalize=True, to_rgb=False):\n    \"\"\" Helper to open files \"\"\"\n    if normalize:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535., axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535.\n    else:\n        if to_rgb:\n            return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n        else:\n            return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)\n        \ndef fix_empty_slices(_row):\n    if int(_row[\"slice_id\"].rsplit(\"_\", 1)[-1]) in remove_seg_slices[_row[\"class\"]]:\n        _row[\"predicted\"] = \"\"\n    return _row\n\ndef is_isolated(_row):\n    return (_row[\"predicted\"]!=\"\" and _row[\"prev_predicted\"]==\"\" and _row[\"next_predicted\"]==\"\")\n\ndef fix_nc_slices(_row):\n    if _row[\"seg_isolated\"]:\n        _row[\"predicted\"] = \"\"\n    return _row\n\nremove_seg_slices = {\n    \"large_bowel\": [1, 138, 139, 140, 141, 142, 143, 144],\n    \"small_bowel\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 138, 139, 140, 141, 142, 143, 144],\n    \"stomach\": [1, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144],\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-12T14:10:58.450311Z","iopub.execute_input":"2022-05-12T14:10:58.451059Z","iopub.status.idle":"2022-05-12T14:10:58.592436Z","shell.execute_reply.started":"2022-05-12T14:10:58.451007Z","shell.execute_reply":"2022-05-12T14:10:58.591847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **I HAVE REDUCED IT TO 5 BASIC PATHS**\n\n* **`'all_random'`**\n    * Predict masks/rle as completely random scattering of 0s and 1s\n* **`'all_zeros'`**\n    * Predict masks/rle as all zeros (black --> rle=\"\")\n* **`'all_ones'`**\n    * Predict masks/rle as all ones (white --> rle=\"1 [numer-of-pixels]\")\n* **`'basic_random'`**\n    * Predict masks/rle by sampling similar examples from the training dataset\n* **`'smart_random'`**\n    * Predict masks/rle by sampling similar examples from the training dataset\n    * Also apply basic heuristics to the final output to try to improve    ","metadata":{}},{"cell_type":"code","source":"SUBMISSION_STYLE = \"smart_random\" # ['smart_random', 'basic_random', 'all_random', all_zeros', 'all_ones']\n\nif SUBMISSION_STYLE==\"all_zeros\":\n    ss_df[\"predicted\"] = \"\"\nelif SUBMISSION_STYLE==\"all_ones\":\n    ss_df[\"predicted\"] = \"1 \"+(ss_df[\"slice_w\"]*ss_df[\"slice_h\"]).astype(str)\nelif SUBMISSION_STYLE==\"all_random\":\n    ss_df[\"predicted\"] = ss_df.apply(lambda row: rle_encode(np.where(np.random.random((row[\"slice_w\"], row[\"slice_h\"]))>0.5, 1.0, 0.0)), axis=1)\nelse:\n    \n    \n    # 1. Remove broken masks\n    remove_ids = [\"case7_day0\", \"case81_day30\"]\n    for _id in remove_ids:\n        train_df = train_df[~train_df.id.str.contains(_id)].reset_index(drop=True)\n\n    # 2. Get existing training data mappings to align with known metadata\n    slice_px_map = {}\n    for _, row in train_df.groupby([\"slice_h\", \"slice_w\", \"px_spacing_h\", \"px_spacing_w\", \"slice_id\"])[[\"lb_seg_rle\", \"sb_seg_rle\", \"st_seg_rle\"]].first().reset_index().iterrows():\n        slice_px_map[f\"{row['slice_h']}-{row['slice_w']}-{row['px_spacing_h']}-{row['px_spacing_w']}-{row['slice_id']}-large_bowel\"] = row[\"lb_seg_rle\"]\n        slice_px_map[f\"{row['slice_h']}-{row['slice_w']}-{row['px_spacing_h']}-{row['px_spacing_w']}-{row['slice_id']}-small_bowel\"] = row[\"sb_seg_rle\"]\n        slice_px_map[f\"{row['slice_h']}-{row['slice_w']}-{row['px_spacing_h']}-{row['px_spacing_w']}-{row['slice_id']}-stomach\"] = row[\"st_seg_rle\"]\n    \n    # 3. Create a lookup and assign the prediction RLE\n    ss_df[\"ident\"] = ss_df['slice_h'].astype(str)+\"-\"+ss_df['slice_w'].astype(str)+\"-\"+ss_df['px_spacing_h'].astype(str)+\"-\"+ss_df['px_spacing_w'].astype(str)+\"-\"+ss_df['slice_id'].astype(str)+\"-\"+ss_df[\"class\"].astype(str)\n    ss_df[\"predicted\"] = ss_df[\"ident\"].map(slice_px_map)\n    ss_df[\"predicted\"] = ss_df[\"predicted\"].apply(lambda x: \"\" if x==None else x)\n\n    \n    # 4. If we want some additional post processing we do that here\n    if SUBMISSION_STYLE==\"smart_random\":\n        \n        # 4a. Remove RLE masks from areas where no mask should exist\n        ss_df = ss_df.apply(fix_empty_slices, axis=1)\n        \n        # 4b. Remove non-contiguous masks that do not align with known patterns\n        ss_df[\"prev_predicted\"] = ss_df.shift(3, fill_value=\"\")[\"predicted\"]\n        ss_df[\"next_predicted\"] = ss_df.shift(-3, fill_value=\"\")[\"predicted\"]\n        ss_df[\"seg_isolated\"] = ss_df.apply(is_isolated, axis=1)\n        ss_df = ss_df.apply(fix_nc_slices, axis=1)\n        \n# 5. Reduce number of columns and save        \nss_df = ss_df[[\"id\", \"class\", \"predicted\"]]\nss_df.to_csv(\"submission.csv\", index=False)\ndisplay(ss_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T14:11:01.228428Z","iopub.execute_input":"2022-05-12T14:11:01.229119Z","iopub.status.idle":"2022-05-12T14:11:01.257267Z","shell.execute_reply.started":"2022-05-12T14:11:01.229079Z","shell.execute_reply":"2022-05-12T14:11:01.256582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}