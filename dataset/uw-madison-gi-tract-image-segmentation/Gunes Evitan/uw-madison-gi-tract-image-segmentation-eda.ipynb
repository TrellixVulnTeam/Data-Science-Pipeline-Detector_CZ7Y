{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm.notebook import tqdm\nfrom glob import glob\n\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-15T11:29:48.083138Z","iopub.execute_input":"2022-04-15T11:29:48.083736Z","iopub.status.idle":"2022-04-15T11:29:48.089308Z","shell.execute_reply.started":"2022-04-15T11:29:48.083687Z","shell.execute_reply":"2022-04-15T11:29:48.088496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UW-Madison GI Tract Image Segmentation","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction\n\nThis competition's objective is segmentation of stomach and intestines on MRI scans. The MRI scans are from actual cancer patients who had 1-5 MRI scans on separate days during their radiation treatment. There are total of 85 cases, 274 MRI scans and 33913 annotations in training set, and there are roughly 50 cases in hidden test set.\n\nThere are 3 columns in `train.csv` file named id, class and segmentation.\n\n* `id` - Unique ID of the slice\n* `class` - Class of the object (large bowel, small bowel or stomach)\n* `segmentation` - Run length encoded segmentation masks\n\nid column can be decomposed into 3 columns; case, day and slice. Those columns can be used for selecting slices from directories.\n\n* `case` - Case ID\n* `day` - Scan day\n* `slice` - Slice number","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\nprint(f'Training Set Shape: {df_train.shape} - {df_train[~df_train[\"segmentation\"].isnull()].shape[0]} Annotations - Memory Usage: {df_train.memory_usage().sum() / 1024 ** 2:.2f} MB')\n\ndf_train = pd.concat((\n    df_train,\n    df_train['id'].str.split('_', expand=True).drop(columns=[2]).rename(columns={0: 'case', 1: 'day', 3: 'slice_number'})\n), axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T11:31:07.871862Z","iopub.execute_input":"2022-04-15T11:31:07.872223Z","iopub.status.idle":"2022-04-15T11:31:08.576455Z","shell.execute_reply.started":"2022-04-15T11:31:07.872187Z","shell.execute_reply":"2022-04-15T11:31:08.575545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training annotations are provided as run-length encoded binary segmentation masks. They have to be decoded into 2 dimensional arrays in order to be processed which can be done with the function defined below.","metadata":{}},{"cell_type":"code","source":"def decode_rle_mask(rle_mask, shape):\n\n    \"\"\"\n    Decode run-length encoded segmentation mask string into 2d array\n\n    Parameters\n    ----------\n    rle_mask (str): Run-length encoded segmentation mask string\n    shape (tuple): Height and width of the mask\n\n    Returns\n    -------\n    mask [numpy.ndarray of shape (height, width)]: Decoded 2d segmentation mask\n    \"\"\"\n\n    rle_mask = rle_mask.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (rle_mask[0:][::2], rle_mask[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n\n    mask = np.zeros((shape[0] * shape[1]), dtype=np.uint8)\n    for start, end in zip(starts, ends):\n        mask[start:end] = 1\n\n    mask = mask.reshape(shape[0], shape[1])\n    return mask\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T11:31:09.38469Z","iopub.execute_input":"2022-04-15T11:31:09.385313Z","iopub.status.idle":"2022-04-15T11:31:09.391739Z","shell.execute_reply.started":"2022-04-15T11:31:09.385264Z","shell.execute_reply":"2022-04-15T11:31:09.391137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Metadata\n\nMRIs are in 16-bit grayscale PNG format, not in DICOM format so their metadata is not available. However, filenames of slices include image height, width and pixel spacings on x and y axes. That information can be extracted from them.\n\n* `image_height` - Image height in pixels\n* `image_width` - Image width in pixels\n* `image_vertical_pixel_spacing` - Physical distance in real world that corresponds to vertical distance between two pixel centers\n* `image_horizontal_pixel_spacing` - Physical distance in real world that corresponds to horizontal distance between two pixel centers\n\nImage statistics such as mean, std, min and max can be extracted for normalization and further analysis.\n\n* `image_mean` - Image mean pixel value\n* `image_std` - Image standard deviation of pixel values \n* `image_min` - Image minimum pixel value\n* `image_max` - Image maximum pixel value\n\nFinally, additional statistics such as area of objects can be extracted from annotations.\n\n* `mask_area` - Total area in binary segmentation mask","metadata":{}},{"cell_type":"code","source":"slice_filenames = glob('../input/uw-madison-gi-tract-image-segmentation/train/*/*/scans/*.png')\n\nfor filename in tqdm(slice_filenames):\n    \n    case, day = filename.split('/')[5].split('_')\n    filename_split = filename.split('/')[-1].split('_')\n    slice_number = filename_split[1]\n    image_height = int(filename_split[2])\n    image_width = int(filename_split[3])\n    image_vertical_pixel_spacing = float(filename_split[4])\n    image_horizontal_pixel_spacing = float(filename_split[5].replace('.png', ''))\n    \n    # Extract metadata from filename\n    slice_idx = (df_train['case'] == case) & (df_train['day'] == day) & (df_train['slice_number'] == slice_number)\n    df_train.loc[slice_idx, 'image_height'] = image_height\n    df_train.loc[slice_idx, 'image_width'] = image_width\n    df_train.loc[slice_idx, 'image_vertical_pixel_spacing'] = image_vertical_pixel_spacing\n    df_train.loc[slice_idx, 'image_horizontal_pixel_spacing'] = image_horizontal_pixel_spacing\n    \n    # Extract metadata from image\n    image = cv2.imread(filename, -1)\n    df_train.loc[slice_idx, 'image_mean'] = np.mean(image)\n    df_train.loc[slice_idx, 'image_std'] = np.std(image)\n    df_train.loc[slice_idx, 'image_min'] = np.min(image)\n    df_train.loc[slice_idx, 'image_max'] = np.max(image)\n    \n    # Extract metadata from annotation\n    for row_idx, row in df_train.loc[slice_idx].iterrows():\n        if isinstance(row['segmentation'], str):\n            mask = decode_rle_mask(row['segmentation'], (image_height, image_width))\n            df_train.loc[row_idx, 'mask_area'] = np.sum(mask)\n\n\ndf_train['slice_count'] = df_train.groupby(['case', 'day'])['slice_number'].transform('count') / 3\ndf_train['slice_count'] = df_train['slice_count'].astype(np.uint16)\ndf_train['image_height'] = df_train['image_height'].astype(np.uint16)\ndf_train['image_width'] = df_train['image_width'].astype(np.uint16)\ndf_train['image_vertical_pixel_spacing'] = df_train['image_vertical_pixel_spacing'].astype(np.float32)\ndf_train['image_horizontal_pixel_spacing'] = df_train['image_horizontal_pixel_spacing'].astype(np.float32)\ndf_train['image_mean'] = df_train['image_mean'].astype(np.float32)\ndf_train['image_std'] = df_train['image_std'].astype(np.float32)\ndf_train['image_min'] = df_train['image_min'].astype(np.float32)\ndf_train['image_max'] = df_train['image_max'].astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T11:31:10.62459Z","iopub.execute_input":"2022-04-15T11:31:10.625269Z","iopub.status.idle":"2022-04-15T12:06:04.387592Z","shell.execute_reply.started":"2022-04-15T11:31:10.625234Z","shell.execute_reply":"2022-04-15T12:06:04.38674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 4 different image dimensions in training set and they are 266x266, 360x310, 276x276 and 234x234. Last two of them are very rare and most of the images are either 266x266 or 360x310. However, raw image dimensions are meaningless since there are borders around them. After removing borders, their dimensions would became smaller. Slice count is 144 in the most of the cases but some of the scans have 80 slices.","metadata":{}},{"cell_type":"code","source":"df_train['image_dimensions'] = df_train['slice_count'].astype(str) + 'x' + df_train['image_height'].astype(str) + 'x' + df_train['image_width'].astype(str)\n\ndef visualize_image_dimensions_distribution(df):\n    \n    fig, ax = plt.subplots(figsize=(24, 5), dpi=100)\n\n    sns.barplot(\n        x=df['image_dimensions'].value_counts().index,\n        y=df['image_dimensions'].value_counts().values,\n        ax=ax\n    )\n\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.set_xticklabels([f'{x} ({value_count:,})' for value_count, x in zip(df['image_dimensions'].value_counts().values, df['image_dimensions'].value_counts().index)])\n    ax.tick_params(axis='x', labelsize=15, pad=10)\n    ax.tick_params(axis='y', labelsize=15, pad=10)\n    ax.set_title('Number of Unique Dimensions in Training Set', size=20, pad=15)\n\n    plt.show()\n\n    \nvisualize_image_dimensions_distribution(df_train)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-15T15:18:56.081444Z","iopub.execute_input":"2022-04-15T15:18:56.082382Z","iopub.status.idle":"2022-04-15T15:18:56.662969Z","shell.execute_reply.started":"2022-04-15T15:18:56.082333Z","shell.execute_reply":"2022-04-15T15:18:56.662057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the images have 1.5 mm pixel spacings in both vertical and horizontal axes. There are only 3600 images that have 1.63 mm pixel spacings and those images are the same ones with 276x276 image dimensions. Even though metadata is not provided, evidences suggest that MRI scans in training set are most likely taken from the same machine with similar configurations. Scans with 80x276x276 dimensions could be exception.","metadata":{}},{"cell_type":"code","source":"df_train['image_pixel_spacings'] = df_train['image_vertical_pixel_spacing'].astype(str) + 'x' + df_train['image_horizontal_pixel_spacing'].astype(str)\n\ndef visualize_image_pixel_spacings_distribution(df):\n    \n    fig, ax = plt.subplots(figsize=(24, 5), dpi=100)\n\n    sns.barplot(\n        x=df['image_pixel_spacings'].value_counts().index,\n        y=df['image_pixel_spacings'].value_counts().values,\n        ax=ax\n    )\n\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.set_xticklabels([f'{x} ({value_count:,})' for value_count, x in zip(df['image_pixel_spacings'].value_counts().values, df['image_pixel_spacings'].value_counts().index)])\n    ax.tick_params(axis='x', labelsize=15, pad=10)\n    ax.tick_params(axis='y', labelsize=15, pad=10)\n    ax.set_title('Number of Unique Image Pixel Spacings in Training Set', size=20, pad=15)\n\n    plt.show()\n\n\nvisualize_image_pixel_spacings_distribution(df_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:19:55.889982Z","iopub.execute_input":"2022-04-15T12:19:55.890768Z","iopub.status.idle":"2022-04-15T12:19:56.269269Z","shell.execute_reply.started":"2022-04-15T12:19:55.890724Z","shell.execute_reply":"2022-04-15T12:19:56.268408Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Objects\n\nThere are 3 classes of objects in annotations. They are large bowel, small bowel and stomach. Their number of annotations are in this order as from most to least annotated class. Differences in their number of annotations show that large bowel takes more space on z-axis while others take less.","metadata":{}},{"cell_type":"code","source":"def visualize_annotation_distribution(df):\n    \n    fig, ax = plt.subplots(figsize=(24, 5), dpi=100)\n\n    sns.barplot(\n        x=df.loc[~df['segmentation'].isnull(), 'class'].value_counts().index,\n        y=df.loc[~df['segmentation'].isnull(), 'class'].value_counts().values,\n        ax=ax\n    )\n\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.set_xticklabels([f'{x} ({value_count:,})' for value_count, x in zip(df.loc[~df['segmentation'].isnull(), 'class'].value_counts().values, df.loc[~df['segmentation'].isnull(), 'class'].value_counts().index)])\n    ax.tick_params(axis='x', labelsize=15, pad=10)\n    ax.tick_params(axis='y', labelsize=15, pad=10)\n    ax.set_title('Number of Annotations in Training Set', size=20, pad=15)\n\n    plt.show()\n\n    \nvisualize_annotation_distribution(df_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:39:47.371977Z","iopub.execute_input":"2022-04-15T12:39:47.37227Z","iopub.status.idle":"2022-04-15T12:39:47.588592Z","shell.execute_reply.started":"2022-04-15T12:39:47.372243Z","shell.execute_reply":"2022-04-15T12:39:47.587758Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mask area distributions among classes are quite different. Small bowel areas are larger than large bowel areas which suggests that small bowel takes more space in x and y axes while large bowel takes more space in z-axis. Stomach is the smallest class which can be seen from its mask area distribution and number of annotations.","metadata":{}},{"cell_type":"code","source":"def visualize_feature_distribution_for_classes(df, feature):\n    \n    print(f'{feature}\\n{\"-\" * len(feature)}')\n    print(f'Class large_bowel Mean: {df.loc[df[\"class\"] == \"large_bowel\"][feature].mean():.4f}  -  Median: {df.loc[df[\"class\"] == \"large_bowel\"][feature].median():.4f}  -  Std: {df.loc[df[\"class\"] == \"large_bowel\"][feature].std():.4f} - Min: {df.loc[df[\"class\"] == \"large_bowel\"][feature].min():.4f} -  Max: {df.loc[df[\"class\"] == \"large_bowel\"][feature].max():.4f}')\n    print(f'Class small_bowel Mean: {df.loc[df[\"class\"] == \"small_bowel\"][feature].mean():.4f}  -  Median: {df.loc[df[\"class\"] == \"small_bowel\"][feature].median():.4f}  -  Std: {df.loc[df[\"class\"] == \"small_bowel\"][feature].std():.4f} - Min: {df.loc[df[\"class\"] == \"small_bowel\"][feature].min():.4f} -  Max: {df.loc[df[\"class\"] == \"small_bowel\"][feature].max():.4f}')\n    print(f'Class stomach Mean: {df.loc[df[\"class\"] == \"stomach\"][feature].mean():.4f}  -  Median: {df.loc[df[\"class\"] == \"stomach\"][feature].median():.4f}  -  Std: {df.loc[df[\"class\"] == \"stomach\"][feature].std():.4f} - Min: {df.loc[df[\"class\"] == \"stomach\"][feature].min():.4f} -  Max: {df.loc[df[\"class\"] == \"stomach\"][feature].max():.4f}')\n\n    fig, ax = plt.subplots(figsize=(24, 8), dpi=100)\n    sns.kdeplot(df.loc[df['class'] == 'large_bowel'][feature], label='large_bowel', fill=True)\n    sns.kdeplot(df.loc[df['class'] == 'small_bowel'][feature], label='small_bowel', fill=True)\n    sns.kdeplot(df.loc[df['class'] == 'stomach'][feature], label='stomach', fill=True)\n    \n    ax.legend(prop={'size': 16})\n    ax.tick_params(axis='x', labelsize=12.5, pad=10)\n    ax.tick_params(axis='y', labelsize=12.5, pad=10)\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.set_title(f'{feature} Distribution in Training Set', fontsize=20, pad=15)\n    \n    plt.show()\n    \n\nfeatures = ['mask_area']\nfor feature in features:\n    visualize_feature_distribution_for_classes(df=df_train, feature=feature)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:27:22.869223Z","iopub.execute_input":"2022-04-15T13:27:22.869942Z","iopub.status.idle":"2022-04-15T13:27:23.799234Z","shell.execute_reply.started":"2022-04-15T13:27:22.869902Z","shell.execute_reply":"2022-04-15T13:27:23.798306Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. MRI Scans","metadata":{}},{"cell_type":"code","source":"# To Be Continued","metadata":{},"execution_count":null,"outputs":[]}]}