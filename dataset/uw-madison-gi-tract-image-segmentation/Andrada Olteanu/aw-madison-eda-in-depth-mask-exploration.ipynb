{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/hEB3a8W.png\">\n\n<center><h1> Deep Dive into Mask Exploration and Understanding </h1></center>\n\n>  ‚öïÔ∏è **Competition Goal:** The goal is to create an algorithm that segments the stomach and intestines on MRI scans. The MRI scans are from actual cancer patients who had 1-5 MRI scans on separate days during their radiation treatment.\n\n### What are MRI scans?\n\n[**Magnetic resonance imaging**](https://www.nhs.uk/conditions/mri-scan/) (MRI) is a type of scan that uses *strong magnetic fields and radio waves* to produce detailed images of the inside of the body.\n\nAn MRI scanner is a large tube that contains powerful magnets. You lie inside the tube during the scan.\n\n<center><img src=\"https://i.imgur.com/zKpMN5S.png\" width=600></center>","metadata":{}},{"cell_type":"code","source":"from IPython.display import YouTubeVideo\n# Full Link: https://www.youtube.com/watch?v=knUTrvJLeEg\n\nYouTubeVideo('knUTrvJLeEg', width=700, height=400)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:45:37.694457Z","iopub.execute_input":"2022-05-28T10:45:37.694942Z","iopub.status.idle":"2022-05-28T10:45:37.761352Z","shell.execute_reply.started":"2022-05-28T10:45:37.694857Z","shell.execute_reply":"2022-05-28T10:45:37.760808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stomach, Large Bowel, Small Bowel\n\nThe `class` widthin the `train.csv` file has 3 distinct values: large bowel, small bowel, stomach. These are all part of the digestive system. The bowels (small and large intestine) are responsible for breaking down food and absorbing the nutrients.\n\n<center><img src=\"https://i.imgur.com/v2fobvp.png\" width=700></center>\n\n### ‚¨á Libraries","metadata":{}},{"cell_type":"code","source":"# Libraries\nimport os\nimport gc\nimport wandb\nimport time\nimport random\nimport shutil\nimport math\nimport glob\nfrom tqdm import tqdm\nimport warnings\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.offsetbox import AnnotationBbox, OffsetImage\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom matplotlib.patches import Rectangle\nfrom IPython.display import display_html\nplt.rcParams.update({'font.size': 16})\n\n# Environment check\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"WANDB_SILENT\"] = \"true\"\nCONFIG = {'competition': 'AWMadison', '_wandb_kernel': 'aot'}\n\n# Custom colors\nclass clr:\n    S = '\\033[1m' + '\\033[92m'\n    E = '\\033[0m'\n    \nmy_colors = [\"#CC5547\", \"#DB905D\", \"#D9AE6C\", \"#93AF5C\", \"#799042\", \"#61783F\"]\nprint(clr.S+\"Notebook Color Scheme:\"+clr.E)\nsns.palplot(sns.color_palette(my_colors))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:45:37.76285Z","iopub.execute_input":"2022-05-28T10:45:37.763133Z","iopub.status.idle":"2022-05-28T10:45:40.191794Z","shell.execute_reply.started":"2022-05-28T10:45:37.763107Z","shell.execute_reply":"2022-05-28T10:45:40.191173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üêù W&B Fork & Run\n\nIn order to run this notebook you will need to input your own **secret API key** within the `! wandb login $secret_value_0` line. \n\nüêù**How do you get your own API key?**\n\nSuper simple! Go to **https://wandb.ai/site** -> Login -> Click on your profile in the top right corner -> Settings -> Scroll down to API keys -> copy your very own key (for more info check [this amazing notebook for ML Experiment Tracking on Kaggle](https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases)).\n\n<center><img src=\"https://i.imgur.com/fFccmoS.png\" width=500></center>","metadata":{}},{"cell_type":"code","source":"# üêù Secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")\n\n! wandb login $secret_value_0","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:45:40.195393Z","iopub.execute_input":"2022-05-28T10:45:40.197106Z","iopub.status.idle":"2022-05-28T10:45:42.04347Z","shell.execute_reply.started":"2022-05-28T10:45:40.195702Z","shell.execute_reply":"2022-05-28T10:45:42.042682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ‚¨á Helper Functions","metadata":{}},{"cell_type":"code","source":"# Functions to get image width and height\ndef get_img_size(x, flag):\n    \n    if x != 0:\n        split = x.split(\"_\")\n        width = split[3]\n        height = split[4]\n    \n        if flag == \"width\":\n            return int(width)\n        elif flag == \"height\":\n            return int(height)\n    \n    return 0\n\n\ndef get_pixel_size(x, flag):\n    \n    if x != 0:\n        split = x.split(\"_\")\n        width = split[-2]\n        height = \".\".join(split[-1].split(\".\")[:-1])\n    \n        if flag == \"width\":\n            return float(width)\n        elif flag == \"height\":\n            return float(height)\n    \n    return 0\n\n# Custom color map in matplotlib\ndef CustomCmap(rgb_color):\n\n    r1,g1,b1 = rgb_color\n\n    cdict = {'red': ((0, r1, r1),\n                   (1, r1, r1)),\n           'green': ((0, g1, g1),\n                    (1, g1, g1)),\n           'blue': ((0, b1, b1),\n                   (1, b1, b1))}\n\n    cmap = LinearSegmentedColormap('custom_cmap', cdict)\n    return cmap\n\n\ndef show_values_on_bars(axs, h_v=\"v\", space=0.4):\n    '''Plots the value at the end of the a seaborn barplot.\n    axs: the ax of the plot\n    h_v: weather or not the barplot is vertical/ horizontal'''\n    \n    def _show_on_single_plot(ax):\n        if h_v == \"v\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() / 2\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_height())\n                ax.text(_x, _y, format(value, ','), ha=\"center\") \n        elif h_v == \"h\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_width())\n                ax.text(_x, _y, format(value, ','), ha=\"left\")\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)\n\n\n# === üêù W&B ===\ndef save_dataset_artifact(run_name, artifact_name, path):\n    '''Saves dataset to W&B Artifactory.\n    run_name: name of the experiment\n    artifact_name: under what name should the dataset be stored\n    path: path to the dataset'''\n    \n    run = wandb.init(project='AWMadison', \n                     name=run_name, \n                     config=CONFIG)\n    artifact = wandb.Artifact(name=artifact_name, \n                              type='dataset')\n    artifact.add_file(path)\n\n    wandb.log_artifact(artifact)\n    wandb.finish()\n    print(\"Artifact has been saved successfully.\")\n    \n    \ndef create_wandb_plot(x_data=None, y_data=None, x_name=None, y_name=None, title=None, log=None, plot=\"line\"):\n    '''Create and save lineplot/barplot in W&B Environment.\n    x_data & y_data: Pandas Series containing x & y data\n    x_name & y_name: strings containing axis names\n    title: title of the graph\n    log: string containing name of log'''\n    \n    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n    table = wandb.Table(data=data, columns = [x_name, y_name])\n    \n    if plot == \"line\":\n        wandb.log({log : wandb.plot.line(table, x_name, y_name, title=title)})\n    elif plot == \"bar\":\n        wandb.log({log : wandb.plot.bar(table, x_name, y_name, title=title)})\n    elif plot == \"scatter\":\n        wandb.log({log : wandb.plot.scatter(table, x_name, y_name, title=title)})\n        \n        \ndef create_wandb_hist(x_data=None, x_name=None, title=None, log=None):\n    '''Create and save histogram in W&B Environment.\n    x_data: Pandas Series containing x values\n    x_name: strings containing axis name\n    title: title of the graph\n    log: string containing name of log'''\n    \n    data = [[x] for x in x_data]\n    table = wandb.Table(data=data, columns=[x_name])\n    wandb.log({log : wandb.plot.histogram(table, x_name, title=title)})\n    \n    \n# üêù Log Cover Photo\nrun = wandb.init(project='AWMadison', name='CoverPhoto', config=CONFIG)\ncover = plt.imread(\"../input/preprocessed-awmadison-gi-tract-segmentation/Cover.png\")\nwandb.log({\"example\": wandb.Image(cover)})\nwandb.finish()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-05-28T10:45:42.04512Z","iopub.execute_input":"2022-05-28T10:45:42.045302Z","iopub.status.idle":"2022-05-28T10:45:55.866744Z","shell.execute_reply.started":"2022-05-28T10:45:42.045279Z","shell.execute_reply":"2022-05-28T10:45:55.865849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- Custom Color Maps ---\n# Yellow Purple Red\nmask_colors = [(1.0, 0.7, 0.1), (1.0, 0.5, 1.0), (1.0, 0.22, 0.099)]\nlegend_colors = [Rectangle((0,0),1,1, color=color) for color in mask_colors]\nlabels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n\nCMAP1 = CustomCmap(mask_colors[0])\nCMAP2 = CustomCmap(mask_colors[1])\nCMAP3 = CustomCmap(mask_colors[2])","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:45:55.867862Z","iopub.execute_input":"2022-05-28T10:45:55.868192Z","iopub.status.idle":"2022-05-28T10:45:55.875001Z","shell.execute_reply.started":"2022-05-28T10:45:55.868158Z","shell.execute_reply":"2022-05-28T10:45:55.874365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Train Data\n \nI am looking first at the `train.csv` dataset, as to get familiar with what are we actually working with. I am also starting a new experiment that will be linked to this entire section of analysis.","metadata":{}},{"cell_type":"code","source":"# üêù New Experiment\nrun = wandb.init(project='AWMadison', name='data_explore', config=CONFIG)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:45:55.875944Z","iopub.execute_input":"2022-05-28T10:45:55.876221Z","iopub.status.idle":"2022-05-28T10:46:00.821309Z","shell.execute_reply.started":"2022-05-28T10:45:55.876195Z","shell.execute_reply":"2022-05-28T10:46:00.819936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**‚öï To Remember**:\n* The `train.csv` has 115,488 total rows and 3 columns\n* There are 38,96 unique `ids` - or cases\n* Each unique `id` appears within the dataset 3 times, depending on the `class` of the image (`large_bowel`, `small_bowel`, `stomach`)\n* the `class` should be treated like a **flag** that shows WHERE is the healthy organs are actually located within one image\n* The `segmentation` category flags precisely (not with bounding box, but using pixels) the organs - if nothing is found in neither classes, it will be marked as `None` (or missing)","metadata":{}},{"cell_type":"code","source":"print(clr.S+\"--- train.csv ---\"+clr.E)\ntrain = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/train.csv\")\n\nprint(clr.S+\"shape:\"+clr.E, train.shape)\nprint(clr.S+\"Unique ID cases:\"+clr.E, train[\"id\"].nunique())\nprint(clr.S+\"Missing Values Column:\"+clr.E, train.isna().sum().index[-1])\nprint(\"\\t\", clr.S+\"with a total missing rows of:\"+clr.E, train.isna().sum().values[-1])\nprint(\"\\t\", clr.S+\"% of missing rows:\"+clr.E, \n      len(train[train[\"segmentation\"].isna()==False]), \"\\n\")\n\nprint(clr.S+\"Sample of train.csv:\"+clr.E)\ntrain.sample(5, random_state=26)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:46:00.823387Z","iopub.execute_input":"2022-05-28T10:46:00.823687Z","iopub.status.idle":"2022-05-28T10:46:02.034947Z","shell.execute_reply.started":"2022-05-28T10:46:00.823652Z","shell.execute_reply":"2022-05-28T10:46:02.033803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# üêù Log in params\nwandb.log({\"train_len\" : train.shape[0],\n           \"train_cols\" : train.shape[1],\n           \"segmentation_no\" : len(train[train[\"segmentation\"].isna()==False]),\n           \"segmentation_perc\" : round((len(train[train[\"segmentation\"].isna()==False])/train.shape[0])*100, 1)})","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:46:02.036262Z","iopub.execute_input":"2022-05-28T10:46:02.037048Z","iopub.status.idle":"2022-05-28T10:46:02.448135Z","shell.execute_reply.started":"2022-05-28T10:46:02.037008Z","shell.execute_reply":"2022-05-28T10:46:02.447607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ‚öï 1.1 Missing Values\n* There are ~30% of places where there is a segmentation found.\n* There is no speciffic missingness patern within the dataset - all missing data are scattered at random throughout the file","metadata":{}},{"cell_type":"code","source":"# Show a dataframe of missing values\nsns.displot(\n    data=train.isna().melt(value_name=\"missing\"),\n    y=\"variable\",\n    hue=\"missing\",\n    multiple=\"fill\",\n    # Change aspect of the chart\n    aspect=3,\n    height=6,\n    # Change colors\n    palette=[my_colors[5], my_colors[2]], \n    legend=False)\n\nplt.title(\"- [train.csv] %Perc Missing Values per variable -\", size=18, weight=\"bold\")\nplt.xlabel(\"Total Percentage\")\nplt.ylabel(\"Dataframe Variable\")\nplt.legend([\"Missing\", \"Not Missing\"]);\nplt.show();\n\nprint(\"\\n\")\n\n# Plot 2\nplt.figure(figsize=(24,6))\n\ncbar_kws = { \n    \"ticks\": [0, 1],\n}\n\nsns.heatmap(train.isna(), cmap=[my_colors[5], my_colors[2]], cbar_kws=cbar_kws)\n\nplt.title(\"- [train.csv] Missing Values per observation -\", size=18, weight=\"bold\")\nplt.xlabel(\"\")\nplt.ylabel(\"Observation\")\nplt.show();","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-05-28T10:46:02.449396Z","iopub.execute_input":"2022-05-28T10:46:02.450211Z","iopub.status.idle":"2022-05-28T10:46:04.212076Z","shell.execute_reply.started":"2022-05-28T10:46:02.450133Z","shell.execute_reply":"2022-05-28T10:46:04.211338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ‚öï 1.2 ID interpretability:\n* The `.png` images within `train` folder have the follosing format: `slice_ImageHeight_ImageWidth_PixelHeight_PixelWidth.png`\n\n<center><img src=\"https://i.imgur.com/uXyDYQi.png\" width=700></center>\n\n*Example of Image Path: `../input/uw-madison-gi-tract-image-segmentation/train/case101/case101_day20/scans/slice_0001_266_266_1.50_1.50.png`*","metadata":{}},{"cell_type":"code","source":"def get_image_path(base_path, df):\n    '''Gets the case, day, slice_no and path of the dataset (either train or test).\n    base_path: path to train image folder\n    return :: modified dataframe'''\n    \n    # Create case, day and slice columns\n    df[\"case\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[0])\n    df[\"day\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[1])\n    df[\"slice_no\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[-1])\n\n    df[\"path\"] = 0\n    \n    n = len(df)\n\n    # Loop through entire dataset\n    for k in tqdm(range(n)):\n        data = df.iloc[k, :]\n        segmentation = data.segmentation\n\n        # In case coordinates for healthy tissue are present\n        if pd.isnull(train.iloc[k, 2]) == False:\n            case = data.case\n            day = data.day\n            slice_no = data.slice_no\n            # Change value to the correct one\n            df.loc[k, \"path\"] = glob.glob(f\"{base_path}/{case}/{case}_{day}/scans/slice_{slice_no}*\")[0]\n            \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:46:04.214503Z","iopub.execute_input":"2022-05-28T10:46:04.214668Z","iopub.status.idle":"2022-05-28T10:46:04.549204Z","shell.execute_reply.started":"2022-05-28T10:46:04.214647Z","shell.execute_reply":"2022-05-28T10:46:04.548097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BASE path (for train)\nbase_path = \"../input/uw-madison-gi-tract-image-segmentation/train\"\n\n# Prep and save file\ntrain = get_image_path(base_path, df=train)\n\nprint(clr.S+\"train.csv now:\"+clr.E)\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:46:04.550606Z","iopub.execute_input":"2022-05-28T10:46:04.550866Z","iopub.status.idle":"2022-05-28T10:48:18.787115Z","shell.execute_reply.started":"2022-05-28T10:46:04.55083Z","shell.execute_reply":"2022-05-28T10:48:18.786654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### - Cases, Day, Slice No. -\n\nSo after I have splitted the `id` into multiple categories:\n* case number\n* day - the day the picture was registered\n* and slice number\n\n... then I can easily plot the distribution (or barplot, as these are categorical values) to see some more information from the data.","metadata":{}},{"cell_type":"code","source":"# Make the columns unique\n# as they repeat sometimes due to multiple \"class\" values\ndata = train.groupby(\"id\")[[\"case\", \"day\", \"slice_no\"]].first().reset_index()\n\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 35))\ntitles = [\"Case\", \"Day\", \"Slice No.\"]\n\nsns.barplot(data=data[\"case\"].value_counts().reset_index(),\n            y=\"index\", x=\"case\", ax=ax1, \n            palette=\"YlOrBr_r\")\n\nsns.barplot(data=data[\"day\"].value_counts().reset_index(),\n            y=\"index\", x=\"day\", ax=ax2,\n            palette=\"YlGn_r\")\n\nsns.barplot(data=data[\"slice_no\"].value_counts().reset_index(),\n            y=\"index\", x=\"slice_no\", ax=ax3,\n            palette=\"Greens_r\")\n\nfor ax, t in zip([ax1, ax2, ax3], titles):\n    show_values_on_bars(ax, h_v=\"h\", space=0.4)\n    ax.set_title(f\"- {t} -\", size=20, weight=\"bold\")\n    ax.set_xlabel(\"Frequency\", weight=\"bold\")\n    ax.set_ylabel(f\"{t}\", weight=\"bold\")\n    ax.get_xaxis().set_ticks([]);\n    \nsns.despine()\nfig.tight_layout();","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:18.788046Z","iopub.execute_input":"2022-05-28T10:48:18.788787Z","iopub.status.idle":"2022-05-28T10:48:24.565897Z","shell.execute_reply.started":"2022-05-28T10:48:18.788734Z","shell.execute_reply":"2022-05-28T10:48:24.564603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### - Frequency between Days -\n\n**Average Day per Case**:\n* Most of the cases were taken on average between day10 and day20\n* There are also many cases took in day0 and day1\n\n**Total Days/Case**:\n* The total number of unique days per case varies between 1 and 6\n* The majority of the cases have data taken for ~ 3 and 5 days in total.","metadata":{}},{"cell_type":"code","source":"# Get only case and day data\n# Creating a new dataframe and extracting only the number\n# from the 2 columns\ncase_day = pd.DataFrame({\"case\" : train[\"case\"].apply(lambda x: int(\"\".join([i for i in x if i.isdigit()]))),\n                         \"day\" : train[\"day\"].apply(lambda x: int(\"\".join([i for i in x if i.isdigit()])))})\n\n# Sepparate 2 dataframes\n# one containing average days per case & the other count of days per case\nday_mean = case_day.groupby(\"case\")[\"day\"].mean().reset_index()\nday_count = case_day.groupby(\"case\")[\"day\"].unique().reset_index()\nday_count[\"day\"] = day_count[\"day\"].apply(lambda x: len(x))\n\nprint(clr.S+\"case_day.head():\"+clr.E, \"\\n\")\ncase_day.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:24.567427Z","iopub.execute_input":"2022-05-28T10:48:24.567641Z","iopub.status.idle":"2022-05-28T10:48:25.325856Z","shell.execute_reply.started":"2022-05-28T10:48:24.567609Z","shell.execute_reply":"2022-05-28T10:48:25.325037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))\ntitles = [\"Average Day/Case Distribution\", \"Total Days/Case Distribution\"]\n# hatches = itertools.cycle(['/', '//', '+', '-', 'x', '\\\\', '*', 'o', 'O', '.'])\n\nsns.histplot(data=day_mean, x=\"day\",bins=30, color=my_colors[1], ax=ax1)\n\nsns.histplot(data=day_count, x=\"day\", color=my_colors[3], ax=ax2)\n\nfor ax, t, label in zip([ax1, ax2], titles, [\"Average Day/Case\", \"Total Days/Case\"]):\n    ax.set_title(f\"- {t} -\", size=20, weight=\"bold\")\n    ax.set_xlabel(f\"{label}\", weight=\"bold\")\n    ax.set_ylabel(\"Frequency\", weight=\"bold\")\n    \n\nfor i, bar in enumerate(ax1.patches):\n    bar.set_hatch(\"/\")\n#     bar.set_edgecolor(my_colors[0])\n    \nfor i, bar in enumerate(ax2.patches):\n    bar.set_hatch(\"\\\\\")\n    \nax2.arrow(x=4.35, y=30, dx=0, dy=-28, head_width=0.1, head_length=1.5,\n          color=my_colors[-1], linewidth=2)\nax2.text(x=3.5, y=31, s=\"In between the value is 0.\", size=18, \n         color=my_colors[-1], weight=\"bold\")\n    \nsns.despine()\nfig.tight_layout();","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:25.327223Z","iopub.execute_input":"2022-05-28T10:48:25.327419Z","iopub.status.idle":"2022-05-28T10:48:26.22391Z","shell.execute_reply.started":"2022-05-28T10:48:25.327392Z","shell.execute_reply":"2022-05-28T10:48:26.223384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ‚öï 1.3 Image/Pixel width & height\n\nFrom the path we can also extract the `image` and `pixel` widths & heights and explore. From the graph below we can see that the dimensions do not vary a lot - moreover, all images are almost squared shapes.","metadata":{}},{"cell_type":"code","source":"# Retrieve image width and height\ntrain[\"image_width\"] = train[\"path\"].apply(lambda x: get_img_size(x, \"width\"))\ntrain[\"image_height\"] = train[\"path\"].apply(lambda x: get_img_size(x, \"height\"))\n\ntrain[\"pixel_width\"] = train[\"path\"].apply(lambda x: get_pixel_size(x, \"width\"))\ntrain[\"pixel_height\"] = train[\"path\"].apply(lambda x: get_pixel_size(x, \"height\"))\n\nprint(clr.S+\"train.csv now:\"+clr.E)\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:26.2252Z","iopub.execute_input":"2022-05-28T10:48:26.226061Z","iopub.status.idle":"2022-05-28T10:48:26.909504Z","shell.execute_reply.started":"2022-05-28T10:48:26.226019Z","shell.execute_reply":"2022-05-28T10:48:26.908601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(24, 15))\ntitles = [\"Img Width\", \"Img Height\", \"Pixel Width\", \"Pixel Height\"]\n\ndt = train[train[\"image_width\"] != 0.0].reset_index(drop=True)\n\nsns.barplot(data=dt[\"image_width\"].value_counts().reset_index(),\n            x=\"index\", y=\"image_width\", ax=ax1, \n            palette=my_colors)\n\nsns.barplot(data=dt[\"image_height\"].value_counts().reset_index(),\n            x=\"index\", y=\"image_height\", ax=ax2,\n            palette=my_colors[::-1])\n\nsns.barplot(data=dt[\"pixel_width\"].value_counts().reset_index(),\n            x=\"index\", y=\"pixel_width\", ax=ax3, \n            palette=my_colors)\n\nsns.barplot(data=dt[\"pixel_height\"].value_counts().reset_index(),\n            x=\"index\", y=\"pixel_height\", ax=ax4,\n            palette=my_colors[::-1])\n\nfor ax, t in zip([ax1, ax2, ax3, ax4], titles):\n    show_values_on_bars(ax, h_v=\"v\", space=0.4)\n    ax.set_title(f\"- {t} -\", size=20, weight=\"bold\")\n    ax.set_ylabel(\"Frequency\", weight=\"bold\")\n    ax.set_xlabel(f\"{t}\", weight=\"bold\")\n    ax.get_yaxis().set_ticks([]);\n    \nsns.despine(left=True)\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.3, hspace=0.5);","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:26.910709Z","iopub.execute_input":"2022-05-28T10:48:26.910905Z","iopub.status.idle":"2022-05-28T10:48:27.644091Z","shell.execute_reply.started":"2022-05-28T10:48:26.910877Z","shell.execute_reply":"2022-05-28T10:48:27.643023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# üêù Log info to Dashboard\ndt = train[\"image_width\"].value_counts().reset_index()\n\ncreate_wandb_plot(x_data=dt[\"index\"],\n                  y_data=dt[\"image_width\"], \n                  x_name=\"Image Width/Height\", \n                  y_name=\"Frequency\", \n                  title=\"Image Width x Height\",\n                  log=\"img_specs\", plot=\"bar\")\n\ndt = train[\"pixel_width\"].value_counts().reset_index()\n\ncreate_wandb_plot(x_data=dt[\"index\"],\n                  y_data=dt[\"pixel_width\"], \n                  x_name=\"Pixel Width/Height\", \n                  y_name=\"Frequency\", \n                  title=\"Pixel Width x Height\",\n                  log=\"pixel_specs\", plot=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:27.646355Z","iopub.execute_input":"2022-05-28T10:48:27.646593Z","iopub.status.idle":"2022-05-28T10:48:28.217828Z","shell.execute_reply.started":"2022-05-28T10:48:27.646562Z","shell.execute_reply":"2022-05-28T10:48:28.216898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ‚öïÔ∏è 1.4 Segmentation View","metadata":{}},{"cell_type":"code","source":"# Data\nsegment_per_id = train.groupby(\"id\")[\"segmentation\"].count()\\\n                    .reset_index()[\"segmentation\"].value_counts().reset_index()\n\nsegment_per_class = train.groupby(\"class\")[\"segmentation\"].count().reset_index()\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 7))\ntitles = [\"How many available segmentations we have per case?\",\n          \"Which class has the most segmentations?\"]\n\n\nsns.barplot(data=segment_per_id,\n            x=\"index\", y=\"segmentation\", ax=ax1, \n            palette=my_colors)\n\nsns.barplot(data=segment_per_class,\n            x=\"class\", y=\"segmentation\", ax=ax2,\n            palette=my_colors[::-1])\n\n\nfor ax, t, x in zip([ax1, ax2], titles, [\"no. segmentations per ID\", \"class\"]):\n    show_values_on_bars(ax, h_v=\"v\", space=0.4)\n    ax.set_title(f\"- {t} -\", size=20, weight=\"bold\")\n    ax.set_ylabel(\"Frequency\", weight=\"bold\")\n    ax.set_xlabel(f\"{x}\", weight=\"bold\")\n    ax.get_yaxis().set_ticks([]);\n    \nsns.despine(left=True)\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.3, hspace=0.5);","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:28.219028Z","iopub.execute_input":"2022-05-28T10:48:28.219241Z","iopub.status.idle":"2022-05-28T10:48:28.833624Z","shell.execute_reply.started":"2022-05-28T10:48:28.219209Z","shell.execute_reply":"2022-05-28T10:48:28.832902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# üêù Log info to Dashboard\ncreate_wandb_plot(x_data=segment_per_id[\"index\"],\n                  y_data=segment_per_id[\"segmentation\"], \n                  x_name=\"no. segmentations per ID\", \n                  y_name=\"Frequency\", \n                  title=f\"{titles[0]}\",\n                  log=\"segm_id\", plot=\"bar\")\n\ncreate_wandb_plot(x_data=segment_per_class[\"class\"],\n                  y_data=segment_per_class[\"segmentation\"], \n                  x_name=\"class\", \n                  y_name=\"Frequency\", \n                  title=f\"{titles[1]}\",\n                  log=\"segm_class\", plot=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:28.835Z","iopub.execute_input":"2022-05-28T10:48:28.835231Z","iopub.status.idle":"2022-05-28T10:48:29.354979Z","shell.execute_reply.started":"2022-05-28T10:48:28.835208Z","shell.execute_reply":"2022-05-28T10:48:29.353988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# üêù End Experiment\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:29.356383Z","iopub.execute_input":"2022-05-28T10:48:29.356806Z","iopub.status.idle":"2022-05-28T10:48:42.951043Z","shell.execute_reply.started":"2022-05-28T10:48:29.356775Z","shell.execute_reply":"2022-05-28T10:48:42.950274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# üêù Save train.csv as artifact\ntrain.to_csv(\"train.csv\", index=False)\n\nsave_dataset_artifact(run_name=\"save_train\",\n                      artifact_name=\"train\",\n                      path=\"../input/preprocessed-awmadison-gi-tract-segmentation/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:42.952217Z","iopub.execute_input":"2022-05-28T10:48:42.95245Z","iopub.status.idle":"2022-05-28T10:48:55.609319Z","shell.execute_reply.started":"2022-05-28T10:48:42.952424Z","shell.execute_reply":"2022-05-28T10:48:55.60851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Images\n\nNow let's explore the `.png` images and their masks.","metadata":{}},{"cell_type":"code","source":"# üêù New Experiment\nrun = wandb.init(project='AWMadison', name='make_masks', config=CONFIG)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:48:55.610961Z","iopub.execute_input":"2022-05-28T10:48:55.611172Z","iopub.status.idle":"2022-05-28T10:49:00.156991Z","shell.execute_reply.started":"2022-05-28T10:48:55.611144Z","shell.execute_reply":"2022-05-28T10:49:00.155733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1 Read an image\n\nFrom the [cv2 documentation](https://docs.opencv.org/3.4/d8/d6a/group__imgcodecs__flags.html#gga61d9b0126a3e57d9277ac48327799c80aeddd67043ed0df14f9d9a4e66d2b0708) we know that `cv2.IMREAD_UNCHANGED` is set it returns the loaded image as is (with alpha channel, otherwise it gets cropped). Ignore EXIF orientation (or JPEG).\n\nIf we don't set this `cv2.IMREAD_UNCHANGED` parameter, the returned image is **black** - because the .png images are on 16 bits.\n\n<center><img src=\"https://i.imgur.com/NLPQo7A.png\" width=900></center>","metadata":{}},{"cell_type":"code","source":"def read_image(path):\n    '''Reads and converts the image.\n    path: the full complete path to the .png file'''\n\n    # Read image in a corresponding manner\n    # convert int16 -> float32\n    image = cv2.imread(path, cv2.IMREAD_UNCHANGED).astype('float32')\n    # Scale to [0, 255]\n    image = cv2.normalize(image, None, alpha = 0, beta = 255, \n                        norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n    image = image.astype(np.uint8)\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:00.15835Z","iopub.execute_input":"2022-05-28T10:49:00.158812Z","iopub.status.idle":"2022-05-28T10:49:00.498419Z","shell.execute_reply.started":"2022-05-28T10:49:00.158781Z","shell.execute_reply":"2022-05-28T10:49:00.49759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_simple_images(sample_paths, image_names=\"sample_images\"):\n    '''Displays simple images (without mask).'''\n\n    # Get additional info from the path\n    case_name = [info.split(\"_\")[0][-7:] for info in sample_paths]\n    day_name = [info.split(\"_\")[1].split(\"/\")[0] for info in sample_paths]\n    slice_name = [info.split(\"_\")[2] for info in sample_paths]\n\n\n    # Plot\n    fig, axs = plt.subplots(2, 5, figsize=(23, 8))\n    axs = axs.flatten()\n    wandb_images = []\n\n    for k, path in enumerate(sample_paths):\n        title = f\"{k+1}. {case_name[k]} - {day_name[k]} - {slice_name[k]}\"\n        axs[k].set_title(title, fontsize = 14, \n                         color = my_colors[-1], weight='bold')\n\n        img = read_image(path)\n        wandb_images.append(wandb.Image(img))\n        axs[k].imshow(img)\n        axs[k].axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n\n    # üêù Log Image to W&B\n    wandb.log({f\"{image_names}\": wandb_images})","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-05-28T10:49:00.499756Z","iopub.execute_input":"2022-05-28T10:49:00.500384Z","iopub.status.idle":"2022-05-28T10:49:00.853875Z","shell.execute_reply.started":"2022-05-28T10:49:00.500346Z","shell.execute_reply":"2022-05-28T10:49:00.853002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CASE = \"case123\"\n\n# Sample a few images from speciffied case\nsample_paths1 = train[(train[\"segmentation\"].isna()==False) & (train[\"case\"]==CASE)][\"path\"]\\\n                .reset_index().groupby(\"path\")[\"index\"].count()\\\n                .reset_index().loc[:9, \"path\"].tolist()\n\nshow_simple_images(sample_paths1, image_names=\"case123_samples\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:00.855272Z","iopub.execute_input":"2022-05-28T10:49:00.855541Z","iopub.status.idle":"2022-05-28T10:49:02.534781Z","shell.execute_reply.started":"2022-05-28T10:49:00.855517Z","shell.execute_reply":"2022-05-28T10:49:02.53397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DAY = \"day25\"\n\n# Sample a few images from speciffied case\nsample_paths2 = train[(train[\"segmentation\"].isna()==False) & (train[\"day\"]==DAY)][\"path\"]\\\n                .reset_index().groupby(\"path\")[\"index\"].count()\\\n                .reset_index().loc[:9, \"path\"].tolist()\n\nshow_simple_images(sample_paths2, image_names=\"day25_samples\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:02.535855Z","iopub.execute_input":"2022-05-28T10:49:02.536478Z","iopub.status.idle":"2022-05-28T10:49:03.99494Z","shell.execute_reply.started":"2022-05-28T10:49:02.536443Z","shell.execute_reply":"2022-05-28T10:49:03.99377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Create the masks\n\n**‚öïÔ∏è A case (or `id`) can have the following possibilities**:\n1. **ALL** `small_bowel`, `large_bowel` and `stomach` have **NO** segmentation\n2. **SOME** of the `small_bowel`, `large_bowel` and `stomach` have **SOME** segmentation\n3. **ALL** `small_bowel`, `large_bowel` and `stomach` **DO HAVE** segmentation\n\n### I. From Segmentation to Mask\n\nThe segmentation (where doesn't have the value `nan`) is formed by a list of numbers containing different pixel points and their length. As an example:\n* `'28094 3 28358 7 28623 9 28889 9 29155 9 29421 9 29687 9 29953 9 30219 9 30484 10 30750 10 31016 10 31282 10 31548 10 31814 10 32081 9 32347 8 32614 6'`\n* where:\n    * 28094, 28358, 28623 etc. are the **startpoints** of the pixels within the matrix\n    * and 3, 7, 9, 9 etc. are how long to strech the startpoints - meaning the total **length**\n    * hence we can compute the **endpoint** of each of these segments as the sum of **startpoints** + **endpoints**\n\n<center><img src=\"https://i.imgur.com/x2AtzF7.png\" width=1000></center>\n\n> üìñ **References**: from [this script](https://www.kaggle.com/code/paulorzp/run-length-encode-and-decode/script) and inspired by Awsaf's [notebook](https://www.kaggle.com/code/awsaf49/uwmgi-mask-data)","metadata":{}},{"cell_type":"code","source":"def mask_from_segmentation(segmentation, shape):\n    '''Returns the mask corresponding to the inputed segmentation.\n    segmentation: a list of start points and lengths in this order\n    max_shape: the shape to be taken by the mask\n    return:: a 2D mask'''\n\n    # Get a list of numbers from the initial segmentation\n    segm = np.asarray(segmentation.split(), dtype=int)\n\n    # Get start point and length between points\n    start_point = segm[0::2] - 1\n    length_point = segm[1::2]\n\n    # Compute the location of each endpoint\n    end_point = start_point + length_point\n\n    # Create an empty list mask the size of the original image\n    # take onl\n    case_mask = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n\n    # Change pixels from 0 to 1 that are within the segmentation\n    for start, end in zip(start_point, end_point):\n        case_mask[start:end] = 1\n\n    case_mask = case_mask.reshape((shape[0], shape[1]))\n    \n    return case_mask","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:03.996534Z","iopub.execute_input":"2022-05-28T10:49:03.997561Z","iopub.status.idle":"2022-05-28T10:49:04.389067Z","shell.execute_reply.started":"2022-05-28T10:49:03.997518Z","shell.execute_reply":"2022-05-28T10:49:04.388146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example\nsegmentation = '45601 5 45959 10 46319 12 46678 14 47037 16 47396 18 47756 18 48116 19 48477 18 48837 19 \\\n                49198 19 49558 19 49919 19 50279 20 50639 20 50999 21 51359 21 51719 22 52079 22 52440 22 52800 22 53161 21 \\\n                53523 20 53884 20 54245 19 54606 19 54967 18 55328 17 55689 16 56050 14 56412 12 56778 4 57855 7 58214 9 58573 12 \\\n                58932 14 59292 15 59651 16 60011 17 60371 17 60731 17 61091 17 61451 17 61812 15 62172 15 62532 15 62892 14 \\\n                63253 12 63613 12 63974 10 64335 7'\n\nshape = (310, 360)\n\ncase_mask = mask_from_segmentation(segmentation, shape)\nwandb_mask = []\nwandb_mask.append(wandb.Image(case_mask))\n\nplt.figure(figsize=(5, 5))\nplt.title(\"Mask Example:\")\nplt.imshow(case_mask)\nplt.axis(\"off\")\nplt.show();\n\n# üêù Log Image to W&B\nwandb.log({f\"mask_example\": wandb_mask})","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:04.394421Z","iopub.execute_input":"2022-05-28T10:49:04.394628Z","iopub.status.idle":"2022-05-28T10:49:04.826134Z","shell.execute_reply.started":"2022-05-28T10:49:04.394605Z","shell.execute_reply":"2022-05-28T10:49:04.825133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### II. Get full Mask for each ID\n\nNow, for each ID, we are going to create an image of shape `[img height, img width, 3]`, where 3 (number of channels) are the 3 layers for each class:\n* **the first layer**: large bowel\n* **the second layer**: small bowel\n* **the third layer**: stomach\n\n<center><img src=\"https://i.imgur.com/gH97y3m.png\" width=700></center>\n\nHence, these masks will accompany the original images and, alongside them will provide valuable information on the evolution of healthy tissue in each slice:\n<center><img src=\"https://i.imgur.com/DyLBCfL.png\" width=700></center>","metadata":{}},{"cell_type":"code","source":"def get_id_mask(ID, verbose=False):\n    '''Returns a mask for each case ID. If no segmentation was found, the mask will be empty\n    - meaning formed by only 0\n    ID: the case ID from the train.csv file\n    verbose: True if we want any prints\n    return: segmentation mask'''\n\n    # ~~~ Get the data ~~~\n    # Get the portion of dataframe where we have ONLY the speciffied ID\n    ID_data = train[train[\"id\"]==ID].reset_index(drop=True)\n\n    # Split the dataframe into 3 series of observations\n    # each for one speciffic class - \"large_bowel\", \"small_bowel\", \"stomach\"\n    observations = [ID_data.loc[k, :] for k in range(3)]\n\n\n    # ~~~ Create the mask ~~~\n    # Get the maximum height out of all observations\n    # if max == 0 then no class has a segmentation\n    # otherwise we keep the length of the mask\n    max_height = np.max([obs.image_height for obs in observations])\n    max_width = np.max([obs.image_width for obs in observations])\n\n    # Get shape of the image\n    # 3 channels of color/classes\n    shape = (max_height, max_width, 3)\n\n    # Create an empty mask with the shape of the image\n    mask = np.zeros(shape, dtype=np.uint8)\n\n    # If there is at least 1 segmentation found in the group of 3 classes\n    if max_height != 0:\n        for k, location in enumerate([\"large_bowel\", \"small_bowel\", \"stomach\"]):\n            observation = observations[k]\n            segmentation = observation.segmentation\n\n            # If a segmentation is found\n            # Append a new channel to the mask\n            if pd.isnull(segmentation) == False:\n                mask[..., k] = mask_from_segmentation(segmentation, shape)\n\n    # If no segmentation was found skip\n    elif max_segmentation == 0:\n        mask = None\n        if verbose:\n            print(\"None of the classes have segmentation.\")\n            \n    return mask","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:04.827278Z","iopub.execute_input":"2022-05-28T10:49:04.827491Z","iopub.status.idle":"2022-05-28T10:49:05.368414Z","shell.execute_reply.started":"2022-05-28T10:49:04.827464Z","shell.execute_reply":"2022-05-28T10:49:05.36742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Full Example\n\n# Read image\npath = '../input/uw-madison-gi-tract-image-segmentation/train/case131/case131_day0/scans/slice_0066_360_310_1.50_1.50.png'\nimg = read_image(path)\n\n# Get mask\nID = \"case131_day0_slice_0066\"\nmask = get_id_mask(ID, verbose=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:05.369489Z","iopub.execute_input":"2022-05-28T10:49:05.36967Z","iopub.status.idle":"2022-05-28T10:49:05.757223Z","shell.execute_reply.started":"2022-05-28T10:49:05.369649Z","shell.execute_reply":"2022-05-28T10:49:05.756475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**‚öï Plotting an Example:**\n1. we change the pixels of the `mask`: when 0 then switch to `NA` (transparent), when 1 we mark as `True`\n2. we split the channels of the `mask`: each mask has 3 channels, one for each `class`\n3. plot the original image\n4. plot over this image the 3 channel layers (or classes)","metadata":{}},{"cell_type":"code","source":"def plot_original_mask(img, mask, alpha=1):\n\n    # Change pixels - when 1 make True, when 0 make NA\n    mask = np.ma.masked_where(mask == 0, mask)\n\n    # Split the channels\n    mask_largeB = mask[:, :, 0]\n    mask_smallB = mask[:, :, 1]\n    mask_stomach = mask[:, :, 2]\n\n\n    # Plot the 2 images (Original and with Mask)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))\n\n    # Original\n    ax1.set_title(\"Original Image\")\n    ax1.imshow(img)\n    ax1.axis(\"off\")\n\n    # With Mask\n    ax2.set_title(\"Image with Mask\")\n    ax2.imshow(img)\n    ax2.imshow(mask_largeB, interpolation='none', cmap=CMAP1, alpha=alpha)\n    ax2.imshow(mask_smallB, interpolation='none', cmap=CMAP2, alpha=alpha)\n    ax2.imshow(mask_stomach, interpolation='none', cmap=CMAP3, alpha=alpha)\n    ax2.legend(legend_colors, labels)\n    ax2.axis(\"off\")\n    \n#     fig.savefig('foo.png', dpi=500)\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-28T10:49:05.758653Z","iopub.execute_input":"2022-05-28T10:49:05.758898Z","iopub.status.idle":"2022-05-28T10:49:06.065076Z","shell.execute_reply.started":"2022-05-28T10:49:05.758865Z","shell.execute_reply":"2022-05-28T10:49:06.064382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_original_mask(img, mask, alpha=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:06.065981Z","iopub.execute_input":"2022-05-28T10:49:06.066628Z","iopub.status.idle":"2022-05-28T10:49:06.89197Z","shell.execute_reply.started":"2022-05-28T10:49:06.066563Z","shell.execute_reply":"2022-05-28T10:49:06.891081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Another example\npath = '../input/uw-madison-gi-tract-image-segmentation/train/case18/case18_day0/scans/slice_0069_360_310_1.50_1.50.png'\nimg = read_image(path)\n\nID = \"case18_day0_slice_0069\"\nmask = get_id_mask(ID, verbose=False)\n\nplot_original_mask(img, mask, alpha=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:06.892879Z","iopub.execute_input":"2022-05-28T10:49:06.893243Z","iopub.status.idle":"2022-05-28T10:49:07.757707Z","shell.execute_reply.started":"2022-05-28T10:49:06.893212Z","shell.execute_reply":"2022-05-28T10:49:07.756182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Explore the masks\n\nLet's now explore the masks on images and observe their **evolution**, how they move and react for each slice.","metadata":{}},{"cell_type":"code","source":"# Filter out all instances with no segmentation\ndata = train[train[\"segmentation\"].isna()==False].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:07.759026Z","iopub.execute_input":"2022-05-28T10:49:07.759257Z","iopub.status.idle":"2022-05-28T10:49:08.181281Z","shell.execute_reply.started":"2022-05-28T10:49:07.759227Z","shell.execute_reply":"2022-05-28T10:49:08.180279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ‚¨á Function below to plot multiple images & masks in chronologic order","metadata":{}},{"cell_type":"code","source":"def plot_masks_chronologic(imgs, masks, ids, alpha=1):\n    \n    slices = [i.split(\"_\")[-1] for i in ids]\n    \n    # Plot\n    fig, axs = plt.subplots(2, 5, figsize=(23, 11))\n    axs = axs.flatten()\n    \n    for k, (img, mask) in enumerate(zip(imgs, masks)):\n\n        # Change pixels - when 1 make True, when 0 make NA\n        mask = np.ma.masked_where(mask == 0, mask)\n\n        # Split the channels\n        mask_largeB = mask[:, :, 0]\n        mask_smallB = mask[:, :, 1]\n        mask_stomach = mask[:, :, 2]\n        \n        title = f\"{k+1}. Slice {slices[k]}\"\n        axs[k].set_title(title, fontsize = 16, \n                         color = my_colors[-1], weight='bold')\n\n        axs[k].imshow(img, cmap=\"gist_gray\")\n        axs[k].axis(\"off\")\n        axs[k].imshow(mask_largeB, interpolation='none', cmap=CMAP1, alpha=alpha)\n        axs[k].imshow(mask_smallB, interpolation='none', cmap=CMAP2, alpha=alpha)\n        axs[k].imshow(mask_stomach, interpolation='none', cmap=CMAP3, alpha=alpha)\n        axs[k].axis(\"off\")\n    \n    axs[0].legend(legend_colors, labels, loc=2)\n    plt.tight_layout()\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-28T10:49:08.182393Z","iopub.execute_input":"2022-05-28T10:49:08.182633Z","iopub.status.idle":"2022-05-28T10:49:08.545718Z","shell.execute_reply.started":"2022-05-28T10:49:08.182601Z","shell.execute_reply":"2022-05-28T10:49:08.544636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Case 123 | Day 20 | Slices 0085 -> 0094**\n* the *stomach* segmentation decreases by each slice\n* the *small bowel* segmentation increases in size and doubles on the left side of the CT too\n* the *large bowel* seems to be decreasing by each slice until it splits in 2 smaller portions","metadata":{}},{"cell_type":"code","source":"# Get random case\ncase = \"case123\"\nday=\"day20\"\n\n# Get ids and paths for that case\n# drop duplicates (for when 2 or more segments are present)\ndf = data[(data[\"case\"]==case) & (data[\"day\"]==day)].drop_duplicates(\"path\")\\\n                            .reset_index().loc[20:29, :]\n\nIMGS = [read_image(path) for path in df[\"path\"].to_list()]\nMASKS = [get_id_mask(i, verbose=False) for i in df[\"id\"].tolist()]\n\nplot_masks_chronologic(IMGS, MASKS, ids=df[\"id\"].tolist(), alpha=0.7)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:08.547242Z","iopub.execute_input":"2022-05-28T10:49:08.547604Z","iopub.status.idle":"2022-05-28T10:49:10.686972Z","shell.execute_reply.started":"2022-05-28T10:49:08.547562Z","shell.execute_reply":"2022-05-28T10:49:10.686098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Case 30 | Day 0 | Slices 0092 -> 0101**\n* the *stomach* segmentation appears in the second slice and starts increasing in size\n* the *small bowel* segmentation is not present at all\n* the *large bowel* increases in size too","metadata":{}},{"cell_type":"code","source":"# Get random case\ncase = \"case30\"\nday=\"day0\"\n\n# Get ids and paths for that case\n# drop duplicates (for when 2 or more segments are present)\ndf = data[(data[\"case\"]==case) & (data[\"day\"]==day)].drop_duplicates(\"path\")\\\n                            .reset_index().head(10)\n\nIMGS = [read_image(path) for path in df[\"path\"].to_list()]\nMASKS = [get_id_mask(i, verbose=False) for i in df[\"id\"].tolist()]\n\nplot_masks_chronologic(IMGS, MASKS, ids=df[\"id\"].tolist(), alpha=0.7)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:10.688423Z","iopub.execute_input":"2022-05-28T10:49:10.688619Z","iopub.status.idle":"2022-05-28T10:49:12.689959Z","shell.execute_reply.started":"2022-05-28T10:49:10.688594Z","shell.execute_reply":"2022-05-28T10:49:12.689079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Case 18 | Day 0 | Slices 0060 -> 0069**\n* the *stomach* segmentation increases by each slice\n* the *small bowel* is not present in any of the slices\n* the *large bowel* increases in size too and duplicates at some point next to the stomach too","metadata":{}},{"cell_type":"code","source":"# Get random case\ncase = \"case18\"\nday=\"day0\"\n\n# Get ids and paths for that case\n# drop duplicates (for when 2 or more segments are present)\ndf = data[(data[\"case\"]==case) & (data[\"day\"]==day)].drop_duplicates(\"path\")\\\n                            .reset_index().head(10)\n\nIMGS = [read_image(path) for path in df[\"path\"].to_list()]\nMASKS = [get_id_mask(i, verbose=False) for i in df[\"id\"].tolist()]\n\nplot_masks_chronologic(IMGS, MASKS, ids=df[\"id\"].tolist(), alpha=0.7)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:12.691268Z","iopub.execute_input":"2022-05-28T10:49:12.691473Z","iopub.status.idle":"2022-05-28T10:49:14.641083Z","shell.execute_reply.started":"2022-05-28T10:49:12.691451Z","shell.execute_reply":"2022-05-28T10:49:14.64062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Case 146 | Day 0 | Slices 0080 -> 0089**\n* the *stomach* segmentation is not present in any of the slices\n* the *small bowel* segmentation has 2 locations and increases and splits in size by each slice (the last slice has 5 distinct locations where the healthy tissue is present)\n* the *large bowel* increases in size, at some point 2 portions even unite in only one singural bigger piece","metadata":{}},{"cell_type":"code","source":"# Get random case\ncase = \"case146\"\nday=\"day0\"\n\n# Get ids and paths for that case\n# drop duplicates (for when 2 or more segments are present)\ndf = data[(data[\"case\"]==case) & (data[\"day\"]==day)].drop_duplicates(\"path\")\\\n                            .reset_index().loc[20:29, :]\n\nIMGS = [read_image(path) for path in df[\"path\"].to_list()]\nMASKS = [get_id_mask(i, verbose=False) for i in df[\"id\"].tolist()]\n\nplot_masks_chronologic(IMGS, MASKS, ids=df[\"id\"].tolist(), alpha=0.7)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:14.64204Z","iopub.execute_input":"2022-05-28T10:49:14.642367Z","iopub.status.idle":"2022-05-28T10:49:16.486519Z","shell.execute_reply.started":"2022-05-28T10:49:14.642342Z","shell.execute_reply":"2022-05-28T10:49:16.484801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:16.487433Z","iopub.execute_input":"2022-05-28T10:49:16.487595Z","iopub.status.idle":"2022-05-28T10:49:23.909321Z","shell.execute_reply.started":"2022-05-28T10:49:16.487573Z","shell.execute_reply":"2022-05-28T10:49:23.908486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Create & Save masks for all instances\n\nNow we can export the `train` masks to a new folder as images - these will be used for training afterwards.\n\n## 3.1 Create and save 3D masks","metadata":{}},{"cell_type":"code","source":"# Create folder to save masks\nos.mkdir(\"masks_png\")\n\n# Get a list of unique ids\nunique_ids = train[train[\"segmentation\"].isna()==False][\"id\"].unique()\n\nfor ID in tqdm(unique_ids):\n    # Get the mask\n    mask = get_id_mask(ID, verbose=False)\n    # Write it in folder\n    cv2.imwrite(f\"masks_png/{ID}.png\", mask)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:49:23.910519Z","iopub.execute_input":"2022-05-28T10:49:23.910716Z","iopub.status.idle":"2022-05-28T10:52:55.977937Z","shell.execute_reply.started":"2022-05-28T10:49:23.910689Z","shell.execute_reply":"2022-05-28T10:52:55.977032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save to zip file\nshutil.make_archive('zip_masks3D', 'zip', 'masks_png')\n\n# Delete the initial folder\nshutil.rmtree('masks_png')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:52:55.97932Z","iopub.execute_input":"2022-05-28T10:52:55.979568Z","iopub.status.idle":"2022-05-28T10:52:59.272947Z","shell.execute_reply.started":"2022-05-28T10:52:55.979533Z","shell.execute_reply":"2022-05-28T10:52:59.271854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Update train dataset\n\nNow we need to update the `train_csv`, adding the path to the masks.\n\n<center><img src=\"https://i.imgur.com/6nMMAqZ.png\" width=800></center>","metadata":{}},{"cell_type":"code","source":"base_zip = \"../input/preprocessed-awmadison-gi-tract-segmentation/zip_masks3D\"\n\n# Create a new column for mask paths\ntrain[\"mask_path\"] = 0\nn = len(train)\n\n# Loop through entire dataset\nfor k in tqdm(range(n)):\n    data = train.iloc[k, :]\n    segmentation = data.segmentation\n\n    # In case coordinates for healthy tissue are present\n    if pd.isnull(train.iloc[k, 2]) == False:\n        ID = data.id\n        # Change value to the correct one\n        train.loc[k, \"mask_path\"] = f\"{base_zip}/{ID}.png\"","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:52:59.274202Z","iopub.execute_input":"2022-05-28T10:52:59.274421Z","iopub.status.idle":"2022-05-28T10:54:39.871029Z","shell.execute_reply.started":"2022-05-28T10:52:59.274391Z","shell.execute_reply":"2022-05-28T10:54:39.870157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# üêù Save train.csv as artifact\ntrain.to_csv(\"train.csv\", index=False)\n\nsave_dataset_artifact(run_name=\"save_train_mask\",\n                      artifact_name=\"train\",\n                      path=\"../input/preprocessed-awmadison-gi-tract-segmentation/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:54:39.873491Z","iopub.execute_input":"2022-05-28T10:54:39.873696Z","iopub.status.idle":"2022-05-28T10:54:50.65606Z","shell.execute_reply.started":"2022-05-28T10:54:39.873666Z","shell.execute_reply":"2022-05-28T10:54:50.655242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Log Masks into W&B\n\n> üôè To log masks I followed **[this amazing notebook from Ayush](https://www.kaggle.com/code/ayuraj/quick-data-eda-segmentation-viz-using-w-b)**.\n\nBelow it's an example of logged image with mask within [my Dashboard connected to this competition](https://wandb.ai/andrada/AWMadison?workspace=user-andrada).\n\n<center><video src=\"https://i.imgur.com/43mudKJ.mp4\" width=900 controls></center>","metadata":{}},{"cell_type":"code","source":"# üêù New Experiment\nrun = wandb.init(project='AWMadison', name='log_masks', config=CONFIG)\n\n# Filter out all instances with no segmentation\ndata = train[train[\"segmentation\"].isna()==False].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:54:50.657589Z","iopub.execute_input":"2022-05-28T10:54:50.657773Z","iopub.status.idle":"2022-05-28T10:54:55.572153Z","shell.execute_reply.started":"2022-05-28T10:54:50.657751Z","shell.execute_reply":"2022-05-28T10:54:55.571396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mask_3D_to_2D(mask):\n    '''convert mask from 3D array to 2D.\n    from 3 layers: large bowel, small bowel, stomach we convert to a 2D matrix\n    with pixel values 0: empty | 1: large bowel | 2: small bowel | 3: stomach\n    '''\n\n    # Create a new 2D mask\n    w = mask.shape[0]\n    h = mask.shape[1]\n\n    mask_2D = np.zeros(w * h, dtype=np.uint16).reshape(w, h)\n\n    # For each layer keep only the pixels == 1\n    # and their position on the new mask\n    for k in [0, 1, 2]:\n        # set pixels\n        # 1: large bowel | 2: small bowel | 3: stomach\n        mask_2D = np.where(mask[:, :, k] > 0, k+1 , mask_2D)\n        \n    return mask_2D","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:54:55.573281Z","iopub.execute_input":"2022-05-28T10:54:55.573871Z","iopub.status.idle":"2022-05-28T10:54:56.056235Z","shell.execute_reply.started":"2022-05-28T10:54:55.573838Z","shell.execute_reply":"2022-05-28T10:54:56.055479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def log_samples_wandb(df, case, day):\n    '''Log samples of images with masks into W&B.'''\n\n    # Labels for W&B logging\n    wandb_masks = []\n    CLASS_LABELS = {\n      1: \"large_bowel\",\n      2: \"small_bowel\",\n      3: \"stomach\"\n    }\n    # For the plotting part\n    fig, axs = plt.subplots(2, 5, figsize=(23, 7))\n    axs = axs.flatten()\n    \n    WANDB_COLORS = [(0.19, 0.4, 0.55), (0.2, 0.72, 0.47), (1.0, 0.9, 0.14)]\n    WANDB_LEGEND = [Rectangle((0,0),1,1, color=color) for color in WANDB_COLORS]    \n\n    # Loop through each observation\n    for k in range(len(df)):\n        obs = df.loc[k, :]\n        image = read_image(obs.path)\n        mask = cv2.imread(obs.mask_path)\n        # Change masks from 3D to 2D (to be supported by W&B)\n        mask = mask_3D_to_2D(mask)\n\n        # Create image & mask and log\n        wandb_mask = wandb.Image(image, \n                                 masks={\n                                     'truth_mask':{\n                                         'mask_data': mask,\n                                         'class_labels': CLASS_LABELS\n                                     }\n                                 })\n        wandb_masks.append(wandb_mask)\n        \n        # Show image\n        axs[k].imshow(mask)\n        title = f\"{k+1}. Slice {obs.slice_no}\"\n        axs[k].set_title(title, fontsize = 14, \n                         color = my_colors[-1], weight='bold')\n        axs[k].axis(\"off\")\n        \n    axs[0].legend(WANDB_LEGEND, labels, loc=3)\n    plt.tight_layout()\n    plt.show()\n\n    wandb.log({f\"{case}_{day}_sample\": wandb_masks})\n    \n    return \"Images & Masks were logged successfully.\"","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:54:56.057358Z","iopub.execute_input":"2022-05-28T10:54:56.058282Z","iopub.status.idle":"2022-05-28T10:54:56.458874Z","shell.execute_reply.started":"2022-05-28T10:54:56.058235Z","shell.execute_reply":"2022-05-28T10:54:56.458392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get case and log it into W&B\ncase = \"case123\"\nday=\"day20\"\n\n# Get ids and paths for that case\ndf = data[(data[\"case\"]==case) & (data[\"day\"]==day)].drop_duplicates(\"path\")\\\n                            .reset_index().loc[20:29, :].reset_index(drop=True)\n\nlog_samples_wandb(df, case, day)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:54:56.459828Z","iopub.execute_input":"2022-05-28T10:54:56.460028Z","iopub.status.idle":"2022-05-28T10:54:57.940442Z","shell.execute_reply.started":"2022-05-28T10:54:56.460002Z","shell.execute_reply":"2022-05-28T10:54:57.939539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# üêù End experiment\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:54:57.941568Z","iopub.execute_input":"2022-05-28T10:54:57.94171Z","iopub.status.idle":"2022-05-28T10:55:06.323638Z","shell.execute_reply.started":"2022-05-28T10:54:57.94169Z","shell.execute_reply":"2022-05-28T10:55:06.322757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 Save 2D Masks\n\nUntil now we have created a folder with 3D masks (size `[width, height, 3]`), meaning that there are 3 \"channels\", with each layer of one mask containing:\n* layer 1: large bowel segmentation\n* layer 2: small bowel segmentation\n* layer 3: stomach segmentation\n\nHowever, I want to **save the images as 2D as well**, meaning that instead of having a size of `[width, height, 3]`, we will have only a size of `[width, height]`. Then, the image will look like this *(exactly how we logged it into W&B)*:\n* 1 matrix (layer) with:\n    * pixels of value `0`: meaning no segmentation\n    * pixels of value `1`: meaning large bowel segmentation\n    * pixels of value `2`: meaning small bowel segmentation\n    * pixels of value `3`: meaning stomach segmentation\n    \n<center><img src=\"https://i.imgur.com/etJITDK.png\"></center>","metadata":{}},{"cell_type":"code","source":"# Create folder to save masks\nos.mkdir(\"masks2D_png\")\n\n# Get unique paths for the 3D masks (generated at step 3.1)\nall_mask_paths = train[train[\"segmentation\"].isna()==False][\"mask_path\"].unique()\n\nfor mask_path in tqdm(all_mask_paths):\n    # Get file name\n    name = mask_path.split(\"/\")[-1]\n\n    # Read mask\n    mask = cv2.imread(mask_path)\n    # Change masks from 3D to 2D\n    mask = mask_3D_to_2D(mask)\n    # Write it in folder\n    cv2.imwrite(f\"masks2D_png/{name}\", mask)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:55:06.324806Z","iopub.execute_input":"2022-05-28T10:55:06.32497Z","iopub.status.idle":"2022-05-28T10:58:07.292111Z","shell.execute_reply.started":"2022-05-28T10:55:06.324948Z","shell.execute_reply":"2022-05-28T10:58:07.290789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save to zip file\nshutil.make_archive('zip_masks2D', 'zip', 'masks2D_png')\n\n# Delete the initial folder\nshutil.rmtree('masks2D_png')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:58:07.29475Z","iopub.execute_input":"2022-05-28T10:58:07.295109Z","iopub.status.idle":"2022-05-28T10:58:10.821308Z","shell.execute_reply.started":"2022-05-28T10:58:07.295065Z","shell.execute_reply":"2022-05-28T10:58:10.820477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.5 Other Updates\n\nLast changes to the `train.csv` file.","metadata":{}},{"cell_type":"code","source":"# Make case and day columns numeric\ntrain[\"case\"] = train[\"case\"].apply(lambda x: int(\"\".join([i for i in x if i.isdigit()])))\ntrain[\"day\"] = train[\"day\"].apply(lambda x: int(\"\".join([i for i in x if i.isdigit()])))\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:58:10.823271Z","iopub.execute_input":"2022-05-28T10:58:10.823551Z","iopub.status.idle":"2022-05-28T10:58:11.390434Z","shell.execute_reply.started":"2022-05-28T10:58:10.823517Z","shell.execute_reply":"2022-05-28T10:58:11.389867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# üêù Save train.csv as artifact\ntrain.to_csv(\"train.csv\", index=False)\n\nsave_dataset_artifact(run_name=\"save_train_mask\",\n                      artifact_name=\"train\",\n                      path=\"../input/preprocessed-awmadison-gi-tract-segmentation/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:58:11.39159Z","iopub.execute_input":"2022-05-28T10:58:11.392379Z","iopub.status.idle":"2022-05-28T10:58:24.215505Z","shell.execute_reply.started":"2022-05-28T10:58:11.392312Z","shell.execute_reply":"2022-05-28T10:58:24.214433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# <center><video src=\"mp4\" width=800 controls></center>","metadata":{"execution":{"iopub.status.busy":"2022-05-28T10:58:24.216945Z","iopub.execute_input":"2022-05-28T10:58:24.21713Z","iopub.status.idle":"2022-05-28T10:58:24.221893Z","shell.execute_reply.started":"2022-05-28T10:58:24.217105Z","shell.execute_reply":"2022-05-28T10:58:24.221138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><img src=\"https://i.imgur.com/0cx4xXI.png\"></center>\n\n### üêù W&B Dashboard\n\n> My [W&B Dashboard](https://wandb.ai/andrada/AWMadison?workspace=user-andrada).\n\n<center><img src=\"https://i.imgur.com/MkW1ZKf.png\"></center>\n\n<center><img src=\"https://i.imgur.com/knxTRkO.png\"></center>\n\n### My Specs\n\n* üñ• Z8 G4 Workstation\n* üíæ 2 CPUs & 96GB Memory\n* üéÆ NVIDIA Quadro RTX 8000\n* üíª Zbook Studio G7 on the go","metadata":{}}]}