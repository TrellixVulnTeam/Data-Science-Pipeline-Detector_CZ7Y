{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-24T21:57:02.688721Z","iopub.execute_input":"2022-05-24T21:57:02.689053Z","iopub.status.idle":"2022-05-24T21:57:02.715625Z","shell.execute_reply.started":"2022-05-24T21:57:02.688966Z","shell.execute_reply":"2022-05-24T21:57:02.714608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Part 1: [Train --> uwmgtis Keras train_03](https://www.kaggle.com/code/benoitdacosta/uwmgtis-keras-train-03) \n* Part 2: [Inference --> uwmgtis Keras infer_03](https://www.kaggle.com/code/benoitdacosta/uwmgtis-keras-infer-03)","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom time import time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom pathlib import Path\nimport os \nfrom glob import glob\nfrom joblib import parallel_backend, Parallel, delayed , dump , load\nfrom tqdm import tqdm\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nimport gc\n\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose\nfrom tensorflow.keras.layers import Concatenate, Input , Dropout\n\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.metrics import binary_crossentropy\n\nfrom keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl\nfrom matplotlib.patches import Rectangle\nimport cv2\n\nimport multiprocessing as mp\nprint(\"Number of processors: \", mp.cpu_count())\n\npd.set_option('display.max_columns',200)\npd.set_option('display.max_colwidth', 200)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:02.902206Z","iopub.execute_input":"2022-05-24T21:57:02.902735Z","iopub.status.idle":"2022-05-24T21:57:08.694877Z","shell.execute_reply.started":"2022-05-24T21:57:02.902697Z","shell.execute_reply":"2022-05-24T21:57:08.69411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data & Configuration","metadata":{}},{"cell_type":"code","source":"repertory ='/kaggle/input/'\n\nDIR = repertory + 'uw-madison-gi-tract-image-segmentation/' \nTRAIN_DIR = DIR + 'train'\nTEST_DIR = DIR + 'test'\ntrain_csv = DIR +'train.csv' \nsample_sub = DIR + 'sample_submission.csv'\n\ndf_train = pd.read_csv(train_csv)\ndf_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:08.696771Z","iopub.execute_input":"2022-05-24T21:57:08.697246Z","iopub.status.idle":"2022-05-24T21:57:09.237008Z","shell.execute_reply.started":"2022-05-24T21:57:08.697206Z","shell.execute_reply":"2022-05-24T21:57:09.236284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    BATCH_SIZE    = 16\n    img_size      = (256, 256, 3)\n    n_fold        = 5\n    fold_selected = 1\n    epochs        = 100\n    seed          = 42\n    nb_cpu        = mp.cpu_count()\n    steps_per_epoch_train = None\n    steps_per_epoch_val = None\n\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:09.238515Z","iopub.execute_input":"2022-05-24T21:57:09.238778Z","iopub.status.idle":"2022-05-24T21:57:09.243836Z","shell.execute_reply.started":"2022-05-24T21:57:09.238743Z","shell.execute_reply":"2022-05-24T21:57:09.243031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREPROCESSING","metadata":{}},{"cell_type":"code","source":"# Metadata\ndef preprocessing(df, subset = 'train'):\n    #--------------------------------------------------------------------------\n    df[\"case\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\n    df[\"day\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\n    df[\"slice\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n    #--------------------------------------------------------------------------\n    if subset == 'train':\n        all_images = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n        x = all_images[0].rsplit('/' , 4)[0] ## ../uw-madison-gi-tract-image-segmentation/train\n    else: \n        all_images = glob(os.path.join(TEST_DIR, \"**\", \"*.png\"), recursive=True)\n        x = all_images[0].rsplit('/' , 4)[0] ## ../uw-madison-gi-tract-image-segmentation/test\n\n    path_partial_list = []\n    for i in range(0, df.shape[0]):\n        path_partial_list.append(os.path.join(x,\n                              \"case\"+str(df[\"case\"].values[i]),\n                              \"case\"+str(df[\"case\"].values[i])+\"_\"+ \"day\"+str(df[\"day\"].values[i]),\n                              \"scans\",\n                              \"slice_\"+str(df[\"slice\"].values[i])))\n    df[\"path_partial\"] = path_partial_list\n    #--------------------------------------------------------------------------\n    path_partial_list = []\n    for i in range(0, len(all_images)):\n        path_partial_list.append(str(all_images[i].rsplit(\"_\",4)[0]))\n\n    tmp_df = pd.DataFrame()\n    tmp_df['path_partial'] = path_partial_list\n    tmp_df['path'] = all_images\n    #--------------------------------------------------------------------------\n    df = pd.merge(df,tmp_df, on=\"path_partial\").drop(columns=[\"path_partial\"])\n    #--------------------------------------------------------------------------\n    df[\"width\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"height\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n    df[\"px_spacing_h\"] = df[\"path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[3]))\n    df[\"px_spacing_w\"] = df[\"path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[4]))\n    #--------------------------------------------------------------------------\n    del x, path_partial_list, tmp_df\n    #--------------------------------------------------------------------------\n    gc.collect()\n    return df ","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:09.246476Z","iopub.execute_input":"2022-05-24T21:57:09.246784Z","iopub.status.idle":"2022-05-24T21:57:09.265027Z","shell.execute_reply.started":"2022-05-24T21:57:09.246743Z","shell.execute_reply":"2022-05-24T21:57:09.264338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = preprocessing(df_train)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:09.266569Z","iopub.execute_input":"2022-05-24T21:57:09.267054Z","iopub.status.idle":"2022-05-24T21:57:18.245844Z","shell.execute_reply.started":"2022-05-24T21:57:09.267017Z","shell.execute_reply":"2022-05-24T21:57:18.245037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function\n","metadata":{}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = np.asarray(mask_rle.split(), dtype=int)\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.247323Z","iopub.execute_input":"2022-05-24T21:57:18.247591Z","iopub.status.idle":"2022-05-24T21:57:18.257039Z","shell.execute_reply.started":"2022-05-24T21:57:18.247556Z","shell.execute_reply":"2022-05-24T21:57:18.25636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def id2mask(id_):\n    itrain_df = train_df[train_df['id']==id_]\n    wh = itrain_df[['height','width']].iloc[0]\n    shape = (wh.height, wh.width, 3)\n    mask = np.zeros(shape, dtype=np.uint8)\n    for i, class_ in enumerate(['large_bowel', 'small_bowel', 'stomach']):\n        ctrain_df = itrain_df[itrain_df['class']==class_]\n        rle = ctrain_df.segmentation.squeeze()\n        if len(ctrain_df) and not pd.isna(rle):\n            mask[..., i] = rle_decode(rle, shape[:2])\n    return mask\n\ndef rgb2gray(mask):\n    pad_mask = np.pad(mask, pad_width=[(0,0),(0,0),(1,0)])\n    gray_mask = pad_mask.argmax(-1)\n    return gray_mask\n\ndef gray2rgb(mask):\n    rgb_mask = tf.keras.utils.to_categorical(mask, num_classes=4)\n    return rgb_mask[..., 1:].astype(mask.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.258479Z","iopub.execute_input":"2022-05-24T21:57:18.259055Z","iopub.status.idle":"2022-05-24T21:57:18.271495Z","shell.execute_reply.started":"2022-05-24T21:57:18.25901Z","shell.execute_reply":"2022-05-24T21:57:18.270492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_img(path):\n    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n    img = img.astype('float32') # original is uint16\n    img = (img - img.min())/(img.max() - img.min())*255.0 # scale image to [0, 255]\n    img = img.astype('uint8')\n    return img\n\ndef show_img(img, mask=None):\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    img = clahe.apply(img)\n#     plt.figure(figsize=(10,10))\n    plt.imshow(img, cmap='bone')\n    \n    if mask is not None:\n        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n        plt.imshow(mask, alpha=0.5)\n        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n        labels = [ \"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n        plt.legend(handles,labels)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.273068Z","iopub.execute_input":"2022-05-24T21:57:18.273642Z","iopub.status.idle":"2022-05-24T21:57:18.28605Z","shell.execute_reply.started":"2022-05-24T21:57:18.273604Z","shell.execute_reply":"2022-05-24T21:57:18.285318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# row=1; col=4\n# plt.figure(figsize=(5*col,5*row))\n# for i, id_ in enumerate(train_df[train_df.segmentation.notna()].sample(frac=1.0)['id'].unique()[:row*col]):\n#     img = load_img(train_df[train_df['id']==id_].path.iloc[0])\n#     mask = id2mask(id_)*255\n#     plt.subplot(row, col, i+1)\n#     i+=1\n#     show_img(img, mask=mask)\n#     plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.287681Z","iopub.execute_input":"2022-05-24T21:57:18.288198Z","iopub.status.idle":"2022-05-24T21:57:18.295205Z","shell.execute_reply.started":"2022-05-24T21:57:18.288157Z","shell.execute_reply":"2022-05-24T21:57:18.294452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Restructure\ndef restructure(df, subset=\"train\"):\n    # RESTRUCTURE  DATAFRAME\n    df_out = pd.DataFrame({'id': df['id'][::3]})\n\n    if subset==\"train\":\n        df_out['large_bowel'] = df['segmentation'][::3].values\n        df_out['small_bowel'] = df['segmentation'][1::3].values\n        df_out['stomach'] = df['segmentation'][2::3].values\n\n    df_out['path'] = df['path'][::3].values\n    df_out['case'] = df['case'][::3].values\n    df_out['day'] = df['day'][::3].values\n    df_out['slice'] = df['slice'][::3].values\n    df_out['width'] = df['width'][::3].values\n    df_out['height'] = df['height'][::3].values\n\n    df_out=df_out.reset_index(drop=True)\n    df_out=df_out.fillna('')\n    if subset==\"train\":\n        df_out['count'] = np.sum(df_out.iloc[:,1:4]!='',axis=1).values\n        \n    display(df_out.sample(5))\n    return df_out","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.301454Z","iopub.execute_input":"2022-05-24T21:57:18.302177Z","iopub.status.idle":"2022-05-24T21:57:18.320624Z","shell.execute_reply.started":"2022-05-24T21:57:18.302128Z","shell.execute_reply":"2022-05-24T21:57:18.319805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_train= restructure(train_df, subset=\"train\")","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.32558Z","iopub.execute_input":"2022-05-24T21:57:18.326098Z","iopub.status.idle":"2022-05-24T21:57:18.4493Z","shell.execute_reply.started":"2022-05-24T21:57:18.326055Z","shell.execute_reply":"2022-05-24T21:57:18.44848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATASET","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, batch_size = CFG.BATCH_SIZE, subset=\"train\", shuffle=False , img_shape = CFG.img_size , aug_dat=False):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.aug_dat = aug_dat\n        self.batch_size = batch_size\n        self.img_shape = img_shape\n        self.indexes = np.arange(len(df))\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index):\n        X = np.empty((self.batch_size,self.img_shape[0],self.img_shape[1],self.img_shape[2]))\n        y = np.empty((self.batch_size,self.img_shape[0],self.img_shape[1],self.img_shape[2]))\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        id_, heights, widths, classes = [] , [] ,[], [] \n        \n        for i, img_path in enumerate(self.df['path'].iloc[indexes]):\n            if self.subset != 'train':\n                id_.append(self.df['id'].iloc[indexes[i]])\n                heights.append(self.df['height'].iloc[indexes[i]])\n                widths.append(self.df['width'].iloc[indexes[i]])\n                classes.append(self.df['class'].iloc[indexes[i]])\n            \n            w=self.df['width'].iloc[indexes[i]]\n            h=self.df['height'].iloc[indexes[i]]\n            \n            img = self.__load_grayscale(img_path)  \n#             X[i,] = img   \n            X[i,] = np.concatenate((img , img , img), axis = -1)\n            \n            if self.subset == 'train':\n                for k,j in enumerate([\"large_bowel\",\"small_bowel\",\"stomach\"]):\n                    rles = self.df[j].iloc[indexes[i]]\n                    mask = rle_decode(rles, shape=(h, w, 1))\n                    mask = cv2.resize(mask, self.img_shape[0:2] )\n                    y[i,:,:,k] = mask\n                  \n        if self.aug_dat : \n            imag_ , mask_ = self.__aug_img(X,y)\n#             imag_ , mask_ = aug_img(X,y , self.batch_size ,self.img_shape)\n            X = np.concatenate((X , imag_ ), axis = 0)\n            y = np.concatenate((y , mask_ ), axis = 0)\n\n        if self.subset == 'train':\n            return tf.convert_to_tensor(X,dtype=tf.float32), tf.convert_to_tensor(y,dtype=tf.float32)\n        else: \n            return X , id_ , widths , heights , classes\n\n        \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n    #         img = cv2.imread(img_path,cv2.IMREAD_UNCHANGED)\n        dsize = self.img_shape[0:2]\n        img = cv2.resize(img, dsize)\n    #         img = img.astype(np.int8) / 255.\n        img = img.astype('float32') # original is uint16\n        img = (img - img.min())/(img.max() - img.min())*255.0 # scale image to [0, 255]\n        img = img.astype('uint8')/255\n        img = np.expand_dims(img, axis=-1)\n        return img\n    \n    def __aug_img(self, img , mask) :\n        im = np.empty((self.batch_size,self.img_shape[0],self.img_shape[1],self.img_shape[2]))\n        mk = np.empty((self.batch_size,self.img_shape[0],self.img_shape[1],self.img_shape[2])) \n        for i in range(self.batch_size):\n            img_ = img[i,]\n            mask_ = mask[i,] \n            while len(np.unique( img[i,] - img_)) == 1 : \n                Nb_random =np.random.randint(low = 0, high=100, size=2)\n                seed = (Nb_random[0],Nb_random[1])\n                if seed[0]/100 <0.3 : \n                    img_ = tf.image.stateless_random_flip_up_down(img_, seed=seed )\n                    mask_ = tf.image.stateless_random_flip_up_down(mask_, seed=seed )\n                elif seed[0]/100 >0.7 : \n                    img_ = tf.image.stateless_random_flip_left_right(img_ , seed=seed )\n                    mask_ =  tf.image.stateless_random_flip_left_right(mask_ , seed=seed )\n                else : \n                    img_ = tf.image.stateless_random_flip_left_right(img_ , seed=seed )\n                    mask_ =  tf.image.stateless_random_flip_left_right(mask_ , seed=seed )\n                    img_ = tf.image.stateless_random_flip_up_down(img_, seed=seed )\n                    mask_ = tf.image.stateless_random_flip_up_down(mask_, seed=seed )\n            im[i,] = img_\n            mk[i,] = mask_\n        return im, mk   \n\n    \n# def aug_img( img , mask, batch_size ,img_shape  ) :\n#     im = np.empty((batch_size,img_shape[0],img_shape[1],img_shape[2]))\n#     mk = np.empty((batch_size,img_shape[0],img_shape[1],img_shape[2])) \n#     for i in range(batch_size):\n#         img_ = img[i,]\n#         mask_ = mask[i,] \n#         while len(np.unique( img[i,] - img_)) == 1 : \n#             Nb_random =np.random.randint(low = 0, high=100, size=2)\n#             seed = (Nb_random[0],Nb_random[1])\n#             if seed[0]/100 <0.3 : \n#                 img_ = tf.image.stateless_random_flip_up_down(img_, seed=seed )\n#                 mask_ = tf.image.stateless_random_flip_up_down(mask_, seed=seed )\n#             elif seed[0]/100 >0.7 : \n#                 img_ = tf.image.stateless_random_flip_left_right(img_ , seed=seed )\n#                 mask_ =  tf.image.stateless_random_flip_left_right(mask_ , seed=seed )\n#             else : \n#                 img_ = tf.image.stateless_random_flip_left_right(img_ , seed=seed )\n#                 mask_ =  tf.image.stateless_random_flip_left_right(mask_ , seed=seed )\n#                 img_ = tf.image.stateless_random_flip_up_down(img_, seed=seed )\n#                 mask_ = tf.image.stateless_random_flip_up_down(mask_, seed=seed )\n#         im[i,] = img_\n#         mk[i,] = mask_\n#     return im, mk    ","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.453162Z","iopub.execute_input":"2022-05-24T21:57:18.454064Z","iopub.status.idle":"2022-05-24T21:57:18.49622Z","shell.execute_reply.started":"2022-05-24T21:57:18.454023Z","shell.execute_reply":"2022-05-24T21:57:18.495277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_masks = list(DF_train[DF_train['large_bowel']!=''].index)\nTrain_masks += list(DF_train[DF_train['small_bowel']!=''].index)\nTrain_masks += list(DF_train[DF_train['stomach']!=''].index)\n\nDF_training = DF_train[DF_train.index.isin(Train_masks)]\nDF_training.reset_index(inplace=True, drop = True)\nprint(DF_training.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.501809Z","iopub.execute_input":"2022-05-24T21:57:18.5026Z","iopub.status.idle":"2022-05-24T21:57:18.573292Z","shell.execute_reply.started":"2022-05-24T21:57:18.502558Z","shell.execute_reply":"2022-05-24T21:57:18.572472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FOLDS","metadata":{}},{"cell_type":"code","source":"skf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=42)\n\nfor fold, (_, val_idx) in enumerate(skf.split(X=DF_training, y=DF_training['count'],groups =DF_training['case']), 1):\n    DF_training.loc[val_idx, 'fold'] = fold\n    \n# DF_training['fold'] = DF_training['fold'].astype(np.uint8)\n\ntrain_idx = DF_training[DF_training[\"fold\"]!=CFG.fold_selected].index\nvalid_idx = DF_training[DF_training[\"fold\"]==CFG.fold_selected].index\n\n# CFG.steps_per_epoch_train = len(train_idx) // CFG.BATCH_SIZE \n# if len(train_idx) % CFG.BATCH_SIZE !=0: \n#     CFG.steps_per_epoch_train +=1\n    \n# CFG.steps_per_epoch_val = len(valid_idx) //CFG.BATCH_SIZE*2\n# if len(valid_idx) //CFG.BATCH_SIZE*2 !=0: \n#     CFG.steps_per_epoch_val +=1\n\ntrain_generator = DataGenerator(DF_training[DF_training.index.isin(train_idx)], batch_size = 11, subset=\"train\", \n                                shuffle=True , img_shape = CFG.img_size , aug_dat=True)\nval_generator = DataGenerator(DF_training[DF_training.index.isin(valid_idx)], batch_size = 29, subset=\"train\", \n                                shuffle=False , img_shape = CFG.img_size , aug_dat=False )\n# display(DF_training.groupby('fold').size())\n# display(DF_training.groupby(['fold','count'])['id'].count())","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.575227Z","iopub.execute_input":"2022-05-24T21:57:18.575802Z","iopub.status.idle":"2022-05-24T21:57:18.682323Z","shell.execute_reply.started":"2022-05-24T21:57:18.575761Z","shell.execute_reply":"2022-05-24T21:57:18.681565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Visualizing\n# fig = plt.figure(figsize=(10, 25))\n# gs = gridspec.GridSpec(nrows=6, ncols=2)\n# colors = ['red','green','blue']\n# labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n# patches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\n# cmap1 = mpl.colors.ListedColormap(colors[0])\n# cmap2 = mpl.colors.ListedColormap(colors[1])\n# cmap3 = mpl.colors.ListedColormap(colors[2])\n\n# for i in range(6):\n#     images, mask = train_generator[i]\n#     sample_img=images[0,:,:,0]\n#     mask1=mask[0,:,:,0]\n#     mask2=mask[0,:,:,1]\n#     mask3=mask[0,:,:,2]\n    \n#     ax0 = fig.add_subplot(gs[i, 0])\n#     im = ax0.imshow(sample_img, cmap='bone')\n\n#     ax1 = fig.add_subplot(gs[i, 1])\n#     if i==0:\n#         ax0.set_title(\"Image\", fontsize=15, weight='bold', y=1.02)\n#         ax1.set_title(\"Mask\", fontsize=15, weight='bold', y=1.02)\n#         plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 14,title='Mask Labels', title_fontsize=14, edgecolor=\"black\",  facecolor='#c5c6c7')\n\n#     l0 = ax1.imshow(sample_img, cmap='bone')\n#     l1 = ax1.imshow(np.ma.masked_where(mask1== False,  mask1),cmap=cmap1, alpha=1)\n#     l2 = ax1.imshow(np.ma.masked_where(mask2== False,  mask2),cmap=cmap2, alpha=1)\n#     l3 = ax1.imshow(np.ma.masked_where(mask3== False,  mask3),cmap=cmap3, alpha=1)\n#     _ = [ax.set_axis_off() for ax in [ax0,ax1]]\n\n#     colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.685384Z","iopub.execute_input":"2022-05-24T21:57:18.685713Z","iopub.status.idle":"2022-05-24T21:57:18.69234Z","shell.execute_reply.started":"2022-05-24T21:57:18.685683Z","shell.execute_reply":"2022-05-24T21:57:18.69159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{}},{"cell_type":"code","source":"#Metrics\nfrom tensorflow.keras.metrics import binary_crossentropy as BCE\n\n# def replacenan(t):            \n#     return tf.where(tf.math.is_nan(t), tf.ones_like(t), t)\n\n# def replacenan(t):\n#     t = tf.clip_by_value(t, clip_value_min=0.0, clip_value_max=1.0)\n#     return tf.math.multiply_no_nan(t, tf.ones_like(t))\n\n# def dice_coef(y_true, y_pred, smooth=1.0):\n#     y_true_f = replacenan(y_true)\n#     y_pred_f = replacenan(y_pred)\n    \n#     y_true_f = tf.keras.backend.flatten(y_true_f)\n#     y_pred_f = tf.keras.backend.flatten(y_pred_f)\n    \n#     intersection = tf.math.reduce_sum(y_true_f * y_pred_f)\n#     sum_ = tf.math.reduce_sum(y_true_f) + tf.math.reduce_sum(y_pred_f)\n    \n#     dice = tf.math.divide_no_nan((2.0 * intersection + smooth) , ( sum_ + smooth))\n#     return dice\n    \n# def iou_coef(y_true, y_pred, smooth=1.0):   \n#     y_true_f = replacenan(y_true)\n#     y_pred_f = replacenan(y_pred)\n    \n#     intersection = tf.math.reduce_sum(y_true_f * y_pred_f, axis=[1,2,3])\n#     union = tf.math.reduce_sum(y_true_f,[1,2,3])+tf.math.reduce_sum(y_pred_f,[1,2,3])-intersection\n    \n#     iou = tf.math.reduce_mean( tf.math.divide_no_nan((intersection + smooth),(union + smooth)) , axis=0)\n#     return iou\n\n# def dice_loss(y_true, y_pred):\n#     loss = 1 - dice_coef(y_true, y_pred)\n#     return loss\n\n# def bce_dice_loss(y_true, y_pred):   \n#     y_true_f = replacenan(y_true)\n#     y_pred_f = replacenan(y_pred)\n#     bce = BCE(y_true_f, y_pred_f)\n#     bce = tf.math.multiply_no_nan(bce, tf.ones_like(bce))\n#     return bce + dice_loss(y_true, y_pred)\n\ndef dice_coef(y_true,y_pred):\n    y_true_f=tf.reshape(tf.dtypes.cast(y_true, tf.float32),[-1])\n    y_pred_f=tf.reshape(tf.dtypes.cast(y_pred, tf.float32),[-1])\n    intersection=tf.reduce_sum(y_true_f*y_pred_f)\n    sum_ = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n    return (2. * intersection + 1.) / (sum_ + 1.)\n\ndef iou_coef(y_true, y_pred):   \n    y_true_f=tf.reshape(tf.dtypes.cast(y_true, tf.float32),[-1])\n    y_pred_f=tf.reshape(tf.dtypes.cast(y_pred, tf.float32),[-1])\n    intersection=tf.reduce_sum(y_true_f*y_pred_f)\n    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection\n    \n    iou = (intersection+1.) / (union+1.)\n    return iou\n\ndef bce_dice_loss(y_true, y_pred):\n    y_true_f = tf.reshape(y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    return BCE(y_true, y_pred) + (1-dice_coef(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.695462Z","iopub.execute_input":"2022-05-24T21:57:18.695899Z","iopub.status.idle":"2022-05-24T21:57:18.713506Z","shell.execute_reply.started":"2022-05-24T21:57:18.695866Z","shell.execute_reply":"2022-05-24T21:57:18.712698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# U-NET Models","metadata":{}},{"cell_type":"code","source":"def conv_block(inputs, num_filters, batchnorm ):\n    x = Conv2D(num_filters, kernel_size = (3,3), padding=\"same\",)(inputs)\n    x = Activation(\"relu\")(x)\n    if batchnorm : \n        x = BatchNormalization()(x)\n    x = Conv2D(num_filters, kernel_size = (3,3), padding=\"same\")(x)\n    x = Activation(\"relu\")(x)\n    if batchnorm : \n        x = BatchNormalization()(x)\n    return x\n\ndef encoder_block(inputs, num_filters, dropout = False ,  batchnorm =True):\n    x = conv_block(inputs, num_filters , batchnorm)\n    p = MaxPool2D((2, 2))(x)\n    if dropout : \n        p = Dropout(0.3)(p)\n    return x, p\n\ndef decoder_block(inputs, skip_features, num_filters, dropout = False, batchnorm = True):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n    x = Concatenate()([x, skip_features])\n    if dropout : \n        x = Dropout(0.3)(x)\n    x = conv_block(x, num_filters, batchnorm)\n    return x\n\ndef build_unet(input_shape, dropout = False , batchnorm = True , activation = 'sigmoid'):\n\n    inputs = Input(shape=input_shape)\n    \n    s0, p0 = encoder_block(inputs, 32 , dropout , batchnorm )\n    s1, p1 = encoder_block(p0, 64 , dropout , batchnorm )\n    s2, p2 = encoder_block(p1, 128, dropout , batchnorm  )\n    s3, p3 = encoder_block(p2, 256, dropout , batchnorm )\n    s4, p4 = encoder_block(p3, 512, dropout , batchnorm )\n    s5, p5 = encoder_block(p4, 1024, dropout , batchnorm )\n\n    b1 = conv_block(p5, 2048, batchnorm)\n\n    d0 = decoder_block(b1, s5, 1024, dropout , batchnorm )\n    d1 = decoder_block(d0, s4, 512, dropout , batchnorm )\n    d2 = decoder_block(d1, s3, 256, dropout , batchnorm )\n    d3 = decoder_block(d2, s2, 128, dropout , batchnorm )\n    d4 = decoder_block(d3, s1, 64, dropout , batchnorm )\n    d5 = decoder_block(d4, s0, 32, dropout , batchnorm )\n\n    outputs = Conv2D(3, 1, padding=\"same\", activation =activation )(d5)\n\n    model = Model(inputs, outputs, name=\"U-Net\")\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(),loss=bce_dice_loss,\n                  metrics=[iou_coef , dice_coef])\n    return model\n\n# PLOT TRAINING\ndef plot_train(model):\n    losses = model if isinstance(model, pd.DataFrame) else pd.DataFrame(model.history.history) \n    plt.figure(figsize=(15,5))\n    plt.subplot(1,3,1)\n    plt.plot(losses['loss'].index,losses['loss'],label='Train_Loss')\n    plt.plot(losses['val_loss'].index,losses['val_loss'],label='Val_loss')\n    plt.title('LOSS'); plt.xlabel('Epoch'); plt.ylabel('loss');plt.legend();\n\n    plt.subplot(1,3,2)\n    plt.plot(losses['dice_coef'].index,losses['dice_coef'],label='Train_dice_coef')\n    plt.plot(losses['val_dice_coef'].index,losses['val_dice_coef'],label='Val_dice_coef')\n    plt.title('DICE'); plt.xlabel('Epoch'); plt.ylabel('dice_coef');plt.legend(); \n\n    plt.subplot(1,3,3)\n    plt.plot(losses['iou_coef'].index,losses['iou_coef'],label='Train_iou_coef')\n    plt.plot(losses['val_iou_coef'].index,losses['val_iou_coef'],label='Val_iou_coef')\n    plt.title('IOU'); plt.xlabel('Epoch'); plt.ylabel('iou_coef');plt.legend();\n    plt.show()\n\ndef fit_model(model ,  model_name , train_dataset , validation_dataset , workers = None):\n    if os.path.isfile(models_path+str(model_name)+'.h5'): \n        model = load_model(models_path+str(model_name)+'.h5', custom_objects={'bce_dice_loss': bce_dice_loss ,'iou_coef':iou_coef ,'dice_coef':dice_coef  })\n        results = load(results_path+'score_'+str(model_name)+'.joblib')\n        # model.summary()\n        plot_train(results)\n    else :\n        # model.summary()\n        early_stop = EarlyStopping(monitor='val_loss', patience=5)\n        if workers : \n            model.fit(x = train_dataset, epochs=CFG.epochs,validation_data=validation_dataset, callbacks=[early_stop],\n                      workers = CFG.nb_cpu)\n   \n        else : \n            model.fit(x = train_dataset, epochs=CFG.epochs, validation_data=validation_dataset, callbacks=[early_stop])\n \n        results = pd.DataFrame(model.history.history)\n        plot_train(model)\n        \n        dump(results,results_path+'score_'+str(model_name)+'.joblib',compress = True)\n        model.save(models_path+str(model_name)+'.h5') \n    \n    return model , results","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.715139Z","iopub.execute_input":"2022-05-24T21:57:18.715406Z","iopub.status.idle":"2022-05-24T21:57:18.743971Z","shell.execute_reply.started":"2022-05-24T21:57:18.715371Z","shell.execute_reply":"2022-05-24T21:57:18.742898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_path = '/kaggle/working/'\nresults_path = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.745175Z","iopub.execute_input":"2022-05-24T21:57:18.745978Z","iopub.status.idle":"2022-05-24T21:57:18.755964Z","shell.execute_reply.started":"2022-05-24T21:57:18.745904Z","shell.execute_reply":"2022-05-24T21:57:18.755146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = CFG.img_size\ngc.collect()\nmodel = build_unet(input_shape, dropout = True , batchnorm = True) ","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:18.759261Z","iopub.execute_input":"2022-05-24T21:57:18.760074Z","iopub.status.idle":"2022-05-24T21:57:22.453033Z","shell.execute_reply.started":"2022-05-24T21:57:18.760044Z","shell.execute_reply":"2022-05-24T21:57:22.449095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model , results = fit_model(model , 'U-net',train_generator , val_generator, workers = None)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:22.454367Z","iopub.execute_input":"2022-05-24T21:57:22.454858Z","iopub.status.idle":"2022-05-24T21:57:22.966418Z","shell.execute_reply.started":"2022-05-24T21:57:22.454816Z","shell.execute_reply":"2022-05-24T21:57:22.965255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"# sub_df = pd.read_csv(sample_sub)\n# if not len(sub_df):\n#     debug = True\n#     sub_df = pd.read_csv(train_csv)\n#     test_df = preprocessing(df_train,  subset = 'train')[0:3000]\n# else : \n#     debug = False\n#     test_df = preprocessing(sub_df , subset = 'test')\n    \n# test_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:22.967486Z","iopub.status.idle":"2022-05-24T21:57:22.968479Z","shell.execute_reply.started":"2022-05-24T21:57:22.968211Z","shell.execute_reply":"2022-05-24T21:57:22.968237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def infer(DF , model , batch_size = CFG.BATCH_SIZE) : \n#     pred_rle = []; pred_ids = []; pred_classes = [];\n    \n#     DF_batch = DataGenerator(DF, batch_size =batch_size, subset=\"test\", shuffle=False)\n#     for idx , (img , id_, widths , heights , classes) in enumerate(tqdm(DF_batch)):\n# #         msk = np.empty((batch_size,CFG.img_size[0],CFG.img_size[1],CFG.img_size[2]))\n                                       \n#         preds = model.predict(img,verbose=0)\n        \n#         # Rle encode \n#         for j in range(batch_size):\n#             k = 0 if classes[j]=='large_bowel' else 1 if classes[j]=='small_bowel' else 2\n\n#             pred_img = cv2.resize(preds[j,:,:,k], ( widths[j] , heights[j]),\n#                                   interpolation=cv2.INTER_NEAREST) # resize probabilities to original shape\n#             pred_img = (pred_img>0.5).astype(dtype='uint8')    # classify\n\n#             pred_ids.append(id_[j])\n#             pred_classes.append(classes[j])\n#             pred_rle.append(rle_encode(pred_img))\n    \n#     return pred_rle, pred_ids , pred_classes","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:22.969579Z","iopub.status.idle":"2022-05-24T21:57:22.970384Z","shell.execute_reply.started":"2022-05-24T21:57:22.970144Z","shell.execute_reply":"2022-05-24T21:57:22.97017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_rle, pred_ids , pred_classes = infer(test_df, model)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:22.971586Z","iopub.status.idle":"2022-05-24T21:57:22.971984Z","shell.execute_reply.started":"2022-05-24T21:57:22.971766Z","shell.execute_reply":"2022-05-24T21:57:22.971789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({\n#     \"id\":pred_ids,\n#     \"class\":pred_classes,\n#     \"predicted\":pred_rle\n# })\n\n# if debug :\n#     sub_df = pd.read_csv(train_csv)\n#     del sub_df['segmentation']\n# else:\n#     sub_df = pd.read_csv(sample_sub)\n#     del sub_df['predicted']\n\n# sub_df = sub_df.merge(submission, on=['id','class'])\n# sub_df.to_csv('submission.csv',index=False)\n\n# submission.sample(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T21:57:22.973102Z","iopub.status.idle":"2022-05-24T21:57:22.974742Z","shell.execute_reply.started":"2022-05-24T21:57:22.9745Z","shell.execute_reply":"2022-05-24T21:57:22.974525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}