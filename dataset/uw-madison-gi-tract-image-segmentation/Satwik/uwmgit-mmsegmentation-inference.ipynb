{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Install packages","metadata":{}},{"cell_type":"markdown","source":"# This is an inference only notebook part for the mmseg notebook shared by @carnozhao. Since internet cannot be used , and multiple packages need to be installed here , I have added all the packages needed offline, and also cloned Carno's mmseg git repo which is needed in the kernel. There is still some bug here , since all the predictions are appearing empty , and the inference code is copied as it is from Carno's notebook. Either the model training has a bug , or the inference code has a bug. will update asap!\n\n# *EDIT - The inference code is working fine , so is this notebook. There was some issue in the model training , leading to empty predictions.\n#   Carno suggested using a larger batch size than 8 , and it worked well for me.*","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nsys.path.append(\"../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1\")\nsys.path.append(\"../input/pretrainedmodels/pretrainedmodels-0.7.4\")\nsys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch-master\")\n\n!pip install ../input/mmdetection/addict-2.4.0-py3-none-any.whl > /dev/null\n!pip install ../input/mmdetection/yapf-0.31.0-py2.py3-none-any.whl > /dev/null\n!pip install ../input/mmdetection/terminaltables-3.1.0-py3-none-any.whl > /dev/null\n!pip install ../input/mmdetection/einops* > /dev/null\n!pip install ../input/mmdetection/mmcv_full-1.3.17-cp37-cp37m-linux_x86_64.whl > /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-13T10:45:54.28458Z","iopub.execute_input":"2022-05-13T10:45:54.284925Z","iopub.status.idle":"2022-05-13T10:48:21.582108Z","shell.execute_reply.started":"2022-05-13T10:45:54.284844Z","shell.execute_reply":"2022-05-13T10:48:21.58127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Install mmsegmentation \n\nThis is from my own [mmseg github repo](https://github.com/CarnoZhao/Kaggle-UWMGIT) (leave a star if you like it!)\n\nI have integrated `segmentation_models_pytorch` in this version of `mmsegmentation`. Although `segmentation_models_pytorch`'s simple Unet performs better than some models of `mmsegmentation`, anyway, `mmsegmentation` is still a good library for segmentation task when you want to compare various models in a unified training pipeline.\n\nI only hard-coded `smp.Unet` in `./mmseg/models/segmentors/smp_models.py`. You can add more `smp` models in it!","metadata":{}},{"cell_type":"code","source":"!cp -r ../input/uwmgitt-mmseg/Kaggle-UWMGIT-kaggle_tractseg ./ && cd Kaggle-UWMGIT-kaggle_tractseg  && pip install -e .\n","metadata":{"execution":{"iopub.status.busy":"2022-05-13T10:48:21.584364Z","iopub.execute_input":"2022-05-13T10:48:21.584816Z","iopub.status.idle":"2022-05-13T10:48:58.942142Z","shell.execute_reply.started":"2022-05-13T10:48:21.584774Z","shell.execute_reply":"2022-05-13T10:48:58.941363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Prepare data","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nfrom PIL import Image\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-13T10:48:58.943679Z","iopub.execute_input":"2022-05-13T10:48:58.943936Z","iopub.status.idle":"2022-05-13T10:48:59.206143Z","shell.execute_reply.started":"2022-05-13T10:48:58.943899Z","shell.execute_reply":"2022-05-13T10:48:59.205463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Read csv and extract meta info","metadata":{}},{"cell_type":"markdown","source":"# 5. Inferencing\n\n## 5.1 Load trained models","metadata":{}},{"cell_type":"code","source":"sys.path.append('./Kaggle-UWMGIT-kaggle_tractseg')\n\nfrom mmseg.apis import init_segmentor, inference_segmentor\nfrom mmcv.utils import config\n\ncfgs = [\n    \"../input/mmdet-20k-iter-test/config.py\",\n]\n\nckpts = [\n    \"../input/mmdet-20k-iter-test/iter_20000.pth\",\n]\n\nmodels = []\nfor cfg, ckpt in zip(cfgs, ckpts):\n    cfg = config.Config.fromfile(cfg)\n    cfg.model.backbone.pretrained = None\n    cfg.model.test_cfg.logits = True\n    cfg.data.test.pipeline[1].transforms.insert(2, dict(type=\"Normalize\", mean=[0,0,0], std=[1,1,1], to_rgb=False))\n\n    model = init_segmentor(cfg, ckpt)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T10:48:59.208209Z","iopub.execute_input":"2022-05-13T10:48:59.208392Z","iopub.status.idle":"2022-05-13T10:49:27.597067Z","shell.execute_reply.started":"2022-05-13T10:48:59.208369Z","shell.execute_reply":"2022-05-13T10:49:27.596245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Make test submission csv","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport glob\nfrom tqdm.auto import tqdm\nfrom scipy.ndimage import binary_closing, binary_opening, measurements\n\ndef rle_encode(img):\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nclasses = ['large_bowel', 'small_bowel', 'stomach']\ndata_dir = \"../input/uw-madison-gi-tract-image-segmentation/\"\ntest_dir = os.path.join(data_dir, \"test\")\nsub = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))\ntest_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n\nif len(test_images) == 0:\n    test_dir = os.path.join(data_dir, \"train\")\n    sub = pd.read_csv(os.path.join(data_dir, \"train.csv\"))[[\"id\", \"class\"]].iloc[:100 * 3]\n    sub[\"predicted\"] = \"\"\n    test_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n    \nid2img = {_.rsplit(\"/\", 4)[2] + \"_\" + \"_\".join(_.rsplit(\"/\", 4)[4].split(\"_\")[:2]): _ for _ in test_images}\nsub[\"file_name\"] = sub.id.map(id2img)\nsub[\"days\"] = sub.id.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\nfname2index = {f + c: i for f, c, i in zip(sub.file_name, sub[\"class\"], sub.index)}\nsub","metadata":{"execution":{"iopub.status.busy":"2022-05-13T10:49:27.59886Z","iopub.execute_input":"2022-05-13T10:49:27.599119Z","iopub.status.idle":"2022-05-13T10:49:32.185276Z","shell.execute_reply.started":"2022-05-13T10:49:27.599086Z","shell.execute_reply":"2022-05-13T10:49:32.184613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Start Inferencing","metadata":{}},{"cell_type":"code","source":"subs = []\nfor day, group in tqdm(sub.groupby(\"days\")):\n    imgs = []\n    for file_name in group.file_name.unique():\n        img = cv2.imread(file_name, cv2.IMREAD_ANYDEPTH)\n        old_size = img.shape[:2]\n        s = int(os.path.basename(file_name).split(\"_\")[1])\n        file_names = [file_name.replace(f\"slice_{s:04d}\", f\"slice_{s + i:04d}\") for i in range(-2, 3)]\n        file_names = [_ for _ in file_names if os.path.exists(_)]\n        imgs = [cv2.imread(file_names[0], cv2.IMREAD_ANYDEPTH)] + [img] + [cv2.imread(file_names[-1], cv2.IMREAD_ANYDEPTH)]\n        \n        new_img = np.stack(imgs, -1)\n        new_img = new_img.astype(np.float32) / new_img.max()\n\n        res = [inference_segmentor(model, new_img)[0] for model in models]\n        res = (sum(res) / len(res)).round().astype(np.uint8)\n        print(res)\n        res = cv2.resize(res, old_size[::-1], interpolation = cv2.INTER_NEAREST)\n        for j in range(3):\n            rle = rle_encode(res[...,j])\n            index = fname2index[file_name + classes[j]]\n            sub.loc[index, \"predicted\"] = rle","metadata":{"execution":{"iopub.status.busy":"2022-05-13T10:49:32.186571Z","iopub.execute_input":"2022-05-13T10:49:32.186991Z","iopub.status.idle":"2022-05-13T10:49:41.862581Z","shell.execute_reply.started":"2022-05-13T10:49:32.186955Z","shell.execute_reply":"2022-05-13T10:49:41.861864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.4 Format submission","metadata":{}},{"cell_type":"code","source":"sub = sub[[\"id\", \"class\", \"predicted\"]]\nsub.to_csv(\"submission.csv\", index = False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-05-13T10:49:41.864032Z","iopub.execute_input":"2022-05-13T10:49:41.864517Z","iopub.status.idle":"2022-05-13T10:49:41.882526Z","shell.execute_reply.started":"2022-05-13T10:49:41.864479Z","shell.execute_reply":"2022-05-13T10:49:41.88176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing the remaining files in the output dir since submission errors out if there are other files than submission.csv in the output.","metadata":{}},{"cell_type":"code","source":"!rm -r ./Kaggle-UWMGIT-kaggle_tractseg","metadata":{"execution":{"iopub.status.busy":"2022-05-13T10:49:41.884076Z","iopub.execute_input":"2022-05-13T10:49:41.884511Z","iopub.status.idle":"2022-05-13T10:49:42.641496Z","shell.execute_reply.started":"2022-05-13T10:49:41.884474Z","shell.execute_reply":"2022-05-13T10:49:42.640557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}