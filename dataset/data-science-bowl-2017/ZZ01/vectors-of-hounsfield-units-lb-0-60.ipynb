{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"a07f5103-d036-968f-40d7-57649bbb4864"},"source":"## Introduction\n\nAfter processing the scans with Guido Zuidhof's great preprocessing tutorial, I got the idea that the distribution of Hounsfield Units might already contain some information about the possibility of malignant nodules. According to Wikipedia, [malignant nodules have a higher density][1] (HU) than benign nodules. Intuitively, a high count of nodules in a certain range of Hounsfield Units might be a good indicator for malignant nodules. \n\nThis Kernel will generate a CSV file that fills a vector for each scan, counting the occurrences of HU values from -1500 to 2000. This is a very basic approach, but already yields a LB score of 0.60021 using XGBoost - which can probably still be improved by experimenting with the data.\n\nAlso, this script doesn't address obvious issues of the data, e.g. that the number of slices varies for each scan, so some scans have a higher HU count for certain ranges just by having more slices. \n\nI would like to hear your opinions about this approach. I am especially trying to find ways to solving this problem that don't require training massive CNNs or other resource intensive techniques.\n\n\n  [1]: https://en.wikipedia.org/wiki/Solitary_pulmonary_nodule#Diagnosis"},{"cell_type":"markdown","metadata":{"_cell_guid":"37f0f8ed-c56b-b82b-424e-b494331386e7"},"source":"Here are the preprocessing steps from Guido to turn the pixels into Hounsfield Unit values:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d12eab6-3340-fa57-84a1-91fe13886996"},"outputs":[],"source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport dicom\nimport os\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\n\nfrom skimage import measure, morphology\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\n# Some constants \nINPUT_FOLDER = '../input/sample_images/'\npatients = os.listdir(INPUT_FOLDER)\npatients.sort()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f50e5b1-c1e8-14a8-591b-eb466e5adc0d"},"outputs":[],"source":"# Load the scans in given folder path\ndef load_scan(path):\n    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        \n    return slices"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e60f402c-0cd9-f0d2-0c3d-3e7af98f9845"},"outputs":[],"source":"def get_pixels_hu(slices):\n    image = np.stack([s.pixel_array for s in slices])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    for slice_number in range(len(slices)):\n        \n        intercept = slices[slice_number].RescaleIntercept\n        slope = slices[slice_number].RescaleSlope\n        \n        if slope != 1:\n            image[slice_number] = slope * image[slice_number].astype(np.float64)\n            image[slice_number] = image[slice_number].astype(np.int16)\n            \n        image[slice_number] += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)"},{"cell_type":"markdown","metadata":{"_cell_guid":"55f00f1c-f310-cbb2-ec23-f6d15c16569e"},"source":"Turn these into vectors of HU for each scan:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb8d8b7c-6684-c240-c6e5-1a3cbadfae8a"},"outputs":[],"source":"def get_unique_counts(hu_pixels):\n    unique, counts = np.unique(hu_pixels, return_counts=True)\n    unique_counts = np.asarray((unique, counts)).T\n\n    return unique_counts\n\n\ndef get_unique_counts_vector(unique_counts):\n    neg_vec = np.zeros(1500, dtype=np.int32)\n    pos_vec = np.zeros(2001, dtype=np.int32)\n\n    for count in unique_counts:\n        if -1500 <= count[0] <= 2000:\n            if count[0] < 0:\n                neg_vec[(count[0]*-1)-1] = count[1]\n            else:\n                pos_vec[count[0]-1] = count[1]\n\n    neg_vec = neg_vec[::-1]\n    vec = np.append(neg_vec, pos_vec)\n\n    return vec"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"64b03078-42ce-2164-f0fe-133f29ffb1d2"},"outputs":[],"source":"def create_header(filename, test=False):\n    header = ['ID'] + range(-1500, 2001)\n    if not test:\n        header += ['CANCER']\n    with open(filename, 'wb') as f:\n        writer = csv.writer(f)\n        writer.writerows([header])\n\ndef process_training_data(filename, patients, labels):\n    with open(filename, 'a') as output:\n        for patient in patients:\n            try:\n                cancer = int(labels.loc[labels['id'] == patient]['cancer'])\n                slices = load_slices(INPUT_FOLDER + patient)\n                pixels = get_pixels_hu(slices)\n                unique_counts = get_unique_counts(pixels)\n                counts_vec = get_unique_counts_vector(unique_counts)\n\n                row = [patient] + list(counts_vec) + [cancer]\n                writer = csv.writer(output)\n                writer.writerows([row])\n            except:\n                print(patient)\n                \ndef process_test_data(filename, test_patients):\n    with open(filename, 'a') as output:\n        for ix, s in test_patients.iterrows():\n            try:\n                patient = s.get(0)\n                slices = load_slices(INPUT_FOLDER + patient)\n                pixels = get_pixels_hu(slices)\n                unique_counts = get_unique_counts(pixels)\n                counts_vec = get_unique_counts_vector(unique_counts)\n\n                row = [patient] + list(counts_vec)\n                writer = csv.writer(output)\n                writer.writerows([row])\n            except:\n                print(patient)\n                \n# test_patients = pd.read_csv('../input/sample_images/stage1_sample_submission.csv', index_col=None)\n\n# patients = os.listdir(INPUT_FOLDER)\n# labels = pd.read_csv('../input/stage1_labels.csv', index_col=0)\n# create_header('hu_counts.csv')\n# process_training_data('hu_counts.csv', patients, labels) "}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}