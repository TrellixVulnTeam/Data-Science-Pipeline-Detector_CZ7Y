{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, KFold, LeaveOneGroupOut\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nimport optuna\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-09T19:44:53.566838Z","iopub.execute_input":"2021-08-09T19:44:53.567301Z","iopub.status.idle":"2021-08-09T19:44:55.646316Z","shell.execute_reply.started":"2021-08-09T19:44:53.567199Z","shell.execute_reply":"2021-08-09T19:44:55.644462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tabular-playground-series-aug-2021/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tabular-playground-series-aug-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:44:55.648034Z","iopub.execute_input":"2021-08-09T19:44:55.648433Z","iopub.status.idle":"2021-08-09T19:45:06.819544Z","shell.execute_reply.started":"2021-08-09T19:44:55.64839Z","shell.execute_reply":"2021-08-09T19:45:06.818567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train shape:',train.shape)\nprint('test shape:',test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:06.821494Z","iopub.execute_input":"2021-08-09T19:45:06.82186Z","iopub.status.idle":"2021-08-09T19:45:06.828077Z","shell.execute_reply.started":"2021-08-09T19:45:06.821828Z","shell.execute_reply":"2021-08-09T19:45:06.827072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:06.830164Z","iopub.execute_input":"2021-08-09T19:45:06.830847Z","iopub.status.idle":"2021-08-09T19:45:06.886098Z","shell.execute_reply.started":"2021-08-09T19:45:06.830801Z","shell.execute_reply":"2021-08-09T19:45:06.884811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:06.888042Z","iopub.execute_input":"2021-08-09T19:45:06.88851Z","iopub.status.idle":"2021-08-09T19:45:06.925881Z","shell.execute_reply.started":"2021-08-09T19:45:06.888461Z","shell.execute_reply":"2021-08-09T19:45:06.924671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:06.927708Z","iopub.execute_input":"2021-08-09T19:45:06.928188Z","iopub.status.idle":"2021-08-09T19:45:06.972505Z","shell.execute_reply.started":"2021-08-09T19:45:06.928139Z","shell.execute_reply":"2021-08-09T19:45:06.971192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = train['loss']\ntrain.drop(['id'], axis=1, inplace=True)\ntest.drop(['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:06.974339Z","iopub.execute_input":"2021-08-09T19:45:06.974809Z","iopub.status.idle":"2021-08-09T19:45:07.072578Z","shell.execute_reply.started":"2021-08-09T19:45:06.974761Z","shell.execute_reply":"2021-08-09T19:45:07.071497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:07.075746Z","iopub.execute_input":"2021-08-09T19:45:07.076388Z","iopub.status.idle":"2021-08-09T19:45:07.140206Z","shell.execute_reply.started":"2021-08-09T19:45:07.076338Z","shell.execute_reply":"2021-08-09T19:45:07.139077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no missing value in the datasets.","metadata":{}},{"cell_type":"markdown","source":"# EDA\n","metadata":{}},{"cell_type":"markdown","source":"**Target (Loss) Distribution**\n* In total, there are 43 discrete losses.\n* The first 15 distributions account for the vast majority of the total.\n* The percentage share of losses decreases with the number of columns for all but columns 2 and 1.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16, 8))\n\nbars = ax.bar(train[\"loss\"].value_counts().sort_index().index,\n              train[\"loss\"].value_counts().sort_index().values,\n              color=[\"deepskyblue\" if i%2==0 else \"darkorange\" for i in range(9)],\n              edgecolor=\"black\")\nax.set_title(\"Loss Distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Amount of Values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Loss Value\", fontsize=14, labelpad=10)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in train[\"loss\"].value_counts().sort_index().values/(len(train)/100)],\n                 padding=5, fontsize=10, rotation=90)\nax.grid(axis=\"y\")\n\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:07.142327Z","iopub.execute_input":"2021-08-09T19:45:07.14276Z","iopub.status.idle":"2021-08-09T19:45:07.749842Z","shell.execute_reply.started":"2021-08-09T19:45:07.142716Z","shell.execute_reply":"2021-08-09T19:45:07.748699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_df = pd.DataFrame(train[\"loss\"].value_counts())\ntarget_df['ratio(%)'] = target_df/train[\"loss\"].value_counts().sum()*100\ntarget_df.sort_values('ratio(%)', ascending=False, inplace=True)\ntarget_df","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:07.751661Z","iopub.execute_input":"2021-08-09T19:45:07.752096Z","iopub.status.idle":"2021-08-09T19:45:07.79484Z","shell.execute_reply.started":"2021-08-09T19:45:07.752052Z","shell.execute_reply":"2021-08-09T19:45:07.793861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Statistics**\n* The size of this dataset is very diverse.","metadata":{}},{"cell_type":"code","source":"train.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:07.796475Z","iopub.execute_input":"2021-08-09T19:45:07.796874Z","iopub.status.idle":"2021-08-09T19:45:09.191609Z","shell.execute_reply.started":"2021-08-09T19:45:07.796828Z","shell.execute_reply":"2021-08-09T19:45:09.190691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Distribution**\n* The data set is very balanced.\n* This means that the distribution of training and testing is almost identical.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(10,10,figsize=(16, 16))\naxes = axes.flatten()\n\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data=train, x=f'f{idx}', \n                fill=True,  \n                ax=ax)\n    sns.kdeplot(data=test, x=f'f{idx}', \n                fill=True, \n                ax=ax)\n    ax.spines['left'].set_visible(False)\n    ax.set_title(f'f{idx}', loc='right', weight='bold', fontsize=10)\n\nfig.supxlabel('Average by class (by feature)', ha='center', fontweight='bold')\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:45:09.193092Z","iopub.execute_input":"2021-08-09T19:45:09.193459Z","iopub.status.idle":"2021-08-09T19:48:56.142608Z","shell.execute_reply.started":"2021-08-09T19:45:09.193419Z","shell.execute_reply":"2021-08-09T19:48:56.141605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Correlation**\n* The correlation of the features can be found in the heat map between ~0.03 and ~0.03.\n* This is quite small. So these features are weakly correlated.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12 , 12))\n\ncorr = train.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, ax=ax,\n        square=True, center=0, linewidth=1,\n        cmap=sns.diverging_palette(240, 10, as_cmap=True),\n        cbar_kws={\"shrink\": .82},    \n        mask=mask\n       ) \n\nax.set_title(\"Feature Correlation\", fontsize=15)     \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:48:56.143843Z","iopub.execute_input":"2021-08-09T19:48:56.144307Z","iopub.status.idle":"2021-08-09T19:49:04.927852Z","shell.execute_reply.started":"2021-08-09T19:48:56.144262Z","shell.execute_reply":"2021-08-09T19:49:04.926925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"x_scaler = StandardScaler()\nX = pd.DataFrame(x_scaler.fit_transform(train.drop([\"loss\"], axis=1)), columns=train.drop([\"loss\"], axis=1).columns)\nX_test = pd.DataFrame(x_scaler.transform(test), columns=test.columns)\n\ny = train[\"loss\"].copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T21:01:43.682093Z","iopub.execute_input":"2021-08-09T21:01:43.682484Z","iopub.status.idle":"2021-08-09T21:01:44.529707Z","shell.execute_reply.started":"2021-08-09T21:01:43.682453Z","shell.execute_reply":"2021-08-09T21:01:44.528722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:49:05.850197Z","iopub.execute_input":"2021-08-09T19:49:05.850605Z","iopub.status.idle":"2021-08-09T19:49:07.018454Z","shell.execute_reply.started":"2021-08-09T19:49:05.85056Z","shell.execute_reply":"2021-08-09T19:49:07.017281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:49:07.020216Z","iopub.execute_input":"2021-08-09T19:49:07.020676Z","iopub.status.idle":"2021-08-09T19:49:07.813581Z","shell.execute_reply.started":"2021-08-09T19:49:07.02063Z","shell.execute_reply":"2021-08-09T19:49:07.812319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameters optimization","metadata":{}},{"cell_type":"markdown","source":"Some ideas are from https://www.kaggle.com/maximkazantsev/tps-08-21-xgboost#Data-preparation","metadata":{}},{"cell_type":"code","source":"def train_model_optuna(trial):\n    \"\"\"\n    A function to train a model using different hyperparamerters combinations provided by Optuna. \n    Loss of validation data predictions is returned to estimate hyperparameters effectiveness.\n    \"\"\"\n    preds = 0\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y, test_size=0.4)\n        \n    #A set of hyperparameters to optimize by optuna\n    xgb_params = {\n                 \"n_estimators\": trial.suggest_categorical('n_estimators', [10000]),\n                 \"learning_rate\": trial.suggest_float('learning_rate', 0.01, 0.8),\n                 \"subsample\": trial.suggest_float('subsample', 0.5, 0.95),\n                 \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.5, 0.95),\n                 \"max_depth\": trial.suggest_int(\"max_depth\", 5, 16),\n                 \"booster\": trial.suggest_categorical('booster', [\"gbtree\"]),\n                 \"tree_method\": trial.suggest_categorical('tree_method', [\"gpu_hist\"]),\n                 \"reg_lambda\": trial.suggest_float('reg_lambda', 2, 100),\n                 \"reg_alpha\": trial.suggest_float('reg_alpha', 1, 50),\n                 \"random_state\": trial.suggest_categorical('random_state', [42]),\n                 \"n_jobs\": trial.suggest_categorical('n_jobs', [4]),\n                    }\n\n    # Model loading and training\n    model = XGBRegressor(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"rmse\",\n              early_stopping_rounds=100,\n              verbose=False)\n    \n    print(f\"Number of boosting rounds: {model.best_iteration}\")\n    oof = model.predict(X_valid)\n    oof[oof<0] = 0\n    \n    return np.sqrt(mean_squared_error(y_valid, oof))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:49:07.81544Z","iopub.execute_input":"2021-08-09T19:49:07.815901Z","iopub.status.idle":"2021-08-09T19:49:07.828721Z","shell.execute_reply.started":"2021-08-09T19:49:07.815852Z","shell.execute_reply":"2021-08-09T19:49:07.82748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data into train and valid folds using target bins for stratification\ntime_limit = 600\nstudy = optuna.create_study(direction='minimize',study_name='XGBRegressor')\nstudy.optimize(train_model_optuna,\n #                n_trials = 100,\n                timeout=time_limit)\n\n# Showing optimization results\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial parameters:', study.best_trial.params)\nprint('Best score:', study.best_value)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T20:32:27.845301Z","iopub.execute_input":"2021-08-09T20:32:27.845687Z","iopub.status.idle":"2021-08-09T20:42:42.511636Z","shell.execute_reply.started":"2021-08-09T20:32:27.845653Z","shell.execute_reply":"2021-08-09T20:42:42.510292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {'n_estimators': 10000, \n              'learning_rate': 0.010363073485236518, \n              'subsample': 0.8674277491335747, \n              'colsample_bytree': 0.8405044208369009, \n              'max_depth': 12, \n              'booster': 'gbtree', \n              'tree_method': 'gpu_hist', \n              'reg_lambda': 75.59819964912153, \n              'reg_alpha': 2.336931955219609, \n              'random_state': 42, \n              'n_jobs': 4}","metadata":{"execution":{"iopub.status.busy":"2021-08-09T20:46:57.789168Z","iopub.execute_input":"2021-08-09T20:46:57.789569Z","iopub.status.idle":"2021-08-09T20:46:57.798029Z","shell.execute_reply.started":"2021-08-09T20:46:57.789521Z","shell.execute_reply":"2021-08-09T20:46:57.797028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"%%time\nsplits = 10\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_rmse = 0\n\nfor num, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n    X_train, X_valid = X.loc[train_idx], X.loc[valid_idx]\n    y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n    \n    model = XGBRegressor(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"rmse\",\n              early_stopping_rounds=100,\n              verbose=False)\n    \n    preds += model.predict(X_test) / splits\n    model_fi += model.feature_importances_\n    oof_preds[valid_idx] = model.predict(X_valid)\n    oof_preds[oof_preds < 0] = 0\n#     fold_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(np.array(y_valid).reshape(-1,1)), y_scaler.inverse_transform(np.array(oof_preds[valid_idx]).reshape(-1,1))))\n    fold_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[valid_idx]))\n    print(f\"Fold {num} RMSE: {fold_rmse}\")\n#         print(f\"Trees: {model.tree_count_}\")\n    total_mean_rmse += fold_rmse / splits\nprint(f\"\\nOverall RMSE: {total_mean_rmse}\")    ","metadata":{"execution":{"iopub.status.busy":"2021-08-09T21:01:50.679308Z","iopub.execute_input":"2021-08-09T21:01:50.679629Z","iopub.status.idle":"2021-08-09T21:57:22.614594Z","shell.execute_reply.started":"2021-08-09T21:01:50.679599Z","shell.execute_reply":"2021-08-09T21:57:22.61358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(columns=[\"Feature\", \"Importance\"])\ndf[\"Feature\"] = X.columns\ndf[\"Importance\"] = model_fi / model_fi.sum()\ndf.sort_values(\"Importance\", axis=0, ascending=False, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T22:01:19.632352Z","iopub.execute_input":"2021-08-09T22:01:19.632693Z","iopub.status.idle":"2021-08-09T22:01:19.642043Z","shell.execute_reply.started":"2021-08-09T22:01:19.632659Z","shell.execute_reply":"2021-08-09T22:01:19.641235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(columns=[\"Feature\", \"Importance\"])\ndf[\"Feature\"] = X.columns\ndf[\"Importance\"] = model_fi / model_fi.sum()\ndf.sort_values(\"Importance\", axis=0, ascending=False, inplace=True)\n\nx = np.arange(0, len(df[\"Feature\"]))\nheight = 0.4\n\nfig, ax = plt.subplots(figsize=(16, 30))\nbars1 = ax.barh(x, df[\"Importance\"], height=height,\n                color=\"mediumorchid\", edgecolor=\"black\")\nax.set_title(\"Feature importances\", fontsize=30, pad=15)\nax.set_ylabel(\"Feature names\", fontsize=20, labelpad=15)\nax.set_xlabel(\"Feature importance\", fontsize=20, labelpad=15)\nax.set_yticks(x)\nax.set_yticklabels(df[\"Feature\"], fontsize=15)\nax.tick_params(axis=\"x\", labelsize=15)\nax.grid(axis=\"x\")\nax2 = ax.secondary_xaxis('top')\nax2.set_xlabel(\"Feature importance\", fontsize=20, labelpad=15)\nax2.tick_params(axis=\"x\", labelsize=15)\nplt.margins(0.04, 0.01)\nplt.gca().invert_yaxis()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T22:01:22.263474Z","iopub.execute_input":"2021-08-09T22:01:22.263787Z","iopub.status.idle":"2021-08-09T22:01:24.323637Z","shell.execute_reply.started":"2021-08-09T22:01:22.263756Z","shell.execute_reply":"2021-08-09T22:01:24.322585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"test1 = pd.read_csv(\"/kaggle/input/tabular-playground-series-aug-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-09T22:02:50.888903Z","iopub.execute_input":"2021-08-09T22:02:50.889277Z","iopub.status.idle":"2021-08-09T22:02:53.442316Z","shell.execute_reply.started":"2021-08-09T22:02:50.889244Z","shell.execute_reply":"2021-08-09T22:02:53.441318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pd.DataFrame()\npredictions[\"id\"] = test1[\"id\"]\npredictions[\"loss\"] = preds\npredictions.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T22:02:56.933669Z","iopub.execute_input":"2021-08-09T22:02:56.934016Z","iopub.status.idle":"2021-08-09T22:02:56.966608Z","shell.execute_reply.started":"2021-08-09T22:02:56.933974Z","shell.execute_reply":"2021-08-09T22:02:56.965354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.to_csv('xgbsubmission.csv', index=False, header=predictions.columns)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T22:03:06.632379Z","iopub.execute_input":"2021-08-09T22:03:06.632697Z","iopub.status.idle":"2021-08-09T22:03:07.016589Z","shell.execute_reply.started":"2021-08-09T22:03:06.632669Z","shell.execute_reply":"2021-08-09T22:03:07.015687Z"},"trusted":true},"execution_count":null,"outputs":[]}]}