{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-21T13:16:49.629142Z","iopub.execute_input":"2022-01-21T13:16:49.629516Z","iopub.status.idle":"2022-01-21T13:16:49.638967Z","shell.execute_reply.started":"2022-01-21T13:16:49.629477Z","shell.execute_reply":"2022-01-21T13:16:49.638025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('max_rows', 7)\ntrain_df = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2021/train.csv', index_col=0)\ntest_df = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2021/test.csv', index_col=0)\nsubmission_df = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2021/sample_submission.csv', index_col=0)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:16:49.640593Z","iopub.execute_input":"2022-01-21T13:16:49.641617Z","iopub.status.idle":"2022-01-21T13:16:56.918365Z","shell.execute_reply.started":"2022-01-21T13:16:49.641566Z","shell.execute_reply":"2022-01-21T13:16:56.917497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:16:56.920079Z","iopub.execute_input":"2022-01-21T13:16:56.920297Z","iopub.status.idle":"2022-01-21T13:16:58.094067Z","shell.execute_reply.started":"2022-01-21T13:16:56.920267Z","shell.execute_reply":"2022-01-21T13:16:58.093109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:16:58.095323Z","iopub.execute_input":"2022-01-21T13:16:58.09557Z","iopub.status.idle":"2022-01-21T13:16:58.113935Z","shell.execute_reply.started":"2022-01-21T13:16:58.09554Z","shell.execute_reply":"2022-01-21T13:16:58.112538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df\ny = X.pop('loss')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:16:58.116518Z","iopub.execute_input":"2022-01-21T13:16:58.117051Z","iopub.status.idle":"2022-01-21T13:16:58.123908Z","shell.execute_reply.started":"2022-01-21T13:16:58.117007Z","shell.execute_reply":"2022-01-21T13:16:58.122897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\ntotal_df = pd.concat([X, test_df])\n\nscaler = MinMaxScaler()\nscaled_features = pd.DataFrame(scaler.fit_transform(total_df))\n\nX_scaled = scaled_features[:X.shape[0]]\ntest_scaled = scaled_features[X.shape[0]:]\n\nX_scaled.shape, test_scaled.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:16:58.125345Z","iopub.execute_input":"2022-01-21T13:16:58.12587Z","iopub.status.idle":"2022-01-21T13:16:59.0834Z","shell.execute_reply.started":"2022-01-21T13:16:58.125806Z","shell.execute_reply":"2022-01-21T13:16:59.082593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:16:59.084673Z","iopub.execute_input":"2022-01-21T13:16:59.08535Z","iopub.status.idle":"2022-01-21T13:16:59.089268Z","shell.execute_reply.started":"2022-01-21T13:16:59.085307Z","shell.execute_reply":"2022-01-21T13:16:59.088251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from warnings import simplefilter\nsimplefilter = True\n\nmodel = keras.Sequential([\n    layers.Dense(128, activation='relu', input_shape=[100]),\n    layers.Dropout(0.3),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='relu')\n])\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.01,\n    decay_steps=10000,\n    decay_rate=0.9)\n\nmodel.compile(\n    optimizer=keras.optimizers.SGD(learning_rate=lr_schedule),\n    loss='mae',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:16:59.090593Z","iopub.execute_input":"2022-01-21T13:16:59.090815Z","iopub.status.idle":"2022-01-21T13:16:59.154768Z","shell.execute_reply.started":"2022-01-21T13:16:59.090788Z","shell.execute_reply":"2022-01-21T13:16:59.154109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y)\n\nearly_stop = EarlyStopping(min_delta=0.01, patience=5, restore_best_weights=True)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=2048,\n    epochs=100,\n    callbacks=[early_stop],\n    verbose=0\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:16:59.15571Z","iopub.execute_input":"2022-01-21T13:16:59.156499Z","iopub.status.idle":"2022-01-21T13:17:16.324388Z","shell.execute_reply.started":"2022-01-21T13:16:59.156465Z","shell.execute_reply":"2022-01-21T13:17:16.323738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:17:16.325498Z","iopub.execute_input":"2022-01-21T13:17:16.325926Z","iopub.status.idle":"2022-01-21T13:17:22.948092Z","shell.execute_reply.started":"2022-01-21T13:17:16.325894Z","shell.execute_reply":"2022-01-21T13:17:22.947177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(y_pred, columns=['loss'], index=test_scaled.index).rename_axis('id', axis='rows')\nprint(submission.head())\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:17:22.950668Z","iopub.execute_input":"2022-01-21T13:17:22.950932Z","iopub.status.idle":"2022-01-21T13:17:23.45521Z","shell.execute_reply.started":"2022-01-21T13:17:22.950895Z","shell.execute_reply":"2022-01-21T13:17:23.454286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}