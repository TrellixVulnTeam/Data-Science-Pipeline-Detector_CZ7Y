{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-01T22:30:35.95842Z","iopub.execute_input":"2021-09-01T22:30:35.958971Z","iopub.status.idle":"2021-09-01T22:30:35.974498Z","shell.execute_reply.started":"2021-09-01T22:30:35.958888Z","shell.execute_reply":"2021-09-01T22:30:35.973396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data processing\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\n# import pandas_profiling as pp\n# import lux\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n\n# Machine Learning\nimport optuna\nfrom optuna.samplers import TPESampler\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold, cross_val_score, StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error,roc_curve,auc,accuracy_score,confusion_matrix,f1_score\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Dense,Dropout,BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2021-09-01T22:30:35.975973Z","iopub.execute_input":"2021-09-01T22:30:35.976365Z","iopub.status.idle":"2021-09-01T22:30:43.581126Z","shell.execute_reply.started":"2021-09-01T22:30:35.976289Z","shell.execute_reply":"2021-09-01T22:30:43.580197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ninput_dir = Path('../input/tabular-playground-series-aug-2021/')\ntrain = pd.read_csv(input_dir / 'train.csv')\ntest = pd.read_csv(input_dir / 'test.csv')\nsubmission = pd.read_csv(input_dir / 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-01T22:30:43.585092Z","iopub.execute_input":"2021-09-01T22:30:43.585353Z","iopub.status.idle":"2021-09-01T22:30:53.497892Z","shell.execute_reply.started":"2021-09-01T22:30:43.585327Z","shell.execute_reply":"2021-09-01T22:30:53.497007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = [col for col in train.columns if col not in [\"id\", 'loss']]\nX=train[columns].values\ny=train['loss'].values\nX_test = test[columns].values","metadata":{"execution":{"iopub.status.busy":"2021-09-01T22:30:53.499673Z","iopub.execute_input":"2021-09-01T22:30:53.500053Z","iopub.status.idle":"2021-09-01T22:30:53.692099Z","shell.execute_reply.started":"2021-09-01T22:30:53.500016Z","shell.execute_reply":"2021-09-01T22:30:53.69126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"bins = len(np.unique(y, return_counts=False))\nfreq = train[\"loss\"].value_counts(normalize=True, sort=False)\ncum_sum = train[\"loss\"].value_counts(normalize=True, sort=False).cumsum()\n\nfig, ax = plt.subplots(2, 1, figsize=(10,10))\nsns.countplot(x=y, label='Train_loss', ax=ax[0])\nax[0].set_title(f'Distribution of the Loss, {bins} unique values', color = \"crimson\")\nax[0].set_xlabel('Loss value')\nax[0].legend()\n\n\n\nsns.ecdfplot(x=y, label='Train_loss', ax=ax[1])\nax[1].set_title(f'Cumulative sum per loss', color = \"crimson\")\nax[1].set_xlabel('Loss value')\nax[1].legend()\n\nfig.tight_layout(pad=3.0);","metadata":{"execution":{"iopub.status.busy":"2021-09-01T22:30:53.693439Z","iopub.execute_input":"2021-09-01T22:30:53.693786Z","iopub.status.idle":"2021-09-01T22:30:55.268636Z","shell.execute_reply.started":"2021-09-01T22:30:53.693735Z","shell.execute_reply":"2021-09-01T22:30:55.26769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfig, ax = plt.subplots(10, 10,figsize=(24,24))\nfor i,col in enumerate(columns):\n    sns.kdeplot(train[columns[i]], legend=False, shade=True, ax = ax[i%10][i//10])\n    ax[i%10][i//10].set_title(f\"{train.columns[i]}\", fontsize=10, weight='bold',)\n    ax[i%10][i//10].set_xlabel('')\n    ax[i%10][i//10].set_ylabel('')\n    ax[i%10][i//10].set_yticks([])\n#     plt.subplots_adjust(hspace=0.2)\n\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T22:30:55.270057Z","iopub.execute_input":"2021-09-01T22:30:55.270411Z","iopub.status.idle":"2021-09-01T22:32:55.627629Z","shell.execute_reply.started":"2021-09-01T22:30:55.270372Z","shell.execute_reply":"2021-09-01T22:32:55.626857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGB/LBG/CATBOOST - HYPERPARAMETERS TUNING","metadata":{}},{"cell_type":"code","source":"%%time\ndef cat_estimation(trial,data=X,target=y):\n    x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4,random_state=1)\n    params = {'iterations':trial.suggest_int(\"iterations\", 1000, 4000),\n              'od_wait':trial.suggest_int('od_wait', 300, 500),\n              'task_type':'GPU',\n              'eval_metric':'RMSE',\n              'learning_rate' : trial.suggest_uniform('learning_rate', 0.008,0.02),\n              'grow_policy': trial.suggest_categorical('grow_policy', ['Depthwise','SymmetricTree']),\n              'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.2 , 0.3),\n              'subsample': trial.suggest_uniform('subsample',0.5,1.0),\n              'random_strength': trial.suggest_uniform('random_strength',10,50),\n              'depth': trial.suggest_int('depth',3,15),\n              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n              'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',10,40),\n              'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bernoulli', 'Poisson']),\n               }\n    \n    \n    model = CatBoostRegressor(**params, random_state=1)\n    model.fit(x_train, y_train,eval_set=[(x_valid,y_valid)], verbose=False)\n    \n    preds = model.predict(x_valid)\n    rmse = mean_squared_error(y_valid, preds,squared=False)\n    \n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-09-01T22:32:55.628695Z","iopub.execute_input":"2021-09-01T22:32:55.62901Z","iopub.status.idle":"2021-09-01T22:32:55.638999Z","shell.execute_reply.started":"2021-09-01T22:32:55.628978Z","shell.execute_reply":"2021-09-01T22:32:55.63808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_time = 1 * 30 * 60\nstudy_cat = optuna.create_study(direction='minimize', sampler=TPESampler(), study_name='CatRegressor')\nstudy_cat.optimize(cat_estimation, timeout=train_time)\n\nprint('Number of finished trials: ', len(study_cat.trials))\nprint('Best trial:')\ntrial_cat = study_cat.best_trial\n\nprint('\\tValue: {}'.format(trial_cat.value))\nprint('\\tParams: ')\nfor key, value in trial_cat.params.items():\n    print('\\t\\t{}: {}'.format(key, value))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T22:32:55.641939Z","iopub.execute_input":"2021-09-01T22:32:55.642535Z","iopub.status.idle":"2021-09-01T23:08:27.757599Z","shell.execute_reply.started":"2021-09-01T22:32:55.642497Z","shell.execute_reply":"2021-09-01T23:08:27.75674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of finished trials:  10\nBest trial:\n\tValue: 7.843146985719494\n\tParams: \n\t\titerations: 3084\n\t\tod_wait: 332\n\t\tlearning_rate: 0.019584817897930977\n\t\tgrow_policy: Depthwise\n\t\treg_lambda: 0.2587005604240873\n\t\tsubsample: 0.6264800857693638\n\t\trandom_strength: 46.10328452158566\n\t\tdepth: 3\n\t\tmin_data_in_leaf: 27\n\t\tleaf_estimation_iterations: 28\n\t\tbootstrap_type: Poisson","metadata":{}},{"cell_type":"code","source":"#Now let's get a lightgbm\ndef lgb_estimation(trial,data=X,target=y):\n    x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4,random_state=1)\n    params = {\n        'reg_alpha' : trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'reg_lambda' : trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'num_leaves' : trial.suggest_int('num_leaves' , 40 , 70),\n        'learning_rate' : trial.suggest_uniform('learning_rate' , 0.008 , 0.04),\n        'max_depth' : trial.suggest_int('max_depth', 3 , 15),\n        'n_estimators' : trial.suggest_int('n_estimators', 400 , 4000),\n        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-4, 100),\n        'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.05), \n        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.15, 0.9, 0.05),\n        'min_child_samples' : trial.suggest_int('min_child_samples', 20, 65),\n        'metric' : 'rmse',\n        'subsample_freq' : 1,\n        'device_type' : 'gpu',}\n\n    model = LGBMRegressor(**params, random_state=1, n_jobs=-1)\n    model.fit(x_train, y_train,eval_set=[(x_valid,y_valid)], verbose=False)\n    \n    preds = model.predict(x_valid)\n    rmse = mean_squared_error(y_valid, preds,squared=False)\n    \n    return rmse\n\n#https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html","metadata":{"execution":{"iopub.status.busy":"2021-09-01T23:08:27.759657Z","iopub.execute_input":"2021-09-01T23:08:27.760046Z","iopub.status.idle":"2021-09-01T23:08:27.770357Z","shell.execute_reply.started":"2021-09-01T23:08:27.760006Z","shell.execute_reply":"2021-09-01T23:08:27.769322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_time = 1 * 30 * 60\nstudy_lgb = optuna.create_study(direction='minimize', sampler=TPESampler(), study_name='LGBRegressor')\nstudy_lgb.optimize(lgb_estimation, timeout=train_time)\n\nprint('Number of finished trials: ', len(study_lgb.trials))\nprint('Best trial:')\ntrial_lgb = study_lgb.best_trial\n\nprint('\\tValue: {}'.format(trial_lgb.value))\nprint('\\tParams: ')\nfor key, value in trial_lgb.params.items():\n    print('\\t\\t{}: {}'.format(key, value))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T23:08:27.771799Z","iopub.execute_input":"2021-09-01T23:08:27.772156Z","iopub.status.idle":"2021-09-01T23:38:48.622737Z","shell.execute_reply.started":"2021-09-01T23:08:27.77212Z","shell.execute_reply":"2021-09-01T23:38:48.621569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of finished trials:  28\nBest trial:\n\tValue: 7.833826248634097\n\tParams: \n\t\talpha: 0.002844219172632396\n\t\tlambda: 0.04988448769361392\n\t\tnum_leaves: 58\n\t\tlearning_rate: 0.010295669290960142\n\t\tmax_depth: 8\n\t\tn_estimators: 3663\n\t\tmin_child_weight: 2.185521963310407\n\t\tsubsample: 0.75\n\t\tcolsample_bytree: 0.35\n\t\tmin_child_samples: 57","metadata":{}},{"cell_type":"code","source":"def xgb_estimation(trial,data=X,target=y):\n    \n    x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4,random_state=1)\n    param = {\n        'tweedie_variance_power': trial.suggest_discrete_uniform('tweedie_variance_power', 1.0, 2.0, 0.1),\n        'lambda': trial.suggest_loguniform('lambda', 1, 100),\n        'alpha': trial.suggest_loguniform('alpha', 1, 100),\n        'gamma': trial.suggest_loguniform('gamma', 1e-3, 1e4),\n        'n_estimators': trial.suggest_int('n_estimators', 400, 4000, 400),\n        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.2, 0.9, 0.05),\n        'colsample_bylevel': trial.suggest_discrete_uniform('colsample_bylevel', 0.2, 0.9, 0.05),\n        'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.05),\n        'eta': trial.suggest_float('eta', 0.007,0.020),\n        'n_estimators': trial.suggest_int(\"n_estimators\",400,4000,400),\n        'max_depth': trial.suggest_int('max_depth', 3,15,1),\n        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1, 1000),\n    }\n    model = xgb.XGBModel(\n        objective='reg:tweedie',\n        tree_method='gpu_hist',   #which tree to chose: https://xgboost.readthedocs.io/en/latest/treemethod.html\n        predictor='gpu_predictor',\n        n_jobs=-1,\n        **param\n    ) \n    \n    model.fit(x_train, y_train,\n            eval_set=[(x_valid, y_valid)], eval_metric='rmse',\n            verbose=False)\n    \n    preds = model.predict(x_valid)\n    \n    rmse = mean_squared_error(y_valid, preds,squared=False)\n    \n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-09-01T23:38:48.625485Z","iopub.execute_input":"2021-09-01T23:38:48.62574Z","iopub.status.idle":"2021-09-01T23:38:48.637445Z","shell.execute_reply.started":"2021-09-01T23:38:48.625714Z","shell.execute_reply":"2021-09-01T23:38:48.636562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_time = 1 * 30 * 60\nstudy_xgb = optuna.create_study(direction='minimize', sampler=TPESampler(), study_name='XGBRegressor')\nstudy_xgb.optimize(xgb_estimation, timeout=train_time)\n\nprint('Number of finished trials: ', len(study_xgb.trials))\nprint('Best trial:')\ntrial_xgb = study_xgb.best_trial\n\nprint('\\tValue: {}'.format(trial_xgb.value))\nprint('\\tParams: ')\nfor key, value in trial_xgb.params.items():\n    print('\\t\\t{}: {}'.format(key, value))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T23:38:48.640596Z","iopub.execute_input":"2021-09-01T23:38:48.64088Z","iopub.status.idle":"2021-09-02T00:08:55.261141Z","shell.execute_reply.started":"2021-09-01T23:38:48.640855Z","shell.execute_reply":"2021-09-02T00:08:55.260303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of finished trials:  47\nBest trial:\n\tValue: 7.835773902876162\n\tParams: \n\t\ttweedie_variance_power: 1.0\n\t\tlambda: 2.1531451037845706\n\t\talpha: 75.55781034374724\n\t\tgamma: 0.003783218732688592\n\t\tn_estimators: 3600\n\t\tcolsample_bytree: 0.8500000000000001\n\t\tcolsample_bylevel: 0.25\n\t\tsubsample: 0.8500000000000001\n\t\teta: 0.008050760753145963\n\t\tmax_depth: 7\n\t\tmin_child_weight: 27.35935907624855","metadata":{}},{"cell_type":"code","source":"# cat_params = {'iterations': 2352,\n#  'od_wait': 423,\n#  'learning_rate': 0.016226794416482,\n#  'grow_policy': 'Depthwise',\n#  'reg_lambda': 0.22443418652185604,\n#  'subsample': 0.6489507065409703,\n#  'random_strength': 33.31677512363275,\n#  'depth': 5,\n#  'min_data_in_leaf': 28,\n#  'leaf_estimation_iterations': 23,\n#  'bootstrap_type': 'Bernoulli',}\n\n# lgb_params = {'reg_alpha': 0.5127042132407919, 'reg_lambda': 5.357028975534249, \n#           'num_leaves': 50, 'learning_rate': 0.011363404060130413, \n#           'max_depth': 10, 'n_estimators': 3279, \n#           'min_child_weight': 0.07984529371109039,\n#           'subsample': 0.65, \n#           'colsample_bytree': 0.35, \n#           'min_child_samples': 43, 'subsample_freq' : 1}\n\n# xgb_params = {'tweedie_variance_power': 1.1,\n#  'max_depth': 6,\n#  'n_estimators': 3200,\n#  'eta': 0.011245712330378816,\n#  'subsample': 0.9,\n#  'min_child_weight': 318.8784492865065,\n#  'colsample_bytree': 0.45,\n#  'colsample_bylevel': 0.30000000000000004,\n#  'subsample': 0.9,\n#  'lambda': 30.619480207080088,\n#  'alpha': 42.00321964378956,\n#  'gamma': 0.24759763410326613,\n#  'tree_method':'gpu_hist'\n#              }    ","metadata":{"execution":{"iopub.status.busy":"2021-09-02T00:08:55.262412Z","iopub.execute_input":"2021-09-02T00:08:55.26273Z","iopub.status.idle":"2021-09-02T00:08:55.266625Z","shell.execute_reply.started":"2021-09-02T00:08:55.262696Z","shell.execute_reply":"2021-09-02T00:08:55.265848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGB/LBG/CATBOOST - VALIDATION AND TEST SET","metadata":{}},{"cell_type":"code","source":"cat_params = trial_cat.params\nlgb_params = trial_lgb.params\nxgb_params = trial_xgb.params\n\nxgb_params['objective'] = 'reg:tweedie'\nxgb_params['tree_method'] = 'gpu_hist'\nxgb_params['predictor'] = 'gpu_predictor'\n        \nn_splits = 10\n\ncat_preds = np.zeros((X_test.shape[0],))\noof_cat_preds = np.zeros((X.shape[0],))\nkf_cat_rmse = []\n\nlgb_preds = np.zeros((X_test.shape[0],))\noof_lgb_preds = np.zeros((X.shape[0],))\nkf_lgb_rmse = []\n\nxgb_preds = np.zeros((X_test.shape[0],))\noof_xgb_preds = np.zeros((X.shape[0],))\nkf_xgb_rmse = []\n\n\nfor fold, (train_idx, valid_idx) in enumerate(KFold(n_splits=n_splits, shuffle=True).split(X, y)):\n    # Fetch the train-validation indices.\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_valid, y_valid = X[valid_idx], y[valid_idx]\n    \n    # Create and fit the models using optuna hyperparameters\n    model_cat = CatBoostRegressor(**cat_params, task_type='GPU') #https://catboost.ai/docs/concepts/python-reference_catboostregressor.html\n    model_cat.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n    \n    model_lgb = LGBMRegressor(**lgb_params, device='gpu') #https://catboost.ai/docs/concepts/python-reference_catboostregressor.html\n    model_lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False,early_stopping_rounds=200,)\n    \n    model_xgb = xgb.XGBModel(**xgb_params)\n    model_xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric='rmse', verbose=False)\n    \n    # Validation predictions.\n    cat_pred = model_cat.predict(X_valid)\n    cat_rmse = mean_squared_error(y_valid, cat_pred,squared=False)\n    kf_cat_rmse.append(cat_rmse)\n    oof_cat_preds[valid_idx] += model_cat.predict(X_valid) / n_splits\n    \n    lgb_pred = model_lgb.predict(X_valid)\n    lgb_rmse = mean_squared_error(y_valid, lgb_pred,squared=False)\n    kf_lgb_rmse.append(lgb_rmse)\n    oof_lgb_preds[valid_idx] += model_lgb.predict(X_valid) / n_splits\n    \n    xgb_pred = model_xgb.predict(X_valid)\n    xgb_rmse = mean_squared_error(y_valid, xgb_pred,squared=False)\n    kf_xgb_rmse.append(xgb_rmse)\n    oof_xgb_preds[valid_idx] += model_xgb.predict(X_valid) / n_splits\n\n    #Pred on test set \n    cat_preds += model_cat.predict(X_test) / n_splits\n    lgb_preds += model_lgb.predict(X_test) / n_splits\n    xgb_preds += model_xgb.predict(X_test) / n_splits\n\nfor i in range(0,10):\n    print(f'Fold {i+1}/{n_splits} CATBOOST RMSE: {kf_cat_rmse[i]:.4f}')\n\nfor i in range(0,10):\n    print(f'Fold {i+1}/{n_splits} LGBM RMSE: {kf_lgb_rmse[i]:.4f}')\n    \nfor i in range(0,10):\n    print(f'Fold {i+1}/{n_splits} XGB RMSE: {kf_xgb_rmse[i]:.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T00:08:55.267941Z","iopub.execute_input":"2021-09-02T00:08:55.268443Z","iopub.status.idle":"2021-09-02T00:46:32.008651Z","shell.execute_reply.started":"2021-09-02T00:08:55.268409Z","shell.execute_reply":"2021-09-02T00:46:32.007852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upper = 11\nmin_value = 1e6\nmae_plot = []\nfor i in range(0,11):\n    for j in range(0,upper-i):\n        pred_ensemble = ((0.1*i) * oof_lgb_preds) + ((0.1*j) * oof_cat_preds) +(0.1*(upper - 1 - i - j)) *  oof_xgb_preds\n        mae = mean_squared_error(y, pred_ensemble,squared=False)\n        if mae < min_value:\n            mae_plot.append(mae)\n            min_value = mae\n            weights = [i, j,upper - 1 - i - j ]\n        else:\n            mae_plot.append(mae)\n#             print(f'lgb_coeff : {i} cat_coeff: {j} lgb_coeff: {upper - 1 - i - j}')\nprint(f'Min_RMSE : {min_value} Best_Weights: {weights}')\nplt.plot(mae_plot)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T00:46:32.010124Z","iopub.execute_input":"2021-09-02T00:46:32.010459Z","iopub.status.idle":"2021-09-02T00:46:32.269857Z","shell.execute_reply.started":"2021-09-02T00:46:32.010422Z","shell.execute_reply":"2021-09-02T00:46:32.269099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BASIC NEURAL NETWORK \n**(added at last minute to check how it worked with optuna)**","metadata":{}},{"cell_type":"code","source":"#We will now build a simple Neural Network using Keras\ndef nn_model(h1, h2, h3, lr, dr):\n    #initiating the model\n    model = Sequential()\n    initializer = tf.keras.initializers.HeUniform()\n    model.add(Dense(input_dim=X.shape[1], units=h1, kernel_initializer=initializer , activation=\"elu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(dr))\n    model.add(Dense(units=h2, activation=\"elu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(dr))\n    model.add(Dense(units=h3, activation=\"elu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(dr))\n    model.add(Dense(units=1, activation='linear'))\n    \n    #compile the model\n    model.compile(optimizer = tf.optimizers.Adam(learning_rate = lr), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-02T00:46:32.271161Z","iopub.execute_input":"2021-09-02T00:46:32.271483Z","iopub.status.idle":"2021-09-02T00:46:32.279322Z","shell.execute_reply.started":"2021-09-02T00:46:32.271447Z","shell.execute_reply":"2021-09-02T00:46:32.278296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef nn_estimation(trial,data=X,target=y):\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4,random_state=1)\n    SS = StandardScaler().fit(X_train)\n    X_train = SS.transform(X_train)\n    X_valid = SS.transform(X_valid)\n    params = {'h1': trial.suggest_int('h1' ,3 , 100),\n              'h2': trial.suggest_int('h2' ,3 , 100),\n              'h3': trial.suggest_int('h3' ,3 , 100),\n              'lr' : trial.suggest_uniform('lr' , 0.002 , 0.1),\n              'dr' : trial.suggest_uniform('dr' ,0.01 , 0.2),\n               }\n        \n    \n    model = nn_model(**params)\n    model.fit(X_train, y_train, validation_data = (X_valid, y_valid), epochs = 30, batch_size = 3000, verbose = 0)\n    \n    model_pred = model.predict(X_valid)\n    rmse = model.evaluate(X_valid, y_valid, verbose=0)\n    \n    return rmse[1]","metadata":{"execution":{"iopub.status.busy":"2021-09-02T00:46:32.280701Z","iopub.execute_input":"2021-09-02T00:46:32.281068Z","iopub.status.idle":"2021-09-02T00:46:32.291647Z","shell.execute_reply.started":"2021-09-02T00:46:32.28103Z","shell.execute_reply":"2021-09-02T00:46:32.290553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_time = 1 * 30 * 60\nstudy_nn = optuna.create_study(direction='minimize', sampler=TPESampler(), study_name='DeepNN')\nstudy_nn.optimize(nn_estimation, timeout=train_time)\n\nprint('Number of finished trials: ', len(study_nn.trials))\nprint('Best trial:')\ntrial_nn = study_nn.best_trial\n\nprint('\\tValue: {}'.format(trial_nn.value))\nprint('\\tParams: ')\nfor key, value in trial_nn.params.items():\n    print('\\t\\t{}: {}'.format(key, value))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T00:46:32.292959Z","iopub.execute_input":"2021-09-02T00:46:32.293311Z","iopub.status.idle":"2021-09-02T01:16:41.799008Z","shell.execute_reply.started":"2021-09-02T00:46:32.293275Z","shell.execute_reply":"2021-09-02T01:16:41.797858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of finished trials:  105\nBest trial:\n\tValue: 7.8848958015441895\n\tParams: \n\t\th1: 9\n\t\th2: 50\n\t\th3: 75\n\t\tlr: 0.005007293309139238\n\t\tdr: 0.19501276039972268","metadata":{}},{"cell_type":"code","source":"n_splits = 10\n\nnn_params = trial_nn.params\n\nnn_preds = np.zeros((X_test.shape[0],))\noof_nn_preds = np.zeros((X.shape[0],))\nkf_nn_rmse = []\n\nSS = StandardScaler().fit(X)\nX_scaled = SS.transform(X)\nX_test_scaled = SS.transform(X_test)\n\nfor fold, (train_idx, valid_idx) in enumerate(KFold(n_splits=n_splits, shuffle=True).split(X_scaled, y)):\n    # Fetch the train-validation indices.\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_valid, y_valid = X[valid_idx], y[valid_idx]\n    \n    X_train = SS.transform(X_train)\n    X_valid = SS.transform(X_valid)\n    \n    # Create and fit the model using optuna hyperparameters\n    model_nn = nn_model(**nn_params)\n    model_nn.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=30, batch_size=3000, verbose=0)\n    \n    # Validation predictions.\n    nn_rmse = model_nn.evaluate(X_valid, y_valid, verbose=0)\n    kf_nn_rmse.append(nn_rmse[1])\n    oof_nn_preds[valid_idx] += model_nn.predict(X_valid).reshape(-1,) / n_splits\n\n    #Pred on test set \n    nn_preds += model_nn.predict(X_test_scaled).reshape(-1,) / n_splits\n\n\nfor i in range(0,10):\n    print(f'Fold {i+1}/{n_splits} NN RMSE: {kf_nn_rmse[i]:.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T01:16:41.800428Z","iopub.execute_input":"2021-09-02T01:16:41.800849Z","iopub.status.idle":"2021-09-02T01:19:17.749Z","shell.execute_reply.started":"2021-09-02T01:16:41.800806Z","shell.execute_reply":"2021-09-02T01:19:17.748099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_value = 1e6\nmae_plot_2 = []\nfor i in range(0,11):\n    pred_ensemble = (0.1 * i) * (weights[0] * oof_lgb_preds + weights[1] * oof_cat_preds + weights[2] * oof_xgb_preds) + (1 - (0.1 * i)) * oof_nn_preds\n    mae = mean_squared_error(y, pred_ensemble,squared=False)\n    if mae < min_value:\n        mae_plot_2.append(mae)\n        min_value = mae\n        weights_2 = [0.1*i, 1-(0.1*i)]\n    else:\n        mae_plot_2.append(mae)\n#             print(f'lgb_coeff : {i} cat_coeff: {j} lgb_coeff: {upper - 1 - i - j}')\nprint(f'Min_RMSE : {min_value} Best_Weights: {weights_2}')\nplt.plot(mae_plot_2)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T01:19:17.750412Z","iopub.execute_input":"2021-09-02T01:19:17.75099Z","iopub.status.idle":"2021-09-02T01:19:17.902394Z","shell.execute_reply.started":"2021-09-02T01:19:17.750951Z","shell.execute_reply":"2021-09-02T01:19:17.901391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION","metadata":{}},{"cell_type":"code","source":"submission[\"loss\"] =  (weights_2[0] * (weights[0] * lgb_preds + weights[1] * cat_preds + weights[2] * xgb_preds))/10 + (weights_2[1] * nn_preds)\nsubmission.to_csv('submission_final.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T01:19:17.903867Z","iopub.execute_input":"2021-09-02T01:19:17.904226Z","iopub.status.idle":"2021-09-02T01:19:18.368674Z","shell.execute_reply.started":"2021-09-02T01:19:17.904187Z","shell.execute_reply":"2021-09-02T01:19:18.36784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"loss\"] =  (0.95 * (0.2 * lgb_preds + 0.6 * cat_preds + 0.2 * xgb_preds)) + (0.05 * nn_preds)\nsubmission.to_csv('submission_average_model.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T01:19:18.369926Z","iopub.execute_input":"2021-09-02T01:19:18.370258Z","iopub.status.idle":"2021-09-02T01:19:18.826957Z","shell.execute_reply.started":"2021-09-02T01:19:18.370225Z","shell.execute_reply":"2021-09-02T01:19:18.826107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}