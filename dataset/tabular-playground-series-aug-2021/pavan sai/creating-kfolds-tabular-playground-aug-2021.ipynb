{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-17T04:18:52.149193Z","iopub.execute_input":"2021-08-17T04:18:52.149692Z","iopub.status.idle":"2021-08-17T04:18:52.162973Z","shell.execute_reply.started":"2021-08-17T04:18:52.149653Z","shell.execute_reply":"2021-08-17T04:18:52.161337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we need to import model_selection from sklearn to create kfolds. so lets do that first","metadata":{}},{"cell_type":"code","source":"from sklearn import model_selection\ntrain = pd.read_csv(\"/kaggle/input/tabular-playground-series-aug-2021/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-17T04:18:54.845242Z","iopub.execute_input":"2021-08-17T04:18:54.845899Z","iopub.status.idle":"2021-08-17T04:19:00.011847Z","shell.execute_reply.started":"2021-08-17T04:18:54.845843Z","shell.execute_reply":"2021-08-17T04:19:00.01102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we have also imported our data. see the first few rows to see how our data lookslike","metadata":{}},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T04:19:03.277326Z","iopub.execute_input":"2021-08-17T04:19:03.278083Z","iopub.status.idle":"2021-08-17T04:19:03.317789Z","shell.execute_reply.started":"2021-08-17T04:19:03.278017Z","shell.execute_reply":"2021-08-17T04:19:03.316418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can see 100 features in our data. lets view the distribution of loss variable which is our target variable.","metadata":{}},{"cell_type":"code","source":"train.loss.hist()\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T04:19:06.878168Z","iopub.execute_input":"2021-08-17T04:19:06.878567Z","iopub.status.idle":"2021-08-17T04:19:07.07385Z","shell.execute_reply.started":"2021-08-17T04:19:06.878534Z","shell.execute_reply":"2021-08-17T04:19:07.072875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"creating Kfolds for cross validation","metadata":{}},{"cell_type":"code","source":"train['kfold']=-1\nkf = model_selection.KFold(n_splits=5,shuffle=True, random_state=8)\nfor fold,(train_indicies, valid_indicies) in enumerate(kf.split(X=train)):\n    train.loc[valid_indicies,'kfold']=fold\n    print(fold, train_indicies,valid_indicies)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T04:23:59.065452Z","iopub.execute_input":"2021-08-17T04:23:59.065974Z","iopub.status.idle":"2021-08-17T04:23:59.140025Z","shell.execute_reply.started":"2021-08-17T04:23:59.065934Z","shell.execute_reply":"2021-08-17T04:23:59.138786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"here we have added a column called 'kfold' to our train dataframe with default value -1.\nso that we can assign each row to the validation fold value (0,1,2,3,4).","metadata":{}},{"cell_type":"code","source":"print(train.kfold.value_counts())\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T04:24:02.532319Z","iopub.execute_input":"2021-08-17T04:24:02.532761Z","iopub.status.idle":"2021-08-17T04:24:02.574388Z","shell.execute_reply.started":"2021-08-17T04:24:02.532725Z","shell.execute_reply":"2021-08-17T04:24:02.572983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train.kfold==4].loss.hist()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T03:51:25.810291Z","iopub.execute_input":"2021-08-17T03:51:25.810831Z","iopub.status.idle":"2021-08-17T03:51:26.033001Z","shell.execute_reply.started":"2021-08-17T03:51:25.81076Z","shell.execute_reply":"2021-08-17T03:51:26.03215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"(run above codecell)here we can check that the distribution of loss variable has not changed much. so we are good to go.","metadata":{}},{"cell_type":"code","source":"train.to_csv('train_folds.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T04:02:37.013955Z","iopub.execute_input":"2021-08-17T04:02:37.014343Z","iopub.status.idle":"2021-08-17T04:03:08.591953Z","shell.execute_reply.started":"2021-08-17T04:02:37.014302Z","shell.execute_reply":"2021-08-17T04:03:08.591056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"finally save the new dataframe with kfold column added to a new csv file.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}