{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabular AutoML","metadata":{}},{"cell_type":"markdown","source":"# Viewing the data sources","metadata":{}},{"cell_type":"code","source":"from pathlib import Path","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:01:01.66213Z","iopub.execute_input":"2021-09-01T08:01:01.662742Z","iopub.status.idle":"2021-09-01T08:01:01.675235Z","shell.execute_reply.started":"2021-09-01T08:01:01.66262Z","shell.execute_reply":"2021-09-01T08:01:01.674364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# constants\nDATA_DIR = Path('/kaggle/input')\nRANDOM_STATE = 24\n\n# list all file paths in DATA_DIR and its subdirectories\nfor filepath in DATA_DIR.rglob('*'):\n     print(filepath)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:01:01.676808Z","iopub.execute_input":"2021-09-01T08:01:01.677497Z","iopub.status.idle":"2021-09-01T08:01:01.707905Z","shell.execute_reply.started":"2021-09-01T08:01:01.677431Z","shell.execute_reply":"2021-09-01T08:01:01.706616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"!pip install tabular-automl==0.2.0a1","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:01:01.712929Z","iopub.execute_input":"2021-09-01T08:01:01.713312Z","iopub.status.idle":"2021-09-01T08:02:03.03105Z","shell.execute_reply.started":"2021-09-01T08:01:01.713277Z","shell.execute_reply":"2021-09-01T08:02:03.029805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\n\nfrom tabular_automl import TabularAutoML, TabularData","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:02:03.033249Z","iopub.execute_input":"2021-09-01T08:02:03.034027Z","iopub.status.idle":"2021-09-01T08:02:03.04486Z","shell.execute_reply.started":"2021-09-01T08:02:03.033969Z","shell.execute_reply":"2021-09-01T08:02:03.043978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# utility functions\ndef get_file_paths(source_dir, file_patterns=None):\n    filepaths = []\n    if file_patterns is None:\n        # remove folders\n        paths = list(source_dir.rglob('*'))\n        for filepath in paths:\n            if filepath.is_file():\n                filepaths.append(filepath)\n    else:\n        # get files matching pattern\n        for pattern in file_patterns:\n            matches = list(source_dir.rglob(f\"*{pattern}*\"))\n            filepaths.extend(matches)\n    return sorted(filepaths)\n\n\ndef get_data(data_path, subsets=[\"train\", \"test\"], index_col=\"id\"):\n    test_file_path, train_file_path = get_file_paths(\n        data_path, file_patterns=[\"train\", \"test\"]\n    )\n    train_data = TabularData(train_file_path, index_col=index_col)\n    test_data = TabularData(test_file_path, index_col=index_col)\n    if test_data is None:\n        return train_data.data, None\n    return train_data.data, test_data.data\n\ndef create_pipeline(train_data, test_data, target_col=\"target\", task_type=\"regression\"):\n    pipeline = TabularAutoML(\n        train_data, test_data=test_data, target_col=target_col, task_type=task_type\n    )\n    return pipeline\n\ndef train_model(pipeline, config):\n    best_model = pipeline.get_best_model(config)\n    # tuned_model = pipeline.tune_model(estimator=best_model)\n    # final_model = pipeline.finalize_model(estimator=tuned_model)\n    model = best_model\n    return model\n\ndef get_predictions(model, test_data=None, predict_proba=False):\n    if task_type == \"classification\":\n        predictions = pipeline.predict_model(\n            estimator=model, data=test_data, raw_score=predict_proba\n        )\n    else:\n        predictions = pipeline.predict_model(estimator=model, data=test_data)\n    display(predictions.head())\n    return predictions\n\ndef create_submission(model, test_data, label_col=\"Label\", multiclass=False):\n    predictions = get_predictions(\n        model, test_data=test_data, predict_proba=multiclass\n    )\n    if multiclass:\n        label_cols = [col for col in predictions.columns if \"Score\" in col]\n        submission_cols = [col.replace(\"Score_\", \"\") for col in label_cols]\n        col_mapper = dict(zip(label_cols, submission_cols))\n        submission = predictions[label_cols].rename(columns=col_mapper).reset_index()\n    else:\n        submission = predictions[label_col].rename(target_col).reset_index()\n\n    display(submission.head())\n    submission.to_csv(f\"{month}_submission.csv\")    ","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:02:03.047489Z","iopub.execute_input":"2021-09-01T08:02:03.048257Z","iopub.status.idle":"2021-09-01T08:02:03.176053Z","shell.execute_reply.started":"2021-09-01T08:02:03.048209Z","shell.execute_reply":"2021-09-01T08:02:03.174895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# general configuration\nconfig = {\n    \"sampling\": dict(sample_frac=round(1/10, 2)),\n    \"setup\": dict(silent=True),\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:02:03.177831Z","iopub.execute_input":"2021-09-01T08:02:03.17817Z","iopub.status.idle":"2021-09-01T08:02:03.199159Z","shell.execute_reply.started":"2021-09-01T08:02:03.178125Z","shell.execute_reply":"2021-09-01T08:02:03.197807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Jan 2021 TPS\nmonth = \"jan\"\nindex_col = \"id\"\ntarget_col = \"target\"\ntask_type = \"regression\"\n\ndata_path = get_file_paths(DATA_DIR, file_patterns=[month])[0]\ntrain_data, test_data = get_data(data_path, index_col=index_col)\npipeline = create_pipeline(\n    train_data, test_data, target_col=target_col, task_type=task_type\n)\nmodel = train_model(pipeline, config)\ncreate_submission(model, test_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:02:03.200969Z","iopub.execute_input":"2021-09-01T08:02:03.201495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feb 2021 TPS\nmonth = \"feb\"\nindex_col = \"id\"\ntarget_col = \"target\"\ntask_type = \"regression\"\n\ndata_path = get_file_paths(DATA_DIR, file_patterns=[month])[0]\ntrain_data, test_data = get_data(data_path, index_col=index_col)\npipeline = create_pipeline(\n    train_data, test_data, target_col=target_col, task_type=task_type\n)\nmodel = train_model(pipeline, config)\ncreate_submission(model, test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# March 2021 TPS\nmonth = \"mar\"\nindex_col = \"id\"\ntarget_col = \"target\"\ntask_type = \"classification\"\n\ndata_path = get_file_paths(DATA_DIR, file_patterns=[month])[0]\ntrain_data, test_data = get_data(data_path, index_col=index_col)\npipeline = create_pipeline(\n    train_data, test_data, target_col=target_col, task_type=task_type\n)\nmodel = train_model(pipeline, config)\ncreate_submission(model, test_data, label_col=\"Score\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# April 2021 TPS\napril_config = copy.deepcopy(config)\napril_config[\"sampling\"] = dict(sample_frac=round(1/20, 2))\n\nmonth = \"apr\"\nindex_col = \"PassengerId\"\ntarget_col = \"Survived\"\ntask_type = \"classification\"\n\ndata_path = get_file_paths(DATA_DIR, file_patterns=[month])[0]\ntrain_data, test_data = get_data(data_path, index_col=index_col)\npipeline = create_pipeline(\n    train_data, test_data, target_col=target_col, task_type=task_type\n)\n# set a special config for April TPS\nmodel = train_model(pipeline, april_config)\ncreate_submission(model, test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# May 2021 TPS\nmonth = \"may\"\nindex_col = \"id\"\ntarget_col = \"target\"\ntask_type = \"classification\"\n\ndata_path = get_file_paths(DATA_DIR, file_patterns=[month])[0]\ntrain_data, test_data = get_data(data_path, index_col=index_col)\npipeline = create_pipeline(\n    train_data, test_data, target_col=target_col, task_type=task_type\n)\nmodel = train_model(pipeline, config)\ncreate_submission(model, test_data, multiclass=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# June 2021 TPS\nmonth = \"jun\"\nindex_col = \"id\"\ntarget_col = \"target\"\ntask_type = \"classification\"\n\ndata_path = get_file_paths(DATA_DIR, file_patterns=[month])[0]\ntrain_data, test_data = get_data(data_path, index_col=index_col)\npipeline = create_pipeline(\n    train_data, test_data, target_col=target_col, task_type=task_type\n)\nmodel = train_model(pipeline, config)\ncreate_submission(model, test_data, multiclass=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aug 2021 TPS\nmonth = \"aug\"\nindex_col = \"id\"\ntarget_col = \"loss\"\ntask_type = \"regression\"\n\ndata_path = get_file_paths(DATA_DIR, file_patterns=[month])[0]\ntrain_data, test_data = get_data(data_path, index_col=index_col)\npipeline = create_pipeline(\n    train_data, test_data, target_col=target_col, task_type=task_type\n)\nmodel = train_model(pipeline, config)\ncreate_submission(model, test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}}]}