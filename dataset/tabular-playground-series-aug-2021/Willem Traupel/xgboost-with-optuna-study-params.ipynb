{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-31T16:17:27.472435Z","iopub.execute_input":"2021-08-31T16:17:27.472832Z","iopub.status.idle":"2021-08-31T16:17:30.963994Z","shell.execute_reply.started":"2021-08-31T16:17:27.472737Z","shell.execute_reply":"2021-08-31T16:17:30.962461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decided to join this competition just before the end date so everything was thrown together quickly.\nAn Optuna study was used for hyperparameter tuning in another notebook and that code is pasted here for reference.","metadata":{}},{"cell_type":"code","source":"training_set = pd.read_csv(\"../input/tabular-playground-series-aug-2021/train.csv\", index_col= 'id')\ntesting_set = pd.read_csv(\"../input/tabular-playground-series-aug-2021/test.csv\", index_col = 'id')","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:17:40.171263Z","iopub.execute_input":"2021-08-31T16:17:40.171618Z","iopub.status.idle":"2021-08-31T16:17:50.354906Z","shell.execute_reply.started":"2021-08-31T16:17:40.171587Z","shell.execute_reply":"2021-08-31T16:17:50.354045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use info to get a quick preview of our data \n#note: there are no null values and every column is an int\n# with pd.option_context('display.max_rows', 101):\nprint(training_set.info())","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:18:43.053953Z","iopub.execute_input":"2021-08-31T16:18:43.054278Z","iopub.status.idle":"2021-08-31T16:18:43.066501Z","shell.execute_reply.started":"2021-08-31T16:18:43.054248Z","shell.execute_reply":"2021-08-31T16:18:43.06535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:18:45.308026Z","iopub.execute_input":"2021-08-31T16:18:45.30833Z","iopub.status.idle":"2021-08-31T16:18:46.313178Z","shell.execute_reply.started":"2021-08-31T16:18:45.308302Z","shell.execute_reply":"2021-08-31T16:18:46.312082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot histogram of our data to get an idea of what the different features look like\ntraining_set.hist(bins = 50, figsize = (20,15))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:18:50.155841Z","iopub.execute_input":"2021-08-31T16:18:50.156169Z","iopub.status.idle":"2021-08-31T16:19:09.045351Z","shell.execute_reply.started":"2021-08-31T16:18:50.156141Z","shell.execute_reply":"2021-08-31T16:19:09.044514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can see the data has many different distributions and scales, which we will deal with later ","metadata":{}},{"cell_type":"code","source":"#check to see if any attributes appear correlated to eachother\n#we also want to remove the self correlated values from the matrix\ncorr_matrix = training_set.corr()\n\n# Retain upper triangular orrelation matrix and make lower values null so we can drop them\nupper_corr_matrix = corr_matrix.where(\n    np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Convert to series and drop Null values\nunique_corr_series = upper_corr_matrix.unstack().dropna()\n\n#then unstack the unique pairs and sort them\nsorted_matrix = unique_corr_series.sort_values()\n\nprint(sorted_matrix)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:19:09.046556Z","iopub.execute_input":"2021-08-31T16:19:09.046911Z","iopub.status.idle":"2021-08-31T16:19:15.582945Z","shell.execute_reply.started":"2021-08-31T16:19:09.046874Z","shell.execute_reply":"2021-08-31T16:19:15.581158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check to see if any attributes appear correlated to our target\ncorr_matrix = training_set.corr()\ncorr_matrix['loss'].sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:20:39.985014Z","iopub.execute_input":"2021-08-31T16:20:39.985346Z","iopub.status.idle":"2021-08-31T16:20:46.368171Z","shell.execute_reply.started":"2021-08-31T16:20:39.985315Z","shell.execute_reply":"2021-08-31T16:20:46.367325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No features appear strongly correlated with one another, or with our target","metadata":{}},{"cell_type":"code","source":"training_set['loss'].dropna(inplace = True)\ny = training_set.loss\ntraining_set.drop(['loss'], axis=1, inplace=True)\nX = training_set","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:25:42.323251Z","iopub.execute_input":"2021-08-31T16:25:42.323569Z","iopub.status.idle":"2021-08-31T16:25:42.327544Z","shell.execute_reply.started":"2021-08-31T16:25:42.323539Z","shell.execute_reply":"2021-08-31T16:25:42.326335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.8,test_size = 0.2, random_state = 1, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:26:01.075953Z","iopub.execute_input":"2021-08-31T16:26:01.076277Z","iopub.status.idle":"2021-08-31T16:26:01.289959Z","shell.execute_reply.started":"2021-08-31T16:26:01.076249Z","shell.execute_reply":"2021-08-31T16:26:01.2891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\nnum_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant')),\n    ('scaler', StandardScaler())\n])","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:26:03.612338Z","iopub.execute_input":"2021-08-31T16:26:03.612659Z","iopub.status.idle":"2021-08-31T16:26:03.627033Z","shell.execute_reply.started":"2021-08-31T16:26:03.612629Z","shell.execute_reply":"2021-08-31T16:26:03.626196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n# categorical_cols = [col.index for col in X_train.columns if X_train[col].dtype == \"object\"]\ncat_cols = X.select_dtypes(include=\"object\").columns\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:26:05.747981Z","iopub.execute_input":"2021-08-31T16:26:05.748292Z","iopub.status.idle":"2021-08-31T16:26:05.754411Z","shell.execute_reply.started":"2021-08-31T16:26:05.748264Z","shell.execute_reply":"2021-08-31T16:26:05.753458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\nnum_cols = X.select_dtypes(exclude=\"object\").columns\ncat_cols = X.select_dtypes(include=\"object\").columns\n\npreprocessor = ColumnTransformer([\n    ('numerical', num_transformer, num_cols),\n    ('categorical', cat_transformer, cat_cols),\n])","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:26:08.831551Z","iopub.execute_input":"2021-08-31T16:26:08.831915Z","iopub.status.idle":"2021-08-31T16:26:08.903228Z","shell.execute_reply.started":"2021-08-31T16:26:08.831877Z","shell.execute_reply":"2021-08-31T16:26:08.902392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is the code for hyperparameter tuning using Optuna, pasted from another notebook\n\n    import optuna\n        def objective(trial):\n        X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.8,test_size = 0.2, random_state = 1)\n        #hyperparameters to optimize with optuna\n        xgb_params = {\n                     \"tree_method\": trial.suggest_categorical('tree_method', [\"gpu_hist\"]),\n                     \"random_state\": trial.suggest_categorical('random_state', [42]),\n                     \"n_estimators\": trial.suggest_int('n_estimators', 50, 1050, 100),\n                     \"verbosity\": trial.suggest_categorical('verbosity', [2]),\n                     \"learning_rate\": trial.suggest_float('learning_rate', 0.01, 0.5),\n                    'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 200, 50),\n                     \"n_jobs\": trial.suggest_categorical('n_jobs', [4]),\n                     \"subsample\": trial.suggest_float('subsample', 0.1, 0.5),\n                     \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.1, 0.5),\n                     \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n                     \"booster\": trial.suggest_categorical('booster', [\"gbtree\"]),\n                     \"reg_lambda\": trial.suggest_float('reg_lambda', 2, 100),\n                     \"reg_alpha\": trial.suggest_float('reg_alpha', 1, 50),\n                    'gamma': trial.suggest_loguniform('gamma', 1e-4,1e4),\n                    'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-4,1e4)\n                     }\n\n        # Model loading \n        model = XGBRegressor(**xgb_params)\n        \n        #fit model\n        model.fit(X_train, y_train,\n                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                  eval_metric=\"rmse\",\n                 early_stopping_rounds=100, \n                  verbose=2)\n        return rmse(y_valid, model.predict(X_valid))\n\n        Best parameters: {'model__early_stopping_rounds': 100, 'model__gamma': 2, 'model__max_depth': 2, \n        'model__min_child_weight': 10, 'model__n_estimators': 50}\n\n        study = optuna.create_study(direction='minimize', study_name = 'XGBRegressor')\n        study.optimize(objective, timeout=60*60)\n\n        trial = study.best_trial\n        print('Best root mean squared error: {}'.format(trial.value))\n        print('Best trial\\'s parameters: ')\n        for key, value in trial.params.items():\n            print('{}: {}'.format(key, value))\n\n        #Showing optimization results\n        print('Number of finished trials:', len(study.trials))\n        print('Best trial parameters:', study.best_trial.params)\n        print('Best score:', study.best_value)\n\n->","metadata":{}},{"cell_type":"code","source":"#BEST PARAMS FOUNT THROUGH OPTUNA STUDY\n# Best root mean squared error: 7.860951003209514\n# Best trial's parameters: \nparams = {\n    'tree_method': 'gpu_hist',\n    'random_state': 42,\n    'n_estimators': 1050,\n    'learning_rate': 0.01934606078775565,\n    'early_stopping_rounds': 150,\n    'n_jobs': 4,\n    'subsample': 0.4838418864520116,\n    'colsample_bytree': 0.344356785743399,\n    'max_depth': 11,\n    'booster': 'gbtree',\n    'reg_lambda': 14.726431379981303,\n    'reg_alpha': 25.499975568916753,\n    'gamma': 465.95365559005677,\n    'min_child_weight': 5.956504210470665\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:28:31.336426Z","iopub.execute_input":"2021-08-31T16:28:31.3368Z","iopub.status.idle":"2021-08-31T16:28:31.341919Z","shell.execute_reply.started":"2021-08-31T16:28:31.33677Z","shell.execute_reply":"2021-08-31T16:28:31.340939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor\n#load our XGBRegressor model with best params from the Optuna study\nxgb_model = XGBRegressor(verbosity = 2, **params)\nxgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', xgb_model)])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:28:38.698843Z","iopub.execute_input":"2021-08-31T16:28:38.699178Z","iopub.status.idle":"2021-08-31T16:28:38.706361Z","shell.execute_reply.started":"2021-08-31T16:28:38.699149Z","shell.execute_reply":"2021-08-31T16:28:38.70554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_pipeline.fit(X_train, y_train)\npredictions = xgb_pipeline.predict(X_valid)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T07:26:11.871744Z","iopub.execute_input":"2021-08-31T07:26:11.872179Z","iopub.status.idle":"2021-08-31T07:26:11.880487Z","shell.execute_reply.started":"2021-08-31T07:26:11.872145Z","shell.execute_reply":"2021-08-31T07:26:11.879285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nrmse = np.sqrt(mean_squared_error(predictions, y_valid))\nprint('RMSE:', rmse)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T07:24:34.574152Z","iopub.status.idle":"2021-08-31T07:24:34.5749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pred = xgb_pipeline.predict(testing_set)\noutput = pd.DataFrame({'Id': testing_set.index,\n                       'loss': final_pred})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T07:24:34.582796Z","iopub.status.idle":"2021-08-31T07:24:34.583539Z"},"trusted":true},"execution_count":null,"outputs":[]}]}