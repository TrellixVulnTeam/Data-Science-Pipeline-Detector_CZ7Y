{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport warnings\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\nimport pylab as plot\n\n# import datasets\ntrain = pd.read_csv('../input/tabular-playground-series-aug-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-aug-2021/test.csv')\nsubmission = pd.read_csv('../input/tabular-playground-series-aug-2021/sample_submission.csv')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# setting up options\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-28T16:31:24.18977Z","iopub.execute_input":"2021-08-28T16:31:24.190342Z","iopub.status.idle":"2021-08-28T16:31:34.179409Z","shell.execute_reply.started":"2021-08-28T16:31:24.190306Z","shell.execute_reply":"2021-08-28T16:31:34.17827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Train dataset\nAs stated before, train dataset is mainly used to train predictive model as there is an available target variable in this set. This dataset is also used to explore more on the data itself including find a relation between each predictors and the target variable.\n\nObservations:\n\n","metadata":{}},{"cell_type":"markdown","source":"Below is the first 5 rows of test dataset:","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:32:04.910292Z","iopub.execute_input":"2021-08-28T16:32:04.910681Z","iopub.status.idle":"2021-08-28T16:32:04.976622Z","shell.execute_reply.started":"2021-08-28T16:32:04.910634Z","shell.execute_reply":"2021-08-28T16:32:04.975801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dimension and number of missing values in the train dataset is as below:","metadata":{}},{"cell_type":"code","source":"print(f'Number of rows: {train.shape[0]};  Number of columns: {train.shape[1]}; No of missing values: {sum(train.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:33:00.157948Z","iopub.execute_input":"2021-08-28T16:33:00.158291Z","iopub.status.idle":"2021-08-28T16:33:00.213816Z","shell.execute_reply.started":"2021-08-28T16:33:00.158261Z","shell.execute_reply":"2021-08-28T16:33:00.212783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data types:**\nExcept for column id, f1, f16, f27, f55, f60, f86 and loss column which are in int64 type, other columns are in float64. (to see the details, please expand)","metadata":{}},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:34:12.032097Z","iopub.execute_input":"2021-08-28T16:34:12.032434Z","iopub.status.idle":"2021-08-28T16:34:12.042365Z","shell.execute_reply.started":"2021-08-28T16:34:12.032401Z","shell.execute_reply":"2021-08-28T16:34:12.041367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Basic statistics:\n**Below is the basic statistics for each variables which contain information on count, mean, standard deviation, minimum, 1st quartile, median, 3rd quartile and maximum.","metadata":{}},{"cell_type":"code","source":"train.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:35:17.691152Z","iopub.execute_input":"2021-08-28T16:35:17.691503Z","iopub.status.idle":"2021-08-28T16:35:18.879094Z","shell.execute_reply.started":"2021-08-28T16:35:17.691471Z","shell.execute_reply":"2021-08-28T16:35:18.878251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Test dataset\nTest dataset is used to make a prediction based on the model that has previously trained. Exploration in this dataset is also needed to see how the data is structured and especially on itâ€™s similiarity with the train dataset.","metadata":{}},{"cell_type":"markdown","source":"\nBelow is the first 5 rows of test dataset:","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:37:10.295214Z","iopub.execute_input":"2021-08-28T16:37:10.295581Z","iopub.status.idle":"2021-08-28T16:37:10.345942Z","shell.execute_reply.started":"2021-08-28T16:37:10.295527Z","shell.execute_reply":"2021-08-28T16:37:10.345038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print(f'Number of rows: {test.shape[0]};  Number of columns: {test.shape[1]}; No of missing values: {sum(test.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:37:38.213792Z","iopub.execute_input":"2021-08-28T16:37:38.214282Z","iopub.status.idle":"2021-08-28T16:37:38.250974Z","shell.execute_reply.started":"2021-08-28T16:37:38.214252Z","shell.execute_reply":"2021-08-28T16:37:38.250343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Data types\n**Except for column id, f1, f16, f27, f55, f60, f86 and loss column which are in int64 type, other columns are in float64 which is consistent with the train dataset. (to see the details, please expand)","metadata":{}},{"cell_type":"code","source":"test.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:38:49.498407Z","iopub.execute_input":"2021-08-28T16:38:49.49881Z","iopub.status.idle":"2021-08-28T16:38:49.508379Z","shell.execute_reply.started":"2021-08-28T16:38:49.498777Z","shell.execute_reply":"2021-08-28T16:38:49.507496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of features available to be used to create a prediction model are 100. The analysis is started by looking on number of uniques value on integer features which are f1, f16, f27, f55, f60 and f86.","metadata":{}},{"cell_type":"code","source":"features=['f1', 'f16', 'f27', 'f55', 'f86', 'loss']\n\nfor col in features:\n    print(f'{col} unique value : {train[col].nunique()}')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:40:12.467487Z","iopub.execute_input":"2021-08-28T16:40:12.467834Z","iopub.status.idle":"2021-08-28T16:40:12.514765Z","shell.execute_reply.started":"2021-08-28T16:40:12.467805Z","shell.execute_reply":"2021-08-28T16:40:12.513988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3.  Submission\nThe submission file is expected to have an id and loss columns.\n\nBelow is the first 5 rows of submission file:","metadata":{}},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:41:13.098575Z","iopub.execute_input":"2021-08-28T16:41:13.099073Z","iopub.status.idle":"2021-08-28T16:41:13.107104Z","shell.execute_reply.started":"2021-08-28T16:41:13.09904Z","shell.execute_reply":"2021-08-28T16:41:13.106458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(['id'], axis=1, inplace=True)\ntest.drop(['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:41:28.859678Z","iopub.execute_input":"2021-08-28T16:41:28.860143Z","iopub.status.idle":"2021-08-28T16:41:28.978873Z","shell.execute_reply.started":"2021-08-28T16:41:28.860113Z","shell.execute_reply":"2021-08-28T16:41:28.978021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(17, 8))\n\ntarget_count = train['loss'].value_counts().sort_index()\n\nax.bar(target_count.index, target_count, color=['#1520E6' if i%2==0 else '#93D1FF' for i in range(9)],\n       width=0.55, \n       edgecolor='black', \n       linewidth=0.7)\n\nax.margins(0.02, 0.05)\n\nfor i in range(20):\n    ax.annotate(f'{target_count[i]/len(train)*100:.3}', xy=(i, target_count[i]+1000),\n                   va='center', ha='center',\n               )\n#Annotate the point xy with text text.\n\n#In the simplest form, the text is placed at xy.\n\nax.set_title('Target Distribution', weight='bold', fontsize=15)\nax.grid(axis='y', linestyle='-', alpha=0.4)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:42:18.520681Z","iopub.execute_input":"2021-08-28T16:42:18.521132Z","iopub.status.idle":"2021-08-28T16:42:18.978898Z","shell.execute_reply.started":"2021-08-28T16:42:18.521103Z","shell.execute_reply":"2021-08-28T16:42:18.978221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a total of 43 discrete losses.\nThe top 12 distributions account for 80% of the total.\nAll except the order of 2 and 1 are in increasing order.","metadata":{}},{"cell_type":"code","source":"target_count = train['loss'].value_counts().sort_index()\ntarget_count_df = pd.DataFrame(target_count)\n#pd.options.display.float_format = '{:,.2f}%'.format\ntarget_count_df['loss(%)'] = (target_count_df/target_count.sum()*100)\ntarget_count_df.sort_values('loss(%)', ascending=False, inplace=True)\ndisplay(target_count_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:43:35.643978Z","iopub.execute_input":"2021-08-28T16:43:35.644486Z","iopub.status.idle":"2021-08-28T16:43:35.677797Z","shell.execute_reply.started":"2021-08-28T16:43:35.644456Z","shell.execute_reply":"2021-08-28T16:43:35.676822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"K-Fold Benchmark Visualization\nLet's create a total of 4 models.\n\nFor demonstration, I used Decistion Tree, SVM, RandomForest, AdaBoost.\n\nThe score is RMSE.","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:44:32.487826Z","iopub.execute_input":"2021-08-28T16:44:32.488161Z","iopub.status.idle":"2021-08-28T16:44:32.937475Z","shell.execute_reply.started":"2021-08-28T16:44:32.488131Z","shell.execute_reply":"2021-08-28T16:44:32.936392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model_cls, X, y):\n    model = model_cls() \n    train_scores, valid_scores = [], []\n    \n    skf = KFold(n_splits=5, shuffle=True)\n\n    for tr_idx, va_idx in skf.split(X, y):\n        X_train, X_val = X.iloc[tr_idx], X.iloc[va_idx]\n        y_train, y_val = y[tr_idx], y[va_idx]\n        model.fit(X_train, y_train)\n        \n        pred = model.predict(X_train)\n        train_score = mean_squared_error(y_train, pred)\n        \n        pred = model.predict(X_val)\n        valid_score = mean_squared_error(y_val, pred)\n        \n        train_scores.append(train_score)    \n        valid_scores.append(valid_score)\n        \n    \n    print('train score mean : ',np.mean(train_scores))\n    print('valid score mean : ',np.mean(valid_scores))\n    return train_scores, valid_scores","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:45:18.293972Z","iopub.execute_input":"2021-08-28T16:45:18.294312Z","iopub.status.idle":"2021-08-28T16:45:18.301656Z","shell.execute_reply.started":"2021-08-28T16:45:18.294283Z","shell.execute_reply":"2021-08-28T16:45:18.300627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For fast implementation, only 1000 random data were used.\n","metadata":{}},{"cell_type":"code","source":"\ntrain = pd.read_csv('../input/tabular-playground-series-aug-2021/train.csv').sample(1000)\ntarget = train['loss']\ntrain = train.drop(['loss'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:50:01.055235Z","iopub.execute_input":"2021-08-28T16:50:01.055616Z","iopub.status.idle":"2021-08-28T16:50:05.141184Z","shell.execute_reply.started":"2021-08-28T16:50:01.05558Z","shell.execute_reply":"2021-08-28T16:50:05.140423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_train, dt_val = train_model(DecisionTreeRegressor, train, target.values)\nsvm_train, svm_val = train_model(SVR, train, target.values)\nrf_train, rf_val = train_model(RandomForestRegressor, train, target.values)\nada_train, ada_val = train_model(AdaBoostRegressor, train, target.values)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:50:29.202394Z","iopub.execute_input":"2021-08-28T16:50:29.203097Z","iopub.status.idle":"2021-08-28T16:51:14.840972Z","shell.execute_reply.started":"2021-08-28T16:50:29.203058Z","shell.execute_reply":"2021-08-28T16:51:14.839999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train2=train.iloc[:,[2,17,28,56,87]]\ntrain2.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:54:10.15439Z","iopub.execute_input":"2021-08-28T16:54:10.154768Z","iopub.status.idle":"2021-08-28T16:54:10.166888Z","shell.execute_reply.started":"2021-08-28T16:54:10.154734Z","shell.execute_reply":"2021-08-28T16:54:10.165804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_train2, dt_val2 = train_model(DecisionTreeRegressor, train2, target.values)\nsvm_train2, svm_val2 = train_model(SVR, train2, target.values)\nrf_train2, rf_val2 = train_model(RandomForestRegressor, train2, target.values)\nada_train2, ada_val2 = train_model(AdaBoostRegressor, train2, target.values)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:54:15.921175Z","iopub.execute_input":"2021-08-28T16:54:15.921506Z","iopub.status.idle":"2021-08-28T16:54:18.802186Z","shell.execute_reply.started":"2021-08-28T16:54:15.921467Z","shell.execute_reply":"2021-08-28T16:54:18.801241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The result is bundled using numpy's stack and overlaid with a DataFrame.","metadata":{}},{"cell_type":"code","source":"raw_data = np.vstack([dt_train, dt_train2,dt_val, dt_val2,\n           svm_train,svm_train2, svm_val, svm_val2,\n           rf_train,rf_train2, rf_val, rf_val2,\n           ada_train, ada_train2,ada_val, ada_val2]).T\n\nraw_data = np.vstack([raw_data, raw_data.mean(axis=0)])\ndf = pd.DataFrame(raw_data,\n                  index=pd.Index([f'Fold {idx}' for idx in range(5)]+['Mean'], name='#:'),\n                  columns=pd.MultiIndex.from_product([['Decision Tree', 'SVM', 'Random Forest', 'AdaBoost'],\n                                                     ['Train', 'Train1','Valid','Valid1']], \n                                                     names=['Model:', 'Train/Split']))\ndisplay(df)\ns = df.style.format('{:.3f}')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:13:53.868748Z","iopub.execute_input":"2021-08-28T17:13:53.869069Z","iopub.status.idle":"2021-08-28T17:13:53.923555Z","shell.execute_reply.started":"2021-08-28T17:13:53.869041Z","shell.execute_reply":"2021-08-28T17:13:53.922771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_color = '#00539C'\nsub_color = '#FFD662'\n\n# Cell\ncell_hover = {\n    'selector': 'td:hover',\n    'props': [('background-color', sub_color),\n              ('color', main_color),\n              ('font-weight', 'bold')\n             ]\n}\n\n# Index Explaination\nindex_names = {\n    'selector': '.index_name',\n    'props': [('font-style', 'italic'), \n              ('color', 'darkgrey'),  \n              ('font-weight', 'normal')]\n}\n\n# header\nheaders = {\n    'selector': 'th:not(.index_name)',\n    'props': [('background-color', main_color),\n              ('color', 'white')]\n}\n\nheaders_head = {\n    'selector': 'th.col_heading', \n    'props': [('text-align', 'center')]\n}\n\n# border\nborder_head1 = {\n    'selector': 'th.col_heading.level0', \n    'props': [\n        ('font-weight', 'bold'),\n        ('color', sub_color),\n        ('border-left', '1px solid white'),\n    \n    ]\n}\n\nborder_head2 = {\n    'selector': 'th:nth-child(2n+2)', \n    'props': [('border-left', '1px solid white')]\n}\n\nborder_body = {\n    'selector': 'td:nth-child(2n+2)', \n    'props': [('border-left', f'1px solid {main_color}')]\n}\n\nborder_footer1 = {\n    'selector': 'tr:last-child td', \n    'props': [('border-top', f'1px solid {main_color}')]\n}\n\nborder_footer2 = {\n    'selector': 'tr:last-child td', \n    'props': [('border-top', f'1px solid {main_color}')]\n}\n\nborder_footer3 = {\n    'selector': 'tr:last-child', \n    'props': [('background-color', main_color+'20')]\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:22:02.206901Z","iopub.execute_input":"2021-08-28T17:22:02.207225Z","iopub.status.idle":"2021-08-28T17:22:02.215692Z","shell.execute_reply.started":"2021-08-28T17:22:02.207197Z","shell.execute_reply":"2021-08-28T17:22:02.21455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s =s.set_table_styles([cell_hover, index_names, headers, headers_head, \n                    border_head1, border_head2, border_body, \n                    border_footer1, border_footer2, border_footer3])\ns","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:22:08.665851Z","iopub.execute_input":"2021-08-28T17:22:08.666341Z","iopub.status.idle":"2021-08-28T17:22:08.680948Z","shell.execute_reply.started":"2021-08-28T17:22:08.666309Z","shell.execute_reply":"2021-08-28T17:22:08.68022Z"},"trusted":true},"execution_count":null,"outputs":[]}]}