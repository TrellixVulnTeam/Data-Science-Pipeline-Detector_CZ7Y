{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nThis notebook was prepared for the [Aug 2021 Playground Series competition](https://www.kaggle.com/c/tabular-playground-series-aug-2021). Questions, comments, feedback welcome!\n\n## Overview\n1. [Quick EDA](#1)\n2. [Hyperparameter tuning with RandomizedSearchCV](#2)\n3. [Stacking Ensemble using OOF predictions](#3)\n    * XGB & LGBM regressors (base), Linear regression (meta)","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import rcParams\nrcParams[\"axes.spines.top\"] = False\nrcParams[\"axes.spines.right\"] = False\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score, KFold, RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nseed=3717\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T23:00:37.38588Z","iopub.execute_input":"2021-09-09T23:00:37.386201Z","iopub.status.idle":"2021-09-09T23:00:39.649996Z","shell.execute_reply.started":"2021-09-09T23:00:37.386171Z","shell.execute_reply":"2021-09-09T23:00:39.649178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n### 1. EDA","metadata":{}},{"cell_type":"code","source":"train_raw = pd.read_csv(\"../input/tabular-playground-series-aug-2021/train.csv\", index_col=\"id\")\ntest_raw = pd.read_csv(\"../input/tabular-playground-series-aug-2021/test.csv\", index_col=\"id\")\n\nprint('Train shape:', train_raw.shape)\nprint('Test shape:', test_raw.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:00:39.651564Z","iopub.execute_input":"2021-09-09T23:00:39.651903Z","iopub.status.idle":"2021-09-09T23:00:49.25275Z","shell.execute_reply.started":"2021-09-09T23:00:39.651868Z","shell.execute_reply":"2021-09-09T23:00:49.250905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combine train and test for pre processing\n# save original end/start indices for re-splitting train/test later\ntrain_end_idx=249999\ntest_start_idx=250000\nall_raw = pd.concat([train_raw,test_raw])\nall_raw.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:00:49.254677Z","iopub.execute_input":"2021-09-09T23:00:49.25505Z","iopub.status.idle":"2021-09-09T23:00:49.53738Z","shell.execute_reply.started":"2021-09-09T23:00:49.25501Z","shell.execute_reply":"2021-09-09T23:00:49.534498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for missing values\nprint('Train data null count:',train_raw.isnull().sum().sum())\nprint('Test data null count:',test_raw.isnull().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:00:49.541152Z","iopub.execute_input":"2021-09-09T23:00:49.544218Z","iopub.status.idle":"2021-09-09T23:00:49.642841Z","shell.execute_reply.started":"2021-09-09T23:00:49.544175Z","shell.execute_reply":"2021-09-09T23:00:49.641764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check feature datatypes\ntrain_raw.dtypes.unique()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:00:49.644408Z","iopub.execute_input":"2021-09-09T23:00:49.644742Z","iopub.status.idle":"2021-09-09T23:00:49.655686Z","shell.execute_reply.started":"2021-09-09T23:00:49.644708Z","shell.execute_reply":"2021-09-09T23:00:49.654756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# see summary statistics for features\nall_raw.drop('loss',axis=1).describe().T.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:00:49.657014Z","iopub.execute_input":"2021-09-09T23:00:49.657624Z","iopub.status.idle":"2021-09-09T23:00:51.385569Z","shell.execute_reply.started":"2021-09-09T23:00:49.657586Z","shell.execute_reply":"2021-09-09T23:00:51.384721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# examine distribution of features\nfig, axs = plt.subplots(20,5,figsize=(12,40))\nplt.suptitle('Feature Distributions')\nfor i, feat in enumerate(all_raw.loc[:,:'f99']):\n    sns.histplot(all_raw[feat],kde=False, ax=axs.flat[i])\n    axs.flat[i].axes.get_yaxis().set_visible(False)\n    axs.flat[i].spines['left'].set_visible(False)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:00:51.386924Z","iopub.execute_input":"2021-09-09T23:00:51.387331Z","iopub.status.idle":"2021-09-09T23:02:21.407129Z","shell.execute_reply.started":"2021-09-09T23:00:51.387274Z","shell.execute_reply":"2021-09-09T23:02:21.406373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# examine distribution for target\nsns.kdeplot(train_raw['loss'], shade=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:02:21.409301Z","iopub.execute_input":"2021-09-09T23:02:21.410074Z","iopub.status.idle":"2021-09-09T23:02:22.810002Z","shell.execute_reply.started":"2021-09-09T23:02:21.410037Z","shell.execute_reply":"2021-09-09T23:02:22.809202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set up train test data \nX =  train_raw.copy()\ny = X.pop('loss')\n\nX_test = test_raw.copy()\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:02:22.811501Z","iopub.execute_input":"2021-09-09T23:02:22.811769Z","iopub.status.idle":"2021-09-09T23:02:23.64532Z","shell.execute_reply.started":"2021-09-09T23:02:22.811743Z","shell.execute_reply":"2021-09-09T23:02:23.644439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n### 2. Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"# RandomizedSearch tuning\ntest_params = {\n    'num_iterations': [300,700,1000],\n    'max_depth': [5,50,100],\n    'learning_rate': [0.05, 0.1, 0.2],\n    'reg_alpha': [1,10,20],\n    'reg_lambda': [0,0.5,2,10]\n}\nlgbr = LGBMRegressor(device_type='gpu', seed=seed)\nsearch_results = RandomizedSearchCV(estimator=lgbr, \n                         param_distributions=test_params,\n                         scoring='neg_mean_squared_error',\n                         n_iter=10,\n                         verbose=1)\n#search_results.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:02:23.64665Z","iopub.execute_input":"2021-09-09T23:02:23.646994Z","iopub.status.idle":"2021-09-09T23:02:23.652621Z","shell.execute_reply.started":"2021-09-09T23:02:23.646956Z","shell.execute_reply":"2021-09-09T23:02:23.651827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(\"Best parameters:\", search_results.best_params_)\n#print(\"Lowest RMSE: \", (-search_results.best_score_)**(1/2.0))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:02:23.653819Z","iopub.execute_input":"2021-09-09T23:02:23.654358Z","iopub.status.idle":"2021-09-09T23:02:23.662641Z","shell.execute_reply.started":"2021-09-09T23:02:23.654323Z","shell.execute_reply":"2021-09-09T23:02:23.661839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best params are from randomized search\nbest_xgb_params = {\n    'n_estimators':1000,\n    'max_depth':5,\n    'learning_rate':0.05,\n    'colsample_bytree':0.7,\n    'min_child_weight':7,\n    'alpha':0.5,\n    'lambda':1.5\n}\n\nbest_lgb_params = {\n    'reg_lambda': 0.5,\n    'reg_alpha': 10,\n    'num_iterations': 700,\n    'max_depth': 5,\n    'learning_rate': 0.05\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:02:23.66357Z","iopub.execute_input":"2021-09-09T23:02:23.665671Z","iopub.status.idle":"2021-09-09T23:02:23.672449Z","shell.execute_reply.started":"2021-09-09T23:02:23.665646Z","shell.execute_reply":"2021-09-09T23:02:23.671675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to get list of models\ndef get_models():\n    models = dict()\n    models['xgb'] = XGBRegressor(tree_method='gpu_hist', **best_xgb_params)\n    models['lgb'] = LGBMRegressor(device_type='gpu', seed=seed, **best_lgb_params)\n    return models\n \n# evaluate a given model using cross-validation, default 5 folds\ndef cv_rmse(model, X, y, folds=5):\n    kfolds = KFold(n_splits=folds, shuffle=True, random_state=seed)\n    scores = cross_val_score(\n        model, X, y, cv=kfolds, scoring=\"neg_mean_squared_error\",\n    )\n    scores = np.sqrt(-1*scores)\n    return scores\n\n# use cv_rmse to evaluate models and plot rsme\ndef evaluate_models():\n    # get the models to evaluate\n    models = get_models()\n\n    # evaluate the models and store results\n    results, names = [], []\n    for name, model in models.items():\n        scores = cv_rmse(model, X, y)\n        results.append(scores)\n        names.append(name)\n        print(f'Model: {name}, Mean RSME: {np.mean(scores):.4f}, Std: {np.std(scores):.4f}')\n\n    plt.boxplot(results, showmeans=True, labels=names)\n    plt.show()\nevaluate_models()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:02:23.675166Z","iopub.execute_input":"2021-09-09T23:02:23.67562Z","iopub.status.idle":"2021-09-09T23:04:27.321435Z","shell.execute_reply.started":"2021-09-09T23:02:23.675593Z","shell.execute_reply":"2021-09-09T23:04:27.320555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n### 3. Stacking Ensemble","metadata":{}},{"cell_type":"code","source":"# create 2 level stack and use oof predictions\n# base estimators: xbg and lgb regressors\n# meta estimator: linear regression\n# average oof predictions over 5 folds\ndef stacking_ensemble():\n    n_splits=5\n    test_preds = []\n    xgb_rmse = []\n    lgb_rmse = []\n    lr_rmse = []\n\n    kfolds = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    \n    xgb_base_estimator = get_models()['xgb']\n    lgb_base_estimator = get_models()['lgb']\n    final_estimator = LinearRegression()\n    \n    print(f'Stacking starting, {n_splits} total folds...')\n\n    for fold, (train_idx, valid_idx) in enumerate(kfolds.split(X, y)):\n        \n        # split train/validate\n        X_train, y_train = X[train_idx], y[train_idx]\n        X_valid, y_valid = X[valid_idx], y[valid_idx]\n        \n        # XGB base model - fit, predict, and score\n        xgb_base_estimator.fit(X_train, y_train)\n        xgb_base_preds = xgb_base_estimator.predict(X_valid)\n        xgb_base_rmse = mean_squared_error(y_valid, xgb_base_preds, squared=False)\n        xgb_rmse.append(xgb_base_rmse)\n        print(f'Fold {fold+1}, Base XGB RMSE: {xgb_base_rmse:.5f}')\n          \n        # LGBM base model - fit, predict, and score\n        lgb_base_estimator.fit(X_train, y_train)\n        lgb_base_preds = lgb_base_estimator.predict(X_valid)\n        lgb_base_rmse = mean_squared_error(y_valid, lgb_base_preds, squared=False)\n        lgb_rmse.append(lgb_base_rmse)\n        print(f'Fold {fold+1}, Base LGBM RMSE: {lgb_base_rmse:.5f}')\n        \n        # Linear regression final (meta) model\n        blend_train = np.c_[xgb_base_preds, lgb_base_preds]\n        blend_test = np.c_[xgb_base_estimator.predict(X_test), lgb_base_estimator.predict(X_test)]\n        final_estimator.fit(blend_train, y_valid)\n        final_estimator_preds = final_estimator.predict(blend_test)\n        final_estimator_rmse = mean_squared_error(y_valid, final_estimator.predict(blend_train), squared=False)\n        lr_rmse.append(final_estimator_rmse)\n        print(f'Fold {fold+1}, Final LR RMSE: {final_estimator_rmse:.5f}')\n        test_preds.append(final_estimator_preds)\n    \n    # get average RMSEs across all folds for all models\n    xgb_rmse_avg = np.mean(xgb_rmse)\n    lgb_rmse_avg = np.mean(lgb_rmse)\n    lr_rmse_avg = np.mean(lr_rmse)\n\n    print(f'Average RMSEs - Base XGB:{xgb_rmse_avg:.5f}, Base LGBM:{lgb_rmse_avg:.5f}, Final LR:{lr_rmse_avg:.5f}')\n    return(sum(test_preds)/n_splits)\n\nstack_preds = stacking_ensemble()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:04:27.322781Z","iopub.execute_input":"2021-09-09T23:04:27.323152Z","iopub.status.idle":"2021-09-09T23:04:27.410931Z","shell.execute_reply.started":"2021-09-09T23:04:27.323113Z","shell.execute_reply":"2021-09-09T23:04:27.409607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create submission file\noutput = pd.DataFrame({'id': test_raw.index, \n                       'loss':stack_preds})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Submission saved.\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:04:27.412131Z","iopub.status.idle":"2021-09-09T23:04:27.412712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sanity check of output\nsns.kdeplot(output['loss'], shade=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T23:04:27.413928Z","iopub.status.idle":"2021-09-09T23:04:27.414641Z"},"trusted":true},"execution_count":null,"outputs":[]}]}