{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-26T21:25:00.134304Z","iopub.execute_input":"2021-08-26T21:25:00.13462Z","iopub.status.idle":"2021-08-26T21:25:00.147278Z","shell.execute_reply.started":"2021-08-26T21:25:00.134559Z","shell.execute_reply":"2021-08-26T21:25:00.146362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn import metrics\n#from xgboost import XGBRegressor\nfrom sklearn.svm import LinearSVR\nfrom sklearn import preprocessing","metadata":{"execution":{"iopub.status.busy":"2021-08-26T22:29:07.604686Z","iopub.execute_input":"2021-08-26T22:29:07.605008Z","iopub.status.idle":"2021-08-26T22:29:07.780086Z","shell.execute_reply.started":"2021-08-26T22:29:07.604979Z","shell.execute_reply":"2021-08-26T22:29:07.779322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tabular-playground-series-aug-2021/train.csv\")\nsample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2021/sample_submission.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2021/test.csv')\ndf['kfold'] = -1\nkfold = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 0)  #5 is more or less a good split value\n\nfor fold, ( train_indices, test_indices ) in enumerate(kfold.split(df)):\n    df.loc[test_indices,'kfold'] = fold\ndf_test.drop('id',axis = 1, inplace = True )\n\ncont = [col for col in df.columns if col.startswith('f')]\nfor col in cont:\n    df[f'{col}_bin'], bins = pd.qcut(df[col], q = 4, retbins = True, labels = [0,1,2,3])\n    df[f'{col}_bin'] = pd.to_numeric(df[f'{col}_bin'])\n    bins = np.concatenate([[-np.Inf], bins[1:-1],[np.Inf]])\n    df_test[f'{col}_bin'] = pd.cut(df_test[col],bins, labels = [0,1,2,3])\n    df_test[f'{col}_bin'] = pd.to_numeric(df_test[f'{col}_bin'])\n\nscaler = preprocessing.Normalizer()\ndf[cont] = scaler.fit_transform(df[cont])\ndf_test[cont] = scaler.transform(df_test[cont])\n\nnot_features = ['id','kfold','loss']\nfinal_predictions = []\nerror_score = []\n\nfor fold in range(5):\n    \n    train_fold = df[df['kfold'] != fold ]\n    xtrain = train_fold.drop( not_features, axis = 1 )\n    ytrain = train_fold['loss']\n    \n    valid_fold = df[df['kfold'] == fold ]\n    xval = valid_fold.drop( not_features, axis = 1 )\n    yval = valid_fold['loss']\n    \n    #model = XGBRegressor(n_jobs = -1, tree_method = 'gpu_hist', gpu_id = 0, predictor = 'gpu_predictor' )\n    #model.fit(xtrain,ytrain)\n    clf = LinearSVR(random_state=0, tol=1e-5, max_iter=5000)\n    clf.fit(xtrain, ytrain)\n    prediction = clf.predict(xval)\n    #prediction = model.predict(xval)\n    final_predictions.append(model.predict(df_test))\n    error = metrics.mean_squared_error(prediction, yval, squared = False )\n    print( fold, error )\n    error_score.append(error)\n    \nprint(f\"Mean : {np.mean(error_score)}\\nStandard Deviation : {np.std(error_score)}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T22:51:11.151734Z","iopub.execute_input":"2021-08-26T22:51:11.152064Z","iopub.status.idle":"2021-08-26T22:56:54.718223Z","shell.execute_reply.started":"2021-08-26T22:51:11.152034Z","shell.execute_reply":"2021-08-26T22:56:54.717328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = np.column_stack(final_predictions)\nresult = final_predictions.mean( axis = 1 )\nsample_submission['loss'] = result\nsample_submission.to_csv('submission.csv', index = False )","metadata":{"execution":{"iopub.status.busy":"2021-08-26T14:39:27.580366Z","iopub.execute_input":"2021-08-26T14:39:27.580756Z","iopub.status.idle":"2021-08-26T14:39:28.049618Z","shell.execute_reply.started":"2021-08-26T14:39:27.580715Z","shell.execute_reply":"2021-08-26T14:39:28.048194Z"},"trusted":true},"execution_count":null,"outputs":[]}]}