{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-26T09:15:26.176972Z","iopub.execute_input":"2021-08-26T09:15:26.177274Z","iopub.status.idle":"2021-08-26T09:15:26.18658Z","shell.execute_reply.started":"2021-08-26T09:15:26.177248Z","shell.execute_reply":"2021-08-26T09:15:26.185456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Packages","metadata":{}},{"cell_type":"code","source":"def submit(model, test_features, test_ids, filename):\n    loss_pred = model.predict(test_features)\n    submission = pd.DataFrame({\"id\": test_ids, \"loss\": loss_pred.reshape(-1)})\n    submission.to_csv(filename, index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:26.187879Z","iopub.execute_input":"2021-08-26T09:15:26.188244Z","iopub.status.idle":"2021-08-26T09:15:26.198871Z","shell.execute_reply.started":"2021-08-26T09:15:26.188218Z","shell.execute_reply":"2021-08-26T09:15:26.198076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Common Functions","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/tabular-playground-series-aug-2021/train.csv\")\n\ntest_data = pd.read_csv(\"/kaggle/input/tabular-playground-series-aug-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:26.200486Z","iopub.execute_input":"2021-08-26T09:15:26.200945Z","iopub.status.idle":"2021-08-26T09:15:32.393013Z","shell.execute_reply.started":"2021-08-26T09:15:26.200917Z","shell.execute_reply":"2021-08-26T09:15:32.391873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:32.394802Z","iopub.execute_input":"2021-08-26T09:15:32.395105Z","iopub.status.idle":"2021-08-26T09:15:32.421322Z","shell.execute_reply.started":"2021-08-26T09:15:32.395078Z","shell.execute_reply":"2021-08-26T09:15:32.420308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:32.422738Z","iopub.execute_input":"2021-08-26T09:15:32.423115Z","iopub.status.idle":"2021-08-26T09:15:32.451872Z","shell.execute_reply.started":"2021-08-26T09:15:32.423086Z","shell.execute_reply":"2021-08-26T09:15:32.451131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:32.452878Z","iopub.execute_input":"2021-08-26T09:15:32.453108Z","iopub.status.idle":"2021-08-26T09:15:32.466216Z","shell.execute_reply.started":"2021-08-26T09:15:32.453085Z","shell.execute_reply":"2021-08-26T09:15:32.465632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe().transpose()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:32.467086Z","iopub.execute_input":"2021-08-26T09:15:32.467423Z","iopub.status.idle":"2021-08-26T09:15:33.563922Z","shell.execute_reply.started":"2021-08-26T09:15:32.467397Z","shell.execute_reply":"2021-08-26T09:15:33.563339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:33.56544Z","iopub.execute_input":"2021-08-26T09:15:33.565771Z","iopub.status.idle":"2021-08-26T09:15:33.570217Z","shell.execute_reply.started":"2021-08-26T09:15:33.565746Z","shell.execute_reply":"2021-08-26T09:15:33.569328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_score = train_data.corr()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:33.571519Z","iopub.execute_input":"2021-08-26T09:15:33.571756Z","iopub.status.idle":"2021-08-26T09:15:40.659125Z","shell.execute_reply.started":"2021-08-26T09:15:33.571732Z","shell.execute_reply":"2021-08-26T09:15:40.658263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_score[\"loss\"].sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:40.660369Z","iopub.execute_input":"2021-08-26T09:15:40.660623Z","iopub.status.idle":"2021-08-26T09:15:40.671362Z","shell.execute_reply.started":"2021-08-26T09:15:40.660598Z","shell.execute_reply":"2021-08-26T09:15:40.670437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Drop Id Column","metadata":{}},{"cell_type":"code","source":"train_data.pop(\"id\")\ntest_ids = test_data.pop(\"id\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:40.672587Z","iopub.execute_input":"2021-08-26T09:15:40.672967Z","iopub.status.idle":"2021-08-26T09:15:40.682388Z","shell.execute_reply.started":"2021-08-26T09:15:40.672929Z","shell.execute_reply":"2021-08-26T09:15:40.681525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mean = train_data.mean()\ntrain_std = train_data.std()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:40.683764Z","iopub.execute_input":"2021-08-26T09:15:40.684147Z","iopub.status.idle":"2021-08-26T09:15:40.812831Z","shell.execute_reply.started":"2021-08-26T09:15:40.684111Z","shell.execute_reply":"2021-08-26T09:15:40.812069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_target_mean = train_mean.pop(\"loss\")\ntrain_targets_std = train_std.pop(\"loss\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:40.814248Z","iopub.execute_input":"2021-08-26T09:15:40.814611Z","iopub.status.idle":"2021-08-26T09:15:40.819827Z","shell.execute_reply.started":"2021-08-26T09:15:40.814574Z","shell.execute_reply":"2021-08-26T09:15:40.819089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Validation Split","metadata":{}},{"cell_type":"code","source":"validation_split = 0.2","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:40.820948Z","iopub.execute_input":"2021-08-26T09:15:40.821296Z","iopub.status.idle":"2021-08-26T09:15:40.829495Z","shell.execute_reply.started":"2021-08-26T09:15:40.821261Z","shell.execute_reply":"2021-08-26T09:15:40.828756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features, validation_features = train_test_split(train_data, test_size = validation_split)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:40.830688Z","iopub.execute_input":"2021-08-26T09:15:40.831054Z","iopub.status.idle":"2021-08-26T09:15:41.044025Z","shell.execute_reply.started":"2021-08-26T09:15:40.831019Z","shell.execute_reply":"2021-08-26T09:15:41.04322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_targets, validation_targets = train_features.pop(\"loss\"), validation_features.pop(\"loss\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:41.045598Z","iopub.execute_input":"2021-08-26T09:15:41.045998Z","iopub.status.idle":"2021-08-26T09:15:41.053528Z","shell.execute_reply.started":"2021-08-26T09:15:41.045958Z","shell.execute_reply":"2021-08-26T09:15:41.052681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Scaling","metadata":{}},{"cell_type":"code","source":"should_scale = False\nif should_scale == True:\n    train_features = (train_features - train_mean) / train_std\n    validation_features = (validation_features - train_mean) / train_std\n    test_features = (test - train_mean) / train_std\n    print(test_features.head())\n    print(train_features.head())\n    print(validation_features.head())\nelse:\n    test_features = test_data","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:41.054734Z","iopub.execute_input":"2021-08-26T09:15:41.055148Z","iopub.status.idle":"2021-08-26T09:15:41.065076Z","shell.execute_reply.started":"2021-08-26T09:15:41.055108Z","shell.execute_reply":"2021-08-26T09:15:41.064292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Develpoment","metadata":{}},{"cell_type":"markdown","source":"#### Using Catboost","metadata":{}},{"cell_type":"code","source":"import catboost\nimport time\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nbegin = time.time()\nparameters = {\n    \"depth\": [6, 7, 8],\n    \"learning_rate\": [0.08, 0.1],\n    \"iterations\": [300, 350], \n}\ndef train_catboost(hyperparameters, X_train, X_val, y_train, y_val):\n    keys = hyperparameters.keys()\n    best_index = {key:0 for key in keys}\n    best_cat = None\n    best_score = 10e8\n    for (index, key) in enumerate(keys):\n        print(\"Find best parameter for %s\" %(key))\n        items = hyperparameters[key]\n        best_parameter = None\n        temp_best = 10e8\n        for (key_index, item) in enumerate(items):\n            iterations = hyperparameters[\"iterations\"][best_index[\"iterations\"]] if key != \"iterations\" else item\n            learning_rate = hyperparameters[\"learning_rate\"][best_index[\"learning_rate\"]] if key != \"learning_rate\" else item\n            depth = hyperparameters[\"depth\"][best_index[\"depth\"]] if key != \"depth\" else item\n            print(\"Train with iterations: %d learning_rate: %.2f depth:%d\"%(iterations, learning_rate, depth))\n            cat = catboost.CatBoostRegressor(\n                iterations = iterations, \n                learning_rate = learning_rate,\n                depth = depth\n            )\n            cat.fit(X_train, y_train, verbose=False)\n            y_pred = cat.predict(X_val)\n            score = np.sqrt(mean_squared_error(y_val, y_pred))\n            print(\"RMSE: %.2f\"%(score))\n            if score < temp_best:\n                temp_best = score\n                best_index[key] = key_index\n                best_parameter = item\n            if score < best_score:\n                best_score = score\n                best_cat = cat\n        print(\"Best Parameter for %s: \"%(key), best_parameter)\n    best_parameters = {\n        \"iterations\": hyperparameters[\"iterations\"][best_index[\"iterations\"]],\n        \"learning_rate\": hyperparameters[\"learning_rate\"][best_index[\"learning_rate\"]],\n        \"depth\": hyperparameters[\"depth\"][best_index[\"depth\"]]\n    }\n    return best_cat, best_score, best_parameters\nbest_cat, best_score, best_parameters = train_catboost(parameters, train_features, validation_features, train_targets, validation_targets)\nprint(\"Best CatBoost Model: \", best_cat)\nprint(\"Best MAE: \", best_score)\nelapsed = time.time() - begin \nprint(\"Elapsed time: \", elapsed)\nsubmit(best_cat, test_features, test_ids, \"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:15:41.066495Z","iopub.execute_input":"2021-08-26T09:15:41.066877Z","iopub.status.idle":"2021-08-26T09:18:19.61045Z","shell.execute_reply.started":"2021-08-26T09:15:41.066824Z","shell.execute_reply":"2021-08-26T09:18:19.60944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfold = 1\nfor train_indices, val_indices in KFold(n_splits=5, shuffle=True).split(train_data):\n    print(\"Training with Fold %d\"%(fold))\n    X_train = train_data.iloc[train_indices]\n    X_val = train_data.iloc[val_indices]\n    y_train = X_train.pop(\"loss\")\n    y_val = X_val.pop(\"loss\")\n    if should_scale:\n        X_train = (X_train - train_mean) / train_std\n        X_val = (X_val - train_mean) / train_std\n    cat = catboost.CatBoostRegressor(\n        iterations = best_parameters[\"iterations\"], \n        learning_rate = best_parameters[\"learning_rate\"],\n        depth = best_parameters[\"depth\"]\n    )\n    cat.fit(X_train, y_train, verbose=False)\n    y_pred = cat.predict(X_val)\n    score = np.sqrt(mean_squared_error(y_val, y_pred))\n    print(\"RMSE: %.2f\"%(score))\n    submit(cat, test_features, test_ids, \"submission_fold%d.csv\"%(fold))\n    fold += 1","metadata":{"execution":{"iopub.status.busy":"2021-08-26T09:18:19.611952Z","iopub.execute_input":"2021-08-26T09:18:19.612351Z","iopub.status.idle":"2021-08-26T09:20:27.314844Z","shell.execute_reply.started":"2021-08-26T09:18:19.612301Z","shell.execute_reply":"2021-08-26T09:20:27.314037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Thank You**","metadata":{}}]}