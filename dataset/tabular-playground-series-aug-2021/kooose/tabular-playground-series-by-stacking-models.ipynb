{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport os, time  \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom typing import Tuple, List, Union, Dict \n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.manifold import TSNE\nimport umap \nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding\nfrom sklearn.metrics import log_loss, accuracy_score\n\nfrom tensorflow.keras.layers import Dense, Dropout \nfrom tensorflow.keras.models import Sequential\nimport warnings \n\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:41:03.169566Z","iopub.execute_input":"2021-09-23T06:41:03.169872Z","iopub.status.idle":"2021-09-23T06:41:03.180092Z","shell.execute_reply.started":"2021-09-23T06:41:03.169837Z","shell.execute_reply":"2021-09-23T06:41:03.178795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Procedure method  \n---  \n  \n\n1. KFold \n2. Stacking Layer1 \n3. TSNE \n4. Clustering \n5. Stacking Layer2  \n6. submit ","metadata":{}},{"cell_type":"code","source":"### ---> production dataset \ntrain = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\")\n\n### ----> debug dataset \n# train = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\", nrows=1000)\n# test = pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\", nrows=1000)\ntrain.drop(\"id\", axis=1, inplace=True)\ntest.drop(\"id\", axis=1, inplace=True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:36:06.248208Z","iopub.execute_input":"2021-09-23T06:36:06.248855Z","iopub.status.idle":"2021-09-23T06:36:55.529045Z","shell.execute_reply.started":"2021-09-23T06:36:06.248813Z","shell.execute_reply":"2021-09-23T06:36:55.528163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:37:04.71768Z","iopub.execute_input":"2021-09-23T06:37:04.718003Z","iopub.status.idle":"2021-09-23T06:37:04.749257Z","shell.execute_reply.started":"2021-09-23T06:37:04.717969Z","shell.execute_reply":"2021-09-23T06:37:04.748194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.pie(x = train.claim.value_counts().values, labels=[0, 1],\n        counterclock=90, startangle=False, autopct=\"%1.1f%%\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:37:06.244349Z","iopub.execute_input":"2021-09-23T06:37:06.244698Z","iopub.status.idle":"2021-09-23T06:37:06.378983Z","shell.execute_reply.started":"2021-09-23T06:37:06.244665Z","shell.execute_reply":"2021-09-23T06:37:06.378366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:37:08.525836Z","iopub.execute_input":"2021-09-23T06:37:08.526746Z","iopub.status.idle":"2021-09-23T06:37:08.780514Z","shell.execute_reply.started":"2021-09-23T06:37:08.526687Z","shell.execute_reply":"2021-09-23T06:37:08.779629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"is_nan = train.isnull().sum(axis=1)\ndf_is_nan = pd.DataFrame({\"nan_cnt\": is_nan.values, \"claim\": train.claim}, index=is_nan.index)\ndf_is_nan.groupby(\"claim\").mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:37:08.929533Z","iopub.execute_input":"2021-09-23T06:37:08.929826Z","iopub.status.idle":"2021-09-23T06:37:09.325758Z","shell.execute_reply.started":"2021-09-23T06:37:08.929797Z","shell.execute_reply":"2021-09-23T06:37:09.324428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"is_nan\"] = train.isnull().sum(axis=1)\ntest[\"is_nan\"] = test.isnull().sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:37:22.618222Z","iopub.execute_input":"2021-09-23T06:37:22.619038Z","iopub.status.idle":"2021-09-23T06:37:23.049442Z","shell.execute_reply.started":"2021-09-23T06:37:22.618991Z","shell.execute_reply":"2021-09-23T06:37:23.048155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fill values ","metadata":{}},{"cell_type":"code","source":"cols = train.drop([\"claim\"], axis=1).columns \nfor col in cols:\n    train[col] = train[col].fillna(train[col].mean())\n    test[col] = test[col].fillna(train[col].mean())","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:38:08.126051Z","iopub.execute_input":"2021-09-23T06:38:08.126711Z","iopub.status.idle":"2021-09-23T06:38:10.37947Z","shell.execute_reply.started":"2021-09-23T06:38:08.126657Z","shell.execute_reply":"2021-09-23T06:38:10.377972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA ","metadata":{}},{"cell_type":"code","source":"s = MinMaxScaler()\ntrain_s = s.fit_transform(train.drop(\"claim\", axis=1))\ntest_s = s.transform(test)\n\npca = PCA(n_components=65, random_state=42) # explained ratio over 80.0%\npca_tr = pca.fit_transform(train_s)\npca_te = pca.transform(test_s)\n\nplt.figure(figsize=(12, 6))\nplt.plot(pca.explained_variance_ratio_.cumsum())\nplt.xticks(np.arange(65).tolist())\nplt.xlabel(\"n_components\")\nplt.ylabel(\"explained_variance_ratio_\")\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:38:29.061108Z","iopub.execute_input":"2021-09-23T06:38:29.061459Z","iopub.status.idle":"2021-09-23T06:38:59.884775Z","shell.execute_reply.started":"2021-09-23T06:38:29.061427Z","shell.execute_reply":"2021-09-23T06:38:59.883718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train.claim.to_list()\ntrain = pd.DataFrame(pca_tr, index=train.index, columns=[f\"c{c}\" for c in range(65)])\ntrain[\"claim\"] = y \ntest = pd.DataFrame(pca_te, index=test.index, columns=[f\"c{c}\" for c in range(65)])\n\ndel pca_tr, pca_te \ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:39:06.281601Z","iopub.execute_input":"2021-09-23T06:39:06.281957Z","iopub.status.idle":"2021-09-23T06:39:06.75531Z","shell.execute_reply.started":"2021-09-23T06:39:06.281918Z","shell.execute_reply":"2021-09-23T06:39:06.754476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, train = train_test_split(train, random_state=42, stratify=train.claim, test_size=0.3)\ntrain.shape ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:41:19.13025Z","iopub.execute_input":"2021-09-23T06:41:19.13055Z","iopub.status.idle":"2021-09-23T06:41:19.136917Z","shell.execute_reply.started":"2021-09-23T06:41:19.130521Z","shell.execute_reply":"2021-09-23T06:41:19.136067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reset_index()\ntrain.drop(\"index\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:42:07.60339Z","iopub.execute_input":"2021-09-23T06:42:07.603834Z","iopub.status.idle":"2021-09-23T06:42:07.660726Z","shell.execute_reply.started":"2021-09-23T06:42:07.603803Z","shell.execute_reply":"2021-09-23T06:42:07.659838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation split ","metadata":{}},{"cell_type":"code","source":"def k_split(train: pd.DataFrame, k=4) -> pd.DataFrame:\n    kf = StratifiedKFold(n_splits=k, random_state=42, shuffle=True)\n    for i, (tr, va) in enumerate(kf.split(train, train.claim)):\n        train.loc[va, \"fold\"] = int(i)\n    train[\"fold\"] = train.fold.astype(np.uint8)\n    return train \n\ntrain = k_split(train)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:42:10.950532Z","iopub.execute_input":"2021-09-23T06:42:10.950973Z","iopub.status.idle":"2021-09-23T06:42:11.019445Z","shell.execute_reply.started":"2021-09-23T06:42:10.950943Z","shell.execute_reply":"2021-09-23T06:42:11.018668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(4):\n    value = train[train.fold == i][\"claim\"].value_counts().values\n    index = train[train.fold == i][\"claim\"].value_counts().index\n    plt.subplot(2, 2, i+1)\n    plt.pie(x=value, labels=index, startangle=90, counterclock=False, autopct=\"%1.1f%%\")\n    plt.title(f\"Fold{i}\")\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:42:16.588846Z","iopub.execute_input":"2021-09-23T06:42:16.589131Z","iopub.status.idle":"2021-09-23T06:42:17.029232Z","shell.execute_reply.started":"2021-09-23T06:42:16.589103Z","shell.execute_reply":"2021-09-23T06:42:17.028272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking_Models","metadata":{}},{"cell_type":"code","source":"def Net():\n    input_size = 65\n    model = Sequential()\n    model.add(Dense(256, activation=\"relu\", input_shape=(input_size, )))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(Dropout(0.2))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    return model \n\ndef model_layers(seed):\n    clfs = []\n    clfs.append((\"XGBClassifier\", Pipeline([\n        (\"XGB\", XGBClassifier(n_jobs=-1, random_state=seed))\n    ])))\n#     clfs.append((\"SVC\", Pipeline([\n#         (\"SVC\", SVC(random_state=seed))\n#     ]))) \n    clfs.append((\"DecisionTreeClassifier\", Pipeline([\n        (\"DecisionTreeClassifier\", DecisionTreeClassifier(random_state=seed))\n    ]))) \n    clfs.append((\"RandomForestClassifier\", Pipeline([\n        (\"RandomForestClassifier\", RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=seed))\n    ]))) \n    clfs.append((\"RidgeClassifier\", Pipeline([\n        (\"RidgeClassifier\", RidgeClassifier(random_state=seed))\n    ]))) \n    clfs.append((\"NN\", Pipeline([\n        (\"NN\", Net())\n    ]))) \n    clfs.append((\"ExtraTreesClassifier\", Pipeline([\n        (\"ExtraTreesClassifier\", ExtraTreesClassifier(n_jobs=-1, random_state=seed))\n    ])))\n    clfs.append((\"BaggingRidgeClassifier\",Pipeline([\n        (\"BaggingClassifier\", BaggingClassifier(n_jobs=-1, random_state=42))\n    ])))\n    return clfs \n\n\n'''\nLayer1:\n\npredict validation -> Next train dataset \npredict test -> mean test \n'''\n\nclass Layer1():\n    def __init__(self, seed=42):\n        self.models = model_layers(seed)\n        \n    def train(self, train, test) -> Tuple[pd.DataFrame, pd.DataFrame]:\n        df_train, df_test = pd.DataFrame(), pd.DataFrame()\n        fold_list = train[\"fold\"].to_list()\n        for name, model in self.models:\n            train_ = train.copy()\n            test_ = test.copy()\n            predict_val, predict_test, val_index = [], [], []\n            for fold in range(4):\n                x_tr, x_va = train_[train_.fold != fold], train_[train_.fold == fold]\n                x_train, y_train = x_tr.drop([\"claim\", \"fold\"], axis=1), x_tr[[\"claim\"]]\n                x_val, y_val = x_va.drop([\"claim\", \"fold\"], axis=1), x_va[[\"claim\"]]\n                x_train, x_val, x_test = self._transform(x_train, x_val, test_)\n                \n                pred_val, va_idx, pred_test = self._predict_cv(model, \n                                                               x_train,\n                                                               y_train,\n                                                               x_val, \n                                                               y_val,\n                                                               x_test,\n                                                               name)\n                self._logs(pred_val, y_val, fold, name)\n                predict_val.append(pred_val)\n                predict_test.append(pred_test)\n                val_index.append(va_idx)\n            # concat predict valid \n            # mean predict test-data \n            va_idxs = np.concatenate(val_index)\n            preds = np.concatenate(predict_val, axis=0)\n            order = np.argsort(va_idxs)\n            pred_train = preds[order] # Next train-dataset \n            pred_test = np.mean(predict_test, axis=0) # Next test-dataset \n            \n            df_train[f\"{name}_feature\"] = pred_train \n            df_test[f\"{name}_feature\"] = pred_test \n        df_train[\"fold\"] = fold_list\n        df_train[\"claim\"] = train[\"claim\"].values.ravel()\n        del pred_train, pred_test, x_train, x_val, y_train, y_val \n        return df_train, df_test \n    \n    def _logs(self, pred_val, y_val, fold, name):\n        loss = log_loss(pred_val, y_val.values.ravel())\n        accuracy = accuracy_score(pred_val.ravel(), y_val.values.ravel())\n        print(\n            f\"Model: {name} | Fold: {fold} | Loss: {loss:.5f} | Accuracy: {accuracy:.5f}\"\n        )\n            \n    def _predict_cv(self, model, x_train, y_train, x_val, y_val, test, name):\n        model.fit(x_train, y_train)\n        pred_val = model.predict(x_val)\n        if name == \"NN\":\n            pred_val = np.where(pred_val >= 0.5, 1, 0)\n        pred_test = model.predict(test)\n        if name == \"NN\":\n            pred_test = np.where(pred_test >= 0.5, 1, 0)\n        va_idx = x_val.index \n        return pred_val, va_idx, pred_test\n        \n    def _transform(self, train, val, test) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n        '''StandardScaler train/val/test '''\n        col = train.columns\n        tr_idx, va_idx, te_idx = train.index, val.index, test.index \n        s = StandardScaler()\n        train = s.fit_transform(train)\n        val = s.transform(val)\n        test = s.transform(test)\n        train = pd.DataFrame(train, columns=col, index=tr_idx)\n        val = pd.DataFrame(val, columns=col, index=va_idx)\n        test = pd.DataFrame(test, columns=col, index=te_idx)\n        return train, val, test \n    \n'''\nLayer2:\nparamter chunning \n'''    \n\nclass Layer2():\n    def __init__(self):\n        self.param = {\n            \"max_depth\": [1, 3, 5, 8, 10],\n            \"colsample_bytree\": [1, 3, 5, 8, 10],\n            \"eta\": [0.001, 0.01, 0.1, 1.0, 10.0]\n        }\n    \n    def fit(self, train):\n        train_ = train.copy()\n        predict_proba = []\n        for fold in range(4):\n            start = time.time()\n            tr, va = train_[train_.fold != fold], train_[train_.fold == fold]\n            x_train, x_val = tr.drop([\"fold\", \"claim\"], axis=1), va.drop([\"fold\", \"claim\"], axis=1)\n            y_train, y_val = tr[[\"claim\"]], va[[\"claim\"]]\n            \n            grid = GridSearchCV(XGBClassifier(random_state=42, silent=1),\n                                param_grid=self.param,\n                                cv=2).fit(x_train, y_train)\n            model = XGBClassifier(random_state=42,\n                                  silent=1, \n                                  **grid.best_params_,\n                                  eval_set=[(x_train, y_train), (x_val, y_val)], \n                                  early_stopping_rounds=30).fit(x_train, y_train)\n            pred_val = model.predict(x_val)\n            proba = model.predict_proba(x_val)[:, 1]\n            predict_proba.append(proba)\n            self._logs(pred_val, y_val, fold, start)\n            self._save(model, fold)\n        predict_proba = np.concatenate(predict_proba, axis=0)\n        del model, x_train, x_val, y_train, y_val, proba \n        return predict_proba \n            \n    def _logs(self, pred_val, y_val, fold, start):\n        loss = log_loss(pred_val, y_val.values.ravel())\n        accuracy = accuracy_score(pred_val, y_val.values.ravel())\n        print(\n            f\"Fold: {fold} | Loss: {loss:.5f} | Accuracy: {accuracy:.5f}|\"\n        )\n        \n    def _save(self, model, fold):\n        os.makedirs(\"models\", exist_ok=True)\n        model.save_model(f\"models/xgb{str(fold)}.model\")\n        print(\"successfully checkpoint model\")\n            \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:42:32.389793Z","iopub.execute_input":"2021-09-23T06:42:32.390213Z","iopub.status.idle":"2021-09-23T06:42:32.433281Z","shell.execute_reply.started":"2021-09-23T06:42:32.390184Z","shell.execute_reply":"2021-09-23T06:42:32.432327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_first = Layer1()\nlayer_second = Layer2()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:43:05.058091Z","iopub.execute_input":"2021-09-23T06:43:05.058397Z","iopub.status.idle":"2021-09-23T06:43:05.19947Z","shell.execute_reply.started":"2021-09-23T06:43:05.058346Z","shell.execute_reply":"2021-09-23T06:43:05.198521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Layer1","metadata":{}},{"cell_type":"code","source":"df_train, df_test = layer_first.train(train, test)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T06:43:06.808037Z","iopub.execute_input":"2021-09-23T06:43:06.808369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_col = df_train.drop([\"fold\", \"claim\"], axis=1).columns \ndf_test = df_test[tr_col]\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clustering","metadata":{}},{"cell_type":"code","source":"pca = TSNE(n_components=2, random_state=42)\npca_tr, pca_te = pca.fit_transform(df_train.drop([\"claim\", \"fold\"], axis=1)), pca.fit_transform(df_test)\n\ny = df_train[\"claim\"]\nplt.scatter(x=pca_tr[:, 0][y==0], y=pca_tr[:, 1][y==0], c=\"b\")\nplt.scatter(x=pca_tr[:, 0][y==1], y=pca_tr[:, 1][y==1], c=\"r\")\nplt.title(\"TSNE vs claim\")\nplt.grid()\nplt.legend([\"0\", \"1\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"km = KMeans(n_clusters=2, random_state=42)\ntr_cluster = km.fit_predict(pca_tr)\nte_cluster = km.predict(pca_te)\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\nax = axes.ravel()\nfor i in range(2):\n    ax[i].scatter(pca_tr[:, 0][tr_cluster == i], pca_tr[:, 1][tr_cluster == i], c=\"b\" if i == 0 else \"r\", alpha=0.8)\n    ax[i].scatter(pca_tr[:, 0], pca_tr[:, 1], c=(0, 0, 0), alpha=0.1)\n    ax[i].set_title(f\"clsuter{i+1}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"cluster\"] = tr_cluster \ndf_test[\"cluster\"] = te_cluster ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[[\"cluster\", \"claim\"]].corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Layer2","metadata":{}},{"cell_type":"code","source":"predict = layer_second.fit(df_train) # return predict proba ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(predict)\nplt.title(\"Train\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit ","metadata":{}},{"cell_type":"code","source":"def submittion(test):\n    model = XGBClassifier(random_state=42)\n    root_path = \"models\"\n    filename = os.listdir(root_path)\n    predict = []\n    for fold in range(4):\n        model.load_model(os.path.join(root_path, filename[fold]))\n        pred = model.predict_proba(test)[:, 1]\n        predict.append(pred.ravel())\n    predict = np.mean(np.array(predict), axis=0)\n    \n    try:\n        sub = pd.read_csv(\"../input/tabular-playground-series-sep-2021/sample_solution.csv\")\n        sub[\"claim\"] = predict \n        sub.to_csv(\"submit.csv\", index=False)\n    finally:\n        del model \n        return predict \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = submittion(df_test)\n\nsns.histplot(predict)\nplt.title(\"Test\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}