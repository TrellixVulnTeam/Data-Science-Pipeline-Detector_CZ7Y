{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T13:11:05.916275Z","iopub.execute_input":"2021-08-01T13:11:05.916701Z","iopub.status.idle":"2021-08-01T13:11:05.928125Z","shell.execute_reply.started":"2021-08-01T13:11:05.916666Z","shell.execute_reply":"2021-08-01T13:11:05.926632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Table of Contents\n<a id = \"table-of-contents\"></a>\n- [Preparations](#0)\n    [1 Importing Necessary Libraries](#0.1)\n    [2 Loading The Dataset](#0.2)\n- [1 Dataset Overview](#1)\n    - [1.1 Size of Dataset. Features, Target column.](#1.1)\n    - [1.2 Brief look at Dataset](#1.2)\n    - [1.3 Distribution of Target Column](#1.3)\n    - [1.4 Unique Values in Each Column](#1.4)\n- [2 Variable Analysis](#2)\n    - [2.1 Distribution: Train Vs Test](#2.1)\n    - [2.2 Corelation Analysis](#2.2)\n- [3 Baseline Models](#3)\n    - [3.1 Preprocessing](#3.1)\n    - [3.2 Model Building](#3.1)\n    - [3.3 Leaderboard Submission](#3.2)","metadata":{}},{"cell_type":"markdown","source":"\n<a id=\"0\"></a>\n# Preparations\n\n<a id=\"0.1\"></a>\n### Importing Necessary Libraries","metadata":{}},{"cell_type":"code","source":"# Data Handling\nimport pandas as pd\npd.set_option('display.max_columns', 150)\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='dark')\n\n# Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\n\n# Preprocessing\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Evaluation\nfrom sklearn.metrics import mean_squared_error\n\nseed = 1999","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:11:07.019306Z","iopub.execute_input":"2021-08-01T13:11:07.019991Z","iopub.status.idle":"2021-08-01T13:11:07.029093Z","shell.execute_reply.started":"2021-08-01T13:11:07.019947Z","shell.execute_reply":"2021-08-01T13:11:07.027781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"0.2\"></a>\n### Loading The Dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-aug-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-aug-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-aug-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:11:07.994603Z","iopub.execute_input":"2021-08-01T13:11:07.995065Z","iopub.status.idle":"2021-08-01T13:11:16.61154Z","shell.execute_reply.started":"2021-08-01T13:11:07.995011Z","shell.execute_reply":"2021-08-01T13:11:16.610236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n[back to top](#table-of-contents)\n<a id=\"1\"></a>\n# Dataset Overview\n\n\n<a id=\"1.1\"></a>\n### 1.1 Size of Dataset. Features, Target column. ","metadata":{}},{"cell_type":"code","source":"print(f\"Shape of Train is : {train.shape}\")\nprint(f\"Shape of Test is : {test.shape}\")\nprint(f\"Shape of sample_submission is : {sample_submission.shape}\")\n\ntarget = 'loss'\nid_col = 'id'\nfeatures = [col for col in train.columns if col not in [id_col, target]]\n\nprint(f\"\\nThe Dataset have total {len(features)} features\")","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:11:16.613586Z","iopub.execute_input":"2021-08-01T13:11:16.613973Z","iopub.status.idle":"2021-08-01T13:11:16.622834Z","shell.execute_reply.started":"2021-08-01T13:11:16.613935Z","shell.execute_reply":"2021-08-01T13:11:16.621502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.2\"></a>\n### 1.2 Brief look at Dataset","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:11:16.62489Z","iopub.execute_input":"2021-08-01T13:11:16.625291Z","iopub.status.idle":"2021-08-01T13:11:16.737517Z","shell.execute_reply.started":"2021-08-01T13:11:16.62525Z","shell.execute_reply":"2021-08-01T13:11:16.736131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe().T.style","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-01T13:11:16.739393Z","iopub.execute_input":"2021-08-01T13:11:16.739757Z","iopub.status.idle":"2021-08-01T13:11:18.278742Z","shell.execute_reply.started":"2021-08-01T13:11:16.739719Z","shell.execute_reply":"2021-08-01T13:11:18.277434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.3\"></a>\n### 1.3 Distribution of Target Column","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(2, 1, figsize = (20, 10))\naxx = ax.flatten()\n\nsns.kdeplot(data = train, x = target, ax = axx[0], color = 'Blue', fill=True)\nsns.boxplot(data = train, x = target, ax = axx[1], color = 'Blue')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:11:18.280289Z","iopub.execute_input":"2021-08-01T13:11:18.280636Z","iopub.status.idle":"2021-08-01T13:11:20.149471Z","shell.execute_reply.started":"2021-08-01T13:11:18.280601Z","shell.execute_reply":"2021-08-01T13:11:20.14788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations:\n1. Target Variable is Highly Right Skewed.\n2. Most of the losses are in between 0 to 10.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1.4\"></a>\n### 1.4 Unique Values in Each Column","metadata":{}},{"cell_type":"code","source":"df = pd.concat((train.nunique(), test.nunique()), axis = 1)\ndf.rename(columns={0: \"Train\", 1: \"Test\"}, inplace=True)\ndf = df.T\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:12:10.927456Z","iopub.execute_input":"2021-08-01T13:12:10.928049Z","iopub.status.idle":"2021-08-01T13:12:15.665381Z","shell.execute_reply.started":"2021-08-01T13:12:10.927988Z","shell.execute_reply":"2021-08-01T13:12:15.664009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n[back to top](#table-of-contents)\n<a id=\"2\"></a>\n# Variable Analysis\n\n<a id=\"2.1\"></a>\n### 2.1 Distribution: Train Vs Test","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:51:34.656465Z","iopub.execute_input":"2021-08-01T11:51:34.656879Z","iopub.status.idle":"2021-08-01T11:51:34.662574Z","shell.execute_reply.started":"2021-08-01T11:51:34.656846Z","shell.execute_reply":"2021-08-01T11:51:34.661488Z"}}},{"cell_type":"code","source":"f, ax = plt.subplots(10, 20, figsize = (120, 60))\naxx = ax.flatten()\n\nindex = 0\n\nfor col in features:\n    sns.kdeplot(data = train, x = col, ax = axx[index], color = 'Blue', fill = True)\n    axx[index].set_title(f'Train {col}', loc = 'right', weight = 'bold', fontsize = 12)\n    index+=1\n    sns.kdeplot(data = test, x = col, ax = axx[index], color = 'Red', fill = True)\n    axx[index].set_title(f'Test {col}', loc = 'right', weight = 'bold', fontsize = 12)\n    index+=1","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:12:38.394903Z","iopub.execute_input":"2021-08-01T13:12:38.39537Z","iopub.status.idle":"2021-08-01T13:16:58.037129Z","shell.execute_reply.started":"2021-08-01T13:12:38.395331Z","shell.execute_reply":"2021-08-01T13:16:58.035982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2.2\"></a>\n### 2.2 Corelation Analysis","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14 , 14))\n\ncorr = train.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, square=True, mask = mask, cmap='coolwarm_r', annot_kws={'size':20}) ","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:18:21.13988Z","iopub.execute_input":"2021-08-01T13:18:21.140415Z","iopub.status.idle":"2021-08-01T13:18:31.224132Z","shell.execute_reply.started":"2021-08-01T13:18:21.14037Z","shell.execute_reply":"2021-08-01T13:18:31.222902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n[back to top](#table-of-contents)\n<a id=\"3\"></a>\n# Baseline Models\n\n<a id=\"3.1\"></a>\n### 3.1 Preprocessing\n\n**1. Since our Target Column is Right Skewed, We will do Log Transformation.**\n\n    Note: Do not forget to convert predicted values to normal form when using log transformations on target variable.","metadata":{"execution":{"iopub.status.busy":"2021-08-01T12:22:45.421606Z","iopub.execute_input":"2021-08-01T12:22:45.422062Z","iopub.status.idle":"2021-08-01T12:22:45.428944Z","shell.execute_reply.started":"2021-08-01T12:22:45.422028Z","shell.execute_reply":"2021-08-01T12:22:45.427389Z"}}},{"cell_type":"code","source":"train[target] = train[target]+1\ntrain[target] = np.log(train[target])","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:18:35.229346Z","iopub.execute_input":"2021-08-01T13:18:35.229837Z","iopub.status.idle":"2021-08-01T13:18:35.25539Z","shell.execute_reply.started":"2021-08-01T13:18:35.229794Z","shell.execute_reply":"2021-08-01T13:18:35.254028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train[features], train[target], test_size = 0.25, random_state = seed)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:18:35.726402Z","iopub.execute_input":"2021-08-01T13:18:35.726887Z","iopub.status.idle":"2021-08-01T13:18:36.459948Z","shell.execute_reply.started":"2021-08-01T13:18:35.726843Z","shell.execute_reply":"2021-08-01T13:18:36.458655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3.2\"></a>\n### 3.2 Model Building","metadata":{}},{"cell_type":"code","source":"model_dict = {}\n\nmodel_dict['Linear Regression'] = LinearRegression()\nmodel_dict['DecisionTree Regressor'] = DecisionTreeRegressor(random_state = seed)\nmodel_dict['LGBM Regressor'] = LGBMRegressor(random_state = seed)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:18:37.78943Z","iopub.execute_input":"2021-08-01T13:18:37.789906Z","iopub.status.idle":"2021-08-01T13:18:37.796506Z","shell.execute_reply.started":"2021-08-01T13:18:37.789867Z","shell.execute_reply":"2021-08-01T13:18:37.795203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_evaluation(X_trn, X_val, y_trn, y_val, model, model_name):\n    model.fit(X_trn,y_trn)\n    y_pred = model.predict(X_val)\n    y_pred = np.exp(y_pred)-1\n    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n    print('======================================{}======================================='.format(model_name))\n    print('RMSE is : {}'.format(RMSE))\n    print()\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:18:38.762371Z","iopub.execute_input":"2021-08-01T13:18:38.762826Z","iopub.status.idle":"2021-08-01T13:18:38.769542Z","shell.execute_reply.started":"2021-08-01T13:18:38.762791Z","shell.execute_reply":"2021-08-01T13:18:38.768609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor model_name,model in model_dict.items():\n    model_evaluation(X_train, X_test, y_train, y_test, model, model_name)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:18:40.973596Z","iopub.execute_input":"2021-08-01T13:18:40.974321Z","iopub.status.idle":"2021-08-01T13:20:02.771121Z","shell.execute_reply.started":"2021-08-01T13:18:40.974277Z","shell.execute_reply":"2021-08-01T13:20:02.770147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Because of the limitation of computational power i've only evaluated 3 models. You can evaluate as mony models as you want.** ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3.3\"></a>\n### 3.3 Leaderboard Submission\n\n**I am going to Use LGBMRegressor to make a submission**","metadata":{}},{"cell_type":"code","source":"%%time\nmodel = LGBMRegressor(random_state = seed)\nmodel.fit(train[features], train[target])\n\npreds = model.predict(test[features])\npreds = np.exp(preds) + 1\n\nsample_submission[target] = preds\nsample_submission.to_csv('sub1.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T13:20:57.417132Z","iopub.execute_input":"2021-08-01T13:20:57.417572Z","iopub.status.idle":"2021-08-01T13:21:10.730937Z","shell.execute_reply.started":"2021-08-01T13:20:57.417536Z","shell.execute_reply":"2021-08-01T13:21:10.729627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Please Do Upvote If You Like The Notebook. And Feel free to give suggestions about improving my work. Thank You. \n\n# Stay Tuned For Advance Model Building","metadata":{}}]}