{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<big>For classical machine learning algorithms, we often use the most popular Python library, Scikit-learn. With Scikit-learn you can fit models and search for optimal parameters, but it sometimes works for hours.</big><br><br>\n​\n<big>I want to show you how to use Scikit-learn library and get the results faster without changing the code. To do this, we will make use of another Python library, <strong> <a href='https://github.com/intel/scikit-learn-intelex'>Intel® Extension for Scikit-learn*</a></strong>.</big><br><br>\n​\n<big>I will show you how to <strong>speed up your kernel more than 4 times</strong> without changing your code!</big><big>","metadata":{}},{"cell_type":"markdown","source":"<big>Import libraries</big>","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:41:29.304806Z","iopub.execute_input":"2021-08-18T11:41:29.305136Z","iopub.status.idle":"2021-08-18T11:41:30.096096Z","shell.execute_reply.started":"2021-08-18T11:41:29.305106Z","shell.execute_reply":"2021-08-18T11:41:30.095399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"<big>Importing data</big>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-aug-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-aug-2021/test.csv')\nsample_sub = pd.read_csv('../input/tabular-playground-series-aug-2021/sample_submission.csv')\npseudo = pd.read_csv('../input/blending-tool-tps-aug-2021/file1_7.85192_file2_7.85192_blend.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:41:50.368052Z","iopub.execute_input":"2021-08-18T11:41:50.368567Z","iopub.status.idle":"2021-08-18T11:41:56.851142Z","shell.execute_reply.started":"2021-08-18T11:41:50.368533Z","shell.execute_reply":"2021-08-18T11:41:56.850462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big><strong>Pseudodating</strong></big><br><br>\n<big>I took the previously predicted labels and added them to the test dataset.</big>","metadata":{}},{"cell_type":"code","source":"test['loss'] = pseudo['loss']","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:41:56.852203Z","iopub.execute_input":"2021-08-18T11:41:56.852608Z","iopub.status.idle":"2021-08-18T11:41:56.85715Z","shell.execute_reply.started":"2021-08-18T11:41:56.852579Z","shell.execute_reply":"2021-08-18T11:41:56.856504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Let's look at the test and train sets.</big>","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:41:40.488119Z","iopub.execute_input":"2021-08-18T11:41:40.488438Z","iopub.status.idle":"2021-08-18T11:41:40.533267Z","shell.execute_reply.started":"2021-08-18T11:41:40.488406Z","shell.execute_reply":"2021-08-18T11:41:40.532394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:41:40.534608Z","iopub.execute_input":"2021-08-18T11:41:40.534874Z","iopub.status.idle":"2021-08-18T11:41:40.561709Z","shell.execute_reply.started":"2021-08-18T11:41:40.534849Z","shell.execute_reply":"2021-08-18T11:41:40.560807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape, train.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:41:40.563001Z","iopub.execute_input":"2021-08-18T11:41:40.563256Z","iopub.status.idle":"2021-08-18T11:41:40.57003Z","shell.execute_reply.started":"2021-08-18T11:41:40.563231Z","shell.execute_reply":"2021-08-18T11:41:40.568916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Drop 'id' field</big>","metadata":{}},{"cell_type":"code","source":"train.drop(['id'], axis=1, inplace=True)\ntest.drop(['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:41:56.858411Z","iopub.execute_input":"2021-08-18T11:41:56.858843Z","iopub.status.idle":"2021-08-18T11:41:57.064231Z","shell.execute_reply.started":"2021-08-18T11:41:56.858815Z","shell.execute_reply":"2021-08-18T11:41:57.063133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>I added features that were obtained as a result of research <code>feature_importances_</code></big>","metadata":{}},{"cell_type":"code","source":"all_data = [train, test]","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:41:58.24313Z","iopub.execute_input":"2021-08-18T11:41:58.243671Z","iopub.status.idle":"2021-08-18T11:41:58.247104Z","shell.execute_reply.started":"2021-08-18T11:41:58.243626Z","shell.execute_reply":"2021-08-18T11:41:58.246464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for df in all_data:\n    df['f77^2/f52^2'] = (df['f77']**2)/(df['f52']**2)\n    df['f74^2/f81^2'] = (df['f74']**2)/(df['f81']**2)\n    df['f77/f69'] = df['f77']/df['f69']\n    df['f81^2/f77^2'] = (df['f81']**2)/(df['f77']**2)\n    df['f96/f28'] = df['f96']/df['f28']\n    df['f96^2/f73^2'] = (df['f96']**2)/(df['f73']**2)\n    df['f78/f28'] = df['f78']/df['f28']\n    df['f73/f28'] = df['f73']/df['f28']\n    df['f66/f69'] = df['f66']/df['f69']\n    df['f46^2/f4^2'] = (df['f46']**2)/(df['f4']**2)\n    df['f4/f75'] = df['f4']/df['f75']\n    df['f69^2/f96^2'] = (df['f69']**2)/(df['f96']**2)\n    df['f25/f69'] = df['f25']/df['f69']\n    df['f78/f69'] = df['f78']/df['f69']\n    df['f96^2/f77^2'] = (df['f96']**2)/(df['f77']**2)\n    df['f4^2/f52^2'] = (df['f4']**2)/(df['f52']**2)\n    df['f66^2/f52^2'] = (df['f66']**2)/(df['f52']**2)\n    df['f4^2/f81^2'] = (df['f4']**2)/(df['f81']**2)\n    df['f46^2/f81^2'] = (df['f46']**2)/(df['f81']**2)\n    df['f47/f69'] = df['f47']/df['f69']\n    df['f74xf70'] = df['f74']*df['f70']\n    df['f46^2/f66^2'] = (df['f46']**2)/(df['f66']**2)\n    df['f74/f47'] = df['f74']/df['f47']\n    df['f96^2xf69^2'] = (df['f96']**2)/(df['f69']**2)\n    df['f66/f46'] = df['f66']/df['f46']\n    df['f25xf96'] = df['f25']*df['f96']\n    df['f28xf81'] = df['f28']*df['f81']\n    df['f52xf66'] = df['f52']*df['f66']\n    df['f46^2xf81^2'] = (df['f46']**2)*(df['f81']**2)\n    df['f46xf74'] = df['f46']*df['f74']\n    df['f28_log'] = np.log2(df['f28'])\n    df['f28xf70'] = df['f28']*df['f70']\n    df['f52_log'] = np.log2(df['f52'])\n    df['f47_log'] = np.log2(df['f47'])\n    df['f66xf73'] = df['f66']*df['f73']\n    df['f69_log'] = np.log2(df['f69'])\n    df['f96/f78'] = df['f96']/df['f78']\n    \n    ","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-18T11:41:59.500279Z","iopub.execute_input":"2021-08-18T11:41:59.500848Z","iopub.status.idle":"2021-08-18T11:41:59.771385Z","shell.execute_reply.started":"2021-08-18T11:41:59.500804Z","shell.execute_reply":"2021-08-18T11:41:59.770409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape, train.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:01.992653Z","iopub.execute_input":"2021-08-18T11:42:01.993013Z","iopub.status.idle":"2021-08-18T11:42:01.999084Z","shell.execute_reply.started":"2021-08-18T11:42:01.992983Z","shell.execute_reply":"2021-08-18T11:42:01.997997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.fillna(0, inplace=True)\ntrain.fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:03.465857Z","iopub.execute_input":"2021-08-18T11:42:03.466335Z","iopub.status.idle":"2021-08-18T11:42:03.876242Z","shell.execute_reply.started":"2021-08-18T11:42:03.466302Z","shell.execute_reply":"2021-08-18T11:42:03.875575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Delete features with low correlation.</big>","metadata":{}},{"cell_type":"code","source":"corr = train.corr()\ncolumns_to_delete = corr[corr.loss<0.001][corr.loss>-0.001].index","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:05.216488Z","iopub.execute_input":"2021-08-18T11:42:05.21699Z","iopub.status.idle":"2021-08-18T11:42:18.135205Z","shell.execute_reply.started":"2021-08-18T11:42:05.216954Z","shell.execute_reply":"2021-08-18T11:42:18.134125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(columns_to_delete, axis=1, inplace=True)\ntest.drop(columns_to_delete, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:18.136584Z","iopub.execute_input":"2021-08-18T11:42:18.136839Z","iopub.status.idle":"2021-08-18T11:42:18.2601Z","shell.execute_reply.started":"2021-08-18T11:42:18.136814Z","shell.execute_reply":"2021-08-18T11:42:18.258936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Concateate train and test sets.</big>","metadata":{}},{"cell_type":"code","source":"full_data = pd.concat([train, test])","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:18.261896Z","iopub.execute_input":"2021-08-18T11:42:18.262204Z","iopub.status.idle":"2021-08-18T11:42:18.539304Z","shell.execute_reply.started":"2021-08-18T11:42:18.262149Z","shell.execute_reply":"2021-08-18T11:42:18.53841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Split the data into 'X' and 'y' </big>","metadata":{}},{"cell_type":"code","source":"X = full_data.drop(['loss'], axis=1)\ny = full_data['loss']\nX_test = test.drop(['loss'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:18.54083Z","iopub.execute_input":"2021-08-18T11:42:18.541093Z","iopub.status.idle":"2021-08-18T11:42:19.017776Z","shell.execute_reply.started":"2021-08-18T11:42:18.541068Z","shell.execute_reply":"2021-08-18T11:42:19.016845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Normalize data.</big>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nscaler_x = MinMaxScaler()\nscaler_y = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:19.019229Z","iopub.execute_input":"2021-08-18T11:42:19.019681Z","iopub.status.idle":"2021-08-18T11:42:19.024823Z","shell.execute_reply.started":"2021-08-18T11:42:19.019639Z","shell.execute_reply":"2021-08-18T11:42:19.023854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler_x.fit(X)\nX = scaler_x.transform(X)\nX_test = scaler_x.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:19.026193Z","iopub.execute_input":"2021-08-18T11:42:19.026812Z","iopub.status.idle":"2021-08-18T11:42:19.834895Z","shell.execute_reply.started":"2021-08-18T11:42:19.026768Z","shell.execute_reply":"2021-08-18T11:42:19.833906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler_y.fit(y.to_numpy().reshape(-1, 1))\ny = scaler_y.transform(y.to_numpy().reshape(-1, 1)).ravel()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:19.836151Z","iopub.execute_input":"2021-08-18T11:42:19.836457Z","iopub.status.idle":"2021-08-18T11:42:19.849639Z","shell.execute_reply.started":"2021-08-18T11:42:19.836417Z","shell.execute_reply":"2021-08-18T11:42:19.848477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Installing Intel(R) Extension for Scikit-learn\n\n<big>Use Intel® Extension for Scikit-learn* for fast compute Scikit-learn estimators.</big>","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn-intelex -q --progress-bar off","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:19.851447Z","iopub.execute_input":"2021-08-18T11:42:19.851763Z","iopub.status.idle":"2021-08-18T11:42:48.26606Z","shell.execute_reply.started":"2021-08-18T11:42:19.851732Z","shell.execute_reply":"2021-08-18T11:42:48.265254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Patch original scikit-learn.</big>","metadata":{}},{"cell_type":"code","source":"from sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:48.267329Z","iopub.execute_input":"2021-08-18T11:42:48.267616Z","iopub.status.idle":"2021-08-18T11:42:48.658596Z","shell.execute_reply.started":"2021-08-18T11:42:48.267587Z","shell.execute_reply":"2021-08-18T11:42:48.657911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train nuSVR model\n<big>Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. The advantage of support vector machines is effective in high dimensional spaces.</big><br><br>\n\n<big>NuSVR similar to SVR, but uses a parameter nu to control the number of support vectors. Nu replaces the parameter epsilon of epsilon-SVR</big><br><br>\n<big>The process of selecting the parameters is too long and computationally intensive, so I selected the parameters in advance.</big><br><br>\n<big>Parameters: </big><br>\n<big>* <code>C</code> -  Parameter inverse to the regularization coefficient.<br></big>\n<big>* <code>nu</code> - An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors..<br><br> </big>","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import NuSVR","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:48.659546Z","iopub.execute_input":"2021-08-18T11:42:48.659933Z","iopub.status.idle":"2021-08-18T11:42:48.663269Z","shell.execute_reply.started":"2021-08-18T11:42:48.659906Z","shell.execute_reply":"2021-08-18T11:42:48.662591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'C': 0.9335786569734156, 'nu': 0.9426690319592885}","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:48.664227Z","iopub.execute_input":"2021-08-18T11:42:48.664685Z","iopub.status.idle":"2021-08-18T11:42:48.678837Z","shell.execute_reply.started":"2021-08-18T11:42:48.664655Z","shell.execute_reply":"2021-08-18T11:42:48.678057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfinal_model = NuSVR(**params).fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T11:42:48.68078Z","iopub.execute_input":"2021-08-18T11:42:48.681305Z","iopub.status.idle":"2021-08-18T14:13:24.497147Z","shell.execute_reply.started":"2021-08-18T11:42:48.681271Z","shell.execute_reply":"2021-08-18T14:13:24.494896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"%%time\ny_pred = final_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T14:13:24.501241Z","iopub.execute_input":"2021-08-18T14:13:24.501641Z","iopub.status.idle":"2021-08-18T14:19:41.115476Z","shell.execute_reply.started":"2021-08-18T14:13:24.501596Z","shell.execute_reply":"2021-08-18T14:19:41.114497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = scaler_y.inverse_transform(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T14:19:41.117014Z","iopub.execute_input":"2021-08-18T14:19:41.117323Z","iopub.status.idle":"2021-08-18T14:19:41.126052Z","shell.execute_reply.started":"2021-08-18T14:19:41.117281Z","shell.execute_reply":"2021-08-18T14:19:41.125137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<big>Save the results in 'submission.csv'.</big>","metadata":{}},{"cell_type":"code","source":"sample_sub['loss'] = y_pred\nsample_sub.to_csv('submission.csv', index=False)\nsample_sub.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T14:19:41.127353Z","iopub.execute_input":"2021-08-18T14:19:41.127661Z","iopub.status.idle":"2021-08-18T14:19:41.501188Z","shell.execute_reply.started":"2021-08-18T14:19:41.127633Z","shell.execute_reply":"2021-08-18T14:19:41.500468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we use the same algorithm with original scikit-learn","metadata":{}},{"cell_type":"markdown","source":"<big>Unfortunately, the original scikit-learn <strong>does not have time to train the model in 9 hours</strong> on the provided data.</big><br>\n<big>On 10% of the total dataset, the patched version is trained in 1 minute 25 seconds, and the stock version in 33 minutes 42 seconds.</big>","metadata":{}},{"cell_type":"code","source":"# from sklearnex import unpatch_sklearn\n# unpatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T10:19:58.467675Z","iopub.execute_input":"2021-08-17T10:19:58.468167Z","iopub.status.idle":"2021-08-17T10:19:58.473887Z","shell.execute_reply.started":"2021-08-17T10:19:58.46812Z","shell.execute_reply":"2021-08-17T10:19:58.472543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.svm import NuSVR","metadata":{"execution":{"iopub.status.busy":"2021-08-17T10:19:58.475713Z","iopub.execute_input":"2021-08-17T10:19:58.476272Z","iopub.status.idle":"2021-08-17T10:19:58.489399Z","shell.execute_reply.started":"2021-08-17T10:19:58.476224Z","shell.execute_reply":"2021-08-17T10:19:58.488068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# final_model = NuSVR(**params).fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:55:23.182005Z","iopub.execute_input":"2021-08-17T17:55:23.182663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusions\n<big>We can see that using only one classical machine learning algorithm may give you a pretty hight accuracy score. We also use well-known libraries Scikit-learn and Optuna, as well as the increasingly popular library Intel® Extension for Scikit-learn. Noted that Intel® Extension for Scikit-learn gives you opportunities to:</big>\n​\n* <big>Use your Scikit-learn code for training and inference without modification.</big>\n* <big>Speed up selection of parameters <strong>from 9+ hours to 2 hours and 30 minutes.</strong></big>\n* <big>Get predictions of the similar quality.</big>\n​","metadata":{}}]}