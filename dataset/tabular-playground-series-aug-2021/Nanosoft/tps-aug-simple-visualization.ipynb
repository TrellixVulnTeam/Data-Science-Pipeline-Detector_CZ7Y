{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ntrain = pd.read_csv('../input/tabular-playground-series-aug-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-aug-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-aug-2021/sample_submission.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-06T01:33:17.18433Z","iopub.execute_input":"2021-08-06T01:33:17.184815Z","iopub.status.idle":"2021-08-06T01:33:25.315539Z","shell.execute_reply.started":"2021-08-06T01:33:17.184779Z","shell.execute_reply":"2021-08-06T01:33:25.314359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reference : https://www.kaggle.com/subinium/tps-aug-simple-eda**","metadata":{}},{"cell_type":"code","source":"discrete_features = []\n\nfor col in train.columns:\n    if np.array_equal(train[col].values, train[col].values.astype(int)):\n        discrete_features.append(col)\n\nprint(f'Total {len(discrete_features)} : ')\nprint(discrete_features)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T01:33:25.317207Z","iopub.execute_input":"2021-08-06T01:33:25.317507Z","iopub.status.idle":"2021-08-06T01:33:25.402637Z","shell.execute_reply.started":"2021-08-06T01:33:25.317479Z","shell.execute_reply":"2021-08-06T01:33:25.401544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nA total of 6 features have no decimal point.\n\n*     f1\n*     f16\n*     f27\n*     f55\n*     f60\n*     f86\n\n","metadata":{}},{"cell_type":"code","source":"f1_loss = train.groupby(['f1'])['loss'].mean().sort_values()\nf16_loss = train.groupby(['f16'])['loss'].mean().sort_values()\nf27_loss = train.groupby(['f27'])['loss'].mean().sort_values()\nf55_loss = train.groupby(['f55'])['loss'].mean().sort_values()\nf60_loss = train.groupby(['f60'])['loss'].mean().sort_values()\nf86_loss = train.groupby(['f86'])['loss'].mean().sort_values()\nprint((f1_loss==0).sum())\nprint((f16_loss==0).sum())\nprint((f27_loss==0).sum())\nprint((f55_loss==0).sum())\nprint((f60_loss==0).sum())\nprint((f86_loss==0).sum())","metadata":{"execution":{"iopub.status.busy":"2021-08-06T01:33:25.405775Z","iopub.execute_input":"2021-08-06T01:33:25.40618Z","iopub.status.idle":"2021-08-06T01:33:25.686196Z","shell.execute_reply.started":"2021-08-06T01:33:25.406148Z","shell.execute_reply":"2021-08-06T01:33:25.685208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n\nax.bar(range(len(f16_loss)), f16_loss, alpha=0.7, color='lightgray', label='Test Dataset')\nax.set_yticks(range(0, 20, 3))\nax.margins(0.01)\nax.grid(axis='y', linestyle='--', zorder=5)\nax.set_title('Average of loss grouped by f16', loc='left', fontweight='bold')\nax.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T01:33:25.6878Z","iopub.execute_input":"2021-08-06T01:33:25.68814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n\nax.bar(range(len(f27_loss)), f27_loss, alpha=0.7, color='lightgray', label='Test Dataset')\nax.set_yticks(range(0, 20, 3))\nax.margins(0.01)\nax.grid(axis='y', linestyle='--', zorder=5)\nax.set_title('Average of loss grouped by f27', loc='left', fontweight='bold')\nax.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n\nax.bar(range(len(f55_loss)), f55_loss, alpha=0.7, color='lightgray', label='Test Dataset')\nax.set_yticks(range(0, 20, 3))\nax.margins(0.01)\nax.grid(axis='y', linestyle='--', zorder=5)\nax.set_title('Average of loss grouped by f55', loc='left', fontweight='bold')\nax.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n\nax.bar(range(len(f60_loss)), f60_loss, alpha=0.7, color='lightgray', label='Test Dataset')\nax.set_yticks(range(0, 20, 3))\nax.margins(0.01)\nax.grid(axis='y', linestyle='--', zorder=5)\nax.set_title('Average of loss grouped by f60', loc='left', fontweight='bold')\nax.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**I decided to consider the loss value.**","metadata":{}},{"cell_type":"code","source":"train2 = train[train<0]\ntrain3 = abs(train2)\ntrain3.sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train4 = train3.sum()\n\nx = np.arange(6)\nids = ['f1', 'f16', 'f27', 'f55', 'f60', 'f86']\nvalues = [530, train4.loc['f16'], train4.loc['f27'], train4.loc['f55'], train4.loc['f60'], train4.loc['f86']]\n\nplt.bar(x, values)\nplt.xticks(x, ids)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**f16 and f60 are big.**","metadata":{}},{"cell_type":"code","source":"x = np.arange(4)\nids = ['f1', 'f27', 'f55', 'f86']\nvalues = [530, train4.loc['f27'], train4.loc['f55'], train4.loc['f86']]\n\nplt.bar(x, values)\nplt.xticks(x, ids)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**f27 is big.**","metadata":{}},{"cell_type":"code","source":"x = np.arange(3)\nids = ['f1', 'f55', 'f86']\nvalues = [530, train4.loc['f55'], train4.loc['f86']]\n\nplt.bar(x, values)\nplt.xticks(x, ids)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**f55 is big.**","metadata":{}},{"cell_type":"markdown","source":"**To be contine**","metadata":{}}]}