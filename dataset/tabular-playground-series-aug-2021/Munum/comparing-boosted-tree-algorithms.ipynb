{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntrain_path = r'../input/tabular-playground-series-aug-2021/train.csv'","metadata":{"execution":{"iopub.status.busy":"2021-08-01T10:34:56.846824Z","iopub.execute_input":"2021-08-01T10:34:56.847829Z","iopub.status.idle":"2021-08-01T10:34:56.858953Z","shell.execute_reply.started":"2021-08-01T10:34:56.847636Z","shell.execute_reply":"2021-08-01T10:34:56.85812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(train_path, index_col=0)\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-08-01T10:34:56.860554Z","iopub.execute_input":"2021-08-01T10:34:56.860924Z","iopub.status.idle":"2021-08-01T10:35:03.134993Z","shell.execute_reply.started":"2021-08-01T10:34:56.86087Z","shell.execute_reply":"2021-08-01T10:35:03.13423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.iloc[:, :-1].values\ny = train.iloc[:, -1].values\n\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-01T10:35:03.136915Z","iopub.execute_input":"2021-08-01T10:35:03.137266Z","iopub.status.idle":"2021-08-01T10:35:03.263334Z","shell.execute_reply.started":"2021-08-01T10:35:03.137231Z","shell.execute_reply":"2021-08-01T10:35:03.262358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nrs = 69420\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-08-01T10:35:03.265077Z","iopub.execute_input":"2021-08-01T10:35:03.265475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=10, shuffle=True, random_state=rs)\nmodels = []\nscores = []\ni = 0\n\nfor train_index, test_index in kf.split(X):\n    i += 1\n    print('='*25, f\"Training Fold {i}\", '='*25)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    # Remove tree method, single precision and deterministic parameters if you do not have a GPU\n    clf = XGBRegressor(tree_method='gpu_hist',\n                       single_precision_histogram=True,\n                       deterministic_histogram=False,\n                       random_state=rs)\n    \n    clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=False)\n    \n    y_pred = clf.predict(X_test)\n    \n    mse = mean_squared_error(y_test, y_pred, squared=False)\n    \n    scores.append(mse)\n    models.append(clf)\n    print(f\"Fold {i} RMSE: {mse}\")\n\nprint(f\"Mean RMSE: {round(np.mean(scores), 5)}\")","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(scores)\nplt.title(\"RMSE Per Fold for XGBoost\")\nplt.xlabel(\"Fold\")\nplt.ylabel(\"RMSE\")\nplt.show()\n\nprint(f\"Mean RMSE: {round(np.mean(scores), 5)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lightgbm","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nrs = 69420\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=10, shuffle=True, random_state=rs)\nmodels = []\nscores = []\ni = 0\n\nfor train_index, test_index in kf.split(X):\n    i += 1\n    print('='*25, f\"Training Fold {i}\", '='*25)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    # device parameters if you do not have a GPU\n    clf = LGBMRegressor(device='gpu',\n                        random_state=rs)\n    \n    clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=False)\n    \n    y_pred = clf.predict(X_test)\n    \n    mse = mean_squared_error(y_test, y_pred, squared=False)\n    \n    scores.append(mse)\n    models.append(clf)\n    print(f\"Fold {i} RMSE: {mse}\")\n\nprint(f\"Mean RMSE: {round(np.mean(scores), 5)}\")","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(scores)\nplt.title(\"RMSE Per Fold for Lightgbm\")\nplt.xlabel(\"Fold\")\nplt.ylabel(\"RMSE\")\nplt.show()\n\nprint(f\"Mean RMSE: {round(np.mean(scores), 5)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Catboost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nrs = 69420\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=10, shuffle=True, random_state=rs)\nmodels = []\nscores = []\ni = 0\n\nfor train_index, test_index in kf.split(X):\n    i += 1\n    print('='*25, f\"Training Fold {i}\", '='*25)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    # remove task_type parameters if you do not have a GPU\n    clf = CatBoostRegressor(task_type='GPU',\n                            random_state=rs)\n    \n    clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=False)\n    \n    y_pred = clf.predict(X_test)\n    \n    mse = mean_squared_error(y_test, y_pred, squared=False)\n    \n    scores.append(mse)\n    models.append(clf)\n    print(f\"Fold {i} RMSE: {mse}\")\n\nprint(f\"Mean RMSE: {round(np.mean(scores), 5)}\")","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(scores)\nplt.title(\"RMSE Per Fold for Catboost\")\nplt.xlabel(\"Fold\")\nplt.ylabel(\"RMSE\")\nplt.show()\n\nprint(f\"Mean RMSE: {round(np.mean(scores), 5)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Scores","metadata":{}},{"cell_type":"markdown","source":"- XGBoost: 7.88824\n- LightGBM: 7.86141\n- Catboost: 7.90038","metadata":{}}]}