{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, I want to remark the usage of subsample hyperparameter.\n\nGenerally, we use subsample or bagging fraction on hyperparameter tuning step.\n\nFor XGBoost and Catboost, we can set subsample to a float number between 0 and 1 to use subsampling. It is enough.\n\nBut, for LightGBM, it is not enough. We have to use subsample_freq additionally.\n\nLet's examine them.","metadata":{}},{"cell_type":"code","source":"import pandas  as pd\nimport numpy as np\n\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\n\nbold = \"\\033[1m\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-19T16:41:20.389579Z","iopub.execute_input":"2021-08-19T16:41:20.390216Z","iopub.status.idle":"2021-08-19T16:41:22.366676Z","shell.execute_reply.started":"2021-08-19T16:41:20.390116Z","shell.execute_reply":"2021-08-19T16:41:22.365406Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-aug-2021/train.csv\")\nprint(bold + \"Training Set :\\n\")\ndisplay(train.head())\nprint(bold + str(train.shape))\n\nprint(bold + \"\\nTest Set :\\n\")\ntest = pd.read_csv(\"../input/tabular-playground-series-aug-2021/test.csv\")\ndisplay(test.head())\nprint(bold + str(test.shape))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:41:22.368439Z","iopub.execute_input":"2021-08-19T16:41:22.36876Z","iopub.status.idle":"2021-08-19T16:41:33.336924Z","shell.execute_reply.started":"2021-08-19T16:41:22.368728Z","shell.execute_reply":"2021-08-19T16:41:33.336214Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = \"loss\"\npredictors = [x for x in train.columns if x not in [\"id\", \"loss\"]]","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:41:33.338348Z","iopub.execute_input":"2021-08-19T16:41:33.338775Z","iopub.status.idle":"2021-08-19T16:41:33.342834Z","shell.execute_reply.started":"2021-08-19T16:41:33.338745Z","shell.execute_reply":"2021-08-19T16:41:33.342037Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train[predictors]\ny = train[target]\ntest = test[predictors]","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:41:33.344731Z","iopub.execute_input":"2021-08-19T16:41:33.345141Z","iopub.status.idle":"2021-08-19T16:41:33.485478Z","shell.execute_reply.started":"2021-08-19T16:41:33.3451Z","shell.execute_reply":"2021-08-19T16:41:33.484511Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:41:33.48887Z","iopub.execute_input":"2021-08-19T16:41:33.489191Z","iopub.status.idle":"2021-08-19T16:41:33.893365Z","shell.execute_reply.started":"2021-08-19T16:41:33.489161Z","shell.execute_reply":"2021-08-19T16:41:33.892272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, make_scorer\n\ndef rmse(y_true, y_pred):\n    return mean_squared_error(y_true, y_pred, squared = False)\n\nrmse_scorer = make_scorer(rmse)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:41:33.895023Z","iopub.execute_input":"2021-08-19T16:41:33.895431Z","iopub.status.idle":"2021-08-19T16:41:33.900509Z","shell.execute_reply.started":"2021-08-19T16:41:33.895386Z","shell.execute_reply":"2021-08-19T16:41:33.899763Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits = 3, shuffle = True, random_state = 42)\n\ndef rmse_cv(model, X, y):    \n    return cross_val_score(model, X, y, scoring = rmse_scorer, cv = kf).mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:04:02.339466Z","iopub.execute_input":"2021-08-19T18:04:02.339924Z","iopub.status.idle":"2021-08-19T18:04:02.345415Z","shell.execute_reply.started":"2021-08-19T18:04:02.339884Z","shell.execute_reply":"2021-08-19T18:04:02.344233Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First one is default lightgbm regressor model.\n\nI just set a random_state for reproducibility, 50 estimator, and high learning rate for faster calculations.\n\nSecond one is default lgbm model with adding subsample.\n\nLet's look at difference","metadata":{}},{"cell_type":"markdown","source":"# LightGBM","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n\nlgb_reg = lgb.LGBMRegressor(random_state = 42, n_jobs = -1, n_estimators = 50, learning_rate = 0.3)\n\nlgb_w_subsample = lgb.LGBMRegressor(random_state = 42, n_jobs = -1, n_estimators = 50, learning_rate = 0.3, subsample = 0.5)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:25:25.508646Z","iopub.execute_input":"2021-08-19T18:25:25.509022Z","iopub.status.idle":"2021-08-19T18:25:35.149557Z","shell.execute_reply.started":"2021-08-19T18:25:25.508976Z","shell.execute_reply":"2021-08-19T18:25:35.148663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(bold + \"RMSE for default LightGBM model: \\t\\t\\t\" + str(rmse_cv(lgb_reg, X_train, y_train)))\n\nprint(bold + \"RMSE for LightGBM model, with setting subsample = 0.5: \\t\" + str(rmse_cv(lgb_w_subsample, X_train, y_train)))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:33:58.013863Z","iopub.execute_input":"2021-08-19T18:33:58.014557Z","iopub.status.idle":"2021-08-19T18:34:17.163621Z","shell.execute_reply.started":"2021-08-19T18:33:58.014513Z","shell.execute_reply":"2021-08-19T18:34:17.162763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Is there a difference? Nope.\n\n**We need to use subsample_freq to enable subsampling.**","metadata":{}},{"cell_type":"code","source":"lgb_w_subsample_freq = lgb.LGBMRegressor(random_state = 42, n_jobs = -1, n_estimators = 100, learning_rate = 0.3, subsample = 0.5, subsample_freq = 1)\n\nrmse_cv(lgb_w_subsample_freq, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:04:48.146454Z","iopub.execute_input":"2021-08-19T18:04:48.146814Z","iopub.status.idle":"2021-08-19T18:05:00.069154Z","shell.execute_reply.started":"2021-08-19T18:04:48.146782Z","shell.execute_reply":"2021-08-19T18:05:00.068236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nice, subsampling works.","metadata":{}},{"cell_type":"markdown","source":"**For XGBoost and Catboost setting subsample to a float number is enough for subsampling.**","metadata":{}},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nxgbreg = xgb.XGBRegressor(random_state = 42, n_jobs = -1, n_estimators = 50, learning_rate = 0.5)\n\nrmse_cv(xgbreg, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:19:10.306205Z","iopub.execute_input":"2021-08-19T18:19:10.306714Z","iopub.status.idle":"2021-08-19T18:22:54.785821Z","shell.execute_reply.started":"2021-08-19T18:19:10.30668Z","shell.execute_reply":"2021-08-19T18:22:54.784832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgbreg_w_subsample = xgb.XGBRegressor(random_state = 42, n_jobs = -1, n_estimators = 50, learning_rate = 0.5, subsample = 0.5)\n\nrmse_cv(xgbreg_w_subsample, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:22:54.790216Z","iopub.execute_input":"2021-08-19T18:22:54.79125Z","iopub.status.idle":"2021-08-19T18:25:25.448095Z","shell.execute_reply.started":"2021-08-19T18:22:54.791188Z","shell.execute_reply":"2021-08-19T18:25:25.447109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 8.02 rmse with default xgboost model. If we set subsample to 0.5, this score will change, we get 8.18 rmse.","metadata":{}},{"cell_type":"markdown","source":"# Catboost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\ncbr = CatBoostRegressor(random_state = 42, thread_count = 4, verbose = 0, iterations = 50, learning_rate = 0.5)\n\nrmse_cv(cbr, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:18:42.332112Z","iopub.execute_input":"2021-08-19T18:18:42.332508Z","iopub.status.idle":"2021-08-19T18:18:51.571306Z","shell.execute_reply.started":"2021-08-19T18:18:42.332472Z","shell.execute_reply":"2021-08-19T18:18:51.570229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cbr_w_subsample = CatBoostRegressor(random_state = 42, thread_count = 4, verbose = 0,  iterations = 50, learning_rate = 0.5, subsample = 0.5)\n\nrmse_cv(cbr_w_subsample, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T18:18:51.572651Z","iopub.execute_input":"2021-08-19T18:18:51.572956Z","iopub.status.idle":"2021-08-19T18:18:59.709937Z","shell.execute_reply.started":"2021-08-19T18:18:51.572913Z","shell.execute_reply":"2021-08-19T18:18:59.708811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Conclusion**\n\n**For using subsampling;**\n\n**LightGBM**: set subsample to a float number and set subsample_freq to a positive integer.\n\n**XGBoost**: set subsample to a float number.\n\n**Catboost**: set subsample to a float number.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}