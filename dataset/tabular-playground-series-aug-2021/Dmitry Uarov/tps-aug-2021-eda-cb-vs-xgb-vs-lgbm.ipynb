{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected = True)\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nfrom sklearn.model_selection import StratifiedKFold, KFold, LeaveOneGroupOut\n\nimport optuna\n\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\n\npd.set_option('display.max_columns', None)\n#########################################################\ntrain = pd.read_csv('../input/tabular-playground-series-aug-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-aug-2021/test.csv')\nss = pd.read_csv('../input/tabular-playground-series-aug-2021/sample_submission.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-02T14:09:53.404897Z","iopub.execute_input":"2021-08-02T14:09:53.405336Z","iopub.status.idle":"2021-08-02T14:10:07.871776Z","shell.execute_reply.started":"2021-08-02T14:09:53.405216Z","shell.execute_reply":"2021-08-02T14:10:07.870782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic information","metadata":{}},{"cell_type":"code","source":"train.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:10:10.409105Z","iopub.execute_input":"2021-08-02T14:10:10.409527Z","iopub.status.idle":"2021-08-02T14:10:10.49887Z","shell.execute_reply.started":"2021-08-02T14:10:10.409491Z","shell.execute_reply":"2021-08-02T14:10:10.497657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:10:11.164022Z","iopub.execute_input":"2021-08-02T14:10:11.164401Z","iopub.status.idle":"2021-08-02T14:10:11.183946Z","shell.execute_reply.started":"2021-08-02T14:10:11.164366Z","shell.execute_reply":"2021-08-02T14:10:11.182756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'NA values in train df: {sum(train.isna().sum())}')\nprint(f'NA values in test df: {sum(test.isna().sum())}')","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-02T14:10:11.633402Z","iopub.execute_input":"2021-08-02T14:10:11.633758Z","iopub.status.idle":"2021-08-02T14:10:11.717215Z","shell.execute_reply.started":"2021-08-02T14:10:11.633727Z","shell.execute_reply":"2021-08-02T14:10:11.716197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in [train, test]:\n    i.drop('id', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:10:12.169105Z","iopub.execute_input":"2021-08-02T14:10:12.169474Z","iopub.status.idle":"2021-08-02T14:10:12.270682Z","shell.execute_reply.started":"2021-08-02T14:10:12.169439Z","shell.execute_reply":"2021-08-02T14:10:12.269676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:10:13.515125Z","iopub.execute_input":"2021-08-02T14:10:13.515555Z","iopub.status.idle":"2021-08-02T14:10:14.62161Z","shell.execute_reply.started":"2021-08-02T14:10:13.515519Z","shell.execute_reply":"2021-08-02T14:10:14.620384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:10:14.623693Z","iopub.execute_input":"2021-08-02T14:10:14.62414Z","iopub.status.idle":"2021-08-02T14:10:15.402345Z","shell.execute_reply.started":"2021-08-02T14:10:14.624076Z","shell.execute_reply":"2021-08-02T14:10:15.401121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The distributions of all 100 features are almost the same.**","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize = (15, 60))\nfor i in range(len(train.columns.tolist()[:100])):\n    plt.subplot(20,5,i+1)\n    sns.set_style(\"white\")\n    plt.title(train.columns.tolist()[:100][i], size = 12, fontname = 'monospace')\n    a = sns.kdeplot(train[train.columns.tolist()[:100][i]], color = '#34675c', shade = True, alpha = 0.9, linewidth = 1.5, edgecolor = 'black')\n    plt.ylabel('')\n    plt.xlabel('')\n    plt.xticks(fontname = 'monospace')\n    plt.yticks([])\n    for j in ['right', 'left', 'top']:\n        a.spines[j].set_visible(False)\n        a.spines['bottom'].set_linewidth(1.2)\n        \nfig.tight_layout(h_pad = 3)\n\nplt.show()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-02T14:10:17.251385Z","iopub.execute_input":"2021-08-02T14:10:17.2517Z","iopub.status.idle":"2021-08-02T14:12:26.32712Z","shell.execute_reply.started":"2021-08-02T14:10:17.251671Z","shell.execute_reply":"2021-08-02T14:12:26.326184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix = np.triu(train.corr())\nplt.figure(figsize = (15, 12))\nsns.heatmap(train.corr(), annot = False, cmap = 'Greens', mask = matrix, vmin = -0.03, vmax = 0.03, linewidths = 0.1, linecolor = 'white', cbar = True)\nplt.xticks(size = 8, fontname = 'monospace')\nplt.yticks(size = 8, fontname = 'monospace')\nplt.figtext(0.77, 0.8, '''All 100 features and the target variable\nhave a very small\ncorrelation''', fontsize = 20, fontname = 'monospace', ha = 'right', color = '#34675c')\nplt.show()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-02T14:12:26.328555Z","iopub.execute_input":"2021-08-02T14:12:26.328878Z","iopub.status.idle":"2021-08-02T14:12:41.967128Z","shell.execute_reply.started":"2021-08-02T14:12:26.328846Z","shell.execute_reply":"2021-08-02T14:12:41.966231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (14, 7))\nsns.set_style(\"white\")\nplt.title('Distribution of loss (target)', size = 25, y = 1.03, fontname = 'monospace', color = '#34675c')\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', alpha = 0.8, zorder = 0,  dashes = (1,7))\na = sns.kdeplot(train['loss'], color = '#34675c', shade = True, alpha = 0.9, linewidth = 1.5, edgecolor = 'black')\nplt.ylabel('')\nplt.xlabel('')\nplt.xticks(fontname = 'monospace')\nplt.yticks([])\nfor j in ['right', 'left', 'top']:\n    a.spines[j].set_visible(False)\n    a.spines['bottom'].set_linewidth(1.2)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-08-02T14:12:41.97061Z","iopub.execute_input":"2021-08-02T14:12:41.971061Z","iopub.status.idle":"2021-08-02T14:12:43.422727Z","shell.execute_reply.started":"2021-08-02T14:12:41.971025Z","shell.execute_reply":"2021-08-02T14:12:43.421885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preproceesing for modeling","metadata":{}},{"cell_type":"code","source":"X = train.drop('loss', axis = 1)\ny = train['loss']\n\nsc = StandardScaler()\nX[X.columns.tolist()] = sc.fit_transform(X[X.columns.tolist()])\ntest[test.columns.tolist()] = sc.fit_transform(test[test.columns.tolist()])\n\nX.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:13:01.685184Z","iopub.execute_input":"2021-08-02T14:13:01.685522Z","iopub.status.idle":"2021-08-02T14:13:12.369883Z","shell.execute_reply.started":"2021-08-02T14:13:01.685492Z","shell.execute_reply":"2021-08-02T14:13:12.369106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost","metadata":{}},{"cell_type":"code","source":"def objective(trial, data = X, target = y):\n    params = {\n        'depth': trial.suggest_int('depth', 2, 6),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n        'iterations': trial.suggest_int('iterations', 500, 5000),\n        'max_bin': trial.suggest_int('max_bin', 1, 300),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 300),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.0001, 1.0, log = True),\n        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n        'leaf_estimation_method': trial.suggest_categorical('leaf_estimation_method', ['Newton', 'Gradient']),\n        'random_seed': 228,\n        'loss_function': 'RMSE',\n        'eval_metric': 'RMSE',\n        'bootstrap_type': 'Bernoulli',\n        'task_type': 'GPU'\n    }\n    \n    model = CatBoostRegressor(**params)\n    scores = []\n    k = KFold(n_splits = 5, random_state = 228, shuffle = True)\n    for i, (trn_idx, val_idx) in enumerate(k.split(X)):\n        \n        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n        model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 150, verbose = False, use_best_model = True)\n        \n        tr_preds = model.predict(X_train)\n        tr_score = np.sqrt(mean_squared_error(y_train, tr_preds))\n        \n        val_preds = model.predict(X_val)\n        val_score = np.sqrt(mean_squared_error(y_val, val_preds))\n\n        scores.append((tr_score, val_score))\n        \n        print(f\"Fold {i+1} | RMSE: {val_score}\")\n        \n        \n    scores = pd.DataFrame(scores, columns = ['train score', 'validation score'])\n    \n    return scores['validation score'].mean()\n\nstudy = optuna.create_study(direction = 'minimize')\nstudy.optimize(objective, n_trials = 100)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best value:', study.best_value)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:15:40.299695Z","iopub.execute_input":"2021-08-02T14:15:40.300022Z","iopub.status.idle":"2021-08-02T14:45:58.730832Z","shell.execute_reply.started":"2021-08-02T14:15:40.299993Z","shell.execute_reply":"2021-08-02T14:45:58.728108Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean RMSE on 5 folds - 7.8448\nparamsCB = {'depth': 5, \n            'learning_rate': 0.04278413956100119, \n            'iterations': 2116, \n            'max_bin': 238, \n            'min_data_in_leaf': 251, \n            'l2_leaf_reg': 0.004676455789227335, \n            'subsample': 0.3773307810571105, \n            'grow_policy': 'Depthwise', \n            'leaf_estimation_method': 'Newton',\n            'random_seed': 228,\n            'loss_function': 'RMSE',\n            'eval_metric': 'RMSE',\n            'bootstrap_type': 'Bernoulli',\n            'task_type': 'GPU'}","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:48:03.801037Z","iopub.execute_input":"2021-08-02T14:48:03.801395Z","iopub.status.idle":"2021-08-02T14:48:03.807286Z","shell.execute_reply.started":"2021-08-02T14:48:03.801362Z","shell.execute_reply":"2021-08-02T14:48:03.806432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = KFold(n_splits = 5, random_state = 228, shuffle = True)\n\npredictions = np.zeros(len(test))\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = CatBoostRegressor(**paramsCB)\n   \n    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 150, use_best_model = True)\n    \n    predictions += model.predict(test) / folds.n_splits \n    \nss['loss'] = predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:48:24.644892Z","iopub.execute_input":"2021-08-02T14:48:24.645286Z","iopub.status.idle":"2021-08-02T14:50:07.32566Z","shell.execute_reply.started":"2021-08-02T14:48:24.64524Z","shell.execute_reply":"2021-08-02T14:50:07.324778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss.to_csv('cb.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T14:51:26.38773Z","iopub.execute_input":"2021-08-02T14:51:26.388089Z","iopub.status.idle":"2021-08-02T14:51:26.890781Z","shell.execute_reply.started":"2021-08-02T14:51:26.388056Z","shell.execute_reply":"2021-08-02T14:51:26.889921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Result - 7.88071**","metadata":{}},{"cell_type":"markdown","source":"# XGB","metadata":{}},{"cell_type":"code","source":"def objective(trial, data = X, target = y):\n\n    params = {\n        'max_depth': trial.suggest_int('max_depth', 2, 8),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n        'n_estimators': trial.suggest_int('n_estimators', 500, 10000),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 200),\n        'gamma': trial.suggest_float('gamma', 0.0001, 1.0, log = True),\n        'alpha': trial.suggest_float('alpha', 0.0001, 10.0, log = True),\n        'lambda': trial.suggest_float('lambda', 0.0001, 10.0, log = True),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.8),\n        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n        'tree_method': 'gpu_hist',\n        'booster': 'gbtree',\n        'random_state': 228,\n        'use_label_encoder': False,\n        'eval_metric': 'rmse'\n    }\n    \n    model = XGBRegressor(**params)\n    scores = []\n    k = KFold(n_splits = 5, random_state = 228, shuffle = True)\n    for i, (trn_idx, val_idx) in enumerate(k.split(X)):\n        \n        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n        model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 150, verbose = False)\n        \n        tr_preds = model.predict(X_train)\n        tr_score = np.sqrt(mean_squared_error(y_train, tr_preds))\n        \n        val_preds = model.predict(X_val)\n        val_score = np.sqrt(mean_squared_error(y_val, val_preds))\n\n        scores.append((tr_score, val_score))\n        \n        print(f\"Fold {i+1} | RMSE: {val_score}\")\n        \n        \n    scores = pd.DataFrame(scores, columns = ['train score', 'validation score'])\n    \n    return scores['validation score'].mean()\n\nstudy = optuna.create_study(direction = 'minimize')\nstudy.optimize(objective, n_trials = 100)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best value:', study.best_value)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-02T16:07:07.693999Z","iopub.execute_input":"2021-08-02T16:07:07.694331Z","iopub.status.idle":"2021-08-02T16:13:31.380329Z","shell.execute_reply.started":"2021-08-02T16:07:07.694284Z","shell.execute_reply":"2021-08-02T16:13:31.377613Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean RMSE on 5 folds - 7.8462\nparamsXGB = {'max_depth': 2, \n             'learning_rate': 0.010707053059983151, \n             'n_estimators': 9688, \n             'min_child_weight': 168, \n             'gamma': 0.0006130691869231192, \n             'alpha': 0.0015540336440723174, \n             'lambda': 0.012133281664909838, \n             'colsample_bytree': 0.5945187331960007, \n             'subsample': 0.3432887319679862,\n             'tree_method': 'gpu_hist',\n             'booster': 'gbtree',\n             'random_state': 228,\n             'use_label_encoder': False,\n             'eval_metric': 'rmse'}","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:16:02.313282Z","iopub.execute_input":"2021-08-02T16:16:02.31363Z","iopub.status.idle":"2021-08-02T16:16:02.320105Z","shell.execute_reply.started":"2021-08-02T16:16:02.3136Z","shell.execute_reply":"2021-08-02T16:16:02.319165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.zeros(len(test))\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = XGBRegressor(**paramsXGB)\n   \n    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 150)\n    \n    predictions += model.predict(test) / folds.n_splits \n    \nss['loss'] = predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:16:54.006336Z","iopub.execute_input":"2021-08-02T16:16:54.006668Z","iopub.status.idle":"2021-08-02T16:19:14.423865Z","shell.execute_reply.started":"2021-08-02T16:16:54.006637Z","shell.execute_reply":"2021-08-02T16:19:14.422965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss.to_csv('xgb.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:19:20.960909Z","iopub.execute_input":"2021-08-02T16:19:20.961219Z","iopub.status.idle":"2021-08-02T16:19:21.419978Z","shell.execute_reply.started":"2021-08-02T16:19:20.961189Z","shell.execute_reply":"2021-08-02T16:19:21.41917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Result - 7.88625**","metadata":{}},{"cell_type":"markdown","source":"# LGBM","metadata":{}},{"cell_type":"code","source":"def objective(trial, data = X, target = y):\n\n    params = {\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 10, 500),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth': trial.suggest_int('max_depth', 2, 8),\n        'n_estimators': trial.suggest_int('n_estimators', 500, 10000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.6),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 10, 100),\n        'cat_l2': trial.suggest_int('cat_l2', 1, 20),\n        'min_data_per_group': trial.suggest_int('min_data_per_group', 1, 200),\n        'device_type': 'gpu',\n        'boosting_type': 'gbdt',\n        'random_state': 228,\n        'metric': 'rmse'\n    }\n    \n    model = LGBMRegressor(**params)\n    scores = []\n    k = KFold(n_splits = 5, random_state = 228, shuffle = True)\n    for i, (trn_idx, val_idx) in enumerate(k.split(X)):\n        \n        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n        model.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 150, verbose = False)\n        \n        tr_preds = model.predict(X_train)\n        tr_score = np.sqrt(mean_squared_error(y_train, tr_preds))\n        \n        val_preds = model.predict(X_val)\n        val_score = np.sqrt(mean_squared_error(y_val, val_preds))\n\n        scores.append((tr_score, val_score))\n        \n        print(f\"Fold {i+1} | RMSE: {val_score}\")\n        \n        \n    scores = pd.DataFrame(scores, columns = ['train score', 'validation score'])\n    \n    return scores['validation score'].mean()\n\nstudy = optuna.create_study(direction = 'minimize')\nstudy.optimize(objective, n_trials = 100)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best value:', study.best_value)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T15:20:12.899499Z","iopub.execute_input":"2021-08-02T15:20:12.899893Z","iopub.status.idle":"2021-08-02T15:52:30.902915Z","shell.execute_reply.started":"2021-08-02T15:20:12.89986Z","shell.execute_reply":"2021-08-02T15:52:30.899949Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean RMSE on 5 folds - 7.8405\nparamsLGBM = {'reg_alpha': 8.682795832798263, \n              'reg_lambda': 8.688528314713478, \n              'num_leaves': 35, \n              'min_child_samples': 5, \n              'max_depth': 8, \n              'n_estimators': 4461, \n              'learning_rate': 0.010109446255049337, \n              'colsample_bytree': 0.104662962036166, \n              'cat_smooth': 56, \n              'cat_l2': 13, \n              'min_data_per_group': 5,\n              'device_type': 'gpu',\n              'boosting_type': 'gbdt',\n              'random_state': 228,\n              'metric': 'rmse'\n              }","metadata":{"execution":{"iopub.status.busy":"2021-08-02T15:53:03.379543Z","iopub.execute_input":"2021-08-02T15:53:03.379882Z","iopub.status.idle":"2021-08-02T15:53:03.386292Z","shell.execute_reply.started":"2021-08-02T15:53:03.379852Z","shell.execute_reply":"2021-08-02T15:53:03.385236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.zeros(len(test))\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = LGBMRegressor(**paramsLGBM)\n   \n    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 150)\n    \n    predictions += model.predict(test) / folds.n_splits \n    \nss['loss'] = predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-02T15:54:32.233611Z","iopub.execute_input":"2021-08-02T15:54:32.233958Z","iopub.status.idle":"2021-08-02T16:02:24.377536Z","shell.execute_reply.started":"2021-08-02T15:54:32.233927Z","shell.execute_reply":"2021-08-02T16:02:24.376689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss.to_csv('lgbm.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T16:02:32.480753Z","iopub.execute_input":"2021-08-02T16:02:32.481124Z","iopub.status.idle":"2021-08-02T16:02:32.978839Z","shell.execute_reply.started":"2021-08-02T16:02:32.48109Z","shell.execute_reply":"2021-08-02T16:02:32.977971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Beautiful result - 7.88000**","metadata":{}},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"**Interesting. When I first started studying machine learning, I often read about how powerful XGB is, but for the second competition in a row, XGB shows the worst result.**","metadata":{}}]}