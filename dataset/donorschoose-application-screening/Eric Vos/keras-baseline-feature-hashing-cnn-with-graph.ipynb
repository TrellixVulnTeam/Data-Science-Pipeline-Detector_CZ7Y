{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":false},"cell_type":"code","source":"# Forked from https://www.kaggle.com/CVxTz/keras-baseline-feature-hashing-cnn\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":false},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nresources = pd.read_csv(\"../input/resources.csv\")\ntrain = train.sort_values(by=\"project_submitted_datetime\")\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f592a49e-f0d0-4e26-ae59-5bfe7434248b","_uuid":"72a58c08a2d4498e4628af5e344dafb4bee99f96","collapsed":true,"trusted":false},"cell_type":"code","source":"train.columns.values\n#print(test.head())\n#print(resources.head())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1b8a0111-65da-49d0-8aa1-14db0c4c8600","_uuid":"fd0e3b2ceaffa53a0704835e80b5e4af80150e97","collapsed":true,"trusted":false},"cell_type":"code","source":"teachers_train = list(set(train.teacher_id.values))\nteachers_test = list(set(test.teacher_id.values))\ninter = set(teachers_train).intersection(teachers_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"788ca21e-68b1-4fa3-81be-bacfb409719c","_uuid":"5c66ea49dc1dbe24415c5b7f0fafa4c493eec321","collapsed":true,"trusted":false},"cell_type":"code","source":"print(\"Number teachers train : %s, Number teachers test : %s, Overlap : %s \"%(len(teachers_train), len(teachers_test), len(inter)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"124ee5e2-d7c0-46ce-bc54-5c3dc6a74b3f","_uuid":"f808ed8bd3e0860f30b0c3ea50061bae31c22c82","collapsed":true,"trusted":false},"cell_type":"code","source":"char_cols = ['project_subject_categories', 'project_subject_subcategories',\n       'project_title', 'project_essay_1', 'project_essay_2',\n       'project_essay_3', 'project_essay_4', 'project_resource_summary']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"addbf60f-8bba-413e-bb91-8aa7ff4dc2ff","_uuid":"0ce0b78b49a1e74cc82590488cdfa74b9f00c4d1","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"62aaa5f9-6313-44cb-9401-03b4f7d2a103","_uuid":"69d9a051b7cbf0e542480ac6c432f2a575ec5b77","collapsed":true,"trusted":false},"cell_type":"code","source":"#https://www.kaggle.com/mmi333/beat-the-benchmark-with-one-feature\nresources['total_price'] = resources.quantity * resources.price\n\nmean_total_price = pd.DataFrame(resources.groupby('id').total_price.mean()) \nsum_total_price = pd.DataFrame(resources.groupby('id').total_price.sum()) \ncount_total_price = pd.DataFrame(resources.groupby('id').total_price.count())\nmean_total_price['id'] = mean_total_price.index\nsum_total_price['id'] = mean_total_price.index\ncount_total_price['id'] = mean_total_price.index\n\ndef create_features(df):\n    \n\n    df = pd.merge(df, mean_total_price, on='id')\n    df = pd.merge(df, sum_total_price, on='id')\n    df = pd.merge(df, count_total_price, on='id')\n    df['year'] = df.project_submitted_datetime.apply(lambda x: x.split(\"-\")[0])\n    df['month'] = df.project_submitted_datetime.apply(lambda x: x.split(\"-\")[1])\n    for col in char_cols:\n        df[col] = df[col].fillna(\"NA\")\n    df['text'] = df.apply(lambda x: \" \".join(x[col] for col in char_cols), axis=1)\n    return df\n\ntrain = create_features(train)\ntest = create_features(test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cd94beed-d105-459e-920a-7e2bd041520b","_uuid":"e3d6230e3bf65049b2d58272d53d01323e37bbf8","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7742c5d2-5d8e-4965-9a1c-a2c2a0164bee","_uuid":"0f84509b4bfbe8555e3f88df35f04ee57c20c435","collapsed":true,"trusted":false},"cell_type":"code","source":"cat_features = [\"teacher_prefix\", \"school_state\", \"year\", \"month\", \"project_grade_category\", \"project_subject_categories\", \"project_subject_subcategories\"]\n#\"teacher_id\", \nnum_features = [\"teacher_number_of_previously_posted_projects\", \"total_price_x\", \"total_price_y\", \"total_price\"]\ncat_features_hash = [col+\"_hash\" for col in cat_features]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6f9594b5-155e-47a5-b6f5-24d3ac49ffee","_uuid":"a2c15bc8a55fcb1c571cfbe6b7062fa2294e581f","collapsed":true,"trusted":false},"cell_type":"code","source":"max_size=15000#0\ndef feature_hash(df, max_size=max_size):\n    for col in cat_features:\n        df[col+\"_hash\"] = df[col].apply(lambda x: hash(x)%max_size)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ccd45300-40ac-4894-b14a-cd5b026aacac","_uuid":"4dc775237b3a4ca40458919bbe9488b0c295fb10","collapsed":true,"trusted":false},"cell_type":"code","source":"train = feature_hash(train)\ntest = feature_hash(test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dddf070f-e7fb-40e5-aba2-71c88c95f79e","_uuid":"012e5a280f975a7a85eaa5911f8c158447138a4b","collapsed":true,"trusted":false},"cell_type":"code","source":"#print(train['text'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8b5e098f-10b7-4bba-a735-f8f7e4e676ce","_uuid":"e3f03f358f98d64c9b6fa429c77f68f6a4929586","collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n#from sklearn.feature_extraction.text import TfidfVectorizer\nfrom keras.preprocessing import text, sequence\n\nmax_features = 50000\nmaxlen = 300\nscaler = StandardScaler()\nX_train_num = scaler.fit_transform(train[num_features])\nX_test_num = scaler.transform(test[num_features])\nX_train_cat = np.array(train[cat_features_hash], dtype=np.int)\nX_test_cat = np.array(test[cat_features_hash], dtype=np.int)\ntokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(train[\"text\"].tolist()+test[\"text\"].tolist())\nlist_tokenized_train = tokenizer.texts_to_sequences(train[\"text\"].tolist())\nlist_tokenized_test = tokenizer.texts_to_sequences(test[\"text\"].tolist())\nX_train_words = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_test_words = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n\n\nX_train_target = train.project_is_approved","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec5c6764-5f3b-4499-a6b7-44e87d2c573d","_uuid":"2d915fdd061d9a07c73fcde4794036e63a5236fb","collapsed":true,"trusted":false},"cell_type":"code","source":"from keras.layers import Input, Dense, Embedding, Flatten, concatenate, Dropout, Convolution1D, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import optimizers\n\ndef get_model():\n    input_cat = Input((len(cat_features_hash), ))\n    input_num = Input((len(num_features), ))\n    input_words = Input((maxlen, ))\n    \n    x_cat = Embedding(max_size, 10)(input_cat)\n    x_cat = Flatten()(x_cat)\n    x_cat = Dropout(0.5)(x_cat)\n    x_words = Embedding(max_features, 100)(input_words)\n    x_words = Convolution1D(100, 3, activation=\"relu\")(x_words)\n    x_words = GlobalMaxPool1D()(x_words)\n    x_words = Dropout(0.5)(x_words)\n    \n    x_cat = Dense(100, activation=\"relu\")(x_cat)\n    x_num = Dense(100, activation=\"relu\")(input_num)\n    x_num = Dropout(0.5)(x_num)\n    x = concatenate([x_cat, x_num, x_words])\n    x = Dense(50, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    predictions = Dense(1, activation=\"sigmoid\")(x)\n    model = Model(inputs=[input_cat, input_num, input_words], outputs=predictions)\n    model.compile(optimizer=optimizers.Adam(0.001, decay=1e-6),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"785f12b8-0bbb-43b5-a709-dabd163017ce","_uuid":"58ac03b1c6ae802a41e3d33f9e61f3dce3e20b3a","collapsed":true,"trusted":false},"cell_type":"code","source":"model = get_model()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2f7e91dc-7b9d-4a77-bdb2-33870f7f4ba8","_uuid":"c18fec095f09fd16be2b55948f920d58cdadc24d","collapsed":true,"trusted":false},"cell_type":"code","source":"history = model.fit([X_train_cat, X_train_num, X_train_words], X_train_target, validation_split=0.1,\n          epochs=6, batch_size=4096)\n\nprint(history.history.keys())\n#\nfig = plt.figure()\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\n#\nfig.savefig('loss.png')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6e935a5c-c498-477a-8aff-9584b56502bb","_uuid":"a65d34c4e98e7085cab5a7ac2405240dced277a1","collapsed":true,"trusted":false},"cell_type":"code","source":"pred_test = model.predict([X_test_cat, X_test_num, X_test_words])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"91f918eb-1e71-4657-a70e-cbb4bbc93118","_uuid":"10711d3d0d0e3e0ab2cd6797b5402f107d3400d8","collapsed":true,"trusted":false},"cell_type":"code","source":"test[\"project_is_approved\"] = pred_test\ntest[['id', 'project_is_approved']].to_csv(\"baseline_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"693c6da0-9e56-47f3-8d55-c8e2a87146fa","_uuid":"b22a2c56df54ae94fd5f7d54a377ee4c9e251ccf","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}