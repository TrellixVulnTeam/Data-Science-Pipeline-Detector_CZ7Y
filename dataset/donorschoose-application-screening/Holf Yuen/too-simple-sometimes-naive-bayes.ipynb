{"cells":[{"metadata":{"_uuid":"95a5931a35e4f02c39b3a0cab622eab2fc70da28","_cell_guid":"32453173-24f4-465f-81f1-40670981569d"},"cell_type":"markdown","source":"# Prediction Using Bag of Words Approach, Beginning with Naive Bayes Algorithm\nWork in progress..."},{"metadata":{"_uuid":"079f1ca10d4f406aa10c2adfeb5e9cb9e8e28cdd","_cell_guid":"3342bdec-e164-4dd1-9ffa-d79f17f23c0d"},"cell_type":"markdown","source":"Loading packages and data:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk import word_tokenize, FreqDist\nfrom nltk.stem import WordNetLemmatizer\nfrom scipy.sparse import hstack\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import train_test_split\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nsub = pd.read_csv(\"../input/sample_submission.csv\")\nresources = pd.read_csv(\"../input/resources.csv\")","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"50ab25a8bbbea55f5fb4efa739560b9d231e4b3d","_cell_guid":"87bb3c96-ad09-485d-9161-93a63d2d7d3c","trusted":true},"cell_type":"code","source":"train.head()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"3d247f3b8a8cdac09cf2a284e7f0b9a708dced33","_cell_guid":"f6ae707a-7db7-40be-9926-bcd4d135be8f"},"cell_type":"markdown","source":"We are going to combine 4 essays into a single column:"},{"metadata":{"_uuid":"29e70e17db24240c65bbad5b0ee3f6d47ab19bb3","collapsed":true,"_cell_guid":"af0629b5-05bc-486d-99cf-aa3e3b25d94f","trusted":true},"cell_type":"code","source":"train.loc[:,['project_essay_3','project_essay_4']] = train.loc[:,['project_essay_3','project_essay_4']].fillna('None')\ntest.loc[:,['project_essay_3','project_essay_4']] = test.loc[:,['project_essay_3','project_essay_4']].fillna('None')\nessays_train = train[['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']].apply(lambda x: ' '.join(x), axis=1)\nessays_test = test[['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']].apply(lambda x: ' '.join(x), axis=1)\nessays_train = essays_train.str.replace(r'\\\\[rn]', '')\nessays_test = essays_test.str.replace(r'\\\\[rn]', '')\nessays_train = essays_train.str.replace('[{}]'.format(string.punctuation.replace('-','')), '') # Remove punctuation, keep hyphen\nessays_test = essays_test.str.replace('[{}]'.format(string.punctuation.replace('-','')), '')","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"4b6faaa7c66dce697c722cd2a72b367cb4a4660e","collapsed":true,"_cell_guid":"c736c42e-502e-4a77-a53f-5f30471e570b","trusted":false},"cell_type":"code","source":"wnl = WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    return [wnl.lemmatize(wnl.lemmatize(w), pos='v') for w in word_tokenize(text)]\n\n# essay_token = essays_train[:100].apply(lambda x: lemmatize_text(x))\n# essay_token[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b359dd015b8474f30f498a5c7aef7bf24428aea8","_cell_guid":"9c77c93d-ab0d-4550-9054-1eb202f49136"},"cell_type":"markdown","source":"We plot a word cloud of project titles, separate by whether the project is accepted, and see if there is any hints:"},{"metadata":{"_uuid":"8af01452a90d4817c0d125c2619c5b83dd77695d","_kg_hide-output":false,"_kg_hide-input":false,"_cell_guid":"a5fba74d-ca04-4f8c-900a-ee30ef9ffd48","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nstopwords = set(STOPWORDS)\n\nplt.subplot(121)\nwords_acc = train.loc[train['project_is_approved']==1,'project_title']\nword_freq_acc = FreqDist(w for w in word_tokenize(' '.join(words_acc).lower()) if (w not in stopwords) & (w.isalpha()))\nwordcloud = WordCloud(background_color = 'white', height=300, max_words=100).generate_from_frequencies(word_freq_acc)\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud (Title) - Approved\", fontsize=12)\nplt.axis(\"off\")\n\nplt.subplot(122)\nwords_rej = train.loc[train['project_is_approved']==0,'project_title']\nword_freq_rej = FreqDist(w for w in word_tokenize(' '.join(words_rej).lower()) if (w not in stopwords) & (w.isalpha()))\nwordcloud = WordCloud(background_color = 'white', height=300, max_words=100).generate_from_frequencies(word_freq_rej)\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud (Title) - Rejected\", fontsize=12)\nplt.axis(\"off\")\nplt.show()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"393a6d6d24446fac655ad478d6b1167e785fb19d"},"cell_type":"markdown","source":"We apply Count Vectorizer on titles and essays:"},{"metadata":{"_uuid":"975dcdec5ae59bea05287a0eaa4346d63da012a5","_cell_guid":"a16378c4-0079-4d71-80f2-970df2e7f387","trusted":true},"cell_type":"code","source":"separate = False\n\nif separate:\n    count_vec = CountVectorizer(stop_words='english', max_features=10000, max_df=0.999, lowercase=True)\n    x_train_e = count_vec.fit_transform(essays_train)\n    x_test_e = count_vec.transform(essays_test)\n    count_vec2 = CountVectorizer(stop_words='english', max_features=5000, max_df=0.999, lowercase=True)\n    x_train_t = count_vec2.fit_transform(train['project_title'])\n    x_test_t = count_vec2.transform(test['project_title'])\n    x_train = hstack([x_train_e, x_train_t])\n    x_test = hstack([x_test_e, x_test_t])\nelse:\n    count_vec = CountVectorizer(stop_words='english', max_features=10000, max_df=0.999, lowercase=True)\n    x_train = count_vec.fit_transform(essays_train + ' ' + train['project_title'])\n    x_test = count_vec.transform(essays_test + ' ' + test['project_title'])","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"b609f5b21026bc16b0078d3640ef84c7a4335ebd","collapsed":true,"_cell_guid":"5842b021-2ba5-4148-b52a-65148c64b81b","trusted":true},"cell_type":"code","source":"y_train = train['project_is_approved']","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"cc61cd6631dcf4258c8fe316e2adbe443254a618","_cell_guid":"6defad6d-ed50-4ce0-acf7-8a5f0b3e17db","trusted":true},"cell_type":"code","source":"# split into train and validation set\nxtr, xv, ytr, yv = train_test_split(x_train, y_train, test_size=0.2, random_state=6894)\nnb = MultinomialNB()\nnb.fit(xtr, ytr)\npred0 = nb.predict_proba(xv)\n\nfrom sklearn import metrics\nfpr, tpr, thresholds = metrics.roc_curve(yv, pred0[:,1], pos_label=1)\nmetrics.auc(fpr, tpr)","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"95af5000f735fda21d438ff3d5f7512d9ce18ce8","collapsed":true,"_cell_guid":"c6459380-b1aa-4cb0-8727-c966ce590cd9","trusted":true},"cell_type":"code","source":"nb = MultinomialNB()\nnb.fit(x_train, y_train)\npred1 = nb.predict_proba(x_test)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"d62c1e8ec723f08cf53c299c9f3fffe7617cfd8b","collapsed":true,"_cell_guid":"8c95a6ca-8d25-4fe4-84b3-08979764803a","trusted":true},"cell_type":"code","source":"subnb = pd.concat([sub, pd.Series(pred1[:,1], name='project_is_approved')], axis=1).iloc[:,[0,2]]\nsubnb.to_csv('subnb.csv', index=False)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"25e5c21e357bd3c4211527ca5d78b9bbb858542f","_cell_guid":"940bc0c0-7dee-4fef-aed8-519d5c35191a"},"cell_type":"markdown","source":"Now let's work on three columns: grade, subject categories and subject subcategories:"},{"metadata":{"_uuid":"764ff00aba950dd24a4ca85d8479baec4599f5ce","collapsed":true,"_cell_guid":"2f38f62c-8d32-4d96-b281-83d2ced57c72","trusted":true},"cell_type":"code","source":"by_grade = train.groupby('project_grade_category', as_index=False)['project_is_approved'].mean()\nby_cat = train.groupby('project_subject_categories', as_index=False)['project_is_approved'].mean()\nby_subcat = train.groupby('project_subject_subcategories', as_index=False)['project_is_approved'].mean()","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"c8eeabdc4a17f97fa357e0514973f60ac905ca59","_cell_guid":"cb7e097a-77bb-482c-a11c-860cc668d835","trusted":true},"cell_type":"code","source":"train_1 = pd.merge(train, by_grade, how='left', on='project_grade_category', suffixes = ['','_grade'])\ntrain_1 = pd.merge(train_1, by_cat, how='left', on='project_subject_categories', suffixes = ['','_cat'])\ntrain_1 = pd.merge(train_1, by_subcat, how='left', on='project_subject_subcategories', suffixes = ['','_subcat'])\ntrain_1.head()","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"70e512c068b6f6bc3f2f5574e8b283feab174116","_cell_guid":"4980ce7b-3f0b-44ff-84e4-5f7535b6b778","trusted":true},"cell_type":"code","source":"test_1 = pd.merge(test, by_grade, how='left', on='project_grade_category')\ntest_1 = pd.merge(test_1, by_cat, how='left', on='project_subject_categories', suffixes = ['','_cat'])\ntest_1 = pd.merge(test_1, by_subcat, how='left', on='project_subject_subcategories', suffixes = ['','_subcat'])\ntest_1 = test_1.rename(index=str, columns={'project_is_approved':'project_is_approved_grade'})\ntest_1.head()","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"6e2126dad8980fdb5cf6e0803da328dabc7db0d7","_cell_guid":"fb24a02d-03cc-4e95-bd09-f6a196c289b5","trusted":true},"cell_type":"code","source":"test_1['project_is_approved_subcat'].fillna(np.mean(train.project_is_approved), inplace=True)\ntest_1[['project_is_approved_grade','project_is_approved_cat','project_is_approved_subcat']].isnull().sum()","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"d48e4c73b361f8c134c28dd48ccb5c159814b508","_cell_guid":"b41eeecf-72eb-4890-a178-bf8c54f7d451"},"cell_type":"markdown","source":"We fit a logistic regression by the three average acceptance probability columns:"},{"metadata":{"_uuid":"bca00aaaf38f0bf0cfcbe8246a32eb5f2dfac8b4","_cell_guid":"88e9ce96-a6ea-4275-aa3b-4fb76ed45ec2","trusted":true,"collapsed":true},"cell_type":"code","source":"lr = LogisticRegression()\nx_train_lr = train_1[['project_is_approved_grade','project_is_approved_cat','project_is_approved_subcat']]\nx_test_lr = test_1[['project_is_approved_grade','project_is_approved_cat','project_is_approved_subcat']]\nlr.fit(x_train_lr, y_train)\npred2 = lr.predict_proba(x_test_lr)\nsublr = pd.concat([sub, pd.Series(pred2[:,1], name='project_is_approved')], axis=1).iloc[:,[0,2]]\nsublr.to_csv('sublr.csv', index=False)","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"b35b3b0d2a2cb8ac826f713856a5a48764e612af","_cell_guid":"ec8eb49e-48ee-42d5-a378-ce1558eea0c1","trusted":false,"collapsed":true},"cell_type":"code","source":"pred3 = pred1[:,1]*0.7 + pred2[:,1]*0.3\nsuben = pd.concat([sub, pd.Series(pred3, name='project_is_approved')], axis=1).iloc[:,[0,2]]\nsuben.to_csv('suben.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}