{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport textacy\nfrom textacy.preprocess import preprocess_text\nimport spacy\n\nnlp = spacy.load('en')\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\",low_memory=False,#index_col=\"id\",\n                    parse_dates=[\"project_submitted_datetime\"])\ntest= pd.read_csv(\"../input/test.csv\",low_memory=False, #index_col=\"id\",\n                    parse_dates=[\"project_submitted_datetime\"])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3e720067-4b57-4577-aae7-37598f93483b","_uuid":"f87f27ed9ef74723011f2f96755cb1f8aa1ca568","trusted":false,"collapsed":true},"cell_type":"code","source":"resources = pd.read_csv(\"../input/resources.csv\")\nresources.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"210875e7-1a43-4e61-a2df-a9d17747cb87","_uuid":"cc8bbac71beb39f9401e50007a08659ff5c6910b","trusted":false,"collapsed":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c48810f-4a7b-4579-9b3d-fe12125d252b","_uuid":"efc897ba0dcdc046547ac344a8d8c8771c3520ce","trusted":false,"collapsed":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e2dd6674-946f-4db8-bb80-ccfc440513e5","_uuid":"c32a59714fbbbc091c76777659dca60be92e2fe5"},"cell_type":"markdown","source":"## Some EDA + feature agg code:\n* https://www.kaggle.com/a45632/keras-baseline-feature-hashing-cnn-with-graph"},{"metadata":{"_cell_guid":"f046f174-35bc-449b-bcf9-b9e6f58cf744","_uuid":"997ae2976812cc9060b1355dd21c9216b75b14eb","trusted":false,"collapsed":true},"cell_type":"code","source":"teachers_train = list(set(train.teacher_id.values))\nteachers_test = list(set(test.teacher_id.values))\ninter = set(teachers_train).intersection(teachers_test)\nprint(\"Number teachers train : %s, Number teachers test : %s, Overlap : %s \"%(len(teachers_train), len(teachers_test), len(inter)))\nprint(\"Percent of test teachers in intersection with train : %f\"%(100*len(inter)/len(teachers_test) ))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5c5426c1-284c-44d1-b8cd-6fe02f54c1d4","collapsed":true,"_uuid":"0fc269a7d48886b57721abb68d1f0672e2446700","trusted":false},"cell_type":"code","source":"# add dum colyumn of target\ntest[\"project_is_approved\"] = -1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d57efee5-30e4-4ce3-8e89-a8dd95fa0fa2","_uuid":"4265ca924921efd6a5aa6bf3b0cd81819213261e","trusted":false,"collapsed":true},"cell_type":"code","source":"df = pd.concat([train,test])\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"177f5373-e031-4b79-9c7a-791da78fd9c0","_uuid":"ddb549d60ca9a6fa65d133f517c7a35c6f8fb610","trusted":false,"collapsed":true},"cell_type":"code","source":"# df[df.project_is_approved != -1].shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"45395537-c5ae-4a5e-8f7d-cff88dcb3ed8","collapsed":true,"_uuid":"68f522b1ba2e277d8e0af3ea20a132169a0dc0d2","trusted":false},"cell_type":"code","source":"#https://www.kaggle.com/mmi333/beat-the-benchmark-with-one-feature\nresources['total_price'] = resources.quantity * resources.price\n\nmean_total_price = pd.DataFrame(resources.groupby('id').total_price.mean()) \nsum_total_price = pd.DataFrame(resources.groupby('id').total_price.sum()) \ncount_total_price = pd.DataFrame(resources.groupby('id').total_price.count())\nmean_total_price['id'] = mean_total_price.index\nsum_total_price['id'] = mean_total_price.index\ncount_total_price['id'] = mean_total_price.index","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"46d2d203-5671-4ffc-a827-6cb2ce5a5611","_uuid":"f6b91d5a3002be3ea71f560bc7d7070722fc7718","trusted":false,"collapsed":true},"cell_type":"code","source":"# all events in  2016-2017 , so post 2010 change in rules is Irrelevant!\ndf['project_submitted_datetime'].describe()\n\n# df[\"after_change_date\"] = df['project_submitted_datetime']>pd.to_datetime(\"18/02/2010\")\n# df[\"after_change_date\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"58a9f1e9-c894-4831-a52c-940df7fb0d6c","collapsed":true,"_uuid":"45151cfd0e54a8487d39322913589d4db975d0cc","trusted":false},"cell_type":"code","source":"# ## Add isi n USA federal holidays:\n# ## https://stackoverflow.com/questions/29688899/pandas-checking-if-a-date-is-a-holiday-and-assigning-boolean-value\n\n# from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n# cal = calendar()\n# holidays = cal.holidays(start=df['project_submitted_datetime'].min(),end =  df['project_submitted_datetime'].max())\n# df['fedHoliday'] = df['project_submitted_datetime'].isin(holidays)\n\n# df['fedHoliday'] .describe()\n# # All negative!  - Drop feature!","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3a6ad807-0a0d-49fc-ac67-049f05026ace","collapsed":true,"_uuid":"550e3ae1fafb122505a4d4a0aced7261913cd972","trusted":false},"cell_type":"code","source":"def create_features(df):\n    df = pd.merge(df, mean_total_price, on='id')\n    df = pd.merge(df, sum_total_price, on='id')\n    df = pd.merge(df, count_total_price, on='id')\n    df[\"dayOfYear\"] = df['project_submitted_datetime'].dt.dayofyear # Day of Year\n#     df[\"Weekday\"] = df['project_submitted_datetime'].dt.weekday\n    df[\"dayOfMonth\"] = df['project_submitted_datetime'].dt.day\n    df[\"teach_in_test\"] = df[\"teacher_id\"].isin(teachers_test)\n#     df['year'] = df.project_submitted_datetime.apply(lambda x: x.split(\"-\")[0])\n#     df['month'] = df.project_submitted_datetime.apply(lambda x: x.split(\"-\")[1])\n#     for col in char_cols:\n#         df[col] = df[col].fillna(\"NA\")\n#     df['text'] = df.apply(lambda x: \" \".join(x[col] for col in char_cols), axis=1)\n    return df\n\n# train = create_features(train)\n# test = create_features(test)\n\ndf = create_features(df)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6ee6b226-c90d-4d9e-9114-a82be39194a9","collapsed":true,"_uuid":"9bdc3bcdfa5cb4f815bcfe91d7f6e2289e2cd310","trusted":false},"cell_type":"code","source":"df.rename(columns={\"total_price_x\":\"mean_price_per_item\",\"total_price\":\"count_items\",\"total_price_y\":\"sum_price\"},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1cbc442b-64a9-48b6-8d0a-641f3fb8f914","collapsed":true,"_uuid":"5aa6e9f5832d8bda3c3208af5905e45f46c1bc01","trusted":false},"cell_type":"code","source":"df[\"teacher_max_proj_diff\"] = df.groupby(\"teacher_id\")[\"teacher_number_of_previously_posted_projects\"].transform(\"max\")\ndf[\"teacher_max_proj_diff\"] = df[\"teacher_max_proj_diff\"] - df[\"teacher_number_of_previously_posted_projects\"]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"8f2a14cb-c2e1-4d86-b08e-dcd1bb94178a","_uuid":"f8501d58346d080e64dc437baacdaca25d24456a","trusted":false,"collapsed":true},"cell_type":"code","source":"df[\"teacher_count\"] = df.groupby(['teacher_id'])[\"id\"].transform(\"count\")\n# df[\"teacher_id\"].value_counts()[\"484aaf11257089a66cfedc9461c6bd0a\"] # counts match up!\n\ndf[\"state_count\"] = df.groupby(['school_state'])[\"id\"].transform(\"count\")\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d9ac7851-d0d2-42a5-9e17-e2adf75e072d","_uuid":"ae6b465422d87d4be3cc1ac4f3ffa6d6354c6322","trusted":false,"collapsed":true},"cell_type":"code","source":"df[\"state_count\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3dac49ab-3699-46c8-bf60-7a13a5b4b919","collapsed":true,"_uuid":"b818a4fcd510a0b66a1f462d6a3ac012ddb10308","trusted":false},"cell_type":"code","source":"df[\"teach_sum_price_max\"] = df.groupby(\"teacher_id\")[\"sum_price\"].transform(\"max\")\ndf[\"teach_mean_price_median\"] = df.groupby(\"teacher_id\")[\"mean_price_per_item\"].transform(\"median\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eb8a597e-28fd-45c5-ac05-da387166cc72","_uuid":"5d7b79b903d5456a026e46418ff897d62d1e148d"},"cell_type":"markdown","source":"## Clean text: we have many frmating (\\n) attached to words. Let's add whitespace!\n* e.g. : \"Hello;\\r\\nMy \""},{"metadata":{"_cell_guid":"9acaeeeb-1fa2-48b2-a75a-8d52bf940c13","collapsed":true,"_uuid":"87a4e0559125f71d0778add6d204548e6d8ed05c","trusted":false},"cell_type":"code","source":"text_cols  = ['project_title', 'project_essay_1', 'project_essay_2','project_essay_3', 'project_essay_4', 'project_resource_summary']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f6669420-a0a2-4c34-b257-46613a420616","_uuid":"607c24ff2e9fbda4bd3a0ddb5e0430f1197b14ce","trusted":false,"collapsed":true},"cell_type":"code","source":"df[text_cols] = df[text_cols].replace(r\"\\\\n\", \" \\\\n \",regex=True)#.str.replace(r\"\\[a-z]\", \"  \\ \",regex=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"58cfdcd9-b870-413c-b9ca-b9ed6e6f738d","_uuid":"f0f0679632ee8b0f5ac90d6cef52fb0f42d97646","trusted":false,"collapsed":true},"cell_type":"code","source":"df[text_cols] = df[text_cols].replace(r\"(\\\\[a-z])\", r\"  \\1 \",regex=True)\n# df[text_cols].head(3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5e27e5f8-f0d1-4de5-87f2-7f98c9ea71e1","_uuid":"418df4caa34dc69ff4cf56a8ae28b219bf1865ad"},"cell_type":"markdown","source":"## merge text\n* Can/should (?) merge text for description/resource files also. (Or just do seperate word2Vec for resources)\n*  https://www.kaggle.com/nicapotato/tf-idf-and-features-logistic-regression"},{"metadata":{"_cell_guid":"755329a3-b702-4e6b-8646-b70685cdd3be","_uuid":"a31fdad71ca41ab2bddb1fee43eb78ad79fa6e98","trusted":false,"collapsed":true},"cell_type":"code","source":"df[\"joint_essays\"] = df.apply(lambda row: ' '.join([\n    str(row['project_essay_1']), \n    str(row['project_essay_2']), \n    str(row['project_essay_3']), \n    str(row['project_essay_4']),\n    str(row['project_resource_summary']),\n    str(row['project_title']),\n#     str(row['description'])\n]),\n       axis=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"e0cd3199-5368-4361-8527-332b43b5c566","_uuid":"b41a288f17737b493d011c96e0feea0b0aa17bd5","trusted":false,"collapsed":true},"cell_type":"code","source":"df[\"joint_essays\"].head(3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ee01086a-6786-4fb6-a680-e5f6587c496c","_uuid":"ab52c713cddbfbdbb2ee50b58779e022b9f29eff"},"cell_type":"markdown","source":"## Lemmatize , then (?)  further lean text\n* lemmatizer: https://www.kaggle.com/enerrio/scary-nlp-with-spacy-and-keras "},{"metadata":{"_cell_guid":"57c6db09-c579-44fe-b1cb-12601fe826f2","_uuid":"486484e36d08230c1adc8d70254f65b6f87c9404","trusted":false,"collapsed":true},"cell_type":"code","source":"# Clean text before feeding it to spaCy\n# punctuations = string.punctuation\n\n# # Define function to cleanup text by removing personal pronouns, stopwords, and puncuation\n# def cleanup_text(docs, logging=False):\n#     texts = []\n#     counter = 1\n#     for doc in docs:\n#         if counter % 1000 == 0 and logging:\n#             print(\"Processed %d out of %d documents.\" % (counter, len(docs)))\n#         counter += 1\n#         doc = nlp(doc, disable=['parser', 'ner'])\n#         tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n#         tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n#         tokens = ' '.join(tokens)\n#         texts.append(tokens)\n#     return pd.Series(texts)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ef28248d-ff1d-4ea6-966a-45731c45b0e7","_uuid":"b6964678f7738158df2512d62cfece0c15570894","trusted":false,"collapsed":true},"cell_type":"code","source":"## disabled in kernels due to timeout!\n\n# df[\"joint_essays\"] = df[\"joint_essays\"].apply(lambda x: preprocess_text(x, fix_unicode=True, lowercase=True, transliterate=False,\n#                                                                         no_urls=True, no_emails=True, no_phone_numbers=True, no_numbers=True,\n#                                                                         no_punct=True, no_contractions=True\n#                                                                        ,no_accents=True))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"95850f51-7355-44e9-b952-554aece61208","collapsed":true,"_uuid":"e86b0503b6d0cf77c17975a9f122020ceea3a7ab","trusted":false},"cell_type":"code","source":"def lemma_text(doc):\n    doc = nlp(doc, disable=['ner'])\n    tokens = [tok.lemma_.lower().strip() for tok in doc  if tok.is_stop == False and tok.is_punct == False]\n    tokens = ' '.join(tokens)\n    return tokens","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9f3855c0-8085-45f1-836a-02bf1aa5a822","_uuid":"002d01dd55a5293df106e65b074eee0131edbeda","trusted":false,"collapsed":true},"cell_type":"code","source":"df[\"joint_essays\"] = df[\"joint_essays\"].apply(lemma_text)\ndf[\"joint_essays\"].head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cdfd038b-6f31-4d60-b12a-701b2548830a","collapsed":true,"_uuid":"70c501dcf4f04c79cbdf06d5113871a84e09a04e","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5c855d08-8d29-47aa-a190-18bbffeb0f98","_uuid":"a6668c82964955f8cf483d18f009e68effcf37e6"},"cell_type":"markdown","source":"# restore, export train, test"},{"metadata":{"_cell_guid":"c6b57c8a-3e93-49ae-b76f-8e1ed802e9f7","collapsed":true,"_uuid":"c61ea98a3be7176217cf4cc9bcb52152d350fa04","trusted":false},"cell_type":"code","source":"print(\"old Train:\", train.shape)\ntrain = df[df.project_is_approved != -1]\nprint(\"Train:\", train.shape)\n\nprint(\"old test:\", train.shape)\ntest = df[df.project_is_approved == -1]\nprint(\"test:\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"91e316ab-f625-457e-855c-0d3eacbfbca7","collapsed":true,"_uuid":"7546fcfb3e3f17e915d9eeb2ddece6ed4a5dd666","trusted":false},"cell_type":"code","source":"train.to_csv(\"donors_train_aug-v1.csv.gz\",index=False,compression=\"gzip\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ee3be474-82b5-4a36-9042-14dbe8cbe216","collapsed":true,"_uuid":"8c60f2b16344a86e01c15a2a6d2e517da1f1b672","trusted":false},"cell_type":"code","source":"test.drop(\"project_is_approved\",axis=1).to_csv(\"donors_test_aug-v1.csv.gz\",index=False,compression=\"gzip\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}