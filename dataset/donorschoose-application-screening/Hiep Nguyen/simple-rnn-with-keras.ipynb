{"cells":[{"metadata":{"_uuid":"465ea7040afeed14b9f6d0ab0b149094f0d2a0c5","_cell_guid":"043fc442-09e8-4e46-aafc-58acd698869c"},"cell_type":"markdown","source":"# Introduction\n\nThis notebook will build a simple RNN model using keras to solve DonorsChoose.org Application Screening problem."},{"metadata":{"_uuid":"4b0302d462ecbed2dde3d3bf42ddb5a61fe264e1","_cell_guid":"bbbf46ba-ec3b-46b6-8765-a42ad59c080f"},"cell_type":"markdown","source":"# Load data\n\nFirstly, we need to read data into memory then process it."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os; os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport keras\nimport keras.backend as K","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51877678b96aff3b9b11ff9e2c2b2e157d269d3c"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\", sep=\",\")\nprint(train_df.shape)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18edb866c564bab0e54333fcb0476402a185fcdc"},"cell_type":"code","source":"train, dev = train_test_split(train_df, random_state=123, shuffle=True, test_size=0.1)\nprint(\"Training data shape:\", train.shape)\nprint(\"Test data shape:\", dev.shape)","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d1b3e042168ed80bedbb7b387d3c0ade969a4dff","_cell_guid":"bb30d776-fa4b-46db-be00-8c89415d20fb"},"cell_type":"markdown","source":"# Process Data\nIn this section, we will dive deeper into the data and process it for RNN model."},{"metadata":{"_uuid":"877746d2d436538315ab45d8c2ca9ee6f40d0994","_cell_guid":"a1e4fe61-31f1-4513-acc4-db64d7757a5b","trusted":true},"cell_type":"code","source":"%%time\n\ndef get_project_essay(df):\n    return (df[\"project_essay_1\"].fillna('') +\n            ' ' + df[\"project_essay_2\"].fillna('') +\n            ' ' + df[\"project_essay_3\"].fillna('') +\n            ' ' + df[\"project_essay_4\"].fillna(''))\n\ndef get_text(df):\n    return df[\"project_title\"].fillna('') + ' ' + get_project_essay(df)\n\n#project_title_tokenizer = keras.preprocessing.text.Tokenizer()\n#project_title_tokenizer.fit_on_texts(train[\"project_title\"])\n\n#project_essay_tokenizer = keras.preprocessing.text.Tokenizer()\n#project_essay_tokenizer.fit_on_texts(get_project_essay(train))\n\ntokenizer = keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(get_text(train))\n\ndef preprocess_target(df):\n    return df[[\"project_is_approved\"]].copy()\n\ndef preprocess_data(df):\n    processed_df = df[[\"teacher_number_of_previously_posted_projects\"]].copy()\n\n    #processed_df[\"project_title\"] = project_title_tokenizer.texts_to_sequences(df[\"project_title\"])\n    processed_df[\"project_title\"] = tokenizer.texts_to_sequences(df[\"project_title\"])\n    \n    #processed_df[\"project_essay\"] = project_essay_tokenizer.texts_to_sequences(get_project_essay(df))\n    processed_df[\"project_essay\"] = tokenizer.texts_to_sequences(get_project_essay(df))\n    \n    return processed_df\n\nprocessed_train = preprocess_data(train)\ny_train = preprocess_target(train)\nprint(processed_train.shape, y_train.shape)\n\nprocessed_dev = preprocess_data(dev)\ny_dev = preprocess_target(dev)\nprint(processed_dev.shape, y_dev.shape)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"a6baa0a67e3760e6bb9fffcdc03cc8ac27444503","_cell_guid":"6e055cb0-8a23-4337-91c3-94e39ad4024b"},"cell_type":"markdown","source":"We now can plot histogram for project_title and project_essay by its length to pick appropriate maximun values:"},{"metadata":{"_uuid":"d25d1fefe49f65498c313e7020e699dd6ec14d78","_cell_guid":"45eae1d4-9f14-47e0-a80d-372fac487c20","trusted":true},"cell_type":"code","source":"processed_train[\"project_title\"].apply(lambda x: len(x)).hist(bins=10)","execution_count":5,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"100b63ef-6bc5-4ff6-8f69-1dd5695c8710","_uuid":"b7862c6742a4fbf87d690bd658e899b08e08d832","trusted":true},"cell_type":"code","source":"processed_train[\"project_essay\"].apply(lambda x: len(x)).hist(bins=10)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"14d32cace14c85e4d98502ee2ef3e4cfcc252b2b","_cell_guid":"1bb2da00-a142-498f-9f64-ea37a1a1599e"},"cell_type":"markdown","source":"Get data so that keras RNN model can deal with it."},{"metadata":{"collapsed":true,"_uuid":"52b1254e73d38ddfaf06a771be28582a17499a29","_cell_guid":"ab44a784-37b7-4f63-bdc6-6af51cc95e29","trusted":true},"cell_type":"code","source":"MAX_PROJECT_TITLE_SEQ_LEN = 12\nMAX_PROJECT_TITLE = processed_train[\"project_title\"].apply(lambda x: max(x) if len(x) > 0 else 0).max() + 1\n\nMAX_PROJECT_ESSAY_SEQ_LEN = 450\nMAX_PROJECT_ESSAY = processed_train[\"project_essay\"].apply(lambda x: max(x) if len(x) > 0 else 0).max() + 1\n\nMAX_TEXT = max([MAX_PROJECT_TITLE, MAX_PROJECT_ESSAY])\n\ndef get_keras_data(df):\n    return {\n        \"teacher_number_of_previously_posted_projects\": np.array(df[\"teacher_number_of_previously_posted_projects\"]),\n        \"project_title\": keras.preprocessing.sequence.pad_sequences(df[\"project_title\"], maxlen=MAX_PROJECT_TITLE_SEQ_LEN),\n        \"project_essay\": keras.preprocessing.sequence.pad_sequences(df[\"project_essay\"], maxlen=MAX_PROJECT_ESSAY_SEQ_LEN),\n    }\n\nX_train = get_keras_data(processed_train)\nX_dev = get_keras_data(processed_dev)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"44166bee5e88aa8caee6ffa965c089b7af948681","_cell_guid":"6ee77e70-d1b7-44db-aa8e-c920ffd4fea0"},"cell_type":"markdown","source":"## RNN Model\n\nWe now can define a RNN model, train, and then evaluate the model."},{"metadata":{"_uuid":"ed6085f8d34feabdb95e7937465b21077c75feb9","_cell_guid":"1953af8d-fcc8-4d56-8b92-ae0846b19ffd","trusted":true},"cell_type":"code","source":"def create_rnn_model():\n    # Input layers\n    teacher_number_of_previously_posted_projects = keras.layers.Input(shape=(1,), name=\"teacher_number_of_previously_posted_projects\")\n    project_title = keras.layers.Input(shape=(MAX_PROJECT_TITLE_SEQ_LEN,), name=\"project_title\")\n    project_essay = keras.layers.Input(shape=(MAX_PROJECT_ESSAY_SEQ_LEN,), name=\"project_essay\")\n    #project_resource_summary = keras.layers.Input(shape=(MAX_PROJECT_RESOURCE_SUMMARY_SEQ_LEN,), name=\"project_resource_summary\")\n    \n    # Embedding layers\n    #emb_project_title = keras.layers.Embedding(MAX_PROJECT_TITLE, 25)(project_title)\n    #emb_project_essay = keras.layers.Embedding(MAX_PROJECT_ESSAY, 50)(project_essay)\n    emb_layer = keras.layers.Embedding(MAX_TEXT, 50)\n    emb_project_title = emb_layer(project_title)\n    emb_project_essay = emb_layer(project_essay)\n    \n    # RNN layers\n    rnn_project_title = keras.layers.GRU(8, activation=\"relu\")(emb_project_title)\n    rnn_project_essay = keras.layers.GRU(16, activation=\"relu\")(emb_project_essay)\n    #rnn_project_resource_summary = keras.layers.GRU(16, activation=\"relu\")(emb_project_resource_summary)\n    \n    # Merge all layers into one\n    x = keras.layers.concatenate([teacher_number_of_previously_posted_projects,\n                                 rnn_project_title,\n                                 rnn_project_essay,\n                                 #rnn_project_resource_summary,\n                                 ])\n    \n    # Dense layers\n    #x = keras.layers.Dense(128, activation=\"relu\")(x)\n\n    # Output layers\n    output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n    \n    return keras.models.Model(\n        inputs=[teacher_number_of_previously_posted_projects,\n                project_title,\n                project_essay,\n                #project_resource_summary,\n               ],\n        outputs=output)\n\nrnn_model = create_rnn_model()\nrnn_model.summary()","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"c06d9758a29cc60313b44b0dacb0cd0a95f4e990","_cell_guid":"4030bb81-2d49-4303-9d7d-45b0633af507","trusted":true},"cell_type":"code","source":"optimizer = keras.optimizers.Adam(lr=0.001)\nrnn_model.compile(optimizer=optimizer,\n                  loss=keras.losses.binary_crossentropy,\n                  metrics=[\"accuracy\"])\n\nfor i in range(3):\n    rnn_model.fit(X_train, y_train,\n                 batch_size=(2 ** (i + 8)),\n                 epochs=1,\n                 validation_data=(X_dev, y_dev))","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"1734f3cc135236e23f3498bf7c69483d3531a80f","_cell_guid":"bb5dae1a-3e17-4ed7-9174-2747cb3a44bf","trusted":true},"cell_type":"code","source":"preds = rnn_model.predict(X_dev, batch_size=512)\nauc_score = roc_auc_score(y_dev, preds)\nprint(\"AUC for validation data: %.4f\" % (auc_score,))","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"0a548ca3e7531a8bd59a83382e20c4d706d21ab5","_cell_guid":"92976220-b344-4796-991f-70d904e033b4"},"cell_type":"markdown","source":"## Submission"},{"metadata":{"_uuid":"9ae5ac1168de8f17501a73eab548ec1a22276a2b","_cell_guid":"91d5afbf-8624-4a76-8dfb-dd95d035d1eb","trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/test.csv\", sep=',')\n\nprocessed_test = preprocess_data(test_df)\n\nX_test = get_keras_data(processed_test)\n\npreds = rnn_model.predict(X_test, batch_size=512)\n\nsubmission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"project_is_approved\": preds.reshape(-1),\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"85fe053ebb87c831374b90de39b98b98c6ef5751","_cell_guid":"07e0e41b-59bb-471f-bf00-871302848c9e"},"cell_type":"markdown","source":"## Something can be tried to improve the model\n\n- Add more features for input data\n- Increase Embedding output size\n- Try difference learning rate\n- Add BatchNormalization layer\n- Add Dropout layer\n- Add more Des"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}