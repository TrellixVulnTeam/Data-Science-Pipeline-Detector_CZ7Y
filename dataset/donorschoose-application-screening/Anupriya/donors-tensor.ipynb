{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nfrom matplotlib import pyplot as plt\n\n# Filepath to main training dataset.\ntrain_file_path = '../input/train.csv'\n\n# Read data and store in DataFrame.\ntrain_data = pd.read_csv(train_file_path, sep=',')\n\ntrain_data.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99432bb8d9e6103f07353cd0cea63d8dba07fdb9","_cell_guid":"b17562cc-b935-467a-9ffd-58bfa6bbcac8","trusted":false,"collapsed":true},"cell_type":"code","source":"train_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4326c169e468f501a109b88c09e62a12c892ec38","_cell_guid":"ae6b790c-7a2c-4263-864a-115d7bf35183","trusted":false,"collapsed":true},"cell_type":"code","source":"# Describe data set and retrieve data for teacher_number_of_previously_posted_projects\ntrain_data.describe()[\"teacher_number_of_previously_posted_projects\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39b5d27caf8d8e565197ac6fc46f18e610d3c64f","_cell_guid":"a6d4c148-cf4e-435c-a66f-441b8b24620f","trusted":false,"collapsed":true},"cell_type":"code","source":"# Plot histogram with 45 bins; each bin representing a range of 10\nplt.hist(train_data[\"teacher_number_of_previously_posted_projects\"], bins=45)\nplt.xticks(range(0, 500, 50))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed69211c1128e57873aa06aacc9b10235bf1b937","_cell_guid":"efd5d574-4391-4026-a392-5122988dee6e","trusted":false,"collapsed":true},"cell_type":"code","source":"# Plot histogram with 45 bins; each bin representing a range of 10\nplt.hist(train_data[\"teacher_number_of_previously_posted_projects\"], bins=[0, 10, 450])\nplt.xticks(range(0, 500, 50))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6ae5e49aee24499f8d8bbc0685681c3f1d3ca99","_cell_guid":"0b735b4b-f9fe-426c-947e-83f54bdf6cbf","trusted":false,"collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.data import Dataset\nimport numpy as np\nimport sklearn.metrics as metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f9d926eec670ec7cb8f8c8a8bbc6f96be688e7b","collapsed":true,"_cell_guid":"610271a7-63df-4f9c-9e08-7b2562315a67","trusted":false},"cell_type":"code","source":"# Define predictor feature(s); start with a simple example with one feature.\nmy_feature_name = 'teacher_number_of_previously_posted_projects'\nmy_feature = train_data[[my_feature_name]]\n\n# Specify the label to predict.\nmy_target_name = 'project_is_approved'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"060918f5172907f5297f00d84beb308a77380f44","collapsed":true,"_cell_guid":"46cae2a8-10d4-477e-8e4c-11e115525ea6","trusted":false},"cell_type":"code","source":"# Prepare training and validation sets.\nN_TRAINING = 160000\nN_VALIDATION = 100000\n\n# Choose examples and targets for training.\ntraining_examples = train_data.head(N_TRAINING)[[my_feature_name]].copy()\ntraining_targets = train_data.head(N_TRAINING)[[my_target_name]].copy()\n\n# Choose examples and targets for validation.\nvalidation_examples = train_data.tail(N_VALIDATION)[[my_feature_name]].copy()\nvalidation_targets = train_data.tail(N_VALIDATION)[[my_target_name]].copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4320bc4a4cbbf9d4de213203bfa2fd8cb9709e6f","collapsed":true,"_cell_guid":"a1365815-cc6a-4218-b5ee-9581f1686929","trusted":false},"cell_type":"code","source":"def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n    \"\"\"Trains a linear regression model of one feature.\n  \n    Args:\n      features: pandas DataFrame of features\n      targets: pandas DataFrame of targets\n      batch_size: Size of batches to be passed to the model\n      shuffle: True or False. Whether to shuffle the data.\n      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n    Returns:\n      Tuple of (features, labels) for next data batch\n    \"\"\"\n    \n    # Convert pandas data into a dict of np arrays.\n    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n \n    # Construct a dataset, and configure batching/repeating\n    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    \n    # Shuffle the data, if specified\n    if shuffle:\n      # Shuffle with a buffer size of 10000\n      ds = ds.shuffle(10000)\n    \n    # Return the next batch of data\n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features, labels","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8638993e448d8f3d9e68c5abbaff83a168857af7","_cell_guid":"849ea690-a642-4d66-a65b-a1a86984f309","trusted":false,"collapsed":true},"cell_type":"code","source":"# Learning rate for training.\nlearning_rate = 0.00001\n\n# Function for constructing feature columns from input features\ndef construct_feature_columns(input_features):\n  \"\"\"Construct the TensorFlow Feature Columns.\n  Args:\n    input_features: The names of the numerical input features to use.\n  Returns:\n    A set of feature columns\n  \"\"\"\n  return set([tf.feature_column.numeric_column(my_feature)\n              for my_feature in input_features])\n\n# Create a linear classifier object.\nmy_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n# Set a clipping ratio of 5.0\nmy_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)  \nlinear_classifier = tf.estimator.LinearClassifier(\n    feature_columns=construct_feature_columns(training_examples),\n    optimizer=my_optimizer\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8970d9b3982c7ca20cdb107aaea6c4daae15c148","collapsed":true,"_cell_guid":"4133b2d0-c75e-4f0d-9bc3-b7d4de650009","trusted":false},"cell_type":"code","source":"#Create input functions for training the model, predicting on the prediction data, and predicting on the validation data:\nbatch_size = 10\n\n# Create input function for training\ntraining_input_fn = lambda: my_input_fn(training_examples, \n                                        training_targets[my_target_name],\n                                        batch_size=batch_size)\n\n# Create input function for predicting on training data\npredict_training_input_fn = lambda: my_input_fn(training_examples,\n                                                training_targets[my_target_name],\n                                                num_epochs=1, \n                                                shuffle=False)\n\n# Create input function for predicting on validation data\npredict_validation_input_fn = lambda: my_input_fn(validation_examples,\n                                                  validation_targets[my_target_name],\n                                                  num_epochs=1, \n                                                  shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbbf04a0dfc6de82c86676cf11806e5efb7584f4","_cell_guid":"4a96fe0c-b527-4268-bb55-026e8091f777","trusted":false,"collapsed":true},"cell_type":"code","source":"#Finally, train the model. This may take a few minutes. When training is complete, the training and validation log losses will be output:\n# Train for 200 steps\nlinear_classifier.train(\n  input_fn=training_input_fn,\n  steps=200\n)\n\n# Compute predictions.    \ntraining_probabilities = linear_classifier.predict(\n    input_fn=predict_training_input_fn)\ntraining_probabilities = np.array(\n      [item['probabilities'] for item in training_probabilities])\n    \nvalidation_probabilities = linear_classifier.predict(\n    input_fn=predict_validation_input_fn)\nvalidation_probabilities = np.array(\n    [item['probabilities'] for item in validation_probabilities])\n    \ntraining_log_loss = metrics.log_loss(\n    training_targets, training_probabilities)\nvalidation_log_loss = metrics.log_loss(\n    validation_targets, validation_probabilities)\n  \n# Print the training and validation log loss.\nprint(\"Training Loss: %0.2f\" % training_log_loss)\nprint(\"Validation Loss: %0.2f\" % validation_log_loss)\n\nauc = metrics.auc\nauc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f7b5be0ada7ae3102b79df9753107d4a8a099d2","collapsed":true,"_cell_guid":"13535eff-ef45-4f4a-b42e-6b78b12f6d37","trusted":false},"cell_type":"code","source":"#Next, let's calculate the AUC (area under the curve), which is the metric this competition uses to assess the accuracy of prediction. This may take a few minutes. When calculation is complete, the training and validation AUC values will be output:\ntraining_metrics = linear_classifier.evaluate(input_fn=predict_training_input_fn)\nvalidation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\nprint(\"hello\")\nprint(\"AUC on the training set: %0.2f\" % training_metrics['auc'])\nprint(\"AUC on the validation set: %0.2f\" % validation_metrics['auc'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47a0201d91f29a45fda30cdb48ec0330bc3b2e96","collapsed":true,"_cell_guid":"12a86517-a5d0-4512-a881-09ea1dc26415","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f48b3229b7d97593bc31b94063f8b976de37437","collapsed":true,"_cell_guid":"5309f02f-a23e-4760-a3ae-014088225b9c","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec931f876492357e4a8885fdd703ce92b3d8c008","collapsed":true,"_cell_guid":"47fb468a-d3f1-4380-92a2-e1b76e45a553","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb1345aa3229b8e230f395c395aa2047723081b4","collapsed":true,"_cell_guid":"7b41208c-801e-41bd-b169-25c3cd68fbd2","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}