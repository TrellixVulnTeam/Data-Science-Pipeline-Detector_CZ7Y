{"cells":[{"metadata":{"_cell_guid":"da81d9e6-9949-4cec-b1a1-c0be961731a0","_uuid":"ab773c1049ca7925cf98b9e1a6ba49349565011a"},"cell_type":"markdown","source":"### LightGBM and NMF starter code"},{"metadata":{"_cell_guid":"99cb4869-3741-43f6-be5f-2fce91de8d75","_uuid":"8bee84d35320ee3036bf9653205dc53c49cd494d"},"cell_type":"markdown","source":"Non-Negative Matrix Factorization (NMF) is described well in the paper by [Lee and Seung, 1999][1].\n\n**Simply Put**\n\nNMF takes as an input a [term-document matrix][2] and generates a set of topics that represent weighted sets of co-occurring terms. The discovered topics form a basis that provides an efficient representation of the original documents. \n\n**About NMF**\n\nNMF is used for [feature extraction][3] and is generally seen to be useful when there are many attributes, particularly when the attributes are ambiguous or are not strong predictors. By combining attributes NMF can display patterns, topics, or themes which have importance.\n\nIn practice, one encounters NMF typically where text is involved. Consider an example, where the same word (love) in a document could different meanings:\n\n 1. I *love* lettuce wraps.\n 2. I *love* the way I feel when I'm on vacation in Mexico.\n 3. I *love* my dog, Euclid.\n 4. I *love* being a Data Scientist.\n\nIn all 4 cases, the word 'love' is used, but it has a different meaning to the reader. By combining attributes, NMF introduces context which creates additional predictive power.\n\n$\"love\" + \"lettuce \\ wraps\" \\ \\Rightarrow \\ \"pleasure \\ by \\ food\"$\n$\"love\" + \"vacation \\ in \\ Mexico\" \\ \\Rightarrow \\ \"pleasure \\ by \\ relaxation\"$\n$\"love\" + \"dog\" \\ \\Rightarrow \\ \"pleasure \\ by \\ companionship\"$\n$\"love\" + \"Data \\ Scientist\" \\ \\Rightarrow  \\ \"pleasure \\ by  \\ occupation\"$\n\n**How Does It Happen**\n\nNMF breaks down the multivariate data by creating a user-defined number of features. Each one of these features is a combination of the original attribute set. It is also key to remember these coefficients of these linear combinations are non-negative. \n\nAnother way to think about it is that NMF breaks your original data features (let's call it V) into the product of two lower ranked matrices (let's call it W and H). NMF uses an iterative approach to modify the initial values of W and H so that the product approaches V. When the approximation error converges or the user-defined number of iterations is reached, NMF terminates.\n\n**NMF data preparation**\n\n - Numeric attributes are normalized. \n - Missing numerical values are replaced with the mean. \n - Missing categorical values are replaced with the mode.\n\nIt is important to note that outliers can impact NMF significantly. In practice, most Data Scientist use a clipping transformation before binning or normalizing. In addition, NMF in many cases will benefit from normalization. \n\nAs in many other algorithmic cases, to improve matrix factorization, one needs to decrease the error tolerance (which will increase compute time). \n\n\n  [1]: https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjQvKC6zc_QAhXLMSYKHY9pDVwQFggcMAA&url=http%3A%2F%2Fwww.columbia.edu%2F~jwp2128%2FTeaching%2FW4721%2Fpapers%2Fnmf_nature.pdf&usg=AFQjCNHOf7BKOMfBKKs1wJ2SxSwfj7bgaA\n  [2]: https://en.wikipedia.org/wiki/Document-term_matrix\n  [3]: https://en.wikipedia.org/wiki/Feature_extraction\n  \nCredits:\n[Oleg Panichev](https://www.kaggle.com/opanichev/lightgbm-and-tf-idf-starter/code)"},{"metadata":{"_cell_guid":"8936a82b-58c5-48b6-8099-1ac9f151f405","_uuid":"6ed16a7ec0fdba2d1fc0b4eb6451f913230d7195"},"cell_type":"markdown","source":"#### Essential imports"},{"metadata":{"collapsed":true,"_cell_guid":"65c1a8a9-829c-4d41-9338-a3a0b6e42337","_uuid":"babcb9dd73a87fef7f64745c19678220a0552b7a","trusted":false},"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nimport os\n\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold, RepeatedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm import tqdm\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f65a8091-2351-4654-bd7a-719e6c6a49e8","_uuid":"fd5584f46fb9c86d70c263abb44a43eab3ce8ed3"},"cell_type":"markdown","source":"#### Load data"},{"metadata":{"collapsed":true,"_cell_guid":"6e0b46d9-4344-4278-9432-d8b65d58a534","_uuid":"0d4b68023179e5905941cda70d2d37f216285afd","trusted":false},"cell_type":"code","source":"dtype = {\n    'id': str,\n    'teacher_id': str,\n    'teacher_prefix': str,\n    'school_state': str,\n    'project_submitted_datetime': str,\n    'project_grade_category': str,\n    'project_subject_categories': str,\n    'project_subject_subcategories': str,\n    'project_title': str,\n    'project_essay_1': str,\n    'project_essay_2': str,\n    'project_essay_3': str,\n    'project_essay_4': str,\n    'project_resource_summary': str,\n    'teacher_number_of_previously_posted_projects': int,\n    'project_is_approved': np.uint8,\n}","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_kg_hide-output":false,"_cell_guid":"f9f6d008-9b1b-4a9c-bdc0-bcb16b69070f","_uuid":"d6d5137e4cd8e9931db390ba66174638d27e3e1c","trusted":false},"cell_type":"code","source":"data_path = os.path.join('..', 'input')\ntrain = pd.read_csv(os.path.join(data_path, 'train.csv'), dtype=dtype, low_memory=True)\ntest = pd.read_csv(os.path.join(data_path, 'test.csv'), dtype=dtype, low_memory=True)\nres = pd.read_csv(os.path.join(data_path, 'resources.csv'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"252b1cea-f619-4754-bcf9-59db1f4c89e8","_uuid":"4de93e91ce8d89b91154204a2eec5937100c8fce"},"cell_type":"markdown","source":"#### Preprocess data"},{"metadata":{"collapsed":true,"_cell_guid":"36dce4c6-ab99-479b-a4c0-11af7c1a1a1e","_uuid":"9075fb5ba2210cd8d808a4815dc8ae8d52577749","trusted":false},"cell_type":"code","source":"train['project_essay'] = train.apply(lambda row: ' '.join([\n    str(row['project_title']),\n    str(row['project_essay_1']), \n    str(row['project_essay_2']), \n    str(row['project_essay_3']), \n    str(row['project_essay_4']),\n    str(row['project_resource_summary']),]), axis=1)\ntest['project_essay'] = test.apply(lambda row: ' '.join([\n    str(row['project_title']),\n    str(row['project_essay_1']), \n    str(row['project_essay_2']), \n    str(row['project_essay_3']), \n    str(row['project_essay_4']),\n    str(row['project_resource_summary']),]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"fe38b82c-77cc-46ce-bb64-f945896d50bd","_uuid":"25f290778066c32a8c91b72e1b164284f96c7ff4","trusted":false},"cell_type":"code","source":"def extract_features(df):\n    df['project_title_len'] = df['project_title'].apply(lambda x: len(str(x)))\n    df['project_essay_1_len'] = df['project_essay_1'].apply(lambda x: len(str(x)))\n    df['project_essay_2_len'] = df['project_essay_2'].apply(lambda x: len(str(x)))\n    df['project_essay_3_len'] = df['project_essay_3'].apply(lambda x: len(str(x)))\n    df['project_essay_4_len'] = df['project_essay_4'].apply(lambda x: len(str(x)))\n    df['project_resource_summary_len'] = df['project_resource_summary'].apply(lambda x: len(str(x)))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"3c868e5f-0230-4784-ad2a-41c742b22786","_uuid":"0a68bdc980176fb097c0d812fe9d897ac0d1b7db","trusted":false},"cell_type":"code","source":"extract_features(train)\nextract_features(test)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"e783c0b3-1e41-4210-8972-c3a15156d63d","_uuid":"5d4ff904e1b247f84bb5e8e9c426740ed5ca55b4","trusted":false},"cell_type":"code","source":"train = train.drop([\n    'project_essay_1', \n    'project_essay_2', \n    'project_essay_3', \n    'project_essay_4'], axis=1)\ntest = test.drop([\n    'project_essay_1', \n    'project_essay_2', \n    'project_essay_3', \n    'project_essay_4'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"424d0c16-3c04-4462-bd1a-6a42ca6d789e","_uuid":"d6c1bac8ad4edbf975e3d78b5a03b48f6ed2acc9"},"cell_type":"markdown","source":"#### Merge with resources"},{"metadata":{"collapsed":true,"_cell_guid":"d76323a7-be40-480f-a33d-33144ec12534","_uuid":"a8f7643cc76f0e01b523dc3d765f6d695c4ba9d7","trusted":false},"cell_type":"code","source":"df_all = pd.concat([train, test], axis=0)\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9ef6b74d-65a2-4d4d-81c4-d6a95fec27d4","_uuid":"069aa85668111bd185172d9c81b8980c47945dee","trusted":false},"cell_type":"code","source":"res = pd.DataFrame(res[['id', 'price']].groupby('id').price.agg(\\\n    [\n        'count', \n        'sum', \n        'min', \n        'max', \n        'mean', \n        'std', \n        # 'median',\n        lambda x: len(np.unique(x)),\n    ])).reset_index()\ntrain = train.merge(res, on='id', how='left')\ntest = test.merge(res, on='id', how='left')\ndel res\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f1cdcbb3-321c-45af-ab2e-dc971868039a","_uuid":"b3489e7a2fbe2e42c7c1865afc1e67b1c4927cfb"},"cell_type":"markdown","source":"#### Preprocess columns with label encoder"},{"metadata":{"collapsed":true,"_cell_guid":"f137278a-b436-4ef2-93af-e588eb409753","_uuid":"96c09e8025bb34b1d4bf43cba1c248be0d285536","trusted":false},"cell_type":"code","source":"cols = [\n    'teacher_id', \n    'teacher_prefix', \n    'school_state', \n    'project_grade_category', \n    'project_subject_categories', \n    'project_subject_subcategories'\n]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"eb23c401-a2c9-4761-98e2-e4d3b5b5e2dd","_uuid":"22d8de80b7b2d9beafb0ec85cb2e37c6961fc9c6","trusted":false},"cell_type":"code","source":"for c in cols:\n    le = LabelEncoder()\n    le.fit(df_all[c].astype(str))\n    train[c] = le.transform(train[c].astype(str))\n    test[c] = le.transform(test[c].astype(str))\ndel le\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"206617be-4091-423c-9354-d85f52b7d22b","_uuid":"73a11ae0231acfd7e8121f3b2079cc02e9e7c1a2"},"cell_type":"markdown","source":"#### Preprocess timestamp"},{"metadata":{"collapsed":true,"_cell_guid":"d419d8cb-d596-4c43-bc48-bcc3ade6050e","_uuid":"84b30d382af2a4c92a8409de0b024950ca564cc3","trusted":false},"cell_type":"code","source":"train['project_submitted_datetime'] = pd.to_datetime(train['project_submitted_datetime']).values.astype(np.int64)\ntest['project_submitted_datetime'] = pd.to_datetime(test['project_submitted_datetime']).values.astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"382f11f3-7834-45db-903a-3a9864194ea1","_uuid":"8a4712925a7f14c3e548606edf453ef50a92ecd5"},"cell_type":"markdown","source":"#### Preprocess text"},{"metadata":{"collapsed":true,"_cell_guid":"4617fbee-de47-45c7-a4ad-66736922b4f4","_uuid":"bd273bdd90ee82a108a00c95b2ec1324e461f167","trusted":false},"cell_type":"code","source":"def print_top_words(model, feature_names, n_top_words):\n    for topic_idx, topic in enumerate(model.components_):\n        message = \"Topic #%d: \" % topic_idx\n        message += \" \".join([feature_names[i]\n                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n        print(message)\n        print(\"-\"*50)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4cee9449-c17b-434e-911e-71f5bdf06906","_uuid":"3f9f0ffdec83042bb2471ac6aec76d464871fc54","trusted":false},"cell_type":"code","source":"n_samples = 2000\nn_features = 1000\nn_components = 10\nn_top_words = 20","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"cd777ef4-844f-46c5-b23d-ca6b7dfd97d6","_uuid":"03b60e0747ce6ab5375bce50eae3cad6b15600e7","trusted":false},"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n                                   max_features=n_features,\n                                   stop_words='english')\ntfidf = tfidf_vectorizer.fit_transform(df_all[\"project_essay\"])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"39815a09-9c58-45cc-a01a-ca44db06a11f","_uuid":"4ee0dd439883f674dce25d08f112255a5fc3387f"},"cell_type":"markdown","source":"### NMF"},{"metadata":{"collapsed":true,"_cell_guid":"af8adfed-bcd5-48af-b4d4-33c44c8139b3","_uuid":"ac58a3dddef87fb0ff6125700c32ab9a4900da47","trusted":false},"cell_type":"code","source":"nmf = NMF(n_components=n_components, random_state=1,\n          alpha=.1, l1_ratio=.5).fit(tfidf)\ntfidf_feature_names = tfidf_vectorizer.get_feature_names()\nprint_top_words(nmf, tfidf_feature_names, n_top_words)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"aec741fd-e74d-4962-8ec5-1b7288d1ba81","_uuid":"90603812359d6c94b3d3f0a14f023581a67d0b72","trusted":false},"cell_type":"code","source":"train_nmf = pd.DataFrame(nmf.transform(tfidf_vectorizer.transform(train.project_essay)),\n                         columns=[\"nmf_%d\"%i for i in range(n_components)])\ntrain = pd.concat([train, train_nmf], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a981c50b-dfa6-4b46-a63a-32139de5b60c","_uuid":"a54b38fa0610d93d828e9d71f823ddcc026d9b74","trusted":false},"cell_type":"code","source":"test_nmf = pd.DataFrame(nmf.transform(tfidf_vectorizer.transform(test.project_essay)),\n                         columns=[\"nmf_%d\"%i for i in range(n_components)])\ntest = pd.concat([test, test_nmf], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f363e9f0-6a8b-4fcf-b0aa-c11aa03dd801","_uuid":"ab345988c3799b440d487bf89c3b26dcaab53ce4"},"cell_type":"markdown","source":"#### Pepare data"},{"metadata":{"collapsed":true,"_cell_guid":"6df63a98-52cb-4fc4-b745-5ea86e580e42","_uuid":"6e3b40c9bbb6424c89220113665598a82ca1b4bb","trusted":false},"cell_type":"code","source":"cols_to_drop = [\n    'id',\n    'project_title', \n    'project_essay', \n    'project_resource_summary',\n    'project_is_approved',\n]\nX = train.drop(cols_to_drop, axis=1, errors='ignore')\ny = train['project_is_approved']\nX_test = test.drop(cols_to_drop, axis=1, errors='ignore')\nid_test = test['id'].values\nfeature_names = list(X.columns)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c44e595f-035f-4235-b827-e4cd163a7133","_uuid":"aeaac2b953cac1e855c481c4e4b79f8267b03e02","trusted":false},"cell_type":"code","source":"del train, test\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aeb78705-f4dc-4d6e-a23f-932bfcd4bd41","_uuid":"5772b4f8288dc4b8c400d25d7598f2da99ea54b6"},"cell_type":"markdown","source":"#### Build the LGB model"},{"metadata":{"collapsed":true,"_cell_guid":"dc1c2c6c-5807-4d7d-8560-d0a31dcb2a6b","_uuid":"86dd2135cf035663897e0cba7e76436d9e99bf41","trusted":false},"cell_type":"code","source":"cnt = 0\np_buf = []\nn_splits = 10\nn_repeats = 1\nkf = RepeatedKFold(\n    n_splits=n_splits, \n    n_repeats=n_repeats, \n    random_state=0)\nauc_buf = []  ","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_kg_hide-output":true,"_cell_guid":"a677cf41-43ba-45e8-8ce5-aacbe5665f7e","_uuid":"42d57bf287e697b171243ea7ab49a6611632eac0","trusted":false},"cell_type":"code","source":"for train_index, valid_index in kf.split(X):\n    print('Fold {}/{}'.format(cnt + 1, n_splits))\n    params = {\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': 'auc',\n        'max_depth': 16,\n        'num_leaves': 64,\n        'learning_rate': 0.025,\n        'verbose': 0,\n        'num_threads': 1,\n        'lambda_l2': 0.7,\n    }  \n\n    \n    model = lgb.train(\n        params,\n        lgb.Dataset(X.loc[train_index], y.loc[train_index], feature_name=feature_names),\n        num_boost_round=10000,\n        valid_sets=[lgb.Dataset(X.loc[valid_index], y.loc[valid_index])],\n        early_stopping_rounds=100,\n        verbose_eval=100,\n    )\n\n    if cnt == 0:\n        importance = model.feature_importance()\n        model_fnames = model.feature_name()\n        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n        tuples = [x for x in tuples if x[1] > 0]\n        print('Important features:')\n        print(tuples[:50])\n\n    p = model.predict(X.loc[valid_index], num_iteration=model.best_iteration)\n    auc = roc_auc_score(y.loc[valid_index], p)\n\n    print('{} AUC: {}'.format(cnt, auc))\n\n    p = model.predict(X_test, num_iteration=model.best_iteration)\n    if len(p_buf) == 0:\n        p_buf = np.array(p)\n    else:\n        p_buf += np.array(p)\n        \n    auc_buf.append(auc)\n    cnt += 1\n\n    del model\n    gc.collect();","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"43054c6e-080d-4189-922e-cfd0f39ad915","_uuid":"be4ae5b9d391833d75fb98c50010d4b20de488c4","trusted":false},"cell_type":"code","source":"auc_mean = np.mean(auc_buf)\nauc_std = np.std(auc_buf)\nprint('AUC = {:.6f} +/- {:.6f}'.format(auc_mean, auc_std))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f85f7598-78b6-4ab7-92cb-d23ab69b203e","_uuid":"34a4439d4e8b968edcacb40bef3c060ab6711730","trusted":false},"cell_type":"code","source":"preds = p_buf/cnt\nsubm = pd.DataFrame()\nsubm['id'] = id_test\nsubm['project_is_approved'] = preds\nsubm.to_csv('submission_nmf.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}