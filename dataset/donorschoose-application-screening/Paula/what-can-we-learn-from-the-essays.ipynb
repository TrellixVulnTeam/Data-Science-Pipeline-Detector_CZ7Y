{"cells":[{"metadata":{"_cell_guid":"cb0094e7-ecae-4074-9676-7dad43ae88c4","_uuid":"6bc4d6369ae23ef4628eac800ce49d84e0bbac5d"},"cell_type":"markdown","source":"# Motivation\n- What can we learn about the types of projects that get approved for DonorsChoose from the teacher submitted essays?\n- Can teachers submitting projects to DonorChoose gain any insights about what to submit to increase their chances of approval?\n- Are there any particular topics that stand out in the projects that get approved?\n- What about essay length? Vocabulary? Spelling errors?"},{"metadata":{"_cell_guid":"dea5148a-276e-42df-992d-ccc00e2d4360","_uuid":"ee8e31a4f7f22decc6aa5cb6d4dc8b65f84f27ab"},"cell_type":"markdown","source":"# Contents"},{"metadata":{"_cell_guid":"38a894e1-b622-4cb7-be54-efa956bcb3d8","_uuid":"262341212b1bbb16d5124f35e7c478f8d4dbc531"},"cell_type":"markdown","source":"PART I\n- Clean Text Data\n- Consolidate Resources (Description & Price)\n\nPART II\n- Explore Rejected Project Proposals\n- A Tangent: Impact of Resource Cost\n- Vocabulary Length and Diversity\n- Full Corpus Tokens Exploration\n- Token Frequency\n- Top 20 Tokens\n\nNote: Every section in the second part has a **~ SUMMARY~** section that summarizes the results. Whenever it isn't obvious I have included a legend, but I kept the colors consistent with blue representing the accepted proposals and orange representing the rejected proposals."},{"metadata":{"_cell_guid":"6f486f81-7d22-4a07-bd3a-e9f31db4879d","_uuid":"289718cdfe00ab6cfffa82234752c85a4599d829"},"cell_type":"markdown","source":"---"},{"metadata":{"_cell_guid":"f3efdf00-a250-41d2-9216-dc693053a728","_uuid":"36471f4ec76d0647cf5e27f9fb71e45acc91c912"},"cell_type":"markdown","source":"# PART I"},{"metadata":{"_cell_guid":"94196252-a4ba-4b2b-8843-ef7661307cbe","_uuid":"aa505c1d387880d109ee80a3f913726630fa41c2"},"cell_type":"markdown","source":"#### Modules"},{"metadata":{"_cell_guid":"be3a2341-be99-45c5-8325-3e89640bdedd","_uuid":"5250bcd4ed09a2a78fc36b6cfc401a7ce53b261c","collapsed":true,"trusted":false,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"# Import initial modules\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport warnings\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"84fea41e-eb8b-4a7a-a4bf-78ac51619e56","_uuid":"484af7afba82c213ca2226d1249aaae80b14c6a9"},"cell_type":"markdown","source":"#### Load Files"},{"metadata":{"_cell_guid":"a1fca70d-78f7-435b-b580-9a9fe2d520e4","_kg_hide-output":false,"_uuid":"d97a07eb26f09cd05b5406da92f843cea886ef28","collapsed":true,"trusted":false,"_kg_hide-input":true},"cell_type":"code","source":"import os\nfile_path = '../input/'\n\n# # # Running the notebook locally:\n# # Change Directory\n# os.chdir('/Users/paula/Dropbox/15. Kaggle/DonorsChoose/Data')\n# print(os.getcwd()) \n# file_path = ''\n\n# Load the data into multiple dataframes\ntrain_full = pd.read_csv(file_path + 'train.csv')\ntest = pd.read_csv(file_path + 'test.csv')\nresources = pd.read_csv(file_path + 'resources.csv')\nsubmission = pd.read_csv(file_path + 'sample_submission.csv')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"b242a2df-478b-47bf-8148-7c77b700dbbe","_uuid":"ba9198760f3ab1fc9b2a7d3a1636a3a03ea81587"},"cell_type":"markdown","source":"#### Smaller Sample Size"},{"metadata":{"_cell_guid":"e576eabc-a838-4d64-8ef6-91e12d75bae6","_uuid":"325d89a569c84f3158d14b917637e8219011a9a0","collapsed":true,"trusted":false},"cell_type":"code","source":"# Reduce the dataframe for fast compute time (10% of the entire df)\nsample_size = round(len(train_full)*.10)\ntrain = train_full.sample(sample_size, random_state = 1)","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"e763bbb0-1d97-4c83-877e-9148f14d7447","_uuid":"b009900c0f54885545d3c31d4a159f06337fa603"},"cell_type":"markdown","source":"## Clean Text Data"},{"metadata":{"_cell_guid":"cd19bb72-c8ed-4426-b7b1-a05543e24c2f","_uuid":"1551b58143a157f1d4752ba70b25d27f9256e58a"},"cell_type":"markdown","source":"#### Text Function\n    (1) Create a combined column of all the other text columns\n    (2) Remove any special characters from the text column"},{"metadata":{"_cell_guid":"28caddc5-7390-4fec-a66e-bdfaa32eb85b","_uuid":"110e65c90a7a8bc959409e0795fa1017c176b648","collapsed":true,"trusted":false},"cell_type":"code","source":"def clean_input_data(df, combined_col_name, text_column_list, \n                     character_remove_list, character_replace_list, replace_numbers):\n    \n    # (1) Combine all text data into one column, separated by spaces\n    \n    # Remove NaN's in columns\n    df.replace(np.nan, '', regex=True, inplace = True)\n    \n    # Join all text columns into one\n    df[combined_col_name] = ''\n    for t in range(0, len(text_column_list)):\n        df[combined_col_name] += df[text_column_list[t]] + ' '\n    # Replace all numbers with a space \n    if replace_numbers == 1:\n        df[combined_col_name] = df[combined_col_name].replace('\\d+', ' ', regex=True)\n\n    \n    # (2) Remove special characters from the text data\n    for i in range(0,len(character_remove_list)):\n        df[combined_col_name] = df[combined_col_name].apply(\n            lambda x: x.replace(character_remove_list[i], character_replace_list[i])\n        )","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"d6f1c639-422c-400b-be4d-733b711dc088","_uuid":"c59476f56d2d67635ce1c07d765fc1b928cb3f4d"},"cell_type":"markdown","source":"## Consolidate Resources\nCombine the resources df with the main train df, since the resources df has extra text data we might want to include in our model."},{"metadata":{"_cell_guid":"8d1ae2d7-753f-433f-9109-2f27c5e65e72","_uuid":"653cf1bc983c9a5cdc89f76d6aba5bce4332265c","trusted":false},"cell_type":"code","source":"resources.head()","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"2c4cbe20-f631-4006-b3e7-36b823578867","_uuid":"0da890a2e1451cf2a6d88d229e5cafa207b73b3a"},"cell_type":"markdown","source":"#### Combine Resource Decription"},{"metadata":{"_cell_guid":"cb8eb12f-66ce-405e-b347-c36b5c0717ca","_uuid":"65445b8f73bdabb402272cb1137d04e3f67ef8f9","trusted":false},"cell_type":"code","source":"# Reset index to the id\nres = resources.set_index('id')\nres['description'] = res['description'].astype(str)\n\n# Join all the resource descriptions into one string, with a space\n%time rs = res.groupby('id')['description'].apply(lambda x: ' '.join(x))\n\n# Convert rs into a DataFrame\ndf_rs = (pd.DataFrame(rs)).reset_index()\ndf_rs.head()","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"a8e81a0e-2349-4882-bdb0-f3c67b73f229","_uuid":"895288aa9fe79c94e7c2d56d18b88b1cd3e5d85c"},"cell_type":"markdown","source":"#### Combine Resource Prices"},{"metadata":{"_cell_guid":"863609a6-3b82-4ed4-bf9c-f19e825be7c7","_uuid":"1c755c01138cf945a98aff5c64e361753156a21f","trusted":false},"cell_type":"code","source":"df_rsp = pd.DataFrame(res.groupby('id')['price'].sum()).reset_index()\ndf_rsp.head()","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"40a20996-8af6-4fa4-b4b9-6ed4bffe58ef","_uuid":"9b758e965ff258a1880d8a10bbe05736622e6e46"},"cell_type":"markdown","source":"#### Join Aggregated Resources DF's to Main DF"},{"metadata":{"_cell_guid":"34a726b1-d88b-4a05-b292-fb3b3dc4b4d7","_uuid":"91b9b6e80ad27671def050008bd1ced574eae8d3","collapsed":true,"trusted":false},"cell_type":"code","source":"# Join the aggregated resources definitions to the main df\ndf = pd.merge(train, df_rs, on='id',  how='left')\n\n# Join the aggregated resources definitions to the main df\ndf = pd.merge(df, df_rsp, on='id',  how='left')","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"d59b2595-21cf-42cf-8495-50dde80ce66b","_uuid":"f4dac2b48285828cd047263f58f9c1e5ff956126"},"cell_type":"markdown","source":"## Apply Text Clean Up Function"},{"metadata":{"_cell_guid":"c1b12184-689a-49f3-9753-68c556fd0103","_uuid":"56682663b9267ab1859180b89cfdd28d3f649a8f"},"cell_type":"markdown","source":"#### List of all text columns\n- project_essay_1\n- project_essay_2\n- project_essay_3\n- project_essay_4 \n- project_resource_summary\n- project_title\n- description"},{"metadata":{"_cell_guid":"965bcd47-cf63-4a4a-85af-506a1c6d9608","_uuid":"3fe471a8308f01a63823190b9954afe0272ff69a"},"cell_type":"markdown","source":"#### Input Variables"},{"metadata":{"_cell_guid":"6dcdd48e-a932-4f0d-8ab1-3fa7b4641d89","_uuid":"348718ad9f639fe9fc6591305bb78d6a51f0fc79","collapsed":true,"trusted":false},"cell_type":"code","source":"combined_col_name = 'full_essay'\ntext_column_list = ['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']\ncharacter_remove_list = ['\\\\r', '\\\\n', '\\\\']\ncharacter_replace_list = [' ', ' ', ' ']\nreplace_numbers = 1","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"7b8b1466-a2a1-41ba-94c4-ba764fbac479","_uuid":"f15d560bad5b666c0180bb3a0d530092e4e2fec1"},"cell_type":"markdown","source":"#### Create New Text Column"},{"metadata":{"_cell_guid":"a42e554d-6db1-44a5-bd84-e62a9e430308","_uuid":"95debd7031227acf6d7e0ecdc86bc12983fd2179","trusted":false},"cell_type":"code","source":"# Apply the function to create the cleaned DF and additional columns\nclean_input_data(df, combined_col_name, text_column_list, \n                 character_remove_list, character_replace_list, replace_numbers)\n\n# Check the first entry in the dataframe\ndf.head(1)","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"9a70f220-f55f-41e2-a853-6588001a0a36","_uuid":"b2994e81fe1c1eb4c095f8cfd582fea56f1ed695"},"cell_type":"markdown","source":"#### Percentage of Approved Projects"},{"metadata":{"_cell_guid":"59264065-fdef-4903-ad02-548ac087e96b","_uuid":"a2af5764545ffe5b8fb4c7cc6425a3baa6270bd6","trusted":false},"cell_type":"code","source":"round(df['project_is_approved'].sum()*100/len(df['project_is_approved']),2)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"62153ccb-932b-4c76-b6a7-d5c790f8a822","_uuid":"cdc84bcb2e3d2344a8278c7970c5169625704845"},"cell_type":"markdown","source":"# PART II"},{"metadata":{"_cell_guid":"44fb961d-ad35-415a-b5c6-b2607a66cf69","_uuid":"a31b1953490cfc610962958da6b0798cb1c6bbfd"},"cell_type":"markdown","source":"## Explore the Text\nSince most projects get accepted, focus on the the essays that get rejected (hypothesis: these proposals will have shorter sentences, grammar mistakes, overall shorter responses, etc.)"},{"metadata":{"_cell_guid":"1ec098e9-9a0d-4e75-8ff6-e13ef9746efb","_uuid":"6f2389d5fabc1abf155b0ef7c7859ddf60e26f17"},"cell_type":"markdown","source":"#### Rejected Proposal IDs"},{"metadata":{"_cell_guid":"987dc192-26e0-4135-8438-f830e1bfb699","_uuid":"39270273fe053243bf2885ff8bf37079ce5dc144","collapsed":true,"trusted":false},"cell_type":"code","source":"ix_list = df.index[df['project_is_approved']==0].tolist()","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"618348a0-ac39-4a13-acef-1e38d67ec65b","_uuid":"7fe11cda197ff22c33401fe8bc4b3db472a697d3"},"cell_type":"markdown","source":"#### EXPLORE: Full Df"},{"metadata":{"_cell_guid":"b13d765f-53f6-42ba-a3b0-3d610cbf0c33","_uuid":"c99e8d6e77fc0d8632a783b0baaad7db2ce5c072","scrolled":true,"trusted":false},"cell_type":"code","source":"# Set the index of the proposal to explore\nix_num = 2341\n\ndf.loc[[ix_list[ix_num]]]","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"1b4e9c45-8152-47f4-80ad-0d07014a98d1","_uuid":"6bc9f32f21a65c7e6f9ee78a790c5f84af630921"},"cell_type":"markdown","source":"#### EXPLORE: New Text Column\nGoal: Get an understanding of what is being requested."},{"metadata":{"_cell_guid":"5a5efb16-335c-4337-939f-6a7e495a7987","_uuid":"4fef53ed536e093424d2b22a208431e635c9f309","trusted":false},"cell_type":"code","source":"df[df['project_is_approved']==0]['full_essay'][ix_list[ix_num]]","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"dd460b0b-c765-460a-a912-3db13f5464e7","_uuid":"24cf848fb46332c6e3b739ec23e0330db124c8e5"},"cell_type":"markdown","source":"#### EXPLORE: Resource Summary\nGoal: See if there are any insights that arrise from just reading some resources summaries of accepted and rejected projects."},{"metadata":{"_cell_guid":"45809f1c-2af6-4253-ad40-496f55d884b7","_uuid":"2aae889c022457121e01394c7469ac66eec8c72a","trusted":false},"cell_type":"code","source":"df[df['project_is_approved']==0]['project_resource_summary'][ix_list[ix_num]]","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"685d10bb-6875-41e7-b664-74d66f819aec","_uuid":"afa699f548d14268350ab4b6684ad72c230ab1aa"},"cell_type":"markdown","source":"#### EXPLORE: Resource Description\nGoal: What are the item descriptions?"},{"metadata":{"_cell_guid":"7823f975-c93c-4cb9-abac-12405f919509","_uuid":"675a7e6f439b6f225f8cff8dddd29b2058d44066","trusted":false},"cell_type":"code","source":"df[df['project_is_approved']==0]['description'][ix_list[ix_num]]","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"1cc70c13-10aa-473b-abbe-5f84129fce93","_uuid":"17dea85125958d3faef9bb9f53d1cc16a8f93f3a"},"cell_type":"markdown","source":"#### ~ SUMMARY~\n\nSome of the things I noticed: \n- Lying: Resource summary does not match requested items p157746 \n\nWould love to undertand why certain projects got rejected: \n- p099141 ask for Osmo Coding Set $50 index = 54\n\n- p070091 ask for books for kindergarders $200 index = 30\n\n- p007150 ask for counting games $400 index = 100\n\n- p009107 ask for cameras $400 index 1000\n\nWhat is the impact of the cost of the resources asked for?"},{"metadata":{"_cell_guid":"1e35f903-025a-414d-b917-a4a2f05c8751","_uuid":"34ee2ef5c1fc48cd474d1d6e60bb5bd5b9dcc1fc"},"cell_type":"markdown","source":"## A Tangent: Cost"},{"metadata":{"_cell_guid":"fce67ae0-2c57-43f3-b6e1-a51e3a749eb9","_uuid":"36c36f828ece118e73527b6e7fdf4d3001e7168e"},"cell_type":"markdown","source":"#### Function Explore Stats by Column"},{"metadata":{"_cell_guid":"678e0e64-bbeb-4634-835b-ae8db510f563","_uuid":"7b122604f8dfc550521d0d8eedf3ab6b42039fbd","collapsed":true,"trusted":false},"cell_type":"code","source":"def describe_by_approval(col_name):\n    R = pd.DataFrame(df[df['project_is_approved'] == 0][col_name].describe())\n    R[col_name] = round(R[col_name],1)\n    R.rename(columns ={col_name: ('Rejected - ' + col_name) }, inplace = True) \n\n    A = pd.DataFrame(df[df['project_is_approved'] == 1][col_name].describe())\n    A[col_name] = round(A[col_name],1)\n    A.rename(columns ={col_name: ('Accepted - ' + col_name) }, inplace = True) \n    RA = pd.concat([R, A], axis =1, join = \"inner\")\n    display(RA)","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"baf99384-6866-4237-bf4d-9a8c9991f5a8","_uuid":"bcaa2bcb67b09de4ced4c323fdec3331d51de168"},"cell_type":"markdown","source":"#### DISTRIBUTION - Total Resource Cost per Proposal"},{"metadata":{"_cell_guid":"6b3fe79d-2e15-47e5-94a7-376bb03bedbf","_uuid":"00fe059970e7c4ca98b4a24cd3d94f9868e604df","scrolled":true,"trusted":false},"cell_type":"code","source":"describe_by_approval('price')","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"f47d2b6e-7bbb-40dd-a384-e1fa6ab419c3","_uuid":"127e26e09133eae81e28e0856561fda4777d1eec"},"cell_type":"markdown","source":"#### Violin Plots"},{"metadata":{"_cell_guid":"02e381d7-1a47-458e-b193-af64b43d11ea","_uuid":"7baa2645976584a22982533e6b91effc7fcbb5c0","trusted":false},"cell_type":"code","source":"# Violin Chart Inputs\ny1 = 'price'\ny2 = 'price'\ndata1 = df\ndata2 = df[df['price'] < 1000]\nT1 = 'All Proposal Prices'\nT2 = 'Proposals less than $1,000'\n\n# Set Dimension and Color\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\ncolor_set = ['sandybrown','cornflowerblue']\n\n# Graph 1\nsns.violinplot(x='project_is_approved', y=y1, data=data1, cut = 0, palette=color_set, ax=axes[0])\n# Graph 2\nsns.violinplot(x='project_is_approved', y=y2, data=data2, cut = 0, palette=color_set, ax=axes[1])\n\naxes[0].set_title(T1)\naxes[1].set_title(T2)\n\nplt.show()","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"dafb746d-1be9-4937-949e-3f50b43d0637","_uuid":"a5bbdca4e687c8f387869b1b676e7942cdd7a112"},"cell_type":"markdown","source":"#### ~ SUMMARY~\n\nInterestingly, there were some pretty expensive projects that got approved. However, as the earlier exploration eluded to, there seems to be a higher price tag for proposals that get rejected. The median for rejected proposals is $63 dollars more than the accepted proposals. The 75th percentile has an even greater difference. As you can see from the above charts, the approved proposal density plot skews more towards 0, indicating that more projects are cheaper. "},{"metadata":{"_cell_guid":"7879fe5b-b0cf-4bd8-b4f0-9839983315da","_uuid":"01a80a92b5c5c3b73737d7b673453b268ab17101"},"cell_type":"markdown","source":"## Vocabulary Length and Diversity\nAre essays that are shorter more likely to be rejected? What about the variety of vocab terms?"},{"metadata":{"_cell_guid":"42517968-051d-4663-8001-2a8db56713f3","_uuid":"5e959df471167530b4ada697536d556bbd755066"},"cell_type":"markdown","source":"#### CountVectorizer"},{"metadata":{"_cell_guid":"aa2428e1-3efd-436e-a1ac-b968a303bf1b","_uuid":"f84c362f20bdbfce28d6a1b331a5ff5b7d4eff6b","collapsed":true,"trusted":false},"cell_type":"code","source":"text = df.full_essay\n\n# Count the token only once from each document (proxy for vocab variety)\nfrom sklearn.feature_extraction.text import CountVectorizer","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"7d0de727-3a27-457c-bf60-3006691e4dc4","_uuid":"82fce74effcd184ca222499649715b4646d5b620"},"cell_type":"markdown","source":"#### Document Term Matrix"},{"metadata":{"_cell_guid":"830a5403-5771-47a2-895c-36c2cf4a7ddb","_uuid":"4a806aca40dacd02c654910b675afad8099fe97f","collapsed":true,"trusted":false},"cell_type":"code","source":"# Appearance of unique tokens\nvect = CountVectorizer(binary=True)\ndtm_token_unique = vect.fit_transform(text)\n\n# Count all appearances of tokens\nvect = CountVectorizer()\ndtm_token_all = vect.fit_transform(text)","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"a1839bd1-2da1-4b15-a650-7565b857dea7","_uuid":"17550c2ea35a9bae2cb2ccb622ed4d2fb649d230"},"cell_type":"markdown","source":"#### Count Tokens"},{"metadata":{"_cell_guid":"af7f92c1-fd82-4131-92f6-36c0d771ae38","_uuid":"0895cffb6eae43a20c2938e52ce6120dcbff7e46","collapsed":true,"trusted":false},"cell_type":"code","source":"# Count the total number of tokens\ntu = pd.DataFrame(dtm_token_unique.sum(axis=1))\ntu.columns = ['count_unique_tokens']\ndf = pd.concat([df, tu], axis = 1, join = \"inner\")\n\n\nta = pd.DataFrame(dtm_token_all.sum(axis=1))\nta.columns = ['count_all_tokens']\ndf = pd.concat([df, ta], axis = 1, join = \"inner\")","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"a40c4fc0-0abd-4b6c-949a-ac62433a16f8","_uuid":"e3b483ea140461035e4d5afbf6ae5e417b10d1a7"},"cell_type":"markdown","source":"#### DISTRIBUTION - Unique Tokens per Proposal"},{"metadata":{"_cell_guid":"b8d75a28-1848-43b4-9741-e1d79b965cc9","_uuid":"e8a30eec2154fcffbd627e0f09e76a7d0c7b92b5","scrolled":true,"trusted":false},"cell_type":"code","source":"describe_by_approval('count_unique_tokens')","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"84681ef0-0b0c-4f9d-846a-87b5b41cccf4","_uuid":"1b56a414f1403f9a053bb83a4d1c5110f6aa431d"},"cell_type":"markdown","source":"#### DISTRIBUTION - Total Tokens per Poposal"},{"metadata":{"_cell_guid":"2a998e8d-4a9a-4dfe-bef8-7ea60ecdfd6c","_uuid":"aa70614b20890f4f93cc6fccd50296049b8f070e","trusted":false},"cell_type":"code","source":"describe_by_approval('count_all_tokens')","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"2c016a34-7737-4b32-a6e3-984f3054741f","_uuid":"94d0b061ec99c48b6bc981bb0a348971909ca8e4","scrolled":true,"trusted":false},"cell_type":"code","source":"# Violin Chart Inputs\ny1 = 'count_unique_tokens'\ny2 = 'count_all_tokens'\ndata1 = df\ndata2 = df\nT1 = 'Unique Tokens Per Proposal'\nT2 = 'Total Tokens per Proposal'\n\n# Set Dimension and Color\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\ncolor_set = ['sandybrown','cornflowerblue']\n\n# Graph 1\nsns.violinplot(x='project_is_approved', y=y1, data=data1, cut = 0, palette=color_set, ax=axes[0])\n# Graph 2\nsns.violinplot(x='project_is_approved', y=y2, data=data2, cut = 0, palette=color_set, ax=axes[1])\n\naxes[0].set_title(T1)\naxes[1].set_title(T2)\n\nplt.show()","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"9f5bca37-69b9-4c65-b1e0-4fffcd933ccf","_uuid":"ef2bb558f8711fafb88a9b7e0ca86edfb91cbdd3"},"cell_type":"markdown","source":"#### ~ SUMMARY~\n\nAs expected, the approved proposals had a greater variety of tokens, with the median above the rejected proposals (126 vs 132). In our sample, the accepted proposals had a minimum of 70 unique tokens. In terms of essay word length, the accepted proposals also tended to be longer. "},{"metadata":{"_cell_guid":"b10dd389-fa38-4097-b189-15664d315d02","_uuid":"e5212e52ef1a1e872c68592db4b83bc2bfb21708"},"cell_type":"markdown","source":"## Full Corpus Tokens Exploration"},{"metadata":{"_cell_guid":"73e09163-bef8-488b-819a-669d7c221258","_uuid":"06c73193e85a03a417a1d1bb666666a8f73a7b9d"},"cell_type":"markdown","source":"#### Full Data Set"},{"metadata":{"_cell_guid":"be71acb6-356d-40b4-8974-47d9408e1ad8","_uuid":"9c3e538bfd5ba6ec7cbe34a4e0c2dbda2e2db2f8","collapsed":true,"trusted":false},"cell_type":"code","source":"# Clean and combine the essay columns\ntext_column_list = ['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']\n\nclean_input_data(train_full, combined_col_name, text_column_list, \n                 character_remove_list, character_replace_list, replace_numbers)","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"6eb3ae69-6777-4e04-8944-f243ac38316d","_uuid":"189e85cc8e7674eb75b1f06c323f233cdcdb592d"},"cell_type":"markdown","source":"#### Larger Rejected Proposal Sample \nSince the data is so heavily skewed towards accepted proposals, I wanted to get more vocabulary about the rejected proposals (learn more about the text variety/patterns). However, I would still like to keep the run time fairly short, so I am going to keep 10% of the accepted proposals and just increase the sample size for rejected projects. "},{"metadata":{"_cell_guid":"6067af5c-a61b-42fa-94bc-bd162a9bb439","_uuid":"d51cffc6d0c234a769cb928d86308fe38ce750f1","collapsed":true,"trusted":false},"cell_type":"code","source":"# Accepted Proposals 10% Sample Size\naccept_ss = round(len(train_full[train_full['project_is_approved'] == 1])*.10)\n\n# What proportion of the rejected df would I need to equal the same amount from the accepted?\n# Create equal sized dataframes\nac_df = train_full[train_full['project_is_approved'] == 1].sample(accept_ss, random_state = 1)\nre_df = train_full[train_full['project_is_approved'] == 0].sample(accept_ss, random_state = 1)\n\ntrain2 = pd.concat([ac_df, re_df])","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"994524ce-e29f-41a9-a98e-73781dc9385a","_uuid":"bcdf2126f45e9df30bfc580b71b37b41431c3a09"},"cell_type":"markdown","source":"#### Function: Tokens and Model Parems"},{"metadata":{"_cell_guid":"6f3f5bd2-8968-4149-b283-cc2e81853b2b","_uuid":"b882169bbb1bbb088c6fd07bdb7cf585025687ab","collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\n\ndef vectorize_and_get_model_params(data, text_column, output_column):\n    vect = CountVectorizer(binary=True, stop_words = 'english', analyzer=\"word\")\n    X_dtm = vect.fit_transform(data[text_column])\n    print('features:', X_dtm.shape[1])    \n    model.fit(X_dtm, data[output_column])\n    token_list = vect.get_feature_names()","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"67616c69-6141-4563-abc6-b402ff83c883","_uuid":"b03249565f22ab4d0506d6bc6013e234c921f5e7","collapsed":true,"trusted":false},"cell_type":"code","source":"# curious about the variety of vocab?\nvectorize_and_get_model_params(ac_df, 'full_essay', 'project_is_approved')\nvectorize_and_get_model_params(re_df, 'full_essay', 'project_is_approved')","execution_count":29,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"d13f3ef6e788290427293e3e6950f71d2d099a45"},"cell_type":"code","source":"data = train2\ntext_column = 'full_essay'\noutput_column = 'project_is_approved'\n\nvect = CountVectorizer(binary=True, stop_words = 'english', analyzer=\"word\")\nX_dtm = vect.fit_transform(data[text_column])\nprint('features:', X_dtm.shape[1])    \nmodel.fit(X_dtm, data[output_column])\ntoken_list = vect.get_feature_names()","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"b137e237-34e6-4864-964a-eedc010caed1","_uuid":"b0a873b2308f96a178a69d65f6668b4ad8ff55dc"},"cell_type":"markdown","source":"#### ~ SUMMARY~\n\nIn terms of shear number of different tokens, the accepted essay corpus had almost the same amount as the rejected corpus. However, given the feature count of the tokens for both, there is about 7,000 tokens that are NOT shared between the two corpuses.\n\n\nQuestions: Is there a concentration of terms in one corpus or is the vocabulary pretty dispersed? If one has a higher concentration, some pattern can be pulled out. However, if one corpus is more evenly spaced, then there might be more randomness and therefore harder to draw a a conclusion since words aren't as frequently repeated across documents."},{"metadata":{"_cell_guid":"1ea89cd3-374b-454a-a071-4885ac1f7188","_uuid":"ae20ed196f1dadb865ae03d4f50685f43d8968bc"},"cell_type":"markdown","source":"### Token Popularity - Prep"},{"metadata":{"_cell_guid":"4883abf4-75c3-4571-b2a2-f1d05ca1b0d7","_uuid":"fe3171548e2ae0bdb654b2feb56f61a90b7b1dc8"},"cell_type":"markdown","source":"#### Number of Tokens"},{"metadata":{"_cell_guid":"5db51150-347e-4fe4-af1d-b9711917faa6","_uuid":"0420c562e5b10465fca04af4f6346f36f25f8c99","collapsed":true,"trusted":false},"cell_type":"code","source":"# number of times each token appears across all feature flag = 0 (in this case Rejected Project)\nclassA_token_count = model.feature_count_[0, :]\n# number of times each token appears across all ClassB  (Accepted Project)\nclassB_token_count = model.feature_count_[1, :]","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"0c55a8de-e529-4b46-829f-72900f044fb8","_uuid":"55cade609965ac57151dbedcca69fc62b26c7bd2"},"cell_type":"markdown","source":"#### Dataframe of Tokens per Class Type"},{"metadata":{"_cell_guid":"3e81551c-0e00-450c-b8b1-4261922e45fd","_uuid":"3092fce3ce279ad3144883b2de8ddeabb24b6d5d","collapsed":true,"trusted":false},"cell_type":"code","source":"# create a DataFrame of tokens with their separate counts\ntokens = pd.DataFrame({'token': token_list, \n                       'classA: Rejected':classA_token_count, \n                       'classB: Accepted':classB_token_count}).set_index('token')\n# Extract the index column into its own column\ntokens = tokens.reset_index()","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"c38ee9ef-33f3-44be-9cd2-3c3cf19c961a","_uuid":"7cea183100bc7a910a5d461afe7e366ffd021e52"},"cell_type":"markdown","source":"#### Standardize Column Names"},{"metadata":{"_cell_guid":"83f380d1-dbf5-4fd2-9b48-cdfef6fa7ee3","_uuid":"b37fbce10b2052e1835b3e1f3ef566bb3641acc1","collapsed":true,"trusted":false},"cell_type":"code","source":"classA_name = 'classA_norm'\nclassA_count = 'classA: Rejected'\n\nclassB_name = 'classB_norm'\nclassB_count = 'classB: Accepted'","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"2a1fa2be-6786-49bf-ac44-8903e45738d6","_uuid":"cc045faccc8389e743e0eab8286b576ab1279c0f"},"cell_type":"markdown","source":"#### Normalized Frequency Count & Ratio between Corpuses (Class Types)"},{"metadata":{"_cell_guid":"69c96c3b-84f9-45c9-b194-19d2f78f6b33","_uuid":"378d90e2a4cbb3de6db7045d40bcdf3bdc3d22eb","collapsed":true,"trusted":false},"cell_type":"code","source":"# Convert the Rejected and Accepted Class counts into normalized frequencies\ntokens[classA_name] = tokens[classA_count]  / model.class_count_[0]\ntokens[classB_name] = tokens[classB_count]  / model.class_count_[1]\n\n# Add 1 to Rejected and Accepted Class counts to avoid dividing by 0\nA_plus = (tokens[classA_count] + 1)  / model.class_count_[0]\nB_plus = (tokens[classB_count] + 1 )  / model.class_count_[1]\n\n# Calculate the ratio of Accepted-to-Rejected for each token\ntokens['classB_ratio'] = tokens[classB_name] / A_plus\ntokens['classB_ratio'][(tokens[classA_name])>0] = tokens[classB_name] / tokens[classA_name]\n\ntokens['classA_ratio_extra'] = tokens[classA_name] / B_plus\ntokens['classA_ratio_extra'][(tokens[classB_name])>0] = tokens[classA_name] / tokens[classB_name]","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"61345776-f548-4481-baeb-0d5c86365651","_uuid":"f20c9495a02d1f2b9471ec7b3c17b0b3d94431c5"},"cell_type":"markdown","source":"#### Proportion of Tokens within Each Corpus"},{"metadata":{"_cell_guid":"ad317719-31bf-4e7f-8240-43bcc50f6f9b","_uuid":"3905d983420e2053ec4a4c0fcacf382039986ea6","collapsed":true,"trusted":false},"cell_type":"code","source":"## Get proportions (true, without adding 1)\ntokens['classA_proportion'] = 0\ntotal_projects_classA = model.class_count_[0]\ntokens['classA_proportion'][(tokens[classA_count])>0] = (tokens[classA_count]) / total_projects_classA\n\ntokens['classB_proportion'] = 0\ntotal_projects_classB = model.class_count_[1]\ntokens['classB_proportion'][(tokens[classB_count])>0] = (tokens[classB_count]) / total_projects_classB\n\n# Subtract the proportions\ntokens['proportion_diff'] = tokens['classB_proportion'] - tokens['classA_proportion']","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"4cb3c215-70ec-4e27-9626-aa68abf0643a","_uuid":"272d67a28fe6826c5f17bc779dafd0f1f09d6723"},"cell_type":"markdown","source":"## Token Frequency"},{"metadata":{"_cell_guid":"624e7bca-1c11-4b09-9d5e-9420460f909b","_uuid":"b4f2dbbb3ec590ebc9401e5214930ecdaa844761","trusted":false},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(14,8)})\n\nsns.kdeplot(tokens['classB_proportion'], color='cornflowerblue')\nsns.kdeplot(tokens['classA_proportion'], color='sandybrown')\n\nplt.show()","execution_count":38,"outputs":[]},{"metadata":{"_cell_guid":"8a05e961-f03e-401a-9a94-ca4a180f1e80","_uuid":"56c0e7c423c5076b9b61e4e7e6ddb2b1dc42b3af"},"cell_type":"markdown","source":"#### ~ SUMMARY ~\n\nMost terms appear infrequently in each corpus, however, the accepted proposal corpus has slightly more repititon of terms (as can be seen from the blue peak around 0.02)."},{"metadata":{"_cell_guid":"c7488ca0-c58f-44ee-a02c-3cbbf482544e","_uuid":"3fdf70c06dade48d222bdd7332b39a1631a9eefe","collapsed":true,"trusted":false},"cell_type":"code","source":"# What tokens appear more than 25% of both the corpuses and are a min length of 2?\ntype_best = tokens[((tokens['classB_proportion'] >= 0.25) | (tokens['classA_proportion'] >= 0.25)  ) \n                   & (tokens['token'].str.len() > 2)\n      ].sort_values('classB_ratio', ascending=False)","execution_count":39,"outputs":[]},{"metadata":{"_cell_guid":"d62ad8c4-d5dd-403c-bf70-d7033a126488","_uuid":"aa9b5ee29de478aa792926b5427f7cbe341a5bf9"},"cell_type":"markdown","source":"#### Visualize Ratio of Accepted Proposal Tokens to Rejected Tokens"},{"metadata":{"_cell_guid":"fde2f31e-053b-43c9-b877-bce6aaee2095","_uuid":"e891b558a087c67a2bc70d0acd03aa488a2e2682","trusted":false},"cell_type":"code","source":"from pylab import suptitle, yticks\n\nmain_var = 'classB_ratio'\nsecondary_var = 'classA_ratio_extra'\ntype_best = type_best.sort_values(main_var, ascending = True)\n\nval1 = type_best[main_var].tolist()\nx_max = max(type_best[main_var].max(), type_best[secondary_var].max())\nval2 = type_best[secondary_var].tolist()\n\nbars = type_best['token'].tolist()\npos = np.arange(len(val1))\n\n\nfig, axes = plt.subplots(ncols=2, sharey=True)\nfig.set_size_inches(7, 11)\naxes[0].barh(pos,val1, align='center', color='cornflowerblue', label = 'Accepted')\naxes[1].barh(pos,val2, align='center', color='sandybrown', label = 'Rejected')\n\nyticks(pos, bars, fontsize = 14)\n\naxes[0].yaxis.set_tick_params(labelsize=14)\naxes[0].xaxis.set_tick_params(labelsize=14)\naxes[1].xaxis.set_tick_params(labelsize=14)\n\n\naxes[0].set_xlim(0, x_max+.1*x_max)\naxes[0].invert_xaxis()\naxes[1].set_xlim(0, x_max+.1*x_max)\n\n\ntitle_string = \"Ratio of Tokens between Corpus Types\"\nsuptitle(title_string, fontsize=18, fontweight='bold')\n\naxes[0].legend(bbox_to_anchor=(0.1, 1.0, 1., .102), loc=3,\n           ncol=2, mode=\"expand\", borderaxespad=0.)\naxes[1].legend(bbox_to_anchor=(0.1, 1.0, 1., .102), loc=3,\n           ncol=2, mode=\"expand\", borderaxespad=0.)\n\nplt.show()","execution_count":42,"outputs":[]},{"metadata":{"_cell_guid":"5a12d688-ff6b-43df-9dd3-b96db9381bbc","_uuid":"3aac1fd85be0f1cc79128c6781ead9a7b4934a60"},"cell_type":"markdown","source":"#### ~ SUMMARY ~\n\nThere aren't that many frequent terms (as seen in the previous chart) and those words that repeat, repeat for both corpuses. Tokens: `reading` and `technology` are a couple of tokens that seem to appear more frequently in Accepted proposals (though these words appear in both corpuses in over 25% of essays). One token that jumps out as appearing more in one corpus and not the other is the token `material`. Perhaps there is a focus on general materials in the rejected proposals while the accepted proposals focus on talking about materials less?"},{"metadata":{"_cell_guid":"315fdf16-13b6-4db1-8e79-119d2a7858da","_uuid":"cec4a37fb92619125c9a8c362790ae6f03dcc449"},"cell_type":"markdown","source":"## Top 20 Tokens"},{"metadata":{"_cell_guid":"6e7d0081-f159-43ce-ae92-d5fe43d24d9b","_uuid":"3d1087c98d45cc7c790ade10e08d1b09bfd1bf8b"},"cell_type":"markdown","source":"### Accepted Proposal Popular Tokens\nAppear at least in more than 0.5% of the documents. Sorted by ratio of appearances in the Accepted Proposals versus the Rejected Proposals."},{"metadata":{"_cell_guid":"4b8105a9-4d14-4ce3-91c4-505f4aee7cee","_uuid":"aae0c27af4f556a66663cc2a1064b2c4a8ec8350","scrolled":true,"trusted":false},"cell_type":"code","source":"type_best = tokens[(tokens['classB_proportion'] > 0.005) & (tokens['token'].str.len() > 2)\n      ].sort_values('classB_ratio', ascending=False).head(50)\n\ntype_best[['token', 'classA_norm', 'classB_norm', 'classB_ratio']].head(20)","execution_count":43,"outputs":[]},{"metadata":{"_cell_guid":"3b8d5828-03c5-4bb7-a032-88918256719e","_uuid":"f8a0ddf7e886f10b6cf02b4bf78ff2c76c7b1e7e"},"cell_type":"markdown","source":"### Rejected Proposal Popular Tokens\nAppear at least in more than 0.5% of the documents. Sorted by ratio of appearances in the Rejected Proposals versus the Accepted Proposals."},{"metadata":{"_cell_guid":"93418452-ee64-4650-ab40-55caa614c33c","_uuid":"0e432f09e60976a396911f5f86e93c765091b078","trusted":false},"cell_type":"code","source":"type_best = tokens[(tokens['classA_proportion'] > 0.005) & (tokens['token'].str.len() > 2)\n      ].sort_values('classA_ratio_extra', ascending=False).head(50)\n\ntype_best[['token', 'classA_norm', 'classB_norm', 'classA_ratio_extra']].head(20)","execution_count":44,"outputs":[]},{"metadata":{"_cell_guid":"8d4c5493-2d4b-4770-8ad6-72d26a3485ef","_uuid":"09207cd7b1590b75a46718d4528a21ef79855edf"},"cell_type":"markdown","source":"#### ~ SUMMARY ~\n\nThere is an interesting pattern that seems to appear in the Accepted Proposal corpus which is not as distinct in the Rejected Proposals. The Accepted proposals have many tokens that are related to **furniture/movement** (hokki - type of chair, bouncy, stools, wobble, durable, stool, rug), **computer/technology** (subscription, chromebooks, minis, download, websites) and **literacy** (which has many once you look past the top 20). \n\nThe patterns for the the Rejected Proposals are less clear, with certain themes coming up such as **food** (cooking, cook, burning, obesity) and **behavior related** (senses, manipulative/s, stimulation, regulate). But these are less unique to this corpus (as can be seen by the ratio column). \n"},{"metadata":{"_cell_guid":"7cae8987-e516-409c-b5f1-3b3084f5ed68","_uuid":"8fbdad33cccbc6ea19d1fb00db00e94d74f20db8"},"cell_type":"markdown","source":"# Future Work\n- Use LDA to automatically detect topics and see how they compare to the ones I was able to pick out.\n- Encorporte some of the findings from this notebook such as document complexity, length and material cost my naiveBayes model."},{"metadata":{"_cell_guid":"b40d70fd-672d-4e7b-9e69-f30b8f746eee","_uuid":"c80708aae0c1832087686090ce7bc4e3f4b611a6"},"cell_type":"markdown","source":"Thank you for making it this far. Feedback is highly welcome and appreciated :)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}