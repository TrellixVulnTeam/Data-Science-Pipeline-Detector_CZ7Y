{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport gc\nimport numpy as np\nimport pandas as pd\nimport os\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold, RepeatedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm import tqdm\nimport lightgbm as lgb\nimport re\n\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nimport nltk.stem as stm\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# Load Data\ndtype = {\n    'id': str,\n    'teacher_id': str,\n    'teacher_prefix': str,\n    'school_state': str,\n    'project_submitted_datetime': str,\n    'project_grade_category': str,\n    'project_subject_categories': str,\n    'project_subject_subcategories': str,\n    'project_title': str,\n    'project_essay_1': str,\n    'project_essay_2': str,\n    'project_essay_3': str,\n    'project_essay_4': str,\n    'project_resource_summary': str,\n    'teacher_number_of_previously_posted_projects': int,\n    'project_is_approved': np.uint8,\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7343451d-0caa-4d31-968e-60cf09bcead0","_uuid":"bed520a2bc1858225c9e0c69ca9b3c590cc90847","trusted":false,"collapsed":true},"cell_type":"code","source":"data_path = os.path.join('../input')\ntrain = pd.read_csv(os.path.join(data_path, 'train.csv'), dtype=dtype)\ntest = pd.read_csv(os.path.join(data_path, 'test.csv'), dtype=dtype)\nres = pd.read_csv(os.path.join(data_path, 'resources.csv'))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d17c8615-c998-4cb9-a7d9-73269650dedd","collapsed":true,"_uuid":"8092f69eb4d728d23b6f6c4df199aecdd9c0df40","trusted":false},"cell_type":"code","source":"# Preprocess data\ntrain['project_essay'] = train.apply(lambda row: ' '.join([\n    str(row['project_essay_1']), \n    str(row['project_essay_2']), \n    str(row['project_essay_3']), \n    str(row['project_essay_4']),\n    ]), axis=1)\ntest['project_essay'] = test.apply(lambda row: ' '.join([\n    str(row['project_essay_1']), \n    str(row['project_essay_2']), \n    str(row['project_essay_3']), \n    str(row['project_essay_4']),\n    ]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec814529-0720-4dc4-b87e-35e33320a735","collapsed":true,"_uuid":"75777037b1a0358531d0e3565af8b06fdd42b530","trusted":false},"cell_type":"code","source":"def cleaning(s):\n    \n    s = str(s)\n    #s = str.split(s)\n    s = s.lower()\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W,\\s',' ',s)\n    s = re.sub(r'[^\\w]', ' ', s)\n    s = re.sub(\"\\d+\", \"\", s)\n    s = re.sub('\\s+',' ',s)\n    s = re.sub('[!@#$_]', '', s)\n    s = s.replace(\",\",\"\")\n    s = s.replace(\"[\\w*\",\" \")\n    s = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', s, flags=re.MULTILINE)\n    s = re.sub(r'\\<a href', ' ', s)\n    s = re.sub(r'&amp;', '', s) \n    s = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', s)\n    s = re.sub(r'[^\\x00-\\x7f]',r'',s) \n    s = re.sub(r'<br />', ' ', s)\n    s = re.sub(r'\\'', ' ', s)\n    \n    return s","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"47ab6882-dc1a-4d4d-8397-407802545118","_uuid":"1282734e499789ccbd6237cba1869ddbd6be83e1","trusted":false,"collapsed":true},"cell_type":"code","source":"train['project_essay'] = [cleaning(s) for s in tqdm(train['project_essay'])]\ntest['project_essay'] = [cleaning(s) for s in tqdm(test['project_essay'])]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"578cbdde-0289-4d18-8d53-8354afea7220","collapsed":true,"_uuid":"00a116b36adf8384d994e2d55d993665f79eecf9","trusted":false},"cell_type":"code","source":"def text_to_wordlist(text, remove_stop_words=False, stem_words=False):\n    # Remove punctuation from text\n    text = ''.join([c for c in text if c not in punctuation])\n    \n    # Optionally, remove stop words\n    if remove_stop_words:\n        text = text.split()\n        text = [w for w in text if not w in stopwords]\n        text = \" \".join(text)\n    \n    # Optionally, shorten words to their stems\n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n    \n    # Return a list of words\n    return(text)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1676ac65-ee63-4876-9a22-ca323b4754ef","_uuid":"e46be9e9aefebcef26343b5880f161f1d8e3fe94","trusted":false,"collapsed":true},"cell_type":"code","source":"train['project_essay'] = [text_to_wordlist(text) for text in train['project_essay']]\ntest['project_essay'] = [text_to_wordlist(text) for text in tqdm(test['project_essay'])]\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"26bf7401-d423-41b1-87ae-cfb49f16ca48","collapsed":true,"_uuid":"fd9a719958327f29edb3082b770ea582599edfcf","trusted":false},"cell_type":"code","source":"# Extract features\ndef extract_features(df):\n    df['project_title_len'] = df['project_title'].apply(lambda x: len(str(x)))\n    df['project_essay_1_len'] = df['project_essay_1'].apply(lambda x: len(str(x)))\n    df['project_essay_2_len'] = df['project_essay_2'].apply(lambda x: len(str(x)))\n    df['project_essay_3_len'] = df['project_essay_3'].apply(lambda x: len(str(x)))\n    df['project_essay_4_len'] = df['project_essay_4'].apply(lambda x: len(str(x)))\n    df['project_resource_summary_len'] = df['project_resource_summary'].apply(lambda x: len(str(x)))\n    \n    df['project_title_wc'] = df['project_title'].apply(lambda x: len(str(x).split(' ')))\n    df['project_essay_1_wc'] = df['project_essay_1'].apply(lambda x: len(str(x).split(' ')))\n    df['project_essay_2_wc'] = df['project_essay_2'].apply(lambda x: len(str(x).split(' ')))\n    df['project_essay_3_wc'] = df['project_essay_3'].apply(lambda x: len(str(x).split(' ')))\n    df['project_essay_4_wc'] = df['project_essay_4'].apply(lambda x: len(str(x).split(' ')))\n    df['project_resource_summary_wc'] = df['project_resource_summary'].apply(lambda x: len(str(x).split(' ')))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8dca5450-a4a2-4558-a1f3-66f741cdf92f","collapsed":true,"_uuid":"c67c32c90744a44917f7ee83a3438e627f4abf09","trusted":false},"cell_type":"code","source":"extract_features (train)\nextract_features (test)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"563e0dd3-0270-466e-8441-34b23cd12ede","_uuid":"65f72976e14f5d9c2b1f1998142e14680253751c","trusted":false,"collapsed":true},"cell_type":"code","source":"train.drop([\n    'project_essay_1', \n    'project_essay_2', \n    'project_essay_3', \n    'project_essay_4'], axis=1, inplace=True)\ntest.drop([\n    'project_essay_1', \n    'project_essay_2', \n    'project_essay_3', \n    'project_essay_4'], axis=1, inplace=True)\n\ndf_all = pd.concat([train, test], axis=0)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"edc071ed-3414-4415-9050-a3049baf2443","collapsed":true,"_uuid":"da890aeac38fb880a4c658c430a693343e03bad3","trusted":false},"cell_type":"code","source":"# Merge with resources\nres = pd.DataFrame(res[['id', 'quantity', 'price']].groupby('id').agg(\\\n    {\n        'quantity': [\n            'sum',\n            'min', \n            'max', \n            'mean', \n            'std', \n            # lambda x: len(np.unique(x)),\n        ],\n        'price': [\n            'count', \n            'sum', \n            'min', \n            'max', \n            'mean', \n            'std', \n            lambda x: len(np.unique(x)),\n        ]}\n    )).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ca1702e4-2062-4ff2-a17e-8d1d6aada577","_uuid":"16e1d584c9dc1ebcf7da7a3f2381e845eb9fce9b","trusted":false,"collapsed":true},"cell_type":"code","source":"res.columns = ['_'.join(col) for col in res.columns]\nres.rename(columns={'id_': 'id'}, inplace=True)\nres['mean_price'] = res['price_sum']/res['quantity_sum']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5ef521e4-a6ae-41f1-a5f2-9011afc37322","_uuid":"b44d45da11690ebde79e632f88a464b097782905","trusted":false,"collapsed":true},"cell_type":"code","source":"train = train.merge(res, on='id', how='left')\ntest = test.merge(res, on='id', how='left')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cad4ce46-59a9-47df-a9f6-9ca0692e7ef1","_uuid":"1a211a5231bea2256468e63ea921b238fa573429","trusted":false,"collapsed":true},"cell_type":"code","source":"# Preprocess columns with label encoder\nprint('Label Encoder...')\ncols = [\n    'teacher_id', \n    'teacher_prefix', \n    'school_state', \n    'project_grade_category', \n    'project_subject_categories', \n    'project_subject_subcategories'\n]\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"18a2a56a-cfaf-4330-8e58-8b658fcdd775","_uuid":"b3f54a2b3ed06f13774f9beadc760ed4de7455a5","trusted":false,"collapsed":true},"cell_type":"code","source":"for c in tqdm(cols):\n    le = LabelEncoder()\n    le.fit(df_all[c].astype(str))\n    train[c] = le.transform(train[c].astype(str))\n    test[c] = le.transform(test[c].astype(str))\ngc.collect()\nprint('Done.')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fe5131f5-3a38-42f8-8846-df12b664f9bb","_uuid":"b08d334a625f78859bb04310e94a6d6a0be84bef","trusted":false,"collapsed":true},"cell_type":"code","source":"# Preprocess timestamp\nprint('Preprocessing timestamp...')\ndef process_timestamp(df):\n    df['year'] = df['project_submitted_datetime'].apply(lambda x: int(x.split('-')[0]))\n    df['month'] = df['project_submitted_datetime'].apply(lambda x: int(x.split('-')[1]))\n    df['date'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[2]))\n    df['day_of_week'] = pd.to_datetime(df['project_submitted_datetime']).dt.weekday\n    df['hour'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[-1].split(':')[0]))\n    df['minute'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[-1].split(':')[1]))\n    df['project_submitted_datetime'] = pd.to_datetime(df['project_submitted_datetime']).values.astype(np.int64)\n    \n\nprocess_timestamp(train)\nprocess_timestamp(test)\nprint('Done.')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9a4cec6b-7b4e-47c0-8732-2f75a3013a50","_uuid":"5998b4a19ec5e02454c42b43846c814366e49072","trusted":false,"collapsed":true},"cell_type":"code","source":"# Preprocess text\nprint('Preprocessing text...')\ncols = [\n    'project_title', \n    'project_essay', \n    'project_resource_summary'\n]\nn_features = [\n    400, \n    4040, \n    400,\n]\n\nfor c_i, c in tqdm(enumerate(cols)):\n    tfidf = TfidfVectorizer(\n        max_features=n_features[c_i],\n        norm='l2',analyzer='word',stop_words=None,ngram_range=(1, 2),sublinear_tf=True,token_pattern=r'\\w{1,}',strip_accents='unicode')\n    tfidf.fit(df_all[c])\n    tfidf_train = np.array(tfidf.transform(train[c]).toarray(), dtype=np.float16)\n    tfidf_test = np.array(tfidf.transform(test[c]).toarray(), dtype=np.float16)\n\n    for i in range(n_features[c_i]):\n        train[c + '_tfidf_' + str(i)] = tfidf_train[:, i]\n        test[c + '_tfidf_' + str(i)] = tfidf_test[:, i]\n        \n    del tfidf, tfidf_train, tfidf_test\n    gc.collect()\n    \nprint('Done.')\ndel df_all\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f4ef1a07-e7ac-497b-85cb-0047ac7428b0","_uuid":"dc81e5044c1de60e540165708d2a2e215397509e","trusted":false,"collapsed":true},"cell_type":"code","source":"# Prepare data\ncols_to_drop = [\n    'id',\n    'teacher_id',\n    'project_title', \n    'project_essay', \n    'project_resource_summary',\n    'project_is_approved',\n]\nX = train.drop(cols_to_drop, axis=1, errors='ignore')\ny = train['project_is_approved']\nX_test = test.drop(cols_to_drop, axis=1, errors='ignore')\nid_test = test['id'].values\nfeature_names = list(X.columns)\nprint(X.shape, X_test.shape)\n\ndel train, test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a4ff0385-5135-44c7-844e-321b97a9940f","_uuid":"7a20a191233d8a3c451ae59819a2daa1e20e6816","trusted":false,"collapsed":true},"cell_type":"code","source":"# Build the model\ncnt = 0\np_buf = []\nn_splits = 5\nn_repeats = 1\nkf = RepeatedKFold(\n    n_splits=n_splits, \n    n_repeats=n_repeats, \n    random_state=0)\nauc_buf = []   \n\nfor train_index, valid_index in kf.split(X):\n    print('Fold {}/{}'.format(cnt + 1, n_splits))\n    params = {\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': 'auc',\n        'max_depth': 14,\n        'num_leaves': 31,\n        'learning_rate': 0.025,\n        'feature_fraction': 0.85,\n        'bagging_fraction': 0.85,\n        'bagging_freq': 5,\n        'verbose': 0,\n        'num_threads': 1,\n        'lambda_l2': 1.0,\n        'min_gain_to_split': 0,\n    }  \n\n    lgb_train = lgb.Dataset(\n        X.loc[train_index], \n        y.loc[train_index], \n        feature_name=feature_names,\n        )\n    lgb_train.raw_data = None\n\n    lgb_valid = lgb.Dataset(\n        X.loc[valid_index], \n        y.loc[valid_index],\n        )\n    lgb_valid.raw_data = None\n\n    model = lgb.train(\n        params,\n        lgb_train,\n        num_boost_round=10000,\n        valid_sets=[lgb_train, lgb_valid],\n        early_stopping_rounds=100,\n        verbose_eval=100,\n    )\n\n    if cnt == 0:\n        importance = model.feature_importance()\n        model_fnames = model.feature_name()\n        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n        tuples = [x for x in tuples if x[1] > 0]\n        print('Important features:')\n        for i in range(60):\n            if i < len(tuples):\n                print(tuples[i])\n            else:\n                break\n            \n        del importance, model_fnames, tuples\n\n    p = model.predict(X.loc[valid_index], num_iteration=model.best_iteration)\n    auc = roc_auc_score(y.loc[valid_index], p)\n\n    print('{} AUC: {}'.format(cnt, auc))\n\n    p = model.predict(X_test, num_iteration=model.best_iteration)\n    if len(p_buf) == 0:\n        p_buf = np.array(p, dtype=np.float16)\n    else:\n        p_buf += np.array(p, dtype=np.float16)\n    auc_buf.append(auc)\n\n    cnt += 1\n    if cnt > 0: # Comment this to run several folds\n        break\n    \n    del model, lgb_train, lgb_valid, p\n    gc.collect","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"51fca916-b6f7-4691-a9b6-094b8ec74019","collapsed":true,"_uuid":"69df93b43cc8dc5295586263547ae3a6f302481b","trusted":false},"cell_type":"code","source":"auc_mean = np.mean(auc_buf)\nauc_std = np.std(auc_buf)\nprint('AUC = {:.6f} +/- {:.6f}'.format(auc_mean, auc_std))\n\npreds = p_buf/cnt\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a797641a-6f87-4064-a084-7441a770581e","collapsed":true,"_uuid":"6188cac525864225ee1819f9a54c92bbc05ff4c4","trusted":false},"cell_type":"code","source":"# Prepare submission\nsubm = pd.DataFrame()\nsubm['id'] = id_test\nsubm['project_is_approved'] = preds\nsubm.to_csv('submission.csv', index=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"422e768d-54df-4dd2-a55e-d3af1f8557b5","_uuid":"d052565281eeea0b86e6baa74e0e4e1069e8271f"},"cell_type":"markdown","source":"Orginial kernal from - https://www.kaggle.com/opanichev/lightgbm-and-tf-idf-starter/code by Oleg Panichev\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}