{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false,"collapsed":true},"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nimport os\nimport re\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold, RepeatedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\n\nfrom keras import initializers, regularizers, constraints\nfrom keras.layers import Dense, Input, Flatten, RepeatVector, Permute\nfrom keras.layers import Input, Dense, LSTM,merge, Merge, Bidirectional, concatenate, SpatialDropout1D, GRU, BatchNormalization, Dropout, Activation,TimeDistributed\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Model, Sequential\nfrom keras.regularizers import l2\nfrom keras.layers import Convolution1D, GlobalMaxPooling1D, Flatten\nfrom keras.layers import Conv1D, MaxPooling1D, Embedding,Lambda\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom keras.callbacks import *\nfrom keras import backend as K\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a39ffe9dec477a0e8400c5e3336b4f1f72d1787","_cell_guid":"5eec27bb-8de3-477a-b4d2-772af8b078e3"},"cell_type":"markdown","source":"# Read data"},{"metadata":{"_uuid":"3aa9daa9e0f9eeabcc79a780255caae329978d8b","_cell_guid":"524d0160-667d-4871-9b0c-4d7b5f880065","trusted":false,"collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/donorschoose-application-screening/train.csv')\ntest = pd.read_csv('../input/donorschoose-application-screening/test.csv')\nresources = pd.read_csv('../input/donorschoose-application-screening/resources.csv')\ntrain = train.sort_values(by=\"project_submitted_datetime\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce2bc99872ce533a009021916de328d02ac5f1a4","_cell_guid":"ce6e0327-95e8-49a9-9764-51a756a79c1d"},"cell_type":"markdown","source":"# Text Preprocessing"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false,"collapsed":true},"cell_type":"code","source":"char_cols = ['project_title', 'project_essay_1', 'project_essay_2',\n             'project_essay_3', 'project_essay_4', 'project_resource_summary']\n\ntrain = train.fillna('NA')\ntest = test.fillna('NA')\n\nteachers_train = list(set(train.teacher_id.values))\nteachers_test = list(set(test.teacher_id.values))\ninter = set(teachers_train).intersection(teachers_test)\n\ntrain['text'] = ''\nfor col in char_cols:\n    train['text'] += train[col]\n    train['text'] += ' '\n\ntest['text'] = ''\nfor col in char_cols:\n    test['text'] += test[col]\n    test['text'] += ' '\n\ndef preprocess(string):\n    '''\n    :param string:\n    :return:\n    '''\n    string = re.sub(r'(\\\\r)', ' ', string)\n    string = re.sub(r'(\\\\n)', ' ', string)\n    string = re.sub(r'(\\\\r\\\\n)', ' ', string)\n    string = re.sub(r'(\\\\)', ' ', string)\n    string = re.sub(r'\\t', ' ', string)\n    string = re.sub(r'\\:', ' ', string)\n    string = re.sub(r'\\\"\\\"\\\"\\\"', ' ', string)\n    string = re.sub(r'_', ' ', string)\n    string = re.sub(r'\\+', ' ', string)\n    string = re.sub(r'\\=', ' ', string)\n    string = re.sub(r'\\d+', ' ', string) \n    string = re.sub(r'(\\\")', ' ', string)\n    string = re.sub(r'[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n]', ' ', string)\n\n    return string\n\ntrain[\"text\"]=train[\"text\"].apply(preprocess)\ntest[\"text\"]=test[\"text\"].apply(preprocess)\n\ny = train.project_is_approved.values\n\ntrain_text = train.text.values\ntest_text = test.text.values\n\ntokenizer = Tokenizer()\n\ntokenizer.fit_on_texts(list(train_text) + list(test_text))\n\nlen(tokenizer.word_index)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"9e0defa91c701823a581cb32f9a36075022b4d59","_cell_guid":"d6d7af7d-4d55-4c34-b278-7a97df16ef80","trusted":false},"cell_type":"code","source":"word_index = tokenizer.word_index\n\nEMBEDDING_DIM = 300\nMAX_SEQUENCE_LENGTH = 600\n\nsequences = tokenizer.texts_to_sequences(train_text)\ndata = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n\nsequence_test = tokenizer.texts_to_sequences(test_text)\ntest_data = pad_sequences(sequence_test, maxlen=MAX_SEQUENCE_LENGTH)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0240105c3da3d28ba8c3aa273c0d11bc00b323c1","_cell_guid":"b2753ce9-9c4a-4022-a280-32629e4213ac"},"cell_type":"markdown","source":"# train test split "},{"metadata":{"collapsed":true,"_uuid":"3cfc769a0a26826d508ca45144547349fa8dfcfd","_cell_guid":"18a3b191-207b-4316-b68d-ea266ea37a90","trusted":false},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(data, y, test_size=0.1, random_state=666)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"656f3718746f461f0853e12e23f2b4878c82f758","_cell_guid":"6783685e-260b-476a-bf85-a60e9d337f06"},"cell_type":"markdown","source":"# Loading embedding matrix \nFor saving space, the embedding matrix is caculated in local meachine."},{"metadata":{"collapsed":true,"_uuid":"85fe7d3814a3edfb1555be552ebee7a41f461456","_cell_guid":"a98f92b8-3222-4ff8-93bb-277f04bbf2ea","trusted":false},"cell_type":"code","source":"embedding_matrix = np.load('../input/crawlembeddingmatric/embedding_matrix.npy')\n\nembedding_layer = Embedding(len(word_index) + 1,\n                            EMBEDDING_DIM,\n                            weights=[embedding_matrix],\n                            input_length=MAX_SEQUENCE_LENGTH,\n                            trainable=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"555bcbf108b89a11ab8ba68e321b0839391626dd","_cell_guid":"f3207794-38b4-4d4e-8452-81c293a407cf"},"cell_type":"markdown","source":"# Defining auc "},{"metadata":{"collapsed":true,"_uuid":"75efa6331c3bc67c6b433fb3cae42ed69633413d","_cell_guid":"b2992abf-78af-42b5-8978-7c487127687a","trusted":false},"cell_type":"code","source":"# AUC for a binary classifier\ndef auc(y_true, y_pred):   \n    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n    binSizes = -(pfas[1:]-pfas[:-1])\n    s = ptas*binSizes\n    return K.sum(s, axis=0)\n# PFA, prob false alert for binary classifier\ndef binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # N = total number of negative labels\n    N = K.sum(1 - y_true)\n    # FP = total number of false alerts, alerts from the negative class labels\n    FP = K.sum(y_pred - y_pred * y_true)    \n    return FP/N\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\n# P_TA prob true alerts for binary classifier\ndef binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # P = total number of positive labels\n    P = K.sum(y_true)\n    # TP = total number of correct alerts, alerts from the positive class labels\n    TP = K.sum(y_pred * y_true)    \n    return TP/P","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81a1a09688b94ed60debdc2495b9bb3f1696ce68","_cell_guid":"5422990c-9cb5-49e1-9b12-c97f7357b257"},"cell_type":"markdown","source":"# Hierarchical Model with Attention"},{"metadata":{"collapsed":true,"_uuid":"43f35978943cb15d8c8446d752ffd584181a866a","_cell_guid":"d697df51-5ea3-4362-b8b5-975012df21d3","trusted":false},"cell_type":"code","source":"def get_model():\n    class AttLayer(Layer):\n        def __init__(self, init='glorot_uniform', kernel_regularizer=None, \n                     bias_regularizer=None, kernel_constraint=None, \n                     bias_constraint=None,  **kwargs):\n            self.supports_masking = True\n            self.init = initializers.get(init)\n            self.kernel_initializer = initializers.get(init)\n\n            self.kernel_regularizer = regularizers.get(kernel_regularizer)\n            self.bias_regularizer = regularizers.get(kernel_regularizer)\n\n            self.kernel_constraint = constraints.get(kernel_constraint)\n            self.bias_constraint = constraints.get(bias_constraint)\n\n            super(AttLayer, self).__init__(** kwargs)\n\n        def build(self, input_shape):\n            assert len(input_shape)==3\n            self.W = self.add_weight((input_shape[-1], 1),\n                                     initializer=self.kernel_initializer,\n                                     name='{}_W'.format(self.name),\n                                     regularizer=self.kernel_regularizer,\n                                     constraint=self.kernel_constraint)\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.bias_regularizer,\n                                     constraint=self.bias_constraint)\n            self.u = self.add_weight((input_shape[1],),\n                                     initializer=self.kernel_initializer,\n                                     name='{}_u'.format(self.name),\n                                     regularizer=self.kernel_regularizer,\n                                     constraint=self.kernel_constraint)\n\n            self.built = True\n\n        def compute_mask(self, input, input_mask=None):\n            return None\n\n        def call(self, x, mask=None):\n            uit = K.dot(x, self.W) # (x, 40, 1)\n            uit = K.squeeze(uit, -1) # (x, 40)\n            uit = uit + self.b # (x, 40) + (40,)\n            uit = K.tanh(uit) # (x, 40)\n\n            ait = uit * self.u # (x, 40) * (40, 1) => (x, 1)\n            ait = K.exp(ait) # (X, 1)\n\n            if mask is not None:\n                mask = K.cast(mask, K.floatx()) #(x, 40)\n                ait = mask*ait #(x, 40) * (x, 40, )\n\n            ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n            ait = K.expand_dims(ait)\n            weighted_input = x * ait\n            output = K.sum(weighted_input, axis=1)\n            return output\n\n        def compute_output_shape(self, input_shape):\n            return (input_shape[0], input_shape[-1])\n\n    inputs = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n    embed = embedding_layer(inputs)\n    gru = Bidirectional(GRU(100, dropout=0.2, recurrent_dropout=0.1, return_sequences=True))(embed)\n    attention = AttLayer()(gru)\n    output = Dense(1, activation='sigmoid')(attention)\n    model = Model(inputs, output)\n    \n    model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=[auc])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45d217ef655f8c8dc24bf8f09e2e7cf93ce9f89a","_cell_guid":"5837073a-2171-4421-85f7-ac348bca57e3"},"cell_type":"markdown","source":"# Get model and load weight"},{"metadata":{"_uuid":"55701762b779f65e96267a9cdfef1c36ef282664","_cell_guid":"4eab80ed-3e2f-474b-9a6a-9ac7f2c3403a","trusted":false,"collapsed":true},"cell_type":"code","source":"model = get_model()\nmodel.load_weights(\"../input/donorweight/atten0.7822.h5\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"34d21a91a00828e48257fc1b95c3251d3db99bef","_cell_guid":"06e1ece0-9012-403a-80e9-09129261cbb0","trusted":false},"cell_type":"code","source":"checkpoint = ModelCheckpoint('atten.h5', monitor=\"val_auc\", verbose=1, save_best_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=0.000001)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"9e3e09d4e8cca818ef74c957c3e459f79e3316f2","_cell_guid":"efcf516c-bd01-41a5-8642-be881a475edc","trusted":false},"cell_type":"code","source":"# model.fit(X_train, y_train, validation_data=(X_val, y_val),\n#           epochs=1, batch_size=128, callbacks=[checkpoint, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"44bc19a660f03578ba2ce9414c89767ff6cd3dff","_cell_guid":"cd8175e7-e480-40f3-b8c6-49af388e70ed","trusted":false},"cell_type":"code","source":"p_sub= model.predict([test_data]).T[0]\n\nsub = pd.read_csv('../input/donorschoose-application-screening/sample_submission.csv')\n\nsub.project_is_approved = p_sub\n\nsub.to_csv('attention.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}