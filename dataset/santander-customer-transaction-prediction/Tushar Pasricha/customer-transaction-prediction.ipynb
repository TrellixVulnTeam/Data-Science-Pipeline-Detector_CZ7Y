{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this project we have to identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted.\n\nEvaluation :\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing all required libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\n\n# Stats\nfrom scipy import stats\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# For ignoring the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nimport gc\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Fetching the data to pandas dataframes\ntrain = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/test.csv')\nsub = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's explore the training data first","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking training data\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training data has 202 columns and 200000 rows that will provide us a good amount of data for training our machine learning models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see the data is anonymized by the company and only target and Id are provided without anonymizing, we would need to explore the data and formulate certain hypothesis to de-anonymize the data and infer some valuable insights from the data that will help us predict the target value for test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the datatypes of columns\ntrain.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the anonymized columns i.e var_0 to var_199 have float datatype, we will have to check the values of all the columns if they are actually a numeric type values or are encoded to values from a categorical type variable.<br>\nWe will then decode the values back to categorical features and that might improve the accuracy of our predictions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Exploratory data analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Checking for missing values in the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum().sort_values(ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As this is a banking related data, as expected there are no null values present in the data, that means the data is properly recorded by the bank without any failure","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Let's explore the columns now","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking if every row has unique id\nlen(train['ID_code'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target column\ntrain['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x=\"target\",data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The target variable is highly imbalanced as value 0 has a much higher count then the value 1.<br>\nwe will need to consider this while doing cross validation of a model that balanced sample is taken for prediction and for cross validation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Checking for duplicate columns\n\nFirstly we will encode each and every column using tqdm function which works as a pipeline operator for handing big amount of data.\n\nFun Fact : **tqdm means \"progress\" in Arabic (taqadum, تقدّم) and is an abbreviation for \"I love you so much\" in Spanish (te quiero demasiado).**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tqdm\ntrain_enc = pd.DataFrame(index = train.index)\nfor col in tqdm.tqdm_notebook(train.columns):\n    train_enc[col] = train[col].factorize()[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no duplicate columns present in the data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Feature Skewness","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = train.columns[2:]\nfeature_names\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find skewed numerical features\nskew_features = train[feature_names].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nprint(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\nskewness = pd.DataFrame({'Skew' :high_skew})\nskew_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As there are not highly skewed features, we do not need to apply any transformation on the data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Outliers\n\nAs the data is huge, we will first calculate the z-score of the training data and then we will further explore if the value found is to be treated as an outlier or not","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping ID and target columns\nz_score_calc = train.drop(columns=['ID_code', 'target'])\n# Calculating z score\nz = np.abs(stats.zscore(z_score_calc))\n# print(z)\nthreshold = 3\nprint(np.where(z > 4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first array gives the row numbers and the 2nd array gives the respective columns of the outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"treated_data = train[(z < 4).all(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"before treating outliers : {}\".format(train.shape))\nprint(\"after treating outliers : {}\".format(treated_data.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We have removed **27** rows having outliers\n\nWe will try fitting our model on treated and non treated data to see which one performs better and then we can try changing the threshold value for finding outliers","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"treated_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the variables for model fitting\nX = treated_data.drop(columns=['ID_code', 'target'])\ny = treated_data['target']\n\n# Test variable\ntest = test.drop(columns=['ID_code'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = .3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Import the random forest model.\nfrom sklearn.ensemble import RandomForestClassifier\n## This line instantiates the model. \nrf = RandomForestClassifier() \n## Fit the model on your training data.\nrf.fit(X_train, y_train) \n## And score it on your testing data.\nrf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_rf = rf.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.DataFrame({\"ID_code\":sub['ID_code'],\n                         \"target\":prediction_rf})\nsubmission.to_csv('submission_rf.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = pd.DataFrame(rf.feature_importances_,\n                                   index = X_train.columns,\n                                    columns=['importance']).sort_values('importance',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances.median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances.tail(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing the features that have importance less than 0.0038\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop( ['var_38','var_158','var_73','var_14','var_10','var_84','var_61','var_103','var_185'],axis = 1,inplace = True )\nX_test.drop( ['var_38','var_158','var_73','var_14','var_10','var_84','var_61','var_103','var_185'],axis = 1 , inplace = True)\nX_train.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(X_train, y_train) \n## And score it on your testing data.\nrf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_selected_test = test.drop( ['var_38','var_158','var_73','var_14','var_10','var_84','var_61','var_103','var_185'],axis = 1)\nfeature_selected_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_rf = rf.predict(feature_selected_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.DataFrame({\"ID_code\":sub['ID_code'],\n                         \"target\":prediction_rf})\nsubmission.to_csv('submission_rf2.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}