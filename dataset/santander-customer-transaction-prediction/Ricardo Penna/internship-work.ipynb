{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Summary\n\nThis work is organized as follows:\n\n* 1. Introduction\n* 2. Data analysis\n* 3. Validation method\n* 4. Model training\n* 5. Submission\n","metadata":{}},{"cell_type":"markdown","source":"# 1. Introduction\n\nThis competition was chosen as a internship work for a study programme in Data Science.\n\nIt was hosted by Santander with the aim do identify \"which customers will make a specidic transaction in the future, irrespective of the amount of money transacted\" (as it is writen in the description of the challenge).\n\nThe data provided were anonymized and contain only numeric feature variables. The target is binary. We have three files to work with: one with traning data, another one with test data and a sample to indicate the correct format for submission\n\nThis work is inspired in the notebook \"Projeto completo de Classificação Binária (Diabetes)\", by Marcos Kalinowski and Tatiana Escovedo, used in the course \"Engenharia de Software para Ciência de Dados - PUC-Rio\"\n\nOther notebooks and sites were used as references:\n* https://towardsdatascience.com/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5\n* https://www.kaggle.com/code/dimanjung/lgbm-with-parameters\n* https://www.kaggle.com/code/dott1718/922-in-3-minutes/notebook\n* https://www.kaggle.com/code/thomasandarilho/tp3-desafio-vivencial\n* https://www.kaggle.com/code/prashant111/lightgbm-classifier-in-python/notebook\n* https://lightgbm.readthedocs.io/en/latest/\n* https://scikit-learn.org/stable/\n\n","metadata":{}},{"cell_type":"markdown","source":"## 1.1. Loading libraries and data","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# Load of libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', None)\n\n# Sklearn preprocessing\nfrom sklearn.preprocessing import StandardScaler # para padronização\nfrom sklearn.preprocessing import MinMaxScaler # para normalização\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import ParameterGrid\n\n# Metrics\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom lightgbm import LGBMClassifier\nimport lightgbm\n\n# To balance data\nfrom imblearn.over_sampling import SMOTE \n\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"6612af53-1f9f-4e00-a662-e89da078e770","_cell_guid":"4628a3f3-1e5b-4496-ba22-08c1e3b0c201","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-31T14:27:44.809296Z","iopub.execute_input":"2022-03-31T14:27:44.809987Z","iopub.status.idle":"2022-03-31T14:27:46.053961Z","shell.execute_reply.started":"2022-03-31T14:27:44.809868Z","shell.execute_reply":"2022-03-31T14:27:46.052775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load of the data\ndf = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/train.csv')\ndf.set_index('ID_code',inplace=True)\n\ntest = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/test.csv')\ntest.set_index('ID_code',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:27:46.056063Z","iopub.execute_input":"2022-03-31T14:27:46.056417Z","iopub.status.idle":"2022-03-31T14:27:59.885525Z","shell.execute_reply.started":"2022-03-31T14:27:46.056367Z","shell.execute_reply":"2022-03-31T14:27:59.884822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data analysis\n\nThe data is comprised of two hundred variables and one target. As the data is anonymized, it is not possible to assign meaning to the variables. There are two hundred thousand entries.","metadata":{}},{"cell_type":"code","source":"df.sample(5)","metadata":{"_uuid":"60e740f0-bb59-4cdc-ac63-68a78384ea53","_cell_guid":"db9ce568-d590-409d-819a-e05be016eaf2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-31T14:27:59.886901Z","iopub.execute_input":"2022-03-31T14:27:59.887377Z","iopub.status.idle":"2022-03-31T14:28:00.04757Z","shell.execute_reply.started":"2022-03-31T14:27:59.887338Z","shell.execute_reply":"2022-03-31T14:28:00.046681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Data has {1} columns and {0} entries'.format(df.shape[0], df.shape[1]))","metadata":{"_uuid":"a46ab824-4d42-4b5d-a3f3-607badd6e86a","_cell_guid":"ae6162fc-b493-46e7-aa00-3df49fd5eca9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-31T14:28:00.048943Z","iopub.execute_input":"2022-03-31T14:28:00.049178Z","iopub.status.idle":"2022-03-31T14:28:00.054653Z","shell.execute_reply.started":"2022-03-31T14:28:00.04915Z","shell.execute_reply":"2022-03-31T14:28:00.053635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The \"target\" is a integer, while all the other columns are flot.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"_uuid":"26422863-3ac7-4d32-b1dc-59eb9dd15a4c","_cell_guid":"56e8f68f-25d4-48c9-874d-8827b47df383","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-31T14:28:00.056779Z","iopub.execute_input":"2022-03-31T14:28:00.057058Z","iopub.status.idle":"2022-03-31T14:28:00.088785Z","shell.execute_reply.started":"2022-03-31T14:28:00.057006Z","shell.execute_reply":"2022-03-31T14:28:00.087745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Variables have different means, minimun and maximun values.","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"_uuid":"a636f640-2b10-405a-a291-1717aae4670a","_cell_guid":"2587ded8-d751-410b-a8b8-e65b94feb4cb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-31T14:28:00.090468Z","iopub.execute_input":"2022-03-31T14:28:00.091013Z","iopub.status.idle":"2022-03-31T14:28:02.380246Z","shell.execute_reply.started":"2022-03-31T14:28:00.090958Z","shell.execute_reply":"2022-03-31T14:28:02.379457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\"Positivies\" are 10.05% of the total entries, meaning that we have imbalanced data.","metadata":{}},{"cell_type":"code","source":"number_of_positive = df.groupby('target').target.count()[1]\nnumber_of_negative = df.groupby('target').target.count()[0]\n\nprint(\"There are {0} entries 'Positive' and {1} entries 'Negative'. Positives are {2:.2f}% of total.\".format(number_of_positive, number_of_negative, 100*number_of_positive/(number_of_positive+number_of_negative)))","metadata":{"_uuid":"2ae88d19-6ac4-4d57-8c47-a16c2fa0345b","_cell_guid":"0ea0e6fb-b042-468e-9bcc-ba9d7581e9bb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-31T14:28:02.381678Z","iopub.execute_input":"2022-03-31T14:28:02.38213Z","iopub.status.idle":"2022-03-31T14:28:02.397567Z","shell.execute_reply.started":"2022-03-31T14:28:02.382092Z","shell.execute_reply":"2022-03-31T14:28:02.396742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The histograms of all variables are shown below.","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(40, 5, figsize=(5*3, 40*3),sharey='row')\n#fig.suptitle('Histogram of all variables')\ni = 0\nfor col in df.columns[1:]:\n\n    if i%5 == 0:\n        legend=True\n    else:\n        legend=False\n        \n    sns.histplot(data=df, x=col,kde=True, hue='target',multiple='stack',ax=axs[i//5,i%5],legend=legend)\n        \n    axs[i//5,i%5].set_title(col)\n    axs[i//5,i%5].set_xlabel('')\n    axs[i//5,i%5].set_ylabel('')\n    i+=1\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:28:02.398764Z","iopub.execute_input":"2022-03-31T14:28:02.399207Z","iopub.status.idle":"2022-03-31T14:33:51.193882Z","shell.execute_reply.started":"2022-03-31T14:28:02.399173Z","shell.execute_reply":"2022-03-31T14:33:51.192876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"median_values = df.iloc[:,1:].median()\nmean_values = df.iloc[:,1:].mean()\nstd_values = df.iloc[:,1:].std()\ncoef_of_variation = df.iloc[:,1:].mean() / df.iloc[:,1:].std()\n\n\n#plt.figure(figsize=(16, 16))\nfig, axs = plt.subplots(1,2,figsize=(12, 4))\n\n\naxs[0].scatter(x=mean_values,y=std_values)\naxs[0].set_title(\"Mean x standard deviation\")\naxs[0].set_xlabel(\"Mean\")\naxs[0].set_ylabel(\"Standard deviation\")\n\naxs[1].scatter(x=mean_values,y=median_values)\naxs[1].set_title(\"Mean x Median\")\naxs[1].set_xlabel(\"Mean\")\naxs[1].set_ylabel(\"Median\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:57:57.408498Z","iopub.execute_input":"2022-03-31T14:57:57.409138Z","iopub.status.idle":"2022-03-31T14:57:59.185405Z","shell.execute_reply.started":"2022-03-31T14:57:57.409085Z","shell.execute_reply":"2022-03-31T14:57:59.184548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The mean correlation between variables is 0.005, and the percentile 99% is 0.0064. According to these results and the histogram of the correlations values, variables are not correlated.","metadata":{}},{"cell_type":"code","source":"correlations = df.iloc[:,1:].corr()\narray_of_correlations = correlations.values.reshape(200*200)\nprint(\"\\nThe mean value of correlations between variables is {0:.2}\".format(array_of_correlations.mean()))\nprint(\"\\nThe percentile 99% of correlatios between variables is {0:.2}\".format(np.percentile(array_of_correlations,q=99)))\nprint('\\n\\n')\n\nplt.hist(correlations.values.reshape(200*200))\nplt.title('Histogram of correlations between variables')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:33:53.396449Z","iopub.execute_input":"2022-03-31T14:33:53.396688Z","iopub.status.idle":"2022-03-31T14:34:15.548467Z","shell.execute_reply.started":"2022-03-31T14:33:53.396658Z","shell.execute_reply":"2022-03-31T14:34:15.547569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Computing the mean between positive and negative values for all variables and comparing them shows that they are quite the same, as the graph shows almost a straight line around the curve x = y.","metadata":{}},{"cell_type":"code","source":"values = df.columns.values[1:]\npivot_table = pd.pivot_table(df,values=values,columns='target',aggfunc=[np.mean])\nprint(pivot_table.sample(10),'\\n\\n')\n\nnegative_mean = pivot_table.loc[:,('mean',0)].values\npositive_mean = pivot_table.loc[:,('mean',1)].values\ndifference = 1 * (negative_mean - positive_mean)\nperc_difference = 100 * (negative_mean / positive_mean - 1)\n\nfig, axs = plt.subplots(2,2,figsize=(4*2, 4*2),constrained_layout=True)\n\n\naxs[0,0].scatter(x=positive_mean,y=negative_mean)\naxs[0,0].set_xlabel('Positive mean')\naxs[0,0].set_ylabel('Negative mean')\naxs[0,0].set_title('Comparison between\\n the mean of positive and negative entries')\naxs[0,0].set_xlim(0,27)\naxs[0,0].set_ylim(0,27)\n\n\naxs[0,1].hist(difference)\naxs[0,1].set_title('Absolute difference between\\n the mean of positive and negative entries')\n\naxs[1,0].hist(perc_difference,bins=100)\naxs[1,0].set_title('Relative difference between\\n the mean of positive and negative entries')\n\naxs[1,1].hist(perc_difference,bins=100)\naxs[1,1].set_title('Relative difference between\\n the mean of positive and negative entries\\n(Between -100% nd 100%)')\naxs[1,1].set_xlim(-100,100)\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:34:15.550026Z","iopub.execute_input":"2022-03-31T14:34:15.550364Z","iopub.status.idle":"2022-03-31T14:34:16.973194Z","shell.execute_reply.started":"2022-03-31T14:34:15.550317Z","shell.execute_reply":"2022-03-31T14:34:16.972519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Validation method","metadata":{}},{"cell_type":"markdown","source":"For testing, data will be splitted into \"train\" and \"test\". Afterwards, the chosen model will be validated using the file \"test.csv\" provided by the competition.\n\nFor evaluating the model, the area under the ROC curve between the predicted probability and the observed target will be used.","metadata":{}},{"cell_type":"code","source":"X = df.iloc[:,1:].values\ny = df.iloc[:,0].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:34:16.974266Z","iopub.execute_input":"2022-03-31T14:34:16.974865Z","iopub.status.idle":"2022-03-31T14:34:17.786019Z","shell.execute_reply.started":"2022-03-31T14:34:16.974825Z","shell.execute_reply":"2022-03-31T14:34:17.785398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Model training","metadata":{}},{"cell_type":"markdown","source":"## 4.1. Resampling","metadata":{}},{"cell_type":"markdown","source":"As the data is unbalanced, SMOTE will be used the balance it.","metadata":{}},{"cell_type":"code","source":"# Resample using SMOTE\nsm = SMOTE(random_state=42,sampling_strategy='minority',k_neighbors=5)\nX_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n\n# Shuffle the data to avoid erros in cross validation score (to avoid creat a group with only one class)\nmatrix_shuffled = np.concatenate((y_resampled.reshape(len(y_resampled),1),X_resampled),axis=1)\nnp.random.shuffle(matrix_shuffled)\n\n# Assign the shuffled data to the variables\nX_resampled = matrix_shuffled[:,1:]\ny_resampled = matrix_shuffled[:,0]","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:34:17.787246Z","iopub.execute_input":"2022-03-31T14:34:17.787777Z","iopub.status.idle":"2022-03-31T14:37:00.396938Z","shell.execute_reply.started":"2022-03-31T14:34:17.787741Z","shell.execute_reply":"2022-03-31T14:37:00.395846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2. Test models","metadata":{}},{"cell_type":"markdown","source":"Firstly, some models will be tested to find out which has the the better results.\n\nThe following models will be tested: Logistic Regression (LR), Decision Tree (CART), Naive Bayes (NB), Ada Boost Classifier (AB), Extra Trees Classifier (ET), Multi-layer Perceptron classifier (MLP) and Light GBM (lgbm).\n\nThese models were chosen according to their results and speed to run.\n\nStandard Scaler and Principal component analysis (PCA) will be used as well.","metadata":{}},{"cell_type":"code","source":"def test_models(scalers, pcas, models, X_resampled_selected, y_resampled, X_test_selected):\n    #kfold = KFold(n_splits=num_folds)\n    results = []\n    names = []\n    durations = []\n\n    runs = len(models) * len(pcas) * len(scalers)    \n    run = 1\n\n    for name_model, model in models:\n        for name_pca, pca in pcas:\n            for name_scaler, scaler in scalers:\n\n                if name_scaler == 'Bypass' and name_pca != 'Bypass':\n                    pipe = Pipeline(steps=[(name_pca, pca),(name_model,model)])\n                elif name_scaler != 'Bypass' and name_pca == 'Bypass':\n                    pipe = Pipeline(steps=[(name_scaler,scaler),(name_model,model)])\n                elif name_scaler == 'Bypass' and name_pca == 'Bypass':\n                    pipe = Pipeline(steps=[(name_model,model)])\n                else:\n                    pipe = Pipeline(steps=[(name_scaler,scaler),(name_pca, pca),(name_model,model)])\n                \n                # Resamped with smote\n                start_time = time.time()\n                #cv_results = cross_val_score(pipe, X_resampled, y_resampled, cv=kfold, scoring=scoring).tolist()\n                pipe.fit(X_resampled_selected, y_resampled)\n                y_predict = pipe.predict(X_test_selected)\n                roc_results = roc_auc_score(y_test,y_predict,average='weighted')\n                f1 = f1_score(y_test,y_predict,average='weighted')\n\n                names.append('Smote|' + name_scaler + ' / ' + name_pca + ' / ' + name_model)\n                #results.append(cv_results)\n                results.append(roc_results)\n                duration = time.time() - start_time\n                durations.append(duration)\n                print('Run {0}/{1}: Smote|{2}|{3}|{4}, AUC: {5:.2f}, F1: {8:.2f}, duration: {6:.2f} s / {7:.2f} min'.format(run,runs,name_scaler,name_pca,name_model,roc_results,duration,duration/60,f1))\n                run = run + 1\n    return names, results, durations\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:37:00.40018Z","iopub.execute_input":"2022-03-31T14:37:00.400501Z","iopub.status.idle":"2022-03-31T14:37:00.414634Z","shell.execute_reply.started":"2022-03-31T14:37:00.400456Z","shell.execute_reply":"2022-03-31T14:37:00.412728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Defining the models:","metadata":{}},{"cell_type":"code","source":"# Model creation\n\nscalers = [('standard_scaler', StandardScaler())\n          ]\npcas = [('pca_10', PCA(n_components=10))]\n\nmodels = [('LR', LogisticRegression(solver='liblinear')),\n          ('CART', DecisionTreeClassifier()),\n          ('NB', GaussianNB()),\n          ('AB', AdaBoostClassifier()),\n          ('ET', ExtraTreesClassifier(n_estimators=10)),\n          ('MLP', MLPClassifier(hidden_layer_sizes=100,activation='relu')),\n          ('lgbm', LGBMClassifier())\n         ]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:37:00.416531Z","iopub.execute_input":"2022-03-31T14:37:00.416917Z","iopub.status.idle":"2022-03-31T14:37:00.436652Z","shell.execute_reply.started":"2022-03-31T14:37:00.416866Z","shell.execute_reply":"2022-03-31T14:37:00.435638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Running the models:","metadata":{}},{"cell_type":"code","source":"names, results, durations = test_models(scalers, pcas, models,X_resampled, y_resampled, X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:37:00.438196Z","iopub.execute_input":"2022-03-31T14:37:00.438998Z","iopub.status.idle":"2022-03-31T14:41:52.875657Z","shell.execute_reply.started":"2022-03-31T14:37:00.438952Z","shell.execute_reply":"2022-03-31T14:41:52.874645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graphs below show the results and time to run of each model.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,6)) \nsns.barplot(y=names,x=results)\nplt.title('Result of the models (AUC)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:41:52.877044Z","iopub.execute_input":"2022-03-31T14:41:52.877298Z","iopub.status.idle":"2022-03-31T14:41:53.058519Z","shell.execute_reply.started":"2022-03-31T14:41:52.877268Z","shell.execute_reply":"2022-03-31T14:41:53.057789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,6)) \nsns.barplot(y=names,x=durations)\nplt.title('Time to run')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:41:53.059776Z","iopub.execute_input":"2022-03-31T14:41:53.060495Z","iopub.status.idle":"2022-03-31T14:41:53.241057Z","shell.execute_reply.started":"2022-03-31T14:41:53.060443Z","shell.execute_reply":"2022-03-31T14:41:53.24008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the previous results and the time to run, the following models were chosen for a deeper investigation: Logistic Regression (LR), Naive Bayes (NB) and LightGBM (lgbm).\n\nFurthermore, Min_Max_Scaler and other PCA number of components will be tested.","metadata":{}},{"cell_type":"code","source":"# Model creation\n\nscalers = [('min_max_scaler', MinMaxScaler()), \n          ('standard_scaler', StandardScaler())\n]\n\npcas = [('Bypass','Bypass'),\n    ('pca_100', PCA(n_components=100)),\n    ('pca_50', PCA(n_components=50)),\n    ('pca_10', PCA(n_components=10)),\n    ('pca_5', PCA(n_components=5))\n]\n\nmodels = [('LR', LogisticRegression(solver='liblinear')),\n          ('NB', GaussianNB()),\n          ('lgbm', LGBMClassifier())\n         ]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:41:53.242481Z","iopub.execute_input":"2022-03-31T14:41:53.243065Z","iopub.status.idle":"2022-03-31T14:41:53.250233Z","shell.execute_reply.started":"2022-03-31T14:41:53.243015Z","shell.execute_reply":"2022-03-31T14:41:53.248967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Running the models:","metadata":{}},{"cell_type":"code","source":"names, results, durations = test_models(scalers, pcas, models,X_resampled, y_resampled, X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:41:53.251458Z","iopub.execute_input":"2022-03-31T14:41:53.251997Z","iopub.status.idle":"2022-03-31T14:47:33.518148Z","shell.execute_reply.started":"2022-03-31T14:41:53.251959Z","shell.execute_reply":"2022-03-31T14:47:33.517216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graphs below show the results and time to run of each model.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,6)) \nsns.barplot(y=names,x=results)\nplt.title('Result of the models (AUC)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:47:33.519972Z","iopub.execute_input":"2022-03-31T14:47:33.520285Z","iopub.status.idle":"2022-03-31T14:47:36.761946Z","shell.execute_reply.started":"2022-03-31T14:47:33.520242Z","shell.execute_reply":"2022-03-31T14:47:36.761204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,6)) \nsns.barplot(y=names,x=durations)\nplt.title('Time to run')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:47:36.76297Z","iopub.execute_input":"2022-03-31T14:47:36.763809Z","iopub.status.idle":"2022-03-31T14:47:37.183112Z","shell.execute_reply.started":"2022-03-31T14:47:36.763766Z","shell.execute_reply":"2022-03-31T14:47:37.18218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3. Parameter adjustment","metadata":{}},{"cell_type":"markdown","source":"In this section, the parameters of the best models will be tuned.","metadata":{}},{"cell_type":"markdown","source":"### 4.3.1. Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Parameters of pipelines\nparam_grid = {\n    'dual': [True,False],\n    'tol':[1e-4,1e-1],\n    'C':[1.0,100.0],\n    'solver': ['liblinear'],\n    'intercept_scaling': [1,100],\n    'max_iter':[300]\n}\n\nparameters = ParameterGrid(param_grid)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:47:37.184433Z","iopub.execute_input":"2022-03-31T14:47:37.18466Z","iopub.status.idle":"2022-03-31T14:47:37.189662Z","shell.execute_reply.started":"2022-03-31T14:47:37.184632Z","shell.execute_reply":"2022-03-31T14:47:37.188631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"runs = len(parameters)\nrun = 1\nfor parameter in parameters:\n    pipe = Pipeline(steps=[('Scaler', StandardScaler()), \n                           ('pca_5', PCA(n_components=5)),\n                           ('LR',LogisticRegression(intercept_scaling=parameter['intercept_scaling'],\n                                                    solver=parameter['solver'],\n                                                    tol=parameter['tol'],\n                                                    C=parameter['C'],  \n                                                    dual=parameter['dual'],\n                                                    max_iter=parameter['max_iter']\n                               \n                                                                               ))])\n    \n    start_time = time.time()\n    pipe.fit(X_resampled, y_resampled)\n    y_predict = pipe.predict(X_test)\n    roc_results = roc_auc_score(y_test,y_predict,average='weighted')\n    f1 = f1_score(y_test,y_predict,average='weighted')\n    duration = time.time() - start_time\n\n    print('Run {0}/{1}: {2}, AUC: {3:.5f}, F1: {4:.5f}'.format(run,runs,parameter,roc_results, f1, duration,duration/60))\n    run = run + 1\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:47:37.190815Z","iopub.execute_input":"2022-03-31T14:47:37.191485Z","iopub.status.idle":"2022-03-31T14:52:18.931881Z","shell.execute_reply.started":"2022-03-31T14:47:37.191449Z","shell.execute_reply":"2022-03-31T14:52:18.930945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3.2. Gaussian Naive Bayes","metadata":{}},{"cell_type":"code","source":"# Parameters of pipelines\nparam_grid = {\n    'var_smoothing': [1e-150,1e-9,1e-3],\n}\n\nparameters = ParameterGrid(param_grid)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:52:18.933954Z","iopub.execute_input":"2022-03-31T14:52:18.934624Z","iopub.status.idle":"2022-03-31T14:52:18.940741Z","shell.execute_reply.started":"2022-03-31T14:52:18.934555Z","shell.execute_reply":"2022-03-31T14:52:18.939327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"runs = len(parameters)\nrun = 1\nfor parameter in parameters:\n    pipe = Pipeline(steps=[('Scaler', StandardScaler()), \n                           ('pca_5', PCA(n_components=5)),\n                           ('NB',GaussianNB(var_smoothing=parameter['var_smoothing']                           \n                                                                               ))])\n    \n    start_time = time.time()\n    pipe.fit(X_resampled, y_resampled)\n    y_predict = pipe.predict(X_test)\n    roc_results = roc_auc_score(y_test,y_predict,average='weighted')\n    f1 = f1_score(y_test,y_predict,average='weighted')\n    duration = time.time() - start_time\n\n    print('Run {0}/{1}: {2}, AUC: {3:.5f}, F1: {4:.5f}'.format(run,runs,parameter,roc_results, f1, duration,duration/60))\n    run = run + 1","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:52:18.942872Z","iopub.execute_input":"2022-03-31T14:52:18.943623Z","iopub.status.idle":"2022-03-31T14:52:39.38048Z","shell.execute_reply.started":"2022-03-31T14:52:18.943552Z","shell.execute_reply":"2022-03-31T14:52:39.379466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3.3. Light GBM","metadata":{}},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/code/dimanjung/lgbm-with-parameters\n\npipe = Pipeline(steps=[('Scaler', StandardScaler()),\n                       ('pca_5', PCA(n_components=5))])\npipe.fit(X_resampled, y_resampled)\nX_resampled_transformed = pipe.transform(X_resampled)\nX_test_transformed = pipe.transform(X_test)\n                \ntrain_data = lightgbm.Dataset(X_resampled_transformed, label=y_resampled)\nvalid_data = lightgbm.Dataset(X_test_transformed, label=y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:52:39.386498Z","iopub.execute_input":"2022-03-31T14:52:39.389277Z","iopub.status.idle":"2022-03-31T14:52:46.583902Z","shell.execute_reply.started":"2022-03-31T14:52:39.389203Z","shell.execute_reply":"2022-03-31T14:52:46.582864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {\n    'n_estimators': [10,25,50],\n    'learning_rate': [0.01,0.05],\n    'metric':['auc'],\n    'verbose': [-1],\n    'boosting': ['gbdt'],\n}\n\n\nparameters = ParameterGrid(param_grid)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:52:46.585305Z","iopub.execute_input":"2022-03-31T14:52:46.585955Z","iopub.status.idle":"2022-03-31T14:52:46.592761Z","shell.execute_reply.started":"2022-03-31T14:52:46.585901Z","shell.execute_reply":"2022-03-31T14:52:46.591854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"runs = len(parameters)\nrun = 1\n\nfor parameter in parameters:\n    model_lgbm = lightgbm.train(parameter,\n                                train_data,\n                                verbose_eval=False,\n                                valid_sets=valid_data,\n                                num_boost_round=20000,\n                                early_stopping_rounds=100)\n\n    y_predictions = model_lgbm.predict(X_test_transformed)\n    print(\"Run {2}/{3}, Parameters: {0}, AUC: {1:.5f}\".format(parameter,roc_auc_score(y_test, y_predictions,average='weighted'),run,runs))\n    \n    run = run + 1","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:52:46.594066Z","iopub.execute_input":"2022-03-31T14:52:46.594605Z","iopub.status.idle":"2022-03-31T14:52:49.264442Z","shell.execute_reply.started":"2022-03-31T14:52:46.594538Z","shell.execute_reply":"2022-03-31T14:52:49.263483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.4. Retrain the model with all data","metadata":{}},{"cell_type":"markdown","source":"Now all data will be used to build the model. Previously, the data had been split into train and test.\n\nLGBM was chosen to be submitted.","metadata":{}},{"cell_type":"code","source":"# Resample using SMOTE\nsm = SMOTE(random_state=42,sampling_strategy='minority',k_neighbors=5)\nX_resampled, y_resampled = sm.fit_resample(X, y)\n\n# Shuffle the data to avoid erros in cross validation score (to avoid creat a group with only one class)\nmatrix_shuffled = np.concatenate((y_resampled.reshape(len(y_resampled),1),X_resampled),axis=1)\nnp.random.shuffle(matrix_shuffled)\n\n# Assign the shuffled data to the variables\nX_resampled = matrix_shuffled[:,1:]\ny_resampled = matrix_shuffled[:,0]","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:52:49.26589Z","iopub.execute_input":"2022-03-31T14:52:49.26621Z","iopub.status.idle":"2022-03-31T14:57:03.825905Z","shell.execute_reply.started":"2022-03-31T14:52:49.266164Z","shell.execute_reply":"2022-03-31T14:57:03.824862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = Pipeline(steps=[('Scaler', StandardScaler()),\n                       ('pca_5', PCA(n_components=5))])\npipe.fit(X_resampled, y_resampled)\nX_resampled_transformed = pipe.transform(X_resampled)\nX_transformed = pipe.transform(X)\n                \ntrain_data = lightgbm.Dataset(X_resampled_transformed, label=y_resampled)\nvalid_data = lightgbm.Dataset(X, label=y)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:57:03.82726Z","iopub.execute_input":"2022-03-31T14:57:03.827506Z","iopub.status.idle":"2022-03-31T14:57:13.014881Z","shell.execute_reply.started":"2022-03-31T14:57:03.827476Z","shell.execute_reply":"2022-03-31T14:57:13.01384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {\n    'n_estimators': [25],\n    'learning_rate': [0.05],\n    'metric':['auc'],\n    'verbose': [-1],\n    'boosting': ['gbdt']\n}\n\n\nparameters = ParameterGrid(param_grid)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:57:13.016593Z","iopub.execute_input":"2022-03-31T14:57:13.01749Z","iopub.status.idle":"2022-03-31T14:57:13.024281Z","shell.execute_reply.started":"2022-03-31T14:57:13.017433Z","shell.execute_reply":"2022-03-31T14:57:13.023015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"runs = len(parameters)\nrun = 1\n\nfor parameter in parameters:\n    model_lgbm = lightgbm.train(parameter,\n                                train_data,\n                                verbose_eval=False,\n                                valid_sets=valid_data,\n                                num_boost_round=20000,\n                                early_stopping_rounds=100)\n\n    y_predictions = model_lgbm.predict(X_transformed)\n    print(\"Run {2}/{3}, Parameters: {0}, AUC: {1:.5f}\".format(parameter,roc_auc_score(y, y_predictions,average='weighted'),run,runs))\n    \n    run = run + 1","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:57:13.026283Z","iopub.execute_input":"2022-03-31T14:57:13.026997Z","iopub.status.idle":"2022-03-31T14:57:14.022543Z","shell.execute_reply.started":"2022-03-31T14:57:13.026945Z","shell.execute_reply":"2022-03-31T14:57:14.021567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Submit","metadata":{}},{"cell_type":"code","source":"test_transformed = pipe.transform(test.values)\ntest_result=model_lgbm.predict(test_transformed)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:57:14.024233Z","iopub.execute_input":"2022-03-31T14:57:14.024763Z","iopub.status.idle":"2022-03-31T14:57:14.59592Z","shell.execute_reply.started":"2022-03-31T14:57:14.024713Z","shell.execute_reply":"2022-03-31T14:57:14.59486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['target']=test_result\ntest.reset_index(inplace=True)\nsubmit=test[['ID_code','target']]\nsubmit.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T14:57:14.597166Z","iopub.execute_input":"2022-03-31T14:57:14.597466Z","iopub.status.idle":"2022-03-31T14:57:15.31213Z","shell.execute_reply.started":"2022-03-31T14:57:14.597426Z","shell.execute_reply":"2022-03-31T14:57:15.311344Z"},"trusted":true},"execution_count":null,"outputs":[]}]}