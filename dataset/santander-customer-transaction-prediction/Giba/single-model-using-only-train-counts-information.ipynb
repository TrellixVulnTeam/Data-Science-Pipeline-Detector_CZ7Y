{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import rankdata\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df  = pd.read_csv(\"../input/test.csv\")\nfeatures = [x for x in train_df.columns if x.startswith(\"var\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reverse some features.\n#Not really necessary for LGB, but helps a little\nfor var in features:\n    if np.corrcoef( train_df['target'], train_df[var] )[1][0] < 0:\n        train_df[var] = train_df[var] * -1\n        test_df[var]  = test_df[var]  * -1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count train values to split Rare/NonRare values\nvar_stats = {}\nfor var in features:\n    var_stats[var] = train_df[var].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logit(p):\n    return np.log(p) - np.log(1 - p)\n\ndef var_to_feat(vr, var_stats, feat_id ):\n    new_df = pd.DataFrame()\n    new_df[\"var\"] = vr.values\n    new_df[\"hist\"] = pd.Series(vr).map(var_stats)\n    new_df[\"feature_id\"] = feat_id\n    new_df[\"var_rank\"] = new_df[\"var\"].rank()/200000.\n    return new_df.values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"TARGET = np.array( list(train_df['target'].values) * 200 )\n\nTRAIN = []\nvar_mean = {}\nvar_var  = {}\nfor var in features:\n    tmp = var_to_feat(train_df[var], var_stats[var], int(var[4:]) )\n    var_mean[var] = np.mean(tmp[:,0]) \n    var_var[var]  = np.var(tmp[:,0])\n    tmp[:,0] = (tmp[:,0]-var_mean[var])/var_var[var]\n    TRAIN.append( tmp )\nTRAIN = np.vstack( TRAIN )\n\ntarget = train_df['target'].values\ndel train_df\n_=gc.collect()\n\nprint( TRAIN.shape, len( TARGET ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.LGBMClassifier(**{\n     'learning_rate': 0.03,\n     'num_leaves': 31,\n     'max_bin': 1023,\n     'min_child_samples': 1000,\n     'feature_fraction': 1.0,\n     'bagging_freq': 1,\n     'bagging_fraction': 0.85,\n     'objective': 'binary',\n     'n_jobs': -1,\n     'n_estimators':200,})\n\nNFOLDS = 10\npredtrain = np.zeros( len(TARGET) )\nMODELS = []\nskf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=11111)\nfor fold_, (train_indexes, valid_indexes) in enumerate(skf.split(TRAIN, TARGET)):\n    print('Fold:', fold_ )\n    model = model.fit( TRAIN[train_indexes], TARGET[train_indexes],\n                      eval_set = (TRAIN[valid_indexes], TARGET[valid_indexes]),\n                      verbose = 100,\n                      eval_metric='auc',\n                      early_stopping_rounds=20,\n                      categorical_feature = [2] )\n    MODELS.append( model )\n    predtrain[valid_indexes] = model.predict_proba( TRAIN[valid_indexes] )[:,1] \n\n#Reshape to original format 200k x 200\npred = np.reshape( predtrain , (200000,200) , order='F' )\n#Use logit for better performance\nprint( NFOLDS,'-Fold CV AUC:',roc_auc_score( target, np.mean( logit(pred),axis=1)  ) )\n_=gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred = np.zeros( (200000,200) )\nfor feat,var in enumerate(features):\n    #build dataset\n    tmp = var_to_feat(test_df[var], var_stats[var], int(var[4:]) )\n    #Standard Scale feature according train statistics\n    tmp[:,0] = (tmp[:,0]-var_mean[var])/var_var[var]\n    tmp[:,1] = tmp[:,1] + 1\n    #Write 1 to frequency of values not seem in trainset\n    tmp[ np.isnan(tmp) ] = 1\n    #Predict testset for N folds\n    for model_id in range(NFOLDS):\n        model = MODELS[model_id]\n        ypred[:,feat] += model.predict_proba( tmp )[:,1] / NFOLDS\nypred = np.mean( logit(ypred), axis=1 )\n\nsub = test_df[['ID_code']]\nsub['target'] = ypred\nsub['target'] = sub['target'].rank() / 200000.\nsub.to_csv('golden_sub.csv', index=False)\nprint( sub.head(20) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}