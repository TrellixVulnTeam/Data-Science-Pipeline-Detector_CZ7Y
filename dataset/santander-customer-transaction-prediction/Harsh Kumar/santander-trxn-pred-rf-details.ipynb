{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Santander Customer Transaction Prediction - Random Forest Details\n\nIn the Kaggle competition, the objective is to identify which customer will make a transaction in the future.\n\n**Link to the competition**: https://www.kaggle.com/c/santander-customer-transaction-prediction/  \n**Type of Problem**: Classification  \n**Metric for evalution**: AOC (Area Under Curve)\n\nThis Python 3 environment comes with many helpful analytics libraries installed\nIt is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.inspection import plot_partial_dependence\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step1: Read CSV\nRead the train csv file and look at the data. There are 200K rows and 200 independent variables.","metadata":{}},{"cell_type":"code","source":"input_dir = '/kaggle/input/santander-customer-transaction-prediction/'\ndf_train = pd.read_csv(input_dir + 'train.csv')\ndf_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split the data into independent and dependent variables. This is required to train the model using sklearn.","metadata":{}},{"cell_type":"code","source":"var_columns = [c for c in df_train if c not in ['ID_code','target']]\nX = df_train.loc[:,var_columns]\ny = df_train.loc[:,'target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step2: Create Random Forest Model\nUse the parameters which are result of hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"model_rf = RandomForestClassifier(class_weight='balanced',\n                                  criterion='gini',\n                                  max_depth=55,\n                                  max_features='log2',\n                                  min_samples_leaf=0.005,\n                                  min_samples_split=0.005,\n                                  n_estimators=190)\nmodel_rf.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step3: Variable Importance\nConvert the variable importance into pandas dataframe. Also sort the variable list based on importance.","metadata":{}},{"cell_type":"code","source":"df_var_imp = pd.DataFrame({'Variable': var_columns,\n                           'Importance': model_rf.feature_importances_}) \\\n                .sort_values(by='Importance', ascending=False) \\\n                .reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us plot the variable importance as bar charts.","metadata":{}},{"cell_type":"code","source":"df_var_imp[:15].sort_values('Importance').plot('Variable','Importance', 'barh', figsize=(15,5), legend=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step4: Partial Dependence of Variables\n`var_81`, `var_139` and `var_110` are the top variables on the basis of variable importance. Let us see how they relate to the dependent variable.","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(18, 4))\nplot_partial_dependence(model_rf, X, ['var_81','var_139','var_110'],\n                        grid_resolution=20, ax=ax);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For `var_81` and `var_139` , we can see that event rate is higher for lower values of the variable. For `var_110`, higher values leads to higher event rate. Also, seems like there can be a cut-off value which can be used for classification.  \n\nLet us also see the distribution of data as histogram for the three variables.","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(1, 3, figsize=(18, 4))\nX['var_81'].hist(ax=ax[0], legend=True)\nX['var_139'].hist(ax=ax[1], legend=True)\nX['var_110'].hist(ax=ax[2], legend=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step5: Prediction on Test Data\nRead the test and sample submission csv","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(input_dir + '/test.csv')\ndf_sample_submission = pd.read_csv(input_dir + '/sample_submission.csv')\n\ndf_test.shape, df_sample_submission.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split the test data between independent variables and find predictions","metadata":{}},{"cell_type":"code","source":"X_test = df_test.loc[:,var_columns]\n\ndf_sample_submission['target'] = model_rf.predict_proba(X_test)[:,1]\ndf_sample_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step6: Confidence of prediction\nWhile probability of prediction can be used to identify how confident we are about predictions for an observation, another way is to use standard deviation of predictions from different trees in the random forest.","metadata":{}},{"cell_type":"code","source":"y_test_pred_trees = np.stack([m.predict(X_test) for m in model_rf.estimators_])\ny_test_pred_trees.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred_std = y_test_pred_trees.std(0)\n\ndf_sample_submission['pred_prob'] = model_rf.predict_proba(X_test)[:,1]\ndf_sample_submission['pred_std'] = y_test_pred_std\ndf_sample_submission[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step7: Export Predictions","metadata":{}},{"cell_type":"code","source":"output_dir = '/kaggle/working/'\ndf_sample_submission[['ID_code','target']].to_csv(output_dir + '02_random_forest_scores.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}