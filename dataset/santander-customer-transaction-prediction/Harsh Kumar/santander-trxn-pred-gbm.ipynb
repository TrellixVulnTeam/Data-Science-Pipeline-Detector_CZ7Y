{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Santander Customer Transaction Prediction - GBM\n\nIn the Kaggle competition, the objective is to identify which customer will make a transaction in the future.\n\n**Link to the competition**: https://www.kaggle.com/c/santander-customer-transaction-prediction/  \n**Type of Problem**: Classification  \n**Metric for evalution**: AOC (Area Under Curve)\n\nThis Python 3 environment comes with many helpful analytics libraries installed\nIt is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pylab as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step1: Read Training Data from CSV\nUse pandas `read_csv` function to read the data from train.csv into a pandas dataframe.  \n\nThen the dataframe is split into train and test datasets using sklean's `train_test_split` function","metadata":{}},{"cell_type":"code","source":"input_dir = '/kaggle/input/santander-customer-transaction-prediction/'\ndf_train = pd.read_csv(input_dir + '/train.csv')\ndf_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var_columns = [c for c in df_train.columns if c not in ['ID_code','target']]\n\nX = df_train.loc[:,var_columns]\ny = df_train.loc[:,'target']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step2: Create a simple GBM Model and evaluate performance\n\nLet us look at meaning of some of the parameters which are passed to GradientBoostingClassifier:  \n- `n_estimators`: **5000** will be the maximum number of trees in the model\n- `learning_rate`: **0.05** will be weights assigned predictions from each tree in the model\n- `max_depth`: **3** will be the maximum depth of any one tree in the model\n- `subsample`: **50%** of the observations would be used for fitting individual trees\n- `validation_fraction`: **10%** of observations would be used for validation\n- `n_iter_no_change`: **20** is the stopping criteria for training. If no change is observed in performance for 20 iterations, training stops\n- `max_features`: **log2(# features)** will be considered for finding best split","metadata":{}},{"cell_type":"code","source":"model_gbm = GradientBoostingClassifier(n_estimators=5000,\n                                       learning_rate=0.05,\n                                       max_depth=3,\n                                       subsample=0.5,\n                                       validation_fraction=0.1,\n                                       n_iter_no_change=20,\n                                       max_features='log2',\n                                       verbose=1)\nmodel_gbm.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Look at how many estimators/trees were finally created during training.","metadata":{}},{"cell_type":"code","source":"len(model_gbm.estimators_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred = model_gbm.predict_proba(X_train)[:,1]\ny_valid_pred = model_gbm.predict_proba(X_valid)[:,1]\n\nprint(\"AUC Train: {:.4f}\\nAUC Valid: {:.4f}\".format(roc_auc_score(y_train, y_train_pred),\n                                                    roc_auc_score(y_valid, y_valid_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step3: Look at performance with respect to number of trees\n`staged_predict_proba` function allows us to look at predictions at for different number of trees in the model","metadata":{}},{"cell_type":"code","source":"y_train_pred_trees = np.stack(list(model_gbm.staged_predict_proba(X_train)))[:,:,1]\ny_valid_pred_trees = np.stack(list(model_gbm.staged_predict_proba(X_valid)))[:,:,1]\n\ny_train_pred_trees.shape, y_valid_pred_trees.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc_train_trees = [roc_auc_score(y_train, y_pred) for y_pred in y_train_pred_trees]\nauc_valid_trees = [roc_auc_score(y_valid, y_pred) for y_pred in y_valid_pred_trees]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\n\nplt.plot(auc_train_trees, label='Train Data')\nplt.plot(auc_valid_trees, label='Valid Data')\n\nplt.title('AUC vs Number of Trees')\nplt.ylabel('AUC')\nplt.xlabel('Number of Trees')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step4: Feature Importance\nLow importance features can be removed from the model for simpler, faster and more stable model","metadata":{}},{"cell_type":"code","source":"pd.DataFrame({\"Variable_Name\":var_columns,\n              \"Importance\":model_gbm.feature_importances_}) \\\n            .sort_values('Importance', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step5: Scoring for Test Data\nFirst, read test.csv and sample_submissions.csv","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(input_dir + 'test.csv')\ndf_sample_submission = pd.read_csv(input_dir + 'sample_submission.csv')\n\ndf_test.shape, df_sample_submission.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = df_test.loc[:,var_columns]\n\ndf_sample_submission['target'] = model_gbm.predict_proba(X_test)[:,1]\ndf_sample_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save the output as a csv","metadata":{}},{"cell_type":"code","source":"output_dir = '/kaggle/working/'\ndf_sample_submission.to_csv(output_dir + '/03_gbm_scores.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}