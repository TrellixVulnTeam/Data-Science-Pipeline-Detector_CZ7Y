{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-19T02:46:16.518361Z","iopub.execute_input":"2021-10-19T02:46:16.518735Z","iopub.status.idle":"2021-10-19T02:46:16.53201Z","shell.execute_reply.started":"2021-10-19T02:46:16.518701Z","shell.execute_reply":"2021-10-19T02:46:16.530906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', None)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:16.533978Z","iopub.execute_input":"2021-10-19T02:46:16.534506Z","iopub.status.idle":"2021-10-19T02:46:16.543661Z","shell.execute_reply.started":"2021-10-19T02:46:16.53447Z","shell.execute_reply":"2021-10-19T02:46:16.542773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(r\"/kaggle/input/santander-customer-transaction-prediction/train.csv\")\ntest_data = pd.read_csv(r\"/kaggle/input/santander-customer-transaction-prediction/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:16.545771Z","iopub.execute_input":"2021-10-19T02:46:16.547108Z","iopub.status.idle":"2021-10-19T02:46:24.523309Z","shell.execute_reply.started":"2021-10-19T02:46:16.547062Z","shell.execute_reply":"2021-10-19T02:46:24.521132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:24.524947Z","iopub.execute_input":"2021-10-19T02:46:24.525181Z","iopub.status.idle":"2021-10-19T02:46:24.668158Z","shell.execute_reply.started":"2021-10-19T02:46:24.525157Z","shell.execute_reply":"2021-10-19T02:46:24.667005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:24.670852Z","iopub.execute_input":"2021-10-19T02:46:24.672115Z","iopub.status.idle":"2021-10-19T02:46:24.816156Z","shell.execute_reply.started":"2021-10-19T02:46:24.67208Z","shell.execute_reply":"2021-10-19T02:46:24.814917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Summary Statistics","metadata":{}},{"cell_type":"code","source":"print(\"shape of training set is \" + str(train_data.shape))\nprint(\"shape of test set is \" + str(test_data.shape))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:24.818701Z","iopub.execute_input":"2021-10-19T02:46:24.819361Z","iopub.status.idle":"2021-10-19T02:46:24.826209Z","shell.execute_reply.started":"2021-10-19T02:46:24.819327Z","shell.execute_reply":"2021-10-19T02:46:24.825343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:24.827299Z","iopub.execute_input":"2021-10-19T02:46:24.827592Z","iopub.status.idle":"2021-10-19T02:46:26.594544Z","shell.execute_reply.started":"2021-10-19T02:46:24.827565Z","shell.execute_reply":"2021-10-19T02:46:26.593458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:26.596088Z","iopub.execute_input":"2021-10-19T02:46:26.59657Z","iopub.status.idle":"2021-10-19T02:46:28.436789Z","shell.execute_reply.started":"2021-10-19T02:46:26.596531Z","shell.execute_reply":"2021-10-19T02:46:28.435049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The summary statistics for the training and test data are similar","metadata":{}},{"cell_type":"markdown","source":"### 2. Check null values","metadata":{}},{"cell_type":"code","source":"missing_data_train = train_data.isna().sum()\nmissing_data_train[missing_data_train != 0]","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:28.438921Z","iopub.execute_input":"2021-10-19T02:46:28.439195Z","iopub.status.idle":"2021-10-19T02:46:28.515579Z","shell.execute_reply.started":"2021-10-19T02:46:28.439172Z","shell.execute_reply":"2021-10-19T02:46:28.513789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_data_test = train_data.isna().sum()\nmissing_data_test[missing_data_train != 0]","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:28.518163Z","iopub.execute_input":"2021-10-19T02:46:28.518485Z","iopub.status.idle":"2021-10-19T02:46:28.609111Z","shell.execute_reply.started":"2021-10-19T02:46:28.518445Z","shell.execute_reply":"2021-10-19T02:46:28.607875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no missing data in both the training and test set","metadata":{}},{"cell_type":"markdown","source":"### 3. Check categorical values","metadata":{}},{"cell_type":"code","source":"### https://stackoverflow.com/questions/29803093/check-which-columns-in-dataframe-are-categorical \ntrain_data.drop(columns=['ID_code', 'target']).select_dtypes(include=['category', 'object', 'int'])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:28.610908Z","iopub.execute_input":"2021-10-19T02:46:28.611177Z","iopub.status.idle":"2021-10-19T02:46:28.679244Z","shell.execute_reply.started":"2021-10-19T02:46:28.611145Z","shell.execute_reply":"2021-10-19T02:46:28.678425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.select_dtypes(include=['category', 'object', 'int'])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:28.680092Z","iopub.execute_input":"2021-10-19T02:46:28.680274Z","iopub.status.idle":"2021-10-19T02:46:28.706036Z","shell.execute_reply.started":"2021-10-19T02:46:28.680245Z","shell.execute_reply":"2021-10-19T02:46:28.70498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no categorical data in this dataset","metadata":{}},{"cell_type":"markdown","source":"### 4. Distribution of target variable","metadata":{}},{"cell_type":"code","source":"### http://seaborn.pydata.org/tutorial/categorical.html?highlight=bar%20plot\nsns.countplot(data=train_data, x='target')","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:28.709221Z","iopub.execute_input":"2021-10-19T02:46:28.709523Z","iopub.status.idle":"2021-10-19T02:46:28.861619Z","shell.execute_reply.started":"2021-10-19T02:46:28.709483Z","shell.execute_reply":"2021-10-19T02:46:28.861061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The dataset is imbalanced. Since there are plenty of data available, we will undersample data with target class 0 before training","metadata":{}},{"cell_type":"markdown","source":"### 5. Plots","metadata":{}},{"cell_type":"code","source":"# PCA\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\npca_train_X = pca.fit_transform(train_data.drop(columns = ['target', 'ID_code']))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:28.862793Z","iopub.execute_input":"2021-10-19T02:46:28.863151Z","iopub.status.idle":"2021-10-19T02:46:31.164325Z","shell.execute_reply.started":"2021-10-19T02:46:28.86312Z","shell.execute_reply":"2021-10-19T02:46:31.163224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_train_X.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:31.1656Z","iopub.execute_input":"2021-10-19T02:46:31.165885Z","iopub.status.idle":"2021-10-19T02:46:31.174674Z","shell.execute_reply.started":"2021-10-19T02:46:31.165855Z","shell.execute_reply":"2021-10-19T02:46:31.173165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.scatter(pca_train_X[:,0], pca_train_X[:,1], c=train_data['target'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T02:46:31.17751Z","iopub.execute_input":"2021-10-19T02:46:31.1779Z","iopub.status.idle":"2021-10-19T02:46:35.50247Z","shell.execute_reply.started":"2021-10-19T02:46:31.177864Z","shell.execute_reply":"2021-10-19T02:46:35.500372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We cannot see any pattern from the plot. Try violin plot now.","metadata":{}},{"cell_type":"code","source":"import math\n\n## Violin plot for training data\nnum_features=5 \nnum_columns = 3\n\ncolumns = list(filter(lambda col: col not in ['ID_code'] + ['target'], train_data.columns))\nnum_graphs = math.ceil(len(columns)/num_features)\nnum_rows = math.ceil(num_graphs/num_columns)\n\nfor row in range(num_rows):\n    print(\"plotting for variables %d - %d\" % (row * num_features * num_columns, row * num_features * num_columns+15))\n    fig, axes = plt.subplots(1, num_columns)\n    fig.set_figheight(5)\n    fig.set_figwidth(8 * num_columns)\n    for col in range(num_columns):\n        curr_cols = columns[row * num_features * num_columns + col * num_features:row * num_features * num_columns + col * num_features + num_features]\n        if len(curr_cols) == 0:\n            break\n        else:\n            curr_cols = curr_cols + ['target']\n        df = train_data[curr_cols]\n        df = df.melt(id_vars = ['target'], var_name = 'Vars', value_name = 'Values')\n        sns.violinplot(x=\"Vars\",y=\"Values\",data=df, hue = 'target', split=True, inner=\"quart\", ax=axes[col])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T03:17:27.924597Z","iopub.execute_input":"2021-10-19T03:17:27.924883Z","iopub.status.idle":"2021-10-19T03:20:50.48458Z","shell.execute_reply.started":"2021-10-19T03:17:27.924856Z","shell.execute_reply":"2021-10-19T03:20:50.482847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Violin plot for train vs test dataset\ncopy_train_data = train_data.copy()\ncopy_test_data = test_data.copy()\n\ncopy_train_data['dataset'] = 'train'\ncopy_test_data['dataset'] = 'test'\n\ncopy_train_data = copy_train_data.drop(columns=['target'])\n\ncolumns = list(filter(lambda col: col not in ['ID_code'] + ['dataset'], copy_train_data.columns))\n\nnum_graphs = math.ceil(len(columns)/num_features)\nnum_rows = math.ceil(num_graphs/num_columns)\n\nfor row in range(num_rows):\n    print(\"plotting for variables %d - %d\" % (row * num_features * num_columns, row * num_features * num_columns+15))\n    fig, axes = plt.subplots(1, num_columns)\n    fig.set_figheight(5)\n    fig.set_figwidth(8 * num_columns)\n    for col in range(num_columns):\n        curr_cols = columns[row * num_features * num_columns + col * num_features:row * num_features * num_columns + col * num_features + num_features]\n        if len(curr_cols) == 0:\n            break\n        else:\n            curr_cols = curr_cols + ['dataset']\n        train_df = copy_train_data[curr_cols]\n        test_df = copy_test_data[curr_cols]\n        df = train_df.append(test_df)\n        df = df.melt(id_vars = ['dataset'], var_name = 'Vars', value_name = 'Values')\n        sns.violinplot(x=\"Vars\",y=\"Values\",data=df, hue = 'dataset', split=True, inner=\"quart\", ax=axes[col])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T03:27:00.244917Z","iopub.execute_input":"2021-10-19T03:27:00.245459Z","iopub.status.idle":"2021-10-19T03:34:50.048405Z","shell.execute_reply.started":"2021-10-19T03:27:00.245428Z","shell.execute_reply":"2021-10-19T03:34:50.047083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The violin plots look identical for training and test dataset. We expect that a model performing well for training set should perform well for test set as well.","metadata":{}},{"cell_type":"code","source":"## plot the histogram of corr coef across all variables\n\n# this function calculates the correlation coefficient for large dataset\ndef corr_coef(df):\n    mean = np.mean(df, axis=0)\n    std = np.std(df, axis=0)\n    scaled = (df-mean)/std\n    return np.matmul(scaled.T, scaled)/df.shape[0]\n\ndef plot_corrcoef(mat):\n    res = []\n    for i in range(len(mat-1)):\n        for j in range(i+1,len(mat)):\n            res.append(mat[i,j])\n    \n    plt.hist(res, bins=100)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T03:08:26.099081Z","iopub.execute_input":"2021-10-19T03:08:26.099776Z","iopub.status.idle":"2021-10-19T03:08:26.107427Z","shell.execute_reply.started":"2021-10-19T03:08:26.099742Z","shell.execute_reply":"2021-10-19T03:08:26.106517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## training set\ncorr = corr_coef(train_data.drop(columns=['target', 'ID_code']))\nplot_corrcoef(corr.to_numpy())","metadata":{"execution":{"iopub.status.busy":"2021-10-19T03:08:26.594597Z","iopub.execute_input":"2021-10-19T03:08:26.596305Z","iopub.status.idle":"2021-10-19T03:08:27.63552Z","shell.execute_reply.started":"2021-10-19T03:08:26.596237Z","shell.execute_reply":"2021-10-19T03:08:27.633389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## test set\ntest_corr = corr_coef(test_data.drop(columns=['ID_code']))\nplot_corrcoef(test_corr.to_numpy())","metadata":{"execution":{"iopub.status.busy":"2021-10-19T03:13:28.118738Z","iopub.execute_input":"2021-10-19T03:13:28.119077Z","iopub.status.idle":"2021-10-19T03:13:29.4724Z","shell.execute_reply.started":"2021-10-19T03:13:28.119046Z","shell.execute_reply":"2021-10-19T03:13:29.471233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The variables exhibits little or no linear correlation with each other.","metadata":{}}]}