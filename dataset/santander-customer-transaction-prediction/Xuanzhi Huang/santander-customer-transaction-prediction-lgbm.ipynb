{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Preliminaries"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install scorecardpy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.special import logit\nimport lightgbm as lgb\nimport scorecardpy as sc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"### Load the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/santander-customer-transaction-prediction/train.csv\")\ntest = pd.read_csv(\"../input/santander-customer-transaction-prediction/test.csv\")\ntrain = train.drop('ID_code', axis = 1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = test.ID_code\ntest = test.drop('ID_code', axis = 1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check if there is any missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Whether there is missing value in the training set\nprint(f\"The number of missing values in the training set is: {np.sum(np.sum(pd.isnull(train)))}\")\n\n# Whether there is missing value in the test set\nprint(f\"The number of missing values in the test set is: {np.sum(np.sum(pd.isnull(test)))}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Obtain the correlations between different variables/response"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = train.drop(\"target\", axis = 1).corr().abs().unstack().sort_values(kind = \"quicksort\").reset_index()\ncorrelations = correlations[correlations['level_0'] != correlations['level_1']]\ncorrelations.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is shown that the correlations between different variables are pretty small. What about the correlations between target and predictors?"},{"metadata":{"trusted":true},"cell_type":"code","source":"variables = train.drop(\"target\", axis = 1).columns.values.tolist()\ncorr_pre_res = np.zeros(len(variables))\ni = 0\nfor var in variables:\n    corr_pre_res[i] = np.corrcoef(train[var], train[\"target\"])[0, 1]\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_pre_res = abs(pd.DataFrame(corr_pre_res))\ncorr_pre_res.columns = ['corr_pre_res']\ncorr_pre_res.sort_values(by = 'corr_pre_res')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlations between target and variables are all small, so we should not drop some variables according to the correlations."},{"metadata":{},"cell_type":"markdown","source":"## Feature Exploration (by WOE & IV)"},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = sc.woebin(train, y = 'target', \n                 min_perc_fine_bin = 0.05, # How many bins to cut initially into\n                 min_perc_coarse_bin = 0.05,  # Minimum percentage per final bin\n                 stop_limit = 0.1, # Minimum information value \n                 max_num_bin = 8, # Maximum number of bins\n                 method = 'tree')\n\nsc.woebin_plot(bins)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can find that the original predictors are not useful enough for prediction (none of the IV is larger than 0.1). Consider constructing some new ones for better prediction."},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering & Model Building (refer to Dott)\n[922 in 3 minutes](https://www.kaggle.com/dott1718/922-in-3-minutes/comments)"},{"metadata":{},"cell_type":"markdown","source":"#### Since the variables are independent, use each of them combined with the frequency of each of its value as predictor to predict the probability of purchasing with LGBM, and then calculate the logit value of each probability and sum up all the logit values (by 200 predictors) to get the final result."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [x for x in train.columns if x.startswith(\"var\")]\n\nhist_df = pd.DataFrame()\nfor var in features:\n    var_stats = train[var].append(test[var]).value_counts()\n    hist_df[var] = pd.Series(test[var]).map(var_stats)\n    hist_df[var] = hist_df[var] > 1\n\nind = hist_df.sum(axis = 1) != 200\nvar_stats = {var: train[var].append(test[ind][var]).value_counts() for var in features}\n\npred = 0\nfor var in features:\n    model = lgb.LGBMClassifier(**{'learning_rate': 0.05, \n                                  'max_bin': 165, \n                                  'max_depth': 5, \n                                  'min_child_samples': 150,\n                                  'min_child_weight': 0.1, \n                                  'min_split_gain': 0.0018, \n                                  'n_estimators': 41,\n                                  'num_leaves': 6, \n                                  'reg_alpha': 2.0, \n                                  'reg_lambda': 2.54, \n                                  'objective': 'binary', \n                                  'n_jobs': -1})\n    model = model.fit(np.hstack([train[var].values.reshape(-1, 1),\n                      train[var].map(var_stats[var]).values.reshape(-1, 1)]), train[\"target\"].values)\n    pred += logit(model.predict_proba(np.hstack([test[var].values.reshape(-1, 1),\n                  test[var].map(var_stats[var]).values.reshape(-1, 1)]))[:, 1])\n    \npd.DataFrame({\"ID_code\": test_id, \"target\": pred}).to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}