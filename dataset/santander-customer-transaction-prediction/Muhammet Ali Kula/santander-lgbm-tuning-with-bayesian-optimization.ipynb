{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SETUP","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgbm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.cluster import KMeans\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom hyperopt import hp, tpe\nfrom hyperopt.fmin import fmin\n\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer\n\nimport xgboost as xgb\n\nimport lightgbm as lgbm\nfrom sklearn.utils import shuffle, resample\nfrom sklearn.preprocessing import StandardScaler\nfrom bayes_opt import BayesianOptimization\nfrom skopt  import BayesSearchCV \nimport lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV\n# Similarly LGBMRegressor can also be imported for a regression model.\nfrom lightgbm import LGBMClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import fbeta_score\nfrom skopt.space import Real, Integer\nfrom skopt.utils import use_named_args\nfrom skopt import gp_minimize\nfrom skopt.plots import plot_convergence","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-02T13:19:28.469037Z","iopub.execute_input":"2021-12-02T13:19:28.469339Z","iopub.status.idle":"2021-12-02T13:19:28.480688Z","shell.execute_reply.started":"2021-12-02T13:19:28.469302Z","shell.execute_reply":"2021-12-02T13:19:28.479779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/santander-customer-transaction-prediction/train.csv\")\ntest = pd.read_csv(\"../input/santander-customer-transaction-prediction/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:19:28.482039Z","iopub.execute_input":"2021-12-02T13:19:28.482418Z","iopub.status.idle":"2021-12-02T13:19:43.603992Z","shell.execute_reply.started":"2021-12-02T13:19:28.482376Z","shell.execute_reply":"2021-12-02T13:19:43.603206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:19:43.605694Z","iopub.execute_input":"2021-12-02T13:19:43.605923Z","iopub.status.idle":"2021-12-02T13:19:43.632115Z","shell.execute_reply.started":"2021-12-02T13:19:43.605895Z","shell.execute_reply":"2021-12-02T13:19:43.631246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Column/Columns that are not in test data: ', end = '')\nfor i in train.columns:\n    if i not in test.columns:\n        print(i)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:19:43.633274Z","iopub.execute_input":"2021-12-02T13:19:43.633578Z","iopub.status.idle":"2021-12-02T13:19:43.639609Z","shell.execute_reply.started":"2021-12-02T13:19:43.633548Z","shell.execute_reply":"2021-12-02T13:19:43.638751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(train['target']);","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:19:43.642013Z","iopub.execute_input":"2021-12-02T13:19:43.642681Z","iopub.status.idle":"2021-12-02T13:19:43.838088Z","shell.execute_reply.started":"2021-12-02T13:19:43.642636Z","shell.execute_reply":"2021-12-02T13:19:43.837308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bayesian Optimization","metadata":{}},{"cell_type":"code","source":"train = train.select_dtypes(include=['int','float'])\ntest = test.select_dtypes(include=['int','float'])\nX = train.drop(columns=[\"target\"])\ny=train[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:19:43.839433Z","iopub.execute_input":"2021-12-02T13:19:43.839679Z","iopub.status.idle":"2021-12-02T13:19:44.14053Z","shell.execute_reply.started":"2021-12-02T13:19:43.839647Z","shell.execute_reply":"2021-12-02T13:19:44.139612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=3, random_seed=6, output_process=False):\n    # prepare data\n    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n    # parameters\n    def lgb_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, lambda_l1,lambda_l2,early_stopping_round):\n        params = {'application':'binary', 'metric':'auc'}\n        params['learning_rate'] = max(min(learning_rate, 1), 0)\n        params[\"num_leaves\"] = int(round(num_leaves))\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n        params['max_depth'] = int(round(max_depth))\n        params['max_bin'] = int(round(max_depth))\n        params['lambda_l1'] = int(round(lambda_l1))\n        params['lambda_l2'] = int(round(lambda_l2))\n        params['early_stopping_round'] = int(round(early_stopping_round))\n        \n        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =250,num_boost_round=1500, metrics=['auc'])\n        return max(cv_result['auc-mean'])\n     \n    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.04, 0.65),\n                                            'num_leaves': (8, 240),\n                                            'feature_fraction': (0.21, 0.9),\n                                            'bagging_fraction': (0.2, 0.9),\n                                            'max_depth': (4, 25),\n                                            'max_bin':(5,65),\n                                            'early_stopping_round' : (10,300),\n                                            'lambda_l1': (0, 10),\n                                            'lambda_l2':  (0, 10)}, random_state=200)                                   \n                                      \n\n\n    \n    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n    \n    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n    \n    model_auc=[]\n    for model in range(len( lgbBO.res)):\n        model_auc.append(lgbBO.res[model]['target'])\n    \n    # return best parameters\n    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n\nopt_params = bayes_parameter_opt_lgb(X, y, init_round=5, opt_round=10, n_folds=3, random_seed=6)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:19:44.144327Z","iopub.execute_input":"2021-12-02T13:19:44.144754Z","iopub.status.idle":"2021-12-02T13:54:22.612124Z","shell.execute_reply.started":"2021-12-02T13:19:44.144693Z","shell.execute_reply":"2021-12-02T13:54:22.611315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Best Params","metadata":{}},{"cell_type":"code","source":"opt_params[1][\"num_leaves\"] = int(round(opt_params[1][\"num_leaves\"]))\nopt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\nopt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin']))\nopt_params[1]['objective']='binary'\nopt_params[1]['metric']='auc'\n#opt_params[1]['is_unbalance']=True\n#opt_params[1]['boost_from_average']=False\nopt_params=opt_params[1]\nopt_params","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:54:22.613699Z","iopub.execute_input":"2021-12-02T13:54:22.613936Z","iopub.status.idle":"2021-12-02T13:54:22.626408Z","shell.execute_reply.started":"2021-12-02T13:54:22.613908Z","shell.execute_reply":"2021-12-02T13:54:22.625534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Undersampling","metadata":{}},{"cell_type":"code","source":"# separate classes into different datasets\nnormal_class = train.query('target == 0')\nfraudulent_class = train.query('target == 1')\n\n# randomize the datasets\nnormal_class = normal_class.sample(frac=1,random_state=1210)\nfraudulent_class = fraudulent_class.sample(frac=1,random_state=1210)\nresampled = normal_class.sample(n=int(len(fraudulent_class)*4.4), random_state=1210)\ntrain = pd.concat([fraudulent_class,resampled])","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:54:22.627639Z","iopub.execute_input":"2021-12-02T13:54:22.627866Z","iopub.status.idle":"2021-12-02T13:54:23.302007Z","shell.execute_reply.started":"2021-12-02T13:54:22.62784Z","shell.execute_reply":"2021-12-02T13:54:23.301157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.select_dtypes(include=['int','float'])\ntest = test.select_dtypes(include=['int','float'])","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:54:23.303279Z","iopub.execute_input":"2021-12-02T13:54:23.303503Z","iopub.status.idle":"2021-12-02T13:54:23.466475Z","shell.execute_reply.started":"2021-12-02T13:54:23.303477Z","shell.execute_reply":"2021-12-02T13:54:23.465382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:54:23.468695Z","iopub.execute_input":"2021-12-02T13:54:23.469017Z","iopub.status.idle":"2021-12-02T13:54:23.494478Z","shell.execute_reply.started":"2021-12-02T13:54:23.468973Z","shell.execute_reply":"2021-12-02T13:54:23.493873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns=[\"target\"])\ny=train[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:54:23.49553Z","iopub.execute_input":"2021-12-02T13:54:23.496462Z","iopub.status.idle":"2021-12-02T13:54:23.561432Z","shell.execute_reply.started":"2021-12-02T13:54:23.496421Z","shell.execute_reply":"2021-12-02T13:54:23.560441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bayesian Opt with Undersampling","metadata":{}},{"cell_type":"code","source":"%%time\n\ndef bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=3, random_seed=6, output_process=False):\n    # prepare data\n    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n    # parameters\n    def lgb_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, lambda_l1,lambda_l2,early_stopping_round):\n        params = {'application':'binary', 'metric':'auc'}\n        params['learning_rate'] = max(min(learning_rate, 1), 0)\n        params[\"num_leaves\"] = int(round(num_leaves))\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n        params['max_depth'] = int(round(max_depth))\n        params['max_bin'] = int(round(max_depth))\n        params['lambda_l1'] = int(round(lambda_l1))\n        params['lambda_l2'] = int(round(lambda_l2))\n        params['early_stopping_round'] = int(round(early_stopping_round))\n        \n        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =250,num_boost_round=1500, metrics=['auc'])\n        return max(cv_result['auc-mean'])\n     \n    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.04, 0.65),\n                                            'num_leaves': (8, 240),\n                                            'feature_fraction': (0.21, 0.9),\n                                            'bagging_fraction': (0.2, 0.9),\n                                            'max_depth': (4, 25),\n                                            'max_bin':(5,65),\n                                            'early_stopping_round' : (10,300),\n                                            'lambda_l1': (0, 10),\n                                            'lambda_l2':  (0, 10)}, random_state=200)                                   \n                                      \n\n\n    \n    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n    \n    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n    \n    model_auc=[]\n    for model in range(len( lgbBO.res)):\n        model_auc.append(lgbBO.res[model]['target'])\n    \n    # return best parameters\n    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n\nopt_params = bayes_parameter_opt_lgb(X, y, init_round=5, opt_round=10, n_folds=3, random_seed=6)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:54:23.562779Z","iopub.execute_input":"2021-12-02T13:54:23.563013Z","iopub.status.idle":"2021-12-02T14:11:15.032673Z","shell.execute_reply.started":"2021-12-02T13:54:23.562986Z","shell.execute_reply":"2021-12-02T14:11:15.031762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Undersampled data best params","metadata":{}},{"cell_type":"code","source":"opt_params[1][\"num_leaves\"] = int(round(opt_params[1][\"num_leaves\"]))\nopt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\nopt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin']))\nopt_params[1]['objective']='binary'\nopt_params[1]['metric']='auc'\n#opt_params[1]['is_unbalance']=True\n#opt_params[1]['boost_from_average']=False\nopt_params=opt_params[1]\nopt_params","metadata":{"execution":{"iopub.status.busy":"2021-12-02T14:11:15.034437Z","iopub.execute_input":"2021-12-02T14:11:15.034966Z","iopub.status.idle":"2021-12-02T14:11:15.044394Z","shell.execute_reply.started":"2021-12-02T14:11:15.034933Z","shell.execute_reply":"2021-12-02T14:11:15.043574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Undersampled and base data params","metadata":{}},{"cell_type":"code","source":"d = {\n    'Datasets': ['Undersampled_Data', 'Base_Data'],\n    'bagging_fraction': [0.9, 0.9],\n    'early_stopping_round': [72,76],\n    'feature_fraction': [0.21,0.21],\n         'lambda_l1': [0,0],\n         'lambda_l2': [10,10],\n         'learning_rate': [0.04,0.04],\n         'max_bin': [34,35],\n         'max_depth': [25,25],\n             'num_leaves': [83,107],\n         'objective': ['binary','binary'],\n         'metric': ['auc', 'auc']\n }\ndf = pd.DataFrame(data=d)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-12-02T14:12:56.329625Z","iopub.execute_input":"2021-12-02T14:12:56.329891Z","iopub.status.idle":"2021-12-02T14:12:56.350091Z","shell.execute_reply.started":"2021-12-02T14:12:56.329862Z","shell.execute_reply":"2021-12-02T14:12:56.349447Z"},"trusted":true},"execution_count":null,"outputs":[]}]}