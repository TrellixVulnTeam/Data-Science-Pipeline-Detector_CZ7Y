{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load training data\ndata = pd.read_csv('../input/train.csv', index_col=0)\nfeatures = [i for i in data.columns if i != 'target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generate fake random data based on train distributions\nnp.random.seed(1)\nnew_train = pd.DataFrame()\nnew_rows = 273000\n\nfor f in features:\n    std = data[f].std()\n    m = data[f].mean()\n    \n    new_train[f] = np.random.normal(m, std, new_rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Randomly set  3000 rows to target=1, the others to target=0\nnew_train['target'] = 0\npos_idx = new_train.sample(n=3000, random_state=1).index\nnew_train.loc[pos_idx, 'target'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now round all features to 4 digits\nnew_train[features] = new_train[features].round(4)\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now upsample positive rows with shuffle method\n#Augment \ndef augment(x, targ=1, seed=1):\n    extra = x[x.target==targ].copy()\n\n    for f in range(200):\n        np.random.seed(seed)        \n        feat = 'var_' + str(f)\n        np.random.shuffle(extra[feat].values)     \n        seed +=1\n    return extra\n\nextras = []\nfor i in range(9):\n    extra_pos = augment(new_train, targ=1, seed=i)\n    extras.append(extra_pos)\n    \nextras = pd.concat(extras)\nnew_train = pd.concat((new_train, extras)).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check that pos frequency is about 10%\nnew_train['target'].value_counts()/len(new_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove 100000 rows for test set\nnew_test = new_train.sample(100000, random_state=1)\nnew_train = new_train.drop(new_test.index)\nprint('Train shape:', new_train.shape, 'Test shape:', new_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check distribution of a favorite variable\nnew_train[new_train.target==0]['var_81'].hist(bins=100)\nnew_train[new_train.target==1]['var_81'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Run 5-fold CV\ndef get_params(seed=1):\n    param = {'num_leaves': 6,\n             #'min_data_in_leaf': 20,\n             'objective':'binary',\n             'metric': 'auc',\n             'learning_rate': 0.2,\n             \"boosting\": \"gbdt\",\n             #\"feature_fraction\": 1.0,\n             #\"bagging_freq\": 5,\n             #\"bagging_fraction\": 0.8,\n             \"lambda_l2\": 10,\n             \"verbosity\": -1,\n             \"seed\": seed,            \n            }\n    return param\n\ndtrain = lgb.Dataset(new_train[features], new_train.target)\ncv = lgb.cv(get_params(), dtrain, 100000, nfold=5, \n            early_stopping_rounds= 100,\n            verbose_eval=100\n       )\n\nbest_score = np.max(cv['auc-mean'])\nbest_iter = np.argmax(cv['auc-mean'])\n\nprint( best_score, best_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}