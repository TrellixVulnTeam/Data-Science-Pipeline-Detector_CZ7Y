{"cells":[{"metadata":{},"cell_type":"markdown","source":"2/2: https://www.kaggle.com/nagiss/9-solution-nagiss-part-2-2-weightshareing-nn"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport time\nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nwarnings.filterwarnings('ignore')\n\nPATH=\"../input/\"\n\nN_SPLITS = 10\nSEED_SKF = 4221","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def merge_train_test(df_train, df_test):\n    if \"target\" not in df_test.columns.values:\n        df_test[\"target\"] = -1\n    res = pd.concat([df_train, df_test])\n    res.reset_index(inplace=True, drop=True)\n    return res\n\ndef split_train_test(df):\n    df_train = df[df[\"target\"] >= 0]\n    df_test = df[df[\"target\"] <= -1]\n    df_train.reset_index(inplace=True, drop=True)\n    df_test.reset_index(inplace=True, drop=True)\n    assert list(df_train[\"ID_code\"].values) == [f\"train_{i}\" for i in range(200000)]\n    assert list(df_test[\"ID_code\"].values) == [f\"test_{i}\" for i in range(200000)]\n    return df_train, df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df = pd.read_csv(PATH+\"train.csv\")\ntest_df = pd.read_csv(PATH+\"test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CountEncoder:\n    def fit(self, series):\n        self.counts = series.groupby(series).count()\n    \n    def transform(self, series):\n        return series.map(self.counts).fillna(0).astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate into real and fake\n\ndf_cnt = pd.DataFrame()\nfor v in range(200):\n    sr = test_df[f\"var_{v}\"]\n    enc = CountEncoder()\n    enc.fit(sr)\n    df_cnt[f\"cnt_{v}\"] = enc.transform(sr)\ntest_df[\"target\"] = -df_cnt.min(1)  # target==-1 -> real, target==-2 -> fake\ndel df_cnt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged = merge_train_test(train_df, test_df)\ndf_merged.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# count encoding\n\ncount_enc = [None] * 200\ndf_real = df_merged[df_merged[\"target\"]!=-2]\nfor v in range(200):\n    enc = CountEncoder()\n    enc.fit(df_real[f\"var_{v}\"])\n    count_enc[v] = enc.transform(df_merged[f\"var_{v}\"])\n    \nfor v in range(200):\n    df_merged[f\"cnt_{v}\"] = count_enc[v]\n\ndel df_real","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = split_train_test(df_merged)\ntarget = train_df['target']\ngc.collect()\nprint(train_df.shape)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1st step - make meta features"},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n    \"objective\": \"binary\", \n    \"boost\": \"gbdt\",\n    \"metric\": \"auc\",\n    \"boost_from_average\": False,\n    \"learning_rate\": 0.01,\n    \"num_leaves\": 5,\n    \"max_depth\": -1,\n    \"tree_learner\": \"serial\",\n    \"feature_fraction\": 1.0,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\": 0.4,\n    \"min_data_in_leaf\": 80,\n    \"min_sum_hessian_in_leaf\": 10.0,\n    \"verbosity\": 1,\n    \"seed\": 44000,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train_df['target']\ndf_merged_cut = [df_merged[[f\"var_{v}\", \n                            f\"cnt_{v}\", \n                           ]] for v in range(200)]\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"%%time\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED_SKF)\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(skf.split(train_df.values, target.values)):\n    print(\"fold n°{}\".format(fold_))\n    df_meta = df_merged[[\"ID_code\", \"target\"]]\n    \n    trn_X, trn_y = train_df.iloc[trn_idx], target.iloc[trn_idx]\n    val_X, val_y = train_df.iloc[val_idx], target.iloc[val_idx]\n    for v in range(200):\n        print(f\"var {v}\")\n        features = [f\"var_{v}\", \n                    f\"cnt_{v}\", \n                   ]\n\n        trn_data = lgb.Dataset(trn_X[features], label=trn_y)\n        val_data = lgb.Dataset(val_X[features], label=val_y)\n\n        num_round = 1000000\n        clf = lgb.train(param, \n                        trn_data, \n                        num_round, \n                        valid_sets=[trn_data, val_data], \n                        verbose_eval=1000, \n                        early_stopping_rounds=100)\n        df_meta[f\"{v}_meta\"] = clf.predict(df_merged_cut[v], num_iteration=clf.best_iteration).astype(np.float32)\n\n    df_meta.to_pickle(f\"fold_{fold_}_meta.pickle\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2nd step - prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n    \"objective\": \"binary\", \n    \"boost\": \"gbdt\",\n    \"metric\": \"auc\",\n    \"boost_from_average\": \"false\",\n    \"learning_rate\": 0.01,\n    \"num_leaves\": 2,\n    \"max_depth\": -1,\n    \"tree_learner\": \"serial\",\n    \"feature_fraction\": 0.5,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\": 0.4,\n    \"min_data_in_leaf\": 80,\n    \"min_sum_hessian_in_leaf\": 10.0,\n    \"verbosity\": 1,\n    \"seed\": 44000,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n%%time\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED_SKF)\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(skf.split(train_df.values, target.values)):\n    print(\"fold n°{}\".format(fold_))\n    df_meta = pd.read_pickle(f\"fold_{fold_}_meta.pickle\")\n    train_df, test_df = split_train_test(df_meta)\n    features = [f\"{v}_meta\" for v in range(200)]\n    \n    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n\n    num_round = 1000000\n    clf = lgb.train(param, \n                    trn_data, \n                    num_round, \n                    valid_sets=[trn_data, val_data], \n                    verbose_eval=1000, \n                    early_stopping_rounds=2000)\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / N_SPLITS\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,80))\nsns.barplot(x=\"importance\", y=\"feature\", data=feature_importance_df.sort_values(by=\"importance\",ascending=False))\nplt.title('Features importance (averaged/folds)')\nplt.tight_layout()\nplt.savefig('FI.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\nsub_df[\"target\"] = predictions\nsub_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance_df.to_csv(\"feature_importance_df.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}