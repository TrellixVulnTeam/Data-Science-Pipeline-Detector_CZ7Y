{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](http://https://api-manager.universia.net/coreplatform-document-management/api/document-management/public/3l6wykk6kjryvb)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\nimport pickle\nimport seaborn as sns\nimport gc\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_context(\"paper\")\nsns.set_style(\"darkgrid\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# training data\ntrain = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# testing data\ntest = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission example\nss = pd.read_csv('../input/santander-customer-transaction-prediction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.columns[2:]].std().plot('hist');\nplt.title('Distribution of stds of all columns');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.columns[2:]].mean().plot('hist');\nplt.title('Distribution of means of all columns');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=train.target.value_counts().index, y=train.target.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cor = train.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ###### Проверим коэффициент корреляции чтобы узнать какие признаки имеют наибольшую связь с target."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(cor[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cor_target = cor_target.sort_values(kind='quicksort',ascending=False)\n#Selecting highly correlated features\nrelevant_features = cor_target[1:31]\nprint(cor_target.mean())\nrelevant_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Сравнение тестовых и тренировочных данных "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nfeatures = train.columns.values[2:202]\nplt.title(\"Distribution of mean values per row in the train and test set\")\nsns.distplot(train[features].mean(axis=1),color=\"green\", kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Distribution of mean values per column in the train and test set\")\nsns.distplot(train[features].mean(axis=0),color=\"magenta\",kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=0),color=\"darkblue\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per row in the train and test set\")\nsns.distplot(train[features].std(axis=1),color=\"black\", kde=True,bins=120, label='train')\nsns.distplot(test[features].std(axis=1),color=\"red\", kde=True,bins=120, label='test')\nplt.legend();plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per column in the train and test set\")\nsns.distplot(train[features].std(axis=0),color=\"blue\",kde=True,bins=120, label='train')\nsns.distplot(test[features].std(axis=0),color=\"green\", kde=True,bins=120, label='test')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Сравнение 0 и 1 в target"},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = train.loc[train['target'] == 0]\nt1 = train.loc[train['target'] == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per row in the train set\")\nsns.distplot(t0[features].mean(axis=1),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per column in the train set\")\nsns.distplot(t0[features].mean(axis=0),color=\"magenta\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].mean(axis=0),color=\"darkblue\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(columns=['target','ID_code'])\ny_train = train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, f1_score, cohen_kappa_score, precision_score, recall_score, confusion_matrix\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Параметры для XGboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# details: https://xgboost.readthedocs.io/en/latest/parameter.html\nparams = {'tree_method': 'hist',\n 'objective': 'binary:logistic',\n 'eval_metric': 'auc',\n 'learning_rate': 0.0936165921314771,\n 'max_depth': 2,\n 'colsample_bytree': 0.3561271102144279,\n 'subsample': 0.8246604621518232,\n 'min_child_weight': 53,\n 'gamma': 9.943467991283027,\n 'silent': 1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> > Чтобы сохранить распределение классов при разбивке, я использовал sklearn.model_selection.StratifiedKFold. Это важно, если классы изначально сильно несбалансированы (0 в девять раз больше чем 1 в train set)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\noof_preds = np.zeros(train.shape[0])\nsub_preds = np.zeros(test.shape[0])\n\nfeature_importance_df = pd.DataFrame()\n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n    \n    trn_x, trn_y = train[features].iloc[trn_idx], y_train.iloc[trn_idx]\n    val_x, val_y = train[features].iloc[val_idx], y_train.iloc[val_idx]\n    \n    dtrain = xgb.DMatrix(trn_x, trn_y, feature_names=trn_x.columns)\n    dval = xgb.DMatrix(val_x, val_y, feature_names=val_x.columns)\n    \n    clf = xgb.train(params=params, dtrain=dtrain, num_boost_round=4000, evals=[(dtrain, \"Train\"), (dval, \"Val\")],\n        verbose_eval= 100, early_stopping_rounds=50) \n    \n    oof_preds[val_idx] = clf.predict(xgb.DMatrix(val_x))\n    sub_preds += clf.predict(xgb.DMatrix(test[features])) / folds.n_splits\n\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n    fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n    fold_importance_df[\"fold\"] = n_fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n    print('\\nFold %1d AUC %.6f & std %.6f' %(n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]), np.std([oof_preds[val_idx]])))\n    print('Fold %1d Precision %.6f' %(n_fold + 1, precision_score(val_y, np.round(oof_preds[val_idx])) ))\n    print('Fold %1d Recall %.6f' %(n_fold + 1, recall_score(val_y, np.round(oof_preds[val_idx]) )))\n    print('Fold %1d F1 score %.6f' % (n_fold + 1,f1_score(val_y, np.round(oof_preds[val_idx]))))\n    print('Fold %1d Kappa score %.6f\\n' % (n_fold + 1,cohen_kappa_score(val_y, np.round(oof_preds[val_idx]))))\n    gc.collect()\n\nprint('\\nCV AUC score %.6f & std %.6f' % (roc_auc_score(y_train, oof_preds), np.std((oof_preds))))\nprint('CV Precision score %.6f' % (precision_score(y_train, np.round(oof_preds))))\nprint('CV Recall score %.6f' % (recall_score(y_train, np.round(oof_preds))))\nprint('CV F1 score %.6f' % (f1_score(y_train, np.round(oof_preds))))\nprint('CV Kappa score %.6f' % (cohen_kappa_score(y_train, np.round(oof_preds))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_train, np.round(oof_preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(10,12)) \nxgb.plot_importance(clf, max_num_features=20, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(10,12)) \nxgb.plot_importance(clf, max_num_features=20, ax=ax, importance_type=\"cover\", xlabel=\"Cover\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(10,12)) \nxgb.plot_importance(clf, max_num_features=20, ax=ax, importance_type=\"gain\", xlabel=\"Gain\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance_df.groupby([\"feature\"])[\"fscore\",].mean().sort_values(\"fscore\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['target'] = sub_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_roc = roc_auc_score(y_train, oof_preds)\noof_roc ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XGboost = pd.DataFrame({\"ID_code\":test[\"ID_code\"], \"target\":test[\"target\"]})\n# XGboost.to_csv(\"xgb_Fold.csv\"%(folds.n_splits, oof_roc), index=None)\nXGboost.to_csv(\"xgb_submission.csv\", index=None)\nXGboost.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XGboost.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Logistics regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(columns=['target','ID_code'])\ny = train['target']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import make_scorer, accuracy_score, roc_auc_score \nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Roc Curve')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\ny_pred_proba = logreg.predict_proba(X_test)[:, 1]\n[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\nprint('Train/Test split results:')\nprint(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\nprint(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\nprint(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n\nidx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95\n\nplt.figure()\nplt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')\nplt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\nplt.ylabel('True Positive Rate (recall)', fontsize=14)\nplt.title('Receiver operating characteristic (ROC) curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nprint(\"Using a threshold of %.3f \" % thr[idx] + \"guarantees a sensitivity of %.3f \" % tpr[idx] +  \n      \"and a specificity of %.3f\" % (1-fpr[idx]) + \n      \", i.e. a false positive rate of %.2f%%.\" % (np.array(fpr[idx])*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# testing data\ntest = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logist_pred = clf.predict_proba(test.drop(columns=['ID_code']))\nsample = pd.DataFrame({'ID_code':test['ID_code'], 'target': logist_pred[:, 1]})\nsample.to_csv('log_reg.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logist_pred[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.DataFrame({'ID_code':test['ID_code'], 'target': logist_pred[:, 1]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('logreg_.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decission Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier()\n\nclf = clf.fit(X_train,y_train)\n\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Acc = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: \" + str(Acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm / cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\ncm = pd.DataFrame(cm, index=np.unique(y_test), columns=np.unique(y_test))\ncm.index.name = 'Actual'\ncm.columns.name = 'Predicted'\n\nfig, ax = plt.subplots(figsize=[5,2])\n\nsns.heatmap(cm, cmap= \"YlGnBu\", annot= annot, fmt='', ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logist_pred = clf.predict_proba(test.drop(columns=['ID_code']))\nss = pd.DataFrame({'ID_code':test['ID_code'], 'target': logist_pred[:, 1]})\nss.to_csv('dec_tree.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb = GaussianNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GaussianNB(priors=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = gnb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logist_pred = gnb.predict_proba(test.drop(columns=['ID_code']))\nss = pd.DataFrame({'ID_code':test['ID_code'], 'target': logist_pred[:, 1]})\nss.to_csv('bayes.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}