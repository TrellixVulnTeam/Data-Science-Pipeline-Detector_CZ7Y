{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nimport random as rn\n\nfrom sklearn.model_selection import StratifiedKFold,KFold\nfrom math import sqrt\nfrom catboost import Pool, CatBoostClassifier,CatBoostRegressor\nfrom sklearn.metrics import roc_auc_score\nimport tqdm\nfrom tqdm import tqdm_notebook,tqdm\nfrom sklearn.utils import shuffle\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nnp.random.seed(42)\npath=\"../input/\"\nos.listdir(\"../input/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=pd.read_csv(path+\"train.csv\")\ntest_data=pd.read_csv(path+\"test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [x for x in train_data.columns if x not in ['ID_code', \"target\"]]\nlabel = \"target\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" df_test = test_data.values\n\nunique_samples = []\nunique_count = np.zeros_like(df_test)\nfor feature in tqdm_notebook(range(df_test.shape[1])):\n    if feature in [0]:\n        print('ok')\n        continue\n    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n    unique_count[index_[count_ == 1], feature] += 1\n\n# Samples which have unique values are real the others are fake\nreal_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\nsynthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_ = list(real_samples_indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.concat([train_data,test_data.loc[idx_]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor col in tqdm_notebook(features):\n   \n    count=data[col].value_counts()\n    rank=len(data[col].unique())\n    train_data[\"rank_\"+col]=train_data[col].map(count)\n    test_data[\"rank_\"+col]=test_data[col].map(count)\n     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n%matplotlib inline\nsns.distplot(train_data['rank_var_188'],color=\"red\")\nsns.distplot(test_data['rank_var_188'],color=\"blue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in tqdm_notebook(features):\n   \n    unique_value = train_data['rank_'+col].unique().tolist()+test_data['rank_'+col].unique().tolist()\n    uq_v = np.min(sorted(list(set(unique_value))))\n    train_data['cut_'+col] = train_data[col]\n    test_data['cut_'+col] = test_data[col]\n    median1=data[col].mean()\n#     median2=data[col].mean()\n\n    train_data['cut_'+col][(train_data['rank_'+col]==uq_v)]=median1\n    test_data['cut_'+col][(test_data['rank_'+col]==uq_v)]=median1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train_data#.join(train_clu)\ntest=test_data#.join(test_clu)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndel train_data,test_data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [x for x in train.columns if x not in ['ID_code', \"target\"]+['o-c_var_'+str(i) for i in range(200)]]\nlabel = \"target\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\"cut_var_\"+str(i) for i in range(200)]+[\"rank_var_\"+str(i) for i in range(200)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"feature count:\",len(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\ndef run_cv_model(train, test, target, model_fn, params={}, eval_fn=None, label='model'):\n    folds=5\n    \n    kf = StratifiedKFold(n_splits=folds, random_state=99999, shuffle=True)\n    fold_splits = kf.split(train, target)\n    \n    cv_scores = []\n    pred_full_test = 0\n    \n    pred_train = np.zeros((train.shape[0], folds))\n    feature_importance_df = pd.DataFrame()\n    i = 1\n    for dev_index, val_index in fold_splits:\n        print( label + ' | FOLD ' + str(i) + '/'+str(folds))\n        if isinstance(train, pd.DataFrame):\n            dev_X, val_X = train.iloc[dev_index], train.iloc[val_index]\n            dev_y, val_y = target[dev_index], target[val_index]\n        else:\n            dev_X, val_X = train[dev_index], train[val_index]\n            dev_y, val_y = target[dev_index], target[val_index]\n        params2 = params.copy()\n        pred_val_y, pred_test_y, importances = model_fn(dev_X, dev_y, val_X, val_y, test, params2)\n        gc.collect()\n        pred_full_test = pred_full_test + pred_test_y\n        pred_train[val_index] = pred_val_y\n       \n        if eval_fn is not None:\n            cv_score = eval_fn(val_y, pred_val_y)\n            cv_scores.append(cv_score)\n          \n           \n            print(label + ' cv score {}: AUC {} '.format(i, cv_score))\n            print(\"##\"*40)\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df['feature'] =train.columns.values\n        fold_importance_df['importance'] =importances\n        fold_importance_df['fold'] = i\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)        \n        i += 1\n#     print('{} cv RMSE scores : {}'.format(label, cv_scores))\n    print('{} cv mean AUC score : {}'.format(label, np.mean(cv_scores)))\n    print('{} cv std AUC score : {}'.format(label, np.std(cv_scores)))\n   \n\n    \n    pred_full_test = pred_full_test / float(folds)\n    results = {'label': label,\n               'train': pred_train, 'test': pred_full_test,\n                'cv': cv_scores, \n               'importance': feature_importance_df,\n               }\n    return results\n\nparams = {\n        'bagging_freq': 5,\n        'bagging_fraction': 0.4,\n        'boost_from_average': 'false',\n        'boost': 'gbdt',\n        'feature_fraction': 0.04,\n        'learning_rate': 0.0083,\n#         'max_depth': 3,\n        'metric': 'auc',\n        'min_data_in_leaf': 80,\n        'min_sum_hessian_in_leaf': 10.0,\n        'num_leaves': 13,\n        'num_threads': -1,\n        'tree_learner': 'serial',\n        'objective': 'binary',\n        # 'device_type':'gpu',\n        # 'is_unbalance':True,\n        'verbosity': -1,\n     'verbose_eval': 4000,\n         \n          'num_rounds': 1000000,\n     'early_stop': 4000,\n    }\n\ndef runLGB(train_X, train_y, test_X, test_y, test_X2, params):\n#     print('Prep LGB')\n    d_train = lgb.Dataset(train_X, label=train_y)\n    d_valid = lgb.Dataset(test_X, label=test_y)\n    watchlist = [d_train, d_valid]\n#     print('Train LGB')\n    num_rounds = params.pop('num_rounds')\n    verbose_eval = params.pop('verbose_eval')\n    early_stop = None\n    if params.get('early_stop'):\n        early_stop = params.pop('early_stop')\n    model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop)\n    print('Predict 1/2')\n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n   \n    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n    gc.collect()\n    return pred_test_y.reshape(-1, 1), pred_test_y2.reshape(-1, 1), model.feature_importance()\ndef runCAT(train_X, train_y, test_X, test_y, test_X2, params):\n#     print('Prep LGB')\n    d_train = Pool(train_X, label=train_y)\n    d_valid = Pool(test_X, label=test_y)\n    watchlist = (d_train, d_valid)\n#     print('Train LGB')\n    num_rounds = params.pop('num_rounds')\n    verbose_eval = params.pop('verbose_eval')\n    early_stop = None\n    if params.get('early_stop'):\n        early_stop = params.pop('early_stop')\n    model = CatBoostClassifier(iterations=num_rounds, \n        learning_rate = 0.003,\n        od_type='Iter',\n         od_wait=early_stop,\n        loss_function=\"Logloss\",\n        eval_metric='AUC',\n#         depth=3,\n        bagging_temperature=0.7,                   \n        random_seed = 2019,\n#         task_type='GPU'\n                          )\n    model.fit(d_train,eval_set=d_valid,\n            use_best_model=True,\n            verbose=verbose_eval\n                         )\n    \n    print('Predict 1/2')\n    pred_test_y = model.predict_proba(test_X)[:,1]\n    \n    pred_test_y2 = model.predict_proba(test_X2)[:,1]\n    gc.collect()\n    return pred_test_y.reshape(-1, 1), pred_test_y2.reshape(-1, 1), 0\n \nresults = run_cv_model(train[features], test[features], train[label], runLGB, params, roc_auc_score, 'LGB')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imports = results['importance'].groupby('feature')['feature', 'importance'].mean().reset_index()\nimp=imports.sort_values('importance', ascending=False)\nimp.index=range(len(imp))\nimp.iloc[:610]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predictions = [r[0] for r in results['train']]\nroc_auc_score(train[label],train_predictions)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_predictions = [r[0] for r in results['train']]\ntest_predictions = [r[0] for r in results['test']]\nsub=test[['ID_code']]\nsub['target']=test_predictions\nif not os.path.exists(\"submit\"):\n    os.mkdir(\"submit\")\nsub.to_csv(\"submit/lgb_submmision.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_oof=train[['ID_code']]\ntrain_oof['target']=train_predictions \noof=pd.concat([train_oof,sub])\nif not os.path.exists(\"oof\"):\n    os.mkdir(\"oof\")\noof.to_csv(\"./oof/lgb_oof.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### augment"},{"metadata":{"trusted":false},"cell_type":"code","source":"# https://stackoverflow.com/questions/50554272/randomly-shuffle-items-in-each-row-of-numpy-array\ndef disarrange(a, axis=-1):\n    \"\"\"\n    Shuffle `a` in-place along the given axis.\n\n    Apply numpy.random.shuffle to the given axis of `a`.\n    Each one-dimensional slice is shuffled independently.\n    \"\"\"\n    b = a.swapaxes(axis, -1)\n    # Shuffle `b` in-place along the last axis.  `b` is a view of `a`,\n    # so `a` is shuffled in place, too.\n    shp = b.shape[:-1]\n    for ndx in np.ndindex(shp):\n        np.random.shuffle(b[ndx])\n    return\n\ndef augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        disarrange(x1,axis=0)\n        xs.append(x1)\n\n    for i in range(t//2):\n        mask = y==0\n        x1 = x[mask].copy()\n        disarrange(x1,axis=0)\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=99999)\n# oof = train[['ID_code']]\n# oof['target'] = 0\n# predictions = test[['ID_code']]\n# val_aucs = []\n# feature_importance_df = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# import lightgbm as lgb\n# # lgb_params  = {\n# #         'bagging_freq': 5,\n# #         'bagging_fraction': 0.4,\n# #         'boost_from_average': 'false',\n# #         'boost': 'gbdt',\n# #         'feature_fraction': 0.05,\n# #         'learning_rate': 0.01,\n# #         'max_depth': -1,\n# #         'metric': 'auc',\n# #         'min_data_in_leaf': 80,\n# #         'min_sum_hessian_in_leaf': 10.0,\n# #         'num_leaves': 13,\n# #         'num_threads': -1,\n# #         'tree_learner': 'serial',\n# #         'objective': 'binary',\n# #         # 'device_type':'gpu',\n# #         # 'is_unbalance':True,\n# #         'verbosity': -1,\n\n# #           \"random_state\":1017,\n# #     }\n# lgb_params  = {\n#         'bagging_freq': 5,\n#         'bagging_fraction': 0.335,\n#         'boost_from_average': 'false',\n#         'boost': 'gbdt',\n#         'feature_fraction': 0.043,\n#         'learning_rate': 0.0083,\n#         'max_depth': -1,\n#         'metric': 'auc',\n#         'min_data_in_leaf': 80,\n#         'min_sum_hessian_in_leaf': 10.0,\n#         'num_leaves': 13,\n#         'num_threads': -1,\n#         'tree_learner': 'serial',\n#         'objective': 'binary',\n#         # 'device_type':'gpu',\n#         # 'is_unbalance':True,\n#         'verbosity': -1,\n\n        \n#     }","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# for fold, (trn_idx, val_idx) in enumerate(skf.split(train, train['target'])):\n#     X_train, y_train = train.iloc[trn_idx][features], train.iloc[trn_idx]['target']\n#     X_valid, y_valid = train.iloc[val_idx][features], train.iloc[val_idx]['target']\n    \n#     N = 5\n#     p_valid,yp = 0,0\n#     for i in range(N):\n#         print(\"##\"*40)\n#         print(\"FOLD {} N {} \".format(fold+1,i+1))\n#         X_t, y_t = augment(X_train.values, y_train.values)\n#         X_t = pd.DataFrame(X_t)\n#         X_t.columns = features\n    \n#         trn_data = lgb.Dataset(X_t, label=y_t)\n#         val_data = lgb.Dataset(X_valid, label=y_valid)\n#         evals_result = {}\n#         lgb_clf = lgb.train(lgb_params,\n#                         trn_data,\n#                         10000000,\n#                         valid_sets = [trn_data, val_data],\n#                         early_stopping_rounds=4000,\n#                         verbose_eval = 4000,\n#                         evals_result=evals_result\n#                        )\n#         p_valid += lgb_clf.predict(X_valid,num_iteration=lgb_clf.best_iteration)\n#         yp += lgb_clf.predict(test[features],num_iteration=lgb_clf.best_iteration)\n#         gc.collect()\n        \n#     gc.collect()\n#     oof['target'][val_idx] = p_valid/N\n#     val_score = roc_auc_score(y_valid, p_valid)\n#     print(\"fold {}|\".format(fold+1),\"auc score : \",val_score)\n#     val_aucs.append(val_score)\n    \n#     predictions['fold{}'.format(fold+1)] = yp/N","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# mean_auc = np.mean(val_aucs)\n# std_auc = np.std(val_aucs)\n# all_auc = roc_auc_score(train['target'], oof['target'])\n# print(\"Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# if not os.path.exists(\"augment\"):\n#     os.mkdir(\"augment\")\n# predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n# predictions.to_csv('./augment/lgb_all_predictions.csv', index=None)\n# sub_df = pd.DataFrame({\"ID_code\":test[\"ID_code\"].values})\n# sub_df[\"target\"] = predictions['target']\n# sub_df.to_csv(\"./augment/lgb_submission.csv\", index=False)\n# oof_all=pd.concat([oof,sub_df])\n# oof_all.to_csv('./augment/augment_lgb_oof.csv', index=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# with open(\"log.txt\",\"w\")as f:\n#     f.write(\"auc oof:{} mean:{}\".format(roc_auc_score(train['target'], oof['target']),np.mean(val_aucs)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}