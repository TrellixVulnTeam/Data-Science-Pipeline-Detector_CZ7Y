{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Reference\n* https://www.kaggle.com/gpreda/santander-eda-and-prediction\n* https://www.kaggle.com/roydatascience/eda-pca-simple-lgbm-on-kfold-technique"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\nimport lightgbm as lgb\nfrom lightgbm import plot_importance\nimport xgboost as xgb\n\n\n\nplt.style.use('seaborn')\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/train.csv')\ntest_df = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/test.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = train_df.drop(['ID_code','target'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\n* Target Percent"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize=(10,4))\ntrain_df['target'].value_counts().plot.pie(\n    explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True\n)\nsns.countplot('target', data=train_df, ax=ax[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_value = train_df.isnull().sum().sort_values(ascending = False)\nnull_percent = round(train_df.isnull().sum().sort_values(ascending = False)/len(train_df)*100, 2)\npd.concat([null_value,null_percent], axis=1,keys=['Null values','Percent'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per row in the train and test set\")\nsns.distplot(train_df[features.columns].mean(axis=1),color=\"black\", kde=True,bins=120, label='train')\nsns.distplot(test_df[features.columns].mean(axis=1),color=\"red\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per column in the train and test set\")\nsns.distplot(train_df[features.columns].mean(),color=\"black\", kde=True,bins=120, label='train')\nsns.distplot(test_df[features.columns].mean(),color=\"red\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per rows in the train and test set\")\nsns.distplot(train_df[features.columns].std(axis=1),color=\"blue\",kde=True,bins=120, label='train')\nsns.distplot(test_df[features.columns].std(axis=1),color=\"green\", kde=True,bins=120, label='test')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = train_df[train_df['target'] == 0]\nt1 = train_df[train_df['target'] == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew values per row in the train set\")\nsns.distplot(t0[features.columns].skew(axis=1),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features.columns].skew(axis=1),color=\"blue\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = train_df[train_df['target'] == 0]\nt1 = train_df[train_df['target'] == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew values per column in the train set\")\nsns.distplot(t0[features.columns].skew(),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features.columns].skew(),color=\"blue\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n* Drop Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop('ID_code', axis=1, inplace=True)\ntest_df.drop('ID_code', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Egineering\n* PCA\n* Split Data to Train / Test / Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_df.drop(['target'], axis=1,)\ny = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nx_scaler = scaler.fit_transform(x)\nx_scaler_df = pd.DataFrame(x_scaler, columns=x.columns)\n\npca = PCA(n_components=2)\nx_scaler_pca = pca.fit_transform(x_scaler)\nx_scaler_pca_df = pd.DataFrame(x_scaler_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_scaler = StandardScaler()\ntrans_test_scaler = test_scaler.fit_transform(test_df)\ntrans_test_scaler_df = pd.DataFrame(trans_test_scaler, columns=test_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_scaler_pca_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(pca.explained_variance_ratio_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_scaler_pca_df['target'] = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x_scaler_pca_df.loc[:, 0], x_scaler_pca_df.loc[:, 1], c=y,  cmap=\"copper_r\")\nplt.axis('off')\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"=> We cant use PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Dataset shape {} / {}\".format(x_train.shape, y_train.shape))\nprint(\"Test Dataset shape {} / {}\".format(x_test.shape, y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling\n* LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = lgb.Dataset(x_train, label=y_train)\nval_data = lgb.Dataset(x_test, label=y_test)\nparams = {\n    'n_estimators': 5000,\n    'num_leaves': 20,\n    'max_depth': -1,\n    'min_data_in_leaf': 80,\n    'learning_rate': 0.01,\n    'boosting': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'Is_training_metric': True,\n    'n_jobs': -1\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.train(params,\n                  train_data,\n                  valid_sets=val_data, \n                  valid_names=['train','valid'],\n                  early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplot_importance(model, max_num_features=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* StandardScaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_scaler_df, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = lgb.Dataset(x_train, label=y_train)\nval_data = lgb.Dataset(x_test, label=y_test)\nparams = {\n    'n_estimators': 5000,\n    'num_leaves': 20,\n    'max_depth': -1,\n    'min_data_in_leaf': 80,\n    'learning_rate': 0.01,\n    'boosting': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'Is_training_metric': True,\n    'n_jobs': -1\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_model = lgb.train(params,\n                  train_data,\n                  valid_sets=val_data, \n                  valid_names=['train','valid'],\n                  early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/sample_submission.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = model.predict(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['target'] = target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_submission = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/sample_submission.csv')\nscaler_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_target = scaler_model.predict(trans_test_scaler_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_submission['target'] = scaler_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_submission.to_csv('scaler_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}