{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"img/dh_logo.png\" align=\"right\" width=\"50%\">\n\n# Desafio 3\n\n# Santander Kaggle\n## Customer Transaction Prediction\n\n<img src=\"img/santander.png\"  >\n\n### Neste desafio será necessário prever a variável target do DataSet\n\nPara acessar e participar desta competição no Kaggle [clique aqui](https://www.kaggle.com/c/santander-customer-transaction-prediction/overview)\n\nPara baixar os dados [clique aqui](https://www.kaggle.com/c/santander-customer-transaction-prediction/data)\n\n## Santander: Overview da proposta do desafio\n\nNo Santander, nossa missão é ajudar pessoas e empresas a prosperar. Estamos sempre procurando maneiras de ajudar nossos clientes a entender sua saúde financeira e identificar quais produtos e serviços podem ajudá-los a atingir suas metas monetárias.\n\nNossa equipe de ciência de dados está desafiando continuamente nossos algoritmos de aprendizado de máquina, trabalhando com a comunidade global de dados científicos para garantir que possamos identificar com mais precisão novas maneiras de resolver nosso desafio mais comum, problemas de classificação binária como: um cliente está satisfeito? Um cliente comprará este produto? Um cliente pode pagar este empréstimo?\n\nNeste desafio, convidamos a Kagglers a nos ajudar a identificar **quais clientes farão uma transação específica no futuro, independentemente do volume de dinheiro transacionado**. Os dados fornecidos para esta competição têm a mesma estrutura que os dados reais que temos disponíveis para resolver este problema.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Algumas possibilidades a serem consideradas para desenvolvimento neste Desafio 3:\n\n1. Explorar as variáveis explicatórias do problema e entender como elas influenciam na variável target\n\n\n2. Identificar possíveis soluções para resolver o desbalancemanto de classes da variável target\n\n\n3. Entender a explicabilidade dos dados utilizando diferentes técnicas não supervisionadas de Clustering e medir como os modelos respondem \n\n\n4. Buscar algumas formas de selecionar as melhores variáveis para classificar as fraudes e medir os resultados em um modelo preditor\n\n\n5. Verificar se a redução de dimensionalidade pode ajudar na explicação das fraudes, com suficiente nível de informação, e medir os resultados em um modelo preditor\n\n\n6. Submeter o melhor resultado na plataforma Keggle. Para isso, verifique qual a métrica adotada pelo examinador do desafio\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"You are provided with an anonymized dataset containing numeric feature variables, the binary target column, and a string ID_code column.\n\nThe task is to predict the value of target column in the test set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Santander DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import packages\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# open train df\ndf = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# check if there are missing values\n# verificando se existem dados nulos\nimport missingno as msno\nmsno.matrix(df)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# print df head\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# print df shape\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"200000 rows and 202 columns.","execution_count":null},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# print df info\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#describe the df variables\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(y = df.target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## correlation between target variable and the other columns\ndf_corr = df.corr().round(2)['target']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_corr.sort_values(ascending =True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variables aren't very correlated with the target value. As there are many variables I'll conduct a PCA to reduce the dataset dimensionality.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## PCA","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# I'll drop the ID_code and target variables of the dataset to do the PCA with the other variables.\n#df_pca = df.drop(['ID_code'], axis = 1)\nX_train = df.drop(['ID_code', 'target'], axis = 1)\nX_test = df.drop(['ID_code', 'target'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# importando as bibliotecas\nfrom sklearn.preprocessing import StandardScaler \n\n# instanciando a variável\nsc = StandardScaler() \n\n\n# ajustando com os dados de treino\nX_train = sc.fit_transform(X_train) \nX_test = sc.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# importando as bibliotecas\nfrom sklearn.decomposition import PCA\n\n# instanciando o modelo\npca = PCA(n_components = 2)\n\n# ajustando com os modelos de treino\nX_train_pca = pca.fit_transform(X_train)\n\n# transformando os dados de teste\nX_test_pca = pca.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"X_train_pca","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plotando um gráfico de dispersão entre as duas variáveis criadas pelo PC\n# para identificaçào de como o PCA distribuiu as categorias\ndf2 = df.copy(deep=True)\n# criação de duas novas colunas com as 2 dimensões do PCA\ndf2['PCA1'] = X_train_pca[:, 0]\ndf2['PCA2'] = X_train_pca[:, 1]\n# criação de duas novas colunas com as 2 dimensões do PCA\ndf2['PCA1_test'] = X_test_pca[:, 0]\ndf2['PCA2_test'] = X_test_pca[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(1,2)\n# plotando uma dispersão das novas colunas diferenciando as espécies\nsns.lmplot('PCA1', 'PCA2', hue='target', data=df2, fit_reg=False);\n# plotando uma dispersão das novas colunas diferenciando as espécies\nsns.lmplot('PCA1_test', 'PCA2_test', hue='target', data=df2, fit_reg=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Regressão Logística","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# importando as bibliotecas\nfrom sklearn.linear_model import LogisticRegression\n\n# instanciando o modelo \nclassifier = LogisticRegression(random_state = 42)\n# ajustando o modelo\nclassifier.fit(X_train_pca, df.target) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# predição de valores com dados de teste com a Regressão Logística\ny_pred_pca = classifier.predict(X_train_pca) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# plotando a Matriz de Confusão entre os valores reais e preditos\n\n# importando a biblioteca\nfrom sklearn.metrics import confusion_matrix \n# plotando a matriz\ncm = confusion_matrix(df.target, y_pred_pca) \ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.heatmap(cm,annot=True,cbar=False, xticklabels='auto' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://medium.com/@alepukhova526/principal-component-analysis-for-logistic-regression-with-scikit-learn-869b04b2f923","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"\n# importar a funcao\nfrom sklearn import metrics\n\n# plotando a curva ROC\ny_pred_proba_pca = classifier.predict_proba(X_train_pca)[::,1]\nfpr, tpr, _ = metrics.roc_curve(df.target,  y_pred_proba_pca)\nauc = metrics.roc_auc_score(df.target, y_pred_proba_pca)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\nplt.legend(loc=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The PCA didn't perform very well on data compression.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Classification","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# importando as bibliotecas\nfrom sklearn.preprocessing import StandardScaler \n\n# instanciando a variável\nsc = StandardScaler() \n\n\n# ajustando com os dados de treino\nX= df.drop(['ID_code', 'target'], axis = 1)\nX = sc.fit_transform(X) \ny= df.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# import the function\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"print(len(y_train))\nprint(len(X_train))\nprint(len(y_test))\nprint(len(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# importar a funcao\nfrom sklearn.linear_model import LogisticRegression\n\n# isntanciar o modelo\nclf = LogisticRegression(dual = False, max_iter = 5000)\n\n# ajustar aos dados de treino\nclf.fit(X_train, y_train)\n\n# predições para os dados de teste\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# importar a funcao\nfrom sklearn import metrics\n\nconfusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# chamando a função da matriz de confusão\nmetrics.confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\", metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy: 0.9132\n\nPrecision: 0.6783854166666666\n\nRecall: 0.25920398009950246","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# plotando a curva ROC\ny_pred_proba = clf.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\nplt.legend(loc=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"auc = 0.859","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# fazendo um undersampling da classe com output zero (em maior número)\ndf_sample=df.sample(n=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# importando as bibliotecas\nfrom sklearn.preprocessing import StandardScaler \n\n# instanciando a variável\nsc = StandardScaler() \n\n\n# ajustando com os dados de treino\nX_sp= df_sample.drop(['ID_code', 'target'], axis = 1)\nX_sp = sc.fit_transform(X_sp) \ny_sp= df_sample.target\n\nfrom sklearn.model_selection import train_test_split\n\nXsp_train, Xsp_test, ysp_train, ysp_test = train_test_split(X_sp, y_sp, test_size = 0.2, random_state = 42, stratify = y_sp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(len(Xsp_train))\nprint(len(Xsp_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# importando as bibliotecas dos modelos classificadores\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n# definindo uma lista com todos os modelos\nclassifiers = [\n    KNeighborsClassifier(),\n    GaussianNB(),\n    LogisticRegression(dual=False,max_iter=5000),\n    SVC(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    GradientBoostingClassifier()]\n\n# rotina para instanciar, predizer e medir os resultados de todos os modelos\nfor clf in classifiers:\n    # instanciando o modelo\n    clf.fit(Xsp_train, ysp_train)\n    # armazenando o nome do modelo na variável name\n    name = clf.__class__.__name__\n    # imprimindo o nome do modelo\n    print(\"=\"*30)\n    print(name)\n    # imprimindo os resultados do modelo\n    print('****Results****')\n    ysp_pred = clf.predict(Xsp_test)\n    print(\"Accuracy:\", metrics.accuracy_score(ysp_test, ysp_pred))\n    print(\"Precision:\", metrics.precision_score(ysp_test, ysp_pred))\n    print(\"Recall:\", metrics.recall_score(ysp_test, ysp_pred))\n    \n     # plotando a curva ROC\n    y_pred_proba = clf.predict_proba(X_test)[::,1]\n    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr,tpr,label=name+\", auc=\"+str(auc))\n    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n    plt.legend(loc=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Balancing","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# definindo variáveis para cada uma das classes\ndf_0 = df[df.target == 0]\ndf_1 = df[df.target==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(len(df_0))\nprint(len(df_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# undersampling\ndf_0=df_0.sample(len(df_1))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_concat = pd.concat([df_0,df_1])\ndf_concat.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# ajustando com os dados de treino\nX= df_concat.drop(['ID_code', 'target'], axis = 1)\nX = sc.fit_transform(X) \ny = df_concat.target\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# ignorando os warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# importnado as bibliotecas com os modelos classificadores\n\n# definindo uma lista com todos os classificadores\nclassifiers = [\n    KNeighborsClassifier(),\n    GaussianNB(),\n    LogisticRegression(),\n    #SVC(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    GradientBoostingClassifier()]\n\n# definindo o tamanho da figura para o gráfico\nplt.figure(figsize=(12,8))\n\n# rotina para instanciar, predizer e medir os rasultados de todos os modelos\nfor clf in classifiers:\n    # instanciando o modelo\n    clf.fit(X_train, y_train)\n    # armazenando o nome do modelo na variável name\n    name = clf.__class__.__name__\n    # imprimindo o nome do modelo\n    print(\"=\"*30)\n    print(name)\n    # imprimindo os resultados do modelo\n    print('****Results****')\n    y_pred = clf.predict(X_test)\n    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n    print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n    print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n    \n    \n    # plotando a curva ROC\n    y_pred_proba = clf.predict_proba(X_test)[::,1]\n    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr,tpr,label=name+\", auc=\"+str(auc))\n    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n    plt.legend(loc=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gaussian NB","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# importar a funcao\nfrom sklearn.naive_bayes import GaussianNB\n\n# isntanciar o modelo\nclassifier = GaussianNB()\n\n# ajustar aos dados de treino\nclassifier.fit(X_train, y_train)\n\n# predições para os dados de teste\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"metrics.confusion_matrix\n\nprint(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\", metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# plotando a curva ROC\ny_pred_proba = classifier.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\nplt.legend(loc=4)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Verificando assimetria:\nfrom scipy import stats\n\n# choose numeric features\nnumeric_feats = df_concat.dtypes[df_concat.dtypes !=\"object\"].index\n\nskewed_feats = df_concat[numeric_feats].apply(lambda x: stats.skew(x.dropna())).sort_values(ascending = False)\n\nprint(\"\\nAssimetria: \\n\")\nskew_df = pd.DataFrame({'Skew' :skewed_feats})\nskew_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"norm = np.linalg.norm(df.var_179)\nnormal_array = df.var_179/norm\nnormal_array.skew()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}