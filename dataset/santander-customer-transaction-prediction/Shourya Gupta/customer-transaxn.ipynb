{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '../input/santander-customer-transaction-prediction/train.csv'\ndf = pd.read_csv(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data has {} rows, {} columns\".format(df.shape[0], df.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data has {} null values\".format(df.isnull().any().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NO NULLS"},{"metadata":{},"cell_type":"markdown","source":"Distribution of values in the Target column"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(nrows = 1, ncols = 2)\nsns.countplot(x = 'target', data = df, ax = ax[0])\nax[1].pie(x = df.target.value_counts().values, labels = df.target.value_counts().index, autopct = \"%.2f%%\")\nax[1].set_title(\"Percentage distribution\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **The data is heavily biased**"},{"metadata":{},"cell_type":"markdown","source":"### corr_help : A function to find co-relation of features with a given columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"def corr_help(df, col):\n    x = []\n    for i in range(200):\n        corr = df[col].corr(df['var_'+str(i)])\n        x.append(corr)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = corr_help(df, 'target')\nsns.distplot(x)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['target']\ndf = df.drop(['ID_code', 'target'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preping for removing the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR1 = Q3-Q1\ndf_c = df[~((df < (Q1-1.5*IQR1))|(df > (Q3+1.5*IQR1))).any(axis = 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Data loss is {}%'.format(((len(y) - len(df_c))/len(y))*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing the values in target columns which were related to outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"c = list(df_c.index)\nf = []\nfor i in range(len(c)-1):\n    for j in range(c[i]+1, c[i+1]):\n        f.append(j)\nfor i in f:\n    y.pop(i)\ny = list(y)\ndf_c['y'] = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df_c","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualising the distribution of values in diff var (selected randomly)"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(nrows = 2, ncols = 2)\nfor i in range(4):\n    g = np.random.randint(0, 200)\n    sns.distplot(a = data['var_'+str(g)].values - data['var_'+str(g)].values.mean(),ax = axes[i//2][i%2], axlabel = ('var_'+str(g)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Machine Learning**"},{"metadata":{},"cell_type":"markdown","source":"To trade off the imbalance I'll undersample the majority class and oversample (SMOTE) the minority class"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.array(data['y'].values, dtype = int)\nX = np.array(data.drop('y', axis = 1).values, dtype = float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling the values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX1 = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using SMOTE to oversample target = 1 data points and then RandomUnderSampling the obtained data such that the ratio of target = 1/ target = 0 data points is 1/2"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nsmote = SMOTE(sampling_strategy = 3/7, k_neighbors = 5, random_state = 9)\nunder = RandomUnderSampler(sampling_strategy = 0.5)\nX1, y = smote.fit_resample(X1, y)\nX1, y = under.fit_resample(X1, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('1\\t', len(y[y==1])/len(y), '% \\n0\\t', len(y[y==0])/len(y), '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the data into train and validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X1, y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First applying Logistic Regression(LR). LR will form the base algorithm and every other algorithm's performace will be compared to it."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nparams = {'C' : [0.0001, 0.0003, 0.0005, 0.001, 0.003, 0.005, 0.01, 0.03, 0.05, 0.1, 0.3, 0.5]}\nclf = GridSearchCV(LogisticRegression(), params)\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(clf.score(X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_prob = clf.predict_proba(X_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In a Classification problem accuracy is not a good measure of performance. Thus using AUC-ROC to compare the performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\ndef auc_roc_plot(x, y, l, colors):\n    #roc curve for clf\n    fpr, tpr, thresh = roc_curve(y_val, pred_prob[:, 1], pos_label = 1)\n\n    # for fpr = tpr\n    random_probs = [0 for i in range(len(y_val))]\n    p_fpr, p_tpr, _ = roc_curve(y_val, random_probs, pos_label=1)\n\n    #auc\n    auc_score = roc_auc_score(y_val, pred_prob[:, 1])\n\n    #plot\n    plt.plot(fpr, tpr, linestyle = '--', color = 'orange', label = \"LogisticRegression\")\n    for i in range(len(x)):\n        plt.plot(x[i], y[i], linestyle = '--', color = colors[i], label = l[i])\n    plt.plot(p_fpr, p_tpr, linestyle = '--', color = 'blue')\n    plt.title(\"ROC curve\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.legend(loc = 'best')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fprs = []\ntprs = []\nlabels = []\ncolors = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf = RandomForestClassifier()\nclf_rf.fit(X_train, y_train)\nclf_rf_pp = clf_rf.predict_proba(X_val)\nclf_rf_fpr, clf_rf_tpr, _ = roc_curve(y_val, clf_rf_pp[:, 1], pos_label = 1)\nfprs.append(clf_rf_fpr)\ntprs.append(clf_rf_tpr)\nlabels.append('Random Forest')\ncolors.append('r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying DecisionTreeClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_dt = DecisionTreeClassifier()\nclf_dt.fit(X_train, y_train)\nclf_dt_pp = clf_dt.predict_proba(X_val)\nclf_dt_fpr, clf_dt_tpr, _ = roc_curve(y_val, clf_dt_pp[:, 1], pos_label = 1)\nfprs.append(clf_dt_fpr)\ntprs.append(clf_dt_tpr)\nlabels.append('Decision Tree')\ncolors.append('c')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying XGBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_xgb = XGBClassifier()\nclf_xgb.fit(X_train, y_train)\nclf_xgb_pp = clf_xgb.predict_proba(X_val)\nclf_xgb_fpr, clf_xgb_tpr, _ = roc_curve(y_val, clf_xgb_pp[:, 1], pos_label = 1)\nfprs.append(clf_xgb_fpr)\ntprs.append(clf_xgb_tpr)\nlabels.append('XGB')\ncolors.append('m')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualising the AUC-ROC plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc_plot(fprs, tprs, labels, colors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is evident that the RandomForestClassifier does a good job followed by XGBClassifier then LogisticRegression (which was the baseline for comparison)"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf.score(X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_test = '../input/santander-customer-transaction-prediction/test.csv'\ntest = pd.read_csv(path_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().any().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Amazing to have no nulls"},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = test['ID_code'].values\nX_test = test.drop('ID_code', axis = 1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = clf_rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = np.array(y_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y_preds[y_preds == 0])/len(y_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'ID_code':ids,\n                          'target':y_preds})\nsubmission.to_csv('cust.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using ML (RandomForestClassifier) the score obtained on submission is about 0.5."},{"metadata":{},"cell_type":"markdown","source":"Applying Deep Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nmodel = Sequential([Dense(256, activation = 'relu', input_dim = X_train.shape[1]),\n           Dense(256, activation = 'relu'),\n           Dense(512, activation = 'relu'),\n           Dense(512, activation = 'relu'),\n           Dense(1024, activation = 'relu'),\n           Dense(1024, activation = 'relu'),\n           Dense(1024, activation = 'relu'),\n           Dense(1024, activation = 'relu'),\n           Dense(512, activation = 'relu'),\n           Dense(512, activation = 'relu'),\n           Dense(256, activation = 'relu'),\n           Dense(256, activation = 'relu'),\n           Dense(1, activation = 'sigmoid')\n            ]\n          )\nmodel.compile(optimizer = 'adam', loss = 'BinaryCrossentropy', metrics = 'AUC')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, epochs = 20, validation_data = (X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_dl = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_dl = [1 if i > 0.5 else 0 for i in preds_dl]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_dl = np.array(preds_dl)\nlen(preds_dl[preds_dl == 1])/len(preds_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'ID_code':ids,\n                          'target':preds_dl})\nsubmission.to_csv('cust1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score obtained via DL is 0.65 (significant improvement)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}