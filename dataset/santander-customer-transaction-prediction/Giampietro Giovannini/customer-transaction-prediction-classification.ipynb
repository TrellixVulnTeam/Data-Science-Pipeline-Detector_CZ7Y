{"cells":[{"metadata":{},"cell_type":"markdown","source":"If you have any advice/suggestion, let me know in the comments and upvote!\nThank you!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/santander-customer-transaction-prediction/train.csv\")\ntest_df = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop([\"ID_code\"] , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ID = test_df[\"ID_code\"]\ntest_df = test_df.drop([\"ID_code\"], axis= 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_df[\"target\"])\ntrain_df[\"target\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_distribution(df1, df2, label1, label2, features):   \n    i = 0                                   \n    sns.set_style('whitegrid')              \n    plt.figure()\n    fig, ax = plt.subplots(10,10,figsize=(15,17))\n\n    for feature in features:\n        i += 1\n        plt.subplot(10,10,i)\n        sns.distplot(df1[feature], hist=False, label = label1)\n        sns.distplot(df2[feature], hist=False, label = label2)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n        plt.tick_params(axis='y', which='major', labelsize=6)\n    plt.show();\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = train_df.loc[train_df['target'] == 0]\nt1 = train_df.loc[train_df['target'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = train_df.columns.values[1:101]\nplot_feature_distribution(t0, t1, '0', '1', features)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = train_df.columns.values[101:201]\nplot_feature_distribution(t0, t1, '0', '1', features)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = train_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations.sort_values(by=[\"target\"]).tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations.sort_values(by=[\"target\"]).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop([\"target\"] ,axis = 1)\ny = train_df[\"target\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler \nrb = RobustScaler()\nX_scaled = rb.fit_transform(X)\n\nX_scaled = pd.DataFrame(X_scaled, columns = X.columns) \nX = X_scaled\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for v in X.columns:\n    variance = X.var()\nvariance = variance.sort_values(ascending = False)\n   \nplt.figure(figsize=(12,5))\nplt.plot(variance)  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"variance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trans = train_df.loc[train_df[\"target\"] == 1]\n\nno_trans = train_df.loc[train_df[\"target\"] == 0]\n\nno_trans = no_trans.sample(n = 20098 , random_state = 42)\n\ntrain_df = pd.concat([trans , no_trans])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_df[\"target\"])\ntrain_df[\"target\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score \nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_auc_score\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers =  [\n       ['Logistic Regression Classifier :', LogisticRegression()] ,\n       ['Support Vector Classifier :', SVC()] ,\n       ['Naive Bayes :' , GaussianNB()] ,\n       ['XGB Classifier :', XGBClassifier()]      \n       ]\n\n       \n\nfor name,model in classifiers:    \n\n    model = model\n    \n    model.fit(X_train,y_train)\n    \n    y_pred_train = model.predict(X_train)\n\n    y_pred = model.predict(X_test)\n     \n    print('-----------------------------------')\n    print(name)\n    \n    print(\" -- TRAINING SET --\")\n    print('Accuracy: ', accuracy_score( y_train , y_pred_train))\n    print(\"f1: \",f1_score( y_train , y_pred_train))\n    print(\"precision: \", precision_score( y_train , y_pred_train))\n    print(\"recall: \", recall_score( y_train , y_pred_train))\n    print(\"ROC AUC: \", roc_auc_score( y_train , y_pred_train))\n    print('---------------------------------')\n        \n     \n    print(\" --  TEST SET --  \")\n    print('Accuracy: ', accuracy_score( y_test, y_pred))\n    print(\"f1:      \",f1_score( y_test, y_pred))\n    print(\"precision: \", precision_score( y_test, y_pred))\n    print(\"recall: \", recall_score( y_test, y_pred))\n    print(\"ROC AUC: \", roc_auc_score( y_test, y_pred))\n    print('---------------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FEATURES IMPORTANCE\n\nfrom xgboost import XGBClassifier\nmodel = XGBClassifier()\nmodel.fit( X_train , y_train)\n\nimportances = model.feature_importances_\nindex = np.argsort(importances)[::-1][0:10]\nfeature_names = X.columns.values\n\nplt.figure(figsize=(10,5))\nsns.barplot(x = feature_names[index], y = importances[index]);\nplt.title(\"Top important features \");\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.Series(importances)\n\nimportances = importances.sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\nsfm = SelectFromModel(model, threshold=0.001)   \n\nX_train = X_train.loc[ :, sfm.fit(X_train , y_train).get_support()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test[X_train.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n\ncolsample_bylevel = [1 , 0.5]\ncolsample_bytree = [1 , 0.5]\ngamma = [0 , 1 , 5]\nlearning_rate = [0.1 , 0.05 , 0.01 ]\nmax_delta_step = [0]\nmax_depth = [1 , 5 , 10 ]\nmin_child_weight = [1]\nn_estimators = [ 300 , 500 , 600 , 700 ]\nobjective = ['binary:logistic']\nrandom_state = [42]     \nreg_alpha = [0, 1]\nreg_lambda = [0 , 1]\nscale_pos_weight = [1]\nsubsample = [0.5, 0.8 ,  1 ]\n\n\nparam_distributions = dict(\n                           colsample_bylevel = colsample_bylevel,\n                           colsample_bytree = colsample_bytree,\n                           gamma = gamma, \n                           learning_rate = learning_rate,\n                           max_depth = max_depth,\n                           min_child_weight = min_child_weight,\n                           n_estimators = n_estimators,\n                           objective = objective,\n                           random_state = random_state,\n                           reg_alpha = reg_alpha,\n                           reg_lambda = reg_lambda,\n                           scale_pos_weight = scale_pos_weight,\n                           subsample = subsample , \n                           ) \n\n\n\nestimator = XGBClassifier()     \n\n\nRandomCV = RandomizedSearchCV(\n                            estimator = estimator,         \n                            param_distributions = param_distributions,\n                            n_iter = 10,\n                            cv = 5,\n                            scoring = \"roc_auc\",   \n                            random_state = 42, \n                            verbose = 1, \n                            n_jobs = -1,\n                            )\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_model = RandomCV.fit(X_train, y_train)                   \n                                              \n\nprint('Best Score: ', hyper_model.best_score_)    \n\nprint('Best Params: ', hyper_model.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_model.best_estimator_.fit(X_train,y_train)\n\ny_pred_train_hyper = hyper_model.best_estimator_.predict(X_train)  \n\ny_pred_hyper = hyper_model.best_estimator_.predict(X_test)  \n\n\n\nprint(\"HYPER   TRAIN\")\nprint('Accuracy Score ', accuracy_score( y_train , y_pred_train_hyper))\nprint(\"f1: \",f1_score(y_train , y_pred_train_hyper))\nprint(\"precision: \", precision_score(y_train , y_pred_train_hyper))\nprint(\"recall_score: \", recall_score( y_train, y_pred_train_hyper))\nprint(\"ROC AUC: \", roc_auc_score( y_train, y_pred_train_hyper))\n\n\nprint(\" HYPER  TEST\")\nprint('Accuracy Score ', accuracy_score( y_test, y_pred_hyper))\nprint(\"f1: \",f1_score(y_test, y_pred_hyper))\nprint(\"precision: \", precision_score(y_test, y_pred_hyper))\nprint(\"recall_score: \", recall_score( y_test, y_pred_hyper))\nprint(\"ROC AUC: \", roc_auc_score( y_test, y_pred_hyper))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = test_df[X_train.columns]\n\nfrom sklearn.preprocessing import RobustScaler \nrb = RobustScaler()\ntest_df_scaled = rb.fit_transform(test_df)\n\ntest_df_scaled = pd.DataFrame(test_df_scaled, columns = test_df.columns)\ntest_df = test_df_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred = hyper_model.best_estimator_.predict(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame({\"ID_code\": test_ID.values})\n\nsub_df[\"target\"] = final_pred\nsub_df.to_csv(\"Final Prediction.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you have any advice/suggestion, let me know in the comments and upvote!\nThank you!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}