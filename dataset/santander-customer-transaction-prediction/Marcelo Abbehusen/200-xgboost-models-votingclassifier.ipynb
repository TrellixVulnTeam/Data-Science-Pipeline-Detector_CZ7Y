{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle competition - Santander Customer Transaction Prediction\n\nMarcelo Abbehusen","metadata":{}},{"cell_type":"markdown","source":"#### This kernel is part of the Petrobras Data Science Training Program final challenge.","metadata":{}},{"cell_type":"markdown","source":"* [Importing Packages](#section-one)\n* [Functions](#section-two)\n* [Loading Data](#section-three)\n* [EDA (Exploratory Data Analysis)](#section-four)\n* [Training a baseline model (XGBoost)](#section-five)\n* [Tuned XGBoost Model](#section-six)\n* [Tuned Weighted XGBoost Model](#section-seven)\n* [Feature Engineering](#section-eight)\n    - [Identifying Magic Numbers](#subsection-one)\n* [Training the best model on the magic numbers dataset](#section-ten)\n* [Training and ensembling 200 different models](#section-eleven)\n* [Ensemble 200 models using VotingClassifier](#section-twelve)\n* [Suggestions](#section-thirteen)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# Importing Packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom collections import Counter\nfrom sklearn.ensemble import VotingClassifier\nimport pickle\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# Functions","metadata":{}},{"cell_type":"code","source":"def plot_boxplots(dataset):\n    '''Plot boxplots of all the variables\n    of the dataset in a row'''\n    for i in range(dataset.shape[1]):\n        sns.boxplot(x=X.iloc[:, i])\n        plt.tight_layout()\n        plt.show()\n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\ndef f1_eval(y_pred, dtrain):\n    '''Calculates f1 score error'''\n    y_true = dtrain.get_label()\n    err = 1-f1_score(y_true, np.round(y_pred))\n    return 'f1_err', err","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:22:29.522967Z","iopub.execute_input":"2022-06-02T14:22:29.523307Z","iopub.status.idle":"2022-06-02T14:22:29.541875Z","shell.execute_reply.started":"2022-06-02T14:22:29.523274Z","shell.execute_reply":"2022-06-02T14:22:29.540967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# Loading data","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')\ndf_train = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:22:29.543759Z","iopub.execute_input":"2022-06-02T14:22:29.544097Z","iopub.status.idle":"2022-06-02T14:22:49.960618Z","shell.execute_reply.started":"2022-06-02T14:22:29.544057Z","shell.execute_reply":"2022-06-02T14:22:49.95895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:22:49.963745Z","iopub.execute_input":"2022-06-02T14:22:49.964101Z","iopub.status.idle":"2022-06-02T14:22:50.025116Z","shell.execute_reply.started":"2022-06-02T14:22:49.964063Z","shell.execute_reply":"2022-06-02T14:22:50.02404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:22:50.028228Z","iopub.execute_input":"2022-06-02T14:22:50.028899Z","iopub.status.idle":"2022-06-02T14:22:50.071655Z","shell.execute_reply.started":"2022-06-02T14:22:50.028849Z","shell.execute_reply":"2022-06-02T14:22:50.070604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape, df_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:22:50.073249Z","iopub.execute_input":"2022-06-02T14:22:50.074368Z","iopub.status.idle":"2022-06-02T14:22:50.081781Z","shell.execute_reply.started":"2022-06-02T14:22:50.07432Z","shell.execute_reply":"2022-06-02T14:22:50.080721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Before starting our studies, we'll use the function reduce_mem_usage, that reduces memory usage by 75%, by changing the data type of each column. This function was obtained in this [kernel](https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm)","metadata":{}},{"cell_type":"code","source":"df_train = reduce_mem_usage(df_train)\ndf_test = reduce_mem_usage(df_test)\nprint(\"Shape of train set: \", df_train.shape)\nprint(\"Shape of test set: \", df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:22:50.082898Z","iopub.execute_input":"2022-06-02T14:22:50.083196Z","iopub.status.idle":"2022-06-02T14:23:13.767845Z","shell.execute_reply.started":"2022-06-02T14:22:50.083156Z","shell.execute_reply":"2022-06-02T14:23:13.766482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Defining df_test_ids and training variables, that will be used later on the submisssion file.","metadata":{}},{"cell_type":"code","source":"df_test_ids = df_test.ID_code\ndf_test = df_test.drop('ID_code', axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:13.769171Z","iopub.execute_input":"2022-06-02T14:23:13.76954Z","iopub.status.idle":"2022-06-02T14:23:13.900437Z","shell.execute_reply.started":"2022-06-02T14:23:13.769505Z","shell.execute_reply":"2022-06-02T14:23:13.899513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Setting target as variable y and the rest of the variables as X","metadata":{}},{"cell_type":"markdown","source":"#### ID_code will be dropped, since It's just an index.","metadata":{}},{"cell_type":"code","source":"y = df_train['target'].copy()\nX = df_train.drop(['target', 'ID_code'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:13.901909Z","iopub.execute_input":"2022-06-02T14:23:13.902399Z","iopub.status.idle":"2022-06-02T14:23:14.190116Z","shell.execute_reply.started":"2022-06-02T14:23:13.902331Z","shell.execute_reply":"2022-06-02T14:23:14.189296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"markdown","source":"#### The first step will be doing some basic exploratory data analysis (EDA) to check If there's any preprocessing that needs to be done before training the models.","metadata":{}},{"cell_type":"markdown","source":"#### Checking If there's any missing data.","metadata":{}},{"cell_type":"code","source":"df_train.isna().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:14.193791Z","iopub.execute_input":"2022-06-02T14:23:14.194149Z","iopub.status.idle":"2022-06-02T14:23:14.394996Z","shell.execute_reply.started":"2022-06-02T14:23:14.194117Z","shell.execute_reply":"2022-06-02T14:23:14.394268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.isna().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:14.396456Z","iopub.execute_input":"2022-06-02T14:23:14.39722Z","iopub.status.idle":"2022-06-02T14:23:14.591731Z","shell.execute_reply.started":"2022-06-02T14:23:14.397185Z","shell.execute_reply":"2022-06-02T14:23:14.590855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### No missing values. Now we'll check If the dataset is balanced or not.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nsns.countplot(data=df_train, x='target')\nplt.title('Target class distribution')\nplt.xlabel('target')\nplt.ylabel('Count')\n#plt.savefig('cnn.png', dpi=500)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:14.593035Z","iopub.execute_input":"2022-06-02T14:23:14.593767Z","iopub.status.idle":"2022-06-02T14:23:14.893179Z","shell.execute_reply.started":"2022-06-02T14:23:14.593733Z","shell.execute_reply":"2022-06-02T14:23:14.892436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see on the chart above, the dataset is pretty imbalanced, which means we'll probably have to deal with this problem later by adjusting the training algorithm to take into account this imbalanced distribution of classes and setting different weights to the classes.","metadata":{}},{"cell_type":"markdown","source":"#### Now we should check if there's any correlation between variables.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(df_train.corr(), cmap='YlGnBu');","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:14.894337Z","iopub.execute_input":"2022-06-02T14:23:14.894938Z","iopub.status.idle":"2022-06-02T14:23:34.198039Z","shell.execute_reply.started":"2022-06-02T14:23:14.894899Z","shell.execute_reply":"2022-06-02T14:23:34.197233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Even though the heatmap above shows that there's no correlation between features, due to the fact that our dataset is large and has 200 columns, It isn't the best way of visualizing this parameter. Let's try then building a histogram to show the distribution between correlations. Note that we need to exclude correlations that are equal to 1, because they refer to variables that are correlated to themselves.","metadata":{}},{"cell_type":"code","source":"train_corr = X.corr()\ntrain_corr = train_corr.values.flatten()\ntrain_corr = train_corr[train_corr != 1]\n\nplt.figure(figsize=(18, 9))\nsns.histplot(train_corr, color='blue', label='train', kde=True, stat='density', linewidth=1)\nplt.xlabel('Correlations between variables on the training dataset')\nplt.ylabel('Frequency')\nplt.title('Frequency of correlations between features')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:34.199251Z","iopub.execute_input":"2022-06-02T14:23:34.199703Z","iopub.status.idle":"2022-06-02T14:23:53.440619Z","shell.execute_reply.started":"2022-06-02T14:23:34.199661Z","shell.execute_reply":"2022-06-02T14:23:53.439537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The histogram above confirms our previous suspicious. The variables are not correlated indeed.\n#### Now we'll check if there's any duplicates.","metadata":{}},{"cell_type":"code","source":"df_train.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:53.44178Z","iopub.execute_input":"2022-06-02T14:23:53.442101Z","iopub.status.idle":"2022-06-02T14:23:55.878094Z","shell.execute_reply.started":"2022-06-02T14:23:53.442071Z","shell.execute_reply":"2022-06-02T14:23:55.877126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we'll build a baseline model using XGBoost, which is a machine learning algorithm based on gradient boosting decision trees.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n# Training a baseline model (XGboost)","metadata":{}},{"cell_type":"code","source":"# creating a 5 fold stratifiedkfold cross-validation object\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:55.879336Z","iopub.execute_input":"2022-06-02T14:23:55.879675Z","iopub.status.idle":"2022-06-02T14:23:55.884873Z","shell.execute_reply.started":"2022-06-02T14:23:55.879644Z","shell.execute_reply":"2022-06-02T14:23:55.883738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting the dataset into training (80%) and test (20%) data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:55.88674Z","iopub.execute_input":"2022-06-02T14:23:55.887223Z","iopub.status.idle":"2022-06-02T14:23:56.422759Z","shell.execute_reply.started":"2022-06-02T14:23:55.887174Z","shell.execute_reply":"2022-06-02T14:23:56.421664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a baseline XGBoost model\n\nmodel_xgb = XGBClassifier(max_depth=7, \n                          random_state=42, \n                          class_weight= 'imbalanced')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:56.423834Z","iopub.execute_input":"2022-06-02T14:23:56.42414Z","iopub.status.idle":"2022-06-02T14:23:56.429773Z","shell.execute_reply.started":"2022-06-02T14:23:56.42411Z","shell.execute_reply":"2022-06-02T14:23:56.428808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing the model using 5-fold cross-validation\n\nscores = cross_val_score(model_xgb, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:23:56.431477Z","iopub.execute_input":"2022-06-02T14:23:56.431958Z","iopub.status.idle":"2022-06-02T14:39:29.981932Z","shell.execute_reply.started":"2022-06-02T14:23:56.431912Z","shell.execute_reply":"2022-06-02T14:39:29.980519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('5-fold Cross validation Roc-auc and std: {:.2f} ({:.4f})'.format(np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:39:29.984846Z","iopub.execute_input":"2022-06-02T14:39:29.985479Z","iopub.status.idle":"2022-06-02T14:39:29.993204Z","shell.execute_reply.started":"2022-06-02T14:39:29.985404Z","shell.execute_reply":"2022-06-02T14:39:29.991873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a variable for the baseline model cross validation roc_auc\n\nbaseline_cv_roc_auc = round(np.mean(scores), 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:39:29.995554Z","iopub.execute_input":"2022-06-02T14:39:29.996431Z","iopub.status.idle":"2022-06-02T14:39:30.01109Z","shell.execute_reply.started":"2022-06-02T14:39:29.996361Z","shell.execute_reply":"2022-06-02T14:39:30.010198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model\n\nmodel_xgb.fit(X_train, y_train, eval_metric=f1_eval)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:39:30.012804Z","iopub.execute_input":"2022-06-02T14:39:30.014801Z","iopub.status.idle":"2022-06-02T14:42:26.542603Z","shell.execute_reply.started":"2022-06-02T14:39:30.014734Z","shell.execute_reply":"2022-06-02T14:42:26.541374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting on X_test\n\ny_pred = model_xgb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:26.545368Z","iopub.execute_input":"2022-06-02T14:42:26.545833Z","iopub.status.idle":"2022-06-02T14:42:26.706608Z","shell.execute_reply.started":"2022-06-02T14:42:26.545789Z","shell.execute_reply":"2022-06-02T14:42:26.705344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:26.708133Z","iopub.execute_input":"2022-06-02T14:42:26.708925Z","iopub.status.idle":"2022-06-02T14:42:26.767389Z","shell.execute_reply.started":"2022-06-02T14:42:26.708885Z","shell.execute_reply":"2022-06-02T14:42:26.766213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see, the model has a high accuracy, because of the highly imbalanced distribution of classes, although It is performing poorly on the class 1. Let's dive a bit deeper into this, by checking the model's confusion matrix.","metadata":{}},{"cell_type":"code","source":"# Creating a variable for the classification report\n\nreport = classification_report(y_test, y_pred, output_dict=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:26.768926Z","iopub.execute_input":"2022-06-02T14:42:26.76966Z","iopub.status.idle":"2022-06-02T14:42:26.823309Z","shell.execute_reply.started":"2022-06-02T14:42:26.76961Z","shell.execute_reply":"2022-06-02T14:42:26.822239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating variables for precision, recall, f1score, accuracy, roc_auc and class1 f1score\n\nbaseline_precision = round(report['macro avg']['precision'], 4)\nbaseline_recall = round(report['macro avg']['recall'], 4)\nbaseline_f1score = round(report['macro avg']['f1-score'], 4)\nbaseline_accuracy = round(report['accuracy'], 4)\nbaseline_roc_auc = round(roc_auc_score(y_test, y_pred), 4)\nbaseline_class1_f1score = round(report['1']['f1-score'], 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:26.824704Z","iopub.execute_input":"2022-06-02T14:42:26.825173Z","iopub.status.idle":"2022-06-02T14:42:26.842011Z","shell.execute_reply.started":"2022-06-02T14:42:26.825129Z","shell.execute_reply":"2022-06-02T14:42:26.840843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking confusion matrix\n\ntarget_names = ['0', '1']\n\nplt.figure(figsize=(6, 5))\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_pred),\n            annot=True, fmt='g', ax=ax)\n\nax.set_xlabel('Predicted values', fontsize=14)\nax.set_ylabel('Expected values', fontsize=14)\nax.set_title('Confusion Matrix', fontsize=14)\n\nax.xaxis.set_ticklabels(target_names, fontsize=14)\nax.yaxis.set_ticklabels(target_names, fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:26.843797Z","iopub.execute_input":"2022-06-02T14:42:26.844275Z","iopub.status.idle":"2022-06-02T14:42:27.133278Z","shell.execute_reply.started":"2022-06-02T14:42:26.844225Z","shell.execute_reply":"2022-06-02T14:42:27.13219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The confusion matrix above confirms what we saw on the classification report. The model's accuracy is high just because of the imbalance of the dataset. As we can see, the model performs poorly on class 1.","metadata":{}},{"cell_type":"code","source":"# Creating a dictionary to compare models performances and parameters\n\ndic = {\n    'Test Precision': baseline_precision,\n    'Test Recall': baseline_recall,\n    'Test F1-Score': baseline_f1score,\n    'Test Accuracy': baseline_accuracy,\n    'Test Roc_auc': baseline_roc_auc,\n    'Class 1 F1-score': baseline_class1_f1score, \n    'Validation Roc_auc': baseline_cv_roc_auc}","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:27.141087Z","iopub.execute_input":"2022-06-02T14:42:27.141518Z","iopub.status.idle":"2022-06-02T14:42:27.147763Z","shell.execute_reply.started":"2022-06-02T14:42:27.141484Z","shell.execute_reply":"2022-06-02T14:42:27.146466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming the dictionary into a dataframe\n\ndf_performance = pd.DataFrame(dic, index=['Baseline Model (XGBoost)'])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:27.151523Z","iopub.execute_input":"2022-06-02T14:42:27.152132Z","iopub.status.idle":"2022-06-02T14:42:27.162089Z","shell.execute_reply.started":"2022-06-02T14:42:27.152095Z","shell.execute_reply":"2022-06-02T14:42:27.161121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_performance","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:27.163596Z","iopub.execute_input":"2022-06-02T14:42:27.164209Z","iopub.status.idle":"2022-06-02T14:42:27.186137Z","shell.execute_reply.started":"2022-06-02T14:42:27.164165Z","shell.execute_reply":"2022-06-02T14:42:27.185234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we have a baseline model performance the needs to be beat.","metadata":{}},{"cell_type":"markdown","source":"#### Even though we've achieved a pretty high accuracy (91%), the precision and recall metrics for class 1 were very low, 72% and 24%, respectively, which means that the accuracy is high due to the imbalance of the dataset. The F-1 score (~37%) confirms this suspicious. Because of that, we'll store class 1 f1-score as a variable, for further comparison between the models we'll build.","metadata":{}},{"cell_type":"markdown","source":"#### Before trying to improve the baseline model, we'll submit this predictions to the kaggle platform and check the results. Before doing that, we'll have to build the model using the entire training dataset.","metadata":{}},{"cell_type":"markdown","source":"## Retraining the baseline model on the whole dataset and submitting the results to kaggle","metadata":{}},{"cell_type":"code","source":"# Creating a baseline XGBoost model\n\nmodel_xgb = XGBClassifier(max_depth=7, \n                          random_state=42, \n                          class_weight= 'imbalanced')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:27.187439Z","iopub.execute_input":"2022-06-02T14:42:27.187955Z","iopub.status.idle":"2022-06-02T14:42:27.192524Z","shell.execute_reply.started":"2022-06-02T14:42:27.187922Z","shell.execute_reply":"2022-06-02T14:42:27.191574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model on the entire dataset\n\nmodel_xgb.fit(X, y, eval_metric=f1_eval)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:42:27.194001Z","iopub.execute_input":"2022-06-02T14:42:27.194518Z","iopub.status.idle":"2022-06-02T14:46:01.293616Z","shell.execute_reply.started":"2022-06-02T14:42:27.194471Z","shell.execute_reply":"2022-06-02T14:46:01.292455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting on the test set (df_set)\n\ny_pred = model_xgb.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:46:01.295287Z","iopub.execute_input":"2022-06-02T14:46:01.295617Z","iopub.status.idle":"2022-06-02T14:46:01.946805Z","shell.execute_reply.started":"2022-06-02T14:46:01.295586Z","shell.execute_reply":"2022-06-02T14:46:01.94525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_1 = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:46:01.948296Z","iopub.execute_input":"2022-06-02T14:46:01.948696Z","iopub.status.idle":"2022-06-02T14:46:01.955074Z","shell.execute_reply.started":"2022-06-02T14:46:01.948663Z","shell.execute_reply":"2022-06-02T14:46:01.953872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_1['ID_code'] = df_test_ids.copy()\nsubmission_1['target'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:46:01.956485Z","iopub.execute_input":"2022-06-02T14:46:01.956932Z","iopub.status.idle":"2022-06-02T14:46:02.011669Z","shell.execute_reply.started":"2022-06-02T14:46:01.956901Z","shell.execute_reply":"2022-06-02T14:46:02.010485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_1.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:46:02.013205Z","iopub.execute_input":"2022-06-02T14:46:02.013901Z","iopub.status.idle":"2022-06-02T14:46:02.02584Z","shell.execute_reply.started":"2022-06-02T14:46:02.013849Z","shell.execute_reply":"2022-06-02T14:46:02.024608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_1.to_csv('final_baseline_model.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:46:02.027524Z","iopub.execute_input":"2022-06-02T14:46:02.0279Z","iopub.status.idle":"2022-06-02T14:46:02.386304Z","shell.execute_reply.started":"2022-06-02T14:46:02.027868Z","shell.execute_reply":"2022-06-02T14:46:02.384959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The model results on kaggle were:\n\n#### Score: 0.61632\n\n#### Public score: 0.62048","metadata":{}},{"cell_type":"code","source":"submission_score = 0.61632\nsubmission_public_score = 0.62048","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:46:02.387826Z","iopub.execute_input":"2022-06-02T14:46:02.388196Z","iopub.status.idle":"2022-06-02T14:46:02.393702Z","shell.execute_reply.started":"2022-06-02T14:46:02.388161Z","shell.execute_reply":"2022-06-02T14:46:02.392463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a dictionary to compare submissions performances\n\ndic = {\n    'Submission Score': submission_score,\n    'Submission Public Score': submission_public_score}","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:46:02.395212Z","iopub.execute_input":"2022-06-02T14:46:02.395601Z","iopub.status.idle":"2022-06-02T14:46:02.405612Z","shell.execute_reply.started":"2022-06-02T14:46:02.395569Z","shell.execute_reply":"2022-06-02T14:46:02.404651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming the dictionary into a dataframe\n\ndf_submissions = pd.DataFrame(dic, index=['Baseline Model (XGBoost)'])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:46:02.409628Z","iopub.execute_input":"2022-06-02T14:46:02.410721Z","iopub.status.idle":"2022-06-02T14:46:02.419609Z","shell.execute_reply.started":"2022-06-02T14:46:02.410684Z","shell.execute_reply":"2022-06-02T14:46:02.418694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submissions","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:46:02.420804Z","iopub.execute_input":"2022-06-02T14:46:02.421601Z","iopub.status.idle":"2022-06-02T14:46:02.438289Z","shell.execute_reply.started":"2022-06-02T14:46:02.421566Z","shell.execute_reply":"2022-06-02T14:46:02.437194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The next attempt will be checking If there's any room for improvement just by tuning a few hyperparameters. During the process of building this kernel, gridsearchcv and randomizedsearchcv were both used to find the best hyperparameters, but due to the fact that training was taking too long and the iterative process of tuning hyperparameters was way too computational expensive, in the end we decided to use the hyperparameters setup based on this [kernel](https://www.kaggle.com/code/ricksun/xgboost-stratifiedkfold-for-beginner/notebook)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-six\"></a>\n# Tuned XGBoost model","metadata":{}},{"cell_type":"code","source":"# creating a 5 fold stratifiedkfold cross-validation object\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:47.654901Z","iopub.execute_input":"2022-06-02T14:49:47.655359Z","iopub.status.idle":"2022-06-02T14:49:47.660214Z","shell.execute_reply.started":"2022-06-02T14:49:47.655324Z","shell.execute_reply":"2022-06-02T14:49:47.659329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a tuned XGBoost model\n\nmodel_xgb =  XGBClassifier(max_depth=2,\n                           colsample_bytree=0.7,\n                           n_estimators=20000,\n                           learning_rate=0.02,\n                           objective='binary:logistic', \n                           verbosity =1,\n                           eval_metric  = f1_eval,\n                           tree_method='gpu_hist',\n                           n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:47.714582Z","iopub.execute_input":"2022-06-02T14:49:47.714998Z","iopub.status.idle":"2022-06-02T14:49:47.721301Z","shell.execute_reply.started":"2022-06-02T14:49:47.714965Z","shell.execute_reply":"2022-06-02T14:49:47.720155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing the model using 5-fold cross-validation\n\nscores = cross_val_score(model_xgb, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:47.79817Z","iopub.execute_input":"2022-06-02T14:49:47.798604Z","iopub.status.idle":"2022-06-02T14:49:51.938204Z","shell.execute_reply.started":"2022-06-02T14:49:47.798571Z","shell.execute_reply":"2022-06-02T14:49:51.937286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('5-fold Cross validation Roc-auc and std: {:.2f} ({:.4f})'.format(np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:18:34.12109Z","iopub.execute_input":"2022-06-02T17:18:34.121679Z","iopub.status.idle":"2022-06-02T17:18:34.225485Z","shell.execute_reply.started":"2022-06-02T17:18:34.121572Z","shell.execute_reply":"2022-06-02T17:18:34.22409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a variable for the tuned model cross validation roc_auc\n\ntuned_roc_auc = round(np.mean(scores), 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:51.946601Z","iopub.execute_input":"2022-06-02T14:49:51.947233Z","iopub.status.idle":"2022-06-02T14:49:51.959833Z","shell.execute_reply.started":"2022-06-02T14:49:51.9472Z","shell.execute_reply":"2022-06-02T14:49:51.958645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model\n\nmodel_xgb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:51.96276Z","iopub.execute_input":"2022-06-02T14:49:51.963867Z","iopub.status.idle":"2022-06-02T14:49:52.640237Z","shell.execute_reply.started":"2022-06-02T14:49:51.963815Z","shell.execute_reply":"2022-06-02T14:49:52.632562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting the model on the test set\n\ny_pred = model_xgb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.641547Z","iopub.status.idle":"2022-06-02T14:49:52.642053Z","shell.execute_reply.started":"2022-06-02T14:49:52.641849Z","shell.execute_reply":"2022-06-02T14:49:52.641872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.643406Z","iopub.status.idle":"2022-06-02T14:49:52.644561Z","shell.execute_reply.started":"2022-06-02T14:49:52.644333Z","shell.execute_reply":"2022-06-02T14:49:52.644355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see, the model performance had a significant improvement, just by tuning the hyperparameters. Now we should check the confusion matrix.","metadata":{}},{"cell_type":"code","source":"# Creating a variable for the classification report\n\nreport = classification_report(y_test, y_pred, output_dict=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.645631Z","iopub.status.idle":"2022-06-02T14:49:52.646695Z","shell.execute_reply.started":"2022-06-02T14:49:52.646468Z","shell.execute_reply":"2022-06-02T14:49:52.646492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating variables for precision, recall, f1score, accuracy, roc_auc and class1 f1score\n\ntuned_precision = round(report['macro avg']['precision'], 4)\ntuned_recall = round(report['macro avg']['recall'], 4)\ntuned_f1score = round(report['macro avg']['f1-score'], 4)\ntuned_accuracy = round(report['accuracy'], 4)\ntuned_roc_auc = round(roc_auc_score(y_test, y_pred), 4)\ntuned_class1_f1score = round(report['1']['f1-score'], 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.647968Z","iopub.status.idle":"2022-06-02T14:49:52.648819Z","shell.execute_reply.started":"2022-06-02T14:49:52.648504Z","shell.execute_reply":"2022-06-02T14:49:52.648531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking confusion matrix\n\ntarget_names = ['0', '1']\n\nplt.figure(figsize=(6, 5))\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_pred),\n            annot=True, fmt='g', ax=ax)\n\nax.set_xlabel('Predicted values', fontsize=14)\nax.set_ylabel('Expected values', fontsize=14)\nax.set_title('Confusion Matrix', fontsize=14)\n\nax.xaxis.set_ticklabels(target_names, fontsize=14)\nax.yaxis.set_ticklabels(target_names, fontsize=14)\n#plt.savefig('baseline_model_heatmap.png', dpi=500)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.650113Z","iopub.status.idle":"2022-06-02T14:49:52.650797Z","shell.execute_reply.started":"2022-06-02T14:49:52.650578Z","shell.execute_reply":"2022-06-02T14:49:52.6506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The confusion matrix above shows that there was a significant improvement on the class 1 true positives, which can be observed on the F1-scores performances.","metadata":{}},{"cell_type":"code","source":"# Adding this results to the df_performance dataframe, for further comparison between models\n\ndf_performance.loc['Tuned XGBoost', :] = [tuned_precision,\n                                          tuned_recall,\n                                          tuned_f1score,\n                                          tuned_accuracy,\n                                          tuned_roc_auc,\n                                          tuned_class1_f1score,\n                                          tuned_roc_auc]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.65197Z","iopub.status.idle":"2022-06-02T14:49:52.652544Z","shell.execute_reply.started":"2022-06-02T14:49:52.652329Z","shell.execute_reply":"2022-06-02T14:49:52.652349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_performance","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.653407Z","iopub.status.idle":"2022-06-02T14:49:52.654094Z","shell.execute_reply.started":"2022-06-02T14:49:52.653875Z","shell.execute_reply":"2022-06-02T14:49:52.653897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we'll do another submission on kaggle and check if there's any improvement on the overall scores.","metadata":{}},{"cell_type":"markdown","source":"## Retraining the Tuned XGBoost model on the whole dataset and submitting the results to kaggle","metadata":{}},{"cell_type":"code","source":"# Creating a tuned XGBoost model\n\nmodel_xgb =  XGBClassifier(max_depth=2,\n                           colsample_bytree=0.7,\n                           n_estimators=20000,\n                           learning_rate=0.02,\n                           objective='binary:logistic', \n                           verbosity =1,\n                           eval_metric  = 'auc',\n                           tree_method='gpu_hist',\n                           n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.655918Z","iopub.status.idle":"2022-06-02T14:49:52.656503Z","shell.execute_reply.started":"2022-06-02T14:49:52.656205Z","shell.execute_reply":"2022-06-02T14:49:52.656227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model on the entire dataset\n\nmodel_xgb.fit(X, y, eval_metric=f1_eval)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.657651Z","iopub.status.idle":"2022-06-02T14:49:52.658097Z","shell.execute_reply.started":"2022-06-02T14:49:52.657892Z","shell.execute_reply":"2022-06-02T14:49:52.657913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting on test set (df_test)\n\ny_pred = model_xgb.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.659476Z","iopub.status.idle":"2022-06-02T14:49:52.659912Z","shell.execute_reply.started":"2022-06-02T14:49:52.659702Z","shell.execute_reply":"2022-06-02T14:49:52.659732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2 = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.661326Z","iopub.status.idle":"2022-06-02T14:49:52.661813Z","shell.execute_reply.started":"2022-06-02T14:49:52.661607Z","shell.execute_reply":"2022-06-02T14:49:52.661629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2['ID_code'] = df_test_ids.copy()\nsubmission_2['target'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.662783Z","iopub.status.idle":"2022-06-02T14:49:52.663176Z","shell.execute_reply.started":"2022-06-02T14:49:52.662984Z","shell.execute_reply":"2022-06-02T14:49:52.663004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.664019Z","iopub.status.idle":"2022-06-02T14:49:52.664432Z","shell.execute_reply.started":"2022-06-02T14:49:52.664212Z","shell.execute_reply":"2022-06-02T14:49:52.664234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.to_csv('final_submission_tuned.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.665212Z","iopub.status.idle":"2022-06-02T14:49:52.665632Z","shell.execute_reply.started":"2022-06-02T14:49:52.665434Z","shell.execute_reply":"2022-06-02T14:49:52.665458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The model results on kaggle were:\n\n#### Score: 0.68044\n\n#### Public score: 0.68329","metadata":{}},{"cell_type":"code","source":"submission_score = 0.68044\nsubmission_public_score = 0.68329","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.666557Z","iopub.status.idle":"2022-06-02T14:49:52.666956Z","shell.execute_reply.started":"2022-06-02T14:49:52.666764Z","shell.execute_reply":"2022-06-02T14:49:52.666784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding this results to the df_submission dataframe, for further comparison between models\n\ndf_submissions.loc['Tuned Model (XGBoost))', :] = [submission_score,\n                                                   submission_public_score]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.668036Z","iopub.status.idle":"2022-06-02T14:49:52.668471Z","shell.execute_reply.started":"2022-06-02T14:49:52.668239Z","shell.execute_reply":"2022-06-02T14:49:52.668259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submissions","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.670071Z","iopub.status.idle":"2022-06-02T14:49:52.670475Z","shell.execute_reply.started":"2022-06-02T14:49:52.670269Z","shell.execute_reply":"2022-06-02T14:49:52.670289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The tuned model had better performance than our baseline model.","metadata":{}},{"cell_type":"markdown","source":"#### The next attempt will be tuning the scale_pos_weight hyperparameter, that enhances the correction of the minority class (class 1), making it more cost-sensitive.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-seven\"></a>\n# Tuned weighted XGBoost Model","metadata":{}},{"cell_type":"code","source":"# Checking the proportion between majority and minority classes\n\ncounter = Counter(y)\nweight = round(counter[0] / counter[1])\nweight","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.672705Z","iopub.status.idle":"2022-06-02T14:49:52.67322Z","shell.execute_reply.started":"2022-06-02T14:49:52.673006Z","shell.execute_reply":"2022-06-02T14:49:52.673028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see, the majority class is nine times more representative than the minority class, so that's the weighting factor that we'll use to minimize the impact of class imbalance.","metadata":{}},{"cell_type":"code","source":"# creating a 5 fold stratifiedkfold cross-validation object\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.674554Z","iopub.status.idle":"2022-06-02T14:49:52.675062Z","shell.execute_reply.started":"2022-06-02T14:49:52.67484Z","shell.execute_reply":"2022-06-02T14:49:52.674862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a tuned XGBoost model and setting scale_pos_weight to 9\n\nmodel_xgb =  XGBClassifier(max_depth=2,\n                           colsample_bytree=0.7,\n                           n_estimators=20000,\n                           learning_rate=0.02,\n                           scale_pos_weight=weight,\n                           objective='binary:logistic', \n                           verbosity =1,\n                           eval_metric  = 'auc',\n                           tree_method='gpu_hist',\n                           n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.676114Z","iopub.status.idle":"2022-06-02T14:49:52.676578Z","shell.execute_reply.started":"2022-06-02T14:49:52.676314Z","shell.execute_reply":"2022-06-02T14:49:52.676334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing the model using 5-fold cross-validation\n\nscores = cross_val_score(model_xgb, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.677683Z","iopub.status.idle":"2022-06-02T14:49:52.678091Z","shell.execute_reply.started":"2022-06-02T14:49:52.677884Z","shell.execute_reply":"2022-06-02T14:49:52.677904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('5-fold Cross validation Roc-auc and std: {:.2f} ({:.4f})'.format(np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.679413Z","iopub.status.idle":"2022-06-02T14:49:52.679887Z","shell.execute_reply.started":"2022-06-02T14:49:52.679615Z","shell.execute_reply":"2022-06-02T14:49:52.679635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a variable for the tuned weighted model cross validation roc_auc\n\ntuned_scale_weight_roc_auc = round(np.mean(scores), 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.681023Z","iopub.status.idle":"2022-06-02T14:49:52.681454Z","shell.execute_reply.started":"2022-06-02T14:49:52.681229Z","shell.execute_reply":"2022-06-02T14:49:52.68125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model\n\nmodel_xgb.fit(X_train, y_train, eval_metric=f1_eval)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.683037Z","iopub.status.idle":"2022-06-02T14:49:52.6835Z","shell.execute_reply.started":"2022-06-02T14:49:52.683254Z","shell.execute_reply":"2022-06-02T14:49:52.683281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting the model on the test set (X_test)\n\ny_pred = model_xgb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.68446Z","iopub.status.idle":"2022-06-02T14:49:52.684861Z","shell.execute_reply.started":"2022-06-02T14:49:52.684661Z","shell.execute_reply":"2022-06-02T14:49:52.684686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.685948Z","iopub.status.idle":"2022-06-02T14:49:52.686351Z","shell.execute_reply.started":"2022-06-02T14:49:52.686148Z","shell.execute_reply":"2022-06-02T14:49:52.686179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see, the model performance had a slight improvement when we minimized the impact of class imbalance. Now we should check the confusion matrix.","metadata":{}},{"cell_type":"code","source":"# Creating a variable for the classification report\n\nreport = classification_report(y_test, y_pred, output_dict=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.688098Z","iopub.status.idle":"2022-06-02T14:49:52.688565Z","shell.execute_reply.started":"2022-06-02T14:49:52.688312Z","shell.execute_reply":"2022-06-02T14:49:52.688332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating variables for precision, recall, f1score, accuracy, roc_auc and class1 f1score\n\ntuned_scale_weight_precision = round(report['macro avg']['precision'], 4)\ntuned_scale_weight_recall = round(report['macro avg']['recall'], 4)\ntuned_scale_weight_f1score = round(report['macro avg']['f1-score'], 4)\ntuned_scale_weight_accuracy = round(report['accuracy'], 4)\ntuned_scale_weight_roc_auc = round(roc_auc_score(y_test, y_pred), 4)\ntuned_scale_weight_class1_f1score = round(report['1']['f1-score'], 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.689771Z","iopub.status.idle":"2022-06-02T14:49:52.690172Z","shell.execute_reply.started":"2022-06-02T14:49:52.689982Z","shell.execute_reply":"2022-06-02T14:49:52.690002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking confusion matrix\n\ntarget_names = ['0', '1']\n\nplt.figure(figsize=(6, 5))\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_pred),\n            annot=True, fmt='g', ax=ax)\n\nax.set_xlabel('Predicted values', fontsize=14)\nax.set_ylabel('Expected values', fontsize=14)\nax.set_title('Confusion Matrix', fontsize=14)\n\nax.xaxis.set_ticklabels(target_names, fontsize=14)\nax.yaxis.set_ticklabels(target_names, fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.692319Z","iopub.status.idle":"2022-06-02T14:49:52.692807Z","shell.execute_reply.started":"2022-06-02T14:49:52.692582Z","shell.execute_reply":"2022-06-02T14:49:52.692604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Despite the fact that the confusion matrix above seems to show that the model's performance got worse, we should check the performance on the test dataset, because there are a few hints on the classification report that could be related to a better overall performance, such as the validation and test roc_auc parameters.","metadata":{}},{"cell_type":"code","source":"df_performance.loc['Tuned Weighted XGBoost', :] = [tuned_scale_weight_precision,\n                                                   tuned_scale_weight_recall,\n                                                   tuned_scale_weight_f1score,\n                                                   tuned_scale_weight_accuracy,\n                                                   tuned_scale_weight_roc_auc,\n                                                   tuned_scale_weight_class1_f1score,\n                                                   tuned_scale_weight_roc_auc]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.694614Z","iopub.status.idle":"2022-06-02T14:49:52.695109Z","shell.execute_reply.started":"2022-06-02T14:49:52.694892Z","shell.execute_reply":"2022-06-02T14:49:52.694914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_performance","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.696226Z","iopub.status.idle":"2022-06-02T14:49:52.696681Z","shell.execute_reply.started":"2022-06-02T14:49:52.696457Z","shell.execute_reply":"2022-06-02T14:49:52.696479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we'll do another submission on kaggle and check if there's any improvement on the overall scores.","metadata":{}},{"cell_type":"markdown","source":"## Rebuilding the Tuned Weighted XGBoost model on the whole dataset and submitting the results to kaggle","metadata":{}},{"cell_type":"code","source":"# Creating a tuned XGBoost model and setting scale_pos_weight to 9\n\nmodel_xgb =  XGBClassifier(max_depth=2,\n                           colsample_bytree=0.7,\n                           n_estimators=20000,\n                           scale_pos_weight = weight,\n                           learning_rate=0.02,\n                           objective='binary:logistic', \n                           verbosity =1,\n                           eval_metric  = 'auc',\n                           tree_method='gpu_hist',\n                           n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.697958Z","iopub.status.idle":"2022-06-02T14:49:52.698377Z","shell.execute_reply.started":"2022-06-02T14:49:52.69817Z","shell.execute_reply":"2022-06-02T14:49:52.69819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model on the entire dataset\n\nmodel_xgb.fit(X, y, eval_metric=f1_eval)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.699735Z","iopub.status.idle":"2022-06-02T14:49:52.700147Z","shell.execute_reply.started":"2022-06-02T14:49:52.699955Z","shell.execute_reply":"2022-06-02T14:49:52.699975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_xgb.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.705135Z","iopub.status.idle":"2022-06-02T14:49:52.70562Z","shell.execute_reply.started":"2022-06-02T14:49:52.705401Z","shell.execute_reply":"2022-06-02T14:49:52.705433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2 = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.706684Z","iopub.status.idle":"2022-06-02T14:49:52.707075Z","shell.execute_reply.started":"2022-06-02T14:49:52.706884Z","shell.execute_reply":"2022-06-02T14:49:52.706903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2['ID_code'] = df_test_ids.copy()\nsubmission_2['target'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.708078Z","iopub.status.idle":"2022-06-02T14:49:52.708543Z","shell.execute_reply.started":"2022-06-02T14:49:52.708287Z","shell.execute_reply":"2022-06-02T14:49:52.708306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.709601Z","iopub.status.idle":"2022-06-02T14:49:52.710018Z","shell.execute_reply.started":"2022-06-02T14:49:52.709818Z","shell.execute_reply":"2022-06-02T14:49:52.709847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.to_csv('final_submission_tuned_weighted_9.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.712021Z","iopub.status.idle":"2022-06-02T14:49:52.712488Z","shell.execute_reply.started":"2022-06-02T14:49:52.712244Z","shell.execute_reply":"2022-06-02T14:49:52.712275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The model results on kaggle were:\n\n#### Score: 0.80703\n\n#### Public score: 0.81134","metadata":{}},{"cell_type":"code","source":"submission_score = 0.80703\nsubmission_public_score = 0.81134","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.714568Z","iopub.status.idle":"2022-06-02T14:49:52.71498Z","shell.execute_reply.started":"2022-06-02T14:49:52.714789Z","shell.execute_reply":"2022-06-02T14:49:52.714809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding this results to the df_submission dataframe, for further comparison between models\n\ndf_submissions.loc['Tuned Weighted Model (XGBoost) - weight 9)', :] = [submission_score,\n                                                                       submission_public_score]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.716135Z","iopub.status.idle":"2022-06-02T14:49:52.716568Z","shell.execute_reply.started":"2022-06-02T14:49:52.716335Z","shell.execute_reply":"2022-06-02T14:49:52.716355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submissions","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.718228Z","iopub.status.idle":"2022-06-02T14:49:52.718677Z","shell.execute_reply.started":"2022-06-02T14:49:52.718475Z","shell.execute_reply":"2022-06-02T14:49:52.718497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we finally obtained a better performance, scoring about ~81% on the kaggle submission platform.","metadata":{}},{"cell_type":"markdown","source":"#### After a few attempts and submissions modifying the scale_pos_weight hyperparameter to check If there's any number that has a better performance, we got to the following results:","metadata":{}},{"cell_type":"code","source":"# weight 11\n\nsubmission_score_11 = 0.80956\n\nsubmission_public_score_11 = 0.81494\n\n# weight 12\n\nsubmission_score_12 = 0.81040\n\nsubmission_public_score_12 = 0.81520\n\n# weight 13\n\nsubmission_score_13 = 0.80975\n\nsubmission_public_score_13 = 0.81488\n\n# weight 14\n\nsubmission_score_14 = 0.80734\n\nsubmission_public_score_14 = 0.81356","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.71993Z","iopub.status.idle":"2022-06-02T14:49:52.720354Z","shell.execute_reply.started":"2022-06-02T14:49:52.72014Z","shell.execute_reply":"2022-06-02T14:49:52.72016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding this results to the df_submission dataframe, for further comparison between models\n\ndf_submissions.loc['Tuned Weighted Model (XGBoost) - weight 11)', :] = [submission_score_11,\n                                                                        submission_public_score_11]\n\ndf_submissions.loc['Tuned Weighted Model (XGBoost) - weight 12)', :] = [submission_score_12,\n                                                                        submission_public_score_12]\n\ndf_submissions.loc['Tuned Weighted Model (XGBoost) - weight 13)', :] = [submission_score_13,\n                                                                        submission_public_score_13]\n\ndf_submissions.loc['Tuned Weighted Model (XGBoost) - weight 14)', :] = [submission_score_14,\n                                                                        submission_public_score_14]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.721983Z","iopub.status.idle":"2022-06-02T14:49:52.722438Z","shell.execute_reply.started":"2022-06-02T14:49:52.722204Z","shell.execute_reply":"2022-06-02T14:49:52.722224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submissions","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.723839Z","iopub.status.idle":"2022-06-02T14:49:52.724264Z","shell.execute_reply.started":"2022-06-02T14:49:52.724056Z","shell.execute_reply":"2022-06-02T14:49:52.724077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see on the dataframe above, the best performance was obtained using 12 as weighting factor.\n\n#### The next step will be trying to improve our model by doing some feature engineering.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-eight\"></a>\n# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"#### It's pretty well documented amongst top kagglers and on the best kernels of this competition that this dataset has what is called \"magic numbers\", which is basically counting the number of times a value occurs in each variable. Thus, we'll add a new \"magic feature\" to each variable. A nice explanation about this magic features can be seen [here](https://www.kaggle.com/code/felipemello/step-by-step-guide-to-the-magic-lb-0-922) and [here](https://www.kaggle.com/code/jganzabal/trying-to-understand-why-magic-counts-works).","metadata":{}},{"cell_type":"markdown","source":"#### Before starting the process of feature engineering, there's another relevant aspect about this dataset that must be explained. Many kagglers found out that the test set consists of real samples as well as synthetic samples. In other words, we'll check If the feature value of a sample is unique. If a sample has at least one unique feature value, then It must be a real sample, and If It has no unique values It is considered to be a synthetic sample. Top kagglers found out that counting only the real samples of the test set raised the model scores.\n\n#### A good explanation about this topic can be found [here](https://www.kaggle.com/code/yag320/list-of-fake-samples-and-public-private-lb-split/notebook).","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-one\"></a>\n## Identifying magic numbers","metadata":{}},{"cell_type":"markdown","source":"#### The next step will be spliting the real and fake test data samples, so then we can properly count the variables unique numbers.","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')\ndf_train = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.726027Z","iopub.status.idle":"2022-06-02T14:49:52.726789Z","shell.execute_reply.started":"2022-06-02T14:49:52.726469Z","shell.execute_reply":"2022-06-02T14:49:52.726502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df_train.copy()\ntest = df_test.copy()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.728697Z","iopub.status.idle":"2022-06-02T14:49:52.729404Z","shell.execute_reply.started":"2022-06-02T14:49:52.729051Z","shell.execute_reply":"2022-06-02T14:49:52.729083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a variable for column names\n\ncol_names = [f'var_{i}' for i in range(200)]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.731997Z","iopub.status.idle":"2022-06-02T14:49:52.732553Z","shell.execute_reply.started":"2022-06-02T14:49:52.732304Z","shell.execute_reply":"2022-06-02T14:49:52.732328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identifying unique values on the test set\n\nfor col in col_names:\n    count = test[col].value_counts()\n    uniques = count.index[count == 1]\n    test[col + \"_u\"] = test[col].isin(uniques)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.733885Z","iopub.status.idle":"2022-06-02T14:49:52.734321Z","shell.execute_reply.started":"2022-06-02T14:49:52.734107Z","shell.execute_reply":"2022-06-02T14:49:52.734128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a column that tells if a sample has at least one unique value\n\ntest['has_unique'] = test[[col + '_u' for col in col_names]].any(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.735136Z","iopub.status.idle":"2022-06-02T14:49:52.73558Z","shell.execute_reply.started":"2022-06-02T14:49:52.735369Z","shell.execute_reply":"2022-06-02T14:49:52.735408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating variables for the real and fake test samples\n\nreal_test = test.loc[test['has_unique'], ['ID_code'] + col_names]\nfake_test = test.loc[~test['has_unique'], ['ID_code'] + col_names]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.736907Z","iopub.status.idle":"2022-06-02T14:49:52.7373Z","shell.execute_reply.started":"2022-06-02T14:49:52.737099Z","shell.execute_reply":"2022-06-02T14:49:52.737118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking how many real and fake samples were identified\n\nreal_test.shape, fake_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.738372Z","iopub.status.idle":"2022-06-02T14:49:52.738822Z","shell.execute_reply.started":"2022-06-02T14:49:52.73862Z","shell.execute_reply":"2022-06-02T14:49:52.738643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The numbers above are quite interesting, because they show that half of the test set consists of synthetic samples.","metadata":{}},{"cell_type":"code","source":"# Merging the original training set to the real samples extracted from the test set\n\ntrain_and_test = pd.concat([train, real_test], axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.739738Z","iopub.status.idle":"2022-06-02T14:49:52.740116Z","shell.execute_reply.started":"2022-06-02T14:49:52.739929Z","shell.execute_reply":"2022-06-02T14:49:52.739948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df_train.copy()\ntest_df = df_test.copy()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.740884Z","iopub.status.idle":"2022-06-02T14:49:52.744675Z","shell.execute_reply.started":"2022-06-02T14:49:52.744442Z","shell.execute_reply":"2022-06-02T14:49:52.744467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating new columns with the unique values count for each variable\n\nfor feat in ['var_' + str(x) for x in range(200)]:\n    count_values = train_and_test.groupby(feat)[feat].count()\n    train_df['new_' + feat] = count_values.loc[train_df[feat]].values\n    test_df['new_' + feat] = count_values.loc[test_df[feat]].values","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.745809Z","iopub.status.idle":"2022-06-02T14:49:52.746204Z","shell.execute_reply.started":"2022-06-02T14:49:52.746003Z","shell.execute_reply":"2022-06-02T14:49:52.746023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the ID_code column\n\ntest_df_final = test_df.drop('ID_code', axis=1).copy()\ntest_df_final.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.747007Z","iopub.status.idle":"2022-06-02T14:49:52.747415Z","shell.execute_reply.started":"2022-06-02T14:49:52.747204Z","shell.execute_reply":"2022-06-02T14:49:52.747223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping ID_code and target columns\n\ntrain_df_final = train_df.drop(['ID_code', 'target'], axis=1).copy()\ntrain_df_final.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.749252Z","iopub.status.idle":"2022-06-02T14:49:52.749785Z","shell.execute_reply.started":"2022-06-02T14:49:52.749564Z","shell.execute_reply":"2022-06-02T14:49:52.749588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df_final.copy()\ny = train_df.target.copy()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.751511Z","iopub.status.idle":"2022-06-02T14:49:52.752314Z","shell.execute_reply.started":"2022-06-02T14:49:52.752097Z","shell.execute_reply":"2022-06-02T14:49:52.752119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the training dataset into train and test subsets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.753621Z","iopub.status.idle":"2022-06-02T14:49:52.754421Z","shell.execute_reply.started":"2022-06-02T14:49:52.754206Z","shell.execute_reply":"2022-06-02T14:49:52.754227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-ten\"></a>\n# Training the best model on the magic numbers dataset","metadata":{}},{"cell_type":"code","source":"# creating a 5 fold stratifiedkfold cross-validation object\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.755581Z","iopub.status.idle":"2022-06-02T14:49:52.756303Z","shell.execute_reply.started":"2022-06-02T14:49:52.756105Z","shell.execute_reply":"2022-06-02T14:49:52.756126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a tuned XGBoost model and setting scale_pos_weight to 12\n\nmodel_xgb =  XGBClassifier(max_depth=2,\n                           colsample_bytree=0.7,\n                           n_estimators=20000,\n                           learning_rate=0.02,\n                           scale_pos_weight=12,\n                           objective='binary:logistic', \n                           verbosity =1,\n                           eval_metric  = 'auc',\n                           tree_method='gpu_hist',\n                           n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.757741Z","iopub.status.idle":"2022-06-02T14:49:52.758725Z","shell.execute_reply.started":"2022-06-02T14:49:52.75852Z","shell.execute_reply":"2022-06-02T14:49:52.758541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing the model using 5-fold cross-validation\n\nscores = cross_val_score(model_xgb, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.759944Z","iopub.status.idle":"2022-06-02T14:49:52.760907Z","shell.execute_reply.started":"2022-06-02T14:49:52.760683Z","shell.execute_reply":"2022-06-02T14:49:52.760706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('5-fold Cross validation Roc-auc and std: {:.2f} ({:.4f})'.format(np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.762091Z","iopub.status.idle":"2022-06-02T14:49:52.762892Z","shell.execute_reply.started":"2022-06-02T14:49:52.762671Z","shell.execute_reply":"2022-06-02T14:49:52.762694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a variable for the tuned weighted model cross validation roc_auc\n\ntuned_scale_weight_roc_auc = round(np.mean(scores), 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.764202Z","iopub.status.idle":"2022-06-02T14:49:52.764875Z","shell.execute_reply.started":"2022-06-02T14:49:52.764666Z","shell.execute_reply":"2022-06-02T14:49:52.764687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model\n\nmodel_xgb.fit(X_train, y_train, eval_metric=f1_eval)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.765861Z","iopub.status.idle":"2022-06-02T14:49:52.766635Z","shell.execute_reply.started":"2022-06-02T14:49:52.766426Z","shell.execute_reply":"2022-06-02T14:49:52.766452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting the model on the test set (X_test)\n\ny_pred = model_xgb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.768136Z","iopub.status.idle":"2022-06-02T14:49:52.769094Z","shell.execute_reply.started":"2022-06-02T14:49:52.768886Z","shell.execute_reply":"2022-06-02T14:49:52.768908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.770272Z","iopub.status.idle":"2022-06-02T14:49:52.771171Z","shell.execute_reply.started":"2022-06-02T14:49:52.770951Z","shell.execute_reply":"2022-06-02T14:49:52.770973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see, the model performance had a slight improvement when we minimized the impact of class imbalance. Now we should check the confusion matrix.","metadata":{}},{"cell_type":"code","source":"# Creating a variable for the classification report\n\nreport = classification_report(y_test, y_pred, output_dict=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.772346Z","iopub.status.idle":"2022-06-02T14:49:52.773273Z","shell.execute_reply.started":"2022-06-02T14:49:52.773055Z","shell.execute_reply":"2022-06-02T14:49:52.773077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating variables for precision, recall, f1score, accuracy, roc_auc and class1 f1score\n\ntuned_scale_weight_precision = round(report['macro avg']['precision'], 4)\ntuned_scale_weight_recall = round(report['macro avg']['recall'], 4)\ntuned_scale_weight_f1score = round(report['macro avg']['f1-score'], 4)\ntuned_scale_weight_accuracy = round(report['accuracy'], 4)\ntuned_scale_weight_roc_auc = round(roc_auc_score(y_test, y_pred), 4)\ntuned_scale_weight_class1_f1score = round(report['1']['f1-score'], 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.774511Z","iopub.status.idle":"2022-06-02T14:49:52.775506Z","shell.execute_reply.started":"2022-06-02T14:49:52.775271Z","shell.execute_reply":"2022-06-02T14:49:52.775294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking confusion matrix\n\ntarget_names = ['0', '1']\n\nplt.figure(figsize=(6, 5))\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_pred),\n            annot=True, fmt='g', ax=ax)\n\nax.set_xlabel('Predicted values', fontsize=14)\nax.set_ylabel('Expected values', fontsize=14)\nax.set_title('Confusion Matrix', fontsize=14)\n\nax.xaxis.set_ticklabels(target_names, fontsize=14)\nax.yaxis.set_ticklabels(target_names, fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.776405Z","iopub.status.idle":"2022-06-02T14:49:52.777452Z","shell.execute_reply.started":"2022-06-02T14:49:52.777218Z","shell.execute_reply":"2022-06-02T14:49:52.777241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The confusion matrix above shows that there was a significant improvement on the class 1 true positives.","metadata":{}},{"cell_type":"code","source":"df_performance.loc['Tuned Weighted XGBoost (Magic Numbers)', :] = [tuned_scale_weight_precision,\n                                                                   tuned_scale_weight_recall,\n                                                                   tuned_scale_weight_f1score,\n                                                                   tuned_scale_weight_accuracy,\n                                                                   tuned_scale_weight_roc_auc,\n                                                                   tuned_scale_weight_class1_f1score,\n                                                                   tuned_scale_weight_roc_auc]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.778332Z","iopub.status.idle":"2022-06-02T14:49:52.779372Z","shell.execute_reply.started":"2022-06-02T14:49:52.779143Z","shell.execute_reply":"2022-06-02T14:49:52.779166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_performance","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.780454Z","iopub.status.idle":"2022-06-02T14:49:52.780856Z","shell.execute_reply.started":"2022-06-02T14:49:52.780661Z","shell.execute_reply":"2022-06-02T14:49:52.780681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The comparison between models confirms that the magic numbers really play an important role in improving the overall performance of our classification models.","metadata":{}},{"cell_type":"markdown","source":"#### Now we'll do another submission on kaggle and check if there's any improvement on the overall scores.","metadata":{}},{"cell_type":"markdown","source":"## Rebuilding the Tuned Weighted XGBoost model on the whole dataset and submitting the results to kaggle","metadata":{}},{"cell_type":"code","source":"# Creating a tuned XGBoost model and setting scale_pos_weight to 12\n\nmodel_xgb =  XGBClassifier(max_depth=2,\n                           colsample_bytree=0.7,\n                           n_estimators=20000,\n                           scale_pos_weight = 15,\n                           learning_rate=0.02,\n                           objective='binary:logistic', \n                           verbosity =1,\n                           eval_metric  = 'auc',\n                           tree_method='gpu_hist',\n                           n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.782127Z","iopub.status.idle":"2022-06-02T14:49:52.782553Z","shell.execute_reply.started":"2022-06-02T14:49:52.782332Z","shell.execute_reply":"2022-06-02T14:49:52.782353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model on the entire dataset\n\nmodel_xgb.fit(X, y, eval_metric='auc')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.783763Z","iopub.status.idle":"2022-06-02T14:49:52.784211Z","shell.execute_reply.started":"2022-06-02T14:49:52.784006Z","shell.execute_reply":"2022-06-02T14:49:52.784031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_xgb.predict(test_df_final)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.785314Z","iopub.status.idle":"2022-06-02T14:49:52.78573Z","shell.execute_reply.started":"2022-06-02T14:49:52.785539Z","shell.execute_reply":"2022-06-02T14:49:52.785558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2 = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.787027Z","iopub.status.idle":"2022-06-02T14:49:52.787446Z","shell.execute_reply.started":"2022-06-02T14:49:52.787222Z","shell.execute_reply":"2022-06-02T14:49:52.787241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2['ID_code'] = df_test_ids.copy()\nsubmission_2['target'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.788562Z","iopub.status.idle":"2022-06-02T14:49:52.788957Z","shell.execute_reply.started":"2022-06-02T14:49:52.788759Z","shell.execute_reply":"2022-06-02T14:49:52.788779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.789757Z","iopub.status.idle":"2022-06-02T14:49:52.790139Z","shell.execute_reply.started":"2022-06-02T14:49:52.789955Z","shell.execute_reply":"2022-06-02T14:49:52.789974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.to_csv('final_submission_tuned_weighted_13_magic_numbers_child.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.79104Z","iopub.status.idle":"2022-06-02T14:49:52.791448Z","shell.execute_reply.started":"2022-06-02T14:49:52.791231Z","shell.execute_reply":"2022-06-02T14:49:52.791257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The model results on kaggle were:\n\n#### Score: 0.82466\n\n#### Public score: 0.83206","metadata":{}},{"cell_type":"markdown","source":"#### Now we'll do a few tests, changing the scale_pos_weight hyperparameter and checking the scores on the test data.","metadata":{}},{"cell_type":"code","source":"# weight 9\n\nsubmission_score_9 = 0.82216\n\nsubmission_public_score_9 = 0.82980\n\n# weight 11\n\nsubmission_score_11 = 0.82359\n\nsubmission_public_score_11 = 0.83247\n\n# weight 12\n\nsubmission_score_12 = 0.82466\n\nsubmission_public_score_12 = 0.83206\n\n# weight 13\n\nsubmission_score_13 = 0.82448\n\nsubmission_public_score_13 = 0.83250\n\n# weight 14\n\nsubmission_score_14 = 0.82533\n\nsubmission_public_score_14 = 0.83196\n\n# weight 15\n\nsubmission_score_15 = 0.82465\n\nsubmission_public_score_15 = 0.83010","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.792317Z","iopub.status.idle":"2022-06-02T14:49:52.792724Z","shell.execute_reply.started":"2022-06-02T14:49:52.792539Z","shell.execute_reply":"2022-06-02T14:49:52.792558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding this results to the df_submission dataframe, for further comparison between models\n\ndf_submissions.loc['Magic Numbers (XGBoost) - weight 9)', :] = [submission_score_9,\n                                                                submission_public_score_9]\n\ndf_submissions.loc['Magic Numbers (XGBoost) - weight 11)', :] = [submission_score_11,\n                                                                 submission_public_score_11]\n\ndf_submissions.loc['Magic Numbers (XGBoost) - weight 12)', :] = [submission_score_12,\n                                                                 submission_public_score_12]\n\ndf_submissions.loc['Magic Numbers (XGBoost) - weight 13)', :] = [submission_score_13,\n                                                                 submission_public_score_13]\n\ndf_submissions.loc['Magic Numbers (XGBoost) - weight 14)', :] = [submission_score_14,\n                                                                 submission_public_score_14]\n\ndf_submissions.loc['Magic Numbers (XGBoost) - weight 15)', :] = [submission_score_15,\n                                                                 submission_public_score_15]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.793994Z","iopub.status.idle":"2022-06-02T14:49:52.794425Z","shell.execute_reply.started":"2022-06-02T14:49:52.7942Z","shell.execute_reply":"2022-06-02T14:49:52.794222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submissions","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.79762Z","iopub.status.idle":"2022-06-02T14:49:52.798527Z","shell.execute_reply.started":"2022-06-02T14:49:52.798256Z","shell.execute_reply":"2022-06-02T14:49:52.798281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see, setting the scale_pos_weight hyperparameter to 13 is the best option to improve our model performance on the test data.","metadata":{}},{"cell_type":"markdown","source":"#### The next step will be trying to isolate the variables and training 200 different models, which means that each pair of variables (var_1 + new_var_1, var_2 + new_var_2, and so on) will work as a single model. At the end, we'll try to ensemble the 200 different models using a voting ensemble methodology. This idea came from the fact that the variables are not correlated, something we noticed during the EDA process, and It was inspired by this [kernel](https://www.kaggle.com/code/cdeotte/200-magical-models-santander-0-920).","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-eleven\"></a>\n# Training and ensembling 200 different models","metadata":{}},{"cell_type":"code","source":"# The code below loops over all features and uses each one of them to train a different model\n\ntrain_probas4 = pd.DataFrame()\ntest_probas4 = pd.DataFrame()\n\ntrain_accuracies4 = []\ntest_accuracies4 = []\n\ntrain_preds4 = pd.DataFrame()\ntest_preds4 = pd.DataFrame()\n\nmodels_dic4 = {}\nmodels_list4 = list()\n\nfor i in range(200): # loop over all features\n    features  = [X_train.columns[i], 'new_'+X_train.columns[i]] # selects a pair of features\n    #features  = X_train.columns[i]\n    print('')\n    print('*'*24)\n    print(features)\n    print('*'*24)\n    print('')\n    \n    model_xgb4 =  XGBClassifier(max_depth=2,\n                              colsample_bytree=0.7,\n                              n_estimators=20000,\n                              scale_pos_weight = 9,\n                              learning_rate=0.02,\n                              objective='binary:logistic', \n                              verbosity =1,\n                              eval_metric  = 'auc',\n                              tree_method='gpu_hist',\n                              n_jobs=-1)\n\n    model_xgb4.fit(X_train[features], y_train, eval_metric=f1_eval)\n        \n    train_preds4[X_train.columns[i]] = model_xgb4.predict(X_train[features])\n    train_probas4[X_train.columns[i]] = model_xgb4.predict_proba(X_train[features])[:, 0]\n    train_accuracies4.append(accuracy_score(y_train, train_preds4[X_train.columns[i]]))\n    \n    test_preds4[X_train.columns[i]] = model_xgb4.predict(X_test[features])\n    test_probas4[X_train.columns[i]] = model_xgb4.predict_proba(X_test[features])[:, 0]\n    test_accuracies4.append(accuracy_score(y_test, test_preds4[X_test.columns[i]]))\n    \n    models_dic4['model_'+str(i)] = model_xgb4\n    models_list4.append(('model_'+str(i), model_xgb4))\n    \n    print(accuracy_score(y_test, test_preds4[X_train.columns[i]]))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.799713Z","iopub.status.idle":"2022-06-02T14:49:52.800132Z","shell.execute_reply.started":"2022-06-02T14:49:52.79993Z","shell.execute_reply":"2022-06-02T14:49:52.799952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the models to pickle files\n\nfor i in range(200):\n    model_name = 'model_'+str(i)\n    pasta = r\"C:\\Users\\U4R9\\OneDrive - PETROBRAS\\Repositorio\\Desafio_Kaggle_BR\\Modelx_xgb_magic_numbers\"+'\\\\'\n    filename = pasta+model_name+'.sav'\n    pickle.dump(models_dic4[model_name], open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.801194Z","iopub.status.idle":"2022-06-02T14:49:52.80168Z","shell.execute_reply.started":"2022-06-02T14:49:52.801441Z","shell.execute_reply":"2022-06-02T14:49:52.801463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the test and train predictions to csv files\n\ntest_preds4.to_csv('test_preds4.csv')\ntrain_preds4.to_csv('train_preds4.csv')\ntrain_probas4.to_csv('train_probas4.csv')\ntest_probas4.to_csv('test_probas4.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.803143Z","iopub.status.idle":"2022-06-02T14:49:52.803898Z","shell.execute_reply.started":"2022-06-02T14:49:52.803689Z","shell.execute_reply":"2022-06-02T14:49:52.803711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now that we've built 200 different models using each of the variables of the dataset, we'll need to ensemble the predictions of this models. The first attempt will be doing a weighted average of the models predictions, giving more weight to the predictions that have more probabilities of being correct, which can be veryfied on the test_probas4 dataframe. This will be an iterative process of checking each one of the instances (rows) of both test_preds4 and test_probas4 datasets.","metadata":{}},{"cell_type":"code","source":"# Iterating through test_preds4 and test_probas4 dataframes\n# Higher weights are given to the higher probabilities\n\nfinal_preds = []\nfinal_probas = []\n\nfor i in range(len(test_preds4)):\n    weights = []\n    for j in test_probas4.iloc[i]:\n        if j >= 0.8:\n            weights.append(2.2)\n        elif 0.7 <= j <0.8:\n            weights.append(1.9)\n        elif 0.6 <= j <0.7:\n            weights.append(1.5)\n        elif 0.5 <= j <0.6:\n            weights.append(1)\n        elif 0.4 <= j <0.5:\n            weights.append(1)\n        elif 0.3 <= j <0.4:\n            weights.append(1.5) \n        elif 0.2 <= j <0.3:\n            weights.append(1.9) \n        else:\n            weights.append(2.2)\n            \n    prediction_proba = sum(test_probas4.iloc[i] * weights) / sum(weights)\n    final_probas.append(prediction_proba)\n    if prediction_proba > 0.5:\n        final_preds.append(0)\n    else:\n        final_preds.append(1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.805331Z","iopub.status.idle":"2022-06-02T14:49:52.80617Z","shell.execute_reply.started":"2022-06-02T14:49:52.805947Z","shell.execute_reply":"2022-06-02T14:49:52.805971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a variable for the ensemble roc_auc score\n\nensembling_roc_auc = round(roc_auc_score(y_test, final_preds), 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.808058Z","iopub.status.idle":"2022-06-02T14:49:52.809079Z","shell.execute_reply.started":"2022-06-02T14:49:52.80885Z","shell.execute_reply":"2022-06-02T14:49:52.808874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, final_preds))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.810285Z","iopub.status.idle":"2022-06-02T14:49:52.811204Z","shell.execute_reply.started":"2022-06-02T14:49:52.810981Z","shell.execute_reply":"2022-06-02T14:49:52.811005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a variable for the classification report\n\nreport = classification_report(y_test, final_preds, output_dict=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.812462Z","iopub.status.idle":"2022-06-02T14:49:52.813289Z","shell.execute_reply.started":"2022-06-02T14:49:52.813066Z","shell.execute_reply":"2022-06-02T14:49:52.813089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating variables for precision, recall, f1score, accuracy, roc_auc and class1 f1score\n\nensembling_precision = round(report['macro avg']['precision'], 4)\nensembling_recall = round(report['macro avg']['recall'], 4)\nensembling_f1score = round(report['macro avg']['f1-score'], 4)\nensembling_accuracy = round(report['accuracy'], 4)\nensembling_roc_auc = round(roc_auc_score(y_test, final_preds), 4)\nensembling_class1_f1score = round(report['1']['f1-score'], 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.81475Z","iopub.status.idle":"2022-06-02T14:49:52.81515Z","shell.execute_reply.started":"2022-06-02T14:49:52.814957Z","shell.execute_reply":"2022-06-02T14:49:52.814977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking confusion matrix\n\ntarget_names = ['0', '1']\n\nplt.figure(figsize=(6, 5))\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, final_preds),\n            annot=True, fmt='g', ax=ax)\n\nax.set_xlabel('Predicted values', fontsize=14)\nax.set_ylabel('Expected values', fontsize=14)\nax.set_title('Confusion Matrix', fontsize=14)\n\nax.xaxis.set_ticklabels(target_names, fontsize=14)\nax.yaxis.set_ticklabels(target_names, fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.817012Z","iopub.status.idle":"2022-06-02T14:49:52.817861Z","shell.execute_reply.started":"2022-06-02T14:49:52.817538Z","shell.execute_reply":"2022-06-02T14:49:52.817563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### It seems that the performance didn't improve at all, based on the confusion matrix predictions.","metadata":{}},{"cell_type":"code","source":"df_performance.loc['Ensemble predictions', :] = [ensembling_precision,\n                                                 ensembling_recall,\n                                                 ensembling_f1score,\n                                                 ensembling_accuracy,\n                                                 ensembling_roc_auc,\n                                                 ensembling_class1_f1score,\n                                                 ensembling_roc_auc]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.8193Z","iopub.status.idle":"2022-06-02T14:49:52.819746Z","shell.execute_reply.started":"2022-06-02T14:49:52.819549Z","shell.execute_reply":"2022-06-02T14:49:52.819571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_performance","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.820941Z","iopub.status.idle":"2022-06-02T14:49:52.821353Z","shell.execute_reply.started":"2022-06-02T14:49:52.821156Z","shell.execute_reply":"2022-06-02T14:49:52.821177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we'll do another submission on kaggle and check if there's any improvement on the overall scores.","metadata":{}},{"cell_type":"markdown","source":"## Retraining the 200 different models on the whole dataset and submitting the results to kaggle","metadata":{}},{"cell_type":"code","source":"train_probas6 = pd.DataFrame()\ntrain_accuracies6 = []\ntrain_preds6 = pd.DataFrame()\n\nmodels_dic6 = {}\nmodels_list6 = list()\n\nfor i in range(200): # loop over all features\n    features  = [X.columns[i], 'new_'+X.columns[i]]\n    #features  = X_train.columns[i]\n    print('')\n    print('*'*24)\n    print(features)\n    print('*'*24)\n    print('')\n    \n    model_xgb6 =  XGBClassifier(max_depth=2,\n                              colsample_bytree=0.7,\n                              n_estimators=20000,\n                              scale_pos_weight = 9,\n                              learning_rate=0.02,\n                              objective='binary:logistic', \n                              verbosity =1,\n                              eval_metric  = 'auc',\n                              tree_method='gpu_hist',\n                              n_jobs=-1)\n    \n    model_xgb6.fit(X[features], y, eval_metric=f1_eval)\n        \n    train_preds6[X.columns[i]] = model_xgb6.predict(X[features])\n    train_probas6[X.columns[i]] = model_xgb6.predict_proba(X[features])[:, 0]\n    train_accuracies6.append(accuracy_score(y, train_preds6[X.columns[i]]))\n    \n    models_dic6['model_'+str(i)] = model_xgb6\n    models_list6.append(('model_'+str(i), model_xgb6))\n    \n    print(accuracy_score(y, train_preds6[X.columns[i]]))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.82356Z","iopub.status.idle":"2022-06-02T14:49:52.82396Z","shell.execute_reply.started":"2022-06-02T14:49:52.823769Z","shell.execute_reply":"2022-06-02T14:49:52.82379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterating through test_preds4 and test_probas4 dataframes\n# Higher weights are given to the higher probabilities\n\nfinal_preds = []\nfinal_probas = []\n\nfor i in range(len(train_preds6)):\n    weights = []\n    for j in train_probas6.iloc[i]:\n        if j >= 0.8:\n            weights.append(2.2)\n        elif 0.7 <= j <0.8:\n            weights.append(1.9)\n        elif 0.6 <= j <0.7:\n            weights.append(1.5)\n        elif 0.5 <= j <0.6:\n            weights.append(1)\n        elif 0.4 <= j <0.5:\n            weights.append(1)\n        elif 0.3 <= j <0.4:\n            weights.append(1.5) \n        elif 0.2 <= j <0.3:\n            weights.append(1.9) \n        else:\n            weights.append(2.2)\n            \n    prediction_proba = sum(train_probas6.iloc[i] * weights) / sum(weights)\n    final_probas.append(prediction_proba)\n    if prediction_proba > 0.5:\n        final_preds.append(0)\n    else:\n        final_preds.append(1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.826003Z","iopub.status.idle":"2022-06-02T14:49:52.826854Z","shell.execute_reply.started":"2022-06-02T14:49:52.826614Z","shell.execute_reply":"2022-06-02T14:49:52.826646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2 = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.828048Z","iopub.status.idle":"2022-06-02T14:49:52.828882Z","shell.execute_reply.started":"2022-06-02T14:49:52.828661Z","shell.execute_reply":"2022-06-02T14:49:52.828684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2['ID_code'] = df_test_ids.copy()\nsubmission_2['target'] = final_preds","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.830182Z","iopub.status.idle":"2022-06-02T14:49:52.831114Z","shell.execute_reply.started":"2022-06-02T14:49:52.830893Z","shell.execute_reply":"2022-06-02T14:49:52.830917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.832273Z","iopub.status.idle":"2022-06-02T14:49:52.833089Z","shell.execute_reply.started":"2022-06-02T14:49:52.832866Z","shell.execute_reply":"2022-06-02T14:49:52.832889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.to_csv('final_submission_ensemble_magic.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.834241Z","iopub.status.idle":"2022-06-02T14:49:52.834945Z","shell.execute_reply.started":"2022-06-02T14:49:52.834729Z","shell.execute_reply":"2022-06-02T14:49:52.834751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The model results on kaggle were:\n\n#### Score: 0.50004\n\n#### Public score: 0.49541","metadata":{}},{"cell_type":"markdown","source":"#### Well, that's very disappointing. Even though the idea of using each variable to train a different model seems promising, the model didn't perform the way we expected. This could be related to a poor choice of algorithm (XGBoost) that might not be suited to this kind of problem, or could be due to a poor choice of weights, during the final predictions calculations.","metadata":{}},{"cell_type":"code","source":"ensemble_submission_score = 0.50004\nensemble_submission_public_score = 0.49541","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.83628Z","iopub.status.idle":"2022-06-02T14:49:52.836764Z","shell.execute_reply.started":"2022-06-02T14:49:52.836548Z","shell.execute_reply":"2022-06-02T14:49:52.836568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding this results to the df_submission dataframe, for further comparison between models\n\ndf_submissions.loc['Ensemble 200 models', :] = [ensemble_submission_score,\n                                                ensemble_submission_public_score]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.837785Z","iopub.status.idle":"2022-06-02T14:49:52.83817Z","shell.execute_reply.started":"2022-06-02T14:49:52.837984Z","shell.execute_reply":"2022-06-02T14:49:52.838003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submissions","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.840202Z","iopub.status.idle":"2022-06-02T14:49:52.840856Z","shell.execute_reply.started":"2022-06-02T14:49:52.840543Z","shell.execute_reply":"2022-06-02T14:49:52.840576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The final attemp will be perform the voting ensemble using a VotingClassifier function.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-twelve\"></a>\n# Ensemble 200 models using VotingClassifier","metadata":{}},{"cell_type":"code","source":"# Using test accuracies as weights\n\nweights = []\nfor i in test_accuracies4:\n    if i >= 0.6:\n        weights.append(4)\n    elif 0.5 <= i <0.6:\n        weights.append(2)\n    else:\n        weights.append(1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.84266Z","iopub.status.idle":"2022-06-02T14:49:52.843261Z","shell.execute_reply.started":"2022-06-02T14:49:52.842955Z","shell.execute_reply":"2022-06-02T14:49:52.842986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a votingclassifier object and fitting it to X_train and y_train\n\neclf = VotingClassifier(estimators=models_list4, voting='soft', weights=weights)\neclf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.845656Z","iopub.status.idle":"2022-06-02T14:49:52.846087Z","shell.execute_reply.started":"2022-06-02T14:49:52.845892Z","shell.execute_reply":"2022-06-02T14:49:52.845913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting on X_test\n\ny_val_pred_weighted = eclf.predict_proba(X_test)\ny_pred_voting_weighted = eclf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.847302Z","iopub.status.idle":"2022-06-02T14:49:52.847733Z","shell.execute_reply.started":"2022-06-02T14:49:52.84754Z","shell.execute_reply":"2022-06-02T14:49:52.84756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a variable for the votingclassifier roc_auc score\n\nensembling_roc_auc = round(roc_auc_score(y_test, y_pred_voting_weighted), 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.848641Z","iopub.status.idle":"2022-06-02T14:49:52.849023Z","shell.execute_reply.started":"2022-06-02T14:49:52.848836Z","shell.execute_reply":"2022-06-02T14:49:52.848856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_voting_weighted))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.851168Z","iopub.status.idle":"2022-06-02T14:49:52.851993Z","shell.execute_reply.started":"2022-06-02T14:49:52.851673Z","shell.execute_reply":"2022-06-02T14:49:52.851713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a variable for the classification report\n\nreport = classification_report(y_test, y_pred_voting_weighted, output_dict=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.85353Z","iopub.status.idle":"2022-06-02T14:49:52.854683Z","shell.execute_reply.started":"2022-06-02T14:49:52.854455Z","shell.execute_reply":"2022-06-02T14:49:52.854481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating variables for precision, recall, f1score, accuracy, roc_auc and class1 f1score\n\nvoting_precision = round(report['macro avg']['precision'], 4)\nvoting_recall = round(report['macro avg']['recall'], 4)\nvoting_f1score = round(report['macro avg']['f1-score'], 4)\nvoting_accuracy = round(report['accuracy'], 4)\nvoting_roc_auc = round(roc_auc_score(y_test, y_pred_voting_weighted), 4)\nvoting_class1_f1score = round(report['1']['f1-score'], 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.855723Z","iopub.status.idle":"2022-06-02T14:49:52.856101Z","shell.execute_reply.started":"2022-06-02T14:49:52.855915Z","shell.execute_reply":"2022-06-02T14:49:52.855933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking confusion matrix\n\ntarget_names = ['0', '1']\n\nplt.figure(figsize=(6, 5))\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_pred_voting_weighted),\n            annot=True, fmt='g', ax=ax)\n\nax.set_xlabel('Predicted values', fontsize=14)\nax.set_ylabel('Expected values', fontsize=14)\nax.set_title('Confusion Matrix', fontsize=14)\n\nax.xaxis.set_ticklabels(target_names, fontsize=14)\nax.yaxis.set_ticklabels(target_names, fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.856859Z","iopub.status.idle":"2022-06-02T14:49:52.857227Z","shell.execute_reply.started":"2022-06-02T14:49:52.857043Z","shell.execute_reply":"2022-06-02T14:49:52.857062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_performance.loc['VotingClassifier predictions', :] = [ensembling_precision,\n                                                         ensembling_recall,\n                                                         ensembling_f1score,\n                                                         ensembling_accuracy,\n                                                         ensembling_roc_auc,\n                                                         ensembling_class1_f1score,\n                                                         ensembling_roc_auc]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.858703Z","iopub.status.idle":"2022-06-02T14:49:52.859137Z","shell.execute_reply.started":"2022-06-02T14:49:52.858935Z","shell.execute_reply":"2022-06-02T14:49:52.858954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_performance","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.861368Z","iopub.status.idle":"2022-06-02T14:49:52.861841Z","shell.execute_reply.started":"2022-06-02T14:49:52.861623Z","shell.execute_reply":"2022-06-02T14:49:52.861644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we'll do another submission on kaggle and check if there's any improvement on the overall scores.","metadata":{}},{"cell_type":"markdown","source":"## Retraining the VotingClassifier model on the whole dataset and submitting the results to kaggle","metadata":{}},{"cell_type":"code","source":"# Using train accuracies as weights\n\nweights = []\n\nfor i in train_accuracies6:\n    if i >= 0.6:\n        weights.append(4)\n    elif 0.5 <= i <0.6:\n        weights.append(2)\n    else:\n        weights.append(1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.863279Z","iopub.status.idle":"2022-06-02T14:49:52.863781Z","shell.execute_reply.started":"2022-06-02T14:49:52.863525Z","shell.execute_reply":"2022-06-02T14:49:52.863546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_probas6 = pd.DataFrame()\ntrain_accuracies6 = []\ntrain_preds6 = pd.DataFrame()\n\nmodels_dic6 = {}\nmodels_list6 = list()\n\nfor i in range(200): # loop over all features\n    features  = [X.columns[i], 'new_'+X.columns[i]]\n    #features  = X_train.columns[i]\n    print('')\n    print('*'*24)\n    print(features)\n    print('*'*24)\n    print('')\n    \n    model_xgb6 =  XGBClassifier(max_depth=2,\n                              colsample_bytree=0.7,\n                              n_estimators=20000,\n                              scale_pos_weight = 9,\n                              learning_rate=0.02,\n                              objective='binary:logistic', \n                              verbosity =1,\n                              eval_metric  = 'auc',\n                              tree_method='gpu_hist',\n                              n_jobs=-1)\n\n    model_xgb6.fit(X[features], y, eval_metric=f1_eval)\n        \n    train_preds6[X.columns[i]] = model_xgb6.predict(X[features])\n    train_probas6[X.columns[i]] = model_xgb6.predict_proba(X[features])[:, 0]\n    train_accuracies6.append(accuracy_score(y, train_preds6[X.columns[i]]))\n    \n    models_dic6['model_'+str(i)] = model_xgb6\n    models_list6.append(('model_'+str(i), model_xgb6))\n    \n    print(accuracy_score(y, train_preds6[X.columns[i]]))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.865758Z","iopub.status.idle":"2022-06-02T14:49:52.866644Z","shell.execute_reply.started":"2022-06-02T14:49:52.866303Z","shell.execute_reply":"2022-06-02T14:49:52.866336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a votingclassifier object and fitting it to X and y\n\neclf = VotingClassifier(estimators=models_list6, voting='soft', weights=weights)\neclf.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.868423Z","iopub.status.idle":"2022-06-02T14:49:52.869032Z","shell.execute_reply.started":"2022-06-02T14:49:52.868722Z","shell.execute_reply":"2022-06-02T14:49:52.868753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting on test_df_final (test set)\n\ny_val_pred_weighted = eclf.predict_proba(test_df_final)\ny_pred_voting_weighted = eclf.predict(test_df_final)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.871024Z","iopub.status.idle":"2022-06-02T14:49:52.871686Z","shell.execute_reply.started":"2022-06-02T14:49:52.87135Z","shell.execute_reply":"2022-06-02T14:49:52.8714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2 = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.873035Z","iopub.status.idle":"2022-06-02T14:49:52.873681Z","shell.execute_reply.started":"2022-06-02T14:49:52.873345Z","shell.execute_reply":"2022-06-02T14:49:52.873375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2['ID_code'] = df_test_ids.copy()\nsubmission_2['target'] = y_pred_voting_weighted","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.875443Z","iopub.status.idle":"2022-06-02T14:49:52.876057Z","shell.execute_reply.started":"2022-06-02T14:49:52.87574Z","shell.execute_reply":"2022-06-02T14:49:52.875771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.877981Z","iopub.status.idle":"2022-06-02T14:49:52.878698Z","shell.execute_reply.started":"2022-06-02T14:49:52.878352Z","shell.execute_reply":"2022-06-02T14:49:52.878404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2.to_csv('final_submission_tuned_weighted_9_magic_numbers_votingclassifier.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.880352Z","iopub.status.idle":"2022-06-02T14:49:52.880983Z","shell.execute_reply.started":"2022-06-02T14:49:52.880676Z","shell.execute_reply":"2022-06-02T14:49:52.880706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The model results on kaggle were:\n\n#### Score: 0.82466\n\n#### Public score: 0.83206","metadata":{}},{"cell_type":"code","source":"voting_submission_score = 0.82466\nvoting_submission_public_score = 0.83206","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.882324Z","iopub.status.idle":"2022-06-02T14:49:52.883012Z","shell.execute_reply.started":"2022-06-02T14:49:52.882652Z","shell.execute_reply":"2022-06-02T14:49:52.882683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding this results to the df_submission dataframe, for further comparison between models\n\ndf_submissions.loc['Ensemble VotingClassifier 200 models', :] = [voting_submission_score,\n                                                                 voting_submission_public_score]","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.884796Z","iopub.status.idle":"2022-06-02T14:49:52.885213Z","shell.execute_reply.started":"2022-06-02T14:49:52.884997Z","shell.execute_reply":"2022-06-02T14:49:52.88502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submissions","metadata":{"execution":{"iopub.status.busy":"2022-06-02T14:49:52.886678Z","iopub.status.idle":"2022-06-02T14:49:52.887128Z","shell.execute_reply.started":"2022-06-02T14:49:52.88693Z","shell.execute_reply":"2022-06-02T14:49:52.88695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-thirteen\"></a>\n# Suggestions","metadata":{}},{"cell_type":"markdown","source":"#### As we can see, VotingClassifier didn't seem to improve much of our overall score.\n\n####  Here are a few suggestions of future tests based on this kernel:\n\n* Optimizing weights of the 200 models in some other way;\n* Training and tuning the 200 models individually using a gridsearch for each one of them, because the best hyperparameters might be different for each of the models;\n* Testing the ensemble method using a meta-learner for final predictions;\n* Testing other algorithms.","metadata":{}},{"cell_type":"markdown","source":"#### This is my first kernel, so I'd really appreciate if you could comment and give me any advice.\n#### Thanks!","metadata":{}}]}