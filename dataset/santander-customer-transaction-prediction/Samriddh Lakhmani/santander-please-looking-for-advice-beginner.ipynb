{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Santanders Customer Transaction - Competition","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I am using this notebook to learn new and advance techniques, before I can begin reading others works, I want to work on the data myself and get a feel of the problem.\n\n* I am looking to understand the limitation this large amount of data\n* I am seeing what a base accuracy any novice can get\n* I recently learnt upscaling, RFE so I want to test it out\n* I am pretty sure, a lot of the improvement will be done based on how the data is preprocessed! So I want to use my own ideas before Begin to read others\n\nReaders, please feel free to comment/ crticize/ advice ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = pd.read_csv('Data/train.csv',index_col='ID_code')\ndata = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/train.csv')\n\n# data.set_index('ID_code',inplace=True)\ndata.drop('ID_code',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratoty Data Analysis - Basic","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"How much of a -ve impact will it make if I run the EDA on \n\n* first 500 or 'x' data\n* random 500 or 'x' data\n\nHow can I determine 'x'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.sample(100)","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1,10,figsize=(30,5))\nfig.subplots_adjust(hspace = .5, wspace=.5)\naxs = axs.ravel()\n\ncounter=0\nfor i in data.columns[1:10]:\n    \n    axs[counter].set_title(i)\n#     axs[counter].hist(data[i])\n    sns.distplot(data[i],ax=axs[counter])\n    axs[counter].set_ylabel(\"Distribution\")\n#     plt.xticks(rotation=90)\n    axs[counter].set_xticklabels(data[i].unique(),rotation=90)\n    counter+=1  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusion\n\n* Some of the features show bimodal, it would be lovely to learn how to treat that?\n\nPS: I did read online, but I would prefer the kaggle community solutions. It tends to be more pragmatic and industrial, compared to some of the material I have read, which seems research-ish \n\n\nAs suggested by these thereads, that the best solutions would be to use \"gausian mixture\" and \"logistic Regression\"\nhttps://www.researchgate.net/post/How_to_analyse_a_Bimodal_response_variable\nhttps://www.researchgate.net/post/How_can_we_deal_with_bimodal_variables\n\nwhich you will see later do yield the best results. The two highest accuracy models are the Naive Bayes and logistic Regression!\n\nBut is there any solution to treat the data, logiacally I dont think so, Help Kagglers?","execution_count":null},{"metadata":{"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1,10,figsize=(30,5))\nfig.subplots_adjust(hspace = .5, wspace=.5)\naxs = axs.ravel()\ncounter=0\n\nfor i in data.columns[1:10]:\n\n    \n    data_pivot = data[['target']]\n    data_pivot[i] = pd.qcut(data[i],q=10,duplicates='drop')\n    data_plot = pd.pivot_table(data_pivot,'target',i)\n\n    plt.title(i)\n    sns.barplot(data_plot.index,'target',data=data_plot,ax=axs[counter])\n    plt.ylabel(\"Percentage of Approval\")\n    plt.xticks(rotation=90)\n\n    counter+=1   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations\n\n* We can observe higher transactions (1s) for 10% of the people in most of the graphs\n \n* Either they are in the begining, ie, 10th percecntile or in the end, ie, 90th percentile\n\n* Such distinctions across all variables will yield a good accuracy","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Ploting afer using minmax just to check what happens to the bimodals","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nX = data.drop('target',axis=1)\ny = data.target\n\nmms = MinMaxScaler()\nX = pd.DataFrame(mms.fit_transform(X),columns=X.columns)\n\ndata_plot = pd.concat([X,y],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1,10,figsize=(30,5))\nfig.subplots_adjust(hspace = .5, wspace=.5)\naxs = axs.ravel()\n\ncounter=0\nfor i in data.columns[1:10]:\n    \n    axs[counter].set_title(i)\n#     axs[counter].hist(data[i])\n    sns.distplot(data_plot[i],ax=axs[counter])\n    axs[counter].set_ylabel(\"Distribution\")\n#     plt.xticks(rotation=90)\n    axs[counter].set_xticklabels(data_plot[i].unique(),rotation=90)\n    counter+=1  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Logistic Regression ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = pd.read_csv('Data/train.csv',index_col='ID_code')\ndata = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/train.csv')\n\n# data.set_index('ID_code',inplace=True)\ndata.drop('ID_code',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop('target',axis=1)\ny = data.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg=LogisticRegression(max_iter=300)\nlogreg.fit(X_train,y_train.values.ravel())\ny_pred = logreg.predict(X_test)\n\nprint('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n\nplt.figure(figsize = (5,4))\nsns.set(font_scale=1.4)\n\nsns.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusion\nSince all the data were a continuous type using logistic regression was obious","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Min Max Scaler Transformation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Since I am using Logistic Regression I want to try using MinMaxScaler() once : It might yield better result. \n\nThe data if it is in 0-1 range it improves logistic regression results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nX = data.drop('target',axis=1)\ny = data.target\n\nmms = MinMaxScaler()\nX = pd.DataFrame(mms.fit_transform(X),columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg=LogisticRegression(max_iter=300)\nlogreg.fit(X_train,y_train.values.ravel())\ny_pred = logreg.predict(X_test)\n\nprint('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n\nplt.figure(figsize = (5,4))\nsns.set(font_scale=1.4)\n\nsns.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see an increase in overall accuracy by 0.01.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Changing sample ratios by using upscaling and down scaling ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline\nfrom collections import Counter\n\n\nunder = RandomUnderSampler(sampling_strategy=0.25)\nover = SMOTE(sampling_strategy=0.5)\n\nX = data.drop('target',axis=1)\ny = data.target\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y = under.fit_resample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y = over.fit_resample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize the new class distribution\ncounter = Counter(y)\nprint(counter)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg2=LogisticRegression(max_iter=300)\nlogreg2.fit(X_train,y_train.values.ravel())\ny_pred = logreg2.predict(X_test)\n\nprint('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg2.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n\nplt.figure(figsize = (5,4))\nsns.set(font_scale=1.4)\n\nsns.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusion of Udersampling and over Sampling\n\nWe can see a reduction in the prediction ratios, that is we are overpredicting the amount of 1s, after sample manuplation, thus we shall not use it!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Min Max Scaler Transformation + Data Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nX = data.drop('target',axis=1)\ny = data.target\n\nmms = MinMaxScaler()\nX = pd.DataFrame(mms.fit_transform(X),columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How to improve the overall accuracy of the model, \n\nLet us first understand : We have high recall for 0 and slightly lower precision for 0, that means we need to reduce the number of 0 predictions. \n\nThat inturn will drive my model prediction of 1s to increase, \n\n* Genrally \n> * I want to reduce the elements with the lower coeff magnituge  \n> * Reduce elements with high p-val (>0.02) (I am chosing a confidence level of 98%) \n* For this model\n> * But I shall keep the values with high coeff magnitude if it is +ve, and Pval <0.05 -> coz the model has low \n> * I shall remove the values with coeff of magnitude -ve and pval>0.02","execution_count":null},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"import statsmodels.api  as sm\n\nlogit_model2=sm.Logit(y_train,X_train)\nresult=logit_model2.fit()\nprint(result.summary2())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### First I will eleminate variables only with -ve coeff. of variables : ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_negd = X_train.drop(['var_7','var_10','var_17','var_29','var_30','var_27',\n                             'var_38','var_39','var_41','var_73','var_98','var_61',\n                             'var_100','var_103','var_136','var_153','var_158',\n                             'var_161',\n                             ],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_negd = X_test.drop(['var_7','var_10','var_17','var_29','var_30','var_27',\n                            'var_38','var_39','var_41','var_73','var_98','var_61',\n                            'var_100','var_103','var_136','var_153','var_158',\n                            'var_161',\n                             ],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg=LogisticRegression(max_iter=300)\nlogreg.fit(X_train_negd,y_train.values.ravel())\ny_pred = logreg.predict(X_test_negd)\n\nprint('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg.score(X_test_negd, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n\nplt.figure(figsize = (5,4))\nsns.set(font_scale=1.4)\n\nsns.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Slight drop in recall for 1, mean a value that was 1 got predicted as 0","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Second, I will eleminate both variables only with -ve & +ve coeff. of variables : ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_negd = X_train.drop(['var_7','var_10','var_17','var_29','var_30','var_27',\n                             'var_38','var_39','var_41','var_73','var_98','var_61',\n                             'var_100','var_103','var_136','var_153','var_158',\n                             'var_161','var_183',\n                             'var_16','var_37','var_46','var_65','var_69','var_79',\n                             'var_96','var_117','var_124','var_126','var_185','var_189',\n                             'var_61','var_60','var_47'                             \n                             ],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_negd = X_test.drop(['var_7','var_10','var_17','var_29','var_30','var_27',\n                            'var_38','var_39','var_41','var_73','var_98','var_61',\n                            'var_100','var_103','var_136','var_153','var_158',\n                            'var_161','var_183',\n                           'var_16','var_37','var_46','var_65','var_69','var_79',\n                             'var_96','var_117','var_124','var_126','var_185','var_189',\n                           'var_61','var_60','var_47'\n                             ],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg=LogisticRegression(max_iter=300)\nlogreg.fit(X_train_negd,y_train.values.ravel())\ny_pred = logreg.predict(X_test_negd)\n\nprint('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg.score(X_test_negd, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n\nplt.figure(figsize = (5,4))\nsns.set(font_scale=1.4)\n\nsns.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Slight drop in recall for 1, mean a value that was 1 got predicted as 0","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Using RFE : For Feature Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recursive Feature Elimination\nfrom sklearn.feature_selection import RFE\n\nlogreg = LogisticRegression(max_iter=4000)\n\n# Select Best X Features\nrfe = RFE(logreg, n_features_to_select=None)\nrfe = rfe.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rfe.support_)\nprint(rfe.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train[X_train.columns[rfe.support_]]\nX_test_rfe = X_test[X_train.columns[rfe.support_]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg=LogisticRegression(max_iter=300)\nlogreg.fit(X_train_rfe,y_train.values.ravel())\ny_pred = logreg.predict(X_test_rfe)\n\nprint('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg.score(X_test_rfe, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n\nplt.figure(figsize = (5,4))\nsns.set(font_scale=1.4)\n\nsns.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trying Other Models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Not all models are running with so many data, So I will select a few on my on. As we have observed, that adjusting the ratios of sample sets are imoacting the accuracy of the model, I have decieded to maintain the same ratios. \n\nMore enlightened folks please, I implore you to give me your sugesstion and valueble feedback on the limitations of my actions!!\n\nAnd also feel free to critize the hell out of this notebook and help me out :P\n\nPlease also let me know if there is a package that would have helped me select a few data points out of these ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ratio = y[y==1].shape[0]/y[y==0].shape[0]\nindex_1 = y[y==1].index\nindex_0 = y[y==0].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import random\n\nindex_0_sel = random.choice(index_1, size = 20000)\nindex_1_sel = random.choice(index_0, size = int(20000*ratio))\nindex_sel = np.concatenate((index_0_sel,index_1_sel))\n\n\nX_sel = X.iloc[index_sel]\ny_sel = y.iloc[index_sel]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X_sel, y_sel, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.drop(['var_7','var_10','var_17','var_29','var_30','var_27',\n                             'var_38','var_39','var_41','var_73','var_98','var_61',\n                             'var_100','var_103','var_136','var_153','var_158',\n                             'var_161','var_183',\n                             'var_16','var_37','var_46','var_65','var_69','var_79',\n                             'var_96','var_117','var_124','var_126','var_185','var_189',\n                             'var_61','var_60','var_47'                             \n                             ],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test.drop(['var_7','var_10','var_17','var_29','var_30','var_27',\n                            'var_38','var_39','var_41','var_73','var_98','var_61',\n                            'var_100','var_103','var_136','var_153','var_158',\n                            'var_161','var_183',\n                           'var_16','var_37','var_46','var_65','var_69','var_79',\n                             'var_96','var_117','var_124','var_126','var_185','var_189',\n                           'var_61','var_60','var_47'\n                             ],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0, penalty = 'l2')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nresults = pd.DataFrame([['Logistic Regression (Lasso)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"010b25699a57030e8a7518cc7c59ea36715c8fd3","trusted":true},"cell_type":"code","source":"## SVM (Linear)\nfrom sklearn.svm import SVC\nclassifier = SVC(random_state = 0, kernel = 'linear', probability= True)\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"425414a5e04f45f7909b3e9f132a8b8eca3e9a2d","trusted":true},"cell_type":"code","source":"## SVM (rbf)\nfrom sklearn.svm import SVC\nclassifier = SVC(random_state = 0, kernel = 'rbf', probability= True)\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['SVM (RBF)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91241878e52cc096ba48a37244fedb9824d868da","trusted":true},"cell_type":"code","source":"## Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Naive Bayes (Gaussian)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ef983937aede84cf54c77ea30d6f090ea82fbe2","trusted":true},"cell_type":"code","source":"## Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\nclassifier.fit(X_train, y_train)\n\n#Predicting the best set result\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Decision Tree', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54f2b219ff65a0cc66dfda45a8b0643285e2fd54","trusted":true},"cell_type":"code","source":"## Random Forest Gini (n=100)\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n                                    criterion = 'gini')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest Gini (n=100)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcf4ea5fd632c29f63b634101c1bd945c594f072","trusted":true},"cell_type":"code","source":"## Random Forest Gini (n=200)\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(random_state = 0, n_estimators = 200,\n                                    criterion = 'gini')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest Gini (n=200)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a77c106bce1f2bfddba6a12f3aa8fa27711e4b42","trusted":true},"cell_type":"code","source":"## Random Forest Gini (n=300)\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(random_state = 0, n_estimators = 300,\n                                    criterion = 'gini')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest Gini (n=300)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c1d0c39f3da1d12ffc1d6c2cad3fbf2392354c5","trusted":true},"cell_type":"code","source":"## Random Forest Entropy (n=100)\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n                                    criterion = 'entropy')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest Entropy (n=100)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b49d5f8096ed72048677192169bf633e5e5ca96a","trusted":true},"cell_type":"code","source":"## Random Forest Entropy (n=200)\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(random_state = 0, n_estimators = 200,\n                                    criterion = 'entropy')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest Entropy (n=200)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29512e15d7406a6a0435af9aadc3ec3ac1890a4f","trusted":true},"cell_type":"code","source":"## Random Forest Entropy (n=300)\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(random_state = 0, n_estimators = 300,\n                                    criterion = 'entropy')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest Entropy (n=300)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## K-Nearest Neighbors (K-NN)\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=15, metric='minkowski', p= 2)\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['K-Nearest Neighbors (minkowski)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes (Gaussian)\n\nUsing the full data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop('target',axis=1)\ny = data.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mms = MinMaxScaler()\nX = pd.DataFrame(mms.fit_transform(X),columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.drop(['var_7','var_10','var_17','var_29','var_30','var_27',\n                             'var_38','var_39','var_41','var_73','var_98','var_61',\n                             'var_100','var_103','var_136','var_153','var_158',\n                             'var_161','var_183',\n                             'var_16','var_37','var_46','var_65','var_69','var_79',\n                             'var_96','var_117','var_124','var_126','var_185','var_189',\n                             'var_61','var_60','var_47'                             \n                             ],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test.drop(['var_7','var_10','var_17','var_29','var_30','var_27',\n                            'var_38','var_39','var_41','var_73','var_98','var_61',\n                            'var_100','var_103','var_136','var_153','var_158',\n                            'var_161','var_183',\n                           'var_16','var_37','var_46','var_65','var_69','var_79',\n                             'var_96','var_117','var_124','var_126','var_185','var_189',\n                           'var_61','var_60','var_47'\n                             ],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n\nprint('Accuracy of Naive bayes classifier on test set: {:.5f}'.format(accuracy_score(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n\nplt.figure(figsize = (5,4))\nsns.set(font_scale=1.4)\n\nsns.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/santander-customer-transaction-prediction/test.csv\",index_col='ID_code')\n\ntest = test.drop(['var_7','var_10','var_17','var_29','var_30','var_27',\n                             'var_38','var_39','var_41','var_73','var_98','var_61',\n                             'var_100','var_103','var_136','var_153','var_158',\n                             'var_161','var_183',\n                             'var_16','var_37','var_46','var_65','var_69','var_79',\n                             'var_96','var_117','var_124','var_126','var_185','var_189',\n                             'var_61','var_60','var_47'                             \n                             ],axis=1)\n\nsol = pd.DataFrame(test.index)\n\nmms = MinMaxScaler()\ntest = pd.DataFrame(mms.fit_transform(test),columns=test.columns)\n\nsol['target']=classifier.predict(test)\n\nsol.set_index('ID_code',inplace=True)\n\nsol.to_csv('submission_NB')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conslusion\n\nSome Advice on how should I proceed to  improve my accuracy?","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}