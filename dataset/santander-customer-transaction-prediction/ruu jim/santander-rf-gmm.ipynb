{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-10T09:50:51.369461Z","iopub.execute_input":"2021-09-10T09:50:51.369876Z","iopub.status.idle":"2021-09-10T09:50:51.381679Z","shell.execute_reply.started":"2021-09-10T09:50:51.369843Z","shell.execute_reply":"2021-09-10T09:50:51.380449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 거래 금액과 상관없이 앞으로 어떤 고객이 특정 거래를 할 것인지를 파악\n- \n\n- 플랫폼 결정 : 코랩 \n- 템플릿\n    - 데이터와 분석 목적을 파악한 후 어떤 프로세스에 따라 분석을 진행할 건지(어떤 걸 할건지!)\n    - 잘 정리된 EDA 같이 보면서 데이터 파악 ","metadata":{}},{"cell_type":"markdown","source":"train\n- ID_code(string)\n- target\n- 200 numerical variables, named from var_0 to var_199","metadata":{}},{"cell_type":"code","source":"# 라이브러리 임포트\n\n# data manipulation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set()\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n# sklearn models & tools\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\n\n# ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\nimport os\nprint(os.listdir(\"../input\"))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:50:51.505774Z","iopub.execute_input":"2021-09-10T09:50:51.506125Z","iopub.status.idle":"2021-09-10T09:50:52.930586Z","shell.execute_reply.started":"2021-09-10T09:50:51.506095Z","shell.execute_reply":"2021-09-10T09:50:52.929497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:50:52.932377Z","iopub.execute_input":"2021-09-10T09:50:52.932828Z","iopub.status.idle":"2021-09-10T09:51:14.561585Z","shell.execute_reply.started":"2021-09-10T09:50:52.93278Z","shell.execute_reply":"2021-09-10T09:51:14.560771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:14.563031Z","iopub.execute_input":"2021-09-10T09:51:14.56349Z","iopub.status.idle":"2021-09-10T09:51:14.5993Z","shell.execute_reply.started":"2021-09-10T09:51:14.563457Z","shell.execute_reply":"2021-09-10T09:51:14.598139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:14.600919Z","iopub.execute_input":"2021-09-10T09:51:14.601215Z","iopub.status.idle":"2021-09-10T09:51:14.621712Z","shell.execute_reply.started":"2021-09-10T09:51:14.601185Z","shell.execute_reply":"2021-09-10T09:51:14.620268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ID_code 빼고 전부 numerical variable","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:14.62344Z","iopub.execute_input":"2021-09-10T09:51:14.624189Z","iopub.status.idle":"2021-09-10T09:51:14.67189Z","shell.execute_reply.started":"2021-09-10T09:51:14.624139Z","shell.execute_reply":"2021-09-10T09:51:14.670854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:14.673277Z","iopub.execute_input":"2021-09-10T09:51:14.67387Z","iopub.status.idle":"2021-09-10T09:51:14.706551Z","shell.execute_reply.started":"2021-09-10T09:51:14.673825Z","shell.execute_reply":"2021-09-10T09:51:14.705094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:14.70767Z","iopub.execute_input":"2021-09-10T09:51:14.707955Z","iopub.status.idle":"2021-09-10T09:51:16.778096Z","shell.execute_reply.started":"2021-09-10T09:51:14.707929Z","shell.execute_reply":"2021-09-10T09:51:16.777184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:16.780599Z","iopub.execute_input":"2021-09-10T09:51:16.780922Z","iopub.status.idle":"2021-09-10T09:51:16.887101Z","shell.execute_reply.started":"2021-09-10T09:51:16.780888Z","shell.execute_reply":"2021-09-10T09:51:16.886052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:16.889039Z","iopub.execute_input":"2021-09-10T09:51:16.889356Z","iopub.status.idle":"2021-09-10T09:51:16.994334Z","shell.execute_reply.started":"2021-09-10T09:51:16.889323Z","shell.execute_reply":"2021-09-10T09:51:16.993332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 결측치 없음","metadata":{}},{"cell_type":"code","source":"train.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:16.995699Z","iopub.execute_input":"2021-09-10T09:51:16.995998Z","iopub.status.idle":"2021-09-10T09:51:17.005146Z","shell.execute_reply.started":"2021-09-10T09:51:16.995969Z","shell.execute_reply":"2021-09-10T09:51:17.004117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(train.target)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:17.006752Z","iopub.execute_input":"2021-09-10T09:51:17.007186Z","iopub.status.idle":"2021-09-10T09:51:17.20566Z","shell.execute_reply.started":"2021-09-10T09:51:17.007141Z","shell.execute_reply":"2021-09-10T09:51:17.204621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[train.target==1].shape[0] / train.loc[train.target==0].shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:17.207089Z","iopub.execute_input":"2021-09-10T09:51:17.207759Z","iopub.status.idle":"2021-09-10T09:51:17.395718Z","shell.execute_reply.started":"2021-09-10T09:51:17.207714Z","shell.execute_reply":"2021-09-10T09:51:17.39458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### class imbalanced 문제 있음 \n\n- stratifiedKFold\n- 성능평가 : ?","metadata":{}},{"cell_type":"code","source":"# ID_code 변수 제거\ntrain[\"Id\"] = train.index.values\noriginal_trainid = train.ID_code.values\ntrain.drop(\"ID_code\", axis=1, inplace=True)\n\ntest[\"Id\"] = test.index.values\noriginal_testid = test.ID_code.values\ntest.drop(\"ID_code\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:17.397265Z","iopub.execute_input":"2021-09-10T09:51:17.397685Z","iopub.status.idle":"2021-09-10T09:51:17.605826Z","shell.execute_reply.started":"2021-09-10T09:51:17.397641Z","shell.execute_reply":"2021-09-10T09:51:17.604752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"correlation 구해서 선형관계 아님을 확인하고, 선형 모델 말고 다른 모델로 돌려보기 : basemodel : lightGBM","metadata":{}},{"cell_type":"markdown","source":"- EDA 필요!! 데이터 파악 필요!!\n- 그런데 EDA를 어떻게 해야 할 지??\n- EDA를 좀 더 해서 어떻게 모델링할지 정해야 한다.","metadata":{}},{"cell_type":"code","source":"# 상관계수 평균\n(train.corr()).mean().mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:17.607594Z","iopub.execute_input":"2021-09-10T09:51:17.608069Z","iopub.status.idle":"2021-09-10T09:51:39.620796Z","shell.execute_reply.started":"2021-09-10T09:51:17.608019Z","shell.execute_reply":"2021-09-10T09:51:39.619733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0.005로 상관계수가 매우 낮다!","metadata":{}},{"cell_type":"code","source":"(train.drop([\"target\"], axis=1).corr()).mean().mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:51:39.622515Z","iopub.execute_input":"2021-09-10T09:51:39.622928Z","iopub.status.idle":"2021-09-10T09:52:01.643336Z","shell.execute_reply.started":"2021-09-10T09:51:39.622885Z","shell.execute_reply":"2021-09-10T09:52:01.642141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_correlations = train.drop([\"target\"], axis=1).corr()\ntrain_correlations = train_correlations.values.flatten()\ntrain_correlations = train_correlations[train_correlations != 1]\n\ntest_correlations = test.corr()\ntest_correlations = test_correlations.values.flatten()\ntest_correlations = test_correlations[test_correlations != 1]\n\nplt.figure(figsize=(20,5))\nsns.distplot(train_correlations, color=\"Red\", label=\"train\")\nsns.distplot(test_correlations, color=\"Green\", label=\"test\")\nplt.xlabel(\"Correlation values found in train (except 1)\")\nplt.ylabel(\"Density\")\nplt.title(\"Are there correlations between features?\"); \nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:52:01.644781Z","iopub.execute_input":"2021-09-10T09:52:01.645098Z","iopub.status.idle":"2021-09-10T09:52:46.799377Z","shell.execute_reply.started":"2021-09-10T09:52:01.645056Z","shell.execute_reply":"2021-09-10T09:52:46.798291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"모든 변수가 선형 상관관계가 아니다. ","metadata":{}},{"cell_type":"markdown","source":"- top 10 feature를 뽑아서 사용하면 데이터의 본질을 이해하는데 도움이 되고, 새로운 변수를 생성하는데 어떠한 아이디어를 얻을 수 있을 것이다.\n- 랜덤 포레스트를 이용해서 중요 변수를 선택 -> 선형 관계가 없기 때문에 nonlinear model을 사용하면 좋을 것이다.(변수의 중요도(importance), 상호작용(interaction)을 발견하는데 도움)\n- 랜덤 포레스트 사용하면 어떤 방식으로 top 10 feature를 뽑는가? 기준이 무엇인가?","metadata":{}},{"cell_type":"code","source":"parameters = {'min_samples_leaf': [20, 25]}\nforest = RandomForestClassifier(max_depth=15, n_estimators=15)\ngrid = GridSearchCV(forest, parameters, cv=3, n_jobs=-1, verbose=2, scoring=make_scorer(roc_auc_score))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:52:46.800693Z","iopub.execute_input":"2021-09-10T09:52:46.800986Z","iopub.status.idle":"2021-09-10T09:52:46.806653Z","shell.execute_reply.started":"2021-09-10T09:52:46.800957Z","shell.execute_reply":"2021-09-10T09:52:46.805495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:52:46.808135Z","iopub.execute_input":"2021-09-10T09:52:46.808528Z","iopub.status.idle":"2021-09-10T09:52:46.82446Z","shell.execute_reply.started":"2021-09-10T09:52:46.80848Z","shell.execute_reply":"2021-09-10T09:52:46.823464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 모델 학습\ngrid.fit(train.drop([\"target\"], axis=1).values, train.target.values)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:52:46.825699Z","iopub.execute_input":"2021-09-10T09:52:46.826006Z","iopub.status.idle":"2021-09-10T09:55:44.198719Z","shell.execute_reply.started":"2021-09-10T09:52:46.825978Z","shell.execute_reply":"2021-09-10T09:55:44.197577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.200409Z","iopub.execute_input":"2021-09-10T09:55:44.200742Z","iopub.status.idle":"2021-09-10T09:55:44.208142Z","shell.execute_reply.started":"2021-09-10T09:55:44.200707Z","shell.execute_reply":"2021-09-10T09:55:44.206953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_score_","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.209573Z","iopub.execute_input":"2021-09-10T09:55:44.210025Z","iopub.status.idle":"2021-09-10T09:55:44.222125Z","shell.execute_reply.started":"2021-09-10T09:55:44.209993Z","shell.execute_reply":"2021-09-10T09:55:44.220812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"점수(roc_auc_score)가 그닥 좋지 않다.","metadata":{}},{"cell_type":"markdown","source":"### feature 뽑기!! : starting point!\n\n- 랜덤 포레스트로 돌림\n- 성능은 안 좋음\n- 여기서 중요 변수 뽑음","metadata":{}},{"cell_type":"markdown","source":"### feature importance\n- **트리 기반 모델**(randomforest, xgboost, lightgbm 등)에서 기본적으로 feature importance를 API 혹은 모델 내장 함수로 제공\n- API(plot_importance)를 import하거나 **feature_importances_** 내장 함수를 이용해서 손쉽게 구현\n- 하지만 이를 통해 구한 지표가 절대적인 것이 아님.\n- feature importance를 고려하여 특성별로 A/B test 를 진행하며 feature selection을 하는 것이 좋다.","metadata":{}},{"cell_type":"markdown","source":"#### feature importance 동작 원리\n- feature importance는 트리기반 모델에서 사용됨\n- 중요도를 구분하는데에는 트리의 분할과 밀접한 관련이 있음.\n- 즉 특정 변수가 트리를 분할하는데 얼마나 기여를 했는지에 따라 중요도가 결정됨\n\n**트리 분할**\n- 트리는 순수도를 기준으로 분할. 즉 가장 잘 분류시키는 변수를 순수도라는 기준으로 판단하는 것\n- 순수도 계산 : 엔트로피, 지니계수\n- 특정 변수로 인한 순수도의 변화량을 파악하기 위해(특정 변수의 중요도를 파악하기 위해 순수도의 변화량을 계산) <u>엔트로피를 활용한 정보이득량</u> 혹은 <u>지니계수를 이용한 지니 split</u>을 계산 -> 이를 기준으로 트리 분할\n- 이때 '정보이득량이 가장 높은' 혹은 '지니 split이 가장 낮은' 변수를 선택하여 트리를 분할하고, 중요도에 반영된다.  \n\n**feature importance는 왜 절대적인 지표가 되지 못할까?**\n- feature importance는 노드가 분기 할때의 정보 이득 혹은 지니 계수만을 고려하여 중요도를 부여하기 때문에 과적합에 대해 고려하지 못함","metadata":{}},{"cell_type":"code","source":"# 모델의 내장 함수인 feature_importances_\ngrid.best_estimator_.feature_importances_ # shape : 200\n\n# 어레이 형태로 반환","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.223624Z","iopub.execute_input":"2021-09-10T09:55:44.224052Z","iopub.status.idle":"2021-09-10T09:55:44.240889Z","shell.execute_reply.started":"2021-09-10T09:55:44.224009Z","shell.execute_reply":"2021-09-10T09:55:44.240031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.argsort(importances)[::-1][0:n_top] \n\n# 인덱스 오름차순 정렬 -> 뒤집어서 내림차순 => 상위 5개의 인덱스","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.246361Z","iopub.execute_input":"2021-09-10T09:55:44.246852Z","iopub.status.idle":"2021-09-10T09:55:44.250479Z","shell.execute_reply.started":"2021-09-10T09:55:44.246811Z","shell.execute_reply":"2021-09-10T09:55:44.249442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train.drop([\"target\", \"ID_code\"], axis=1).columns.values","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.253192Z","iopub.execute_input":"2021-09-10T09:55:44.253562Z","iopub.status.idle":"2021-09-10T09:55:44.262509Z","shell.execute_reply.started":"2021-09-10T09:55:44.253528Z","shell.execute_reply":"2021-09-10T09:55:44.261573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_top = 5","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.263795Z","iopub.execute_input":"2021-09-10T09:55:44.264344Z","iopub.status.idle":"2021-09-10T09:55:44.275059Z","shell.execute_reply.started":"2021-09-10T09:55:44.264309Z","shell.execute_reply":"2021-09-10T09:55:44.274176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = grid.best_estimator_.feature_importances_ # 변수 중요도\nidx = np.argsort(importances)[::-1][0:n_top] # 상위 5개의 인덱스\nfeature_names = train.drop([\"target\"], axis=1).columns.values # 변수 이름\n\n# 변수 중요도 기준 상위 5개 변수의 중요도 시각화\nplt.figure(figsize=(20,5))\nsns.barplot(x=feature_names[idx], y=importances[idx]);\nplt.title(\"What are the top important features to start with?\");","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.276445Z","iopub.execute_input":"2021-09-10T09:55:44.276946Z","iopub.status.idle":"2021-09-10T09:55:44.585711Z","shell.execute_reply.started":"2021-09-10T09:55:44.276905Z","shell.execute_reply":"2021-09-10T09:55:44.584877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"변수를 뽑아서 얘네를 가지고 데이터 이해 여행을 떠나보자~","metadata":{}},{"cell_type":"markdown","source":"Q. 왜 랜덤 포레스트로 중요 변수를 뽑았는지?\n\nQ. 변수 선택 방법으로는 또 어떤 것이 있는지?\n\nQ. 중요 변수를 몇개를 뽑아서 탐색하는 것이 전체 EDA에 어떤 도움이 되는지? ","metadata":{}},{"cell_type":"markdown","source":"- train 데이터의 target에 대한 변수들의 분포가 어떤지?\n\n- 선택된 상위 변수에 대해 train과 test 데이터의 형상의 불일치를 관찰할 수 있는지?","metadata":{}},{"cell_type":"code","source":"train.var_81","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.587026Z","iopub.execute_input":"2021-09-10T09:55:44.587524Z","iopub.status.idle":"2021-09-10T09:55:44.595712Z","shell.execute_reply.started":"2021-09-10T09:55:44.58749Z","shell.execute_reply":"2021-09-10T09:55:44.594719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train.loc[train.target==0, feature_names[idx][0]]).mean()  # var81","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.597453Z","iopub.execute_input":"2021-09-10T09:55:44.597906Z","iopub.status.idle":"2021-09-10T09:55:44.613919Z","shell.execute_reply.started":"2021-09-10T09:55:44.597858Z","shell.execute_reply":"2021-09-10T09:55:44.612764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(n_top,2,figsize=(20,5*n_top))\n\nfor n in range(n_top):\n    sns.distplot(train.loc[train.target==0, feature_names[idx][n]], ax=ax[n,0], color=\"Orange\", norm_hist=True)\n    sns.distplot(train.loc[train.target==1, feature_names[idx][n]], ax=ax[n,0], color=\"Red\", norm_hist=True)\n    sns.distplot(test.loc[:, feature_names[idx][n]], ax=ax[n,1], color=\"Mediumseagreen\", norm_hist=True)\n    ax[n,0].set_title(\"Train {}\".format(feature_names[idx][n]))\n    ax[n,1].set_title(\"Test {}\".format(feature_names[idx][n]))\n    ax[n,0].set_xlabel(\"\")\n    ax[n,1].set_xlabel(\"\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:44.615475Z","iopub.execute_input":"2021-09-10T09:55:44.61591Z","iopub.status.idle":"2021-09-10T09:55:59.850907Z","shell.execute_reply.started":"2021-09-10T09:55:44.615866Z","shell.execute_reply":"2021-09-10T09:55:59.838959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- some peeks for variables 81, 12\n- test 데이터에서 누적 밀도가 더 낮다","metadata":{}},{"cell_type":"markdown","source":"- train의 target=0과 test가 비슷한 모양이다.\n- train의 target=1이 test는 많이 다르다. 왜 다를까?\n- test에도 target=0이 훨씬 많을 것이다.(거래를 하지 않을 고객) => class imbalaced\n- target=1은 데이터의 수가 적다.(거래를 할 고객)\n- target=1과 target=0의 분포 모양이 달라야 확실하게 구분 가능하고, 이러한 변수를 사용해야 예측 정확도를 높일 수 있다. ","metadata":{}},{"cell_type":"markdown","source":"- 그러면 target에 따라 데이터의 분포가 많이 다른 변수들이 선택된 것일 거다.","metadata":{}},{"cell_type":"code","source":"top = train.loc[:, feature_names[idx]]\ntop.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:59.852518Z","iopub.execute_input":"2021-09-10T09:55:59.852864Z","iopub.status.idle":"2021-09-10T09:55:59.920701Z","shell.execute_reply.started":"2021-09-10T09:55:59.852824Z","shell.execute_reply":"2021-09-10T09:55:59.91969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 이항분포\n- 질량함수 : 1, 2, 3 (x값 int)\n- 밀도함수 : 연속된 값 (x값 float)\n\n- ","metadata":{}},{"cell_type":"code","source":"top.join(train.target)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:55:59.922106Z","iopub.execute_input":"2021-09-10T09:55:59.922413Z","iopub.status.idle":"2021-09-10T09:55:59.946762Z","shell.execute_reply.started":"2021-09-10T09:55:59.922385Z","shell.execute_reply":"2021-09-10T09:55:59.945867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scatter plot\n# top = top.join(train.target)\n# sns.pairplot(top, hue=\"target\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:30.529634Z","iopub.execute_input":"2021-09-10T09:58:30.529997Z","iopub.status.idle":"2021-09-10T09:58:30.534816Z","shell.execute_reply.started":"2021-09-10T09:58:30.529965Z","shell.execute_reply":"2021-09-10T09:58:30.533915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- target=1인 데이터들이 갑자기 누적되어서 거의 넘어가지 않는 날카로운 지점이 있다.\n- 예를 들어, 81번 변수에서는 10에, 12번 변수에서는 13.5에 데이터가 누적되어 날카롭게 솟은 지점이 있다.(limit)\n- This finding could be a nice entry point(진입점) for further feature engineering. => 이후 피처 엔지니어링에 좋은 출발선이 될 거다.?","metadata":{}},{"cell_type":"markdown","source":"- train, test PDF 동일!!\n- train의 target=0과 target=1의 PDF 꽤 비슷함","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:37.129534Z","iopub.execute_input":"2021-09-10T09:58:37.129943Z","iopub.status.idle":"2021-09-10T09:58:37.164329Z","shell.execute_reply.started":"2021-09-10T09:58:37.129903Z","shell.execute_reply":"2021-09-10T09:58:37.163298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_proba = grid.predict_proba(test.values)\ny_proba_train = grid.predict_proba(train.drop('target', axis=1).values)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:37.166081Z","iopub.execute_input":"2021-09-10T09:58:37.166409Z","iopub.status.idle":"2021-09-10T09:58:38.952343Z","shell.execute_reply.started":"2021-09-10T09:58:37.166378Z","shell.execute_reply":"2021-09-10T09:58:38.9511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(y_proba_train[:,1]).mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:38.954539Z","iopub.execute_input":"2021-09-10T09:58:38.95487Z","iopub.status.idle":"2021-09-10T09:58:38.960589Z","shell.execute_reply.started":"2021-09-10T09:58:38.95484Z","shell.execute_reply":"2021-09-10T09:58:38.959779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2,1,figsize=(20,8))\nsns.distplot(y_proba_train[train.target==1,1], norm_hist=True, color=\"mediumseagreen\",\n             ax=ax[0], label=\"1\")\nsns.distplot(y_proba_train[train.target==0,1], norm_hist=True, color=\"coral\",\n             ax=ax[0], label=\"0\")\nsns.distplot(y_proba[:,1], norm_hist=True,\n             ax=ax[1], color=\"purple\")\nax[1].set_xlabel(\"Predicted probability for test data\");\nax[1].set_ylabel(\"Density\");\nax[0].set_xlabel(\"Predicted probability for train data\");\nax[0].set_ylabel(\"Density\");\nax[0].legend();","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:38.961981Z","iopub.execute_input":"2021-09-10T09:58:38.962456Z","iopub.status.idle":"2021-09-10T09:58:41.9558Z","shell.execute_reply.started":"2021-09-10T09:58:38.962422Z","shell.execute_reply":"2021-09-10T09:58:41.953905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- train 데이터에서 1이라고 예측한 것들의 확률값도 그닥 1에 가깝지 않다. -> cut-off가 중요할까? 했지만 평가 지표가 auc니까 상관없네.\n    - 곡선이 완만하긴 하지만 제일 높은 값은 0.2 정도\n- test는 대부분 0에 가까운 확률값으로 예측했다. -> 당연 : 0이 많으니까\n- 몇 없는 1을 찾아내는 것이 중요!","metadata":{}},{"cell_type":"markdown","source":"- 이 예측값을 제출했더니 public leaderboard에서 점수 0.662 받음\n- submission[\"target\"] = y_proba","metadata":{}},{"cell_type":"markdown","source":"### feature engineering","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:41.957828Z","iopub.execute_input":"2021-09-10T09:58:41.958539Z","iopub.status.idle":"2021-09-10T09:58:41.996523Z","shell.execute_reply.started":"2021-09-10T09:58:41.95847Z","shell.execute_reply":"2021-09-10T09:58:41.995285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:41.998252Z","iopub.execute_input":"2021-09-10T09:58:41.998846Z","iopub.status.idle":"2021-09-10T09:58:42.028304Z","shell.execute_reply.started":"2021-09-10T09:58:41.9988Z","shell.execute_reply":"2021-09-10T09:58:42.02711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_features = train.drop([\"target\", \"Id\"], axis=1).columns.values\noriginal_features","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.029786Z","iopub.execute_input":"2021-09-10T09:58:42.030126Z","iopub.status.idle":"2021-09-10T09:58:42.142123Z","shell.execute_reply.started":"2021-09-10T09:58:42.030091Z","shell.execute_reply":"2021-09-10T09:58:42.141065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 반올림 및 분위수 기반 binning\n\n- pd.qcut() : 수치형 변수를 특정 구간으로 나눈 범주형 레이블을 생성\n    - 데이터를 동일한 길이로 나누는 것","metadata":{}},{"cell_type":"code","source":"top","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.145185Z","iopub.execute_input":"2021-09-10T09:58:42.145744Z","iopub.status.idle":"2021-09-10T09:58:42.167099Z","shell.execute_reply.started":"2021-09-10T09:58:42.145705Z","shell.execute_reply":"2021-09-10T09:58:42.166096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.qcut(\n        train.loc[:, 'var_81'].values,\n        q=10,\n        labels=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.171173Z","iopub.execute_input":"2021-09-10T09:58:42.171536Z","iopub.status.idle":"2021-09-10T09:58:42.209511Z","shell.execute_reply.started":"2021-09-10T09:58:42.1715Z","shell.execute_reply":"2021-09-10T09:58:42.208428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.round(train.loc[:, 'var_81'].values)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.211052Z","iopub.execute_input":"2021-09-10T09:58:42.211489Z","iopub.status.idle":"2021-09-10T09:58:42.219569Z","shell.execute_reply.started":"2021-09-10T09:58:42.211442Z","shell.execute_reply":"2021-09-10T09:58:42.218482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 중요변수 qcut한 변수 생성\nencoder = LabelEncoder()\nfor your_feature in top.drop(\"target\", axis=1).columns.values:\n    train[your_feature + \"_qbinned\"] = pd.qcut(\n        train.loc[:, your_feature].values,\n        q=10,\n        labels=False\n    )\n    train[your_feature + \"_qbinned\"] = encoder.fit_transform(\n        train[your_feature + \"_qbinned\"].values.reshape(-1, 1)\n    )","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.221215Z","iopub.execute_input":"2021-09-10T09:58:42.221836Z","iopub.status.idle":"2021-09-10T09:58:42.437532Z","shell.execute_reply.started":"2021-09-10T09:58:42.221789Z","shell.execute_reply":"2021-09-10T09:58:42.436596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 중요 변수 반올림한 변수 생성\nencoder = LabelEncoder()\nfor your_feature in top.drop(\"target\", axis=1).columns.values:\n    train[your_feature + \"_rounded\"] = np.round(train.loc[:, your_feature].values)\n    train[your_feature + \"_rounded_10\"] = np.round(10*train.loc[:, your_feature].values)\n    train[your_feature + \"_rounded_100\"] = np.round(100*train.loc[:, your_feature].values)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.438996Z","iopub.execute_input":"2021-09-10T09:58:42.439646Z","iopub.status.idle":"2021-09-10T09:58:42.471335Z","shell.execute_reply.started":"2021-09-10T09:58:42.439597Z","shell.execute_reply":"2021-09-10T09:58:42.470265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test에도 같이 적용\n\n# 중요변수 qcut한 변수 생성\nencoder = LabelEncoder()\nfor your_feature in top.drop(\"target\", axis=1).columns.values:\n    test[your_feature + \"_qbinned\"] = pd.qcut(\n        test.loc[:, your_feature].values,\n        q=10,\n        labels=False\n    )\n    test[your_feature + \"_qbinned\"] = encoder.fit_transform(\n        test[your_feature + \"_qbinned\"].values.reshape(-1, 1)\n    )\n\n# 중요 변수 반올림한 변수 생성\nencoder = LabelEncoder()\nfor your_feature in top.drop(\"target\", axis=1).columns.values:\n    test[your_feature + \"_rounded\"] = np.round(test.loc[:, your_feature].values)\n    test[your_feature + \"_rounded_10\"] = np.round(10*test.loc[:, your_feature].values)\n    test[your_feature + \"_rounded_100\"] = np.round(100*test.loc[:, your_feature].values)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.472744Z","iopub.execute_input":"2021-09-10T09:58:42.473373Z","iopub.status.idle":"2021-09-10T09:58:42.717971Z","shell.execute_reply.started":"2021-09-10T09:58:42.473326Z","shell.execute_reply":"2021-09-10T09:58:42.717164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.71933Z","iopub.execute_input":"2021-09-10T09:58:42.719923Z","iopub.status.idle":"2021-09-10T09:58:42.765393Z","shell.execute_reply.started":"2021-09-10T09:58:42.719875Z","shell.execute_reply":"2021-09-10T09:58:42.764325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.qcut() : 데이터를 동일한 길이로 나눔\ntrain['var_81_qbinned'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.766893Z","iopub.execute_input":"2021-09-10T09:58:42.767499Z","iopub.status.idle":"2021-09-10T09:58:42.778479Z","shell.execute_reply.started":"2021-09-10T09:58:42.767453Z","shell.execute_reply":"2021-09-10T09:58:42.777334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 새로운 변수 중요도","metadata":{}},{"cell_type":"code","source":"# KFold로 데이터 나눠서 RandomForestClassifier 모델 돌림\n\ncv = StratifiedKFold(n_splits=3, random_state=0)\nforest = RandomForestClassifier(max_depth=15, n_estimators=15, min_samples_leaf=20,\n                                n_jobs=-1)\n\nscores = []\nX = train.drop(\"target\", axis=1).values\ny = train.target.values\n\nfor train_idx, test_idx in cv.split(X, y):\n    x_train = X[train_idx]\n    x_test = X[test_idx]\n    y_train = y[train_idx]\n    y_test = y[test_idx]\n    \n    forest.fit(x_train, y_train)\n    y_proba = forest.predict_proba(x_test)\n    y_pred = np.zeros(y_proba.shape[0])\n    y_pred[y_proba[:,1] >= 0.166] = 1\n    \n    score = roc_auc_score(y_test, y_pred)\n    print(score)\n    scores.append(score)\n\nprint(np.round(np.mean(scores),4))\nprint(np.round(np.std(scores), 4))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:58:42.780612Z","iopub.execute_input":"2021-09-10T09:58:42.781346Z","iopub.status.idle":"2021-09-10T09:59:29.731998Z","shell.execute_reply.started":"2021-09-10T09:58:42.781297Z","shell.execute_reply":"2021-09-10T09:59:29.730821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 중요 변수 뽑기 : feature_importances_\n\nimportances = forest.feature_importances_\nfeature_names = train.drop(\"target\", axis=1).columns.values\nidx = np.argsort(importances)[::-1][0:30]\n\nplt.figure(figsize=(20,5))\nsns.barplot(x=feature_names[idx], y=importances[idx]);\nplt.xticks(rotation=90);","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:59:29.73345Z","iopub.execute_input":"2021-09-10T09:59:29.73376Z","iopub.status.idle":"2021-09-10T09:59:30.530902Z","shell.execute_reply.started":"2021-09-10T09:59:29.73373Z","shell.execute_reply":"2021-09-10T09:59:30.529818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gaussian Mixture Clustering \n\n#### Gaussian Mixture Model(GMM) : \n- 개별 데이터가 가우시안 분포에 속한다고 가정을 한 상태에서 특정 정규분포에 속할 확률을 추정 => 확률 기반 군집화\n- 가우시안 분포 = 정규분포\n- 전체 데이터셋은 서로 다른 정규분포 형태를 가진 여러 가지 확률 분포 곡선으로 구성될 수 있으며, 이러한 서로 다른 정규분포에 기반해 군집화를 수행하는 것이 GMM 군집화 방식이다.\n- 예를 들어 1000개의 데이터가 있다면 이를 구성하는 여러 개의 정규 분포 곡선을 추출하고, 개별 데이터가 이 중 어떤 정규분포에 속하는지 결정하는 방식\n- 이와 같은 방식은 GMM에서는 모수 추정이라고 한다. 대표적으로 2가지 추정\n    - 1) 개별 정규 분포의 평균과 분산\n    - 2) 각 데이터가 어떤 정규 분포에 해당되는지의 확률\n- GaussianMixture 객체의 주요 파라미터 : n_components\n    - GaussianMixture의 모델의 총 개수. 군집화 개수\n- GMM이 특히 잘 적용되는 데이터 분포 : 타원형으로 길게 늘어진 데이터 분포\n\n#### RobustScaler\n- 표준 정규화\n- sklearn.preprocessing.RobustScaler\n- 중앙값(median)과 IQR(interquartile range, 사분위값) 사용. \n- **이상치의 영향을 최소화**\n- 중앙값을 제거하고 Quantile 범위(기본값은 IQR)에 따라 데이터를 스케일링\n- IQR은 1분위(25분위)와 3분위(75분위) 사이의 범위이다.\n- 데이터에서 이상치의 존재를 확인하고 그래서 이 스케일러를 사용하겠다고 하면 되겠다. ","metadata":{}},{"cell_type":"code","source":"col1 = \"var_81\"\ncol2 = \"var_12\"\nN=70000","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:59:30.532323Z","iopub.execute_input":"2021-09-10T09:59:30.532617Z","iopub.status.idle":"2021-09-10T09:59:30.537281Z","shell.execute_reply.started":"2021-09-10T09:59:30.532589Z","shell.execute_reply":"2021-09-10T09:59:30.536147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize=(20,10))\nsns.kdeplot(train[col1].values[0:N], train[col2].values[0:N])\nax.scatter(train[col1].values[0:N], train[col2].values[0:N],\n           s=2, c=train.target.values[0:N], cmap=\"coolwarm\", alpha=0.5)\nax.set_xlabel(col1)\nax.set_xlabel(col2);","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:59:30.538591Z","iopub.execute_input":"2021-09-10T09:59:30.538877Z","iopub.status.idle":"2021-09-10T10:00:40.137601Z","shell.execute_reply.started":"2021-09-10T09:59:30.538843Z","shell.execute_reply":"2021-09-10T10:00:40.136485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig, ax = plt.subplots(1,1, figsize=(20,10))\nsns.kdeplot(train[col1].values[0:N], train[col2].values[0:N])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:00:40.139055Z","iopub.execute_input":"2021-09-10T10:00:40.139419Z","iopub.status.idle":"2021-09-10T10:01:48.250083Z","shell.execute_reply.started":"2021-09-10T10:00:40.139384Z","shell.execute_reply":"2021-09-10T10:01:48.249093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# var_81\nsns.kdeplot(train[col1].values[0:N])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:48.251752Z","iopub.execute_input":"2021-09-10T10:01:48.252089Z","iopub.status.idle":"2021-09-10T10:01:48.92176Z","shell.execute_reply.started":"2021-09-10T10:01:48.252053Z","shell.execute_reply":"2021-09-10T10:01:48.920283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# var_12\nsns.kdeplot(train[col2].values[0:N])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:48.92335Z","iopub.execute_input":"2021-09-10T10:01:48.923696Z","iopub.status.idle":"2021-09-10T10:01:49.575089Z","shell.execute_reply.started":"2021-09-10T10:01:48.923663Z","shell.execute_reply":"2021-09-10T10:01:49.573934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined = train.drop([\"target\", \"Id\"], axis=1).append(test.drop(\"Id\", axis=1))\ncombined.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:49.581045Z","iopub.execute_input":"2021-09-10T10:01:49.581367Z","iopub.status.idle":"2021-09-10T10:01:51.346396Z","shell.execute_reply.started":"2021-09-10T10:01:49.581337Z","shell.execute_reply":"2021-09-10T10:01:51.345354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_components = 10\nstart_components = 3\nn_splits = 3\nK = train.shape[0] # 400000\n\nX = train.loc[:, original_features].values[0:K]\ny = train.target.values[0:K]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:51.349078Z","iopub.execute_input":"2021-09-10T10:01:51.349526Z","iopub.status.idle":"2021-09-10T10:01:51.456464Z","shell.execute_reply.started":"2021-09-10T10:01:51.349481Z","shell.execute_reply":"2021-09-10T10:01:51.455372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.arange(start_components, max_components, 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:51.457766Z","iopub.execute_input":"2021-09-10T10:01:51.458051Z","iopub.status.idle":"2021-09-10T10:01:51.465451Z","shell.execute_reply.started":"2021-09-10T10:01:51.458024Z","shell.execute_reply":"2021-09-10T10:01:51.464254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seeds = np.random.RandomState(0).randint(0,100, size=(max_components-start_components))\nseeds","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:51.466811Z","iopub.execute_input":"2021-09-10T10:01:51.467131Z","iopub.status.idle":"2021-09-10T10:01:51.479466Z","shell.execute_reply.started":"2021-09-10T10:01:51.4671Z","shell.execute_reply":"2021-09-10T10:01:51.478342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = RobustScaler()\nX_scaled = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:51.480734Z","iopub.execute_input":"2021-09-10T10:01:51.481028Z","iopub.status.idle":"2021-09-10T10:01:53.328547Z","shell.execute_reply.started":"2021-09-10T10:01:51.480999Z","shell.execute_reply":"2021-09-10T10:01:53.327549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_gaussians = False","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:53.32996Z","iopub.execute_input":"2021-09-10T10:01:53.330471Z","iopub.status.idle":"2021-09-10T10:01:53.334953Z","shell.execute_reply.started":"2021-09-10T10:01:53.330437Z","shell.execute_reply":"2021-09-10T10:01:53.333982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fit_gaussians:\n    components = np.arange(start_components, max_components, 1)\n    kf = StratifiedKFold(random_state=0, n_splits=n_splits)\n    \n    scores = np.zeros(shape=(max_components-start_components, n_splits))\n\n    for m in components:\n        split=0\n        print(\"Components \" + str(m))\n        for train_index, test_index in kf.split(X_scaled, y):\n            print(\"Split \" + str(split))\n            x_train, x_test = X_scaled[train_index], X_scaled[test_index]\n            gm = GaussianMixture(n_components=m, random_state=seeds[m-start_components])\n            gm.fit(x_train)\n            score = gm.score(x_test)\n            scores[m-start_components,split] = score\n            split +=1\n    \n    print(np.round(np.mean(scores, axis=1), 2))\n    print(np.round(np.std(scores, axis=1), 2))\n    best_idx = np.argmax(np.mean(scores, axis=1))\n    best_component = components[best_idx]\n    best_seed = seeds[best_idx]\n    print(\"Best component found \" + str(best_component))\n    \nelse:\n    best_seed = seeds[0]\n    best_component = 3","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:53.336528Z","iopub.execute_input":"2021-09-10T10:01:53.336926Z","iopub.status.idle":"2021-09-10T10:01:53.351447Z","shell.execute_reply.started":"2021-09-10T10:01:53.336885Z","shell.execute_reply":"2021-09-10T10:01:53.350309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.loc[:, original_features].values\n\ngm = GaussianMixture(n_components=best_component, random_state=best_seed)\nX_scaled = scaler.transform(X)\ngm.fit(X_scaled) # 스케일한 데이터로 모델 학습","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:01:53.352763Z","iopub.execute_input":"2021-09-10T10:01:53.35318Z","iopub.status.idle":"2021-09-10T10:03:22.100649Z","shell.execute_reply.started":"2021-09-10T10:01:53.353142Z","shell.execute_reply":"2021-09-10T10:03:22.099618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:22.101914Z","iopub.execute_input":"2021-09-10T10:03:22.102206Z","iopub.status.idle":"2021-09-10T10:03:22.109367Z","shell.execute_reply.started":"2021-09-10T10:03:22.102178Z","shell.execute_reply":"2021-09-10T10:03:22.108421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gm.score_samples(X_scaled) # 각 샘플에 대한 개별 점수 배열을 반환","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:22.110992Z","iopub.execute_input":"2021-09-10T10:03:22.111457Z","iopub.status.idle":"2021-09-10T10:03:24.262644Z","shell.execute_reply.started":"2021-09-10T10:03:22.11141Z","shell.execute_reply":"2021-09-10T10:03:24.261579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"cluster\"] = gm.predict(X_scaled)\ntrain[\"logL\"] = gm.score_samples(X_scaled)\ntest[\"cluster\"] = gm.predict(test.loc[:, original_features].values)\ntest[\"logL\"] = gm.score_samples(test.loc[:, original_features].values)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:24.264034Z","iopub.execute_input":"2021-09-10T10:03:24.264352Z","iopub.status.idle":"2021-09-10T10:03:33.39015Z","shell.execute_reply.started":"2021-09-10T10:03:24.264319Z","shell.execute_reply":"2021-09-10T10:03:33.38921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:33.392128Z","iopub.execute_input":"2021-09-10T10:03:33.392623Z","iopub.status.idle":"2021-09-10T10:03:33.427659Z","shell.execute_reply.started":"2021-09-10T10:03:33.392572Z","shell.execute_reply":"2021-09-10T10:03:33.426571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:33.429134Z","iopub.execute_input":"2021-09-10T10:03:33.429573Z","iopub.status.idle":"2021-09-10T10:03:33.466547Z","shell.execute_reply.started":"2021-09-10T10:03:33.429529Z","shell.execute_reply":"2021-09-10T10:03:33.465404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport lightgbm as lgb","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:33.468018Z","iopub.execute_input":"2021-09-10T10:03:33.46834Z","iopub.status.idle":"2021-09-10T10:03:34.675447Z","shell.execute_reply.started":"2021-09-10T10:03:33.468308Z","shell.execute_reply":"2021-09-10T10:03:34.674134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [c for c in train.columns if c not in ['Id', 'target']]\n\ncols = [\"target\",\"Id\"]\nX = train.drop(cols, axis=1)\ny = train[\"target\"]\n\nX_test = test.drop(\"Id\",axis=1)\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n#tree_model = DecisionTreeClassifier(random_state=0, max_depth=5, min_samples_split=5).fit(train_X, train_y)\n# test = test.drop('Id', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:34.676669Z","iopub.execute_input":"2021-09-10T10:03:34.676991Z","iopub.status.idle":"2021-09-10T10:03:35.846306Z","shell.execute_reply.started":"2021-09-10T10:03:34.676959Z","shell.execute_reply":"2021-09-10T10:03:35.845117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.847911Z","iopub.execute_input":"2021-09-10T10:03:35.848262Z","iopub.status.idle":"2021-09-10T10:03:35.855361Z","shell.execute_reply.started":"2021-09-10T10:03:35.848204Z","shell.execute_reply":"2021-09-10T10:03:35.854109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.856997Z","iopub.execute_input":"2021-09-10T10:03:35.857341Z","iopub.status.idle":"2021-09-10T10:03:35.869749Z","shell.execute_reply.started":"2021-09-10T10:03:35.857305Z","shell.execute_reply":"2021-09-10T10:03:35.868616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_X.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.871362Z","iopub.execute_input":"2021-09-10T10:03:35.871785Z","iopub.status.idle":"2021-09-10T10:03:35.881187Z","shell.execute_reply.started":"2021-09-10T10:03:35.871749Z","shell.execute_reply":"2021-09-10T10:03:35.880158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 모델링!!","metadata":{}},{"cell_type":"markdown","source":"### lightGBM\n\n- https://www.kaggle.com/mjbahmani/santander-ml-explainability","metadata":{}},{"cell_type":"code","source":"# params is based on following kernel https://www.kaggle.com/brandenkmurray/nothing-works\n# 모델의 정확도는 설정된 파라미터 값에 전적으로 달려 있다.\nparams = {'objective' : \"binary\",  \n               'boost':\"gbdt\", # gbdt : Gradient Boosting Desicion Tree # 실행하고자 하는 알고리즘 타입 정의\n               'metric':\"auc\",\n               'boost_from_average':\"false\",\n               'num_threads':8,\n               'learning_rate' : 0.01, # 최종 결과에 대한 각각의 Tree에 영향을 미치는 변수\n               'num_leaves' : 13, # 전체 Tree의 leave 수. Tree 모델의 복잡성을 컨트롤하는 주요 파라미터.\n                # 이상적으로 num_leaves의 값은 2^(max_depth) 값보다 적거나 같아야 한다. 많으면 과적합 유발  \n               'max_depth':-1,  # tree의 최대 깊이\n               'tree_learner' : \"serial\",\n               'feature_fraction' : 0.05, # 모델이 tree를 만들 때 매번 각각의 iteration에서 파라미터 중 5%를 랜덤하게 선택\n               'bagging_freq' : 5,\n               'bagging_fraction' : 0.4, # 매번 iteration을 돌 때 사용되는 데이터의 일부를 선택하는데 트레이닝 속도를 높이고 과적합을 방지할 때 주로 사용\n               'min_data_in_leaf' : 80, # Leaf가 가지고 있는 최소한의 레코드 수, 과적합 해결에 사용, 디폴트 20(최적값)\n               'min_sum_hessian_in_leaf' : 10.0,\n               'verbosity' : 1}","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:06:50.162923Z","iopub.execute_input":"2021-09-10T10:06:50.163367Z","iopub.status.idle":"2021-09-10T10:06:50.170159Z","shell.execute_reply.started":"2021-09-10T10:06:50.163333Z","shell.execute_reply":"2021-09-10T10:06:50.168985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 파라미터 튜닝\n\n더 빠른 속도를 위해 :\n\n- bagging_fraction과 baggin_freq 을 설정하여 bagging 을 적용\n- feature_fraction을 설정하여 feature sub-sampling을 하기\n- 작은 max_bin 값을 사용\n- save_binary 를 값을 통해 다가오는 학습에서 데이터 로딩 속도를 줄이기\n- parallel learning 병렬 학습을 적용\n- early_stopping_round : 만약 어떤 validation 데이터 중 하나의 지표가 지난 early_stopping_round 라운드에서 향상되지 않았다면 학습을 중단한다. 이는 지나친 iteration을 줄이는데 도움이 된다.\n\n\n더 나은 정확도를 위해 :\n\n- 큰 max_bin 값을 사용 (아마 속도는 느려질 수 있습니다)\n- 작은 learning_rate 값을 큰 num_iterations 값과 함께 사용\n- 큰 num_leaves 값을 사용 (아마 과적합을 유발할 수도 있습니다)\n- 더 큰 트레이닝 데이터를 사용\n- dart를 사용\n- 범주형 feature를 사용\n\n\n과적합을 해결하기 위해 :\n\n- 작은 max_bin 값을 사용\n- 작은 num_leaves 값을 사용\n- min_data_in_leaf 와 min_sum_hessian_in_leaf 파라미터를 사용\n- bagging_fraction 과 bagging_freq 을 사용하여 bagging 을 적용\n- feature_fraction을 세팅하여 feature sub-sampling을 하기\n- lambda_l1, lambda_l2 그리고 min_gain_to_split 파라미터를 이용해 regularization (정규화) 를 적용\n- max_depth 를 설정해 Deep Tree 가 만들어지는 것을 방지\n\n[출처]https://nurilee.com/2020/04/03/lightgbm-definition-parameter-tuning/","metadata":{}},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.893164Z","iopub.execute_input":"2021-09-10T10:03:35.893581Z","iopub.status.idle":"2021-09-10T10:03:35.902934Z","shell.execute_reply.started":"2021-09-10T10:03:35.893542Z","shell.execute_reply":"2021-09-10T10:03:35.90154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# y_pred_lgb = np.zeros(len(X_test))\n\n# num_round = 1000000 # 일반적으로 100 이상\n\n# fold_n=5\n# folds = StratifiedKFold(n_splits=fold_n, shuffle=True, random_state=10)\n\n# for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n#     print('Fold', fold_n, 'started at', time.ctime())\n#     X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n#     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n#     # train 데이터를 LightGBM에 맞는 데이터 세트 포맷으로 변환\n#     train_data = lgb.Dataset(X_train, label=y_train)\n#     valid_data = lgb.Dataset(X_valid, label=y_valid)\n        \n#     lgb_model = lgb.train(params, train_data, num_round,#change 20 to 2000\n#                     valid_sets = [train_data, valid_data], verbose_eval=1000, early_stopping_rounds = 3500)##change 10 to 200\n            \n#     y_pred_lgb += lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)/5 # folds.n_splits","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.904804Z","iopub.execute_input":"2021-09-10T10:03:35.905159Z","iopub.status.idle":"2021-09-10T10:03:35.914182Z","shell.execute_reply.started":"2021-09-10T10:03:35.905127Z","shell.execute_reply":"2021-09-10T10:03:35.913191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test2 = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T11:44:47.470113Z","iopub.execute_input":"2021-09-10T11:44:47.470713Z","iopub.status.idle":"2021-09-10T11:44:55.536408Z","shell.execute_reply.started":"2021-09-10T11:44:47.470659Z","shell.execute_reply":"2021-09-10T11:44:55.535355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission_lgb = pd.DataFrame({\n#         \"ID_code\": test2[\"ID_code\"],\n#         \"target\": y_pred_lgb\n#     })\n# submission_lgb.to_csv('submission_lgb.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.915482Z","iopub.execute_input":"2021-09-10T10:03:35.915782Z","iopub.status.idle":"2021-09-10T10:03:35.929434Z","shell.execute_reply.started":"2021-09-10T10:03:35.915753Z","shell.execute_reply":"2021-09-10T10:03:35.928508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 제출 : 스코어 0.84381 ","metadata":{}},{"cell_type":"markdown","source":"### catboost\n- https://www.kaggle.com/mjbahmani/santander-ml-explainability","metadata":{}},{"cell_type":"code","source":"# from catboost import CatBoostClassifier,Pool\n\n# train_pool = Pool(train_X, train_y)\n# cat_model = CatBoostClassifier(\n#                                iterations=3000,# change 25 to 3000 to get best performance \n#                                learning_rate=0.03,\n#                                objective=\"Logloss\",\n#                                eval_metric='AUC',\n#                               )\n# cat_model.fit(train_X,train_y,silent=True)\n# y_pred_cat = cat_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.931036Z","iopub.execute_input":"2021-09-10T10:03:35.931423Z","iopub.status.idle":"2021-09-10T10:03:35.943458Z","shell.execute_reply.started":"2021-09-10T10:03:35.931388Z","shell.execute_reply":"2021-09-10T10:03:35.942267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission_cat = pd.DataFrame({\n#         \"ID_code\": test2[\"ID_code\"],\n#         \"target\": y_pred_cat\n#     })\n# submission_cat.to_csv('submission_cat.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.944677Z","iopub.execute_input":"2021-09-10T10:03:35.945112Z","iopub.status.idle":"2021-09-10T10:03:35.955539Z","shell.execute_reply.started":"2021-09-10T10:03:35.945068Z","shell.execute_reply":"2021-09-10T10:03:35.954187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 제출 : 스코어 0.73194","metadata":{}},{"cell_type":"markdown","source":"### lightGBM\n- https://www.kaggle.com/gpreda/santander-eda-and-prediction","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.956732Z","iopub.execute_input":"2021-09-10T10:03:35.957135Z","iopub.status.idle":"2021-09-10T10:03:35.998721Z","shell.execute_reply.started":"2021-09-10T10:03:35.957101Z","shell.execute_reply":"2021-09-10T10:03:35.997326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:35.999968Z","iopub.execute_input":"2021-09-10T10:03:36.000471Z","iopub.status.idle":"2021-09-10T10:03:36.039716Z","shell.execute_reply.started":"2021-09-10T10:03:36.000422Z","shell.execute_reply":"2021-09-10T10:03:36.03858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = train['target']","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.040986Z","iopub.execute_input":"2021-09-10T10:03:36.041281Z","iopub.status.idle":"2021-09-10T10:03:36.050752Z","shell.execute_reply.started":"2021-09-10T10:03:36.041252Z","shell.execute_reply":"2021-09-10T10:03:36.049861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\noof = np.zeros(len(train))\npredictions = np.zeros(len(test))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n\n    num_round = 1000000\n    clf = lgb.train(params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 3000)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:06:59.200399Z","iopub.execute_input":"2021-09-10T10:06:59.200815Z","iopub.status.idle":"2021-09-10T11:42:12.72122Z","shell.execute_reply.started":"2021-09-10T10:06:59.200777Z","shell.execute_reply":"2021-09-10T11:42:12.720039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(target, oof)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T11:43:14.975493Z","iopub.execute_input":"2021-09-10T11:43:14.97596Z","iopub.status.idle":"2021-09-10T11:43:15.055533Z","shell.execute_reply.started":"2021-09-10T11:43:14.975917Z","shell.execute_reply":"2021-09-10T11:43:15.054585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_lgb2 = pd.DataFrame({\n        \"ID_code\": test2[\"ID_code\"],\n        \"target\": predictions\n    })\nsubmission_lgb2.to_csv('submission_lgb2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T11:45:02.653643Z","iopub.execute_input":"2021-09-10T11:45:02.654016Z","iopub.status.idle":"2021-09-10T11:45:03.45913Z","shell.execute_reply.started":"2021-09-10T11:45:02.653985Z","shell.execute_reply":"2021-09-10T11:45:03.458086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 제출 : 스코어 0.89692","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.countplot(train.cluster, palette=\"Set2\", ax=ax[0])\nsns.distplot(train.logL, color=\"Dodgerblue\", ax=ax[1]);","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.674553Z","iopub.status.idle":"2021-09-10T10:03:36.675011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Gaussian Mixture Model을 학습시킴으로써 로그 우도(log likelihood)를 최대화하고 있다.(logL)\n- 로그 우도(logL)가 높을 수록 데이터가 가우시안 분포에 더 잘 맞는다는 것이다.\n- 올바른 n_components를 선택하는 것이 어렵기 때문에 train 데이터의 stratified k fold를 사용하자.\n- 이렇게 하면 train subset에 가우시안을 적합시키고, test subset에서 로그 우도가 얼마나 큰지 검정할 수 있다.\n- 선택한 n_components에 대해 3번(k=3) 이 작업을 수행하면 solution의 안전성에 대한 정보를 얻을 수 있다.\n- **n_components가 클수록 로그 우도 값이 감소하므로 n_components=3일 때 충분하다는 것을 알 수 있다.**","metadata":{}},{"cell_type":"markdown","source":"- **데이터 spot당 개별 점수(logL)는 밀도를 측정하는 척도로 이해할 수 있다.** \n- logL이 낮으면 데이터 spot이 다른 데이터 지점과 멀리 떨어진 곳에 있는 것이다. -> 멀리 떨어져 있다? -> 이상치인가?\n- logL이 높으면 이웃이 많을 것이다.(주변에 데이터가 많다.) -> 이상치 아님\n- **따라서 개별 logL-score는 데이터의 이상치에 대한 정보를 제공할 수 있다.**\n    - 구체적으로 logL-score를 보고 어떻게 이상치를 확인하는데?\n    - 가장 낮은 데이터들을 제거해야 되는 거야?","metadata":{}},{"cell_type":"code","source":"train[\"logL\"].sort_values()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.676019Z","iopub.status.idle":"2021-09-10T10:03:36.67647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"logL\"].argsort() # 오름차순 -> 제일 큰 값의 인덱스가 맨 아래","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.677372Z","iopub.status.idle":"2021-09-10T10:03:36.677805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"cluster\").target.value_counts() / train.groupby(\"cluster\").size() * 100","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.678716Z","iopub.status.idle":"2021-09-10T10:03:36.679149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cluster_occupation\n(train.groupby(\"cluster\").target.value_counts() / train.groupby(\"cluster\").size() * 100).loc[:, 1]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.680281Z","iopub.status.idle":"2021-09-10T10:03:36.680714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# target_occupation\n(train.groupby(\"target\").cluster.value_counts() / train.groupby(\"target\").size() * 100).loc[1, :]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.681566Z","iopub.status.idle":"2021-09-10T10:03:36.682001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 각 cluster가 target=1일 확률\ncluster_occupation = train.groupby(\"cluster\").target.value_counts() / train.groupby(\"cluster\").size() * 100\ncluster_occupation = cluster_occupation.loc[:, 1] \n\n# target=1인 데이터가 각 클러스터에 속할 확률\ntarget_occupation = train.groupby(\"target\").cluster.value_counts() / train.groupby(\"target\").size() * 100\ntarget_occupation = target_occupation.loc[1, :]\ntarget_occupation.index = target_occupation.index.droplevel(\"target\")\n\nfig, ax = plt.subplots(1,2,figsize=(20,5))\nax[0].set_title(\"How many % of the data per cluster has hot targets?\")\nsns.barplot(cluster_occupation.index, cluster_occupation.values, ax=ax[0], color=\"cornflowerblue\")\nax[0].set_ylabel(\"% of cluster data\")\nax[0].set_ylim([0,100])\n\nax[1].set_title(\"How many % of total hot targets are in one cluster?\")\nsns.barplot(target_occupation.index, target_occupation.values, ax=ax[1], color=\"tomato\")\nax[1].set_ylabel(\"% of hot targets\")\nax[1].set_ylim([0,100]);","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.683015Z","iopub.status.idle":"2021-09-10T10:03:36.68348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- cluster 2 has more hot target(1) than others\n- hot target(1)의 대부분이 cluster 2에 위치한다.","metadata":{}},{"cell_type":"markdown","source":"- 클러스터링으로 데이터 분류\n- 어떤 기준으로 클러스터링? -> 가우시안 분포도?\n- 분류별로 target=1이 속한 비율 확인하기(그래프)\n- 어떤 클러스터에 target=1인 데이터가 많은지 확인 가능, 순서도\n","metadata":{}},{"cell_type":"code","source":"# # KFold로 데이터 나눠서 RandomForestClassifier 모델 돌림\n\n# cv = StratifiedKFold(n_splits=3, random_state=0)\n# forest = RandomForestClassifier(max_depth=15, n_estimators=15, min_samples_leaf=20,\n#                                 n_jobs=-1)\n\n# scores = []\n# X = train.drop(\"target\", axis=1).values\n# y = train.target.values\n\n# for train_idx, test_idx in cv.split(X, y):\n#     x_train = X[train_idx]\n#     x_test = X[test_idx]\n#     y_train = y[train_idx]\n#     y_test = y[test_idx]\n    \n#     forest.fit(x_train, y_train)\n#     y_proba = forest.predict_proba(x_test)\n#     y_pred = np.zeros(y_proba.shape[0])\n#     y_pred[y_proba[:,1] >= 0.166] = 1\n    \n#     score = roc_auc_score(y_test, y_pred)\n#     print(score)\n#     scores.append(score)\n\n# print(np.round(np.mean(scores),4))\n# print(np.round(np.std(scores), 4))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.684475Z","iopub.status.idle":"2021-09-10T10:03:36.684913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gm.means_[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.685755Z","iopub.status.idle":"2021-09-10T10:03:36.686179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gm.means_.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.687119Z","iopub.status.idle":"2021-09-10T10:03:36.687569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nfor n in range(gm.means_.shape[0]): # 클러스터 3개 -> gm.means_.shape[0] : 3\n    plt.plot(gm.means_[n,:], 'o')\nplt.title(\"How do the gaussian means look like?\")\nplt.ylabel(\"Cluster mean value\")\nplt.xlabel(\"Feature\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:03:36.688762Z","iopub.status.idle":"2021-09-10T10:03:36.689184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only some features are important to separate the structure of the data.","metadata":{}},{"cell_type":"markdown","source":"- 그래서 어떤 피처를 사용해야 되는데?\n- 이상치 처리는 어떻게 하는데?\n- 피처 선택을 하긴 하는 거야?","metadata":{}}]}