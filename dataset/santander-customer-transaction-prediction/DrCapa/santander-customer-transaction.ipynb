{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Intro\nWelcome to the [Santander Customer Transaction Prediction](https://www.kaggle.com/c/santander-customer-transaction-prediction/overview)\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/10385/logos/header.png)\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Thank you. </span>"},{"metadata":{},"cell_type":"markdown","source":"# Libraries\nWe load some standard libraries and packages of sklearn."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Path\nDefine the input path and show the content of the input folder:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"path = '/kaggle/input/santander-customer-transaction-prediction/'\nos.listdir(path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(path+'train.csv')\ntest_data = pd.read_csv(path+'test.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Overview"},{"metadata":{},"cell_type":"markdown","source":"This is a big dataset with 200,000 samples and 200 features:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('number of train samples:', len(train_data))\nprint('number of test samples:', len(test_data))\nprint('number of features:', len(train_data.columns)-2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The target distribution is very imbalanced:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_data['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values on the train and test data:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_data.isnull().sum().sum(), test_data.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA\nWe want to analyse if we can reduce the dimension of the features:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pca = PCA().fit(train_data[train_data.columns[2:]])\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('No of components')\nplt.ylabel('Cumulative explained variance')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the cumulative variance, overall 99% is being captured by about 150 components. Hence, we can decide that the number of principal components for our dataset is 150. This is a reduction about 25%."},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\nFor every sample (row) we add the statistical features sum, mean, std, min and max:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_data['sum'] = train_data[train_data.columns[2:202]].sum(axis=1)\ntest_data['sum'] = test_data[test_data.columns[1:201]].sum(axis=1)\ntrain_data['mean'] = train_data[train_data.columns[2:202]].mean(axis=1)\ntest_data['mean'] = test_data[test_data.columns[1:201]].mean(axis=1)\ntrain_data['std'] = train_data[train_data.columns[2:202]].std(axis=1)\ntest_data['std'] = test_data[test_data.columns[1:201]].std(axis=1)\ntrain_data['min'] = train_data[train_data.columns[2:202]].min(axis=1)\ntest_data['min'] = test_data[test_data.columns[1:201]].min(axis=1)\ntrain_data['max'] = train_data[train_data.columns[2:202]].max(axis=1)\ntest_data['max'] = test_data[test_data.columns[1:201]].max(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the distribution of the new features for train (upper row) and test (lower row) data:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_distrubution():\n    fig, axs = plt.subplots(2, 5, figsize=(20, 5))\n    fig.subplots_adjust(hspace = 0.5, wspace=0.2)\n    axs = axs.ravel()\n    features = ['sum', 'mean', 'std', 'min', 'max']\n    bins = 50\n    for col in range(5):\n        axs[col].hist(train_data[features[col]], bins=bins, color='blue', alpha=0.7)\n        axs[col+5].hist(test_data[features[col]], bins=bins, color='red', alpha=0.7)\n        axs[col].set_title(features[col]+' - train')\n        axs[col+5].set_title(features[col]+' - test')\n        axs[col].set_ylabel('Frequence')\n        axs[col+5].set_ylabel('Frequence')\n        axs[col].grid()\n        axs[col+5].grid()\n        axs[col].set_yticks([])\n        axs[col+5].set_yticks([])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_distrubution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Train and Test Data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X_train = train_data[train_data.columns[2:]]\ny_train = train_data['target']\nX_test = test_data[test_data.columns[1:]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"assert(len(X_train.columns) == len(X_test.columns))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('number of train samples:', len(X_train))\nprint('number of test samples:', len(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scale Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max = MinMaxScaler()\nX_train = min_max.fit_transform(X_train)\nX_test = min_max.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split Train And Val"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=2020)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('number of train samples:', len(X_train))\nprint('number of val samples:', len(X_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.XGBRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'objective': ['binary:logistic'],\n          'random_sate': [2020],\n          'n_estimators': [300, 500, 700],\n          'max_depth': [4, 6, 8],\n          'learning_rate': [0.1, 0.01]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = GridSearchCV(model, params, n_jobs=4, scoring='roc_auc', verbose=3)\ngrid.fit(X_train, y_train)\nprint('best score:', grid.best_score_)\nprint('best param:', grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.set_param(**grid.best_params_)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict validation data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val_pred = model.predict(X_val)\nroc_auc_score(y_val, y_val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict test data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write Output"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"output = pd.DataFrame({'ID_code': samp_subm['ID_code'],\n                       'target': y_test})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"output['target'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}