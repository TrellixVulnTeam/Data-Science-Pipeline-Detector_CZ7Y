{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Santander Kaggle\n## Customer Transaction Prediction\n\n\n<img src=\"https://i.imgur.com/3jkg3yS.jpg\" />\n\n\n\n\n\n## Neste desafio será necessário prever a variável target do DataSet\n\n## Santander: Overview da proposta do desafio\n\n No Santander, nossa missão é ajudar pessoas e empresas a prosperar. Estamos sempre procurando maneiras de ajudar nossos clientes a entender sua saúde financeira e identificar quais produtos e serviços podem ajudá-los a atingir suas metas monetárias.\n\n Nossa equipe de ciência de dados está desafiando continuamente nossos algoritmos de aprendizado de máquina, trabalhando com a comunidade global de dados científicos para garantir que possamos identificar com mais precisão novas maneiras de resolver nosso desafio mais comum, problemas de classificação binária como: um cliente está satisfeito? Um cliente comprará este produto? Um cliente pode pagar este empréstimo?\n\n Neste desafio, convidamos a Kagglers a nos ajudar a identificar quais clientes farão uma transação específica no futuro, independentemente do volume de dinheiro transacionado. Os dados fornecidos para esta competição têm a mesma estrutura que os dados reais que temos disponíveis para resolver este problema.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\n%matplotlib inline\n\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time train_data = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv')\n%time test_data = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Verificando a variável target:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=train_data.target ,data=train_data)\nplt.xlabel(\"Contagem dos valores da target\")\nplt.ylabel(\"Target\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note que a um desbalenaceamento da target, mas vamos prosseguir mesmo com esse desbalanecamento.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Vamos verificar se a desbalanceamento na demais variáveis:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.hist(figsize=(30,24),bins = 15)\nplt.title(\"Distribuição das variáveis\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note que as variávies então próximas de uma curva normal ou seja não estão muito desbalanceadas, estão muito boas logo seguiremos para os próximos passo. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Redução de dimensionalidade 'PCA'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Por que o PCA agora ?\n\nResposta: O PCA é usado principalmente como uma ferramenta na análise exploratória de dados e na criação de modelos preditivos.\n\nSe tivermos dados de alta dimensão, pode ser difícil plotá-lo de maneira eficaz. Às vezes, a plotagem dos dois primeiros componentes principais pode revelar uma estrutura geométrica interessante nos dados.\n\nE ele encontra atributos / variáveis ​​ essenciais (seleção de recursos em dados de alta dimensão)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nmmscale = MinMaxScaler()  \nX_train = mmscale.fit_transform(train_data.drop(['ID_code','target'],axis=1))  \nX_test = mmscale.transform(test_data.drop(['ID_code'], axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA()  \na = pca.fit_transform(X_train) \nb = pca.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"variancia_pca = pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(variancia_pca,columns=['Variância após o PCA']).plot(kind='box')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context('classic'):\n    plt.figure(figsize=(12, 9))\n\n    plt.bar(range(200), variancia_pca, alpha=0.5, align='center',\n            label='variância individual')\n    plt.ylabel('Taxa de variância')\n    plt.xlabel('Componentes principais')\n    plt.legend(loc='best')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(variancia_pca[:100])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusão: Não usaremos o PCA, pois encotramos baixa correlação entre as variáveis, portanto o PCA não ficaria eficaz nesse cenário:**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Vamos criar um Modelo com Gaussian Naive","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_data.iloc[:, 2:].values.astype('float64')\ny_train = train_data['target'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import QuantileTransformer\n\npipeline = make_pipeline(QuantileTransformer(output_distribution='normal'), GaussianNB())\npipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Após o treinamento do modelo, plotamos a curva ROC nos dados de treinamento e avaliamos o modelo calculando a AUC do treinamento e a AUC para validação","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thr = roc_curve(y_train, pipeline.predict_proba(X_train)[:,1])\nplt.plot(fpr, tpr)\nplt.xlabel('Taxa de falsos positivos')\nplt.ylabel('Taxa verdadeiros positivos')\nplt.title('Curva ROC')\nauc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aplicando o Cross-Validation para obter um score:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ncross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=10).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclução: Alcançamos uma boa AUC em treinamento e uma boa Cross-Validation com score de 0.889**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}