{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing the necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"Basic details of the data:\n \n- Shape\n- features\n- null values\n- data types\n- sample of the data\n- statistical description "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of columns in the data\",data.shape[1])\nprint(\"The number of rows in the data\",data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The data types of the data are as follows:\")\ndata.info(verbose=True, show_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Understanding the data visually"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting target to category\n\ndata['target'] = data['target'].astype('category')\ntarget = data['target'].value_counts().to_frame()\n\nfig , ax = plt.subplots(figsize=(15,8))\nax.bar(target.index,target['target'])\nax.xaxis.set_ticks([0,1])\nax.xaxis.set_ticklabels(['No transaction','transaction'])\nax.xaxis.set_ticklabels(ax.xaxis.get_ticklabels(),fontsize=20)\n\nfor x in ax.patches:\n    value = x.get_height()\n    ax.text(x.get_x() + x.get_width()/2,value+10,value, ha='center', fontsize=20)\n    \nax.set_title('Count of Target', fontsize = 20)\nax.set_ylabel('Count')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def range_val(X):\n    \n    ran = {}\n    for col in X.columns:\n        if X[col].dtype == 'float64':\n            minimum = min(X[col])\n            maximum = max(X[col])\n            ran[col] = maximum - minimum\n    return ran","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_range = range_val(data)\ncol_range1 = pd.DataFrame(col_range,index=['range']).melt()\n\nlabels = np.arange(0,200)\n\nax = col_range1.plot(kind='bar',figsize=(30,10))\nax.xaxis.set_ticklabels(labels,fontsize=6,rotation = 30)\n\nax.set_title('Range of values across columns',fontsize=20)\nax.set_xlabel('Columns')\nax.set_ylabel('values')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def min_max(X):\n    \n    minmax = {}\n    for col in X.columns:\n        if X[col].dtype == 'float64':\n            minimum = min(X[col])\n            maximum = max(X[col])\n            minmax[col] = [minimum,maximum]\n    return minmax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_minmax = min_max(data)\ncol_minmax1 = pd.DataFrame(col_minmax,index=['Min','Max'])\nfig, ax = plt.subplots(figsize=(30,8))\nax.boxplot(col_minmax1, showfliers=False,showbox=True, showmeans=False, whis=[0,100])\nax.axhline(0, label=\"zeroline\")\nlabels = np.arange(0,200)\nax.xaxis.set_ticklabels(labels, fontsize=6, rotation =30)\n\nax.set_title('Min and Max values across columns', fontsize=20)\nax.set_xlabel('Columns')\nax.set_ylabel('values')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tran = data[data['target']==1]\nnon = data[data['target']==0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am plotting the distributions of each column with respect to the target variable being 0 and 1. \\\nThis is done to observe if there are any considerable differences with the distributions for the transactions vs the non transactions."},{"metadata":{"trusted":true},"cell_type":"code","source":"features100 = data.columns[2:102]\n#features100\n\nfig, ax = plt.subplots(nrows=10,ncols=10,figsize=(30,30))\n\nfig.tight_layout()\n\nfor x,col in zip(ax.flat,features100):\n   \n    #plt.subplot(10,10,i)\n    x.hist(tran[col],density=True, label='1')\n    x.hist(non[col],density=True,alpha=0.7, label='0')\n    x.legend()\nfig.suptitle('Distribution of data with respect to target transaction and non transaction', fontsize=20,y=1.03 )\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features200 = data.columns[102:]\n\nfig, ax = plt.subplots(10,10, figsize=(30,30))\n\nfig.tight_layout()\n\nfor x,col in zip(ax.flat,features200):\n    \n    x.hist(tran[col],density=True, label='1')\n    x.hist(non[col],density=True, alpha=0.7,label='0')\n    x.legend()\nfig.suptitle('Distribution of data with respect to target transaction and non transaction', fontsize=20,y=1.03)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We sure do observe slight difference in the variation of distribution but noting note worthy.\\\nThis variabtion could be taken as randomness in collecting data."},{"metadata":{"trusted":true},"cell_type":"code","source":"col = {}\n\nfor x in data.columns:\n    \n    if data[x].dtype == 'float64':\n        col[x] = data[x].value_counts().index[0],max(data[x].value_counts())\n\nduplicate = pd.DataFrame(col,index=['value','count'])\n#duplicate.sort_values('count',ascending=False,axis=1, inplace=True)\n\nduplicate = duplicate.T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we find the highest count of duplicates in the data across columns.\\\nWe find the column var_68 has a single value which is unusally high. This column needs further analysis to see if there has been more transactions with duplicate values"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(30,10))\n\nax.bar(duplicate.index, duplicate['count'])\n\nax.set_xticks(np.arange(len(duplicate)))\nax.set_xticklabels(np.arange(0,200),rotation = 30, fontsize=7)\n\nfor x,value in zip(ax.patches, duplicate['value']):\n    \n    ax.text(x.get_x()+x.get_width()/2, x.get_height()+10, value, ha='center',rotation=90, fontsize=7)\n\nax.set_title('Highest duplicates and the value of dupicates',fontsize=20)\nplt.setp(ax,xlabel='variable',ylabel='count',ylim=[0,1220])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = data[data['var_68'] == 5.0214][['var_68','target']].groupby('target').count().plot(kind='bar',figsize=(15,8))\nax.set_title('Analysing the highest dupicate value with the target', fontsize=20)\nax.set_ylabel('count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"observing this graph we do find that there is not much of abnormality. the porportion of trancations(1) is comparable to the whole dataset."},{"metadata":{},"cell_type":"markdown","source":"Down below I display the correlation table.\\\nFrom the table it is very evident that the features do not have high correlation with the target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = data.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{},"cell_type":"markdown","source":"First, I am importing the test dataset.\\\nThen importing all the required libraries\n\nSplitting the data to train and test.\nFirst applying Naive bayes, getting a benchmark score.\n\nNow implementing standardscaler and then a quantile transformation.\nThis is to bring the data to a gaussian distribution and move all the values to mean of 0.\n\nThis helps imporve the prediction. I ended up with a accuracy of about 0.923\n\nNow finally implementing the model in the test set and submitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split, cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, QuantileTransformer\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(['target','ID_code'],axis=1)\ny = data['target']\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NB = GaussianNB()\nNB.fit(X_train,y_train)\npredict = NB.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,predict)\naccuracy_score(y_test,predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nqa = QuantileTransformer(output_distribution='normal')\nsfk = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline(steps=[('t',scaler),('q',qa),('m',NB)])\npipeline.fit(X_train,y_train)\nscore = cross_val_score(pipeline,X_train,y_train,scoring='accuracy',cv = sfk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pipeline.predict_proba(test.drop('ID_code',axis=1))[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/santander-customer-transaction-prediction/sample_submission.csv')\nsample_submission['target'] = predict ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()\nsample_submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion:\n\nAfter understanding the data through EDA, and applying Naive Bayes I have mangaged to get a accuracy score of 0.923."},{"metadata":{},"cell_type":"markdown","source":"# Reference:\n\nhttps://www.kaggle.com/blackblitz/gaussian-naive-bayes\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}