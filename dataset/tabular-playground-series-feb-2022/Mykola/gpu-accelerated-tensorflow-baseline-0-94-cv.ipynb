{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Basic model baseline","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, KFold\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:20:00.421761Z","iopub.execute_input":"2022-02-01T18:20:00.422154Z","iopub.status.idle":"2022-02-01T18:20:06.672518Z","shell.execute_reply.started":"2022-02-01T18:20:00.422023Z","shell.execute_reply":"2022-02-01T18:20:06.671428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{}},{"cell_type":"code","source":"csv_train = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/train.csv')\ncsv_test = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/test.csv')\ncsv_submission = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/sample_submission.csv')\n\nlbl_coder = LabelEncoder()\nlbl_coder.fit(csv_train.target)\n\ncsv_train['target'] = lbl_coder.transform(csv_train.target)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:20:08.986287Z","iopub.execute_input":"2022-02-01T18:20:08.986589Z","iopub.status.idle":"2022-02-01T18:20:45.717843Z","shell.execute_reply.started":"2022-02-01T18:20:08.986557Z","shell.execute_reply":"2022-02-01T18:20:45.716823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define feature columns\n\nIt would be easy to slice input features and targets using predefined column names. Even more - we are aware of column positions by accesing features by column names","metadata":{}},{"cell_type":"code","source":"feature_columns = {x for x in csv_train.columns}.difference({'row_id', 'target'})\ntarget = 'target'","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:20:45.728186Z","iopub.execute_input":"2022-02-01T18:20:45.728851Z","iopub.status.idle":"2022-02-01T18:20:45.740805Z","shell.execute_reply.started":"2022-02-01T18:20:45.728808Z","shell.execute_reply":"2022-02-01T18:20:45.739722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hists = []\nfor i, (train_idx, val_idx) in enumerate(KFold().split(csv_train)):\n    print(f'Fold #{i}')\n    _csv_train = csv_train.iloc[train_idx]\n    _csv_val = csv_train.iloc[val_idx]\n    \n    model = tf.keras.models.Sequential([\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(32, activation='relu' ),\n        tf.keras.layers.Dense(32, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(16, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(10, activation='softmax'),\n    ])\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n\n    x = _csv_train[feature_columns].to_numpy()\n    y = tf.one_hot(_csv_train[target], 10)\n\n    x_val = _csv_val[feature_columns].to_numpy()\n    y_val = tf.one_hot(_csv_val[target], 10)\n\n    save_cb = tf.keras.callbacks.ModelCheckpoint(f'./best_val_{i}', save_best_only=True, monitor='val_loss', save_weights_only=True)\n\n    class LearningRateReducerCb(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            old_lr = self.model.optimizer.lr.read_value()\n            new_lr = old_lr * 0.99\n            self.model.optimizer.lr.assign(new_lr)\n\n    h = model.fit(x, y, validation_data=(x_val, y_val), epochs=20, batch_size=256, verbose=0, callbacks=[save_cb, LearningRateReducerCb()])\n    hists.append(h)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:20:53.056837Z","iopub.execute_input":"2022-02-01T18:20:53.057214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = []\n\nsplits = list(KFold().split(csv_train))\n\nfor i in range(5):\n    model.load_weights(f'./best_val_{i}')\n    val_idx = splits[i][1]\n    \n    _csv_val = csv_train.iloc[val_idx]\n    \n    x_val = _csv_val[feature_columns].to_numpy()\n    y_val = tf.one_hot(_csv_val[target], 10)\n    \n    acc = model.evaluate(x_val, y_val)[1]\n    scores.append(acc)\n    \nprint(f'CV score: {np.mean(scores)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor i in range(5):\n    model.load_weights(f'./best_val_{i}')\n    test_pred = np.argmax(model.predict(csv_test[feature_columns]), axis=-1)\n    predictions.append(test_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n \ndef most_frequent(List):\n    occurence_count = Counter(List)\n    return occurence_count.most_common(1)[0][0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_matrix = np.stack(predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_maj = []\n\nfor i in range(pred_matrix.shape[1]):\n    pred_maj.append(most_frequent(pred_matrix[:, i]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_str = lbl_coder.inverse_transform(pred_maj)\ncsv_submission['target'] = test_pred_str\ncsv_submission.to_csv('./submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}