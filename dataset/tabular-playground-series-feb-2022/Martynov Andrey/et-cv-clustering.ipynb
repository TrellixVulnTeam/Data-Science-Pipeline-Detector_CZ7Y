{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install scikit-learn-intelex\nfrom sklearnex import patch_sklearn\npatch_sklearn()\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport gc\nfrom math import factorial\nfrom datetime import datetime\nfrom scipy.stats import mode\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Previous attempt\n*  In previous notebook [Four models, one for each GCD](https://www.kaggle.com/martynovandrey/four-models-one-for-each-gcd) I tried to split the dataset into four by GCD and model separately.","metadata":{}},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv', index_col=\"row_id\")\ntest = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv', index_col=\"row_id\").astype(np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add GCD feature","metadata":{}},{"cell_type":"code","source":"elements = [e for e in train.columns if e != 'row_id' and e != 'target']\n\ndef bias(w, x, y, z):\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ndef bias_of(s):\n    w = int(s[1:s.index('T')])\n    x = int(s[s.index('T')+1:s.index('G')])\n    y = int(s[s.index('G')+1:s.index('C')])\n    z = int(s[s.index('C')+1:])\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ntrain_i = pd.DataFrame({col: ((train[col] + bias_of(col)) * 1000000).round().astype(int) for col in elements})\ntest_i = pd.DataFrame({col: ((test[col] + bias_of(col)) * 1000000).round().astype(int) for col in elements})\n\ndef gcd_of_all(df_i):\n    gcd = df_i[elements[0]]\n    for col in elements[1:]:\n        gcd = np.gcd(gcd, df_i[col])\n    return gcd\n\ntrain['gcd'] = gcd_of_all(train_i)\ntest['gcd'] = gcd_of_all(test_i)\n\ndel train_i\ndel test_i\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(\"target\", axis=1).astype(np.float32)\n\ntarget_encoder = LabelEncoder()\ny = pd.Series(target_encoder.fit_transform(train[\"target\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"fold_probs = []\ny_preds = []\nscores = []\n\nfolds = StratifiedKFold(n_splits=20, shuffle=True)\nestimators = 2500\n\nfor fold, (train_id, test_id) in enumerate(folds.split(X, y)):  \n    X_train = X.iloc[train_id]\n    y_train = y.iloc[train_id]\n    X_valid = X.iloc[test_id]\n    y_valid = y.iloc[test_id]\n    \n    model = ExtraTreesClassifier(n_estimators=estimators, n_jobs=-1)\n    \n    start = datetime.now()\n    model.fit(X_train, y_train)\n    end = datetime.now()\n    \n    valid_pred = model.predict(X_valid)\n    valid_score = accuracy_score(y_valid, valid_pred)\n    \n    print(\"Fold:\", fold + 1, \"Accuracy:\", valid_score, 'Time:', end - start)\n    \n    scores.append(valid_score)\n    \n    # Save predictions to later submit the mean values\n    y_preds.append(model.predict(test))\n    fold_probs.append(model.predict_proba(test))\n\nprint(\"Mean accuracy score:\", np.array(scores).mean())    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = target_encoder.inverse_transform(mode(y_preds).mode[0])\n\nmean_prob = sum(fold_probs) / len(fold_probs) # Mean probability for each row\nmean_prob += np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0.027, 0, 0])\n\nmean_pred = target_encoder.inverse_transform(np.argmax(mean_prob, axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\")\nsubmission[\"target\"] = target_encoder.inverse_transform(np.argmax(mean_prob, axis=1))\n# out.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clustering","metadata":{}},{"cell_type":"code","source":"def pca_gcd10_full(df, target):\n    \"\"\"Plot a 2d projection of all points of df with gcd = 10, colored by target\"\"\"\n    subset = df[df.gcd == 10]\n    pred_subset = target_encoder.transform(target)[df.gcd == 10]\n    # Compute the PCA\n    pca3 = TruncatedSVD(n_components=10, random_state=1)\n    pca3.fit(subset[elements])\n\n    # Transform the data so that the components can be analyzed\n    Xt_tr3 = pca3.transform(subset[elements])\n    \npca_gcd10_full(train, train.target)\npca_gcd10_full(test, submission.target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pca_gcd10_selection(df, target, title, clustering, innermost):\n    \"\"\"Plot a 2d projection of certain points of df, colored by target\n    or by a clustering, and add the new clustering labels to df.\n    \n    We select the two innermost clusters with gcd = 10 of bacteria 3 and 4\"\"\"\n    # Get the subset\n    subset = df[df.gcd == 10].copy()\n    subset['radius'] = np.sqrt(np.square(subset[elements]).sum(axis=1))\n    subset['pred'] = target_encoder.transform(target)[df.gcd == 10]\n    mean_radius = subset.radius.groupby(subset.pred).mean()\n    mean_radius.name = 'mean_radius'\n    subset = subset.merge(mean_radius, left_on='pred', right_index=True).sort_index()\n    if innermost:\n        selection = ((subset.radius < subset.mean_radius * 0.388) &\n                     subset.pred.isin([3, 4]))\n    else:\n        selection = ((subset.radius >= subset.mean_radius * 0.388) &\n                     (subset.radius < subset.mean_radius * 0.64) & \n                     subset.pred.isin([3, 4]))\n    subset = subset[selection]\n    if clustering:\n        # Cluster the data into two clusters\n        km = KMeans(n_clusters=2, random_state=1)\n\n        km.fit(subset[elements])\n        # For every cluster, predict the most frequent label for all cluster members\n        new_pred = subset.pred.groupby(km.labels_).transform(lambda s: [mode(s)[0][0]] * len(s))\n        print(f\"Relabeled {(new_pred != subset.pred).sum()} samples\")\n\n    # Compute the PCA\n    pca3 = TruncatedSVD(n_components=10, random_state=1)\n    pca3.fit(subset[elements])\n\n    # Transform the data so that the components can be analyzed\n    Xt_tr3 = pca3.transform(subset[elements])\n\n    # Plot a scattergram, projected to two PCA components\n#     d0, d1 = 2, 1\n#     plt.scatter(Xt_tr3[:,d0], Xt_tr3[:,d1],\n#                 cmap=ListedColormap(plt.get_cmap('tab10').colors[3:5]),\n#                 c=(new_pred if clustering else subset.pred),\n#                 s=25)\n#     plt.title(title)\n    if clustering:\n        selected = pd.Series(False, index=df.index)\n        selected.loc[df.gcd == 10] = selection\n        df.loc[selected, 'new_pred'] = new_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(train, train.target, \n                    'Training, gcd=10: True labels',\n                    clustering=False, innermost=True)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(train, train.target,\n                    'Training, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=True)\nplt.show()\n\nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(test, submission.target, \n                    'Test, gcd=10: Labels of top submission',\n                    clustering=False, innermost=True)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(test, submission.target, \n                    'Test, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(train, train.target,\n                    'Training, gcd=10: True labels', \n                    clustering=False, innermost=False)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(train, train.target, \n                    'Training, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=False)\nplt.show()\n\nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(test, submission.target,\n                    'Test, gcd=10: Labels of top submission',\n                    clustering=False, innermost=False)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(test, submission.target,\n                    'Test, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissions","metadata":{}},{"cell_type":"code","source":"test = test.reset_index()\nsubmission['new_pred'] = submission.target\nsubmission.loc[~test.new_pred.isna(), 'new_pred'] = target_encoder.inverse_transform(test.new_pred.dropna().astype(int))\n\nprint(f\"Relabeled predictions: {(submission.new_pred != submission.target).sum()}\")\nfinal_submission = submission[['row_id', 'new_pred']].rename(columns={'new_pred': 'target'})\nfinal_submission.to_csv('submission.csv', index=False)\nfinal_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The next step\n* blending","metadata":{}},{"cell_type":"markdown","source":"Thanks to [Luca Massaron](https://www.kaggle.com/lucamassaron), [AmbrosM](https://www.kaggle.com/ambrosm), [ŞAFAK TÜRKELI](https://www.kaggle.com/sfktrkl`)","metadata":{}}]}