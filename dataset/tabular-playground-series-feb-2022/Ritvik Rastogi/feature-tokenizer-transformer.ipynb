{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Feature Tokenizer Transformer\nFeatured in the paper [Revisiting Deep Learning Models for Tabular Data (2021, June)](https://arxiv.org/abs/2106.11959) Feature Tokenizer Transformer is a simple adaptation of the Transformer architecture for the tabular domain. In a nutshell, Feature Tokenizer Transformer transforms all features (categorical and numerical) to embeddings and applies a stack of Transformer layers to the embeddings. Thus, every Transformer layer operates on the feature level of one object.\n\nIn this notebook we will be implementing Feature Tokenizer Transformer using TensorFlow 2 from scratch.","metadata":{"papermill":{"duration":0.013455,"end_time":"2022-02-07T18:12:52.570537","exception":false,"start_time":"2022-02-07T18:12:52.557082","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers as L\nfrom tensorflow_addons.activations import sparsemax\nfrom tensorflow.data import Dataset\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold\nimport joblib\n\npd.options.display.max_columns = 300","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":5.795589,"end_time":"2022-02-07T18:12:58.379417","exception":false,"start_time":"2022-02-07T18:12:52.583828","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-09T09:09:07.506498Z","iopub.execute_input":"2022-02-09T09:09:07.506995Z","iopub.status.idle":"2022-02-09T09:09:14.708304Z","shell.execute_reply.started":"2022-02-09T09:09:07.50688Z","shell.execute_reply":"2022-02-09T09:09:14.707416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data\nLoading the train and test csv files into `pandas.DataFrame` and splitting the columns as features and target.\n\nWe will be using Stratified K folds as our local cross validation.","metadata":{"papermill":{"duration":0.012707,"end_time":"2022-02-07T18:12:58.40506","exception":false,"start_time":"2022-02-07T18:12:58.392353","status":"completed"},"tags":[]}},{"cell_type":"code","source":"data = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv')\ndata = data.drop_duplicates(subset=data.columns[1:]).reset_index(drop=True)\nprint(data.shape)\ndata.head()","metadata":{"papermill":{"duration":24.684216,"end_time":"2022-02-07T18:13:23.101621","exception":false,"start_time":"2022-02-07T18:12:58.417405","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-09T09:12:07.377931Z","iopub.execute_input":"2022-02-09T09:12:07.378547Z","iopub.status.idle":"2022-02-09T09:12:22.912329Z","shell.execute_reply.started":"2022-02-09T09:12:07.378505Z","shell.execute_reply":"2022-02-09T09:12:22.911535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv')\nprint(test.shape)\nX_test = test.drop(['row_id'], axis=1)","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:23.136683Z","iopub.status.busy":"2022-02-07T18:13:23.136015Z","iopub.status.idle":"2022-02-07T18:13:34.247145Z","shell.execute_reply":"2022-02-07T18:13:34.247562Z","shell.execute_reply.started":"2022-02-07T16:57:49.893665Z"},"papermill":{"duration":11.13067,"end_time":"2022-02-07T18:13:34.247723","exception":false,"start_time":"2022-02-07T18:13:23.117053","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.drop(['row_id', 'target'], axis=1)\ny = pd.get_dummies(data['target'])","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:34.42031Z","iopub.status.busy":"2022-02-07T18:13:34.419471Z","iopub.status.idle":"2022-02-07T18:13:34.448577Z","shell.execute_reply":"2022-02-07T18:13:34.44812Z","shell.execute_reply.started":"2022-02-07T16:58:00.28421Z"},"papermill":{"duration":0.185277,"end_time":"2022-02-07T18:13:34.448696","exception":false,"start_time":"2022-02-07T18:13:34.263419","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:34.48384Z","iopub.status.busy":"2022-02-07T18:13:34.483282Z","iopub.status.idle":"2022-02-07T18:13:34.486907Z","shell.execute_reply":"2022-02-07T18:13:34.486451Z","shell.execute_reply.started":"2022-02-07T16:58:00.453938Z"},"papermill":{"duration":0.022634,"end_time":"2022-02-07T18:13:34.487021","exception":false,"start_time":"2022-02-07T18:13:34.464387","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model\n**Creating some data utility classes**:\n\n`DataConfig` helps to segregate the features into numeric features and categorical features and maintain a vocabulary for the categorical ones.\n\n`DataLoader` class creates `tf.data.Dataset` objects from `pandas.DataFrame` to ensure efficiency in the input pipeline to the model.","metadata":{"papermill":{"duration":0.015038,"end_time":"2022-02-07T18:13:34.517167","exception":false,"start_time":"2022-02-07T18:13:34.502129","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class DataConfig:\n    def __init__(self, numeric_feature_names, categorical_features_with_vocabulary):\n        self.NUMERIC_FEATURE_NAMES = numeric_feature_names\n        self.CATEGORICAL_FEATURES_WITH_VOCABULARY = categorical_features_with_vocabulary\n        self.CATEGORICAL_FEATURE_NAMES = list(self.CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n        self.FEATURE_NAMES = self.NUMERIC_FEATURE_NAMES + self.CATEGORICAL_FEATURE_NAMES\n        \nclass DataLoader:\n    @classmethod\n    def from_df(cls, X, y=None, batch_size=1024):\n        return (\n            Dataset.from_tensor_slices(({col: X[col].values.tolist() for col in X.columns}, y.values.tolist())).batch(\n                batch_size\n            )\n            if y is not None\n            else Dataset.from_tensor_slices({col: X[col].values.tolist() for col in X.columns}).batch(batch_size)\n        )        ","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:34.554938Z","iopub.status.busy":"2022-02-07T18:13:34.554113Z","iopub.status.idle":"2022-02-07T18:13:34.558301Z","shell.execute_reply":"2022-02-07T18:13:34.557895Z","shell.execute_reply.started":"2022-02-07T16:58:00.460541Z"},"papermill":{"duration":0.026091,"end_time":"2022-02-07T18:13:34.558405","exception":false,"start_time":"2022-02-07T18:13:34.532314","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating Input Layers and Feature Encoding Layers**\n\n`get_inputs` returns a dictionary of Input Layers based on the data types of the feature columns mentioned in the `DataConfig` object.\n\n`encode_inputs` applies StringLookup and Embedding Layer to the categorical features and Reshapes the Numeric Features in order to encode the inputs.","metadata":{}},{"cell_type":"code","source":"def get_inputs(config):\n    return {\n        feature_name: L.Input(\n            name=feature_name,\n            shape=(),\n            dtype=(tf.float32 if feature_name in config.NUMERIC_FEATURE_NAMES else tf.string),\n        )\n        for feature_name in config.FEATURE_NAMES\n    }\n\ndef encode_inputs(inputs, config, use_embeddings=False, embedding_dim=32, prefix=\"\", concat_features=False):\n    cat_features = []\n    num_features = []\n    for feature_name in inputs:\n        if feature_name in config.CATEGORICAL_FEATURE_NAMES:\n            vocabulary = config.CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n            lookup = L.StringLookup(\n                vocabulary=vocabulary,\n                mask_token=None,\n                num_oov_indices=0,\n                output_mode=\"int\" if use_embeddings else \"binary\",\n                name=f\"{prefix}{feature_name}_lookup\",\n            )\n            if use_embeddings:\n                encoded_feature = lookup(inputs[feature_name])\n                embedding = L.Embedding(\n                    input_dim=len(vocabulary),\n                    output_dim=embedding_dim,\n                    name=f\"{prefix}{feature_name}_embeddings\",\n                )\n                encoded_feature = embedding(encoded_feature)\n            else:\n                encoded_feature = lookup(\n                    L.Reshape((1,), name=f\"{prefix}{feature_name}_reshape\")(inputs[feature_name])\n                )\n            cat_features.append(encoded_feature)\n        else:\n            encoded_feature = L.Reshape((1,), name=f\"{prefix}{feature_name}_reshape\")(inputs[feature_name])\n            num_features.append(encoded_feature)\n\n    features = (\n        L.Concatenate(name=f\"{prefix}inputs_concatenate\")(cat_features + num_features)\n        if concat_features\n        else (cat_features, num_features)\n    )\n\n    return features","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:34.599364Z","iopub.status.busy":"2022-02-07T18:13:34.596549Z","iopub.status.idle":"2022-02-07T18:13:34.602472Z","shell.execute_reply":"2022-02-07T18:13:34.602021Z","shell.execute_reply.started":"2022-02-07T16:58:00.472966Z"},"papermill":{"duration":0.028764,"end_time":"2022-02-07T18:13:34.602587","exception":false,"start_time":"2022-02-07T18:13:34.573823","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining Model Configurations**\n* Number of Outputs\n* Activation of the Output Layer\n* Number of Transformer Blocks\n* Number of heads in the Transformer Blocks\n* Embedding Dimension for the features\n* Dimesion of the Dense Projections in the transfomer blocks","metadata":{}},{"cell_type":"code","source":"class FeatureTokenizerTransformerConfig:\n    def __init__(\n        self,\n        num_outputs,\n        out_activation,\n        num_transformer_blocks=2,\n        num_heads=8,\n        embedding_dim=32,\n        dense_dim=16,\n    ):\n        self.NUM_OUT = num_outputs\n        self.OUT_ACTIVATION = out_activation\n        self.NUM_TRANSFORMER_BLOCKS = num_transformer_blocks\n        self.NUM_HEADS = num_heads\n        self.EMBEDDING_DIM = embedding_dim\n        self.DENSE_DIM = dense_dim","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:34.638109Z","iopub.status.busy":"2022-02-07T18:13:34.637281Z","iopub.status.idle":"2022-02-07T18:13:34.639301Z","shell.execute_reply":"2022-02-07T18:13:34.639674Z","shell.execute_reply.started":"2022-02-07T16:58:00.487521Z"},"papermill":{"duration":0.022233,"end_time":"2022-02-07T18:13:34.639818","exception":false,"start_time":"2022-02-07T18:13:34.617585","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining a standard Transformer Block**","metadata":{}},{"cell_type":"code","source":"class TransformerBlock(L.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention = L.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.dense_proj = tf.keras.Sequential([L.Dense(dense_dim, activation=\"relu\"), L.Dense(embed_dim)])\n        self.layernorm1 = L.LayerNormalization()\n        self.layernorm2 = L.LayerNormalization()\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            mask = mask[: tf.newaxis, :]\n        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n        proj_input = self.layernorm1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm2(proj_input + proj_output)","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:34.68568Z","iopub.status.busy":"2022-02-07T18:13:34.678699Z","iopub.status.idle":"2022-02-07T18:13:34.687965Z","shell.execute_reply":"2022-02-07T18:13:34.687445Z","shell.execute_reply.started":"2022-02-07T16:58:00.496789Z"},"papermill":{"duration":0.033103,"end_time":"2022-02-07T18:13:34.68807","exception":false,"start_time":"2022-02-07T18:13:34.654967","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining the Model**\nThe model takes Inputs Layers and then encodes the features from the functions defined above, the numerical features are then passed through a Dense layer of the same dimensions as the embeddings of the categorical features.\n\nAll the feature embeddings are then stacked and then passed through a series of Transformer Blocks followed by the Global Average Pooling and Final Output Layer","metadata":{}},{"cell_type":"code","source":"class FeatureTokenizerTransformer:\n    @classmethod\n    def from_config(cls, data_config, model_config, name):\n        inputs = get_inputs(data_config)\n        cat_features, num_features = encode_inputs(\n            inputs,\n            data_config,\n            use_embeddings=True,\n            embedding_dim=model_config.EMBEDDING_DIM,\n            prefix=\"\",\n            concat_features=False,\n        )\n        num_feat_emb = [\n            L.Dense(model_config.EMBEDDING_DIM, name=f\"{feature_name}_embeddings\")\n            for _, feature_name in zip(range(len(num_features)), data_config.NUMERIC_FEATURE_NAMES)\n        ]\n        num_features = [emb(feat) for emb, feat in zip(num_feat_emb, num_features)]\n\n        features = L.Concatenate(axis=1, name=\"feature_embeddings_stack\")(\n            [\n                L.Reshape((1, 32), name=f\"{feat_name}_reshape_2\")(feat)\n                for feat, feat_name in zip((num_features + cat_features), data_config.FEATURE_NAMES)\n            ]\n        )\n\n        for _ in range(model_config.NUM_TRANSFORMER_BLOCKS):\n            features = TransformerBlock(\n                embed_dim=model_config.EMBEDDING_DIM,\n                dense_dim=model_config.DENSE_DIM,\n                num_heads=model_config.NUM_HEADS,\n            )(features)\n        features = L.GlobalMaxPooling1D()(features)\n        outputs = L.Dense(\n            units=model_config.NUM_OUT,\n            activation=model_config.OUT_ACTIVATION,\n            name=\"outputs\",\n        )(features)\n        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n        return model","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:34.68568Z","iopub.status.busy":"2022-02-07T18:13:34.678699Z","iopub.status.idle":"2022-02-07T18:13:34.687965Z","shell.execute_reply":"2022-02-07T18:13:34.687445Z","shell.execute_reply.started":"2022-02-07T16:58:00.496789Z"},"papermill":{"duration":0.033103,"end_time":"2022-02-07T18:13:34.68807","exception":false,"start_time":"2022-02-07T18:13:34.654967","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating instances of the various classes defined so far**","metadata":{}},{"cell_type":"code","source":"data_config = DataConfig(\n    numeric_feature_names=X.columns.tolist(), categorical_features_with_vocabulary={}\n)\nmodel_config = FeatureTokenizerTransformerConfig(num_outputs=len(y.columns), out_activation='softmax')","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:34.723561Z","iopub.status.busy":"2022-02-07T18:13:34.722585Z","iopub.status.idle":"2022-02-07T18:13:34.724319Z","shell.execute_reply":"2022-02-07T18:13:34.724711Z","shell.execute_reply.started":"2022-02-07T16:58:00.515632Z"},"papermill":{"duration":0.021357,"end_time":"2022-02-07T18:13:34.724838","exception":false,"start_time":"2022-02-07T18:13:34.703481","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blank_model = FeatureTokenizerTransformer.from_config(data_config, model_config, name='ftt')\nblank_model.summary()","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:13:34.759383Z","iopub.status.busy":"2022-02-07T18:13:34.758778Z","iopub.status.idle":"2022-02-07T18:14:42.204081Z","shell.execute_reply":"2022-02-07T18:14:39.891841Z","shell.execute_reply.started":"2022-02-07T16:58:00.52588Z"},"papermill":{"duration":67.464486,"end_time":"2022-02-07T18:14:42.204275","exception":false,"start_time":"2022-02-07T18:13:34.739789","status":"completed"},"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_EPOCHS  = 50\n\nget_callbacks = lambda : [\n    keras.callbacks.EarlyStopping(min_delta=1e-4, patience=3, verbose=1, restore_best_weights=True),\n    keras.callbacks.ReduceLROnPlateau(patience=2, verbose=1)\n]","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:14:45.153667Z","iopub.status.busy":"2022-02-07T18:14:45.152738Z","iopub.status.idle":"2022-02-07T18:14:45.156365Z","shell.execute_reply":"2022-02-07T18:14:45.157034Z","shell.execute_reply.started":"2022-02-07T16:59:04.408088Z"},"papermill":{"duration":1.263735,"end_time":"2022-02-07T18:14:45.157276","exception":false,"start_time":"2022-02-07T18:14:43.893541","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"preds = []\n\nfor fold, (train_index, valid_index) in enumerate(skf.split(X, data['target'])):\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    scaler = StandardScaler().fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n    X_valid = pd.DataFrame(scaler.transform(X_valid), columns=X.columns)\n    x_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n    \n    data_train = DataLoader.from_df(X_train, y_train, batch_size=512)\n    data_valid = DataLoader.from_df(X_valid, y_valid, batch_size=512)\n    data_test = DataLoader.from_df(x_test, batch_size=512)\n    \n    model = FeatureTokenizerTransformer.from_config(data_config, model_config, name=f'ftt_fold_{fold}')\n    model.compile(\n        loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy']\n    )\n    model.fit(\n        data_train, validation_data=data_valid, callbacks=get_callbacks(), \n        epochs=MAX_EPOCHS\n    )  \n    preds.append(model.predict(data_test))","metadata":{"execution":{"iopub.execute_input":"2022-02-07T18:14:47.728655Z","iopub.status.busy":"2022-02-07T18:14:47.727726Z","iopub.status.idle":"2022-02-08T01:03:55.388013Z","shell.execute_reply":"2022-02-08T01:03:55.388773Z","shell.execute_reply.started":"2022-02-07T16:59:04.417412Z"},"papermill":{"duration":24548.967574,"end_time":"2022-02-08T01:03:55.388957","exception":false,"start_time":"2022-02-07T18:14:46.421383","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":12.091898,"end_time":"2022-02-08T01:04:20.090404","exception":false,"start_time":"2022-02-08T01:04:07.998506","status":"completed"},"tags":[]}},{"cell_type":"code","source":"submissions = pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')\nsubmissions['target'] = pd.DataFrame(\n    np.array([arr for arr in preds]).mean(axis=0),columns=y.columns\n).idxmax(axis=1).values.tolist()\nsubmissions.to_csv('preds.csv', index=False)","metadata":{"execution":{"iopub.execute_input":"2022-02-08T01:04:44.920911Z","iopub.status.busy":"2022-02-08T01:04:44.920214Z","iopub.status.idle":"2022-02-08T01:04:45.388067Z","shell.execute_reply":"2022-02-08T01:04:45.388534Z","shell.execute_reply.started":"2022-02-07T17:05:49.950752Z"},"papermill":{"duration":13.401781,"end_time":"2022-02-08T01:04:45.388685","exception":false,"start_time":"2022-02-08T01:04:31.986904","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}