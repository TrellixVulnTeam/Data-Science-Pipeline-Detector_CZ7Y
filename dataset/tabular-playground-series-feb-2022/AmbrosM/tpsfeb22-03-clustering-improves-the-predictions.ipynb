{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Solving GCD = 10 by Clustering\n\nThis notebook shows how to solve a special case of the February TPS by clustering. It focuses only on this special case and merges the output into [dmitryuarov](https://www.kaggle.com/dmitryuarov)'s [top-scoring notebook](https://www.kaggle.com/dmitryuarov/forest-of-extra-trees-0-9895-up-to-4th-place).\n\nThe main point of the notebook is: Because training and test distributions differ in the February TPS, supervised learning (e.g. ExtraTreesClassifier) doesn't find the optimum decision boundaries. By clustering the test data, we can move the decision boundaries to where they belong.\n\n# Preparation\n\nWe start by reading the data and adding two columns\n- `target_num` (target label encoded with an integer from 0 through 9)\n- `gcd` (gcd of all integer features, which is 1, 10, 1000 or 10000 as described in the [EDA](https://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport gc\n\nfrom math import factorial\nfrom scipy.stats import mode\n\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T22:17:47.177348Z","iopub.execute_input":"2022-02-13T22:17:47.179702Z","iopub.status.idle":"2022-02-13T22:17:47.189898Z","shell.execute_reply.started":"2022-02-13T22:17:47.179576Z","shell.execute_reply":"2022-02-13T22:17:47.189329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv')\n\nelements = [e for e in train_df.columns if e != 'row_id' and e != 'target']\n\n# Convert the 10 bacteria names to the integers 0 .. 9\nle = LabelEncoder()\ntrain_df['target_num'] = le.fit_transform(train_df.target)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T22:17:47.191265Z","iopub.execute_input":"2022-02-13T22:17:47.192076Z","iopub.status.idle":"2022-02-13T22:18:12.017118Z","shell.execute_reply.started":"2022-02-13T22:17:47.192017Z","shell.execute_reply":"2022-02-13T22:18:12.016194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bias(w, x, y, z):\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ndef bias_of(s):\n    w = int(s[1:s.index('T')])\n    x = int(s[s.index('T')+1:s.index('G')])\n    y = int(s[s.index('G')+1:s.index('C')])\n    z = int(s[s.index('C')+1:])\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ntrain_i = pd.DataFrame({col: ((train_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in elements})\ntest_i = pd.DataFrame({col: ((test_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in elements})\n\ndef gcd_of_all(df_i):\n    gcd = df_i[elements[0]]\n    for col in elements[1:]:\n        gcd = np.gcd(gcd, df_i[col])\n    return gcd\n\ntrain_df['gcd'] = gcd_of_all(train_i)\ntest_df['gcd'] = gcd_of_all(test_i)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T22:18:12.018421Z","iopub.execute_input":"2022-02-13T22:18:12.018657Z","iopub.status.idle":"2022-02-13T22:18:14.456546Z","shell.execute_reply.started":"2022-02-13T22:18:12.018629Z","shell.execute_reply":"2022-02-13T22:18:14.455625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis of the top-scoring public submission\n","metadata":{}},{"cell_type":"code","source":"# Read @dmitryuarov's notebook\ntop_submission = pd.read_csv('../input/forest-of-extra-trees-0-9895-up-to-4th-place/submission__blend.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-13T22:18:14.457865Z","iopub.execute_input":"2022-02-13T22:18:14.458196Z","iopub.status.idle":"2022-02-13T22:18:14.500008Z","shell.execute_reply.started":"2022-02-13T22:18:14.458154Z","shell.execute_reply":"2022-02-13T22:18:14.499368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a first step of the analysis, we select the samples with gcd = 10 from the training data and from the public submission. We then plot a 2d projection of the data, colored by the target label (for the training data, this is the ground truth; for the public submission, this is the prediction). We see\n1. Training data and test data look similar (which is good).\n2. The samples of every bacterium (i.e. of every color) are arranged in eight clusters which lie on a ray emanating from the origin. With 10 bacteria and 8 clusters per bacterium, this gives a total of 80 clusters.","metadata":{}},{"cell_type":"code","source":"def pca_gcd10_full(df, target, title):\n    \"\"\"Plot a 2d projection of all points of df with gcd = 10, colored by target\"\"\"\n    subset = df[df.gcd == 10]\n    pred_subset = le.transform(target)[df.gcd == 10]\n    # Compute the PCA\n    pca3 = TruncatedSVD(n_components=10, random_state=1)\n    pca3.fit(subset[elements])\n\n    # Transform the data so that the components can be analyzed\n    Xt_tr3 = pca3.transform(subset[elements])\n\n    # Plot a scattergram, projected to two PCA components\n    d0, d1 = 1, 2\n    plt.scatter(Xt_tr3[:,d0], Xt_tr3[:,d1], c=pred_subset, cmap='tab10', s=1)\n    plt.title(title)\n    \nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_full(train_df, train_df.target, 'Training, gcd=10')\nplt.subplot(1, 2, 2)\npca_gcd10_full(test_df, top_submission.target, 'Top submission, gcd=10')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T22:18:14.502353Z","iopub.execute_input":"2022-02-13T22:18:14.50265Z","iopub.status.idle":"2022-02-13T22:18:18.046287Z","shell.execute_reply.started":"2022-02-13T22:18:14.50261Z","shell.execute_reply":"2022-02-13T22:18:18.045505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The two diagrams above suggest that the test data has been accurately classified - except maybe the innermost part (near the origin), which is not clearly visible.\n\nWe now zoom in on the innermost cluster of bacteria 3 and 4.","metadata":{}},{"cell_type":"code","source":"def pca_gcd10_selection(df, target, title, clustering, innermost):\n    \"\"\"Plot a 2d projection of certain points of df, colored by target\n    or by a clustering, and add the new clustering labels to df.\n    \n    We select the two innermost clusters with gcd = 10 of bacteria 3 and 4\"\"\"\n    # Get the subset\n    subset = df[df.gcd == 10].copy()\n    subset['radius'] = np.sqrt(np.square(subset[elements]).sum(axis=1))\n    subset['pred'] = le.transform(target)[df.gcd == 10]\n    mean_radius = subset.radius.groupby(subset.pred).mean()\n    mean_radius.name = 'mean_radius'\n    subset = subset.merge(mean_radius, left_on='pred', right_index=True).sort_index()\n    if innermost:\n        selection = ((subset.radius < subset.mean_radius * 0.388) &\n                     subset.pred.isin([3, 4]))\n    else:\n        selection = ((subset.radius >= subset.mean_radius * 0.388) &\n                     (subset.radius < subset.mean_radius * 0.64) & \n                     subset.pred.isin([3, 4]))\n    subset = subset[selection]\n    #print(subset.groupby(subset.pred).count()['row_id'])\n\n    if clustering:\n        # Cluster the data into two clusters\n        #km = KMeans(n_clusters=2, random_state=1)\n        km = AgglomerativeClustering(n_clusters=2)\n        km.fit(subset[elements])\n        # For every cluster, predict the most frequent label for all cluster members\n        new_pred = subset.pred.groupby(km.labels_).transform(lambda s: [mode(s)[0][0]] * len(s))\n        print(f\"Relabeled {(new_pred != subset.pred).sum()} samples\")\n\n    # Compute the PCA\n    pca3 = TruncatedSVD(n_components=10, random_state=1)\n    pca3.fit(subset[elements])\n\n    # Transform the data so that the components can be analyzed\n    Xt_tr3 = pca3.transform(subset[elements])\n\n    # Plot a scattergram, projected to two PCA components\n    d0, d1 = 2, 1\n    plt.scatter(Xt_tr3[:,d0], Xt_tr3[:,d1],\n                cmap=ListedColormap(plt.get_cmap('tab10').colors[3:5]),\n                c=(new_pred if clustering else subset.pred),\n                s=25)\n    plt.title(title)\n    if clustering:\n        selected = pd.Series(False, index=df.index)\n        selected.loc[df.gcd == 10] = selection\n        df.loc[selected, 'new_pred'] = new_pred","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-13T22:18:18.047514Z","iopub.execute_input":"2022-02-13T22:18:18.04793Z","iopub.status.idle":"2022-02-13T22:18:18.063335Z","shell.execute_reply.started":"2022-02-13T22:18:18.0479Z","shell.execute_reply":"2022-02-13T22:18:18.062111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next four diagrams show:\n- Top left: In the training data, the samples form a red cluster (bacterium 3) and a violet cluster (bacterium 4).\n- Top right: In the training data, the clustering algorithm clusters the samples into bacterium 3 and bacterium 4 with high accuracy.\n- Bottom left: In the test data, the labels predicted by the current top submission **do not follow the cluster boundaries**.\n- Bottom right: If we relabel the test data with the output of the clustering algorithm, the labels look better (more similar to the training labels) than the current top submission.\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(train_df, train_df.target, \n                    'Training, gcd=10: True labels',\n                    clustering=False, innermost=True)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(train_df, train_df.target,\n                    'Training, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=True)\nplt.show()\n\nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(test_df, top_submission.target, \n                    'Test, gcd=10: Labels of top submission',\n                    clustering=False, innermost=True)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(test_df, top_submission.target, \n                    'Test, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T22:18:18.065255Z","iopub.execute_input":"2022-02-13T22:18:18.066287Z","iopub.status.idle":"2022-02-13T22:18:20.814552Z","shell.execute_reply.started":"2022-02-13T22:18:18.066241Z","shell.execute_reply":"2022-02-13T22:18:20.813559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The diagrams above suggest that we can improve the top submission if we replace its predictions by the cluster labels.\n\nLet's try the same operation with the second-to-innermost clusters:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(train_df, train_df.target,\n                    'Training, gcd=10: True labels', \n                    clustering=False, innermost=False)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(train_df, train_df.target, \n                    'Training, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=False)\nplt.show()\n\nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(test_df, top_submission.target,\n                    'Test, gcd=10: Labels of top submission',\n                    clustering=False, innermost=False)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(test_df, top_submission.target,\n                    'Test, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T22:18:20.815993Z","iopub.execute_input":"2022-02-13T22:18:20.81643Z","iopub.status.idle":"2022-02-13T22:18:24.486766Z","shell.execute_reply.started":"2022-02-13T22:18:20.816386Z","shell.execute_reply":"2022-02-13T22:18:24.486048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission\n\nTo finish today's work, we relabel 68 predictions and submit the result.\n","metadata":{}},{"cell_type":"code","source":"top_submission['new_pred'] = top_submission.target\ntop_submission.loc[~test_df.new_pred.isna(), 'new_pred'] = le.inverse_transform(test_df.new_pred.dropna().astype(int))\n\nprint(f\"Relabeled predictions: {(top_submission.new_pred != top_submission.target).sum()}\")\nsubmission = top_submission[['row_id', 'new_pred']].rename(columns={'new_pred': 'target'})\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-02-13T22:18:24.489915Z","iopub.execute_input":"2022-02-13T22:18:24.490557Z","iopub.status.idle":"2022-02-13T22:18:24.802666Z","shell.execute_reply.started":"2022-02-13T22:18:24.490517Z","shell.execute_reply":"2022-02-13T22:18:24.802083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Future work: It is plausible that a similar method will improve the predictions for gcd=1000 and gcd=10000 as well.","metadata":{}}]}