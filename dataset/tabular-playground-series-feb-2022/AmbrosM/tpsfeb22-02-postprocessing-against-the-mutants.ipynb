{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Postprocessing for the February TPS\n\nMost of this code has been copied from @[maxencefzr](https://www.kaggle.com/maxencefzr)'s [notebook](https://www.kaggle.com/maxencefzr/tps-feb22-eda-extratrees). I've added the postprocessing and the code for dealing with duplicate training samples. \n\nRelease notes:\n- V3: Using scipy.optimize to optimize the postprocessing (didn't improve the lb score)\n- V4: Dealing with duplicate training data and sample weights","metadata":{}},{"cell_type":"code","source":"#%%capture\n\n# IntelÂ® Extension for Scikit-learn installation:\n!pip install scikit-learn-intelex\n\nimport os\nimport warnings\n\nimport numpy as np  # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom scipy.stats import mode\nfrom tqdm import tqdm\nfrom pathlib import Path\n\nfrom sklearnex import patch_sklearn\npatch_sklearn()\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\n# Mute warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-06T19:04:47.256078Z","iopub.execute_input":"2022-02-06T19:04:47.256469Z","iopub.status.idle":"2022-02-06T19:05:21.397362Z","shell.execute_reply.started":"2022-02-06T19:04:47.256371Z","shell.execute_reply":"2022-02-06T19:05:21.396372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = Path('../input/tabular-playground-series-feb-2022')\n\ndf_train = pd.read_csv(data_dir / 'train.csv', index_col='row_id')\ndf_test  = pd.read_csv(data_dir / 'test.csv', index_col='row_id')\n\nTARGET = df_train.columns.difference(df_test.columns)[0]\nfeatures = df_train.columns[df_train.columns != TARGET]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-06T19:05:21.399206Z","iopub.execute_input":"2022-02-06T19:05:21.399545Z","iopub.status.idle":"2022-02-06T19:06:02.933315Z","shell.execute_reply.started":"2022-02-06T19:05:21.399502Z","shell.execute_reply":"2022-02-06T19:06:02.932168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deduplicating the training data\n\nAmong the 200000 training samples, there are 76007 duplicates. These duplicates are an issue for two reasons:\n1. They make training times unnecessarily long (ok, if you have enough patience, this could be a non-issue).\n2. They inflate the cv scores, if not handled correctly.\n\nWe must not simply drop the duplicates because this would change the probability distribution. After all, if one particular measurement outcome has been measured 18 times, it should have higher weight than an outcome which has been measured only once. Fortunately, the `fit()` method of most scikit-learn estimators has an optional parameter `sample_weight` for this purpose.\n\nIn the following, we convert the training dataframe to a new dataframe without the duplicated rows. To compensate for dropping the duplicates, we add a column `sample_weight` to the dataframe.","metadata":{}},{"cell_type":"code","source":"# Count the duplicates in the training data\ndf_train.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T19:06:02.934362Z","iopub.execute_input":"2022-02-06T19:06:02.934605Z","iopub.status.idle":"2022-02-06T19:06:05.014714Z","shell.execute_reply.started":"2022-02-06T19:06:02.934576Z","shell.execute_reply":"2022-02-06T19:06:05.013699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new dataframe without duplicates, but with an additional sample_weight column\nvc = df_train.value_counts()\ndedup_train = pd.DataFrame([list(tup) for tup in vc.index.values], columns=df_train.columns)\ndedup_train['sample_weight'] = vc.values\ndedup_train","metadata":{"execution":{"iopub.status.busy":"2022-02-06T19:06:05.017504Z","iopub.execute_input":"2022-02-06T19:06:05.017842Z","iopub.status.idle":"2022-02-06T19:06:28.022569Z","shell.execute_reply.started":"2022-02-06T19:06:05.017797Z","shell.execute_reply":"2022-02-06T19:06:28.021132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's do a quick check for correctness. The first row of `dedup_train` has a sample_weight of 18. If everything is correct, the original dataframe should have 18 rows with the same data:","metadata":{}},{"cell_type":"code","source":"(df_train[features].values == dedup_train[features].iloc[0].values.reshape(1, -1)).all(axis=1).sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T19:06:28.024501Z","iopub.execute_input":"2022-02-06T19:06:28.02494Z","iopub.status.idle":"2022-02-06T19:06:28.363243Z","shell.execute_reply.started":"2022-02-06T19:06:28.024886Z","shell.execute_reply":"2022-02-06T19:06:28.36213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training, cross-validation & inference\n\nAfter deduplicating the training data, we apply two small changes to the training loop:\n1. When calling `fit()`, we add the sample weights of the training data.\n2. When calling `accuracy_score()`, we add the sample weights of the validation data.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Encoding categorical features\nle = LabelEncoder()\n\nX = dedup_train[features]\ny = pd.DataFrame(le.fit_transform(dedup_train[TARGET]), columns=[TARGET])\nsample_weight = dedup_train['sample_weight']","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-06T19:06:28.371971Z","iopub.execute_input":"2022-02-06T19:06:28.372345Z","iopub.status.idle":"2022-02-06T19:06:28.487777Z","shell.execute_reply.started":"2022-02-06T19:06:28.372298Z","shell.execute_reply":"2022-02-06T19:06:28.486606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\n\nN_SPLITS = 10\nfolds = StratifiedKFold(n_splits=N_SPLITS, shuffle=True)\ny_pred_list, y_proba_list, scores = [], [], []\n\nfor fold, (train_id, valid_id) in enumerate(tqdm(folds.split(X, y), total=N_SPLITS)):\n    print('####### Fold: ', fold)\n    \n    # Splitting\n    X_train, y_train, sample_weight_train = X.iloc[train_id], y.iloc[train_id], sample_weight.iloc[train_id]\n    X_valid, y_valid, sample_weight_valid = X.iloc[valid_id], y.iloc[valid_id], sample_weight.iloc[valid_id]\n    \n    # Model\n    model = ExtraTreesClassifier(\n        n_estimators=300,\n        n_jobs=-1,\n        verbose=0,\n        random_state=1\n    )\n\n    # Training\n    model.fit(X_train, y_train, sample_weight_train)\n        \n    # Validation\n    valid_pred = model.predict(X_valid)\n    valid_score = accuracy_score(y_valid, valid_pred, sample_weight=sample_weight_valid)\n    print(f'Accuracy score: {valid_score:5f}\\n')\n    scores.append(valid_score)\n    \n    # Prediction for submission\n    y_pred_list.append(model.predict(df_test))\n    y_proba_list.append(model.predict_proba(df_test))\n    \nscore = np.array(scores).mean()\nprint(f'Mean accuracy score: {score:6f}')","metadata":{"execution":{"iopub.status.busy":"2022-02-06T19:12:33.248348Z","iopub.execute_input":"2022-02-06T19:12:33.248638Z","iopub.status.idle":"2022-02-06T19:21:20.834959Z","shell.execute_reply.started":"2022-02-06T19:12:33.248608Z","shell.execute_reply":"2022-02-06T19:21:20.833992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensembling\n\nWe are happy about the high cv score and ensemble the ten predictions by majority vote:","metadata":{}},{"cell_type":"code","source":"# Majority vote\ny_pred = mode(y_pred_list).mode[0]\ny_pred = le.inverse_transform(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T19:26:01.889667Z","iopub.execute_input":"2022-02-06T19:26:01.890103Z","iopub.status.idle":"2022-02-06T19:26:05.360937Z","shell.execute_reply.started":"2022-02-06T19:26:01.890069Z","shell.execute_reply":"2022-02-06T19:26:05.360026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The surprise\n\nLet's compare the distribution of classes in training and in our predictions. Something went wrong:","metadata":{}},{"cell_type":"code","source":"target_distrib = pd.DataFrame({\n    'count': df_train.target.value_counts(),\n    'share': df_train[TARGET].value_counts() / df_train.shape[0] * 100\n})\n\ntarget_distrib['pred_count'] = pd.Series(y_pred, index=df_test.index).value_counts()\ntarget_distrib['pred_share'] = target_distrib['pred_count'] / len(df_test) * 100\ntarget_distrib.sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T19:26:05.362806Z","iopub.execute_input":"2022-02-06T19:26:05.363361Z","iopub.status.idle":"2022-02-06T19:26:05.467917Z","shell.execute_reply.started":"2022-02-06T19:26:05.363313Z","shell.execute_reply":"2022-02-06T19:26:05.466951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What went wrong? In the training data, all classes have equal frequencies of 10 %. In our predictions, *E. coli* is underpredicted with a frequency of only 8.7 %. Two explanations are possible:\n1. In the test data, *E. coli* really has a frequency of only 8.7 %. And *E. fergusonii* really has a frequency of 10.8 %.\n2. Because the bacteria have mutated and changed their DNA, our classifier no longer classifies them correctly.\n\nI think the correct explanation is 2, because the [EDA has already shown that the bacteria mutate between training and test](https://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense).\n\nFortunately, we can account for the mutations with a little postprocessing.","metadata":{}},{"cell_type":"markdown","source":"# Postprocessing\n\nOur classifier predicts not only classes, but also probabilities. These probabilities have already been collected in `y_proba_list`. We now tune these probabilities by manually adding a small bias to the probabilities of `Enterococcus hirae` and `E. coli`.\n\nFrom these tuned probabilities, we can determine new predictions by applying `np.argmax(axis=1)`, and we see that the class frequencies now are much better.","metadata":{}},{"cell_type":"code","source":"y_proba = sum(y_proba_list) / len(y_proba_list)\ny_proba += np.array([0, 0, 0.01, 0.03, 0, 0, 0, 0, 0, 0])\ny_pred_tuned = le.inverse_transform(np.argmax(y_proba, axis=1))\npd.Series(y_pred_tuned, index=df_test.index).value_counts().sort_index() / len(df_test) * 100","metadata":{"execution":{"iopub.status.busy":"2022-02-06T19:26:35.066384Z","iopub.execute_input":"2022-02-06T19:26:35.066713Z","iopub.status.idle":"2022-02-06T19:26:35.115723Z","shell.execute_reply.started":"2022-02-06T19:26:35.066677Z","shell.execute_reply":"2022-02-06T19:26:35.115122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(data_dir / 'sample_submission.csv')\nsubmission[TARGET] = y_pred_tuned\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-02-06T19:28:20.427654Z","iopub.execute_input":"2022-02-06T19:28:20.427982Z","iopub.status.idle":"2022-02-06T19:28:20.738205Z","shell.execute_reply.started":"2022-02-06T19:28:20.42795Z","shell.execute_reply":"2022-02-06T19:28:20.737302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final remark\n\nUnderstanding a model's weaknesses is part of data science. The present ExtraTreesClassifier has the weakness that it does not take the train-test drift into account.\n\nBut please note that the postprocessing in this notebook is not data science. It is a workaround to compensate for the model's weakness. The real data science remains to be done: Create a model for the train-test drift which doesn't need postprocessing workarounds.","metadata":{}}]}