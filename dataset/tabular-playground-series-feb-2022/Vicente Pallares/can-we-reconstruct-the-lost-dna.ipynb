{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n<img src=\"https://i.insider.com/51f6ca3deab8eac47b000004?width=1200&format=jpeg\" width=\"800\">","metadata":{}},{"cell_type":"markdown","source":"In this notebook I just want to show a proof of concept of maybe new possible ways of tackling this problem. The starting point is what has been already shown in many other notebooks and I further explain [here](https://www.kaggle.com/vpallares/semi-supervised-learning-extratrees). Basically, as introduced in [here](https://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense) we have 4 types of samples in this dataset. This type represents the resolution at which the DNA sequences were sampled. Two of them, resolutions 1 and 10, are the easier to classify, especially in the CV. The other two, 1000 and 10000, are quite noisy and, therefore, more challenging. I think we can help the classifier during the CV by taking advantage of having both, high-resolution and low-resolution samples already labelled.  ","metadata":{}},{"cell_type":"code","source":"%%capture\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom scipy.stats import mode\nfrom math import factorial\nimport gc\nimport sys\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Model\n\n!pip install scikit-learn-intelex","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-02-17T15:12:30.247993Z","iopub.execute_input":"2022-02-17T15:12:30.24897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Preparing the data","metadata":{}},{"cell_type":"markdown","source":"I'm going to load only the training set and apply the same preprocessing that I did in [here](https://www.kaggle.com/vpallares/semi-supervised-learning-extratrees). ","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/tabular-playground-series-feb-2022/train.csv\", index_col=0)\ntrain_df = reduce_mem_usage(train_df)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bias_of(s):\n    w = int(s[1:s.index('T')])\n    x = int(s[s.index('T')+1:s.index('G')])\n    y = int(s[s.index('G')+1:s.index('C')])\n    z = int(s[s.index('C')+1:])\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ndef gcd_of_all(df_i, elements):\n    gcd = df_i[elements[0]]\n    for col in elements[1:]:\n        gcd = np.gcd(gcd, df_i[col])\n    return gcd","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat = [col for col in train_df.columns if col != 'target']\n\nle = LabelEncoder()\ny = train_df['target']\ny_le = le.fit_transform(y)\n\ntrain_int = pd.DataFrame({col: ((train_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in feat})\ntrain_int['res'] = gcd_of_all(train_int, feat)\ntrain_int['target'] = y_le\ntrain_int.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just by looking at the data samples reformatted as integers, two things caught my eye. First, samples 1, 2 and 3 belong to class 6, and they are actually very similar, with sample 1 having less resolution but kind of following the same pattern as the other two. The second thing was that this reminded me a lot of an image, so I thought, why not plotting it as one?","metadata":{}},{"cell_type":"markdown","source":"## 2. Plotting the images","metadata":{}},{"cell_type":"code","source":"del train_df\ngc.collect()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 2, figsize=(20,6), sharex=True)\nsns.heatmap(train_int[(train_int.target==4) & (train_int.res==1)][feat].head(100), ax=ax[0,0])\nsns.heatmap(train_int[(train_int.target==4) & (train_int.res==10)][feat].head(100), ax=ax[0,1])\nsns.heatmap(train_int[(train_int.target==4) & (train_int.res==1000)][feat].head(100), ax=ax[1,0])\nsns.heatmap(train_int[(train_int.target==4) & (train_int.res==10000)][feat].head(100), ax=ax[1,1])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The upper four plots show samples of the same class (target 4) by resolution. The horizontal axis is the feature axis, while in the y-axis we just have 100 rows randomly sampled out of the training data. When I saw this I thought, this looks like a real spectrum, with two high-resolution images and other two with a lot of noise in them. \n\nThen I came up with something: maybe we can reconstruct those noisy samples by applying autoencoders... So, next I'm rearranging the data to have the 4-dimensions format in order to train and test an autoencoder for image reconstruction. \n\nNote: I haven't explored these parameters. I just thought that 100 rows was okay since we have 286 features, which is a long x-axis already. Since the images for resolutions 1 and 10 kind of look like similar, I decided to mix them up in the train set for the autoencoder. Each 2D image is made of 100 rows sampled from the training data. ","metadata":{}},{"cell_type":"code","source":"n_rows = 100\nn_samples = 5000\ntrain_data = np.zeros((n_samples, 100, 288, 1))\nlabels = []\nfor k in tqdm(range(n_samples)):\n    c = np.random.randint(10)\n    if np.random.rand() > 0.5:\n        im = train_int[(train_int.target == c) & (train_int.res == 1)][feat].sample(n_rows).values\n    else:\n        im = train_int[(train_int.target == c) & (train_int.res == 10)][feat].sample(n_rows).values\n    train_data[k, :, :, 0] = np.append(im/im.max(), np.zeros((100,2)), axis=1)\n    labels.append(c)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = 1000\nn_rows = 100\nn_samples = 5000\nlowres_data = np.zeros((n_samples, 100, 288, 1))\nlowres_labels = []\nfor k in tqdm(range(n_samples)):\n    c = np.random.randint(10)\n    im = train_int[(train_int.target == c) & (train_int.res == res)][feat].sample(n_rows).values\n    lowres_data[k, :, :, 0] = np.append(im/im.max(), np.zeros((100,2)), axis=1)\n    lowres_labels.append(c)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Building the autoencoder","metadata":{}},{"cell_type":"markdown","source":"\n <img src=\"https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/60bcd0b7b750bae1a953d61d_autoencoder.png\" width=\"500\">","metadata":{}},{"cell_type":"markdown","source":"As you may know, an autoencoder consists of two blocks, one encoder and one decoder that by fitting a latent representation of the input data allow to reconstruct an input with noisy or missing data according to that latent representation. Here I'm just going to build the enconder-decoder architecture with very standard parameters.","metadata":{}},{"cell_type":"code","source":"input = layers.Input(shape=(100, 288, 1))\n\n# Encoder\nx = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\nx = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\nx = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n\n# Decoder\nx = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n\n# Autoencoder\nautoencoder = Model(input, x)\nautoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\nautoencoder.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next step is to fit the model to the training data with the same data as target and check the output. ","metadata":{}},{"cell_type":"code","source":"autoencoder.fit(\n    x=train_data,\n    y=train_data,\n    epochs=10,\n    batch_size=128,\n    shuffle=True,\n    validation_data=(train_data,train_data),\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now I predict on some samples from the same training data and plot the result. ","metadata":{}},{"cell_type":"code","source":"X_pred = autoencoder.predict(train_data[:100,:,:,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 1, figsize=(14,6), sharex=True)\nsns.heatmap(train_data[7,:,:,0], ax=ax[0])\nsns.heatmap(X_pred[7,:,:,0], ax=ax[1])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that for this sample the autoencoder is actually learning and the output has even better resolution. The discontinuities that we see on the original image is due to the noise that we have in each of the four resolution types (check AmbrosM's notebook if you don't know what I mean).\n\nSo this means it's working with a very simple architecture. Can we actually reconstruct images with 1000 or 10000 resolution?","metadata":{}},{"cell_type":"markdown","source":"## 4. Reconstructing the noisy data","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://i.ytimg.com/vi/h58lRIVHhGc/maxresdefault.jpg\" width=\"600\">","metadata":{}},{"cell_type":"markdown","source":"Now we use as input those images with resolution=1000 and we fit them to the training data. The idea is that the autoencoder learns to fill those gaps and resolution errors in the input samples. ","metadata":{}},{"cell_type":"code","source":"#callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\nautoencoder.fit(\n    x=lowres_data,\n    y=train_data,\n    epochs=30,\n    batch_size=128,\n    shuffle=True,\n    validation_data=(lowres_data, train_data),\n)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see the result on those samples!","metadata":{}},{"cell_type":"code","source":"lowres_pred = autoencoder.predict(lowres_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 1, figsize=(14,8), sharex=True)\nsns.heatmap(lowres_data[10,:,:,0], ax=ax[0])\nsns.heatmap(lowres_pred[10,:,:,0], ax=ax[1])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is pretty cool! the autoencoder is learning to reconstruct the noisy input data and the output is almost as good as one of the high-resolution images. However, a resolution of 1000 isn't that bad, would it work with the poor-quality images of resolution=10000?","metadata":{}},{"cell_type":"code","source":"res = 10000\nn_rows = 100\nn_samples = 1000\nlowres_data2 = np.zeros((n_samples, 100, 288, 1))\nlowres_labels = []\nfor k in tqdm(range(n_samples)):\n    c = np.random.randint(10)\n    im = train_int[(train_int.target == c) & (train_int.res == res)][feat].sample(n_rows).values\n    lowres_data2[k, :, :, 0] = np.append(im/im.max(), np.zeros((100,2)), axis=1)\n    lowres_labels.append(c)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.fit(\n    x=lowres_data2,\n    y=train_data[:1000,:,:,:],\n    epochs=30,\n    batch_size=128,\n    shuffle=True,\n    validation_data=(lowres_data2, train_data[:1000,:,:,:]),\n)\n\nlowres_pred2 = autoencoder.predict(lowres_data2)\n\nfig, ax = plt.subplots(2, 1, figsize=(14,8), sharex=True)\nsns.heatmap(lowres_data2[4,:,:,0], ax=ax[0])\nsns.heatmap(lowres_pred2[4,:,:,0], ax=ax[1])\nplt.show()","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, that's not too bad. The reconstructed output has a way better look than the input. We'll probably get better results if we train with more samples and for longer\n. ","metadata":{}},{"cell_type":"markdown","source":"## 5. But there was a trick...\n\nHowever, I cheated a bit in this problem. I am using class information so I can group similar samples into a 2D structure, and I obviously don't have that information in the test set. But I still think this idea could be useful for:\n\n1. Training with more different resolution images\n2. Samples could be grouped using clustering and then passed to the autoencoder to be reconstructed\n3. A similar idea could be used with a VAE to generate more samples for the different resolution types\n4. Reconstructing those samples in test with resolution 1 and 10 (which should be easy to cluster) would already remove the intra-class noise that we see in the PCA\n5. A sample could be replicated 100 times which would make it an image and then reconstructed","metadata":{}},{"cell_type":"markdown","source":"So, that's all for the moment... Thanks for reading!\n\nPS: Of course, you might think of doing the same in 1D, why should we complicate our lives by transforming it into 2D? the answer is that in 2D you can apply convolutions, which could be useful to build a CNN for example. But the second and more important reason is that in 2D we can compensate the intra-class error for all the resolution (the differences in intensities that we see in some vertical lines). The price, as we saw, is that you need the label to group them as a 2D image.","metadata":{}},{"cell_type":"markdown","source":"![gif](https://media.giphy.com/media/IL1sMUfQVRNFC/giphy.gif)","metadata":{}}]}