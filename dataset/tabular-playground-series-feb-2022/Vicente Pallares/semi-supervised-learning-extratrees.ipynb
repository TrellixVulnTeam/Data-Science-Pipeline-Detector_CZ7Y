{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 0. Import libraries","metadata":{}},{"cell_type":"code","source":"%%capture\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom scipy.stats import mode\nfrom math import factorial\nimport gc\nimport sys\n\n!pip install scikit-learn-intelex","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-24T13:35:07.928389Z","iopub.execute_input":"2022-02-24T13:35:07.929389Z","iopub.status.idle":"2022-02-24T13:35:48.356266Z","shell.execute_reply.started":"2022-02-24T13:35:07.929258Z","shell.execute_reply":"2022-02-24T13:35:48.354622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Loading the data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/tabular-playground-series-feb-2022/train.csv\", index_col=0)\ntest_df = pd.read_csv(\"../input/tabular-playground-series-feb-2022/test.csv\", index_col=0)\n\nprint(f\"Nb samples in train: {train_df.shape[0]}\\nNb columns in train: {train_df.shape[1]}\\nNb samples in test: {test_df.shape[0]}\\nNb columns in test: {test_df.shape[1]}\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:35:48.360684Z","iopub.execute_input":"2022-02-24T13:35:48.361108Z","iopub.status.idle":"2022-02-24T13:36:28.475092Z","shell.execute_reply.started":"2022-02-24T13:35:48.361052Z","shell.execute_reply":"2022-02-24T13:36:28.474254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at the data:","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:36:28.476401Z","iopub.execute_input":"2022-02-24T13:36:28.479451Z","iopub.status.idle":"2022-02-24T13:36:28.522168Z","shell.execute_reply.started":"2022-02-24T13:36:28.479416Z","shell.execute_reply":"2022-02-24T13:36:28.521302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataframes are quite large so let's reduce the precision of some columns","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-24T13:36:28.524751Z","iopub.execute_input":"2022-02-24T13:36:28.525148Z","iopub.status.idle":"2022-02-24T13:36:28.539976Z","shell.execute_reply.started":"2022-02-24T13:36:28.525099Z","shell.execute_reply":"2022-02-24T13:36:28.539102Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train data\")\ntrain_df = reduce_mem_usage(train_df)\nprint(\"\\nTest data\")\ntest_df = reduce_mem_usage(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:36:28.542909Z","iopub.execute_input":"2022-02-24T13:36:28.543145Z","iopub.status.idle":"2022-02-24T13:36:58.956894Z","shell.execute_reply.started":"2022-02-24T13:36:28.543117Z","shell.execute_reply":"2022-02-24T13:36:58.956212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Cleaning and feature extraction","metadata":{}},{"cell_type":"markdown","source":"As some people pointed out, there are many duplicated rows in both sets that could cause overfitting and data leakage, so we should remove them before training","metadata":{}},{"cell_type":"code","source":"print(f\"Total number of duplicated rows: {train_df.duplicated().sum()} out of {train_df.shape[0]} ({train_df.duplicated().sum()/train_df.shape[0]*100:.2f}%)\")\ntrain_df = train_df.drop_duplicates()\nprint(f\"Total number of rows after removal: {train_df.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:36:58.958111Z","iopub.execute_input":"2022-02-24T13:36:58.958474Z","iopub.status.idle":"2022-02-24T13:37:04.719042Z","shell.execute_reply.started":"2022-02-24T13:36:58.958439Z","shell.execute_reply":"2022-02-24T13:37:04.718075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label encoding of categorical features\nle = LabelEncoder()\ny = train_df['target']\ny_le = le.fit_transform(y)\n\nfeat = [col for col in train_df.columns if col != 'target']","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:37:04.720568Z","iopub.execute_input":"2022-02-24T13:37:04.720804Z","iopub.status.idle":"2022-02-24T13:37:04.761866Z","shell.execute_reply.started":"2022-02-24T13:37:04.720775Z","shell.execute_reply":"2022-02-24T13:37:04.761132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As proved in [this kernel](https://www.kaggle.com/hamzaghanmi/train-test-286), some samples in the test set are already in the train set, so let's save those labels for later.","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/hamzaghanmi/train-test-286\ncommon_labels = pd.merge(train_df.reset_index(), test_df.reset_index(), how='inner', on=feat)\ncommon_labels.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:37:04.763363Z","iopub.execute_input":"2022-02-24T13:37:04.763686Z","iopub.status.idle":"2022-02-24T13:37:19.95428Z","shell.execute_reply.started":"2022-02-24T13:37:04.763655Z","shell.execute_reply":"2022-02-24T13:37:19.953472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this part I copied the code from the [great kernel](http://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense) made by AmbrosM to convert the features to integers and tag them acording to their resolution","metadata":{}},{"cell_type":"code","source":"def bias_of(s):\n    w = int(s[1:s.index('T')])\n    x = int(s[s.index('T')+1:s.index('G')])\n    y = int(s[s.index('G')+1:s.index('C')])\n    z = int(s[s.index('C')+1:])\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ndef gcd_of_all(df_i, elements):\n    gcd = df_i[elements[0]]\n    for col in elements[1:]:\n        gcd = np.gcd(gcd, df_i[col])\n    return gcd\n","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-02-24T13:37:19.95596Z","iopub.execute_input":"2022-02-24T13:37:19.956263Z","iopub.status.idle":"2022-02-24T13:37:19.965083Z","shell.execute_reply.started":"2022-02-24T13:37:19.956223Z","shell.execute_reply":"2022-02-24T13:37:19.964082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_int = pd.DataFrame({col: ((train_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in feat})\ntest_int = pd.DataFrame({col: ((test_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in feat})\n\n#train_df['res'] = gcd_of_all(train_int, feat)\n#test_df['res'] = gcd_of_all(test_int, feat)\ntrain_int['target'] = y_le\n\ntrain_int['res'] = gcd_of_all(train_int, feat)\ntest_int['res'] = gcd_of_all(test_int, feat)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:37:19.969038Z","iopub.execute_input":"2022-02-24T13:37:19.969328Z","iopub.status.idle":"2022-02-24T13:37:21.80608Z","shell.execute_reply.started":"2022-02-24T13:37:19.969298Z","shell.execute_reply":"2022-02-24T13:37:21.805278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# credits: https://www.kaggle.com/c/tabular-playground-series-feb-2022/discussion/308876\ndef get_gc(s, v):\n    a = int(s[1:s.index('T')])\n    t = int(s[s.index('T')+1:s.index('G')])\n    g = int(s[s.index('G')+1:s.index('C')])\n    c = int(s[s.index('C')+1:])\n    return ((g + c) / 10) * v\n\ndf = pd.DataFrame({col: get_gc(col, (train_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in feat})\ntrain_int['gc_content'] = df.sum(axis=1)/1000000\ndf = pd.DataFrame({col: get_gc(col, (test_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in feat})\ntest_int['gc_content'] = df.sum(axis=1)/1000000\nfeat = feat + ['gc_content']","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:37:21.807459Z","iopub.execute_input":"2022-02-24T13:37:21.80794Z","iopub.status.idle":"2022-02-24T13:37:23.029663Z","shell.execute_reply.started":"2022-02-24T13:37:21.807863Z","shell.execute_reply":"2022-02-24T13:37:23.02877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_int.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:37:23.030856Z","iopub.execute_input":"2022-02-24T13:37:23.031088Z","iopub.status.idle":"2022-02-24T13:37:23.050145Z","shell.execute_reply.started":"2022-02-24T13:37:23.031059Z","shell.execute_reply":"2022-02-24T13:37:23.049568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Modeling: Supervised Learning","metadata":{}},{"cell_type":"code","source":"def sizeof_fmt(num, suffix='B'):\n    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n        if abs(num) < 1024.0:\n            return \"%3.1f %s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n\nfor name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n                         key= lambda x: -x[1])[:10]:\n    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-02-24T13:37:23.051187Z","iopub.execute_input":"2022-02-24T13:37:23.051914Z","iopub.status.idle":"2022-02-24T13:37:23.226457Z","shell.execute_reply.started":"2022-02-24T13:37:23.051876Z","shell.execute_reply":"2022-02-24T13:37:23.225769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# release some memory\ndel train_df, test_df, df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:37:23.22756Z","iopub.execute_input":"2022-02-24T13:37:23.228174Z","iopub.status.idle":"2022-02-24T13:37:23.351666Z","shell.execute_reply.started":"2022-02-24T13:37:23.228142Z","shell.execute_reply":"2022-02-24T13:37:23.350853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res    = [1, 10, 1000, 10000]\nnFolds = 5\n\netc_params = {\n        'n_estimators': 300,\n        'n_jobs': -1,\n        'bootstrap': False,\n        'verbose': 0\n        }\n\n#sca = StandardScaler()\n\ny_pred = pd.DataFrame()\nacc_avg = 0\nn_valid = 0\nfor res_i in res:\n    print(f\"\\nResolution = {res_i}\")\n    X_train = train_int.loc[train_int['res'] == res_i][feat]\n    y_train = train_int.loc[train_int['res'] == res_i]['target']\n    X_test = test_int.loc[test_int['res'] == res_i][feat]\n\n    y_preds = []\n    y_probs = []\n    perf = []\n    cv = KFold(n_splits=nFolds, shuffle=True, random_state=2022)\n    for fold, (train_idx, valid_idx) in enumerate(cv.split(X_train, y_train)):         \n        X_train_cv = X_train.iloc[train_idx] \n        y_train_cv = y_train.iloc[train_idx]  \n        X_valid = X_train.iloc[valid_idx]\n        y_valid = y_train.iloc[valid_idx]\n        \n        #X_train_cv = sca.fit_transform(X_train_cv)\n        #X_valid = sca.transform(X_valid)\n\n        # train\n        clf = ExtraTreesClassifier(**etc_params)    \n        clf.fit(X_train_cv, y_train_cv.values.ravel())\n\n        # predict\n        y_pred_val = clf.predict(X_valid)\n        acc = accuracy_score(y_valid.values.ravel(),  y_pred_val)\n        perf.append(acc)\n        \n        y_preds.append(clf.predict(X_test))\n        y_probs.append(clf.predict_proba(X_test))\n        print(f\"CV - FOLD {fold+1} | Samples train: {len(train_idx)} | Samples validation: {len(valid_idx)} | acc = {acc:.4f}\")\n\n            \n    print(f\">>> Average across folds for res = {res_i} : acc = {np.mean(perf):.2f}\")\n    acc_avg += np.mean(perf)*len(valid_idx)\n    n_valid += len(valid_idx)\n    \n    # Majority vote\n    y_pred_res = mode(y_preds).mode[0]\n    test_ind_res = test_int[test_int['res'] == res_i].index\n    y_pred = y_pred.append(pd.DataFrame(le.inverse_transform(y_pred_res), index=test_ind_res, columns=['target']))\n    test_int.loc[test_ind_res, 'target'] = y_pred_res.astype(int)\n    y_pred.loc[test_ind_res]['res'] = res_i\nprint(f\"\\n>>> Weighted avg across folds and resolutions: {acc_avg/n_valid:.4f}\")\nsub = y_pred.copy()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:37:23.352935Z","iopub.execute_input":"2022-02-24T13:37:23.353188Z","iopub.status.idle":"2022-02-24T13:40:19.763747Z","shell.execute_reply.started":"2022-02-24T13:37:23.353161Z","shell.execute_reply":"2022-02-24T13:40:19.762848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We get perfect accuracy for the first two resolution levels. It is pretty clear, though, that the main problem here are the samples with lower resolution, i.e., those with a gcd value of 1000 and 10000 are noisier and, therefore, more difficult to classify. Moreover, those two subsets have a third of the number of samples we have for the other two. \nWe know from other kernels that there are replicated rows in the test set too, so we should check on that. \n\nSPOILER ALERT: I bet those samples correspond to the lower resolution sets, those with res=1000 and res=10000.","metadata":{}},{"cell_type":"code","source":"# convert float labels to int to make things easier\ntest_int = test_int.astype({'target': 'int32'})","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:40:19.765112Z","iopub.execute_input":"2022-02-24T13:40:19.765343Z","iopub.status.idle":"2022-02-24T13:40:19.863593Z","shell.execute_reply.started":"2022-02-24T13:40:19.765314Z","shell.execute_reply":"2022-02-24T13:40:19.862825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_high = test_int[(test_int['res']==1) | (test_int['res']==10)]\ntest_low = test_int[(test_int['res']==1000) | (test_int['res']==10000)]\n\nprint(f\"Total number of duplicated samples in high res test: {test_high.duplicated().sum()} out of {test_high.shape[0]} ({test_high.duplicated().sum()/test_high.shape[0]*100:.2f}%)\")\nprint(f\"Total number of duplicated samples in low res test: {test_low.duplicated().sum()} out of {test_low.shape[0]} ({test_low.duplicated().sum()/test_low.shape[0]*100:.2f}%)\")","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:40:19.864741Z","iopub.execute_input":"2022-02-24T13:40:19.864949Z","iopub.status.idle":"2022-02-24T13:40:21.28644Z","shell.execute_reply.started":"2022-02-24T13:40:19.864923Z","shell.execute_reply":"2022-02-24T13:40:21.285682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And that's exactly what happened. So from now on I'm going to **assume** that the high resolution samples are so easy to classify that all the predictions I've got for them are correct. Based on that **assumption** I could use those samples to artificially increase the training set and try to get better predictions on the remaining low-resolution test set samples. \n\n![img](https://media.giphy.com/media/Y2mXijj144TeY630d0/giphy.gif)","metadata":{}},{"cell_type":"markdown","source":"## 4. Modeling: Semi-supervised Learning","metadata":{}},{"cell_type":"markdown","source":"Now we are going to used the high resolution samples as pseudo-labeled data to retrain the model. To do that, we just extend the train dataframe by adding the samples in the test set that correspond to resolutions 1 and 10","metadata":{}},{"cell_type":"code","source":"train_ext = pd.concat([train_int, test_high.drop_duplicates()])\nfeat.append('res')\nprint(f\"Nb samples in train set extended: {len(train_ext)} ({(len(train_ext)-len(train_int))/len(train_ext)*100:.2f}% increase)\")","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:40:21.287894Z","iopub.execute_input":"2022-02-24T13:40:21.288797Z","iopub.status.idle":"2022-02-24T13:40:21.910375Z","shell.execute_reply.started":"2022-02-24T13:40:21.288749Z","shell.execute_reply":"2022-02-24T13:40:21.909559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ext.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:40:21.911371Z","iopub.execute_input":"2022-02-24T13:40:21.911578Z","iopub.status.idle":"2022-02-24T13:40:21.932176Z","shell.execute_reply.started":"2022-02-24T13:40:21.911552Z","shell.execute_reply":"2022-02-24T13:40:21.931107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train_ext[feat].copy()\ny_train = train_ext['target'].copy()\nX_test = test_low[feat].copy()\nindex_test_low = test_low.index.copy()\n\nX_train = reduce_mem_usage(X_train)\nX_test = reduce_mem_usage(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:40:21.933742Z","iopub.execute_input":"2022-02-24T13:40:21.934085Z","iopub.status.idle":"2022-02-24T13:40:44.418101Z","shell.execute_reply.started":"2022-02-24T13:40:21.934028Z","shell.execute_reply":"2022-02-24T13:40:44.41711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n                         key= lambda x: -x[1])[:10]:\n    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-02-24T13:40:44.419263Z","iopub.execute_input":"2022-02-24T13:40:44.419481Z","iopub.status.idle":"2022-02-24T13:40:44.640739Z","shell.execute_reply.started":"2022-02-24T13:40:44.419453Z","shell.execute_reply":"2022-02-24T13:40:44.639743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_ext, train_int, test_int, test_high, test_low\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:40:44.642341Z","iopub.execute_input":"2022-02-24T13:40:44.64267Z","iopub.status.idle":"2022-02-24T13:40:44.795347Z","shell.execute_reply.started":"2022-02-24T13:40:44.642628Z","shell.execute_reply":"2022-02-24T13:40:44.794559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This time I'm not training four different models, but the same one with the *resolution* as a feature. I increase the number of estimators and perform 10 fold CV to do ensembling by averaging the predictions.","metadata":{}},{"cell_type":"code","source":"#credits: https://www.kaggle.com/alexandreayari/tps-02-22-extratrees-gcd-memory-opti\nnFolds = 10 \n\nSEED = 2022  \nN_ESTIMATORS = 2000\nMAX_DEPTH = 3691\nMIN_SAMPLES_SPLIT = 3\nMIN_SAMPLES_LEAF = 1\nCRITERION  = 'gini'\nVERBOSE = 0\n\n#sca = StandardScaler()\n\ny_preds_ext = []\ny_probs_ext = []\nperf = []\nacc_avg = 0\nn_valid = 0\ncv = StratifiedKFold(n_splits=nFolds, shuffle=True, random_state=2022)\nprint(\"Starting training...\")\nfor fold, (train_idx, valid_idx) in enumerate(cv.split(X_train, y_train)):         \n    X_train_cv = X_train.iloc[train_idx] \n    y_train_cv = y_train.iloc[train_idx]  \n    X_valid = X_train.iloc[valid_idx]\n    y_valid = y_train.iloc[valid_idx]\n        \n    #X_train_cv = sca.fit_transform(X_train_cv)\n    #X_valid = sca.transform(X_valid)\n\n    etc_params = {\n        'n_estimators': N_ESTIMATORS,\n        'max_depth': MAX_DEPTH,\n        'min_samples_split': MIN_SAMPLES_SPLIT,\n        'min_samples_leaf': MIN_SAMPLES_LEAF,\n        'criterion': CRITERION,\n        'bootstrap': False,\n        'n_jobs': -1,\n        'random_state': SEED + fold + 1,\n        'verbose': VERBOSE,\n    }\n\n    \n    # train\n    clf = ExtraTreesClassifier(**etc_params)    \n    clf.fit(X_train_cv, y_train_cv.values.ravel())\n\n    # predict\n    y_pred_val = clf.predict(X_valid)\n    acc = accuracy_score(y_valid.values.ravel(),  y_pred_val)\n    perf.append(acc)\n        \n    y_preds_ext.append(clf.predict(X_test))\n    y_probs_ext.append(clf.predict_proba(X_test))\n    print(f\"CV - FOLD {fold} | acc = {acc:.4f}\")\n\nprint(f\">>> Average across folds: {np.mean(perf):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:58:08.603459Z","iopub.execute_input":"2022-02-24T13:58:08.603761Z","iopub.status.idle":"2022-02-24T14:00:46.582466Z","shell.execute_reply.started":"2022-02-24T13:58:08.60373Z","shell.execute_reply":"2022-02-24T14:00:46.581268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PS: You might be wondering how accurate the model would be using the initial train set and adding the resolution as a feature. The answer is   0.9786 (avg for 10-fold CV), which is slightly better than using 4 separate models, but still worse than using the pseudo-labelling approach, as we just saw.","metadata":{}},{"cell_type":"markdown","source":"## 5. Ensembling predictions","metadata":{}},{"cell_type":"code","source":"# Average prob\n#y_probs_avg = sum(y_probs_ext) / len(y_probs_ext)\n# The explanations for these numbers are in AMBROSM's code\n#y_probs_avg += np.array([0, 0, 0.01, 0.03, 0, 0, 0, 0, 0, 0])\n#y_pred_tuned = le.inverse_transform(np.argmax(y_probs_avg, axis=1))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-24T13:09:41.580771Z","iopub.status.idle":"2022-02-24T13:09:41.581618Z","shell.execute_reply.started":"2022-02-24T13:09:41.581315Z","shell.execute_reply":"2022-02-24T13:09:41.581347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# credits: https://www.kaggle.com/max1mum/extra-trees-cv-voting\nmean_prob = sum(y_probs_ext) / len(y_probs_ext)\n\n# The distribution of bacteria types\ntarget_dist = pd.Series(y_train).value_counts().sort_index() / len(y_train) * 100\n\n# Finds the difference in percent between the normal and tuned target distributions\ndef get_diff(deltas, distribution):\n    tuned_predictions = pd.Series(np.argmax(mean_prob + deltas, axis=1))\n    return distribution - tuned_predictions.value_counts().sort_index() / len(X_test) * 100\n\n# The list of probability deltas to match distributions\ndeltas = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\ndiff = get_diff(deltas, target_dist)\nprint(\"Mean difference before tuning:\", diff.abs().mean(), \"%\")\n\n# Finding the optimal probability deltas\nfor i in range(1000):\n    diff_max_id = np.argmax(diff.abs())\n\n    if diff[diff_max_id] > 0.1:\n        deltas[diff_max_id] += 0.001\n    elif diff[diff_max_id] < -0.1:\n        deltas[diff_max_id] -= 0.001\n    else:\n        break\n    diff = get_diff(deltas, target_dist)\n\nprint(\"Mean difference after tuning:\", diff.abs().mean(), \"%\")\nmean_prob += deltas","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:09:41.583151Z","iopub.status.idle":"2022-02-24T13:09:41.58388Z","shell.execute_reply.started":"2022-02-24T13:09:41.583575Z","shell.execute_reply":"2022-02-24T13:09:41.583607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_tuned = le.inverse_transform(np.argmax(mean_prob, axis=1))\ny_pred_tuned","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:09:41.585659Z","iopub.status.idle":"2022-02-24T13:09:41.586173Z","shell.execute_reply.started":"2022-02-24T13:09:41.585898Z","shell.execute_reply":"2022-02-24T13:09:41.585926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_res = mode(y_preds_ext).mode[0]\nsub.loc[index_test_low, 'target'] = y_pred_tuned\nsub.sort_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:09:41.587886Z","iopub.status.idle":"2022-02-24T13:09:41.588429Z","shell.execute_reply.started":"2022-02-24T13:09:41.588132Z","shell.execute_reply":"2022-02-24T13:09:41.588159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Correcting labels","metadata":{}},{"cell_type":"code","source":"# credits: https://www.kaggle.com/hamzaghanmi/train-test-286\n#sub.loc[common_labels.row_id_y, 'target'] = common_labels.target","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:09:41.589951Z","iopub.status.idle":"2022-02-24T13:09:41.59047Z","shell.execute_reply.started":"2022-02-24T13:09:41.590172Z","shell.execute_reply":"2022-02-24T13:09:41.590198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Submission","metadata":{}},{"cell_type":"code","source":"#sub_samp = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\", index_col=0)\n#sub_samp","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-24T13:09:41.591649Z","iopub.status.idle":"2022-02-24T13:09:41.592136Z","shell.execute_reply.started":"2022-02-24T13:09:41.59188Z","shell.execute_reply":"2022-02-24T13:09:41.591907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert(sub.index.duplicated(keep='first').any() == False)\nsub.to_csv('submission.csv')\nprint(sub)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T13:09:41.594679Z","iopub.status.idle":"2022-02-24T13:09:41.595535Z","shell.execute_reply.started":"2022-02-24T13:09:41.595245Z","shell.execute_reply":"2022-02-24T13:09:41.595278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Future steps:\n\nI think that there are two main problems to solve in this competition:\n\n1. The first is what we saw: the classification of noisy samples with resolution of 1000 and 10000. This is something that can be addressed just using CV as we did here and trying to tune hyper-parameters, generate more data, create more useful features. \n2. The second problem is the deviation train and test samples that AmbrosM showed when plotting both datasets using PCA. He suggested a correction in the probabilities to fix the difference in the number of samples per class between sets. \n\nWith regards to the first problem, I strongly believe that the most efficient approach is to split it into two more specific (and maybe smaller) problems: one easy and one hard. The easy problem consists simply in predicting the high-resolution samples, the ones with res=1 and res=10 (and it's very easy indeed as we saw earlier). The hard problem, though, is to somehow use the information extracted from the data and also from the easy problem to address the classification of the low-resolution samples. \n\nThanks for reading!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}