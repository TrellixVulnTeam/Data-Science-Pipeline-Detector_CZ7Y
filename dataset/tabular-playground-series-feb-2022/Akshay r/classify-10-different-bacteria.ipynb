{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-17T09:38:09.723172Z","iopub.execute_input":"2022-02-17T09:38:09.724438Z","iopub.status.idle":"2022-02-17T09:38:09.756649Z","shell.execute_reply.started":"2022-02-17T09:38:09.724304Z","shell.execute_reply":"2022-02-17T09:38:09.755652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I'll be starting with tensorflow \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, datasets\n\nfrom tqdm.auto import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:38:09.75805Z","iopub.execute_input":"2022-02-17T09:38:09.758294Z","iopub.status.idle":"2022-02-17T09:38:15.462289Z","shell.execute_reply.started":"2022-02-17T09:38:09.758267Z","shell.execute_reply":"2022-02-17T09:38:15.461553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-feb-2022/train.csv\", index_col=0)\ntest = pd.read_csv(\"../input/tabular-playground-series-feb-2022/test.csv\", index_col=0)\n\nprint(\"Training data shape: \", train.shape)\nprint(\"Test data shape: \", test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:38:15.463947Z","iopub.execute_input":"2022-02-17T09:38:15.464204Z","iopub.status.idle":"2022-02-17T09:38:53.936444Z","shell.execute_reply.started":"2022-02-17T09:38:15.464175Z","shell.execute_reply":"2022-02-17T09:38:53.935584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking available data types\nprint(\"Data types:\\n\", train.dtypes.unique())\n\n# checking for missing data\nprint(\"\\nMissing data in train set:\\n\", np.sum(train.isna().sum()))\nprint(\"\\nMissing data in test set:\\n\", np.sum(test.isna().sum()))\n\n# checking for duplicate values\nprint(\"\\nDuplicate values in train set:\\n\", train.duplicated().sum())\nprint(\"\\nDuplicate values in test set:\\n\", test.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:38:53.937746Z","iopub.execute_input":"2022-02-17T09:38:53.937962Z","iopub.status.idle":"2022-02-17T09:38:56.802996Z","shell.execute_reply.started":"2022-02-17T09:38:53.937937Z","shell.execute_reply":"2022-02-17T09:38:56.801915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, have to deal with duplicate values in the dataset\ntrain_with_duplicates = train.copy()\n\n# drop the duplicate values out of the dataset for both the train and test sets\ntrain.drop_duplicates(keep='first', inplace=True)\n# Dont't temper with the test set.\n# test.drop_duplicates(keep='first', inplace=True)\n\nprint(\"Shape of new training data: \", train.shape)\nprint(\"Checking number of duplicates in new training data: \", train.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:38:56.805465Z","iopub.execute_input":"2022-02-17T09:38:56.80597Z","iopub.status.idle":"2022-02-17T09:38:59.938446Z","shell.execute_reply.started":"2022-02-17T09:38:56.805922Z","shell.execute_reply":"2022-02-17T09:38:59.937464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CHECKING FOR THE DISTRIBUTION OF THE TARGETS FOR BOTH CASES\ndef plot(train, title):\n    plt.figure(figsize=(10, 6))\n    plt.title(title)\n    plt.xticks(rotation=30, ha='right')\n    ax = sns.countplot(x=train['target'], data=train)\n    print(pd.Series(train['target'], index=train.index).value_counts().sort_index() / len(train) * 100)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:38:59.939771Z","iopub.execute_input":"2022-02-17T09:38:59.94001Z","iopub.status.idle":"2022-02-17T09:38:59.946389Z","shell.execute_reply.started":"2022-02-17T09:38:59.939984Z","shell.execute_reply":"2022-02-17T09:38:59.945583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(train, \"Dataset without duplicates\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:38:59.947608Z","iopub.execute_input":"2022-02-17T09:38:59.94784Z","iopub.status.idle":"2022-02-17T09:39:00.532036Z","shell.execute_reply.started":"2022-02-17T09:38:59.947813Z","shell.execute_reply":"2022-02-17T09:39:00.531209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(train_with_duplicates, \"Dataset with duplicates\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:00.533231Z","iopub.execute_input":"2022-02-17T09:39:00.533468Z","iopub.status.idle":"2022-02-17T09:39:01.236601Z","shell.execute_reply.started":"2022-02-17T09:39:00.533441Z","shell.execute_reply":"2022-02-17T09:39:01.23579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Next, checking for memory usage \n# print(\"Memory usage(train_with_duplicates): {:5.2f} Mb\".format(train_with_duplicates.memory_usage().sum()/1024**2))\n# print(\"Memory usage(train): {:5.2f} Mb\".format(train.memory_usage().sum()/1024**2))\n\n# Still, the memory usage can be reduced further\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int8', 'int16', 'int32', 'int64', 'float32', 'float64']\n    initial_mem = df.memory_usage().sum()/1024**2\n    \n    for col in df.columns:\n        col_dtype = df[col].dtypes\n        \n        if col_dtype in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_dtype)[:3] == 'int':  \n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n                \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n                    \n    end_mem = df.memory_usage().sum()/1024**2\n    if verbose:\n        print(\"Mem usage decreased to {:5.2f} Mb, ({:4.2f}%)\".format(end_mem, 100*(initial_mem - end_mem)/initial_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:01.237916Z","iopub.execute_input":"2022-02-17T09:39:01.238639Z","iopub.status.idle":"2022-02-17T09:39:01.253581Z","shell.execute_reply.started":"2022-02-17T09:39:01.238592Z","shell.execute_reply":"2022-02-17T09:39:01.252684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reducing memory usage for the dataset without duplicates\nprint(\"New memory usage for train set\")\ntrain = reduce_mem_usage(train)\n\nprint(\"New memory usage for test set\")\ntest = reduce_mem_usage(test)\n# Reducing memory usage for the dataset with duplicates\n# train_with_duplicates = reduce_mem_usage(train_with_duplicates)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:01.255151Z","iopub.execute_input":"2022-02-17T09:39:01.255481Z","iopub.status.idle":"2022-02-17T09:39:23.983477Z","shell.execute_reply.started":"2022-02-17T09:39:01.255436Z","shell.execute_reply":"2022-02-17T09:39:23.982617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, we can separate the features from the targets\nfeatures = train.columns[:-1]\ntarget = 'target'\n\nprint(\"# of features: \", len(features))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:23.986864Z","iopub.execute_input":"2022-02-17T09:39:23.987247Z","iopub.status.idle":"2022-02-17T09:39:23.99311Z","shell.execute_reply.started":"2022-02-17T09:39:23.987205Z","shell.execute_reply":"2022-02-17T09:39:23.992298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Target encoding, that is turn the bacteria into numeric labels\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ntrain[target] = encoder.fit_transform(train[target])\n\n# sample_weight = train.value_counts().values","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:23.994459Z","iopub.execute_input":"2022-02-17T09:39:23.994681Z","iopub.status.idle":"2022-02-17T09:39:24.17132Z","shell.execute_reply.started":"2022-02-17T09:39:23.994657Z","shell.execute_reply":"2022-02-17T09:39:24.170413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train[features]\ny = train[target]\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:24.172412Z","iopub.execute_input":"2022-02-17T09:39:24.172682Z","iopub.status.idle":"2022-02-17T09:39:24.315524Z","shell.execute_reply.started":"2022-02-17T09:39:24.172654Z","shell.execute_reply":"2022-02-17T09:39:24.314704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:24.316691Z","iopub.execute_input":"2022-02-17T09:39:24.316926Z","iopub.status.idle":"2022-02-17T09:39:24.561656Z","shell.execute_reply.started":"2022-02-17T09:39:24.3169Z","shell.execute_reply":"2022-02-17T09:39:24.56098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ExtraTreesModel(N_ESTIMATORS=300):\n    model = ExtraTreesClassifier(\n        n_estimators=N_ESTIMATORS,\n        n_jobs=-1,\n        verbose=0,\n        random_state=1221\n    )\n    return model\n\ndef DNN():\n    inputs = keras.Input(shape=X.shape[1])\n    x = layers.Dense(512, activation='relu')(inputs)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dense(64, activation='relu')(x)\n    outputs = layers.Dense(10, activation='softmax')(x)\n    model = keras.Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:24.562716Z","iopub.execute_input":"2022-02-17T09:39:24.563398Z","iopub.status.idle":"2022-02-17T09:39:24.570588Z","shell.execute_reply.started":"2022-02-17T09:39:24.563364Z","shell.execute_reply":"2022-02-17T09:39:24.569881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_loop(model_name = \"etc\", N_SPLITS=10):\n    sample_weight = train.value_counts().values\n    folds = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=1223)\n    scores = []\n\n    for fold, (train_id, valid_id) in enumerate(tqdm(folds.split(X, y), total=N_SPLITS)):\n        X_train = X.iloc[train_id]\n        y_train = y.iloc[train_id]\n        X_valid = X.iloc[valid_id]\n        y_valid = y.iloc[valid_id]\n\n        if model_name == \"etc\":\n            # etc stands for ExtraTreeClassifier\n            # Training\n            model = ExtraTreesModel()\n            if len(sample_weight) == 0:\n                model.fit(X_train, y_train)\n            else:\n                sample_weight_train = sample_weight[train_id]\n                model.fit(X_train, y_train, sample_weight=sample_weight_train)\n            \n            # validation\n            valid_pred = model.predict(X_valid)\n            valid_score = 0\n            if len(sample_weight) == 0:\n                valid_score = accuracy_score(valid_pred, y_valid)\n            else:\n                sample_weight_valid = sample_weight[valid_id]\n                valid_score = accuracy_score(valid_pred, y_valid, sample_weight=sample_weight_valid)\n                scores.append(valid_score)\n            print(f\"Fold {fold+1} \\tAccuracy: {valid_score:.4f}\")\n            \n        if model_name == \"dnn\" or model_name == \"nn\":\n            y_train = keras.utils.to_categorical(y_train)\n            y_valid = keras.utils.to_categorical(y_valid)\n            model = DNN()\n            earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True, verbose=1)\n            learningRate = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, mode='min', min_lr=1e-5, verbose=1)\n            model.compile(optimizer='rmsprop',\n                         loss='categorical_crossentropy',\n                         metrics=['accuracy'])\n            model.fit(X_train, y_train,\n                      validation_data=(X_valid, y_valid),\n                      batch_size=128,\n                      epochs=50,\n                      callbacks = [earlyStopping, learningRate], verbose=0)\n            print(f\"Fold {fold+1} \\tAccuracy: {model.evaluate(X_valid, y_valid)[1]:.4f}\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:24.571884Z","iopub.execute_input":"2022-02-17T09:39:24.572126Z","iopub.status.idle":"2022-02-17T09:39:24.58753Z","shell.execute_reply.started":"2022-02-17T09:39:24.572099Z","shell.execute_reply":"2022-02-17T09:39:24.586829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dnn_model = training_loop(model_name='nn', N_SPLITS=3)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:24.588498Z","iopub.execute_input":"2022-02-17T09:39:24.589325Z","iopub.status.idle":"2022-02-17T09:39:24.603455Z","shell.execute_reply.started":"2022-02-17T09:39:24.589292Z","shell.execute_reply":"2022-02-17T09:39:24.602656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"etc_model = training_loop()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:39:24.604775Z","iopub.execute_input":"2022-02-17T09:39:24.605447Z","iopub.status.idle":"2022-02-17T09:48:15.793914Z","shell.execute_reply.started":"2022-02-17T09:39:24.605416Z","shell.execute_reply":"2022-02-17T09:48:15.792625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Neural network outputs are probabilistic. \n# Doing the same for the ExtraTreeClassifier\n# dnn_probas = dnn_model.predict(test)\netc_probas = etc_model.predict_proba(test)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:48:15.796372Z","iopub.execute_input":"2022-02-17T09:48:15.796768Z","iopub.status.idle":"2022-02-17T09:48:21.043675Z","shell.execute_reply.started":"2022-02-17T09:48:15.79672Z","shell.execute_reply":"2022-02-17T09:48:21.04285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # averaging/weighting the predictions\n# preds1 = 0.5*(dnn_probas + etc_probas)\n# preds2 = 0.65*dnn_probas + 0.35*etc_probas","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:48:21.045088Z","iopub.execute_input":"2022-02-17T09:48:21.045522Z","iopub.status.idle":"2022-02-17T09:48:21.051975Z","shell.execute_reply.started":"2022-02-17T09:48:21.045449Z","shell.execute_reply":"2022-02-17T09:48:21.051318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(np.argmax(dnn_probas, axis=1))\n# print(np.argmax(etc_probas, axis=1))\n# print(np.argmax(preds1, axis=1))\n# print(np.argmax(preds2, axis=1))\n\npredictions = np.argmax(etc_probas, axis=1)\npredictions","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:48:21.052959Z","iopub.execute_input":"2022-02-17T09:48:21.053833Z","iopub.status.idle":"2022-02-17T09:48:21.077479Z","shell.execute_reply.started":"2022-02-17T09:48:21.053803Z","shell.execute_reply":"2022-02-17T09:48:21.076898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the numbers into the respective names of the bacteria\nlabels = encoder.inverse_transform(predictions)\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:48:21.078596Z","iopub.execute_input":"2022-02-17T09:48:21.079109Z","iopub.status.idle":"2022-02-17T09:48:21.091874Z","shell.execute_reply.started":"2022-02-17T09:48:21.079076Z","shell.execute_reply":"2022-02-17T09:48:21.091103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:48:21.092933Z","iopub.execute_input":"2022-02-17T09:48:21.093463Z","iopub.status.idle":"2022-02-17T09:48:21.17304Z","shell.execute_reply.started":"2022-02-17T09:48:21.093431Z","shell.execute_reply":"2022-02-17T09:48:21.172235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample['target'] = labels\nsample.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:48:21.174817Z","iopub.execute_input":"2022-02-17T09:48:21.175138Z","iopub.status.idle":"2022-02-17T09:48:21.459366Z","shell.execute_reply.started":"2022-02-17T09:48:21.175096Z","shell.execute_reply":"2022-02-17T09:48:21.458557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\").head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:48:21.462265Z","iopub.execute_input":"2022-02-17T09:48:21.46265Z","iopub.status.idle":"2022-02-17T09:48:21.513786Z","shell.execute_reply.started":"2022-02-17T09:48:21.462604Z","shell.execute_reply":"2022-02-17T09:48:21.512983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}