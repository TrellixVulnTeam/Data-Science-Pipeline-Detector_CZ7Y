{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hi. I'm new at machine learning and data science and this is my first public notebook, so sorry if it's messy.\n\nMy notebook scales my data on both axis (0 & 1) and then \"extends\" the data on a 3 dimensional array, expanding every feature to the actual number of gene you have in the snippet by creating the list of all the possible combinations (A x M ; T x C ; G x D ; C x 1) \n\nThis will allow my model, which is a 2D convnet to convolve the input on 2 dimensions. \nAt first I tried to build a great model, but I ended having 0.90 accuracy on the test submission, will being able to have 0.98 on both training and validation with like 50 epochs. So I decided to train 30 \"quicks\" models on only 7 epochs (having around 0.95 accuracy), each of them having their weights initialized with a different seed to increase the \"diversity\", and then blend their results. \n\nI also supposed that any model which could give me a prediction where a certain category of bacteria gets a total number > 11000 or < 9000 is a bad model, so I droped it out (assuming that the repartition in the test set is similar to the train set, meaning each category of bacteria represents 1/10 of the total population, so 10000 elements)\n\nI didn't test this notebook I'm publishing now (cause I've run out of daily subscriptions) but you can test it if you want (and please do change the params, I'm pretty sure this can do better). I obtained 0.93 with a similare approach (so it should be around this number, or maybe not?) but with \"better\" models (around 20 epochs each) but it seemed to be overfitting every time so... \n\nIf you have any remark, please punish me in the comments. ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T19:12:14.177639Z","iopub.execute_input":"2022-02-28T19:12:14.178681Z","iopub.status.idle":"2022-02-28T19:12:14.203568Z","shell.execute_reply.started":"2022-02-28T19:12:14.178563Z","shell.execute_reply":"2022-02-28T19:12:14.202704Z"}}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\ndataraw = pd.read_csv(\"../input/tabular-playground-series-feb-2022/train.csv\",index_col=0)\ndatarawtest = pd.read_csv(\"../input/tabular-playground-series-feb-2022/test.csv\",index_col=0)\n#dataraw.drop_duplicates(inplace=True)\nprint(dataraw.shape)\ndataraw = dataraw.sample(frac = 1)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:34.860342Z","iopub.execute_input":"2022-03-01T14:35:34.86079Z","iopub.status.idle":"2022-03-01T14:35:46.500265Z","shell.execute_reply.started":"2022-03-01T14:35:34.860671Z","shell.execute_reply":"2022-03-01T14:35:46.497633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing as skp \n\ndatanorm = pd.concat([dataraw.iloc[:,:-1],datarawtest])\ndatanorm = skp.scale(datanorm, axis = 1)\nscalerraw = skp.StandardScaler()\n\nscalerraw.fit(datanorm) \ndatanorm = scalerraw.transform(datanorm) \nprint(datanorm)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.502129Z","iopub.status.idle":"2022-03-01T14:35:46.502993Z","shell.execute_reply.started":"2022-03-01T14:35:46.502667Z","shell.execute_reply":"2022-03-01T14:35:46.502703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"namelist = dataraw[\"target\"].unique()\nj = 0\nfor i in namelist:\n    print(i)\n    dataraw['target'].replace(i, j, inplace = True)\n    j+=1","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.504748Z","iopub.status.idle":"2022-03-01T14:35:46.505636Z","shell.execute_reply.started":"2022-03-01T14:35:46.50528Z","shell.execute_reply":"2022-03-01T14:35:46.505315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"L = np.zeros((286, 4))\nL[0,:] = [0, 0 ,0 ,10]\nind = 1\nfor k in range(10000):\n    r = k\n    M = int(r/1000)\n    r -= M*1000\n    C = int(r/100)\n    r -= C*100\n    D = int(r/10)\n    r -= D*10\n    U = r\n    if U + D+ C +M == 10:\n        L[ind,:] = [M, C , D , U]\n        ind+=1\n        if D == 9 and U ==1:\n            L[ind,:] = [0, 0, 10, 0]\n            ind+=1\n        if C == 9 and D ==1:\n            L[ind,:] = [0, 10, 0, 0]\n            ind+=1\n        if M == 9 and C ==1:\n            L[ind,:] = [10, 0, 0, 0]\n            ind+=1\n\nL/=10  \nL+= 0.0001\nprint(L)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.50731Z","iopub.status.idle":"2022-03-01T14:35:46.508188Z","shell.execute_reply.started":"2022-03-01T14:35:46.507864Z","shell.execute_reply":"2022-03-01T14:35:46.507898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.zeros((datanorm.shape[0], 286, 4))\n\nfor k in range(datanorm.shape[0]):\n        datatemp = datanorm[k, :][:,np.newaxis]\n       \n        data[k,:,:] = datatemp * L\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.509913Z","iopub.status.idle":"2022-03-01T14:35:46.510823Z","shell.execute_reply.started":"2022-03-01T14:35:46.510422Z","shell.execute_reply":"2022-03-01T14:35:46.510457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"limval = int(dataraw.shape[0]*.99)\n\nXtrain = data[:limval,:,:]\nYtrain = pd.get_dummies(dataraw[\"target\"].iloc[:limval]).to_numpy()\nXval = data[limval:dataraw.shape[0],:,:]\nYval = pd.get_dummies(dataraw[\"target\"].iloc[limval:]).to_numpy()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.51241Z","iopub.status.idle":"2022-03-01T14:35:46.513278Z","shell.execute_reply.started":"2022-03-01T14:35:46.512948Z","shell.execute_reply":"2022-03-01T14:35:46.512984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nXtrainnew = np.reshape(Xtrain, (Xtrain.shape[0], Xtrain.shape[1], Xtrain.shape[2], 1))\n\nXvalnew = np.reshape(Xval, (Xval.shape[0], Xval.shape[1], Xtrain.shape[2], 1))\nN = 20\nYpredvect = np.zeros((datarawtest.shape[0],N))\n\nkernel = 4\nfor i in range(N):\n    print(\"model number \" + str(i+1))\n    tf.keras.backend.clear_session()\n    initializer = tf.keras.initializers.GlorotNormal(seed = i)\n    \n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(16, (kernel, 4), activation = 'tanh',padding = 'same', input_shape = (286, 4, 1), kernel_initializer=initializer),\n        tf.keras.layers.AveragePooling2D((kernel,1),kernel,padding = 'same'),\n        tf.keras.layers.Conv2D(32, (kernel, 1), activation = 'tanh',padding = 'same', kernel_initializer=initializer),\n        \n        tf.keras.layers.Flatten(),\n        #tf.keras.layers.Dropout(0.2),\n        #tf.keras.layers.BatchNormalization(),\n        #tf.keras.layers.Dense(512, activation = \"relu\", kernel_initializer=initializer),\n        tf.keras.layers.Dropout(0.1),\n        #tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(512, activation = \"relu\", kernel_initializer=initializer),\n        #tf.keras.layers.Dropout(0.1),\n        #tf.keras.layers.BatchNormalization(),\n        \n        tf.keras.layers.Dense(128, activation = \"tanh\", kernel_initializer=initializer),\n        #tf.keras.layers.Dropout(0.1),\n        #tf.keras.layers.BatchNormalization(),\n        \n        #tf.keras.layers.Dense(10, activation = \"tanh\", kernel_initializer=initializer),\n\n        tf.keras.layers.Dense(10, activation = \"sigmoid\", kernel_initializer=initializer)\n    ])\n    #model.summary()\n    optimizer = tf.keras.optimizers.Adam()\n    loss = tf.keras.losses.CategoricalCrossentropy()\n    model.compile(optimizer = optimizer, loss = loss, metrics=['accuracy'] )\n    model.fit(Xtrainnew, Ytrain, epochs = 20, shuffle = True, validation_data = (Xvalnew, Yval), batch_size = 512)\n\n    datatest = data[dataraw.shape[0]:,:,:]\n    Xtest = np.reshape(datatest, (datatest.shape[0], datatest.shape[1], datatest.shape[2], 1))\n    Ypred = model.predict(Xtest)\n    Ypredvect[:,i] = Ypred.argmax(axis = 1)\n    #answer = namelist[Ypredvect]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.514966Z","iopub.status.idle":"2022-03-01T14:35:46.515849Z","shell.execute_reply.started":"2022-03-01T14:35:46.515462Z","shell.execute_reply":"2022-03-01T14:35:46.515496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"L = [i for i in range(N)]\nprint(L)\nfor name in range(10):\n    \n        print(namelist[name])\n        print(\"train\")\n        print(data[dataraw[dataraw.target==name].index,:,:].shape)\n        print(\"test\")\n        L2 = np.copy(L)\n        for j in L2:\n            \n            X = datatest[Ypredvect[:,j]==name,:,:].shape[0]    \n            print( \"modelel num \" + str(j) + \" : \" + str(X) + \" elements\")\n            if abs(X-10000) > 3000:\n                del L[L.index(j)]\n        print(L)         \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.517487Z","iopub.status.idle":"2022-03-01T14:35:46.518385Z","shell.execute_reply.started":"2022-03-01T14:35:46.518059Z","shell.execute_reply":"2022-03-01T14:35:46.518103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\n\nblender = stats.mode(Ypredvect[:,L], axis = 1)[0]\nanswers = namelist[blender.astype(int)]\nfor name in range(10):\n    \n        print(namelist[name])\n        print(str(blender[blender==name].shape[0]) + \" elements\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.520112Z","iopub.status.idle":"2022-03-01T14:35:46.520969Z","shell.execute_reply.started":"2022-03-01T14:35:46.520651Z","shell.execute_reply":"2022-03-01T14:35:46.520687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(answers)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.522518Z","iopub.status.idle":"2022-03-01T14:35:46.523354Z","shell.execute_reply.started":"2022-03-01T14:35:46.523041Z","shell.execute_reply":"2022-03-01T14:35:46.523075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\")\n\nsubmission['target'] = answers","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.525061Z","iopub.status.idle":"2022-03-01T14:35:46.525966Z","shell.execute_reply.started":"2022-03-01T14:35:46.525643Z","shell.execute_reply":"2022-03-01T14:35:46.525678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"./submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T14:35:46.528017Z","iopub.status.idle":"2022-03-01T14:35:46.528954Z","shell.execute_reply.started":"2022-03-01T14:35:46.528621Z","shell.execute_reply":"2022-03-01T14:35:46.528658Z"},"trusted":true},"execution_count":null,"outputs":[]}]}