{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BACTERIA AS IMAGE?\nLet's imagine that datset is a image classification problem. Each bacteria is represented as image. How bacteria will look like? How NN deal with this problem? Let's try and make experiment ...\n\nIn this notebook you will find:\n* How to convert tabular data into images and redefine problem\n* Keras neural network hybrid model - 2DConvolution (images) and Dense (additional tabular features)\n* NN model cross validation using StratifiedKFold - to evalueate model locally \n* NN feature maps visualizations\n* Grad-CAM - show parts of images (bacteria) which influence the choice of the class\n* Simplex model prediction optimizations - to find best weights for class \n* Another way of looking on tabular data (as images or NLP problem)\n* Tricks with Magic Functions (conditional cell run) - could be helpful and used instead of if function\n* Replacing target class in test dataset based on duplicates in train dataset\n\n<div align=\"center\"><img src=\"https://i.ibb.co/ydZdXCX/BACT-001.jpg\" width=800/></div>\n<div align=\"center\"><img src=\"https://i.ibb.co/CtK0YFg/oryg-grad.jpg\" width=800/></div>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-07T05:04:49.444199Z","iopub.execute_input":"2022-02-07T05:04:49.444791Z","iopub.status.idle":"2022-02-07T05:04:49.45218Z","shell.execute_reply.started":"2022-02-07T05:04:49.444754Z","shell.execute_reply":"2022-02-07T05:04:49.45132Z"}}},{"cell_type":"code","source":"%%capture\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport gc\nimport os\nimport time \n\nfrom scipy.stats import mode\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.metrics import accuracy_score\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom keras.utils.vis_utils import plot_model\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport matplotlib.cm as cm\nfrom IPython.display import Image, display\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-10T19:01:25.061489Z","iopub.execute_input":"2022-02-10T19:01:25.061979Z","iopub.status.idle":"2022-02-10T19:01:30.933586Z","shell.execute_reply.started":"2022-02-10T19:01:25.061891Z","shell.execute_reply":"2022-02-10T19:01:30.932793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CUTOM MAGIC FUNCTION\nI implemented magic function to skip execution of notebook cell. It can be helpful for your other notebooks.","metadata":{}},{"cell_type":"code","source":"from IPython.core.magic import (register_line_cell_magic)\n\n@register_line_cell_magic\ndef skip(line, cell=None):\n    if eval(line):\n        print(\"Cell skipped - not executed\")\n        return\n    get_ipython().ex(cell)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:01:30.935538Z","iopub.execute_input":"2022-02-10T19:01:30.935796Z","iopub.status.idle":"2022-02-10T19:01:30.941545Z","shell.execute_reply.started":"2022-02-10T19:01:30.93576Z","shell.execute_reply":"2022-02-10T19:01:30.940878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# notebook configuration \n\ncfg = {\n    'TARGET' : 'target',\n    'N_FOLDS' : 10,\n    'RANDOM': 42,\n    'SCORING': 'accuracy',\n    'PROD': True\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:01:30.942975Z","iopub.execute_input":"2022-02-10T19:01:30.94345Z","iopub.status.idle":"2022-02-10T19:01:30.950357Z","shell.execute_reply.started":"2022-02-10T19:01:30.943413Z","shell.execute_reply":"2022-02-10T19:01:30.949684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DATA PREPARATION","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/tabular-playground-series-feb-2022/test.csv\", index_col = 'row_id')\ntrain = pd.read_csv(\"../input/tabular-playground-series-feb-2022/train.csv\", index_col = 'row_id')\nsub_df = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\")\n\ntrain.drop_duplicates(keep='first', inplace=True)\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\n\ntarget = train.target\nnum_classes = target.nunique()\n\nFEATURES = [col for col in train.columns if col not in ['target']]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:57:14.125567Z","iopub.execute_input":"2022-02-10T19:57:14.125827Z","iopub.status.idle":"2022-02-10T19:57:36.783051Z","shell.execute_reply.started":"2022-02-10T19:57:14.125798Z","shell.execute_reply":"2022-02-10T19:57:36.782322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This dataset I create only for NN filter and Grad-CAM visualization\nscaler = MinMaxScaler()\ntrain_df = pd.DataFrame(scaler.fit_transform(train[FEATURES]), columns = FEATURES)\ntest_df = pd.DataFrame(scaler.transform(test[FEATURES]), columns = FEATURES)\n\n# Target feature encoder\nlb = LabelEncoder()\nenc_target = lb.fit_transform(target)\ntrain_df['target_enc'] = enc_target\ntrain['target_enc'] = enc_target\ntrain_df['target'] = target","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:57:36.784893Z","iopub.execute_input":"2022-02-10T19:57:36.785171Z","iopub.status.idle":"2022-02-10T19:57:37.431285Z","shell.execute_reply.started":"2022-02-10T19:57:36.785125Z","shell.execute_reply":"2022-02-10T19:57:37.430566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CONVERT TABULAR DATA TO IMAGES","metadata":{}},{"cell_type":"code","source":"# We creatively convert each obserwation to 2D (1 channel) image\nimg_rows = 13\nimg_cols = 22","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:02:11.161936Z","iopub.execute_input":"2022-02-10T19:02:11.162206Z","iopub.status.idle":"2022-02-10T19:02:11.166687Z","shell.execute_reply.started":"2022-02-10T19:02:11.162173Z","shell.execute_reply":"2022-02-10T19:02:11.165614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SHOW BACTERIA \"SPECTROGRAM\" BY CLASS\n- Do you see any patterns in images?\n- Are bacterias mixed or shifted?","metadata":{}},{"cell_type":"code","source":"def plot_bacteria(images, labels, indexes):\n    num_row = 10\n    num_col = 5\n\n    fig, axes = plt.subplots(num_row, num_col, constrained_layout=True,  sharex=True, sharey=True, figsize=(3*num_col,2*num_row))\n\n    for i in range(len(images)):\n        ax = axes[i//num_col, i%num_col]\n        image = images[i].reshape(img_rows, img_cols, 1)\n        ax.imshow(image, cmap='Spectral')\n        ax.set_title(f'{labels[i]}\\n{indexes[i]}')\n        plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.1, hspace=0.5)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:02:11.168425Z","iopub.execute_input":"2022-02-10T19:02:11.16868Z","iopub.status.idle":"2022-02-10T19:02:11.177123Z","shell.execute_reply.started":"2022-02-10T19:02:11.168646Z","shell.execute_reply":"2022-02-10T19:02:11.176326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot bacteria representants (4x 10) \n\nimages = train_df.groupby(\"target\").sample(5).drop([\"target_enc\"], axis = 1)\nlabels = images.target.values\nindexes = images.index.values\nimages = images[FEATURES].values.reshape(images.shape[0], img_rows, img_cols, 1).astype('float32')\n\nplot_bacteria(images, labels, indexes)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:02:11.178453Z","iopub.execute_input":"2022-02-10T19:02:11.178729Z","iopub.status.idle":"2022-02-10T19:02:16.841759Z","shell.execute_reply.started":"2022-02-10T19:02:11.178693Z","shell.execute_reply":"2022-02-10T19:02:16.840994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LETS'S LOOK INTO PATTERNS","metadata":{}},{"cell_type":"code","source":"train_df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:02:16.842958Z","iopub.execute_input":"2022-02-10T19:02:16.843248Z","iopub.status.idle":"2022-02-10T19:02:16.87356Z","shell.execute_reply.started":"2022-02-10T19:02:16.84321Z","shell.execute_reply":"2022-02-10T19:02:16.872838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot first 50 Bacteroides_fragilis         \n\nimages = train_df.query(\"target == 'Campylobacter_jejuni'\").sort_index()[:50].drop([\"target_enc\"], axis = 1)\nlabels = images.target.values\nindexes = images.index.values\nimages = images[FEATURES].values.reshape(images.shape[0], img_rows, img_cols, 1).astype('float32')\n\nplot_bacteria(images, labels, indexes)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T21:00:19.940965Z","iopub.execute_input":"2022-02-10T21:00:19.941603Z","iopub.status.idle":"2022-02-10T21:00:25.507077Z","shell.execute_reply.started":"2022-02-10T21:00:19.941559Z","shell.execute_reply":"2022-02-10T21:00:25.506229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot first 50 observations       \n\nimages = train_df.sort_index()[:50].drop([\"target_enc\"], axis = 1)\nlabels = images.target.values\nindexes = images.index.values\nimages = images[FEATURES].values.reshape(images.shape[0], img_rows, img_cols, 1).astype('float32')\n\nplot_bacteria(images, labels, indexes)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:02:22.184032Z","iopub.execute_input":"2022-02-10T19:02:22.185297Z","iopub.status.idle":"2022-02-10T19:02:27.491876Z","shell.execute_reply.started":"2022-02-10T19:02:22.185257Z","shell.execute_reply":"2022-02-10T19:02:27.491209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CREATE NN ARCHITECTURE (USING KERAS SEQUENTIAL)","metadata":{}},{"cell_type":"code","source":"batch_size = 512\nepochs = 100\n\ninput_shape = (img_rows, img_cols, 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:02:27.493036Z","iopub.execute_input":"2022-02-10T19:02:27.494316Z","iopub.status.idle":"2022-02-10T19:02:27.498595Z","shell.execute_reply.started":"2022-02-10T19:02:27.494272Z","shell.execute_reply":"2022-02-10T19:02:27.497817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n\ndef get_model():\n    model = Sequential()\n    x = Conv2D(128, kernel_size=(3, 3), padding='same', activation='swish', input_shape=input_shape, kernel_initializer='he_uniform')\n    model.add(x)\n    model.add(Conv2D(64, (3, 3), padding='same', activation='swish', kernel_initializer='he_uniform'))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(128, (3, 3), padding='same', activation = 'swish', kernel_initializer='he_uniform', name='conv_last'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(128, activation='swish', kernel_initializer='he_uniform'))\n    model.add(Dropout(0.2))\n    model.add(Dense(64, activation='swish', kernel_initializer='he_uniform'))\n    model.add(Dense(32, activation='swish', kernel_initializer='he_uniform'))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),\n                  metrics=['accuracy'])\n    \n    return model, x","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-10T21:44:09.530367Z","iopub.execute_input":"2022-02-10T21:44:09.53072Z","iopub.status.idle":"2022-02-10T21:44:09.554483Z","shell.execute_reply.started":"2022-02-10T21:44:09.530681Z","shell.execute_reply":"2022-02-10T21:44:09.553428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PLOT MODEL","metadata":{}},{"cell_type":"code","source":"model_global, _ = get_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:02:27.518921Z","iopub.execute_input":"2022-02-10T19:02:27.51951Z","iopub.status.idle":"2022-02-10T19:02:30.25247Z","shell.execute_reply.started":"2022-02-10T19:02:27.519471Z","shell.execute_reply":"2022-02-10T19:02:30.251734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model_global, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T21:44:15.472104Z","iopub.execute_input":"2022-02-10T21:44:15.472448Z","iopub.status.idle":"2022-02-10T21:44:15.852089Z","shell.execute_reply.started":"2022-02-10T21:44:15.47241Z","shell.execute_reply":"2022-02-10T21:44:15.85106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MODEL VALIDATION (k-FOLD) AND PREDICTION\n\nThe most important think in experimentation with NN architecture and feature engineering is to make good validation procedure. I use StratifiedKFold validation loop. I foud this better then train_test split approach. This attitude give us many advantages: \n* you can validate model on whole dataset (no test/train bias)\n* you can customize prediction for further preprocessing (in this notebook I use Simple optimization)","metadata":{}},{"cell_type":"code","source":"# FOLD validation\noof_preds = np.zeros((len(train_df), 1))\noof_proba = np.zeros((len(train_df), num_classes))\ntest_proba = np.zeros((len(test), num_classes))\ntest_preds = []\nfold_scores = []\nx = None #This is only for NN filter and Grad-CAM visualizations\n\nkf = StratifiedKFold(n_splits = cfg['N_FOLDS'], random_state = cfg['RANDOM'])\nprint(f\"Start CV model - {cfg['N_FOLDS']} for folds\")\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(train, train.target_enc)):\n    X_train, y_train = train[FEATURES].iloc[train_idx], train[['target_enc']].iloc[train_idx]\n    X_val, y_val = train[FEATURES].iloc[val_idx], train[['target_enc']].iloc[val_idx]\n    \n    ## in fold scaling\n    scaler = MinMaxScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n    X_test = scaler.transform(test[FEATURES].values)\n    \n    # in fold data transformation -> convert to images\n    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1).astype('float32')\n    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1).astype('float32')\n    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1).astype('float32')\n    \n    # in fold target one hot encoding \n    enc = OneHotEncoder(categories = 'auto', drop = None, sparse = False)\n    y_train = enc.fit_transform(y_train)\n    y_val = enc.transform(y_val) \n    \n    model, conv = get_model()\n    \n    es = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', min_delta = 0.00001, \n                                          patience = 6, verbose = 0, mode = 'max', baseline=None, \n                                          restore_best_weights=True)\n\n    plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', \n                                                   factor = 0.04, patience = 5, \n                                                   verbose = 0, mode = 'max')\n    \n    history = model.fit(X_train, y_train,\n                    batch_size = batch_size,\n                    epochs = epochs,\n                    verbose = 0,\n                    validation_data = (X_val, y_val),\n                    callbacks = [es, plateau])\n    \n    val_score = model.evaluate(X_val, y_val, verbose=0)\n    print(f\"   FOLD: {fold + 1} - accuracy on val set: \", val_score[1])\n    \n    fold_scores.append(history)\n    oof_preds[val_idx, 0] = np.argmax(model.predict(X_val), axis = -1)\n    oof_proba[val_idx, :] = model.predict(X_val)\n    \n    test_preds.append(np.argmax(model.predict(X_test), axis = -1))\n    test_proba[: , :] += model.predict(X_test)\n    \n    # Save last model for filter/grad-CAM visualization\n    if fold == cfg['N_FOLDS'] - 1:\n        model_global = model\n        x = conv\n    else:\n        del model, val_score, es, plateau\n        gc.collect()\n\ntest_proba = test_proba / cfg['N_FOLDS']\noof_score = accuracy_score(train_df.target_enc.values, oof_preds)\nprint(f\"OOF accuracy: {oof_score}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-10T21:44:23.645512Z","iopub.execute_input":"2022-02-10T21:44:23.645778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2022.02.10 - BASELINE (5 first fold - 10f cv) \n# FOLD: 1 - accuracy on val set:  0.935967743396759\n# FOLD: 2 - accuracy on val set:  0.9441128969192505\n# FOLD: 3 - accuracy on val set:  0.946854829788208\n# FOLD: 4 - accuracy on val set:  0.9544318318367004\n# FOLD: 5 - accuracy on val set:  0.9666101932525635","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.360591Z","iopub.status.idle":"2022-02-10T19:17:02.361329Z","shell.execute_reply.started":"2022-02-10T19:17:02.360906Z","shell.execute_reply":"2022-02-10T19:17:02.360956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PLOT LEARNING HISTORY","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor fold in range(len(fold_scores)):\n    history_f = fold_scores[fold]\n\n    fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(14,4))\n    fig.suptitle('Fold : '+str(fold), fontsize=14)\n        \n    plt.subplot(1,2,1)\n    plt.plot(history_f.history['loss'], label= ['loss'])\n    plt.plot(history_f.history['val_loss'], label= ['val_loss'])\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.title('loss')\n    plt.grid()\n    \n    plt.subplot(1,2,2)\n    plt.plot(history_f.history['accuracy'], label= ['accuracy'])\n    plt.plot(history_f.history['val_accuracy'], label= ['val_accuracy'])\n    plt.title('accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.grid()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-10T19:17:02.365874Z","iopub.status.idle":"2022-02-10T19:17:02.366258Z","shell.execute_reply.started":"2022-02-10T19:17:02.366041Z","shell.execute_reply":"2022-02-10T19:17:02.36606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SHOW MODEL SAMPLE CONV2D FILTERS","metadata":{}},{"cell_type":"code","source":"filters, biases = x.get_weights()\nconv_weight = filters[:,:,0,:]\n\n# Check the shape of first Conv2D layer\nprint(f'First conv2D shape: {filters.shape}')\nprint(f'First conv2D output size: {x.output.shape} \\n')\n\nplt.figure(figsize = (10,10))\nprint(\"First 16 filters of conv2D layer\")\nfor i in range(1,17):\n    plt.subplot(4,4,i)\n    plt.imshow(conv_weight[:,:,i], interpolation='nearest', cmap='summer', aspect='auto')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.36706Z","iopub.status.idle":"2022-02-10T19:17:02.367554Z","shell.execute_reply.started":"2022-02-10T19:17:02.367231Z","shell.execute_reply":"2022-02-10T19:17:02.367254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PLOT IMAGES FROM FIRST CONV2D LAYER  ","metadata":{}},{"cell_type":"code","source":"bacteria_sample = train_df[FEATURES].iloc[5].values.reshape(1, img_rows, img_cols, 1).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.369335Z","iopub.status.idle":"2022-02-10T19:17:02.369865Z","shell.execute_reply.started":"2022-02-10T19:17:02.369637Z","shell.execute_reply":"2022-02-10T19:17:02.36966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import expand_dims\nfrom keras.models import Model\n\n#img = expand_dims(bacteria_samples[1], axis=0)\n# Then hijacked output from first layer\nmodel_first2D = Model(inputs=model.inputs, outputs=x.output)\n\n# Made prediction of first sample\nfeature_maps = model_first2D.predict(bacteria_sample)\n\n# Plot all (32) images from our conv2D layer \nplt.figure(figsize = (40,20))\nsquare = 8\nix = 1\nfor _ in range(4):\n    for _ in range(square):\n        ax = plt.subplot(square, square, ix)\n        plt.imshow(feature_maps[0, :, :, ix-1], cmap='cool', interpolation='nearest')\n        ix += 1\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.378285Z","iopub.status.idle":"2022-02-10T19:17:02.378788Z","shell.execute_reply.started":"2022-02-10T19:17:02.378496Z","shell.execute_reply":"2022-02-10T19:17:02.378536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SIMPLEX OPTIMIZATIONS\n\nThe Nelder-Mead simplex method uses a simplex to traverse the space in search of a minimum. A simplex is a generalization of a tetrahedron to n-dimensional space. A simplex in one dimension is a line, and in two dimensions it is a triangle. The simplex derives its name from the fact that it is the simplest possible polytope in any given space. Source: Algorithms for Optimization (Mykel J. Kochenderfer, Tim A. Wheeler)","metadata":{}},{"cell_type":"code","source":"np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\nprint(oof_proba[0:10])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:40:58.326114Z","iopub.execute_input":"2022-02-10T19:40:58.326791Z","iopub.status.idle":"2022-02-10T19:40:58.334781Z","shell.execute_reply.started":"2022-02-10T19:40:58.326756Z","shell.execute_reply":"2022-02-10T19:40:58.33394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.optimize import minimize\n\ndef inter_class_optimizer(weights, oof_preds_opt):\n    oof = oof_preds_opt * weights\n    oof = np.argmax(oof, axis = -1)\n    y_val = enc_target\n    return (1 - accuracy_score(y_val, oof))\n\n\ndef pred_fold_optimizer(oof_preds_opt, test_preds_opt):   \n    \n    print(f\"OOF ACCURACY score BEFORE optimization: {accuracy_score(enc_target, np.argmax(oof_preds_opt, axis = -1))}\")\n    \n    cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n    \n    bon = [(0.0, 1.0)] * 10\n    \n    res = minimize(fun = inter_class_optimizer,\n                   x0 = [1/10 for _ in range(10)],\n                   args = oof_preds_opt,\n                   method = 'Nelder-Mead',\n                   options = {'maxiter': 500, 'maxfev': 500},\n                   bounds = bon,\n                   constraints = cons)\n    \n    print(f\"   Class scaler: {res.x}\")\n    \n    oof_preds_opt = np.array([res.x[i] * oof_preds_opt[ :, i] for i in range(10)]).transpose()\n    test_preds_opt = np.array([res.x[i] * test_preds_opt[ :, i] for i in range(10)]).transpose()\n    \n    print(f\"OOF ACCURACY score AFTER optimization: {accuracy_score(enc_target, np.argmax(oof_preds_opt, axis = -1))}\")\n    print('Status : %s' % res['message'])\n    print('Total Evaluations: %d' % res['nfev'])\n\n    solution = res['x']\n    evaluation = inter_class_optimizer(solution, oof_preds_opt)\n    print('Solution: f(%s) = %.5f' % (solution, evaluation))\n    return res[\"fun\"], oof_preds_opt, test_preds_opt ","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:41:01.83787Z","iopub.execute_input":"2022-02-10T19:41:01.838283Z","iopub.status.idle":"2022-02-10T19:41:01.849913Z","shell.execute_reply.started":"2022-02-10T19:41:01.838247Z","shell.execute_reply":"2022-02-10T19:41:01.849225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res, _, optim_preds = pred_fold_optimizer(oof_proba, test_proba)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:41:04.741608Z","iopub.execute_input":"2022-02-10T19:41:04.742352Z","iopub.status.idle":"2022-02-10T19:41:06.259202Z","shell.execute_reply.started":"2022-02-10T19:41:04.742314Z","shell.execute_reply":"2022-02-10T19:41:06.258359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MAKE PREDICTION AND SUBMISSION","metadata":{}},{"cell_type":"code","source":"preds = lb.inverse_transform(mode(test_preds).mode[0])\npd.Series(preds, index=test_df.index).value_counts().sort_index() / len(test) * 100","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:41:20.951169Z","iopub.execute_input":"2022-02-10T19:41:20.951706Z","iopub.status.idle":"2022-02-10T19:41:23.788782Z","shell.execute_reply.started":"2022-02-10T19:41:20.951668Z","shell.execute_reply":"2022-02-10T19:41:23.788041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.target = preds\nsub_df.to_csv(\"TPS02-Conv2D-BASE-submission.csv\", index=False)\nsub_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:41:23.791396Z","iopub.execute_input":"2022-02-10T19:41:23.792692Z","iopub.status.idle":"2022-02-10T19:41:24.061715Z","shell.execute_reply.started":"2022-02-10T19:41:23.792653Z","shell.execute_reply":"2022-02-10T19:41:24.060927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MAKE SIMPLEX OPTIMIZED SUBMISSION","metadata":{}},{"cell_type":"code","source":"_, _, optim_preds = pred_fold_optimizer(oof_proba, test_proba)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:41:26.745595Z","iopub.execute_input":"2022-02-10T19:41:26.746258Z","iopub.status.idle":"2022-02-10T19:41:28.146007Z","shell.execute_reply.started":"2022-02-10T19:41:26.746221Z","shell.execute_reply":"2022-02-10T19:41:28.145243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = lb.inverse_transform(np.argmax(optim_preds, axis = -1))\npd.Series(preds, index=test_df.index).value_counts().sort_index() / len(test) * 100","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:41:33.870523Z","iopub.execute_input":"2022-02-10T19:41:33.870786Z","iopub.status.idle":"2022-02-10T19:41:33.909665Z","shell.execute_reply.started":"2022-02-10T19:41:33.870757Z","shell.execute_reply":"2022-02-10T19:41:33.908864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.target = preds\nsub_df.to_csv(\"TPS02-Conv2D-SIMPLEX-submission.csv\", index=False)\nsub_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:49:26.301363Z","iopub.execute_input":"2022-02-10T19:49:26.302022Z","iopub.status.idle":"2022-02-10T19:49:26.549848Z","shell.execute_reply.started":"2022-02-10T19:49:26.301974Z","shell.execute_reply":"2022-02-10T19:49:26.549042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## FIX SUBMISSION PREDICTION WITH TEST DATA\nPart of data in training is included in test dataset so we can fix model prediction using oryginal data. It should improve our score a little bit.","metadata":{}},{"cell_type":"code","source":"train.index.name = 'row_id'\ntrain = train.reset_index(drop = False)\n\ntest.index = sub_df.index\ntest.index.name = 'row_id'\ntest = test.reset_index(drop = False)\n\ns1 = pd.merge(train, test, how='inner', on=FEATURES)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:46:48.851681Z","iopub.execute_input":"2022-02-10T19:46:48.851929Z","iopub.status.idle":"2022-02-10T19:47:01.445922Z","shell.execute_reply.started":"2022-02-10T19:46:48.851901Z","shell.execute_reply":"2022-02-10T19:47:01.445205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = 0\ndic = {}\nfor i in range(len(s1)):\n    dic[s1.loc[i]['row_id_y']] = s1.loc[i]['row_id_x']\n\nfor e in dic:\n    sub_df.loc[sub_df[sub_df.index==e].index.to_list(),'target'] = \\\n    train.loc[train[train.index==dic[e]].index.tolist()[0],'target']\n    counter +=1\nprint(f\"Changed {counter} rows!\")\n    \npd.Series(sub_df.target, index=test_df.index).value_counts().sort_index() / len(test) * 100","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:55:40.383647Z","iopub.execute_input":"2022-02-10T19:55:40.383938Z","iopub.status.idle":"2022-02-10T19:55:41.632207Z","shell.execute_reply.started":"2022-02-10T19:55:40.383905Z","shell.execute_reply":"2022-02-10T19:55:41.631484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"TPS02-Conv2D-SIM-TRAIN-submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.62149Z","iopub.status.idle":"2022-02-10T19:17:02.622741Z","shell.execute_reply.started":"2022-02-10T19:17:02.622423Z","shell.execute_reply":"2022-02-10T19:17:02.622487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grad-CAM class activation visualization\n\nBased on Keras \"[Grad-CAM class activation visualization](https://keras.io/examples/vision/grad_cam/)\" Let's see which part of image is responsible for class assignment.","metadata":{}},{"cell_type":"code","source":"def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n\n    img = np.squeeze(img_path, axis=0)\n\n    heatmap = np.uint8(255 * heatmap)\n\n    jet = cm.get_cmap(\"jet\")\n\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n    \n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n    \n    return superimposed_img","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.62468Z","iopub.status.idle":"2022-02-10T19:17:02.625895Z","shell.execute_reply.started":"2022-02-10T19:17:02.625664Z","shell.execute_reply":"2022-02-10T19:17:02.625691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.target[7:16]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.627535Z","iopub.status.idle":"2022-02-10T19:17:02.628655Z","shell.execute_reply.started":"2022-02-10T19:17:02.628425Z","shell.execute_reply":"2022-02-10T19:17:02.628451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's print some bacteria from dataset","metadata":{}},{"cell_type":"code","source":"bacteria_sample_set = train_df[FEATURES][7:16]\nbacteria_sample_set = bacteria_sample_set.values.reshape(len(bacteria_sample_set), img_rows, img_cols, 1).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.630545Z","iopub.status.idle":"2022-02-10T19:17:02.631957Z","shell.execute_reply.started":"2022-02-10T19:17:02.631605Z","shell.execute_reply":"2022-02-10T19:17:02.631633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,8))\nfor i, bacteria in enumerate(bacteria_sample_set):\n    plt.subplot(3,3,i+1)\n    plt.imshow(np.squeeze(expand_dims(bacteria, axis=0), axis=0), interpolation='nearest', cmap='Spectral', aspect='auto')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.633887Z","iopub.status.idle":"2022-02-10T19:17:02.63528Z","shell.execute_reply.started":"2022-02-10T19:17:02.634868Z","shell.execute_reply":"2022-02-10T19:17:02.634896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we can see grad-cam heatmaps","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16,8))\nfor i, bacteria in enumerate(bacteria_sample_set):\n    plt.subplot(3,3,i+1)\n    img = expand_dims(bacteria, axis=0)\n    preds = model_global.predict(img)\n    heatmap = make_gradcam_heatmap(img, model, \"conv_last\")\n    plt.imshow(heatmap, interpolation='nearest', cmap='Spectral', aspect='auto')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.637074Z","iopub.status.idle":"2022-02-10T19:17:02.638257Z","shell.execute_reply.started":"2022-02-10T19:17:02.637999Z","shell.execute_reply":"2022-02-10T19:17:02.638034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### And final products .... grad-CAM heatmaps on bacteria images\n\nNow we can see which part of bacteria image is important for network to recognize appropriate class","metadata":{}},{"cell_type":"code","source":"model.layers[-1].activation = None\nplt.figure(figsize = (16,8))\nfor i, bacteria in enumerate(bacteria_sample_set):\n    plt.subplot(3,3,i+1)\n    img = expand_dims(bacteria, axis=0)\n    preds = model_global.predict(img)\n    heatmap = make_gradcam_heatmap(img, model, \"conv_last\")\n    grad_cam = save_and_display_gradcam(img, heatmap)\n    plt.imshow(grad_cam, interpolation='nearest', cmap='Spectral', aspect='auto')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-10T19:17:02.639937Z","iopub.status.idle":"2022-02-10T19:17:02.641065Z","shell.execute_reply.started":"2022-02-10T19:17:02.640822Z","shell.execute_reply":"2022-02-10T19:17:02.640846Z"},"trusted":true},"execution_count":null,"outputs":[]}]}