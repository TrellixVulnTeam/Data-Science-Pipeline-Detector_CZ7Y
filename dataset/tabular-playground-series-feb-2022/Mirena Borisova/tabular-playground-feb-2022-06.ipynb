{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly as py\nfrom statistics import mean\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)\nimport seaborn as sns\nfrom scipy import stats\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom umap import UMAP\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport optuna\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Input, Concatenate\n\nnp.random.seed(228)\ntf.random.set_seed(228)\n\npd.set_option('display.max_columns', None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-18T07:16:16.278792Z","iopub.execute_input":"2022-02-18T07:16:16.279136Z","iopub.status.idle":"2022-02-18T07:16:42.947785Z","shell.execute_reply.started":"2022-02-18T07:16:16.279045Z","shell.execute_reply":"2022-02-18T07:16:42.946576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv', index_col='row_id')\ntest = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv', index_col='row_id')\nss = pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:16:42.949786Z","iopub.execute_input":"2022-02-18T07:16:42.950236Z","iopub.status.idle":"2022-02-18T07:17:26.006825Z","shell.execute_reply.started":"2022-02-18T07:16:42.950195Z","shell.execute_reply":"2022-02-18T07:17:26.005744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    print('MEMORY USAGE OF DATAFRAME IS: {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col]= df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n    \n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    print('MEMORY USAGE AFTER OPTIMIZATION IS: {:.2f} MB'.format(end_mem))\n    print('DECREASED BY: {:.1f} %'.format((start_mem - end_mem) / start_mem * 100))\n    \n    return df\n\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:17:26.008026Z","iopub.execute_input":"2022-02-18T07:17:26.008232Z","iopub.status.idle":"2022-02-18T07:18:12.981291Z","shell.execute_reply.started":"2022-02-18T07:17:26.008207Z","shell.execute_reply":"2022-02-18T07:18:12.980091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train.columns.tolist()[0:-1]\n\ndef statistics(df):\n    df['std'] = df[features].std(axis=1)\n    df['min'] = df[features].min(axis=1)\n    df['max'] = df[features].max(axis=1)\n    \nstatistics(train)\nstatistics(test)\n\nfeatures += ['std', 'min', 'max']\n\nle = LabelEncoder()\ntrain['target'] = le.fit_transform(train['target'])\n\nsc = StandardScaler()\n\ntrain[features] = sc.fit_transform(train[features])\ntest[features] = sc.transform(test[features])\n\nX = train[features]\ny = train['target']","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:12.984157Z","iopub.execute_input":"2022-02-18T07:18:12.985241Z","iopub.status.idle":"2022-02-18T07:18:47.20159Z","shell.execute_reply.started":"2022-02-18T07:18:12.985184Z","shell.execute_reply":"2022-02-18T07:18:47.200568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    BATCH_SIZE = tpu_strategy.num_replicas_in_sync * 64\n    print('RUNNING ON TPU:', tpu.master)\n    print(f'BATCH SIZE: {BATCH_SIZE}')\nexcept ValueError:\n    strategy = tf.distribute.get_strategy()\n    BATCH_SIZE = 512\n    print(f'RUNNING ON {strategy.num_replicas_in_sync} REPLICAS')\n    print(f'BATCH SIZE: {BATCH_SIZE}')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:47.20276Z","iopub.execute_input":"2022-02-18T07:18:47.202979Z","iopub.status.idle":"2022-02-18T07:18:47.219798Z","shell.execute_reply.started":"2022-02-18T07:18:47.202951Z","shell.execute_reply":"2022-02-18T07:18:47.218831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_model():\n    x_input = Input(shape=(X.shape[-1]), name='input')\n    x_1 = Dense(256, activation='selu')(x_input)\n    b_1 = BatchNormalization()(x_1)\n    x_2 = Dense(128, activation='selu')(b_1)\n    b_2 = BatchNormalization()(x_2)\n    x_3 = Dense(128, activation='selu')(b_1)\n    b_3 = BatchNormalization()(x_3)\n    \n    d_1 = Dropout(0.15)(Concatenate()([b_2, b_3]))\n    x_4 = Dense(128, activation='relu')(d_1)\n    b_4 = BatchNormalization()(x_4)\n    x_5 = Dense(64, activation='selu')(b_4)\n    b_5 = BatchNormalization()(x_5)\n    x_6 = Dense(32, activation='selu')(b_5)\n    b_6 = BatchNormalization()(x_6)\n    \n    output = Dense(10, activation='softmax', name='output')(b_6)\n    \n    model = tf.keras.Model(x_input, output, name='DNN_Model')\n    \n    return model\n\nmodel = my_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:47.221131Z","iopub.execute_input":"2022-02-18T07:18:47.221847Z","iopub.status.idle":"2022-02-18T07:18:47.501481Z","shell.execute_reply.started":"2022-02-18T07:18:47.221809Z","shell.execute_reply":"2022-02-18T07:18:47.500789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(\n    model,\n    to_file='SUPER_MODEL.png',\n    show_shapes=True,\n    show_layer_names=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:47.50279Z","iopub.execute_input":"2022-02-18T07:18:47.503154Z","iopub.status.idle":"2022-02-18T07:18:48.708171Z","shell.execute_reply.started":"2022-02-18T07:18:47.503122Z","shell.execute_reply":"2022-02-18T07:18:48.7069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = X.values\ny = y.values\ntest = test.values","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:48.710027Z","iopub.execute_input":"2022-02-18T07:18:48.710628Z","iopub.status.idle":"2022-02-18T07:18:48.71631Z","shell.execute_reply.started":"2022-02-18T07:18:48.710585Z","shell.execute_reply":"2022-02-18T07:18:48.715591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VERBOSE = True\npredictions, scores = [], []\nskf = StratifiedKFold(n_splits=10, random_state=228, shuffle=True)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X, y)):\n    X_train, X_val = X[trn_idx], X[val_idx]\n    y_train, y_val = y[trn_idx], y[val_idx]\n    \n    model = my_model()\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n    \n    lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=3, verbose=VERBOSE)\n    es = EarlyStopping(monitor='val_loss', patience=7, verbose=VERBOSE, mode='min', restore_best_weights=True)\n    \n    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n    chk_point = ModelCheckpoint(f'./TPS1_model_2022_{fold + 1}C.h5', options=save_locally,\n                                monitor='val_loss', verbose=VERBOSE,\n                                save_best_only=True,\n                                mode='min')\n    \n    model.fit(X_train,\n              y_train,\n              validation_data=(X_val, y_val),\n              epochs=300,\n              verbose=VERBOSE,\n              batch_size=BATCH_SIZE,\n              callbacks=[lr, chk_point, es])\n    \n    load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n    model = load_model(f'./TPS1_model_2022_{fold + 1}C.h5', options=load_locally)\n    \n    y_pred = model.predict(X_val, batch_size=BATCH_SIZE)\n    score = accuracy_score(y_val, np.argmax(y_pred, axis=1))\n    scores.append(score)\n    predictions.append(np.argmax(model.predict(test, batch_size=BATCH_SIZE), axis=1))\n    print(f'FOLD: {fold + 1} | OOF SCORE: {score}')\n    \nprint(f'MEAN ACCURACY ON {skf.n_splits} folds - {mean(scores)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:12:25.475822Z","iopub.execute_input":"2022-02-18T08:12:25.476628Z","iopub.status.idle":"2022-02-18T08:56:28.232438Z","shell.execute_reply.started":"2022-02-18T08:12:25.476589Z","shell.execute_reply":"2022-02-18T08:56:28.23184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retarget = {train['target'].value_counts().reset_index()['index'][i]: i for i in range(len(train['target'].value_counts()))}\nretarget_2 = {i: key for key, i in retarget.items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-18T09:03:23.037642Z","iopub.execute_input":"2022-02-18T09:03:23.037897Z","iopub.status.idle":"2022-02-18T09:03:23.068396Z","shell.execute_reply.started":"2022-02-18T09:03:23.037873Z","shell.execute_reply":"2022-02-18T09:03:23.06786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss['target'] = stats.mode(np.column_stack(predictions), axis=1)[0]\nss['target'] = ss['target'].map(retarget_2)\nss.to_csv('submission_03.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T09:03:24.749231Z","iopub.execute_input":"2022-02-18T09:03:24.749531Z","iopub.status.idle":"2022-02-18T09:03:27.942634Z","shell.execute_reply.started":"2022-02-18T09:03:24.749488Z","shell.execute_reply":"2022-02-18T09:03:27.941881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, scores = [], []\nskf = StratifiedKFold(n_splits=10, random_state=228, shuffle=True)\n\nfor i, (trn_idx, val_idx) in enumerate(skf.split(X, y)):\n    X_train, X_val = X[trn_idx], X[val_idx]\n    y_train, y_val = y[trn_idx], y[val_idx]\n    \n    model = ExtraTreesClassifier(n_estimators=1111, n_jobs=-1)\n    model.fit(X_train, y_train)\n    \n    val_pred = model.predict(X_val)\n    val_score = accuracy_score(y_val, val_pred)\n    print(f'FOLD: {i + 1} ACCURACY SCORE: {round(val_score, 4)}')\n    \n    scores.append(val_score)\n    predictions.append(model.predict_proba(test))\n    \nprint(f'\\nMEAN ACCURACY: {round(mean(scores), 4)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T09:12:54.818853Z","iopub.execute_input":"2022-02-18T09:12:54.819139Z","iopub.status.idle":"2022-02-18T10:15:12.791324Z","shell.execute_reply.started":"2022-02-18T09:12:54.819108Z","shell.execute_reply":"2022-02-18T10:15:12.790018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_proba = sum(predictions) / len(predictions)\ny_proba += np.array([0, 0, 0.025, 0.045, 0, 0, 0, 0, 0, 0])\ny_pred_tuned = le.inverse_transform(np.argmax(y_proba, axis=1))\n# pd.Series(y_pred_tuned, index=test.index).value_counts().sort_index() / len(test) * 100","metadata":{"execution":{"iopub.status.busy":"2022-02-18T10:22:50.259313Z","iopub.execute_input":"2022-02-18T10:22:50.259913Z","iopub.status.idle":"2022-02-18T10:22:50.283459Z","shell.execute_reply.started":"2022-02-18T10:22:50.259881Z","shell.execute_reply":"2022-02-18T10:22:50.282889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss['target'] = y_pred_tuned\nss.to_csv('submission_04.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T10:22:53.115296Z","iopub.execute_input":"2022-02-18T10:22:53.116099Z","iopub.status.idle":"2022-02-18T10:22:53.348585Z","shell.execute_reply.started":"2022-02-18T10:22:53.116046Z","shell.execute_reply":"2022-02-18T10:22:53.347704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_1 = pd.read_csv('../input/forest-of-extra-trees-0-9895-up-to-4th-place/submission__.csv')\nsub_2 = pd.read_csv('../input/forest-of-extra-trees-0-9895-up-to-4th-place/submission__blend.csv')\nsub_3 = pd.read_csv('../input/forest-of-extra-trees-0-9895-up-to-4th-place/submission__blend_2.csv')\n\nss['target'] = le.fit_transform(ss['target'])\nsub_1['target'] = le.transform(sub_1['target'])\nsub_2['target'] = le.transform(sub_2['target'])\nsub_3['target'] = le.transform(sub_3['target'])\n\nblend_preds = []\nfor preds in [ss, sub_1, sub_2, sub_3]:\n    blend_preds.append(preds['target'])\n    \nblend_ss = ss.copy()\nblend_ss['target'] = le.inverse_transform(stats.mode(np.column_stack(blend_preds), axis=1)[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-18T10:23:00.600356Z","iopub.execute_input":"2022-02-18T10:23:00.600622Z","iopub.status.idle":"2022-02-18T10:23:03.871335Z","shell.execute_reply.started":"2022-02-18T10:23:00.600594Z","shell.execute_reply":"2022-02-18T10:23:03.870704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blend_ss.to_csv('submission_05.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T10:23:06.315411Z","iopub.execute_input":"2022-02-18T10:23:06.315691Z","iopub.status.idle":"2022-02-18T10:23:06.543235Z","shell.execute_reply.started":"2022-02-18T10:23:06.315662Z","shell.execute_reply":"2022-02-18T10:23:06.542641Z"},"trusted":true},"execution_count":null,"outputs":[]}]}