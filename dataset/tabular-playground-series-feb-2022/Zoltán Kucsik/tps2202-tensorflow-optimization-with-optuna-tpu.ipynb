{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score\nimport optuna\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-14T09:55:44.012372Z","iopub.execute_input":"2022-02-14T09:55:44.013667Z","iopub.status.idle":"2022-02-14T09:55:51.582888Z","shell.execute_reply.started":"2022-02-14T09:55:44.013517Z","shell.execute_reply":"2022-02-14T09:55:51.581976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Greetings! :)\nThis my first public notebook so please be patient and please let me know if you find any errors/bugs or if you have any idea about improving the notebook. Important remark that this notebook won't find the optimal values for a neural network (because of time and resource constraints) but it can be a good start.","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:55:51.58467Z","iopub.execute_input":"2022-02-14T09:55:51.584944Z","iopub.status.idle":"2022-02-14T09:56:32.077581Z","shell.execute_reply.started":"2022-02-14T09:55:51.584914Z","shell.execute_reply":"2022-02-14T09:56:32.076609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=df_train.drop('row_id', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:56:32.079057Z","iopub.execute_input":"2022-02-14T09:56:32.079626Z","iopub.status.idle":"2022-02-14T09:56:32.374924Z","shell.execute_reply.started":"2022-02-14T09:56:32.079591Z","shell.execute_reply":"2022-02-14T09:56:32.373913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remove of duplicated rows:\n**The remove method of the duplicated rows is based on AmbrosM's notebook**: https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants","metadata":{}},{"cell_type":"code","source":"vc = df_train.value_counts()\ndedup_train = pd.DataFrame([list(tup) for tup in vc.index.values], columns=df_train.columns)\ndedup_train['sample_weight'] = vc.values\ndedup_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:56:32.37702Z","iopub.execute_input":"2022-02-14T09:56:32.377273Z","iopub.status.idle":"2022-02-14T09:56:57.448167Z","shell.execute_reply.started":"2022-02-14T09:56:32.377245Z","shell.execute_reply":"2022-02-14T09:56:57.446706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_dictionary = {\n    'Streptococcus_pyogenes': 0,\n    'Salmonella_enterica': 1,\n    'Enterococcus_hirae': 2, \n    'Escherichia_coli': 3, \n    'Campylobacter_jejuni': 4,\n    'Streptococcus_pneumoniae': 5, \n    'Staphylococcus_aureus': 6,\n    'Escherichia_fergusonii': 7, \n    'Bacteroides_fragilis': 8,\n    'Klebsiella_pneumoniae': 9\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dedup_train['target'] = dedup_train['target'].replace(target_dictionary)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:56:57.46042Z","iopub.execute_input":"2022-02-14T09:56:57.460794Z","iopub.status.idle":"2022-02-14T09:56:57.60015Z","shell.execute_reply.started":"2022-02-14T09:56:57.460758Z","shell.execute_reply":"2022-02-14T09:56:57.599154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [c for c in df_train.columns if c not in ('row_id', 'target')]","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:56:57.6017Z","iopub.execute_input":"2022-02-14T09:56:57.602035Z","iopub.status.idle":"2022-02-14T09:56:57.607459Z","shell.execute_reply.started":"2022-02-14T09:56:57.602Z","shell.execute_reply":"2022-02-14T09:56:57.60632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = dedup_train[features]\ny = dedup_train['target']\nsample_weight = dedup_train['sample_weight']","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:56:57.608988Z","iopub.execute_input":"2022-02-14T09:56:57.609631Z","iopub.status.idle":"2022-02-14T09:56:57.742769Z","shell.execute_reply.started":"2022-02-14T09:56:57.609581Z","shell.execute_reply":"2022-02-14T09:56:57.741823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid, sample_weight_train, sample_weight_valid  = train_test_split(X, y, sample_weight, test_size = 0.2, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:56:57.744336Z","iopub.execute_input":"2022-02-14T09:56:57.74466Z","iopub.status.idle":"2022-02-14T09:56:58.053735Z","shell.execute_reply.started":"2022-02-14T09:56:57.744629Z","shell.execute_reply":"2022-02-14T09:56:58.053024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_valid = sc.transform(X_valid)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:56:58.054844Z","iopub.execute_input":"2022-02-14T09:56:58.055432Z","iopub.status.idle":"2022-02-14T09:56:58.734085Z","shell.execute_reply.started":"2022-02-14T09:56:58.055399Z","shell.execute_reply":"2022-02-14T09:56:58.73317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n        patience=30,\n        min_delta=0.001,\n        restore_best_weights=True,\n    )","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:56:58.735316Z","iopub.execute_input":"2022-02-14T09:56:58.73556Z","iopub.status.idle":"2022-02-14T09:56:58.740394Z","shell.execute_reply.started":"2022-02-14T09:56:58.73553Z","shell.execute_reply":"2022-02-14T09:56:58.739717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect and init the TPU\ntry: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:56:58.741496Z","iopub.execute_input":"2022-02-14T09:56:58.742644Z","iopub.status.idle":"2022-02-14T09:57:04.737035Z","shell.execute_reply.started":"2022-02-14T09:56:58.742603Z","shell.execute_reply":"2022-02-14T09:57:04.7363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def runNN(trial):\n    batch_size=trial.suggest_int(\"batch_size\", 1024,4096)\n    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n    dropout = trial.suggest_uniform('dropout', 0.0, 0.5)\n    optimizer = trial.suggest_categorical(\"optimizer\", ['adam', 'rmsprop'])\n    activation = trial.suggest_categorical(\"activation\", ['relu', 'sigmoid'])\n    \n    model = tf.keras.Sequential()\n    for i in range(n_layers):\n        num_hidden = trial.suggest_int(\"n_units_l{}\".format(i), 512, 2048, log=True)\n        model.add(tf.keras.layers.Dense(num_hidden, activation=\"relu\"))\n        model.add(tf.keras.layers.BatchNormalization())\n        model.add(tf.keras.layers.Dropout(dropout))\n        \n    tf.keras.layers.Dense(10, activation='softmax')\n\n    model.compile(optimizer = optimizer, loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n\n    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=200, sample_weight = sample_weight_train, callbacks=early_stopping, verbose=0)\n\n    valid_pred=model.predict(X_valid)\n    valid_pred = np.argmax(valid_pred, axis=-1)\n    valid_score = accuracy_score(y_valid,valid_pred, sample_weight = sample_weight_valid)\n    return valid_score","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:57:04.738168Z","iopub.execute_input":"2022-02-14T09:57:04.738613Z","iopub.status.idle":"2022-02-14T09:57:04.750104Z","shell.execute_reply.started":"2022-02-14T09:57:04.738574Z","shell.execute_reply":"2022-02-14T09:57:04.749062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Final remarks:\nUnfortunately it takes too much time to find the optimal values and the TPU time is limited so I set the number of trials (n_trials) to 30.","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    study=optuna.create_study(direction=\"maximize\")\n    study.optimize(runNN,n_trials=30)\n    study.best_params","metadata":{"execution":{"iopub.status.busy":"2022-02-14T09:57:04.753275Z","iopub.execute_input":"2022-02-14T09:57:04.754107Z","iopub.status.idle":"2022-02-14T10:03:33.35254Z","shell.execute_reply.started":"2022-02-14T09:57:04.754042Z","shell.execute_reply":"2022-02-14T10:03:33.350944Z"},"trusted":true},"execution_count":null,"outputs":[]}]}