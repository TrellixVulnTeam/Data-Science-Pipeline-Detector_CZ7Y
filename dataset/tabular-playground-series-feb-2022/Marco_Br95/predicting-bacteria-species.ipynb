{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>\n    <p style=\"text-align:center; font-size:180%\"> Tabular Playground Series - Feb 2022</p> \n</h1>\n\n<center>\n    <img src=\"https://media.snl.no/media/58661/article_topimage_28881401596_d2c61ee954_o.jpg\" width=\"600\" height=\"1800\"> \n</center>","metadata":{}},{"cell_type":"markdown","source":"<h2>\n    <p style=\"text-align:center; font-family:Verdana; letter-spacing:0.5px; font-size:120%\"> Predicting bacteria species based on repeated lossy measurements of DNA snippets\n    </p>\n</h2> ","metadata":{}},{"cell_type":"markdown","source":"# 1. Importing Libraries","metadata":{}},{"cell_type":"code","source":"# Data manipulation\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Maths\nimport numpy as np\n\n# Patching sklearn\n!pip install scikit-learn-intelex\nfrom sklearnex import patch_sklearn\npatch_sklearn()\n\n# Model Building \nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nimport shap\nfrom sklearn.metrics import accuracy_score\n\n\n\n# Lgbm\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgbm\nimport optuna\nfrom optuna.integration import LightGBMPruningCallback\n\n# Visualization\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pprint\n\n# Settings\nsns.set(rc = {'figure.figsize': (26, 8)})\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style = \"ticks\", rc = custom_params)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:16:16.487947Z","iopub.execute_input":"2022-02-08T06:16:16.488611Z","iopub.status.idle":"2022-02-08T06:16:59.538056Z","shell.execute_reply.started":"2022-02-08T06:16:16.488472Z","shell.execute_reply":"2022-02-08T06:16:59.537187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Loading and EDA","metadata":{}},{"cell_type":"code","source":"# Data loading\ntrain_data = pd.read_csv(\"../input/tabular-playground-series-feb-2022/train.csv\", index_col = 'row_id')\ntest_data = pd.read_csv(\"../input/tabular-playground-series-feb-2022/test.csv\", index_col = 'row_id')\nsubmission = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:16:59.540012Z","iopub.execute_input":"2022-02-08T06:16:59.540384Z","iopub.status.idle":"2022-02-08T06:17:45.280422Z","shell.execute_reply.started":"2022-02-08T06:16:59.540352Z","shell.execute_reply":"2022-02-08T06:17:45.279135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop Not relevant columns\ndef drop_nrv(df):\n    na_df = pd.DataFrame(df.isna().sum(), \n                         columns = ['Number of NaN'])\n    \n    na_df = na_df.sort_values('Number of NaN', \n                              ascending = False).head(10)\n    \n    na_df['Perc'] = round(na_df['Number of NaN']/len(train_data.index)*100, 2)\n    \n    # Drop columns that have more than 50% of NaN\n    to_drop = list(na_df[na_df['Perc'] > 50.00].index)\n    na_df['Perc'] = na_df['Perc'].astype(str) + '%'\n    df.drop(to_drop, \n            inplace = True, axis = 1)\n    \n    if to_drop == []:\n        print('No column has been removed (< 50% NaN)\\n',\n                f'Overall missing values: {(df.isna().sum().sum())/(df.shape[0]*df.shape[1])}%\\n', sep = '')\n    else:\n        print(to_drop, ' columns have been removed (> 50% NaN)\\n', sep = '')\n    \n    return na_df, df.astype('float64', errors = 'ignore')\n\nprint('TRAIN DATA\\n')\nmissing_val_train, train_data = drop_nrv(train_data)\nprint(missing_val_train, '\\n\\n', '-'*80, '\\n', sep = '')\n\nprint('TEST DATA\\n')\nmissing_val_test, test_data = drop_nrv(test_data)\nprint(missing_val_test, '\\n\\n', '-'*80, '\\n', sep = '')\n\nprint(f'Train Data rows: {train_data.shape[0]} \\nTrain Data Columns: {train_data.shape[1]}\\n')\nprint(f'Test Data rows: {test_data.shape[0]} \\nTest Data Columns: {test_data.shape[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:17:45.282459Z","iopub.execute_input":"2022-02-08T06:17:45.282785Z","iopub.status.idle":"2022-02-08T06:17:46.292883Z","shell.execute_reply.started":"2022-02-08T06:17:45.282749Z","shell.execute_reply":"2022-02-08T06:17:46.291662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Target Column\ntarget_bacteria_list = train_data['target'].unique()\ntarget_bacteria = train_data['target']\ntrain_data.drop('target', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:17:46.294291Z","iopub.execute_input":"2022-02-08T06:17:46.29451Z","iopub.status.idle":"2022-02-08T06:17:46.457691Z","shell.execute_reply.started":"2022-02-08T06:17:46.294483Z","shell.execute_reply":"2022-02-08T06:17:46.456927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def obj_int_identifier(train_data, test_data):\n\n    num_unique_val = pd.DataFrame(train_data.nunique(), columns = ['Unique Values']).sort_values(by = 'Unique Values')\n    cat = num_unique_val[num_unique_val['Unique Values']<=10].index\n    cont  = num_unique_val[num_unique_val['Unique Values']>10].index\n    \n    train_data_cont_var = train_data.filter(cont).columns\n    train_data_disc_var = train_data.filter(cat).columns\n    \n    print('Train data total columns: ', \n          len(train_data_cont_var)+len(train_data_disc_var), \n          '\\nContinuous Features: ', len(train_data_cont_var),\n          '\\nDiscrete Features: ', len(train_data_disc_var), '\\n', sep ='')\n    \n    test_data_cont_var = test_data.filter(cont).columns\n    test_data_disc_var = test_data.filter(cat).columns\n\n    print('Test data total columns: ', \n          len(test_data_cont_var)+len(test_data_disc_var), \n          '\\nContinuous Features: ', len(test_data_cont_var),\n          '\\nDiscrete Features: ', len(test_data_disc_var), sep ='')\n    \n    return train_data_cont_var, train_data_disc_var, test_data_cont_var, test_data_disc_var\n\ntrain_data_cont_var, train_data_disc_var, test_data_cont_var, test_data_disc_var = obj_int_identifier(train_data, test_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:17:46.460919Z","iopub.execute_input":"2022-02-08T06:17:46.461507Z","iopub.status.idle":"2022-02-08T06:17:47.530955Z","shell.execute_reply.started":"2022-02-08T06:17:46.461454Z","shell.execute_reply":"2022-02-08T06:17:47.529958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Align Features\ndef discrepancies_check(train, test):\n    dict_train = {}\n    dict_test = {}\n    \n    for el in train_data_disc_var:\n        dict_train[el] = train[el].unique().tolist()\n    \n    for el in test_data_disc_var:\n        dict_test[el] = test[el].unique().tolist()\n    \n    if dict_train.keys() == dict_test.keys():\n        print('Train and Test set have the same discrete features.\\nResults:')\n    else: \n        print('Pay attention, different discrete features in Train and Test!\\n')\n\n    dict_diff = {}\n    train_or_test = {}\n    \n    for key in dict_train.keys():\n        if set(dict_train[key]) ^ set(dict_test[key]) != set():\n            dict_diff[key] = list(set(dict_train[key]) ^ set(dict_test[key]))\n    \n    for key in dict_train.keys():\n        if (set(dict_test[key]) - set(dict_train[key]) != set()) & (set(dict_train[key]) - set(dict_test[key]) != set()):\n            train_or_test[key] = 'Both'        \n        elif set(dict_train[key]) - set(dict_test[key]) != set():\n            train_or_test[key] = 'Train'\n        elif set(dict_test[key]) - set(dict_train[key]) != set():\n            train_or_test[key] = 'Test'        \n        elif set(dict_train[key]) ^ set(dict_test[key]) == set():\n            pass\n        else:\n            print('Pay attention possible errors!')\n    \n    df = pd.DataFrame(index = dict_diff.keys(), columns = ['Discrepancies'])\n    df['Discrepancies'] = dict_diff.values()\n    \n    df1 = pd.DataFrame(index = train_or_test.keys(), columns = ['Where'])\n    df1['Where'] = train_or_test.values()\n    \n    final_df = df.merge(df1, right_index = True, left_index = True)\n    \n    if final_df.empty:\n        print('\\nNo discrepancies!')\n    else:\n        return final_df\n    \ndiscrepancies_check(train_data, test_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:17:47.532358Z","iopub.execute_input":"2022-02-08T06:17:47.532605Z","iopub.status.idle":"2022-02-08T06:17:47.561963Z","shell.execute_reply.started":"2022-02-08T06:17:47.532574Z","shell.execute_reply":"2022-02-08T06:17:47.561096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_count = pd.DataFrame(target_bacteria.value_counts())\ntarget_count\n\nfig = go.Figure(data=[go.Bar(\n    x = target_count.index,\n    y = target_count.target,\n    marker={'color': target_count.target,\n            'colorscale': 'RdBu'}\n)])\n\nfig.update_traces(marker_line_width=1.5, \n                  opacity=0.8)\n\nfig.update_layout(title_text = 'Bacteria Species Overview',\n                  template = 'plotly_white')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:17:47.563619Z","iopub.execute_input":"2022-02-08T06:17:47.564376Z","iopub.status.idle":"2022-02-08T06:17:48.921592Z","shell.execute_reply.started":"2022-02-08T06:17:47.564327Z","shell.execute_reply":"2022-02-08T06:17:48.920685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_count = pd.DataFrame(target_bacteria.value_counts())\ntarget_count\n\nfig = go.Figure(data=[go.Bar(\n    x = target_count.index,\n    y = np.round(target_count.target/(target_count.target.sum()),4)*100,\n    marker={'color': target_count.target,\n            'colorscale': 'RdBu'}\n)])\n\nfig.update_traces(marker_line_width=1.5, \n                  opacity=0.8)\n\nfig.update_layout(title_text = 'Bacteria Species Overview (percentage)',\n                  template = 'plotly_white')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:17:48.922907Z","iopub.execute_input":"2022-02-08T06:17:48.923146Z","iopub.status.idle":"2022-02-08T06:17:49.003693Z","shell.execute_reply.started":"2022-02-08T06:17:48.923116Z","shell.execute_reply":"2022-02-08T06:17:49.0028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_corr = pd.DataFrame(train_data.corr())\n\nfig = go.Figure(data=go.Heatmap(\n        z=feat_corr.values,\n        x=feat_corr.columns,\n        y=feat_corr.columns,\n        colorscale='RdBu'))\n\nfig.update_layout(\n    title='Correlation between all features')\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:17:49.005259Z","iopub.execute_input":"2022-02-08T06:17:49.006229Z","iopub.status.idle":"2022-02-08T06:18:34.40996Z","shell.execute_reply.started":"2022-02-08T06:17:49.006189Z","shell.execute_reply":"2022-02-08T06:18:34.40888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"high_corr = feat_corr.abs()\nhigh_corr = high_corr.unstack()\nhigh_corr = pd.DataFrame(high_corr).reset_index()\nhigh_corr.columns = ['Feature 1', 'Feature 2', 'Abs Correlation']\n\nhigh_corr = high_corr[(high_corr['Abs Correlation'] != 1) &\n                      (high_corr['Abs Correlation'] >= .5)]\n\nhigh_corr = high_corr.drop_duplicates(subset=['Feature 1', 'Feature 2'])\nhigh_corr = high_corr.sort_values(by = 'Abs Correlation', ascending = False)\nhigh_corr","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:18:34.412382Z","iopub.execute_input":"2022-02-08T06:18:34.412878Z","iopub.status.idle":"2022-02-08T06:18:34.454251Z","shell.execute_reply.started":"2022-02-08T06:18:34.412833Z","shell.execute_reply":"2022-02-08T06:18:34.45362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engineering(df):\n    \n    df['MEAN'] = df.mean(axis=1)\n    df['MEDIAN'] = df.median(axis=1)\n    df['STD'] = df.std(axis=1)\n    df['SKEW'] = df.skew(axis=1)\n    \n    return df\n\nfeature_engineering(train_data);\nfeature_engineering(test_data);","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:18:34.455688Z","iopub.execute_input":"2022-02-08T06:18:34.456114Z","iopub.status.idle":"2022-02-08T06:18:41.387354Z","shell.execute_reply.started":"2022-02-08T06:18:34.45608Z","shell.execute_reply":"2022-02-08T06:18:41.386394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scaling_feat(train_set, test_set):\n    print(f'Dimensions before scaling: \\ntrain_set: {train_set.shape} \\ntest_set: {test_set.shape}')\n    \n    scaler = StandardScaler()\n\n    train_set_scaled = scaler.fit_transform(train_set)\n    test_set_scaled = scaler.transform(test_set)\n\n    train_set = pd.DataFrame(train_set_scaled, index=train_set.index, columns=train_set.columns)\n    test_set = pd.DataFrame(test_set_scaled, index=test_set.index, columns=test_set.columns)\n    \n    print(f'\\nDimensions after scaling: \\ntrain_set: {train_set.shape} \\ntest_set: {test_set.shape}')\n    \n    return train_set, test_set\n\ntrain_set, test_set = scaling_feat(train_data, test_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:18:41.388748Z","iopub.execute_input":"2022-02-08T06:18:41.389002Z","iopub.status.idle":"2022-02-08T06:18:44.456825Z","shell.execute_reply.started":"2022-02-08T06:18:41.38897Z","shell.execute_reply":"2022-02-08T06:18:44.455701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"code","source":"train_x, validation_x, train_y, validation_y = train_test_split(train_set, \n                                                                target_bacteria, \n                                                                test_size=0.2,\n                                                                random_state=1505)\n\ntrain_x.columns = train_set.columns\nvalidation_x.columns = train_set.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:18:44.458445Z","iopub.execute_input":"2022-02-08T06:18:44.458805Z","iopub.status.idle":"2022-02-08T06:18:44.737244Z","shell.execute_reply.started":"2022-02-08T06:18:44.458756Z","shell.execute_reply":"2022-02-08T06:18:44.736044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x, test_x, train_y, test_y = train_test_split(train_x, \n                                                    train_y, \n                                                    test_size=0.2,\n                                                    random_state=1505)\n\ntrain_x.columns = train_set.columns\ntest_x.columns = train_set.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:18:44.74111Z","iopub.execute_input":"2022-02-08T06:18:44.741445Z","iopub.status.idle":"2022-02-08T06:18:44.947293Z","shell.execute_reply.started":"2022-02-08T06:18:44.741407Z","shell.execute_reply":"2022-02-08T06:18:44.946314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_x.shape, train_y.shape)\nprint(test_x.shape, test_y.shape)\nprint(validation_x.shape, validation_y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:18:44.948949Z","iopub.execute_input":"2022-02-08T06:18:44.949305Z","iopub.status.idle":"2022-02-08T06:18:44.957135Z","shell.execute_reply.started":"2022-02-08T06:18:44.949259Z","shell.execute_reply":"2022-02-08T06:18:44.956294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(target_bacteria)\ntarget_bacteria_enc = le.transform(target_bacteria)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:18:44.95872Z","iopub.execute_input":"2022-02-08T06:18:44.959518Z","iopub.status.idle":"2022-02-08T06:18:45.026838Z","shell.execute_reply.started":"2022-02-08T06:18:44.959468Z","shell.execute_reply":"2022-02-08T06:18:45.025735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_SPLITS = 10\nESTIMATORS = 500\n\nscores = []\ny_probs = []\nfolds = StratifiedKFold(n_splits=N_SPLITS, \n                        shuffle=True)\n\nfor fold, (train_id, test_id) in enumerate(folds.split(train_set, target_bacteria_enc)):  \n    \n    X_train = train_set.iloc[train_id]\n    y_train = target_bacteria_enc[train_id]\n    X_valid = train_set.iloc[test_id]\n    y_valid = target_bacteria_enc[test_id]\n    \n    model = ExtraTreesClassifier(\n        n_estimators=ESTIMATORS,\n        n_jobs=-1\n    )\n    \n    model.fit(X_train, y_train)\n    \n    valid_pred = model.predict(X_valid)\n    valid_score = accuracy_score(y_valid, valid_pred)\n    \n    print(\"Fold:\", fold + 1, \"Accuracy:\", valid_score)\n    scores.append(valid_score)\n    y_probs.append(model.predict_proba(test_set))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T06:42:37.017999Z","iopub.execute_input":"2022-02-08T06:42:37.01832Z","iopub.status.idle":"2022-02-08T07:12:11.908465Z","shell.execute_reply.started":"2022-02-08T06:42:37.018282Z","shell.execute_reply":"2022-02-08T07:12:11.907447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Mean accuracy score:\", np.array(scores).mean())","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:12:53.866897Z","iopub.execute_input":"2022-02-08T07:12:53.867246Z","iopub.status.idle":"2022-02-08T07:12:53.874359Z","shell.execute_reply.started":"2022-02-08T07:12:53.867212Z","shell.execute_reply":"2022-02-08T07:12:53.873268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob = sum(y_probs) / len(y_probs)\ny_prob += np.array([0, 0, 0.06, 0.06, 0.01, 0, 0, 0.02, 0, 0.01])\ny_pred_tuned = le.inverse_transform(np.argmax(y_prob, axis=1))\npd.Series(y_pred_tuned, index=test_set.index).value_counts().sort_index() / len(test_set) * 100","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:14:05.645696Z","iopub.execute_input":"2022-02-08T07:14:05.646062Z","iopub.status.idle":"2022-02-08T07:14:05.701099Z","shell.execute_reply.started":"2022-02-08T07:14:05.646026Z","shell.execute_reply":"2022-02-08T07:14:05.700311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Predictions","metadata":{}},{"cell_type":"code","source":"# Test CSV Submission\n\nsubmission = pd.DataFrame(test_set.index, columns = ['row_id'])\nsubmission['target'] = y_pred_tuned \nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T07:12:58.301046Z","iopub.execute_input":"2022-02-08T07:12:58.301386Z","iopub.status.idle":"2022-02-08T07:12:58.583587Z","shell.execute_reply.started":"2022-02-08T07:12:58.301354Z","shell.execute_reply":"2022-02-08T07:12:58.582403Z"},"trusted":true},"execution_count":null,"outputs":[]}]}