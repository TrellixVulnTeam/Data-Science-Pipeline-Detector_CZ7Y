{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-08T11:08:36.254552Z","iopub.execute_input":"2022-02-08T11:08:36.254898Z","iopub.status.idle":"2022-02-08T11:08:36.287197Z","shell.execute_reply.started":"2022-02-08T11:08:36.254811Z","shell.execute_reply":"2022-02-08T11:08:36.286549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The codes here a copy of Ambrosm's notebook. I have only created the pseudo-labelled data using the model in this notebook and re-run the notebook after adding it to the training data.\n\n#### Pseudo-labelled data was created by taking all rows from the test data where the predicted probability is >=0.99. We find that these are exclusively from rows with gcd = 1 or 10 which is not surprising.\n\n#### Code for creating the pseudo-labelled data is commented in this notebook as we do not need to re-create it.\n\n### We see an improvement in the CV score by 0.00653 and LB by 0.00015 when using Pseudo Labelling.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport gc\n\nfrom scipy.stats import mode\nfrom math import factorial\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-02-08T11:08:43.122797Z","iopub.execute_input":"2022-02-08T11:08:43.123253Z","iopub.status.idle":"2022-02-08T11:08:44.102266Z","shell.execute_reply.started":"2022-02-08T11:08:43.123221Z","shell.execute_reply":"2022-02-08T11:08:44.101357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Install Intelex","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn-intelex\n\nfrom sklearnex import patch_sklearn\npatch_sklearn()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read train, test and pseudo-labelled data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv', index_col='row_id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv', index_col='row_id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pseudo_train = pd.read_csv('../input/pseudo-labelled-data-for-tps-2022/test_pseudo.csv', index_col='row_id')\npseudo_train.drop(['proba','gcd'], axis=1, inplace=True)\npseudo_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([train_df, pseudo_train], axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.duplicated().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.duplicated().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_bins=train_df.columns.drop('target')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculate bias and add it","metadata":{}},{"cell_type":"code","source":"def bias(w, x, y, z):\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ndef bias_of(s):\n    w = int(s[1:s.index('T')])\n    x = int(s[s.index('T')+1:s.index('G')])\n    y = int(s[s.index('G')+1:s.index('C')])\n    z = int(s[s.index('C')+1:])\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ntrain_i = pd.DataFrame({col: ((train_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in hist_bins})\ntest_i = pd.DataFrame({col: ((test_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in hist_bins})\ntrain_i","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add gcd feature","metadata":{}},{"cell_type":"code","source":"def gcd_of_all(df_i):\n    gcd = df_i[hist_bins[0]]\n    for col in hist_bins[1:]:\n        gcd = np.gcd(gcd, df_i[col])\n    return gcd\n\ntrain_df['gcd'] = gcd_of_all(train_i)\ntest_df['gcd'] = gcd_of_all(test_i)\nnp.unique(train_df['gcd'], return_counts=True), np.unique(test_df['gcd'], return_counts=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remove duplicates and create sample weight for train data","metadata":{}},{"cell_type":"code","source":"vc = train_df.value_counts()\ndedup_train = pd.DataFrame([list(tup) for tup in vc.index.values], columns=train_df.columns)\ndedup_train['sample_weight'] = vc.values\ndedup_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_df[hist_bins].values == dedup_train[hist_bins].iloc[0].values.reshape(1, -1)).all(axis=1).sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['target_num'] = le.fit_transform(train_df.target)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA","metadata":{}},{"cell_type":"code","source":"for scale in np.sort(train_df['gcd'].unique()):\n    # Compute the PCA\n    pca = PCA(whiten=True, random_state=1)\n    pca.fit(train_i[hist_bins][train_df['gcd'] == scale])\n\n    # Transform the data so that the components can be analyzed\n    Xt_tr = pca.transform(train_i[hist_bins][train_df['gcd'] == scale])\n    Xt_te = pca.transform(test_i[hist_bins][test_df['gcd'] == scale])\n\n    # Plot a scattergram, projected to two PCA components, colored by classification target\n    plt.figure(figsize=(6,6))\n    plt.scatter(Xt_tr[:,0], Xt_tr[:,1], c=train_df.target_num[train_df['gcd'] == scale], s=1)\n    plt.title(f\"{1000000 // scale} decamers ({(train_df['gcd'] == scale).sum()} samples with gcd = {scale})\")\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Observation: We can see that some of the deviation between train and test data is captured by Pseudo labelling","metadata":{}},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"X = dedup_train[hist_bins]\ny = pd.DataFrame(le.fit_transform(dedup_train['target']), columns=['target'])\nsample_weight = dedup_train['sample_weight']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test_df.drop(['gcd'], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\n\nN_SPLITS = 10\nfolds = StratifiedKFold(n_splits=N_SPLITS, shuffle=True)\ny_pred_list, y_proba_list, scores = [], [], []\n\nfor fold, (train_id, valid_id) in enumerate(tqdm(folds.split(X, y), total=N_SPLITS)):\n    print('####### Fold: ', fold)\n    \n    # Splitting\n    X_train, y_train, sample_weight_train = X.iloc[train_id], y.iloc[train_id], sample_weight.iloc[train_id]\n    X_valid, y_valid, sample_weight_valid = X.iloc[valid_id], y.iloc[valid_id], sample_weight.iloc[valid_id]\n    \n    # Model\n    model = ExtraTreesClassifier(\n        n_estimators=1300,\n        n_jobs=-1,\n        verbose=0,\n        random_state=1\n    )\n\n    # Training\n    model.fit(X_train, y_train, sample_weight_train)\n        \n    # Validation\n    valid_pred = model.predict(X_valid)\n    valid_score = accuracy_score(y_valid, valid_pred, sample_weight=sample_weight_valid)\n    print(f'Accuracy score: {valid_score:5f}\\n')\n    scores.append(valid_score)\n    \n    # Prediction for submission\n    y_pred_list.append(model.predict(X_test))\n    y_proba_list.append(model.predict_proba(X_test))\n    \nscore = np.array(scores).mean()\nprint(f'Mean accuracy score: {score:6f}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = mode(y_pred_list).mode[0]\ny_pred = le.inverse_transform(y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_proba = sum(y_proba_list) / len(y_proba_list)\ny_proba += np.array([0, 0, 0.01, 0.03, 0, 0, 0, 0, 0, 0])\ny_pred_tuned = le.inverse_transform(np.argmax(y_proba, axis=1))\npd.Series(y_pred_tuned, index=test_df.index).value_counts().sort_index() / len(test_df) * 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df['target'] = y_pred_tuned\n# test_df['proba'] = np.max(y_proba, axis=1)\n\n# test_pseudo_2 = test_df[test_df['proba']>=0.99\n# test_pseudo_2.to_csv('test_pseudo2.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.unique(test_pseudo['gcd'], return_counts=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# On running the above cell, we find that all the pseudo labelled data is from gcd = 1 or 10 which is not surprising.","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')\nsubmission['target'] = y_pred_tuned\nsubmission.to_csv('submission2.csv', index=False)\nsubmission","metadata":{},"execution_count":null,"outputs":[]}]}