{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabular Playground Series Feb. 2022\n* Introduction of Competition\n* Loading Libaries\n* Exploratory Data Analysis(EDA)\n* Model Training and Inference\n\n# 1.Introduction Of Competition\nWe have a competition on genetic data this month, 10 bacteria will be classified according to the results of genomic analysis in this competition. \nIn this technique, 10-mer snippets of DNA are sampled and analyzed to give the histogram of base count\n## 1.1. 🦠 Bacteria species (classes)\n* [Streptococcus pyogenes](https://en.wikipedia.org/wiki/Streptococcus_pyogenes)\n* [Salmonella enterica](https://ru.wikipedia.org/wiki/Salmonella_enterica)\n* [Escherichia coli](https://en.wikipedia.org/wiki/Enterococcus_hirae)\n* [Campylobacter jejuni](https://en.wikipedia.org/wiki/Campylobacter_jejuni)\n* [Streptococcus pneumoniae](https://en.wikipedia.org/wiki/Streptococcus_pneumoniae)\n* [Staphylococcus aureus](https://en.wikipedia.org/wiki/Staphylococcus_aureus)\n* [Escherichia fergusonii](https://en.wikipedia.org/wiki/Escherichia_fergusonii)\n* [Bacteroides fragilis](https://en.wikipedia.org/wiki/Bacteroides_fragilis)\n* [Klebsiella pneumoniae](https://en.wikipedia.org/wiki/Klebsiella_pneumoniae)\n\nTODO: The next version of my notebook will be investigating case bacteria. \n\n# 2. 📚 Import Libraries & Reduce Memory","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.stats import mode\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport warnings\nimport gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nwarnings.simplefilter('ignore')\nKAGGLE_DIR = r'../input/tabular-playground-series-feb-2022/'\nLOCAL_DIR = r''\nKAGGLE = True\nRS = 69420","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:45:07.800663Z","iopub.execute_input":"2022-02-06T14:45:07.801272Z","iopub.status.idle":"2022-02-06T14:45:10.62712Z","shell.execute_reply.started":"2022-02-06T14:45:07.801153Z","shell.execute_reply":"2022-02-06T14:45:10.626289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1. Reduce the memory Usage","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:45:10.628811Z","iopub.execute_input":"2022-02-06T14:45:10.629023Z","iopub.status.idle":"2022-02-06T14:45:10.644221Z","shell.execute_reply.started":"2022-02-06T14:45:10.628998Z","shell.execute_reply":"2022-02-06T14:45:10.643597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif KAGGLE:\n    print(f\"{'*'*10} Loading Training Data... {'*'*10}\")\n    df = pd.read_csv(KAGGLE_DIR+'train.csv', index_col=0).pipe(reduce_mem_usage)\n    print(f\"{'*'*10} Loading Testing Data... {'*'*10}\")\n    test = pd.read_csv(KAGGLE_DIR+'test.csv', index_col=0).pipe(reduce_mem_usage)\n    sub = pd.read_csv(KAGGLE_DIR+'sample_submission.csv').pipe(reduce_mem_usage)\nelse:\n    print(f\"{'*'*10} Loading Training Data... {'*'*10}\")\n    df = pd.read_csv(LOCAL_DIR+'train.csv', index_col=0).pipe(reduce_mem_usage)\n    print(f\"{'*'*10} Loading Testing Data... {'*'*10}\")\n    test = pd.read_csv(LOCAL_DIR+'test.csv', index_col=0).pipe(reduce_mem_usage)\n    sub = pd.read_csv(LOCAL_DIR+'sample_submission.csv').pipe(reduce_mem_usage)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:45:10.645512Z","iopub.execute_input":"2022-02-06T14:45:10.645975Z","iopub.status.idle":"2022-02-06T14:46:21.775193Z","shell.execute_reply.started":"2022-02-06T14:45:10.645936Z","shell.execute_reply":"2022-02-06T14:46:21.774191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del df \n#gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.777262Z","iopub.execute_input":"2022-02-06T14:46:21.777535Z","iopub.status.idle":"2022-02-06T14:46:21.780973Z","shell.execute_reply.started":"2022-02-06T14:46:21.777504Z","shell.execute_reply":"2022-02-06T14:46:21.78017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 🔍 Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.785756Z","iopub.execute_input":"2022-02-06T14:46:21.786427Z","iopub.status.idle":"2022-02-06T14:46:21.835277Z","shell.execute_reply.started":"2022-02-06T14:46:21.78638Z","shell.execute_reply":"2022-02-06T14:46:21.834685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.836332Z","iopub.execute_input":"2022-02-06T14:46:21.836789Z","iopub.status.idle":"2022-02-06T14:46:21.862286Z","shell.execute_reply.started":"2022-02-06T14:46:21.836736Z","shell.execute_reply":"2022-02-06T14:46:21.861679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train set - dimensions:\\t', df.shape)\nprint('Test set - dimensions:\\t', test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.863591Z","iopub.execute_input":"2022-02-06T14:46:21.864077Z","iopub.status.idle":"2022-02-06T14:46:21.869447Z","shell.execute_reply.started":"2022-02-06T14:46:21.864045Z","shell.execute_reply":"2022-02-06T14:46:21.868345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Missing value of Train set:{df.isnull().sum().sum()} and Missing value of Test set: {test.isnull().sum().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.870856Z","iopub.execute_input":"2022-02-06T14:46:21.871418Z","iopub.status.idle":"2022-02-06T14:46:22.376346Z","shell.execute_reply.started":"2022-02-06T14:46:21.871374Z","shell.execute_reply":"2022-02-06T14:46:22.375447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_dist = df[\"target\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:22.378762Z","iopub.execute_input":"2022-02-06T14:46:22.379014Z","iopub.status.idle":"2022-02-06T14:46:22.385952Z","shell.execute_reply.started":"2022-02-06T14:46:22.378983Z","shell.execute_reply":"2022-02-06T14:46:22.384671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(df,values=target_dist,names=target_dist.index,\n             color_discrete_sequence=px.colors.sequential.RdBu,\n            hole=0.1)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:22.38775Z","iopub.execute_input":"2022-02-06T14:46:22.388261Z","iopub.status.idle":"2022-02-06T14:46:23.398073Z","shell.execute_reply.started":"2022-02-06T14:46:22.388107Z","shell.execute_reply":"2022-02-06T14:46:23.397142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub25 = df.nunique()[df.nunique() < 25][:-1]\nsub25","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:23.399581Z","iopub.execute_input":"2022-02-06T14:46:23.400093Z","iopub.status.idle":"2022-02-06T14:46:25.351539Z","shell.execute_reply.started":"2022-02-06T14:46:23.40006Z","shell.execute_reply":"2022-02-06T14:46:25.350597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_feat = sub25.index.tolist()\nall_feat = df.columns.difference(cat_feat)[:-1] # -1 cuz last index is target we dont need it.\ndf.columns.difference(cat_feat)[-1]","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:25.352874Z","iopub.execute_input":"2022-02-06T14:46:25.353174Z","iopub.status.idle":"2022-02-06T14:46:25.36172Z","shell.execute_reply.started":"2022-02-06T14:46:25.353134Z","shell.execute_reply":"2022-02-06T14:46:25.360684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(df,names = [\"Continous Features\",\"Categorical Features\"],\n             values = [len(cat_feat),len(all_feat)],\n             hole = 0.4,\n            color_discrete_sequence=px.colors.sequential.RdBu)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:25.363048Z","iopub.execute_input":"2022-02-06T14:46:25.363839Z","iopub.status.idle":"2022-02-06T14:46:25.419262Z","shell.execute_reply.started":"2022-02-06T14:46:25.363798Z","shell.execute_reply":"2022-02-06T14:46:25.418388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.Preprocessing & Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfeature = df.columns[df.columns != \"target\"]\nle = LabelEncoder()\nX = df[feature]\ny = pd.DataFrame(le.fit_transform(df[\"target\"]), columns=[\"target\"])\nprint(f\"X shape:{X.shape} & y Shape:{y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:25.420274Z","iopub.execute_input":"2022-02-06T14:46:25.420477Z","iopub.status.idle":"2022-02-06T14:46:25.754113Z","shell.execute_reply.started":"2022-02-06T14:46:25.420451Z","shell.execute_reply":"2022-02-06T14:46:25.753108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.Modeling & Feature İmportance\nWe are using model as ExtraTreesClassifier for these case, so what is ExtraTreesClassifier and what is difference with RandomForest?\n\n![](https://miro.medium.com/max/640/0*4VpGqWJUJnmD2mm0.jpg))\n\nExtraTreesClassifier is an ensemble learning method fundamentally based on decision trees. ExtraTreesClassifier, like RandomForest, randomizes certain decisions and subsets of data to minimize over-learning from the data and overfitting.\nLet’s look at some ensemble methods ordered from high to low variance, ending in ExtraTreesClassifier.\n## 5.1. Trees:\n### 5.1.1. Decision Tree (High Variance)\nA single decision tree is usually overfits the data it is learning from because it learn from only one pathway of decisions. Predictions from a single decision tree usually don’t make accurate predictions on new data.\n### 5.1.2.Random Forest (Medium Variance)\nRandom forest models reduce the risk of overfitting by introducing randomness by:\nbuilding multiple trees (n_estimators)\ndrawing observations with replacement (i.e., a bootstrapped sample)\nsplitting nodes on the best split among a random subset of the features selected at every node\n![](https://1.bp.blogspot.com/-Ax59WK4DE8w/YK6o9bt_9jI/AAAAAAAAEQA/9KbBf9cdL6kOFkJnU39aUn4m8ydThPenwCLcBGAsYHQ/s0/Random%2BForest%2B03.gif)\n### 5.1.3.Extra Trees (Low Variance)\nExtra Trees is like Random Forest, in that it builds multiple trees and splits nodes using random subsets of features, but with two key differences: it does not bootstrap observations (meaning it samples without replacement), and nodes are split on random splits, not best splits. So, in summary, ExtraTrees:\nbuilds multiple trees with bootstrap = False by default, which means it samples without replacement\nnodes are split based on random splits among a random subset of the features selected at every node\nIn Extra Trees, randomness doesn’t come from bootstrapping of data, but rather comes from the random splits of all observations.\nExtraTrees is named for (Extremely Randomized Trees).\n![](https://www.researchgate.net/publication/346995264/figure/fig1/AS:969705405812741@1608207193473/The-structure-of-ExtraTree.png)\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\nimport time\n\nn_splits= 10\nfolds = StratifiedKFold(n_splits=n_splits,shuffle=True)\n\ny_pred = []\nscore = []\nfor fold,(train_id,test_id) in enumerate(folds.split(X,y)):\n    print(f\"{fold}. Fold\")\n    start_time = time.time()\n    #splitting the data per fold\n    X_train,y_train = X.iloc[train_id],y.iloc[train_id]\n    X_valid,y_valid = X.iloc[test_id],y.iloc[test_id]\n    \n    #create a model\n    etc = ExtraTreesClassifier(n_estimators=1000) # grid search or optuna will be coming soon!\n    #Train for per fold\n    etc.fit(X_train,y_train)\n    \n    #evaluation of per fold\n    val_pred = etc.predict(X_valid)\n    valid_score_acc = accuracy_score(y_valid,val_pred)\n    score.append(valid_score_acc)\n    run_time = time.time() - start_time\n    print(f\"fold acc: {valid_score_acc} run time :{run_time} The overall average of the trainings done so far: {np.mean(score)}\")  \n    # Now train our whole data for submission and ensemble it\n    y_pred.append(etc.predict(test))\nprint(f\"Mean acc score:{np.mean(score)}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:25.755861Z","iopub.execute_input":"2022-02-06T14:46:25.756172Z","iopub.status.idle":"2022-02-06T17:02:02.897149Z","shell.execute_reply.started":"2022-02-06T14:46:25.756129Z","shell.execute_reply":"2022-02-06T17:02:02.895964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2. Feature İmportance","metadata":{}},{"cell_type":"code","source":"df_feature_imp = pd.DataFrame({\n    'feature': X.columns, \n    'importance': etc.feature_importances_\n})\n\nfeature_imp_25 = df_feature_imp.sort_values(\n    by='importance', ascending=False\n).iloc[:25].reset_index(drop=True)\n\nfig = go.Figure(\n    go.Bar(\n        x=feature_imp_25.importance,\n        y=feature_imp_25.feature,\n        orientation='h',\n        marker=dict(color=feature_imp_25.importance)\n    )\n)\n\nfig.update_layout(\n    width=1000, height=1000,\n    yaxis=dict(autorange='reversed')\n)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T17:02:02.899537Z","iopub.execute_input":"2022-02-06T17:02:02.899873Z","iopub.status.idle":"2022-02-06T17:02:03.410924Z","shell.execute_reply.started":"2022-02-06T17:02:02.899837Z","shell.execute_reply":"2022-02-06T17:02:03.410107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"y_pred = mode(y_pred).mode[0]\ny_pred = le.inverse_transform(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T17:02:03.412385Z","iopub.execute_input":"2022-02-06T17:02:03.413202Z","iopub.status.idle":"2022-02-06T17:02:06.710429Z","shell.execute_reply.started":"2022-02-06T17:02:03.413157Z","shell.execute_reply":"2022-02-06T17:02:06.709481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\")\nsubmission[\"target\"] = y_pred\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-02-06T17:45:16.163179Z","iopub.execute_input":"2022-02-06T17:45:16.16357Z","iopub.status.idle":"2022-02-06T17:45:16.255909Z","shell.execute_reply.started":"2022-02-06T17:45:16.163462Z","shell.execute_reply":"2022-02-06T17:45:16.253762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T17:02:06.785405Z","iopub.execute_input":"2022-02-06T17:02:06.785659Z","iopub.status.idle":"2022-02-06T17:02:07.048731Z","shell.execute_reply.started":"2022-02-06T17:02:06.785627Z","shell.execute_reply":"2022-02-06T17:02:07.047904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  6.References \n[Trees-namanbhandari.medium](https://medium.com/@namanbhandari/extratreesclassifier-8e7fc0502c7)\n\n[Quantdare](https://quantdare.com/what-is-the-difference-between-extra-trees-and-random-forest/)","metadata":{}},{"cell_type":"markdown","source":"### I hope you get a great time when you looking my notebook, have a good day.\n### Don't forget to mention my shortcomings and give an upvote! ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}