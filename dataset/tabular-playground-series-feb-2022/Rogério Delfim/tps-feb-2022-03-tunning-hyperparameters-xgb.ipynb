{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 div class='alert alert-success'><center> Tunning Hyperparameters XGB\n </center></h1>\n\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/26480/logos/header.png?t=2021-04-09-00-57-05)","metadata":{"id":"xFogj-Cdi34f","papermill":{"duration":0.062831,"end_time":"2022-02-18T03:57:59.782186","exception":false,"start_time":"2022-02-18T03:57:59.719355","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\">  0. IMPORTAÇÕES </div>","metadata":{"id":"sKJFMrjqi34j","papermill":{"duration":0.060611,"end_time":"2022-02-18T03:57:59.904057","exception":false,"start_time":"2022-02-18T03:57:59.843446","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install --q optuna\n!pip install --q GPUtil\n!pip install --q Boruta","metadata":{"ExecuteTime":{"end_time":"2022-02-13T14:36:57.637127Z","start_time":"2022-02-13T14:36:49.058099Z"},"executionInfo":{"elapsed":12874,"status":"ok","timestamp":1645145676268,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"U2CKimxvi34k","outputId":"5fa75f99-0fdc-48f2-ea90-839f9f6df8c3","papermill":{"duration":26.515095,"end_time":"2022-02-18T03:58:26.480329","exception":false,"start_time":"2022-02-18T03:57:59.965234","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:26.432638Z","iopub.execute_input":"2022-02-23T13:04:26.432954Z","iopub.status.idle":"2022-02-23T13:04:52.291451Z","shell.execute_reply.started":"2022-02-23T13:04:26.432868Z","shell.execute_reply":"2022-02-23T13:04:52.290645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/drive')","metadata":{"ExecuteTime":{"end_time":"2022-02-15T20:41:09.622469Z","start_time":"2022-02-15T20:41:09.240463Z"},"executionInfo":{"elapsed":2727,"status":"ok","timestamp":1645145678988,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"Fk0qDNyXlyY4","outputId":"b3bf4126-20cf-43ef-f1ba-1a175887adb6","papermill":{"duration":0.067995,"end_time":"2022-02-18T03:58:26.611947","exception":false,"start_time":"2022-02-18T03:58:26.543952","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:52.293128Z","iopub.execute_input":"2022-02-23T13:04:52.29335Z","iopub.status.idle":"2022-02-23T13:04:52.298615Z","shell.execute_reply.started":"2022-02-23T13:04:52.293322Z","shell.execute_reply":"2022-02-23T13:04:52.297872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0.1. Bibliotecas","metadata":{"id":"ckrEOEuUi34l","papermill":{"duration":0.060234,"end_time":"2022-02-18T03:58:26.732418","exception":false,"start_time":"2022-02-18T03:58:26.672184","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import warnings\nimport os\nimport gc\nimport random\nimport glob\nimport optuna\nimport re\nimport sklearn.exceptions","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:37:32.218706Z","start_time":"2022-02-20T21:37:28.904134Z"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1645145678988,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"icBhRH0Si34m","papermill":{"duration":1.643517,"end_time":"2022-02-18T03:58:28.436349","exception":false,"start_time":"2022-02-18T03:58:26.792832","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:52.300018Z","iopub.execute_input":"2022-02-23T13:04:52.300284Z","iopub.status.idle":"2022-02-23T13:04:53.833562Z","shell.execute_reply.started":"2022-02-23T13:04:52.300251Z","shell.execute_reply":"2022-02-23T13:04:53.832767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas               as pd\nimport numpy                as np\nimport matplotlib.pyplot    as plt \nimport seaborn              as sns\nimport joblib               as jb","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:37:32.282877Z","start_time":"2022-02-20T21:37:32.221719Z"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1645145678989,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"OjwX36f3i34m","papermill":{"duration":0.128457,"end_time":"2022-02-18T03:58:28.627075","exception":false,"start_time":"2022-02-18T03:58:28.498618","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:53.836072Z","iopub.execute_input":"2022-02-23T13:04:53.836324Z","iopub.status.idle":"2022-02-23T13:04:53.899646Z","shell.execute_reply.started":"2022-02-23T13:04:53.836291Z","shell.execute_reply":"2022-02-23T13:04:53.899017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn             as nn","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:08.412987Z","start_time":"2022-02-20T21:37:32.285718Z"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1645145678990,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"xyxT1_-ei34n","papermill":{"duration":1.31662,"end_time":"2022-02-18T03:58:30.004564","exception":false,"start_time":"2022-02-18T03:58:28.687944","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:53.900739Z","iopub.execute_input":"2022-02-23T13:04:53.901036Z","iopub.status.idle":"2022-02-23T13:04:55.084809Z","shell.execute_reply.started":"2022-02-23T13:04:53.900971Z","shell.execute_reply":"2022-02-23T13:04:55.084097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost              as xgb","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:08.50595Z","start_time":"2022-02-20T21:38:08.414955Z"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1645145678990,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"me4iqeW8i34o","papermill":{"duration":0.14308,"end_time":"2022-02-18T03:58:30.209463","exception":false,"start_time":"2022-02-18T03:58:30.066383","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.086154Z","iopub.execute_input":"2022-02-23T13:04:55.086384Z","iopub.status.idle":"2022-02-23T13:04:55.155898Z","shell.execute_reply.started":"2022-02-23T13:04:55.086352Z","shell.execute_reply":"2022-02-23T13:04:55.154603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection       import train_test_split, StratifiedKFold, KFold\nfrom sklearn.preprocessing         import QuantileTransformer, StandardScaler\nfrom sklearn.preprocessing         import RobustScaler, MinMaxScaler, MaxAbsScaler, LabelEncoder\nfrom sklearn                       import metrics\nfrom sklearn.feature_selection     import SelectKBest, SelectPercentile, f_classif","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:08.537958Z","start_time":"2022-02-20T21:38:08.507955Z"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1645145678991,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"RM2RI3_ti34p","papermill":{"duration":0.076855,"end_time":"2022-02-18T03:58:30.34785","exception":false,"start_time":"2022-02-18T03:58:30.270995","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.157528Z","iopub.execute_input":"2022-02-23T13:04:55.15814Z","iopub.status.idle":"2022-02-23T13:04:55.17836Z","shell.execute_reply.started":"2022-02-23T13:04:55.158094Z","shell.execute_reply":"2022-02-23T13:04:55.177637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from optuna.samplers               import TPESampler\nfrom optuna.visualization          import plot_edf\nfrom optuna.visualization          import plot_optimization_history\nfrom optuna.visualization          import plot_parallel_coordinate\nfrom optuna.visualization          import plot_param_importances\nfrom optuna.visualization          import plot_slice\nfrom optuna.visualization          import plot_intermediate_values\nfrom optuna.visualization          import plot_contour\nfrom optuna.pruners                import MedianPruner\nfrom optuna.pruners                import BasePruner\nfrom optuna.trial._state           import TrialState","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:08.553951Z","start_time":"2022-02-20T21:38:08.539957Z"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1645145678991,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"IMnB1bcOi34p","papermill":{"duration":0.069198,"end_time":"2022-02-18T03:58:30.478124","exception":false,"start_time":"2022-02-18T03:58:30.408926","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.179715Z","iopub.execute_input":"2022-02-23T13:04:55.180375Z","iopub.status.idle":"2022-02-23T13:04:55.192666Z","shell.execute_reply.started":"2022-02-23T13:04:55.180333Z","shell.execute_reply":"2022-02-23T13:04:55.191407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from GPUtil                        import showUtilization as gpu_usage\nfrom numba                         import cuda\nfrom sklearn.ensemble              import IsolationForest\nfrom psutil                        import virtual_memory\nfrom datetime                      import datetime\nfrom psutil                        import virtual_memory\nfrom sklearn.utils.class_weight    import compute_sample_weight\nfrom boruta                        import BorutaPy\nfrom multiprocessing               import cpu_count","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.410985Z","start_time":"2022-02-20T21:38:08.555958Z"},"executionInfo":{"elapsed":1318,"status":"ok","timestamp":1645145680299,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"rxIrWu38i34q","outputId":"5c90197d-4977-4549-de18-8dac945cdd66","papermill":{"duration":0.587345,"end_time":"2022-02-18T03:58:31.126788","exception":false,"start_time":"2022-02-18T03:58:30.539443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.194206Z","iopub.execute_input":"2022-02-23T13:04:55.194572Z","iopub.status.idle":"2022-02-23T13:04:55.760253Z","shell.execute_reply.started":"2022-02-23T13:04:55.194535Z","shell.execute_reply":"2022-02-23T13:04:55.759541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0.2. Funções","metadata":{"id":"LwyizAfdi34r","papermill":{"duration":0.061772,"end_time":"2022-02-18T03:58:31.253664","exception":false,"start_time":"2022-02-18T03:58:31.191892","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def jupyter_setting():\n    \n    %matplotlib inline\n      \n    #os.environ[\"WANDB_SILENT\"] = \"true\" \n    #plt.style.use('bmh') \n    #plt.rcParams['figure.figsize'] = [20,15]\n    #plt.rcParams['font.size']      = 13\n     \n    pd.options.display.max_columns = None\n    #pd.set_option('display.expand_frame_repr', False)\n\n    warnings.filterwarnings(action='ignore')\n    warnings.simplefilter('ignore')\n    warnings.filterwarnings('ignore')\n    warnings.filterwarnings('ignore', category=DeprecationWarning)\n    warnings.filterwarnings('ignore', category=FutureWarning)\n    warnings.filterwarnings('ignore', category=RuntimeWarning)\n    warnings.filterwarnings('ignore', category=UserWarning)\n    warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n    warnings.filterwarnings(\"ignore\", category= sklearn.exceptions.UndefinedMetricWarning)\n\n    pd.set_option('display.max_rows', 200)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.max_colwidth', None)\n\n    icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n    #sns.palplot(sns.color_palette(icecream))\n    \n    colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]\n    \n    # Colors\n    dark_red   = \"#b20710\"\n    black      = \"#221f1f\"\n    green      = \"#009473\"\n    myred      = '#CD5C5C'\n    myblue     = '#6495ED'\n    mygreen    = '#90EE90'    \n    color_cols = [myred, myblue,mygreen]\n    \n    return icecream, colors, color_cols\n\nicecream, colors, color_cols = jupyter_setting()","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.426954Z","start_time":"2022-02-20T21:38:09.413952Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680300,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"hide_input":true,"id":"1vHZjDzgi34r","papermill":{"duration":0.079795,"end_time":"2022-02-18T03:58:31.395618","exception":false,"start_time":"2022-02-18T03:58:31.315823","status":"completed"},"run_control":{"marked":false},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.765651Z","iopub.execute_input":"2022-02-23T13:04:55.765851Z","iopub.status.idle":"2022-02-23T13:04:55.781732Z","shell.execute_reply.started":"2022-02-23T13:04:55.765826Z","shell.execute_reply":"2022-02-23T13:04:55.78104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) / start_mem\n            )\n        )\n    return df","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.44296Z","start_time":"2022-02-20T21:38:09.428952Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680300,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"m-u-wKS5i34s","papermill":{"duration":0.075703,"end_time":"2022-02-18T03:58:31.532703","exception":false,"start_time":"2022-02-18T03:58:31.457","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.783203Z","iopub.execute_input":"2022-02-23T13:04:55.783635Z","iopub.status.idle":"2022-02-23T13:04:55.801143Z","shell.execute_reply.started":"2022-02-23T13:04:55.783597Z","shell.execute_reply":"2022-02-23T13:04:55.800441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n    plt.rcParams['font.size'] = 12\n    plt.title('Precision Recall vs threshold')\n    plt.xlabel('Threshold')\n    plt.legend(loc=\"lower left\")\n    \n    plt.grid(True)","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.458953Z","start_time":"2022-02-20T21:38:09.444955Z"},"code_folding":[0],"executionInfo":{"elapsed":16,"status":"ok","timestamp":1645145680300,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"oT4xvNQxi34t","papermill":{"duration":0.073516,"end_time":"2022-02-18T03:58:31.66705","exception":false,"start_time":"2022-02-18T03:58:31.593534","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.802567Z","iopub.execute_input":"2022-02-23T13:04:55.802999Z","iopub.status.idle":"2022-02-23T13:04:55.812559Z","shell.execute_reply.started":"2022-02-23T13:04:55.802951Z","shell.execute_reply":"2022-02-23T13:04:55.811699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_precision_vs_recall(precisions, recalls):\n    plt.plot(recalls[:-1], precisions[:-1], \"b-\", label=\"Precision\")\n    \n    plt.rcParams['font.size'] = 12\n    plt.title('Precision vs recall')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    # plt.legend(loc=\"lower left\")\n    \n    plt.grid(True)","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.474954Z","start_time":"2022-02-20T21:38:09.460971Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680301,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"OzJVgUuTi34u","papermill":{"duration":0.068545,"end_time":"2022-02-18T03:58:31.797089","exception":false,"start_time":"2022-02-18T03:58:31.728544","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.814243Z","iopub.execute_input":"2022-02-23T13:04:55.814634Z","iopub.status.idle":"2022-02-23T13:04:55.822793Z","shell.execute_reply.started":"2022-02-23T13:04:55.814592Z","shell.execute_reply":"2022-02-23T13:04:55.822021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr, label=None):\n    fig, ax = plt.subplots()\n    ax.plot(fpr, tpr, \"r-\", label=label)\n    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.rcParams['font.size'] = 12\n    plt.title('XGBR ROC curve for TPS 09')\n    plt.xlabel('False Positive Rate (1 - Specificity)')\n    plt.ylabel('True Positive Rate (Sensitivity)')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.490951Z","start_time":"2022-02-20T21:38:09.476954Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680301,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"51KsDDGLi34u","papermill":{"duration":0.06895,"end_time":"2022-02-18T03:58:31.926635","exception":false,"start_time":"2022-02-18T03:58:31.857685","status":"completed"},"run_control":{"marked":false},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.824426Z","iopub.execute_input":"2022-02-23T13:04:55.824771Z","iopub.status.idle":"2022-02-23T13:04:55.833228Z","shell.execute_reply.started":"2022-02-23T13:04:55.824709Z","shell.execute_reply":"2022-02-23T13:04:55.832541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def graf_feature_corr(df, annot_=False, threshold=.8, print_var=False):\n    \n    df = df.corr(method ='pearson').round(5)\n\n    # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n    mask = np.zeros_like(df)\n    mask[np.triu_indices_from(mask)] = True\n\n    # Making a plot\n    plt.figure(figsize=(20,12))\n    ax = sns.heatmap(df, annot=annot_, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\n\n    ax.set_title(\"Mapa de calor de correlação das variável\", fontsize=17)\n\n    plt.setp(ax.get_xticklabels(), \n             rotation      = 90, \n             ha            = \"right\",\n             rotation_mode = \"anchor\", \n             weight        = \"normal\")\n\n    plt.setp(ax.get_yticklabels(), \n             weight        = \"normal\",\n             rotation_mode = \"anchor\", \n             rotation      = 0, \n             ha            = \"right\");\n    \n    if print_var: \n        print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold))\n        df_corr = df[abs(df)>threshold][df!=1.0].unstack().dropna().reset_index()\n        df_corr.columns =  ['var_1', 'var_2', 'corr']\n        display(df_corr)\n","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.506988Z","start_time":"2022-02-20T21:38:09.492959Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680301,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"3gf0D8QLi34u","papermill":{"duration":0.070047,"end_time":"2022-02-18T03:58:32.056995","exception":false,"start_time":"2022-02-18T03:58:31.986948","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.834661Z","iopub.execute_input":"2022-02-23T13:04:55.835612Z","iopub.status.idle":"2022-02-23T13:04:55.847112Z","shell.execute_reply.started":"2022-02-23T13:04:55.835451Z","shell.execute_reply":"2022-02-23T13:04:55.846388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlation(dataset, threshold):\n\n    col_corr    = set()  # Conjunto de todos os nomes de colunas correlacionadas\n    corr_matrix = dataset.corr()\n    \n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) >= threshold: # estamos interessados no valor coeficiente absoluto\n                colname = corr_matrix.columns[i]        # obtendo o nome da coluna\n                col_corr.add(colname)\n    \n    return col_corr","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.522958Z","start_time":"2022-02-20T21:38:09.508953Z"},"code_folding":[0],"executionInfo":{"elapsed":16,"status":"ok","timestamp":1645145680301,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"YYXsmuJwi34u","papermill":{"duration":0.07063,"end_time":"2022-02-18T03:58:32.191628","exception":false,"start_time":"2022-02-18T03:58:32.120998","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.848303Z","iopub.execute_input":"2022-02-23T13:04:55.849189Z","iopub.status.idle":"2022-02-23T13:04:55.85745Z","shell.execute_reply.started":"2022-02-23T13:04:55.849136Z","shell.execute_reply":"2022-02-23T13:04:55.856689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def free_gpu_cache():\n    \n    # https://www.kaggle.com/getting-started/140636\n    #print(\"Initial GPU Usage\")\n    #gpu_usage()                             \n\n    #cuda.select_device(0)\n    #cuda.close()\n    #cuda.select_device(0)   \n    \n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.538952Z","start_time":"2022-02-20T21:38:09.524954Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680302,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"GuS0Lh52i34v","papermill":{"duration":0.066949,"end_time":"2022-02-18T03:58:32.318918","exception":false,"start_time":"2022-02-18T03:58:32.251969","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.858711Z","iopub.execute_input":"2022-02-23T13:04:55.859608Z","iopub.status.idle":"2022-02-23T13:04:55.86554Z","shell.execute_reply.started":"2022-02-23T13:04:55.859572Z","shell.execute_reply":"2022-02-23T13:04:55.864266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def diff(t_a, t_b):\n    from dateutil.relativedelta import relativedelta\n    t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n    return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.554954Z","start_time":"2022-02-20T21:38:09.540954Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680302,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"25zqU_0-dvOi","papermill":{"duration":0.068318,"end_time":"2022-02-18T03:58:32.447875","exception":false,"start_time":"2022-02-18T03:58:32.379557","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:04:55.866626Z","iopub.execute_input":"2022-02-23T13:04:55.866807Z","iopub.status.idle":"2022-02-23T13:04:55.874358Z","shell.execute_reply.started":"2022-02-23T13:04:55.866786Z","shell.execute_reply":"2022-02-23T13:04:55.873284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def describe(df):\n    var = df.columns\n\n    # Medidas de tendência central, média e mediana \n    ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n    ct2 = pd.DataFrame(df[var].apply(np.median)).T\n\n    # Dispensão - str, min , max range skew, kurtosis\n    d1 = pd.DataFrame(df[var].apply(np.std)).T\n    d2 = pd.DataFrame(df[var].apply(min)).T\n    d3 = pd.DataFrame(df[var].apply(max)).T\n    d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n    d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n    d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n    d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) / np.std(x) ))).T\n\n    # concatenete \n    m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n    m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n    \n    return m","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.570958Z","start_time":"2022-02-20T21:38:09.556953Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680302,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"apj7RUQqdxBz","papermill":{"duration":0.080776,"end_time":"2022-02-18T03:58:32.589498","exception":false,"start_time":"2022-02-18T03:58:32.508722","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:05:57.57075Z","iopub.execute_input":"2022-02-23T13:05:57.571539Z","iopub.status.idle":"2022-02-23T13:05:57.583555Z","shell.execute_reply.started":"2022-02-23T13:05:57.571499Z","shell.execute_reply":"2022-02-23T13:05:57.581062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr, label=None):\n    fig, ax = plt.subplots()\n    ax.plot(fpr, tpr, \"r-\", label=label)\n    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.rcParams['font.size'] = 12\n    plt.title('ROC curve for TPS 09')\n    plt.xlabel('False Positive Rate (1 - Specificity)')\n    plt.ylabel('True Positive Rate (Sensitivity)')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.586966Z","start_time":"2022-02-20T21:38:09.572956Z"},"code_folding":[0],"executionInfo":{"elapsed":16,"status":"ok","timestamp":1645145680302,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"itZLuff_d27q","papermill":{"duration":0.077438,"end_time":"2022-02-18T03:58:32.734219","exception":false,"start_time":"2022-02-18T03:58:32.656781","status":"completed"},"run_control":{"marked":false},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:05:58.082231Z","iopub.execute_input":"2022-02-23T13:05:58.082452Z","iopub.status.idle":"2022-02-23T13:05:58.088598Z","shell.execute_reply.started":"2022-02-23T13:05:58.082426Z","shell.execute_reply":"2022-02-23T13:05:58.087472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_plot(matrix, labels = None, title = None):\n        \n    labels = labels if labels else ['Negative (0)', 'Positive (1)']    \n    \n    fig, ax = plt.subplots(nrows=1, ncols=1)\n    \n    sns.heatmap(data        = matrix, \n                cmap        = 'Blues', \n                annot       = True, \n                fmt         = 'd',\n                xticklabels = labels, \n                yticklabels = labels, \n                ax          = ax);\n    \n    ax.set_xlabel('\\n PREVISTO', fontsize=15)\n    ax.set_ylabel('REAL \\n', fontsize=15)\n    ax.set_title(title)\n    \n    plt.close();\n    \n    return fig;","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.602956Z","start_time":"2022-02-20T21:38:09.589955Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680303,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"TRIUWUu0d68a","papermill":{"duration":0.081141,"end_time":"2022-02-18T03:58:32.879252","exception":false,"start_time":"2022-02-18T03:58:32.798111","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:05:58.479312Z","iopub.execute_input":"2022-02-23T13:05:58.480039Z","iopub.status.idle":"2022-02-23T13:05:58.487106Z","shell.execute_reply.started":"2022-02-23T13:05:58.479994Z","shell.execute_reply":"2022-02-23T13:05:58.486293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def graf_outlier(df, feature):\n    col = [(0,4), (5,9)]\n\n    df_plot = ((df[feature] - df[feature].min())/\n               (df[feature].max() - df[feature].min()))\n\n    fig, ax = plt.subplots(len(col), 1, figsize=(15,7))\n\n    for i, (x) in enumerate(col): \n        sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]); ","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.618958Z","start_time":"2022-02-20T21:38:09.606957Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680303,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"q6u5INXLd_Vy","papermill":{"duration":0.073793,"end_time":"2022-02-18T03:58:33.023609","exception":false,"start_time":"2022-02-18T03:58:32.949816","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:05:58.857814Z","iopub.execute_input":"2022-02-23T13:05:58.858496Z","iopub.status.idle":"2022-02-23T13:05:58.865663Z","shell.execute_reply.started":"2022-02-23T13:05:58.858439Z","shell.execute_reply":"2022-02-23T13:05:58.864583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def graf_eval():\n\n    results     = model.evals_result()\n    ntree_limit = model.best_ntree_limit\n\n    plt.figure(figsize=(20,7))\n\n    for i, error in  enumerate(['mlogloss', 'merror']):#\n        \n        plt.subplot(1,2,i+1)\n        plt.plot(results[\"validation_0\"][error], label=\"Treinamento\")\n        plt.plot(results[\"validation_1\"][error], label=\"Validação\")\n\n        plt.axvline(ntree_limit, \n                    color=\"gray\", \n                    label=\"N. de árvore ideal {}\".format(ntree_limit))\n                    \n        \n        title_name ='\\n' + error.upper() + ' PLOT \\n'\n        plt.title(title_name)\n        plt.xlabel(\"Número de árvores\")\n        plt.ylabel(error)\n        plt.legend();","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.634956Z","start_time":"2022-02-20T21:38:09.620953Z"},"code_folding":[0],"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680303,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"lNMWoOTNeCni","papermill":{"duration":0.074269,"end_time":"2022-02-18T03:58:33.162804","exception":false,"start_time":"2022-02-18T03:58:33.088535","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:05:59.168541Z","iopub.execute_input":"2022-02-23T13:05:59.169043Z","iopub.status.idle":"2022-02-23T13:05:59.176324Z","shell.execute_reply.started":"2022-02-23T13:05:59.169001Z","shell.execute_reply":"2022-02-23T13:05:59.175555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0.3. GPU","metadata":{"id":"puAI82JpDOJO","papermill":{"duration":0.059938,"end_time":"2022-02-18T03:58:33.28494","exception":false,"start_time":"2022-02-18T03:58:33.225002","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### 0.3.1. Informações","metadata":{"id":"iISld6GaDyRM","papermill":{"duration":0.060529,"end_time":"2022-02-18T03:58:33.405688","exception":false,"start_time":"2022-02-18T03:58:33.345159","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\n\nif gpu_info.find('failed') >= 0:\n  print('Not connected to a GPU')\nelse:\n  print(gpu_info)","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:09.902951Z","start_time":"2022-02-20T21:38:09.679953Z"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1645145680303,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"Je1LG7eeDL1s","outputId":"5f68635a-c0ed-4f19-979a-83456e39b44d","papermill":{"duration":0.12607,"end_time":"2022-02-18T03:58:33.592385","exception":false,"start_time":"2022-02-18T03:58:33.466315","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:00.803879Z","iopub.execute_input":"2022-02-23T13:06:00.804711Z","iopub.status.idle":"2022-02-23T13:06:00.864733Z","shell.execute_reply.started":"2022-02-23T13:06:00.804661Z","shell.execute_reply":"2022-02-23T13:06:00.863807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0.3.2. Memória","metadata":{"id":"RWJ4r84ZEAIM","papermill":{"duration":0.06595,"end_time":"2022-02-18T03:58:33.720046","exception":false,"start_time":"2022-02-18T03:58:33.654096","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ram_gb = virtual_memory().total / 1e9\n\nprint('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n\nif ram_gb < 20:\n  print('Not using a high-RAM runtime')\nelse:\n  print('You are using a high-RAM runtime!')","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:11.374956Z","start_time":"2022-02-20T21:38:11.362959Z"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1645133006185,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"OVohZ_xSD33t","outputId":"040c8b16-54f0-41c5-bd8a-52cb5aea9e58","papermill":{"duration":0.071981,"end_time":"2022-02-18T03:58:33.865429","exception":false,"start_time":"2022-02-18T03:58:33.793448","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:01.709699Z","iopub.execute_input":"2022-02-23T13:06:01.710481Z","iopub.status.idle":"2022-02-23T13:06:01.716163Z","shell.execute_reply.started":"2022-02-23T13:06:01.71044Z","shell.execute_reply":"2022-02-23T13:06:01.71536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0.4. Dados","metadata":{"id":"8_PfcxeGi34v","papermill":{"duration":0.061017,"end_time":"2022-02-18T03:58:33.98797","exception":false,"start_time":"2022-02-18T03:58:33.926953","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### 4.1. Estrutura de diretório","metadata":{"id":"lTgQwT5NeSu6","papermill":{"duration":0.060746,"end_time":"2022-02-18T03:58:34.110711","exception":false,"start_time":"2022-02-18T03:58:34.049965","status":"completed"},"tags":[]}},{"cell_type":"code","source":"paths = ['img', 'Data', 'Data/pkl', 'Data/submission', 'model', \n         'model/preds', 'model/optuna','model/preds/test', 'model/mdl/',\n         'model/preds/test/n1', 'model/preds/test/n2', 'model/preds/test/n3', \n         'model/preds/train', 'model/preds/train/n1', 'model/preds/train/n2', \n         'model/preds/train/n3', 'model/preds/param',  \n         'Data/submission/tunning/']\n\nfor path in paths:\n    try:\n        os.mkdir(path)       \n    except:\n        pass   ","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:38:14.393842Z","start_time":"2022-02-20T21:38:14.378841Z"},"id":"nvZIRsuIePhl","papermill":{"duration":0.07172,"end_time":"2022-02-18T03:58:34.245611","exception":false,"start_time":"2022-02-18T03:58:34.173891","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:02.887604Z","iopub.execute_input":"2022-02-23T13:06:02.888467Z","iopub.status.idle":"2022-02-23T13:06:02.893716Z","shell.execute_reply.started":"2022-02-23T13:06:02.888426Z","shell.execute_reply":"2022-02-23T13:06:02.893027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#path      = '/content/drive/MyDrive/kaggle/Tabular Playground Series/2022/02 - Fevereiro/'\n#path      = '../input/tabular-playground-series-feb-2022/'\npath      = ''\npath_data = ''  \npath_pkl  = '../input/tps-feb-01-22/'\npath_sub  = '../input/tabular-playground-series-feb-2022/'\ntarget    = 'target'","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:40:35.353159Z","start_time":"2022-02-20T21:40:35.347162Z"},"id":"UaT5Rgjli34v","papermill":{"duration":0.067957,"end_time":"2022-02-18T03:58:34.375506","exception":false,"start_time":"2022-02-18T03:58:34.307549","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:03.550261Z","iopub.execute_input":"2022-02-23T13:06:03.551133Z","iopub.status.idle":"2022-02-23T13:06:03.555754Z","shell.execute_reply.started":"2022-02-23T13:06:03.551086Z","shell.execute_reply":"2022-02-23T13:06:03.555084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2. Carregar Datasets","metadata":{"ExecuteTime":{"end_time":"2022-02-13T14:40:57.479332Z","start_time":"2022-02-13T14:40:57.473293Z"},"id":"3lCczGg3cCgV","papermill":{"duration":0.061762,"end_time":"2022-02-18T03:58:34.501058","exception":false,"start_time":"2022-02-18T03:58:34.439296","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df3_train     = jb.load(path + path_data + path_pkl + 'df2_nb_02_train.pkl.z')\ndf3_test      = jb.load(path + path_data + path_pkl + 'df2_nb_02_test.pkl.z')\ndf_submission = pd.read_csv(path + path_sub + 'sample_submission.csv')\n\ndf3_train.shape, df3_test.shape","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:41:13.614908Z","start_time":"2022-02-20T21:41:11.853566Z"},"executionInfo":{"elapsed":5127,"status":"ok","timestamp":1645133017005,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"Ar5Fty2Ei34v","outputId":"b01a91f0-f9b6-4502-831b-6abe6c10335b","papermill":{"duration":3.456604,"end_time":"2022-02-18T03:58:38.018591","exception":false,"start_time":"2022-02-18T03:58:34.561987","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:04.633008Z","iopub.execute_input":"2022-02-23T13:06:04.633714Z","iopub.status.idle":"2022-02-23T13:06:07.695535Z","shell.execute_reply.started":"2022-02-23T13:06:04.633676Z","shell.execute_reply":"2022-02-23T13:06:07.694843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3_train.head()","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:41:27.170592Z","start_time":"2022-02-20T21:41:26.924479Z"},"executionInfo":{"elapsed":724,"status":"ok","timestamp":1645133017725,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"-qfjHtY0i34w","outputId":"68c97d0c-e852-484b-e19d-47e003f2f3d4","papermill":{"duration":0.267393,"end_time":"2022-02-18T03:58:38.348227","exception":false,"start_time":"2022-02-18T03:58:38.080834","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:07.697521Z","iopub.execute_input":"2022-02-23T13:06:07.698084Z","iopub.status.idle":"2022-02-23T13:06:07.944414Z","shell.execute_reply.started":"2022-02-23T13:06:07.698045Z","shell.execute_reply":"2022-02-23T13:06:07.943676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3_train = reduce_memory_usage(df3_train)\ndf3_test  = reduce_memory_usage(df3_test)","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:41:28.874932Z","start_time":"2022-02-20T21:41:27.816149Z"},"executionInfo":{"elapsed":1926,"status":"ok","timestamp":1645133019645,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"_JUntp99QiWX","outputId":"36f4d652-f431-43c4-eeef-bf1d3462823a","papermill":{"duration":2.275806,"end_time":"2022-02-18T03:58:40.689532","exception":false,"start_time":"2022-02-18T03:58:38.413726","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:07.945452Z","iopub.execute_input":"2022-02-23T13:06:07.945721Z","iopub.status.idle":"2022-02-23T13:06:10.22958Z","shell.execute_reply.started":"2022-02-23T13:06:07.945685Z","shell.execute_reply":"2022-02-23T13:06:10.228711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\"> 1.  Modelagem </div>","metadata":{"ExecuteTime":{"end_time":"2022-02-13T14:42:43.769709Z","start_time":"2022-02-13T14:42:43.75774Z"},"id":"lXM1616ZcCgX","papermill":{"duration":0.107583,"end_time":"2022-02-18T03:58:40.93197","exception":false,"start_time":"2022-02-18T03:58:40.824387","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 1.1. Funções","metadata":{"id":"BTfHy5aLcCgY","papermill":{"duration":0.1027,"end_time":"2022-02-18T03:58:41.138015","exception":false,"start_time":"2022-02-18T03:58:41.035315","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_, y_pred_test_, score_, seed_, level_='1', target_='target'):    \n    \n    level = 'n' + level_ + '/'\n\n    if score_>.6:    \n        path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_) + '.pkl.z'\n        path_name_train = path_ + 'model/preds/train/' + level + model_name_.format(score_, seed_)  + '.pkl.z'\n        path_name_test  = path_ + 'model/preds/test/'  + level + model_name_.format(score_, seed_)  + '.pkl.z'   \n        path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)  + '.pkl.z'   \n        \n        jb.dump(y_pred_train_prob_, path_name_train)\n        jb.dump(y_pred_test_prob_, path_name_test)\n        jb.dump(model_, path_name_model)","metadata":{"ExecuteTime":{"end_time":"2022-02-20T21:41:29.73927Z","start_time":"2022-02-20T21:41:29.724274Z"},"code_folding":[0],"id":"YMyY91OecCgZ","papermill":{"duration":0.124943,"end_time":"2022-02-18T03:58:41.375728","exception":false,"start_time":"2022-02-18T03:58:41.250785","status":"completed"},"run_control":{"marked":false},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:10.231408Z","iopub.execute_input":"2022-02-23T13:06:10.231732Z","iopub.status.idle":"2022-02-23T13:06:10.239055Z","shell.execute_reply.started":"2022-02-23T13:06:10.231693Z","shell.execute_reply":"2022-02-23T13:06:10.238317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_train_cv_fit(model_, X_, y_, X_test_, target_, model_name_, sc_=MinMaxScaler(), \n                       sc_second_=None, n_splits_=5, seed_=12359, save_sub_=True, \n                       path_='', save_predict_=False, level_='1'):\n    \n    taco              = 52 \n    y_preds_test      = []\n    y_preds_val_prob  = [] \n    y_preds_test_prob = []\n    score             = []\n    mdl               = []\n    lb                = LabelEncoder()\n    y_                = pd.DataFrame(lb.fit_transform(y_), columns=[target_])\n    col_prob          = y_[target_].sort_values().unique()\n    df_preds_prob     = pd.DataFrame()\n    df_feature_imp    = pd.DataFrame()\n    time_start        = datetime.now()    \n    n_estimators      = model_.get_params()['n_estimators']\n    dub_scaler        = '=> Double Scaler' if sc_second_!=None else ''\n    \n    print('='*taco)\n    print('Scaler: {} - n_estimators: {} {}'.format(sc, n_estimators, dub_scaler))\n    print('='*taco)\n\n    folds = StratifiedKFold(n_splits=n_splits_, shuffle=True, random_state=seed_)\n\n    for fold, (trn_idx, val_idx) in enumerate(folds.split(X_, y_, groups=y)): \n        \n        time_fold_start = datetime.now()\n        \n        # ----------------------------------------------------\n        # Separar dados para treino \n        # ----------------------------------------------------\n        X_trn, X_val, sample_weight_train = X_.iloc[trn_idx], X_.iloc[val_idx], X_.iloc[trn_idx]['sample_weight']\n        y_trn, y_val, sample_weight_valid = y_.iloc[trn_idx], y_.iloc[val_idx], X_.iloc[val_idx]['sample_weight'] \n                \n        # ----------------------------------------------------\n        # Processamento\n        # ----------------------------------------------------        \n        X_trn.drop('sample_weight', axis=1, inplace=True)\n        X_val.drop('sample_weight', axis=1, inplace=True)\n        \n        X_trn = pd.DataFrame(sc_.fit_transform(X_trn), columns=X_trn.columns)\n        X_val = pd.DataFrame(sc_.transform(X_val), columns=X_val.columns)\n        X_tst = pd.DataFrame(sc_.transform(X_test_), columns=X_test_.columns)\n\n        if sc_second_ is not None: \n            X_trn = pd.DataFrame(sc_second_.fit_transform(X_trn), columns=X_trn.columns)\n            X_val = pd.DataFrame(sc_second_.transform(X_val), columns=X_val.columns)\n            X_tst = pd.DataFrame(sc_second_.transform(X_tst), columns=X_tst.columns)\n                        \n        # ---------------------------------------------------- \n        # Treinar o modelo \n        # ----------------------------------------------------     \n        model_.fit(X_trn, \n                   y_trn,\n                   sample_weight_train,\n                   eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n                   early_stopping_rounds = int(n_estimators*.1),\n                   verbose               = False)\n\n        # ---------------------------------------------------- \n        # Predição \n        # ----------------------------------------------------     \n        #y_pred_val       = model_.predict(X_val, ntree_limit=model_.best_ntree_limit)    \n        y_pred_val_prob  = model_.predict_proba(X_val, ntree_limit=model_.best_ntree_limit) \n        y_pred_test_prob = model_.predict_proba(X_tst, ntree_limit=model_.best_ntree_limit)\n        \n        y_pred_val_prob += np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0])         \n        y_pred_val       = np.argmax(y_pred_val_prob, axis=1)\n        \n        y_preds_test.append(model_.predict(X_tst))\n        y_preds_test_prob.append(y_pred_test_prob)\n       \n        df_prob_temp    = pd.DataFrame(y_pred_val_prob, columns=col_prob)\n        y_pred_pbro_max = df_prob_temp.max(axis=1)\n\n        df_prob_temp['fold']    = fold+1\n        df_prob_temp['id']      = val_idx        \n        df_prob_temp['y_val']   = y_val.values        \n        df_prob_temp['y_pred']  = y_pred_val\n        df_prob_temp['y_proba'] = np.max(y_pred_val_prob, axis=1)\n                \n        df_preds_prob = pd.concat([df_preds_prob, df_prob_temp], axis=0)\n        \n        # ---------------------------------------------------- \n        # Score \n        # ---------------------------------------------------- \n        acc = metrics.accuracy_score(y_val, y_pred_val, sample_weight=sample_weight_valid)\n        score.append(acc)     \n\n        # ---------------------------------------------------- \n        # Print resultado  \n        # ---------------------------------------------------- \n        time_fold_end = diff(time_fold_start, datetime.now())        \n        msg = '[Fold {}] ACC: {:2.5f} -  {}'\n        print(msg.format(fold+1, acc, time_fold_end))\n\n        # ---------------------------------------------------- \n        # Feature Importance\n        # ----------------------------------------------------             \n        feat_imp = pd.DataFrame(index   = X_trn.columns,\n                                data    = model_.feature_importances_,                            \n                                columns = ['fold_{}'.format(fold+1)])\n\n        feat_imp['acc_'+str(fold+1)] = acc\n        df_feature_imp = pd.concat([df_feature_imp, feat_imp], axis=1)\n\n        # ---------------------------------------------------- \n        # Salvar o modelo \n        # ---------------------------------------------------- \n        dic_model = {'scaler': sc, 'scaler_second': sc_second_,'fold': fold+1,'model': model_}\n        mdl.append(dic_model)\n\n        time_end = diff(time_start, datetime.now())   \n\n    acc_mean = np.mean(score) \n    acc_std  = np.std(score)\n\n    df_preds_prob.sort_values(\"id\", axis=0, ascending=True, inplace=True)\n\n    # ------------------------------\n    # Pós-processamento\n    # referencia: https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\n    # -------------------------------        \n    y_proba  = sum(y_preds_test_prob) / len(y_preds_test_prob)\n    y_proba += np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0])  \n    \n    y_pred_tuned      = lb.inverse_transform(np.argmax(y_proba, axis=1))\n    y_pred_tuned_prob = np.max(y_proba, axis=1)\n\n    if save_predict_:                 \n        save_data_model(model_             = mdl, \n                        model_name_        = model_name_ +'_'+str(sc_second_).lower()[:4], \n                        path_              = path_, \n                        y_pred_train_prob_ = df_preds_prob['y_proba'], \n                        y_pred_test_prob_  = y_pred_tuned_prob, \n                        y_pred_test_       = y_pred_tuned,\n                        score_             = acc_mean, \n                        seed_              = seed_, \n                        level_             = level_, \n                        target_            = target_\n                        ) \n\n    print('-'*taco)\n    print('[Mean Fold] ACC: {:2.5f} std: {:2.5f} - {}'.format(acc_mean, acc_std, time_end))    \n    print('='*taco)\n    print()\n\n    if save_sub_:         \n        df_submission[target_] = y_pred_tuned        \n        name_file_sub          = model_name_ +'_'+str(sc_second_).lower()[:4]+'.csv'\n        df_submission.to_csv(path_+'Data/submission/'+name_file_sub.format(acc_mean), index=False)\n        \n    del X_trn, X_val, y_trn, y_val, feat_imp\n\n    return mdl, df_feature_imp, df_feature_imp , df_preds_prob","metadata":{"ExecuteTime":{"end_time":"2022-02-20T23:59:20.384328Z","start_time":"2022-02-20T23:59:20.359332Z"},"code_folding":[0],"id":"W-AfEFTYcCga","papermill":{"duration":0.153287,"end_time":"2022-02-18T03:58:41.874592","exception":false,"start_time":"2022-02-18T03:58:41.721305","status":"completed"},"run_control":{"marked":false},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:10.719862Z","iopub.execute_input":"2022-02-23T13:06:10.720377Z","iopub.status.idle":"2022-02-23T13:06:10.753838Z","shell.execute_reply.started":"2022-02-23T13:06:10.720342Z","shell.execute_reply":"2022-02-23T13:06:10.753044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_graf(mdl_, df_fe_imp_, eval_metric_ ):\n\n    for erro in eval_metric_:\n        plt.figure(figsize=(20,15))\n        for m in range(len(mdl_)):\n            row = int(len(mdl_[m])/3 + 1)\n            for fold in range(len(mdl_[m])): \n                results     = mdl_[m][fold]['model'].evals_result() # merror\n                ntree_limit = mdl_[m][fold]['model'].best_ntree_limit\n                plt.subplot(row,3,fold+1)\n                plt.plot(results[\"validation_0\"][erro], label=\"Treinamento\")\n                plt.plot(results[\"validation_1\"][erro], label=\"Validação\")\n\n                plt.axvline(ntree_limit, \n                            color=\"gray\", \n                            label=\"N. de árvore ideal {}\".format(ntree_limit))\n\n                plt.xlabel(\"Número de árvores\")\n                plt.ylabel(erro)\n                plt.legend();           \n\n            plt.suptitle('Performance XGB - {}'.format(erro), y=1.05, fontsize=24);\n            plt.tight_layout(h_pad=3.0); \n\n    for i in range(len(df_fe_imp_)):\n        plt.figure(figsize=(20,15))\n        row = int(np.round(df_fe_imp_[i].filter(regex=r'fold').shape[1] / 3 +1))\n        for fold, col in enumerate(df_fe_imp_[i].filter(regex=r'fold').columns):            \n            col_acc = 'acc_' + str(fold+1)\n            df_fi = df_fe_imp_[i].sort_values(by=col, ascending=False).reset_index().iloc[:25]\n            df_fi = df_fi[['index', col, col_acc]]\n            df_fi.columns = ['Feature', 'score', col_acc]\n            plt.subplot(row,3, fold+1)\n            sns.barplot(x='score', y='Feature', data=df_fi)    \n            plt.title('Fold {} - score: {:2.5f}'.format(fold+1, df_fi[col_acc].mean()), \n                      fontdict={'fontsize':18})    \n\n        plt.suptitle('Feature Importance XGB - {}'.format(scaler_list[i]), y=1.05, fontsize=24);\n        plt.tight_layout(h_pad=3.0); ","metadata":{"ExecuteTime":{"end_time":"2022-02-20T23:59:20.825437Z","start_time":"2022-02-20T23:59:20.812434Z"},"code_folding":[0],"execution":{"iopub.status.busy":"2022-02-23T13:06:11.133123Z","iopub.execute_input":"2022-02-23T13:06:11.133556Z","iopub.status.idle":"2022-02-23T13:06:11.150931Z","shell.execute_reply.started":"2022-02-23T13:06:11.133526Z","shell.execute_reply":"2022-02-23T13:06:11.150172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2. Modelo ","metadata":{"id":"3CiKMmrgcCgc","papermill":{"duration":0.065734,"end_time":"2022-02-18T03:58:42.006011","exception":false,"start_time":"2022-02-18T03:58:41.940277","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X          = df3_train.drop([target], axis=1)\ny          = df3_train[target]\nX_test     = df3_test\n\nX.shape, y.shape, X_test.shape","metadata":{"ExecuteTime":{"end_time":"2022-02-20T23:03:13.334536Z","start_time":"2022-02-20T23:03:13.250421Z"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1645133019991,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"GjKxi26LcCgc","outputId":"e7d089e2-269d-41f0-c95d-66b740d7ba51","papermill":{"duration":0.301276,"end_time":"2022-02-18T03:58:42.372598","exception":false,"start_time":"2022-02-18T03:58:42.071322","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:12.200657Z","iopub.execute_input":"2022-02-23T13:06:12.20099Z","iopub.status.idle":"2022-02-23T13:06:12.429637Z","shell.execute_reply.started":"2022-02-23T13:06:12.20094Z","shell.execute_reply":"2022-02-23T13:06:12.428563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path             = ''\ncols_original_tr = X.filter(regex='A[0-9]').columns.to_list()\ncols_original_ts = cols_original_tr.copy()\ncols_original_tr.append('sample_weight')","metadata":{"ExecuteTime":{"end_time":"2022-02-20T23:03:14.431262Z","start_time":"2022-02-20T23:03:14.366089Z"},"papermill":{"duration":0.073302,"end_time":"2022-02-18T03:58:42.514291","exception":false,"start_time":"2022-02-18T03:58:42.440989","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T13:06:12.750216Z","iopub.execute_input":"2022-02-23T13:06:12.75043Z","iopub.status.idle":"2022-02-23T13:06:12.875453Z","shell.execute_reply.started":"2022-02-23T13:06:12.750404Z","shell.execute_reply":"2022-02-23T13:06:12.874653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\"> \n    \nVamos fazer um modelo com as variáveis originais, para termos uma noção do efeito das novas variáveis, neste primeiro momento defini os parametros manualmente.\n       \n</div>","metadata":{}},{"cell_type":"code","source":"%%time \n\nseed_          = 12359\nmdl            = []\ndf_trn_mdl     = []\ndf_fe_imp      = []\nscaler_list    = [None]\nname_model_clf = 'xgb_'\nname_model     = name_model_clf + 'tunning_score_01_{:2.5f}'\neval_metric    = ['merror', 'mlogloss']\n\nparams = {\"objective\"          : 'multi:softprob', \n          'eval_metric'        : eval_metric,\n          'max_depth'          : 6, \n          'learning_rate'      : .1, \n          'subsample'          : 0.75, \n          'n_estimators'       : 1000,           \n          'reg_alpha'          : 1, \n          'reg_lambda'         : 75, \n          'min_child_weight'   : 7, \n          'colsample_bytree'   : 0.85,\n          'sampling_method'    : 'gradient_based',\n          'booster'            : 'gbtree',\n          'use_label_encoder'  : 'False', \n          'random_state'       : seed_}\n\nif torch.cuda.is_available():           \n    params.update({'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor'})\n    \nfor sc in scaler_list:    \n    model, df_trn, df_feature_imp, df_preds_prob = \\\n    model_train_cv_fit(model_        = xgb.XGBClassifier(**params),\n                       model_name_   = name_model,\n                       X_            = X[cols_original_tr],\n                       y_            = y,\n                       X_test_       = X_test[cols_original_ts],                       \n                       target_       = target,\n                       sc_           = RobustScaler(), \n                       sc_second_    = sc,\n                       n_splits_     = 5,\n                       seed_         = seed_,\n                       save_sub_     = True,\n                       path_         = path, \n                       save_predict_ = True)\n\n    mdl.append(model)\n    df_trn_mdl.append(df_trn)\n    df_fe_imp.append(df_feature_imp)\n\ndel model, df_trn, df_feature_imp\n\nprint_graf(mdl, df_fe_imp, eval_metric)","metadata":{"ExecuteTime":{"end_time":"2022-02-20T23:07:47.534595Z","start_time":"2022-02-20T23:03:16.2755Z"},"execution":{"iopub.status.busy":"2022-02-23T13:06:13.961782Z","iopub.execute_input":"2022-02-23T13:06:13.962428Z","iopub.status.idle":"2022-02-23T13:06:19.222474Z","shell.execute_reply.started":"2022-02-23T13:06:13.962391Z","shell.execute_reply":"2022-02-23T13:06:19.2218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\"> \nObtivemos na submissão o score de 0.93243, como podemos observar o nosso modelo tem uma performance boa, pois estamos apenas 1.83% abaixo, sendo assim, temos um baixo underfitting. \n    \n<br> \n    \nAgora vamos executar o mesmo modelo com todas as variáveis, isso é, com as novas variáveis criadas. \n       \n</div>","metadata":{}},{"cell_type":"code","source":"%%time \n\nseed_          = 12359\nmdl            = []\ndf_trn_mdl     = []\ndf_fe_imp      = []\nscaler_list    = [None]\nname_model_clf = 'xgb_'\nname_model     = name_model_clf + 'tunning_score_02_{:2.5f}'\n\neval_metric = ['merror', 'mlogloss']\n\nparams = {\"objective\"          : 'multi:softprob', \n          'eval_metric'        : eval_metric,\n          'max_depth'          : 6, \n          'learning_rate'      : .1, \n          'subsample'          : 0.75, \n          'n_estimators'       : 1000,           \n          'reg_alpha'          : 1, \n          'reg_lambda'         : 75, \n          'min_child_weight'   : 7, \n          'colsample_bytree'   : 0.85,\n          'sampling_method'    : 'gradient_based',\n          'booster'            : 'gbtree',  \n          'use_label_encoder'  : 'False',\n          'random_state'       : seed_}\n\nif torch.cuda.is_available():           \n    params.update({'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor'})\n    \nfor sc in scaler_list:    \n    model, df_trn, df_feature_imp, df_preds_prob = \\\n    model_train_cv_fit(model_        = xgb.XGBClassifier(**params),\n                       model_name_   = name_model,\n                       X_            = X,\n                       y_            = y,\n                       X_test_       = X_test,                      \n                       target_       = target,\n                       sc_           = RobustScaler(), \n                       sc_second_    = sc,\n                       n_splits_     = 5,\n                       seed_         = seed_,\n                       save_sub_     = True,\n                       path_         = path, \n                       save_predict_ = True)\n\n    mdl.append(model)\n    df_trn_mdl.append(df_trn)\n    df_fe_imp.append(df_feature_imp)\n\ndel model, df_trn, df_feature_imp\n   \nprint_graf(mdl, df_fe_imp, eval_metric)","metadata":{"ExecuteTime":{"end_time":"2022-02-21T00:09:50.093981Z","start_time":"2022-02-21T00:03:15.223036Z"},"code_folding":[53],"executionInfo":{"elapsed":39246,"status":"error","timestamp":1645133061299,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"ZR3VduvAcCgd","outputId":"6e737ebf-155f-4e32-9254-f67c58d8f1b0","papermill":{"duration":619.258635,"end_time":"2022-02-18T04:09:01.839519","exception":false,"start_time":"2022-02-18T03:58:42.580884","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\"> \n\nNa submissão obtivemos o score de 0.93032 que pior que o score anterior com apenas as variáveis originais, provavelmente isso acontece porque estamos adionando ruido com as novas variávies, o ponto importante é que podemos observar na importância das variáveis que temos variáveis que foram criadas entre as 25 mais importantes, sendo assim, precisamos fazer uma filtragem das melhores variáveis, mais à frente vamos utilizar o Boruta para fazer uma filtagem das melhores variáveis.\n\n       \n</div>","metadata":{}},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\"> 2.  TUNNING </div>","metadata":{"id":"gQ6DBwBLi34z","papermill":{"duration":0.139742,"end_time":"2022-02-18T04:09:03.133617","exception":false,"start_time":"2022-02-18T04:09:02.993875","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 2.1. Split Train/Test","metadata":{"id":"9cJfauA3i34z","papermill":{"duration":0.123981,"end_time":"2022-02-18T04:09:03.381493","exception":false,"start_time":"2022-02-18T04:09:03.257512","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X      = df3_train.drop([target], axis=1)    \ny      = pd.DataFrame(df3_train[target], columns=[target]) \nX_test = df3_test\nidx_sample = X.sample(5000).index \n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      test_size    = 0.2,\n                                                      shuffle      = True, \n                                                      stratify     = y,\n                                                      random_state = 12359)\n\nX_train.shape, y_train.shape, X_valid.shape, y_valid.shape ","metadata":{"ExecuteTime":{"end_time":"2022-02-21T00:46:57.815594Z","start_time":"2022-02-21T00:46:56.9916Z"},"executionInfo":{"elapsed":1066,"status":"ok","timestamp":1645133076007,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"DvwbgoMAi340","outputId":"a9f3eece-c8f7-4182-eae5-6b98e582100a","papermill":{"duration":1.034451,"end_time":"2022-02-18T04:09:04.539516","exception":false,"start_time":"2022-02-18T04:09:03.505065","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T01:21:20.546216Z","iopub.execute_input":"2022-02-23T01:21:20.546903Z","iopub.status.idle":"2022-02-23T01:21:21.694909Z","shell.execute_reply.started":"2022-02-23T01:21:20.546867Z","shell.execute_reply":"2022-02-23T01:21:21.694226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2. Classe Tunning ","metadata":{"id":"8l1vmUmRi340","papermill":{"duration":0.075,"end_time":"2022-02-18T04:09:04.689659","exception":false,"start_time":"2022-02-18T04:09:04.614659","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class LastPlacePruner(BasePruner):\n    # https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/006_user_defined_pruner.html#sphx-glr-tutorial-20-recipes-006-user-defined-pruner-py    \n    def __init__(self, warmup_steps, warmup_trials):\n        self._warmup_steps = warmup_steps\n        self._warmup_trials = warmup_trials\n\n    def prune(self, study: \"optuna.study.Study\", trial: \"optuna.trial.FrozenTrial\") -> bool:\n        # Obtenha a pontuação mais recente relatada neste teste\n        step = trial.last_step\n\n        if step:  # trial.last_step == None when no scores have been reported yet\n            this_score = trial.intermediate_values[step]\n\n            # Get scores from other trials in the study reported at the same step\n            completed_trials = study.get_trials(deepcopy=False, states=(TrialState.COMPLETE,))\n            other_scores = [\n                t.intermediate_values[step]\n                for t in completed_trials\n                if step in t.intermediate_values\n            ]\n            other_scores = sorted(other_scores)\n\n            # Prune if this trial at this step has a lower value than all completed trials\n            # at the same step. Note that steps will begin numbering at 0 in the objective\n            # function definition below.\n            if step >= self._warmup_steps and len(other_scores) > self._warmup_trials:\n                if this_score < other_scores[0]:\n                    #print(f\"prune() True: Trial {trial.number}, Step {step}, Score {this_score}\")\n                    return True\n\n        return False","metadata":{"ExecuteTime":{"end_time":"2022-02-21T00:46:58.695731Z","start_time":"2022-02-21T00:46:58.679702Z"},"code_folding":[0],"id":"Yhn5ylJScCgh","papermill":{"duration":0.084857,"end_time":"2022-02-18T04:09:04.849798","exception":false,"start_time":"2022-02-18T04:09:04.764941","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T01:21:27.199999Z","iopub.execute_input":"2022-02-23T01:21:27.200801Z","iopub.status.idle":"2022-02-23T01:21:27.209406Z","shell.execute_reply.started":"2022-02-23T01:21:27.200753Z","shell.execute_reply":"2022-02-23T01:21:27.20871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from operator import le\nclass TunningModels(nn.Module):\n\n    from sklearn.preprocessing  import StandardScaler\n    from sklearn.linear_model   import RidgeClassifier\n    \n    def __init__(self, name_model_, X_trn_, y_trn_, X_ts_, feature_=None, \n                 seed_=12359, scaler_=StandardScaler(), feature_bin_=None, \n                 target_='target', path_='', level_='1', sc_second_= None, \n                 n_splits_=5):\n        \n        super(TunningModels,self).__init__() \n\n        self.name_clf    = name_model\n        self.X_trn       = X_trn_\n        self.y_trn       = y_trn_\n        self.X_ts        = X_ts_         \n        self.feature     = feature_\n        self.seed        = seed_\n        self.scaler      = scaler_\n        self.feature_bin = feature_bin_ \n        self.target      = target_\n        self.path        = path_\n        self.level       = level_\n        self.sc_second   = sc_second_\n        self.n_splits    = n_splits_\n\n    def recover_prediction_first_level():\n        \n        preds_train1 = glob.glob(\"model/train/*.pkl.z\")\n        preds_test   = glob.glob(\"model/test/*.pkl.z\")\n        preds_val1   = glob.glob(\"model/valid/*.pkl.z\")\n\n        df_train1     = []\n        scores_traint = dict()\n\n        for p_name in preds_train1:    \n            p    = jb.load(p_name)\n            p_df = pd.DataFrame(p, columns=[p_name.replace('model/train\\\\', '')])    \n            df_train1.append(p_df)    \n            scores_traint[p_name] = f1_score(y_train1, (p_df>.5))\n\n        df_val1     = [] \n        scores_val1 = dict()\n        for p_name in preds_val1:    \n            p    = jb.load(p_name)\n            p_df = pd.DataFrame(p, columns=[p_name.replace('model/valid\\\\', '')])    \n            df_val1.append(p_df)    \n            scores_val1[p_name] = f1_score(y_val1, (p_df>.5))\n\n        df_test     = [] \n        scores_test = dict()\n        for p_name in preds_test:    \n            p         = jb.load(p_name)\n            p_df_test = pd.DataFrame(p, columns=[p_name.replace('model/test\\\\', '')])    \n            df_test.append(p_df_test)\n\n        df_train1 = pd.concat(df_train1, axis=1)\n        df_val1   = pd.concat(df_val1, axis=1)\n        df_test   = pd.concat(df_test, axis=1)\n\n        return df_train1, df_val1, df_test.shape\n        \n    def delete_files(namefile):\n\n        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna', \n                'model/preds/train', 'model/preds/test', 'model/preds/test/n1', \n                'model/preds/test/n2', 'model/preds/test/n3', 'model/preds/train/n1', \n                'model/preds/train/n2', 'model/preds/train/n3','model/preds/param', \n                'Data/submission/tunning', 'Data/submission', 'model/mdl'\n                \n               ]\n\n        for path_ in path:\n            for raiz, diretorios, arquivos in os.walk(path_):\n                for arquivo in arquivos:\n                    if arquivo.startswith(namefile):\n                        os.remove(os.path.join(raiz, arquivo))\n \n    def logging_callback(study, frozen_trail):\n        prev_best = study.user_attrs.get('prev_best', None)\n        if prev_best != study.best_value:\n            study.set_user_attr('prev_best', study.best_value)\n            print(f\"Trail {frozen_trail.number} finished with best value {frozen_trail.value}\")\n\n    def df_return_preds_tunning(model_name=None, level=1, target_='target', train_shape_row=0, test_shape_row=0): \n\n        if level==1: \n            level_ = 'n1'\n        else: \n            if level==2:\n                level_ = 'n2'\n            else: \n                level_ = 'n3'\n\n        paths = ['model/preds/test/'+ level_, 'model/preds/train/' + level_ ]    \n\n        if model_name==None: \n            model_name=''\n\n        for i, path in enumerate(paths): \n\n            name_file_pkl     = glob.glob(path + '/'+ model_name + '*.pkl.z')\n            dic_preds_mdl_pkl = dict()\n\n            for p_name in name_file_pkl:    \n                y_model_pkl_name_col  = p_name.replace(path + '/', '').replace('.pkl.z','') \n                y_model_pkl           = jb.load(p_name)   \n\n                if i==0:\n                    if len(y_model_pkl)==test_shape_row:\n                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n\n                if i==1:\n                    if len(y_model_pkl)==train_shape_row:                        \n                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n\n                gc.collect()\n\n            if i==0:         \n                X_test_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n            else:\n                X_train_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n\n            gc.collect()\n\n        X_train_pred_nivel_1[target_] = y\n\n        return X_train_pred_nivel_1, X_test_pred_nivel_1\n\n    \n    def feature_select(mdl, feature=[], best_score=0):\n    \n        best_feature = ''\n\n        for col in df_train1.columns:\n\n            if col not in feature:\n                Xtr  = df_train1[feature+[col]].copy()\n                Xval = df_val1[feature+[col]].copy()                \n\n                mdl.fit(Xtr, y_train1)\n\n                p = mdl.predict(Xval)\n                c = f1_score(y_val1, p)\n\n                if c > best_score:\n                    best_score = c\n                    best_feature = col \n\n        return best_score, best_feature\n\n    def permutation_test(mdl, feature_selected):\n\n        dist = []\n\n        for seed in range(100):\n\n            Xtr  = df_train1[feature_selected].copy()\n            Xval = df_val1[feature_selected].copy()\n\n            np.random.seed(seed)\n\n            Xtr['random']  = np.random.permutation(Xtr.iloc[:, -1].values)\n            Xval['random'] = np.random.permutation(Xval.iloc[:, -1].values)\n\n            mdl.fit(Xtr, y_train1)\n\n            p = mdl.predict(Xval)\n            c = f1_score(y_val1, p)\n\n            dist.append(c)\n\n        dist = np.array(dist)\n\n        return dist.max()\n\n    def feature_selected_model(model = RidgeClassifier(alpha=1.) ):\n   \n        score_feature, best_feature =  TunningModels.feature_select(model)\n        print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n\n        feature_selected = []\n        feature_selected.append(best_feature)\n\n        loop = True\n\n        while loop:\n\n            best_score = TunningModels.permutation_test(model, feature_selected) \n            best_score = best_score + 1e-4\n\n            score_feature, best_feature = TunningModels.feature_select(model, feature=feature_selected, best_score=best_score)\n            \n\n            if score_feature <= best_score:  \n                print('Fim')\n                loop= False\n            else: \n                feature_selected.append(best_feature)\n                print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n\n        return feature_selected\n    \n    def model_of_diversity_feature_group(model_, name_model, X_, y_, X_ts_, sc_, target_, feature_imp_num=5, \n                                         seed_=12359, path_=''):\n\n        TunningModels.delete_files(name_model)\n\n        cols_tr = X_.columns.to_list() \n        cols_ts = cols_tr.copy()\n        cols_ts.remove('sample_weight')\n\n        model = model_\n        model = model.fit(X_[cols_ts], y_)\n\n        df               = pd.DataFrame()\n        df[\"feature\"]    = cols_ts\n        df[\"importance\"] = model.feature_importances_\n\n        df.sort_values(\"importance\", axis=0, ascending=False, inplace=True)\n\n        feature_import = df[:feature_imp_num]['feature'].to_list()\n\n        for feature_imp in  feature_import:\n\n            score_                =  0.09\n            feature_best          = []\n            feature               = X_ts_.columns            \n            feature               = [s for s in feature if s not in feature_import]\n            feature_number        = len(feature)\n            feature_select_number = np.round(np.sqrt(len(feature)))\n            feature_number_sample = int(np.round((feature_number/feature_select_number)))\n            feature_sample        = []\n\n            print('='*60)\n            print(' Divercidade de Grupos de Features => ({})'.format(feature_imp))\n            print('='*60)\n\n\n            for i in  range(0,5):\n\n                feature            = [s for s in feature if s not in feature_sample]\n                feature_sample     = pd.Series(feature).sample(feature_number_sample).to_list() \n                name_model_xgb_div = name_model + 'group_fe_' + str(i)   \n\n                feature_sample.append(feature_imp)\n                feature_sample_ts = feature_sample.copy()\n\n                feature_sample.append('sample_weight')\n\n                model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n                TunningModels.train_model_cv(model_         = model_, \n                                             X_             = X_[feature_sample], \n                                             y_             = y_, \n                                             X_test_        = X_ts_[feature_sample_ts], \n                                             target_        = target_, \n                                             model_name_    = name_model_xgb_div, \n                                             sc_            = sc_, \n                                             sc_second_     = None, \n                                             n_splits_      = 3, \n                                             seed_          = seed_,\n                                             path_          = path_, \n                                             save_predict_  = True, \n                                             level_         = '1', \n                                             print_result_  = False, \n                                             feature_       = None, \n                                             trial_         = None)\n\n                if score >.59:\n                    create = '*'\n                else: \n                    create = ' '\n\n                if score > score_:\n                    # score_ = np.abs(score)\n                    feature_best.append(feature)\n                    print('Score: {:2.5f} =>{} Gr.Feature: {} {}'.format(score, create, i,''))\n\n                gc.collect()\n\n            print('')\n\n        print('')\n        print('FIM')\n        print('')\n\n\n    def model_of_diversity_feature_one_(model, name_model, seed_=12359):\n\n        score_       =  0.09\n        feature_best = []\n\n        print('')\n        print('Feature apenas uma')\n        print('-'*20)\n\n        TunningModels.delete_files(name_model)\n\n        for feature in X_train.columns:\n\n            name_model_xgb_div = name_model + feature \n\n            score = TunningModels.cross_valid(model       = model, \n                                              model_name_ = name_model_xgb_div, \n                                              X_          = X, \n                                              y_          = y, \n                                              X_test_     = X_test_sc_qt, \n                                              type_model  = 2, \n                                              feature     = feature,\n                                              seed        = seed_, \n                                              tunning     = 1, \n                                              print_result= False, \n                                              n_splits    = 2\n                                              )\n            if score >.59:\n                create = '*'\n            else: \n                create = ' '\n\n            if score > score_:\n                score_ = np.abs(score)\n                feature_best.append(feature)\n                print('F1-score: {:2.5f} => {} feature: {}'.format(score, create, feature ))        \n\n        print('')\n        print('Feature dupla')\n        print('-'*20)\n\n        for feature in feature_best:\n\n            for feature_ in feature_best:\n                if feature != feature_:            \n                    name_model_xgb_div = name_model + feature + '_' + feature_     \n\n                    score = TunningModels.cross_valid(model       = model, \n                                                      model_name_ = name_model_xgb_div, \n                                                      X_          = X, \n                                                      y_          = y, \n                                                      X_test_     = X_test_sc_qt, \n                                                      type_model  = 2, \n                                                      feature     = [feature, feature_],\n                                                      seed        = seed_, \n                                                      tunning     = 1, \n                                                      print_result= False, \n                                                      n_splits    = 2\n                                                      )\n\n                    if score >.59:\n                        create = '*'\n                    else: \n                        create = ' '\n\n                    print('F1-score: {:.4f} => {} feature: {} | {}'.format(score*100, create,  feature, feature_ )) \n\n        print('')\n        print('FIM')\n        print('')\n    \n\n\n        from dateutil.relativedelta import relativedelta\n        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n        \n    def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_,\n                        y_pred_test_, score_, seed_, level_='1', target_='target'):\n        \n        level_ = 'n'+ level_ + '/'\n\n        if score_>.6:          \n\n            path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_)\n            path_name_train = path_ + 'model/preds/train/' + level_ + model_name_.format(score_, seed_)\n            path_name_test  = path_ + 'model/preds/test/'  + level_ + model_name_.format(score_, seed_)    \n            path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)    \n\n            jb.dump(y_pred_train_prob_, path_name_train)\n            jb.dump(y_pred_test_prob_, path_name_test)\n            jb.dump(model_, path_name_model)\n            #jb.dump(pd.DataFrame([model_[0][0]['model'].get_params()]), path_name_param)   \n\n            if score_>.7:                \n                # Gerar o arquivo de submissão \n                df_submission[target_] = y_pred_test_\n                name_file_sub =  path_ + 'Data/submission/tunning/' + model_name_.format(score_, seed_) + '.csv'\n                df_submission.to_csv(name_file_sub, index = False)\n                \n    def diff(t_a, t_b):\n        from dateutil.relativedelta import relativedelta\n        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n        \n    def feature_scaler(df_, scaler_=None, feature_bin_=None):\n    \n        if scaler_!=None: \n            \n            #if feature_bin_!=None:\n            #    disc = KBinsDiscretizer(n_bins=50, encode='ordinal', strategy='uniform')\n            #    df_[feature_bin_] = disc.fit_transform(df_[feature_bin_])\n\n            df_ = pd.DataFrame(scaler_.fit_transform(df_), columns=df_.columns)\n    \n        return df_\n\n    def cross_valid(model_, model_name_, X_train_, y_train_, X_test_, fold_=5, target_='target', \n            path_='', level_='1', save_predict_=True, print_result_=True, seed_=12359, \n            feature_=None, feature_bin=None, scaler_=StandardScaler(), threshold=.5, print_report_=False \n            ):\n\n        if feature_!=None: \n            X_train_ = X_train_[feature_]\n            X_test_  = X_test_[feature_]\n\n        #--------------------------------------------------------  \n        # Escorpo de variáveis\n        #--------------------------------------------------------\n\n        time_pred_start    = datetime.now()\n        preds_valid_f      = {}\n        preds_test         = []\n        total_auc          = []\n        f_scores           = []\n        auc_mean           = []\n        f1_mean            = []\n        lloss_mean         = []\n        preds_test         = 0  \n        pred_test_prob     = 0\n        df_score_history   = pd.DataFrame()\n        df_train_pred_fold = pd.DataFrame()\n        df_pred_fold       = pd.DataFrame()\n        random             = str(np.random.rand(1)[0]).replace('.','')\n        model_name_        = model_name_ + '_score_{:2.5f}_{}_' + random + '.pkl.z'\n        clf_name           = model_.__class__.__name__\n        pri_result         = 92\n        learning_rate      = model_.learning_rate         \n        le                 = LabelEncoder()\n        y_train_           = pd.DataFrame(le.fit_transform(y_train_), columns=[target_])\n                                                   \n        #--------------------------------------------------------  \n        # Início do process de varilidação\n        #--------------------------------------------------------\n        have_observation=''\n\n        if print_result_:\n            num_parallel_tree = 1 #model_.get_params()['num_parallel_tree']\n            learning_rate     = model_.learning_rate\n            n_estimators      = model_.n_estimators * num_parallel_tree  \n            max_depth         = model_.max_depth \n            msg               = 'Training model: {} - seed {} - n_estimators: {} - learning_rate: {} {:2.5f}'\n\n            print('='*pri_result)            \n            print(msg.format(clf_name, seed_, n_estimators, max_depth, learning_rate))\n            print('='*pri_result)\n\n        kf = StratifiedKFold(n_splits=fold_, random_state=42, shuffle=True)\n\n        for fold,(idx_train, idx_val) in enumerate(kf.split(X_train_, y_train_, groups=y_train_)):\n\n            time_fold_start = datetime.now()\n\n            #--------------------------------------------------------  \n            # Seleção dos dados\n            #--------------------------------------------------------\n            X_trn, X_val = X_train_.iloc[idx_train], X_train_.iloc[idx_val]\n            y_trn, y_val = y_train_.iloc[idx_train], y_train_.iloc[idx_val]\n            index_valid  = idx_train\n\n             \n        \n            #--------------------------------------------------------  \n            # Processamento\n            #--------------------------------------------------------        \n            X_trn = TunningModels.feature_scaler(X_trn, scaler_, feature_bin) \n            X_val = TunningModels.feature_scaler(X_val, scaler_, feature_bin) \n\n            #--------------------------------------------------------  \n            # Modelo\n            #--------------------------------------------------------\n            model = model_.fit(X_trn, y_trn,\n                               eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n                               early_stopping_rounds = int(n_estimators*.1),\n                               verbose               = False)\n\n            #--------------------------------------------------------  \n            # oof\n            #--------------------------------------------------------\n            preds_valid_proba = model.predict_proba(X_val, ntree_limit=model_.best_ntree_limit)\n            y_pred_valid      = le.inverse_transform(np.argmax(preds_valid_proba, axis=1))\n            \n            #--------------------------------------------------------  \n            # Obtenha os valores médios de cada fold para a previsão\n            #--------------------------------------------------------  \n            y_pred_test_prob = model.predict_proba(X_test_, ntree_limit=model_.best_ntree_limit)\n            pred_test_prob  += np.max(y_pred_test_prob, axis=1) / fold_\n            preds_test      += le.inverse_transform(np.argmax(y_pred_test_prob, axis=1)) / fold_\n\n            #--------------------------------------------------------  \n            # Métricas \n            #-------------------------------------------------------- \n            y_val = le.inverse_transform(y_val)\n            acc   = metrics.accuracy_score(y_val, y_pred_valid)\n            f1    = metrics.f1_score(y_val, y_pred_valid, average='weighted')\n            prec  = metrics.precision_score(y_val, y_pred_valid, average='macro')\n\n            #--------------------------------------------------------  \n            # Concatenar validação e predição\n            #--------------------------------------------------------        \n            df_val_pred_fold = pd.DataFrame({'fold'     : fold+1,\n                                             'index'    : idx_val, \n                                             'acc'      : acc, \n                                             'f1'       : f1,\n                                             'prec'     : prec,                                              \n                                             'target'   : y_val, \n                                             'y_pred'   : y_pred_valid, \n                                             'pred_val' : np.max(preds_valid_proba, axis=1)\n                                             })\n\n            df_train_pred_fold = pd.concat([df_train_pred_fold, df_val_pred_fold], axis=0)\n\n            col_name        = le.inverse_transform(list(model.classes_))\n            df_prob_temp    = pd.DataFrame(preds_valid_proba, columns=col_name)\n            y_pred_pbro_max = df_prob_temp.max(axis=1)\n\n            \n            df_prob_temp['y_val']     = y_val\n            df_prob_temp['y_pred']    = y_pred_valid \n            df_prob_temp['y_proba']   = np.max(preds_valid_proba, axis=1)            \n            df_prob_temp['acc']       = acc   \n            df_prob_temp['f1']        = f1 \n            df_prob_temp['precision'] = prec              \n            df_prob_temp['fold']      = fold+1\n            df_prob_temp['index']     = idx_val   \n            \n            df_pred_fold = pd.concat([df_pred_fold, df_prob_temp], axis=0)\n            \n            del df_prob_temp\n            \n            #df_prob_temp['scaler']  = str(string_scaler)\n            \n            #preds_valid_proba = np.max(preds_valid_proba, axis=1)\n            \n            \n            auc_mean.append(acc)   \n            f1_mean.append(f1)    \n            lloss_mean.append(prec) \n\n            #--------------------------------------------------------  \n            # Print resultado Fold\n            #--------------------------------------------------------\n            if print_result_:\n                msg = 'Fold: {} - ACC: {:2.5f} - F1-score: {:2.5f} - Precision: {:2.5f} - {}'\n                time_fold_start_end = TunningModels.diff(time_fold_start, datetime.now())\n                print(msg.format(fold+1, acc, f1, prec, time_fold_start_end))\n\n            free_gpu_cache() \n        \n        \n\n        del X_trn, y_trn, X_val, y_val \n\n        df_train_pred_fold.sort_values(\"index\", axis=0, ascending=True, inplace=True)\n\n        #--------------------------------------------------------  \n        # Salvar predição em disco\n        #--------------------------------------------------------\n        X_train_prob      = df_train_pred_fold['pred_val'].to_list()\n        score             = np.mean(auc_mean)\n        y_pred_test       = np.int32(preds_test)\n\n        if save_predict_:\n            TunningModels.save_data_model(model_             = model_, \n                                          model_name_        = model_name_, \n                                          path_              = path_, \n                                          y_pred_train_prob_ = X_train_prob, \n                                          y_pred_test_prob_  = pred_test_prob, \n                                          y_pred_test_       = y_pred_test,\n                                          score_             = score, \n                                          seed_              = seed_, \n                                          level_             = level_, \n                                          target_            = target_\n                                          )  \n\n        #--------------------------------------------------------  \n        # Print média dos Folds\n        #--------------------------------------------------------\n        time_pred_end = TunningModels.diff(time_pred_start, datetime.now())\n\n        if print_result_:\n            msg = '[Mean Fold]  ACC: {:.5f}(Std:{:.5f}) - F1: {:.5f} - Precision: {:.5f}  {}'        \n            print('-'*pri_result)            \n            print(msg.format(np.mean(auc_mean),np.std(auc_mean) , np.mean(f1_mean), np.mean(lloss_mean), time_pred_end))\n            print('='*pri_result)\n            print()\n            \n            if print_report_: \n                y_pred = df_train_pred_fold['y_pred']\n                y_vl   = df_train_pred_fold['target']\n                print(metrics.classification_report(y_vl, y_pred))\n\n        free_gpu_cache() \n\n        return model, score, y_pred_test, df_pred_fold        \n    \n    def train_model_cv(model_, X_, y_, X_test_, target_, model_name_, sc_=MinMaxScaler(), sc_second_=None, \n                       n_splits_=5, seed_=12359, path_='', save_predict_=True, level_='1', \n                       print_result_=True, feature_=None, trial_=None):\n            \n        if feature_!=None: \n            X_      = X_[feature_]\n            X_test_ = X_test_[feature_]\n            \n        taco              = 52 \n        y_preds_test      = []\n        y_preds_val_prob  = [] \n        y_preds_test_prob = []\n        score             = []\n        mdl               = []\n        random            = str(np.random.rand(1)[0]).replace('.','')\n        model_name_       = model_name_ + '_score_{:2.5f}_{}_' + random + '.pkl.z'    \n        clf_name          = model_.__class__.__name__        \n        df_preds_prob     = pd.DataFrame()\n        df_feature_imp    = pd.DataFrame()\n        time_start        = datetime.now()    \n        n_estimators      = model_.get_params()['n_estimators']\n        dub_scaler        = '=> Double Scaler' if sc_second_!=None else ''        \n        lb                = LabelEncoder()\n        y_                = pd.DataFrame(lb.fit_transform(y_), columns=[target_])\n        col_prob          = y_[target_].sort_values().unique()\n        vies              = np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0]) \n        \n        if print_result_:\n            print('='*taco)\n            print('{} - n_estimators: {} seed: {}  {}'.format(clf_name, n_estimators, seed_, dub_scaler))\n            print('='*taco)\n\n        folds = StratifiedKFold(n_splits=n_splits_, shuffle=True, random_state=seed_)\n\n        for fold, (trn_idx, val_idx) in enumerate(folds.split(X_, y_)): #, groups=y\n\n            time_fold_start = datetime.now()\n\n            # ----------------------------------------------------\n            # Separar dados para treino \n            # ----------------------------------------------------\n            X_trn, X_val, sample_weight_train = X_.iloc[trn_idx], X_.iloc[val_idx], X_.iloc[trn_idx]['sample_weight']\n            y_trn, y_val, sample_weight_valid = y_.iloc[trn_idx], y_.iloc[val_idx], X_.iloc[val_idx]['sample_weight'] \n\n            # ----------------------------------------------------\n            # Processamento\n            # ----------------------------------------------------        \n            X_trn.drop('sample_weight', axis=1, inplace=True)\n            X_val.drop('sample_weight', axis=1, inplace=True)\n\n            X_trn = pd.DataFrame(sc_.fit_transform(X_trn), columns=X_trn.columns)\n            X_val = pd.DataFrame(sc_.transform(X_val), columns=X_val.columns)\n            X_tst = pd.DataFrame(sc_.transform(X_test_), columns=X_test_.columns)\n\n            if sc_second_ is not None: \n                X_trn = pd.DataFrame(sc_second_.fit_transform(X_trn), columns=X_trn.columns)\n                X_val = pd.DataFrame(sc_second_.transform(X_val), columns=X_val.columns)\n                X_tst = pd.DataFrame(sc_second_.transform(X_tst), columns=X_tst.columns)\n\n            # ---------------------------------------------------- \n            # Treinar o modelo \n            # ----------------------------------------------------     \n            model_.fit(X_trn, \n                       y_trn,\n                       sample_weight_train,\n                       eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n                       early_stopping_rounds = int(n_estimators*.1),\n                       verbose               = False)\n\n            # ---------------------------------------------------- \n            # Predição \n            # ----------------------------------------------------     \n            #y_pred_val       = model_.predict(X_val, ntree_limit=model_.best_ntree_limit)    \n            y_pred_val_prob  = model_.predict_proba(X_val, ntree_limit=model_.best_ntree_limit) \n            y_pred_test_prob = model_.predict_proba(X_tst, ntree_limit=model_.best_ntree_limit)\n\n            y_pred_val_prob += vies         \n            y_pred_val       = np.argmax(y_pred_val_prob, axis=1)\n\n            y_preds_test.append(model_.predict(X_tst))\n            y_preds_test_prob.append(y_pred_test_prob)\n\n            df_prob_temp    = pd.DataFrame(y_pred_val_prob, columns=col_prob)\n            y_pred_pbro_max = df_prob_temp.max(axis=1)\n\n            df_prob_temp['fold']    = fold+1\n            df_prob_temp['id']      = val_idx        \n            df_prob_temp['y_val']   = y_val.values        \n            df_prob_temp['y_pred']  = y_pred_val\n            df_prob_temp['y_proba'] = np.max(y_pred_val_prob, axis=1)\n\n            df_preds_prob = pd.concat([df_preds_prob, df_prob_temp], axis=0)\n\n            # ---------------------------------------------------- \n            # Score \n            # ---------------------------------------------------- \n            acc = metrics.accuracy_score(y_val, y_pred_val, sample_weight=sample_weight_valid)\n            score.append(acc)     \n\n            # ---------------------------------------------------- \n            # Print resultado  \n            # ---------------------------------------------------- \n            time_fold_end = diff(time_fold_start, datetime.now())        \n            msg = '[Fold {}] ACC: {:2.5f} -  {}'\n            \n            if print_result_:\n                print(msg.format(fold+1, acc, time_fold_end))\n\n            # ---------------------------------------------------- \n            # Feature Importance\n            # ----------------------------------------------------             \n            feat_imp = pd.DataFrame(index   = X_trn.columns,\n                                    data    = model_.feature_importances_,                            \n                                    columns = ['fold_{}'.format(fold+1)])\n\n            feat_imp['acc_'+str(fold+1)] = acc\n            df_feature_imp = pd.concat([df_feature_imp, feat_imp], axis=1)\n\n            # ---------------------------------------------------- \n            # Salva o modelo \n            # ---------------------------------------------------- \n            dic_model = {'scaler': sc_, \n                         'scaler_second': sc_second_,\n                         'fold': fold+1,\n                         'model': model_,                         \n                         'vies': vies}\n\n            mdl.append(dic_model)\n            \n            if trial_ is not None:\n                trial_.report(acc, fold)\n                if trial_.should_prune():\n                    raise optuna.TrialPruned()\n\n            time_end = diff(time_start, datetime.now())   \n\n        acc_mean = np.mean(score) \n        acc_std  = np.std(score)\n        \n        df_preds_prob.sort_values(\"id\", axis=0, ascending=True, inplace=True)\n\n        # ------------------------------\n        # Pós-processamento\n        # referencia: https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\n        # -------------------------------        \n        y_proba  = sum(y_preds_test_prob) / len(y_preds_test_prob)\n        y_proba += vies          \n\n        y_pred_test       = np.argmax(y_proba, axis=1)\n        y_pred_tuned      = lb.inverse_transform(y_pred_test)\n        y_pred_tuned_prob = np.max(y_proba, axis=1)\n\n        if save_predict_:                 \n            TunningModels.save_data_model(model_             = mdl, \n                                          model_name_        = model_name_, \n                                          path_              = path_, \n                                          y_pred_train_prob_ = df_preds_prob['y_proba'], \n                                          y_pred_test_prob_  = y_pred_tuned_prob, \n                                          y_pred_test_       = y_pred_tuned,\n                                          score_             = acc_mean, \n                                          seed_              = seed_, \n                                          level_             = level_, \n                                          target_            = target_\n                                          ) \n\n        if print_result_:\n            print('-'*taco)\n            print('[Mean Fold] ACC: {:2.5f} std: {:2.5f} - {}'.format(acc_mean, acc_std, time_end))    \n            print('='*taco)\n            print()\n\n        del X_trn, X_val, y_trn, y_val, feat_imp\n\n        return mdl, acc_mean , df_feature_imp , df_preds_prob, y_pred_test\n   \n    def xgb(self, trial):\n           \n        # https://xgboost.readthedocs.io/en/latest/parameter.html\n        # https://amangupta16.medium.com/xgboost-hyperparameters-explained-bb6ce580501d     \n        \n        eval_metric = ['mlogloss']\n                \n        params = {'objective'         : trial.suggest_categorical('objective', ['multi:softprob']), \n                  'booster'           : trial.suggest_categorical('booster', ['gbtree']),                 \n                  'eval_metric'       : trial.suggest_categorical('eval_metric', ['mlogloss']), \n                  'use_label_encoder' : trial.suggest_categorical('use_label_encoder', ['False']),                   \n                  'n_estimators'      : trial.suggest_int('n_estimators', 550, 1500, 100),                  \n                  'max_depth'         : trial.suggest_int('max_depth', 5, 15),\n                  'subsample'         : trial.suggest_discrete_uniform('subsample', .7, 1.0, .05), \n                  'learning_rate'     : trial.suggest_discrete_uniform('learning_rate', .01, 0.19, 0.01),\n                  'reg_alpha'         : trial.suggest_int('reg_alpha', 1, 10), \n                  'reg_lambda'        : trial.suggest_int('reg_lambda', 5, 50),\n                  'min_child_weight'  : trial.suggest_int('min_child_weight', 5, 25),  \n                  'colsample_bytree'  : trial.suggest_float('colsample_bytree', 0.8, 1.0),   \n                  'sampling_method'   : trial.suggest_categorical('sampling_method', ['gradient_based']), \n                 }\n             \n        if torch.cuda.is_available():           \n            params.update({'predictor'  : trial.suggest_categorical('predictor', ['gpu_predictor']), \n                           'tree_method': trial.suggest_categorical('tree_method', ['gpu_hist']) , \n                           'gpu_id'     : trial.suggest_int('gpu_id', 0,0)})\n                \n        #pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-auc\")\n        \n        mdl = xgb.XGBClassifier(**params) #, callbacks=[pruning_callback])\n        \n        _, score, _, _, _  = TunningModels.train_model_cv(model_        = mdl, \n                                                          X_            = self.X_trn, \n                                                          y_            = self.y_trn, \n                                                          X_test_       = self.X_ts, \n                                                          target_       = self.target, \n                                                          model_name_   = self.name_clf, \n                                                          sc_           = self.scaler, \n                                                          sc_second_    = self.sc_second, \n                                                          feature_      = self.feature,\n                                                          n_splits_     = self.n_splits, \n                                                          seed_         = self.seed,\n                                                          path_         = self.path,\n                                                          level_        = self.level, \n                                                          trial_        = trial\n                                                      )\n            \n        print('param = {}'.format(params))\n        print()\n\n        return score","metadata":{"ExecuteTime":{"end_time":"2022-02-21T02:52:46.324392Z","start_time":"2022-02-21T02:52:46.223894Z"},"code_folding":[1,6,27,63,80,86,121,142,167,194,261,338,361,366,368,378,577,752],"id":"LpYUOrRpi340","papermill":{"duration":0.357889,"end_time":"2022-02-18T04:09:05.282578","exception":false,"start_time":"2022-02-18T04:09:04.924689","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T01:33:23.839296Z","iopub.execute_input":"2022-02-23T01:33:23.839552Z","iopub.status.idle":"2022-02-23T01:33:23.962012Z","shell.execute_reply.started":"2022-02-23T01:33:23.839524Z","shell.execute_reply":"2022-02-23T01:33:23.961284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3. Tunning \nNesta etapa da modelagem, vamos criar 30 modelos e salvá-los para a nossa `Stacking`.","metadata":{"id":"S5fsZ-O5i345","papermill":{"duration":0.074708,"end_time":"2022-02-18T04:09:05.584391","exception":false,"start_time":"2022-02-18T04:09:05.509683","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\n\nSEED       = 12359\nn_trials_  = 25\nname_model = name_model_clf + '003_tunning' \n\nTunningModels.delete_files(name_model)\n    \nmodelOpt = TunningModels(name_model_     = name_model, \n                         X_trn_          = X, \n                         y_trn_          = y, \n                         X_ts_           = X_test,                                     \n                         feature_        = None,  \n                         scaler_         = RobustScaler(), \n                         seed_           = SEED, \n                         feature_bin_    = None, \n                         target_         = target, \n                         path_           = path, \n                         level_          = '1')\n\npruner = LastPlacePruner(warmup_steps  = 1, warmup_trials = 5)\nstudy  = optuna.create_study(direction  = 'maximize',\n                             sampler    = optuna.samplers.TPESampler(seed=SEED),\n                             #pruner     = optuna.pruners.MedianPruner(n_warmup_steps=10),\n                             pruner     = pruner,\n                             study_name = 'xgb_tuning')\n\nstudy.optimize(modelOpt.xgb, n_trials=n_trials_)\n\nscore_seed  = study.best_value \nparams      = study.best_params \npath_name   = path + 'model/optuna/' + name_model + '_{:2.5f}.pkl.z'.format(score_seed)   \nscare_best  = score_seed \nparams_best = params\n\nprint()\nprint('-'*110)\nprint('Best score: {:2.5f}'.format(scare_best))\nprint('Seed      : {}'.format(SEED))\nprint('Parameters:\\n\\n{}'.format(params_best))\nprint()","metadata":{"ExecuteTime":{"end_time":"2022-02-21T00:53:14.884707Z","start_time":"2022-02-21T00:47:05.328974Z"},"code_folding":[],"executionInfo":{"elapsed":12744938,"status":"ok","timestamp":1645060664988,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"-yNlljM6i345","outputId":"f164f267-df11-4f7d-9b9d-0234eba6e7a2","papermill":{"duration":10401.646477,"end_time":"2022-02-18T07:02:27.30556","exception":false,"start_time":"2022-02-18T04:09:05.659083","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-22T06:40:41.42434Z","iopub.execute_input":"2022-02-22T06:40:41.424688Z","iopub.status.idle":"2022-02-22T06:40:54.779039Z","shell.execute_reply.started":"2022-02-22T06:40:41.424649Z","shell.execute_reply":"2022-02-22T06:40:54.777838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.4. Análise  de Hyperparametros","metadata":{"id":"KEQa44wEi346","papermill":{"duration":0.139401,"end_time":"2022-02-18T07:02:27.882297","exception":false,"start_time":"2022-02-18T07:02:27.742896","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T22:42:51.619175Z","iopub.execute_input":"2022-02-21T22:42:51.619976Z","iopub.status.idle":"2022-02-21T22:42:51.637128Z","shell.execute_reply.started":"2022-02-21T22:42:51.619925Z","shell.execute_reply":"2022-02-21T22:42:51.63646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_parallel_coordinate(study)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T22:28:16.063568Z","iopub.execute_input":"2022-02-21T22:28:16.06382Z","iopub.status.idle":"2022-02-21T22:28:16.113353Z","shell.execute_reply.started":"2022-02-21T22:28:16.063791Z","shell.execute_reply":"2022-02-21T22:28:16.112548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_slice(study)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T22:43:16.628557Z","iopub.execute_input":"2022-02-21T22:43:16.62917Z","iopub.status.idle":"2022-02-21T22:43:16.906506Z","shell.execute_reply.started":"2022-02-21T22:43:16.629128Z","shell.execute_reply":"2022-02-21T22:43:16.905821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.5. Modelo\n\nAgora que temos os melhores parametros, vamos treinar um modelo com esse parametros e fazer algumas análises. ","metadata":{"id":"5nVNrHHSi347","papermill":{"duration":0.343167,"end_time":"2022-02-18T07:02:29.625515","exception":false,"start_time":"2022-02-18T07:02:29.282348","status":"completed"},"tags":[]}},{"cell_type":"code","source":"params_best","metadata":{"ExecuteTime":{"end_time":"2022-02-21T02:53:21.526543Z","start_time":"2022-02-21T02:53:21.512503Z"},"id":"GYk6QWP5lUM4","papermill":{"duration":0.257755,"end_time":"2022-02-18T07:02:30.113419","exception":false,"start_time":"2022-02-18T07:02:29.855664","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-22T14:48:12.006733Z","iopub.execute_input":"2022-02-22T14:48:12.007269Z","iopub.status.idle":"2022-02-22T14:48:12.013702Z","shell.execute_reply.started":"2022-02-22T14:48:12.00723Z","shell.execute_reply":"2022-02-22T14:48:12.012888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nname_model = name_model_clf + '004_tunning'\n\nmodel, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_best), \n                                 X_             = X_train, \n                                 y_             = y_train, \n                                 X_test_        = X_test, \n                                 target_        = target, \n                                 model_name_    = name_model, \n                                 sc_            = RobustScaler(), \n                                 sc_second_     = None, \n                                 n_splits_      = 5, \n                                 seed_          = SEED,\n                                 path_          = path, \n                                 save_predict_  = False, \n                                 level_         = '1', \n                                 print_result_  = True, \n                                 feature_       = None, \n                                 trial_         = None)","metadata":{"ExecuteTime":{"end_time":"2022-02-21T02:56:31.277921Z","start_time":"2022-02-21T02:53:22.163676Z"},"code_folding":[],"executionInfo":{"elapsed":1129658,"status":"ok","timestamp":1644988187609,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"52gsbtwyi348","outputId":"5b06c926-ae7f-4ca8-d984-aff36e76f82e","papermill":{"duration":716.130964,"end_time":"2022-02-18T07:14:26.533079","exception":false,"start_time":"2022-02-18T07:02:30.402115","status":"completed"},"run_control":{"marked":false},"tags":[],"execution":{"iopub.status.busy":"2022-02-21T22:43:59.099826Z","iopub.execute_input":"2022-02-21T22:43:59.100093Z","iopub.status.idle":"2022-02-21T22:52:29.483491Z","shell.execute_reply.started":"2022-02-21T22:43:59.100062Z","shell.execute_reply":"2022-02-21T22:52:29.482676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.5.1. Feature Importances  ","metadata":{"id":"9FAnuS_dlUM5","papermill":{"duration":0.145538,"end_time":"2022-02-18T07:14:26.823756","exception":false,"start_time":"2022-02-18T07:14:26.678218","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nrow = int(np.round(df_feature_imp.filter(regex=r'fold').shape[1] / 3 +1))\nfor fold, col in enumerate(df_feature_imp.filter(regex=r'fold').columns):            \n    col_acc = 'acc_' + str(fold+1)\n    df_fi = df_feature_imp.sort_values(by=col, ascending=False).reset_index().iloc[:30]\n    df_fi = df_fi[['index', col, col_acc]]\n    df_fi.columns = ['Feature', 'score', col_acc]\n    plt.subplot(row,3, fold+1)\n    sns.barplot(x='score', y='Feature', data=df_fi)    \n    plt.title('Fold {} - score: {:2.5f}'.format(fold+1, df_fi[col_acc].mean()), \n              fontdict={'fontsize':18})    \n\nplt.suptitle('Feature Importance XGB ', y=1.05, fontsize=24);\nplt.tight_layout(h_pad=3.0); \n\ndel df_fi","metadata":{"ExecuteTime":{"end_time":"2022-02-21T02:56:33.85895Z","start_time":"2022-02-21T02:56:31.2799Z"},"executionInfo":{"elapsed":4557,"status":"ok","timestamp":1644988192152,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"RvmfIdSslUM6","outputId":"4512a075-34f4-4e35-f886-ddf8d92c7dcb","papermill":{"duration":2.731522,"end_time":"2022-02-18T07:14:29.700645","exception":false,"start_time":"2022-02-18T07:14:26.969123","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-21T22:52:36.036803Z","iopub.execute_input":"2022-02-21T22:52:36.037103Z","iopub.status.idle":"2022-02-21T22:52:38.682505Z","shell.execute_reply.started":"2022-02-21T22:52:36.037069Z","shell.execute_reply":"2022-02-21T22:52:38.68184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\">\n    \n**`NOTA:`** <br>\n    \n</div>","metadata":{"ExecuteTime":{"end_time":"2022-02-21T03:20:02.217776Z","start_time":"2022-02-21T03:20:02.197736Z"}}},{"cell_type":"markdown","source":"### 2.5.2. Predição","metadata":{}},{"cell_type":"code","source":"cols = X_valid.columns.to_list()\ncols.remove('sample_weight')","metadata":{"ExecuteTime":{"end_time":"2022-02-21T02:57:05.059405Z","start_time":"2022-02-21T02:57:05.042368Z"},"execution":{"iopub.status.busy":"2022-02-23T01:33:51.578943Z","iopub.execute_input":"2022-02-23T01:33:51.579201Z","iopub.status.idle":"2022-02-23T01:33:51.582965Z","shell.execute_reply.started":"2022-02-23T01:33:51.579171Z","shell.execute_reply":"2022-02-23T01:33:51.582304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb     = LabelEncoder()\nscaler = model[0]['scaler'] \nmdl    = model[0]['model']\ny_lb   = lb.fit_transform(y_valid)\n\nX_vld_scaler  = pd.DataFrame(scaler.transform(X_valid[cols]), columns=cols)\ny_pred_val    = mdl.predict(X_vld_scaler)\nacc           = metrics.accuracy_score(y_lb, y_pred_val)\n\nprint('ACC: {:2.5f}'.format(acc))\n\nprint(metrics.classification_report(y_lb, y_pred_val, target_names=lb.classes_))","metadata":{"ExecuteTime":{"end_time":"2022-02-21T03:11:41.591683Z","start_time":"2022-02-21T03:11:40.842638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.5.3. Predição Teste e Submission","metadata":{"ExecuteTime":{"end_time":"2022-02-21T03:14:35.72603Z","start_time":"2022-02-21T03:14:35.710001Z"}}},{"cell_type":"code","source":"X_test_scaler = pd.DataFrame(scaler.transform(X_test[cols]), columns=cols)\ny_pred_test   = mdl.predict(X_test_scaler)","metadata":{"ExecuteTime":{"end_time":"2022-02-21T03:14:47.954046Z","start_time":"2022-02-21T03:14:46.125413Z"},"execution":{"iopub.status.busy":"2022-02-21T22:57:39.220073Z","iopub.execute_input":"2022-02-21T22:57:39.220342Z","iopub.status.idle":"2022-02-21T22:57:42.843767Z","shell.execute_reply.started":"2022-02-21T22:57:39.220312Z","shell.execute_reply":"2022-02-21T22:57:42.843035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name_model = name_model_clf + 'tunning_score_05_{:2.5f}_final.csv'.format(acc)\n\ndf_submission[target] = lb.inverse_transform(y_pred_test)\ndf_submission.to_csv(path +'Data/submission/' + name_model, index=False)","metadata":{"ExecuteTime":{"end_time":"2022-02-21T03:18:39.574832Z","start_time":"2022-02-21T03:18:39.400271Z"},"execution":{"iopub.status.busy":"2022-02-21T23:05:11.311645Z","iopub.execute_input":"2022-02-21T23:05:11.311911Z","iopub.status.idle":"2022-02-21T23:05:11.528872Z","shell.execute_reply.started":"2022-02-21T23:05:11.311881Z","shell.execute_reply":"2022-02-21T23:05:11.52816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\">\n    \n**`NOTA:`** <br>\n    \n</div>","metadata":{"ExecuteTime":{"end_time":"2022-02-21T03:00:37.806126Z","start_time":"2022-02-21T03:00:37.799127Z"}}},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\"> 3. FEATURE SELECTION </div>","metadata":{}},{"cell_type":"markdown","source":"## 3.1. Boruta","metadata":{"papermill":{"duration":0.14977,"end_time":"2022-02-18T07:14:29.999438","exception":false,"start_time":"2022-02-18T07:14:29.849668","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sc = RobustScaler()\nlb = LabelEncoder()\n\nX_scaler = X.drop(['sample_weight'], axis=1)\nX_scaler = pd.DataFrame(sc.fit_transform(X_scaler), columns=X_scaler.columns)\ny_label  = pd.DataFrame(lb.fit_transform(y), columns=[target])\n\nX_scaler.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-22T14:48:46.608145Z","iopub.execute_input":"2022-02-22T14:48:46.608823Z","iopub.status.idle":"2022-02-22T14:48:49.837662Z","shell.execute_reply.started":"2022-02-22T14:48:46.60879Z","shell.execute_reply":"2022-02-22T14:48:49.836977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_best","metadata":{"execution":{"iopub.status.busy":"2022-02-23T01:35:18.215084Z","iopub.execute_input":"2022-02-23T01:35:18.215356Z","iopub.status.idle":"2022-02-23T01:35:18.220828Z","shell.execute_reply.started":"2022-02-23T01:35:18.215325Z","shell.execute_reply":"2022-02-23T01:35:18.219904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = xgb.XGBClassifier(**params_best)\n\nfeat_selector = BorutaPy(model, \n                         n_estimators = 'auto', \n                         two_step     = False,\n                         verbose      = 2, \n                         max_iter     = 100,\n                         random_state = 42)\n\nfeat_selector.fit(X_scaler.values, y_label.values)","metadata":{"ExecuteTime":{"end_time":"2022-02-21T01:26:16.914255Z","start_time":"2022-02-21T00:59:15.085066Z"},"executionInfo":{"elapsed":3610,"status":"ok","timestamp":1645133128911,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"SYbncKdAVzZI","outputId":"95d3a417-7240-449a-9baa-1207bafa77a3","papermill":{"duration":8034.542892,"end_time":"2022-02-18T09:28:24.692174","exception":false,"start_time":"2022-02-18T07:14:30.149282","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-02-21T23:07:33.226238Z","iopub.execute_input":"2022-02-21T23:07:33.226491Z","iopub.status.idle":"2022-02-21T23:20:01.056023Z","shell.execute_reply.started":"2022-02-21T23:07:33.226463Z","shell.execute_reply":"2022-02-21T23:20:01.05525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_selected = X_scaler.iloc[:,feat_selector.support_]\nX_test_selected  = X_test.iloc[:,feat_selector.support_]\n\nX_train_selected['sample_weight'] = X['sample_weight']\nX_test_selected.shape , X_test_selected.shape","metadata":{"ExecuteTime":{"end_time":"2022-02-21T03:27:28.352272Z","start_time":"2022-02-21T03:27:28.31029Z"},"executionInfo":{"elapsed":556,"status":"ok","timestamp":1645112502849,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"mRf1BebkTqdW","outputId":"8fdead1a-081f-4f0f-e1ae-7faaad8c85a2","papermill":{"duration":0.709069,"end_time":"2022-02-18T09:28:25.58063","exception":false,"start_time":"2022-02-18T09:28:24.871561","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-21T23:20:45.827702Z","iopub.execute_input":"2022-02-21T23:20:45.828004Z","iopub.status.idle":"2022-02-21T23:20:45.857388Z","shell.execute_reply.started":"2022-02-21T23:20:45.827951Z","shell.execute_reply":"2022-02-21T23:20:45.85674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. Feature ","metadata":{}},{"cell_type":"code","source":"cols_feature_selected_boruta = X_train_selected.columns.to_list()\nprint(cols_feature_selected_boruta)","metadata":{"ExecuteTime":{"end_time":"2022-02-21T03:27:30.308524Z","start_time":"2022-02-21T03:27:30.302527Z"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1645112536955,"user":{"displayName":"Rogério Delfim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64","userId":"04235763959036945343"},"user_tz":180},"id":"kzN_XEkFWLiG","outputId":"98fbf679-e03f-41e7-8bcf-08c0f70f07ff","papermill":{"duration":0.318072,"end_time":"2022-02-18T09:28:26.255868","exception":false,"start_time":"2022-02-18T09:28:25.937796","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-23T02:11:22.768111Z","iopub.execute_input":"2022-02-23T02:11:22.768767Z","iopub.status.idle":"2022-02-23T02:11:22.773313Z","shell.execute_reply.started":"2022-02-23T02:11:22.768726Z","shell.execute_reply":"2022-02-23T02:11:22.772102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_rejected = [col for col in X.columns if col not in cols_feature_selected_boruta]\nprint(feature_rejected)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:08:05.381658Z","iopub.execute_input":"2022-02-23T13:08:05.381959Z","iopub.status.idle":"2022-02-23T13:08:05.390672Z","shell.execute_reply.started":"2022-02-23T13:08:05.381902Z","shell.execute_reply":"2022-02-23T13:08:05.389754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3. Feature autocorrelaciondas","metadata":{}},{"cell_type":"code","source":"threshold = .75\n\nprint('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold))\ndf = X[cols_feature_selected_boruta].corr(method ='pearson').round(5)\ndf_corr = df[abs(df)>threshold][df!=1.0].unstack().dropna().reset_index()\ndf_corr.columns =  ['var_1', 'var_2', 'corr']\ndf_corr.head(100)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:08:13.48157Z","iopub.execute_input":"2022-02-23T13:08:13.481886Z","iopub.status.idle":"2022-02-23T13:08:41.523455Z","shell.execute_reply.started":"2022-02-23T13:08:13.481851Z","shell.execute_reply":"2022-02-23T13:08:41.522798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_aut_corr = list(df_corr['var_1'].unique())\n#feature_aut_corr.remove('sample_weight')\nprint('Temos {} variáveis autocorrelaciodas.'.format(len(feature_aut_corr)))","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:09:33.534165Z","iopub.execute_input":"2022-02-23T13:09:33.534684Z","iopub.status.idle":"2022-02-23T13:09:33.54255Z","shell.execute_reply.started":"2022-02-23T13:09:33.534646Z","shell.execute_reply":"2022-02-23T13:09:33.541744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Vamos remover as variáveis autocorrelacionadas. ","metadata":{}},{"cell_type":"code","source":"cols_feature_selected = [col for col in cols_feature_selected_boruta if col not in feature_aut_corr]\nprint('Temos agora {} variáveis.'.format(len(cols_feature_selected)), end='\\n\\n')\nprint(cols_feature_selected)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:09:42.006045Z","iopub.execute_input":"2022-02-23T13:09:42.006355Z","iopub.status.idle":"2022-02-23T13:09:42.015783Z","shell.execute_reply.started":"2022-02-23T13:09:42.006321Z","shell.execute_reply":"2022-02-23T13:09:42.015063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3. Modelagem\nVamos fazer dois modelos, um com as variáveis selecionadas com o boruta e outro sem as variáveis autocorrelacionadas. ","metadata":{}},{"cell_type":"code","source":"cols_feature_selected_boruta_ts = cols_feature_selected_boruta.copy()\ncols_feature_selected_ts        = cols_feature_selected.copy() \n\ncols_feature_selected_boruta_ts.remove('sample_weight')\ncols_feature_selected_ts.remove('sample_weight')","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:16:56.396762Z","iopub.execute_input":"2022-02-23T03:16:56.397035Z","iopub.status.idle":"2022-02-23T03:16:56.403712Z","shell.execute_reply.started":"2022-02-23T03:16:56.396998Z","shell.execute_reply":"2022-02-23T03:16:56.402951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlist_feature_imp = []\nfeature          = [cols_feature_selected_boruta, cols_feature_selected]\n\nfor i, cols in enumerate(feature): \n    cols_ts = cols.copy()\n    cols_ts.remove('sample_weight')\n    \n    name_model = name_model_clf + 'tunning_boruta_' + str(i+1) + '_score_06'\n        \n    model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_best), \n                                 X_             = X[cols], \n                                 y_             = y, \n                                 X_test_        = X_test[cols_ts], \n                                 target_        = target, \n                                 model_name_    = name_model, \n                                 sc_            = RobustScaler(), \n                                 sc_second_     = None, \n                                 n_splits_      = 5, \n                                 seed_          = SEED,\n                                 path_          = path, \n                                 save_predict_  = True, \n                                 level_         = '1', \n                                 print_result_  = True, \n                                 feature_       = None, \n                                 trial_         = None)\n    \n    list_feature_imp.append(df_feature_imp)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T02:47:20.625153Z","iopub.execute_input":"2022-02-23T02:47:20.625752Z","iopub.status.idle":"2022-02-23T03:12:49.139727Z","shell.execute_reply.started":"2022-02-23T02:47:20.625713Z","shell.execute_reply":"2022-02-23T03:12:49.138931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\">\n    \n**`NOTA:`** <br>\nAqui temos um ponto interessante, o primeiro modelo tem melhor score, mas também com mais variáveis se tornando mais complexo e com mais ruidos, sendo assim, o segundo modelo me parece mais estável e a diferença é relativamente pequena, a partir desse ponto vamos utilizar apenas as variáveis do segundo modelo na geração dos próximos modelos.           \n    \n</div>","metadata":{}},{"cell_type":"code","source":"for i in range(len(list_feature_imp)):\n    plt.figure(figsize=(20,20))\n    row = int(np.round(list_feature_imp[0].filter(regex=r'fold').shape[1] / 3 +1))\n    for fold, col in enumerate(list_feature_imp[0].filter(regex=r'fold').columns):            \n        col_acc = 'acc_' + str(fold+1)\n        df_fi = list_feature_imp[0].sort_values(by=col, ascending=False).reset_index().iloc[:25]\n        df_fi = df_fi[['index', col, col_acc]]\n        df_fi.columns = ['Feature', 'score', col_acc]\n        plt.subplot(row,3, fold+1)\n        sns.barplot(x='score', y='Feature', data=df_fi)    \n        plt.title('Fold {} - score: {:2.5f}'.format(fold+1, df_fi[col_acc].mean()), \n                  fontdict={'fontsize':18})    \n\n    plt.suptitle('Feature Importance XGB ', y=1.02, fontsize=24);\n    plt.tight_layout(h_pad=3.0); \n\ndel df_fi","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:27:35.244454Z","iopub.execute_input":"2022-02-23T03:27:35.245099Z","iopub.status.idle":"2022-02-23T03:27:39.929297Z","shell.execute_reply.started":"2022-02-23T03:27:35.245059Z","shell.execute_reply":"2022-02-23T03:27:39.928591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\"> 3. DIVERCIDADE </div>\n\nNesta etapa vamos utilizar os melhores parametros, que encontramos na tunagem, para gerar diversos modelos com divercidade.","metadata":{}},{"cell_type":"markdown","source":"## 3.1. Seed ","metadata":{}},{"cell_type":"code","source":"%%time \n\nSEED_      = [42, 59, 1000, 1500, 2020, 2021]\ndf_seed    = pd.DataFrame()\nscore_best = 0 \nseed_best  = 0 \n\nTunningModels.delete_files(name_model)\n\nfor i, seed_ in  enumerate (SEED_):     \n    name_model = name_model_clf + 'seed_'+ str(i+1) +'_score_07'\n        \n    model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_best), \n                                 X_             = X[cols_feature_selected], \n                                 y_             = y,\n                                 X_test_        = X_test[cols_feature_selected_ts], \n                                 target_        = target, \n                                 model_name_    = name_model, \n                                 sc_            = RobustScaler(), \n                                 sc_second_     = None, \n                                 n_splits_      = 5, \n                                 seed_          = seed_,\n                                 path_          = path, \n                                 save_predict_  = True, \n                                 level_         = '1', \n                                 print_result_  = True, \n                                 feature_       = None, \n                                 trial_         = None)\n    \n    if score > score_best:\n        seed_best  = seed_  \n        score_best = score\n    \n    df_seed['seed_' + str(seed_)] = y_pred_test \n    \nprint()\nprint('Seed : {}'.format(seed_best))\nprint('Score: {}'.format(score_best))\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:28:34.531157Z","iopub.execute_input":"2022-02-23T03:28:34.531866Z","iopub.status.idle":"2022-02-23T03:34:57.277947Z","shell.execute_reply.started":"2022-02-23T03:28:34.531828Z","shell.execute_reply":"2022-02-23T03:34:57.277113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_seed.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:35:04.876179Z","iopub.execute_input":"2022-02-23T03:35:04.876731Z","iopub.status.idle":"2022-02-23T03:35:04.888718Z","shell.execute_reply.started":"2022-02-23T03:35:04.876695Z","shell.execute_reply":"2022-02-23T03:35:04.887867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.1.1. Gerar submission ","metadata":{}},{"cell_type":"code","source":"lb = LabelEncoder()\nlb.fit_transform(y)\n\ny_pred_test = df_seed.mode(axis=1)[0]\ny_pred_test = lb.inverse_transform(y_pred_test.astype(int))\n\nname_model = name_model_clf + 'stacking_01_seed.csv'.format(score_best)\n\ndf_submission[target] = y_pred_test\ndf_submission.to_csv(path +'Data/submission/' + name_model, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:36:39.577029Z","iopub.execute_input":"2022-02-23T03:36:39.577313Z","iopub.status.idle":"2022-02-23T03:37:15.130681Z","shell.execute_reply.started":"2022-02-23T03:36:39.577284Z","shell.execute_reply":"2022-02-23T03:37:15.129976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. Leaning Rate","metadata":{"execution":{"iopub.status.busy":"2022-02-21T23:39:05.860166Z","iopub.execute_input":"2022-02-21T23:39:05.860706Z","iopub.status.idle":"2022-02-21T23:39:05.866755Z","shell.execute_reply.started":"2022-02-21T23:39:05.860656Z","shell.execute_reply":"2022-02-21T23:39:05.865831Z"}}},{"cell_type":"code","source":"%%time \n\nlearning_rate      = [0.1, 0.01, 0.005, 0.007]\ndf_learning_rate   = pd.DataFrame()\ndf_leaning_rate    = pd.DataFrame()\nparams_l_rate      = params_best.copy()\nscore_best         = 0 \nlearning_rate_best = 0 \n\nTunningModels.delete_files(name_model)\n\nfor i, learning_rate_ in  enumerate (learning_rate):   \n    name_model         = name_model_clf + 'leanig_rate_'+ str(i+1) +'_score_08'\n    params_l_rate['learning_rate'] = learning_rate_     \n    model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_l_rate), \n                                 X_             = X[cols_feature_selected], \n                                 y_             = y, \n                                 X_test_        = X_test[cols_feature_selected_ts], \n                                 target_        = target, \n                                 model_name_    = name_model, \n                                 sc_            = RobustScaler(), \n                                 sc_second_     = None, \n                                 n_splits_      = 5, \n                                 seed_          = seed_best,\n                                 path_          = path, \n                                 save_predict_  = True, \n                                 level_         = '1', \n                                 print_result_  = True, \n                                 feature_       = None, \n                                 trial_         = None)\n    \n    if score > score_best:\n        learning_rate_best  = learning_rate_  \n        score_best          = score\n    \n    df_leaning_rate['leaning_rate_' + str(learning_rate_)] = y_pred_test \n\nprint()\nprint('Leaning Rate : {}'.format(learning_rate_best))\nprint('Score        : {}'.format(score_best))\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:40:32.81095Z","iopub.execute_input":"2022-02-23T03:40:32.8112Z","iopub.status.idle":"2022-02-23T03:41:30.686643Z","shell.execute_reply.started":"2022-02-23T03:40:32.811172Z","shell.execute_reply":"2022-02-23T03:41:30.685911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_leaning_rate.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:42:14.742563Z","iopub.execute_input":"2022-02-23T03:42:14.742823Z","iopub.status.idle":"2022-02-23T03:42:14.750295Z","shell.execute_reply.started":"2022-02-23T03:42:14.742795Z","shell.execute_reply":"2022-02-23T03:42:14.749646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.1. Gerar submission ","metadata":{}},{"cell_type":"code","source":"lb = LabelEncoder()\nlb.fit_transform(y)\n\ny_pred_test = df_leaning_rate.mode(axis=1)[0]\ny_pred_test = lb.inverse_transform(y_pred_test.astype(int))\n\nname_model = name_model_clf + 'stacking_02_leaning_rate.csv'.format(score_best)\n\ndf_submission[target] = y_pred_test\ndf_submission.to_csv(path +'Data/submission/' + name_model, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:42:20.355906Z","iopub.execute_input":"2022-02-23T03:42:20.35618Z","iopub.status.idle":"2022-02-23T03:42:40.972476Z","shell.execute_reply.started":"2022-02-23T03:42:20.356148Z","shell.execute_reply":"2022-02-23T03:42:40.971597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3. Max Depth","metadata":{}},{"cell_type":"code","source":"%%time \n\nmax_dep        = [1, 3, 13, 15, 19]\ndf_max_depth   = pd.DataFrame()\nparams_max_dep = params_best.copy()\nscore_best     = 0 \nmax_dep_best   = 0 \n\nTunningModels.delete_files(name_model)\n\nfor i, max_dep_ in  enumerate (max_dep):    \n    name_model = name_model_clf + 'max_dep_'+ str(i+1) + '_score_09'\n    params_max_dep['max_depth'] = max_dep_     \n    \n    model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_max_dep), \n                                 X_             = X[cols_feature_selected], \n                                 y_             = y, \n                                 X_test_        = X_test[cols_feature_selected_ts], \n                                 target_        = target, \n                                 model_name_    = name_model, \n                                 sc_            = RobustScaler(), \n                                 sc_second_     = None, \n                                 n_splits_      = 5, \n                                 seed_          = seed_best,\n                                 path_          = path, \n                                 save_predict_  = True, \n                                 level_         = '1', \n                                 print_result_  = True, \n                                 feature_       = None, \n                                 trial_         = None)\n    \n    if score > score_best:\n        max_dep_best  = max_dep_  \n        score_best    = score\n    \n    df_max_depth['max_depth_' + str(max_dep_)] = y_pred_test \n\nprint()\nprint('Max Depth: {}'.format(max_dep_best))\nprint('Score    : {}'.format(score_best))\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:43:06.969619Z","iopub.execute_input":"2022-02-23T03:43:06.969873Z","iopub.status.idle":"2022-02-23T03:44:56.001822Z","shell.execute_reply.started":"2022-02-23T03:43:06.969845Z","shell.execute_reply":"2022-02-23T03:44:56.000962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_max_depth.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:44:56.003505Z","iopub.execute_input":"2022-02-23T03:44:56.003835Z","iopub.status.idle":"2022-02-23T03:44:56.013559Z","shell.execute_reply.started":"2022-02-23T03:44:56.003798Z","shell.execute_reply":"2022-02-23T03:44:56.011709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3.1. Gerar submission ","metadata":{}},{"cell_type":"code","source":"lb = LabelEncoder()\nlb.fit_transform(y)\n\ny_pred_test = df_max_depth.mode(axis=1)[0]\ny_pred_test = lb.inverse_transform(y_pred_test.astype(int))\n\nname_model = name_model_clf + 'stacking_03_max_depth.csv'.format(score_best)\n\ndf_submission[target] = y_pred_test\ndf_submission.to_csv(path +'Data/submission/' + name_model, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:48:07.80902Z","iopub.execute_input":"2022-02-23T03:48:07.809294Z","iopub.status.idle":"2022-02-23T03:48:41.159154Z","shell.execute_reply.started":"2022-02-23T03:48:07.809263Z","shell.execute_reply":"2022-02-23T03:48:41.158367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4. Feature","metadata":{}},{"cell_type":"code","source":"%%time\n\nname_model = name_model_clf + '_div_feature_10_'\n\nTunningModels.model_of_diversity_feature_group(model_     = xgb.XGBClassifier(**params_best), \n                                               name_model = name_model, \n                                               X_         = X[cols_feature_selected], \n                                               y_         = y, \n                                               X_ts_      = X_test[cols_feature_selected_ts],\n                                               target_    = target,\n                                               sc_        = RobustScaler(),\n                                               seed_      = seed_best)  ","metadata":{"execution":{"iopub.status.busy":"2022-02-23T03:49:05.435804Z","iopub.execute_input":"2022-02-23T03:49:05.436052Z","iopub.status.idle":"2022-02-23T03:54:06.645937Z","shell.execute_reply.started":"2022-02-23T03:49:05.436025Z","shell.execute_reply":"2022-02-23T03:54:06.645253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div class=\"alert alert-success\"> 4. ENSEMBLE </div>","metadata":{}},{"cell_type":"markdown","source":"## 4.1. Recuparar dataset\nVamos recuperar todas as previsões do XGBoost para gerar um ensable. ","metadata":{}},{"cell_type":"code","source":"%%time \ndf_train_xgb, df_test_xgb = TunningModels.df_return_preds_tunning('xgb', \n                                                                  train_shape_row = X.shape[0],\n                                                                  test_shape_row  = X_test.shape[0])\nprint(df_train_xgb.shape, df_test_xgb.shape)\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T04:05:57.514697Z","iopub.execute_input":"2022-02-23T04:05:57.515004Z","iopub.status.idle":"2022-02-23T04:06:06.572161Z","shell.execute_reply.started":"2022-02-23T04:05:57.514971Z","shell.execute_reply":"2022-02-23T04:06:06.570648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_xgb.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T04:06:45.283646Z","iopub.execute_input":"2022-02-23T04:06:45.283898Z","iopub.status.idle":"2022-02-23T04:06:45.293949Z","shell.execute_reply.started":"2022-02-23T04:06:45.283869Z","shell.execute_reply":"2022-02-23T04:06:45.293303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jb.dump(df_train_xgb, 'Data/pkl/df_nb_03_train_xgb.pkl.z')\njb.dump(df_test_xgb,  'Data/pkl/df_nb_03_test_xgb.pkl.z')","metadata":{"execution":{"iopub.status.busy":"2022-02-23T04:07:05.648355Z","iopub.execute_input":"2022-02-23T04:07:05.649075Z","iopub.status.idle":"2022-02-23T04:07:06.055288Z","shell.execute_reply.started":"2022-02-23T04:07:05.64903Z","shell.execute_reply":"2022-02-23T04:07:06.054623Z"},"trusted":true},"execution_count":null,"outputs":[]}]}