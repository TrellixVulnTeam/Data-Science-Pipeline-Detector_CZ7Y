{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <span style='color:#A80808'>Motivation</span>\n\nThis notebook examines some ideas initialized by @ambrosm","metadata":{"_uuid":"7b4abacb-8306-4fcc-bf55-4d5ac18f02c4","_cell_guid":"d04ffd99-b9e3-4b5d-abc0-a5104771a45a","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-22T21:20:55.543705Z","iopub.execute_input":"2022-02-22T21:20:55.543982Z","iopub.status.idle":"2022-02-22T21:20:55.549216Z","shell.execute_reply.started":"2022-02-22T21:20:55.543953Z","shell.execute_reply":"2022-02-22T21:20:55.54853Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom math import factorial\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.cluster import KMeans","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style='color:#A80808'>Data</span>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv')\n\nfeatures = train.columns[1:-1]\n\nle = LabelEncoder()\ntrain['target'] = le.fit_transform(train.target)\n\n# Use top public score prediction for analysis\ntest['target'] = le.transform(pd.read_csv('../input/early-ensemble/submission.csv')['target'])","metadata":{"_uuid":"10fba476-266b-44c6-8cf2-82f3df8f8d9f","_cell_guid":"df3c84d4-48c9-4c3c-a851-82079c9487f0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-22T21:20:55.550883Z","iopub.execute_input":"2022-02-22T21:20:55.55131Z","iopub.status.idle":"2022-02-22T21:21:18.124866Z","shell.execute_reply.started":"2022-02-22T21:20:55.551268Z","shell.execute_reply":"2022-02-22T21:21:18.124051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense\ndef bias_of(s):\n    w = int(s[1:s.index('T')])\n    x = int(s[s.index('T')+1:s.index('G')])\n    y = int(s[s.index('G')+1:s.index('C')])\n    z = int(s[s.index('C')+1:])\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ntrain_i = pd.DataFrame({col: ((train[col] + bias_of(col)) * 1000000).round().astype(int)\n                        for col in features})\ntest_i = pd.DataFrame({col: ((test[col] + bias_of(col)) * 1000000).round().astype(int)\n                       for col in features})\n\ntrain['gcd'] = np.gcd.reduce(train_i[features], axis=1)\ntest['gcd'] = np.gcd.reduce(test_i[features], axis=1)","metadata":{"_uuid":"870ac0fe-f476-4146-9834-c84da29ae2bf","_cell_guid":"a0267cb5-90c8-4136-a651-fb477c1be4b2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-22T21:21:18.126657Z","iopub.execute_input":"2022-02-22T21:21:18.127275Z","iopub.status.idle":"2022-02-22T21:21:20.627318Z","shell.execute_reply.started":"2022-02-22T21:21:18.127226Z","shell.execute_reply":"2022-02-22T21:21:20.626061Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style='color:#A80808'>GCD=1</span>","metadata":{}},{"cell_type":"code","source":"gcd = 1\n\nplt.figure(figsize=(18, 24))\n\nfor idx in range(10):\n    features_sum = train[features][(train['gcd'] == gcd) & (train['target'] == idx)].abs().sum(axis=1)\n    features_sum_test = test[features][(test['gcd'] == gcd) & (test['target'] == idx)].abs().sum(axis=1)\n    \n    plt.subplot(10,2,2*idx+1)\n    plt.title(f'Train dataset, {le.inverse_transform([idx])[0]}')\n    plt.hist(features_sum, \n             bins=np.linspace(0,features_sum.max(),200),\n             color=plt.cm.get_cmap('tab10', 10)(idx))\n    plt.xlabel('Feature sum')\n    plt.ylabel('Frequence')\n    plt.tight_layout()\n\n    plt.subplot(10,2,2*idx+2)\n    plt.title(f'Test dataset, {le.inverse_transform([idx])[0]}')\n    plt.hist(features_sum_test, \n             bins=np.linspace(0,features_sum.max(),200),\n             color=plt.cm.get_cmap('tab10', 10)(idx), density=True)\n    plt.xlabel('Feature sum')\n    plt.ylabel('Frequence')\n    plt.tight_layout()\nplt.show()","metadata":{"_uuid":"6e74aa35-fe22-463f-9365-5f37c888e4f6","_cell_guid":"de8ec7b8-4a8d-4cda-9c4d-95f824469106","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-22T21:25:36.141366Z","iopub.execute_input":"2022-02-22T21:25:36.141723Z","iopub.status.idle":"2022-02-22T21:25:58.000765Z","shell.execute_reply.started":"2022-02-22T21:25:36.141677Z","shell.execute_reply":"2022-02-22T21:25:58.000027Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style='color:#A80808'>GCD=10</span>","metadata":{}},{"cell_type":"code","source":"gcd = 10\n\nplt.figure(figsize=(18, 24))\n\nfor idx in range(10):\n    features_sum = train[features][(train['gcd'] == gcd) & (train['target'] == idx)].abs().sum(axis=1)\n    features_sum_test = test[features][(test['gcd'] == gcd) & (test['target'] == idx)].abs().sum(axis=1)\n    \n    plt.subplot(10,2,2*idx+1)\n    plt.title(f'Train dataset, {le.inverse_transform([idx])[0]}')\n    plt.hist(features_sum, \n             bins=np.linspace(0,features_sum.max(),200),\n             color=plt.cm.get_cmap('tab10', 10)(idx))\n    plt.xlabel('Feature sum')\n    plt.ylabel('Frequence')\n    plt.tight_layout()\n\n    plt.subplot(10,2,2*idx+2)\n    plt.title(f'Test dataset, {le.inverse_transform([idx])[0]}')\n    plt.hist(features_sum_test, \n             bins=np.linspace(0,features_sum.max(),200),\n             color=plt.cm.get_cmap('tab10', 10)(idx), density=True)\n    plt.xlabel('Feature sum')\n    plt.ylabel('Frequence')\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T21:28:52.294282Z","iopub.execute_input":"2022-02-22T21:28:52.294606Z","iopub.status.idle":"2022-02-22T21:29:12.873362Z","shell.execute_reply.started":"2022-02-22T21:28:52.294573Z","shell.execute_reply":"2022-02-22T21:29:12.872436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style='color:#A80808'>GCD=1000</span>","metadata":{}},{"cell_type":"code","source":"gcd = 1000\n\nplt.figure(figsize=(18, 24))\n\nfor idx in range(10):\n    features_sum = train[features][(train['gcd'] == gcd) & (train['target'] == idx)].abs().sum(axis=1)\n    features_sum_test = test[features][(test['gcd'] == gcd) & (test['target'] == idx)].abs().sum(axis=1)\n    \n    plt.subplot(10,2,2*idx+1)\n    plt.title(f'Train dataset, {le.inverse_transform([idx])[0]}')\n    plt.hist(features_sum, \n             bins=np.linspace(0,features_sum.max(),200),\n             color=plt.cm.get_cmap('tab10', 10)(idx))\n    plt.xlabel('Feature sum')\n    plt.ylabel('Frequence')\n    plt.tight_layout()\n\n    plt.subplot(10,2,2*idx+2)\n    plt.title(f'Test dataset, {le.inverse_transform([idx])[0]}')\n    plt.hist(features_sum_test, \n             bins=np.linspace(0,features_sum.max(),200),\n             color=plt.cm.get_cmap('tab10', 10)(idx), density=True)\n    plt.xlabel('Feature sum')\n    plt.ylabel('Frequence')\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T21:30:36.849121Z","iopub.execute_input":"2022-02-22T21:30:36.849433Z","iopub.status.idle":"2022-02-22T21:30:57.808938Z","shell.execute_reply.started":"2022-02-22T21:30:36.849401Z","shell.execute_reply":"2022-02-22T21:30:57.807949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style='color:#A80808'>GCD=10000</span>","metadata":{}},{"cell_type":"code","source":"gcd = 10000\n\nplt.figure(figsize=(18, 24))\n\nfor idx in range(10):\n    features_sum = train[features][(train['gcd'] == gcd) & (train['target'] == idx)].abs().sum(axis=1)\n    features_sum_test = test[features][(test['gcd'] == gcd) & (test['target'] == idx)].abs().sum(axis=1)\n    \n    plt.subplot(10,2,2*idx+1)\n    plt.title(f'Train dataset, {le.inverse_transform([idx])[0]}')\n    plt.hist(features_sum, \n             bins=np.linspace(0,features_sum.max(),200),\n             color=plt.cm.get_cmap('tab10', 10)(idx))\n    plt.xlabel('Feature sum')\n    plt.ylabel('Frequence')\n    plt.tight_layout()\n\n    plt.subplot(10,2,2*idx+2)\n    plt.title(f'Test dataset, {le.inverse_transform([idx])[0]}')\n    plt.hist(features_sum_test, \n             bins=np.linspace(0,features_sum.max(),200),\n             color=plt.cm.get_cmap('tab10', 10)(idx), density=True)\n    plt.xlabel('Feature sum')\n    plt.ylabel('Frequence')\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T21:30:57.810942Z","iopub.execute_input":"2022-02-22T21:30:57.811231Z","iopub.status.idle":"2022-02-22T21:31:18.459118Z","shell.execute_reply.started":"2022-02-22T21:30:57.811199Z","shell.execute_reply":"2022-02-22T21:31:18.458481Z"},"trusted":true},"execution_count":null,"outputs":[]}]}