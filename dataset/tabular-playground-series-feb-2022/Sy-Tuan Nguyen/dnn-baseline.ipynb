{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Goal\n\nThis notebook provides a baseline for solving the present problem using DNN. There are a lot of room to grow. So play with it and have fun ^_^\n\nIf you like this, plz **upvote** to give me some motivation to continue.\n\n\n### Versions\n\nversion 1: consider 5 folds, run just the first fold using optimizer RMSprop, 200 epochs\n\nversion 2: add some comments, reduce the learning_rate to have a smoother learning curve\n\nversion 3: increase to 1000 epochs, hope that we can reach to a stable CV of 0.99x\n\nversion 4: consider updated dataset with removed duplicates to rebalance the folds\n\nversion 7: CV 5 folds\n\nversion 9: correct data duplicated issue","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:50:44.936237Z","iopub.execute_input":"2022-02-05T15:50:44.936773Z","iopub.status.idle":"2022-02-05T15:50:53.088103Z","shell.execute_reply.started":"2022-02-05T15:50:44.93668Z","shell.execute_reply":"2022-02-05T15:50:53.087293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reproducibility\nSEED=2022\nnp.random.seed(SEED)\nrandom.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:50:53.089889Z","iopub.execute_input":"2022-02-05T15:50:53.090212Z","iopub.status.idle":"2022-02-05T15:50:53.100836Z","shell.execute_reply.started":"2022-02-05T15:50:53.090167Z","shell.execute_reply":"2022-02-05T15:50:53.100082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"# Consider light version of the dataset to gain some memory and speed\n# see https://www.kaggle.com/sytuannguyen/avoid-oom-issues-with-pickle\ntrain = pd.read_pickle('../input/tpsfeb2022-ds-to-pickle-with-folds/train.pkl')\nprint(train.shape)\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:50:53.102506Z","iopub.execute_input":"2022-02-05T15:50:53.104453Z","iopub.status.idle":"2022-02-05T15:50:57.616879Z","shell.execute_reply.started":"2022-02-05T15:50:53.104423Z","shell.execute_reply":"2022-02-05T15:50:57.616113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [col for col in train.columns if 'A' in col]\n\n# Encode the labels\nlb = LabelEncoder()\ntrain.target = lb.fit_transform(train.target)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:50:57.618051Z","iopub.execute_input":"2022-02-05T15:50:57.618461Z","iopub.status.idle":"2022-02-05T15:50:57.661189Z","shell.execute_reply.started":"2022-02-05T15:50:57.618423Z","shell.execute_reply":"2022-02-05T15:50:57.660507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = pd.read_pickle('../input/tpsfeb2022-ds-to-pickle-with-folds/test.pkl')\nX_test.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:50:57.663583Z","iopub.execute_input":"2022-02-05T15:50:57.663842Z","iopub.status.idle":"2022-02-05T15:50:59.950358Z","shell.execute_reply.started":"2022-02-05T15:50:57.663807Z","shell.execute_reply":"2022-02-05T15:50:59.94968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# Baseline ANN model\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.Dense(512, activation='relu', input_shape=(286,)))\nmodel.add(keras.layers.Dense(256, activation='relu'))\nmodel.add(keras.layers.Dense(10, activation='softmax')) # softmax is appropriate for multi classification","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-05T15:51:01.53854Z","iopub.status.idle":"2022-02-05T15:51:01.539083Z","shell.execute_reply.started":"2022-02-05T15:51:01.538847Z","shell.execute_reply":"2022-02-05T15:51:01.538874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:51:01.540211Z","iopub.status.idle":"2022-02-05T15:51:01.540776Z","shell.execute_reply.started":"2022-02-05T15:51:01.540544Z","shell.execute_reply":"2022-02-05T15:51:01.540569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = 0.0005\nmodel.compile(optimizer=keras.optimizers.RMSprop(learning_rate=LR), # try also other optimizers such as Adam, SGD, etc.\n             loss='categorical_crossentropy', # this loss function is appropriate for multi classification\n             metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:51:01.541868Z","iopub.status.idle":"2022-02-05T15:51:01.542434Z","shell.execute_reply.started":"2022-02-05T15:51:01.542179Z","shell.execute_reply":"2022-02-05T15:51:01.542205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\nEPOCHS=1000\nBATCH_SIZE=1024\n\nearly_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=5) # stop the model if it cannot improve after 5 epochs","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-05T15:51:01.543494Z","iopub.status.idle":"2022-02-05T15:51:01.544014Z","shell.execute_reply.started":"2022-02-05T15:51:01.543788Z","shell.execute_reply":"2022-02-05T15:51:01.543814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choose a fold to train and validation\npreds=[]\nfor FOLD in [0.0,1.0,2.0,3.0,4.0]:\n    print(f'Fold: {FOLD}')\n    X_train = train[features][train['5_folds'] != FOLD] # try also 10 folds, 20 folds\n    X_val   = train[features][train['5_folds'] == FOLD]\n    y_train = train['target'][train['5_folds'] != FOLD]\n    y_val   = train['target'][train['5_folds'] == FOLD]\n\n    \n    # Transform labels to categories\n    y_train = to_categorical(y_train)\n    y_val = to_categorical(y_val)\n\n    checkpoint = keras.callbacks.ModelCheckpoint(f\"ann_{FOLD}\", save_best_only=True) # save best model\n    history=model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[checkpoint, early_stop], verbose=0)\n    \n    print('Max accuracy:', np.max(history.history['accuracy']))\n    preds.append(model.predict(X_test))\n\n    # show the evolution of loss and metrics during the training process\n    plt.figure(figsize=(10,5))\n    plt.plot(history.history['accuracy'], 'k', label='train')\n    plt.plot(history.history['val_accuracy'], 'b', label='val')\n    plt.ylabel('Accuracy', fontsize=16)\n    plt.xlabel('Epochs', fontsize=16)\n    plt.legend(fontsize=16)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:51:01.545081Z","iopub.status.idle":"2022-02-05T15:51:01.545642Z","shell.execute_reply.started":"2022-02-05T15:51:01.545413Z","shell.execute_reply":"2022-02-05T15:51:01.545439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"y_test = np.mean(preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:51:01.546691Z","iopub.status.idle":"2022-02-05T15:51:01.547225Z","shell.execute_reply.started":"2022-02-05T15:51:01.546987Z","shell.execute_reply":"2022-02-05T15:51:01.547013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = lb.inverse_transform(np.argmax(y_test, axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:51:01.54832Z","iopub.status.idle":"2022-02-05T15:51:01.548847Z","shell.execute_reply.started":"2022-02-05T15:51:01.548619Z","shell.execute_reply":"2022-02-05T15:51:01.548644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_pickle('../input/tpsfeb2022-ds-to-pickle-with-folds/sub.pkl')\nsub.target = y_test","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:51:01.5499Z","iopub.status.idle":"2022-02-05T15:51:01.550446Z","shell.execute_reply.started":"2022-02-05T15:51:01.550202Z","shell.execute_reply":"2022-02-05T15:51:01.550234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the distribution of the classes\n# hint: you may want to some postprocessing technique to rebalance the classes to make it consistent with the train set.\ntarget_df = pd.DataFrame((sub.target.value_counts().sort_index())).reset_index()\ntarget_df.columns = ['target', 'count']\nfig = px.bar(data_frame = target_df, \n             x = 'target',\n             y = 'count' , \n             color = \"count\",\n             color_continuous_scale=\"Emrld\") \nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:51:01.551503Z","iopub.status.idle":"2022-02-05T15:51:01.552031Z","shell.execute_reply.started":"2022-02-05T15:51:01.551805Z","shell.execute_reply":"2022-02-05T15:51:01.551829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:51:01.553071Z","iopub.status.idle":"2022-02-05T15:51:01.553729Z","shell.execute_reply.started":"2022-02-05T15:51:01.553465Z","shell.execute_reply":"2022-02-05T15:51:01.553494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}