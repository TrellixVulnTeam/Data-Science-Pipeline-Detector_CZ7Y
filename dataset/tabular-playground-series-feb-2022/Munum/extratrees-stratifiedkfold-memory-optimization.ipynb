{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> Shoutout to Maxence Fuzellier and his project \"TPS-Feb22 | ðŸ“Š EDA + ðŸ“ˆ ExtraTrees\" for the idea of sampling the data and using mode to find best bacteria type!\n\n\n\n> Also, a big thanks to AMBROSM and his project \"TPSFEB22-02 Postprocessing against the mutants ðŸ’€\" for the idea of using the probabilities!","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T14:15:43.267377Z","iopub.execute_input":"2022-02-03T14:15:43.268356Z","iopub.status.idle":"2022-02-03T14:15:44.611291Z","shell.execute_reply.started":"2022-02-03T14:15:43.268219Z","shell.execute_reply":"2022-02-03T14:15:44.610464Z"}}},{"cell_type":"code","source":"!pip install scikit-learn-intelex\nfrom sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:38:33.369229Z","iopub.execute_input":"2022-02-03T19:38:33.369663Z","iopub.status.idle":"2022-02-03T19:39:13.688628Z","shell.execute_reply.started":"2022-02-03T19:38:33.369536Z","shell.execute_reply":"2022-02-03T19:39:13.687295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom scipy.stats import mode\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nKAGGLE_DIR = r'../input/tabular-playground-series-feb-2022/'\nLOCAL_DIR = r''\nKAGGLE = True\nRS = 69","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:39:22.781453Z","iopub.execute_input":"2022-02-03T19:39:22.781983Z","iopub.status.idle":"2022-02-03T19:39:22.789661Z","shell.execute_reply.started":"2022-02-03T19:39:22.781931Z","shell.execute_reply":"2022-02-03T19:39:22.788752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:39:52.011522Z","iopub.execute_input":"2022-02-03T19:39:52.011863Z","iopub.status.idle":"2022-02-03T19:39:52.028287Z","shell.execute_reply.started":"2022-02-03T19:39:52.011817Z","shell.execute_reply":"2022-02-03T19:39:52.027232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif KAGGLE:\n    print(f\"{'*'*10} Loading Training Data... {'*'*10}\")\n    train = pd.read_csv(KAGGLE_DIR+'train.csv', index_col=0).pipe(reduce_mem_usage)\n    print(f\"{'*'*10} Loading Testing Data... {'*'*10}\")\n    test = pd.read_csv(KAGGLE_DIR+'test.csv', index_col=0).pipe(reduce_mem_usage)\n    sub = pd.read_csv(KAGGLE_DIR+'sample_submission.csv').pipe(reduce_mem_usage)\nelse:\n    print(f\"{'*'*10} Loading Training Data... {'*'*10}\")\n    train = pd.read_csv(LOCAL_DIR+'train.csv', index_col=0).pipe(reduce_mem_usage)\n    print(f\"{'*'*10} Loading Testing Data... {'*'*10}\")\n    test = pd.read_csv(LOCAL_DIR+'test.csv', index_col=0).pipe(reduce_mem_usage)\n    sub = pd.read_csv(LOCAL_DIR+'sample_submission.csv').pipe(reduce_mem_usage)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:39:52.70871Z","iopub.execute_input":"2022-02-03T19:39:52.709082Z","iopub.status.idle":"2022-02-03T19:41:11.722705Z","shell.execute_reply.started":"2022-02-03T19:39:52.709045Z","shell.execute_reply":"2022-02-03T19:41:11.721511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_encoder = LabelEncoder()\ntrain[\"target\"] = target_encoder.fit_transform(train[\"target\"])\n\nX = train.drop([\"target\"], axis=1)\ny = train[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:41:31.918508Z","iopub.execute_input":"2022-02-03T19:41:31.918824Z","iopub.status.idle":"2022-02-03T19:41:32.363991Z","shell.execute_reply.started":"2022-02-03T19:41:31.918791Z","shell.execute_reply":"2022-02-03T19:41:32.362634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"y_probs = []\nscores = []\n\nfolds = StratifiedKFold(n_splits=10, shuffle=True)\n\nestimators = 2100\nfor fold, (train_id, test_id) in enumerate(folds.split(X, y)):  \n    X_train = X.iloc[train_id]\n    y_train = y.iloc[train_id]\n    X_valid = X.iloc[test_id]\n    y_valid = y.iloc[test_id]\n    \n    model = ExtraTreesClassifier(\n        n_estimators=estimators,\n        n_jobs=-1\n    )\n\n    model.fit(X_train, y_train)\n    \n    valid_pred = model.predict(X_valid)\n    valid_score = accuracy_score(y_valid, valid_pred)\n    \n    print(\"Fold:\", fold + 1, \"Accuracy:\", valid_score)\n    \n    scores.append(valid_score)\n    \n    # Save predictions to later submit the mean values\n    #if submission: \n    y_probs.append(model.predict_proba(test))\n    \n    estimators = estimators + 75","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:43:28.784583Z","iopub.execute_input":"2022-02-03T19:43:28.784909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Mean accuracy score:\", np.array(scores).mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob = sum(y_probs) / len(y_probs)\n# The explanations for these numbers are in AMBROSM's code\ny_prob += np.array([0, 0, 0.01, 0.03, 0, 0, 0, 0, 0, 0])\ny_pred_tuned = target_encoder.inverse_transform(np.argmax(y_prob, axis=1))\npd.Series(y_pred_tuned, index=test.index).value_counts().sort_index() / len(test) * 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submitting results","metadata":{}},{"cell_type":"code","source":"sub[\"target\"] = y_pred_tuned\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}