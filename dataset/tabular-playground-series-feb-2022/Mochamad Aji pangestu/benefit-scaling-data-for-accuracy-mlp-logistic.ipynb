{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.utils import np_utils\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n\nfrom matplotlib import pyplot as plt\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-05T05:24:46.692946Z","iopub.execute_input":"2022-03-05T05:24:46.6933Z","iopub.status.idle":"2022-03-05T05:24:46.703159Z","shell.execute_reply.started":"2022-03-05T05:24:46.693265Z","shell.execute_reply":"2022-03-05T05:24:46.70197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T05:24:54.236673Z","iopub.execute_input":"2022-03-05T05:24:54.237527Z","iopub.status.idle":"2022-03-05T05:25:11.304773Z","shell.execute_reply.started":"2022-03-05T05:24:54.237479Z","shell.execute_reply":"2022-03-05T05:25:11.303671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:19:33.588029Z","iopub.execute_input":"2022-03-02T16:19:33.588244Z","iopub.status.idle":"2022-03-02T16:19:33.59687Z","shell.execute_reply.started":"2022-03-02T16:19:33.588218Z","shell.execute_reply":"2022-03-02T16:19:33.595815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:19:33.598507Z","iopub.execute_input":"2022-03-02T16:19:33.598982Z","iopub.status.idle":"2022-03-02T16:19:33.641104Z","shell.execute_reply.started":"2022-03-02T16:19:33.598923Z","shell.execute_reply":"2022-03-02T16:19:33.640288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes[df.dtypes == 'category']","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:35:53.940021Z","iopub.execute_input":"2022-03-02T16:35:53.940609Z","iopub.status.idle":"2022-03-02T16:35:53.949585Z","shell.execute_reply.started":"2022-03-02T16:35:53.940569Z","shell.execute_reply":"2022-03-02T16:35:53.948556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop('row_id', axis = 1)\ndf['target'] = df['target'].astype('category')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T05:25:11.306521Z","iopub.execute_input":"2022-03-05T05:25:11.306754Z","iopub.status.idle":"2022-03-05T05:25:11.526412Z","shell.execute_reply.started":"2022-03-05T05:25:11.306723Z","shell.execute_reply":"2022-03-05T05:25:11.525793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:19:34.101247Z","iopub.execute_input":"2022-03-02T16:19:34.101503Z","iopub.status.idle":"2022-03-02T16:19:34.129611Z","shell.execute_reply.started":"2022-03-02T16:19:34.101473Z","shell.execute_reply":"2022-03-02T16:19:34.128612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:25:46.380985Z","iopub.execute_input":"2022-03-02T16:25:46.381298Z","iopub.status.idle":"2022-03-02T16:25:46.525875Z","shell.execute_reply.started":"2022-03-02T16:25:46.381268Z","shell.execute_reply":"2022-03-02T16:25:46.52498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['target'].value_counts().plot(kind = 'bar')","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:26:10.76645Z","iopub.execute_input":"2022-03-02T16:26:10.766706Z","iopub.status.idle":"2022-03-02T16:26:11.091998Z","shell.execute_reply.started":"2022-03-02T16:26:10.766675Z","shell.execute_reply":"2022-03-02T16:26:11.090959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(df, scale = False):\n    X = df.copy().drop('target', axis=1)\n    y = df.copy().pop('target')\n    \n    \n    if scale == True:\n        min_max_scaler = preprocessing.MinMaxScaler().fit(X)\n        X = min_max_scaler.transform(X)\n    \n    return X, y\n\n\ndef get_data_nn(df, scale = False):\n    X = df.copy().drop('target', axis=1)\n    y = df.copy().pop('target')\n\n    encoder = LabelEncoder()\n    y = encoder.fit_transform(y)\n\n    dummy_y = np_utils.to_categorical(y)\n    \n    if scale == True:\n        min_max_scaler = preprocessing.MinMaxScaler().fit(X)\n        X = min_max_scaler.transform(X)\n    else:\n        X = X.values\n        \n    return X, y, dummy_y\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T05:25:11.527355Z","iopub.execute_input":"2022-03-05T05:25:11.528129Z","iopub.status.idle":"2022-03-05T05:25:11.536203Z","shell.execute_reply.started":"2022-03-05T05:25:11.52809Z","shell.execute_reply":"2022-03-05T05:25:11.53554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = get_data(df)\n\nmodel = LogisticRegression(solver='liblinear')\n\nresult = cross_val_score(model, X, y)\n\nprint('Accuracy : {}'.format(result.mean()))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:54:04.71241Z","iopub.execute_input":"2022-03-02T16:54:04.712775Z","iopub.status.idle":"2022-03-02T16:55:48.117979Z","shell.execute_reply.started":"2022-03-02T16:54:04.712735Z","shell.execute_reply":"2022-03-02T16:55:48.117186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef create_nn(input_dim, output_dim):\n    model_nn = Sequential()\n    model_nn.add(Dense(256, input_dim = input_dim, activation='relu'))\n    model_nn.add(Dropout(0.2))\n    model_nn.add(Dense(512, activation = 'relu'))\n    model_nn.add(Dropout(0.2))\n    model_nn.add(Dense(output_dim, activation='softmax'))\n    opt = keras.optimizers.Adam(learning_rate = 0.0001)\n    model_nn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model_nn","metadata":{"execution":{"iopub.status.busy":"2022-03-05T05:24:41.132064Z","iopub.execute_input":"2022-03-05T05:24:41.132824Z","iopub.status.idle":"2022-03-05T05:24:41.142985Z","shell.execute_reply.started":"2022-03-05T05:24:41.132776Z","shell.execute_reply":"2022-03-05T05:24:41.140895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y, dummy_y= get_data_nn(df)\n\ninput_dim = len(X[0])\noutput_dim = 10\n\nkfold = StratifiedKFold()\nresult1 = []\n\nfold_no = 0\n\nfor idx_train, idx_test in kfold.split(X, y):\n    model_nn = create_nn(input_dim, output_dim)\n    history_model_nn = model_nn.fit(X[idx_train]\n              ,dummy_y[idx_train]\n              ,epochs=20\n              ,batch_size=256\n              ,verbose = 0)\n\n    score = model_nn.evaluate(X[idx_test], dummy_y[idx_test], verbose = 0)\n    result1.append(score[1]*100)\n\nprint('Accuracy : {}'.format(np.array(result1).mean()))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T05:26:17.241644Z","iopub.execute_input":"2022-03-05T05:26:17.242598Z","iopub.status.idle":"2022-03-05T05:35:02.134681Z","shell.execute_reply.started":"2022-03-05T05:26:17.242528Z","shell.execute_reply":"2022-03-05T05:35:02.132933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-05T05:42:32.583111Z","iopub.execute_input":"2022-03-05T05:42:32.583898Z","iopub.status.idle":"2022-03-05T05:42:32.590502Z","shell.execute_reply.started":"2022-03-05T05:42:32.58385Z","shell.execute_reply":"2022-03-05T05:42:32.589687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = get_data(df, scale = True)\n\nmodel2 = LogisticRegression(solver='liblinear')\n\nresult = cross_val_score(model2, X, y)\n\nprint('Accuracy : {}'.format(result.mean()))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T04:36:11.222981Z","iopub.execute_input":"2022-03-05T04:36:11.22374Z","iopub.status.idle":"2022-03-05T04:49:41.177378Z","shell.execute_reply.started":"2022-03-05T04:36:11.223688Z","shell.execute_reply":"2022-03-05T04:49:41.175781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y, dummy_y= get_data_nn(df, scale = True)\n\ninput_dim = len(X[0])\noutput_dim = 10\n\nkfold = StratifiedKFold()\nresult2 = []\n\nfold_no = 0\n\nfor idx_train, idx_test in kfold.split(X, y):\n    model2_nn = create_nn(input_dim, output_dim)\n    history_model2_nn = model2_nn.fit(X[idx_train]\n              ,dummy_y[idx_train]\n              ,epochs=20\n              ,batch_size=256\n              ,verbose = 0)\n\n    score = model2_nn.evaluate(X[idx_test], dummy_y[idx_test], verbose = 0)\n    result2.append(score[1]*100)\n\nprint('Accuracy : {}'.format(np.array(result2).mean()))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:08:04.251179Z","iopub.execute_input":"2022-03-05T03:08:04.251826Z","iopub.status.idle":"2022-03-05T03:08:05.937475Z","shell.execute_reply.started":"2022-03-05T03:08:04.251753Z","shell.execute_reply":"2022-03-05T03:08:05.936607Z"},"trusted":true},"execution_count":null,"outputs":[]}]}