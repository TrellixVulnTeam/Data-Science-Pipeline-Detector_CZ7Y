{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# IntelÂ® Extension for Scikit-learn installation:\n!pip install scikit-learn-intelex\n\nimport pandas as pd\nimport numpy as np\nfrom math import factorial\nfrom numpy import mean, std, asarray, vstack, hstack\n\nimport random\nimport time\nimport os\nfrom pathlib import Path\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, KFold, train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom scipy.stats import mode\nimport lightgbm as lgb\n\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:35:33.363629Z","iopub.execute_input":"2022-02-18T21:35:33.364438Z","iopub.status.idle":"2022-02-18T21:36:14.238332Z","shell.execute_reply.started":"2022-02-18T21:35:33.364167Z","shell.execute_reply":"2022-02-18T21:36:14.236668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Memory Optimization - Credit to @munumbutt**\n https://www.kaggle.com/munumbutt/extratrees-stratifiedkfold-memory-optimization","metadata":{}},{"cell_type":"code","source":"\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:36:14.240728Z","iopub.execute_input":"2022-02-18T21:36:14.241082Z","iopub.status.idle":"2022-02-18T21:36:14.256032Z","shell.execute_reply.started":"2022-02-18T21:36:14.241046Z","shell.execute_reply":"2022-02-18T21:36:14.254741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Removing duplicated rows with adapting the sample weight - Credit to @ambrosm**\nhttps://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants#Deduplicating-the-training-data","metadata":{}},{"cell_type":"code","source":"print(f\"{'*'*10} Loading Training Data... {'*'*10}\")\ntrain_df = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv', index_col=\"row_id\")#.pipe(reduce_mem_usage)\nprint(f\"{'*'*10} Loading Testing Data... {'*'*10}\")\ntest_df = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv', index_col=\"row_id\")#.pipe(reduce_mem_usage)\nsubmission_df = pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')#.pipe(reduce_mem_usage)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:36:14.257371Z","iopub.execute_input":"2022-02-18T21:36:14.257588Z","iopub.status.idle":"2022-02-18T21:36:54.094947Z","shell.execute_reply.started":"2022-02-18T21:36:14.257558Z","shell.execute_reply":"2022-02-18T21:36:54.093459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the duplicates in the training data\nf\"There is {train_df.duplicated().sum()} duplciated rows\"","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:36:54.096898Z","iopub.execute_input":"2022-02-18T21:36:54.097095Z","iopub.status.idle":"2022-02-18T21:36:55.859642Z","shell.execute_reply.started":"2022-02-18T21:36:54.097072Z","shell.execute_reply":"2022-02-18T21:36:55.8587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new df w/o duplicates, but with additional sample_weight column\nvalue_count = train_df.value_counts() # counts of unique values\ndedup_train_df = pd.DataFrame([list(tup) for tup in value_count.index.values], columns = train_df.columns)\ndedup_train_df[\"sample_weight\"] = value_count.values","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:36:55.861432Z","iopub.execute_input":"2022-02-18T21:36:55.861684Z","iopub.status.idle":"2022-02-18T21:37:08.610551Z","shell.execute_reply.started":"2022-02-18T21:36:55.86165Z","shell.execute_reply":"2022-02-18T21:37:08.609708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dedup_train_df.shape)\ndedup_train_df","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:08.611573Z","iopub.execute_input":"2022-02-18T21:37:08.611853Z","iopub.status.idle":"2022-02-18T21:37:08.671126Z","shell.execute_reply.started":"2022-02-18T21:37:08.611827Z","shell.execute_reply":"2022-02-18T21:37:08.670046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Define Feature Columns**","metadata":{}},{"cell_type":"markdown","source":"### **Adding Bias feature - Credit to Ambrosm**\n don't hesitate to upvote original content https://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense","metadata":{}},{"cell_type":"code","source":"features =[e for e in dedup_train_df.columns if e != 'row_id' and e != 'target' and e!='target_num' and e!='sample_weight']","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:08.672396Z","iopub.execute_input":"2022-02-18T21:37:08.672697Z","iopub.status.idle":"2022-02-18T21:37:08.679184Z","shell.execute_reply.started":"2022-02-18T21:37:08.672659Z","shell.execute_reply":"2022-02-18T21:37:08.677632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bias(w, x, y, z):\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ndef bias_of(s):\n    w = int(s[1:s.index('T')])\n    x = int(s[s.index('T')+1:s.index('G')])\n    y = int(s[s.index('G')+1:s.index('C')])\n    z = int(s[s.index('C')+1:])\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:08.680415Z","iopub.execute_input":"2022-02-18T21:37:08.680605Z","iopub.status.idle":"2022-02-18T21:37:08.699507Z","shell.execute_reply.started":"2022-02-18T21:37:08.680582Z","shell.execute_reply":"2022-02-18T21:37:08.698098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_i = pd.DataFrame({col: ((dedup_train_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in features})\ntest_i = pd.DataFrame({col: ((test_df[col] + bias_of(col)) * 1000000).round().astype(int) for col in features})","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:08.701218Z","iopub.execute_input":"2022-02-18T21:37:08.7016Z","iopub.status.idle":"2022-02-18T21:37:09.359818Z","shell.execute_reply.started":"2022-02-18T21:37:08.701568Z","shell.execute_reply":"2022-02-18T21:37:09.359183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding GCD feature\nhttps://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense","metadata":{}},{"cell_type":"code","source":"def gcd_of_all(df_i):\n    \"\"\"\n    adding Greatest Common Divisor for every target. Every target are multiplier of 10, 100, 1000, etc.\n    \"\"\"\n    gcd = df_i[features[0]]\n    for col in features[1:]:\n        gcd = np.gcd(gcd, df_i[col])\n    return gcd\n\ndedup_train_df['gcd'] = gcd_of_all(train_i)\ntest_df['gcd'] = gcd_of_all(test_i)\nnp.unique(dedup_train_df['gcd'], return_counts=True), np.unique(test_df['gcd'], return_counts=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:09.362379Z","iopub.execute_input":"2022-02-18T21:37:09.362674Z","iopub.status.idle":"2022-02-18T21:37:10.005127Z","shell.execute_reply.started":"2022-02-18T21:37:09.362643Z","shell.execute_reply":"2022-02-18T21:37:10.004293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dedup_train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.006186Z","iopub.execute_input":"2022-02-18T21:37:10.006491Z","iopub.status.idle":"2022-02-18T21:37:10.027763Z","shell.execute_reply.started":"2022-02-18T21:37:10.006467Z","shell.execute_reply":"2022-02-18T21:37:10.026354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"dedup_train_df shape :\", dedup_train_df.shape)\nprint(\"test_df shape :\", test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.02931Z","iopub.execute_input":"2022-02-18T21:37:10.029542Z","iopub.status.idle":"2022-02-18T21:37:10.047496Z","shell.execute_reply.started":"2022-02-18T21:37:10.029512Z","shell.execute_reply":"2022-02-18T21:37:10.046034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dedup_train_df.groupby([\"gcd\",\"target\"]).size()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.04933Z","iopub.execute_input":"2022-02-18T21:37:10.04997Z","iopub.status.idle":"2022-02-18T21:37:10.088282Z","shell.execute_reply.started":"2022-02-18T21:37:10.049927Z","shell.execute_reply":"2022-02-18T21:37:10.087088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **The distribution appears to be similar**","metadata":{}},{"cell_type":"markdown","source":"# **Model**","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:48:45.500525Z","iopub.execute_input":"2022-02-02T16:48:45.501051Z","iopub.status.idle":"2022-02-02T16:48:45.572787Z","shell.execute_reply.started":"2022-02-02T16:48:45.500998Z","shell.execute_reply":"2022-02-02T16:48:45.57195Z"}}},{"cell_type":"markdown","source":"## **Encoding**","metadata":{}},{"cell_type":"code","source":"target = train_df.columns.difference(test_df.columns)[0]\nfeatures += [\"gcd\"] \nle = LabelEncoder()\nX = dedup_train_df[features]\ny = le.fit_transform(\n    dedup_train_df[target])\nsample_weight = dedup_train_df[\"sample_weight\"]\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.090266Z","iopub.execute_input":"2022-02-18T21:37:10.090538Z","iopub.status.idle":"2022-02-18T21:37:10.217125Z","shell.execute_reply.started":"2022-02-18T21:37:10.090513Z","shell.execute_reply":"2022-02-18T21:37:10.216291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **SUPER LEARNER ENSEMBLE** - Credit to @remekkinas\nhttps://www.kaggle.com/remekkinas/super-learner-ensemble-extree-tuned-lda-umap#STARTING-MODEL","metadata":{}},{"cell_type":"code","source":"def get_models():\n    models = {}\n    \n    models['ExtraTreesClassifier'] = ExtraTreesClassifier(\n        n_estimators=N_ESTIMATORS,\n        n_jobs=-1,\n        random_state=SEED,\n        verbose=VERBOSE,\n        max_depth = MAX_DEPTH,\n        min_samples_split = MIN_SAMPLES_SPLIT,\n        min_samples_leaf  = MIN_SAMPLES_LEAF,\n        criterion = CRITERION\n    )\n\n    models['RandomForestClassifier'] = RandomForestClassifier(n_estimators= 200)\n    return models","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.218181Z","iopub.execute_input":"2022-02-18T21:37:10.21834Z","iopub.status.idle":"2022-02-18T21:37:10.22433Z","shell.execute_reply.started":"2022-02-18T21:37:10.218319Z","shell.execute_reply":"2022-02-18T21:37:10.223291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_out_of_fold_predictions(X, y, models) :\n    meta_X, meta_y = list(), list()\n    kfold = KFold(n_splits = N_SPLITS, shuffle = True)\n    print(\" ** START OFF PREDICTIONS for base models ** \")\n    for fold_id, (train_ix, test_ix) in enumerate(kfold.split(X)) :\n        print(f\" FOLD : {fold_id+1}\")\n        fold_yhats = list()\n        train_X = X[train_ix]\n        test_X  = X[test_ix]  \n        train_y = y[train_ix]\n        test_y  = y[test_ix]\n        meta_y.extend(test_y)\n        \n        for name, model in models.items():\n            # Model Training\n            model.fit(train_X, train_y)\n            yhat = model.predict_proba(test_X)    # give the probabilities for each # class \n            fold_yhats.append(yhat)\n            \n            # Model Validation\n            yhat_eval = model.predict(test_X)\n            \n            # Score\n            score = accuracy_score(test_y, yhat_eval)\n            print( '\\t %s: %.5f' %(name, score))\n        \n        meta_X.append(hstack(fold_yhats))    # stack horizontally\n    return vstack(meta_X), asarray(meta_y)\n\ndef fit_base_models(X, y, models) :\n    print(\" ** START - Fitting base models ** \")\n    for name, model in models.items():\n        print(f\" Fitting model -{name}\")\n        model.fit(X, y)\n    print(\" ** FINISH - Fitting base models ** \")\n\ndef fit_meta_model(X, y):\n    print(\" ** START - Fitting meta models ** \")\n    model = LogisticRegression(solver = 'liblinear')\n    model.fit(X, y)\n    print(\" ** FINISH - Fitting meta models ** \")\n    return model\n\ndef evaluate_models(X, y, models):\n    for name, model in models.items():\n        yhat = model.predict(X)\n        score = accuracy_score(y, yhat)\n        print('%s: %.5f' % (model.__class__.__name__, score))\n        \ndef super_learner_predictions(X, models, meta_model):\n    meta_data_X = []\n    for name, model in models.items():\n        yhat = model.predict_proba(X)\n\n        meta_data_X.append(yhat)\n    meta_data_X = hstack(meta_data_X)\n    return meta_model.predict(meta_data_X)\n            \ndef super_learner_predictions_proba(X, models, meta_model):\n    meta_data_X = []\n    for name, model in models.items():\n\n        yhat = model.predict_proba(X)\n        meta_data_X.append(yhat)\n    meta_data_X = hstack(meta_data_X)\n    return meta_model.predict_proba(meta_data_X)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T22:45:39.462272Z","iopub.execute_input":"2022-02-18T22:45:39.463783Z","iopub.status.idle":"2022-02-18T22:45:39.479025Z","shell.execute_reply.started":"2022-02-18T22:45:39.463712Z","shell.execute_reply":"2022-02-18T22:45:39.477722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Parameters**","metadata":{}},{"cell_type":"markdown","source":"### Credits to @cv13j0 for Optuna Optimization, don't hesitate to upvote original work : https://www.kaggle.com/cv13j0/extra-trees-classification-optuna-optimization","metadata":{}},{"cell_type":"code","source":"KAGGLE = True\nN_SPLITS = 10 # 10\nSEED = 42\nN_CLASSES = 10\nN_ESTIMATORS = 100\nMAX_DEPTH = 1500\nif KAGGLE :\n    N_ESTIMATORS = 1000 # 2370 \n    MAX_DEPTH = 3691\n    \n\nMIN_SAMPLES_SPLIT = 3\nMIN_SAMPLES_LEAF = 1\nCRITERION  = 'gini'\nVERBOSE = 0","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.247079Z","iopub.execute_input":"2022-02-18T21:37:10.247347Z","iopub.status.idle":"2022-02-18T21:37:10.269174Z","shell.execute_reply.started":"2022-02-18T21:37:10.247323Z","shell.execute_reply":"2022-02-18T21:37:10.267411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T21:46:17.43856Z","iopub.execute_input":"2022-02-17T21:46:17.43935Z","iopub.status.idle":"2022-02-17T21:46:17.448301Z","shell.execute_reply.started":"2022-02-17T21:46:17.439295Z","shell.execute_reply":"2022-02-17T21:46:17.447338Z"}}},{"cell_type":"code","source":"print(f'target : {target}')\nprint(f'features : {features[0:10]}..')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.270882Z","iopub.execute_input":"2022-02-18T21:37:10.271229Z","iopub.status.idle":"2022-02-18T21:37:10.287743Z","shell.execute_reply.started":"2022-02-18T21:37:10.271185Z","shell.execute_reply":"2022-02-18T21:37:10.286537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X.values, y, test_size=0.10)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.289996Z","iopub.execute_input":"2022-02-18T21:37:10.29025Z","iopub.status.idle":"2022-02-18T21:37:10.940607Z","shell.execute_reply.started":"2022-02-18T21:37:10.290223Z","shell.execute_reply":"2022-02-18T21:37:10.9394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = get_models()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.942182Z","iopub.execute_input":"2022-02-18T21:37:10.942433Z","iopub.status.idle":"2022-02-18T21:37:10.947312Z","shell.execute_reply.started":"2022-02-18T21:37:10.942398Z","shell.execute_reply":"2022-02-18T21:37:10.946017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_X, meta_y = get_out_of_fold_predictions(X_train, y_train, models)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:37:10.949078Z","iopub.execute_input":"2022-02-18T21:37:10.949374Z","iopub.status.idle":"2022-02-18T22:16:47.895321Z","shell.execute_reply.started":"2022-02-18T21:37:10.949339Z","shell.execute_reply":"2022-02-18T22:16:47.893693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_base_models(X_train, y_train, models)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T22:16:47.897372Z","iopub.execute_input":"2022-02-18T22:16:47.897586Z","iopub.status.idle":"2022-02-18T22:21:12.349758Z","shell.execute_reply.started":"2022-02-18T22:16:47.897563Z","shell.execute_reply":"2022-02-18T22:21:12.348193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_model = fit_meta_model(meta_X, meta_y)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T22:43:32.16573Z","iopub.execute_input":"2022-02-18T22:43:32.165997Z","iopub.status.idle":"2022-02-18T22:43:40.391136Z","shell.execute_reply.started":"2022-02-18T22:43:32.16597Z","shell.execute_reply":"2022-02-18T22:43:40.390368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_models(X_val, y_val, models)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T22:43:40.392911Z","iopub.execute_input":"2022-02-18T22:43:40.396027Z","iopub.status.idle":"2022-02-18T22:43:41.497608Z","shell.execute_reply.started":"2022-02-18T22:43:40.395965Z","shell.execute_reply":"2022-02-18T22:43:41.496177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(meta_model)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T22:43:41.499854Z","iopub.execute_input":"2022-02-18T22:43:41.500349Z","iopub.status.idle":"2022-02-18T22:43:41.506872Z","shell.execute_reply.started":"2022-02-18T22:43:41.500316Z","shell.execute_reply":"2022-02-18T22:43:41.505293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat = super_learner_predictions(X_val, models, meta_model)\nscore = accuracy_score(y_val, y_hat)\nprint(\"Super Learner : %.5f\" % score)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T22:45:45.773944Z","iopub.execute_input":"2022-02-18T22:45:45.77423Z","iopub.status.idle":"2022-02-18T22:45:46.945667Z","shell.execute_reply.started":"2022-02-18T22:45:45.774203Z","shell.execute_reply":"2022-02-18T22:45:46.94331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training on full data for final prediction","metadata":{}},{"cell_type":"code","source":"final_models = get_models()\nmeta_X_full, meta_y_full = get_out_of_fold_predictions(X.values, y, final_models)\nfit_base_models(X.values, y, final_models)\nmeta_model_full = fit_meta_model(meta_X_full, meta_y_full)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T23:33:57.05939Z","iopub.execute_input":"2022-02-18T23:33:57.059676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = super_learner_predictions(test_df[features], final_models, meta_model_full)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T20:02:07.647439Z","iopub.status.idle":"2022-02-18T20:02:07.647952Z","shell.execute_reply.started":"2022-02-18T20:02:07.647668Z","shell.execute_reply":"2022-02-18T20:02:07.647697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob = super_learner_predictions_proba(test_df[features], final_models, meta_model_full)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T20:02:07.649883Z","iopub.status.idle":"2022-02-18T20:02:07.650347Z","shell.execute_reply.started":"2022-02-18T20:02:07.650113Z","shell.execute_reply":"2022-02-18T20:02:07.650133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Post Processing**","metadata":{}},{"cell_type":"code","source":"# \"Optimization\" code from https://www.kaggle.com/sfktrkl/tps-feb-2022\n\ntarget_distribution = train_df['target'].value_counts().sort_index() / len(train_df) * 100\ndef get_diff(tune):\n    y_pred_tuned = np.argmax(y_prob + tune, axis=1)\n    return target_distribution - pd.Series(y_pred_tuned).value_counts().sort_index() / len(test_df) * 100\n\ntune = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\ndiff = get_diff(tune)\nwhile abs(diff).max() > 0.1:\n    for i in range(len(diff)):\n        if diff[i] > 0.1:\n            tune[i] += 0.001\n            break\n        if diff[i] < -0.1:\n            tune[i] -= 0.001\n            break\n    diff = get_diff(tune)\n\n# Credits to https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\ny_prob += tune\ny_pred_tuned = le.inverse_transform(np.argmax(y_prob, axis=1))\npd.Series(y_pred_tuned, index=test_df.index).value_counts().sort_index() / len(test_df) * 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Submission**","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.target = y_pred_tuned\nsub.to_csv(\"sl-tuned-submission.csv\", index=False)\nsub.head(10)\n\nsub.target = le.inverse_transform(preds)\nsub.to_csv(\"sl-base-submission.csv\", index=False)\nsub.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" --------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# **Post Processing**","metadata":{}},{"cell_type":"markdown","source":"# Majority vote\ny_pred = mode(y_preds_list).mode[0]\ny_pred = le.inverse_transform(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T15:50:50.10094Z","iopub.execute_input":"2022-02-13T15:50:50.101783Z","iopub.status.idle":"2022-02-13T15:50:53.482588Z","shell.execute_reply.started":"2022-02-13T15:50:50.101746Z","shell.execute_reply":"2022-02-13T15:50:53.481594Z"}}},{"cell_type":"markdown","source":"\ny_preds_list, y_proba_list, scores = [],[],[]\nskf = StratifiedKFold(n_splits = N_SPLITS, shuffle = True, random_state = SEED)\n\nfor fold, (train_i, val_i) in enumerate(tqdm(skf.split(X, y), total = N_SPLITS)) :\n    X_train = X.iloc[train_i]\n    y_train = y.iloc[train_i]\n    sample_weight_train = sample_weight.iloc[train_i]\n    \n    X_valid = X.iloc[val_i]\n    y_valid = y.iloc[val_i]\n    sample_weight_valid = sample_weight.iloc[val_i]\n    \n    start = time.time()\n\n    # Model tuning\n    clf =  ExtraTreesClassifier(\n        n_estimators=N_ESTIMATORS,\n        n_jobs=-1,\n        random_state=SEED,\n        verbose=VERBOSE,\n        max_depth = MAX_DEPTH,\n        min_samples_split = MIN_SAMPLES_SPLIT,\n        min_samples_leaf  = MIN_SAMPLES_LEAF,\n        criterion = CRITERION\n    )\n    \n    # Model Training\n    clf.fit(X_train, y_train, sample_weight_train)\n    \n    # Model Validation\n    valid_pred = clf.predict(X_valid)\n    valid_score = accuracy_score(y_valid, valid_pred, \n                                 sample_weight = sample_weight_valid)\n    scores.append(valid_score)\n    \n    # Prediction for submission\n    y_preds_list.append(clf.predict(test_df))\n    y_proba_list.append(clf.predict_proba(test_df))\n    elapsed = time.time() - start\n    print(f'Accuracy score: {valid_score:5f}, elapsed time: {elapsed:.2f}sec \\n')\n    \nscore = np.array(scores).mean()\nprint(f'Mean accuracy score: {score:6f}')   \n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-13T15:34:02.432944Z","iopub.execute_input":"2022-02-13T15:34:02.433214Z","iopub.status.idle":"2022-02-13T15:50:50.097057Z","shell.execute_reply.started":"2022-02-13T15:34:02.433182Z","shell.execute_reply":"2022-02-13T15:50:50.09612Z"}}},{"cell_type":"markdown","source":"target_distrib = pd.DataFrame({\n    'count': train_df.target.value_counts(),\n    'share': train_df[target].value_counts() / train_df.shape[0] * 100\n})\n\ntarget_distrib['pred_count'] = pd.Series(y_pred, index=test_df .index).value_counts()\ntarget_distrib['pred_share'] = target_distrib['pred_count'] / len(test_df) * 100\ntarget_distrib.sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T15:50:53.483866Z","iopub.execute_input":"2022-02-13T15:50:53.484105Z","iopub.status.idle":"2022-02-13T15:50:53.59349Z","shell.execute_reply.started":"2022-02-13T15:50:53.484075Z","shell.execute_reply":"2022-02-13T15:50:53.592579Z"}}},{"cell_type":"markdown","source":"y_proba = sum(y_proba_list) / len(y_proba_list)\ny_proba += np.array([0, 0, 0.01, 0.03, 0, 0, 0, 0, 0, 0])\ny_pred_tuned = le.inverse_transform(np.argmax(y_proba, axis=1))\npd.Series(y_pred_tuned, index=test_df.index).value_counts().sort_index() / len(test_df) * 100","metadata":{"execution":{"iopub.status.busy":"2022-02-13T15:50:53.595104Z","iopub.execute_input":"2022-02-13T15:50:53.595829Z","iopub.status.idle":"2022-02-13T15:50:53.65515Z","shell.execute_reply.started":"2022-02-13T15:50:53.595786Z","shell.execute_reply":"2022-02-13T15:50:53.654546Z"}}},{"cell_type":"markdown","source":"# **Submission**","metadata":{}},{"cell_type":"markdown","source":"submission_df[\"target\"] = y_pred_tuned\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2022-02-13T16:06:14.941983Z","iopub.execute_input":"2022-02-13T16:06:14.942523Z","iopub.status.idle":"2022-02-13T16:06:15.44292Z","shell.execute_reply.started":"2022-02-13T16:06:14.942473Z","shell.execute_reply":"2022-02-13T16:06:15.441051Z"}}}]}