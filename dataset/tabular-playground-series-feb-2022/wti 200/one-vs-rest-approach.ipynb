{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport pyarrow.csv as pv\nimport pyarrow.parquet as pq\n\nimport time\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-02T19:52:27.354649Z","iopub.execute_input":"2022-02-02T19:52:27.355073Z","iopub.status.idle":"2022-02-02T19:52:28.876383Z","shell.execute_reply.started":"2022-02-02T19:52:27.355031Z","shell.execute_reply":"2022-02-02T19:52:28.8755Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n* In this short notebook I demonstrate two things:\n\n    1. How to load the data quickly with **parquet**.\n    2. The **One-vs-Rest** for Multi-Class Classification.\n    \n---","metadata":{}},{"cell_type":"markdown","source":"**1. Parquet**\n\nFirst I load the train data in `csv` format this takes around **16 seconds**. After that I save the dataframe in `parquet` format using `.to_parquet()` method of pandas. In the last step I load the `parquet` data file and this takes less than **1 second**.","metadata":{}},{"cell_type":"code","source":"# Read the csv data. This you have to do just once. \ntrain = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv', index_col='row_id',low_memory=True)\ntest = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv',index_col='row_id', low_memory=True)\n\n# Save the csv file to parquet. This you have to do just once.\ntrain.to_parquet('train_parquet.parquet')\ntest.to_parquet('test_parquet.parquet')\n\n# Read the parquet data.\ntrain_parquet = pd.read_parquet('train_parquet.parquet')\ntest_parquet = pd.read_parquet('test_parquet.parquet')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:47:54.191786Z","iopub.execute_input":"2022-02-02T19:47:54.192283Z","iopub.status.idle":"2022-02-02T19:48:21.069917Z","shell.execute_reply.started":"2022-02-02T19:47:54.192247Z","shell.execute_reply":"2022-02-02T19:48:21.068769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n**2. One-Vs-Rest for Multi-Class Classification**\n\nThe One-vs-Rest strategy splits a multi-class classification into one binary classification problem per class.\n\nOne-vs-rest (OvR for short, also referred to as One-vs-All or OvA) is a heuristic method for using binary classification algorithms for multi-class classification.\n\nIt involves splitting the multi-class dataset into multiple binary classification problems. A binary classifier is then trained on each binary classification problem and predictions are made using the model that is the most confident.\n\nThis approach requires that each model predicts a class membership probability or a probability-like score. The argmax of these scores (class index with the largest score) is then used to predict a class.\n\nOne advantage of this approach is its interpretability. Since each class is represented by one and one classifier only, it is possible to gain knowledge about the class by inspecting its corresponding classifier.\n\nA possible downside of this approach is that it requires one model to be created for each class.\n","metadata":{}},{"cell_type":"code","source":"list_target = list(train_parquet[\"target\"].unique())\nlist_features = [col for col in train_parquet.columns if col != \"target\"]\n\n# generate binary values using get_dummies\ntrain_dummy = pd.get_dummies(train_parquet, columns=[\"target\"], prefix_sep=\"\", prefix=\"\")\n\npred = pd.DataFrame(index=test_parquet.index)\n\nfor target_cat in list_target:\n    X = train_dummy[list_features]\n    y = train_dummy[target_cat]\n    \n    lr = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1)\n\n    lr.fit(X, y)\n    pred[target_cat] = lr.predict_proba(test_parquet)[:,1]\n\npred['target'] = pred[list_target].idxmax(1)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T19:55:47.283016Z","iopub.execute_input":"2022-02-02T19:55:47.28359Z","iopub.status.idle":"2022-02-02T20:45:28.124383Z","shell.execute_reply.started":"2022-02-02T19:55:47.283506Z","shell.execute_reply":"2022-02-02T20:45:28.123161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pred[\"target\"]\nsubmission.to_csv(\"submission.csv\", index=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T20:56:06.0473Z","iopub.execute_input":"2022-02-02T20:56:06.047739Z","iopub.status.idle":"2022-02-02T20:56:06.344453Z","shell.execute_reply.started":"2022-02-02T20:56:06.04769Z","shell.execute_reply":"2022-02-02T20:56:06.343725Z"},"trusted":true},"execution_count":null,"outputs":[]}]}