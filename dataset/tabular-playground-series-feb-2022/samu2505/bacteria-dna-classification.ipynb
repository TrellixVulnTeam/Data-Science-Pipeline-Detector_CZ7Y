{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-03T16:24:57.977623Z","iopub.execute_input":"2022-03-03T16:24:57.977939Z","iopub.status.idle":"2022-03-03T16:24:58.011037Z","shell.execute_reply.started":"2022-03-03T16:24:57.977857Z","shell.execute_reply":"2022-03-03T16:24:58.010192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I'll be starting with tensorflow \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, datasets\n\nfrom tqdm.auto import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:24:58.013239Z","iopub.execute_input":"2022-03-03T16:24:58.013827Z","iopub.status.idle":"2022-03-03T16:25:05.129738Z","shell.execute_reply.started":"2022-03-03T16:24:58.013782Z","shell.execute_reply":"2022-03-03T16:25:05.128716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-feb-2022/train.csv\", index_col=0)\ntest = pd.read_csv(\"../input/tabular-playground-series-feb-2022/test.csv\", index_col=0)\n\nprint(\"Training data shape: \", train.shape)\nprint(\"Test data shape: \", test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:25:05.131802Z","iopub.execute_input":"2022-03-03T16:25:05.132127Z","iopub.status.idle":"2022-03-03T16:25:46.427763Z","shell.execute_reply.started":"2022-03-03T16:25:05.132087Z","shell.execute_reply":"2022-03-03T16:25:46.42637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking available data types\nprint(\"Data types:\\n\", train.dtypes.unique())\n\n# checking for missing data\nprint(\"\\nMissing data in train set:\\n\", np.sum(train.isna().sum()))\nprint(\"\\nMissing data in test set:\\n\", np.sum(test.isna().sum()))\n\n# checking for duplicate values\nprint(\"\\nDuplicate values in train set:\\n\", train.duplicated().sum())\nprint(\"\\nDuplicate values in test set:\\n\", test.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:25:46.429844Z","iopub.execute_input":"2022-03-03T16:25:46.430205Z","iopub.status.idle":"2022-03-03T16:25:49.187536Z","shell.execute_reply.started":"2022-03-03T16:25:46.43016Z","shell.execute_reply":"2022-03-03T16:25:49.186654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, have to deal with duplicate values in the dataset\ntrain_with_duplicates = train.copy()\n\n# drop the duplicate values out of the dataset for both the train and test sets\ntrain.drop_duplicates(keep='first', inplace=True)\n# Dont't temper with the test set.\n# test.drop_duplicates(keep='first', inplace=True)\n\nprint(\"Shape of new training data: \", train.shape)\nprint(\"Checking number of duplicates in new training data: \", train.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:25:49.189655Z","iopub.execute_input":"2022-03-03T16:25:49.189881Z","iopub.status.idle":"2022-03-03T16:25:52.318274Z","shell.execute_reply.started":"2022-03-03T16:25:49.189851Z","shell.execute_reply":"2022-03-03T16:25:52.317077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CHECKING FOR THE DISTRIBUTION OF THE TARGETS FOR BOTH CASES\ndef plot(train, title):\n    plt.figure(figsize=(10, 6))\n    plt.title(title)\n    plt.xticks(rotation=30, ha='right')\n    ax = sns.countplot(x=train['target'], data=train)\n    print(pd.Series(train['target'], index=train.index).value_counts().sort_index() / len(train) * 100)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:25:52.319628Z","iopub.execute_input":"2022-03-03T16:25:52.319908Z","iopub.status.idle":"2022-03-03T16:25:52.327051Z","shell.execute_reply.started":"2022-03-03T16:25:52.31987Z","shell.execute_reply":"2022-03-03T16:25:52.325903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(train, \"Dataset without duplicates\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:25:52.328538Z","iopub.execute_input":"2022-03-03T16:25:52.328771Z","iopub.status.idle":"2022-03-03T16:25:52.833433Z","shell.execute_reply.started":"2022-03-03T16:25:52.328733Z","shell.execute_reply":"2022-03-03T16:25:52.832514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(train_with_duplicates, \"Dataset with duplicates\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:25:52.834731Z","iopub.execute_input":"2022-03-03T16:25:52.834961Z","iopub.status.idle":"2022-03-03T16:25:53.474035Z","shell.execute_reply.started":"2022-03-03T16:25:52.834931Z","shell.execute_reply":"2022-03-03T16:25:53.473054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Next, checking for memory usage \n# print(\"Memory usage(train_with_duplicates): {:5.2f} Mb\".format(train_with_duplicates.memory_usage().sum()/1024**2))\n# print(\"Memory usage(train): {:5.2f} Mb\".format(train.memory_usage().sum()/1024**2))\n\n# Still, the memory usage can be reduced further\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int8', 'int16', 'int32', 'int64', 'float32', 'float64']\n    initial_mem = df.memory_usage().sum()/1024**2\n    \n    for col in df.columns:\n        col_dtype = df[col].dtypes\n        \n        if col_dtype in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_dtype)[:3] == 'int':  \n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n                \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n                    \n    end_mem = df.memory_usage().sum()/1024**2\n    if verbose:\n        print(\"Mem usage decreased to {:5.2f} Mb, ({:4.2f}%)\".format(end_mem, 100*(initial_mem - end_mem)/initial_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:25:53.475505Z","iopub.execute_input":"2022-03-03T16:25:53.47589Z","iopub.status.idle":"2022-03-03T16:25:53.491255Z","shell.execute_reply.started":"2022-03-03T16:25:53.475845Z","shell.execute_reply":"2022-03-03T16:25:53.490136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reducing memory usage for the dataset without duplicates\nprint(\"New memory usage for train set\")\ntrain = reduce_mem_usage(train)\n\nprint(\"New memory usage for test set\")\ntest = reduce_mem_usage(test)\n# Reducing memory usage for the dataset with duplicates\n# train_with_duplicates = reduce_mem_usage(train_with_duplicates)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:25:53.492786Z","iopub.execute_input":"2022-03-03T16:25:53.493047Z","iopub.status.idle":"2022-03-03T16:26:17.64422Z","shell.execute_reply.started":"2022-03-03T16:25:53.492994Z","shell.execute_reply":"2022-03-03T16:26:17.642862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, we can separate the features from the targets\nfeatures = train.columns[:-1]\ntarget = 'target'\n\nprint(\"# of features: \", len(features))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:17.646145Z","iopub.execute_input":"2022-03-03T16:26:17.64641Z","iopub.status.idle":"2022-03-03T16:26:17.653977Z","shell.execute_reply.started":"2022-03-03T16:26:17.646376Z","shell.execute_reply":"2022-03-03T16:26:17.653071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Target encoding, that is turn the bacteria into numeric labels\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ntrain[target] = encoder.fit_transform(train[target])\n\n# sample_weight = train.value_counts().values","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:17.657791Z","iopub.execute_input":"2022-03-03T16:26:17.658096Z","iopub.status.idle":"2022-03-03T16:26:17.835611Z","shell.execute_reply.started":"2022-03-03T16:26:17.65806Z","shell.execute_reply":"2022-03-03T16:26:17.834491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the features\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(train_with_duplicates[features])\nscaled_data = pd.DataFrame(scaled_data, columns=features)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:17.837531Z","iopub.execute_input":"2022-03-03T16:26:17.838066Z","iopub.status.idle":"2022-03-03T16:26:19.628737Z","shell.execute_reply.started":"2022-03-03T16:26:17.837997Z","shell.execute_reply":"2022-03-03T16:26:19.628084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = scaler.fit_transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:19.629961Z","iopub.execute_input":"2022-03-03T16:26:19.630626Z","iopub.status.idle":"2022-03-03T16:26:20.233282Z","shell.execute_reply.started":"2022-03-03T16:26:19.630592Z","shell.execute_reply":"2022-03-03T16:26:20.232234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:20.234898Z","iopub.execute_input":"2022-03-03T16:26:20.235166Z","iopub.status.idle":"2022-03-03T16:26:20.26873Z","shell.execute_reply.started":"2022-03-03T16:26:20.235135Z","shell.execute_reply":"2022-03-03T16:26:20.267907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:20.270209Z","iopub.execute_input":"2022-03-03T16:26:20.271311Z","iopub.status.idle":"2022-03-03T16:26:20.536305Z","shell.execute_reply.started":"2022-03-03T16:26:20.27126Z","shell.execute_reply":"2022-03-03T16:26:20.535231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_data['target'] = train_with_duplicates[target]","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:20.538345Z","iopub.execute_input":"2022-03-03T16:26:20.538588Z","iopub.status.idle":"2022-03-03T16:26:20.547281Z","shell.execute_reply.started":"2022-03-03T16:26:20.538559Z","shell.execute_reply":"2022-03-03T16:26:20.546226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ExtraTreesModel(N_ESTIMATORS=1000):\n    model = ExtraTreesClassifier(\n        n_estimators=N_ESTIMATORS,\n        n_jobs=-1,\n        verbose=0,\n        random_state=1221\n    )\n    return model\n\ndef DNN():\n    inputs = keras.Input(shape=X.shape[1])\n    x = layers.Dense(512, activation='relu')(inputs)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dense(64, activation='relu')(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(64, activation='relu')(x)\n    x = layers.Dense(32, activation='relu')(x)\n    x = layers.Dense(32, activation='relu')(x)\n    outputs = layers.Dense(10, activation='softmax')(x)\n    model = keras.Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:20.54871Z","iopub.execute_input":"2022-03-03T16:26:20.549339Z","iopub.status.idle":"2022-03-03T16:26:20.561232Z","shell.execute_reply.started":"2022-03-03T16:26:20.549296Z","shell.execute_reply":"2022-03-03T16:26:20.560433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_data[target] = encoder.fit_transform(scaled_data[target])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:20.562318Z","iopub.execute_input":"2022-03-03T16:26:20.562792Z","iopub.status.idle":"2022-03-03T16:26:20.634728Z","shell.execute_reply.started":"2022-03-03T16:26:20.562761Z","shell.execute_reply":"2022-03-03T16:26:20.633781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# N_SPLITS = 10\n# X, y = scaled_data[features], scaled_data[target]\n# folds = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=1334)\n# dnn_preds = []\n# for fold, (train_id, valid_id) in enumerate(tqdm(folds.split(X, y), total=N_SPLITS)):\n#     x_tr = X.iloc[train_id]\n#     y_tr = y.iloc[train_id]\n#     x_val = X.iloc[valid_id]\n#     y_val = y.iloc[valid_id]\n#     y_tr = keras.utils.to_categorical(y_tr)\n#     y_val = keras.utils.to_categorical(y_val)\n#     model = DNN()\n#     callbacks = [\n#         keras.callbacks.EarlyStopping(\n#             monitor='val_loss', patience=10, verbose=1\n#         )\n#     ]\n#     model.compile(optimizer='adam',\n#                  loss='categorical_crossentropy',\n#                  metrics=['accuracy'])\n#     model.fit(x_tr, y_tr, validation_data=(x_val, y_val), batch_size=128, epochs=50, callbacks=callbacks, verbose=0)\n#     print(f\"Fold {fold} Evaluation: {model.evaluate(x_val, y_val)}\")\n#     dnn_preds.append(model.predict(test))","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:20.635849Z","iopub.execute_input":"2022-03-03T16:26:20.636107Z","iopub.status.idle":"2022-03-03T16:26:20.640782Z","shell.execute_reply.started":"2022-03-03T16:26:20.636071Z","shell.execute_reply":"2022-03-03T16:26:20.640074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_loop(data, model_name = \"etc\", N_SPLITS=10):\n    X = data[features]\n    # hard coded (:\n    y = train_with_duplicates[target]\n    sample_weight = data.value_counts().values\n    folds = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=1223)\n    scores = []\n    predictions = []\n\n    for fold, (train_id, valid_id) in enumerate(tqdm(folds.split(X, y), total=N_SPLITS)):\n        X_train = X.iloc[train_id]\n        y_train = y.iloc[train_id]\n        X_valid = X.iloc[valid_id]\n        y_valid = y.iloc[valid_id]\n\n        if model_name == \"etc\":\n            # etc stands for ExtraTreeClassifier\n            # Training\n            model = ExtraTreesModel()\n            if len(sample_weight) == 0:\n                model.fit(X_train, y_train)\n            else:\n#                  sample_weight_train = sample_weight[train_id]\n                model.fit(X_train, y_train)\n            \n#             validation\n            valid_pred = model.predict(X_valid)\n            valid_score = 0\n            if len(sample_weight) == 0:\n                valid_score = accuracy_score(valid_pred, y_valid)\n            else:\n#                 sample_weight_valid = sample_weight[valid_id]\n                valid_score = accuracy_score(valid_pred, y_valid)\n                scores.append(valid_score)\n            print(f\"Fold {fold+1} \\tAccuracy: {valid_score:.4f}\")\n        \n        predictions.append(model.predict_proba(test))\n    \n    return {\"model\": model, \"logits\": predictions}","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:20.642085Z","iopub.execute_input":"2022-03-03T16:26:20.642298Z","iopub.status.idle":"2022-03-03T16:26:20.653577Z","shell.execute_reply.started":"2022-03-03T16:26:20.64227Z","shell.execute_reply":"2022-03-03T16:26:20.653058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"etc_model = training_loop(data=scaled_data, N_SPLITS=3)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:26:20.654696Z","iopub.execute_input":"2022-03-03T16:26:20.655189Z","iopub.status.idle":"2022-03-03T16:41:01.169013Z","shell.execute_reply.started":"2022-03-03T16:26:20.655158Z","shell.execute_reply":"2022-03-03T16:41:01.168038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Neural network outputs are probabilistic. \n# Doing the same for the ExtraTreeClassifier\n# dnn_probas = dnn_model.predict(test)\n# etc_probas = etc_model.predict_proba(test)\nmodel = etc_model['model']\nlogits = etc_model['logits']\n\nlogits = sum(logits)/len(logits)\n# dnn_preds = sum(dnn_preds)/len(dnn_preds)\n\n# preds = 0.9*logits + 0.1*dnn_preds\n\npredictions = pd.DataFrame({'predictions': np.argmax(logits, axis=1)})\npredictions.to_csv('Predictions.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:41:01.171107Z","iopub.execute_input":"2022-03-03T16:41:01.171518Z","iopub.status.idle":"2022-03-03T16:41:01.418052Z","shell.execute_reply.started":"2022-03-03T16:41:01.171478Z","shell.execute_reply":"2022-03-03T16:41:01.417034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pd.read_csv(\"Predictions.csv\", index_col=0)\npredictions.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:41:01.41963Z","iopub.execute_input":"2022-03-03T16:41:01.420057Z","iopub.status.idle":"2022-03-03T16:41:01.46987Z","shell.execute_reply.started":"2022-03-03T16:41:01.419997Z","shell.execute_reply":"2022-03-03T16:41:01.469234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the numbers into the respective names of the bacteria\nlabels = encoder.inverse_transform(predictions)\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:41:01.470881Z","iopub.execute_input":"2022-03-03T16:41:01.471826Z","iopub.status.idle":"2022-03-03T16:41:01.488984Z","shell.execute_reply.started":"2022-03-03T16:41:01.471784Z","shell.execute_reply":"2022-03-03T16:41:01.4874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:41:01.491261Z","iopub.execute_input":"2022-03-03T16:41:01.492055Z","iopub.status.idle":"2022-03-03T16:41:01.592554Z","shell.execute_reply.started":"2022-03-03T16:41:01.491977Z","shell.execute_reply":"2022-03-03T16:41:01.591746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample['target'] = labels\nsample.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:41:01.593961Z","iopub.execute_input":"2022-03-03T16:41:01.594667Z","iopub.status.idle":"2022-03-03T16:41:01.872478Z","shell.execute_reply.started":"2022-03-03T16:41:01.594616Z","shell.execute_reply":"2022-03-03T16:41:01.871228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\").head()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:41:01.875133Z","iopub.execute_input":"2022-03-03T16:41:01.875431Z","iopub.status.idle":"2022-03-03T16:41:01.925649Z","shell.execute_reply.started":"2022-03-03T16:41:01.875398Z","shell.execute_reply":"2022-03-03T16:41:01.924645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}