{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nTESTING = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T13:08:07.790506Z","iopub.execute_input":"2022-02-13T13:08:07.791142Z","iopub.status.idle":"2022-02-13T13:08:07.81522Z","shell.execute_reply.started":"2022-02-13T13:08:07.791038Z","shell.execute_reply":"2022-02-13T13:08:07.814584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Motivation\n\nThe motivation for this approach is to use a pretrained image classifier on image representations of the data provided. The reason I'm trying this is that Jeremy Howard of Fast AI provided several examples in his book about deep learning where such approach provided state of the art results. So let's try how it will perform with this problem.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tabular-playground-series-feb-2022/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tabular-playground-series-feb-2022/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:08:07.816804Z","iopub.execute_input":"2022-02-13T13:08:07.817552Z","iopub.status.idle":"2022-02-13T13:08:44.561338Z","shell.execute_reply.started":"2022-02-13T13:08:07.817514Z","shell.execute_reply":"2022-02-13T13:08:44.560622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:08:44.563171Z","iopub.execute_input":"2022-02-13T13:08:44.56343Z","iopub.status.idle":"2022-02-13T13:08:44.57309Z","shell.execute_reply.started":"2022-02-13T13:08:44.563396Z","shell.execute_reply":"2022-02-13T13:08:44.572419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TRAIN:\")\ndisplay(train.head(10))\n\nprint(\"TEST:\")\ndisplay(test.head(10))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:08:44.574452Z","iopub.execute_input":"2022-02-13T13:08:44.575011Z","iopub.status.idle":"2022-02-13T13:08:44.632335Z","shell.execute_reply.started":"2022-02-13T13:08:44.574966Z","shell.execute_reply":"2022-02-13T13:08:44.631641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert one row into a 2D array\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfeats = train.columns[1:-1]\n\n# Extract row array\nsample = train[feats].iloc[0].values\n\n# Min Max Scaling\nsample = (sample - train[feats].min(axis=0)) / (train[feats].max(axis=0) - train[feats].min(axis=0))\n\n# Rescale to 255\nsample *= 255\n\n# Append 3 extra features to make dim 289 -> (17, 17)\nsample = np.append(sample, [0, 0, 0])\nsample = np.reshape(sample, (17, 17))\n\nplt.imshow(sample);","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:08:44.634208Z","iopub.execute_input":"2022-02-13T13:08:44.634528Z","iopub.status.idle":"2022-02-13T13:08:45.984219Z","shell.execute_reply.started":"2022-02-13T13:08:44.63449Z","shell.execute_reply":"2022-02-13T13:08:45.983468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now if we are going to use a ResNet model we'll need to upsize such image into a `224 x 224` array.","metadata":{}},{"cell_type":"code","source":"from torchvision.transforms import Resize\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:08:45.98551Z","iopub.execute_input":"2022-02-13T13:08:45.985767Z","iopub.status.idle":"2022-02-13T13:08:47.488999Z","shell.execute_reply.started":"2022-02-13T13:08:45.985733Z","shell.execute_reply":"2022-02-13T13:08:47.488235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = Resize((224, 224))\n\nPIL_image = Image.fromarray(np.uint8(sample))\nPIL_image = transform(PIL_image)\nplt.imshow(PIL_image);","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:08:47.492212Z","iopub.execute_input":"2022-02-13T13:08:47.492445Z","iopub.status.idle":"2022-02-13T13:08:47.706738Z","shell.execute_reply.started":"2022-02-13T13:08:47.492414Z","shell.execute_reply":"2022-02-13T13:08:47.706055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert Training Data into 3D array ","metadata":{}},{"cell_type":"code","source":"def convert_df_to_3d(data, train_min_max=None):\n    # Add 3 features to enable resizing into 17x17\n    data.loc[:, ['extra_0', 'extra_1', 'extra_2']] = [0, 0, 0]\n    \n    # Min Max Scaling\n    if not train_min_max:\n        data_min, data_max = data.min(axis=0), data.max(axis=0)\n    else:\n        data_min, data_max = train_min_max \n        \n    data = (data - data_min) / (data_max - data_min)\n    \n    # Scale to 255\n    data *= 255\n\n    # Reshape data into 17x17\n    data = data.values.reshape((-1, 17, 17))[..., None]\n    data = np.repeat(data, 3, axis=-1)\n    \n    return data, (data_min, data_max)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:08:47.707953Z","iopub.execute_input":"2022-02-13T13:08:47.708275Z","iopub.status.idle":"2022-02-13T13:08:47.715393Z","shell.execute_reply.started":"2022-02-13T13:08:47.708236Z","shell.execute_reply":"2022-02-13T13:08:47.714461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train[feats]\ntrain_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:17:18.07468Z","iopub.execute_input":"2022-02-13T13:17:18.075193Z","iopub.status.idle":"2022-02-13T13:17:18.215683Z","shell.execute_reply.started":"2022-02-13T13:17:18.075156Z","shell.execute_reply":"2022-02-13T13:17:18.214683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training/Validation Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(train_data, train.target.to_list(), test_size=test.shape[0])\n\nif TESTING:\n    X_train, y_train = X_train[:64], y_train[:64]\n    X_val, y_val = X_val[:64], y_val[:64]\n\n    \nX_train, train_min_max = convert_df_to_3d(X_train)\nX_val, _ = convert_df_to_3d(X_val, train_min_max)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:18:24.170846Z","iopub.execute_input":"2022-02-13T13:18:24.171147Z","iopub.status.idle":"2022-02-13T13:18:25.030932Z","shell.execute_reply.started":"2022-02-13T13:18:24.171114Z","shell.execute_reply":"2022-02-13T13:18:25.029985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = Resize(224)\nplt.imshow(tmp(Image.fromarray(np.uint8(X_train[4])).convert('RGB')))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:31.684355Z","iopub.execute_input":"2022-02-13T13:19:31.684908Z","iopub.status.idle":"2022-02-13T13:19:31.891971Z","shell.execute_reply.started":"2022-02-13T13:19:31.684868Z","shell.execute_reply":"2022-02-13T13:19:31.891285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# License: BSD\n# Author: Sasank Chilamkurthy\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\ncudnn.benchmark = True\nplt.ion()   # interactive mode","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:34.137489Z","iopub.execute_input":"2022-02-13T13:19:34.138072Z","iopub.status.idle":"2022-02-13T13:19:34.147154Z","shell.execute_reply.started":"2022-02-13T13:19:34.138037Z","shell.execute_reply":"2022-02-13T13:19:34.146492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[1, 2,] == None","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:34.456523Z","iopub.execute_input":"2022-02-13T13:19:34.457207Z","iopub.status.idle":"2022-02-13T13:19:34.463364Z","shell.execute_reply.started":"2022-02-13T13:19:34.457169Z","shell.execute_reply":"2022-02-13T13:19:34.462598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, data, labels, transform=None, target_transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image = Image.fromarray(np.uint8(self.data[idx])).convert('RGB')\n        label = self.labels[idx] if self.labels != None else 0\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        if self.target_transform and self.labels:\n            label = self.target_transform.transform([label])\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:35.017151Z","iopub.execute_input":"2022-02-13T13:19:35.017756Z","iopub.status.idle":"2022-02-13T13:19:35.02508Z","shell.execute_reply.started":"2022-02-13T13:19:35.017718Z","shell.execute_reply":"2022-02-13T13:19:35.024328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:35.659279Z","iopub.execute_input":"2022-02-13T13:19:35.659538Z","iopub.status.idle":"2022-02-13T13:19:35.663658Z","shell.execute_reply.started":"2022-02-13T13:19:35.659502Z","shell.execute_reply":"2022-02-13T13:19:35.662565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nlabel_transformer = LabelEncoder().fit(train['target'])\n\ndatasets = {source: CustomImageDataset(X, y, transformer, label_transformer) for source, X, y in (('train', X_train, y_train),\n                                                                                                  ('val', X_val, y_val))}\n\ndataloaders = {source: DataLoader(dataset, batch_size=64, shuffle=True) for source, dataset in datasets.items()}\n\ndataset_sizes = {source: len(dataset) for source, dataset in datasets.items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:35.958865Z","iopub.execute_input":"2022-02-13T13:19:35.959339Z","iopub.status.idle":"2022-02-13T13:19:35.978478Z","shell.execute_reply.started":"2022-02-13T13:19:35.959302Z","shell.execute_reply":"2022-02-13T13:19:35.97765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display image and label.\ntrain_features, train_labels = next(iter(dataloaders['train']))\nprint(f\"Feature batch shape: {train_features.size()}\")\nprint(f\"Labels batch shape: {train_labels.size()}\")\nimg = train_features[0].squeeze()\nlabel = train_labels[0]\nplt.imshow(img[0])\nplt.show()\nprint(f\"Label: {label_transformer.inverse_transform(label)[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:39.574137Z","iopub.execute_input":"2022-02-13T13:19:39.574394Z","iopub.status.idle":"2022-02-13T13:19:39.869454Z","shell.execute_reply.started":"2022-02-13T13:19:39.574365Z","shell.execute_reply":"2022-02-13T13:19:39.868748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:46.350837Z","iopub.execute_input":"2022-02-13T13:19:46.351416Z","iopub.status.idle":"2022-02-13T13:19:46.355609Z","shell.execute_reply.started":"2022-02-13T13:19:46.351376Z","shell.execute_reply":"2022-02-13T13:19:46.354639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    preds = torch.argmax(outputs, 1)\n                    loss = criterion(outputs, labels.squeeze())\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            \n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:47.182357Z","iopub.execute_input":"2022-02-13T13:19:47.182903Z","iopub.status.idle":"2022-02-13T13:19:47.194987Z","shell.execute_reply.started":"2022-02-13T13:19:47.182864Z","shell.execute_reply":"2022-02-13T13:19:47.194197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\nmodel_ft.fc = nn.Linear(num_ftrs, len(label_transformer.classes_))\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:19:47.786919Z","iopub.execute_input":"2022-02-13T13:19:47.787386Z","iopub.status.idle":"2022-02-13T13:19:48.01135Z","shell.execute_reply.started":"2022-02-13T13:19:47.787351Z","shell.execute_reply":"2022-02-13T13:19:48.010508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:11:35.698425Z","iopub.execute_input":"2022-02-13T13:11:35.699135Z","iopub.status.idle":"2022-02-13T13:11:36.377204Z","shell.execute_reply.started":"2022-02-13T13:11:35.699098Z","shell.execute_reply":"2022-02-13T13:11:36.376472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_ft, 'model_ft')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"test_data = test[feats]\ntest_data, _ = convert_df_to_3d(test_data, train_min_max)\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:11:36.37891Z","iopub.execute_input":"2022-02-13T13:11:36.379312Z","iopub.status.idle":"2022-02-13T13:11:38.444169Z","shell.execute_reply.started":"2022-02-13T13:11:36.379275Z","shell.execute_reply":"2022-02-13T13:11:38.443263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = CustomImageDataset(test_data, None, transformer, label_transformer)\ntest_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:11:38.445926Z","iopub.execute_input":"2022-02-13T13:11:38.446414Z","iopub.status.idle":"2022-02-13T13:11:38.451333Z","shell.execute_reply.started":"2022-02-13T13:11:38.446376Z","shell.execute_reply":"2022-02-13T13:11:38.450614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft.eval()\n\ntest_preds = []\ncount = 0\nfor inputs, _ in test_dataloader:\n    count += len(inputs)\n    inputs, _ = next(iter(test_dataloader))\n    inputs = inputs.to(device)\n    outputs = model_ft(inputs)\n    preds = torch.argmax(outputs, 1)\n    test_preds += preds.tolist()\n    print(f'{count}/{test.shape[0]}', end='\\r', flush=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:11:39.521141Z","iopub.execute_input":"2022-02-13T13:11:39.521398Z","iopub.status.idle":"2022-02-13T13:16:44.904027Z","shell.execute_reply.started":"2022-02-13T13:11:39.521368Z","shell.execute_reply":"2022-02-13T13:16:44.903155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/sample_submission.csv')\nsubmission['target'] = label_transformer.inverse_transform(test_preds[:test.shape[0]])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:16:44.905978Z","iopub.execute_input":"2022-02-13T13:16:44.906239Z","iopub.status.idle":"2022-02-13T13:16:44.994765Z","shell.execute_reply.started":"2022-02-13T13:16:44.906204Z","shell.execute_reply":"2022-02-13T13:16:44.993976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:16:44.996072Z","iopub.execute_input":"2022-02-13T13:16:44.996314Z","iopub.status.idle":"2022-02-13T13:16:45.005405Z","shell.execute_reply.started":"2022-02-13T13:16:44.996281Z","shell.execute_reply":"2022-02-13T13:16:45.004657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T13:16:45.007233Z","iopub.execute_input":"2022-02-13T13:16:45.007681Z","iopub.status.idle":"2022-02-13T13:16:45.219654Z","shell.execute_reply.started":"2022-02-13T13:16:45.007645Z","shell.execute_reply":"2022-02-13T13:16:45.21891Z"},"trusted":true},"execution_count":null,"outputs":[]}]}