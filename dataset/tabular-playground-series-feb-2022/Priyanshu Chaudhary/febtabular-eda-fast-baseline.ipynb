{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"background-color:#000000;font-family:newtimeroman;color:#FFFFFF;font-size:150%;text-align:center;border-radius:2px 2px;\">EXPLORATORY DATA     ANALYSIS</p>\n\n<p style=\"background-color:#FFFFFF;font-family:calibri; color:#0077b6;font-size:120%;\">This notebook gives extensive overview about the data features with interactive plots to describe the pattern among the features. I will be updating this notebook during the competition.<br>\nLet's describe the problem first:<br>\nWe will be estimating bacterium species based on repeated lossy measurements of DNA snippets for this assignment. Raman spectroscopy is used to examine snippets of length 10 to compute the histogram of bases in the snippet.\nEach row of data provides a spectrum of histograms formed by repeated measurements of a sample, with each row including the output of all 286 histogram possibilities (e.g., to), which is then subtracted from the findings by a bias spectrum (of entirely random ATGC).\nTo make it more believable The data (both train and test) also includes generated measurement errors (at various rates) for many of the samples, which complicates the situation.\n</p>\n\n<p style=\"background-color:#FFFFFF;font-family:calibri; color:#0077b6;font-size:120%;\">See more facintating images of the bacterias to be predicted you can refer the discussion topic by <b>Remek Kinas:</b> \n<a href=\"https://www.kaggle.com/c/tabular-playground-series-feb-2022/discussion/304472\">BACTERIAS in competition</a></p>\n\n","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn-intelex -q --progress-bar off","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:38:46.983708Z","iopub.execute_input":"2022-02-10T07:38:46.98408Z","iopub.status.idle":"2022-02-10T07:39:23.868379Z","shell.execute_reply.started":"2022-02-10T07:38:46.984012Z","shell.execute_reply":"2022-02-10T07:39:23.867098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nfrom colorama import Fore\nfrom math import factorial\n\nimport seaborn as sns\nfrom sklearn import metrics\nfrom scipy import stats\nimport matplotlib as mpl\nfrom sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB,CategoricalNB\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.display.max_columns = 999\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import ExtraTreesClassifier,AdaBoostClassifier,RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n\ncell_hover = {  # for row hover use <tr> instead of <td>\n    'selector': 'td:hover',\n    'props': [('background-color', '#ffffb3')]\n}\nindex_names = {\n    'selector': '.index_name',\n    'props': 'font-style: italic; color: darkgrey; font-weight:normal;'\n}\nheaders = {\n    'selector': 'th:not(.index_name)',\n    'props': 'background-color: #000000; color: white;'\n}\nfrom IPython.display import HTML","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-10T07:39:23.872159Z","iopub.execute_input":"2022-02-10T07:39:23.872912Z","iopub.status.idle":"2022-02-10T07:39:23.888939Z","shell.execute_reply.started":"2022-02-10T07:39:23.872859Z","shell.execute_reply":"2022-02-10T07:39:23.887348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_folds=10\nseed=42\nn_estimators=500\npseudolabel=False  ## to do pseudo labelling or not ","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:23.890731Z","iopub.execute_input":"2022-02-10T07:39:23.891065Z","iopub.status.idle":"2022-02-10T07:39:23.909694Z","shell.execute_reply.started":"2022-02-10T07:39:23.891012Z","shell.execute_reply":"2022-02-10T07:39:23.908091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_map={0:'Streptococcus_pyogenes', 1:'Salmonella_enterica',\n       2:'Enterococcus_hirae', 3:'Escherichia_coli', 4:'Campylobacter_jejuni',\n       5:'Streptococcus_pneumoniae', 6:'Staphylococcus_aureus',\n       7:'Escherichia_fergusonii', 8:'Bacteroides_fragilis',\n       9:'Klebsiella_pneumoniae'}\n\ntrain=pd.read_parquet('../input/tabular-february/train.parquet')\ntest=pd.read_parquet('../input/tabular-february/test.parquet') #\n\nif pseudolabel:\n    ptrain=pd.read_csv('../input/febpseudolabelling/pseudo_labels.csv')\n    ptrain=ptrain['0'].map(lambda x:target_map[x])\n    ptest=pd.read_csv('../input/febpseudolabelling/submission(16).csv')\n\n    train['pseudo']=ptrain\n    test['pseudo']=ptest['target']","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:23.912253Z","iopub.execute_input":"2022-02-10T07:39:23.91275Z","iopub.status.idle":"2022-02-10T07:39:26.374585Z","shell.execute_reply.started":"2022-02-10T07:39:23.912709Z","shell.execute_reply":"2022-02-10T07:39:26.372424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=train.head()\ns.style.set_table_styles([cell_hover, index_names, headers])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:26.383703Z","iopub.execute_input":"2022-02-10T07:39:26.385512Z","iopub.status.idle":"2022-02-10T07:39:26.549438Z","shell.execute_reply.started":"2022-02-10T07:39:26.385255Z","shell.execute_reply":"2022-02-10T07:39:26.548242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop('row_id',axis=1,inplace=True)\nduplicates_train = train.duplicated().sum()\nprint('Duplicates in train data: {0}'.format(duplicates_train))\n\ntrain.drop_duplicates(keep='first', inplace=True)\nduplicates_train = train.duplicated().sum()\n\nprint('Train data shape:', train.shape)\nprint('Duplicates in train data: {0}'.format(duplicates_train))\ntrain.reset_index(drop=True,inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:26.550891Z","iopub.execute_input":"2022-02-10T07:39:26.551258Z","iopub.status.idle":"2022-02-10T07:39:32.610413Z","shell.execute_reply.started":"2022-02-10T07:39:26.551214Z","shell.execute_reply":"2022-02-10T07:39:32.609138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color:#000000;font-family:newtimeroman;color:#FFFFFF;font-size:150%;text-align:center;border-radius:2px 2px;\">CHECK MISSING VALUES</p>\n\n<p style=\"background-color:#FFFFFF;font-family:calibri; color:#000000;font-size:120%;\">There are no missing data in train and test datasets.</p>","metadata":{}},{"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))\n\nprint(\"==\"*30)\nprint('TRAIN')\nprint(\"==\"*30)\ndisplay(missing_data(train).style.set_table_styles([cell_hover, index_names, headers]))\nprint(\"==\"*30)\nprint('TEST')\nprint(\"==\"*30)\ndisplay(missing_data(test).style.set_table_styles([cell_hover, index_names, headers]))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:32.612513Z","iopub.execute_input":"2022-02-10T07:39:32.612862Z","iopub.status.idle":"2022-02-10T07:39:33.876923Z","shell.execute_reply.started":"2022-02-10T07:39:32.612819Z","shell.execute_reply":"2022-02-10T07:39:33.876242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color:#000000;font-family:newtimeroman;color:#FFFFFF;font-size:150%;text-align:center;border-radius:2px 2px;\">DESCRIBE TRAIN AND TEST</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"background-color:#FFFFFF;font-family:calibri; color:#0077b6;font-size:120%;\"><b>We can make few observations here:</b></p>\n\n<ul style=\"background-color:#FFFFFF;font-family:calibri; color:#0077b6;font-size:120%;\">\n  <li>Mean,Standard deviation is relatively less for both train and test variable data</li>\n  <li>Mean,std are quite the same in both train and test</li>\n  <li>Since all the values lie between -1 to 1 we won't  be need to scale the features</li>\n  <li>Train and test data looks very much similar.</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"print(\"==\"*30)\nprint('TRAIN')\nprint(\"==\"*30)\ns=train.describe()\ndisplay(s.style.set_table_styles([cell_hover, index_names, headers]))\nprint(\"==\"*30)\nprint('TEST')\nprint(\"==\"*30)\ns=test.describe()\ndisplay(s.style.set_table_styles([cell_hover, index_names, headers]))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:33.878475Z","iopub.execute_input":"2022-02-10T07:39:33.879532Z","iopub.status.idle":"2022-02-10T07:39:37.876954Z","shell.execute_reply.started":"2022-02-10T07:39:33.879481Z","shell.execute_reply":"2022-02-10T07:39:37.875615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#FFFFFF;font-size:150%;text-align:center;border-radius:2px 2px;\">TARGET DISTRIBUTION</p>\n\n<ul style=\"background-color:#FFFFFF;font-family:calibri; color:#0077b6;font-size:120%;\">\n  <li>Classes appears to be balanced. (Good thing)</li>\n  <li>Each target value has about 20000 frequency</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\ndf = px.data.tips()\nfig = px.histogram(train, x=\"target\",color='target', template='plotly_white',opacity=0.7)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:37.878932Z","iopub.execute_input":"2022-02-10T07:39:37.879835Z","iopub.status.idle":"2022-02-10T07:39:39.309418Z","shell.execute_reply.started":"2022-02-10T07:39:37.879765Z","shell.execute_reply":"2022-02-10T07:39:39.308527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color:#000000;font-family:newtimeroman;color:#FFFFFF;font-size:150%;text-align:center;border-radius:2px 2px;\">FEATURES DISTRIBUTION</p>\n\n<ul style=\"background-color:#FFFFFF;font-family:calibri; color:#0077b6;font-size:120%;\">\n  <li>All the values are highly skewed around zero</li>\n  <li>there are some columns where we are having two local peaks</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"numerical_columns=test.columns[1:13]\nnum_rows, num_cols = 4,3\nf, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 20))\nf.suptitle('Distribution of Features', fontsize=16)\n\nfor index, column in enumerate(train[numerical_columns].columns):\n    i,j = (index // num_cols, index % num_cols)\n    g = sns.kdeplot(train[column], color=\"m\", shade=True, label=\"%.2f\"%(train[column].skew()), ax=axes[i,j])\n    g = g.legend(loc=\"best\")\n\nf.delaxes(axes[3,2 ])\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:39.312092Z","iopub.execute_input":"2022-02-10T07:39:39.31293Z","iopub.status.idle":"2022-02-10T07:39:47.065094Z","shell.execute_reply.started":"2022-02-10T07:39:39.312889Z","shell.execute_reply":"2022-02-10T07:39:47.063899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# violin plot","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:47.066923Z","iopub.execute_input":"2022-02-10T07:39:47.067291Z","iopub.status.idle":"2022-02-10T07:39:47.072778Z","shell.execute_reply.started":"2022-02-10T07:39:47.067247Z","shell.execute_reply":"2022-02-10T07:39:47.071641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nnumerical_columns=test.columns[3:7]\nnum_rows, num_cols = 4,1\nf, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 20))\nf.suptitle('Distribution of Targets wit hfeatures', fontsize=16)\n\nset3=['FF6363','FFAB76','FFFDA2','BAFFB4','8946A6']\n\nfor index, column in enumerate(train[numerical_columns].columns):\n    i,j = (index // num_cols, index % num_cols)\n    g=sns.violinplot(x=column, y='target',palette=['r','g','b','m','y'], data=train,ax=axes[i],scale='width',linewidth=0.1)\n    g = g.legend(loc=\"best\")\n\nf.delaxes(axes[0])\n# f.delaxes(axes[3, 2])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:47.074587Z","iopub.execute_input":"2022-02-10T07:39:47.075168Z","iopub.status.idle":"2022-02-10T07:39:50.873993Z","shell.execute_reply.started":"2022-02-10T07:39:47.075118Z","shell.execute_reply":"2022-02-10T07:39:50.872883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color:#000000;font-family:newtimeroman;color:#FFFFFF;font-size:150%;text-align:center;border-radius:2px 2px;\">CORRELATION</p>\n\n<ul style=\"background-color:#FFFFFF;font-family:calibri; color:#0077b6;font-size:120%;\">\n  <li>starting features are highly uncorrelated</li>\n  <li>you can change the slices or add column names to check the correlation between them </li>\n</ul>","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\ncols=train.columns[1:25]\nz =train[cols].corr()\n\nfig = px.imshow(z, text_auto=True, aspect=\"auto\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:50.875999Z","iopub.execute_input":"2022-02-10T07:39:50.876343Z","iopub.status.idle":"2022-02-10T07:39:51.14478Z","shell.execute_reply.started":"2022-02-10T07:39:50.876301Z","shell.execute_reply":"2022-02-10T07:39:51.143562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unique_data(data):\n    total = data.nunique()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n    return(np.transpose(tt))\nprint(\"==\"*30)\nprint('TRAIN')\nprint(\"==\"*30)\ndisplay(unique_data(train).style.set_table_styles([cell_hover, index_names, headers]))\nprint(\"==\"*30)\nprint('TEST')\nprint(\"==\"*30)\ndisplay(unique_data(test).style.set_table_styles([cell_hover, index_names, headers]))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:51.146603Z","iopub.execute_input":"2022-02-10T07:39:51.146826Z","iopub.status.idle":"2022-02-10T07:39:52.569188Z","shell.execute_reply.started":"2022-02-10T07:39:51.1468Z","shell.execute_reply":"2022-02-10T07:39:52.567901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color:#000000;font-family:newtimeroman;color:#FFFFFF;font-size:150%;text-align:center;border-radius:2px 2px;\">CONVERTING BACK TO INTEGERS</p>\n\n<ul style=\"background-color:#FFFFFF;font-family:calibri; color:#0077b6;font-size:120%;\">\n  <li>FROM THIS PART I HAVE TAKEN REFERENCE FROM AMOBROSM'S NOTEBOOK THINK IS PROVIDED IN REFERENCES</li>\n</ul>","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color:#000000;font-family:newtimeroman;color:#FFFFFF;font-size:150%;text-align:center;border-radius:2px 2px;\">KMEANS FOR VALIDATION SPLIT AND EXTRA TREES+NAIVE BIAS FOR TRAINING</p>\n\n<ul style=\"background-color:#FFFFFF;font-family:calibri; color:#0077b6;font-size:120%;\">\n  <li>i have clustered the data into 8 clusters i haven't tested how changing clusters will affect score</li>\n  <li>I have used extra tress for training as so far it is the breakthrough model for this competition</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncont_features =[col for col in train.columns if col not in [\"row_id\",'target']]\ncat_features = []\n\ntarget_map={'Streptococcus_pyogenes':0, 'Salmonella_enterica':1,\n       'Enterococcus_hirae':2, 'Escherichia_coli':3, 'Campylobacter_jejuni':4,\n       'Streptococcus_pneumoniae':5, 'Staphylococcus_aureus':6,\n       'Escherichia_fergusonii':7, 'Bacteroides_fragilis':8,\n       'Klebsiella_pneumoniae':9}\n\ntarget_encoder = LabelEncoder()\ntrain[\"target\"] = target_encoder.fit_transform(train[\"target\"])\ntarget=train['target']\nif pseudolabel:\n    train['pseudo']=train['pseudo'].map(lambda x:target_map[x])\n    test['pseudo']=test['pseudo'].map(lambda x:target_map[x])\nk_fold = StratifiedKFold(n_splits=n_folds, random_state=seed, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:52.571231Z","iopub.execute_input":"2022-02-10T07:39:52.571519Z","iopub.status.idle":"2022-02-10T07:39:52.618763Z","shell.execute_reply.started":"2022-02-10T07:39:52.571481Z","shell.execute_reply":"2022-02-10T07:39:52.617609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_weight=train.value_counts().values","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:52.620087Z","iopub.execute_input":"2022-02-10T07:39:52.620326Z","iopub.status.idle":"2022-02-10T07:39:56.298014Z","shell.execute_reply.started":"2022-02-10T07:39:52.620297Z","shell.execute_reply":"2022-02-10T07:39:56.296691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"et_pred = []\nrf_pred = []\n\n\net_scores = []\nrf_scores = []\n\net_train_preds=np.zeros(len(train))\nrf_train_preds=np.zeros(len(train))\n\nfor fold, (train_id, test_id) in tqdm(enumerate(k_fold.split(train,train['target']))):\n    print('####### Fold: ', fold)\n    \n    # Splitting\n    X_train, y_train = train.iloc[train_id][cont_features], target[train_id]\n    X_valid, y_valid = train.iloc[test_id][cont_features], target[test_id]\n    \n    # Model\n    et_model = ExtraTreesClassifier(\n        n_estimators=n_estimators,\n        n_jobs=-1,\n        verbose=1\n    )\n    \n    rf_model = RandomForestClassifier(\n        n_estimators=n_estimators,\n        n_jobs=-1,\n                    \n    )\n    # Training\n    sample_weight_train=sample_weight[train_id]\n    sample_weight_valid=sample_weight[test_id]\n    \n    et_model.fit(X_train, y_train,sample_weight_train)\n    rf_model.fit(X_train, y_train,sample_weight_train)\n    \n    # Evaluation\n    et_valid_pred = et_model.predict(X_valid)\n    rf_valid_pred = rf_model.predict(X_valid)\n    \n    et_valid_score = accuracy_score(y_valid, et_valid_pred,sample_weight=sample_weight_valid)\n    rf_valid_score = accuracy_score(y_valid, rf_valid_pred,sample_weight=sample_weight_valid)\n    \n\n    \n    print(f'Extra Trees Accuracy score: {et_valid_score:6f}\\n')\n    print(f'Random Forest_SCORE Accuracy score: {rf_valid_score:6f}\\n')\n    et_scores.append(et_valid_score)\n    rf_scores.append(rf_valid_score)\n\n    # Prediction for submission\n    et_pred.append(et_model.predict_proba(test[cont_features]))\n    rf_pred.append(rf_model.predict_proba(test[cont_features]))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T07:39:56.299897Z","iopub.execute_input":"2022-02-10T07:39:56.300304Z","iopub.status.idle":"2022-02-10T08:04:44.726242Z","shell.execute_reply.started":"2022-02-10T07:39:56.300269Z","shell.execute_reply":"2022-02-10T08:04:44.725115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def post_processing(y_probs, train, tune = []):\n    y_prob = sum(y_probs) / len(y_probs)\n    target_distribution = train['target'].value_counts().sort_index() / len(train) * 100\n    def get_diff(tune):\n        y_pred_tuned = target_encoder.inverse_transform(np.argmax(y_prob + tune, axis=1))\n        return target_distribution - pd.Series(y_pred_tuned).value_counts().sort_index() / len(test) * 100\n\n    if len(tune) == 0:\n        tune = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n        diff = get_diff(tune)\n        while abs(diff).max() > 0.1:\n            for i in range(len(diff)):\n                if diff[i] > 0.1:\n                    tune[i] += 0.001\n                    break\n                if diff[i] < -0.1:\n                    tune[i] -= 0.001\n                    break\n            diff = get_diff(tune)\n\n    # Credits to https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\n    print(tune)\n    y_pred_tuned = target_encoder.inverse_transform(np.argmax(y_prob + tune, axis=1))\n    print(pd.Series(y_pred_tuned, index=test.index).value_counts().sort_index() / len(test) * 100)\n    return y_pred_tuned","metadata":{"execution":{"iopub.status.busy":"2022-02-10T08:05:03.540629Z","iopub.execute_input":"2022-02-10T08:05:03.540968Z","iopub.status.idle":"2022-02-10T08:05:03.55375Z","shell.execute_reply.started":"2022-02-10T08:05:03.540934Z","shell.execute_reply":"2022-02-10T08:05:03.552912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tune = [0, 0, 0.01, 0.03, 0, 0, 0, 0, 0, 0]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T08:05:52.167359Z","iopub.execute_input":"2022-02-10T08:05:52.167757Z","iopub.status.idle":"2022-02-10T08:05:52.173596Z","shell.execute_reply.started":"2022-02-10T08:05:52.167719Z","shell.execute_reply":"2022-02-10T08:05:52.172599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds=et_pred\ny_preds.extend(rf_pred)\n\ny_pred_tuned = post_processing(et_pred, train)\ny_pred_tuned_with_tune = post_processing(et_pred, train, tune)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T08:13:59.42346Z","iopub.execute_input":"2022-02-10T08:13:59.424128Z","iopub.status.idle":"2022-02-10T08:13:59.599257Z","shell.execute_reply.started":"2022-02-10T08:13:59.424087Z","shell.execute_reply":"2022-02-10T08:13:59.598022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')\nsubmission['target']=y_pred_tuned_with_tune","metadata":{"execution":{"iopub.status.busy":"2022-02-10T08:12:57.207404Z","iopub.execute_input":"2022-02-10T08:12:57.207709Z","iopub.status.idle":"2022-02-10T08:12:57.252084Z","shell.execute_reply.started":"2022-02-10T08:12:57.207679Z","shell.execute_reply":"2022-02-10T08:12:57.251013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T08:12:58.921948Z","iopub.execute_input":"2022-02-10T08:12:58.922843Z","iopub.status.idle":"2022-02-10T08:12:59.180709Z","shell.execute_reply.started":"2022-02-10T08:12:58.922768Z","shell.execute_reply":"2022-02-10T08:12:59.179481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pseudolabels=pd.DataFrame(np.array(tpreds)).astype(int)\n# pseudolabels.to_csv('pseudo_labels.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T08:04:44.816184Z","iopub.status.idle":"2022-02-10T08:04:44.816515Z","shell.execute_reply.started":"2022-02-10T08:04:44.816344Z","shell.execute_reply":"2022-02-10T08:04:44.816361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color:#000000;font-family:newtimeroman;color:#FFFFFF;font-size:150%;text-align:center;border-radius:2px 2px;\">REFERENCES</p>\n<ul>\n    <li>Analysis of Identification Method for Bacterial Species and Antibiotic Resistance Genes Using Optical Data From DNA Oligomers</li>\n    <li><a href='https://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense'>Notebook by ambrosM</a></li>","metadata":{}}]}