{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nHey, thanks for viewing my Kernel!\n\nIf you like my work, please, leave an upvote: it will be really appreciated and it will motivate me in offering more content to the Kaggle community ! ðŸ˜Š","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\n\nwarnings.simplefilter(\"ignore\")\ntrain = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv')\nsub = pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')\n\ndisplay(train.head())\ndisplay(sub.head())","metadata":{"execution":{"iopub.status.busy":"2022-02-19T15:49:44.741061Z","iopub.execute_input":"2022-02-19T15:49:44.741431Z","iopub.status.idle":"2022-02-19T15:50:09.939446Z","shell.execute_reply.started":"2022-02-19T15:49:44.74138Z","shell.execute_reply":"2022-02-19T15:50:09.938821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.shape)\ndisplay(test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T15:50:27.023117Z","iopub.execute_input":"2022-02-19T15:50:27.024086Z","iopub.status.idle":"2022-02-19T15:50:27.033133Z","shell.execute_reply.started":"2022-02-19T15:50:27.024027Z","shell.execute_reply":"2022-02-19T15:50:27.032487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_cols = train.select_dtypes(include=np.number).columns.tolist()\nobject_cols = list(set(train.columns) - set(numeric_cols))\nnumeric_cols.remove('row_id')\ningore_cols = ['row_id']\nprint('numeric cols len: ', len(numeric_cols))\nprint('object col: ', object_cols)\nprint('ignore col: ', ingore_cols)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T15:50:28.929245Z","iopub.execute_input":"2022-02-19T15:50:28.930171Z","iopub.status.idle":"2022-02-19T15:50:29.181005Z","shell.execute_reply.started":"2022-02-19T15:50:28.930119Z","shell.execute_reply":"2022-02-19T15:50:29.17994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"duplicates_train = train.duplicated().sum()\nduplicates_test = test.duplicated().sum()\ndisplay(duplicates_train)\ndisplay(duplicates_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T15:50:31.321358Z","iopub.execute_input":"2022-02-19T15:50:31.321718Z","iopub.status.idle":"2022-02-19T15:50:35.42354Z","shell.execute_reply.started":"2022-02-19T15:50:31.321685Z","shell.execute_reply":"2022-02-19T15:50:35.422596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-19T15:50:41.058253Z","iopub.execute_input":"2022-02-19T15:50:41.058598Z","iopub.status.idle":"2022-02-19T15:50:41.073947Z","shell.execute_reply.started":"2022-02-19T15:50:41.058549Z","shell.execute_reply":"2022-02-19T15:50:41.072806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T15:50:44.425139Z","iopub.execute_input":"2022-02-19T15:50:44.42547Z","iopub.status.idle":"2022-02-19T15:51:30.434135Z","shell.execute_reply.started":"2022-02-19T15:50:44.425435Z","shell.execute_reply":"2022-02-19T15:51:30.432844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pseudo Labeling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nenc = OneHotEncoder(handle_unknown='ignore', sparse=False)\ntargets =  pd.DataFrame(enc.fit_transform(train[['target']]))\ntargets.columns = list(enc.categories_[0])\ntargets.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T18:00:33.36903Z","iopub.execute_input":"2022-02-16T18:00:33.369543Z","iopub.status.idle":"2022-02-16T18:00:34.558441Z","shell.execute_reply.started":"2022-02-16T18:00:33.369488Z","shell.execute_reply":"2022-02-16T18:00:34.557603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_th(auc):\n    auc_last_digits = str(auc)[-2:]\n    th = float('0.' + auc_last_digits)\n    return th","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-16T18:00:46.390416Z","iopub.execute_input":"2022-02-16T18:00:46.390688Z","iopub.status.idle":"2022-02-16T18:00:46.395284Z","shell.execute_reply.started":"2022-02-16T18:00:46.390661Z","shell.execute_reply":"2022-02-16T18:00:46.394632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nselected_indexs = []\nth = 0.95\nfor col in targets.columns:\n    X_train = train[numeric_cols]\n    X_test = test[numeric_cols]\n    y_train = targets[[col]]\n    \n    oof = np.zeros(len(X_train))\n    preds = np.zeros(len(test))\n    \n    idx1 = X_train.index; idx2 = X_test.index\n    \n    skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(X_train, y_train):\n        clf = RandomForestClassifier()\n        clf.fit(X_train.loc[train_index,:], y_train.loc[train_index, col])\n        oof[idx1[test_index]] = clf.predict_proba(X_train.loc[test_index,:])[:,1]\n        preds[idx2] += clf.predict_proba(X_test)[:,1] / skf.n_splits\n    \n    auc = roc_auc_score(y_train, oof)\n    print(col, 'RF Scores CV =',round(auc,5), end='')\n    \n    #th = get_th(round(auc,5))\n    test_temp = test.copy()\n    test_temp['target'] = preds\n    test_temp = test_temp[test_temp['target'] >= th]\n    selected_indexs.append(list(test_temp.index))\n    \n    print(' - Pseudo Labels Len =', len(test_temp))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T18:22:11.160509Z","iopub.execute_input":"2022-02-16T18:22:11.161458Z","iopub.status.idle":"2022-02-16T18:48:50.719669Z","shell.execute_reply.started":"2022-02-16T18:22:11.161416Z","shell.execute_reply":"2022-02-16T18:48:50.718302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labeled_test = test.copy()\nlabeled_test['target'] = ''\nfor index, col in enumerate(targets.columns):\n    indexs = selected_indexs[index]\n    labeled_test.loc[indexs, 'target'] = col\nlabeled_test = labeled_test[labeled_test['target'] != '']\nprint(labeled_test.shape)\ndisplay(labeled_test.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train = pd.concat([train, labeled_test])\nprint(new_train.shape)\ndisplay(new_train.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train.to_csv('new_train.csv', index=False)\nnew_train.to_pickle('new_train.pkl')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install pycaret[full]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pycaret.classification import *\n\nnumeric_cols = train.select_dtypes(include=np.number).columns.tolist()\nignore_cols = ['row_id']\n\nclf = setup(data=new_train,\n            target='target',\n            #normalize = True, #normalisation helps some algorithms\n            #normalize_method = 'robust', #resilient to outliers\n            #transformation = True, #applies transformation to target column\n            #transformation_method = 'quantile',\n            data_split_shuffle = False, #so that we do not use \"future\" observations to predict \"past\" observations\n            create_clusters = True,\n            remove_outliers = True,\n            #feature_interaction = True,\n            numeric_features = numeric_cols,\n            ignore_features = ignore_cols,\n            session_id = 42,\n            use_gpu = False,\n            silent = True,\n            fold = 10,\n            n_jobs = -1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#top = [create_model('et', n_estimators=300), create_model('rf', n_estimators=300)]\nmodel_et = create_model('et')\nmodel_rf = create_model('rf')\n\n#model_et_calib = calibrate_model(model_et)\n#model_rf_calib = calibrate_model(model_rf)\n\ntop = [model_et, model_rf]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stack = stack_models(top, optimize='Accuracy')\npredict_model(stack);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_stack = finalize_model(stack)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(final_stack, plot='error')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(final_stack, plot = 'confusion_matrix')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"import gc\ngc.collect()\nunseen_predictions = predict_model(final_stack, data=test)\nunseen_predictions.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert(len(test.index)==len(unseen_predictions))\nsub = pd.DataFrame(list(zip(sub.row_id, unseen_predictions.Label)),columns = ['row_id', 'target'])\nsub.to_csv('submission_stack.csv', index = False)\nsub.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ntrain_test_preds = pd.DataFrame()\ntrain_test_preds['label'] = list(train['target']) + list(unseen_predictions['Label'])\ntrain_test_preds['train_test'] = 'Test preds'\ntrain_test_preds.loc[0:len(train[['target']]), 'train_test'] = 'Training'\n\nfig, ax = plt.subplots(figsize=(16,3))\nsns.countplot(data=train_test_preds, x='label', hue='train_test', ax=ax)\nplt.xticks(rotation=90)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}