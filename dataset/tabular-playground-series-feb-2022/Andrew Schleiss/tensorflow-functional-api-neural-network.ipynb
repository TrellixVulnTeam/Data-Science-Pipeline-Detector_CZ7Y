{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Summary of Kernel -> Functional Api\nIn this notebook we will start with a basic Functional API model\nhttps://www.tensorflow.org/guide/keras/functional\n\nThe functional Api allows for additional functionality as opposed to the basic Sequential model which most model builders will be familiar with \\\nThe most important features include the ability to: \n* Additional input layers  -> for multiple input data sources ( create seperate pipeline in your model for differnet datasets)\n* Multiple hidden layers -> important for recurrent neural networks\n* Additional outputs -> i.e. output a classification result and regression \n* Multiple metrics, losses and training sets \n\nFor this example we will use the tabular playground competition data from [TPS February ](https://www.kaggle.com/c/tabular-playground-series-feb-2022)","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nimport tensorflow\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras import regularizers \n\nfrom sklearn.preprocessing import StandardScaler\n","metadata":{"_kg_hide-input":true,"papermill":{"duration":7.867113,"end_time":"2022-02-14T11:00:43.496394","exception":false,"start_time":"2022-02-14T11:00:35.629281","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T08:03:39.112501Z","iopub.execute_input":"2022-04-06T08:03:39.112836Z","iopub.status.idle":"2022-04-06T08:03:46.968343Z","shell.execute_reply.started":"2022-04-06T08:03:39.112748Z","shell.execute_reply":"2022-04-06T08:03:46.967415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# experimental params \nITERATIONS = 2000\nFOLDS = 10\n\nSCALER = StandardScaler()\n\nPSEUDO = True\nCLUSTER = True\n\nDROP_DUPS = False","metadata":{"papermill":{"duration":0.046556,"end_time":"2022-02-14T11:00:43.579408","exception":false,"start_time":"2022-02-14T11:00:43.532852","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T08:03:46.970594Z","iopub.execute_input":"2022-04-06T08:03:46.970931Z","iopub.status.idle":"2022-04-06T08:03:46.975865Z","shell.execute_reply.started":"2022-04-06T08:03:46.970887Z","shell.execute_reply":"2022-04-06T08:03:46.975192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will start with the usual processing and import of data ","metadata":{}},{"cell_type":"markdown","source":"# Import Data","metadata":{"papermill":{"duration":0.039607,"end_time":"2022-02-14T11:00:43.655691","exception":false,"start_time":"2022-02-14T11:00:43.616084","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-feb-2022/train.csv\", index_col = 0) \ntest = pd.read_csv(\"../input/tabular-playground-series-feb-2022/test.csv\", index_col = 0) \nsub = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\", index_col = 0)","metadata":{"_kg_hide-input":true,"papermill":{"duration":40.216279,"end_time":"2022-02-14T11:01:23.915598","exception":false,"start_time":"2022-02-14T11:00:43.699319","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T08:03:46.976867Z","iopub.execute_input":"2022-04-06T08:03:46.977373Z","iopub.status.idle":"2022-04-06T08:04:30.740965Z","shell.execute_reply.started":"2022-04-06T08:03:46.977333Z","shell.execute_reply":"2022-04-06T08:04:30.739988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.076008,"end_time":"2022-02-14T11:01:24.028441","exception":false,"start_time":"2022-02-14T11:01:23.952433","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T08:04:30.745336Z","iopub.execute_input":"2022-04-06T08:04:30.745803Z","iopub.status.idle":"2022-04-06T08:04:30.788308Z","shell.execute_reply.started":"2022-04-06T08:04:30.745752Z","shell.execute_reply":"2022-04-06T08:04:30.787283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print( \"Total segments\" , len( train.columns ) -1 ) ","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.047289,"end_time":"2022-02-14T11:01:24.114102","exception":false,"start_time":"2022-02-14T11:01:24.066813","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T08:04:30.789582Z","iopub.execute_input":"2022-04-06T08:04:30.789868Z","iopub.status.idle":"2022-04-06T08:04:30.794936Z","shell.execute_reply.started":"2022-04-06T08:04:30.789834Z","shell.execute_reply":"2022-04-06T08:04:30.794087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding \n\nThis dataset required endoding, we will use Label Encoder from sklearn","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain[\"target\"] = encoder.fit_transform(train[\"target\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-06T08:04:30.796063Z","iopub.execute_input":"2022-04-06T08:04:30.796304Z","iopub.status.idle":"2022-04-06T08:04:30.871423Z","shell.execute_reply.started":"2022-04-06T08:04:30.796273Z","shell.execute_reply":"2022-04-06T08:04:30.869882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split and Scale","metadata":{"papermill":{"duration":0.127824,"end_time":"2022-02-14T11:45:42.563357","exception":false,"start_time":"2022-02-14T11:45:42.435533","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X = train.drop(\"target\",axis =1)\ny = train[\"target\"]\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42)","metadata":{"papermill":{"duration":3.445318,"end_time":"2022-02-14T11:45:46.138651","exception":false,"start_time":"2022-02-14T11:45:42.693333","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T08:04:30.873482Z","iopub.execute_input":"2022-04-06T08:04:30.873758Z","iopub.status.idle":"2022-04-06T08:04:31.661606Z","shell.execute_reply.started":"2022-04-06T08:04:30.873722Z","shell.execute_reply":"2022-04-06T08:04:31.660754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = SCALER\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"papermill":{"duration":5.242225,"end_time":"2022-02-14T11:45:51.509807","exception":false,"start_time":"2022-02-14T11:45:46.267582","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T08:04:31.663171Z","iopub.execute_input":"2022-04-06T08:04:31.663519Z","iopub.status.idle":"2022-04-06T08:04:32.673146Z","shell.execute_reply.started":"2022-04-06T08:04:31.663477Z","shell.execute_reply":"2022-04-06T08:04:32.672096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functional API Model\n\nWith the functional API we build each indvidual layer seperately, each layer then references the previous layer ","metadata":{"papermill":{"duration":0.132453,"end_time":"2022-02-14T11:45:51.78058","exception":false,"start_time":"2022-02-14T11:45:51.648127","status":"completed"},"tags":[]}},{"cell_type":"code","source":"stopping = EarlyStopping(monitor=\"val_loss\",patience = 31)\nlr = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=20)","metadata":{"papermill":{"duration":0.13872,"end_time":"2022-02-14T11:45:52.053219","exception":false,"start_time":"2022-02-14T11:45:51.914499","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T08:04:32.674331Z","iopub.execute_input":"2022-04-06T08:04:32.67455Z","iopub.status.idle":"2022-04-06T08:04:32.68015Z","shell.execute_reply.started":"2022-04-06T08:04:32.674523Z","shell.execute_reply":"2022-04-06T08:04:32.67898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build model \ninput_layer = keras.Input(shape = (X.shape[1],) , name = \"input_layer\" ) \n\n# each subsequent layer will reference the previous one (see brackets at the end of each line)\nhidden_1 = layers.Dense(300, activation =\"selu\", name = \"hidden_1\" )(input_layer)\nhidden_2 = layers.Dense(300, activation =\"selu\", name = \"hidden_2\" )(hidden_1)\n\noutput_layer = layers.Dense(10,activation = \"softmax\",  name = \"output_layer\" )(hidden_2)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-06T07:38:22.054168Z","iopub.status.idle":"2022-04-06T07:38:22.054492Z","shell.execute_reply.started":"2022-04-06T07:38:22.054336Z","shell.execute_reply":"2022-04-06T07:38:22.054353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We bring this all together in our Model by referencing the input layer and final output layer\nmodel = keras.Model(inputs = input_layer, \n                   outputs = output_layer)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T07:38:22.056313Z","iopub.status.idle":"2022-04-06T07:38:22.056791Z","shell.execute_reply.started":"2022-04-06T07:38:22.056605Z","shell.execute_reply":"2022-04-06T07:38:22.056626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model,show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T07:38:22.057939Z","iopub.status.idle":"2022-04-06T07:38:22.058725Z","shell.execute_reply.started":"2022-04-06T07:38:22.058533Z","shell.execute_reply":"2022-04-06T07:38:22.058555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T07:38:22.059777Z","iopub.status.idle":"2022-04-06T07:38:22.060309Z","shell.execute_reply.started":"2022-04-06T07:38:22.060084Z","shell.execute_reply":"2022-04-06T07:38:22.060103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss= \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"],optimizer = \"adam\")\nmodel.fit(X_train,\n          y_train, \n          validation_data=(X_test,y_test), \n          batch_size=128,\n          callbacks=[stopping, lr],\n          epochs= ITERATIONS)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-06T07:38:22.061331Z","iopub.status.idle":"2022-04-06T07:38:22.06163Z","shell.execute_reply.started":"2022-04-06T07:38:22.061485Z","shell.execute_reply":"2022-04-06T07:38:22.061502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{"papermill":{"duration":5.203838,"end_time":"2022-02-14T12:06:24.883111","exception":false,"start_time":"2022-02-14T12:06:19.679273","status":"completed"},"tags":[]}},{"cell_type":"code","source":"results = pd.DataFrame(model.history.history )\nresults","metadata":{"papermill":{"duration":5.18519,"end_time":"2022-02-14T12:06:35.177778","exception":false,"start_time":"2022-02-14T12:06:29.992588","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T07:38:22.062765Z","iopub.status.idle":"2022-04-06T07:38:22.063098Z","shell.execute_reply.started":"2022-04-06T07:38:22.062935Z","shell.execute_reply":"2022-04-06T07:38:22.062952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nresults[\"val_accuracy\"].plot()\nresults[\"accuracy\"].plot()\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":5.819416,"end_time":"2022-02-14T12:06:46.054466","exception":false,"start_time":"2022-02-14T12:06:40.23505","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T07:38:22.064171Z","iopub.status.idle":"2022-04-06T07:38:22.064531Z","shell.execute_reply.started":"2022-04-06T07:38:22.06436Z","shell.execute_reply":"2022-04-06T07:38:22.064378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nresults[\"val_loss\"].plot()\nresults[\"loss\"].plot()\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":5.504707,"end_time":"2022-02-14T12:06:56.634994","exception":false,"start_time":"2022-02-14T12:06:51.130287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T07:38:22.065424Z","iopub.status.idle":"2022-04-06T07:38:22.065719Z","shell.execute_reply.started":"2022-04-06T07:38:22.06557Z","shell.execute_reply":"2022-04-06T07:38:22.065586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred = model.predict(X_test)\nval_pred = tensorflow.nn.softmax(val_pred).numpy()\nval_pred = np.argmax(val_pred,axis =1)\n\nprint(accuracy_score(y_test,val_pred))\nprint(classification_report(y_test,val_pred ))","metadata":{"papermill":{"duration":13.906733,"end_time":"2022-02-14T12:07:15.604322","exception":false,"start_time":"2022-02-14T12:07:01.697589","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T07:38:22.066892Z","iopub.status.idle":"2022-04-06T07:38:22.067512Z","shell.execute_reply.started":"2022-04-06T07:38:22.067348Z","shell.execute_reply":"2022-04-06T07:38:22.067366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Full Run submission \n","metadata":{"execution":{"iopub.execute_input":"2022-02-04T13:33:23.118782Z","iopub.status.busy":"2022-02-04T13:33:23.118112Z","iopub.status.idle":"2022-02-04T13:33:23.124013Z","shell.execute_reply":"2022-02-04T13:33:23.122894Z","shell.execute_reply.started":"2022-02-04T13:33:23.118728Z"},"papermill":{"duration":5.187667,"end_time":"2022-02-14T12:07:26.066532","exception":false,"start_time":"2022-02-14T12:07:20.878865","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_pred_full = model.predict(scaler.transform(test)) \n\n# Covert logits to probabilities \ntest_pred_full = tensorflow.nn.softmax(test_pred_full).numpy()\nfull_preds = encoder.inverse_transform(np.argmax(test_pred_full,axis =1) )","metadata":{"papermill":{"duration":12.702308,"end_time":"2022-02-14T12:07:43.943124","exception":false,"start_time":"2022-02-14T12:07:31.240816","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T07:38:22.068406Z","iopub.status.idle":"2022-04-06T07:38:22.069071Z","shell.execute_reply.started":"2022-04-06T07:38:22.068874Z","shell.execute_reply":"2022-04-06T07:38:22.068893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_full = sub.copy(deep=True)\nsub_full[\"target\"] = full_preds\nsub_full.to_csv(\"submission_full.csv\")\nsub_full.head()","metadata":{"papermill":{"duration":5.626982,"end_time":"2022-02-14T12:07:54.783864","exception":false,"start_time":"2022-02-14T12:07:49.156882","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-06T07:38:22.070351Z","iopub.status.idle":"2022-04-06T07:38:22.07084Z","shell.execute_reply.started":"2022-04-06T07:38:22.070563Z","shell.execute_reply":"2022-04-06T07:38:22.070595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Thoughts & bonus model\n\nThis was a quick & easy notebook to get started with the Functional API \\\nAs you may have seen we could add many layers to our model and reference layers to others to create very complex model architectures\n\nBelow are some alternative models for this problem, however with this dataset it might not make as much sense to overcomplicate it","metadata":{}},{"cell_type":"markdown","source":"### Create additional features\nNeural networks like homogeneous data so we will keep our features as is but create new calculated values as a seperate input","metadata":{}},{"cell_type":"code","source":"original_features = test.columns\n\ndef add_feats(df):\n    df[\"mean\"] = df.mean(axis = 1)\n    df[\"median\"] = df.median(axis = 1)\n    df[\"std\"] = df.std(axis = 1)\n    df[\"variance\"] = df.std(axis = 1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-06T08:04:32.68307Z","iopub.execute_input":"2022-04-06T08:04:32.683479Z","iopub.status.idle":"2022-04-06T08:04:32.700174Z","shell.execute_reply.started":"2022-04-06T08:04:32.683444Z","shell.execute_reply":"2022-04-06T08:04:32.699142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_feats(train)\nadd_feats(test)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-04-06T08:04:32.701684Z","iopub.execute_input":"2022-04-06T08:04:32.70196Z","iopub.status.idle":"2022-04-06T08:04:37.288322Z","shell.execute_reply.started":"2022-04-06T08:04:32.701927Z","shell.execute_reply":"2022-04-06T08:04:37.287306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"added_features = [col for col in test.columns if col not in original_features]","metadata":{"execution":{"iopub.status.busy":"2022-04-06T08:04:45.381741Z","iopub.execute_input":"2022-04-06T08:04:45.382022Z","iopub.status.idle":"2022-04-06T08:04:45.387038Z","shell.execute_reply.started":"2022-04-06T08:04:45.381991Z","shell.execute_reply":"2022-04-06T08:04:45.386289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Alternative model \nWe will use the original features as one input and the added features as another","metadata":{}},{"cell_type":"code","source":"# Create two input layers, for the original feature data and the new added features (mean, median,std etc..)\ninput_layer1 = layers.Input(shape=( len(original_features), ))\ninput_layer2 = layers.Input(shape=( len(added_features), ))\n\n# pass inputs to seperate hidden layer\nh1 = layers.Dense(300, activation = \"selu\")(input_layer1)\nh2 = layers.Dense(300, activation = 'selu')(input_layer2)\n\n#concatenate the hidden layers\nconcat_layer = layers.Concatenate(axis =1)([h1,h2])\n\nh3 = layers.Dense(300, activation = \"selu\")(concat_layer)\noutput_layer = layers.Dense(10, activation = \"softmax\")(h3)\n\n#ensure to have both inputs as a list\nmodel = keras.Model(inputs = [input_layer1,input_layer2] , outputs = output_layer)\n\nmodel.compile(loss= \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"],optimizer = \"adam\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T08:10:32.105014Z","iopub.execute_input":"2022-04-06T08:10:32.10538Z","iopub.status.idle":"2022-04-06T08:10:32.653359Z","shell.execute_reply.started":"2022-04-06T08:10:32.105342Z","shell.execute_reply":"2022-04-06T08:10:32.652518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we need two input datasets the original features and the added (pass as a list to X)\nmodel.fit( [ train[original_features], \n            train[added_features]],  \n            y, \n          batch_size=128, \n          epochs= 10)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T08:10:36.649252Z","iopub.execute_input":"2022-04-06T08:10:36.649575Z","iopub.status.idle":"2022-04-06T08:12:30.136141Z","shell.execute_reply.started":"2022-04-06T08:10:36.649542Z","shell.execute_reply":"2022-04-06T08:12:30.135084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remember to pass two datasets for prediction\ntest_preds = model.predict([ test[original_features], \n                                test[added_features]]) ","metadata":{"execution":{"iopub.status.busy":"2022-04-06T08:14:33.173367Z","iopub.execute_input":"2022-04-06T08:14:33.17369Z","iopub.status.idle":"2022-04-06T08:14:42.032837Z","shell.execute_reply.started":"2022-04-06T08:14:33.173656Z","shell.execute_reply":"2022-04-06T08:14:42.031694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Covert logits to probabilities \ntest_preds = tensorflow.nn.softmax(test_preds).numpy()\nfinal_preds = encoder.inverse_transform(np.argmax(test_preds,axis =1) )\nfinal_preds","metadata":{"execution":{"iopub.status.busy":"2022-04-06T08:14:42.0347Z","iopub.execute_input":"2022-04-06T08:14:42.034951Z","iopub.status.idle":"2022-04-06T08:14:42.055005Z","shell.execute_reply.started":"2022-04-06T08:14:42.034919Z","shell.execute_reply":"2022-04-06T08:14:42.053686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}