{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T22:58:01.488618Z","iopub.execute_input":"2022-02-28T22:58:01.488995Z","iopub.status.idle":"2022-02-28T22:58:01.502663Z","shell.execute_reply.started":"2022-02-28T22:58:01.488954Z","shell.execute_reply":"2022-02-28T22:58:01.501861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-28T22:58:01.506767Z","iopub.execute_input":"2022-02-28T22:58:01.50824Z","iopub.status.idle":"2022-02-28T22:58:01.522074Z","shell.execute_reply.started":"2022-02-28T22:58:01.5082Z","shell.execute_reply":"2022-02-28T22:58:01.521472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv', index_col=0)\ntest = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv', index_col=0)\nsubmission = pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T22:58:01.526361Z","iopub.execute_input":"2022-02-28T22:58:01.527718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe(include='object')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum() #check for null data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train['target'] \nX = train.drop(columns=['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring target data","metadata":{}},{"cell_type":"code","source":"y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.value_counts().transpose().plot(kind='bar')\nplt.title('Target data')\nplt.ylabel('Frequency')\nplt.xlabel('Bactrria type')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Model: RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"avg = train.groupby(['target']).mean() # getting the average contributuion for each target\n# avg.head()\navg.transpose().plot(kind='line',figsize=(25, 10))\nplt.title('Contribution to the target')\nplt.ylabel('Average contribution')\nplt.xlabel('ATGC combination')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(random_state=1)\nrf_model.fit(train_X, train_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_val_predictions = rf_model.predict(val_X) # predicting for validation\nrf_val_predictions[:25]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"a_s = accuracy_score(val_y, rf_val_predictions)\nprint('Accuracy score:',a_s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing accuracy","metadata":{}},{"cell_type":"code","source":"labl = y.unique().tolist() #List of Names of Bacteria\n# using confusion_matrix from sklearn.metrics\ncm = confusion_matrix(val_y, rf_val_predictions, labels= labl)\nprint(cm)\n# Normalise\ncmn = cm.astype('float') / cm.sum(axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,10))           \nax = sns.heatmap(cmn, annot=True, fmt='.5f',cmap=\"Blues\",vmin=0.0, vmax=0.005)\nax.set_xticklabels(labl, rotation=90)\nax.set_yticklabels(labl,rotation=0)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Retrain the model with whole train data set","metadata":{}},{"cell_type":"code","source":"rf_model.fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_val_predictions_test = rf_model.predict(test) #predictions for test data set\nrf_val_predictions_test[:25]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing submission","metadata":{}},{"cell_type":"code","source":"col_nam = test.columns # all column names of test data set\ntest_pred = test.copy(deep=False) # make a copy of test data set\ntest_pred['target'] = rf_val_predictions_test # adding new column to test tata set\noutput= test_pred.drop(columns=col_nam) # droping unnecessary columns\noutput.reset_index(inplace=True) # rest index\noutput.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Writing in to a csv file","metadata":{}},{"cell_type":"code","source":"output.to_csv('submission.csv', index=False)\nprint(\"submission was successful\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nimport optuna","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_row_id = df_test.row_id \ntrain_data = df_train.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tar = pd.DataFrame(df_train['target'].value_counts())\ndf_tar['species']=df_tar.index\ndf_tar = df_tar.reset_index(drop=True)\nfor i in df_tar.index:\n    df_tar['percentage']=df_tar['target']/df_tar['target'].sum()*100\ndf_tar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.barplot(y='species',x='target',data=df_tar)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = [e for e in df_test.columns if e not in ('row_id')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s1 = pd.merge(df_train, df_test, how='inner', on=cols)\ns1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic = {}\nfor i in range(len(s1)):\n    dic[s1.loc[i]['row_id_y']] = s1.loc[i]['row_id_x']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s1 = s1.set_index('row_id_x')\ns1_idx = s1.index.to_list()\ndf_train = df_train.drop(s1_idx)\n\ndf_train = df_train.drop_duplicates(subset=cols, keep='first')\ndf_train = df_train.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df_train)):\n    df_train.loc[valid_indicies,\"kfold\"] = fold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [c for c in df_train.columns if c not in (\"row_id\", \"target\", \"kfold\")]\ndf_test = df_test[useful_features]\nfor col in useful_features:\n    df_train[col] = np.log1p(df_train[col])\n    df_test[col] = np.log1p(df_test[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def xgboost(trial):\n    fold = 0\n    \n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.1, log=True)\n    reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n    reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n    subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n    max_depth = trial.suggest_int(\"max_depth\", 3, 25)\n    \n    xtrain =  df_train[df_train.kfold != fold].reset_index(drop=True)\n    xvalid = df_train[df_train.kfold == fold].reset_index(drop=True)\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    le = preprocessing.LabelEncoder()\n    ytrain = le.fit_transform(ytrain)\n    yvalid = le.fit_transform(yvalid)\n    \n    model = XGBClassifier(random_state=fold,\n                          tree_method='gpu_hist',\n                          gpu_id=0, predictor=\"gpu_predictor\",\n                          use_label_encoder =False,\n                          n_jobs=-1,\n                          n_estimators=1000,\n                          eval_metric='rmse',\n                          learning_rate=learning_rate,\n                          reg_lambda=reg_lambda,\n                          reg_alpha=reg_alpha,\n                          subsample=subsample,\n                          colsample_bytree=colsample_bytree,\n                          max_depth=max_depth,\n                         )\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    return rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#study = optuna.create_study(direction=\"minimize\")\n#study.optimize(xgboost, n_trials=20,gc_after_trial=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#study.best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(5):\n    \n    xtrain = df_train[df_train.kfold != fold].reset_index(drop=True)\n    xvalid = df_train[df_train.kfold == fold].reset_index(drop=True)\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    le = preprocessing.LabelEncoder()\n    ytrain = le.fit_transform(ytrain)\n    yvalid = le.fit_transform(yvalid)\n    \n    model = XGBClassifier(random_state=fold,\n                          tree_method='gpu_hist',\n                          gpu_id=0, predictor=\"gpu_predictor\",\n                          use_label_encoder =False,\n                          n_jobs=-1,\n                          n_estimators=1000,\n                          eval_metric='rmse',\n                          learning_rate=0.0958614407371858,\n                          reg_lambda= 0.013277441840190538,\n                          reg_alpha= 0.0078106631860548935,\n                          subsample= 0.5644494238856632,\n                          colsample_bytree=0.854776309994251,\n                          max_depth=15,\n                         )\n    model.fit(xtrain, ytrain)\n    print(f'fold{fold} ',model.score(xvalid,yvalid))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(df_test)\nres = le.inverse_transform(preds)\ndf = pd.DataFrame({'row_id': df_test_row_id,'target': res})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for e in dic:\n    df.loc[df[df['row_id']==e].index.to_list(),'target'] = train_data.loc[train_data[train_data['row_id']==dic[e]].index.tolist()[0],'target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('Submission_01.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}