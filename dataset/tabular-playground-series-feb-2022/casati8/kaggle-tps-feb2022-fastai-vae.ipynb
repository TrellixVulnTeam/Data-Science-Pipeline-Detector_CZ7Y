{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from fastai.tabular.all import * \nfrom fastai.test_utils import show_install\n\nshow_install()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-18T16:03:42.637722Z","iopub.execute_input":"2022-02-18T16:03:42.637969Z","iopub.status.idle":"2022-02-18T16:03:45.219919Z","shell.execute_reply.started":"2022-02-18T16:03:42.637904Z","shell.execute_reply":"2022-02-18T16:03:45.219108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:03:45.221871Z","iopub.execute_input":"2022-02-18T16:03:45.222173Z","iopub.status.idle":"2022-02-18T16:03:45.228438Z","shell.execute_reply.started":"2022-02-18T16:03:45.222134Z","shell.execute_reply":"2022-02-18T16:03:45.227655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed_value(seed=718):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed_value()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:03:45.229742Z","iopub.execute_input":"2022-02-18T16:03:45.2301Z","iopub.status.idle":"2022-02-18T16:03:45.238813Z","shell.execute_reply.started":"2022-02-18T16:03:45.230059Z","shell.execute_reply":"2022-02-18T16:03:45.238107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path('../input/tabular-playground-series-feb-2022')\nPath.BASE_PATH = path\npath.ls()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:03:45.240907Z","iopub.execute_input":"2022-02-18T16:03:45.241338Z","iopub.status.idle":"2022-02-18T16:03:45.254973Z","shell.execute_reply.started":"2022-02-18T16:03:45.241286Z","shell.execute_reply":"2022-02-18T16:03:45.254154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(path, 'train.csv')).set_index(\"row_id\")\ntest_df = pd.read_csv(os.path.join(path, 'test.csv')).set_index(\"row_id\")\nsample_submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:03:45.2572Z","iopub.execute_input":"2022-02-18T16:03:45.257457Z","iopub.status.idle":"2022-02-18T16:04:22.281948Z","shell.execute_reply.started":"2022-02-18T16:03:45.257425Z","shell.execute_reply":"2022-02-18T16:04:22.281063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dep_var= 'target'","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:22.283525Z","iopub.execute_input":"2022-02-18T16:04:22.283769Z","iopub.status.idle":"2022-02-18T16:04:22.297059Z","shell.execute_reply.started":"2022-02-18T16:04:22.283735Z","shell.execute_reply":"2022-02-18T16:04:22.296361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = train_df[(train_df[dep_var] == 'Enterococcus_hirae') | (train_df[dep_var] == 'Escherichia_coli')]\nlen(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:22.298109Z","iopub.execute_input":"2022-02-18T16:04:22.298721Z","iopub.status.idle":"2022-02-18T16:04:22.306031Z","shell.execute_reply.started":"2022-02-18T16:04:22.298685Z","shell.execute_reply":"2022-02-18T16:04:22.3053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_vars, cat_vars = cont_cat_split(train_df, dep_var= dep_var)\nlen(cat_vars), len(cont_vars)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:22.308253Z","iopub.execute_input":"2022-02-18T16:04:22.3098Z","iopub.status.idle":"2022-02-18T16:04:22.514018Z","shell.execute_reply.started":"2022-02-18T16:04:22.309768Z","shell.execute_reply":"2022-02-18T16:04:22.513365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ReadTabBatchIdentity(ItemTransform):\n    \"Read a batch of data and return the inputs as both `x` and `y`\"\n    def __init__(self, to): store_attr()\n\n    def encodes(self, to):\n        if not to.with_cont: res = (tensor(to.cats).long(),) + (tensor(to.cats).long(),)\n        else: res = (tensor(to.cats).long(),tensor(to.conts).float()) + (tensor(to.cats).long(), tensor(to.conts).float())\n        if to.device is not None: res = to_device(res, to.device)\n        return res\n    \nclass TabularPandasIdentity(TabularPandas): pass","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:22.515011Z","iopub.execute_input":"2022-02-18T16:04:22.515358Z","iopub.status.idle":"2022-02-18T16:04:22.523985Z","shell.execute_reply.started":"2022-02-18T16:04:22.515327Z","shell.execute_reply":"2022-02-18T16:04:22.523353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@delegates()\nclass TabDataLoaderIdentity(TabDataLoader):\n    \"A transformed `DataLoader` for AutoEncoder problems with Tabular data\"\n    do_item = noops\n    def __init__(self, dataset, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):\n        if after_batch is None: after_batch = L(TransformBlock().batch_tfms)+ReadTabBatchIdentity(dataset)\n        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)\n\n    def create_batch(self, b): \n        return self.dataset.iloc[b]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:22.526608Z","iopub.execute_input":"2022-02-18T16:04:22.527149Z","iopub.status.idle":"2022-02-18T16:04:22.539959Z","shell.execute_reply.started":"2022-02-18T16:04:22.527111Z","shell.execute_reply":"2022-02-18T16:04:22.539373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TabularPandasIdentity._dl_type = TabDataLoaderIdentity","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:22.541578Z","iopub.execute_input":"2022-02-18T16:04:22.541972Z","iopub.status.idle":"2022-02-18T16:04:22.553814Z","shell.execute_reply.started":"2022-02-18T16:04:22.541937Z","shell.execute_reply":"2022-02-18T16:04:22.55309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to = TabularPandasIdentity(train_df, \n                           [Categorify, FillMissing, Normalize], \n                           cat_vars, cont_vars, \n                           device=device,\n                           splits=RandomSplitter(seed=32)(train_df))\ndls = to.dataloaders(bs=1024)\ndls.n_inp = 2\n\nlen(dls.train), len(dls.valid)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:22.554688Z","iopub.execute_input":"2022-02-18T16:04:22.554933Z","iopub.status.idle":"2022-02-18T16:04:24.750478Z","shell.execute_reply.started":"2022-02-18T16:04:22.554896Z","shell.execute_reply":"2022-02-18T16:04:24.749695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = dls.one_batch()\nbatch[1].min(), batch[1].max()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:24.751573Z","iopub.execute_input":"2022-02-18T16:04:24.752408Z","iopub.status.idle":"2022-02-18T16:04:27.494862Z","shell.execute_reply.started":"2022-02-18T16:04:24.75237Z","shell.execute_reply":"2022-02-18T16:04:27.494157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"means = pd.DataFrame.from_dict({k:[v] for k,v in dls.train_ds.means.items()})\nstds = pd.DataFrame.from_dict({k:[v] for k,v in dls.train_ds.stds.items()})\n\nlow = (train_df[cont_vars].min().to_frame().T.values - means.values) / stds.values\nhigh = (train_df[cont_vars].max().to_frame().T.values - means.values) / stds.values","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:27.495992Z","iopub.execute_input":"2022-02-18T16:04:27.49637Z","iopub.status.idle":"2022-02-18T16:04:28.097815Z","shell.execute_reply.started":"2022-02-18T16:04:27.496333Z","shell.execute_reply":"2022-02-18T16:04:28.09701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_cats = {k:len(v) for k,v in to.classes.items()}\ntotal_cats","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.101043Z","iopub.execute_input":"2022-02-18T16:04:28.101474Z","iopub.status.idle":"2022-02-18T16:04:28.107697Z","shell.execute_reply.started":"2022-02-18T16:04:28.101443Z","shell.execute_reply":"2022-02-18T16:04:28.106825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RecreatedLoss(Module):\n    \"Measures how well we have created the original tabular inputs\"\n    def __init__(self, cat_dict, reduction='mean'):\n        ce = CrossEntropyLossFlat(reduction='none')\n        mse = MSELossFlat(reduction='none')\n        store_attr('cat_dict,ce,mse,reduction')\n\n    def forward(self, preds, cat_targs, cont_targs):\n        cats, conts = preds\n        tot_ce, pos = [0], 0\n        for i, (k,v) in enumerate(self.cat_dict.items()):\n            tot_ce += [self.ce(cats[:, pos:pos+v], cat_targs[:,i])]\n            pos += v\n            \n        tot_ce = torch.zeros(cats.shape[0], device=device)\n        if len(self.cat_dict.items())>0:\n            tot_ce += torch.stack(tot_ce, axis=1).mean(axis=1)\n        cont_loss = self.mse(conts, cont_targs).view(conts.shape).mean(axis=1)\n        \n        total_loss = torch.stack([tot_ce, cont_loss], axis=1).sum(axis=1)\n        # total_loss = cont_loss\n        \n        if self.reduction == 'mean':\n            return total_loss.mean()\n        elif self.reduction == 'sum':\n            return total_loss.sum()\n        \n        return total_loss\n    \nloss_func = RecreatedLoss(total_cats)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.109103Z","iopub.execute_input":"2022-02-18T16:04:28.109844Z","iopub.status.idle":"2022-02-18T16:04:28.123483Z","shell.execute_reply.started":"2022-02-18T16:04:28.109807Z","shell.execute_reply":"2022-02-18T16:04:28.122794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAERecreatedLoss(Module):\n    \"Measures how well we have created the original tabular inputs, plus the KL Divergence with the unit normal distribution\"\n    def __init__(self, cat_dict, dataset_size, bs=1024):\n        ce = CrossEntropyLossFlat(reduction='sum')\n        mse = MSELossFlat()\n        store_attr('ce,mse,dataset_size,bs')\n      \n    def forward(self, preds, cat_targs, cont_targs):\n        \n        if(len(preds) == 5):\n            cats,conts, mu, logvar, kl_weight = preds\n        else:\n            cats,conts, mu, logvar = preds\n            kl_weight = 1\n\n        r_loss = self.mse(conts, cont_targs) /(1 + len(conts))\n        r_loss *= self.dataset_size / self.bs\n        \n        kld_loss =  -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n        kld_loss = kl_weight * torch.mean(kld_loss)\n       # if kl_weight > 0:\n       #     print('kl_weight ', kl_weight.item(), 'kld_loss ', kld_loss.item() , ' r_loss ', r_loss.item())\n        return kld_loss + r_loss\n        \nvae_loss_func = VAERecreatedLoss(total_cats, train_df.shape[0], bs=dls.bs)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.124831Z","iopub.execute_input":"2022-02-18T16:04:28.12511Z","iopub.status.idle":"2022-02-18T16:04:28.136369Z","shell.execute_reply.started":"2022-02-18T16:04:28.125075Z","shell.execute_reply":"2022-02-18T16:04:28.135665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BatchSwapNoise(Module):\n    \"Swap Noise Module\"\n    def __init__(self, p): store_attr()\n\n    def forward(self, x):\n        if self.training:\n            mask = torch.rand(x.size()) > (1 - self.p)\n            l1 = torch.floor(torch.rand(x.size()) * x.size(0)).type(torch.LongTensor)\n            l2 = (mask.type(torch.LongTensor) * x.size(1))\n            res = (l1 * l2).view(-1)\n            idx = torch.arange(x.nelement()) + res\n            idx[idx>=x.nelement()] = idx[idx>=x.nelement()]-x.nelement()\n            return x.flatten()[idx].view(x.size())\n        else:\n            return x","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.138698Z","iopub.execute_input":"2022-02-18T16:04:28.140396Z","iopub.status.idle":"2022-02-18T16:04:28.1487Z","shell.execute_reply.started":"2022-02-18T16:04:28.140359Z","shell.execute_reply":"2022-02-18T16:04:28.147953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TabularAE(TabularModel):\n    \"A simple AutoEncoder model\"\n    def __init__(self, emb_szs, n_cont, hidden_size, cats, low, high, ps=0.2, embed_p=0.01, bswap=None, act_cls=Mish()):\n        super().__init__(emb_szs, n_cont, out_sz=hidden_size, layers=[1024, 512, 256], embed_p=embed_p, act_cls=act_cls)\n        \n        self.bswap = bswap\n        self.cats = cats\n        self.activation_cats = sum([v for k,v in cats.items()])\n        \n        self.layers = nn.Sequential(*L(self.layers.children())[:-1] + nn.Sequential(LinBnDrop(256, hidden_size, p=ps, act=Mish())))\n        \n        if(bswap != None): self.noise = BatchSwapNoise(bswap)\n        self.decoder = nn.Sequential(\n            LinBnDrop(hidden_size, 256, p=ps, act=act_cls),\n            # tab_vae1\n            LinBnDrop(256, 512, p=ps, act=act_cls),\n            LinBnDrop(512, 1024, p=ps, act=act_cls),\n        )\n        \n        self.decoder_cont = nn.Sequential(\n            LinBnDrop(1024, 512, p=ps, act=act_cls),\n            LinBnDrop(512, 128, p=ps, act=act_cls),\n            LinBnDrop(128, n_cont, p=ps, bn=False, act=None),\n            SigmoidRange(low=low, high=high)\n        )\n        \n        self.decoder_cat = nn.Sequential(\n            LinBnDrop(1024, 512, p=ps, act=act_cls),\n            LinBnDrop(512, 128, p=ps, act=act_cls),\n            LinBnDrop(128, self.activation_cats, p=ps, bn=False, act=None)\n        )\n        \n    def forward(self, x_cat, x_cont=None, do_encode=False):\n        if(self.bswap != None):\n            x_cat = self.noise(x_cat)\n            x_cont = self.noise(x_cont)\n            \n        encoded = super().forward(x_cat, x_cont)\n        if do_encode: \n            return encoded # return the representation\n        decoded_trunk = self.decoder(encoded)\n        decoded_cats = self.decoder_cat(decoded_trunk)\n        decoded_conts = self.decoder_cont(decoded_trunk)\n        return decoded_cats, decoded_conts","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.149861Z","iopub.execute_input":"2022-02-18T16:04:28.150566Z","iopub.status.idle":"2022-02-18T16:04:28.165494Z","shell.execute_reply.started":"2022-02-18T16:04:28.15053Z","shell.execute_reply":"2022-02-18T16:04:28.164703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TabularVAE(TabularModel):\n    def __init__(self, emb_szs, n_cont, hidden_size, cats, low, high, ps=0.2, embed_p=0.01, bswap=None, act_cls=Mish()):\n        super().__init__(emb_szs, n_cont, layers=[300,200,100], out_sz=2*hidden_size, embed_p=embed_p, act_cls=act_cls)\n        \n        self.bswap = bswap\n        self.cats = cats\n        self.activation_cats = sum([v for k,v in cats.items()])\n        \n        self.logVarLayer = LinBnDrop(2*hidden_size, hidden_size, p=ps)\n        self.muLayer = LinBnDrop(2*hidden_size, hidden_size, p=ps)\n        \n        if self.bswap != None: \n            self.noise = BatchSwapNoise(self.bswap)\n            \n        self.decoder = nn.Sequential(\n            LinBnDrop(hidden_size, 256, p=ps, act=act_cls),\n            LinBnDrop(256, 512, p=ps, act=act_cls),\n            LinBnDrop(512, 256, p=ps, act=act_cls)\n        )\n        \n        self.decoder_cont = nn.Sequential(\n            LinBnDrop(256, n_cont, p=ps, bn=False, act=None),\n            SigmoidRange(low=low, high=high)\n        )\n        \n        self.decoder_cat = nn.Sequential(\n            LinBnDrop(256, self.activation_cats, p=ps, bn=False, act=None)\n        )\n        \n        self.decoder = nn.Sequential(\n            LinBnDrop(hidden_size, 256, p=ps, act=act_cls),\n            LinBnDrop(256, 512, p=ps, act=act_cls),\n            LinBnDrop(512, 1024, p=ps, act=act_cls)\n        )\n        \n        self.decoder_cont = nn.Sequential(\n            LinBnDrop(1024, n_cont, p=ps, bn=False, act=None),\n            SigmoidRange(low=-10, high=10)\n        )\n        \n        self.decoder_cat = LinBnDrop(1024, self.activation_cats, p=ps, bn=False, act=None)\n        \n    \n    @staticmethod\n    def reparameterize(mu, logvar):\n        std = torch.exp(logvar/2)\n        eps = torch.randn_like(std, device=device)\n        return mu + eps * std\n    \n    def bottleneck(self, x):\n        mu = self.muLayer(x)\n        logvar = self.logVarLayer(x)\n        z = self.reparameterize(mu, logvar)\n        return z, mu, logvar\n        \n    def forward(self, x_cat, x_cont=None, do_encode=False):\n        if(self.bswap != None):\n            x_cencodedat = self.noise(x_cat)\n            x_cont = self.noise(x_cont)\n        \n        encoded = super().forward(x_cat, x_cont)\n        z, mu, logvar = self.bottleneck(encoded)\n        \n        if(do_encode): \n            return z\n        \n        decoded_trunk = self.decoder(z)\n        decoded_cats = self.decoder_cat(decoded_trunk)\n        decoded_conts = self.decoder_cont(decoded_trunk)\n        return decoded_cats, decoded_conts, mu, logvar","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.16861Z","iopub.execute_input":"2022-02-18T16:04:28.169092Z","iopub.status.idle":"2022-02-18T16:04:28.186938Z","shell.execute_reply.started":"2022-02-18T16:04:28.169064Z","shell.execute_reply":"2022-02-18T16:04:28.18623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MSEMetric(Metric):\n    def __init__(self): \n        self.preds = []\n        mse = MSELossFlat()\n        store_attr('mse')\n        \n    def reset(self): \n        self.preds.clear()\n        \n    def accumulate(self, learn):\n        _, conts, _, _ = learn.pred\n        _, cont_targs = learn.y\n        r_loss = self.mse(conts, cont_targs) /(1 + len(conts))\n        \n        self.preds.append(to_detach(r_loss))\n    @property\n    def value(self):\n        return np.array(self.preds).mean()\n    \nclass CEMetric(Metric):\n    def __init__(self): self.preds = []\n    def accumulate(self, learn):\n        cats, conts, mu, logvar = learn.pred\n        cat_targs, cont_targs = learn.y\n        CE = cats.new([0])\n        pos=0\n        for i, (k,v) in enumerate(total_cats.items()):\n            CE += F.cross_entropy(cats[:, pos:pos+v], cat_targs[:, i], reduction='sum')\n            pos += v\n \n        norm = cats.new([len(total_cats.keys())])\n        self.preds.append(to_detach(CE/norm))\n        \n    @property\n    def value(self):\n        return np.array(self.preds).mean()\n    \nclass KldMetric(Metric):\n    def __init__(self):\n        self.preds = []\n    \n    def reset(self): \n        self.preds.clear()\n        \n    def accumulate(self, learn):\n        _, _,mu,logvar = learn.pred\n        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n        self.preds.append(to_detach(torch.mean(KLD)))\n        \n    @property\n    def value(self):\n        return np.array(self.preds).mean()\n    \nclass MuMetric(Metric):\n    def __init__(self): \n        self.preds = []\n    \n    def reset(self): \n        self.preds.clear()\n        \n    def accumulate(self, learn):\n        _, _, mu,_ = learn.pred\n        self.preds.append(to_detach(mu.mean()))\n    @property\n    def value(self):\n        return np.array(self.preds).mean()\n    \nclass StdMetric(Metric):\n    def __init__(self): \n        self.preds = []\n    \n    def reset(self): \n        self.preds.clear()\n        \n    def accumulate(self, learn):\n        _, _,_, logvar = learn.pred\n        self.preds.append(to_detach(logvar.mean()))\n    @property\n    def value(self):\n        return np.array(self.preds).mean()\n    \nclass CeMetric(Metric):\n    def __init__(self): self.preds = []\n    def accumulate(self, learn):\n        cats, conts, mu, logvar = learn.pred\n        cat_targs, cont_targs = learn.y\n        CE = cats.new([0])\n        pos=0\n        for i, (k,v) in enumerate(total_cats.items()):\n            CE += F.cross_entropy(cats[:, pos:pos+v], cat_targs[:, i], reduction='sum')\n            pos += v\n\n        norm = cats.new([1+len(total_cats.keys())])\n        self.preds.append(to_detach(CE/norm))\n    @property\n    def value(self):\n        return np.array(self.preds).mean()    ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.188473Z","iopub.execute_input":"2022-02-18T16:04:28.188684Z","iopub.status.idle":"2022-02-18T16:04:28.211457Z","shell.execute_reply.started":"2022-02-18T16:04:28.188654Z","shell.execute_reply":"2022-02-18T16:04:28.210715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_szs = get_emb_sz(to.train)\nlatent_space_size = 8\nlow_values = tensor(low).to(device)\nhigh_values = tensor(high).to(device)\n\nmodelVAE = TabularVAE(emb_szs, len(cont_vars), \n                      latent_space_size, \n                      ps=0.0, cats=total_cats, \n                      embed_p=0.0,\n                      bswap=None, \n                      low=low_values, high=high_values)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.213657Z","iopub.execute_input":"2022-02-18T16:04:28.21484Z","iopub.status.idle":"2022-02-18T16:04:28.302113Z","shell.execute_reply.started":"2022-02-18T16:04:28.214803Z","shell.execute_reply":"2022-02-18T16:04:28.301377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AnnealedLossCallback(Callback):\n    def after_pred(self):\n        if (len(self.learn.pred)):\n            kl = self.learn.pred[0].new(1)\n            kl[0] = self.opt.hypers[0]['kl_weight']\n\n            self.learn.pred = self.learn.pred + (kl,)\n        \n    def after_batch(self):\n        if(len(self.learn.pred)):\n            cats, conts, mu, logvar, _ = self.learn.pred\n        else:\n            cats, conts, mu, logvar = self.learn.pred\n            \n        self.learn.pred = (cats, conts, mu, logvar)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.303233Z","iopub.execute_input":"2022-02-18T16:04:28.303785Z","iopub.status.idle":"2022-02-18T16:04:28.312384Z","shell.execute_reply.started":"2022-02-18T16:04:28.303747Z","shell.execute_reply":"2022-02-18T16:04:28.311544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = combine_scheds([.1, .3, .6], [SchedCos(0,0), SchedCos(0,1), SchedNo(1,1)])\ncallbacks = [ParamScheduler({'kl_weight': f }), AnnealedLossCallback()]\n\nlearn = Learner(dls, modelVAE, loss_func= vae_loss_func, \n                cbs=callbacks, \n                wd=0.01,\n                metrics=[MSEMetric(), KldMetric(),  MuMetric(), StdMetric()], \n                opt_func=ranger)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.313831Z","iopub.execute_input":"2022-02-18T16:04:28.314284Z","iopub.status.idle":"2022-02-18T16:04:28.331729Z","shell.execute_reply.started":"2022-02-18T16:04:28.314248Z","shell.execute_reply":"2022-02-18T16:04:28.33111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.332927Z","iopub.execute_input":"2022-02-18T16:04:28.33317Z","iopub.status.idle":"2022-02-18T16:04:28.336777Z","shell.execute_reply.started":"2022-02-18T16:04:28.333128Z","shell.execute_reply":"2022-02-18T16:04:28.336027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lear#n.fit_one_cycle(200, 5e-3, cbs=SaveModelCallback(fname='tab_vae1', with_opt=True)) \nlearn.fit_flat_cos(200, lr=5e-5, cbs=SaveModelCallback(fname='tab_vae1', with_opt=True)) ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:04:28.338358Z","iopub.execute_input":"2022-02-18T16:04:28.338842Z","iopub.status.idle":"2022-02-18T16:16:31.711462Z","shell.execute_reply.started":"2022-02-18T16:04:28.338807Z","shell.execute_reply":"2022-02-18T16:16:31.710766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#learn.load('tab_vae1')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:31.712792Z","iopub.execute_input":"2022-02-18T16:16:31.713047Z","iopub.status.idle":"2022-02-18T16:16:31.716178Z","shell.execute_reply.started":"2022-02-18T16:16:31.713012Z","shell.execute_reply":"2022-02-18T16:16:31.715506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_compressed_representation(l, df):\n    dl = l.dls.test_dl(df)\n    comp_reps = []\n    l.model.eval()\n    l.model.cuda()\n    for batch in dl:\n        with torch.no_grad():\n            act_rep = l.model(*batch[:2], True).cpu().numpy()\n            comp_reps.append(act_rep)\n    return np.concatenate(comp_reps)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:31.721059Z","iopub.execute_input":"2022-02-18T16:16:31.721462Z","iopub.status.idle":"2022-02-18T16:16:31.729004Z","shell.execute_reply.started":"2022-02-18T16:16:31.721428Z","shell.execute_reply":"2022-02-18T16:16:31.728186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dl = learn.dls.test_dl(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:31.730242Z","iopub.execute_input":"2022-02-18T16:16:31.730513Z","iopub.status.idle":"2022-02-18T16:16:32.739298Z","shell.execute_reply.started":"2022-02-18T16:16:31.730478Z","shell.execute_reply":"2022-02-18T16:16:32.738472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outs = []\nlearn.model.eval()\nlearn.model.cuda()\nfor batch in dl:\n    with torch.no_grad():\n        out = learn.model(*batch[:2], True).cpu().numpy()\n        outs.append(out)\nouts = np.concatenate(outs)\n\nouts.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:32.740514Z","iopub.execute_input":"2022-02-18T16:16:32.741224Z","iopub.status.idle":"2022-02-18T16:16:34.135802Z","shell.execute_reply.started":"2022-02-18T16:16:32.741184Z","shell.execute_reply":"2022-02-18T16:16:34.135093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(cat_preds, cont_preds, mu, logvar), (cat_targs, cont_targs) = learn.get_preds(dl=dl)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:34.136833Z","iopub.execute_input":"2022-02-18T16:16:34.137221Z","iopub.status.idle":"2022-02-18T16:16:37.248711Z","shell.execute_reply.started":"2022-02-18T16:16:34.137181Z","shell.execute_reply":"2022-02-18T16:16:37.247991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ys = train_df[dep_var].to_numpy()\nlen(outs), len(ys)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:37.250195Z","iopub.execute_input":"2022-02-18T16:16:37.250472Z","iopub.status.idle":"2022-02-18T16:16:37.256807Z","shell.execute_reply.started":"2022-02-18T16:16:37.250438Z","shell.execute_reply":"2022-02-18T16:16:37.256033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"para_col_names = [str(x).zfill(3) for x in range(0,latent_space_size)]\nencoded_train_df = pd.DataFrame(columns=[dep_var] + para_col_names)\nencoded_train_df[dep_var] = train_df[dep_var]\nencoded_train_df[para_col_names] = outs\nencoded_train_df[para_col_names] = encoded_train_df[para_col_names].astype(np.float32)\n\nencoded_train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:37.258054Z","iopub.execute_input":"2022-02-18T16:16:37.258384Z","iopub.status.idle":"2022-02-18T16:16:37.429632Z","shell.execute_reply.started":"2022-02-18T16:16:37.258349Z","shell.execute_reply":"2022-02-18T16:16:37.428681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nx_col = '000'\ny_col = '001'\ndf_x = encoded_train_df[[x_col, y_col, dep_var]].copy()\n\nplt.figure(figsize=(14,7))\nsns.scatterplot(data=df_x, x=x_col, y=y_col, hue=dep_var, alpha=0.8, palette=\"bright\")\nplt.title(\"AutoEncoder\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:37.431182Z","iopub.execute_input":"2022-02-18T16:16:37.431459Z","iopub.status.idle":"2022-02-18T16:16:44.212845Z","shell.execute_reply.started":"2022-02-18T16:16:37.431423Z","shell.execute_reply":"2022-02-18T16:16:44.212172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new_names =  [str(x).zfill(3) for x in range(0,128)]\nsplits = RandomSplitter()(range_of(encoded_train_df))\nto2 = TabularPandas(encoded_train_df, \n                   procs = [Normalize], \n                   cont_names=para_col_names, \n                   splits=splits, \n                   y_names=dep_var,\n                   y_block=CategoryBlock())","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:44.213753Z","iopub.execute_input":"2022-02-18T16:16:44.213958Z","iopub.status.idle":"2022-02-18T16:16:44.331379Z","shell.execute_reply.started":"2022-02-18T16:16:44.21393Z","shell.execute_reply":"2022-02-18T16:16:44.330636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls2 = to2.dataloaders(bs=2048)\nlen(dls2.train), len(dls2.valid)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:44.33248Z","iopub.execute_input":"2022-02-18T16:16:44.332726Z","iopub.status.idle":"2022-02-18T16:16:44.348253Z","shell.execute_reply.started":"2022-02-18T16:16:44.332695Z","shell.execute_reply":"2022-02-18T16:16:44.347494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(inp, targ, axis=-1):\n    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n    pred,targ = flatten_check(inp.argmax(dim=axis), targ)\n    return (pred == targ).float().mean()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:44.349659Z","iopub.execute_input":"2022-02-18T16:16:44.349941Z","iopub.status.idle":"2022-02-18T16:16:44.354603Z","shell.execute_reply.started":"2022-02-18T16:16:44.349904Z","shell.execute_reply":"2022-02-18T16:16:44.353959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn2 = tabular_learner(dls2, \n                         layers=[1024,1024,512,256,128], \n                         metrics=[accuracy])\nlearn2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:44.355853Z","iopub.execute_input":"2022-02-18T16:16:44.35626Z","iopub.status.idle":"2022-02-18T16:16:44.568272Z","shell.execute_reply.started":"2022-02-18T16:16:44.356223Z","shell.execute_reply":"2022-02-18T16:16:44.567505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn2.lr_find()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:44.569765Z","iopub.execute_input":"2022-02-18T16:16:44.570041Z","iopub.status.idle":"2022-02-18T16:16:46.841559Z","shell.execute_reply.started":"2022-02-18T16:16:44.570001Z","shell.execute_reply":"2022-02-18T16:16:46.840817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn2.fit_one_cycle(250, 7e-3, wd=0.01, cbs=SaveModelCallback(fname='kaggle_tps_feb_2022_vae', with_opt=True)) ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:16:46.84276Z","iopub.execute_input":"2022-02-18T16:16:46.843331Z","iopub.status.idle":"2022-02-18T16:21:59.934555Z","shell.execute_reply.started":"2022-02-18T16:16:46.843274Z","shell.execute_reply":"2022-02-18T16:21:59.933896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn2.load('kaggle_tps_feb_2022_vae')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:21:59.935662Z","iopub.execute_input":"2022-02-18T16:21:59.93592Z","iopub.status.idle":"2022-02-18T16:21:59.963802Z","shell.execute_reply.started":"2022-02-18T16:21:59.935882Z","shell.execute_reply":"2022-02-18T16:21:59.963192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn2)\ninterp.plot_confusion_matrix(normalize=True, norm_dec=3, figsize=(10, 10))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:21:59.964904Z","iopub.execute_input":"2022-02-18T16:21:59.965208Z","iopub.status.idle":"2022-02-18T16:22:01.036843Z","shell.execute_reply.started":"2022-02-18T16:21:59.965171Z","shell.execute_reply":"2022-02-18T16:22:01.036139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#outs = get_compressed_representation(learn, test_df)\n\ndl = learn.dls.test_dl(test_df)\nouts = []\nlearn.model.eval()\nlearn.model.cuda()\nfor batch in dl:\n    with torch.no_grad():\n        out = learn.model(*batch[:2], True).cpu().numpy()\n        outs.append(out)\nouts = np.concatenate(outs)\n\nouts.shape\n\nencoded_test_df = pd.DataFrame(columns=para_col_names)\nencoded_test_df[para_col_names] = outs\nencoded_test_df[para_col_names] = encoded_train_df[para_col_names].astype(np.float32)\n\nencoded_test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:22:01.038094Z","iopub.execute_input":"2022-02-18T16:22:01.03887Z","iopub.status.idle":"2022-02-18T16:22:02.318959Z","shell.execute_reply.started":"2022-02-18T16:22:01.038829Z","shell.execute_reply":"2022-02-18T16:22:02.318217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dlt = learn2.dls.test_dl(encoded_test_df, bs=4096) \npreds, _ = learn2.get_preds(dl=dlt) \nprint(preds[:2])","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:22:02.320118Z","iopub.execute_input":"2022-02-18T16:22:02.321506Z","iopub.status.idle":"2022-02-18T16:22:02.616795Z","shell.execute_reply.started":"2022-02-18T16:22:02.321461Z","shell.execute_reply":"2022-02-18T16:22:02.616032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoded_preds_str = dls2.train.categorize.vocab.map_ids(np.argmax(preds, axis=1))\nsample_submission[dep_var] =  decoded_preds_str\nsample_submission.to_csv(\"submission.csv\", index=False)\nsample_submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:22:02.618234Z","iopub.execute_input":"2022-02-18T16:22:02.618497Z","iopub.status.idle":"2022-02-18T16:22:03.572667Z","shell.execute_reply.started":"2022-02-18T16:22:02.618461Z","shell.execute_reply":"2022-02-18T16:22:03.571987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dep_var_dist = pd.DataFrame({\n    'target_count': train_df[dep_var].value_counts(),\n    'target_quota (%)': train_df[dep_var].value_counts() / train_df.shape[0] * 100,\n})\n\n\ndep_var_dist['pred_count'] = pd.Series(decoded_preds_str, index=test_df.index).value_counts()\ndep_var_dist['pred_quota (%)'] = dep_var_dist['pred_count'] / len(test_df) * 100\ndep_var_dist.sort_index().head(11)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:22:03.573999Z","iopub.execute_input":"2022-02-18T16:22:03.574246Z","iopub.status.idle":"2022-02-18T16:22:03.662578Z","shell.execute_reply.started":"2022-02-18T16:22:03.574212Z","shell.execute_reply":"2022-02-18T16:22:03.661889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -la ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:22:03.663639Z","iopub.execute_input":"2022-02-18T16:22:03.663887Z","iopub.status.idle":"2022-02-18T16:22:04.38351Z","shell.execute_reply.started":"2022-02-18T16:22:03.663854Z","shell.execute_reply":"2022-02-18T16:22:04.382749Z"},"trusted":true},"execution_count":null,"outputs":[]}]}