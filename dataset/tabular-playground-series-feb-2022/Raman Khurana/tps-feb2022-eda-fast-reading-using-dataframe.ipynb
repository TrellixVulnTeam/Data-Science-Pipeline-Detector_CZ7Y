{"nbformat_minor":4,"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-01T21:46:18.586709Z","iopub.execute_input":"2022-02-01T21:46:18.587133Z","iopub.status.idle":"2022-02-01T21:46:18.631501Z","shell.execute_reply.started":"2022-02-01T21:46:18.587015Z","shell.execute_reply":"2022-02-01T21:46:18.630815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading\n\n","metadata":{}},{"cell_type":"code","source":"ls -lhtr /kaggle/input/tabular-playground-series-feb-2022","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:46:18.633078Z","iopub.execute_input":"2022-02-01T21:46:18.633351Z","iopub.status.idle":"2022-02-01T21:46:19.406932Z","shell.execute_reply.started":"2022-02-01T21:46:18.633308Z","shell.execute_reply":"2022-02-01T21:46:19.405928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset is about 1.2 GB and takes some time to load as csv, so I convert it to pickle file in order to save some loading time, everytime kernal restart. \n* the pickle size is 439 MB, which is way less than original and hence faster start. https://www.kaggle.com/khurana0112/tpsfeb2022train \nhttps://www.kaggle.com/khurana0112/uniquant-data-loading\n\n* Another way to bypass this is to read the dataset using other tools, one such is dask. https://docs.dask.org/en/stable/dataframe.html but disadvantage there is to learn a new (similar) tool. \n\n","metadata":{}},{"cell_type":"code","source":"#%%time\n#dna_train_tmp = pd.read_csv(\"/kaggle/input/tabular-playground-series-feb-2022/train.csv\")\n#dna_test  = pd.read_csv(\"/kaggle/input/tabular-playground-series-feb-2022/test.csv\")\n#This cell takes 22.2 s\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:46:19.408731Z","iopub.execute_input":"2022-02-01T21:46:19.40901Z","iopub.status.idle":"2022-02-01T21:46:19.413621Z","shell.execute_reply.started":"2022-02-01T21:46:19.408976Z","shell.execute_reply":"2022-02-01T21:46:19.412734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \ndna_train = pd.read_pickle(\"../input/d/khurana0112/tpsfeb2022train/train-2.pkl\")\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:46:19.416325Z","iopub.execute_input":"2022-02-01T21:46:19.417056Z","iopub.status.idle":"2022-02-01T21:46:24.111431Z","shell.execute_reply.started":"2022-02-01T21:46:19.417008Z","shell.execute_reply":"2022-02-01T21:46:24.110459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### * 22000 ms vs 716 ms, quite fast *","metadata":{}},{"cell_type":"markdown","source":"## EDA \n\n### Step 1\nFrom following cells a quick inspenction of data shows following features: \n1. total 288 columns\n2. except row_id and target all other are the features which can be used for inference. \n3. There are 10 unique target values, bacretial types. \n4. The frequency of the bacteria in the training dataset is very even, likely because its an scientific experiemnt or may be becuase they want to provide an even dataset, without any bias. ","metadata":{}},{"cell_type":"code","source":"print (dna_train.shape, dna_train.columns)\ndna_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:46:24.112861Z","iopub.execute_input":"2022-02-01T21:46:24.113315Z","iopub.status.idle":"2022-02-01T21:46:24.158764Z","shell.execute_reply.started":"2022-02-01T21:46:24.113278Z","shell.execute_reply":"2022-02-01T21:46:24.157906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dna_train.target.unique() ## 10 unique target values, ","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:46:24.160175Z","iopub.execute_input":"2022-02-01T21:46:24.160482Z","iopub.status.idle":"2022-02-01T21:46:24.196815Z","shell.execute_reply.started":"2022-02-01T21:46:24.160439Z","shell.execute_reply":"2022-02-01T21:46:24.19579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dna_train.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:46:24.198436Z","iopub.execute_input":"2022-02-01T21:46:24.198795Z","iopub.status.idle":"2022-02-01T21:46:24.242222Z","shell.execute_reply.started":"2022-02-01T21:46:24.198728Z","shell.execute_reply":"2022-02-01T21:46:24.241317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Step 2 \n- The genomic analysis technique has done some data compression and resulted in some data loss.\n- In this technique, 10-mer snippets of DNA are sampled and analyzed to give the histogram of base count. \n- The bases are ATGC\n- The distribution of the bases for 10-mers of sample (286 features) is from 0 to 10. Lets see the distribution of each of these for the full dataset. \n- ATGC distribution over the 286 features are exactly the same. There is no special feature/bias. \n","metadata":{}},{"cell_type":"code","source":"features = dna_train.columns[1:-1].tolist()\nfeatures[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:46:24.244245Z","iopub.execute_input":"2022-02-01T21:46:24.244573Z","iopub.status.idle":"2022-02-01T21:46:24.257769Z","shell.execute_reply.started":"2022-02-01T21:46:24.244528Z","shell.execute_reply":"2022-02-01T21:46:24.256822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfor frs in features[0:10]:\n    print (re.split('A|T|G|C',frs)[1:] )","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:46:24.259277Z","iopub.execute_input":"2022-02-01T21:46:24.259615Z","iopub.status.idle":"2022-02-01T21:46:24.270903Z","shell.execute_reply.started":"2022-02-01T21:46:24.259576Z","shell.execute_reply":"2022-02-01T21:46:24.269893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getbases(feature):\n    return re.split('A|T|G|C',frs)[1:]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:46:24.273534Z","iopub.execute_input":"2022-02-01T21:46:24.273779Z","iopub.status.idle":"2022-02-01T21:46:24.280888Z","shell.execute_reply.started":"2022-02-01T21:46:24.27373Z","shell.execute_reply":"2022-02-01T21:46:24.279893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_a=[]\nbase_t=[]\nbase_g=[]\nbase_c=[]\nfor frs in features:\n    a_,t_,g_,c_ = (getbases(frs))\n    base_a.append(int(a_)) ;    base_t.append(int(t_));   base_g.append(int(g_));   base_c.append(int(c_));\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:48:46.110959Z","iopub.execute_input":"2022-02-01T21:48:46.111704Z","iopub.status.idle":"2022-02-01T21:48:46.120948Z","shell.execute_reply.started":"2022-02-01T21:48:46.111644Z","shell.execute_reply":"2022-02-01T21:48:46.119825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bases = pd.DataFrame()\ndf_bases['base_a'] = pd.Series(base_a)\ndf_bases['base_t'] = pd.Series(base_t)\ndf_bases['base_g'] = pd.Series(base_g)\ndf_bases['base_c'] = pd.Series(base_c)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:48:49.363692Z","iopub.execute_input":"2022-02-01T21:48:49.367005Z","iopub.status.idle":"2022-02-01T21:48:49.377054Z","shell.execute_reply.started":"2022-02-01T21:48:49.366951Z","shell.execute_reply":"2022-02-01T21:48:49.375821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_bases.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:48:55.907528Z","iopub.execute_input":"2022-02-01T21:48:55.907896Z","iopub.status.idle":"2022-02-01T21:48:55.937719Z","shell.execute_reply.started":"2022-02-01T21:48:55.907859Z","shell.execute_reply":"2022-02-01T21:48:55.937056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure()\ndf_bases.base_a.value_counts().plot(title=\"base_a\")\nplt.figure()\ndf_bases.base_t.value_counts().plot(title=\"base_t\")\nplt.figure()\ndf_bases.base_g.value_counts().plot(title=\"base_g\")\nplt.figure()\ndf_bases.base_c.value_counts().plot(title=\"base_c\")","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:48:56.912044Z","iopub.execute_input":"2022-02-01T21:48:56.912631Z","iopub.status.idle":"2022-02-01T21:48:57.738275Z","shell.execute_reply.started":"2022-02-01T21:48:56.912591Z","shell.execute_reply":"2022-02-01T21:48:57.737183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \nsns.pairplot(df_bases, vars=df_bases.columns[0:4]) # i can't plot the histplot and distplot for some reason, so easy way is to see the pair plot\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:55:32.792181Z","iopub.execute_input":"2022-02-01T21:55:32.792545Z","iopub.status.idle":"2022-02-01T21:55:36.747778Z","shell.execute_reply.started":"2022-02-01T21:55:32.792506Z","shell.execute_reply":"2022-02-01T21:55:36.746919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:56:10.795185Z","iopub.execute_input":"2022-02-01T21:56:10.795696Z","iopub.status.idle":"2022-02-01T21:56:10.802734Z","shell.execute_reply.started":"2022-02-01T21:56:10.795657Z","shell.execute_reply":"2022-02-01T21:56:10.801907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}