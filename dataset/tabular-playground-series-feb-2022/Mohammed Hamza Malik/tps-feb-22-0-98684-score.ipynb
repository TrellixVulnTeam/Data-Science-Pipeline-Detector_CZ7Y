{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-20T19:35:55.693Z","iopub.execute_input":"2022-02-20T19:35:55.693442Z","iopub.status.idle":"2022-02-20T19:35:55.73284Z","shell.execute_reply.started":"2022-02-20T19:35:55.693319Z","shell.execute_reply":"2022-02-20T19:35:55.731878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import mode\n\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\n\nfrom matplotlib import ticker\nimport time\nimport warnings\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')\n\n\nRANDOM_STATE = 12 \nFOLDS = 10","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:35:55.734482Z","iopub.execute_input":"2022-02-20T19:35:55.735464Z","iopub.status.idle":"2022-02-20T19:36:00.430147Z","shell.execute_reply.started":"2022-02-20T19:35:55.735417Z","shell.execute_reply":"2022-02-20T19:36:00.429129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir=\"../input/tabular-playground-series-feb-2022\"\ntrain = pd.read_csv(data_dir+\"/train.csv\")\ntest = pd.read_csv(data_dir+\"/test.csv\")\nsubmission = pd.read_csv(data_dir+\"/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:36:00.431561Z","iopub.execute_input":"2022-02-20T19:36:00.432203Z","iopub.status.idle":"2022-02-20T19:36:39.565272Z","shell.execute_reply.started":"2022-02-20T19:36:00.432155Z","shell.execute_reply":"2022-02-20T19:36:39.564307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop([\"row_id\"] , axis = 1 , inplace = True)\ntest.drop([\"row_id\"] , axis = 1 , inplace = True)\nTARGET = 'target'\nFEATURES = [col for col in train.columns if col not in ['row_id', TARGET]]\nRANDOM_STATE = 12 ","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:36:39.567936Z","iopub.execute_input":"2022-02-20T19:36:39.568268Z","iopub.status.idle":"2022-02-20T19:36:39.843156Z","shell.execute_reply.started":"2022-02-20T19:36:39.568225Z","shell.execute_reply":"2022-02-20T19:36:39.842017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"mean\"] = train[FEATURES].mean(axis=1)\ntrain[\"std\"] = train[FEATURES].std(axis=1)\ntrain[\"min\"] = train[FEATURES].min(axis=1)\ntrain[\"max\"] = train[FEATURES].max(axis=1)\n\ntest[\"mean\"] = test[FEATURES].mean(axis=1)\ntest[\"std\"] = test[FEATURES].std(axis=1)\ntest[\"min\"] = test[FEATURES].min(axis=1)\ntest[\"max\"] = test[FEATURES].max(axis=1)\n\nFEATURES.extend(['mean', 'std', 'min', 'max'])","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:36:39.844652Z","iopub.execute_input":"2022-02-20T19:36:39.845196Z","iopub.status.idle":"2022-02-20T19:36:43.724568Z","shell.execute_reply.started":"2022-02-20T19:36:39.845148Z","shell.execute_reply":"2022-02-20T19:36:43.723542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ntrain[TARGET] = encoder.fit_transform(train[TARGET])","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:36:43.72645Z","iopub.execute_input":"2022-02-20T19:36:43.726769Z","iopub.status.idle":"2022-02-20T19:36:43.790612Z","shell.execute_reply.started":"2022-02-20T19:36:43.726724Z","shell.execute_reply":"2022-02-20T19:36:43.789529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_params = {\n    'objective' : 'multiclass',\n    'metric' : 'multi_logloss',\n    'device' : 'gpu',\n}\n\n\nlgb_predictions = []\nlgb_scores = []\nlgb_fimp = []\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx]\n    \n    model = LGBMClassifier(**lgb_params)\n    model.fit(X_train, y_train,verbose=0)\n    \n    preds_valid = model.predict(X_valid)\n    acc = accuracy_score(y_valid,  preds_valid)\n    lgb_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold={fold+1}, Accuracy: {acc:.2f}, Run Time: {run_time:.2f}s\")\n    fim = pd.DataFrame(index=FEATURES,\n                 data=model.feature_importances_,\n                 columns=[f'{fold}_importance'])\n    lgb_fimp.append(fim)\n    test_preds = model.predict(test[FEATURES])\n    lgb_predictions.append(test_preds)\n    \nprint(\"Mean Accuracy :\", np.mean(lgb_scores))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:36:43.792893Z","iopub.execute_input":"2022-02-20T19:36:43.793257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catb_params = {\n    \"objective\": \"MultiClass\",\n    \"task_type\": \"GPU\",\n}\n\ncatb_predictions = []\ncatb_scores = []\ncatb_fimp = []\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx]\n    \n    model = CatBoostClassifier(**catb_params)\n    model.fit(X_train, y_train,verbose=0)\n    \n    preds_valid = model.predict(X_valid)\n    acc = accuracy_score(y_valid,  preds_valid)\n    catb_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold={fold+1}, Accuracy: {acc:.2f}, Run Time: {run_time:.2f}s\")\n    fim = pd.DataFrame(index=FEATURES,\n                 data=model.feature_importances_,\n                 columns=[f'{fold}_importance'])\n    catb_fimp.append(fim)\n    test_preds = model.predict(test[FEATURES])\n    catb_predictions.append(test_preds)\n    \nprint(\"Mean Accuracy :\", np.mean(catb_scores))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {\n    'objective': 'multi:softmax',\n    'eval_metric': 'mlogloss',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    }\n\n\nxgb_predictions = []\nxgb_scores = []\nxgb_fimp = []\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx]\n    \n    model = XGBClassifier(**xgb_params)\n    model.fit(X_train, y_train,verbose=0)\n    \n    preds_valid = model.predict(X_valid)\n    acc = accuracy_score(y_valid,  preds_valid)\n    xgb_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold={fold+1}, Accuracy: {acc:.2f}, Run Time: {run_time:.2f}s\")\n    test_preds = model.predict(test[FEATURES])\n    fim = pd.DataFrame(index=FEATURES,\n                 data=model.feature_importances_,\n                 columns=[f'{fold}_importance'])\n    xgb_fimp.append(fim)\n    xgb_predictions.append(test_preds)\n    \nprint(\"Mean Accuracy :\", np.mean(xgb_scores))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_submission = submission.copy()\nlgb_submission[\"target\"] = encoder.inverse_transform(np.squeeze(mode(np.column_stack(lgb_predictions),axis = 1)[0]).astype('int'))\nlgb_submission.to_csv(\"lgb-subs.csv\",index=False)\nlgb_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catb_submission = submission.copy()\ncatb_submission[\"target\"] = encoder.inverse_transform(np.squeeze(mode(np.column_stack(catb_predictions),axis = 1)[0]).astype('int'))\ncatb_submission.to_csv(\"catb-subs.csv\",index=False)\ncatb_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_submission = submission.copy()\nxgb_submission[\"target\"] = encoder.inverse_transform(np.squeeze(mode(np.column_stack(xgb_predictions),axis = 1)[0]).astype('int'))\nxgb_submission.to_csv(\"xgb-subs.csv\",index=False)\nxgb_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}