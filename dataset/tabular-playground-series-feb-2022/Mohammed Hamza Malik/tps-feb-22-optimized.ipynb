{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> This notebook is inspired and influenced by the excellent notebook of 'ExtraTrees StratifiedKFold + Memory Optimization' by Munum Butt, here is the notebook [link](https://www.kaggle.com/munumbutt/extratrees-stratifiedkfold-memory-optimization) ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-04T20:10:54.573065Z","iopub.execute_input":"2022-02-04T20:10:54.573623Z","iopub.status.idle":"2022-02-04T20:10:54.581707Z","shell.execute_reply.started":"2022-02-04T20:10:54.573595Z","shell.execute_reply":"2022-02-04T20:10:54.580338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install scikit-learn-intelex\nfrom sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2022-02-04T20:10:54.583017Z","iopub.execute_input":"2022-02-04T20:10:54.583256Z","iopub.status.idle":"2022-02-04T20:11:03.083186Z","shell.execute_reply.started":"2022-02-04T20:10:54.583226Z","shell.execute_reply":"2022-02-04T20:11:03.081997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom scipy.stats import mode\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nKAGGLE_DIR = r'../input/tabular-playground-series-feb-2022/'\nLOCAL_DIR = r''\nKAGGLE = True\nRS = 69420","metadata":{"execution":{"iopub.status.busy":"2022-02-04T20:11:03.085604Z","iopub.execute_input":"2022-02-04T20:11:03.085865Z","iopub.status.idle":"2022-02-04T20:11:03.090315Z","shell.execute_reply.started":"2022-02-04T20:11:03.085818Z","shell.execute_reply":"2022-02-04T20:11:03.089689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-04T20:11:03.091177Z","iopub.execute_input":"2022-02-04T20:11:03.091372Z","iopub.status.idle":"2022-02-04T20:11:03.661664Z","shell.execute_reply.started":"2022-02-04T20:11:03.091348Z","shell.execute_reply":"2022-02-04T20:11:03.660919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif KAGGLE:\n    print(f\"{'*'*10} Loading Training Data... {'*'*10}\")\n    train = pd.read_csv(KAGGLE_DIR+'train.csv', index_col=0).pipe(reduce_mem_usage)\n    print(f\"{'*'*10} Loading Testing Data... {'*'*10}\")\n    test = pd.read_csv(KAGGLE_DIR+'test.csv', index_col=0).pipe(reduce_mem_usage)\n    sub = pd.read_csv(KAGGLE_DIR+'sample_submission.csv').pipe(reduce_mem_usage)\nelse:\n    print(f\"{'*'*10} Loading Training Data... {'*'*10}\")\n    train = pd.read_csv(LOCAL_DIR+'train.csv', index_col=0).pipe(reduce_mem_usage)\n    print(f\"{'*'*10} Loading Testing Data... {'*'*10}\")\n    test = pd.read_csv(LOCAL_DIR+'test.csv', index_col=0).pipe(reduce_mem_usage)\n    sub = pd.read_csv(LOCAL_DIR+'sample_submission.csv').pipe(reduce_mem_usage)","metadata":{"execution":{"iopub.status.busy":"2022-02-04T20:11:03.663593Z","iopub.execute_input":"2022-02-04T20:11:03.663903Z","iopub.status.idle":"2022-02-04T20:11:58.729727Z","shell.execute_reply.started":"2022-02-04T20:11:03.663831Z","shell.execute_reply":"2022-02-04T20:11:58.728667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_encoder = LabelEncoder()\ntrain[\"target\"] = target_encoder.fit_transform(train[\"target\"])\n\nX = train.drop([\"target\"], axis=1)\ny = train[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-04T20:11:58.731636Z","iopub.execute_input":"2022-02-04T20:11:58.731926Z","iopub.status.idle":"2022-02-04T20:11:58.90174Z","shell.execute_reply.started":"2022-02-04T20:11:58.731885Z","shell.execute_reply":"2022-02-04T20:11:58.900377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_probs = []\nscores = []\n\nfolds = StratifiedKFold(n_splits=10, shuffle=True)\n\nestimators = 1300\nfor fold, (train_id, test_id) in enumerate(folds.split(X, y)):  \n    X_train = X.iloc[train_id]\n    y_train = y.iloc[train_id]\n    X_valid = X.iloc[test_id]\n    y_valid = y.iloc[test_id]\n    \n    model = ExtraTreesClassifier(\n        n_estimators=estimators,\n        n_jobs=-1\n    )\n\n    model.fit(X_train, y_train)\n    \n    valid_pred = model.predict(X_valid)\n    valid_score = accuracy_score(y_valid, valid_pred)\n    \n    print(\"Fold:\", fold + 1, \"Accuracy:\", valid_score)\n    \n    scores.append(valid_score)\n    \n    # Save predictions to later submit the mean values\n    #if submission: \n    y_probs.append(model.predict_proba(test))\n    \n    estimators = estimators + 75","metadata":{"execution":{"iopub.status.busy":"2022-02-04T20:11:58.903447Z","iopub.execute_input":"2022-02-04T20:11:58.90369Z","iopub.status.idle":"2022-02-04T21:50:04.491904Z","shell.execute_reply.started":"2022-02-04T20:11:58.90366Z","shell.execute_reply":"2022-02-04T21:50:04.490533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Mean accuracy score:\", np.array(scores).mean())","metadata":{"execution":{"iopub.status.busy":"2022-02-04T21:50:04.49675Z","iopub.execute_input":"2022-02-04T21:50:04.497069Z","iopub.status.idle":"2022-02-04T21:50:04.508495Z","shell.execute_reply.started":"2022-02-04T21:50:04.497041Z","shell.execute_reply":"2022-02-04T21:50:04.506215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob = sum(y_probs) / len(y_probs)\n# The explanations for these numbers are in AMBROSM's code\ny_prob += np.array([0, 0, 0.01, 0.03, 0, 0, 0, 0, 0, 0])\ny_pred_tuned = target_encoder.inverse_transform(np.argmax(y_prob, axis=1))\npd.Series(y_pred_tuned, index=test.index).value_counts().sort_index() / len(test) * 100","metadata":{"execution":{"iopub.status.busy":"2022-02-04T21:50:04.509631Z","iopub.execute_input":"2022-02-04T21:50:04.509879Z","iopub.status.idle":"2022-02-04T21:50:04.590061Z","shell.execute_reply.started":"2022-02-04T21:50:04.509825Z","shell.execute_reply":"2022-02-04T21:50:04.589161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[\"target\"] = y_pred_tuned\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-04T21:50:04.591418Z","iopub.execute_input":"2022-02-04T21:50:04.591994Z","iopub.status.idle":"2022-02-04T21:50:04.770151Z","shell.execute_reply.started":"2022-02-04T21:50:04.591963Z","shell.execute_reply":"2022-02-04T21:50:04.768949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}