{"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","version":"3.6.4","mimetype":"text/x-python","name":"python"}},"nbformat_minor":1,"cells":[{"outputs":[],"cell_type":"code","execution_count":null,"source":"from datetime import datetime\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport xgboost as xgb\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.grid_search import GridSearchCV\n\n# set seed\nnp.random.seed(42)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# from subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"collapsed":true,"_uuid":"3570a09f878825f9fda8195e95ad1eaf0d1a7980","_cell_guid":"945451ec-93bd-4b82-8559-140232d7b33c"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n\ntrainData = pd.read_table('../input/train.tsv')\ntestData = pd.read_table('../input/test.tsv')\n\nprint(trainData.shape, testData.shape)","metadata":{"collapsed":true,"_uuid":"922ba6a51c24f1b94ec8f8a0b5c9e8deee8fe515","_cell_guid":"4020a355-b404-41da-bc3c-282c750a5a32"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"trainData = trainData.drop(trainData[(trainData.price < 3.0)].index)\ntrainData.shape","metadata":{"collapsed":true,"_uuid":"d53990ed7365039ed605b5b66fe37f06bb4d205b","_cell_guid":"d15e7cbc-2e92-442b-9bbd-850c13d24fd1"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n# get name and description lengths\ndef wordCount(text):\n    try:\n        if text == 'No description yet':\n            return 0\n        else:\n            text = text.lower()\n            words = [w for w in text.split(\" \")]\n            return len(words)\n    except: \n        return 0\ntrainData['descLen'] = trainData['item_description'].apply(lambda x: wordCount(x))\ntestData['descLen'] = testData['item_description'].apply(lambda x: wordCount(x))\ntrainData['nameLen'] = trainData['name'].apply(lambda x: wordCount(x))\ntestData['nameLen'] = testData['name'].apply(lambda x: wordCount(x))\ntrainData.head()","metadata":{"collapsed":true,"_uuid":"e6cf00b14a4bf1e4a79995a6c68f5590b320a11c","_cell_guid":"25209a03-8dd6-4982-a580-c9ff7875d341"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n# split category name into 3 parts\ndef split_cat(text):\n    try: return text.split(\"/\")\n    except: return (\"No Label\", \"No Label\", \"No Label\")\ntrainData['subcat_1'], trainData['subcat_2'], trainData['subcat_3'] = \\\nzip(*trainData['category_name'].apply(lambda x: split_cat(x)))\ntestData['subcat_1'], testData['subcat_2'], testData['subcat_3'] = \\\nzip(*testData['category_name'].apply(lambda x: split_cat(x)))","metadata":{"collapsed":true,"_uuid":"0d1dddc301f344b3dcbd520ee250348d46f2a4d8","_cell_guid":"a31302c6-60b7-46da-89c0-8b6e7f967a88"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\nfullData = pd.concat([trainData,testData])\nbrands = set(fullData['brand_name'].values)\ntrainData.brand_name.fillna(value=\"missing\", inplace=True)\ntestData.brand_name.fillna(value=\"missing\", inplace=True)\n\nmissing = len(trainData.loc[trainData['brand_name'] == 'missing'])\ndef brandfinder(line):\n    brand = line[0]\n    name = line[1]\n    namesplit = name.split(' ')\n    if brand == 'missing':\n        for x in namesplit:\n            if x in brands:\n                return name\n    if name in brands:\n        return name\n    return brand\ntrainData['brand_name'] = trainData[['brand_name','name']].apply(brandfinder, axis = 1)\ntestData['brand_name'] = testData[['brand_name','name']].apply(brandfinder, axis = 1)\nfound = missing-len(trainData.loc[trainData['brand_name'] == 'missing'])\nprint(found)","metadata":{"collapsed":true,"_uuid":"5b572a93ef01101d19c91c54412c92a132f70072","_cell_guid":"39f98551-563a-4df9-8786-e9e5d599f1fe"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n# Scale target variable to log.\n# trainData[\"target\"] = np.log1p(trainData.price)\n\n# Split training examples into train/dev examples.\ntrainData, devData = train_test_split(trainData, random_state=42, train_size=0.9)\n\n# Calculate number of train/dev/test examples.\nn_trains = trainData.shape[0]\nn_devs = devData.shape[0]\nn_tests = testData.shape[0]\nprint(\"Training on\", n_trains, \"examples\")\nprint(\"Validating on\", n_devs, \"examples\")\nprint(\"Testing on\", n_tests, \"examples\")\n\n# Concatenate train - dev - test data for easy to handle\nfullData = pd.concat([trainData, devData, testData])","metadata":{"collapsed":true,"_uuid":"8b964d10340dfd19b9565ddc4850f344770b4514","_cell_guid":"63815bd6-f73c-4ed7-a603-39fcf7131697"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n\n# Filling missing values\ndef fill_missing_values(df):\n    df.category_name.fillna(value=\"missing\", inplace=True)\n    df.brand_name.fillna(value=\"missing\", inplace=True)\n    df.item_description.fillna(value=\"missing\", inplace=True)\n    df.item_description.replace('No description yet',\"missing\", inplace=True)\n    return df\n\nprint(\"Filling missing data ...\")\nfullData = fill_missing_values(fullData)\nprint(fullData.category_name[1])","metadata":{"collapsed":true,"_uuid":"fc1a9835e779a009696cacae01107480d9c0126a","_cell_guid":"0a4d3ce3-0718-4007-a5e7-29145246da29"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n\nprint(\"Processing categorical data...\")\nle = LabelEncoder()\n\nle.fit(fullData.category_name)\nfullData['category'] = le.transform(fullData.category_name)\n\nle.fit(fullData.brand_name)\nfullData.brand_name = le.transform(fullData.brand_name)\n\nle.fit(fullData.subcat_1)\nfullData.subcat_1 = le.transform(fullData.subcat_1)\n\nle.fit(fullData.subcat_2)\nfullData.subcat_2 = le.transform(fullData.subcat_2)\n\nle.fit(fullData.subcat_3)\nfullData.subcat_3 = le.transform(fullData.subcat_3)\n\ndel le","metadata":{"collapsed":true,"_uuid":"468720e988788007e1a382e1763b5e169b09ac8f","_cell_guid":"f8831f3b-3612-406a-88e6-6e1edf1aa580"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n\nprint(\"Handling missing values...\")\nfullData['category_name'] = fullData['category_name'].fillna('missing').astype(str)\nfullData['subcat_1'] = fullData['subcat_1'].astype(str)\nfullData['subcat_2'] = fullData['subcat_2'].astype(str)\nfullData['subcat_3'] = fullData['subcat_3'].astype(str)\nfullData['brand_name'] = fullData['brand_name'].fillna('missing').astype(str)\nfullData['shipping'] = fullData['shipping'].astype(str)\nfullData['item_condition_id'] = fullData['item_condition_id'].astype(str)\nfullData['descLen'] = fullData['descLen'].astype(str)\nfullData['nameLen'] = fullData['nameLen'].astype(str)\nfullData['item_description'] = fullData['item_description'].fillna('No description yet').astype(str)","metadata":{"collapsed":true,"_uuid":"24fb040f590668f5b2450abf4335d89535cb8a31","_cell_guid":"a34dd1e1-abff-454c-be95-2402d8afee7b"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n\nprint(\"Vectorizing data...\")\ndefault_preprocessor = CountVectorizer().build_preprocessor()\ndef build_preprocessor(field):\n    field_idx = list(fullData.columns).index(field)\n    return lambda x: default_preprocessor(x[field_idx])\n\nvectorizer = FeatureUnion([\n    ('name', CountVectorizer(\n        ngram_range=(1, 2),\n        max_features=100000,\n        stop_words='english',\n        preprocessor=build_preprocessor('name'))),\n    ('category_name', CountVectorizer(\n        token_pattern='.+',\n        max_features=20000,\n        stop_words='english',\n        preprocessor=build_preprocessor('category_name'))),\n    ('subcat_1', CountVectorizer(\n        token_pattern='.+',\n        stop_words='english',\n        preprocessor=build_preprocessor('subcat_1'))),\n    ('subcat_2', CountVectorizer(\n        token_pattern='.+',\n        stop_words='english',\n        preprocessor=build_preprocessor('subcat_2'))),\n    ('subcat_3', CountVectorizer(\n        token_pattern='.+',\n        stop_words='english',\n        max_features=20000,\n        preprocessor=build_preprocessor('subcat_3'))),\n    ('brand_name', CountVectorizer(\n        token_pattern='.+',\n        stop_words='english',\n        preprocessor=build_preprocessor('brand_name'))),\n    ('shipping', CountVectorizer(\n        token_pattern='\\d+',\n        preprocessor=build_preprocessor('shipping'))),\n    ('item_condition_id', CountVectorizer(\n        token_pattern='\\d+',\n        preprocessor=build_preprocessor('item_condition_id'))),\n    ('item_description', TfidfVectorizer(\n        ngram_range=(1, 3),\n        max_features=20000,\n        stop_words='english',\n        preprocessor=build_preprocessor('item_description'))),\n])\n\nX = vectorizer.fit_transform(fullData.values)","metadata":{"collapsed":true,"_uuid":"b81fdab4b08fc93fe7b43a501aac4e52e8b5e436","_cell_guid":"13d97089-0908-498a-bc3a-c27abebb98ac"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"X = sparse.hstack((X, fullData[['nameLen', 'descLen']].astype(float).as_matrix()), format = 'csr')\n\ntrainData[\"target\"] = np.log1p(trainData.price)\ndevData[\"target\"] = np.log1p(devData.price)\n\nX_train = X[:n_trains]\nY_train = trainData.target.values.reshape(-1, 1)\n\nX_dev = X[n_trains:n_trains+n_devs]\nY_dev = devData.target.values.reshape(-1, 1)\n\nX_test = X[n_trains+n_devs:]\n\nprint(X.shape, X_train.shape, X_dev.shape, X_test.shape)","metadata":{"collapsed":true,"_uuid":"748f962c0ad6e8220153003ff91a581f23c0c23b","_cell_guid":"59b54bac-9e05-4ba8-b942-4b9045f0e5d3"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"# del trainData\n# del testData\n# del fullData","metadata":{"collapsed":true,"_uuid":"c773137cee9a14871175dd0fd540badb8bcd5a02","_cell_guid":"4a2e62d5-cde9-4029-ae94-6859b7cc2e73"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n%env JOBLIB_TEMP_FOLDER=/tmp\n\nxgb_model = xgb.XGBRegressor()\n\nxgb_parameters = {'n_estimators': [100],\n              'subsample': [0.5],\n              'colsample_bytree': [0.1],\n              'colsample_bylevel': [0.1],\n              'reg_lambda': [0.7],\n              'reg_alpha': [0.3],\n              'seed': [42]}\n\n\nxgb_clf = GridSearchCV(xgb_model, xgb_parameters, n_jobs=-1, cv=3, \n                   scoring='neg_mean_squared_error')\n\nxgb_clf.fit(X_train, Y_train)\n\nprint('XGBoost training score: ', mean_squared_error(Y_train, xgb_clf.predict(X_train)))\nprint('XGBoost validation score: ', mean_squared_error(Y_dev, xgb_clf.predict(X_dev)))","metadata":{"collapsed":true,"scrolled":true,"_uuid":"0a8c922fe17b2e516bdcba5d25e97adb9e5291d3","_cell_guid":"48f5c95c-3a82-4bbb-96ed-c292d15ce430"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"# xgb_pred_test = np.expm1(xgb_clf.predict(X_test))\n\n# submissionData = pd.DataFrame({\n#         \"test_id\": testData.test_id,\n#         \"price\": xgb_pred_test.reshape(-1),\n# })\n\n# submissionData.to_csv(\"./xgb_submission_first.csv\", index=False)","metadata":{"collapsed":true,"_uuid":"8af6cce6a01f8a2e12dce931919cd3195b454d90","_cell_guid":"c1d8b718-8fbb-4ea5-8b3b-53354c9dd49d"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\nridge_model = Ridge(\n    fit_intercept=True, alpha=[10.0],\n    normalize=False, solver='sag', tol=0.05, random_state=42)\n\nridge_model.fit(X_train, Y_train)\n\nprint('Ridge training score: ', mean_squared_error(Y_train, ridge_model.predict(X_train)))\nprint('Ridge validation score: ', mean_squared_error(Y_dev, ridge_model.predict(X_dev)))","metadata":{"collapsed":true,"_uuid":"23e9cdb02892b1c6c51031876d4677bb3878b454","_cell_guid":"97dbc38a-4f93-40fb-a844-239c8ac0d122"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"# ridge_pred_test = np.expm1(ridge_model.predict(X_test))\n\n# submissionData = pd.DataFrame({\n#         \"test_id\": testData.test_id,\n#         \"price\": ridge_pred_test.reshape(-1),\n# })\n\n# submissionData.to_csv(\"./ridge_submission_first.csv\", index=False)","metadata":{"collapsed":true,"_uuid":"f8958feb0a54e893e8fd1987e6cf786e3481fe12","_cell_guid":"8693040f-4761-405b-bf7f-4b731edd4e92"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"%%time\n\nxgb_pred_dev = np.expm1(xgb_clf.predict(X_dev))\nridge_pred_dev = np.expm1(ridge_model.predict(X_dev))\n\nxgb_pred_test = np.expm1(xgb_clf.predict(X_test))\nridge_pred_test = np.expm1(ridge_model.predict(X_test))\n\ndef aggregate_predicts2(Y1, Y2,ratio):\n    assert Y1.shape == Y2.shape\n    return Y1 * ratio + Y2 * (1.0 - ratio)\n\n#ratio optimum finder\nbest = 0\nlowest = 0.99\nfor i in range(100):\n    r = i*0.01\n    Y_dev_preds = aggregate_predicts2(xgb_pred_dev, ridge_pred_dev, r)\n    fpred = mean_squared_error(Y_dev, Y_dev_preds)\n    if fpred < lowest:\n        best = r\n        lowest = fpred\n    print(str(r) + \" - score for XGBoost + Ridge on dev set:\", fpred)\n","metadata":{"collapsed":true,"_uuid":"07e49e7a00d65e0f239cee368ede37d2db5c46c2","_cell_guid":"20bb9fb5-b739-41cc-a391-af7aa8fced42"}},{"outputs":[],"cell_type":"code","execution_count":null,"source":"weighted_preds = aggregate_predicts2(xgb_pred_test, ridge_pred_test, best)\n\nsubmissionData = pd.DataFrame({\n        \"test_id\": testData.test_id,\n        \"price\": weighted_preds.reshape(-1),\n})\n\nsubmissionData.to_csv(\"./ridge_xgb_weighted_submission.csv\", index=False)","metadata":{"collapsed":true,"_uuid":"030f42870cf5f6f1f88e2a056a6e5e8186ea3c1c","_cell_guid":"154de846-ab98-424d-a25f-e817a7febeba"}}]}