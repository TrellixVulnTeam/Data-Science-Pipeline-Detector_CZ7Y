{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Họ tên: Vương Trí Thiên Công**\n\n**Mã sinh viên: 18020240**\n\n**Lớp: K63-K2**","metadata":{}},{"cell_type":"code","source":"! pip install py7zr\nimport py7zr\nwith py7zr.SevenZipFile('/kaggle/input/mercari-price-suggestion-challenge/train.tsv.7z', mode='r') as z:\n    z.extractall()\n!unzip /kaggle/input/mercari-price-suggestion-challenge/sample_submission_stg2.csv.zip\n!unzip /kaggle/input/mercari-price-suggestion-challenge/test_stg2.tsv.zip\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.utils import shuffle\nimport pickle\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-02T04:10:08.461135Z","iopub.execute_input":"2022-01-02T04:10:08.461626Z","iopub.status.idle":"2022-01-02T04:10:45.85113Z","shell.execute_reply.started":"2022-01-02T04:10:08.461479Z","shell.execute_reply":"2022-01-02T04:10:45.850175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">  # Workflow\n1. <a href=\"#Problem-description\">Problem description</a> \n2. <a href=\"#Data-preprocessing\">Data preprocessing</a>\n    * <a href=\"#Compare-TRAIN-and-TEST-dataset\">Compare TRAIN and TEST dataset</a>\n    * <a href=\"#Price-distribution\">Price distribution</a>\n    * <a href=\"#Data-cleansing\">Data cleansing</a>\n    * <a href=\"#Preprocessor-function\">Preprocessor function</a>\n    * <a href=\"#Text-encoding\">Text encoding</a>\n    * <a href=\"#Evaluate\">Evaluate</a>\n3. <a href=\"#Model-training\">Model training</a>\n    * <a href=\"#Linear-Regression\">Linear Regression</a>     \n    * <a href=\"#Ridge-Regression\">Ridge Regression</a>     \n    * <a href=\"#SGD-Regressor\">SGD Regressor</a>\n    * <a href=\"#Ensemble-models-(Boosting-method)\">Ensemble models (Boosting method)</a>\n4. <a href=\"#Conclusion\">Conclusion</a>\n5. <a href=\"#Result\">Result</a>","metadata":{}},{"cell_type":"markdown","source":"# Problem description\n\nDự đoán giá của sản phẩm.\n\n**Input:** Dữ liệu dạng text về **tên**, **tình trạng**, **danh mục**, **nhãn hiệu**, **shipping** và **nhận xét của khách hàng** về sản phẩm.\n\n**Output:** Giá của sản phẩm (>0) và được Kaggle đánh giá theo công thức:\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=RMSLE&space;=&space;\\sqrt{&space;\\frac{1}{N}\\sum_{i=1}^{N}&space;(log(\\hat{y}_{i}&plus;1)-&space;log(y_{i}&plus;1))^2}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?RMSLE&space;=&space;\\sqrt{&space;\\frac{1}{N}\\sum_{i=1}^{N}&space;(log(\\hat{y}_{i}&plus;1)-&space;log(y_{i}&plus;1))^2}\" title=\"RMSLE = \\sqrt{ \\frac{1}{N}\\sum_{i=1}^{N} (log(\\hat{y}_{i}+1)- log(y_{i}+1))^2}\" /></a>\n\ntrong đó:\n\n* $\\hat{y}_{i}$: giá dự đoán\n\n* $y_{i}$: giá thực sự\n\n**Kết luận:** dạng bài toán hồi quy.","metadata":{}},{"cell_type":"markdown","source":"# Data preprocessing\nTập train data với hơn 1 triệu điểm dữ liệu gồm 7 cột features và 1 cột giá (**price**).\n\nTrộn tập dữ liệu với random_state=0.","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_table('../working/train.tsv')\ntrain_data = shuffle(train_data, random_state=0)\nprint(train_data.shape)\n# train_data = train_data[:100]\n# print(train_data.shape)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:10:45.853017Z","iopub.execute_input":"2022-01-02T04:10:45.853414Z","iopub.status.idle":"2022-01-02T04:10:54.517873Z","shell.execute_reply.started":"2022-01-02T04:10:45.853366Z","shell.execute_reply":"2022-01-02T04:10:54.516549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tập test data thì không có cột **price** vì đây là giá trị cần dự đoán để submit.","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_table('../working/test_stg2.tsv')\nprint(test_data.shape)\n# test_data = test_data[:100]\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:10:54.520295Z","iopub.execute_input":"2022-01-02T04:10:54.520695Z","iopub.status.idle":"2022-01-02T04:11:10.200369Z","shell.execute_reply.started":"2022-01-02T04:10:54.520624Z","shell.execute_reply":"2022-01-02T04:11:10.199042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compare TRAIN and TEST dataset\n\n**Vấn đề**: Nếu 2 tập dữ liệu train và test quá khác nhau, việc học trên tập train sẽ không mang lại ý nghĩa khi cần dự đoán trên tập test.\n\nVậy nên trước khi phân tích sâu hơn, ta cần kiểm tra độ tương đồng của tập train và test.\n\n**Giải pháp**: So sánh **phần trăm** các giá trị chiếm đa số trong một vài feature để có cái nhìn cơ bản về tập dữ liệu ta cần làm việc cùng.","metadata":{}},{"cell_type":"code","source":"print(\"Train dataset:\\n\" + str(train_data['item_condition_id'].value_counts() / train_data.shape[0]))\nprint(\"\\nTest dataset:\\n\" + str(test_data['item_condition_id'].value_counts() / test_data.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:10.204312Z","iopub.execute_input":"2022-01-02T04:11:10.204617Z","iopub.status.idle":"2022-01-02T04:11:10.249598Z","shell.execute_reply.started":"2022-01-02T04:11:10.204585Z","shell.execute_reply":"2022-01-02T04:11:10.248656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5 giá trị **item_condition_id** trên tập train và test có tỷ lệ tương đồng.","metadata":{}},{"cell_type":"code","source":"print(\"Train dataset:\\n\" + str(train_data['brand_name'].value_counts().head() / train_data.shape[0]))\nprint(\"\\nTest dataset:\\n\" + str(test_data['brand_name'].value_counts().head() / test_data.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:10.251081Z","iopub.execute_input":"2022-01-02T04:11:10.251948Z","iopub.status.idle":"2022-01-02T04:11:10.860979Z","shell.execute_reply.started":"2022-01-02T04:11:10.251894Z","shell.execute_reply":"2022-01-02T04:11:10.859856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Giá trị **brand_name** trên tập train và test có tỷ lệ tương đồng.","metadata":{}},{"cell_type":"code","source":"print(\"Train dataset:\\n\" + str(train_data['shipping'].value_counts() / train_data.shape[0]))\nprint(\"\\nTest dataset:\\n\" + str(test_data['shipping'].value_counts() / test_data.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:10.862819Z","iopub.execute_input":"2022-01-02T04:11:10.86317Z","iopub.status.idle":"2022-01-02T04:11:10.901882Z","shell.execute_reply.started":"2022-01-02T04:11:10.86311Z","shell.execute_reply":"2022-01-02T04:11:10.900421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2 giá trị **shipping** trên tập train và test có tỷ lệ tương đồng.","metadata":{}},{"cell_type":"markdown","source":"### Kết luận về tập dữ liệu\n\nTập train và test có dữ liệu cân bằng, thuận lợi cho việc train model và dự đoán.\n\n**Để chuẩn bị dữ liệu một cách tốt nhất, ta cần khái quát các features và đề xuất cách xử lý:**\n* **name** và **item_description**: dùng các kỹ thuật xử lý ngôn ngữ tự nhiên\n* **item_condition_id**, **shipping** và **brand_name**: các features này chỉ xuất hiện một vài giá trị nên sẽ chia thành các label\n* **category_name**: feature này có dạng A/B/C nên dự định sẽ tách riêng ra làm 3 phần rồi xử lý theo dạng label","metadata":{}},{"cell_type":"markdown","source":"## Price distribution\n\nKhảo sát giá sản phẩm cho thấy sự không cân xứng (giá đồ tiêu dùng so với trang sức).","metadata":{}},{"cell_type":"code","source":"import seaborn\n\nseaborn.distplot(train_data['price'])","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:10.903189Z","iopub.execute_input":"2022-01-02T04:11:10.903465Z","iopub.status.idle":"2022-01-02T04:11:16.64951Z","shell.execute_reply.started":"2022-01-02T04:11:10.903431Z","shell.execute_reply":"2022-01-02T04:11:16.648224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hàm đồng biến log() sẽ đưa đồ thị giá về gần dạng phân bố chuẩn.","metadata":{}},{"cell_type":"code","source":"seaborn.distplot(np.log1p(train_data.price))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:16.651738Z","iopub.execute_input":"2022-01-02T04:11:16.652999Z","iopub.status.idle":"2022-01-02T04:11:22.733684Z","shell.execute_reply.started":"2022-01-02T04:11:16.652947Z","shell.execute_reply":"2022-01-02T04:11:22.732534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Vấn đề:** Kết quả đánh giá của kaggle dựa trên logarit của giá sản phẩm nên bắt buộc giá trả về phải lớn hơn 0.\n\nQua một số lần thử nghiệm thì số lần dự đoán giá bị âm khá nhiều, dẫn đến khi lấy log() bị lỗi.\n\n**Giải pháp:** dự đoán log() của giá rồi qua hàm exp() sẽ trả về giá trị luôn dương.\n","metadata":{}},{"cell_type":"code","source":"train_data['log_price'] = np.log1p(train_data.price)\ntrain_data.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:22.734985Z","iopub.execute_input":"2022-01-02T04:11:22.735289Z","iopub.status.idle":"2022-01-02T04:11:22.777184Z","shell.execute_reply.started":"2022-01-02T04:11:22.735255Z","shell.execute_reply":"2022-01-02T04:11:22.775884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tập dữ liệu train giờ đã có thêm cột log_price.","metadata":{}},{"cell_type":"markdown","source":"## Data cleansing\n\nCột danh mục sản phẩm (**category_name**) đa số ở dạng top/sub/item.\n\nTa thêm 3 cột vào dữ liệu: **top**, **sub** và **item** để dễ dàng phân tích text.","metadata":{}},{"cell_type":"code","source":"def split_cat(category_name):\n    try:\n        return category_name.split('/')\n    except:\n        return ['Others', 'Others', 'Others']\ntrain_data['cat_top'], train_data['cat_sub'], train_data['cat_item'] = zip(*train_data['category_name'].apply(lambda x: split_cat(x)))\ntest_data['cat_top'], test_data['cat_sub'], test_data['cat_item'] = zip(*test_data['category_name'].apply(lambda x: split_cat(x)))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:22.778829Z","iopub.execute_input":"2022-01-02T04:11:22.779485Z","iopub.status.idle":"2022-01-02T04:11:42.748717Z","shell.execute_reply.started":"2022-01-02T04:11:22.779437Z","shell.execute_reply":"2022-01-02T04:11:42.745915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### NaN values \n\n**Vấn đề:** Giá trị NaN sẽ gây ra lỗi khi chuyển hóa dữ liệu dạng text về vector.\n\n**Giải pháp:** Tìm trên 2 tập dữ liệu những features nào chứa giá trị NaN rồi thay thế chúng.","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:42.750219Z","iopub.execute_input":"2022-01-02T04:11:42.750542Z","iopub.status.idle":"2022-01-02T04:11:44.333679Z","shell.execute_reply.started":"2022-01-02T04:11:42.750505Z","shell.execute_reply":"2022-01-02T04:11:44.332606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:44.335426Z","iopub.execute_input":"2022-01-02T04:11:44.335771Z","iopub.status.idle":"2022-01-02T04:11:47.265238Z","shell.execute_reply.started":"2022-01-02T04:11:44.335726Z","shell.execute_reply":"2022-01-02T04:11:47.264233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thay thế NaN thành giá trị null trên 3 features: **category**, **brand** và **item_description**","metadata":{}},{"cell_type":"code","source":"train_data['category_name'] = train_data['category_name'].fillna(value='Null')\ntrain_data['brand_name'] = train_data['brand_name'].fillna(value='Null')\ntrain_data['item_description'] = train_data['item_description'].fillna(value='Null')\n\ntest_data['category_name'] = test_data['category_name'].fillna(value='Null')\ntest_data['brand_name'] = test_data['brand_name'].fillna(value='Null')\ntest_data['item_description'] = test_data['item_description'].fillna(value='Null')","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:47.269397Z","iopub.execute_input":"2022-01-02T04:11:47.269655Z","iopub.status.idle":"2022-01-02T04:11:49.8144Z","shell.execute_reply.started":"2022-01-02T04:11:47.269627Z","shell.execute_reply":"2022-01-02T04:11:49.812873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessor function \n\nHàm làm sạch text giúp cải thiện két quả khá nhiều (giảm 0.1 loss ở kết quả submib Kaggle ~ cao hơn 100 vị trí so với không dùng)\n\nNhiệm vụ:\n* Xóa thẻ tag và các ký tự đặc biệt.\n* Chuyển ký tự viết hoa thành thường.","metadata":{}},{"cell_type":"code","source":"import re\ndef clean_text(text):\n    \"\"\"\n    Applies some pre-processing on the given text.\n\n    Steps :\n    - Removing HTML tags\n    - Removing punctuation\n    - Lowering text\n    \"\"\"\n    \n    # remove HTML tags\n    text = re.sub(r'<.*?>', '', text)\n    \n    # remove the characters [\\], ['] and [\"] using the resub method:\n    text = re.sub(r'\\\\', '', text)\n\n    text = re.sub(r'\\\"', '', text)   \n\n    text = re.sub(r'\\'', '', text)    \n    \n    # convert text to lowercase\n    text = text.strip().lower()\n    \n    # replace punctuation characters with spaces\n    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n    translate_dict = dict((c, \" \") for c in filters)\n    translate_map = str.maketrans(translate_dict)\n    text = text.translate(translate_map)\n\n    return text\n\n# Example\nclean_text(\"<html>This is is not a\\\" sentence.<\\html>\").split()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:49.816066Z","iopub.execute_input":"2022-01-02T04:11:49.816404Z","iopub.status.idle":"2022-01-02T04:11:49.830026Z","shell.execute_reply.started":"2022-01-02T04:11:49.816369Z","shell.execute_reply":"2022-01-02T04:11:49.828642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text encoding\n\nDựa vào số lượng mẫu của các đặc tính (unique number of each feature) ta chia dữ liệu thành 2 dạng để xử lý:\n* Biến đổi về dạng vector số: **name**, **item_description**.\n* Phân loại theo các label: **item_condition_id**, **brand_name**, **shipping**, **cat_top**, **cat_sub**, **cat_item**.","metadata":{}},{"cell_type":"code","source":"train_data.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:49.832192Z","iopub.execute_input":"2022-01-02T04:11:49.832601Z","iopub.status.idle":"2022-01-02T04:11:54.325913Z","shell.execute_reply.started":"2022-01-02T04:11:49.832548Z","shell.execute_reply":"2022-01-02T04:11:54.324666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Vectorizer\n\nMô hình **Bag of words**: biểu diễn mỗi mẫu dữ liệu dưới dạng một vector số trong đó mỗi chiều là một từ cụ thể trong kho dữ liệu.\n\nKho dữ liệu được khởi tạo khi gọi lệnh fit_transform từ tập train.\n\nĐối với tập test thì chỉ việc biểu diễn vector theo kho dữ liệu đã có (transform).\n\nNhững từ như and, a, the, ... (stopwords) là những từ không có ý nghĩa và xuất hiện nhiều khiến lu mờ các từ khác sẽ được loại bỏ.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer(stop_words=\"english\",\n                            preprocessor=clean_text)\n\n# train_name = vectorizer.fit_transform(train_data['name'])\n# test_name = vectorizer.transform(test_data['name'])\n# pickle.dump(train_name, open(\"train_name.pickle\", \"wb\"))\n# pickle.dump(test_name, open(\"test_name.pickle\", \"wb\"))\n\ntrain_name = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'train_name.pickle'), 'rb'))\ntest_name = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'test_name.pickle'), 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:54.327199Z","iopub.execute_input":"2022-01-02T04:11:54.327442Z","iopub.status.idle":"2022-01-02T04:11:57.86171Z","shell.execute_reply.started":"2022-01-02T04:11:54.327413Z","shell.execute_reply":"2022-01-02T04:11:57.860574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Vấn đề:** Đối với phần nhận xét của khách hàng **item_description** thì cần cách xử lý khác Bag of words bởi:\n* Những từ xuất hiện với tần suất nhiều sẽ làm lu mờ ý nghĩa của những từ quan trọng.\n\n**Giải pháp:** Cách xử lý là dùng mô hình **TF-IDF**: vector biểu diễn điểm dữ liệu sẽ dựa vào độ quan trọng của từ.\n\nĐộ quan trọng được tính theo công thức:\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=i&space;*log(\\frac{n}{1&space;&plus;&space;n_{i}})\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?i&space;*log(\\frac{n}{1&space;&plus;&space;n_{i}})\" title=\"i *log(\\frac{n}{1 + n_{i}})\" /></a>\n\ntrong đó:\n* $i$: là số lần từ xuất hiện trong câu\n* $n$: là tổng số điểm dữ liệu\n* $n_{i}$: là số điểm dữ liệu có từ đó\n\nThay vì tạo kho dữ liệu với từ riêng lẻ (unigrams: 'do', 'not') thì sẽ đi kèm với 2 từ (bigrams: 'do', 'not', 'do-not').","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(stop_words=\"english\",\n                             preprocessor=clean_text,\n                             ngram_range=(1, 2))\n\n# train_des = tfidf.fit_transform(train_data['item_description'])\n# test_des = tfidf.transform(test_data['item_description'])\n# pickle.dump(train_des, open(\"train_des.pickle\", \"wb\"))\n# pickle.dump(test_des, open(\"test_des.pickle\", \"wb\"))\n\ntrain_des = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'train_des.pickle'), 'rb'))\ntest_des = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'test_des.pickle'), 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:11:57.864393Z","iopub.execute_input":"2022-01-02T04:11:57.864802Z","iopub.status.idle":"2022-01-02T04:12:15.019762Z","shell.execute_reply.started":"2022-01-02T04:11:57.864755Z","shell.execute_reply":"2022-01-02T04:12:15.019075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Các features phân loại theo label\n\nSố lượng giá trị unique của các feature sau khá ít khi so với số điểm dữ liệu (1,482,535) nên ta vector hóa nó theo các label.","metadata":{}},{"cell_type":"markdown","source":"Number of unique elements in **brand**: 4810\n\nCó thể coi đây không phải một số lớn khi so với 1 triệu 4 điểm dữ liệu.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\n\nlb_brand = LabelBinarizer(sparse_output=True)\n\n# train_brand = lb_brand.fit_transform(train_data['brand_name'])\n# test_brand = lb_brand.transform(test_data['brand_name'])\n# pickle.dump(train_brand, open(\"train_brand.pickle\", \"wb\"))\n# pickle.dump(test_brand, open(\"test_brand.pickle\", \"wb\"))\n\ntrain_brand = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'train_brand.pickle'), 'rb'))\ntest_brand = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'test_brand.pickle'), 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:15.020896Z","iopub.execute_input":"2022-01-02T04:12:15.021274Z","iopub.status.idle":"2022-01-02T04:12:15.676249Z","shell.execute_reply.started":"2022-01-02T04:12:15.021242Z","shell.execute_reply":"2022-01-02T04:12:15.675242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of unique elements in **condition_id**: 5","metadata":{}},{"cell_type":"code","source":"lb_condition_id = LabelBinarizer(sparse_output=True)\n\n# train_condition_id = lb_condition_id.fit_transform(train_data['item_condition_id'])\n# test_condition_id = lb_condition_id.transform(test_data['item_condition_id'])\n# pickle.dump(train_condition_id, open(\"train_condition_id.pickle\", \"wb\"))\n# pickle.dump(test_condition_id, open(\"test_condition_id.pickle\", \"wb\"))\n\ntrain_condition_id = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'train_condition_id.pickle'), 'rb'))\ntest_condition_id = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'test_condition_id.pickle'), 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:15.679627Z","iopub.execute_input":"2022-01-02T04:12:15.680031Z","iopub.status.idle":"2022-01-02T04:12:16.310566Z","shell.execute_reply.started":"2022-01-02T04:12:15.679983Z","shell.execute_reply":"2022-01-02T04:12:16.309646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of unique elements in **shipping**: 2","metadata":{}},{"cell_type":"code","source":"lb_shipping = LabelBinarizer(sparse_output=True)\n\n# train_shipping = lb_shipping.fit_transform(train_data['shipping'])\n# test_shipping = lb_shipping.transform(test_data['shipping'])\n# pickle.dump(train_shipping, open(\"train_shipping.pickle\", \"wb\"))\n# pickle.dump(test_shipping, open(\"test_shipping.pickle\", \"wb\"))\n\ntrain_shipping = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'train_shipping.pickle'), 'rb'))\ntest_shipping = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'test_shipping.pickle'), 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:16.312195Z","iopub.execute_input":"2022-01-02T04:12:16.312819Z","iopub.status.idle":"2022-01-02T04:12:16.625849Z","shell.execute_reply.started":"2022-01-02T04:12:16.31277Z","shell.execute_reply":"2022-01-02T04:12:16.624581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of unique elements in **cat_top**: 11","metadata":{}},{"cell_type":"code","source":"lb_cat_top = LabelBinarizer(sparse_output=True)\n\n# train_cat_top = lb_cat_top.fit_transform(train_data['cat_top'])\n# test_cat_top = lb_cat_top.transform(test_data['cat_top'])\n# pickle.dump(train_cat_top, open(\"train_cat_top.pickle\", \"wb\"))\n# pickle.dump(test_cat_top, open(\"test_cat_top.pickle\", \"wb\"))\n\ntrain_cat_top = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'train_cat_top.pickle'), 'rb'))\ntest_cat_top = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'test_cat_top.pickle'), 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:16.627212Z","iopub.execute_input":"2022-01-02T04:12:16.627469Z","iopub.status.idle":"2022-01-02T04:12:17.315612Z","shell.execute_reply.started":"2022-01-02T04:12:16.627439Z","shell.execute_reply":"2022-01-02T04:12:17.314418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of unique elements in **cat_sub**: 113","metadata":{}},{"cell_type":"code","source":"lb_cat_sub = LabelBinarizer(sparse_output=True)\n\n# train_cat_sub = lb_cat_sub.fit_transform(train_data['cat_sub'])\n# test_cat_sub = lb_cat_sub.transform(test_data['cat_sub'])\n# pickle.dump(train_cat_sub, open(\"train_cat_sub.pickle\", \"wb\"))\n# pickle.dump(test_cat_sub, open(\"test_cat_sub.pickle\", \"wb\"))\n\ntrain_cat_sub = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'train_cat_sub.pickle'), 'rb'))\ntest_cat_sub = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'test_cat_sub.pickle'), 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:17.317267Z","iopub.execute_input":"2022-01-02T04:12:17.317666Z","iopub.status.idle":"2022-01-02T04:12:17.91575Z","shell.execute_reply.started":"2022-01-02T04:12:17.317624Z","shell.execute_reply":"2022-01-02T04:12:17.914628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of unique elements in **cat_item**: 870","metadata":{}},{"cell_type":"code","source":"lb_cat_item = LabelBinarizer(sparse_output=True)\n\n# train_cat_item = lb_cat_item.fit_transform(train_data['cat_item'])\n# test_cat_item = lb_cat_item.transform(test_data['cat_item'])\n# pickle.dump(train_cat_item, open(\"train_cat_item.pickle\", \"wb\"))\n# pickle.dump(test_cat_item, open(\"test_cat_item.pickle\", \"wb\"))\n\ntrain_cat_item = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'train_cat_item.pickle'), 'rb'))\ntest_cat_item = pickle.load(open(os.path.join('/kaggle/input/trained-sparse-matrix', 'test_cat_item.pickle'), 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:17.917381Z","iopub.execute_input":"2022-01-02T04:12:17.917657Z","iopub.status.idle":"2022-01-02T04:12:18.570919Z","shell.execute_reply.started":"2022-01-02T04:12:17.917623Z","shell.execute_reply":"2022-01-02T04:12:18.570231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate\n\nVì bài toán giờ đã trở thành dự đoán log() và hàm đánh giá của kaggle là Root Mean Squared Log Error:\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=RMSLE&space;=&space;\\sqrt{&space;\\frac{1}{N}\\sum_{i=1}^{N}&space;(log(\\hat{y}_{i}&plus;1)-&space;log(y_{i}&plus;1))^2}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?RMSLE&space;=&space;\\sqrt{&space;\\frac{1}{N}\\sum_{i=1}^{N}&space;(log(\\hat{y}_{i}&plus;1)-&space;log(y_{i}&plus;1))^2}\" title=\"RMSLE = \\sqrt{ \\frac{1}{N}\\sum_{i=1}^{N} (log(\\hat{y}_{i}+1)- log(y_{i}+1))^2}\" /></a>\n\ntrong đó:\n\n* $\\hat{y}_{i}$: giá dự đoán\n\n* $y_{i}$: giá thực sự\n\nnên hàm evaluate có dạng như sau:","metadata":{}},{"cell_type":"code","source":"def evaluate(preds, y_test):\n    return np.sqrt(np.mean(np.power(preds - y_test, 2)))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:18.572582Z","iopub.execute_input":"2022-01-02T04:12:18.57291Z","iopub.status.idle":"2022-01-02T04:12:18.578892Z","shell.execute_reply.started":"2022-01-02T04:12:18.572866Z","shell.execute_reply":"2022-01-02T04:12:18.577601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gói các features phục vụ quá trình training và testing.\n\nĐể đánh giá độ hiệu quả của model, ta lấy 20% tập train làm tập valid.","metadata":{}},{"cell_type":"code","source":"from scipy.sparse import hstack\nfrom sklearn.model_selection import train_test_split\n\ntrain_features = (train_name, train_des, train_brand, train_condition_id, train_shipping, train_cat_top, train_cat_sub, train_cat_item)\nX = hstack(train_features).tocsr()\nX_train, X_test, y_train, y_test = train_test_split(X, train_data['log_price'], test_size=0.2, random_state=0)\n\ntest_features = (test_name, test_des, test_brand, test_condition_id, test_shipping, test_cat_top,  test_cat_sub, test_cat_item)\ntest_features = hstack(test_features).tocsr()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:18.580446Z","iopub.execute_input":"2022-01-02T04:12:18.580805Z","iopub.status.idle":"2022-01-02T04:12:36.379112Z","shell.execute_reply.started":"2022-01-02T04:12:18.580759Z","shell.execute_reply":"2022-01-02T04:12:36.378202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training\n\n3 models cổ điển được [sklearn](https://scikit-learn.org/stable/modules/classes.html#classical-linear-regressors) hỗ trợ.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import *\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\nimport xgboost as xgb\n\nrmsle_result = 100\nbest_model = ''","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:36.380355Z","iopub.execute_input":"2022-01-02T04:12:36.380696Z","iopub.status.idle":"2022-01-02T04:12:36.750032Z","shell.execute_reply.started":"2022-01-02T04:12:36.380652Z","shell.execute_reply":"2022-01-02T04:12:36.749241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, file_name):\n    print('Start training ' + str(model).split('(')[0] + '...')\n    model.fit(X_train, y_train)\n    pickle.dump(model, open(file_name, 'wb'))\ndef loss(model, X_test, y_test):\n    print('Root Mean Squared Error: ', end = '')\n    result = evaluate(model.predict(X_test), y_test)\n    print(result)\n    return result\ndef load(file_name):\n    model = pickle.load(open(os.path.join('/kaggle/input/trained-model', file_name), 'rb'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:36.751361Z","iopub.execute_input":"2022-01-02T04:12:36.751592Z","iopub.status.idle":"2022-01-02T04:12:36.760823Z","shell.execute_reply.started":"2022-01-02T04:12:36.751564Z","shell.execute_reply":"2022-01-02T04:12:36.759665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Regression\n\nĐầu tiên ta sẽ chọn loại model phổ biến và đơn giản nhất khi tiếp cận với bài toán regression: Hồi quy tuyến tính (trường hợp này là hồi quy đa bội: Multi linear regression).\n\n![Multi linear regression](https://i.stack.imgur.com/nqI6I.png)\n\nÁp dụng cho nghiên cứu mối quan hệ của nhiều biến độc lập và một biến phụ thuộc.\n\nPhương trình tổng quát:\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=y&space;=&space;b_{0}&space;&plus;&space;b_{1}&space;*&space;x_{1}&space;&plus;&space;b_{2}&space;*&space;x_{2}&space;&plus;&space;...&space;&plus;&space;s\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?y&space;=&space;b_{0}&space;&plus;&space;b_{1}&space;*&space;x_{1}&space;&plus;&space;b_{2}&space;*&space;x_{2}&space;&plus;&space;...&space;&plus;&space;s\" title=\"y = b_{0} + b_{1} * x_{1} + b_{2} * x_{2} + ... + s\" /></a>\n\ntrong đó: \n* $y$: biến phụ thuộc (biến ta sẽ dự đoán giá trị)\n* $x_{1}, x_{2}, ...$: biến độc lập (tác động lên y)\n* $b_{1}, b_{2}, ...$: độ dốc (mức độ thay đổi của y khi x thay đổi 1 đơn vị)\n* $s$: sai số\n* $b_{0}$: giá trị chặn (intercept)\n\n![](https://www.mometrix.com/blog/wp-content/uploads/2020/10/unnamed.png)\n\n\n\nMột nhược điểm của mô hình này là nó rất nhạy cảm với dữ liệu bất thường (outliners). Trong trường hợp này đã được khắc phục khi đưa về dự đoán log (đồ thị khảo sát giá đã làm).\n\n*Update: do thiết bị không đủ RAM và kaggle giới hạn thời gian training để chạy toàn bộ tập dữ liệu nên mô hình này chưa thể cho ra kết quả*.\n\n","metadata":{}},{"cell_type":"code","source":"# model = LinearRegression()\n# file_name = 'linear_regression.sav'\n\n## TRAINING\n# train(model, file_name)\n\n# model = load(file_name)\n\n## EVALUATE\n# result = loss(model, X_test, y_test)\n\n# if(result < rmsle_result):\n#     rmsle_result = result\n#     best_model = file_name","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:36.762095Z","iopub.execute_input":"2022-01-02T04:12:36.762588Z","iopub.status.idle":"2022-01-02T04:12:36.776454Z","shell.execute_reply.started":"2022-01-02T04:12:36.762553Z","shell.execute_reply":"2022-01-02T04:12:36.775566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ridge Regression\n\nVề cơ bản cũng giống với Linear Regression truyền thống, nhưng có điểm khác là công thức tìm giá trị hệ số b thì bổ sung thêm ràng buộc để sao cho các hệ số b nhỏ nhất có thể đến mức gần bằng 0, nghĩa là các feature (x) ít có ảnh hưởng tới giá trị đầu ra.\n\nLambda còn gọi là tham số Regularization, hay tham số Penalty, là số luôn dương (nghĩa là hệ số b càng to loss càng lớn)\n\n![](https://www.analyticsinsight.net/wp-content/uploads/2017/09/ridge_regression_geomteric.png)\n\nTrên hình là giá trị hệ số b1, b2 theo OLS (linear regression truyền thống) và theo Ridge.\n\nCác hệ số theo Ridge sẽ nhỏ hơn đáng kể so với OLS, dẫn đến đa phần training score sẽ thấp hơn nhưng điểm test thực tế lại cao hơn (so với linear regression truyền thống). Vì Ridge đã loại bớt được số lượng các hệ số, giảm bớt độ phức tạp của mô hình, qua đó tránh được tình trạng overfitting, đạt được genelization với dữ liệu test.","metadata":{}},{"cell_type":"code","source":"model = Ridge()\nfile_name = 'ridge.sav'\n\n## TRAINING\n# train(model, file_name)\n\nmodel = load(file_name)\n\n## EVALUATE\nresult = loss(model, X_test, y_test)\n\nif(result < rmsle_result):\n    rmsle_result = result\n    best_model = file_name","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:36.777782Z","iopub.execute_input":"2022-01-02T04:12:36.778653Z","iopub.status.idle":"2022-01-02T04:12:38.138977Z","shell.execute_reply.started":"2022-01-02T04:12:36.778609Z","shell.execute_reply":"2022-01-02T04:12:38.137786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SGD Regressor\n\nVới default *loss='squared_loss'*, model đang sử dụng là Linear Regression truyền thống với thuật toán tối ưu hàm mất mát Stochastic Gradient Descent.\n\nViệc tìm global minimum của hàm mất mát gần như bất khả thi. Thay vào đó ta tìm điểm local minimum có giá trị chấp nhận được rồi coi đó là kết quả của bài toán. Hướng tiếp cận ta đề cập đến là Gradient Descent: xuất phát từ một điểm mà chúng ta coi là *gần* với nghiệm của bài toán, sau đó dùng một phép toán lặp để *tiến dần* đến điểm cần tìm, tức đến khi đạo hàm gần với 0.\n\n![](https://1.bp.blogspot.com/-GQOE2Jf92oA/XNQDNLoQl7I/AAAAAAAAA1I/ifpzMryE2zgx7Y7SGy2IS4nTSNbE2EgggCLcBGAs/s1600/theta_new.png)\n\nHàm mất mát của Linear Regression là:\n\n![](https://upload.wikimedia.org/wikipedia/commons/8/89/Linear_Regression_Loss_Function.png)\n\nGradient Descent\n\nTìm local minimum bằng cách cập nhật $w_{t}$ (vector các hệ số), dấu trừ thể hiện việc phải đi ngược với đạo hàm: \n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=w_{t&plus;1}&space;=&space;w_{t}&space;-&space;\\Delta&space;*&space;{loss}'(w)\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?w_{t&plus;1}&space;=&space;w_{t}&space;-&space;\\Delta&space;*&space;{loss}'(w)\" title=\"w_{t+1} = w_{t} - \\Delta * {loss}'(w)\" /></a>\n\ntrong đó:\n* $\\Delta$: tốc độ học (learning rate)\n* ${loss}'(w)$: đạo hàm của hàm loss theo w\n\nStochastic Gradient Descent\n\nThay vì tính đạo hàm hàm loss trên toàn bộ tập dữ liệu rồi mới cập nhật w, giờ đây ta cập nhật trên mỗi điểm dữ liệu. Việc cập nhật từng điểm một như thế này có thể làm giảm đi tốc độ thực hiện 1 epoch (một lần duyệt qua toàn bộ các điểm trên tập dữ liệu). Nhưng mặt khác, SGD chỉ yêu cầu một lượng epoch rất nhỏ. Vì vậy SGD phù hợp với các bài toán có lượng data lớn.","metadata":{"execution":{"iopub.status.busy":"2022-01-02T03:09:54.860981Z","iopub.execute_input":"2022-01-02T03:09:54.861327Z","iopub.status.idle":"2022-01-02T03:09:55.08832Z","shell.execute_reply.started":"2022-01-02T03:09:54.861288Z","shell.execute_reply":"2022-01-02T03:09:55.087309Z"}}},{"cell_type":"code","source":"model = SGDRegressor()\nfile_name = 'sgd_regressor.sav'\n\n## TRAINING\n# train(model, file_name)\n\nmodel = load(file_name)\n\n## EVALUATE\nresult = loss(model, X_test, y_test)\n\nif(result < rmsle_result):\n    rmsle_result = result\n    best_model = file_name","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:38.1406Z","iopub.execute_input":"2022-01-02T04:12:38.140902Z","iopub.status.idle":"2022-01-02T04:12:39.186065Z","shell.execute_reply.started":"2022-01-02T04:12:38.140869Z","shell.execute_reply":"2022-01-02T04:12:39.185381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble models (Boosting method)\n\n**Cơ chế hoạt động**:\n\nMỗi base model được gọi là một weak learner. Chúng sẽ không hoạt động tốt trên toàn bộ tập D, nhưng khi kết hợp nhiều weak learners ta được một strong learner. Strong learner này chắc chắn sẽ hiệu quả trên tập D.\n\n(Một model thuộc nhóm **Bagging** là RandomForestRegressor đã được thử nhưng vượt quá 9 tiếng kaggle cho phép)","metadata":{}},{"cell_type":"markdown","source":"### XGBoost\nSử dụng nhiều base model là Decision Tree, làm mịn Training Loss (Sai số khi huấn luyện) và Regularization (Chuẩn hóa sai số, hệ số và số biến)\n\n\n\nMang nhiều ưu điểm vượt trội như:\n* Tốc độ xử lý\n* Cơ chế regularization xử lý overfit\n* Tự động bỏ qua nodes không mang giá trị tích cực trong việc mở rộng Tree\n* ...\n\nChính vì những ưu điểm đó mà hiệu năng của XGBoost tăng lên đáng kể so với các thuật toán ensemble learning khác.","metadata":{}},{"cell_type":"markdown","source":"**Kết quả trả về của model không được tốt!** \n\nRoot Mean Squared Error: 0.5341069414140582\n\n<a href=\"#Conclusion\">Giải thích về kết quả của XGBoost</a>\n\n\nTrên thực tế, có một model được đánh giá tốt hơn XGBoost trong việc xử lý lượng data lớn là Light GBM.\n\n### Light GBM\n\nLight GBM đánh bại tất cả các thuật toán khác khi tập dataset có kích thước cực lớn. Thực tế chứng minh, nó cần ít thời gian đê xử lý hơn trên tập dữ liệu này. Nguyên nhân sâu xa của sự khác biệt này nằm ở cơ chế làm viêc của Light GBM. Trong khi các thuật toán khác sử dụng cơ chế level-wise thì nó lại sử dụng leaf-wise.\n\n![](https://rohitgr7.github.io/content/images/2019/03/Screenshot-from-2019-03-27-23-09-47-1.png)\n\nNhư chúng ta thấy, leaf-wise chỉ mở rộng tree theo 1 trong 2 hướng so với cả 2 hướng của level-wise, tức là số lượng tính toán của Light GBM chỉ bằng 1/2 so với XGBoost.","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nmodel = lgb.LGBMRegressor()\nfile_name = 'lgbm.sav'\n\n## TRAINING\n# train(model, file_name)\n\nmodel = load(file_name)\n\n## EVALUATE\nresult = loss(model, X_test, y_test)\n\nif(result < rmsle_result):\n    rmsle_result = result\n    best_model = file_name","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:39.18754Z","iopub.execute_input":"2022-01-02T04:12:39.188082Z","iopub.status.idle":"2022-01-02T04:12:51.426414Z","shell.execute_reply.started":"2022-01-02T04:12:39.188035Z","shell.execute_reply":"2022-01-02T04:12:51.424798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance của Light GBM còn kém hơn cả XGBoost. Có lẽ Light GBM chỉ mạnh hơn XGBoost ở tốc độ tính toán mà thôi.","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\n\n**Tham khảo từ:**\n\n[**Kaggle discussion**: điểm mạnh và điểm yếu của XGBoost.](https://www.kaggle.com/discussion/196542)\n\n[**Medium post**: những bài toán không phải điểm mạnh của XGBoost và cách giải quyết.](https://towardsdatascience.com/why-xgboost-cant-solve-all-your-problems-b5003a62d12a)\n\n**Vấn đề:**\n\nXGBoost được đánh giá vô cùng mạnh mẽ khi có thể giải quyết các bài toán phi tuyến tính cùng các kỹ thuật như regularization để giảm overfiting dữ liệu.\n\nNhưng bên cạnh đó, XGBoost nói riêng và các thuật toán tree-based nói chung vẫn không tránh khỏi một vài hạn chế, đặc biệt là trong việc giải quyết bài toán xử lý ngôn ngữ.\n\nTrích nguyên văn từ trang web tham khảo:\n\n***When to NOT use XGBoost?***\n* *Natural language processing*\n* *Regression tasks that involve predicting a continuous output.*\n\nBài toán của ta bao gồm cả 2 nhiệm vụ trên: xử lý ngôn ngữ và dự đoán giá trị liên tục - đều không phải điểm mạnh của XGBoost.\n\n**Giải pháp:**\n\nCách giải quyết được đề ra là sử dụng Neural Network với khả năng fit đa dạng loại dữ liệu và cho phép *capture complex trends in data.*\n\n*Đã huấn luyện trên model MLPRegressor nhưng không thành công do vượt quá memory.*\n\n**Future work:**\n\nSẽ huấn luyện tập dự liệu này bằng Neural Network khi điều kiện về thiết bị và thời gian cho phép!","metadata":{}},{"cell_type":"markdown","source":"# Result\nDựa vào đánh giá trên tập valid, chọn model tốt nhất để đưa ra kết quả cuối cùng:","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../working/sample_submission_stg2.csv')\n\nmodel = pickle.load(open(os.path.join('/kaggle/input/trained-model', best_model), 'rb'))\nprint('Use ' + best_model + ' model')\npreds = model.predict(test_features)\npreds = np.exp(preds) - 1\nsubmission.loc[:, 'price'] = preds\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:51.428333Z","iopub.execute_input":"2022-01-02T04:12:51.428689Z","iopub.status.idle":"2022-01-02T04:12:53.799695Z","shell.execute_reply.started":"2022-01-02T04:12:51.428643Z","shell.execute_reply":"2022-01-02T04:12:53.798331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T04:12:53.801048Z","iopub.execute_input":"2022-01-02T04:12:53.801363Z","iopub.status.idle":"2022-01-02T04:13:06.876617Z","shell.execute_reply.started":"2022-01-02T04:12:53.801329Z","shell.execute_reply":"2022-01-02T04:13:06.874858Z"},"trusted":true},"execution_count":null,"outputs":[]}]}