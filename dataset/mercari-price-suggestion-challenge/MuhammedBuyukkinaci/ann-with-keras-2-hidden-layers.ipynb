{"nbformat_minor":1,"nbformat":4,"cells":[{"outputs":[],"execution_count":null,"source":"from datetime import datetime \nstart = datetime.now()\n#Importing libraries\nimport pandas as pd\nimport numpy as np\nimport scipy as sci\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport multiprocessing\n%matplotlib inline","cell_type":"code","metadata":{"collapsed":true,"_uuid":"5c083b5a1e71d7d99661b59a24ace295bcdf9c4f","_cell_guid":"0b5e892c-3be3-477c-9b11-d4af9d656e92"}},{"outputs":[],"execution_count":null,"source":"train = pd.read_csv(\"../input/train.tsv\", sep='\\t')\ntest = pd.read_csv(\"../input/test.tsv\", sep='\\t')","cell_type":"code","metadata":{"collapsed":true,"_uuid":"d41a5b16854d741a8e55c677c018df95f7a81504","_cell_guid":"c1cbd6d5-038a-4818-8483-c9e6a1f1be04"}},{"outputs":[],"execution_count":null,"source":"#Getting rid of outliers\ntrain['bigger_than_200'] = train['price'].map(lambda x: 1 if x >200 else 0)\ntrain = train[train['bigger_than_200'] ==0]\ndel train['bigger_than_200']","cell_type":"code","metadata":{"collapsed":true,"_uuid":"649af4fc08b8e9a7ec1ee7c5603a9b36c635badd","_cell_guid":"0894e0d5-3596-4996-ba01-5d8fc0db592a"}},{"outputs":[],"execution_count":null,"source":"print(train.shape)\nprint(test.shape)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"b4ac71eab56e3cac6d96627e9a4bce36877391ea","_cell_guid":"2fe0462c-49f3-4cc7-8a53-7f81de004c35"}},{"outputs":[],"execution_count":null,"source":"#Checking any missing values,\nimport missingno as msno\nmsno.bar(train,sort=True,figsize=(10,5))\nmsno.bar(test,sort=True,figsize=(10,5))","cell_type":"code","metadata":{"collapsed":true,"_uuid":"ac40409a61fb37845e03e41ef57f7ccfa6b9f6f2","_cell_guid":"40f45355-7b2d-4932-b480-6c941b13b8d7"}},{"outputs":[],"execution_count":null,"source":"#Getting the length of item description\ntrain['length'] = train['item_description'].map(lambda x: len(str(x)))\ntest['length'] = test['item_description'].map(lambda x: len(str(x)))\n\nnp.mean(train['length'])\nnp.mean(test['length'])","cell_type":"code","metadata":{"collapsed":true,"_uuid":"ac8ef0c80276ae5e59b867ddc29434bc90918326","_cell_guid":"94e1f728-fe0a-4602-a0cb-1dd169a2e37d"}},{"source":"They are close. Good !","cell_type":"markdown","metadata":{"_uuid":"cfb95ad6812a4ff82b9a34112f2603ef58fd344d","_cell_guid":"ecf3224f-4074-4b92-b39a-f0e9338e7fa0"}},{"outputs":[],"execution_count":null,"source":"train.head()","cell_type":"code","metadata":{"collapsed":true,"_uuid":"4e8c3e7ea763d70e3df79e34a98d5858a0a26cc8","_cell_guid":"b3a7525f-2fc8-4343-b373-625b53dfb5cb"}},{"outputs":[],"execution_count":null,"source":"#Merging data\ndata = pd.concat([train,test])\n#Defining a variable\ndata['train_or_not'] = data['train_id'].map(lambda x: 1 if x.is_integer() else 0)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"56057dfa36f67c199021d2b7fee6d0cef6a74ffe","_cell_guid":"6ceff7dd-9dbd-4fbd-abee-6acb44d4c0fd"}},{"outputs":[],"execution_count":null,"source":"#lowering letters\ndata['brand_name'] = data['brand_name'].map(lambda x: str(x).lower())\ndata['category_name'] = data['category_name'].map(lambda x: str(x).lower())\ndata['item_description'] = data['item_description'].map(lambda x: str(x).lower())\ndata['name'] = data['name'].map(lambda x: str(x).lower())","cell_type":"code","metadata":{"collapsed":true,"_uuid":"1dc0c2bb985c725b848d3cce6f45c002c3ead3f4","_cell_guid":"adeb7c90-0bb5-4abc-b3c0-45859805a687"}},{"outputs":[],"execution_count":null,"source":"data['no_of_words'] = data['item_description'].map(lambda x: len(str(x).split()))\n\nnp.mean(data['no_of_words'])","cell_type":"code","metadata":{"collapsed":true,"_uuid":"b1cd5acecce7f85e075797b424d4edc21385dbdc","_cell_guid":"0cbacbcc-94e7-41b6-bc74-4229c205c71f"}},{"source":"There are 25.63 words in a description on average","cell_type":"markdown","metadata":{"_uuid":"02e111dc206fd2a743e8bfeff0165da63d355d0e","_cell_guid":"3f7dee6d-e7d7-4c36-86e3-ad46e58d1f89"}},{"outputs":[],"execution_count":null,"source":"##Brand names\n#Number of unique brand names\nprint(len(set(data['brand_name'])))\nprint('brand_name in train',len(set(train['brand_name'])))\nprint('brand_name in test',len(set(test['brand_name'])))","cell_type":"code","metadata":{"collapsed":true,"_uuid":"d99c625c0261372b5b3d932fae4b4247c6039d49","_cell_guid":"998b6847-5a74-443d-893f-f5fd2a93f806"}},{"outputs":[],"execution_count":null,"source":"train_cat_names= list(set(train['brand_name']))\ntest_cat_names= list(set(test['brand_name']))\n\nin_test_not_in_train = [x for x in test_cat_names if x not in train_cat_names]\nprint(len(in_test_not_in_train))\n\nin_train_not_in_test = [x for x in train_cat_names if x not in test_cat_names]\nprint(len(in_train_not_in_test))\n","cell_type":"code","metadata":{"collapsed":true,"_uuid":"1ad1c6ecbd459f128290e33466fec65296dff7b6","_cell_guid":"917b2d34-0741-4a38-8f12-ed954e350228"}},{"outputs":[],"execution_count":null,"source":"#category\ndata['categories'] = data['category_name'].map(lambda x: list(str(x).split('/')))","cell_type":"code","metadata":{"collapsed":true,"_uuid":"0e679e3958576b06e8b95791a32543722b3cbb42","_cell_guid":"4feb0d8d-00c8-45c5-8997-d2f812d4142d"}},{"outputs":[],"execution_count":null,"source":"#no descriptions\ndata['no_description'] = data['item_description'].map(lambda x: 1 if str(x) =='no description yet' else 0)\nprint(len(data[data['no_description']==1]))","cell_type":"code","metadata":{"collapsed":true,"_uuid":"d0e01e199625c1df274341ae5ecae5096413696d","_cell_guid":"d007c33d-4529-4bd5-83cf-b119c6bc4c14"}},{"outputs":[],"execution_count":null,"source":"print('brand_name = nan & no description',len(data[(data['brand_name']=='nan') & (data['no_description'] ==1)]))\n","cell_type":"code","metadata":{"collapsed":true,"_uuid":"708b9b2c93e65be3b97c4f2cf8e5aa391f7604c2","_cell_guid":"054f6a6a-a154-46c7-9a09-2f0cf9e63d8b"}},{"outputs":[],"execution_count":null,"source":"#No brand name and no desc\nno_desc_no_brand = data[(data['brand_name']=='nan') & (data['no_description'] ==1)]\nno_desc_no_brand['test'] = no_desc_no_brand['test_id'].map(lambda x: 1 if x.is_integer() else 0)\nno_desc_no_brand = no_desc_no_brand[no_desc_no_brand['test'] ==0]","cell_type":"code","metadata":{"collapsed":true,"_uuid":"81e67c385f4299e722c150ff3e119298b1682337","_cell_guid":"6eed2bbe-5f35-414f-92f7-8683fe053d1d"}},{"outputs":[],"execution_count":null,"source":"plt.style.use('fivethirtyeight')\nplt.subplots(figsize=(10,5))\nno_desc_no_brand['price'].hist(bins=150,edgecolor='black',grid=False)\nplt.xticks(list(range(0,100,5)))\nplt.title('Price vs no brand&no_description')\nplt.show() ","cell_type":"code","metadata":{"collapsed":true,"_uuid":"c7d8c994b864e17d98271111401e8bb74e4f7b17","_cell_guid":"82a19f63-ef73-4b4b-80e6-c8cac06f9878"}},{"outputs":[],"execution_count":null,"source":"#No of rows whose price is bigger than 100\nprint(\"No of rows whose price is bigger than hundred in no_brand&no_description\",len(no_desc_no_brand[no_desc_no_brand['price'] >200]))\n\nno_desc_no_brand['price'].describe()\ndel no_desc_no_brand","cell_type":"code","metadata":{"collapsed":true,"_uuid":"85866864cb55a549bed1a06efb020455f9c915c6","_cell_guid":"84302b13-78c0-4f67-8838-5af72b04366c"}},{"outputs":[],"execution_count":null,"source":"from ggplot import *\np = ggplot(aes(x='price'), data=train[train['price']<200]) + geom_histogram(binwidth=10)+ theme_bw() + ggtitle('Histogram of price in train data')\nprint(p)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"31b9578f9726f25ac7d3b16368a43f8e1c6213ce","_cell_guid":"2dd28fa5-7af4-4319-91ce-75991cc0882f"}},{"outputs":[],"execution_count":null,"source":"data['price'].describe().apply(lambda x: format(x, 'f'))","cell_type":"code","metadata":{"collapsed":true,"_uuid":"4fdc8e2acaab0245fbe3105dbc05afd43ab0554e","_cell_guid":"dfa0861d-968d-4ce8-9666-174b8cdf84bd"}},{"outputs":[],"execution_count":null,"source":"#Length of categories\ndata['len_categories'] = data['categories'].map(lambda x: len(x))","cell_type":"code","metadata":{"collapsed":true,"_uuid":"1b495645348679f0c942551e54c1028b85f8af80","_cell_guid":"ef52ced5-9b7d-48e7-8d52-8dd9a452274f"}},{"source":"Most of products have 3 categories","cell_type":"markdown","metadata":{"_uuid":"34f4bc3cda80378b0bea490b1c9a271745054e4a","_cell_guid":"f8eb1e35-1d28-41b9-996f-1f880f9721c7"}},{"outputs":[],"execution_count":null,"source":"#Value_counts for item_condition_id\ntemp1=data['item_condition_id'].value_counts()[:5].to_frame()\nsns.barplot(temp1.index,temp1['item_condition_id'],palette='inferno')\nplt.title('Item condition id')\nplt.xlabel('')\nfig=plt.gcf()\nfig.set_size_inches(10,10)\nplt.show()","cell_type":"code","metadata":{"collapsed":true,"_uuid":"2d921cabe82212027c67c45c77d0bbcf258f68c0","_cell_guid":"ac83a0b7-1cea-47eb-8298-df8cc5822c3c"}},{"outputs":[],"execution_count":null,"source":"#Making binary 'item_condition_id'\nic_list = list(set(data['item_condition_id']))\n\nfor i in ic_list:\n    data['item_condition_id'+str(i)] = data['item_condition_id'].map(lambda x: 1 if x==i else 0)\n\ndel data['item_condition_id']","cell_type":"code","metadata":{"collapsed":true,"_uuid":"fa8df88a0136f0e75a725f086341f7c0986580ed","_cell_guid":"2b3c7b29-bb89-4547-97a4-d4d8b78572b9"}},{"outputs":[],"execution_count":null,"source":"#Correlation between no_of_words and price\ncorr = data[['no_of_words','price','shipping','len_categories','length']].corr()\n\n# Set up the matplot figure\nf,ax = plt.subplots(figsize=(12,9))\n\n#Draw the heatmap using seaborn\nsns.heatmap(corr, cmap='inferno', annot=True)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"26229e7c997de43a40a895df55880620628b048b","_cell_guid":"e7546881-8957-48d4-aa1b-a2bb4c57e793"}},{"source":"Please don't care the name of variables I defined below, I defined them according to 100 but due to time constrain, i lowered them.","cell_type":"markdown","metadata":{"_uuid":"dc18b6a9fb54b36fd890fd1442b96f953d671160","_cell_guid":"cd671689-5e45-40de-8e12-3908ef94dd38"}},{"outputs":[],"execution_count":null,"source":"##Name\nimport nltk\nimport collections as co\nstopWords =co.Counter( nltk.corpus.stopwords.words() )\nwords = list(data['name'])\n#Merging in a big string\nbig_string=\" \".join(words)\n#Splitting them via blank\nname_list = big_string.split()\n#Omitting splitwords\nname_list = [x for x in name_list if x not in stopWords]\n#Getting unique words\nunique_names = list(set(name_list))\n#Counting them\nc = co.Counter(name_list)\nmost_common_100 = c.most_common(60)\nmost_common_100_2 = [x[0] for x in most_common_100]\n#Making them a column\nfor i in most_common_100_2:\n    data['name_'+str(i)] = data['name'].map(lambda x: 1 if i in x else 0)\n\nprint(\"name completed\")","cell_type":"code","metadata":{"collapsed":true,"_uuid":"f7aa269305d183179d28520486a5459ca12be721","_cell_guid":"97e86058-8bf2-4d02-a796-60a5065a1820"}},{"source":"Please don't care the name of variables I defined below. Due to time constraint, I reduced number of columns.","cell_type":"markdown","metadata":{"_uuid":"cbca85855592d26be8e56f3f00c53f1536f08fde","_cell_guid":"fd940dbb-8a1b-4f02-8eba-e1a6923988b3"}},{"outputs":[],"execution_count":null,"source":"##Description\nwords1 = list(data['item_description'])\nbig_string1=\" \".join(words1)\nname_list1 = big_string1.split()\n\nname_list1 = [x for x in name_list1 if x not in stopWords]\n\nunique_names1 = list(set(name_list1))\n\nc = co.Counter(name_list1)\nmost_common_100_desc = c.most_common(60)\nmost_common_100_2_desc = [x[0] for x in most_common_100_desc]\nfor i in most_common_100_2_desc:\n    data['item_description_'+str(i)] = data['item_description'].map(lambda x: 1 if i in x else 0)\n\nprint(\"description completed\")","cell_type":"code","metadata":{"collapsed":true,"_uuid":"4395463efca9d6253b7cc07492cff7c2c0ae19cd","_cell_guid":"cc37e55e-5621-4dd1-9fc5-aa545b8dcd96"}},{"outputs":[],"execution_count":null,"source":"##First common 200 brands\nmost_common_brands = data['brand_name'].value_counts().sort_values(ascending=False)[:100]\n\nmost_common_brands = list(most_common_brands.index)\n#If a brand not in common brands, it was labeled as other_brand\nother_brand = \"other_brand\"\ndata['brand_name'] = data['brand_name'].map(lambda x: x if x in most_common_brands else other_brand)\n\nempty_df = pd.get_dummies(data['brand_name'])\nemp_list = list(empty_df.columns.values)\nemp_list = ['brand_' + str(x) for x in emp_list]\nempty_df.columns = emp_list\n        \ndata2 = pd.concat([data,empty_df],axis=1)\ndata = data2\ndel data2,empty_df\ndel name_list,name_list1,words,words1,big_string,big_string1\nprint(\"brand completed\")","cell_type":"code","metadata":{"collapsed":true,"_uuid":"bfbbb5f347995b3725fdf4ea822c390b7580e92d","_cell_guid":"3eb094d5-8a48-4f4d-a8bd-3500253aa749"}},{"outputs":[],"execution_count":null,"source":"#categories\ndata['categories']= data['categories'].map(lambda x: list(x)+[0,0,0,0])\ndata['cat1']=data['categories'].map(lambda x: x[0])\ndata['cat2']=data['categories'].map(lambda x: x[1])\ndata['cat3']=data['categories'].map(lambda x: x[2])\ndata['cat4']=data['categories'].map(lambda x: x[3])\ndata['cat5']=data['categories'].map(lambda x: x[4])\nmost_common_cat1=data['cat1'].value_counts().sort_values(ascending=False)[:11]\nmost_common_cat2=data['cat2'].value_counts().sort_values(ascending=False)[:35]\nmost_common_cat3=data['cat3'].value_counts().sort_values(ascending=False)[:50]\nmost_common_cat4=data['cat4'].value_counts().sort_values(ascending=False)[:100]\nmost_common_cat5=data['cat5'].value_counts().sort_values(ascending=False)[:100]\n\n\n#Categories, we fill focus on first 3 categories\ncat1_list = list(most_common_cat1.index)\ncat2_list = list(most_common_cat2.index)\ncat3_list = list(most_common_cat3.index)\n","cell_type":"code","metadata":{"collapsed":true,"_uuid":"b86c8bfec28112d4950b14ef5121539461f2bd0a","_cell_guid":"817b7745-57eb-4d17-be62-a9c884304010"}},{"outputs":[],"execution_count":null,"source":"#If a category not in cat1, it was labeled as 'cat1_other'\ncat1_other = \"cat1_other\"\ndata['cat1'] = data['cat1'].map(lambda x: x if x in cat1_list else cat1_other)\n#If a category not in cat2, it was labeled as 'cat2_other'\ncat2_other = \"cat2_other\"\ndata['cat2'] = data['cat2'].map(lambda x: x if x in cat2_list else cat2_other)\n#If a category not in cat3, it was labeled as 'cat3_other'\ncat3_other = \"cat3_other\"\ndata['cat3'] = data['cat3'].map(lambda x: x if x in cat3_list else cat3_other)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"c368b264a91327b875bd08bc6930ae86823b7814","_cell_guid":"83f5d040-80db-4b99-acd0-de999705a721"}},{"outputs":[],"execution_count":null,"source":"#Making binary for cat1\nempty_df1 = pd.get_dummies(data['cat1'])\nemp_list1 = list(empty_df1.columns.values)\nemp_list1 = ['cat1_' + str(x) for x in emp_list1]\nempty_df1.columns = emp_list1\n#Making binary for cat2\nempty_df2 = pd.get_dummies(data['cat2'])\nemp_list2 = list(empty_df2.columns.values)\nemp_list2 = ['cat2_' + str(x) for x in emp_list2]\nempty_df2.columns = emp_list2\n#Making binary for cat3\nempty_df3 = pd.get_dummies(data['cat3'])\nemp_list3 = list(empty_df3.columns.values)\nemp_list3 = ['cat3_' + str(x) for x in emp_list3]\nempty_df3.columns = emp_list3\n#Merging them\ndata2 = pd.concat([data,empty_df1,empty_df2,empty_df3],axis=1)\ndata = data2\n#Deleting unnecessary things\ndel data2,empty_df1,empty_df2,empty_df3\ndel data['cat1'],data['cat2'],data['cat3'],data['cat4'],data['cat5'],data['item_description'],data['name'],data['categories'],data['category_name'],data['brand_name']","cell_type":"code","metadata":{"collapsed":true,"_uuid":"bcab5f9daa6ee8b88fbcc2a5af6d7efadcddac46","_cell_guid":"2c223800-9698-4d07-be3d-38ed688f52b0"}},{"outputs":[],"execution_count":null,"source":"print(\"category completed\")\nstop = datetime.now()\nexecution_time = stop-start \nprint(execution_time)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"99643e975fbb7227576a3ccf53be9b0a43cff139","_cell_guid":"42022f06-107f-4441-9791-e76c1b65eef7"}},{"outputs":[],"execution_count":null,"source":"test_id = data['test_id']\ntrain_id = data['train_id']\ndel data['train_id'],data['test_id']\ndata_head = data.head()\n#Separating the merged data into train and test\ntraining = data[data['train_or_not'] ==1]\ntesting = data[data['train_or_not'] ==0]","cell_type":"code","metadata":{"collapsed":true,"_uuid":"30e39538440661ce5a633f122915be91ed736598","_cell_guid":"83b63b96-2554-43f4-8cc2-12bc9130c95c"}},{"outputs":[],"execution_count":null,"source":"del training['train_or_not']\ndel testing['train_or_not']","cell_type":"code","metadata":{"collapsed":true,"_uuid":"ddaf310eed8409c382709e8e4b1e0d4b780ec57d","_cell_guid":"23e1cb15-e0bf-4e71-a6b9-f366a815469e"}},{"outputs":[],"execution_count":null,"source":"y = training['price'].values\n#Deleting unnecessary columns\ndel training['price']\ndel testing['price']\ntrain_size = len(list(training.columns.values))\ntrain_names = list(training.columns.values)\n","cell_type":"code","metadata":{"collapsed":true,"_uuid":"8bc0ed9f9dfd090fdfe4ba228e4534e9389456ca","_cell_guid":"b52b54da-9f62-40e7-9880-dbe8c0450384"}},{"source":"I decided which parameters are important via XGBoost .The code below takes approximately 45 minutes on a CPU. I made it comment because I donT we have enough time","cell_type":"markdown","metadata":{"_uuid":"ec5357f212473f16313c8f95e53cd1d2dd194146","_cell_guid":"3b9d52e9-6d34-480e-be74-f01c9df72712"}},{"outputs":[],"execution_count":null,"source":"\"\"\"\ntraining = training.values\ntesting = testing.values\nstart = datetime.now()\nimport xgboost as xgb\nmodel = xgb.XGBRegressor(n_estimators=50)\nmodel.fit(training,y)\nending = datetime.now()\nprint(ending-start)\nprint (model)\n\n\nfrom xgboost import plot_importance\nfig, ax = plt.subplots(figsize=(20, 15))\nplot_importance(model, ax=ax)\n\ntraining = pd.DataFrame(training)\ntesting= pd.DataFrame(testing)\n\ntemp = pd.DataFrame(model.feature_importances_)\ntemp2 = list(temp[temp[0]>0].index)\n\"\"\"","cell_type":"code","metadata":{"collapsed":true,"_uuid":"8bcf3b2b3f42e5c819651b5223116fb56ec1eb9f","_cell_guid":"06b0ebad-204d-4010-9dba-697fd86f5511"}},{"outputs":[],"execution_count":null,"source":"#The numbers below represent which columns are important.We obtained them via the code above\ntemp2 =[0, 1, 4, 5, 8, 10, 11, 14, 17, 21, 23, 27, 50, 52, 53, 63, 65, 70, 71, 72, 73, 74, 84, 89, 91, 102, 104, 109, 110, 115, 124, 125, 131, 133, 139, 157, 158, 162, 173, 174, 178, 180, 185, 188, 194, 196, 205, 208, 218, 220, 231, 232, 235, 236, 247, 248, 251, 259, 265, 268, 272, 277, 281, 284, 288, 289, 303, 306, 308, 310, 312]\n","cell_type":"code","metadata":{"collapsed":true,"_uuid":"cd888af894b7ee95930a19dedbf6073f48e5e6ff","_cell_guid":"15cbc592-d8e4-4ca2-abab-27f5bd056c6f"}},{"outputs":[],"execution_count":null,"source":"#Getting the names of important features via indexing\ntemp3 = [train_names[x] for x in temp2]\nprint(\"some important features are \",temp3[:20])","cell_type":"code","metadata":{"collapsed":true,"_uuid":"bc2ee3c8880cb69d3fa438637d140d2c31fb68aa","_cell_guid":"d4bb439c-1edf-4e33-930c-b489b926c94c"}},{"outputs":[],"execution_count":null,"source":"#Preparing model for ANN\ntesting.columns = train_names\ntraining.columns = train_names\n#Getting important columns\ntraining_last = training[temp3]\ntesting_last = testing[temp3]\nprint(training_last.shape)\nprint(testing_last.shape)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"90d5e7ada8934c7ba25cfe0e4f49ce57a1976697","_cell_guid":"b32d24dc-2bcb-4c9c-93d4-b6481814d6ff"}},{"outputs":[],"execution_count":null,"source":"input_node = len(list(training_last.columns.values))\nprint(\"there are \",input_node,\" nodes in input layer\")\n#Makin ndarray\ntraining_last = training_last.values\ntesting_last = testing_last.values","cell_type":"code","metadata":{"collapsed":true,"_uuid":"1febd0a5b2550fd9c7275928dd73da54d485648a","_cell_guid":"2479c1b2-a3f8-4445-9143-32d50a7e5563"}},{"source":"I didn't normalize the columns because it takes time. Most of our columns are binary. Therefore, it doesn't look logical to standardize.","cell_type":"markdown","metadata":{"_uuid":"df50214a9e13c6f0ce26b415972afb7286081b0c","_cell_guid":"e3c36926-b8af-4acc-a2e3-a062e9b80189"}},{"outputs":[],"execution_count":null,"source":"#part 2 :Let'S make ANN\n# importing the keras library\nimport keras\n# required to initialize NN\nfrom keras.models import Sequential\n#Required to build layers of NN\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n#Initializing the ANN\nclassifier = Sequential()","cell_type":"code","metadata":{"collapsed":true,"_uuid":"e7ac7befebd57f8c28b0cf768ae0ff0c92109e44","_cell_guid":"4da57d83-0176-45a6-829f-1b483b93c5ba"}},{"outputs":[],"execution_count":null,"source":"#adding the input layer and first hidden layer (71 nodes on Input layer, 71 nodes on Hidden Layer 1) and RELU\nclassifier.add(Dense(output_dim = 100 , init ='he_normal', activation ='relu',input_dim = input_node))\nclassifier.add(Dropout(p=0.15))\n#Adding the second layer(71 nodes on Hidden layer 1, 60 nodes on Hidden Layer 2) and RELU\nclassifier.add(Dense(output_dim = 40 , init ='glorot_uniform', activation ='tanh'))\nclassifier.add(Dropout(p=0.07))\n#adding the output layer- \nclassifier.add(Dense(output_dim = 1 , init ='uniform'))\n#compiling ANN- optimizer for weights on ANN , adam = storchastik gradient descentlerden birisi\nclassifier.compile( optimizer='adam' , loss='mean_squared_logarithmic_error', metrics = ['mae']  )","cell_type":"code","metadata":{"collapsed":true,"_uuid":"db32896684202371081e994365d5d66186969de2","_cell_guid":"f2ae7a1b-4310-4570-b399-c9514d009c17"}},{"outputs":[],"execution_count":null,"source":"start = datetime.now()\nclassifier.fit(training_last, y ,batch_size=64,nb_epoch=8)\nstop = datetime.now()\nexecution_time = stop-start \nprint(execution_time)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"060c54a6fa8d44bfd644bfeb3198599cfb617ac5","_cell_guid":"3c493f6d-9deb-4c9e-8a2a-db81ad0d894c"}},{"outputs":[],"execution_count":null,"source":"#Preparing the submission file\nour_pred = classifier.predict(testing_last)\nour_pred = pd.DataFrame(our_pred)\nourpred = pd.DataFrame(our_pred).rename(columns={0:'price'})\n\ntest_id = test_id[len(train):len(data)]\ntest_id = test_id.map(lambda x: int(x))\ntest_id = test_id.reset_index(drop=True)\ntest_id = pd.DataFrame(test_id)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"0dc9127642146c66f222b890cf0bff0ee7ef1564","_cell_guid":"47548e04-259c-4e26-bdf3-683c69ab4895"}},{"outputs":[],"execution_count":null,"source":"output_file = pd.concat([test_id,ourpred],axis=1)\n\nprint(\"average of test predictions = \",np.mean(output_file['price']))\n\noutput_file.to_csv('16-01-2018-mercari-ANN3.csv',index=False)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"00d4abae20851aee7538aa45e41a0fcc177f1c5c","_cell_guid":"1d8e9317-bfa6-475a-b42c-928304f51e81"}},{"outputs":[],"execution_count":null,"source":"","cell_type":"code","metadata":{"collapsed":true,"_uuid":"285774f0f7b2d92a140eb63e0b5656c32ce23b0b","_cell_guid":"72684c96-c030-4f09-994a-fdb08e8d13f4"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"file_extension":".py","pygments_lexer":"ipython3","name":"python","version":"3.6.4","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3}}}}