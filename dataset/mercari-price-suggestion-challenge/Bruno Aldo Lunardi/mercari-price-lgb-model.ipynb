{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Python ≥3.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn ≥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# Common imports\nimport numpy as np\nimport os\nimport gc\nimport time\n\n#NLP packages\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nimport re\nfrom string import punctuation\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import TruncatedSVD\n\nstop_words = set(stopwords.words('english'))\n\n\nfrom collections import Counter\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npalette = sns.color_palette('Paired', 10)\n\nimport numpy as np\nimport pandas as pd\n# Pandas display options\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\n\n#setting fontsize and style for all the plots\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.size'] = 18\nplt.rcParams['figure.figsize'] = (16,5)\n\n%matplotlib inline \n#plotting directly without requering the plot()\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\") #ignoring most of warnings, cleaning up the notebook for better visualization\n\npd.set_option('display.max_columns', 500) #fixing the number of rows and columns to be displayed\npd.set_option('display.max_rows', 500)\n\nprint(os.listdir(\"../input\")) #showing all the files in the ../input directory\n\n# Set random seed \nrandomseed = 42\n\n# Any results you write to the current directory are saved as output. Kaggle message :D","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_table('../input/train.tsv',low_memory=True)\ntest = pd.read_table('../input/test_stg2.tsv', low_memory=True)\nprint('Training set shape: {}'.format(train.shape))\nprint('Testing set shape: {}'.format(test.shape))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,5))\nplt.subplot(2,1,1)\nsns.distplot(train['price'])\nplt.subplot(2,1,2)\nsns.distplot(np.log1p(train['price']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,10))\nplt.subplot(2,1,1)\nsns.countplot(train['shipping'])\nplt.subplot(2,1,2)\nsns.countplot(train['item_condition_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference: BuryBuryZymon at https://www.kaggle.com/maheshdadhich/i-will-sell-everything-for-free-0-55\ndef split_cat(text):\n    try: return text.split(\"/\")\n    except: return (\"missing\", \"missing\", \"missing\")\n\ntrain['general_cat'], train['subcat_1'], train['subcat_2'] = \\\nzip(*train['category_name'].apply(lambda x: split_cat(x)))\ntest['general_cat'], test['subcat_1'], test['subcat_2'] = \\\nzip(*test['category_name'].apply(lambda x: split_cat(x)))\n\n\nprint('Training set shape: {}'.format(train.shape))\nprint('Testing set shape: {}'.format(test.shape))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imputing_nan_values(X):\n    X.category_name.fillna(value=\"missing\", inplace=True)\n    X.brand_name.fillna(value=\"missing\", inplace=True)\n    X.item_description.fillna(value=\"missing\", inplace=True)\n    return (X)\n\ntrain = imputing_nan_values(train)\ntest = imputing_nan_values(test)\n\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,5))\nsns.countplot(train['general_cat'])\nplt.xlabel('General Category',fontsize = 15,color='blue')\nplt.ylabel('Count',fontsize = 15,color='blue')\nplt.xticks(rotation=45)\nplt.title('General Category/Count',fontsize = 20,color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['brand_name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['has_brand'] = 1 #setting all the values to true as default\ntest['has_brand'] = 1\ntrain['has_description'] = 1 #setting all the values to true as default\ntest['has_description'] = 1\n\ntrain.loc[train['item_description'] == 'No description yet', 'has_description'] = 0\ntrain.loc[train['item_description'] == 'No description yet', 'has_description'] = 0\ntrain.loc[train['brand_name'] == 'missing', 'has_brand'] = 0\ntrain.loc[train['brand_name'] == 'missing', 'has_brand'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='has_brand', y='price', data=train, aspect=1.5,alpha=0.8)\nplt.xlabel('Has brand: 0 = missing', fontsize = 15,color='blue')\nplt.ylabel('Price',fontsize = 15,color='blue')\nplt.title('Has Brand X Price',fontsize = 20,color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='has_description', y='price', data=train, aspect=1.5,alpha=0.8)\nplt.xlabel('has_description: 0 = No description', fontsize = 15,color='blue')\nplt.ylabel('Price',fontsize = 15,color='blue')\nplt.title('HAS DESCRIPTION X Price',fontsize = 20,color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# description related tf-idf features \n# I guess \"No dscription present won't affact these features ... So, I am not removing them.\n## https://www.kaggle.com/maheshdadhich/i-will-sell-everything-for-free-0-55\nstart = time.time()\ntfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,1))\nfull_tfidf = tfidf_vec.fit_transform(train['item_description'].values.tolist() + test['item_description'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train['item_description'].values.tolist())\ntest_tfidf = tfidf_vec.transform(train['item_description'].values.tolist())\n\nn_comp = 40\nsvd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\nsvd_obj.fit(full_tfidf)\ntrain_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\ntest_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n    \ntrain_svd.columns = ['svd_item_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_item_'+str(i) for i in range(n_comp)]\ntrain = pd.concat([train, train_svd], axis=1)\ntest = pd.concat([test, test_svd], axis=1)\nend = time.time()\n\nprint(\"time taken {}\".format(end - start))\nprint('Training set shape: {}'.format(train.shape))\nprint('Testing set shape: {}'.format(test.shape))\ngc.enable()\ndel tfidf_vec, full_tfidf,train_tfidf,test_tfidf,svd_obj,train_svd,test_svd\ngc.collect()\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb = LabelEncoder()\nlabel_encoder_columns = ['brand_name','subcat_1','subcat_2']\nfor name in label_encoder_columns:  \n    train[name] = lb.fit_transform(train[name])\n    test[name] = lb.fit_transform(test[name])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"fig = plt.figure(figsize=(16,10))\nsns.set_context(\"notebook\", font_scale=1.5)\n\nsns.pointplot(x=train['desc_len'],y=train['price'],color='#606060',alpha=0.8)\nplt.xlabel('Number of the words in the description', fontsize = 15,color='blue')\nplt.ylabel('Target variable: price',fontsize = 15,color='blue')\nplt.xticks(np.arange(0,150,2), fontsize=10, rotation=45)\nplt.title('Word Count/target',fontsize = 20,color='blue')"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"train[train['desc_len'] >= 77]['desc_len'].value_counts().sum()"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.get_dummies(train, columns=['general_cat','item_condition_id'])\ntest = pd.get_dummies(test, columns=['general_cat','item_condition_id'])\n\nprint('Training set shape: {}'.format(train.shape))\nprint('Testing set shape: {}'.format(test.shape))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_columns = ['general_cat','item_description','category_name','item_condition_id','name',\n                           'train_id', 'price']\nfeatures_to_be_used = [f for f in train.columns if f not in drop_columns]\n\ntrain_labels = np.log1p(train['price'].values)\ntrain = train.loc[:,features_to_be_used]\ntest = test.loc[:,features_to_be_used]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training set shape: {}'.format(train.shape))\nprint('Testing set shape: {}'.format(test.shape))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_final,train_validation, train_y, train_val_y  = train_test_split(train, train_labels,test_size=0.2, shuffle = True, random_state=randomseed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_final.shape, train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's create this function to make it easier and clean to fit the model and use the cross_val_score and obtain results\nimport time #implementing in this function the time spent on training the model\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor, Pool\nimport lightgbm as lgb\nimport xgboost as xgb\nimport eli5\nimport gc\n\ndef train_model(X_train, x_val, y, y_val, params=None, model_type='lgb', plot_feature_importance=False):\n  \n    evals_result={}\n    \n    \n    if model_type == 'lgb':\n        start = time.time()\n        \n        model = lgb.LGBMRegressor(**params, n_estimators = 15000, nthread = 4, n_jobs = -1)\n        \n        model.fit(X_train, y, eval_set=[(X_train, y), (x_val, y_val)], eval_metric='rmse', early_stopping_rounds=200,\n                    verbose=50)\n            \n        y_pred_valid = model.predict(x_val, num_iteration=model.best_iteration_)\n        \n        end = time.time()\n        \n        #y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n        \n        print('RMSE validation data: {}'.format(np.sqrt(mean_squared_error(y_val,y_pred_valid))))\n        \n        \n        if plot_feature_importance:\n            # feature importance\n            fig, ax = plt.subplots(figsize=(16,16))\n            lgb.plot_importance(model, max_num_features=50, height=0.8,color='c', ax=ax)\n            plt.title(\"LightGBM - Feature Importance\", fontsize=14)\n            \n        print('Total time spent: {}'.format(end-start))\n        return model\n            \n    if model_type == 'xgb':\n        start = time.time()\n        \n        model = xgb.XGBRegressor(**params, nthread = 4, n_jobs = -1)\n\n        model.fit(X_train, y, eval_metric=\"rmse\", \n                      eval_set=[(X_train, y), (x_val, y_val)],verbose=20,\n                      early_stopping_rounds=50)\n        \n        y_pred_valid = model.predict(x_val, ntree_limit=model.best_ntree_limit)\n        \n        end = time.time()\n\n        print('RMSE validation data: {}'.format(np.sqrt(mean_squared_error(y_val,y_pred_valid))))\n        \n        print('Total time spent: {}'.format(end-start))\n        return model\n            \n    if model_type == 'cat':\n        start = time.time()\n        model = CatBoostRegressor(eval_metric='RMSE', **params)\n        model.fit(X_train, y, eval_set=(x_val, y_val), \n                  cat_features=[], use_best_model=True)\n\n        y_pred_valid = model.predict(x_val)\n        \n        print('RMSE validation data: {}'.format(np.sqrt(mean_squared_error(y_val,y_pred_valid))))\n        \n        end = time.time()\n        \n        if plot_feature_importance:\n            feature_score = pd.DataFrame(list(zip(X_train.dtypes.index, model.get_feature_importance(Pool(X_train, label=y, cat_features=[])))), columns=['Feature','Score'])\n            feature_score = feature_score.sort_values(by='Score', kind='quicksort', na_position='last')\n            feature_score.plot('Feature', 'Score', kind='barh', color='c', figsize=(16,16))\n            plt.title(\"Catboost Feature Importance plot\", fontsize = 14)\n            plt.xlabel('')\n\n        print('Total time spent: {}'.format(end-start))\n        return model\n        \n    # Clean up memory\n    gc.enable()\n    del model, y_pred_valid, X_test,X_train,X_valid, y_pred, y_train, start, end,evals_result, x_val\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_cat = {\n    'iterations': 1500,\n    'max_ctr_complexity': 6,\n    'random_seed': 42,\n    'od_type': 'Iter',\n    'od_wait': 100,\n    'verbose': 50,\n    'depth': 4\n}\n\n#cat_model = train_model(train_final.drop('tokens',axis=1),train_validation.drop('tokens',axis=1),train_y,train_val_y,params_cat,\n                        #model_type='cat',plot_feature_importance=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_lgb = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\",\n        \"num_leaves\" : 30,\n        \"min_child_weight\" : 50,\n        \"learning_rate\" : 0.1,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.7,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 42,\n        'reg_aplha': 1,\n        'reg_lambda': 0.001\n}\n\nlgb_model = train_model(train_final,train_validation,train_y,train_val_y,params_lgb,plot_feature_importance=True)\npreds_lgb = lgb_model.predict(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission_stg2.csv')\nsubmission['price'] = np.expm1(preds_lgb)\nsubmission.to_csv(\"lgb_model.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}