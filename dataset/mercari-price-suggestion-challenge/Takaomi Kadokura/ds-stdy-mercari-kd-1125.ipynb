{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"圧縮されているので解凍する必要有り"},{"metadata":{"trusted":true},"cell_type":"code","source":"# !apt-get install p7zip\n# !p7zip -d -f -k /kaggle/input/mercari-price-suggestion-challenge/train.tsv.7z\n# !p7zip -d -f -k /kaggle/input/mercari-price-suggestion-challenge/test.tsv.7z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# タブ区切りのデータ\ntrain = pd.read_csv('/kaggle/input/mercari/train.tsv', sep='\\t')\ntest = pd.read_csv('/kaggle/input/mercari/test.tsv', sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* train_id, test_id\tID\n* name\t商品名\n* item_condition_id\t商品のコンディション(悪い〜良いの5段階)　※1は良好～5は不良\n* category_name\t商品のカテゴリ (最大3つ)\n* brand_name\tブランド名\n* price\t商品が販売された時の価格(ドル)で、今回求める数値\n* shipping\t送料が出品者負担かどうか(出品者負担: 1、購入者負担: 0)\n* item_description\t商品の説明\n\n"},{"metadata":{},"cell_type":"markdown","source":"\n## 必要なライブラリをインポート"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n\nfrom datetime import datetime\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nimport lightgbm as lgb\n\n# 最大カラム数を100に拡張(デフォルトだと省略されてしまうので)\n# 常に全ての列（カラム）を表示\npd.options.display.max_columns = None\npd.options.display.max_rows = 80\n\n# 小数点2桁で表示(指数表記しないように)\npd.options.display.float_format = '{:.2f}'.format\n%matplotlib inline\n#ワーニングを抑止\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nfrom sklearn.linear_model import Ridge\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nimport string\n\n# 出現回数がMAX_FEAT_DESCP以下の単語は排除する\nMAX_FEAT_DESCP = 1000\n\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[:10000]\ntest = test[:10000]\n\n# Idは不要なので、削除して別に変数化し、スコア提出時に使用\ntrain_Id = train.train_id\ntest_Id = test.test_id\n\n# Id列削除\ntrain.drop('train_id', axis=1, inplace=True)\ntest.drop('test_id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.データの概要確認"},{"metadata":{},"cell_type":"markdown","source":"## データのレコード数とカラム数を確認"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## データのデータ定義を確認"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## データの数値項目の統計要約量を表示"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## オブジェクト型のレコード数、ユニーク数、最頻値の出現回数を表示"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include='O')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 欠損値を確認"},{"metadata":{"trusted":true},"cell_type":"code","source":"#isnull().sum()を使用して欠損値のカウントを表示する\nprint(train.isnull().sum())\nprint(\"-\"*30)\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 欠損値を補完\n* brand_nameとcategory_nameについては欠損値補完が必要\n* brand_nameは、missingを設定\n* item_descriptionは、Noneを設定"},{"metadata":{"trusted":true},"cell_type":"code","source":"def handle_missing_inplace(dataset):\n    dataset['brand_name'].fillna(value='missing', inplace=True)\n    dataset['item_description'].fillna(value='None', inplace=True)\n\nhandle_missing_inplace(train)\nhandle_missing_inplace(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#isnull().sum()を使用して欠損値のカウントを表示する\nprint(train.isnull().sum())\nprint(\"-\"*30)\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.目的変数の確認"},{"metadata":{},"cell_type":"markdown","source":"## 目的変数であるpriceの要約統計量を表示"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"price\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 分布確認\nfig = plt.figure(figsize=(10, 4))\nplt.subplots_adjust(wspace=0.4)\n\n# ヒストグラム\nax = fig.add_subplot(1, 2, 1)\nsns.distplot(train['price'], ax=ax)\n\n# QQプロット\nax2 = fig.add_subplot(1, 2, 2)\nstats.probplot(train['price'], plot=ax2)\n\nplt.show()\n\n# 変換後の要約統計量表示\nprint(train['price'].describe())\nprint(\"-\"*30)\nprint(\"歪度: %f\" % train['price'].skew())\nprint(\"尖度: %f\" % train['price'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## priceを対数変換"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = train.copy()\n\n#目的変数の対数log(x+1)をとる\ndf['price'] = np.log1p(df['price'])\n\n# 標準化(平均0, 分散1)\nscaler=StandardScaler()\ndf['price']=scaler.fit_transform(df[['price']])\n\n# 分布確認\nfig = plt.figure(figsize=(10, 4))\nplt.subplots_adjust(wspace=0.4)\n\n# ヒストグラム\nax = fig.add_subplot(1, 2, 1)\nsns.distplot(df['price'], ax=ax)\n\n# QQプロット\nax2 = fig.add_subplot(1, 2, 2)\nstats.probplot(df['price'], plot=ax2)\n\nplt.show()\n\n# 変換後の要約統計量表示\nprint(df['price'].describe())\nprint(\"-\"*30)\nprint(\"歪度: %f\" % df['price'].skew())\nprint(\"尖度: %f\" % df['price'].kurt())\n\n\ndel df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.説明変数の確認"},{"metadata":{},"cell_type":"markdown","source":"##  データ型を確認"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats = list(train.select_dtypes(include=['object']).columns)\nnums = list(train.select_dtypes(exclude=['object']).columns)\nprint(f'categorical variables:  {cats}')\nprint(f'numerical variables:  {nums}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ユニーク数を表示"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.nunique(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 名義変数、順序変数、連続変数に分ける"},{"metadata":{},"cell_type":"markdown","source":"## name、category_name、brand_name、item_descriptionについて、ユニーク数が多すぎるため、加工をする必要あり。"},{"metadata":{},"cell_type":"markdown","source":"## カテゴリ変数を処理\n* カテゴリを/区切りで3分割する。"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_cat(text):\n    \"\"\"\n    ・カテゴリを/で切り分ける\n    ・データが存在しない場合は'No Label'を返す\n    \"\"\"\n    try: return text.split(\"/\")\n    except: return ('No Label', 'No Label', 'No Label')\n\n# 3つに切り分けたカテゴリ名を'subcat_0'、'subcat_1'、'subcat_2'に登録\ntrain['subcat_0'], train['subcat_1'], train['subcat_2'] = \\\n    zip(*train['category_name'].apply(lambda x: split_cat(x)))\n\ntest['subcat_0'], test['subcat_1'], test['subcat_2'] = \\\n    zip(*test['category_name'].apply(lambda x: split_cat(x)))\n\n# 元のカテゴリネームは削除\ntrain.drop('category_name', axis=1, inplace=True)\ntest.drop('category_name', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## brand_nameを処理\nbrand_nameは、欠損値が多いので、nameにて補完を行う"},{"metadata":{},"cell_type":"markdown","source":"* ブランドリストを作成 \n* missing'の商品名の単語がブランドリストに存在する場合、ブランド名の'missing'を商品名に置き換える\n* 商品名がブランドリストの名前と完全に一致する場合、ブランド名を商品名に置き換える"},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainとtestを縦方向に結合\nfull_set = pd.concat([train, test])\n# full_setの'brand_name'から重複なしのブランドリスト(集合)を生成\nall_brands = set(full_set['brand_name'].values)\n\n# 'brand_name'の欠損値NaNを'missing'に置き換える\ntrain['brand_name'].fillna(value='missing', inplace=True)\ntest['brand_name'].fillna(value='missing', inplace=True)\n\n# 訓練データの'brand_name'が'missing'に一致するレコード数を取得\ntrain_premissing = len(train.loc[train['brand_name'] == 'missing'])\n# テストデータの'brand_name'が'missing'に一致するレコード数を取得\ntest_premissing = len(test.loc[test['brand_name'] == 'missing'])\n\nprint('train_before:',train_premissing) # 書き換える前の'missing'の数\nprint('test_before:',test_premissing) # 書き換える前の'missing'の数","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def brandfinder(line):\n    \"\"\"\n    Parameters: line(str): ブランド名\n\n    ・ブランド名の'missing'を商品名に置き換える:\n         missing'の商品名の単語がブランドリストに存在する場合\n    ・ブランド名を商品名に置き換える:\n        商品名がブランドリストの名前と完全に一致する場合\n    ・ブランド名をそのままにする:\n        商品名がブランドリストの名前と一致しない\n        商品名が'missing'だが商品名の単語がブランドリストにない\n    \"\"\"\n    brand = line[0] # 第1要素はブランド名\n    name = line[1]  # 第2要素は商品名\n    namesplit = name.split(' ') # 商品名をスペースで切り分ける\n    \n    if brand == 'missing':  # ブランド名が'missing'と一致\n        for x in namesplit: # 商品名から切り分けた単語を取り出す\n            if x in all_brands:                \n                return name # 単語がブランドリストに一致したら商品名を返す\n    if name in all_brands:  # 商品名がブランドリストに存在すれば商品名を返す\n        return name\n    \n    return brand            # どれにも一致しなければブランド名を返す\n\n# ブランド名の付替えを実施\ntrain['brand_name'] = train[['brand_name','name']].apply(brandfinder, axis = 1)\ntest['brand_name'] = test[['brand_name','name']].apply(brandfinder, axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 書き換えられた'missing'の数を取得\ntrain_found = train_premissing-len(train.loc[train['brand_name'] == 'missing'])\ntest_found = test_premissing-len(test.loc[test['brand_name'] == 'missing'])\nprint('train_before 書き換える前のmissingの数:',train_premissing) # 書き換える前の'missing'の数\nprint('train_after 書き換えられたmissingの数:',train_found)      # 書き換えられた'missing'の数\nprint('test_before 書き換える前のmissingの数:',test_premissing)  # 書き換える前の'missing'の数\nprint('test_after 書き換えられたmissingの数:',test_found)       # 書き換えられた'missing'の数","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.nunique(axis=0))\nprint(\"-\"*20)\nprint(test.nunique(axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 名義変数\nnominal_list = ['shipping','subcat_0','subcat_1','subcat_2','brand_name']\n# 順序変数\nordinal_list = ['item_condition_id']\n# 数値変数\n# num_list = ['price']\n\nprint(f'nominal_list variables:  {nominal_list}')\nprint(f'ordinal_list variables:  {ordinal_list}')\n# print(f'num_list variables:  {num_list}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 名義変数の分布確認"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train\n\n# 50分類まで表示\nMAX_NUM = 50\n\ncolumns = len(nominal_list)/1+1\n\nfig = plt.figure(figsize=(40, 40))\nplt.subplots_adjust(hspace=0.6, wspace=0.4)\n\nfor i in range(len(nominal_list)):\n    \n    top_list = df[nominal_list[i]].value_counts().index[:MAX_NUM]\n    df_tmp = df.loc[df[nominal_list[i]].isin(top_list)]\n    \n    ax = fig.add_subplot(columns, 1, i+1)\n    sns.countplot(x=nominal_list[i], data=df_tmp, ax=ax)\n    plt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 順序変数の分布確認"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = len(ordinal_list)/2+1\n\nfig = plt.figure(figsize=(10, 5))\nplt.subplots_adjust(hspace=0.6, wspace=0.4)\n\nfor i in range(len(ordinal_list)):\n    ax = fig.add_subplot(columns, 1, i+1)\n    sns.countplot(x=ordinal_list[i], data=train, ax=ax)\n    plt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 数値変数の分布確認"},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns = len(num_list)/2+1\n\n# fig = plt.figure(figsize=(10, 5))\n# plt.subplots_adjust(hspace=0.6, wspace=0.4)\n\n# for i in range(len(num_list)):\n#     ax = fig.add_subplot(columns, 1, i+1)\n\n#     train[num_list[i]].hist(ax=ax)\n#     ax2 = train[num_list[i]].plot.kde(ax=ax, secondary_y=True,title=num_list[i])\n#     ax2.set_ylim(0)\n    \n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 名義変数とターゲットの関係を確認\n* 100ドル以下を対象、50分類まで表示"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 100ドル以下を対象とする\ndf = train[train['price']<100]\n\n# 50分類まで表示\nMAX_NUM = 50\n\ncolumns = len(nominal_list)/1+1\n\nfig = plt.figure(figsize=(40, 40))\nplt.subplots_adjust(hspace=0.6, wspace=0.4)\n\nfor i in range(len(nominal_list)):\n    ax = fig.add_subplot(columns, 1, i+1)\n\n    top_list = df[nominal_list[i]].value_counts().index[:MAX_NUM]\n    df_tmp = df.loc[df[nominal_list[i]].isin(top_list)]\n    \n    # 回帰の場合    \n    sns.boxplot(x=nominal_list[i], y=df_tmp.price, data=df_tmp, ax=ax)\n    plt.xticks(rotation=45)\n    # 分類の場合\n#     sns.barplot(x = nominal_list[i], y = df_tmp.price, data=df, ax=ax)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 順序変数とターゲットの関係を確認\n* 100ドル以下を対象"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 100ドル以下を対象とする\ndf = train[train['price']<100]\n\ncolumns = len(ordinal_list)/1+1\n\nfig = plt.figure(figsize=(10, 10))\nplt.subplots_adjust(hspace=0.6, wspace=0.4)\n\nfor i in range(len(ordinal_list)):\n\n    ax = fig.add_subplot(columns, 1, i+1)\n\n    # 回帰の場合    \n    sns.boxplot(x=ordinal_list[i], y=df.price, data=df, ax=ax)\n    plt.xticks(rotation=45)\n    # 分類の場合\n#     sns.barplot(x = ordinal_list[i], y = df.price, data=df, ax=ax)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_categorical(dataset):\n    dataset['subcat_0'] = dataset['subcat_0'].astype('category')\n    dataset['subcat_1'] = dataset['subcat_1'].astype('category')\n    dataset['subcat_2'] = dataset['subcat_2'].astype('category')  \n    dataset['brand_name'] = dataset['brand_name'].astype('category')\n    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')\n\nprint('Convert categorical')\nto_categorical(train)\nto_categorical(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 学習デートとテストデータを集約"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_train = train.shape[0]\nnum_test = test.shape[0]\nprint(num_train, num_test)\n\nfull_data = pd.concat([train, test], ignore_index=True)\n\ndel train\ndel test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# カテゴリ、ブランド、3カテゴリのテキストをラベルエンコードする\nfrom sklearn.preprocessing import LabelEncoder\n\n# LabelEncoderの生成\nle = LabelEncoder()\n\n# 'brand_name'のエンコード\nle.fit(full_data.brand_name)\nfull_data.brand_name = le.transform(full_data.brand_name)\n\n# 'subcat_0'のエンコード\nle.fit(full_data.subcat_0)\nfull_data.subcat_0 = le.transform(full_data.subcat_0)\n\n# 'subcat_1'のエンコード\nle.fit(full_data.subcat_1)\nfull_data.subcat_1 = le.transform(full_data.subcat_1)\n\n# 'subcat_2'のエンコード\nle.fit(full_data.subcat_2)\nfull_data.subcat_2 = le.transform(full_data.subcat_2)\n\nfull_data.head()\n\ndel le\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## item_descriptionを処理\n\n* WordCloudでitem_descriptionを図示\n* WordCloudは、文章中で出現頻度が高い単語を複数選び出し、その頻度に応じた大きさで図示する手法。"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nimport os\nwordcloud = WordCloud(width = 2400, height = 1200).generate(\" \".join(full_data.item_description.astype(str)))\nplt.figure(figsize = (13, 10))\nplt.imshow(wordcloud)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"「新品」、「送料無料」、「状態良好」、「未使用」、「ビクトリアシークレット」、「無煙」、「大サイズ」、「中サイズ」、 「小さいサイズ」、「良好な状態」は、いくつかの頻繁に現れるアイテム説明テキストです。"},{"metadata":{},"cell_type":"markdown","source":"## テキスト項目(item_description,name)について前処理を実施\n\n* テキスト前処理に適用する手順は次の通り。\n\n\n1. 句読点の削除\n1. 数字の削除\n1. ストップワードの削除(ストップワードとは、the, a, forなど)\n1. 小文字への変更"},{"metadata":{},"cell_type":"markdown","source":"1.句読点の削除関数"},{"metadata":{"trusted":true},"cell_type":"code","source":"from string import punctuation\n\n# 句読点を含む英数字以外のアスキー文字\npunctuation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a list of punctuation replacements\npunctuation_symbols = []\nfor symbol in punctuation:\n    punctuation_symbols.append((symbol, ''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\ndef remove_punctuation(sentence: str) -> str:\n    return sentence.translate(str.maketrans('', '', string.punctuation))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.数字の削除関数"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove Digits\ndef remove_digits(x):\n    x = ''.join([i for i in x if not i.isdigit()])\n    return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.ストップワードの削除関数"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove Stopwords\nfrom nltk.corpus import stopwords\n\nstop = stopwords.words('english')\n\ndef remove_stop_words(x):\n    x = ' '.join([i for i in x.lower().split(' ') if i not in stop])\n    return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4.小文字へ変換関数"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change to LowerCase Words\ndef to_lower(x):\n    return x.lower()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* item_description、nameにて上記のテキスト前処理を実施"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove Digits, Punctuation, Stopwords, Converting to Lower-case for full_data\nfull_data.item_description = full_data.item_description.astype(str)\nfull_data['item_description'] = full_data['item_description'].apply(remove_digits)\nfull_data['item_description'] = full_data['item_description'].apply(remove_punctuation)\nfull_data['item_description'] = full_data['item_description'].apply(remove_stop_words)\nfull_data['item_description'] = full_data['item_description'].apply(to_lower)\nfull_data['name'] = full_data['name'].apply(remove_digits)\nfull_data['name'] = full_data['name'].apply(remove_punctuation)\nfull_data['name'] = full_data['name'].apply(remove_stop_words)\nfull_data['name'] = full_data['name'].apply(to_lower)\nfull_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## TfidfVectorizerをitem_descriptionに適用\n* TfidfVectorizerとはCountVectorizerとは違い、単語の出現回数だけでなく単語のレア度も考慮する。\n* 例えば「です」「ます」といったどの文章にも存在する単語だったり、英語では「a」「the」のような冠詞は出現回数が大きく、CountVectorizerではこのような単語に大きく引きずられてしまう。\n* そうではなく単語の重要度に着目してベクトル化を行いたい場合に用いられる。\n* TF（単語の出現頻度）とIDF（単語のレア度）のこと\n* ngram_range = (1,3)は、3つの単語の組み合わせでカウントするということ\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_descp = TfidfVectorizer(\n    min_df=5, strip_accents='unicode', lowercase =True,\n    analyzer='word', token_pattern=r'\\w+', ngram_range=(1, 3), use_idf=True, \n    smooth_idf=True, sublinear_tf=True, stop_words='english')\n\nX_descp = tfidf_descp.fit_transform(full_data[\"item_description\"])\n\ntfidf_name = TfidfVectorizer(\n    min_df=5, strip_accents='unicode', lowercase =True,\n    analyzer='word', token_pattern=r'\\w+', ngram_range=(1, 3), use_idf=True, \n    smooth_idf=True, sublinear_tf=True, stop_words='english')\n\nX_name = tfidf_name.fit_transform(full_data[\"name\"])\n\nprint(pd.DataFrame(X_descp.toarray(), columns=tfidf_descp.get_feature_names()).head())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 説明欄について、idf値(レア度)を集計する\ndef compute_tfidf(description):\n    description = str(description)\n    description.translate(string.punctuation)\n\n    tfidf_sum=0\n    words_count=0\n    for w in description.lower().split():\n        words_count += 1\n        if w in tfidf_dict:\n            tfidf_sum += tfidf_dict[w]\n    \n    if words_count > 0:\n        return tfidf_sum/words_count\n    else:\n        return 0\n    \n    \ntfidf_dict = dict(zip(tfidf_descp.get_feature_names(), tfidf_descp.idf_))\nfull_data['tfidf_desp'] = full_data['item_description'].apply(compute_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nplt.scatter(full_data['price'], full_data['tfidf_desp'])\nplt.title('Train price X item_description TF-IDF', fontsize=15)\nplt.xlabel('Price', fontsize=15)\nplt.ylabel('TF-IDF', fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.legend(fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"この散布図を見ると、TF-IDFの高低は、「価格」とあまり影響がないといえる。。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# item_descriptionにて上位10位の変数を表示\nidf = dict(zip(tfidf_descp.get_feature_names(), tfidf_descp.idf_))\ndf_idf_descp = pd.DataFrame(columns=['idf']).from_dict(\n                    dict(idf), orient='index')\ndf_idf_descp.columns = ['idf']\ndisplay(df_idf_descp.sort_values(\"idf\").head(10).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nameにて上位10位の変数を表示\nidf = dict(zip(tfidf_descp.get_feature_names(), tfidf_name.idf_))\ndf_idf_name = pd.DataFrame(columns=['idf']).from_dict(\n                    dict(idf), orient='index')\ndf_idf_name.columns = ['idf']\ndisplay(df_idf_name.sort_values(\"idf\").head(10).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# item_descriptionとname変数をスタック\nX = scipy.sparse.hstack((X_name,\n                         X_descp)).tocsr()\nX_desc_name = pd.DataFrame(X.toarray())\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 元変数を削除\nfull_data.drop('name', axis=1, inplace=True)\nfull_data.drop('item_description', axis=1, inplace=True)\n\n#　元のデータフレームと結合\nfull_data = pd.concat([full_data, X_desc_name], axis=1,sort=False)\n\ndel X_desc_name\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# データを再度分割\nX_train = full_data[:num_train]\nX_test = full_data[num_train:]\n\n# priceを対数変換する\ny_train = np.log1p(X_train['price'])\n# priceを削除\nX_train.drop('price', axis=1, inplace=True)\n\ndel full_data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#訓練データとモデル評価用データに分けるライブラリ\nfrom sklearn.model_selection import train_test_split\n\n#フォールドアウト法により、学習データとテストデータに分割 \n(X_train, X_valid, y_train, y_valid) = train_test_split(X_train, y_train , test_size = 0.3 , random_state = 0)\n\nprint(\"X_train: \"+str(X_train.shape))\nprint(\"X_valid: \"+str(X_valid.shape))\nprint(\"y_train: \"+str(y_train.shape))\nprint(\"y_valid: \"+str(y_valid.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LightGBMライブラリ\nimport lightgbm as lgb\n#ハイパーパラメータチューニング自動化ライブラリ\nimport optuna\n\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Optunaで最適化されたパラメータ\nparams = {\"metric\": {'rmse'},\n          \"max_depth\" : 7,\n          \"subsumple\" : 0.0527053286950852,\n          \"subsample_freq\" : 0,\n          \"leaning_rate\" : 0.00012337315517641352,\n          \"feature_fraction\" : 0.27094712699951107,\n          \"lambda_l1\" : 0.4567708349707908,\n          \"lambda_l2\" :6.452511288039886e-07\n         }\n \n#LightGBMのモデル構築\ngbm = lgb.train(params,\n                lgb_train,\n                valid_sets=(lgb_train, lgb_eval),\n                num_boost_round=10000,\n                early_stopping_rounds=100,\n                verbose_eval=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#特徴量の重要度\nlgb.plot_importance(gbm, figsize=(12, 6), max_num_features=10)\nplt.show();\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}