{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.3","file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{},"cell_type":"markdown","source":"Relied heavily on all of the kernels below. Thank you all for sharing your work!\n\nCredits: \nhttps://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl  <br>\nhttps://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling  <Br>\nhttps://www.kaggle.com/rakeshbhat9/mercari-simple-data-exploration  <br>\nhttps://www.kaggle.com/maheshdadhich/i-will-sell-everything-for-free-0-55 <br> \nhttps://www.kaggle.com/lopuhin/eli5-for-mercari <br>\nhttps://www.kaggle.com/tunguz/more-effective-ridge-lgbm-script-lb-0-44341-2 <br>\nhttps://machinelearningmastery.com/prepare-text-data-deep-learning-keras/ "},{"metadata":{"_uuid":"6f32c006d0236da808159c2c662eab14047d4584","_cell_guid":"5839037b-7eb6-4ebc-9831-0def88d72056"},"execution_count":null,"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom scipy.sparse import csr_matrix, hstack\n\nimport time\nimport re\nimport math\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler,LabelBinarizer\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nimport xgboost as xgb\n\nseed = 90","outputs":[]},{"metadata":{"_uuid":"475c7ce2081132a6fd884665be2c9084f5f621fb","collapsed":true,"_cell_guid":"1b566e59-6062-40b4-938e-98d5e5e8969f"},"execution_count":null,"cell_type":"code","source":"Time_0 = time.time()\ntrain = pd.read_csv('../input/train.tsv',sep='\\t')\ntest = pd.read_csv('../input/test.tsv',sep='\\t')","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"#Get log price\ny_train = train['log_price'] = np.log((train['price'] + 1))","outputs":[]},{"metadata":{"_uuid":"b170004bcff1d02b65791ec3bc4ed103b665772c","_cell_guid":"1671206f-f122-47ed-aa6d-f1d5f1f6aa02"},"execution_count":null,"cell_type":"code","source":"#Data prep functions\ndef handle_missing(dataset):\n    dataset['category_name'].fillna(value=\"NA/NA/NA\", inplace=True)\n    dataset['brand_name'].fillna(value=\"missing\", inplace=True)\n    dataset['item_description'].fillna(value=\"missing\", inplace=True)\n    return (dataset)\n\ndef split_cat(dataset):\n    dataset['cat1'], dataset['cat2'], dataset['cat3'] =  zip(*dataset['category_name'].str.split(\"/\",2))\n    return dataset\n\ndef label_maker(dataset):\n    \n    lb = LabelBinarizer(sparse_output=True)\n    \n    cat1 = lb.fit_transform(dataset['cat1'])\n    cat2 = lb.fit_transform(dataset['cat2'])\n    cat3 = lb.fit_transform(dataset['cat3'])\n    brand_name = lb.fit_transform(dataset['brand_name'])\n    \n    del lb\n    \n    return cat1,cat2,cat3,brand_name\n\ndef get_dums(dataset):\n    X_dummies = csr_matrix(pd.get_dummies(dataset[['item_condition_id', 'shipping']],\n                                          sparse=True).values)\n    \n    return X_dummies\n\ndef text_processing(dataset):\n    MIN_DF_COUNT = 10\n    MAX_DF_COUNT = 10000\n    cv = CountVectorizer(min_df = MIN_DF_COUNT, max_df = MAX_DF_COUNT)\n    name = cv.fit_transform(dataset['name'])\n    \n    MIN_DF_TF = 10\n    MAX_DF_TF = 51000\n    MAX_FEATURES_TF = 51000\n    \n    tv = TfidfVectorizer(max_features=MAX_FEATURES_TF,\n                         min_df = MIN_DF_TF,\n                         max_df = MAX_DF_TF,\n                         ngram_range=(1, 3),\n                         stop_words='english')\n    description = tv.fit_transform(dataset['item_description'])\n    \n    del cv, tv\n    \n    return name, description\n\n","outputs":[]},{"metadata":{"_uuid":"058a2376502c1f3ca7ca3dcc155a95575c7b0714","_cell_guid":"3b5e958d-c6b9-4180-88b1-16c9094ed15c"},"execution_count":null,"cell_type":"code","source":"#Merge dataset\nnrow_train = train.shape[0]\nmerge: pd.DataFrame = pd.concat([train, test])\nsubmission: pd.DataFrame = test[['test_id']]\n    \ndel train\ndel test","outputs":[]},{"metadata":{"_uuid":"5829d27cf4bf37640ed5572e8f3f00387c9659e3","_cell_guid":"0be6367a-4131-41d8-a732-1161ea83c9ec"},"execution_count":null,"cell_type":"code","source":"#Preparing training data\n# Time ~ 9 mins\nstart_time = time.time()\n\nprint(\"Handle Missing...\")\nmerge = handle_missing(merge)\n\nprint(\"splitting cat...\")\nmerge = split_cat(merge)\n\nprint(\"making labels...\")\ncat1,cat2,cat3,brand_name = label_maker(merge)\n\nprint(\"getting dummies...\")\nX_dummies = get_dums(merge)\n\nprint(\"processing text...\")\nname,description = text_processing(merge)\n\nprint(\"stacking train...\")\nsparse_merge = hstack((cat1,cat3,cat3,brand_name,X_dummies,name,description)).tocsr()\n\nprint(\"TIME:\", time.time() - start_time)","outputs":[]},{"metadata":{"_uuid":"9a6fa92fdc03510efb0b41b1b4419cf2c9a5e035","collapsed":true,"_cell_guid":"1b24f7aa-4514-40c1-af48-9d92085433a2"},"execution_count":null,"cell_type":"code","source":"#Split data\nX_train = sparse_merge[:nrow_train]\nX_test = sparse_merge[nrow_train:]","outputs":[]},{"metadata":{"_uuid":"a0fa99633411503c71869302aaa4cc63c27d6a14","_cell_guid":"6053c3f1-05b2-4ef6-b3eb-beecdca16b7a"},"execution_count":null,"cell_type":"code","source":"#Model building functions\ndef model_testing(model,X_test, y_test):\n    y_pred = model.predict(X_test)\n    error = rmsle(y_test, y_pred)\n    print(error)\n    \n\ndef rmsle(y, y0):\n    assert len(y) == len(y0)\n    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))\n\n","outputs":[]},{"metadata":{"_uuid":"5a83f724cc238478aa971f8cfa311160a0e36aa7","_cell_guid":"e761c163-7525-4075-83b7-6918d032e77c"},"execution_count":null,"cell_type":"code","source":"#Initiating models\nridge_model_1 = Ridge(alpha=5.0, fit_intercept=True, normalize=False, copy_X=True, \n                    max_iter=None, tol=0.001, solver='auto', random_state=None)\nridge_model_2 = Ridge(alpha=5.0, fit_intercept=True, normalize=False, copy_X=True, \n                    max_iter=None, tol=0.001, solver='sag', random_state=None)\nridge_model_3 = Ridge(alpha=5.0, fit_intercept=True, normalize=False, copy_X=True, \n                    max_iter=None, tol=0.001, solver='lsqr', random_state=None)\ngbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 5, \n                                 learning_rate = 0.9,subsample=0.9)","outputs":[]},{"metadata":{"_uuid":"5ca0121e6481e4939500f3e83a5e051850284839","_cell_guid":"5153889f-2a94-4d5c-958f-ae8c993460b0"},"execution_count":null,"cell_type":"code","source":"#Model execution\n#Time ~ 6mins\nstart_time = time.time()\n\nprint(\"train test splitting...\")\nX_t, X_v, y_t, y_v = train_test_split(X_train, y_train,test_size = 0.20)\n\nprint(\"training model...\")\nprint(\"1\")\nridge_model_1.fit(X_train, y_train)\nmodel_testing(ridge_model_1, X_test = X_v, y_test = y_v)\n#Current best: .1233\n\nprint(\"training model...\")\nprint(\"2\")\n#ridge_model_2.fit(X_t, y_t)\n#model_testing(ridge_model_2, X_test = X_v, y_test = y_v)\n\nprint(\"training model...\")\nprint(\"3\")\n#ridge_model_3.fit(X_t, y_t)\n#model_testing(ridge_model_3, X_test = X_v, y_test = y_v)\n\nprint(\"TIME:\", time.time() - start_time)","outputs":[]},{"metadata":{"_uuid":"83c45021279e9af237ae998847d3a67718c12039","collapsed":true,"_cell_guid":"1832e70e-70c0-4f9f-9816-276054a38044"},"execution_count":null,"cell_type":"code","source":"#Submission functions\ndef create_submission(model,test = X_test, submission=submission,path=\"./predictions.csv\"):\n    predictions = model.predict(test)\n    predictions = pd.Series(np.exp(predictions) - 1)\n    \n    submission['price'] = predictions\n    \n    submission.to_csv(path, index=False)\n    \n    print(submission.describe())","outputs":[]},{"metadata":{"_uuid":"ef367b66276bd25059be3373a1c51768d1d7805b","_cell_guid":"1cc932cb-7aa5-492e-a3f0-6ebd81934137"},"execution_count":null,"cell_type":"code","source":"#Generating submission\n#Time ~ 15 secs\nstart_time = time.time()\n\ncreate_submission(ridge_model_1)\n\nprint(\"TIME:\", time.time() - start_time)\nprint(\"TOTAL TIME:\", time.time() - Time_0)\n#Total Time ~ ","outputs":[]},{"metadata":{"_uuid":"e23905dcd843a509ca1f8f78e40e96df74fa801b","collapsed":true,"_cell_guid":"ed460728-0461-46fa-95b2-1797dacd9252"},"execution_count":null,"cell_type":"code","source":"","outputs":[]}]}