{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom nltk.stem.porter import PorterStemmer\n\nimport re\n# Tutorial about Python regular expressions: https://pymotw.com/2/re/\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nimport pickle\nfrom collections import Counter\n\nfrom tqdm import tqdm\nimport os\n\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n# word cloud library\nfrom wordcloud import WordCloud\n\n# matplotlib\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/mercari-price-suggestion-challenge/train.tsv\", sep='\\t') \nprint(\"Shape of train_data\",train_data.shape)\n\ntest_data = pd.read_csv(\"/kaggle/input/mercari-price-suggestion-challenge/test_stg2.tsv\", sep='\\t') \ntrain_data.head(3)\n\ntrain_data.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"# price"},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(train_data['price']==0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### 874 items are free","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplot(1,2,1)\n(train_data['price']).hist(bins=50, figsize=(20,10), range=[0,250], edgecolor = 'white',grid=False)\nplt.xlabel('price')\nplt.ylabel('frequency')\n\nplt.subplot(1,2,2)\nnp.log(train_data['price']).hist(bins=50, figsize=(20,10), range=[0,7], edgecolor = 'white', grid=False)\nplt.xlabel('log of price')\nplt.ylabel('frequency')\n\nplt.plot();\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## thus ditribution of price is log-normal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shipping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['shipping'])\nplt.title('train shipping')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(test_data['shipping'])\nplt.title('test shipping')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### thus we can say train and test data for shipping has same distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price_ship0 = train_data[train_data['shipping']==1]['price'].values\nprice_ship1 = train_data[train_data['shipping']==0]['price'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8), edgecolor = 'black')\nplt.hist(price_ship0, bins = 50, range=[0,250], alpha = 1, color = 'green', label = 'ship = 0')\nplt.hist(price_ship1, bins = 50, range=[0,250],alpha = 0.7, color = 'blue', label = 'ship = 1')\nplt.plot();\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### generally the higher priced elements has shipping 1 i.e. paid by seller","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# item condition","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['item_condition_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(test_data['item_condition_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot('item_condition_id','price',train_data, ratio = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### thus as item condition id increases price generally decreases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# brand name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['brand_name'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(train_data['brand_name'].isnull())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.fillna('Nobrand',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,7))\nsns.barplot(list(train_data['brand_name'].value_counts()[:20].index),train_data['brand_name'].value_counts()[:20], )\nplt.xticks(rotation = 45)\nplt.title(\"Brands with their number of products\")\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"brand_mean_price={}\n\nfor brand in train_data['brand_name'].unique():\n    mean_price = train_data[train_data['brand_name'] == brand]['price'].mean()\n    brand_mean_price[brand] = mean_price"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"markdown","source":"top_15= sorted(brand_mean_price, key = brand_mean_price.get, reverse = True)[:15]"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"plt.figure(figsize = (15,7))\nsns.barplot(top_15, [brand_mean_price[x] for x in top_15])\nplt.xticks(rotation = 45)\nplt.plot();"},{"metadata":{"trusted":true},"cell_type":"code","source":"### these are costlier brands","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# category_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sep_in_cat(x):\n    try:\n        if(len(x.split('/'))<3):\n            return (x.split('/')[0],'','')\n        return x.split('/')\n    except:\n        return (\"No label\",\"No label\",\"No label\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['cat1'], train_data['cat2'], train_data['cat3'] = zip(*train_data['category_name'].apply(lambda x: sep_in_cat(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['cat1'], test_data['cat2'], test_data['cat3'] = zip(*test_data['category_name'].apply(lambda x: sep_in_cat(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,7))\nsns.barplot(list(train_data['cat1'].value_counts()[:20].index),train_data['cat1'].value_counts()[:20], )\nplt.xticks(rotation = 45)\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### approx 6k points have no value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['cat2'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,7))\nsns.barplot(list(train_data['cat2'].value_counts()[:20].index),train_data['cat2'].value_counts()[:20], )\nplt.xticks(rotation = 45)\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['cat3'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,7))\nsns.barplot(list(train_data['cat3'].value_counts()[:20].index),train_data['cat3'].value_counts()[:20], )\nplt.xticks(rotation = 45)\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef decontracted(phrase):\n    # specific\n    phrase = str(phrase)\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\n# tqdm is for printing the status bar\ndef clean_para(row):\n    preprocessed_item_description = []\n    sentance = row\n    sent = decontracted(sentance)\n    sent = sent.replace('\\\\r', ' ')\n    sent = sent.replace('\\\\\"', ' ')\n    sent = sent.replace('\\\\n', ' ')\n    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n    # https://gist.github.com/sebleier/554280\n    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n    preprocessed_item_description.append(sent.lower().strip())\n    return preprocessed_item_description[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['item_description'] = train_data['item_description'].apply(lambda x:clean_para(x))\ntest_data['item_description'] = test_data['item_description'].apply(lambda x:clean_para(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['name'] = train_data['name'].apply(lambda x:clean_para(x))\ntest_data['name'] = test_data['name'].apply(lambda x:clean_para(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_simple(i):\n    temp = \"\"\n    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n        temp +=j.strip()+\" \"#\" abc \".strip() will return \"abc\", remove the trailing spaces\n        temp = temp.replace('&','_')\n        temp = temp.replace('-','_')\n        temp = temp.replace('+','_')\n        \n    return temp.strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['cat1'] = train_data['cat1'].apply(lambda x:clean_simple(x))\ntrain_data['cat2'] = train_data['cat2'].apply(lambda x:clean_simple(x))\ntrain_data['cat3'] = train_data['cat3'].apply(lambda x:clean_simple(x))\n\ntest_data['cat1'] = test_data['cat1'].apply(lambda x:clean_simple(x))\ntest_data['cat2'] = test_data['cat2'].apply(lambda x:clean_simple(x))\ntest_data['cat3'] = test_data['cat3'].apply(lambda x:clean_simple(x))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['brand_name'] = train_data['brand_name'].apply(lambda x:clean_simple(str(x)))\ntest_data['brand_name'] = test_data['brand_name'].apply(lambda x:clean_simple(str(x)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(columns = ['category_name'], inplace = True)\ntest_data.drop(columns = ['category_name'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import h5py\n\n#train_data.to_hdf(\"train_data_preprocessed.h5\",key=\"train\")\n\n#test_data.to_hdf(\"test_data_preprocessed.h5\",key=\"test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train_data['price'].values\ntrain_data.drop(['price'], axis=1, inplace=True)      # drop project is approved columns  \n\nx=train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train,x_cv,y_train,y_cv= train_test_split(x,y,test_size=0.3,random_state=0)\n\nprint(\"Shape of train\",x_train.shape,y_train.shape)\nprint(\"Shape of cv\",x_cv.shape,y_cv.shape)\nprint(\"Shape of test\",test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## OHE of categorical data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OHE of subject category\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizercat1 = CountVectorizer(ngram_range = (1,2),)\nvectorizercat1.fit(x_train['cat1'].values) # fit has to happen only on train data\n\n\n# we use the fitted CountVectorizer to convert the text to vector\nx_train_bow_cat1 = vectorizercat1.transform(x_train['cat1'].values)\nx_cv_bow_cat_1 = vectorizercat1.transform(x_cv['cat1'].values)\nx_test_bow_cat_1 = vectorizercat1.transform(test_data['cat1'].values)\n\nprint(\"After vectorizations\")\nprint(x_train_bow_cat1.shape, y_train.shape)\nprint(x_cv_bow_cat_1.shape, y_cv.shape)\nprint(x_test_bow_cat_1.shape)\n\nprint(\"=\"*100)\n\n\nvectorizercat2 = CountVectorizer(ngram_range = (1,3),)\nvectorizercat2.fit(x_train['cat2'].values) # fit has to happen only on train data\n\n\n# we use the fitted CountVectorizer to convert the text to vector\nx_train_bow_cat2 = vectorizercat2.transform(x_train['cat2'].values)\nx_cv_bow_cat2 = vectorizercat2.transform(x_cv['cat2'].values)\nx_test_bow_cat2 = vectorizercat2.transform(test_data['cat2'].values)\n\nprint(\"After vectorizations\")\nprint(x_train_bow_cat2.shape, y_train.shape)\nprint(x_cv_bow_cat2.shape, y_cv.shape)\nprint(x_test_bow_cat2.shape)\n\nprint(\"=\"*100)\n\nvectorizercat3 = CountVectorizer(ngram_range = (1,4),)\nvectorizercat3.fit(x_train['cat3'].values) # fit has to happen only on train data\n# we use the fitted CountVectorizer to convert the text to vector\nx_train_bow_cat3 = vectorizercat3.transform(x_train['cat3'].values)\nx_cv_bow_cat3 = vectorizercat3.transform(x_cv['cat3'].values)\nx_test_bow_cat3 = vectorizercat3.transform(test_data['cat3'].values)\n\nprint(\"After vectorizations\")\nprint(x_train_bow_cat3.shape, y_train.shape)\nprint(x_cv_bow_cat3.shape, y_cv.shape)\nprint(x_test_bow_cat3.shape)\n\nprint(\"=\"*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#brand name\nvectorizercat1 = CountVectorizer(ngram_range = (1,2))\nvectorizercat1.fit(x_train['brand_name'].values) # fit has to happen only on train data\n\n\n# we use the fitted CountVectorizer to convert the text to vector\nx_train_bow_brand_name = vectorizercat1.transform(x_train['brand_name'].values)\nx_cv_bow_brand_name = vectorizercat1.transform(x_cv['brand_name'].values)\nx_test_bow_brand_name = vectorizercat1.transform(test_data['brand_name'].values)\n\nprint(\"After vectorizations\")\nprint(x_train_bow_brand_name.shape, y_train.shape)\nprint(x_cv_bow_brand_name.shape, y_cv.shape)\nprint(x_test_bow_brand_name.shape)\n\nprint(\"=\"*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## TFIDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# item description\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer8 = TfidfVectorizer(ngram_range = (1,3), max_features = 80000)\n\ncleaned_item_description_xtr_tfidf = vectorizer8.fit_transform(x_train['item_description'])\nprint(\"Shape of matrix after one hot encodig \",cleaned_item_description_xtr_tfidf.shape)\ncleaned_item_description_xcv_tfidf = vectorizer8.transform(x_cv['item_description'])\nprint(\"Shape of matrix after one hot encodig \",cleaned_item_description_xcv_tfidf.shape)\n\n\ncleaned_item_description_xtest_tfidf = vectorizer8.transform(test_data['item_description'])\nprint(\"Shape of matrix after one hot encodig \",cleaned_item_description_xtest_tfidf.shape)\n\nprint(\"After vectorizations\")\nprint(cleaned_item_description_xtr_tfidf.shape, y_train.shape)\nprint(cleaned_item_description_xcv_tfidf.shape, y_cv.shape)\nprint(cleaned_item_description_xtest_tfidf.shape)\n\nprint(\"=\"*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#name\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer9 = TfidfVectorizer(ngram_range = (1,2), max_features = 50000)\n\nclean_names_xtr_tfidf = vectorizer9.fit_transform(x_train['name'])\n\nclean_names_xcv_tfidf = vectorizer9.transform(x_cv['name'])\n\nclean_names_xtest_tfidf = vectorizer9.transform(test_data['name'])\n\nprint(\"After vectorizations\")\nprint(clean_names_xtr_tfidf.shape, y_train.shape)\nprint(clean_names_xcv_tfidf.shape, y_cv.shape)\nprint(clean_names_xtest_tfidf.shape)\n\nprint(\"=\"*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shipping and item_condition\nfrom sklearn.preprocessing import MinMaxScaler # NORMALIZE\n\nmnn=MinMaxScaler()\nX_train_std = mnn.fit_transform(x_train[[\"item_condition_id\",\"shipping\" ]])\nX_cv_std = mnn.fit_transform(x_cv[[ \"item_condition_id\",\"shipping\" ]])\nX_test_std = mnn.transform(test_data[[ \"item_condition_id\",\"shipping\" ]])\nprint(X_train_std.shape)\nprint(X_cv_std.shape)\nprint(X_test_std.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.sparse import hstack\nX_train = hstack((x_train_bow_cat1 ,x_train_bow_cat2 ,x_train_bow_cat3 ,x_train_bow_brand_name,cleaned_item_description_xtr_tfidf, clean_names_xtr_tfidf, X_train_std)).tocsr()\n\nX_cv =    hstack((x_cv_bow_cat_1 ,x_cv_bow_cat2 ,x_cv_bow_cat3 ,x_cv_bow_brand_name, cleaned_item_description_xcv_tfidf, clean_names_xcv_tfidf, X_cv_std)).tocsr()\n\nX_test = hstack((x_test_bow_cat_1,x_test_bow_cat2 ,x_test_bow_cat3 ,x_test_bow_brand_name, cleaned_item_description_xtest_tfidf,clean_names_xtest_tfidf, X_test_std)).tocsr()\n\nprint(\"Final Data matrix\")\nprint(X_train.shape, y_train.shape)\nprint(X_cv.shape, y_cv.shape)\nprint(X_test.shape)\nprint(\"=\"*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.to_hdf(\"train_data_preprocessed.h5\",key=\"train\")\ntest_data.to_hdf(\"test_data_preprocessed.h5\",key=\"test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def rmsle(real, predicted):\n    sum=0.0\n    for x in range(len(predicted)):\n        if predicted[x]<0 or real[x]<0: #check for negative values\n            continue\n        p = np.log(predicted[x]+1)\n        r = np.log(real[x]+1)\n        sum = sum + (p - r)**2\n    return (sum/len(predicted))**0.5"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"X_train.shape"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(192, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"model.fit(X_train, y_train, epochs=15, batch_size=10000)\n# evaluate the keras model\n_, accuracy = model.evaluate(X_train, y_train)\nprint('Accuracy: %.2f' % (accuracy*100))"},{"metadata":{"trusted":true},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from torchvision import models\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.nn as nn\n\nclass MLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden1 = nn.Linear(X_train.shape[0],192)\n        self.hidden2 = nn.Linear(192,64)\n        self.hidden3 = nn.Linear(64,64)\n        self.output = nn.Linear(64,1)\n        \n    def forward(self,x):\n        x = self.hidden1(x)\n        x = F.relu(x)\n        x = self.hidden2(x)\n        x = F.relu(x)\n        x = F.hidden3(x)\n        x = F.relu(x)\n        x = self.output(x)\n        return x\n    "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"MLP = MLP().cuda()\nloss_function = nn.CrossEntropyLoss()\noptimizer = optim.Adam(MLP.parameters(), lr=0.01)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Acoo = X_train.tocoo()\nApt = torch.sparse.LongTensor(torch.LongTensor([Acoo.row.tolist(), Acoo.col.tolist()]),\n                              torch.LongTensor(Acoo.data.astype(np.int32)))\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"for epoch in range(1,10):\n    train_loss, val_loss=[],[]\n    MLP.train()\n    optimizer.zero_grad()\n    data = X_train.to('cuda:0')\n    target = y_train.to('cuda:0')\n    output = MLP(data)\n    "},{"metadata":{"trusted":true},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from sklearn.linear_model import SGDRegressor\n\nmodel = SGDRegressor()\nmodel.fit(X_train, y_train)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"train_preds = model.predict(X_train)\ncv_preds = model.predict(X_cv)\ntest_preds = model.predict(X_test)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"print(rmsle(y_train,train_preds),\"    \",rmsle(y_cv,cv_preds))"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"result = pd.DataFrame({'test_id' : range(0,len(test_preds)),\n                       'price' : test_preds})"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"result.shape"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\n\nresult.to_csv(\"submission.csv\", index = False)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}