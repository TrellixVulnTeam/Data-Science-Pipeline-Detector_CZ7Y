{"nbformat_minor":1,"nbformat":4,"cells":[{"outputs":[],"execution_count":null,"cell_type":"code","source":"","metadata":{"_cell_guid":"67f6af03-148c-4e8b-9e9a-bc495e5dfcb5","_uuid":"d554a198f034b2032f3ff4f819e20d1603206ba9","collapsed":true}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom wordcloud import WordCloud\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom matplotlib import pyplot as plt\nfrom subprocess import check_output\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom collections import Counter\nfrom tqdm import tqdm\nimport nltk\nfrom string import printable,punctuation\nfrom sklearn.feature_selection import SelectKBest,f_regression\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"4fd2558b-c9af-45fa-a98f-e8b3b761a420","_uuid":"e44817bb61c0153449954c0487c8c6d83e9d2440","_kg_hide-input":true}},{"cell_type":"markdown","source":"## Reading all the files below and cleaning the data with the following steps:\n*  Replace all NaNs with Missing.\n* Removing stopwords and punctuations and non printable words","metadata":{"_cell_guid":"a0fbc546-895d-47f5-be81-43ad3789b564","_uuid":"e97e1de8b46fca18ef86aef12eb82a9ad35de515"}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"train=pd.read_csv('../input/train.tsv',sep='\\t')\ndef useable_words(x):\n    temp=[]\n    for i in nltk.word_tokenize(str(x)):\n        if i not in nltk.corpus.stopwords.words('english'):\n            clean_word=\"\".join([j for j in i if j in printable and j not in punctuation])\n            temp.append(clean_word)\n    return \" \".join(temp)\n#lem=nltk.stem.wordnet.WordNetLemmatizer()\nfor col in tqdm(['brand_name','item_description','name','category_name']):\n    train.loc[pd.isnull(train[col]),col]='Missing'\n    #if col=='item_description':\n    #    train[col].apply(useable_words)","metadata":{"_cell_guid":"16b3aed9-77e3-481e-a0f1-b7bef24f0172","_uuid":"4dfc05a464c6535607df8a518ccf01ec877f61c0","_kg_hide-input":true}},{"cell_type":"markdown","source":"## Breaking down the category_name columns into different levels such as FirstLevel cat, Second Level and so on","metadata":{"_cell_guid":"93bbf913-ef97-4df1-a9b1-226a7d0ecd6a","_uuid":"04181b79ea4b18ca98d1b0b914066a2dfe469bd4"}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"# x=train.item_description\n# for word in tqdm(nltk.corpus.stopwords.words('english')):\n#     x=x.str.replace(pat=word,repl='')\ntrain.head()","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"catlevels=train.category_name.astype('str').str.split('/',expand=True)\ncatlevels.rename(columns={0:'FirstLevelCat',1:'SecondLevelCat',2:'ThirdLevelCat',3:'FourthLevelCat',4:'FifthLevelCat'},inplace=True)\ncatlevels.fillna('Missing',inplace=True)\nfor col in tqdm(['FirstLevelCat','SecondLevelCat','ThirdLevelCat','FourthLevelCat','FifthLevelCat']):\n    train[col]=catlevels[col]\nprint('Generated the following columns:',catlevels.columns)\ndel catlevels","metadata":{"_cell_guid":"7359914a-8f0a-47fa-99d6-eff18a18632c","_uuid":"290c520623206dd5d8d04892176f8b72fa738530","_kg_hide-input":true,"collapsed":true}},{"cell_type":"markdown","source":"## Using CountVectorizer generating counts for each ngrams (upto 3) for the item description column and storing it in sparse format.","metadata":{"_cell_guid":"f603abe9-ab1c-4cb2-aff6-53872a3198fd","_uuid":"3d503a93792657dbcf3d6c36bd0aa27d40d550e9"}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"def tokenize(x):\n    return x.split('/')\nfor col in tqdm(['item_description']):\n    CV=CountVectorizer(ngram_range=(1,1),min_df=10,binary=True)\n    data_sparse=CV.fit_transform(train[col])\nprint('Generated the following sparse data based on ngrams:',data_sparse.shape)","metadata":{"_cell_guid":"cf1d44cf-39e5-441b-8662-6e03d02f0408","_uuid":"5ba9297df8593bccbef63d6ab772afe087419af3","_kg_hide-input":true,"collapsed":true,"_kg_hide-output":false}},{"cell_type":"markdown","source":"# Calculating feature importance based on F-Scores for the features in sparse data and features generated based on category_name,brand_name etc.","metadata":{"_cell_guid":"2661f3f8-16b4-4e36-8a85-bbeed5d7b269","_uuid":"16b80fd2c70d73157d0b8b1fe7d65fe2e07eb546"}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"print('Started working on the sparse data')\nskbest=SelectKBest(score_func=f_regression,k=data_sparse.shape[1])\nskbest.fit_transform(data_sparse,train['price'])\nfeat_imp=pd.Series(skbest.scores_,index=CV.get_feature_names())\npvalues=pd.Series(skbest.pvalues_,index=CV.get_feature_names())\nprint('Sparse data feature selection completed. Starting on other features')\nfor col in tqdm(['FirstLevelCat','SecondLevelCat','ThirdLevelCat','FourthLevelCat','FifthLevelCat']):\n    dummy_sparse=pd.get_dummies(train[col],prefix=col,prefix_sep='_',sparse=True)\n    skbest=SelectKBest(score_func=f_regression,k=dummy_sparse.shape[1])\n    skbest.fit_transform(dummy_sparse,train['price'])\n    feat_imp=feat_imp.append(pd.Series(skbest.scores_,index=dummy_sparse.columns))\n    pvalues=pvalues.append(pd.Series(skbest.pvalues_,index=dummy_sparse.columns))\n    del dummy_sparse\nskbest=SelectKBest(score_func=f_regression,k=2)\nskbest.fit_transform(train[['shipping','item_condition_id']],train['price'])\nfeat_imp=feat_imp.append(pd.Series(skbest.scores_,index=['shipping','item_condition_id']))\npvalues=pvalues.append(pd.Series(skbest.pvalues_,index=['shipping','item_condition_id']))\n    \n# skbest=SelectKBest(score_func=f_regression,k=dummy_sparse.shape[1])\n# skbest.fit_transform(dummy_sparse,train['price'])\n# feat_imp=feat_imp.append(pd.Series(skbest.scores_,index=dummy_sparse.columns))\nfeat_imp.sort_values(ascending=False,inplace=True)\npvalues.sort_values(ascending=True,inplace=True)","metadata":{"_cell_guid":"ae9494cd-9454-4d5a-a6c0-f3c4da5ced9c","_uuid":"f8d12f7fdc9ebc61c83cd0c35b3128ae5b758724","_kg_hide-input":true,"collapsed":true}},{"cell_type":"markdown","source":"# Trying to visualize the top 200 features with high scores.\n","metadata":{"_cell_guid":"64f6aca6-1399-4166-98d7-a46e9f1f728d","_uuid":"362fae070a76e1c7040f7d897ab5e676d895e529"}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"fig,ax=plt.subplots(1,1,figsize=(10,100))\nsns.barplot(y=list(feat_imp[:200].index),x=feat_imp[:200],orient='h')","metadata":{"_cell_guid":"a7b4b882-63a8-4742-8675-66ed65f3f3dc","_uuid":"edcb1418e41d95dd2a6699d0aa87aa0735b56435","_kg_hide-input":true,"collapsed":true,"scrolled":false}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"","metadata":{"_cell_guid":"1303921e-e2c3-4a69-a34b-7cdc98e9c9ad","_uuid":"bee0d1ceebb48ac8827ed7a47a2151b9cd83c312","collapsed":true}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"","metadata":{"_cell_guid":"6f2e311a-6aa6-4cec-8ddc-0b328576b269","_uuid":"95e80ffa2a142d9fbb83373981433be3b45ed8c9","collapsed":true}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"name":"python","pygments_lexer":"ipython3","version":"3.6.3","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}}}}