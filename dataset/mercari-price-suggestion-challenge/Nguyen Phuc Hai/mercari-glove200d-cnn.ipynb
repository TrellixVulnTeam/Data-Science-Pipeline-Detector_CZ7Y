{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **DATA INITIZLIZATION**","metadata":{"id":"y-oIFq9H4F07"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport gc\n\nimport pandas as pd\nimport numpy as np\nimport string\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport seaborn as sns\nimport math\nimport lightgbm as lgb\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\n#!pip install Wordbatch\n#from wordbatch.models import FTRL, FM_FTRL  # https://github.com/anttttti/Wordbatch\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import word_tokenize\nfrom nltk.corpus import wordnet\nfrom nltk.stem import PorterStemmer \nfrom nltk.tokenize import word_tokenize\nnltk.download('wordnet')\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nfrom sklearn.model_selection import train_test_split\nimport scipy\nfrom scipy.sparse import hstack\n\nfrom sklearn.metrics import mean_squared_log_error\nimport pickle\nimport regex as re\nimport os\nos.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/My Drive/Colab Notebooks/'","metadata":{"id":"xc5Uaunz4F1E","executionInfo":{"status":"ok","timestamp":1607445228558,"user_tz":-330,"elapsed":7395,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"outputId":"df5c40d5-fa61-4310-ab4d-188932131564","execution":{"iopub.status.busy":"2021-05-23T09:58:27.450638Z","iopub.execute_input":"2021-05-23T09:58:27.451014Z","iopub.status.idle":"2021-05-23T09:58:31.459281Z","shell.execute_reply.started":"2021-05-23T09:58:27.450933Z","shell.execute_reply":"2021-05-23T09:58:31.458422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if 'train.tsv' not in os.listdir(): \n#     !kaggle competitions download -c mercari-price-suggestion-challenge\n#     get_ipython().system_raw(\"7z x \\*.7z && rm *.7z\")\n#     get_ipython().system_raw(\"7z x \\*.zip && rm *.zip\")","metadata":{"id":"b3qFUON04F1K","executionInfo":{"status":"ok","timestamp":1607445282195,"user_tz":-330,"elapsed":61018,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"outputId":"bfed5c50-ff4b-478a-b31f-63b9d18fb94d","execution":{"iopub.status.busy":"2021-05-23T09:58:31.460945Z","iopub.execute_input":"2021-05-23T09:58:31.461306Z","iopub.status.idle":"2021-05-23T09:58:31.466809Z","shell.execute_reply.started":"2021-05-23T09:58:31.46127Z","shell.execute_reply":"2021-05-23T09:58:31.466047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_pickle('../input/mercari-ml-data-processed/improved_train.pkl')\ntest_df = pd.read_pickle('../input/mercari-ml-data-processed/improved_test.pkl')\n\n# train_df.head(5)","metadata":{"id":"FzkKGiU64F1N","executionInfo":{"status":"ok","timestamp":1607445286602,"user_tz":-330,"elapsed":65413,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"outputId":"559a18ad-f9f6-47b5-851b-670b559f0ef1","execution":{"iopub.status.busy":"2021-05-23T09:58:31.468747Z","iopub.execute_input":"2021-05-23T09:58:31.469278Z","iopub.status.idle":"2021-05-23T09:58:37.305514Z","shell.execute_reply.started":"2021-05-23T09:58:31.469182Z","shell.execute_reply":"2021-05-23T09:58:37.304595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = train_df.head(50)\n# test_df = test_df.head(50)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T09:58:37.307243Z","iopub.execute_input":"2021-05-23T09:58:37.307649Z","iopub.status.idle":"2021-05-23T09:58:37.312151Z","shell.execute_reply.started":"2021-05-23T09:58:37.307615Z","shell.execute_reply":"2021-05-23T09:58:37.310923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train Test Split**","metadata":{"id":"sTYomfJM4F1X"}},{"cell_type":"code","source":"X = train_df.drop(['train_id','log_prices','price'], axis=1)\ny = train_df['log_prices']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\ndel X, y, train_df","metadata":{"id":"l2tkr5Oz4F1Y","executionInfo":{"status":"ok","timestamp":1607445295652,"user_tz":-330,"elapsed":74440,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"execution":{"iopub.status.busy":"2021-05-23T09:58:37.313556Z","iopub.execute_input":"2021-05-23T09:58:37.313896Z","iopub.status.idle":"2021-05-23T09:58:39.159597Z","shell.execute_reply.started":"2021-05-23T09:58:37.313863Z","shell.execute_reply":"2021-05-23T09:58:39.158654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"id":"mMJLnhGP4F1a","executionInfo":{"status":"ok","timestamp":1607445295653,"user_tz":-330,"elapsed":74428,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"outputId":"3395743c-0dc3-41bd-d04c-b59cf0004ecd","execution":{"iopub.status.busy":"2021-05-23T09:58:39.161562Z","iopub.execute_input":"2021-05-23T09:58:39.162121Z","iopub.status.idle":"2021-05-23T09:58:39.168787Z","shell.execute_reply.started":"2021-05-23T09:58:39.162076Z","shell.execute_reply":"2021-05-23T09:58:39.167912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Feature Engineering pipeline**","metadata":{"id":"a_TjH19SddlN"}},{"cell_type":"markdown","source":"# **CNN MODEL**","metadata":{"id":"G9mZONrq4N7m"}},{"cell_type":"code","source":"from sklearn.preprocessing import Normalizer\nimport tensorflow as tf\nfrom numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Input, Embedding, Conv1D, Conv2D, MaxPool1D, MaxPool2D, AveragePooling1D, GlobalAveragePooling1D, \\\n                                    Flatten, Dropout, Dense, BatchNormalization, LayerNormalization, Concatenate\nfrom tensorflow.keras.layers import ReLU\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import initializers, regularizers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import LSTM","metadata":{"id":"LKPxH2em7Gzg","executionInfo":{"status":"ok","timestamp":1607445310221,"user_tz":-330,"elapsed":14536,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"execution":{"iopub.status.busy":"2021-05-23T09:58:39.170251Z","iopub.execute_input":"2021-05-23T09:58:39.170869Z","iopub.status.idle":"2021-05-23T09:58:43.707012Z","shell.execute_reply.started":"2021-05-23T09:58:39.170821Z","shell.execute_reply":"2021-05-23T09:58:43.70619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# THIS CODE IS USED TO OVERCOME THE UNKNOWN CATEGORICAL VALUES ENCOUNTERED IN THE TEST DATA, WHEN USING Sklearn's LabelEncoder\n# We basically add a 'Unknown' category when fitting, to accomodate all the unseen/unknown values in test data\n# https://stackoverflow.com/a/56876351/7697658\n\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\nclass LabelEncoderExt(object):\n    def __init__(self):\n        \"\"\"\n        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n        \"\"\"\n        self.label_encoder = LabelEncoder()\n        # self.classes_ = self.label_encoder.classes_\n\n    def fit(self, data_list):\n        \"\"\"\n        This will fit the encoder for all the unique values and introduce unknown value\n        :param data_list: A list of string\n        :return: self\n        \"\"\"\n        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n        self.classes_ = self.label_encoder.classes_\n\n        return self\n\n    def transform(self, data_list):\n        \"\"\"\n        This will transform the data_list to id list where the new values get assigned to Unknown class\n        :param data_list:\n        :return:\n        \"\"\"\n        new_data_list = list(data_list)\n        for unique_item in np.unique(data_list):\n            if unique_item not in self.label_encoder.classes_:\n                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n\n        return self.label_encoder.transform(new_data_list)","metadata":{"id":"_lmOHS61PXNg","executionInfo":{"status":"ok","timestamp":1607445310223,"user_tz":-330,"elapsed":14532,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"execution":{"iopub.status.busy":"2021-05-23T09:58:43.709711Z","iopub.execute_input":"2021-05-23T09:58:43.710058Z","iopub.status.idle":"2021-05-23T09:58:43.721224Z","shell.execute_reply.started":"2021-05-23T09:58:43.710021Z","shell.execute_reply":"2021-05-23T09:58:43.720376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Why you should not use One Hot Encoding for this,\n# https://stackoverflow.com/a/51184399/7697658\n\n# Embedding categorical data,\n# https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/\ndef categorical_embeddings(cat_train, cat_test):\n    \"\"\"\n    This function will do Label encoding of the categorical feature.\n    \"\"\"\n    vocab_size = len(cat_train.unique())+1\n    le = LabelEncoderExt()\n    le.fit(cat_train.values)\n    encoded_train = le.transform(cat_train.values)\n    encoded_test = le.transform(cat_test.values)\n\n    return vocab_size, encoded_train, encoded_test\n\n#vocab_size, encoded_train, encoded_test = categorical_embeddings(X_train['project_subject_subcategories'], X_test['project_subject_subcategories'])","metadata":{"id":"8E9fDV1AOt1p","executionInfo":{"status":"ok","timestamp":1607445310224,"user_tz":-330,"elapsed":14530,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"execution":{"iopub.status.busy":"2021-05-23T09:58:43.725326Z","iopub.execute_input":"2021-05-23T09:58:43.725634Z","iopub.status.idle":"2021-05-23T09:58:43.732832Z","shell.execute_reply.started":"2021-05-23T09:58:43.725599Z","shell.execute_reply":"2021-05-23T09:58:43.732038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How does embedding layer work,\n# https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work\n\ndef text_embeddings(text_train, text_test):\n    \"\"\"\n    This function does the tokenizing, padding, creating vocab and creating the embedding matrix for text data\n    \"\"\"\n    # Word Tokenizer\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(text_train)\n    encoded_docs_train = tokenizer.texts_to_sequences(text_train)\n\n    encoded_docs_test = tokenizer.texts_to_sequences(text_test)\n\n    # Getting the 'max len' of doc among the text_train\n    len_docs = []\n    for doc in text_train:\n        splitted_doc = doc.split()\n        len_docs.append(len(splitted_doc))\n    max_len_doc = max(len_docs)\n    #print('max doc len=',max_len_doc) # in terms of words\n\n    text_train_padded = pad_sequences(encoded_docs_train, maxlen=max_len_doc, padding='post')\n    text_test_padded = pad_sequences(encoded_docs_test, maxlen=max_len_doc, padding='post')\n\n    vocab_size = len(tokenizer.word_index) + 1\n    #print(vocab_size)\n\n    embeddings_index = dict()\n    with open('../input/glove6b/glove.6B.200d.txt') as f:\n        for line in f:\n            w_coef = line.rstrip().rsplit(' ')\n            word = w_coef[0]\n            coefs = asarray(w_coef[1:], dtype='float32')\n            embeddings_index[word]=coefs\n\n    embedding_matrix = zeros((vocab_size, 200))\n    for word, i in tokenizer.word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n    \n    return embedding_matrix, vocab_size, max_len_doc, text_train_padded, text_test_padded","metadata":{"id":"sDMIBfadrwp8","executionInfo":{"status":"ok","timestamp":1607445310224,"user_tz":-330,"elapsed":14524,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"execution":{"iopub.status.busy":"2021-05-23T09:58:43.734154Z","iopub.execute_input":"2021-05-23T09:58:43.734551Z","iopub.status.idle":"2021-05-23T09:58:43.746199Z","shell.execute_reply.started":"2021-05-23T09:58:43.734515Z","shell.execute_reply":"2021-05-23T09:58:43.745455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_model_pipeline(input_len, vocab_size, embedding_matrix, layer_name):\n    \"\"\"\n    This function will create a sub-model of the text data using embedding layer, 1D CNN, Maxpooling.\n    \"\"\"\n    input_layer = Input(shape=input_len, name=layer_name+'_input')\n    e_layer = Embedding(input_dim=vocab_size, output_dim=200, weights=[embedding_matrix], input_length=input_len, trainable=False, name=layer_name+'_embedding')(input_layer)\n    conv_1 = Conv1D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer=initializers.glorot_normal(seed=0), \n                activation='relu', kernel_regularizer=regularizers.l2(),name=layer_name+'Conv_1')(e_layer)\n    conv_1 = MaxPool1D(pool_size=20, strides=1, padding='same', name=layer_name+'Maxpool_1')(conv_1)\n    conv_1 = Flatten()(conv_1)\n\n    out = conv_1\n    model = Model(inputs=input_layer ,outputs=out)\n    return model\n\ndef categorical_model_pipeline(input_len, vocab_size, layer_name):   # Here vocab_size will be the number of unique values in the column\n    \"\"\"\n    This function will create a sub-model of the categorical data. It will use embedding layer to embedd the categories.\n    \"\"\"\n    input_layer = Input(shape=input_len, name=layer_name+'_input')\n    e_layer  = Embedding(input_dim=vocab_size, output_dim=32, input_length=input_len, trainable=True, name=layer_name+'_embedding')(input_layer)\n    flat = Flatten()(e_layer)\n    out = flat\n    model = Model(inputs=input_layer ,outputs=out)\n    return model\n\ndef numeric_model_pipeline(input_len, layer_name):\n    \"\"\"\n    This function will create a sub-model of the numeric data using a single dense layer.\n    \"\"\"\n    input_layer = Input(shape=input_len, name=layer_name+'_input')\n    dense = Dense(units=32,activation='relu', name=layer_name+'_dense')(input_layer)\n    out = dense\n    model = Model(inputs=input_layer ,outputs=out)\n    return model\n\ndef low_cardinal_categories(input_len, layer_name):\n    \"\"\"\n    This function will create a sub-model of the low cardinal features. This just flattens the input and nothing else.\n    \"\"\"\n    input_layer = Input(shape=input_len, name=layer_name+'_input')\n    flat = Flatten()(input_layer)\n    out = flat\n    model = Model(inputs=input_layer ,outputs=out)\n    return model","metadata":{"id":"5-hbvp9Ft452","execution":{"iopub.status.busy":"2021-05-23T09:58:43.747527Z","iopub.execute_input":"2021-05-23T09:58:43.747885Z","iopub.status.idle":"2021-05-23T09:58:43.762739Z","shell.execute_reply.started":"2021-05-23T09:58:43.747849Z","shell.execute_reply":"2021-05-23T09:58:43.76179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def numeric_standardizing(X_train_numeric, X_test_numeric):\n    \"\"\"\n    This function will normalize the numeric feature.\n    \"\"\"\n    scaler = Normalizer()\n    scaler.fit(X_train_numeric.values.reshape(1,-1))\n\n    X_train_price_scaled = scaler.transform(X_train_numeric.values.reshape(1,-1))\n    X_test_price_scaled = scaler.transform(X_test_numeric.values.reshape(1,-1))\n    return X_train_price_scaled.flatten(), X_test_price_scaled.flatten()","metadata":{"id":"3Kzt4oQy0Ov8","execution":{"iopub.status.busy":"2021-05-23T09:58:43.764011Z","iopub.execute_input":"2021-05-23T09:58:43.7644Z","iopub.status.idle":"2021-05-23T09:58:43.774624Z","shell.execute_reply.started":"2021-05-23T09:58:43.764364Z","shell.execute_reply":"2021-05-23T09:58:43.773811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\ndef create_cnn_model(X_train, X_test):\n    \"\"\"\n    This function creates the model structure.\n    \"\"\"\n    ####################### Text data ######################\n    desc_embedding_matrix, desc_vocab_size, desc_max_len_doc, desc_text_train_padded, desc_text_test_padded = text_embeddings(X_train['item_description'].apply(str), X_test['item_description'].apply(str))\n    name_embedding_matrix, name_vocab_size, name_max_len_doc, name_text_train_padded, name_text_test_padded = text_embeddings(X_train['name'].apply(str), X_test['name'].apply(str))\n\n    desc_flat_model = text_model_pipeline(desc_max_len_doc, desc_vocab_size, desc_embedding_matrix, 'description')\n    name_flat_model = text_model_pipeline(name_max_len_doc, name_vocab_size, name_embedding_matrix, 'name')\n    ########################################################\n\n\n    ################### Categorical data ###################\n    bn_vocab_size, bn_encoded_train, bn_encoded_test = categorical_embeddings(X_train['brand_name'], X_test['brand_name'])\n    gc_vocab_size, gc_encoded_train, gc_encoded_test = categorical_embeddings(X_train['general_cat'], X_test['general_cat'])\n    sc1_vocab_size, sc1_encoded_train, sc1_encoded_test = categorical_embeddings(X_train['subcat_1'], X_test['subcat_1'])\n    sc2_vocab_size, sc2_encoded_train, sc2_encoded_test = categorical_embeddings(X_train['subcat_2'], X_test['subcat_2'])\n\n    bn_flat_model = categorical_model_pipeline(1, bn_vocab_size, 'bn')\n    gc_flat_model = categorical_model_pipeline(1, gc_vocab_size, 'gc')\n    sc1_flat_model = categorical_model_pipeline(1, sc1_vocab_size, 'sc1')\n    sc2_flat_model = categorical_model_pipeline(1, sc2_vocab_size, 'sc2')\n    ic_flat_model = low_cardinal_categories(5, 'item_condition')\n    sh_flat_model = low_cardinal_categories(2, 'shipping')\n    is_ex_flat_model = low_cardinal_categories(2, 'isExpensive')\n    #########################################################\n\n\n    ################### Numeric data ###################\n    numeric_train_input = pd.concat((X_train['scaler_desc_len'], X_train['scaler_name_len']), axis=1).to_numpy()\n    numeric_test_input = pd.concat((X_test['scaler_desc_len'], X_test['scaler_name_len']), axis=1).to_numpy()\n\n    numeric_model = numeric_model_pipeline(numeric_train_input.shape[1], 'numeric')\n    ####################################################\n\n\n    ############### Concatenating layers ###############\n    combined_layers = [desc_flat_model.output, name_flat_model.output, \n                       bn_flat_model.output, gc_flat_model.output, sc1_flat_model.output, sc2_flat_model.output, ic_flat_model.output, \\\n                       sh_flat_model.output, is_ex_flat_model.output, numeric_model.output]\n    concatenate_layer = Concatenate()(combined_layers)\n    ####################################################\n\n    dense = BatchNormalization()(concatenate_layer)\n    dense = Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(dense)\n    dense = Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(dense)\n    concatenate_layer = Concatenate()([dense, ic_flat_model.output, sh_flat_model.output, is_ex_flat_model.output, numeric_model.output])\n    dense = LayerNormalization(axis=1)(concatenate_layer)\n    #dense = Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(concatenate_layer)\n\n    out = Dense(units=1, activation='linear', name='Output')(dense)\n\n    model = Model(inputs=[desc_flat_model.input, name_flat_model.input, \n                       bn_flat_model.input, gc_flat_model.input, sc1_flat_model.input, sc2_flat_model.input, ic_flat_model.input, \\\n                       sh_flat_model.input, is_ex_flat_model.input, numeric_model.input], \\\n                  outputs=out)\n\n\n    X_train_inputs = [desc_text_train_padded, name_text_train_padded, bn_encoded_train, gc_encoded_train, sc1_encoded_train, sc2_encoded_train, tf.one_hot(X_train['item_condition_id'], 5),\\\n                      tf.one_hot(X_train['shipping'], 2), tf.one_hot(X_train['is_expensive'], 2), numeric_train_input]\n    X_test_inputs = [desc_text_test_padded, name_text_test_padded, bn_encoded_test, gc_encoded_test, sc1_encoded_test, sc2_encoded_test, tf.one_hot(X_test['item_condition_id'], 5),\\\n                     tf.one_hot(X_test['shipping'], 2), tf.one_hot(X_test['is_expensive'], 2), numeric_test_input]\n    return model, X_train_inputs, X_test_inputs","metadata":{"id":"wwyZlBCqA3cU","execution":{"iopub.status.busy":"2021-05-23T09:58:43.777594Z","iopub.execute_input":"2021-05-23T09:58:43.777914Z","iopub.status.idle":"2021-05-23T09:58:43.807938Z","shell.execute_reply.started":"2021-05-23T09:58:43.777889Z","shell.execute_reply":"2021-05-23T09:58:43.807214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train, scaler_name_len, scaler_desc_len = feature_pipeline(X_train, scaler_name_len=None, scaler_desc_len=None)\n# X_test, _, _ = feature_pipeline(X_test, scaler_name_len, scaler_desc_len)\nscaler_name_len = X_train['scaler_name_len']\nscaler_desc_len = X_train['scaler_desc_len']\n\nprint(scaler_name_len.shape, scaler_desc_len.shape)","metadata":{"id":"6lPH-zqNI7k5","executionInfo":{"status":"ok","timestamp":1606536336377,"user_tz":-330,"elapsed":463185,"user":{"displayName":"Chintan Dave (TCS)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpsGfvt4rX9_OeSYS8SmCfsdq-bIb9HZDuLdqU=s64","userId":"08183815725666051005"}},"outputId":"0004f77e-09e4-4e99-da53-ac07696cd9ff","execution":{"iopub.status.busy":"2021-05-23T09:58:43.808994Z","iopub.execute_input":"2021-05-23T09:58:43.809328Z","iopub.status.idle":"2021-05-23T09:58:43.814252Z","shell.execute_reply.started":"2021-05-23T09:58:43.809296Z","shell.execute_reply":"2021-05-23T09:58:43.813059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model, X_train_inputs, X_test_inputs = create_cnn_model(X_train, X_test)\ncnn_model.summary()","metadata":{"id":"ACR8rDsDIVxl","executionInfo":{"status":"ok","timestamp":1606796665726,"user_tz":-330,"elapsed":234579,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"outputId":"7993e4dc-9e52-426e-bcd9-5c46e966aadb","execution":{"iopub.status.busy":"2021-05-23T09:58:43.815549Z","iopub.execute_input":"2021-05-23T09:58:43.816246Z","iopub.status.idle":"2021-05-23T10:01:45.425948Z","shell.execute_reply.started":"2021-05-23T09:58:43.816098Z","shell.execute_reply":"2021-05-23T10:01:45.425143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model=cnn_model, to_file='cnn_model_plot.png', show_shapes=True)","metadata":{"id":"4YbTco7hG-tN","executionInfo":{"status":"ok","timestamp":1606796667125,"user_tz":-330,"elapsed":230366,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"outputId":"ed843c6c-d89b-4b48-d01c-be4a0aebc5f8","execution":{"iopub.status.busy":"2021-05-23T10:01:45.427267Z","iopub.execute_input":"2021-05-23T10:01:45.427652Z","iopub.status.idle":"2021-05-23T10:01:46.254313Z","shell.execute_reply.started":"2021-05-23T10:01:45.427613Z","shell.execute_reply":"2021-05-23T10:01:46.25346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # For more info on ModelCheckpoint, refer https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n# from tensorflow.keras.callbacks import ModelCheckpoint\n# model_path = \"/content/drive/My Drive/Colab Notebooks/Applied AI Assignments/Case Study 1 Mercari Price Suggestion/zzFINAL COMPLETED/FAST TEXT CNN/BEST_FT_CNN_MODEL.hdfs\"\n# checkpoint_best = ModelCheckpoint(filepath=model_path, monitor='val_loss',verbose=1, save_best_only=True, mode='min')","metadata":{"id":"sy8qLG0EiEry","execution":{"iopub.status.busy":"2021-05-23T10:01:46.255689Z","iopub.execute_input":"2021-05-23T10:01:46.256021Z","iopub.status.idle":"2021-05-23T10:01:46.260248Z","shell.execute_reply.started":"2021-05-23T10:01:46.255985Z","shell.execute_reply":"2021-05-23T10:01:46.258959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n# https://stackoverflow.com/a/42963385/7697658\nlrschedule_1 = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.70, mode='min')","metadata":{"id":"tLqXR1sqiYf7","execution":{"iopub.status.busy":"2021-05-23T10:01:46.262117Z","iopub.execute_input":"2021-05-23T10:01:46.262691Z","iopub.status.idle":"2021-05-23T10:01:46.273946Z","shell.execute_reply.started":"2021-05-23T10:01:46.262655Z","shell.execute_reply":"2021-05-23T10:01:46.273181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For more info on EarlyStoppingdelCheckpoint, refer https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\nfrom tensorflow.keras.callbacks import EarlyStopping\nearlystop = EarlyStopping(monitor='val_loss', verbose=1, patience=5)","metadata":{"id":"PFuGbEx4tF9i","execution":{"iopub.status.busy":"2021-05-23T10:01:46.276993Z","iopub.execute_input":"2021-05-23T10:01:46.277415Z","iopub.status.idle":"2021-05-23T10:01:46.28991Z","shell.execute_reply.started":"2021-05-23T10:01:46.277374Z","shell.execute_reply":"2021-05-23T10:01:46.289074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"./cnn_checkpoints/cnn_ckpt.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_path,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    verbose=1,\n    save_freq = 'epoch',\n    save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T10:01:46.291276Z","iopub.execute_input":"2021-05-23T10:01:46.291885Z","iopub.status.idle":"2021-05-23T10:01:46.301617Z","shell.execute_reply.started":"2021-05-23T10:01:46.291847Z","shell.execute_reply":"2021-05-23T10:01:46.300873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 100\nBATCH_SIZE = 256\nadam = Adam(learning_rate=0.0003)\ncnn_model.compile(optimizer=adam, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\ncnn_model_hist = cnn_model.fit(x=X_train_inputs, y=y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True, validation_data=(X_test_inputs, y_test), \n                            callbacks=[cp_callback, lrschedule_1, earlystop])","metadata":{"id":"z8YrNNAuN4-F","executionInfo":{"status":"ok","timestamp":1606804157031,"user_tz":-330,"elapsed":7487527,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"outputId":"a1dcdcd7-d3e4-4f55-bb24-c528209767dc","execution":{"iopub.status.busy":"2021-05-23T10:01:46.30295Z","iopub.execute_input":"2021-05-23T10:01:46.303507Z","iopub.status.idle":"2021-05-23T10:04:39.65473Z","shell.execute_reply.started":"2021-05-23T10:01:46.303471Z","shell.execute_reply":"2021-05-23T10:04:39.653771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Glove CNN = 0.21801/0.4551; Embeddings Trainable=True","metadata":{"id":"vehb2ck-lki9","execution":{"iopub.status.busy":"2021-05-23T10:04:39.656462Z","iopub.execute_input":"2021-05-23T10:04:39.656835Z","iopub.status.idle":"2021-05-23T10:04:39.661741Z","shell.execute_reply.started":"2021-05-23T10:04:39.656798Z","shell.execute_reply":"2021-05-23T10:04:39.660794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Test Pipeline**","metadata":{"id":"A-w9YUEVIUci"}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ndef get_len_feature(col_series, scaler_text_len=None):\n    \"\"\"\n    Description:\n    This funciton will calculate the word count of the text and standardize it.\n\n    Input: Series, fitted scaler[optional; used during inference]\n    Output: standardized text length for each product and object of the fitted scaler\n    \"\"\"\n    text_len = col_series.apply(lambda x: len(x.split()))\n    if scaler_text_len==None:\n        scaler_text_len = StandardScaler()\n        scaler_text_len.fit(text_len.values.reshape(-1, 1))\n    text_len = scaler_text_len.transform(text_len.values.reshape(-1, 1))\n    return text_len, scaler_text_len","metadata":{"execution":{"iopub.status.busy":"2021-05-23T10:04:39.666547Z","iopub.execute_input":"2021-05-23T10:04:39.666913Z","iopub.status.idle":"2021-05-23T10:04:39.680252Z","shell.execute_reply.started":"2021-05-23T10:04:39.666877Z","shell.execute_reply":"2021-05-23T10:04:39.679214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with open('/content/drive/My Drive/Colab Notebooks/Applied AI Assignments/Case Study 1 Mercari Price Suggestion/zzFINAL COMPLETED/BERT CNN/scalers.pkl', 'rb') as f:\n#     scaler_name_len, scaler_desc_len = pickle.load(f)\n","metadata":{"id":"fT3DuikT_8eR","execution":{"iopub.status.busy":"2021-05-23T10:04:39.681881Z","iopub.execute_input":"2021-05-23T10:04:39.682309Z","iopub.status.idle":"2021-05-23T10:04:39.691559Z","shell.execute_reply.started":"2021-05-23T10:04:39.682271Z","shell.execute_reply":"2021-05-23T10:04:39.690707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test = pd.read_csv('test_stg2.tsv', sep='\\t')\n# X_te, _, _ = feature_pipeline(test, scaler_name_len, scaler_desc_len)","metadata":{"id":"B0DXp48zIbI3","executionInfo":{"status":"ok","timestamp":1606807345693,"user_tz":-330,"elapsed":1128071,"user":{"displayName":"Chintan Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmJHgrmE2Cy613CGp3VLGT4ArHqx-ep8QIX19uNQ=s64","userId":"10322362860674468501"}},"outputId":"9452ca04-20cd-468b-d4b0-353eed5d9683","execution":{"iopub.status.busy":"2021-05-23T10:04:39.692459Z","iopub.execute_input":"2021-05-23T10:04:39.692713Z","iopub.status.idle":"2021-05-23T10:04:39.704013Z","shell.execute_reply.started":"2021-05-23T10:04:39.69269Z","shell.execute_reply":"2021-05-23T10:04:39.703152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################### Text data ######################\n_, _, _, _, desc_text_test_padded = text_embeddings(X_train['item_description'].apply(str), X_test['item_description'].apply(str))\n_, _, _, _, name_text_test_padded = text_embeddings(X_train['name'].apply(str), X_test['name'].apply(str))\n########################################################\n\n\n################### Categorical data ###################\n_, _, bn_encoded_test = categorical_embeddings(X_train['brand_name'], X_test['brand_name'])\n_, _, gc_encoded_test = categorical_embeddings(X_train['general_cat'], X_test['general_cat'])\n_, _, sc1_encoded_test = categorical_embeddings(X_train['subcat_1'], X_test['subcat_1'])\n_, _, sc2_encoded_test = categorical_embeddings(X_train['subcat_2'], X_test['subcat_2'])\n#########################################################\n\n\n################### Numeric data ###################\nnumeric_test_input = pd.concat((X_test['scaler_desc_len'], X_test['scaler_name_len']), axis=1).to_numpy()\n\n\nX_te = [desc_text_test_padded, name_text_test_padded, bn_encoded_test, gc_encoded_test, sc1_encoded_test, sc2_encoded_test, tf.one_hot(X_test['item_condition_id'], 5),\\\n                tf.one_hot(X_test['shipping'], 2), tf.one_hot(X_test['is_expensive'], 2), numeric_test_input]","metadata":{"id":"8UR342RT7m-K","execution":{"iopub.status.busy":"2021-05-23T10:04:39.704966Z","iopub.execute_input":"2021-05-23T10:04:39.705237Z","iopub.status.idle":"2021-05-23T10:07:34.981459Z","shell.execute_reply.started":"2021-05-23T10:04:39.705212Z","shell.execute_reply":"2021-05-23T10:07:34.980543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_dl_model(model, X_data, y_act):\n    y_pred = model.predict(X_data)\n\n    act_prices = np.exp(y_act)\n    pred_prices = np.exp(y_pred)\n\n    rms = np.sqrt(mean_squared_log_error(act_prices, pred_prices))\n    return rms","metadata":{"execution":{"iopub.status.busy":"2021-05-23T10:07:34.982732Z","iopub.execute_input":"2021-05-23T10:07:34.983066Z","iopub.status.idle":"2021-05-23T10:07:34.987221Z","shell.execute_reply.started":"2021-05-23T10:07:34.983032Z","shell.execute_reply":"2021-05-23T10:07:34.986449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_dl_model(cnn_model, X_te, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T10:07:34.988529Z","iopub.execute_input":"2021-05-23T10:07:34.989055Z","iopub.status.idle":"2021-05-23T10:07:41.950357Z","shell.execute_reply.started":"2021-05-23T10:07:34.989012Z","shell.execute_reply":"2021-05-23T10:07:41.949554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(cnn_model_hist.history['root_mean_squared_error'], label='RMLE (training data)')\nplt.plot(cnn_model_hist.history['val_root_mean_squared_error'], label='RMLE (validation data)')\nplt.title('RMLE for CNN Model')\nplt.ylabel('RMLE value')\nplt.xlabel('No. epochs')\nplt.legend(loc=\"upper left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T10:08:58.483936Z","iopub.execute_input":"2021-05-23T10:08:58.484262Z","iopub.status.idle":"2021-05-23T10:08:58.64392Z","shell.execute_reply.started":"2021-05-23T10:08:58.484233Z","shell.execute_reply":"2021-05-23T10:08:58.643048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def create_submission_output_file(model, X_data, bs=64):\n#     submission_prices = model.predict(X_data, batch_size=bs)\n#     submission_prices = np.exp(submission_prices)\n#     submission_prices = np.squeeze(submission_prices, axis=1)\n#     my_submission = pd.DataFrame({'test_id': test['test_id'], 'price': submission_prices})\n#     my_submission.to_csv(\"/content/drive/My Drive/Colab Notebooks/Applied AI Assignments/Case Study 1 Mercari Price Suggestion/Submission/submission_ft_cnn.csv\", index=False)","metadata":{"id":"r3UPSyP0IhGG","execution":{"iopub.status.busy":"2021-05-23T10:07:41.951576Z","iopub.execute_input":"2021-05-23T10:07:41.951906Z","iopub.status.idle":"2021-05-23T10:07:41.957029Z","shell.execute_reply.started":"2021-05-23T10:07:41.951869Z","shell.execute_reply":"2021-05-23T10:07:41.954821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_path = \"/content/drive/My Drive/Colab Notebooks/Applied AI Assignments/Case Study 1 Mercari Price Suggestion/zzFINAL COMPLETED/FAST TEXT CNN/BEST_FT_CNN_MODEL.hdfs\"\n# model_best = tf.keras.models.load_model(model_path)","metadata":{"id":"Cs5OkLENIhvm","execution":{"iopub.status.busy":"2021-05-23T10:07:41.958362Z","iopub.execute_input":"2021-05-23T10:07:41.958968Z","iopub.status.idle":"2021-05-23T10:07:41.971303Z","shell.execute_reply.started":"2021-05-23T10:07:41.958931Z","shell.execute_reply":"2021-05-23T10:07:41.970467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create_submission_output_file(model_best, X_test_submission)","metadata":{"id":"qqvHQZhBlXGb","execution":{"iopub.status.busy":"2021-05-23T10:07:41.972496Z","iopub.execute_input":"2021-05-23T10:07:41.972994Z","iopub.status.idle":"2021-05-23T10:07:41.980723Z","shell.execute_reply.started":"2021-05-23T10:07:41.972958Z","shell.execute_reply":"2021-05-23T10:07:41.9799Z"},"trusted":true},"execution_count":null,"outputs":[]}]}