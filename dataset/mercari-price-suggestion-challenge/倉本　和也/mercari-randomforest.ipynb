{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n!apt-get install p7zip\n!apt-get install p7zip-full \n\n!7za e '../input/mercari-price-suggestion-challenge/train.tsv.7z';\n!7za e '../input/mercari-price-suggestion-challenge/test_stg2.tsv.zip';\n!7za e '../input/mercari-price-suggestion-challenge/sample_submission.csv.7z';","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-21T11:54:21.918714Z","iopub.execute_input":"2022-01-21T11:54:21.919005Z","iopub.status.idle":"2022-01-21T11:54:52.202032Z","shell.execute_reply.started":"2022-01-21T11:54:21.918975Z","shell.execute_reply":"2022-01-21T11:54:52.201218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# -----------------------------------\n# 学習データ、テストデータの読み込み\n# -----------------------------------\n\n# データタイプを指定\ntypes_dict_train = {'train_id':'int64', 'item_condition_id':'int8', 'price':'float64', 'shipping':'int8'}\ntypes_dict_test = {'test_id':'int64', 'item_condition_id':'int8', 'shipping':'int8'}\n\n# 学習データ、テストデータの読み込み\n# tsvファイルからPandas DataFrameへ読み込み\ntrain = pd.read_csv('./train.tsv', delimiter='\\t', low_memory=True, dtype=types_dict_train)\ntest = pd.read_csv('./test_stg2.tsv', delimiter='\\t', low_memory=True, dtype=types_dict_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T11:54:52.204548Z","iopub.execute_input":"2022-01-21T11:54:52.205098Z","iopub.status.idle":"2022-01-21T11:55:13.145683Z","shell.execute_reply.started":"2022-01-21T11:54:52.205054Z","shell.execute_reply":"2022-01-21T11:55:13.144675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 欠損値の確認と補完\n\n# この後合体させるためtrainとtestのidカラム名を共通化する\ntrain = train.rename(columns = {'train_id':'id'})\ntest = test.rename(columns = {'test_id':'id'})\n\n# 絶対に使用しない変数をリストアップ\ndrop_train = ['id','is_train']\ndrop_test = ['id','is_train']\n\n# 数値変数をリストに追加\nvalue_vars = ['item_condition_id','shipping']\n# カテゴリ変数をリストに追加\ncategory_vars = ['name','category_name','brand_name','item_description']\n\nprint(train.isna())\nprint(test.isna())\nfor v in value_vars:\n    print(v)\n    print(train[train[v].isna()])\n\nfor c in category_vars:\n    print(c)\n    print(train[train[c].isna()])\n\n    \ntrain = train.fillna('Blank')\ntest = test.fillna('Blank')\n\nprint(\"Blank set\")\n\nprint(train.isna())","metadata":{"execution":{"iopub.status.busy":"2022-01-21T11:55:13.147094Z","iopub.execute_input":"2022-01-21T11:55:13.147354Z","iopub.status.idle":"2022-01-21T11:55:19.991391Z","shell.execute_reply.started":"2022-01-21T11:55:13.147323Z","shell.execute_reply":"2022-01-21T11:55:19.990403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 一度testとtrainを合体して一括でデータタイプを変更する\n#双方のセットに分割するためのカラムを追加\ntrain['is_train'] = 1\ntest['is_train'] = 0\n\n# セット連結\ncombine = pd.concat([train.drop(['price'], axis=1),test],axis=0)\n\n# カテゴリ変数のデータタイプを変更\ncombine.category_name = combine.category_name.astype('category')\ncombine.item_description = combine.item_description.astype('category')\ncombine.name = combine.name.astype('category')\ncombine.brand_name = combine.brand_name.astype('category')\n\n# combineの文字列を「.cat.codes」でラベルエンコーディングする\ncombine.name = combine.name.cat.codes\ncombine.category_name = combine.category_name.cat.codes\ncombine.brand_name = combine.brand_name.cat.codes\ncombine.item_description = combine.item_description.cat.codes\n\ncombine.head()\ncombine.dtypes\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T11:55:19.992511Z","iopub.execute_input":"2022-01-21T11:55:19.992748Z","iopub.status.idle":"2022-01-21T11:56:12.860372Z","shell.execute_reply.started":"2022-01-21T11:55:19.992718Z","shell.execute_reply":"2022-01-21T11:56:12.859772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## データの成型\n\n# 連結したdfを分離\ndf_test = combine.loc[combine['is_train'] == 0]\ndf_train = combine.loc[combine['is_train'] == 1]\n\n\nprint(df_train.columns)\nprint(df_test.columns)\n#使用しない変数をdrop\ny_train = train['price']\nx_train = df_train.drop(drop_train, axis=1)\nx_test = df_test.drop(drop_test, axis=1)\n\n\n# 今回扱うのは金額の為、log関数で非線形変換する　p127\ny_train = y_train.apply(lambda x: np.log(x) if x>0 else x)\nprint(x_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T11:56:12.862276Z","iopub.execute_input":"2022-01-21T11:56:12.862745Z","iopub.status.idle":"2022-01-21T11:56:16.309594Z","shell.execute_reply.started":"2022-01-21T11:56:12.862704Z","shell.execute_reply":"2022-01-21T11:56:16.308727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#モデルの学習\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\n#モデルの作成,学習\nmodel = RandomForestRegressor(n_jobs=-1, min_samples_leaf=5, n_estimators=200)\nmodel.fit(x_train, y_train)\n\n#スコア表示\nprint(model.score(x_train, y_train))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T11:56:16.310793Z","iopub.execute_input":"2022-01-21T11:56:16.311008Z","iopub.status.idle":"2022-01-21T12:08:24.325519Z","shell.execute_reply.started":"2022-01-21T11:56:16.310981Z","shell.execute_reply":"2022-01-21T12:08:24.324464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.columns)\nprint(x_test.columns)\n\n# テストデータの予測\npreds = model.predict(x_test)\n\n# 予測値 predsを指数関数np.exp()で正常の金額に戻す\npreds = np.exp(preds)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T12:08:24.326937Z","iopub.execute_input":"2022-01-21T12:08:24.32715Z","iopub.status.idle":"2022-01-21T12:10:41.301792Z","shell.execute_reply.started":"2022-01-21T12:08:24.327123Z","shell.execute_reply":"2022-01-21T12:10:41.300854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 提出用ファイルを作成\ncsvname = 'submission.csv'\nprint(csvname)\nsubmission_col = ['test_id','Price']\nsubmission = pd.DataFrame(preds,\n                  columns=['Price'])\n# ID追加\nid_num = pd.RangeIndex(start=0, stop=len(submission.index), step=1)\nsubmission['test_id'] = id_num\n\nsubmission = submission.reindex(columns=['test_id', 'Price'])\nsubmission.to_csv(csvname, index=False)\nprint(submission)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T12:10:41.303165Z","iopub.execute_input":"2022-01-21T12:10:41.305099Z","iopub.status.idle":"2022-01-21T12:10:54.018625Z","shell.execute_reply.started":"2022-01-21T12:10:41.305052Z","shell.execute_reply":"2022-01-21T12:10:54.018011Z"},"trusted":true},"execution_count":null,"outputs":[]}]}