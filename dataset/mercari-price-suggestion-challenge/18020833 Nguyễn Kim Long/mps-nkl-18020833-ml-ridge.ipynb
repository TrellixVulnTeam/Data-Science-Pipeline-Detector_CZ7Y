{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Giới thiệu\nMercari Price suggestion là cuộc thi dự đoán một mặt hàng- thực sự đáng giá bao nhiêu. Chi tiết nhỏ có thể có nghĩa là sự khác biệt lớn về giá cả. Ví dụ, một trong những chiếc áo len có giá 335 đô la và chiếc còn lại có giá 9,99 đô la thì điều gì quyết định về giá của sản phẩm </br>\n\nViệc định giá sản phẩm thậm chí còn khó hơn trên quy mô lớn, chỉ cần xem xét có bao nhiêu sản phẩm được bán trực tuyến. Quần áo có xu hướng định giá theo mùa mạnh mẽ và bị ảnh hưởng nhiều bởi thương hiệu, trong khi đồ điện tử có giá dao động dựa trên thông số kỹ thuật của sản phẩm. </br>\n\nMercari muốn đưa ra đề xuất về giá cho người bán, nhưng điều này rất khó vì người bán của họ được phép đưa bất kỳ thứ gì hoặc bất kỳ gói nào lên thị trường của Mercari.\n\n# Mục tiêu\nMục tiêu ở đây là phát triển một hệ thống tự động dự đoán giá của một sản phẩm một cách phù hợp dựa trên thông tin về sản phẩm đó được cung cấp","metadata":{}},{"cell_type":"markdown","source":"# Giải nén đầu vào","metadata":{}},{"cell_type":"code","source":"!apt-get install p7zip\n!p7zip -d -f -k /kaggle/input/mercari-price-suggestion-challenge/train.tsv.7z\n!p7zip -d -f -k /kaggle/input/mercari-price-suggestion-challenge/test.tsv.7z\n!p7zip -d -f -k /kaggle/input/mercari-price-suggestion-challenge/sample_submission.csv.7z","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-10T21:32:53.371983Z","iopub.execute_input":"2021-06-10T21:32:53.372836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /kaggle/input/mercari-price-suggestion-challenge/sample_submission_stg2.csv.zip\n!unzip /kaggle/input/mercari-price-suggestion-challenge/test_stg2.tsv.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thư viện\nimport một số thư viện để sử dụng","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.linear_model import Ridge, LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Đọc dữ liệu","metadata":{}},{"cell_type":"code","source":"#Đọc dữ liệu từ 2 tập 'train.tsv' và tập 'test_stg2.tsv'(đưa về dạng bảng)\ntrain = pd.read_table('train.tsv')\ntest = pd.read_table('test_stg2.tsv')\nprint(train.shape)\nprint(test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Kiểm tra thông tin của tập 'train'\ntrain.info()\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Quan sát:**\n- Ở tập train, mỗi 1 sản phấm sẽ có các thuộc tính: train_id, name, item_condition_id, category_name, shipping, item_description và cột price\n- Ở cột brand_name có nhiều giá trị NaN(giá trị rỗng)\n\n=> kiểm tra các giá trị trong tập 'train'","metadata":{}},{"cell_type":"markdown","source":"# 2. Xử lí và phân tích dữ liệu\n* **Mục tiêu**: Ở phần này chúng ta sẽ xử lí các dữ liệu. Vì bài toán này là bài toán hồi quy tuyến tính nên cần chuyển các thuộc tính về dạng vector hoặc số thực\n\n* Như đã quan sát ở trên ta thấy rằng ở tập 'train' và tập 'test' đều chứa các giá trị rỗng nên ta cần phải kiểm tra các giá trị rỗng này","metadata":{}},{"cell_type":"markdown","source":"> # a. Quan sát tổng quan","metadata":{}},{"cell_type":"code","source":"#sử dung hàm isnull() đếm các giá trị null\ntrain.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> tồn tại giá trị null ở category_name và brand_name\n","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**=> Quan sát dữ liệu ở trên ta thấy được:**\n- Ở tập dữ liệu train và test, cột category_name có nhiều cấp được phân tách bằng \"/\"\n- Có 2 tập có giá trị null\n- brand_name có gần một nửa giá trị bị thiếu cả trong tập train và tập test, vì vậy không thể xóa những hàng mà phải lấp các giá trị đó\n- trong khi cột category_name thiếu 0,43-0,44% giá trị nên có thể xóa các hàng đó hoặc lấp đầy các giá trị đó\n","metadata":{}},{"cell_type":"markdown","source":"> # b. Xử lí các giá trị rỗng\nViệc tồn trại các giá trị rỗng sẽ làm cho đánh giá không chính xác\n**Lấp các giá trị null**","metadata":{}},{"cell_type":"code","source":"def handle_missing(dataset):\n    #xử lý dữ liệu trống\n    dataset.category_name.fillna(value=\"missing\", inplace=True)\n    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n    dataset.item_description.fillna(value=\"missing\", inplace=True)\n    return (dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = handle_missing(train)\ntest = handle_missing(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Quan sát dữ liệu ở tập tain sau khi lấp các giá trị null\ntrain.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Quan sát:**\n\n- Quan sát 10 sản phẩm đau tiên của tập 'train' các giá trị rống đã được thay thế bằng các text phù hợp\n**Sử dụng LabelBinarizer để xử lí các dữ liệu dạng label và Vectorizer để xử lí các dữ liệu dạng text**\n\nVì đây là mô hình hồi quy nên cần phải đưa dữ liệu về dạng vecto để xử lí","metadata":{}},{"cell_type":"markdown","source":"> # c. Xử lí dữ liệu ở cột category_name","metadata":{}},{"cell_type":"code","source":"#kiểm tra category_name\ntrain.head(10)\ntest.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Quan sát**\n- category_name có 3 mục được phân biệt bằng \"/\"\n=> Chia category_name thành 3 cột riêng biệt\n**Chia cột category_name thành subcat_1, subcat_2, subcat_3**\n\n=> việc này giúp cho mô hình huấn luyện chính xác hơn","metadata":{}},{"cell_type":"code","source":"#Hàm split_cat dùng để cắt các nhãn trong cột 'category_name' thành các cột riêng biệt\ndef transform_category_name(category_name):\n    try:\n        sub1, sub2, sub3 = category_name.split('/')\n        return sub1, sub2, sub3\n    except:\n        return \"none\", \"none\", \"none\"\n\ntrain['subcat_1'], train['subcat_2'], train['subcat_3'] = zip(*train['category_name'].apply(transform_category_name))\ntest['subcat_1'], test['subcat_2'], test['subcat_3'] = zip(*test['category_name'].apply(transform_category_name))\ntrain.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"There are %d unique subcat_1.\" % train['subcat_1'].nunique())\nprint(\"There are %d unique subcat_2.\" % train['subcat_2'].nunique())\nprint(\"There are %d unique subcat_3.\" % train['subcat_3'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> dữ liệu trong tập 'train' có thêm 3 cột 'subcat_1', 'subcat_2', 'subcat_3'","metadata":{}},{"cell_type":"markdown","source":"> # d. Quan sát và phân tích các dữ liệu dạng số\n- Các cột thuộc dữ liệu dạng số bao gồm: train_id, item_condition_id, price, shipping\n\n","metadata":{}},{"cell_type":"code","source":"#Định dạng các dữ liệu ở dạng số\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n#Thống kê \ntrain.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Quan sát**\n- Ở đây chỉ có 2 cột dữ liệu dùng để phân tích dự đoán là cột item_condition_id và shipping\n- Giá trị của các mặt hàng nhỏ nhất là không tức là có những sản phẩm có thể xem như là miễn phí và lớn nhất là 2009\n- Giá trị phổ biến của các sản phẩm dao động từ 17 $ - 2009 $\n- Phần lớn các mặt hàng có shipping = 1\n> #  **Đánh giá cột price**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(figsize=(14,8))\nax.hist(train.price,bins = 30, range = [0,200],label=\"Price\")\nax.set_xlabel('Price',fontsize=15)\nax.set_ylabel('No of items', fontsize=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- chúng ta có thể thấy rằng phân phối trên PRICE bị lệch trái","metadata":{}},{"cell_type":"code","source":"train[\"logPrice\"] = np.log(train[\"price\"]+1)\n\nfrom scipy.stats import norm\nimport seaborn as sns\n\nfig, axes = plt.subplots(1, 3, figsize=(10,4))\n\naxes[0].set_title('Price')\nsns.distplot(train.price, ax=axes[0], kde=False)\naxes[0].grid()\n\naxes[1].set_title('Price < 75')\nsns.distplot(train.price[train.price<75], ax=axes[1], kde=False)\naxes[1].grid()\n\naxes[2].set_title('log(Price + 1)')\nsns.distplot(train[\"logPrice\"], ax=axes[2], fit=norm, kde=False)\naxes[2].set_xticks(range(0,9))\naxes[2].grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Quan sát**\n- Phân bố của log(price) ít lệch hơn và được phân bố tốt xung quanh giá trị trung bình\n=> Sử dụng log(price) thay vì price để huấn luyện\n> #  **Đánh giá cột item_condition_id**","metadata":{}},{"cell_type":"code","source":"#Biểu đồ phân tích cột item_condition_id\nax = sns.countplot(x = 'item_condition_id',data=train, palette ='Blues_r')\nax.set_title(\"Tổng số lượng sản phẩm theo item_condition_id\", fontsize = 13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Quan sát**\n- Có 5 loại tình item_condition_id\n- Loại 1, loại 2 và loại 3 là phổ biến nhất\n- Loại 4 và loại 5 là ít phổ biến nhất\n> #  **Đánh giá cột shipping**","metadata":{}},{"cell_type":"code","source":"(train['shipping'].value_counts())\ndef plot_distribution_and_violin(variable):\n    fig, axes = plt.subplots(2,1,figsize=(5,6), sharex=True)\n    axes[0].set_title(variable)\n    sns.countplot(x=variable, data=train, palette=\"ch:.25\", color=\"c\", ax=axes[0])\n    sns.violinplot(x=variable, y='logPrice', palette=\"ch:.25\", data=train, ax=axes[1])\n    fig.tight_layout()\n\nplot_distribution_and_violin('shipping')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Giá trị trung bình của những sản phẩm có shipping = 0 nhỏ hơn giá trị trung bình của những sản phẩm có shipping = 1.=> Có khoảng 55% khách hàng không phải trả phí vận chuyển\n> #  **Đánh giá cột brand_name**","metadata":{}},{"cell_type":"code","source":"train['category_name'].value_counts()[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Quan sát:**\n- Phần lớn sản phẩm không có thương hiệu.\n- Ngoài ra top các thương hiệu phổ biến nhất là: PINK, Nike, Victoria's Secret, LuLaRoe, Apple, FOREVER 21, Nintendo, Lululemon, Michael Kors.\n> #  **Đánh giá các cột subcat_1 subcat_2 và subcat_3**\n> **subcat_1**","metadata":{}},{"cell_type":"code","source":"print(\"Có %d nhãn ở cột subcat_1.\" % train['subcat_1'].nunique())\n\nimport plotly\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\n\n\nx = train['subcat_1'].value_counts().index.values.astype('str')\ny = train['subcat_1'].value_counts().values\npct = [(\"%.2f\"%(v*100))+\"%\"for v in (y/len(train))]\n\ntrace1 = go.Bar(x=x, y=y, text=pct)\nlayout = dict(title= 'Number of Items by Main Category',\n              yaxis = dict(title='Count'),\n              xaxis = dict(title='subcat_1'))\nfig=dict(data=[trace1], layout=layout)\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> Woman và Beauty là 2 danh mục hàng đầu và chiếm lượng rất lớn\n> **subcat_2**","metadata":{}},{"cell_type":"code","source":"print(\"Có %d nhãn ở cột subcat_2.\" % train['subcat_2'].nunique())\n\nimport plotly\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\n\n\nx = train['subcat_2'].value_counts().index.values.astype('str')\ny = train['subcat_2'].value_counts().values\npct = [(\"%.2f\"%(v*100))+\"%\"for v in (y/len(train))]\n\ntrace1 = go.Bar(x=x, y=y, text=pct)\nlayout = dict(title= 'Number of Items by Main Category',\n              yaxis = dict(title='Count'),\n              xaxis = dict(title='subcat_2'))\nfig=dict(data=[trace1], layout=layout)\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **subcat_3**","metadata":{}},{"cell_type":"code","source":"print(\"Có %d nhãn ở cột subcat_3.\" % train['subcat_3'].nunique())\n\nimport plotly\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\n\n\nx = train['subcat_3'].value_counts().index.values.astype('str')\ny = train['subcat_3'].value_counts().values\npct = [(\"%.2f\"%(v*100))+\"%\"for v in (y/len(train))]\n\ntrace1 = go.Bar(x=x, y=y, text=pct)\nlayout = dict(title= 'Number of Items by Main Category',\n              yaxis = dict(title='Count'),\n              xaxis = dict(title='subcat_3'))\nfig=dict(data=[trace1], layout=layout)\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vì các sản phẩm 'women' xuất hiện với số lượng lớn trong Danh mục 'subcat_1', nên các danh mục xuất hiện nhiều nhất trong Danh mục 'subcat_2' phù hợp với danh các danh mục nhiều nhất ở mục 'subcat_2' ('Athletic Apparel','Makeup','Tops&Blueses') và mục 'subcat_3' cũng vậy","metadata":{}},{"cell_type":"markdown","source":"> # e. Quan sát dữ liệu ở cột 'item_description'","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport os\nwordcloud = WordCloud(width = 2400, height = 1200).generate(\" \".join(train.item_description.astype(str)))\nplt.figure(figsize = (13, 10))\nplt.imshow(wordcloud)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Các cụm từ \"Brand new\", \"free shipping\", \"great condition\", \" good condition\", \"never worn\", \"smoke free\", \" description yet\" là những cụm từ xuất hiện nhiều nhất","metadata":{}},{"cell_type":"markdown","source":"# 3. Vecto hóa dữ dữ liệu\n**Mục tiêu:** là huấn luyện theo mô hình hồi quy tuyến tính nên cần đưa dữ liệu về dạng vecto \n\n**Sử dụng LabelBinarizer để chuyển đổi các nhãn nhiều lớp sang nhãn nhị phân**\n\n","metadata":{}},{"cell_type":"code","source":"lb_item_condition_id = LabelBinarizer(sparse_output=True)\ntrain_condition = lb_item_condition_id.fit_transform(train['item_condition_id'])\ntest_condition = lb_item_condition_id.transform(test['item_condition_id'])\n\ntrain_condition.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> ma trận trả về có 1482535 hàng theo 1482535 dữ liệu của từng sản phẩm và có 5 loại item_condition\n","metadata":{}},{"cell_type":"code","source":"lb_shipping = LabelBinarizer(sparse_output=True)\ntrain_shipping = lb_shipping.fit_transform(train['shipping'])\ntest_shipping = lb_shipping.transform(test['shipping'])\n\ntrain_shipping.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> ma trận trả về có 1482535 hàng (vì trong tập train có dữ liệu của 1482535 sản phẩm) và có 1 cột vì chỉ có 2 kiểu shipping","metadata":{}},{"cell_type":"code","source":"lb_brand_name = LabelBinarizer(sparse_output=True)\ntrain_brand_name= lb_brand_name.fit_transform(train['brand_name'])\ntest_brand_name = lb_brand_name.transform(test['brand_name'])\n\ntrain_brand_name.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> ma trận trả về có 1482535 hàng (vì trong tập train có dữ liệu của 1482535 sản phẩm) và có 4810 cột vì  có 4810 thương hiệu\n","metadata":{}},{"cell_type":"markdown","source":"Vì mỗi một chuỗi ở cột \"name\" khá ngắn nên Sử dụng CountVectorizer() để chuyển cột name từ dạng text về dạng một vecto trên cơ sở số lần xuất hiện của mỗi từ (xuất hiện càng nhiều đánh giá càng cao)","metadata":{}},{"cell_type":"code","source":"count_vec = CountVectorizer()\n\ntrain_name = count_vec.fit_transform(train['name'])\ntest_name = count_vec.transform(test['name'])\n\nprint(train_name.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=> ma trận 'train_name'có 1482535 hàng là vì có 1482535 sản phẩm trong tập 'train' và có 105757 tức là có tất cả 105757 từ xuất hiện trong cột 'name'","metadata":{}},{"cell_type":"markdown","source":"Do số lượng từ ở cột item_description nhiều\n\nSẽ khó khăn hơn khi phân tích mục description vì đó là dữ liệu phi cấu trúc. Nhìn sơ qua về dữ liệu có thể nhận thấy, khi description càng dài thì mặt hàng có xu hướng giá cao hơn. Chúng ta sẽ loại bỏ tất cả các dấu câu, loại bỏ một số từ ngắn (stop words) trong tiếng Anh (như \"a\", \"the\", v.v.) và bất kỳ từ nào khác có độ dài nhỏ hơn 3\n\n=> sử dụng TfidfVectorizer() để chuyển đổi dữ liệu thành dạng ma trận","metadata":{}},{"cell_type":"markdown","source":"> # TF-IDF (Term Frequency – Inverse Document Frequency)\n\nlà 1 kĩ thuật sử dụng trong khai phá dữ liệu văn bản. Trọng số này được sử dụng để đánh giá tầm quan trọng của một từ trong một văn bản.\n\nTF: Term Frequency(Tần suất xuất hiện của từ) là số lần từ xuất hiện trong văn bản. Trong các văn bản thì tần suất xuất hiện của các từ có thể lớn hoặc nhỏ, TF sẽ chia độ dài văn bản (theo số từ)\n\n\nIDF: Inverse Document Frequency(Nghịch đảo tần suất của văn bản), nhằm đánh giá giá trị của các từ. Khi tính toán TF , tất cả các từ được coi như có độ quan trọng bằng nhau. Nhưng một số từ ngắn như \"is\" \"a\" \"or\"... thường xuất hiện nhiều nhưng giá trị không lớn => IDF sẽ giảm giá trị đánh giá các từ này","metadata":{}},{"cell_type":"code","source":"tfidf_des = TfidfVectorizer(max_features=50000, ngram_range=(1, 3), stop_words='english')\n\ntrain_des = tfidf_des.fit_transform(train['item_description'])\ntest_des = tfidf_des.transform(test['item_description'])\n\ntrain_des.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sau khi chuẩn hóa dữ liệu ở các cột category_name, sử dụng LabelBinarizer để chuyển đổi các nhãn nhiều lớp sang nhãn nhị phân ở các cột subcat_1, subcat_2, subcat_3\n","metadata":{}},{"cell_type":"code","source":"lb_cat_1 = LabelBinarizer(sparse_output=True)\ntrain_cat_1 = lb_cat_1.fit_transform(train['subcat_1'])\ntest_cat_1 = lb_cat_1.transform(test['subcat_1'])\n\nlb_cat_2 = LabelBinarizer(sparse_output=True)\ntrain_cat_2 = lb_cat_2.fit_transform(train['subcat_2'])\ntest_cat_2 = lb_cat_2.transform(test['subcat_2'])\n\nlb_cat_3 = LabelBinarizer(sparse_output=True)\ntrain_cat_3 = lb_cat_3.fit_transform(train['subcat_3'])\ntest_cat_3 = lb_cat_3.transform(test['subcat_3'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Mô hình hóa dữ liệu\n **Tạo sparse matrix để kết hợp các dữ liệu với nhau**","metadata":{}},{"cell_type":"code","source":"from scipy.sparse import hstack\nimport gc\n\nsparse_matrix_list = (train_name, train_des, train_brand_name, train_condition,\n                      train_shipping, train_cat_1, train_cat_2, train_cat_3)\n\nX_train = hstack(sparse_matrix_list).tocsr()\nprint( X_train.shape)\n\ndel X_train\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Đánh giá mô hình\n\n> # a. Số liệu đánh giá\n**RMSLE**\n\n- Lỗi trung bình bình phương (RMSE) là độ lệch chuẩn của phần dư ( lỗi dự đoán ). ... Nó thực hiện điều này bằng cách đo sự khác biệt giữa các giá trị dự đoán và giá trị thực tế . R-MSE càng nhỏ tức là sai số càng bé thì mức độ ước lượng cho thấy độ tin cậy của mô hình có thể đạt cao nhất.\n- Công thức:\n\n![alt](https://secureservercdn.net/160.153.137.16/70j.58d.myftpupload.com/wp-content/uploads/2019/03/rmsle-2.png)\n\nTrong đó: \n+ y^i là giá trị ước lượng\n+ yi là biến độc lập\n+ n=(N – k – 1)\n+ N : số tổng lượng quan sát\n+ K : tổng lượng biến\n","metadata":{}},{"cell_type":"code","source":"def rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n    return (sum(to_sum) * (1.0/len(y))) ** 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef run_model(model, matrix_list):\n    #X= train[['item_condition_id','shipping','name','brand_name','cat_1','cat_2','cat_3']]\n    #X_train, x_test, Y_train, y_test = train_test_split(X, train['price'], test_size=0.25)\n    X = hstack(matrix_list).tocsr()\n    X_train, x_test, Y_train, y_test = train_test_split(X, np.log1p(train['price']), test_size=0.2)\n    model.fit(X_train, Y_train)\n    preds = model.predict(x_test)\n    del X, X_train, x_test, Y_train\n    gc.collect()\n    \n    return preds, y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" > # b Model: Ridge Regression\n \n **Tổng quan:**\n\n- Hồi quy Ridge là một kỹ thuật để phân tích nhiều dữ liệu hồi quy chịu sự đa hình. Khi đa cộng tuyến xảy ra, ước tính bình phương tối thiểu là không thiên vị, nhưng phương sai của chúng lớn nên chúng có thể cách xa giá trị thực. Bằng cách thêm một mức độ sai lệch cho các ước tính hồi quy, hồi quy sườn giúp giảm các lỗi tiêu chuẩn.\n\n- Ridge Regression là mô hình hồi quy phân tích mối quan hệ giữa các biến độc lập và các biến phụ thuộc sử dụng phương pháp Regularization, điều chình mô hình sao cho giảm thiểu các vấn đề Overfitting, tối ưu hay kiểm soát mức độ phức tạp của mô hình để cân đối giữa Biased và Variance Quan đó giảm sai số của mô hình.\n- Công thức tổng quát của mô hình:\n\n >![alt](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQbpyppaTUqoiV9l9SM72xpWq_d31m4-Ofbig&usqp=CAU)\n\nHệ số λ hay còn gọi là tham số Regularization, là số luôn dương, là giá trị mà ở đó phương trình tuyến tính sẽ tính toán được để sai số của mô hình được giảm tối đa, nghĩa là giá trị λ nào làm cho MSE (ở đây dùng RLMSE) nhỏ nhất thì mô hình đó được chọn","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nmodel = ridge = Ridge()\nRidge_preds, y_test = run_model(model, matrix_list=sparse_matrix_list)\n\nprint(\"rmsle: \"+str(rmsle(np.expm1(y_test), np.expm1(Ridge_preds))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6 Kết quả\n","metadata":{}},{"cell_type":"code","source":"sparse_matrix_list = (train_name, train_des, train_brand_name, train_condition,\n                      train_shipping, train_cat_1, train_cat_2, train_cat_3)\nX_train = hstack(sparse_matrix_list).tocsr()\nX_train\n\ny_train = np.log1p(train['price'])\ny_train\n\nRidge_model =  Ridge()\nRidge_model.fit(X_train, y_train)\n\nsparse_matrix_list = (test_name, test_des, test_brand_name, test_condition,\n                      test_shipping, test_cat_1, test_cat_2, test_cat_3)\nX_test = hstack(sparse_matrix_list).tocsr()\n\npreds = Ridge_model.predict(X_test)\npreds\npreds = np.expm1(preds)\npreds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('sample_submission_stg2.csv')\nsubmission\nsubmission.loc[:, 'price'] = preds\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}