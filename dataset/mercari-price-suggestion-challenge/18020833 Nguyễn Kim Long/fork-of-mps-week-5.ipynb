{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mercari Price Suggestion Challenge:\n> Dự đoán giá tiền của một loại mặt hàng dựa vào các thông số kĩ thuật, mô tả của người bán, hình thức bán...\n\nBáo cáo vấn đề Có thể khó biết thứ gì đó thực sự đáng giá bao nhiêu. Chi tiết nhỏ có thể có nghĩa là sự khác biệt lớn về giá cả. Ví dụ, một trong những chiếc áo len có giá 335 đô la và chiếc còn lại có giá 9,99 đô la thì điều gì quyết định về giá của sản phẩm </br>\n\nViệc định giá sản phẩm thậm chí còn khó hơn trên quy mô lớn, chỉ cần xem xét có bao nhiêu sản phẩm được bán trực tuyến. Quần áo có xu hướng định giá theo mùa mạnh mẽ và bị ảnh hưởng nhiều bởi thương hiệu, trong khi đồ điện tử có giá dao động dựa trên thông số kỹ thuật của sản phẩm. </br>\n\nMercari muốn đưa ra đề xuất về giá cho người bán, nhưng điều này rất khó vì người bán của họ được phép đưa bất kỳ thứ gì hoặc bất kỳ gói nào lên thị trường của Mercari.","metadata":{}},{"cell_type":"markdown","source":"# YÊU CẦU\nSử dụng các thông số về danh mục sản phẩm, thương hiệu, tình trạng mặt hàng,... để dự đoán giá của các mặt hàng được bán","metadata":{}},{"cell_type":"markdown","source":"**Mục tiêu** </br>\nDự đoán giá của một mặt hàng với tình trạng, mô tả và các tính năng liên quan khác. Giảm thiểu sự khác biệt giữa giá dự đoán và giá thực tế (RMSLE) </br>\n**Đánh giá tổng quan:** </br>\nĐây là bài toán hồi quy tuyến tính. Dữ liệu được cung cấp ở dạng text và lable, nên cần chuyển các đặc trưng về dạng số thực hoặc vector để xử lý tuyến tính","metadata":{}},{"cell_type":"markdown","source":"# Điều làm được trong lần test này (version4):\nNhận thấy loss vẫn còn ở tỉ số cao -> tăng thời gian huấn luyện\ntăng epoch(5->20) Nhận thấy được loss giảm đi tương đối nhiều (0.0159->0.0112) \nKết quả: Giảm được Error của hàm RMSLE từ 0.506 xuống 0.488","metadata":{}},{"cell_type":"markdown","source":"**Hạn chế:** Code còn lớn, chiếm dung lượng nhiều, xử lý chậm (mỗi epoch chạy trong khoảng 280s)\n\nChưa khắc phục được: Chưa tìm được model tốt hơn để thay thế (score vẫn giữ ở mức ~ 0.6) (best: 0.3888)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport math\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:28:27.452589Z","iopub.execute_input":"2021-06-09T08:28:27.453036Z","iopub.status.idle":"2021-06-09T08:28:27.657199Z","shell.execute_reply.started":"2021-06-09T08:28:27.453Z","shell.execute_reply":"2021-06-09T08:28:27.655835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get install p7zip\n!p7zip -d -f -k /kaggle/input/mercari-price-suggestion-challenge/train.tsv.7z","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n#Source: https://www.kaggle.com/marknagelberg/rmsle-function","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:28:27.659185Z","iopub.execute_input":"2021-06-09T08:28:27.659535Z","iopub.status.idle":"2021-06-09T08:28:27.665963Z","shell.execute_reply.started":"2021-06-09T08:28:27.659501Z","shell.execute_reply":"2021-06-09T08:28:27.664946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LOAD DATA\nprint(\"Loading data...\")\n\n\n\ntrain = pd.read_table(\"train.tsv\", sep=\"\\t\")\ntest = pd.read_csv(\"../input/mercari-price-suggestion-challenge/test_stg2.tsv.zip\" , sep='\\t')\nprint(train.shape)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:28:27.667644Z","iopub.execute_input":"2021-06-09T08:28:27.668132Z","iopub.status.idle":"2021-06-09T08:28:58.489561Z","shell.execute_reply.started":"2021-06-09T08:28:27.668097Z","shell.execute_reply":"2021-06-09T08:28:58.488644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HANDLE MISSING VALUES\nprint(\"Handling missing values...\")\ndef handle_missing(dataset):\n    dataset.category_name.fillna(value=\"missing\", inplace=True)\n    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n    dataset.item_description.fillna(value=\"missing\", inplace=True)\n    return (dataset)\n\ntrain = handle_missing(train)\ntest = handle_missing(test)\nprint(train.shape)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:28:58.491155Z","iopub.execute_input":"2021-06-09T08:28:58.491587Z","iopub.status.idle":"2021-06-09T08:29:00.008593Z","shell.execute_reply.started":"2021-06-09T08:28:58.491555Z","shell.execute_reply":"2021-06-09T08:29:00.007619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(3)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:00.009813Z","iopub.execute_input":"2021-06-09T08:29:00.010298Z","iopub.status.idle":"2021-06-09T08:29:00.027005Z","shell.execute_reply.started":"2021-06-09T08:29:00.010249Z","shell.execute_reply":"2021-06-09T08:29:00.025845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PROCESS CATEGORICAL DATA\n\nprint(\"Handling categorical variables...\")\nle = LabelEncoder()\n\nle.fit(np.hstack([train.category_name, test.category_name]))\ntrain.category_name = le.transform(train.category_name)\ntest.category_name = le.transform(test.category_name)\n\nle.fit(np.hstack([train.brand_name, test.brand_name]))\ntrain.brand_name = le.transform(train.brand_name)\ntest.brand_name = le.transform(test.brand_name)\ndel le\n\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:00.028602Z","iopub.execute_input":"2021-06-09T08:29:00.028964Z","iopub.status.idle":"2021-06-09T08:29:04.626477Z","shell.execute_reply.started":"2021-06-09T08:29:00.02893Z","shell.execute_reply":"2021-06-09T08:29:04.625003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PROCESS TEXT: RAW\nprint(\"Text to seq process...\")\nfrom keras.preprocessing.text import Tokenizer\nraw_text = np.hstack([train.item_description.str.lower(), train.name.str.lower()])\n\nprint(\"   Fitting tokenizer...\")\ntok_raw = Tokenizer()\ntok_raw.fit_on_texts(raw_text)\nprint(\"   Transforming text to seq...\")\n\ntrain[\"seq_item_description\"] = tok_raw.texts_to_sequences(train.item_description.str.lower())\ntest[\"seq_item_description\"] = tok_raw.texts_to_sequences(test.item_description.str.lower())\ntrain[\"seq_name\"] = tok_raw.texts_to_sequences(train.name.str.lower())\ntest[\"seq_name\"] = tok_raw.texts_to_sequences(test.name.str.lower())\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:04.627976Z","iopub.execute_input":"2021-06-09T08:29:04.628332Z","iopub.status.idle":"2021-06-09T08:29:15.728688Z","shell.execute_reply.started":"2021-06-09T08:29:04.628302Z","shell.execute_reply":"2021-06-09T08:29:15.725325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SEQUENCES VARIABLES ANALYSIS\nmax_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\nmax_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x)))\n                                   , np.max(test.seq_item_description.apply(lambda x: len(x)))])\nprint(\"max name seq \"+str(max_name_seq))\nprint(\"max item desc seq \"+str(max_seq_item_description))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.730017Z","iopub.status.idle":"2021-06-09T08:29:15.730478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.seq_name.apply(lambda x: len(x)).hist()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.732061Z","iopub.status.idle":"2021-06-09T08:29:15.732712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.seq_item_description.apply(lambda x: len(x)).hist()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.734343Z","iopub.status.idle":"2021-06-09T08:29:15.735045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EMBEDDINGS MAX VALUE\n#Base on the histograms, we select the next lengths\nMAX_NAME_SEQ = 10\nMAX_ITEM_DESC_SEQ = 75\nMAX_TEXT = np.max([np.max(train.seq_name.max())\n                   , np.max(test.seq_name.max())\n                  , np.max(train.seq_item_description.max())\n                  , np.max(test.seq_item_description.max())])+2\nMAX_CATEGORY = np.max([train.category_name.max(), test.category_name.max()])+1\nMAX_BRAND = np.max([train.brand_name.max(), test.brand_name.max()])+1\nMAX_CONDITION = np.max([train.item_condition_id.max(), test.item_condition_id.max()])+1","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.743887Z","iopub.status.idle":"2021-06-09T08:29:15.744674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SCALE target variable\ntrain[\"target\"] = np.log(train.price+1)\npd.DataFrame(train.target).hist()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.746305Z","iopub.status.idle":"2021-06-09T08:29:15.747002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EXTRACT DEVELOPTMENT TEST\ndtrain, dvalid = train_test_split(train, random_state=123, train_size=0.99)\nprint(dtrain.shape)\nprint(dvalid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.74824Z","iopub.status.idle":"2021-06-09T08:29:15.748679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KERAS DATA DEFINITION\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef get_keras_data(dataset):\n    X = {\n        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n        ,'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ)\n        ,'brand_name': np.array(dataset.brand_name)\n        ,'category_name': np.array(dataset.category_name)\n        ,'item_condition': np.array(dataset.item_condition_id)\n        ,'num_vars': np.array(dataset[[\"shipping\"]])\n    }\n    return X\n\nX_train = get_keras_data(dtrain)\nX_valid = get_keras_data(dvalid)\nX_test = get_keras_data(test)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.749588Z","iopub.status.idle":"2021-06-09T08:29:15.750045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KERAS MODEL DEFINITION\nfrom keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras import backend as K\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\n\ndef rmsle_cust(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n\ndef get_model():\n    #params\n    dr_r = 0.1\n\n    #Inputs\n    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n    brand_name = Input(shape=[1], name=\"brand_name\")\n    category_name = Input(shape=[1], name=\"category_name\")\n    item_condition = Input(shape=[1], name=\"item_condition\")\n    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n    \n    #Embeddings layers\n    emb_name = Embedding(MAX_TEXT, 50)(name)\n    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n    \n    #rnn layer\n    rnn_layer1 = GRU(16) (emb_item_desc)\n    rnn_layer2 = GRU(8) (emb_name)\n    \n    #main layer\n    main_l = concatenate([\n        Flatten() (emb_brand_name)\n        , Flatten() (emb_category_name)\n        , Flatten() (emb_item_condition)\n        , rnn_layer1\n        , rnn_layer2\n        , num_vars\n    ])\n    main_l = Dropout(dr_r) (Dense(128) (main_l))\n    main_l = Dropout(dr_r) (Dense(64) (main_l))\n    \n    #output\n    output = Dense(1, activation=\"linear\") (main_l)\n    \n    #model\n    model = Model([name, item_desc, brand_name\n                   , category_name, item_condition, num_vars], output)\n    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n    \n    return model\n\nmodel = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.751103Z","iopub.status.idle":"2021-06-09T08:29:15.751529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#FITTING THE MODEL\nBATCH_SIZE = 20000\nepochs = 5\n\nmodel = get_model()\nmodel.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n          , validation_data=(X_valid, dvalid.target)\n          , verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.752492Z","iopub.status.idle":"2021-06-09T08:29:15.752933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\nval_preds = model.predict(X_valid)\n#val_preds = target_scaler.inverse_transform(val_preds)\nval_preds = np.exp(val_preds)+1\n\n#mean_absolute_error, mean_squared_log_error\ny_true = np.array(dvalid.price.values)\ny_pred = val_preds[:,0]\nv_rmsle = rmsle(y_true, y_pred)\nprint(\" RMSLE error on dev test: \"+str(v_rmsle))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.753898Z","iopub.status.idle":"2021-06-09T08:29:15.754311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CREATE PREDICTIONS\npreds = model.predict(X_test, batch_size=BATCH_SIZE)\npreds = np.exp(preds)-1\n\nsubmission = test[[\"test_id\"]]\nsubmission[\"price\"] = preds","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.755157Z","iopub.status.idle":"2021-06-09T08:29:15.755579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"./submission.csv\", index=False)\nsubmission.price.hist()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:29:15.756534Z","iopub.status.idle":"2021-06-09T08:29:15.757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}