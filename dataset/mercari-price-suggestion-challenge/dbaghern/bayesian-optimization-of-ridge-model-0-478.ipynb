{"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"17c7d5f570c1ff82ffbaa5828e83869122436902","_cell_guid":"a91ebe3d-8524-406c-9bad-3f57f2d143ab"},"source":"# Hyper Parameter Tuning With Bayesian Optimization\n\nBayesian Optimization is a powerful way to tune hyper parameters in a model. Instead of a brute force approach like with sklearn's grid_search, it tries to optimize the loss function by intelligently exploring the underlying distribution.  This script can be run with the develop flag to find the optimal hyperparameters, then to deploy a final model, specify the optimal found parameters by hand. \n\nTo see more of the documentation, check out the project github:\nhttps://github.com/fmfn/BayesianOptimization"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"302f8c8ad167a57b1c24ae36847b7c4a837e0dad","_cell_guid":"8c0250d1-2573-4031-aa39-987f3fa81151"},"source":"import gc\nimport time\nimport numpy as np\nimport pandas as pd\nimport sys\nfrom scipy.sparse import csr_matrix, hstack\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nstart_time = time.time()\ntcurrent   = start_time\n\nnp.random.seed(54)   \n\nNUM_BRANDS = 4550\nNUM_CATEGORIES = 1280\nMAX_FEATURES_NAME = 10000\nMAX_FEATURES_DESC =10000\n\ndevelop = True"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"59fff548841ae3236461f610b3d7810203b4af01","_cell_guid":"240314b7-f277-482d-aa09-1e463098727f"},"source":"from sklearn.metrics import make_scorer\n\ndef rmsle(y_true, y_pred):\n    # Remember, we transformed price with log1p previously.\n    return np.sqrt(mean_squared_log_error(np.expm1(y_true), np.expm1(y_pred)))\n\nneg_rmsle = make_scorer(rmsle, greater_is_better=False)\n\ndef split_cat(text):\n    try:\n        return text.split(\"/\")\n    except:\n        return (\"No Label\", \"No Label\", \"No Label\")\n\n\ndef handle_missing_inplace(dataset):\n    dataset['general_cat'].fillna(value='missing', inplace=True)\n    dataset['subcat_1'].fillna(value='missing', inplace=True)\n    dataset['subcat_2'].fillna(value='missing', inplace=True)\n    dataset['brand_name'].fillna(value='missing', inplace=True)\n    dataset['item_description'].fillna(value='missing', inplace=True)\n\n\ndef cutting(dataset):\n    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n    pop_category1 = dataset['general_cat'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATEGORIES]\n    pop_category2 = dataset['subcat_1'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATEGORIES]\n    pop_category3 = dataset['subcat_2'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATEGORIES]\n    dataset.loc[~dataset['general_cat'].isin(pop_category1), 'general_cat'] = 'missing'\n    dataset.loc[~dataset['subcat_1'].isin(pop_category2), 'subcat_1'] = 'missing'\n    dataset.loc[~dataset['subcat_2'].isin(pop_category3), 'subcat_2'] = 'missing'\n\n\ndef to_categorical(dataset):\n    dataset['general_cat'] = dataset['general_cat'].astype('category')\n    dataset['subcat_1'] = dataset['subcat_1'].astype('category')\n    dataset['subcat_2'] = dataset['subcat_2'].astype('category')\n    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"9c51600748c32975d862aa5739568735a7923d0b","_cell_guid":"b991c7e0-a6bb-412e-9a8d-ebe25b5622db","scrolled":true},"source":"from time import gmtime, strftime\nprint(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n\ntrain = pd.read_table('../input/train.tsv', engine='c')\ntest = pd.read_table('../input/test.tsv', engine='c')\n\n\ntrain = train.drop(train[(train.price == 0.0)].index)\ny = np.log1p(train[\"price\"])\n\nprint('[{}] Finished to load data'.format(time.time() - start_time))\nprint('Train shape: ', train.shape)\nprint('Test shape: ', test.shape)\n\nsubmission: pd.DataFrame = test[['test_id']]\n    \ntrain.head()"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"85221a9c0b86d80320605087267dd499e9ce5530","_cell_guid":"f2f9571b-7720-4a09-8f03-e5ea5cbfbe50"},"source":"import re, string, timeit\n\nregex = re.compile('[%s]' % re.escape(string.punctuation))\n\ntrain['item_description'] = train['item_description'].apply(lambda x: regex.sub('',str(x).lower()))\ntest['item_description'] = test['item_description'].apply(lambda x: regex.sub('',str(x).lower()))\ntrain['name'] = train['name'].apply(lambda x: regex.sub('',x.lower()))\ntest['name'] = test['name'].apply(lambda x: regex.sub('',x.lower()))\n\ntrain.head()"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"d3f3556034be61104dd454e64cc66bb0c9757b17","_cell_guid":"8662eb45-cafb-4b75-9b7b-5332ad7b98b7"},"source":"train['general_cat'], train['subcat_1'], train['subcat_2'] = \\\n        zip(*train['category_name'].apply(lambda x: split_cat(x)))\ntrain.drop('category_name', axis=1, inplace=True)\n\ntest['general_cat'], test['subcat_1'], test['subcat_2'] = \\\n        zip(*test['category_name'].apply(lambda x: split_cat(x)))\ntest.drop('category_name', axis=1, inplace=True)\nprint('[{}] Split categories completed.'.format(time.time() - start_time))\n\n\nhandle_missing_inplace(train)\nhandle_missing_inplace(test)\nprint('[{}] Handle missing completed.'.format(time.time() - start_time))\n\n\ncutting(train)\ncutting(test)\nprint('[{}] Cut completed.'.format(time.time() - start_time))\n\n\nto_categorical(train)\nto_categorical(test)\nprint('[{}] Convert categorical completed'.format(time.time() - start_time))\ntrain.head()"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"f95943417650a0583834174993438e4a1846c85d","_cell_guid":"b13b45e9-7a7e-425b-b443-4351d69ec029"},"source":"from sklearn.pipeline import FeatureUnion\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction import DictVectorizer\n\n\nclass ItemSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, x, y=None):\n        return self\n\n    def transform(self, data_dict):\n        return data_dict[self.key]"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"f5fcee7680822564f33787213e9d02fa3db12c8c","_cell_guid":"e43fa938-fc38-4fbd-a4d7-9f89e3e713f9"},"source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\npipeline = Pipeline([\n            ('selector', ItemSelector(key='name')),\n            ('tfidf', TfidfVectorizer(ngram_range = (1, 3),\n                            strip_accents = 'unicode', \n                            stop_words = 'english',\n                            min_df=20,\n                            max_df=.9,\n                            max_features = MAX_FEATURES_NAME))\n])\n\nX_name = pipeline.fit_transform(train, train['price'])\nX_name_test = pipeline.transform(test)\n\nX_name.shape"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"157f9aa1b59b5c1cf9b4fb129113c0dd2afac958","_cell_guid":"8ecf3b43-f0ec-4a29-b73e-4e1c09c0cbf0"},"source":"pipeline = Pipeline([\n    ('item_description', Pipeline([\n            ('selector', ItemSelector(key='item_description')),\n            ('tfidf', TfidfVectorizer(ngram_range = (1, 3),\n                                stop_words = 'english',\n                                min_df=20,\n                                max_df=.9,\n                                max_features = MAX_FEATURES_DESC))\n            ]))\n])\n\nX_text = pipeline.fit_transform(train, train['price'])\nX_text_test = pipeline.transform(test)\n\nX_text.shape"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"5a2e3dd5010494363450982294f92be96b800325","_cell_guid":"4fc7c1e7-197c-44ae-871a-494ac5b67d2b"},"source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\n\nwb = CountVectorizer()\nX_category1 = wb.fit_transform(train['general_cat'])\nX_category1_test = wb.transform(test['general_cat'])\nX_category2 = wb.fit_transform(train['subcat_1'])\nX_category2_test = wb.transform(test['subcat_1'])\nX_category3 = wb.fit_transform(train['subcat_2'])\nX_category3_test = wb.transform(test['subcat_2'])\nprint('[{}] Count vectorize `categories` completed.'.format(time.time() - start_time))\n\n\nlb = LabelBinarizer(sparse_output=True)\nX_brand = lb.fit_transform(train['brand_name'])\nX_brand_test = lb.transform(test['brand_name'])\nprint('[{}] Label binarize `brand_name` completed.'.format(time.time() - start_time))"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"e04f361fbaa1e8fe87316baefa78d057d3263e60","_cell_guid":"40e61dbc-2d43-4a8c-bbf5-9a50a77980ec"},"source":"X_dummies = csr_matrix(pd.get_dummies(train[['item_condition_id', 'shipping']],\n                                          sparse=True).values)\nX_dummies_test = csr_matrix(pd.get_dummies(test[['item_condition_id', 'shipping']],\n                                          sparse=True).values)\nprint('[{}] Get dummies on `item_condition_id` and `shipping` completed.'.format(time.time() - start_time))\nprint(X_dummies.shape, X_brand.shape, X_category1.shape, X_category2.shape, X_category3.shape,\n          X_text.shape)\n\n\nsparse_merge = hstack((X_dummies, X_brand, X_name, X_text,\n                       X_category1, X_category2, X_category3)).tocsr()\nsparse_merge_test = hstack((X_dummies_test, X_brand_test, X_name_test, X_text_test,\n                            X_category1_test, X_category2_test, X_category3_test)).tocsr()\n\nprint('[{}] Create sparse merge completed'.format(time.time() - start_time))\ndel X_dummies, lb, X_brand, X_category1, X_category2, X_category3\ndel X_name, X_text\ndel X_dummies_test, X_brand_test, X_category1_test, X_category2_test, X_category3_test\ndel X_name_test, X_text_test\n\ngc.collect()"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"b5449f17bf71ad932b2cd5755a8d770199bd1af1","_cell_guid":"48279f3a-e911-41b0-8573-0e7c250eb4ce"},"source":"from sklearn.model_selection import train_test_split\n\nX = sparse_merge\nX_test = sparse_merge_test\n\ntrain_X, train_y = X, y\ndel X, sparse_merge, sparse_merge_test\ngc.collect()"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"d4e85b076b091a05c0375e9ed41c40d4b39c169a","_cell_guid":"aabd3520-0511-43c1-b1a0-9fcf90cc99cd"},"source":"from bayes_opt import BayesianOptimization\nfrom sklearn.metrics import make_scorer, mean_squared_log_error\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.linear_model import Ridge\n\nseed = 101 # Lucky seed\n\n    \ndef target(**params):\n    fit_intercept = int(params['fit_intercept'])\n    fit_intercept_dict = {0:False, 1:True}\n\n    model = Ridge(alpha = params['alpha'],\n                    fit_intercept = fit_intercept_dict[fit_intercept],\n                    copy_X = True)\n    \n    scores = cross_val_score(model, train_X, train_y, scoring=neg_rmsle, cv=3)\n    return scores.mean()\n    \nparams = {'alpha':(1, 4),\n          'fit_intercept':(0,1.99)}\nif develop:\n    bo = BayesianOptimization(target, params, random_state=seed)\n    bo.gp.set_params(alpha=1e-8)\n    bo.maximize(init_points=5, n_iter=10, acq='ucb', kappa=2)\n    \n    print(bo.res['max']['max_params'])"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"234f0ac5ce49022be7c7bdc0748c1f92ac28908b","_cell_guid":"ba51caf8-7eb7-4e88-b9c1-55cc80e91391"},"source":"model = Ridge(alpha = 3.0656,\n                  fit_intercept = True,\n                  copy_X = True)\n\nmodel.fit(train_X, train_y)\npredsR = model.predict(X_test)\nsubmission['price'] = np.expm1(predsR)\nsubmission.to_csv(\"Bayesian_Ridge.csv\", index=False)"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"6a25dea8789f02b3346d8e09eba222dda951432b","_cell_guid":"48e473e5-f9e3-4c93-8793-e146d90ac2ef"},"source":"nm=(time.time() - start_time)/60\nprint (\"Total processing time %s min\" % nm)"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"pygments_lexer":"ipython3","version":"3.6.4","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","name":"python"}},"nbformat_minor":1}