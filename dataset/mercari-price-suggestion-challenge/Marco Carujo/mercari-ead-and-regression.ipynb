{"cells":[{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"!pip install nb_black -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"%load_ext nb_black","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To unpack our dataset:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\n\napt install --assume-yes p7zip-full\n7z x ../input/mercari-price-suggestion-challenge/train.tsv.7z -y\n7z x ../input/mercari-price-suggestion-challenge/test.tsv.7z -y\n7z x ../input/mercari-price-suggestion-challenge/test_stg2.tsv.zip -y\n7z x ../input/mercari-price-suggestion-challenge/sample_submission.csv.7z -y\n7z x ../input/mercari-price-suggestion-challenge/sample_submission_stg2.csv.zip -y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The libs","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"import math\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom wordcloud import WordCloud\nfrom string import punctuation\nfrom string import punctuation\nimport nltk\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the dataset with 100k sample.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":false},"cell_type":"code","source":"train = pd.read_csv(\n    \"train.tsv\",\n    sep=\"\\t\",\n    usecols=[\n        \"name\",\n        \"item_condition_id\",\n        \"category_name\",\n        \"brand_name\",\n        \"price\",\n        \"shipping\",\n        \"item_description\",\n    ],\n)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clean data\nFirst fill in brand_name because there are so many rows without a brand...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.brand_name.fillna(\"No Brand\", inplace=True)\ntrain.dropna(inplace=True)\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helpers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"punctuation = [p for p in punctuation]\nstopwords = nltk.corpus.stopwords.words(\"english\")\nstopwords = stopwords + punctuation + [\"...\"] + [\"!!\"]\ntoken_punct = nltk.WordPunctTokenizer()\nstemmer = nltk.RSLPStemmer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def plot_value_counts(serie, name_column, number=20):\n    y = serie.value_counts()[:number].values\n    x = serie.value_counts()[:number].index\n\n    fig = go.Figure(data=[go.Bar(x=x, y=y, text=y, textposition=\"auto\",)])\n    fig.update_layout(\n        title_text=\"Counting \" + name_column,\n        xaxis_title=name_column,\n        yaxis_title=\"count\",\n    )\n    fig.show()\n\n\ndef hist_plot(serie, titles=[\"Histogram\", \"Acumulative\"]):\n    fig = make_subplots(rows=1, cols=2, subplot_titles=titles)\n    fig.add_trace(\n        go.Histogram(x=serie), row=1, col=1,\n    )\n    fig.add_trace(\n        go.Histogram(x=serie, cumulative_enabled=True), row=1, col=2,\n    )\n    fig.show()\n\n\ndef remove_punct(my_str):\n    no_punct = \"\"\n    for char in my_str:\n        if char not in punctuation:\n            no_punct = no_punct + char\n    return no_punct\n\n\ndef tokenizer_column(serie):\n    clear_col = list()\n    for row in serie:\n        new_line = list()\n        line = token_punct.tokenize(remove_punct(row.lower()))\n        for word in line:\n            if word not in stopwords:  # stopwords\n                new_line.append(stemmer.stem(word))\n        clear_col.append(\" \".join(new_line))\n    return clear_col\n\n\ndef wordcloud(text, column_name, title):\n    all_words = \" \".join([text for text in text[column_name]])\n    wordcloud = WordCloud(\n        width=800, height=500, max_font_size=110, collocations=False\n    ).generate(all_words)\n    plt.figure(figsize=(24, 12))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## category_name\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column = train.category_name\nprint(\"How much NAN we have here?\", column.isna().sum())\nprint(\"How much categories we have here?\", len(column.unique()))\ntrain.category_name = train.category_name.fillna(\"no category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_value_counts(column, \"category_name\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_split_category_name(df):\n    aux = df[\"category_name\"].str.split(\"/\", n=2, expand=True)\n    for i in [0, 1, 2]:\n        df[\"category_name_\" + str(i)] = aux[i]\n        df[\"category_name_\" + str(i)].fillna(\"No category\", inplace=True)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_split_category_name(train)\nplot_value_counts(train.category_name_0, \"category_name_0\")\nplot_value_counts(train.category_name_1, \"category_name_1\")\nplot_value_counts(train.category_name_2, \"category_name_2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.category_name_0.isin([\"Electronics\"])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_value_counts(train.category_name_1, \"category_name_1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_value_counts(train.category_name_2, \"category_name_2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### name\n\nAnalysis the column name.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"column = train.name\nprint(\"How much NAN we have here?\", column.isna().sum())\nprint(\"How much categories we have here?\", len(column.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.name = tokenizer_column(train.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"plot_value_counts(column, \"name\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud(train, \"name\", \"Name wordcloud\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## item_description","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.item_description = tokenizer_column(train.item_description)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud(train, \"item_description\", \"Description wordcloud\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## item_condition_id\nCondition comes from 1 to 5","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"column = train.item_condition_id\nprint(\"How much NAN we have here?\", column.isna().sum())\nprint(\"How much categories we have here?\", len(column.unique()))\nplot_value_counts(column, \"item_condition_id\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like a kind of rank for product condition and 1 must be good and 5 must be bad.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## brand_name","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"column = train.brand_name\nprint(\"How much NAN we have here?\", column.isna().sum())\nprint(\"How much categories we have here?\", len(column.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting NaN as 'no brand' and puting all lower.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train.brand_name = train.brand_name.fillna(\"no brand\")\ntrain.brand_name = train.brand_name.str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"plot_value_counts(column.sample(10000), \"brand_name\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grouping the less popular brands  as 'other brand'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list_top_50_brand = train.brand_name.value_counts()[:51].index\nlist_top_50_brand","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"brands_column = []\nfor i, brand in enumerate(train.brand_name):\n    if not brand in list_top_50_brand:\n        brands_column.append(\"other brand\")\n    else:\n        brands_column.append(brand)\nbrands_column[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.brand_name = brands_column\nplot_value_counts(column.sample(10000), \"brand_name\", 52)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## price","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"column = train.price\nprint(\"How much NAN we have here?\", column.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing outlines using quantile as 0.98, 98%.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.price.isin([0]) == False]  # removing 0 prices\nroof = train.price.quantile(0.98)  # removing outlines\nprint(f\"removing values higher than {roof}\")\ntrain = train.query(f\"price < {roof}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"hist_plot(column.sample(10000))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Log transformation","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train[\"log_price\"] = np.log(train.price)\nhist_plot(train[\"log_price\"].sample(10000))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## shipping ","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"column = train.shipping\nprint(\"How much NAN we have here?\", column.isna().sum())\nprint(\"How much categories we have here?\", len(column.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"plot_value_counts(column.sample(10000), \"shipping\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EAD","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## item_condition_id","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### item_condition_id x price","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"px.box(train.sample(10000), x=\"item_condition_id\", y=\"price\", color='item_condition_id',title=\"Price boxplot by condition id\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"table = train.groupby(\"item_condition_id\")[\"price\"].describe().round(3)\nff.create_table(table, height_constant=40, index=True, index_title=\"item_condition_id\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### item_condition_id x shipping","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# 1 means free ship for the customer\n# 0 means the customer have to pay the ship\n\ntable = train.groupby(\"item_condition_id\")[\"shipping\"].describe()[[\"count\", \"mean\"]]\ntable[\"free ship in %\"] = table[\"mean\"].round(3) * 100\ntable[\"not free ship in %\"] = 100 - (table[\"mean\"].round(3) * 100)\nff.create_table(\n    table.round(3), height_constant=40, index=True, index_title=\"item_condition_id\"\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More than 70% items on item condition id equals to 1 are free ship.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### item_condition_id x category_name (category_name_0~1)","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"most_popular_categories = train.category_name.value_counts()[:30].index\n\n\ndef count_cond_cat(id_v):\n    aux = train[\n        train.item_condition_id.isin([id_v])\n        & train.category_name.isin(most_popular_categories)\n    ]\n    aux = aux.category_name_0.value_counts()\n    x = aux.index\n    y = aux.values\n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"fig = go.Figure()\n\nx, y = count_cond_cat(1)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 1\"))\n\nx, y = count_cond_cat(2)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 2\"))\n\nx, y = count_cond_cat(3)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 3\"))\n\nx, y = count_cond_cat(4)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 4\"))\n\nx, y = count_cond_cat(5)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 5\"))\n\nfig.update_layout(\n    title=\"Comparative item_condition by most popular categories in our dataset\",\n    xaxis_tickfont_size=14,\n    yaxis=dict(title=\"count\", titlefont_size=16, tickfont_size=14,),\n    legend=dict(\n        bgcolor=\"rgba(255, 255, 255, 0)\", bordercolor=\"rgba(255, 255, 255, 0)\",\n    ),\n    barmode=\"group\",\n    bargap=0.15,  # gap between bars of adjacent location coordinates.\n    bargroupgap=0.1,  # gap between bars of the same location coordinate.\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### item_condition_id x brand_name\n\nFilltering the brands by 30 most popular.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"most_popular_categories = train.brand_name.value_counts()[\n    :30\n].index  # skipping the most popular: 'No brand' hahaha\n\n\ndef count_brand_cat(id_v):\n    aux = train[\n        train.item_condition_id.isin([id_v])\n        & train.brand_name.isin(most_popular_categories)\n    ]\n    aux = aux.brand_name.value_counts()\n    x = aux.index\n    y = aux.values\n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"fig = go.Figure()\n\nx, y = count_brand_cat(1)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 1\"))\n\nx, y = count_brand_cat(2)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 2\"))\n\nx, y = count_brand_cat(3)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 3\"))\n\nx, y = count_brand_cat(4)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 4\"))\n\nx, y = count_brand_cat(5)\nfig.add_trace(go.Bar(x=x, y=y, name=\"item_condition_id = 5\"))\n\nfig.update_layout(\n    title=\"Comparative brand_name by most popular categories in our dataset\",\n    xaxis_tickfont_size=14,\n    yaxis=dict(title=\"count\", titlefont_size=16, tickfont_size=14,),\n    legend=dict(\n        bgcolor=\"rgba(255, 255, 255, 0)\", bordercolor=\"rgba(255, 255, 255, 0)\",\n    ),\n    barmode=\"group\",\n    bargap=0.15,  # gap between bars of adjacent location coordinates.\n    bargroupgap=0.1,  # gap between bars of the same location coordinate.\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### price x brand","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To plot the real price value, we must remove the outline, that means filter the values using the roof.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"roof = train.price.quantile(0.95)\npx.box(\n    train.query(f\"price < {roof}\").sample(10000),\n    x=\"brand_name\",\n    y=\"price\",\n    color=\"brand_name\",\n    title=\"Price boxplot by brand_name\",\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"px.box(\n    train.sample(10000),\n    x=\"brand_name\",\n    y=\"log_price\",\n    color=\"brand_name\",\n    title=\"Price boxplot by brand_name with log transformation\",\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The data is too large, because this I'll reduce until 50k.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train = train.sample(10000)\ntrain.reset_index(inplace=True, drop=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Building function to help in train and spit.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom sklearn.linear_model import (\n    BayesianRidge,\n    SGDRegressor,\n)\n\n# split the dataset beteween train and test\ndef split(x, y, plot=False):\n    # seed\n    # train_test_split\n    train_x, test_x, train_y, test_y = train_test_split(\n        x, y, test_size=0.1, random_state=42367,\n    )\n    if plot:\n        print(\n            \"sizes: train (x,y) and test (x,y)\",\n            train_x.shape,\n            train_y.shape,\n            test_x.shape,\n            test_y.shape,\n        )\n    return train_x, test_x, train_y, test_y\n\n\n# Just train and valid the model\ndef run_reg_linear(train_x, test_x, train_y, test_y, model, plot=False):\n    model.fit(train_x, train_y)\n    test_pred = model.predict(test_x)\n\n    mse = mean_squared_error(test_y, test_pred)\n    mae = mean_absolute_error(test_y, test_pred)\n    r2 = r2_score(test_y, test_pred)\n\n    if plot:\n        print(\"*\" * 40)\n        print(\"r2 score\", r2)\n        print(\"mse\", mse)\n        print(\"mae\", mae)\n        print(\"*\" * 40)\n\n    return r2, mse\n\n\n# Train with all models then return a table with scores\ndef train_test_show(train_x, test_x, train_y, test_y):\n    valores = []\n    models = [\n        (\"BayesianRidge\", BayesianRidge()),\n        (\"MLPRegressor\", MLPRegressor()),\n        (\"SGDRegressor\", SGDRegressor()),\n        (\"RandomForestRegressor\", RandomForestRegressor(n_jobs=-1)),\n    ]\n    for model in models:\n        print(model[0])\n        valores.append(\n            (model[0], *run_reg_linear(train_x, test_x, train_y, test_y, model[1]))\n        )\n    valores = pd.DataFrame(valores, columns=[\"Model\", \"R2\", \"MSE\"])\n    return valores.style.background_gradient(cmap=\"Reds\", low=0, high=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data aproach's\n\nTokenize the name using TfidfVectorizer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_extraction.text import TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### OneHotEncoder\nOneHotEncoder to get our dummies for both column: name and item_description. \n\nUsing TfidfVectorizer to process the text data and get dummies.\n\nAt least PCA will reduce our dimensionality util 200 features.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"enc = OneHotEncoder()\npca = PCA(n_components=200)\nvectorizer = TfidfVectorizer(\n    max_features=50000,\n    min_df=10,\n    ngram_range=(1, 3),\n    analyzer=\"word\",\n    stop_words=\"english\",\n)\n\n\nX_ohe = pca.fit_transform(\n    np.concatenate(\n        (\n            vectorizer.fit_transform(train[\"name\"]).toarray(),\n            vectorizer.fit_transform(train[\"item_description\"]).toarray(),\n            vectorizer.fit_transform(train[\"name\"]).toarray(),\n            enc.fit_transform(\n                train[\n                    [\n                        \"brand_name\",\n                        # \"category_name_0\",\n                        \"category_name_1\",\n                        \"category_name_2\",\n                        \"shipping\",\n                        \"item_condition_id\",\n                    ]\n                ].values\n            ).toarray(),\n        ),\n        axis=1,\n    )\n)\nY_ohe = train.log_price\n\nprint(\"X shape ->\", X_ohe.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_x_ohe, test_x_ohe, train_y_ohe, test_y_ohe = split(X_ohe, Y_ohe, True)\n\ntrain_test_show(train_x_ohe, test_x_ohe, train_y_ohe, test_y_ohe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LabelEncoder\n\nUsing all columns with Label encoder.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"enc = LabelEncoder()\ntrain_values = train[\n    [\n        \"name\",\n        \"brand_name\",\n        \"category_name_0\",\n        \"category_name_1\",\n        \"category_name_2\",\n        \"shipping\",\n        \"item_condition_id\",\n        \"item_description\",\n    ]\n]\n\n\nfor col in train_values.columns:\n    train_values[col] = enc.fit_transform(train_values[col])\n\nX_le = train_values.values\nY_le = train.log_price.values\nprint(\"X shape ->\", X_le.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"%%time\n\ntrain_x_le, test_x_le, train_y_le, test_y_le = split(X_le, Y_le, True)\n\ntrain_test_show(train_x_le, test_x_le, train_y_le, test_y_le)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LabelEncoder Standard\n\nUsing all columns with LabelEncoder + StandardScaler.","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"enc = LabelEncoder()\nscaler = StandardScaler()\n\ntrain_values = train[\n    [\n        \"name\",\n        \"brand_name\",\n        \"category_name_0\",\n        \"category_name_1\",\n        \"category_name_2\",\n        \"shipping\",\n        \"item_condition_id\",\n        \"item_description\",\n    ]\n]\n\n\nfor col in train_values.columns:\n    train_values[col] = scaler.fit_transform(\n        enc.fit_transform(train_values[col]).reshape(-1, 1)\n    )\n\nX_le_sc = train_values.values\nY_le_sc = train.log_price.values\nprint(\"X shape ->\", X_le_sc.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"%%time\n\ntrain_x_le_sc, test_x_le_sc, train_y_le_sc, test_y_le_sc = split(X_le_sc, Y_le_sc, True)\n\ntrain_test_show(train_x_le_sc, test_x_le_sc, train_y_le_sc, test_y_le_sc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RandomForestRegressor\n\nBoosting this model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nimport numpy as np\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start=10, stop=100, num=10)]\n# Number of features to consider at every split\nmax_features = [\"auto\", \"sqrt\"]\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num=11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {\n    \"n_estimators\": n_estimators,\n    \"max_features\": max_features,\n    \"max_depth\": max_depth,\n    \"min_samples_split\": min_samples_split,\n    \"min_samples_leaf\": min_samples_leaf,\n    \"bootstrap\": bootstrap,\n}\n\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestRegressor()\n# Random search of parameters, using 3 fold cross validation,\n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(\n    estimator=rf,\n    param_distributions=random_grid,\n    n_iter=50,\n    cv=3,\n    verbose=2,\n    random_state=42,\n    n_jobs=-1,\n)\n# Fit the random search model\nrf_random.fit(\n   X_ohe, Y_ohe\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot-outputs\nmodel = RandomForestRegressor(\n    n_estimators=80,\n    min_samples_split=2,\n    min_samples_leaf=4,\n    max_features=\"sqrt\",\n    max_depth=10,\n    bootstrap=True,\n)\n\nmodel.fit(train_x_ohe, train_y_ohe)\ny_predict = model.predict(test_x_ohe)\n\nprint(\"MSE: \", mean_squared_error(test_y_ohe, y_predict))\nprint(\"R2: \", r2_score(test_y_ohe, y_predict))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}