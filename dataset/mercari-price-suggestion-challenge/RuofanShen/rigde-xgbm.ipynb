{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","file_extension":".py","version":"3.6.3","nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python"}},"nbformat":4,"cells":[{"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv\nimport matplotlib.pyplot as plt\nimport re\n# Evalaluation\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nimport scipy\nimport lightgbm as lgb\nfrom sklearn.linear_model import Ridge\nimport time\nimport gc\nfrom scipy.sparse import csr_matrix, hstack\nget_ipython().magic('pylab inline')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\ndf = pd.read_csv(\"../input/train.tsv\", delimiter='\\t')\ntest = pd.read_csv(\"../input/test.tsv\", delimiter='\\t')\nY = df['price']\ntrain_test_split = df.shape[0]\nbrand = dict()\n\nfor i in range(len(df['brand_name'])):\n    if(not pd.isnull(df['brand_name'][i])):\n        if (df['brand_name'][i] not in brand):\n            brand[df['brand_name'][i]] = []\n        brand[df['brand_name'][i]].append(np.log1p(df['price'][i]))\n        \ndel df['price']\ndel df['train_id']\ndel test['test_id']\ndf = pd.concat([df,test])\ndf = df.reset_index(drop=True)\nsplit_str = df[\"category_name\"].str.split(\"/\", expand=True, n=2)\nsplit_str.columns = [\"cat1\", \"cat2\", \"cat3\"]\nsplit_str[\"cat2\"][split_str[\"cat2\"].isnull()] = -1\nsplit_str[\"cat3\"][split_str[\"cat3\"].isnull()] = -1\ndf[\"category1\"] = df[\"category_name\"]\ndf[\"category2\"] = split_str[\"cat2\"]\ndf[\"category3\"] = split_str[\"cat3\"]\ndf[\"category1\"][df[\"category1\"].isnull()] = -1\ndf.drop(['category_name'], axis=1, inplace=True)\ndf\n\navg_col = []\nvar_col = []\navg_dict = {}\nvar_dict = {}\nfor i in range(len(df['brand_name'])):\n    if pd.isnull(df['brand_name'][i]):\n        avg_col.append(0)\n        var_col.append(0)\n    else:\n        name = df['brand_name'][i]\n        if name not in avg_dict:\n            if name not in brand:\n                avg_col.append(0)\n                var_col.append(0)\n                continue\n            priceList = brand[name]\n            avg_dict[name] = np.mean(priceList)\n            var_dict[name] = np.var(priceList)\n        avg_col.append(avg_dict[name])\n        var_col.append(var_dict[name])\nprint(len(avg_col), len(var_col))\n\ndf[\"brand_avg\"] = avg_col\ndf[\"brand_var\"] = var_col\ndf[\"brand_name\"] = pd.Categorical(df[\"brand_name\"])\ndf[\"brand_code\"] = df.brand_name.cat.codes\n\ndef change_to_code(colName, df):\n    df[colName] = pd.Categorical(df[colName])\n    df[colName+\"_code\"] = df[colName].cat.codes\nfor category in [\"category1\", \"category2\", \"category3\"]:\n    change_to_code(category, df)\n    \ndf['name'] = df['name'].fillna('missing')\ndf['item_description'] = df['item_description'].fillna('missing')\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\ncount = CountVectorizer(min_df=10)\nX_name = count.fit_transform(df[\"name\"])\n\ncount_descp = TfidfVectorizer(max_features = 20000, \n                              ngram_range = (1,3),\n                              stop_words = \"english\")\nX_descp = count_descp.fit_transform(df[\"item_description\"])\ndel df['name']\ndel df['item_description']\ndel df['brand_name']\ndel df['category1']\ndel df['category2']\ndel df['category3']\nimport scipy\nitem_condition_dummy = pd.get_dummies(df['item_condition_id'])\nitem_condition_dummy.columns = [\"c1\", \"c2\", \"c3\", \"c4\", \"c5\"]\ndf = pd.concat([df, item_condition_dummy], axis=1)\ndel df['item_condition_id']\nY = np.log1p(Y)\nprint(df)\nsparse_matrix = scipy.sparse.csr_matrix(df.values)\nX = scipy.sparse.hstack((sparse_matrix, \n                         X_descp,\n                         X_name)).tocsr()\n\nprint(X.shape)\ntrain_test_split = 1482535\ntrain_X = X[:train_test_split]\ntest_X = X[train_test_split:]\n\ntest = pd.read_csv(\"test.tsv\", delimiter='\\t')\nsubmission: pd.DataFrame = test[['test_id']]\ndef trainAndTest(X_train, Y_train, X_test):\n    \n    model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3)\n    model.fit(X_train, Y_train)\n    predsR = model.predict(X=X_test)\n    print('Predict ridge completed')\n    \n    model = Ridge(solver=\"auto\", fit_intercept=True, random_state=144, alpha=3)\n    model.fit(X_train, Y_train)\n    predsR2 = model.predict(X=X_test)\n    print('Predict ridge 2 completed.')\n    \n    X_train_train, X_train_valid, Y_train_train, Y_train_valid = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 144) \n    d_train = lgb.Dataset(X_train_train, label=Y_train_train, max_bin=8192)\n    d_valid = lgb.Dataset(X_train_valid, label=Y_train_valid, max_bin=8192)\n    watchlist = [d_train, d_valid]\n    \n    params = {\n        'learning_rate': 0.65,\n        'application': 'regression',\n        'max_depth': 3,\n        'num_leaves': 60,\n        'verbosity': -1,\n        'metric': 'RMSE',\n        'data_random_seed': 1,\n        'bagging_fraction': 0.5,\n        'nthread': 4\n    }\n\n    params2 = {\n        'learning_rate': 0.85,\n        'application': 'regression',\n        'max_depth': 3,\n        'num_leaves': 140,\n        'verbosity': -1,\n        'metric': 'RMSE',\n        'data_random_seed': 2,\n        'bagging_fraction': 1,\n        'nthread': 4\n    }\n    model = lgb.train(params, train_set=d_train, num_boost_round=8000, valid_sets=watchlist, \\\n    early_stopping_rounds=500, verbose_eval=500) \n    predsL = model.predict(X_test)\n    print('Finished to predict lgb 1')\n    X_train_train, X_train_valid, Y_train_train, Y_train_valid = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 101) \n    d_train2 = lgb.Dataset(X_train_train, label=Y_train_train, max_bin=8192)\n    d_valid2 = lgb.Dataset(X_train_valid, label=Y_train_valid, max_bin=8192)\n    watchlist2 = [d_train2, d_valid2]\n    \n    model = lgb.train(params2, train_set=d_train2, num_boost_round=4000, valid_sets=watchlist2, \\\n    early_stopping_rounds=500, verbose_eval=500) \n    predsL2 = model.predict(X_test)\n    print('Finished to predict lgb 2')\n    \n#     preds = predsR2*0.20 + predsR*0.20 + predsL*0.40 + predsL2*0.20\n#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n    \n#     preds = predsR2*0.19 + predsR*0.19 + predsL*0.44 + predsL2*0.18\n#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n    \n#     preds = predsR2*0.18 + predsR*0.18 + predsL*0.45 + predsL2*0.19\n#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n    \n#     preds = predsR2*0.17 + predsR*0.17 + predsL*0.46 + predsL2*0.20\n#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n    \n    preds = predsR2*0.16 + predsR*0.16 + predsL*0.48 + predsL2*0.20\n    submission['price'] = np.expm1(preds)\n    submission.to_csv(\"submission.csv\", index=False)\n#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n\nfrom sklearn.model_selection import train_test_split\ntrainAndTest(train_X, Y, test_X)\n# Any results you write to the current directory are saved as output.","cell_type":"code","metadata":{"_cell_guid":"8bd107a5-25f3-40a7-b779-ae8de8e2626b","_uuid":"178935477b05113e10509214e41ad4d392792a52"},"outputs":[]}],"nbformat_minor":1}