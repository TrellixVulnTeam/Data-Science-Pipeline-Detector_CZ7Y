{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Input,Dense ,Dropout\nimport numpy as np  \nimport pandas as pd\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.layers import Input,Dense,Dropout,LeakyReLU \nfrom tensorflow.keras.models import Sequential\nfrom matplotlib import pyplot as plt\nimport gc\nfrom sklearn.impute import SimpleImputer\nimport scipy.stats as spstats","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path=\"/kaggle/input/predict-volcanic-eruptions-ingv-oe/\"\ntest=pd.read_csv('/kaggle/input/predict-volcanic-eruptions-ingv-oe/sample_submission.csv')\ntrain=pd.read_csv('/kaggle/input/predict-volcanic-eruptions-ingv-oe/train.csv')\n\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_train=pd.read_csv('/kaggle/input/predict-volcanic-eruptions-ingv-oe/train/1004561781.csv')\nsample_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , axs = plt.subplots(nrows=2,ncols=5)\nfig.set_size_inches(50,7)\nfig.subplots_adjust(hspace=1)\n\nfor col,ax in zip(sample_train.columns, axs.flatten()):\n    ax.plot(range(len(sample_train[col])),sample_train[col])\n    ax.set_title(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"code","source":"def extract(dir_=\"train\"):\n    \n    if dir_==\"train\":\n        data=pd.read_csv(\"/kaggle/input/predict-volcanic-eruptions-ingv-oe/train.csv\")\n    elif dir_==\"test\":\n        data=pd.read_csv(\"/kaggle/input/predict-volcanic-eruptions-ingv-oe/sample_submission.csv\")\n    else:\n        raise KeyError(\"noob\")\n        \n    i=0\n    \n    for seg_id in data['segment_id']:\n        \n        f = pd.read_csv(f\"/kaggle/input/predict-volcanic-eruptions-ingv-oe/{dir_}/{seg_id}.csv\")\n\n        # Fill NaN\n        f.interpolate(axis=0,inplace=True)\n\n\n        for sensor in f.columns:\n\n            data.loc[i:i+1,f'{sensor}_mean']=f[f'{sensor}'].mean(axis=0)\n            data.loc[i,f'{sensor}_std']=f[f'{sensor}'].std(axis=0)\n            data.loc[i,f'{sensor}_max']=f[f'{sensor}'].max(axis=0)\n            data.loc[i,f'{sensor}_min']=f[f'{sensor}'].min(axis=0)\n            data.loc[i,f'{sensor}_mad']=f[f'{sensor}'].mad(axis=0)\n            data.loc[i,f'{sensor}_skew']=f[f'{sensor}'].skew(axis=0)\n            data.loc[i,f'{sensor}_kurt']=f[f'{sensor}'].kurt(axis=0)\n            data.loc[i,f'{sensor}_var']=f[f'{sensor}'].var(axis=0)\n            data.loc[i,f'{sensor}_median']=f[f'{sensor}'].median(axis=0)\n\n            data.loc[i,f'{sensor}_nunique']=f[f'{sensor}'].nunique()\n\n            data.loc[i,f'{sensor}_q005'] = f[f'{sensor}'].quantile(0.05)\n            data.loc[i,f'{sensor}_q010'] = f[f'{sensor}'].quantile(0.1 )\n            data.loc[i,f'{sensor}_q030'] = f[f'{sensor}'].quantile(0.3 )\n            data.loc[i,f'{sensor}_q070'] = f[f'{sensor}'].quantile(0.7 )\n            data.loc[i,f'{sensor}_q090'] = f[f'{sensor}'].quantile(0.9 )\n            data.loc[i,f'{sensor}_q095'] = f[f'{sensor}'].quantile(0.95)\n            data.loc[i,f'{sensor}_q999'] = f[f'{sensor}'].quantile(0.999)\n            data.loc[i,f'{sensor}_q87'] = f[f'{sensor}'].quantile(0.8)\n            data.loc[i,f'{sensor}_q13'] = f[f'{sensor}'].quantile(0.13)  \n            data.loc[i,f'{sensor}_q01'] = f[f'{sensor}'].quantile(0.01)\n            data.loc[i,f'{sensor}_q001'] = f[f'{sensor}'].quantile(0.001)\n\n            #f[f'{sensor}_pctchange'e(f[f'{sensor}]).pct_change(period=)\n            #f[f'{sensor}_pctchange']=pd.DataFrame(f[f'{sensor}']).pct_change(period=)\n            #f[f'{sensor}_pctchange']=pd.DataFrame(f[f'{sensor}']).pct_change(period=)\n            #f[f'{sensor}_pctchange']=pd.DataFrame(f[f'{sensor}']).pct_change(period=)\n           # data.iloc[i,[f'{sensor}_pctchange']=pd.DataFrame(f[f'{sensor}']).pct_change(period=)\n\n            x_abs=np.abs(f[f'{sensor}'])\n            data.loc[i,f'{sensor}_q999_abs'] = np.quantile(x_abs, 0.999)\n            data.loc[i,f'{sensor}_q99_abs']  = np.quantile(x_abs, 0.99)\n            data.loc[i,f'{sensor}_q95_abs']  = np.quantile(x_abs, 0.95)\n            data.loc[i,f'{sensor}_q87_abs']  = np.quantile(x_abs, 0.87)\n            data.loc[i,f'{sensor}_q13_abs']  = np.quantile(x_abs, 0.13)\n            data.loc[i,f'{sensor}_q05_abs']  = np.quantile(x_abs, 0.05)\n            data.loc[i,f'{sensor}_q01_abs']  = np.quantile(x_abs, 0.01)\n            data.loc[i,f'{sensor}_q001_abs'] = np.quantile(x_abs, 0.001)\n\n            z = np.fft.fft(f[f'{sensor}'].fillna(0))\n            fft_real = np.real(z)\n            fft_imag = np.imag(z)\n            data.loc[i,f'{sensor}_fft_real_mean'] = fft_real.mean()\n            data.loc[i,f'{sensor}_fft_real_std']  = fft_real.std()\n            data.loc[i,f'{sensor}_fft_real_max']= fft_real.max()\n            data.loc[i,f'{sensor}_fft_real_min']= fft_real.min()\n            data.loc[i,f'{sensor}_fft_real_median'] = np.median(fft_real)\n            data.loc[i,f'{sensor}_fft_real_skew'] = spstats.skew(fft_real)\n            data.loc[i,f'{sensor}_fft_real_kurtosis']= spstats.kurtosis(fft_real)\n\n            data.loc[i,f'{sensor}_fft_imag_mean'] = fft_imag.mean()\n            data.loc[i,f'{sensor}_fft_imag_std']= fft_imag.std()\n            data.loc[i,f'{sensor}_fft_imag_max'] = fft_imag.max()\n            data.loc[i,f'{sensor}_fft_imag_min'] = fft_imag.min()\n            data.loc[i,f'{sensor}_fft_imag_median']= np.median(fft_imag)\n            data.loc[i,f'{sensor}_fft_imag_skew'] = spstats.skew(fft_imag)\n            data.loc[i,f'{sensor}_fft_imag_kurtosis']= spstats.kurtosis(fft_imag)\n\n            #roll = f.rolling(300)\n            #roll_300_mean = roll.mean()\n            #roll_300_max = roll.max()\n            #roll_300_min = roll.min()\n            #roll_300_dist = roll_300_max - roll_300_min\n            #roll_300_dist_diff =roll_300_dist.diff()\n\n            #data.loc[i,f'{sensor}_roll_300_dist_min']=roll_300_dist.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_dist_max']=roll_300_dist.max(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_dist_diff_max']=roll_300_dist_diff.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_dist_diff_min']=roll_300_dist_diff.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_mean_min']=roll_300_dist.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_300_mean_max']=roll_300_dist.max(axis=0)\n\n\n            #roll = f.rolling(3000)\n            #roll_3000_mean = roll.mean()\n            #roll_3000_max = roll.max()\n            #roll_3000_min = roll.min()\n            #roll_3000_dist = roll_3000_max - roll_3000_min\n            #roll_3000_dist_diff = roll_3000_dist.diff()\n\n            #data.loc[i,f'{sensor}_roll_3000_dist_max']=roll_3000_dist.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_dist_min']=roll_3000_dist.max(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_dist_diff_max']=roll_3000_dist_diff.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_dist_diff_min']=roll_3000_dist_diff.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_mean_min']=roll_300_mean.min(axis=0)\n            #data.loc[i,f'{sensor}_roll_3000_mean_max']=roll_300_mean.max(axis=0)\n        i+=1\n    data.fillna(0)\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=pd.read_csv('/kaggle/input/volcaniceruptiondatasets/train_data.csv')\ntrain_data=train_data.iloc[:,1:]\ntrain_data.fillna(0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test=pd.read_csv('/kaggle/input/volcaniceruptiondatasets/test_data.csv')\nX_test.drop([\"time_to_eruption\"],axis=1,inplace=True)\nX_test.fillna(0,inplace=True)\nX_test=X_test.iloc[:,2:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#imputer=SimpleImputer(strategy=\"mean\")\n#pd.DataFrame(imputer.fit_transform(train_data.iloc[:,2:]))\n#test_data_imp=pd.DataFrame(imputer.fit_transform(test_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features Scaling","metadata":{}},{"cell_type":"code","source":"features = list(train_data.drop([\"segment_id\", \"time_to_eruption\"], axis=1).columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler=StandardScaler()\nscaler.fit(train_data[features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[features]=pd.DataFrame(scaler.transform(train_data[features]))\nX_test=scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=train_data[features]\ny_train=train_data[\"time_to_eruption\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgbm\ntarget_name = [\"time_to_eruption\"]\n\nsub_preds = np.zeros(X_test.shape[0])\n\nmodel = lgbm.LGBMRegressor(n_estimators=3000,metric=\"mse\",num_leaves=400,random_state=42,max_bins=3000)\n\nmodel.fit(X_train, y_train, eval_set= [(X_train, y_train)], eval_metric=\"mae\", verbose=12)\n\nsub_preds += model.predict(X_test)","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"bruh dw ik that i overfitted","metadata":{}},{"cell_type":"markdown","source":":D","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['segment_id'] = test[\"segment_id\"]\nsubmission['time_to_eruption'] = sub_preds\nsubmission.to_csv('submission.csv', header=True, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}