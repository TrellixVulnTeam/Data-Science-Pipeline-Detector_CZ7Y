{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import rcParams\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, r2_score, mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        # print(os.path.join(dirname, filename))\n        # x = filename.replace('.csv','')\n        # print(f'File:{filename}')\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### File paths"},{"metadata":{"trusted":true},"cell_type":"code","source":"# path for train data - segments\nfile_path_train_segments = '/kaggle/input/predict-volcanic-eruptions-ingv-oe/train/'\n# path for test data - segments\nfile_path_test_segments = '/kaggle/input/predict-volcanic-eruptions-ingv-oe/test/'\n# path for train data with label\ntrain_data_path = '/kaggle/input/predict-volcanic-eruptions-ingv-oe/train.csv'\n# path for saample submission\nsample_submissioin_path = '/kaggle/input/predict-volcanic-eruptions-ingv-oe/sample_submission.csv'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis [EDA]"},{"metadata":{},"cell_type":"markdown","source":"### Load train.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the train.csv\ntrain_data = pd.read_csv(train_data_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Perform basic checks"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape :',train_data.shape)\nprint('Missing data:')\nprint(train_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = [15,4]\ntrain_data.time_to_eruption.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistics data\ntrain_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a graph\n\ndef plot_graph(df, features):\n\n    rcParams['figure.figsize'] = [15,5]\n    for cols in features:\n        df.iloc[0:100][cols].plot()\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_org  = ['sensor_1','sensor_2','sensor_3','sensor_4','sensor_5',\n                    'sensor_6','sensor_7','sensor_8','sensor_9','sensor_10']\ncols_rms  = ['sensor_1_rms','sensor_2_rms','sensor_3_rms','sensor_4_rms','sensor_5_rms',\n                    'sensor_6_rms','sensor_7_rms','sensor_8_rms','sensor_9_rms','sensor_10_rms']\ncols_mean  = ['sensor_1_mean','sensor_2_mean','sensor_3_mean','sensor_4_mean','sensor_5_mean',\n                    'sensor_6_mean','sensor_7_mean','sensor_8_mean','sensor_9_mean','sensor_10_mean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load one train data segment[ 1136037770 ]\ntrain_data_segments = pd.read_csv('/kaggle/input/predict-volcanic-eruptions-ingv-oe/train/1136037770.csv')\nplot_graph(train_data_segments, cols_org)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load train/test CSV data\n\ndef load_train_csv(file_path, filename, df):\n        \n        input_data = pd.read_csv(file_path+str(filename)+'.csv')\n        \n        total_count = input_data.shape[0]\n        \n        for cols in input_data.columns:\n            \n            df.loc[df['segment_id']== filename, cols+'_rms'] = \\\n            np.sqrt(np.sum(input_data[cols].apply(lambda x: x**2)) / total_count)\n            \n            df.loc[df['segment_id']== filename, cols+'_mean'] = input_data[cols].mean()\n            \n        return()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import datetime as dt\nprint('Started at : ', dt.datetime.now().time())\n\ni = 0\n\n# for idx, cols in train_data.iterrows():\n    \n    filename = int(cols['segment_id'])\n    \n    # load_train_csv(file_path_train_segments, filename, train_data)\n    \n    i += 1\n    \n    if i%500 == 0:\n        print(i,' -> processed')\n\nprint('Finished at : ', dt.datetime.now().time())\n\n# train_data.to_csv('train_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the file\ntrain_data.to_csv('train_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Line plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_graph(train_data, cols_rms)\nplot_graph(train_data, cols_mean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Boxplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.boxplot(cols_rms)\nplt.show()\ntrain_data.boxplot(cols_mean)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot graph : Time to eruption vs Sensor data [ RMS and Mean ]"},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = [15,4]\nfor cols in cols_rms:\n    sns.scatterplot(cols,'time_to_eruption', data=train_data)\nplt.show()\nfor cols in cols_mean:\n    sns.scatterplot(cols,'time_to_eruption', data=train_data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check on linear relationship between Time to eruption and sensor data [ RMS ]"},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = [15,5]\n\nfig, ax = plt.subplots(2,5)\n\ni = 0\n\nfor cols in cols_rms:\n    if i<5:\n        row = 0\n    else:\n        row = 1\n    col = i%5\n    \n    i += 1\n    ax[row][col].plot(cols,'time_to_eruption','+', data=train_data)\n    ax[row][col].set_xlabel(cols)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check on linear relationship between Time to eruption and sensor data [ Mean ]"},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = [15,5]\n\nfig, ax = plt.subplots(2,5)\n\ni = 0\n\nfor cols in cols_mean:\n    if i<5:\n        row = 0\n    else:\n        row = 1\n    col = i%5\n    \n    i += 1\n    ax[row][col].plot(cols,'time_to_eruption','+', data=train_data)\n    ax[row][col].set_xlabel(cols)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_data.time_to_eruption\nX = train_data[cols_rms]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scale the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# X = StandardScaler().fit_transform(X) \nX = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_xgb = XGBRegressor(random_state=15,\n                        learning_rate = 0.1,\n                        n_estimators = 1200,\n                        reg_lambda = 6,\n                        reg_alpha = 80,\n                        max_depth = 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cross validate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_score = cross_val_score(model_xgb, X_train, y_train, cv=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Scores  : ', xgb_score)\nprint('Average : ', xgb_score.mean())\nprint('STD     : ', xgb_score.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_xgb.fit(X_train, y_train,\n          eval_metric = \"mae\",\n          verbose     = False ,\n          early_stopping_rounds = 100,\n          eval_set=[(X_train, y_train), (X_test,y_test)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model learning curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = [5,4]\nresults = model_xgb.evals_result()\nepoch = len(results['validation_0']['mae'])\nx_axes = range(0,epoch)\nplt.plot(x_axes,results['validation_0']['mae'], label='Training')\nplt.plot(x_axes,results['validation_1']['mae'], label='Validation')\nplt.legend()\nplt.ylabel(\"mae\")\nplt.xlabel(\"Estimators\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_xgb.best_ntree_limit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = model_xgb.predict(X_test)\nprint(f'R2 Score : {r2_score(y_test, y_predict)*100}')\nprint(f'MAE      : {mean_absolute_error(y_test,y_predict)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = [15,4]\nplt.plot(range(y_test.shape[0]), y_test)\nplt.show()\nplt.plot(range(y_test.shape[0]), y_predict)\nplt.show()\nplt.plot(range(y_test.shape[0]), abs(y_test - y_predict))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparation for sample submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submissioin_data = pd.read_csv(sample_submissioin_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import datetime as dt\n\nprint('Started at : ', dt.datetime.now().time())\ni = 0\n# for idx, cols in sample_submissioin_data.iterrows():\n    \n    filename = int(cols['segment_id'])\n    \n    # load_train_csv(file_path_test_segments, filename, sample_submissioin_data)\n    \n    #i += 1\n    #if i % 500 == 0:\n    #    print(i, '-> processed')\n    \nprint('Finished at : ', dt.datetime.now().time())\n# sample_submissioin_data.to_csv('sample_submissioin_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = [15,4]\nfor cols in cols_rms:\n    sns.scatterplot(range(sample_submissioin_data.shape[0]), cols, data=sample_submissioin_data)\nplt.show()\nfor cols in cols_mean:\n    sns.scatterplot(range(sample_submissioin_data.shape[0]), cols, data=sample_submissioin_data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = [15,5]\n\nfig, ax = plt.subplots(2,5)\n\ni = 0\n\nfor cols in cols_rms:\n    if i<5:\n        row = 0\n    else:\n        row = 1\n    col = i%5\n    \n    i += 1\n    ax[row][col].plot(range(sample_submissioin_data.shape[0]),cols,'+', c='y', data=sample_submissioin_data)\n    ax[row][col].set_xlabel(cols)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test_data = sample_submissioin_data[cols_rms]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test_predict = model_xgb.predict(sample_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submissioin = pd.DataFrame({'segment_id' : sample_submissioin_data.segment_id, 'time_to_eruption':sample_test_predict})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Write to a file"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submissioin.to_csv('sample_submissioin.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}