{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom scipy.stats import entropy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"ref_df=pd.read_csv('../input/predict-volcanic-eruptions-ingv-oe/train.csv')\nprint(ref_df.isna().sum().sum())\nref_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For test set and submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub=pd.read_csv('../input/predict-volcanic-eruptions-ingv-oe/sample_submission.csv')\nprint(sample_sub.isna().sum().sum())\nsample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"%%time\nmissings=pd.DataFrame()\nfor seg_id in ref_df['segment_id']:\n    df=pd.read_csv(f'../input/predict-volcanic-eruptions-ingv-oe/train/{seg_id}.csv')\n    missings=missings.append(pd.DataFrame(df.isna().sum()).T)\n    \n    \nmissings.set_index(ref_df['segment_id'],inplace=True)\nprint(missings.head())\nplt.figure(figsize=(15,25))\nsns.heatmap(missings,cmap = 'magma_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making new train set"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"%%time\n\ntrain=pd.DataFrame()\nfor seg_id in ref_df['segment_id']:\n    df=pd.read_csv(f'../input/predict-volcanic-eruptions-ingv-oe/train/{seg_id}.csv')\n    #print(df.isna().sum())\n    for col in df.columns:\n        if df[col].isna().sum()==len(df):\n            df[col].fillna(0,inplace=True)\n        else:\n            df[col].fillna(df[col].mean(),inplace=True)\n    #print(df.isna().sum())\n    #print(df.head())\n    summary=pd.DataFrame()\n    des=df.describe()\n    \n    # df describe statistics\n    for i in range(10):\n        col=pd.DataFrame(des.iloc[:,i][1:]).T.reset_index(drop=True)\n        summary=pd.concat([summary,col],axis=1)\n    \n    # skew statistics\n    stat=pd.DataFrame(df.skew().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    # mean absolute deviation statistics\n    stat=pd.DataFrame(df.mad().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    # standard error statistics\n    stat=pd.DataFrame(df.sem().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n\n    #print(summary)\n    \n    train=train.append(summary)\n    del summary, des, df\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### New Columns for better understading of both new train and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.columns=range(train.shape[1])\ntrain.set_index(ref_df['segment_id'].values,inplace=True)\nprint(train.shape)\ntrain.to_csv('train__.csv', index=False)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making new test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntest=pd.DataFrame()\nfor seg_id in sample_sub['segment_id']:\n    df=pd.read_csv(f'../input/predict-volcanic-eruptions-ingv-oe/test/{seg_id}.csv')\n    #print(df.isna().sum())\n    for col in df.columns:\n        if df[col].isna().sum()==len(df):\n            df[col].fillna(0,inplace=True)\n        else:\n            df[col].fillna(df[col].mean(),inplace=True)\n    #print(df.isna().sum())\n    #print(df.head())\n    summary=pd.DataFrame()\n    des=df.describe()\n\n    \n    for i in range(10):\n        col=pd.DataFrame(des.iloc[:,i][1:]).T.reset_index(drop=True)\n        summary=pd.concat([summary,col],axis=1)\n    \n    # skew statistics\n    stat=pd.DataFrame(df.skew().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    # mean absolute deviation statistics\n    stat=pd.DataFrame(df.mad().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    # standard error statistics\n    stat=pd.DataFrame(df.sem().values.reshape(1,-1))\n    summary=pd.concat([summary,stat],axis=1)\n    \n    #print(summary)\n    \n    test=test.append(summary)\n    del summary, des, df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)\ntest.columns=range(test.shape[1])\ntest.set_index(sample_sub['segment_id'].values,inplace=True)\nprint(test.shape)\ntest.to_csv('test__.csv', index=False)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train_df=pd.read_csv('./train__.csv')\ntest_df=pd.read_csv('./test__.csv')\nX=train_df.values\ny=ref_df['time_to_eruption']\nx_tr,x_ts,y_tr,y_ts=train_test_split(X,y,test_size=.25,random_state=40)\nx_tr.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=DecisionTreeRegressor()\nclf .fit(x_tr,y_tr)\npred=clf.predict(x_ts)\nprint('training mae: ',mae(y_tr,clf.predict(x_tr)))\nprint('testing mae: ',mae(y_ts,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams={'max_depth':range(13,18,3), 'min_samples_split':range(2,20,3), 'min_samples_leaf':range(1,20,4)}\nclf=DecisionTreeRegressor()\nclfcv=RandomizedSearchCV(clf,params,n_iter=1000,n_jobs=-1,random_state=10,return_train_score=True)\nclfcv.fit(x_tr,y_tr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train error: ',mae(y_tr,clfcv.best_estimator_.predict(x_tr)))\nprint('test error: ',mae(y_ts,clfcv.best_estimator_.predict(x_ts)))\nclfcv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_im=pd.DataFrame({'features':x_tr.columns,'importance':clfcv.best_estimator_.feature_importances_})\nfeat_im.sort_values(by='importance',inplace=True,ascending=False)\nplt.figure(figsize=(9,18))\nsns.barplot(y='features',x='importance',data=feat_im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=feat_im[feat_im['importance']>=.015]['features'].values\nx_tr_n=x_tr[columns]\nx_ts_n=x_ts[columns]\nx_tr_n.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams={'max_depth':range(13,18),'min_samples_split':range(2,20,3), 'min_samples_leaf':range(1,20,2)}\n        #'max_features':[\"auto\", \"sqrt\", \"log2\"]}\nclf=DecisionTreeRegressor()\nclfcv=GridSearchCV(clf,params,n_jobs=-1,cv=5)\nclfcv.fit(x_tr_n,y_tr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train error: ',mae(y_tr,clfcv.best_estimator_.predict(x_tr_n)))\nprint('test error: ',mae(y_ts,clfcv.best_estimator_.predict(x_ts_n)))\nclfcv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams={'max_depth':range(13,18),'min_samples_split':range(2,20,3), 'min_samples_leaf':range(1,20,2)}\nclf=RandomForestRegressor(n_estimators=15)\nclfcv=RandomizedSearchCV(clf,params,n_iter=100,n_jobs=-1,random_state=23,cv=10)\nclfcv.fit(x_tr_n,y_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train error: ',mae(y_tr,clfcv.best_estimator_.predict(x_tr_n)))\nprint('test error: ',mae(y_ts,clfcv.best_estimator_.predict(x_ts_n)))\nclfcv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# subfile\ntest_n=test[columns]\npred=clfcv.predict(test_n)\nsub_file['time_to_eruption']=pred\nsub_file.to_csv('sub.csv',index=False)\nsub_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}