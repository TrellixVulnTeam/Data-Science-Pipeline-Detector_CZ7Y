{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install colabcode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from colabcode import ColabCode\nColabCode(port = 10000, password = 'bluebrown')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport os\nimport pandas as pd\nimport numpy as np\n\nfrom joblib import Parallel, delayed\n\nimport xgboost as xgb\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npd.set_option('display.max_columns', None)\n\ntrain_csv_path = '../input/predict-volcanic-eruptions-ingv-oe/train/'\ntest_csv_path = '../input/predict-volcanic-eruptions-ingv-oe/test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_time = pd.read_csv('../input/predict-volcanic-eruptions-ingv-oe/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_csv(name, df, path):\n    fname = str(name) + '.csv'\n    return pd.read_csv(path + fname), df[df.segment_id == name].time_to_eruption.values[0]\n\n\n\ndef get_top_freq(df, n = 5):\n    top_freq = pd.DataFrame()\n    freq_col_names = ['freq_' + str(i+1) for i in range(n)]\n    sensor_col_names = ['sensor_' + str(i+1) for i in range(1, 11)]\n    \n    for i in df.columns:        \n        sf = len(df)\n        fft_val = np.fft.fft(df[i])\n        fft_theo = 2/sf * abs(fft_val)\n\n        freq = np.fft.fftfreq(len(df[i]))\n        freq_axis = sf/2 * np.linspace(0, 1, int(sf/2))\n\n        temp = pd.Series(data = fft_theo[0:len(freq_axis)], index = freq_axis)\n        temp = temp.nlargest(n).index.values\n        temp = pd.DataFrame(temp).T\n        temp.columns = freq_col_names\n        temp = temp.add_prefix(i + '_')\n        top_freq = pd.concat([top_freq, temp], axis = 1)\n    \n    return top_freq\n\n\n\ndef combine_data(df, meta_stats = True, freq = True, n = 5, pca = False):\n    out_df = pd.DataFrame()\n    col_names_for_percentiles = list(range(1, 11))\n    \n    for i in tqdm(df.segment_id):\n        empty = pd.DataFrame()\n        \n        eg, val = load_csv(i, train_time, train_csv_path)\n        eg = eg.fillna(0)\n        \n        if pca:\n            eg = pd.DataFrame(pca.fit_transform(eg))\n            eg.columns = col_names_for_percentiles\n            eg = eg.add_prefix('sensor_')\n        \n        if meta_stats:\n            # Mean, Min., Max., 25%. 75%, 90%, 95%, 99%, Std., Top n frequencies\n            temp = pd.DataFrame(eg.mean()).T\n            temp = temp.add_suffix('_mean')\n            empty = temp\n\n            temp = pd.DataFrame(eg.min()).T\n            temp = temp.add_suffix('_min')\n            empty = pd.concat([empty, temp], axis = 1)\n\n            temp = pd.DataFrame(eg.max()).T\n            temp = temp.add_suffix('_max')\n            empty = pd.concat([empty, temp], axis = 1)\n        \n            percentiles = [25, 75, 90, 95, 99]\n            for p in percentiles:\n                temp = pd.DataFrame(np.percentile(eg, q = p, axis = 0)).T\n                temp.columns = col_names_for_percentiles\n                temp = temp.add_prefix('sensor_')\n                temp = temp.add_suffix(f'_{p}%')\n                empty = pd.concat([empty, temp], axis = 1)\n        \n        if freq:\n            temp = get_top_freq(eg, n)\n            empty = pd.concat([empty, temp], axis = 1)\n        \n        out_df = pd.concat([out_df, empty], axis = 0)\n    return out_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = combine_data(train_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('./combined_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink('./combined_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('./combined_data.csv')\ndata.drop('Unnamed: 0', axis = 1, inplace = True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(data, train_time.time_to_eruption, test_size = 0.1, random_state = 0)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"p1 = {'n_estimators':range(260, 281, 5)}\n\nrforest = RandomForestRegressor(n_jobs = -1, random_state = 0)\n\ngrid = GridSearchCV(rforest, p1, cv = 5, n_jobs = -1, scoring = 'neg_mean_absolute_error')\n\ngrid.fit(data, train_time.time_to_eruption)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(grid.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rforest = RandomForestRegressor(n_estimators = 265, n_jobs = -1, random_state = 0)\nrforest.fit(x_train, y_train)\n\n# y_pred = grid.predict(x_test)\ny_pred = rforest.predict(x_test)\n\nmetrics.mean_absolute_error(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"gboost = GradientBoostingRegressor(learning_rate = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p2 = {'n_estimators':range(500, 800, 50)}\n\ngrid2 = GridSearchCV(gboost, p2, cv = 5, n_jobs = -1, scoring = 'neg_mean_absolute_error')\n\ngrid2.fit(data, train_time.time_to_eruption)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(grid2.cv_results_)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}