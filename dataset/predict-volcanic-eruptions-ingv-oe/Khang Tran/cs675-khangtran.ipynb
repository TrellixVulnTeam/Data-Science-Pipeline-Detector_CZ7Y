{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport pandas as pd \nimport os\nimport dask.dataframe as dd\n\nfrom tsfresh.feature_extraction import feature_calculators\nimport librosa\nimport pywt\n\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm_notebook\nimport scipy as sp\nimport itertools\nimport gc\n\nfrom sklearn.metrics import mean_absolute_error\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/predict-volcanic-eruptions-ingv-oe/train.csv')\ntrain['segment_id'] = train['segment_id'].astype(str)\ntrain = train.sort_values('segment_id')\ny = train['time_to_eruption']\ndel(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_paths = sorted(glob('/kaggle/input/predict-volcanic-eruptions-ingv-oe/train/*'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/predict-volcanic-eruptions-ingv-oe/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(1337)\nnoise = np.random.normal(-10, 200, 60_001)\n\n\ndef denoise_signal_simple(x, wavelet='db4', level=1):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    #univeral threshold\n    uthresh = 10\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n    # Reconstruct the signal using the thresholded coefficients\n    return pywt.waverec(coeff, wavelet, mode='per')\n\n\ndef feature_gen(path):\n    X = (pd.read_csv(path).fillna(200).values.T + noise).T\n    z = X - np.median(X,axis=0)\n    features = []\n    for i in range(X.shape[1]):\n        sig = z[:,i]\n        den_sample_simple = denoise_signal_simple(sig)\n        mfcc = librosa.feature.mfcc(sig)\n        mfcc_mean = mfcc.mean(axis=1)\n        percentile_roll50_std_20 = np.percentile(pd.Series(sig).rolling(50).std().dropna().values, 20)\n        features.extend([feature_calculators.number_peaks(den_sample_simple, 2),percentile_roll50_std_20,mfcc_mean[18],mfcc_mean[4]])\n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_samples = [Parallel(n_jobs=4)(delayed(feature_gen)(train_path) for train_path in tqdm_notebook(train_paths))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_samples = np.array(train_samples).reshape(-1,40)\n# del(samples)\ndel(train_paths)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_paths = sorted(glob('/kaggle/input/predict-volcanic-eruptions-ingv-oe/test/*'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_samples = [Parallel(n_jobs=4)(delayed(feature_gen)(test_path) for test_path in tqdm_notebook(test_paths))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_samples = np.array(test_samples).reshape(-1,40)\ndel(test_paths)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.DataFrame(train_samples)\ntrain_targets = pd.DataFrame({'target': y})\ntest_features = pd.DataFrame(test_samples)\ntrain_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.concat([train_features, train_targets], axis = 1)\ntest_features['target'] = None\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.concat([train_data, test_features])\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['id'] = all_data.index\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['target'] = all_data['target'].astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nfor col in all_data.drop(['target', 'id'],axis=1).columns:\n    all_data[col] = scaler.fit_transform(np.array(all_data[col]).reshape(-1, 1))\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = all_data[:train_features.shape[0]]\ntest_data = all_data[train_features.shape[0]:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, scale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = train_data.drop(['target'],axis=1)\ntrain_targets = pd.DataFrame(train_data['target'])\ntest_features = test_data.drop(['target'],axis=1)\ntrain_targets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': ['mae'],\n    'learning_rate': 0.001,\n    'feature_fraction': 0.9,\n    'subsample': 0.85,\n    'subsample_freq': 2,\n    'verbose': 0,\n    \"max_depth\": 40,\n    \"num_leaves\": 250,  \n    \"max_bin\": 128,\n    \"num_iterations\": 10000,\n    'device': 'gpu',\n    'gpu_platform_id': 0,\n    'gpu_device_id': 0\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nimport lightgbm as lgb\nimport math  \nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nscore = []\n\nskf = KFold(n_splits = 10, shuffle=True, random_state=123)\nskf.get_n_splits(train_features, train_targets)\noof_lgbm_df = pd.DataFrame()\npredictions = pd.DataFrame(test_features['id'])\nx_test = test_features.drop(['id'], axis = 1)\n\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(train_features, train_targets)):\n    x_train, y_train = train_features.iloc[trn_idx], train_targets.iloc[trn_idx]['target']\n    x_valid, y_valid = train_features.iloc[val_idx], train_targets.iloc[val_idx]['target']\n    index = x_valid['id']\n    x_train = x_train.drop(['id'], axis = 1)\n    x_valid = x_valid.drop(['id'], axis = 1)\n    p_valid = 0\n    yp = 0\n    gbm = lgb.LGBMRegressor(**hyper_params)\n    gbm.fit(x_train, y_train,\n        eval_set=[(x_valid, y_valid)],\n        eval_metric='mae',\n        verbose = 500,\n        early_stopping_rounds=100)\n    score.append(mean_absolute_error(gbm.predict(x_valid), y_valid))\n    yp += gbm.predict(x_test)\n    fold_pred = pd.DataFrame({'ID': index,\n                              'label':gbm.predict(x_valid)})\n    oof_rfr_df = pd.concat([oof_lgbm_df, fold_pred], axis=0)\n    predictions['fold{}'.format(fold+1)] = yp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = pd.DataFrame(score)\nprint(score[0].mean())\nprint(score[0].std())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}