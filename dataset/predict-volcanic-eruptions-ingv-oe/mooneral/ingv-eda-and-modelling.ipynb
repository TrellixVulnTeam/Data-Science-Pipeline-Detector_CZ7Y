{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport glob\nfrom tqdm import tqdm\nfrom numba import njit\nimport time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Investigating train.csv"},{"metadata":{},"cell_type":"markdown","source":"`train.csv` is containing target value for sensors data. for example this `[1136037770 ,12262005]` tells us given 10 mins of 10 sensors data in `1136037770.csv`, 12262005 time (in some unit) remain to eruption."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/predict-volcanic-eruptions-ingv-oe/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('info: \\n', train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('info: \\n', train.info())\nprint('-+-'*30)\nprint('Statistics: \\n',train['time_to_eruption'].describe(),\n      '\\nskewness:', train['time_to_eruption'].skew(),\n      '\\nkurtosis: ', train['time_to_eruption'].kurtosis(),\n      '\\nIQR:', train['time_to_eruption'].quantile(0.75) - train['time_to_eruption'].quantile(.25),\n      '\\nrange: ', train['time_to_eruption'].max() - train['time_to_eruption'].min())\nprint('-+-'*30)\nprint('train.head:\\n',train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no missing value (of course!).\n\nIdeas to investigate:\n1. sort `time_to_eruption` values and see the relation with volano activity and remaining time.\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's look at the histogram of the target value\npx.histogram(train,\n             x='time_to_eruption',\n             nbins=200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems, `time_to_eruption` uniformly distributed (roughly)."},{"metadata":{"trusted":true},"cell_type":"code","source":"px.line(train, \n        x=train.index, \n        y='time_to_eruption',\n        log_y=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's sort values by `time_to_eruption`"},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_df = train.sort_values(by='time_to_eruption', ascending=False)\nsorted_df.reset_index(inplace=True)\n# sorted_df.drop('index', axis='columns', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.line(sorted_df, \n        x=sorted_df.index,\n        y=(sorted_df['time_to_eruption']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.line(sorted_df, \n        x=sorted_df.index,\n        y=(sorted_df['time_to_eruption']),\n        log_y=True\n       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_df['step'] = sorted_df['time_to_eruption'].shift(-1) - sorted_df['time_to_eruption']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.line(sorted_df, x=sorted_df.index,\n        y=sorted_df['step'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Investigating Sensors Data"},{"metadata":{},"cell_type":"markdown","source":"Let's See what a single file look's like."},{"metadata":{"trusted":true},"cell_type":"code","source":"sensor_path = '/kaggle/input/predict-volcanic-eruptions-ingv-oe/train'\n\ndef read_sensor_data(path=sensor_path, fname='1000015382.csv'):\n    df = pd.read_csv(path+'/'+fname, dtype='Int16')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensor_df = read_sensor_data()\nsensor_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensor_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensor_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_sensor_data(df, size=(1000, 1000), fixed_range=[-5000, 5000]):\n    fig = make_subplots(rows=10, \n                        cols=1,\n                        shared_xaxes=True,\n                        vertical_spacing=0.03,\n                        subplot_titles = df.columns.to_list())\n    \n    for i in range(df.shape[1]):\n        fig.add_trace(go.Scatter(x=df.index,\n                                 y=df.iloc[:, i].fillna(0),\n                                 mode='lines',\n                                 name=df.columns[i]),\n                        row=i+1,\n                        col=1)\n        fig.update_yaxes(range=fixed_range)\n        \n    fig.layout.update(\n        {'width':size[0],\n         'height':size[1],\n         'showlegend':False})\n    return fig\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_sensor_data(sensor_df, fixed_range=None)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_sensors_hist(df, shape=[5, 2]):\n\n    fig = make_subplots(rows=shape[0], \n                        cols=shape[1],\n                        vertical_spacing=0.09,\n                        specs=[[{\"secondary_y\": True}]*shape[1] for i in range(shape[0])],\n                        subplot_titles = df.columns.to_list())\n    \n    for i in range(df.shape[1]):\n        row = int(i % shape[0] + 1)\n        col = int(i // shape[0] + 1)\n\n        fig.add_trace(go.Histogram(x=df.iloc[:, i].fillna(0),\n                                   name=df.columns[i]),\n                      row=row,\n                      col=col)\n        fig.add_trace(go.Histogram(x=df.iloc[:, i].fillna(0),\n                                   name=df.columns[i],\n                                   cumulative={'enabled':True},\n                                   histnorm='probability',\n                                   opacity=0.5),\n\n                      row=row,\n                      col=col,\n                      secondary_y=True)\n\n    fig.layout.update(\n        {'width': shape[1]*280,\n         'height':shape[0]*280,\n         'showlegend':False})\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sensors_hist(sensor_df, shape=[2,5])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing Data"},{"metadata":{},"cell_type":"markdown","source":"If an entire sensor is `Null` we will drop it."},{"metadata":{"trusted":true},"cell_type":"code","source":"sensor_path = '/kaggle/input/predict-volcanic-eruptions-ingv-oe/train'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 15G training data!\n!du -h -d 1 /kaggle/input/predict-volcanic-eruptions-ingv-oe/train/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# collect file names\nsensors_files = glob.glob(f\"{sensor_path}/*\")\nprint(len(sensors_files))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# counting missing values and columns\n\n# meta_df = pd.DataFrame(np.zeros((10,2)), columns=['full_null', 'partial_null'], \n#              index=[f'sensor_{i+1}' for i in range(10)])\n# for f in tqdm(sensors_files):\n#     df = pd.read_csv(f, dtype='Int16')\n    \n#     partial_null = df.columns[df.isnull().any()].to_list()\n#     full_null = df.columns[df.isnull().all()].to_list()\n    \n#     if partial_null:\n#         meta_df.loc[partial_null,'partial_null'] +=1\n    \n#     if full_null:\n#         meta_df.loc[full_null,'full_null'] +=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save this data and to not go with the process again\n# meta_df.to_csv('/kaggle/working/null_data.csv')\nmeta_df = pd.read_csv('../input/null-data/null_data.csv',index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" meta_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_group_bar(df, columns, title='Count of missing data for each sensor'):\n    x = df.index\n    traces = [go.Bar(x=x, y=meta_df[i], name=i) for i in columns]\n    \n    fig = go.Figure(data=traces, layout={'title':title, \n                                         'yaxis':{'title': 'Count'},\n                                         'xaxis':{'title': 'Sensors'}})\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_group_bar(meta_df, ['full_null', 'partial_null'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_df['full_null_percent'] = meta_df['full_null'] / train.shape[0] * 100\nmeta_df['partial_null_percent'] = meta_df['partial_null'] / train.shape[0] * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_group_bar(meta_df, ['full_null_percent', 'partial_null_percent'], title='Count of missing data for each sensor(%)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"near 20% of `sensor_2` data are missing, and almost 10% of `sensor_3, sensor_5, and sensor_8` are missing.\n`sensor_4 and sensor_6` are not missing entirly. and `sensor_2, and sensor_9` have partially missing data in the intire dataset. \n\nfor a sensor if it's entirely missing we drop and just not use it. But for partially missing values I think '`Back fill`' is good strategy than filling with `0s`."},{"metadata":{},"cell_type":"markdown","source":"### Transformation and Feature Extraction\nwe will use continuous wavelet transform (`cwt`) to transform raw data to usefull features then use `PCA` to get the most useful features.\nwe accoumplish this with the `sklearn` custom transformer\n\n![](http://)[wavelet reference](http://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pywt\nfrom skimage.transform import resize\nfrom sklearn.decomposition import PCA\nfrom sklearn.base import BaseEstimator, TransformerMixin\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features(df: pd.DataFrame, scale: int= 64, wavelet: str='morl', comps: int=5):\n    scales = np.arange(1, scale + 1)\n    pca = PCA(n_components=comps)\n\n    pca_comps = np.empty((0, scales.shape[0] * comps), dtype='float32')\n    df.fillna(method='bfill').fillna(0, inplace=True)\n    for i in range(df.shape[1]):\n        signal = df.iloc[:,i]\n        coeff, freq = pywt.cwt(signal, scales, wavelet)\n        coeff = np.nan_to_num(coeff)\n        pca_comps = np.vstack([pca_comps, pca.fit_transform(coeff).flatten()]) \n    return pca_comps.flatten()\n    # output shape 64 * 5 * 10 \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_training_data(glob_list: glob.glob):\n    data = np.empty((0, 3201))\n    for i, file in enumerate(glob_list):\n#         segment_id = file.split('/')[-1].split('.')[0]\n        \n        df = pd.read_csv(file)\n        \n        features = extract_features(df)\n        \n#         features = np.append(segment_id, features) # append the segment id to the begining of the features\n        data = np.vstack([data, features])\n        \n        if i % 100 == 0:\n            print(time.time())\n            df = pd.DataFrame(data, columns=['segment_id']+list(range(1, 3201)))\n            df.to_csv('/kaggle/working/train_data.csv')\n            \n    df = pd.DataFrame(data, columns=['segment_id']+list(range(1, 3201)))\n    df.to_csv('/kaggle/working/train_data.csv')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data = load_training_data(sensors_files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data_chunks(glob_list):\n    main_arr = np.empty((len(glob_list), 60001, 10))\n    for i, file in tqdm(enumerate(glob_list), total=len(glob_list)):\n        \n        main_arr[i,:, :] = np.genfromtxt(file, delimiter=',')[1:, :]\n    return main_arr\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = load_data_chunks(sensors_files[:1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ffill(arr):\n    mask = np.isnan(arr)\n    idx = np.where(~mask,np.arange(mask.shape[1]),0)\n    np.maximum.accumulate(idx,axis=1, out=idx)\n    arr[mask] = arr[np.nonzero(mask)[0], idx[mask]]\n    return np.nan_to_num(arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features(arr, scale: int= 64, wavelet: str='morl', comps: int=5):\n    scales = np.arange(1, scale + 1)\n    pca = PCA(n_components=comps)\n\n    pca_comps = np.empty((0, scales.shape[0] * comps), dtype='float32')\n    arr = ffill(arr)\n    for i in range(arr.shape[1]):\n        signal = arr[:,i]\n        coeff, freq = pywt.cwt(signal, scales, wavelet)\n        coeff = np.nan_to_num(coeff)\n        pca_comps = np.vstack([pca_comps, pca.fit_transform(coeff).flatten()]) \n    return pca_comps.flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_train_set(ndarr):\n    num_samples = ndarr.shape[0]\n    train = np.empty((num_samples, 3200))\n    for i in tqdm(range(num_samples)):\n        train[i,:] = extract_features(ndarr[i, :, :])\n    \n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = make_train_set(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(f)\ndf['segment_id'] = [int(i.split('/')[-1].split('.')[0]) for i in sensors_files[:1000]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.merge(train.astype(np.float32), on='segment_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('/kaggle/working/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.imshow(coeff)\nfig.update_layout(width=400, height=1000)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coeff_1, freq = pywt.cwt(sensor_df['sensor_1'].fillna(method='backfill').astype(np.float32), np.arange(1, 65), 'morl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=0.95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = pca.fit_transform(coeff[:, :, 1 ].T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coeff[:, :, 9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coeff_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data=np.zeros((2,2)), columns=['a','b'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[0,0] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\npd.read_csv('/kaggle/working/train_data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using CNN\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}