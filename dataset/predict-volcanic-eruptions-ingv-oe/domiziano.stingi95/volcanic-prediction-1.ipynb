{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install ProgressBar\n!pip install lifelines","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob \nfrom progressbar import ProgressBar\nimport lifelines\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('../input/predict-volcanic-eruptions-ingv-oe/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare(name):\n    index = []\n    frag = glob.glob(\"../input/predict-volcanic-eruptions-ingv-oe/{}/*\".format(name))\n    df=pd.DataFrame()\n\n    pbar = ProgressBar()\n    for i in pbar(frag):\n        df = np.append(df,pd.read_csv(i).mean())\n    \n    df = pd.DataFrame(df.reshape(len(frag),10))  \n\n    for i in range(0,len(frag)):\n        index = np.append(index,os.path.splitext(frag[i].split('{}/'.format(name))[1])[0])\n        \n    df['segment_id']=index\n    df['segment_id']=df['segment_id'].astype(int)\n    if name == 'train': \n        df = pd.merge(df, train_csv, on =['segment_id'],how='left') \n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_means = prepare('train')\ntest_means = prepare('test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_means['time_to_eruption'] = train_means['time_to_eruption'] // 6000\ntrain_means.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_means.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_na(dataset):\n    for i in range(0,10):\n        dataset[i]= dataset[i].fillna(np.mean(dataset[i]))\n    \n    for i in dataset.columns:\n        print(sum(dataset[i].isnull()))\n        \n    return(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_means=remove_na(train_means)\ntest_means=remove_na(test_means)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_means['segment_id']\nx = train_means.drop(columns=['segment_id','time_to_eruption'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom  sklearn.tree import DecisionTreeClassifier\nfrom  sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nimport xgboost as xgb\n\n\nclass estimators:\n    \n    pred = [] \n    \n    def __init__(self):   \n        pass\n    \n    \n    \n    def lin_reg(self,x,y,test):\n        del self.pred[:]\n        Xt, Xv, Yt, Yv = train_test_split(x, y, test_size =0.2, shuffle=False)\n        reg = linear_model.LinearRegression()\n        reg.fit(Xt,Yt)\n        print('mean abosulte error: ', mae(reg.predict(Xv),Yv))\n        prediction = reg.predict(test)\n        self.pred = np.append(self.pred,prediction)\n    \n    \n    \n    def extreme(self,x,y,test):\n        del self.pred[:]\n        model = xgb.XGBRegressor(n_estimators=100000,max_depth=8,learning_rate=0.05,alpha=0.1,SUBSAMPLE=0.6) #tree_method='gpu_hist'\n        Xt, Xv, Yt, Yv = train_test_split(x, y, test_size =0.2, shuffle=False)\n        eval_set = [(Xv,Yv)]\n        model.fit(Xt, Yt,early_stopping_rounds=10,eval_metric='mae', eval_set=eval_set, verbose=False)\n        prediction = model.predict(test)\n        self.pred = np.append(self.pred,prediction)\n \n           \n     \n    def lgb(self,x,y,test):\n        del self.pred[:]\n        Xt, Xv, Yt, Yv = train_test_split(x, y, test_size =0.2, shuffle=False)\n\n        params = {\n        'objective': 'regression', #specify how is the dependet variable, binary can be used for logistic regression or log loss classification\n        'max_bin': 600, #max number of bins that features values will be bucketed in. Small number may reduce training accuracy but may increase general power\n        'learning_rate': 0.02, #learning_rate refers to the step size at each interation while moving toward an optimal point\n        'num_leaves': 80, # maximum number of leaves in a tree, where a leave is a final termination of a tree\n        'metric' : 'mae'\n        }\n\n\n        lgb_train = lgb.Dataset(Xt, Yt)\n        lgb_eval = lgb.Dataset(Xv, Yv, reference=lgb_train)\n        #lightgbm need to take as argument lightgbm dataset, it is required to make this trasformation\n\n        model = lgb.train(\n            params, lgb_train, #it is required to insert the parameters, then the train set\n            valid_sets=[lgb_train, lgb_eval],\n            verbose_eval=0,\n            num_boost_round=1500, # number of boosting iterations \n            early_stopping_rounds=1000 # will stop training if one metric of one validation data doesnâ€™t improve in last early_stopping_round rounds, so if \n            #  for ten 'epochs' the model will stop, in this way the num_boost_round is a maximum value.  \n        )  \n\n        y_pred = model.predict(Xv)\n        y_true = np.array(Yv)\n        print('mean absolute error:',mae(y_true, y_pred))\n\n        prediction = model.predict(test)\n        self.pred = np.append(self.pred,prediction)\n \n    \n    \n    def sub(self,test):\n        df = pd.DataFrame(test['segment_id'])\n        df = pd.concat([df,pd.Series(self.pred)],axis=1)\n        sample_submission=pd.read_csv('../input/predict-volcanic-eruptions-ingv-oe/sample_submission.csv')\n        \n        sample_submission = pd.merge(sample_submission,df, on =['segment_id'])\n        sample_submission = sample_submission.drop(columns=['time_to_eruption'])\n        sample_submission.columns = ['segment_id', 'time_to_eruption']\n        sample_submission.to_csv('sample_submission.csv', header=True, index=False)\n        print('saved')\n        return(sample_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est = estimators()\nest.lin_reg(x,y,test_means.iloc[:,0:10])\nest.sub(test_means)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est = estimators()\nest.extreme(x,y,test_means.iloc[:,0:10])\nest.sub(test_means)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est = estimators()\nest.lgb(x,y,test_means.iloc[:,0:10])\nest.sub(test_means)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}