{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\n    \"../input/tabular-playground-series-jan-2021/train.csv\"\n)\ntest = pd.read_csv(\n    \"../input/tabular-playground-series-jan-2021/test.csv\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import combinations\nfrom sklearn.feature_selection import mutual_info_regression\nimport pickle\n\nclass Create_Features:\n    def __init__(self):\n        self.features_added = []\n        self.feature_bins = {}\n        self.bin_labels = {}\n        pass\n        \n    def find_interaction_features(self, df, target, sample_size = 0.5):\n        # Getting correct feature list for combinations\n        feature_list = df.columns.tolist()\n        \n        print(\"Calculating Score Threshold...\")\n        mi = self.score_feature(df, target, sample_size)\n        threshold = (mi.max() - mi.min()) / 1.5 + mi.min()\n        threshold = mi.max()\n        print(f'Scores: {mi}, Score Threshold: {threshold}')\n        print()\n        \n        ff = pd.DataFrame()\n        for combo in combinations(feature_list, 2):\n            # Addition\n            feature_name = f'{combo[0]}_+_{combo[1]}'\n            print(f'Trying {feature_name}...', end = '\\r')\n            add = df[combo[0]] + df[combo[1]]\n            score = self.score_feature(add, target, sample_size)\n            if score > threshold:\n                ff[feature_name] = add\n                print(f'Added {feature_name}: {score}')\n                self.features_added.append(feature_name)\n                \n            # Multiplication\n            feature_name = f'{combo[0]}_x_{combo[1]}'\n            print(f'Trying {feature_name}...', end = '\\r')\n            mult = df[combo[0]] * df[combo[1]]\n            score = self.score_feature(mult, target, sample_size)\n            if score > threshold:\n                ff[feature_name] = mult\n                print(f'Added {feature_name}: {score}')\n                self.features_added.append(feature_name)\n                \n            # Subtraction\n            feature_name = f'{combo[0]}_-_{combo[1]}'\n            print(f'Trying {feature_name}...', end = '\\r')\n            sub = df[combo[0]] - df[combo[1]]\n            score = self.score_feature(sub, target, sample_size)\n            if score > threshold:\n                ff[feature_name] = sub\n                print(f'Added {feature_name}: {score}')\n                self.features_added.append(feature_name)\n                \n            # Divison\n            feature_name = f'{combo[0]}_/_{combo[1]}'\n            print(f'Trying {feature_name}...', end = '\\r')\n            div = df[combo[0]] / df[combo[1]]\n            score = self.score_feature(div, target, sample_size)\n            if score > threshold:\n                ff[feature_name] = div\n                print(f'Added {feature_name}: {score}')\n                self.features_added.append(feature_name)\n        \n        print(f'Finished -- Total Features Added: {len(self.features_added)}', end = '\\r')\n        return pd.concat([df,ff], axis = 1)\n    \n    def interaction_transform(self, df):\n        ff = pd.DataFrame()\n        for feature in self.features_added:\n            interaction = feature.split(\"_\")\n            if interaction[1] == '+':\n                ff[feature] = df[interaction[0]] + df[interaction[2]]\n            elif interaction[1] == 'x':\n                ff[feature] = df[interaction[0]] * df[interaction[2]]\n            elif interaction[1] == '-':\n                ff[feature] = df[interaction[0]] - df[interaction[2]]\n            else:\n                ff[feature] = df[interaction[0]] / df[interaction[2]]\n        return pd.concat([df,ff], axis = 1)\n    \n    def load_interactions(self, interactions, filepath, display_features = False):\n        with open(filepath, 'rb') as fp:\n            self.features_added = pickle.load(fp)\n            print(f'Loaded interaction features. Please use interaction_transform() to apply interactions.')\n        if display_features:\n            print(f'Features Loaded: {self.features_added}')\n    \n    def save_interactions(self, filepath):\n        with open(filepath, 'wb') as fp:\n            pickle.dump(self.features_added, fp)\n            print(f'Features have been saved at {filepath}')\n        \n    \n    def score_feature(self, feature, target, sample_size = 0.5):\n        subset = feature.sample(frac = sample_size)\n        sample_target = target[subset.index]\n        if type(subset) == type(pd.DataFrame()):\n            return mutual_info_regression(subset, sample_target)\n        else:\n            return mutual_info_regression(subset.values.reshape(-1,1), sample_target)\n    \n    def bin_features(self, df,features = 'all', n_bins = 10):\n        \"\"\"\n        Creates the binned features and stores the bins for later use\n        \"\"\"\n        if features == 'all':\n            features = df.columns.tolist()\n        binned_features = {}\n        for col in features:\n            self.bin_labels[col] = [i/n_bins for i in range(n_bins)]\n            binned_features[f'{col}_bin'], self.feature_bins[col] = pd.qcut(df[col], q = n_bins, labels = self.bin_labels[col], retbins = True)\n            binned_features[f'{col}_bin'] = binned_features[f'{col}_bin'].astype(float)\n            \n        bf = pd.DataFrame.from_dict(binned_features)\n        return pd.concat([df, bf], axis = 1)\n    \n    def bin_transform(self, df, features = 'all'):\n        \"\"\"\n        Uses the defined bins to bin another set of the same features\n        \"\"\"\n        if features == 'all':\n            features = df.columns.tolist()\n        bf = {}\n        for col in features:    \n            bf[f'{col}_bin'] = pd.cut(df[col], bins = cf.feature_bins[col], labels = self.bin_labels[col])\n            bf[f'{col}_bin'] = bf[f'{col}_bin'].astype(float)\n        bf = pd.DataFrame.from_dict(bf)\n        return pd.concat([df, bf], axis = 1)\n    \n    def flag_outliers(self, df):\n        pass\n    \n    def outlier_transform(self, df):\n        pass\n            \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.iloc[:,1:-1]\ny = train.iloc[:,-1]\nX_val = test.iloc[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf = Create_Features()\nX = cf.find_interaction_features(X, y, sample_size = 0.1)\nX_val = cf.interaction_transform(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf.bin_features(pd.concat([X, X_val], axis = 0), n_bins = 500)\nX = cf.bin_transform(X)\nX_val = cf.bin_transform(X_val)\nX = X.fillna(-1)\nX_val = X_val.fillna(-1)\nX_val.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop = ['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8',\n       'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14',\n       'cont3_+_cont12', 'cont4_x_cont11', 'cont7_x_cont12']\nX = X.drop(drop, axis = 1)\nX_val = X_val.drop(drop, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport joblib\nimport xgboost as xg\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = True) \n\nclf = xg.XGBRegressor(objective ='reg:squarederror', eta = .3).fit(X_train, y_train) \n  \ny_pred = clf.predict(X_test)\nrms = mean_squared_error(y_test, y_pred, squared = False)\nrms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame()\n\nsubmission['id'] = test['id']\nsubmission['target'] = clf.predict(X_val)\n\nsubmission.to_csv(\n    \"2021_01_27_xgb_allfeatures_500bins.csv\",\n    index= False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Voting Ensembles"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xg\nfrom sklearn.ensemble import VotingRegressor\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = True) \n\n# Regressors\nr1 = ElasticNet(alpha = 1.5)\nr2 = RandomForestRegressor(n_estimators = 150, max_depth = 4)\nr3 = xg.XGBRegressor(objective ='reg:squarederror',eta = 0.1, gamma = 2, max_depth = 4, alpha = 0.5) \nr4 = HistGradientBoostingRegressor(learning_rate = 0.1, max_depth = 4, l2_regularization = 0.5)\n\ner = VotingRegressor([\n    ('lr', r1), \n    ('rf', r2),\n    ('xg', r3),\n    ('gb', r4),\n], weights = [1, 1, 1, 1])\n\ner.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nrms = mean_squared_error(y_test, y_pred, squared = False)\nrms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame()\n\nsubmission['id'] = test['id']\nsubmission['target'] = er.predict(X_val)\n\nsubmission.to_csv(\n    \"2021_01_27_voting_withMoarReg_allfeatures.csv\",\n    index= False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nplt.figure(figsize = (8,4))\nsns.heatmap(X_val.isinf())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}