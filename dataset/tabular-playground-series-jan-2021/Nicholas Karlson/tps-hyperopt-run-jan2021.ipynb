{"cells":[{"metadata":{},"cell_type":"markdown","source":"Tabular Playground Series Jan2021\n\nXGBoost VS XGBoost + Hyperopt\n\nThe January 2021 Tabular Playground Series competition is almost over and thanks to all the people who have posted great notebooks with a lot of great ideas. One question I usually think about is, \"How good is best?\". It is said that time is money, so how much time (or money) should a person spend to make a job as good as relatively possible? Unfortunately, this is a difficult question to answer but should probably always be asked.\n\nSo, given the above paragraph, suppose you are asked by your boss to predict thousands of outcomes from some data that is circulating around the office (think the data in the Tabular Playground Series competition!), what to do? Fortunately, your co-workers have been busy on the problem and they tell you that XGBoost on the raw data should work fine. XGBoost sounds good to you, but how much extra work would it be to use Hyperopt to make the results potentially better? Is the extra effort worth it?\n\nThe information provided in this notebook will not provide definitive answers to the above questions. The idea is, why not give it a go and see for yourself? Here is what I tried, starting with notebook code generously posted by:\nhttps://www.kaggle.com/jamesmcguigan/tabular-playground-xgboost\nand\nhttps://www.kaggle.com/marionhesse/hyperopt-xgboost-parameter-tuning\nThanks for the great posts!\nAs with the above notebooks, this notebook is released under the Apache 2.0 open source license. http://www.apache.org/licenses/LICENSE-2.0\n\nBelow is the XGBoost plus Hyperopt Run..."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\nimport matplotlib.pyplot as plt\nimport gc #garbage collection\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom tqdm import tqdm\n\npath = '../input/tabular-playground-series-jan-2021/'\ntrain = pd.read_csv(path+'train.csv')\n\nfeatures = [col for col in train.columns if 'cont' in col]\nlabel = 'target'\n\n\n# train/eval set split\nX_train,X_valid, y_train,y_valid = train_test_split(train[features],train[label],test_size=0.2)\n\nd_tr = xgb.DMatrix(X_train, y_train)\nd_val = xgb.DMatrix(X_valid,y_valid)\n\n\nparams_base = {'objective': 'reg:squarederror',\n               'tree_method': 'gpu_hist',\n               'random_state': 0}\nbase_model = xgb.train(params = params_base,\n                       dtrain = d_tr,\n                       num_boost_round = 1500,\n                       evals = [(d_val,'eval')],\n                       early_stopping_rounds=30,\n                       verbose_eval = 20)\ny_pred_base = base_model.predict(d_val)\nbase_score = mean_squared_error(y_valid, y_pred_base,squared=False)\nprint(base_score)\n\n\n# Simple Cross Val score as function to be optimized\n\ndef score(params):\n    \n    ps = {'learning_rate': params['learning_rate'],\n         'max_depth': params['max_depth'], \n         'gamma': params['gamma'], \n         'min_child_weight': params['min_child_weight'], \n         'subsample': params['subsample'], \n         'colsample_bytree': params['colsample_bytree'], \n         'verbosity': 1, \n         'objective': 'reg:squarederror',\n         'eval_metric': 'rmse', \n         'tree_method': 'gpu_hist', \n         'random_state': 27,\n        }\n    model = xgb.train(ps,d_tr, params['n_round'], [(d_val, 'eval')], early_stopping_rounds=10, verbose_eval = False)\n    y_pred = model.predict(d_val)\n    score = mean_squared_error(y_valid, y_pred,squared=False)\n\n    return score\n\n\n# Define parameter space\nparam_space = {'learning_rate': hp.uniform('learning_rate', 0.01, 0.3), \n               'n_round': scope.int(hp.quniform('n_round', 200, 3000, 100)),\n               'max_depth': scope.int(hp.quniform('max_depth', 5, 16, 1)), \n               'gamma': hp.uniform('gamma', 0, 10), \n               'min_child_weight': hp.uniform('min_child_weight', 0, 10),\n               'subsample': hp.uniform('subsample', 0.1, 1), \n               'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1)\n              }\n\n\n# Run optimiser with tpe\n%time\ntrials = Trials()\n \nhopt = fmin(fn = score,\n            space = param_space, \n            algo = tpe.suggest, \n            max_evals = 1200, \n            trials = trials, \n           )\n\n\nparams_best = hopt\nparams_best['max_depth'] = int(hopt['max_depth'])\nn_rounds_best = int(hopt['n_round'])\ndel params_best['n_round']\nprint(params_best)\nprint(n_rounds_best)\n\n\n%time\n# Train with full dataset and best params\nparams_best['tree_method'] = 'gpu_hist'\nd = xgb.DMatrix(train[features], train[label])\nxgb_final = xgb.train(params_best,d,n_rounds_best)\n\n\ny_pred_final = xgb_final.predict(d)\nscore_final = np.sqrt(mean_squared_error(train[label], y_pred_final))\nprint(score_final) #sanity check\n\n\n# Load test data\ntest = pd.read_csv(path + 'test.csv')\ntest.set_index('id',drop=True,inplace=True)\nd_tst = xgb.DMatrix(test[features])\n\n\n# Predictions for test data\nmodels = []\n\nfor seed in range(0,10):\n    params_best['seed'] = seed\n    xgb_final = xgb.train(params_best,d,num_boost_round = n_rounds_best)\n    models.append(xgb_final)\n    \nxgb_pred = xgb_final.predict(d_tst)\n\n\n# Save test predictions to file\nids = test.index\noutput = pd.DataFrame({'id': ids,\n                       'target': xgb_pred})\noutput.to_csv('submission.csv', index=False)\n\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}