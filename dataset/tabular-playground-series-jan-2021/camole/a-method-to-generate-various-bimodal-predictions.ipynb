{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Generating various bimodal predictions"},{"metadata":{},"cell_type":"markdown","source":"Sharing some of my predictions that displayed bimodal distribution. Public scores are around 0.70. Tried some ensembles but public score isn't necessarily any better than \"unimodal\" predictions.."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport glob\nimport os\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nimport plotly_express as px\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of target in train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = ff.create_distplot(\n    [train.target[:10000]], \n    group_labels = ['kde']\n)\n\nfig.update_xaxes(range=[5, 10])\n\nfig","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of predictions for test set (ensemble, public score = 0.69685 )"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_69685 = pd.read_csv('../input/dataset/0.69685-others-submission6.csv')\nfig = ff.create_distplot(\n    [df_69685.target[:10000]], \n    group_labels = ['kde']\n)\n\nfig.update_xaxes(range=[5, 10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simulating the shape of target in the train set"},{"metadata":{},"cell_type":"markdown","source":"I trained 5 additional models: \n\n- XGBRegressor,  using train set where target is <9. \n- Same XGBRegressor model, except using train set where target >7\n- LightGBM, using train set where target is <9. \n- Same LightGBM model, except using train set where target >7\n- CatBoostRegressor, using train set where target is <9. \n- Same CatBoostRegressor model, except using train set where target >7\n\nAll 6 models were tuned using Optuna. Each model has an RMSE of bewteen 0.3-0.5 for prediction within its specified region. Then I used each of the models to predict the **full** test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# light GBM optuna tuned params\nlight_opt_best_random = {'n_estimators': 8540,\n 'min_data_per_group': 45,\n 'num_leaves': 126,\n 'max_depth': 20,\n 'learning_rate': 0.0032598944879946414,\n 'subsample_for_bin': 32553,\n 'lambda_l1': 0.11917413918151999,\n 'lambda_l2': 6.857359561808505e-05,\n 'bagging_fraction': 0.8910429482743759,\n 'min_data_in_leaf': 94,\n 'min_sum_hessian_in_leaf': 0.01,\n 'bagging_freq': 2,\n 'feature_fraction': 0.4699812049606955,\n 'min_child_samples': 61}\n\n# xgboost upotuna tuned params\nxgb_opt_best_random = {'learning_rate': 0.004138539806617361, \n 'gamma': 0.020496820582462844, \n 'max_depth': 19, \n 'min_child_weight': 308, \n 'max_delta_step': 9, \n 'subsample': 0.6437442427644592, \n 'colsample_bytree': 0.41845630929589844, \n 'lambda': 0.0038484657676066394, \n 'alpha': 0.09281553090596092, \n 'n_estimators': 4767\n}\n\n# catboost optuna tuned params\ncatboost_opt_best_random= {\n    'n_estimators': 9639, \n    'learning_rate': 0.025621857270512527, \n    'reg_lambda': 0.03261099593456338, \n    'subsample': 0.6319711159148579, \n    'depth': 7, \n    'min_child_samples': 48, \n    'colsample_bylevel': 0.14898612913306458, \n    'langevin': False, \n    'model_shrink_rate': 0.28621265987632455, \n    'model_shrink_mode': 'Decreasing', \n    'model_size_reg': 2.373053070327802\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading predictions for the 6 models above\nsub26a = pd.read_csv('../input/dataset/submission26a-optuna-light-sm.csv')\nsub26b = pd.read_csv('../input/dataset/submission26b-optuna-light-lg.csv')\nsub26c = pd.read_csv('../input/dataset/submission26c-optuna-xgb-sm.csv')\nsub26d = pd.read_csv('../input/dataset/submission26d-optuna-xgb-lg.csv')\nsub26e = pd.read_csv('../input/dataset/submission26e-optuna-catboost-sm.csv')\nsub26f = pd.read_csv('../input/dataset/submission26f-optuna-catboost-lg.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generate some bi-modal predictions"},{"metadata":{},"cell_type":"markdown","source":"## Mix 1 - public score = 0.7034"},{"metadata":{"trusted":true},"cell_type":"code","source":"ls = []\nfor idx, num in enumerate(df_69685.target):\n    \n    if np.mean([sub26b.target[idx], sub26d.target[idx], sub26f.target[idx]]) > 8.1:# change this threshold or swap the if/elif clause, you will get different shapes\n        ls.append(np.mean([sub26b.target[idx], sub26d.target[idx], sub26f.target[idx]]))\n    elif np.mean([sub26a.target[idx], sub26c.target[idx], sub26e.target[idx]]) < 8.1:\n        ls.append( np.mean([sub26a.target[idx], sub26c.target[idx], sub26e.target[idx]]))\n\n    else:\n        ls.append(num)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = ff.create_distplot(\n    [ls[:1000]], \n    group_labels = ['kde']\n)\n\nfig.update_xaxes(range=[5, 10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mix 2 - public score = 0.70714"},{"metadata":{"trusted":true},"cell_type":"code","source":"ls = []\nfor idx, num in enumerate(df_69685.target):\n    \n    if np.mean([sub26a.target[idx], sub26c.target[idx], sub26f.target[idx]]) < 7.8: # change this threshold or swap the if/elif clause, you will get different shapes\n        ls.append( np.mean([sub26a.target[idx], sub26c.target[idx], sub26f.target[idx]]))\n    \n    elif np.mean([sub26b.target[idx], sub26d.target[idx], sub26e.target[idx]]) > 7.8 :\n        ls.append(np.mean([sub26b.target[idx], sub26d.target[idx], sub26e.target[idx]]))\n    else:\n        ls.append(num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = ff.create_distplot(\n    [ls[:10000]], \n    group_labels = ['kde']\n)\n\nfig.update_xaxes(range=[5, 10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So in theory you can generate predictions with bimodal distributions, but their does not seem to be as good as the best model I have, which only has 1 peak. Any thoughts?"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}