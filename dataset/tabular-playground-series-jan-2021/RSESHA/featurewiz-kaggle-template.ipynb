{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## This Featurewiz+SimpleXGBModel Template has Received Top Scores in Multiple Hackathons - Current Ranks in the following Hackathons are:\nAnalyticsVidhya Hackathons: https://datahack.analyticsvidhya.com/contest/all/\n1.  Big_Mart Sales Prediction Score: 1147  -- Rank 250 out of 41,361 = That's a Top <1% Rank!!\n1.  Loan Status Predictions Score 0.791  -- Rank 850 out of 67,424 - Top 1.25% Rank\n\nMachine Hack Hackathons: https://www.machinehack.com/hackathon\n1.  Machine Hack Flight Ticket Score 0.9389 -- Rank 165 out of 2723 - Top 6% Rank!\n1.  Machine Hack Data Scientist Salary class Score 0.417 -- Rank 58 out of 1547 - Top 3.7% Rank! (Autoviml Score was 0.329 -- less than 0.417 of Featurewiz+Simple even though an NLP problem!)\n1.  MCHACK Book Price NLP Score 0.7336 -- Rank 104 Autoviml NLP problem and should have done better\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.dates as md\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import host_subplot\nimport mpl_toolkits.axisartist as AA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.covariance import EllipticEnvelope\n\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.svm import OneClassSVM\nfrom mpl_toolkits.mplot3d import Axes3D\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from load_kaggle import load_kaggle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm, train, test = load_kaggle()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remember to install featurewiz first","metadata":{}},{"cell_type":"code","source":"!pip install featurewiz --upgrade \n#!python3 -m pip install git+https://github.com/AutoViML/featurewiz.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from featurewiz import FE_kmeans_resampler, FE_find_and_cap_outliers, EDA_find_outliers\nfrom featurewiz import FE_convert_all_object_columns_to_numeric, split_data_n_ways, FE_create_categorical_feature_crosses\nfrom featurewiz import FE_create_time_series_features, FE_concatenate_multiple_columns\nfrom featurewiz import simple_XGBoost_model\nimport featurewiz as FW","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = 'target'\nidcols = ['id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### In regression problems, you might want to convert target into log(target)\n#df[target] = (df[target] - np.mean(df[target]))/np.std(df[target])\n#train[target] = np.log(train[target].values)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:51:50.240377Z","iopub.execute_input":"2021-12-16T11:51:50.240993Z","iopub.status.idle":"2021-12-16T11:51:50.25916Z","shell.execute_reply.started":"2021-12-16T11:51:50.240895Z","shell.execute_reply":"2021-12-16T11:51:50.258499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### you can manually set features you want included in dataset here or automatically\nfeatures = test.columns.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.max_columns', 500)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = train[features+[target]]\ntrain = train[features+[target]]\nprint(train.shape)\ntrain.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[features]\nprint(test.shape)\ntest.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nums = [x for x in df.select_dtypes(include='float').columns.tolist() if x not in [target]]\nnums","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cats = [x for x in df.select_dtypes(include='object').columns.tolist() if x not in [target]]\ncats","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# You can use AutoViz to first get some insights and do additional feature selection or engineering","metadata":{}},{"cell_type":"code","source":"#!pip install autoviz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from autoviz.AutoViz_Class import AutoViz_Class\n#AV = AutoViz_Class()\n#filename = \"\"\n#sep = \",\"\n#dft = AV.AutoViz(\n#    filename,\n#    sep=\",\",\n#    depVar=target,\n#    dfte=train,\n#    header=0,\n#    verbose=0,\n#    lowess=False,\n#    chart_format=\"svg\",\n#    max_rows_analyzed=50000,\n#    max_cols_analyzed=30,\n#)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## These are what I learned from AutoViz Plots on the Tabular Playground Jan 2021 dataset:\nCreate new categorical variables based on:\ncont2 into 9 clusters\ncont3 into 2 clusters\ncont14 into 2 clusters\ncont10 into 2 clusters\ncont4 into 3 clusters\n\nCreate new interaction variables based on:\ncont3, cont14\ncont6, cont7\ncont6, cont9\ncont6, cont12\ncont11, cont12\n\n\nCreate new binning variables based on distributions:\ncont1 4 modes \ncont3 3 modes\ncont11 3 modes\ncont13 might need 4 binning\ncont9 might need 4 binning\ncont 12 might need 9 bins\ncont4 might need 3 bins\n\nIn-situ transform these variables:\ncont12 needs log transformation\ncont8 needs log transformation","metadata":{}},{"cell_type":"markdown","source":"## You can do some binning of numeric columns here using Featurewiz","metadata":{}},{"cell_type":"code","source":"### You can plot to see how this numeric column would be good for binning\n#df['cont2'].hist(bins=30);","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:54:23.790416Z","iopub.execute_input":"2021-12-16T11:54:23.790888Z","iopub.status.idle":"2021-12-16T11:54:23.793979Z","shell.execute_reply.started":"2021-12-16T11:54:23.790833Z","shell.execute_reply":"2021-12-16T11:54:23.793185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## This dictionary tells Featurewiz how many bins for each feature\nbin_dict = {'cont1':4, 'cont2':9, 'cont3':3, 'cont4':3, 'cont6':3,\n            'cont9':4, 'cont10':2, 'cont11':3, \n            'cont12':9, 'cont13':4, 'cont14':2}","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:55:04.974649Z","iopub.execute_input":"2021-12-16T11:55:04.974935Z","iopub.status.idle":"2021-12-16T11:55:04.98Z","shell.execute_reply.started":"2021-12-16T11:55:04.974903Z","shell.execute_reply":"2021-12-16T11:55:04.979032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = FW.FE_discretize_numeric_variables(train, bin_dict, test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binned_cols = [x for x in train.columns if x.endswith('_discrete')]\nlen(binned_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy = train.copy(deep=True)\ntest_copy = test.copy(deep=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now create some groupby aggregates based on the binned variables","metadata":{}},{"cell_type":"code","source":"### This handy function subtracts one list from another\ndef left_subtract(l1,l2):\n    lst = []\n    for i in l1:\n        if i not in l2:\n            lst.append(i)\n    return lst","metadata":{"execution":{"iopub.status.busy":"2021-12-16T11:56:21.119271Z","iopub.execute_input":"2021-12-16T11:56:21.11957Z","iopub.status.idle":"2021-12-16T11:56:21.125193Z","shell.execute_reply.started":"2021-12-16T11:56:21.119538Z","shell.execute_reply":"2021-12-16T11:56:21.124222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remember you can transform highly skewed variables using log_transform","metadata":{}},{"cell_type":"code","source":"col_dict = {'cont12':'log', 'cont8':'log'}\ntrain_copy = FW.FE_transform_numeric_columns(train_copy, col_dict)\ntest_copy = FW.FE_transform_numeric_columns(test_copy, col_dict)\ntrain_copy.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add groupby features based on binned columns above","metadata":{}},{"cell_type":"code","source":"train_copy, test_copy = FW.FE_add_groupby_features_aggregated_to_dataframe(train, agg_types=['mean', 'std'],\n                                    groupby_columns=binned_cols,\n                                    ignore_variables=idcols+[target], test=test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_copy.shape)\ntrain_copy.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_copy.shape)\ntest_copy.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now find outliers and cap them to their second highest values","metadata":{}},{"cell_type":"code","source":"### Take a look at whether it makes sense to cap outliers ###\n_ = FE_find_and_cap_outliers(train,[target],verbose=1)\n#test = FE_find_and_cap_outliers(test,nums,verbose=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## In some cases it makes sense to drop training rows where target is less than a certain number - so it removes outliers","metadata":{}},{"cell_type":"code","source":"train_copy = train_copy[~(train[target]<5)]\n#train_copy[target].hist(bins=30);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now let us select the best variables using featurewiz","metadata":{}},{"cell_type":"code","source":"train_best, test_best = FW.featurewiz(train_copy, \n                        target, test_data=test_copy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = test_best.columns.tolist()\npreds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = preds[1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_best = train_copy[preds+[target]]\ntest_best = test_copy[preds]\nprint(train_best.shape, test_best.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## This simple XGBoost model works wonders since it is highly effective in many competitions","metadata":{}},{"cell_type":"code","source":"y_preds = simple_XGBoost_model(X_XGB=train_best[preds], Y_XGB=train_best[target],\n                               X_XGB_test=test_best[preds], modeltype='Regression')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#subm = test[idcols]\n#subm = pd.DataFrame()\nsubm[target] = y_preds\nsubm.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #!pip3 install --upgrade Pillow","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm.to_csv(target+'_Regression_submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}