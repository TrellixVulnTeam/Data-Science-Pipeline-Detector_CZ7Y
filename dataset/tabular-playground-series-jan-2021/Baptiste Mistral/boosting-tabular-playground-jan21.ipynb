{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Tabular playground series January 2021**\n\nDataset : Open kaggle [dataset](https://www.kaggle.com/c/tabular-playground-series-jan-2021)\n\n## Task\n\nMake a regression model based on a specific dataset. \n\n\n## Files\n\n- `train.csv` : training data with the `target` column. \n- `test.csv` : test set. The trained model will be applied here.\n- `sample_submission.csv` : a sample submission for the test set.\n\n*@author : Baptiste Mistral - Jan2021*"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns \nsns.set()\nimport matplotlib.pyplot as plt\n\npath_input = '../input/tabular-playground-series-jan-2021/'\npath_output = './'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring dataset\n\nWe start first by analysing the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(path_input+'train.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if we have missing data or NaN values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok no problem with data. Let's focus on our target then. We can check its distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(a=data['target'], rug = True, color='g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The 'id' column seems to be useless to predict the target. We delete it to start reducing the amount of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(['id'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = np.zeros_like(data.corr())\nmask[np.tril_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(80, 15))\ncorr = data.corr()\nsns.heatmap(corr, vmax=1, square=True,annot=True,cmap='viridis', mask=mask.T)\n\nplt.title('Correlation between different fearures')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlations between conts and the target are not that obvious. However, we can see that the features itselves are strong-correlated."},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ny = data.target  # all rows, target only\nX = data.drop('target',axis=1)  # all rows, all the features and no target\n\n\nx_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state = np.random.RandomState(0))\nprint(\"training size : {}\\ntest size : {}\".format(x_train.shape,x_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fisrt try Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boost=xgb.XGBRegressor(tree_method='gpu_hist')\nboost.fit(x_train,y_train)\npred = boost.predict(x_test)\nrmse = np.sqrt(mean_squared_error(y_test,pred))\nprint(\"Result : RMSE =\",rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid Search CV - Tuning parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\ndef tune_model(model,params):\n    modelCV = GridSearchCV(estimator=model,\n                             param_grid=params,\n                             cv=3,\n                             n_jobs=-1,\n                             pre_dispatch='8',\n                             scoring='neg_root_mean_squared_error',\n                             verbose=4,\n                             refit=True)\n    modelCV.fit(x_train,y_train)\n    print(\"CV results :\\n{}\\n\".format(modelCV.cv_results_))\n    print(\"-----------\")\n    print(\"Best estimator : \\n{}\\n\".format(modelCV.best_estimator_))\n    print(\"----------------\")\n    print(\"Best parameters : \\n{}\\n\".format(modelCV.best_params_))\n    print(\"-----------------\")\n    print(\"Best score : \\n{}\\n\".format(modelCV.best_score_))\n    print(\"-----------\")\n    return modelCV.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok with verbosity its very explicit. But it was to be sure. You can set verbosity to 1 for less informations. The important parameter is the pre_dispatch parameter. Reducing this number can be useful to avoid an explosion of memory consumption when more jobs get dispatched than CPUs can process. Visit the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) for more details."},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\nparams_xgb={'n_estimators' : [2200,2500,2800],\n            'learning_rate' : [0.01, 0.015, 0.02]}\n\nboost = xgb.XGBRegressor(\n        objective = 'reg:squarederror',\n        subsample = 0.8,\n        colsample_bytree = 0.8,\n        learning_rate = 0.01,\n        tree_method = 'gpu_hist')\n\nbest_xgb=tune_model(boost,params_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boost=xgb.XGBRegressor(**best_xgb,tree_method = 'gpu_hist')\nboost.fit(x_train,y_train)\npred = boost.predict(x_test)\nrmse = np.sqrt(mean_squared_error(y_test,pred))\nprint(\"Result : RMSE =\",rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final prediction and submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = pd.read_csv(path_input+'test.csv')\npred=boost.predict(data_test.drop(\"id\",axis=1))\nsub=pd.DataFrame({\n    \"id\":data_test[\"id\"],\n    \"target\":pred\n})\nsub.to_csv(path_output+'submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}