{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import RepeatedKFold\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom skopt import BayesSearchCV\nfrom scipy.stats import randint \nfrom scipy.stats import uniform\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import mean_squared_error as MSE \nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nimport xgboost as xgb\n\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error \nfrom matplotlib import pyplot as plt\n\nimport warnings \nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nfrom xgboost import XGBRegressor\nfrom tpot import TPOTClassifier\nfrom tpot import TPOTRegressor\nimport time\nfrom scipy.stats import uniform","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import the data\ntrain = pd.read_csv(\"../input/tabular-playground-series-jan-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-jan-2021/test.csv\")\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"train.rename(columns={'target': 'class'}, inplace=True)\ntest.rename(columns={'target': 'class'}, inplace=True)\n\ntargets = train['class'].values\ntrain.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate features from label\ntrain.drop(['id'],axis=1, inplace=True)\n\ny = train['class'].values\nX = train.drop(['class'], axis=1)\n\n# Opsplitsen in test en training_set met 1000 waarden in test set en random_state = 0. Normaliseer de features.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)   #Splitting train and test data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluateModel(X_test, y_test, model):\n\n    y_predicted = model.predict(X_test)\n\n    ## Mean Absolute Error\n    MAE = mean_absolute_error(y_test, y_predicted)\n    print('MAE = ',MAE)\n\n    ## Mean Squared Error\n    MSE = mean_squared_error(y_test, y_predicted)\n    print('MSE = ',MSE)\n\n    ## coefficient of determination = r2 score\n    r2 = r2_score(y_test, y_predicted)\n    print('Test r2 score = ',r2)\n    \n    ## R2 score on train set\n    y_predicted = model.predict(X_train)\n    r2 = r2_score(y_train, y_predicted)\n    print('Train r2 score = ',r2)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# define evaluation procedure\ncv = RepeatedKFold(n_splits=4, n_repeats=3, random_state=1)\ntpot = TPOTRegressor(verbosity=2, max_time_mins=320, max_eval_time_mins=0.5, population_size=1000, n_jobs=-1, scoring='neg_mean_squared_error',cv=cv)\ntpot.fit(X_train, y_train)\nprint(tpot.score(X_test, y_test))\n\n# Predict the model \npred = tpot.predict(X_test) \n  \n# RMSE Computation \nrmse = np.sqrt(MSE(y_test, pred)) \nprint(\"RMSE : % f\" %(rmse)) \n\nevaluateModel(X_test, y_test, tpot) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Seperate features from label\n# train.drop(['id'],axis=1, inplace=True)\n\n# y = train['target'].values\n# X = train.drop(['target'], axis=1)\n\n# # Opsplitsen in test en training_set met 1000 waarden in test set en random_state = 0. Normaliseer de features.\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)   #Splitting train and test data\n\n# scaler = preprocessing.StandardScaler().fit(X_train)\n# scaler = preprocessing.RobustScaler().fit(X_train)\n# scaler = preprocessing.MinMaxScaler().fit(X_train)\n\n# the data is fitted onto the train data, and applied to both train and test features\n# X_train = scaler.transform(X_train)\n# X_test = scaler.transform(X_test)\n# X_Kaggle = scaler.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"%%time\nax = sns.pairplot(train.sample(1000), hue='target')"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# # Instantiation \n# xgb_r = xgb.XGBRegressor(objective ='reg:squarederror', \n#                   n_estimators = 100, \n#                         tree_method = 'gpu_hist',\n#                         max_depth = 2,\n#                         n_jobs  = -1,\n#                         seed = 42,\n#                        verbosity=2) \n  \n# # Fitting the model \n# xgb_r.fit(X_train, y_train) \n  \n# # Predict the model \n# pred = xgb_r.predict(X_test) \n  \n# # RMSE Computation \n# rmse = np.sqrt(MSE(y_test, pred)) \n# print(\"RMSE : % f\" %(rmse)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Various hyper-parameters to tune\n# xgb1 = XGBRegressor()\n# parameters = {'objective':['reg:squarederror'],#'reg:linear', \n#               'max_depth': [1, 2, 3, 4], #5, 6, 7, 10, 20\n#               'min_child_weight': [4],\n#               'subsample': [0.7],\n#               'colsample_bytree': [0.7],\n#               'tree_method' : ['gpu_hist'],\n#               'n_estimators': [1, 10, 20, 30, 50, 100, 200, 300, 500, 1000, 2000, 5000]}# , \n\n# xgb_grid = GridSearchCV(xgb1,\n#                         parameters,\n#                         cv = 4,\n#                         n_jobs = -1,\n#                         scoring = 'neg_mean_squared_error',\n#                         verbose=5)\n\n# xgb_grid.fit(X_train, y_train)\n\n# print(xgb_grid.best_score_)\n# print(xgb_grid.best_params_)\n\n# # Predict the model \n# pred = xgb_r.predict(X_test) \n  \n# # RMSE Computation \n# rmse = np.sqrt(MSE(y_test, pred)) \n# print(\"RMSE : % f\" %(rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# regr = RandomForestRegressor(n_estimators=200, n_jobs=-1, max_depth=20, verbose=5, random_state=0)\n# regr.fit(X, y)\n\n# pred = regr.predict(X_test)\n# rmse = np.sqrt(MSE(y_test, pred))\n# print(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## NN Classiefier\n# from keras.layers import LeakyReLU\n\n# NN_model = Sequential()\n\n# # The Input Layer :\n# NN_model.add(Dense(2000, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n\n# # The Hidden Layers :\n# NN_model.add(LeakyReLU(alpha=0.05))\n# NN_model.add(LeakyReLU(alpha=0.05))\n# NN_model.add(LeakyReLU(alpha=0.05))\n# NN_model.add(LeakyReLU(alpha=0.05))\n\n\n# # The Output Layer :\n# NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n\n# # Compile the network :\n# NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_squared_error'])\n# NN_model.summary()\n\n# checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n# checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n# callbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# NN_model.fit(X_train, y_train, epochs=50, batch_size=4000, validation_split = 0.2, callbacks=callbacks_list)\n\n# pred = NN_model.predict(X_test)\n# rmse = np.sqrt(MSE(y_test, pred))\n# print(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred = NN_model.predict(X_test)\n# NNrmse = np.sqrt(MSE(y_test, pred))\n# print(\"RMSE : % f\" %(NNrmse))\n\n# # Predict the model \n# pred = xgb_r.predict(X_test) \n# Xgbrmse = np.sqrt(MSE(y_test, pred)) \n# print(\"RMSE : % f\" %(Xgbrmse))\n\n\n#sub.to_csv('submission.csv',index=False)\n\n\n    \n# features = [f'cont{x}'for x in range(1,15)]\n# preds = NN_model.predict(test.loc[:,features].values)\n# sub = pd.DataFrame({'id':test.id, 'target':preds})\n# sub.to_csv('NN_submission.csv', index=False)\n# print('Done NN')\n# #else:\n# features = [f'cont{x}'for x in range(1,15)]\n# preds = Xgb_r.predict(test.loc[:,features].values)\n# sub = pd.DataFrame({'id':test.id, 'target':preds})\n# sub.to_csv('XGB_submission.csv', index=False)\n# print('Done XGB')\n\nfeatures = [f'cont{x}'for x in range(1,15)]\npreds = tpot.predict(test.loc[:,features].values)\nsub = pd.DataFrame({'id':test.id, 'target':preds})\nsub.to_csv('submission.csv', index=False)\nprint('- Done TPOT -')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}