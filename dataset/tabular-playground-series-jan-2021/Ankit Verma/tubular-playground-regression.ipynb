{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets import the basic libraries first then we will proceed to the others as the need arises\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the test and train data\ntrain_original  = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')\ntest_original = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the sample\nsample = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# i like to do it this way i.e. preserve the original data.... just in case if i went wrong somewhere.\n# it can also lead to confusion and multiplicity of variable so one has to be careful\ntrain = train_original.copy()\ntest = test_original.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying the train data\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets see the test data as well\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the Basic data hygiene and preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"300000 rows and 16 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check the null values if any\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No null values here... so one less thing to deal with"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check if there are any duplicates\ntrain.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good no duplicates..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check the test data\ntest.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"200000 rows and 15 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No duplicates"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No categorical variables. Hence no encoding of variables will be required later"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets drop the id column. Else it will interfere with the regression results. \ntrain.drop(['id'], axis=1,inplace=True)\ntest.drop(['id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets see the stats for train dataset\ntrain.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA 1.0\n\nlets explore the datasets. if there's any processing required, we will do it and perform the EDA again. Hence this is EDA 1.0"},{"metadata":{},"cell_type":"markdown","source":"First lets check the distribution of the variables, and see how test and train datasets vary in this "},{"metadata":{"trusted":true},"cell_type":"code","source":"figure, ax = plt.subplots(7,2,figsize=(15,30))\nc=1\nfor i in train.drop(['target'],axis=1).columns:\n    plt.subplot(7,2,c)\n    sns.distplot(train[i],color = 'blue', label='train')\n    sns.distplot(test[i],color = 'red', label='test')\n    c=c+1\n    plt.xlabel(i, fontsize=9)\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. both the test and train datasets have the same distribution. So we can say that the test and train datasets are quite identical\n2. Most variables are not normally distributed. (Not that they are required to be)\n3. there could be some outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets checkhow variables vary with respect to the other. This will help us identify any multicollinearity\nsns.pairplot(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmmm..... Independent variables do not show any specific correlation with each other. Also the target variable doesnot seem to be correlated with any of the independent variables.\n\nWe will further check for correlation in the heatmap. But even if any of the independent variables show any correlation there, it will be difficult to conclude that there is actually a correlation between them. To me the dataset variables seem like randomly generated numbers. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets draw the correlation heatmap \nplt.figure(figsize=(20,20))\nsns.heatmap(train.corr(),annot=True, cmap = 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Heatmap above does show quite a few variables correlated. But again, it is difficult to ascertain that there is a correlation. Hence we will keep these variables in the dataset. Else I would have remove the correlated variables.\n\nAlso we should note that none of the independent variables show any correlation with the target. there seems to be too much noise in the dataset. We should expect low R-Square values in the Regression model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check for the outliers\nplt.figure(figsize=(20,10))\nsns.boxplot(data=train.drop(['target'],axis=1))\nplt.title('The boxplot to study outliers')\nplt.xlabel('Variables that predict the Target')\nplt.ylabel('Values')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The scale of all the variables look similar. Hence there is no need to perform the scaling.\n\nNo outlier treatment is required since the test and the train data are absolutely identical.\n\nVariables such as cont2, count4, cont5, cont8 are skewed and cont 11, con12, cont 14 have double peaks in the data. \n\nTypically these might represent the different clusters. \n"},{"metadata":{},"cell_type":"markdown","source":"# Analysing the target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The target variable should be normally distributed all the values of the independent variables.\n# lets check if the target variable is normally distributed\n# lets check with the distplot first\n\nsns.distplot(train['target'],color = 'blue', label='train')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The target variable is double peaked. Can't say if it is normally distributed. If it not we will need to transform it so that it becomes normal"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.gofplots import qqplot\nqqplot(train['target'], line='s')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From qq plot, it seems that the target is normally distributed."},{"metadata":{},"cell_type":"markdown","source":"# Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the libraries\nfrom sklearn.model_selection import train_test_split\nX = train.drop(['target'],axis=1)\ny = train['target']\nX_train, X_test,y_train, y_test = train_test_split(X,y, train_size=0.75, random_state=42) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The train test function gives 4 values: \n1. first is the train dataframe (without target)\n1. second value is the test dataframe(without target)\n1. third is the training dataframe of target variable\n1. fourth is the test dataframe of target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Linear Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import linear regression library\n\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining a variable to store the linear regression function for ease of use\n\nreg_model = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, col_name in enumerate(X_train.columns):\n    print(\"The coefficient for\",col_name, \"is\", reg_model.coef_[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us check the intercept for the model\n\nintercept = reg_model.intercept_\n\nprint(\"The intercept for our model is\", intercept)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# R^2 value of the train dataset\nreg_model.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that the R square value is very low as expected. There is a lot of noise in the train as well as test datasets. Typically we would see some pattern in the data while plotting the correlation heatmap and the scatter plots.\n\nFor a good model the R^2 and adjusted R^2 values would be close to 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# R^2 value of the test dataset\nreg_model.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Same case with the test data, the R square value is very low"},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression using Statsmodels"},{"metadata":{},"cell_type":"markdown","source":"R^2 is not a reliable metric as it always increases with addition of more attributes even if the attributes have no influence on the predicted variable.\n\nInstead we use adjusted R^2 which removes the statistical chance that improves R^2.\n\nScikit does not provide a facility for adjusted R^2, so we use statsmodel, a library that gives results similar to what you obtain in R language. This library expects the X and Y to be given in one single dataframe\n\nfurther we can immprove the model by backward elimination"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.concat([X_train, y_train], axis=1)\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# forming the regression equation\n\nreg_expression = 'target ~ cont1+cont2+cont3+cont4+cont5+cont6+cont7+cont8+cont9+cont10+cont11+cont12+cont13+cont14'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.formula.api as smf\nmodel1 = smf.ols(formula=reg_expression, data=data_train).fit()\n# displaying first 5 parameters\nmodel1.params.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model1.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.regression.linear_model import RegressionResults\nnp.sqrt(model1.mse_resid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.rsquared_adj","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# forming the second regression equation\n\nreg_expression_2 = 'target ~ cont1+cont2+cont3+cont4+cont5+cont6+cont7+cont8+cont9+cont10+cont11+cont12+cont13'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = smf.ols(formula=reg_expression_2, data=data_train).fit()\n# displaying first 5 parameters\nmodel2.params.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(model2.mse_resid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.rsquared_adj","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# another way of finding RSME\nfrom sklearn.metrics import mean_squared_error\nprint(\"model1 train RMSE:\", np.sqrt(mean_squared_error(y_train, model1.predict(X_train))))\nprint(\"model1 test RMSE:\", np.sqrt(mean_squared_error(y_test, model1.predict(X_test))))\nprint(\"model2 train RMSE:\", np.sqrt(mean_squared_error(y_train, model2.predict(X_train))))\nprint(\"model2 test RMSE:\", np.sqrt(mean_squared_error(y_test, model2.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ridge and Lasso"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import linear models\nfrom sklearn import linear_model\n# Create lasso and ridge objects\nlasso = linear_model.Lasso()\nridge = linear_model.Ridge()\n# Fit the models\nlasso.fit(X_train, y_train)\nridge.fit(X_train, y_train)\n# Print scores, MSE, and coefficients\nprint(\"R^2_lasso score:\", lasso.score(X_train, y_train))\nprint(\"R^2_ridge score:\",ridge.score(X_train, y_train))\nprint(\"lasso RMSE:\", np.sqrt(mean_squared_error(y_test, lasso.predict(X_test))))\nprint(\"ridge RMSE:\", np.sqrt(mean_squared_error(y_test, ridge.predict(X_test))))\nprint(\"lasso coef:\", lasso.coef_)\nprint(\"ridge coef:\", ridge.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets compare the RSME values of all the models that we have built\nprint(\"model1 test RMSE:\", np.sqrt(mean_squared_error(y_test, model1.predict(X_test))))\nprint(\"model2 test RMSE:\", np.sqrt(mean_squared_error(y_test, model2.predict(X_test))))\nprint(\"lasso test RMSE:\", np.sqrt(mean_squared_error(y_test, lasso.predict(X_test))))\nprint(\"ridge test RMSE:\", np.sqrt(mean_squared_error(y_test, ridge.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"out of all, model2 performs the best. \n\nwith lasso since all the coefficients are 0, we will omit the lasso"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predicted_ols = model2.predict(test)\ntest_predicted_ols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test_original['id']\ntest_pred = pd.DataFrame(test_predicted_ols)\nsubmission = pd.concat([submission,test_predicted_ols],axis=1)\nsubmission.rename({0:'target'},axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check the distribution of the predicted values of the v/s original target values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['target'],color = 'blue', label='train')\nsns.distplot(submission['target'],color = 'red', label='test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well even though the model RSME was 0.73, we can see above, that the prediction might not be very good. Lets submit and check whats the score. "},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"result.csv\", index = False, header = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}