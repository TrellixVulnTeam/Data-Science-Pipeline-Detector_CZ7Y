{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing libraries\n\nImporting all the necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport os\n\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler,StandardScaler,OneHotEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error,auc\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse(y_true, y_pred):\n    return mean_squared_error(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train.drop('id', axis = 1)\ntest_df = test.drop('id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop('target', axis = 1)\ny = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Different Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso = Lasso(alpha=0.0005, random_state = 1,max_iter=100)\n\nENet = ElasticNet(alpha = 0.0005, l1_ratio=0.9, random_state = 3,max_iter=100)\n\nGBoost = GradientBoostingRegressor(n_estimators = 100,learning_rate=0.05,\n                                   max_depth = 10, random_state=5)\n\nmodel_rf = RandomForestRegressor(max_depth=17,n_estimators=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [lasso,ENet,GBoost,model_rf]\nscores={}\nfor model in models:\n    print(model)\n    model.fit(X,y)\n    tr_pred = model.predict(X)\n    scores[model] = rmse(y,tr_pred)\n    print(scores[model])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stacked regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=3):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X.iloc[train_index], y[train_index])\n                y_pred = instance.predict(X.iloc[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, model_rf),\n                                                 meta_model = lasso)\n\n\nstacked_averaged_models.fit(X, y)\n\nstacked_train_pred = stacked_averaged_models.predict(X)\n# stacked_pred = np.expm1(stacked_averaged_models.predict(test_))\nprint(rmse(y, stacked_train_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting for the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = stacked_averaged_models.predict(test)\ntest_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['target'] = test_pred\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}