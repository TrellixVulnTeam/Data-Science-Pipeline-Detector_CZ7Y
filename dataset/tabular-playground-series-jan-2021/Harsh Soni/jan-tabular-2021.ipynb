{"cells":[{"metadata":{},"cell_type":"markdown","source":"The notebook was created after studying [this notebook](https://www.kaggle.com/ankitverma2010/tubular-playground-regression). "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Maths and data imports\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\n\n# Plots imports\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# ML modeling imports\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '/kaggle/input/tabular-playground-series-jan-2021/train.csv'\ntest_path = '/kaggle/input/tabular-playground-series-jan-2021/test.csv'\n\ntrain = pd.read_csv(train_path, index_col='id')\ntest = pd.read_csv(test_path, index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train.copy()\ntest_df = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the shape, to find the number of examples and features in training data\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for null values\ntrain_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let check for duplicate examples\ntrain_df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the dtype (examine no of categorical and numerical features)\ntrain_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets see some stats\ntrain_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(7, 2, figsize=(15, 30))\n\nfor i, ax in zip(train_df.drop(['target'], axis=1), axs.flatten()):\n    sns.distplot(train_df[i], ax=ax, label='Train')\n    sns.distplot(test_df[i], ax=ax, color='red', label='Test')\n    ax.set_xlabel(i)\n    ax.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check for (multi)collinearity\nsns.pairplot(train_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\n* The explanatory variables don't seem to be multicollinear\n* No explanatory variable seems to be correlated to the targets\n* Further inspection required"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\nsns.heatmap(train_df.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_df.corr()\n\nfor col in corr.columns:\n    for rel_col in corr[col][corr[col] > 0.7].index:\n        if rel_col != col:\n            print((col, rel_col))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nThere seem to be quite a few correlated (positively) variables. Let's try leaving them for now. (may be we'll look at them in the next iteration)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check for outliers and skewness\nfig = plt.figure(figsize=(20, 10))\nsns.boxplot(data=train_df.drop(['target'], axis=1))\nplt.xlabel('Exploratory Variables')\nplt.ylabel('Values')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\n* The exploratory variables seem almost in the same range, so, we'll skip standardization for now.\n* Few variables such as, count2, count3, count5, count8 etc seem to be skewed. Lets confirm it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check for skewness again\nfig = plt.figure(figsize=(20, 10))\nsns.violinplot(data=train_df.drop(['target'], axis=1))\nplt.xlabel('Exploratory Variable')\nplt.ylabel('Values')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\n* count5, count13 seem to be right skewed\n* Most of the variables seem to have multiple peaks \n\nMaybe they have muliple clusters"},{"metadata":{},"cell_type":"markdown","source":"## Analysing the response/target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let draw its distribution, if it's not normal let's convert it to normal\nfig = plt.figure(figsize=(10, 5))\nsns.distplot(train_df['target'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nThis seems like a bimodeal distribution. It could be the case that it is created by mixing two normal distribuitons. Let's confirm."},{"metadata":{"trusted":true},"cell_type":"code","source":"# import statsmodels.api as sm\n\n# fig = plt.figure(figsize=(10, 5))\n# sm.qqplot(train_df['target'], line='s')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = (train_df.target - train_df.target.mean()) / train_df.target.std()\n\nfig = plt.figure(figsize=(5, 5))\nstats.probplot(z, dist='norm', plot=plt)\nplt.xlabel('Theoretical Quantiles')\nplt.ylabel('Experimental Quantiles')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nSeems like a normal distribution."},{"metadata":{},"cell_type":"markdown","source":"## Train Dev Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop(['target'], axis=1)\ny = train_df['target']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_valid.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\n    'RFR': RandomForestRegressor,\n    'ABR': AdaBoostRegressor,\n    'XGBR': XGBRegressor\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model(name, model, train_ds, valid_ds):\n    X, y = train_ds\n    X_val, y_val = valid_ds\n    \n    model.fit(X, y)\n    y_hat = model.predict(X)\n    y_hat_val = model.predict(X_val)\n    \n    mse = mean_squared_error(y, y_hat)\n    mse_val = mean_squared_error(y_val, y_hat_val)\n    \n    print(f'Model: {name}, Train MSE: {mse}, Val MSE: {mse_val}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_est = [10, 25, 50, 100, 200]\nfor i in range(len(n_est)):\n    print(f'n_estimators: {n_est[i]}')\n    for name, model in models.items():\n        model = model(n_estimators=n_est[i])\n        fit_model(name, model, (X_train, y_train), (X_valid, y_valid))\n    print('-'*20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nIt seems `AdaBoostRegressor` and `XGBRegressor` tend to perform good with `n_estimators=50` and `n_estimators=100` respectively. At `n_estimators=100`, `XGBRegressor` seem to slightly overfit.\n\nLets try an ensembel of both."},{"metadata":{"trusted":true},"cell_type":"code","source":"abr = AdaBoostRegressor(n_estimators=100)\nxgbr = XGBRegressor(n_estimators=50)\n\nabr.fit(X_train, y_train)\nxgbr.fit(X_train, y_train)\n\ny_hat1, y_hat2 = abr.predict(X_valid), xgbr.predict(X_valid)\ny_hat = (y_hat1+y_hat2)/2\nmse = mean_squared_error(y_valid, y_hat)\nprint(f'Ensembel MSE: {mse}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = (abr.predict(test_df) + xgbr.predict(test_df))/2\nsubmission = pd.DataFrame(pred, columns=['target'])\nsubmission = pd.concat([pd.DataFrame(test_df.index), submission], axis=1)\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20, 10))\nsns.distplot(train['target'], label='Train')\nsns.distplot(submission['target'], color='red', label='Test')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nThe result seems to have a normal distribution, but its a huge peak, so, we can expect an okaish performance on the test set. We can reiterate and try out a couple of things to make the model better."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('result.csv', index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}