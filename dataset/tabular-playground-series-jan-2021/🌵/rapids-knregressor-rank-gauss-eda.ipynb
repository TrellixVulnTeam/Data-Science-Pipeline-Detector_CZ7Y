{"cells":[{"metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA\nfrom scipy.special import erfinv\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nimport cuml\nfrom cuml.neighbors import KNeighborsRegressor as KNR\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-jan-2021/train.csv\")\nX = train.iloc[:,1:15]\nY = train.iloc[:,15]\ntest = pd.read_csv(\"../input/tabular-playground-series-jan-2021/test.csv\")\ntest = test.iloc[:,1:15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let´s take a look at the data:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, p = plt.subplots(7, 2, figsize=(20,40))\n\nr=0\nc=0\ni=\"cont1\"\nfor i in X.columns:\n \n    p[r, c].scatter(X[i], Y, \n                    lw=2, \n                    color=\"#440154FF\", \n                    alpha=0.4,\n                    edgecolors='#FDE725FF')\n    \n    p[r, c].set_xlabel(i)\n    \n    if c == 0:\n        p[r, c].set_ylabel('target')\n    \n    if r == 0:\n        p[r, c].set_title('Scatter Plot')\n    \n    if c < 1:\n        c+=1\n    else:\n        c=0\n        r+=1\n        \nplt.show()     ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, p = plt.subplots(7, 2, figsize=(20,40))\n\nn_bins = 50\n\nr=0\nc=0\ni=\"cont1\"\nfor i in X.columns:\n    \n    tr = X[i]\n    te = test[i]\n    \n    p[r, c].hist(tr, \n                 n_bins, \n                 density=True, \n                 histtype='bar', \n                 color=\"#440154FF\", \n                 label='train', \n                 linestyle='dashed',\n                 edgeColor = 'white')\n    \n    p[r, c].hist(te, \n                 n_bins, \n                 density=True, \n                 histtype='bar', \n                 color=\"#FDE725FF\", \n                 label='test', \n                 alpha=0.6)\n    \n    p[r, c].legend(loc='upper right')\n    p[r, c].set_xlabel(i)\n    \n    if c == 0:\n        p[r, c].set_ylabel('frequency')\n    \n    if r == 0:\n        p[r, c].set_title('Histogram')\n    \n    if c < 1:\n        c+=1\n    else:\n        c=0\n        r+=1\n        \nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalization for PCA using Rank Gauss**"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"def rg(df, e, start, end):\n    for i in df.columns[start:end]:\n        r = df[i].rank()\n        Range = (r/np.max(r)-0.5)*2\n        Range = np.clip(Range, a_max = 1-e, a_min = -1+e)\n        rg = erfinv(Range)\n        df[i] = rg * 2**0.5\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def norm(df, start, end):\n    for i in df.columns[start:end]:\n        df[i] = (df[i] - np.mean(df[i])) / np.std(df[i])\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"X[\"part\"] = 1\ntest[\"part\"] = 0\n\nXx = pd.concat([X, test])\nXx = Xx.reset_index(drop=True)\nXx.loc[Xx.index.duplicated(),:]\n\nXx = rg(df = Xx, e = 0.00001, start = 0, end = 14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This leads to perfect normal distribution**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, p = plt.subplots(7, 2, figsize=(20,40))\n\nn_bins = 50\n\nr=0\nc=0\ni=\"cont1\"\nfor i in Xx.columns[0:len(Xx.columns)-1]:\n    \n    tr = Xx.loc[Xx[\"part\"] == 1, i]\n    te = Xx.loc[Xx[\"part\"] == 0, i]\n    \n    p[r, c].hist(tr, \n                 n_bins, \n                 density=True, \n                 histtype='bar', \n                 color=\"#440154FF\", \n                 label='train', \n                 linestyle='dashed',\n                 edgeColor = 'white')\n    \n    p[r, c].hist(te, \n                 n_bins, \n                 density=True, \n                 histtype='bar', \n                 color=\"#FDE725FF\", \n                 label='test', \n                 alpha=0.6)\n    \n    p[r, c].legend(loc='upper right')\n    p[r, c].set_xlabel(i)\n    \n    if c == 0:\n        p[r, c].set_ylabel('frequency')\n    \n    if r == 0:\n        p[r, c].set_title('Histogram')\n    \n    if c < 1:\n        c+=1\n    else:\n        c=0\n        r+=1\n        \nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PCA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"treshold = 0.975\n\npca = PCA()\npca.fit(Xx.iloc[:,0:14])\ncumPCA = np.cumsum(pca.explained_variance_ratio_)\nn_comps = np.min(np.where(cumPCA >= treshold))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cols = list((\"PC\" + str(i) for i in range(1,15))) #generator\nxPos = list(range(len(cumPCA)))\n\np = plt.figure(figsize = (16,9))\np = plt.bar(xPos, cumPCA, color=\"#440154FF\")\np = p[n_comps].set_color('#FDE725FF')\np = plt.axhline(y=treshold,linewidth=2, color=\"#1F968BFF\", alpha=0.8, ls='dashed')\np = plt.xticks(xPos, cols)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = n_comps+1)\nPCs = pca.fit_transform(Xx.iloc[:,0:14])\n\npcaXx = pd.DataFrame(data=PCs, #values\n                     index=list(range(len(PCs))), #rows   \n                     columns=cols[0:n_comps+1] #columns\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pcaXx.loc[Xx[\"part\"] == 1, pcaXx.columns[0:11]]\ntest = pcaXx.loc[Xx[\"part\"] == 0, pcaXx.columns[0:11]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let´s take a look at the three most important principal components."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"viz = pd.concat([X,Y], axis = 1)\nviz = viz.loc[viz[\"target\"] > 4.5,:]\nz =  np.random.uniform(low=0.0, high=1.0, size=len(viz))\nviz = viz.loc[z > 0.8,:]\n\nfig = px.scatter_3d(viz, \n                    x='PC1', \n                    y='PC2', \n                    z='PC3',\n                    color='target',\n                    hover_data={'PC1': False, \n                                'PC2': False,\n                                'PC3': False,\n                                'target': True\n                         },\n                 opacity=1,\n                 color_continuous_scale=px.colors.sequential.Viridis,\n                 title=\"PCA\")\n\nfig.update_traces(marker=dict(size=4,\n                              line=dict(width=1,\n                                        color='grey')),\n                  selector=dict(mode='markers'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**KNN**"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"KFold = KFold(n_splits=folds, \n              shuffle=False, \n              random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nMSE = []\nk = 0\n\nfor train_index, test_index in KFold.split(X):\n    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n    model = KNR(n_neighbors = 200)\n    model.fit(X_train, y_train)\n    PredCV = model.predict(X_test)\n    MSE.append(mean_squared_error(y_test, PredCV))\n    \n    if k == 0:\n        Pred = model.predict(test) / folds\n    else:\n        Pred = Pred + model.predict(test) / folds\n        \n    k +=1\n    ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"RMSE by fold is: \", np.sqrt(MSE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SamSub = pd.read_csv(\"../input/tabular-playground-series-jan-2021/sample_submission.csv\")\nSamSub[\"target\"] = Pred\n\nSamSub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}