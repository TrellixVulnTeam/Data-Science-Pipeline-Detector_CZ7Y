{"cells":[{"metadata":{},"cell_type":"markdown","source":"# TabNet for Tabular data\nTabNet is a Transformer-based Deep Learning model which is developed by Google researchers. A PyTorch implementation that is sklearn-friendly can be found here: https://github.com/dreamquark-ai/tabnet\n\nHere is the original paper: https://arxiv.org/pdf/1908.07442.pdf"},{"metadata":{},"cell_type":"markdown","source":"# Install TabNet and load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\ntry:\n    from pytorch_tabnet.tab_model import TabNetRegressor\nexcept:\n    !pip install ../input/officialpytorchtabnet/pytorch_tabnet-3.0.0-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport torch\nfrom torch import nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import KFold\n\ntrain = pd.read_csv(\"../input/tabular-playground-series-jan-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-jan-2021/test.csv\")\nsub = pd.read_csv(\"../input/tabular-playground-series-jan-2021/sample_submission.csv\")\ntrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Drop the ID column"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop([\"id\"], axis=1)\nfeatures = [c for c in train.columns if \"cont\" in c]\ntest = test.drop(\"id\", axis=1)\ntest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"fe = dict(\n    rankgauss = False,\n    stats = True,\n    gaussmix = True,\n    pca = True,\n    tsne = True,\n    umap = True,\n    drop_original = True,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.concat([train, test], axis=0, ignore_index=True)\ntargets = all_data.target[:300000]\nall_data = all_data.drop(\"target\", axis=1)\nCOLS = [c for c in all_data.columns if \"cont\" in c]\nall_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tqdm\n\nif fe[\"stats\"]:\n    for stats in tqdm.tqdm([\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]):\n        all_data[\"cont_\" + stats] = getattr(all_data[COLS], stats)(axis = 1)\n        \nall_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append(\"../input/rank-gauss\")\nfrom gauss_rank_scaler import GaussRankScaler\n\nif fe[\"rankgauss\"]:\n    scaler = GaussRankScaler()\n    rankgauss_feat = scaler.fit_transform(all_data[COLS])\n    rankgauss_df = pd.DataFrame(rankgauss_feat, columns=[f\"rankgauss_{i}\" for i in range(rankgauss_feat.shape[1])])\n    all_data = pd.concat([all_data, rankgauss_df], axis=1)\nall_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n\nif fe[\"gaussmix\"]:\n    def get_gmm_class_feature(feat, n):\n        gmm = GaussianMixture(n_components=n, random_state=42)\n\n        gmm.fit(all_data[feat].values.reshape(-1, 1))\n\n        all_data[f'{feat}_class'] = gmm.predict(all_data[feat].values.reshape(-1, 1))\n\n    get_gmm_class_feature('cont1', 4)\n    get_gmm_class_feature('cont2', 10)\n    get_gmm_class_feature('cont3', 6)\n    get_gmm_class_feature('cont4', 4)\n    get_gmm_class_feature('cont5', 3)\n    get_gmm_class_feature('cont6', 2)\n    get_gmm_class_feature('cont7', 3)\n    get_gmm_class_feature('cont8', 4)\n    get_gmm_class_feature('cont9', 4)\n    get_gmm_class_feature('cont10', 8)\n    get_gmm_class_feature('cont11', 5)\n    get_gmm_class_feature('cont12', 4)\n    get_gmm_class_feature('cont13', 6)\n    get_gmm_class_feature('cont14', 6)\n    CLASS_COLS = [c for c in all_data.columns if \"_class\" in c]\n    CLASS_COLS_IDX = []\n    for c in CLASS_COLS:\n        CLASS_COLS_IDX.append(all_data.columns.get_loc(c))\n    assert len(CLASS_COLS) > 0\nall_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\nif fe[\"pca\"]:\n    pca = PCA(n_components = 0.8, random_state = 42).fit(all_data[COLS])\n    pca_feat = pca.transform(all_data[COLS])\n    pca_df = pd.DataFrame(pca_feat, columns = [f\"pca_cont{i}\" for i in range(pca.n_components_)])\n    all_data = pd.concat([all_data, pca_df], axis=1)\n    PCA_COLS = [c for c in all_data.columns if \"pca\" in c]\n    assert len(PCA_COLS) > 0\n\nall_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from cuml import TSNE\n\nif fe[\"tsne\"]:\n    tsne_components = 2\n    \n    perplexity = [10, 20, 30, 40, 50]\n    for per in perplexity:\n        tsne = TSNE(n_components = tsne_components, perplexity = per, n_neighbors = 3.01 * per)\n        tsne_feat = tsne.fit_transform(all_data[COLS])\n        tsne_df = pd.DataFrame(tsne_feat, columns=[f\"tsne_{per}_{i}\" for i in range(tsne_components)])\n        all_data = pd.concat([all_data, tsne_df], axis = 1)\n    TSNE_COLS = [c for c in all_data.columns if \"tsne\" in c]\nall_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from cuml import UMAP\n\nif fe[\"umap\"]:\n    umap_components = 10\n    umap = UMAP(n_components = umap_components)\n    umap_feat = umap.fit_transform(all_data[COLS])\n    umap_df = pd.DataFrame(umap_feat, columns=[f\"umap{i}\" for i in range(umap_components)])\n    all_data = pd.concat([all_data, umap_df], axis=1)\n    UMAP_COLS = [c for c in all_data.columns if \"umap\" in c]\n    assert len(UMAP_COLS) > 0\nall_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if fe[\"drop_original\"]:\n    all_data = all_data.drop(COLS, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = all_data[:300000]\ntest = all_data[300000:]\nfeatures = list(all_data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the model\nWe will not use any Feature Engineering technique to test the model's power!"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"MAX_EPOCHS = 200\nBATCH_SIZE = 512\nVIRTUAL_BS = 32\nSEED = 421789\nN_SPLITS = 5\ntabnet_params = dict(\n    n_d = 16,\n    n_a = 16,\n    n_steps = 3,\n    gamma = 1.2,\n    lambda_sparse = 1e-5,\n    optimizer_fn = optim.RMSprop,\n    optimizer_params = dict(lr = 2e-2, weight_decay=1e-5),\n    mask_type = \"entmax\",\n    scheduler_params = dict(\n        mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n    scheduler_fn = ReduceLROnPlateau,\n    seed = SEED,\n    verbose = 1,\n    cat_idxs = CLASS_COLS_IDX if fe[\"gaussmix\"] else None\n)\n\n\npredictions = np.zeros((N_SPLITS, len(test), 1))\nfor fold, (tr_idx, val_idx) in enumerate(KFold(n_splits=N_SPLITS, shuffle=True).split(train, targets)):\n    print(f\"FOLD: {fold}\")\n    X_tr, y_tr = train.loc[tr_idx, features].values, targets[tr_idx].values.reshape(-1, 1)\n    X_val, y_val = train.loc[val_idx, features].values, targets[val_idx].values.reshape(-1, 1)\n    \n    model = TabNetRegressor(**tabnet_params)\n    model.fit(\n        X_train = X_tr,\n        y_train = y_tr,\n        eval_set = [(X_val, y_val)],\n        eval_metric = [\"rmse\"],\n        max_epochs = MAX_EPOCHS,\n        batch_size = BATCH_SIZE,\n        virtual_batch_size = VIRTUAL_BS,\n        num_workers = 1,\n        drop_last=False,\n        patience = 20\n    )\n    predictions[fold] = model.predict(test.values)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get mean of predictions and submit!"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[\"target\"] = predictions.mean(axis=0)\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}