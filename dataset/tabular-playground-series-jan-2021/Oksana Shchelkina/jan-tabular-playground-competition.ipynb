{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\n        \ninput_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read in the data files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(input_path / 'train.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nplt.figure(figsize = (14,6))\nsns.heatmap(train.corr(),annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(input_path / 'test.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(input_path / 'sample_submission.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pull out the target, and make a validation split"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train.pop('target')\nX_train, X_test, y_train, y_test = train_test_split(train, target, train_size=0.60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot results"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_results(name, y, yhat, num_to_plot=10000, lims=(0,12), figsize=(6,6)):\n    plt.figure(figsize=figsize)\n    score = mean_squared_error(y, yhat, squared=False)\n    plt.scatter(y[:num_to_plot], yhat[:num_to_plot])\n    plt.plot(lims, lims)\n    plt.ylim(lims)\n    plt.xlim(lims)\n    plt.title(f'{name}: {score:0.5f}', fontsize=18)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names = [\"Dummy Median\", \"Linear\",  \"Lasso\", \"Random Forest\"]\n\nmodels = [\n    DummyRegressor(strategy='median'),\n    LinearRegression(fit_intercept=False),\n    Lasso(fit_intercept=False),\n    RandomForestRegressor(n_estimators=50, n_jobs=-1)]\n\nfor name, model in zip(model_names, models):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    plot_results(name, y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost\nRead about parameters here: https://xgboost.readthedocs.io/en/latest/parameter.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = xgb.XGBRegressor(colsample_bytree=0.5,\n                 alpha=0.01,\n                 reg_lambda=0.003,\n                 learning_rate=0.01,\n                 max_depth=15,\n                 min_child_weight=257,\n                 n_estimators=1000, \n                 subsample=0.7,\n                 random_state=2020,\n                 metric_period=100,\n                 silent=1)\n\nregressor.fit(X_train, y_train, early_stopping_rounds=6, eval_set=[(X_test, y_test)], verbose=1)\n\ny_pred = regressor.predict(X_test)\nplot_results(\"XGBRegressor\", y_test, y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM\nRead about parameters here: https://lightgbm.readthedocs.io/en/latest/Parameters.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, y_train)\nlgb_valid = lgb.Dataset(X_test, y_test)\nparam = {\n    'seed': 2021,\n    'objective': 'regression',\n    'metric': 'rmse',\n    'verbosity': -1,\n    'feature_pre_filter': False,\n    'lambda_l1': 6.540486456085813,\n    'lambda_l2': 0.01548480538099245,\n    'num_leaves': 256,\n    'feature_fraction': 0.52,\n    'bagging_fraction': 0.6161835249194311,\n    'bagging_freq': 7,\n    'min_child_samples': 20,\n    'learning_rate' : 0.001,\n    'early_stopping_round' : 1000,\n    'num_iterations' : 20000\n}\n\nlgb_model = lgb.train(param,\n                       lgb_train,\n                       valid_sets=lgb_valid,\n                       num_boost_round=5000,\n                       early_stopping_rounds=100)\n\nplot_results('LightGBM', y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PyTorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class linearRegression(torch.nn.Module):\n    def __init__(self, inputSize, outputSize):\n        super(linearRegression, self).__init__()\n        self.head = torch.nn.Linear(inputSize, inputSize//2)\n        self.out = torch.nn.Linear(inputSize//2, outputSize)\n\n\n    def forward(self, x):\n        y = self.out(self.head(x))\n        return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linearRegression(X_train.shape[-1], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learningRate = 3e-4\ncriterion = torch.nn.MSELoss() \noptimizer = torch.optim.AdamW(model.parameters(), lr=learningRate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n    inputs = torch.Tensor(np.array(X_train)).cuda()\n    labels = torch.Tensor(np.array(y_train)).cuda()\nelse:\n    inputs = torch.Tensor(np.array(X_train))\n    labels = torch.Tensor(np.array(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(10):\n\n    for i in range(0, len(labels), 64):\n        X = inputs[i:i+64]\n        target = labels[i:i+64]\n\n        optimizer.zero_grad()\n        outputs = model(X).view(len(target))\n\n        loss = criterion(outputs, target)\n        loss.backward()\n        optimizer.step()\n\n    print('epoch {}, loss {}'.format(epoch, loss.item()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad(): # we don't need gradients in the testing phase\n    if torch.cuda.is_available():\n        predicted = model(torch.Tensor(np.array(X_test)).cuda()).view(len(y_test)).cpu()\n    else:\n        predicted = model(torch.Tensor(np.array(X_test))).view(len(y_test))\n    print(criterion(predicted, torch.Tensor(np.array(y_test))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission['target'] = regressor.predict(test)\n# submission['target'] = lgb_model.predict(test)\nsubmission['target'] = model(torch.Tensor(np.array(test))).view(-1).detach()\nsubmission.to_csv('res.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}