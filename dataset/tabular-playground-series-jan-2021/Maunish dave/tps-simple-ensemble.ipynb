{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport datatable as dt\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\n\nfrom xgboost import XGBRegressor\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, Pool, CatBoost\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, mean_squared_error\nfrom sklearn.preprocessing import RobustScaler, QuantileTransformer, StandardScaler,PowerTransformer\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '../input/tabular-playground-series-jan-2021/'\ntrain_data = pd.read_csv(path + 'train.csv')\ntest_data = pd.read_csv(path + 'test.csv')\nsample = pd.read_csv(path + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['cont13_cont4_mul'] = train_data['cont13']*train_data['cont4']\ntrain_data['cont13_cont11_mul'] = train_data['cont13']*train_data['cont11']\ntrain_data['cont13_cont7_mul'] = train_data['cont13']*train_data['cont7']\ntrain_data['cont13_cont2_mul'] = train_data['cont13']*train_data['cont2']\ntrain_data['cont13_cont10_mul'] = train_data['cont13']*train_data['cont10']\n\ntest_data['cont13_cont4_mul'] = test_data['cont13']*test_data['cont4']\ntest_data['cont13_cont11_mul'] = test_data['cont13']*test_data['cont11']\ntest_data['cont13_cont7_mul'] = test_data['cont13']*test_data['cont7']\ntest_data['cont13_cont2_mul'] = test_data['cont13']*test_data['cont2']\ntest_data['cont13_cont10_mul'] = test_data['cont13']*test_data['cont10']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"## stratified k-fold for regression data\nnum_bins = int(1 + np.log2(len(train_data)))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'].to_numpy(),bins=num_bins,labels=False)\n\nfeatures = [f'cont{x}' for x in range(1,15)]\nfeatures += [\n    'cont13_cont4_mul',\n    'cont13_cont11_mul',\n    'cont13_cont7_mul',\n    'cont13_cont2_mul',\n    'cont13_cont10_mul',\n]\n\ntarget_feature = 'target'\n\ntrain_data = train_data.query('target >=5')\nbins = train_data['bins'].to_numpy()\n\ntarget = train_data[target_feature].to_numpy()\ntrain_data = train_data[features].to_numpy()\ntest_data = test_data[features].to_numpy()\n\nscaler = PowerTransformer()\ntrain_data = scaler.fit_transform(train_data)\ntest_data = scaler.transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## lgbm model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse_score(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 2021\nnfolds = 5\n\nparams={    \n 'objective':'regression',\n 'metrics':'rmse',\n 'boosting':'gbdt',\n 'min_data_per_group': 5,\n 'num_leaves': 256,\n 'max_depth': -1,\n 'learning_rate': 0.005,\n 'subsample_for_bin': 200000,\n 'lambda_l1': 1.074622455507616e-05,\n 'lambda_l2': 2.0521330798729704e-06,\n 'n_jobs': -1,\n 'cat_smooth': 1.0,\n 'silent': True,\n 'importance_type': 'gain',\n 'feature_pre_filter': False,\n 'bagging_fraction': 0.8206341150202605,\n 'min_data_in_leaf': 100,\n 'min_sum_hessian_in_leaf': 0.001,\n 'bagging_freq': 6,\n 'feature_fraction': 0.5,\n 'min_gain_to_split': 0.0,\n 'min_child_samples': 20}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"lgbm_preds = np.zeros(test_data.shape[0])\n\nkfold = StratifiedKFold(n_splits=nfolds,random_state=seed)\nlgbm_scores = list()\nfor train_idx, valid_idx in kfold.split(X=train_data,y=bins):\n    lgb_train = lgb.Dataset(train_data[train_idx],target[train_idx])\n    lgb_valid = lgb.Dataset(train_data[valid_idx],target[valid_idx],reference=lgb_train)\n    lgb_model = lgb.train(params,\n                      lgb_train, \n                      valid_sets=[lgb_train,lgb_valid],\n                      num_boost_round=10000,\n                      verbose_eval=200,\n                      early_stopping_rounds=100,\n                      )\n    lgbm_scores.append(rmse_score(target[valid_idx],lgb_model.predict(train_data[valid_idx])))\n    lgbm_preds += lgb_model.predict(test_data)/nfolds\n\nprint(\"mean rmse score\",np.mean(lgbm_scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_feature_importance(model):\n    feature_importance = pd.DataFrame({\"feature\":features,\"importance\":model.feature_importance(importance_type='gain')})\n    feature_importance = feature_importance.sort_values(by='importance',ascending=False)\n    \n    plt.figure(figsize=(10,10))\n    plt.subplot(211)\n    sns.barplot(data=feature_importance,x='importance',y='feature')\n    \n    for idx, v in enumerate(feature_importance.importance):\n            plt.text(v, idx, \"  {:.2e}\".format(v))\n    \n    feature_importance = pd.DataFrame({\"feature\":features,\"importance\":model.feature_importance(importance_type='split')})\n    feature_importance = feature_importance.sort_values(by='importance',ascending=False)\n    \n    plt.subplot(212)\n    sns.barplot(data=feature_importance,x='importance',y='feature')\n    \n    for idx, v in enumerate(feature_importance.importance):\n            plt.text(v, idx, \"  {:.2e}\".format(v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importance(lgb_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'lambda': 0.0030282073258141168, \n         'alpha': 0.01563845128469084,\n         'colsample_bytree': 0.55,\n         'subsample': 0.7,\n         'learning_rate': 0.01,\n         'max_depth': 15,\n         'random_state': 2020, \n         'min_child_weight': 257,\n         }","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"xgb_preds = np.zeros(test_data.shape[0])\n\nkfold = StratifiedKFold(n_splits=nfolds,random_state=seed)\nparams['random_state'] = seed\nxgb_scores = list()\nfor train_idx, valid_idx in kfold.split(X=train_data,y=bins):\n    xgb_train = xgb.DMatrix(train_data[train_idx],label=target[train_idx])\n    xgb_valid = xgb.DMatrix(train_data[valid_idx],label=target[valid_idx])\n\n    xgb_model = xgb.train(params,\n                    xgb_train,\n                    10000,\n                    verbose_eval=200,\n                    evals=[(xgb_train,'train'),(xgb_valid,'valid')],\n                    early_stopping_rounds=100)\n    xgb_scores.append(rmse_score(target[valid_idx],xgb_model.predict(xgb.DMatrix(train_data[valid_idx]))))\n    xgb_preds += xgb_model.predict(xgb.DMatrix(test_data))/nfolds\n\nprint(\"mean rmse score\",np.mean(xgb_scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Catboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'l2_leaf_reg': 0.02247766515106271, \n          'max_bin': 364,\n          'subsample': 0.6708650091202213,\n             'learning_rate': 0.010290546311954876,\n          'max_depth': 10,\n           'verbose':200,\n          'random_state': seed, \n          'min_data_in_leaf': 300,\n            'loss_function': 'RMSE',\n          'n_estimators':  25000,\n          'rsm':0.5,\n         'early_stopping_rounds':100}","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"cat_preds = np.zeros(test_data.shape[0])\nkfold = StratifiedKFold(n_splits=nfolds,random_state=seed)\nparams['random_state'] = seed\ncat_scores = list()\nfor train_idx, valid_idx in kfold.split(X=train_data,y=bins):\n    cat_train = Pool(train_data[train_idx],target[train_idx])\n    cat_valid = Pool(train_data[valid_idx],target[valid_idx])\n\n    cat_model = CatBoost(params)\n    cat_model.fit(cat_train,eval_set=cat_valid)\n    cat_scores.append(rmse_score(target[valid_idx],cat_model.predict(train_data[valid_idx])))\n    cat_preds += cat_model.predict(test_data)/nfolds\n    \nprint('mean rmse score:',np.mean(cat_scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stacking \n\n[Notebook](https://www.kaggle.com/maunish/tps-simple-stacking)"},{"metadata":{"trusted":true},"cell_type":"code","source":"stacking_preds = pd.read_csv('../input/tps-simple-stacking/submission.csv')\nstacking_preds = stacking_preds.target.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## correlation matrix"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"predictions = pd.DataFrame({\"lgbm\":lgbm_preds,\"xgboost\":xgb_preds,'catboost':cat_preds,'stacking':stacking_preds})\nplt.figure(figsize=(7,7))\nsns.heatmap(predictions.corr(),annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.target = (0.6 * lgbm_preds.ravel() +  0.2 * xgb_preds.ravel() + 0.1 * cat_preds.ravel() + 0.1 * stacking_preds)\nsample.to_csv(\"submission.csv\",index=False)\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.subplot(131)\nsns.distplot(sample.target)\nplt.title(\"test-target distribution\")\nplt.subplot(132)\nsns.distplot(target)\nplt.title(\"train-target distribution\")\nplt.subplot(133)\nsns.distplot(sample.target.to_numpy(),label='test')\nsns.distplot(target,label='target')\nplt.legend()\nplt.title(\"train and test target distribution\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}