{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Import libraries\n\nimport pandas as pd\nimport numpy as np\n\n!pip install -q fastai==2.2.5 fastcore==1.3.19 fast-tabnet==0.2.0\n\nfrom fastai.tabular.all import *\nfrom fast_tabnet.core import *\n\n!pip install -Uqq fastbook \nimport fastbook\nfastbook.setup_book()\n\nfrom fastbook import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set input path and download the test and training datasets\n\ninput_path = Path('/kaggle/input/tabular-playground-series-jan-2021')\ntrain_df = pd.read_csv(input_path/'train.csv')\ntest_df = pd.read_csv(input_path/'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def r_mse(pred,y): \n    return round(math.sqrt(((pred-y)**2).mean()), 6)\n\ndef m_rmse(m, xs, y): \n    return r_mse(m.predict(xs), y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image, display_svg, SVG\n\npd.options.display.max_rows = 20\npd.options.display.max_columns = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_bkp = train_df.copy(deep=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntarget = train_df.pop('target')\nX_train, X_test, y_train, y_test = train_test_split(train_df, target, train_size=0.80)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple model #1: Decision tree with stopping criteria (max leaves = 4)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\n#Creating a Decision tree -- with stopping criteria (max leaves = 4)\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"training error\", m_rmse(m, X_train, y_train))\nprint (\"test error\", m_rmse(m, X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_tree(m, X_train, size=15, leaves_parallel=True, precision=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### with 25 max leaf nodes"},{"metadata":{"trusted":true},"cell_type":"code","source":"m25 = DecisionTreeRegressor(max_leaf_nodes=25)\nm25.fit(X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"training error\", m_rmse(m25, X_train, y_train))\nprint (\"test error\", m_rmse(m25, X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple model #2: Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\ndef rf(xs, y, n_estimators=40, max_samples=50000,\n       max_features='sqrt', min_samples_leaf=5, **kwargs):\n    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mrf = rf(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# before box cox\nprint (\"training error\", m_rmse(mrf, X_train, y_train))\nprint (\"test error\", m_rmse(mrf, X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi = rf_feat_importance(mrf, X_train)\nfi[:14]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n\nplot_fi(fi[:14]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Light GBM"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#remove the id columns \n\nX_train.pop('id')\nX_test.pop('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nLGB = lgb.LGBMRegressor(random_state=33, n_estimators=5000, min_data_per_group=5, boosting_type='gbdt',\n num_leaves=246, max_dept=-1, learning_rate=0.005, subsample_for_bin=200000,\n lambda_l1= 1.07e-05, lambda_l2= 2.05e-06, n_jobs=-1, cat_smooth=1.0, \n importance_type='split', metric='rmse', min_child_samples=20, min_gain_to_split=0.0, feature_fraction=0.5, \n bagging_freq=6, min_sum_hessian_in_leaf=0.001, min_data_in_leaf=100, bagging_fraction=0.80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_LGB = LGB.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"training error\", m_rmse(m_LGB, X_train, y_train))\nprint (\"test error\", m_rmse(m_LGB, X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#view the importance of the features\n\nlgb.plot_importance(m_LGB, ax=None, height=0.2, xlim=None, ylim=None, \n                      title='Feature importance', xlabel='Feature importance', ylabel='Features', \n                      importance_type='split', max_num_features=None, \n                      ignore_zero=True, figsize=None, dpi=None, grid=True, precision=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hypothesis: feature scaling : box-cox transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ninput_path = Path('/kaggle/input/tabular-playground-series-jan-2021')\ntrain_df = pd.read_csv(input_path/'train.csv')\ntest_df = pd.read_csv(input_path/'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import boxcox\n\ntrain_df['cont5'] = boxcox(train_df['cont5'], 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train_df.pop('target')\n\nX_train, X_test, y_train, y_test = train_test_split(train_df, target, train_size=0.80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#remove the id columns \n\nX_train.pop('id')\nX_test.pop('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nLGB = lgb.LGBMRegressor(random_state=33, n_estimators=5000, min_data_per_group=5, boosting_type='gbdt',\n num_leaves=246, max_dept=-1, learning_rate=0.005, subsample_for_bin=200000,\n lambda_l1= 1.07e-05, lambda_l2= 2.05e-06, n_jobs=-1, cat_smooth=1.0, \n importance_type='split', metric='rmse', min_child_samples=20, min_gain_to_split=0.0, feature_fraction=0.5, \n bagging_freq=6, min_sum_hessian_in_leaf=0.001, min_data_in_leaf=100, bagging_fraction=0.80)\n\nm_LGB_box_cox = LGB.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"training error\", m_rmse(m_LGB_box_cox, X_train, y_train))\nprint (\"test error\", m_rmse(m_LGB_box_cox, X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hypothesis 2: Normalizing leads to better performance\n**##### Excluded from the article**"},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nset_seed(SEED, reproducible=True)\n\ny_names = ['target']\ncontl = list(train_df_bkp.columns.values)\ncontl.remove('id')\ncont_names = contl\n\n#cat_names is blank because the dataset does not contain any categorical variables\n\ncat_names = []\n\nprocs = [FillMissing, Normalize]\n#procs = [FillMissing]\nsplits = RandomSplitter(seed=SEED)(range_of(train_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using tabular pandas\nto = TabularPandas(\n    train_df_bkp, \n    procs=procs, \n    cat_names=cat_names, \n    cont_names=cont_names, \n    y_names=y_names, \n    y_block=RegressionBlock(),\n    splits=splits,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualisation before Normalisation\nimport seaborn as sns\n\nj = 1\nplt.figure()\nfig, ax = plt.subplots(5, 3,figsize=(12, 22))\nfor feature in cont_names:\n    plt.subplot(5, 3,j)\n    sns.distplot(X_train[feature],color=\"blue\", kde=True,bins=120, label='train')\n    sns.distplot(X_test[feature],color=\"red\", kde=True,bins=120, label='test')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    j += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# before Normalisation\nX_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualisation after Normalisation\n\nj = 1\nplt.figure()\nfig, ax = plt.subplots(5, 3,figsize=(12, 22))\nfor feature in cont_names:\n    plt.subplot(5, 3,j)\n    sns.distplot(to.train.xs[feature],color=\"blue\", kde=True,bins=120, label='train')\n    sns.distplot(to.valid.xs[feature],color=\"red\", kde=True,bins=120, label='test')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    j += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# after Normalisation\nto.train.xs.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nLGB = lgb.LGBMRegressor(random_state=33, n_estimators=5000, min_data_per_group=5, boosting_type='gbdt',\n num_leaves=246, max_dept=-1, learning_rate=0.005, subsample_for_bin=200000,\n lambda_l1= 1.07e-05, lambda_l2= 2.05e-06, n_jobs=-1, cat_smooth=1.0, \n importance_type='split', metric='rmse', min_child_samples=20, min_gain_to_split=0.0, feature_fraction=0.5, \n bagging_freq=6, min_sum_hessian_in_leaf=0.001, min_data_in_leaf=100, bagging_fraction=0.80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_LGB_norm = LGB.fit(to.train.xs, to.train.y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"training error\", m_rmse(m_LGB_norm, to.train.xs, to.train.y))\nprint (\"test error\", m_rmse(m_LGB_norm, to.valid.xs, to.valid.y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.train.y.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to.valid.y.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\n#Creating a Decision tree -- with stopping criteria (max leaves = 4)\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(to.train.xs, to.train.y);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"training error\", m_rmse(m, to.train.xs, to.train.y))\nprint (\"test error\", m_rmse(m, to.valid.xs, to.valid.y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\n#Creating a Decision tree -- with stopping criteria (max leaves = 4)\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"training error\", m_rmse(m, X_train, y_train))\nprint (\"test error\", m_rmse(m, X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}