{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()\nprint('-'*70)\nprint('-'*70)\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looking at the distribution of each feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(5,3,figsize=(16,15))\nplt.subplots_adjust(hspace=0.4, wspace=0.3)\n\nfor i in range(14):\n    sns.histplot(train['cont' + str(i+1)], ax=axes[i//3, i%3])\n    axes[i//3, i%3].set(title='cont' + str(i+1), xlabel='')\n    \nsns.histplot(train['target'], ax=axes[4,2])\naxes[4,2].set(title='target', xlabel='')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The feature 'cont5' seems to be very distorted as more than $1/3^{rd}$ of the values are concentrated around zero. So, we can ignore that column, neglecting its effect on the prediction of the target value."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['id', 'cont5'], axis=1, inplace=True)\ntest.drop('cont5', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we will split the training dataset into training \\& validation sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, val_x, train_y, val_y = train_test_split(train.drop(['target'], axis=1), \n                                                  train.target, \n                                                  test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## NN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, input_shape=(13,)),\n                                    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(1, activation=tf.nn.relu)])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n\nmodel.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test.drop('id', axis=1))\npred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame({'id':list(test['id']) , 'target':pred[:,0]})\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}