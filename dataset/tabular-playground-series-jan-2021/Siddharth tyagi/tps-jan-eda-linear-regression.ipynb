{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nimport pathlib\nimport itertools\nimport collections\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import gaussian_kde\nimport matplotlib.pyplot as plt\n\nfrom sklearn import linear_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_folder = pathlib.Path(\"../input/tabular-playground-series-jan-2021\")\ntrain_file = data_folder / \"train.csv\"\ntest_file = data_folder / \"test.csv\"\nsample_file = data_folder / \"sample_submission.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(train_file)\ntest_df = pd.read_csv(test_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"total data points in train set: {train_df.shape[0]}\")\nprint(f\"total data points in test set: {test_df.shape[0]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop(\"id\", axis=1)\ntest_df = test_df.drop(\"id\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualise the data"},{"metadata":{},"cell_type":"markdown","source":"First we will see the correlation between features. i.e the redundancy in features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_corr = np.abs(train_df.drop(\"target\", axis=1).corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x_idx, y_idx in itertools.product(range(len(df_corr.index)), range(len(df_corr.columns))):\n    if y_idx>=x_idx:\n        df_corr.loc[df_corr.index[x_idx], df_corr.columns[y_idx]] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(111)\n\nim = ax.imshow(df_corr.values, cmap=\"plasma\")\nfig.colorbar(im, ax=ax)\n\nax.set_title(\"feature correlations!!\")\nax.set_xticks(range(len(df_corr.index)))\nax.set_xticklabels(df_corr.index, rotation=90)\nax.set_yticks(range(len(df_corr.columns)))\nax.set_yticklabels(df_corr.columns)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the visual above, we can safely infer that the feature cont8 onwards are highly correlated with other features. These features are expendible and can be discarded. But, we will keep them for our primitive model and drop them when necessary."},{"metadata":{},"cell_type":"markdown","source":"## Feature distributions\n\nVisualising feature distribtions"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,15))\naxes = fig.subplots(5,3).ravel()\n\nfor i, ax in enumerate(axes):\n    if not i<len(train_df.columns):\n        break\n    # Get data and columns\n    column = train_df.columns[i]\n    distribution = train_df.loc[:, column].values\n    x = np.linspace(0, 1, 100)\n    \n    # Get KDE\n    kde = gaussian_kde(distribution)(x)\n    ax.fill_between(x, kde, alpha=0.3, color=\"b\",linestyle=\"--\")\n    ax.set_title(f\"distribution for columns: {column}\")\n    ax.set_ylabel(\"kde\")\n\nfig.suptitle(\"Feature distributions\")\nfig.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target distribution\nNow we do the same thing for our target"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nax = fig.subplots(1)\n\nx = np.linspace(0, 1, 100)\ndistribution = train_df.loc[:, \"target\"]\nkde = gaussian_kde(distribution)(x)\n\nax.fill_between(x, kde, alpha=0.5, color=\"b\")\n\nax.set_title(\"Target distribution\")\nax.set_ylabel(\"kde\")\nax.set_xlabel(\"x\")\n\nfig.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y = train_df.drop(\"target\", axis=1).values, train_df.loc[:, \"target\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = linear_model.LinearRegression()\nreg.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(sample_file, index_col='id')\npreds = reg.predict(test_df.values)\nsample_submission.loc[:, \"target\"] = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_file_stem = sample_file.name\nsample_submission.to_csv(out_filename,index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}