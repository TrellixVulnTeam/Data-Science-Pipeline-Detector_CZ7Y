{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nimport pandas_profiling\n%matplotlib inline\n\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\nimport sklearn.metrics as metrics\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Path to the dataset\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')\nsample_sub = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')\norg_len = len(train.drop('id',axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Understanding Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train data set dtypes: \\n\")\nprint(f\"Shape : {train.shape}\")\nprint(f\"{train.dtypes.value_counts()}\")\n\nprint('*'*30)\n\nprint(\"Test data set dtypes: \\n\")\nprint(f\"Shape : {test.shape}\")\nprint(f\"{test.dtypes.value_counts()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gives a details on Count number of non-NA/null observations, Maximum and Minimum of the values in the object, Mean and Standard Deviation of the Values\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### No Missing Values\n**As we can see above the count of no_null values are equal to the len of columns (300000)**"},{"metadata":{},"cell_type":"markdown","source":"# Pandas Profiling üêº \n**pandas_profiling extends the pandas DataFrame for quick data analysis.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"profile = pandas_profiling.ProfileReport(train,minimal=True)\nprofile.to_file(output_file=\"output.html\")\nprofile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Univariate Analysis\n**We will usually use Distribution plot to visualize their data distribution for continuous Values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cont = train.drop('id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18,16))\n\nfor index,col in enumerate(train_cont):\n    plt.subplot(5,3,index+1)\n    sns.distplot(train_cont.loc[:,col], kde=False)\nfig.tight_layout(pad=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    for c in train_cont.columns:\n        fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n        sns.boxplot(y=c, data=train_cont, ax=axs[0]) # 1\n\n        sns.violinplot(y=c, data=train_cont, ax=axs[1]) # 2\n\n        sns.stripplot(y=c, data=train_cont, size=4, color=\".3\", linewidth=0, ax=axs[2]) # 3\n\n\n        fig.suptitle(c, fontsize=15, y=1.1)\n        axs[0].set_title('Box Plot')\n        axs[1].set_title('Violin Plot')\n        axs[2].set_title('Strip Plot')\n\n        plt.tight_layout()\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Few Outliers in target, cont10, cont9, cont7** <br>\n**Cont2 have some regular interval gaps**<br>\n**Cont5 is dominated with lesser value**"},{"metadata":{},"cell_type":"markdown","source":"# Bi-variate Analysis"},{"metadata":{},"cell_type":"markdown","source":"Scatterplot with the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18,16))\ntrain_cont = train.drop('id',axis=1)\nfor index,col in enumerate(train_cont):\n    plt.subplot(5,3,index+1)\n    sns.scatterplot(x=train_cont.iloc[:,index], y=train['target'],alpha=0.5)\nfig.tight_layout(pad=1.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,12))\ncorr = train_cont.corr()\nsns.heatmap(corr,cmap='Blues',linewidth=0.5,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No good correlation with target column üëÄ"},{"metadata":{},"cell_type":"markdown","source":"# Data Processing "},{"metadata":{},"cell_type":"markdown","source":"### **Feature Engineering**\n\n**Tried some randomn combinations**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cont['new'] = train_cont['cont2']*train_cont['cont3']*train_cont['cont6']*train_cont['cont7']*train_cont['cont11']*train_cont['cont12']\ntest['new'] = test['cont2']*test['cont3']*test['cont6']*test['cont7']*test['cont11']*test['cont12']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cont['new1'] = train_cont['cont9']*train_cont['cont10']*train_cont['cont1']\ntest['new1'] = test['cont9']*test['cont10']*test['cont1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = train_cont.drop('target',axis=1).columns\ntrain_cont['mean'] = train_cont[features].mean(axis=1)\ntest['mean'] = test[features].mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Removing Outliers** "},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing outlier in lower region\nlow_cont = ['target', 'cont10', 'cont9', 'cont7']\n# removing outlier in upper region\nup_cont = ['cont10']\nn999 = [ np.percentile(train_cont[i],99.9) for i in train_cont[up_cont]]\nn001 = [ np.percentile(train_cont[i],0.1) for i in train_cont[low_cont]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nfor i, j in enumerate(low_cont):\n    train_cont = train_cont[train_cont[j] > n001[i]]\n    gc.collect()\nfor i, j in enumerate(up_cont):\n    train_cont = train_cont[train_cont[j] < n999[i]]\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**After removing outlier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"    for c in train_cont.columns:\n        fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n        sns.boxplot(y=c, data=train_cont, ax=axs[0]) # 1\n        sns.stripplot(y=c, data=train_cont, size=4, color=\".3\", linewidth=0, ax=axs[1]) # 2\n\n\n        fig.suptitle(c, fontsize=15, y=1.1)\n        axs[0].set_title('Box Plot')\n        axs[1].set_title('Strip Plot')\n\n        plt.tight_layout()\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Percentage of data removed**"},{"metadata":{"trusted":true},"cell_type":"code","source":"str(round(((org_len - len(train_cont))/org_len)*100,2))+'%'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling "},{"metadata":{},"cell_type":"markdown","source":"**We'll be using XGBRegressor**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_cont.drop('target',axis=1)\ny_train = train_cont['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection  import KFold\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\n\ndef objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 350, 1000),\n        'max_depth': trial.suggest_int('max_depth', 6, 13),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.009, 0.10),\n        'subsample': trial.suggest_uniform('subsample', 0.50, 1),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n        'gamma': trial.suggest_int('gamma', 0, 0.05),\n        'objective':'reg:squarederror',\n        'eval_metric' : 'rmse',\n        'tree_method':'gpu_hist',\n       }\n        \n    clf = xgb.XGBRegressor(**params)\n    rmse_scores = []\n    X_train_k = X_train.values\n    y_train_k = y_train.values\n    skf = KFold(n_splits=3,shuffle=True)\n    for train_idx, valid_idx in skf.split(X_train_k,y_train_k):\n        train_data = X_train_k[train_idx, :], y_train_k[train_idx]\n        valid_data = X_train_k[valid_idx, :], y_train_k[valid_idx]\n        \n        clf.fit(X_train_k[train_idx, :], y_train_k[train_idx])\n        pred = clf.predict(X_train_k[valid_idx, :])\n        rmse = np.sqrt(mean_squared_error(y_train_k[valid_idx],pred))\n        rmse_scores.append(rmse)\n    print(f'Trial done: Accuracy values on folds: {rmse_scores}')\n    return np.average(rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Just for lesser time I've used less trials,Please do increase the trials \nn_trials = 5\n\nFIT_XGB = True\n\nif FIT_XGB:\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n\n    print(\"  Value: {}\".format(trial.value))\n\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optuna.visualization.plot_slice(study)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"#best_param = study.best_params\nbest_param = {'n_estimators': 751, 'max_depth': 10, \n              'learning_rate': 0.019789645280696613, \n              'subsample': 0.8730019407814834, \n              'colsample_bytree': 0.6012295369579667,'gamma':0}\nbest_param['objective'] ='reg:squarederror'\nbest_param['tree_method'] ='gpu_hist'\nbest_param['eval_metric'] ='rmse'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.XGBRegressor(**best_param)\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Importance "},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.plot_importance(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_final = model.predict(test.drop('id',axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"id\": test[\"id\"],\n        \"target\":predictions_final\n    })\nsubmission.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# If you liked it. Please do upvote ‚úå‚úîüò∫"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}