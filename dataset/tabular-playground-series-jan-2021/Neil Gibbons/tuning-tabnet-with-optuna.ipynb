{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nimport lightgbm as lgbm\n\nimport optuna\nfrom optuna import Trial, visualization","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')\nsub = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch-tabnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_tabnet.tab_model import TabNetRegressor\nfrom sklearn.model_selection import KFold\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['target', 'id'], axis=1).values\ny = train['target'].values\ny = y.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Objective(trial):\n    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n    tabnet_params = dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n                     lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,\n                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n                     mask_type=mask_type, n_shared=n_shared,\n                     scheduler_params=dict(mode=\"min\",\n                                           patience=trial.suggest_int(\"patienceScheduler\",low=3,high=10), # changing sheduler patience to be lower than early stopping patience \n                                           min_lr=1e-5,\n                                           factor=0.5,),\n                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n                     verbose=0,\n                     ) #early stopping\n    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n    CV_score_array    =[]\n    for train_index, test_index in kf.split(X):\n        X_train, X_valid = X[train_index], X[test_index]\n        y_train, y_valid = y[train_index], y[test_index]\n        regressor = TabNetRegressor(**tabnet_params)\n        regressor.fit(X_train=X_train, y_train=y_train,\n                  eval_set=[(X_valid, y_valid)],\n                  patience=trial.suggest_int(\"patience\",low=15,high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n                  eval_metric=['rmse'])\n        CV_score_array.append(regressor.best_cost)\n    avg = np.mean(CV_score_array)\n    return avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\", study_name='TabNet optimization')\nstudy.optimize(Objective, timeout=6*60) #5 hours","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train a TabNet with the best params to make submission\nTabNet_params = study.best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TabNet_params = {'epochs':6}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(TabNet_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_params = dict(n_d=TabNet_params['n_da'], n_a=TabNet_params['n_da'], n_steps=TabNet_params['n_steps'], gamma=TabNet_params['gamma'],\n                     lambda_sparse=TabNet_params['lambda_sparse'], optimizer_fn=torch.optim.Adam,\n                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n                     mask_type=TabNet_params['mask_type'], n_shared=TabNet_params['n_shared'],\n                     scheduler_params=dict(mode=\"min\",\n                                           patience=TabNet_params['patienceScheduler'],\n                                           min_lr=1e-5,\n                                           factor=0.5,),\n                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n                     verbose=0,\n                     )\nepochs = TabNet_params['epochs']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = TabNetRegressor(**final_params)\nregressor.fit(X_train=X, y_train=y,\n          patience=TabNet_params['patience'], max_epochs=epochs,\n          eval_metric=['rmse'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test.drop('id', axis=1).values\nsub['target']=regressor.predict(X_test)\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}