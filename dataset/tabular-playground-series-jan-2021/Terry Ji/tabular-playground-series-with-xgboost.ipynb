{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Start"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\n\nimport time\nimport os\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##import the data\ntrain = pd.read_csv(\"../input/tabular-playground-series-jan-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-jan-2021/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train data shape:',train.shape)\nprint('test data shape:',test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##misssing values count\nprint(\"train x data null value sum:\", train.isnull().sum().sum())\nprint(\"train y data null value sum:\", test.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ####  Now I have basic understanding of how data looks like. Then I would like to check if exists any correlations among 14 features "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Separate features and targets \ndf_x = train.iloc[:,1:15]\ndf_y = train.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation map\ncorr_data = df_x.corr()\n\nplt.figure(figsize=(10,10))\nsns.heatmap(corr_data,square = True,vmax = 0.8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### Seems feature 11 and 12 have strong correlations, maybe can do some explorations later"},{"metadata":{},"cell_type":"markdown","source":"> #### If exists outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = plt.boxplot(df_x.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = plt.boxplot(test.iloc[:,1:].T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### handle outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"def IQR(dist):\n    return np.percentile(dist, 75) - np.percentile(dist, 25)\n\ndef handle_outliers(series):\n    \n    IQR_data = IQR(series)\n    percentile_75 = np.percentile(series, 75)\n    percentile_25 = np.percentile(series, 25)\n    \n    for i in range(series.shape[0]):\n        \n        if series[i] > percentile_75 + 1.5*IQR_data:\n            series[i] = percentile_75 + 1.5*IQR_data\n            \n        if series[i] < percentile_25 - 1.5*IQR_data:\n            series[i] = percentile_25 - 1.5*IQR_data\n            \n    return series\n\n            \ndf_x['cont7'] = handle_outliers(df_x['cont7'] )\ndf_x['cont9'] = handle_outliers(df_x['cont9'] )\n\ntest['cont7'] = handle_outliers(test['cont7'] )\ntest['cont9'] = handle_outliers(test['cont9'] )    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### distribution "},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\ncolumn_reshape = np.array(df_x.columns).reshape(2,7)\n\nfig, ax = plt.subplots(2,7,figsize = (20,5))\nfor i in range(ax.shape[0]):\n    for j in range(ax.shape[1]):\n        plot = ax[i,j].hist(df_x[column_reshape[i,j]],bins = 50, density = True, color = 'purple')\n        ax[i,j].set_title(column_reshape[i,j])\n        ax[i,j].axis('off')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##decrease Skewness\ndf_x['cont7'] = np.log1p(df_x['cont7'])\ndf_x['cont11'] = np.log1p(df_x['cont11'])\ndf_x['cont12'] = np.log1p(df_x['cont12'])\n\ntest['cont7'] = np.log1p(test['cont7'])\ntest['cont11'] = np.log1p(test['cont11'])\ntest['cont12'] = np.log1p(test['cont12'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train XG Boost model"},{"metadata":{"trusted":true},"cell_type":"code","source":"##Split the train and validate data set\ntrainX, testX, trainY, testY = train_test_split(df_x,df_y,test_size=0.18, random_state=2021)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\nmodel = XGBRegressor(\n    max_depth=20,\n    n_estimators=300,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42)\n\nmodel.fit(\n    trainX, \n    trainY, \n    eval_metric=\"rmse\", \n    eval_set=[(testX, testY)], \n    verbose=True, \n    early_stopping_rounds = 30)\n\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_xgb  = model.predict(test.iloc[:,1:])\n\nresults = pd.Series(prediction_xgb,name=\"target\")\n\nsubmission = pd.concat([test.iloc[:,0],results],axis = 1)\n\nsubmission.to_csv(\"submission_xgb.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}