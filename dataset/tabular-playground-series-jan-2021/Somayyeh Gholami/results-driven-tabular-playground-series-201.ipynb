{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div>\n    <h1 align=\"center\">\"Optimizing Results\"</h1></h1>\n    <h3 align=\"center\">Tabular Playground Series - Jan 2021</h3>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"# Description:\n\n### - In this notebook, we use the results of other notebooks. But in the end, the score of this notebook will be better than the score of each notebook used. Of course this type of method only works for some challenges and is not a general method.\n\n### - In steps one through six, I used \"ensembling\" and in step seven, I used the \"Comparative Method\". The \"Comparative Method\" is new to you because it's my own idea. Of course, outside of Kaggle, I have used the \"Comparative Method\" many times, and this method has always worked very well. That's why I decided to share this method with you in this challenge. As you will see in this notebook, the positive effect of the \"Comparative Method\" is even greater than the effect of all the \"ensembling\" steps.\n\n### - For example, suppose you have a real project (not a Kaggle challenge). You got seven mediocre results with seven simple methods and three good results with three advanced methods. You usually miss out on seven mediocre results, but my suggestion is that even mediocre results are important. You can improve good results by \"ensembling\" and use mediocre results for the \"Comparative Method\".\n\n### - To date, I have used the results of twelve kernels. Of course, better scores have a greater impact on the score of this notebook. However, each kernel has helped me with the voting (Comparative Method). Thanks to everyone and again I will mention the addresses of some of these kernels below. Certainly the credit of this notebook belongs to all of us.\n\n### https://www.kaggle.com/shogosuzuki/0-69701-folds-10-lightgbm\n\n### https://www.kaggle.com/ryanzhang/tabular-playground-some-slightly-useful-features\n\n### https://www.kaggle.com/hamzaghanmi/xgboost-hyperparameter-tuning-using-optuna\n\n### https://www.kaggle.com/hamditarek/tabular-playground-series-xgboost-lightgbm\n\n### https://www.kaggle.com/kailex/tabular-playground\n\n### - You can also find more information about this notebook at the following address:\n\n### [[results-driven] How to convert a score of <0.69701> to a score of <0.69652>](http://www.kaggle.com/c/tabular-playground-series-jan-2021/discussion/213093).\n\n"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"# If you find this work useful, please don't forget upvoting :)\n"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Import & Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# _______________________________________\n\n# Kernels Data (Public Score & File Path)\n\ndfk = pd.DataFrame({ \n    'Kernel ID': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'],  \n    'Score':     [ 0.69864 , 0.69846 , 0.69836 , 0.69824 , 0.69813, 0.69795, 0.69751, 0.69749, 0.69747, 0.69735, 0.69731, 0.69701],   \n    'File Path': ['../input/aa69864/AA69864.csv', '../input/bb69846/BB69846.csv', '../input/cc69836/CC69836.csv', '../input/a69824/A69824.csv', '../input/c69813/C69813.csv', '../input/ff69795/FF69795.csv', '../input/gg69751/GG69751.csv' , '../input/g69749/G69749.csv', '../input/h69747/H69747.csv', '../input/i69735/I69735.csv', '../input/j69731/J69731.csv', '../input/l69701/L69701.csv']     \n})    \n    \ndfk         ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Functions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate(main, support, coeff):\n    \n    g = main.copy()    \n    for i in main.columns[1:]:\n        \n        res = []\n        lm, Is = [], []        \n        lm = main[i].tolist()\n        ls = support[i].tolist()  \n        \n        for j in range(len(main)):\n            res.append((lm[j] * coeff) + (ls[j] * (1.- coeff)))            \n        g[i] = res\n        \n    return g\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def drawing(main, support, generated):\n    \n    X  = main.iloc[:, 1]\n    Y1 = support.iloc[:, 1]\n    Y2 = generated.iloc[:, 1]\n    \n    plt.style.use('seaborn-whitegrid') \n    plt.figure(figsize=(8, 8), facecolor='lightgray')\n    plt.title(f'\\nOn the X axis >>> main\\nOn the Y axis >>> support\\n')           \n    plt.scatter(X, Y1, s=0.1)\n    plt.show() \n    \n    plt.style.use('seaborn-whitegrid') \n    plt.figure(figsize=(8, 8), facecolor='lightgray')\n    plt.title(f'\\nOn the X axis >>> main\\nOn the Y axis >>> generated\\n')           \n    plt.scatter(X, Y2, s=0.1)\n    plt.show()     \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def drawing1(main, support, generated):\n    \n    X  = main.iloc[:, 1]\n    Y1 = support.iloc[:, 1]\n    Y2 = generated.iloc[:, 1]\n    \n    plt.style.use('seaborn-whitegrid') \n    plt.figure(figsize=(8, 8), facecolor='lightgray')\n    plt.title(f'\\nBlue | X axis >> main | Y axis >> support\\n\\nOrange | X axis >> main | Y axis >> generated\\n') \n    \n    plt.scatter(X, Y1, s=0.1)    \n    plt.scatter(X, Y2, s=0.1)\n    \n    plt.show() \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def drawing2(pxy, mxy):\n    \n    plt.style.use('seaborn-whitegrid') \n    plt.figure(figsize=(8, 8), facecolor='lightgray')\n    plt.title(f'\\nComparative Method\\n\\nBlue | X(main) | Y(average - smaller result)\\n\\nOrange | X(main) | Y(generated)\\n') \n    plt.scatter(pxy[0], pxy[1], s=0.1)\n    plt.scatter(pxy[0], pxy[2], s=0.1)\n    plt.show() \n\n    plt.style.use('seaborn-whitegrid') \n    plt.figure(figsize=(8, 8), facecolor='lightgray')\n    plt.title(f'\\nComparative Method\\n\\nBlue | X(main) | Y(average - bigger results)\\n\\nOrange | X(main) | Y(generated)\\n') \n    plt.scatter(mxy[0], mxy[1], s=0.1)\n    plt.scatter(mxy[0], mxy[2], s=0.1)\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def comparison(main, majority, pcoeff, mcoeff):\n    '''\n    majority: Must be greater than half the total number of kernels. \n              In this example it must be greater than six.(Hyper parameter)\n    \n    pcoeff:   More than one (Hyper parameter)\n    mcoeff:   Less than one (Hyper parameter)\n    \n              First you can assume: (mcoeff = 2 - pcoeff)\n              Then update the numbers based on the results.    \n    '''    \n    comp = main.copy()\n    for i in main.columns[1:]:\n        res = []\n        pxy = [[],[],[]]\n        mxy = [[],[],[]]        \n        lm  = main[i].tolist() \n        ls  = [[],[],[],[],[],[],[],[],[],[],[],[]]\n        for n in range (12):       \n            csv   = pd.read_csv(dfk.iloc[n, 2])  \n            ls[n] = csv[i].tolist() \n            \n        for j in range(len(main)):\n            pcount = 0\n            pvalue = 0.0        \n            mcount = 0\n            mvalue = 0.0 \n    \n            for k in range (12):            \n                if lm[j] > ls[k][j]:\n                    pcount += 1\n                    pvalue += ls[k][j]                 \n                else: \n                    mcount += 1\n                    mvalue += ls[k][j] \n                    \n            if (pcount > majority): \n                res.append(lm[j] * pcoeff)\n                pxy[2].append(lm[j] * pcoeff)                \n                pxy[1].append(pvalue / pcount)\n                pxy[0].append(lm[j])\n                        \n            elif (mcount > majority): \n                res.append(lm[j] * mcoeff)\n                mxy[2].append(lm[j] * mcoeff)                \n                mxy[1].append(mvalue / mcount)\n                mxy[0].append(lm[j])\n                        \n            else: \n                res.append(lm[j])       \n    \n        comp[i] = res    \n\n    drawing2(pxy, mxy)    \n    return comp\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Step #1\nIn this step, we use the results of kernels \"A, B, C, D, E, F, G\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"support = pd.read_csv(dfk.iloc[0, 2])\n    \nfor k in range (1, 7):\n    main = pd.read_csv(dfk.iloc[k, 2])\n    support = generate(main, support, 0.99)\n    \nsub1 = support ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Result: \n[ A: (Score: 0.69864), B: (Score: 0.69846), ... , G: (Score: 0.69795), H: (Score: 0.69751) ] >>> sub1: (Score: **0.69751**)\n\nThe results of these kernels are used in the \"Comparative Method\" and can not have a direct effect on improving the score.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sub1(Last Support)    | Score: 0.69751')\nsub1.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Step #2\nUse the results of the \"H\" kernel as well as the results of step #1."},{"metadata":{"trusted":true},"cell_type":"code","source":"main = pd.read_csv(dfk.iloc[7, 2])\n\nsub2 = generate(main, sub1, 0.65)\n\n#drawing(main, sub1, sub2)\n\ndrawing1(main, sub1, sub2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Result:\n\n[ H: (Score: 0.69749) , sub1: (Score: 0.69751) ] >>> sub2: (Score: **0.69744**)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sub2    | Score: 0.69744')\nsub2.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Step #3\nUse the results of the \"I\" kernel as well as the results of step #2."},{"metadata":{"trusted":true},"cell_type":"code","source":"main = pd.read_csv(dfk.iloc[8, 2])\n\nsub3 = generate(main, sub2, 0.50)\n\n#drawing(main, sub2, sub3)\n\ndrawing1(main, sub2, sub3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Result:\n\n[ I: (Score: 0.69747) , sub2: (Score: 0.69744) ] >>> sub3: (Score: **0.69737**)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sub3    | Score: 0.69737')\nsub3.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Step #4\nUse the results of the \"J\" kernel as well as the results of step #3."},{"metadata":{"trusted":true},"cell_type":"code","source":"main = pd.read_csv(dfk.iloc[9, 2])\n\nsub4 = generate(main, sub3, 0.55)\n\n#drawing(main, sub3, sub4)\n\ndrawing1(main, sub3, sub4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Result:\n\n[ J: (Score: 0.69735) , sub3: (Score: 0.69737) ] >>> sub4: (Score: **0.69725**)\n\nMy research showed that it is better to ignore this step. Deleting the \"J kernel\" at this stage will make the \"Comparative Method\" work better later. The variety of notebooks solutions is even more important than their score.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sub4    | Score: 0.69725')\nsub4.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Step #5\nUse the results of the \"K\" kernel as well as the results of step #4."},{"metadata":{"trusted":true},"cell_type":"code","source":"main = pd.read_csv(dfk.iloc[10, 2])\n\nsub5 = generate(main, sub3, 0.43)\n\n#drawing(main, sub3, sub5)\n\ndrawing1(main, sub3, sub5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Result:\n\n[ K: (Score: 0.69731) , sub3: (Score: 0.69737) ] >>> sub5: (Score: **0.69698**)\n\nThe difference in notebook solutions is the reason for the good progress at this step. When solutions are different, they reinforce each other's weaknesses."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sub5    | Score: 0.69698')\nsub5.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Step #6\nUse the results of the \"L\" kernel as well as the results of step #5."},{"metadata":{"trusted":true},"cell_type":"code","source":"main = pd.read_csv(dfk.iloc[11, 2])\n\nsub6 = generate(main, sub5, 0.40)\n\n#drawing(main, sub5, sub6)\n\ndrawing1(main, sub5, sub6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Result:\n\n[ Ł: (Score: 0.69701) , sub5: (Score: 0.69698) ] >>> sub6: (Score: **0.69684**)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sub6    | Score: 0.69684')\nsub6.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Step #7\n## Comparative Method\nIn this step, we so-called recover some of the results of the previous step. That is, we compensate for the bad effects of the previous stages."},{"metadata":{"trusted":true},"cell_type":"code","source":"sub7 = comparison(sub6, 7, 1.0036, 0.9972)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Result:\n\nsub6: (Score: 0.69684)  >>>  sub7: (Score: **0.69652**)\n\nWe first compared the result of our previous step with the results of each kernel used. We looked for rows where the results of all kernels (or the majority of kernels) differed from the results of our previous step (more or less). On the other hand, we know that the results of the previous step are better than the results of all the kernels used. So we can guess that these rows have been oppressed !!! That is, in the previous steps, they were mistakenly increased or decreased. We compensate for these possible errors to some extent by applying the coefficients \"pcoeff\" and \"mcoeff\" (of course, only in these rows). Fortunately, the pictures illustrate the method well.\n\nThat is, first we hold a vote and then, exactly contrary to the result of the vote, we make the corrections:)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sub7    | Score: 0.69652')\nsub7.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = sub7\nsub.to_csv(\"submission.csv\", index=False)\n\nsub1.to_csv(\"submission1.csv\", index=False)\nsub2.to_csv(\"submission2.csv\", index=False)\nsub3.to_csv(\"submission3.csv\", index=False)\nsub4.to_csv(\"submission4.csv\", index=False)\nsub5.to_csv(\"submission5.csv\", index=False)\nsub6.to_csv(\"submission6.csv\", index=False)\n\n!ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Conclusion:\n### In this notebook, only the results of a number of kernels were used. The best score was \"0.69701\". But as you can see, we were able to score much better. >>> \"Score: 0.69652\"\n"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-success\">  \n</div>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}