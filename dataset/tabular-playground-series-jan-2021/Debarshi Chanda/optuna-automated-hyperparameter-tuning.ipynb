{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/optuna/optuna/master/docs/image/optuna-logo.png)"},{"metadata":{},"cell_type":"markdown","source":"<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\n<link href=\"https://fonts.googleapis.com/css2?family=Open+Sans&display=swap\" rel=\"stylesheet\">\n<h1 style=\"text-align: center; font-family: 'Open Sans', sans-serif;\"> A SIMPLE GUIDE TO PERFORM HYPERPARAMETER OPTIMIZATION WITH OPTUNA </h1>"},{"metadata":{},"cell_type":"markdown","source":"<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\n<link href=\"https://fonts.googleapis.com/css2?family=Lato&family=Open+Sans&display=swap\" rel=\"stylesheet\">\n<h2 style=\"font-family: 'Lato', sans-serif; text-align:center\">Let's Begin!</h2>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport time\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport optuna\nfrom optuna import Trial, visualization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')\nsample = pd.read_csv('../input/tabular-playground-series-jan-2021/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = [col for col in train.columns.tolist() if col not in ['id', 'target']]\ntarget_cols = ['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Folds"},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, random_state=2021, shuffle=True)\n\nfor i, (trn, val) in enumerate(kf.split(train)):\n    train.loc[val, 'kfold'] = i\ntrain['kfold'] = train['kfold'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Function"},{"metadata":{},"cell_type":"markdown","source":"1. trial.suggest_categorical : Suggest a value for the categorical parameter. The value is sampled from the `choices`\n2. trial.suggest_discrete_uniform: Suggest a value for the discrete parameter. The value is sampled uniformely from the range `[low,high]`, with some step of discretization\n3. trial.suggest_logunifrom: Suggest a value for the continuous parameter. The value is sampled from the range `[low,high)` in the log domain.\n4. trial.suggest_int: Suggest a value for the integer parameter. The value is sampled from the integers in `[low,high]`"},{"metadata":{},"cell_type":"markdown","source":"[Visit this site to learn more](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_xgb(trial, xtr, ytr, xval, yval):\n    params = {\n        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [150, 200, 250, 300]),\n        \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.6,1,0.1),\n        \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\", 0.6,1,0.1),\n        \"eta\": trial.suggest_loguniform(\"eta\",1e-2,0.1),\n        # \"gamma\": trial.suggest_loguniform(\"gamma\",0.05,1),\n        \"max_depth\": trial.suggest_categorical(\"max_depth\",[5,7,9,11,13]),\n        \"min_child_weight\": trial.suggest_int(\"min_child_weight\",5,11),\n        \"random_state\": 2021\n    }\n    \n    model = xgb.XGBRegressor(**params)\n    model.fit(xtr, ytr.reshape(-1,))\n    \n    y_val_pred = model.predict(xval)\n    \n    log = {\n        \"train rmse\": mean_squared_error(ytr, model.predict(xtr), squared=False), # setting squared=False returns root_mean_squared_error\n        \"valid rmse\": mean_squared_error(yval, y_val_pred, squared=False)  # setting squared=False returns root_mean_squared_error\n    }\n    \n    return model, log","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Objective Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial):\n    rmse = 0\n    for fold in range(5):\n        trn_idx = train['kfold'] != fold\n        val_idx = train['kfold'] == fold\n        trn = train.loc[trn_idx, :]\n        val = train.loc[val_idx, :]\n\n        xtr, ytr = trn[feature_cols].values, trn[target_cols].values\n        xval, yval = val[feature_cols].values, val[target_cols].values\n        \n        model, log = fit_xgb(trial, xtr, ytr, xval, yval)\n        rmse += log['valid rmse']/5\n        \n    return rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **NOTE** : The Objective Function should return the metric to be minimized or maximized "},{"metadata":{},"cell_type":"markdown","source":"## CREATE STUDY\n### Specify whether to maximize or minimize your metric (which is returned by the Objective Function)"},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\", study_name='Xgboost optimization')\nstudy.optimize(objective, n_trials=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = study.trials_dataframe()\nhistory.sort_values(by=\"value\", ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study.best_params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{},"cell_type":"markdown","source":"### The `visualization` module provides utility functions for plotting the optimization process using plotly and matplotlib\n[https://optuna.readthedocs.io/en/stable/reference/visualization/index.html](https://optuna.readthedocs.io/en/stable/reference/visualization/index.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization.plot_optimization_history(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization.plot_parallel_coordinate(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization.plot_param_importances(study)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Retraining on the Entire Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBRegressor(**(study.best_params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(train[feature_cols], train[target_cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = pd.Series(clf.predict(test[feature_cols]), name='target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = pd.concat([test['id'], preds], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Public Score: 0.69986"},{"metadata":{},"cell_type":"markdown","source":"## If you learnt something new, Consider upvoting my kernel :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}