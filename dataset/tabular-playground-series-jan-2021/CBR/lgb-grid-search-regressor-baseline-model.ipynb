{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n### Graphic libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading train and test data sets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train =pd.read_csv(\"../input/tabular-playground-series-jan-2021/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Now let's check test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=pd.read_csv(\"../input/tabular-playground-series-jan-2021/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA\n\n"},{"metadata":{},"cell_type":"markdown","source":"Some columns have little negative correlation with target variable.\n\nThese can prove to be important features to predict target."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split data for training & validation"},{"metadata":{},"cell_type":"markdown","source":"Data is clean with continues target variable. let's make split into 70:20 train and validation data. and drop id column. "},{"metadata":{},"cell_type":"markdown","source":"Storing values in numpy array saves memory."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_train.iloc[:, 1:15].values  \nprint(x) \ny = df_train.iloc[:, -1].values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\n#from sklearn.preprocessing import StandardScaler\n\n#sc = StandardScaler()\n#X_train = sc.fit_transform(X_train)\n#X_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LGB regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn import model_selection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from xgboost import XGBRegressor\nimport lightgbm as ltb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RandomizedSearch: Hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#ltb_r = ltb.LGBMRegressor()\n\nlgbm = ltb.LGBMRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining a dictionary containing all the releveant parameters\nparam_grid = {\n    \"boosting_type\": ['gbdt'],\n    \"num_leaves\": [ 19, 31, 37, 47],\n    \"max_depth\": [7, 15, 29, 37, 47, 53], \n    \"learning_rate\": [0.1, 0.15, 0.01],\n    \"n_estimators\": [500, 1000, 2000], \n    \"subsample_for_bin\": [20000, 200000, 2000000], \n    \"objective\": [\"regression\"],\n    \"min_child_weight\": [0.001, 0.01], \n    \"min_child_samples\":[20, 50, 100], \n    \"subsample\":[1.0], \n    \"subsample_freq\":[0], \n    \"colsample_bytree\":[1.0], \n    \"reg_alpha\":[0.0], \n    \"reg_lambda\":[0.0]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model_selection.RandomizedSearchCV(\n    estimator=lgbm,\n    param_distributions=param_grid,\n    n_iter=100,\n    scoring=\"neg_root_mean_squared_error\",\n    verbose=10,\n    n_jobs=-1,\n    cv=5\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the model and extract best score\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Best score: {model.best_score_}\")\nprint(\"Best parameters from the RandomSearchCV:\")\nbest_parameters = model.best_estimator_.get_params()\nfor param_name in sorted(param_grid.keys()):\n    print(f\"\\t{param_name}: {best_parameters[param_name]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#ltb_r = ltb.LGBMRegressor()\n\n'''\nltb_r = ltb.LGBMRegressor(boosting_type= 'gbdt', #'rf', #'goss',#'dart', #\n                         num_leaves=31, \n                         max_depth= 11, #12, #16, #- 1, \n                         learning_rate=0.1, \n                         n_estimators=1000, #500, \n                         subsample_for_bin=200000, \n                         objective=None, \n                         class_weight=None, \n                         min_split_gain=0.0, \n                         min_child_weight=0.001, \n                         min_child_samples=20, \n                         subsample=1.0, \n                         subsample_freq=0, \n                         colsample_bytree=1.0, \n                         reg_alpha=0.0, \n                         reg_lambda=0.0, \n                         random_state=None, \n                         n_jobs=- 1, \n                         silent=True\n                        )\n\nltb_r.fit(X_train,y_train)\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get best model\nbest_model = model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= best_model.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_train, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = best_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For previous grid_search\n    \n    Mean Absolute Error: 0.590135219891411\n    Mean Squared Error: 0.4941394332980038\n    Root Mean Squared Error: 0.7029505198077627"},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_t = sc.transform(df_test[:,1:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare predictions for submission.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make prediction for submission using best_estimators from grid search.\npreds = best_model.predict(df_test.iloc[:,1:].values)\n#preds=XGB.predict(df_test.iloc[:,1:].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv(\"../input/tabular-playground-series-jan-2021/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.target =preds\nsub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}