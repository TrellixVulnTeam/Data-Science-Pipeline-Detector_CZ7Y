{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pathlib import Path\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\n        \ninput_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read in the data files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(input_path / 'train.csv', index_col='id')\ndisplay(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(input_path / 'test.csv', index_col='id')\ndisplay(test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(input_path / 'sample_submission.csv', index_col='id')\ndisplay(submission.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the shape of the dataset\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train data contains 300000 rows, 14 columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for null values  in train data\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset has no null values to deal with. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for duplicates\ntrain.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No duplicates found in the dataset to deal with."},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for null values in the test data\ntest.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The test data contains no missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test data contains 200000 rows in 14 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train data contains no categorical variables and only real numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistical information on train data set\ntrain.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Glance at the distribution of variables in train and test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"figure, ax = plt.subplots(7,2,figsize=(15,30))\nc=1\nfor i in train.drop(['target'],axis=1).columns:\n    plt.subplot(7,2,c)\n    sns.distplot(train[i],color = 'blue', label='train')\n    sns.distplot(test[i],color = 'red', label='test')\n    c=c+1\n    plt.xlabel(i, fontsize=9)\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### The data falls in a multimodal distribution. Multimodal distribution indicates the population is not normally distributed and that sample has several patterns of response or extreme views, preferences or attitudes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize the relationship between variables\ng = sns.PairGrid(train)\ng.map(sns.scatterplot)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### The data has no linear correlation between vaiables. This leads us to see if there is even a correlation between variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize the correlation between varibles\nplt.figure(figsize=(25,25))\nsns.heatmap(train.corr(), annot=True, cmap = 'mako')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### A few of the variables shown in dark blue are correlated. Most of the independent variable do not show any correlation with the target variable. This leads us to think if there are outliers in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find if there are outliers in the data\nplt.figure(figsize=(20,10))\nsns.boxplot(data=train.drop(['target'],axis=1))\nplt.title('The boxplot to study outliers')\nplt.xlabel('Variables that predict the Target')\nplt.ylabel('Values')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Except in cont7 there are no outliers in the data. In some of the samples, such as cont2, cont4, cont13, cont14 the data is more dispersed. In cont3, cont7, cont9 the datta is less dispersed. Both right skewed and left skewed data distribution is seen."},{"metadata":{},"cell_type":"markdown","source":"## Pull out the target, and make a validation split"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train.pop('target')\nX_train, X_test, y_train, y_test = train_test_split(train, target, train_size=0.60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How well can we do with a completely naive model?\n\nWe'll want any of our models to do (hopefully much!) better than this."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's get a benchmark score\nmodel_dummy = DummyRegressor(strategy='median')\nmodel_dummy.fit(X_train, y_train)\ny_dummy = model_dummy.predict(X_test)\nscore_dummy = mean_squared_error(y_test, y_dummy, squared=False)\nprint(f'{score_dummy:0.5f}') # 0.54118","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Linear Regression\n\nA simple linear regression doesn't do better than our dummy regressor!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simple Linear Regression\nmodel_simple_linear = LinearRegression(fit_intercept=True) # data is not centered, fit intercept\nmodel_simple_linear.fit(X_train, y_train)\ny_simple_linear = model_simple_linear.predict(X_test)\nscore_simple_linear = mean_squared_error(y_test, y_simple_linear, squared=False)\nprint(f'{score_simple_linear:0.5f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Automate the process"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_results(name, y, yhat, num_to_plot=10000, lims=(0,12), figsize=(6,6)):\n    plt.figure(figsize=figsize)\n    score = mean_squared_error(y, yhat, squared=False)\n    plt.scatter(y[:num_to_plot], yhat[:num_to_plot])\n    plt.plot(lims, lims)\n    plt.ylim(lims)\n    plt.xlim(lims)\n    plt.title(f'{name}: {score:0.5f}', fontsize=18)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementing different ML models\n"},{"metadata":{},"cell_type":"markdown","source":"DummyClassifier is a classifier that makes predictions using simple rules.This classifier is useful as a simple baseline to compare with other (real) classifiers. We do not use it for real problems.\nLinear regression  is the most basic form, where the model is not penalized for its choice of weights, at all. ... Lasso is a modification of linear regression, where the model is penalized for the sum of absolute values of the weights."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names = [\"Dummy Median\", \"Linear\",  \"Lasso\", \"Random Forest\"]\n\nmodels = [\n    DummyRegressor(strategy='median'),\n    LinearRegression(fit_intercept=True),\n    Lasso(fit_intercept=True),\n    RandomForestRegressor(n_estimators=50, n_jobs=-1)]\n\n\nfor name, model in zip(model_names, models):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    plot_results(name, y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# It looks like RandomForest did the best. Let's train it on all the data and make a submission!"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor(n_estimators=50, n_jobs=-1)\nmodel.fit(train, target)\nsubmission['target'] = model.predict(test)\nsubmission.to_csv('random_forest.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}