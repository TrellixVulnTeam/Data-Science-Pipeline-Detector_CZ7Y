{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Table of Contents\n* [Exploration of Target](#1)\n* [Exploration of Features](#2)\n* [Target vs Features](#3)\n* [TabNet Model](#4)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# install TabNet first\n!pip install pytorch-tabnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# TabNet and ML tools\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nfrom sklearn.model_selection import KFold\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# load training data\ndf_train = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='1'></a>\n# Exploration of Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram of target\ndf_train.target.plot(kind='hist', bins=50)\nplt.title('Target - Histogram')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KDE plot of target\ndf_train.target.plot(kind='kde')\nplt.title('Target - Kernel Density Estimator')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# boxplot of target => looking for outliers\ndf_train.target.plot(kind='box')\nplt.title('Target - Boxplot')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check for the zero value"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_zero = df_train[df_train.target==0]\ndf_zero","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This is just one of 30'000 rows, let's remove this row..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train[df_train.target>0]\ndf_train.target.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='2'></a>\n# Exploration of Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n            'cont6', 'cont7', 'cont8', 'cont9', 'cont10',\n            'cont11', 'cont12', 'cont13', 'cont14']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summary stats\ndf_train[features].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature distributions"},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in features:\n    plt.figure(figsize=(8,4))\n    plt.hist(df_train[f], bins=100)\n    plt.title(f)\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_pearson = df_train[features].corr(method='pearson')\ncorr_spearman = df_train[features].corr(method='spearman')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (12,9))\nsns.heatmap(corr_pearson, annot=True, cmap=\"RdYlGn\")\nplt.title('Pearson Correlation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (12,9))\nsns.heatmap(corr_spearman, annot=True, cmap=\"RdYlGn\")\nplt.title('Spearman Correlation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pairwise scatter plot of features (takes some time to render!)\nsns.pairplot(df_train[features], kind='scatter', plot_kws={'alpha': 0.01})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='3'></a>\n# Target vs Features"},{"metadata":{},"cell_type":"markdown","source":"### Scatter Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in features:\n    c = df_train[f].corr(df_train.target, method='pearson')\n    c = np.round(c,4)\n    plt.figure(figsize=(7,7))\n    plt.scatter(df_train[f], df_train.target, alpha=0.01)\n    plt.title('Target vs ' + f + ' / corr = ' + str(c))\n    plt.xlabel(f)\n    plt.ylabel('Target')\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization based on binned features"},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in features:\n    new_var = f + '_bin'\n    df_train[new_var] = pd.cut(df_train[f], bins=10, include_lowest=True)\n    plt.figure(figsize=(7,7))\n    sns.boxplot(data=df_train, x=new_var, y='target')\n    plt.xticks(rotation=90)\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='4'></a>\n# TabNet model"},{"metadata":{},"cell_type":"markdown","source":"Thanks to the following notebook for a quick introduction: [https://www.kaggle.com/elvinagammed/tabnet-regression-baseline](https://www.kaggle.com/elvinagammed/tabnet-regression-baseline)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# load test data\ndf_test = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dimensions of test set\ndf_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature matrices\nX = df_train[features].to_numpy()\nX_test = df_test[features].to_numpy()\n\n# target\ny = df_train.target.to_numpy().reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random seeds\nrnd_seed_cv = 1234\nrnd_seed_reg = 1234","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross validation\nn_cv = 7\nkf = KFold(n_splits=n_cv, random_state=rnd_seed_cv, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train\n\nCVs = []\npreds_train = []\npreds_test = []\nhists = []\n\nt1 = time.time()\nfor train_index, test_index in kf.split(X):\n    # get current train/valid set according to CVs\n    X_train, X_valid = X[train_index], X[test_index]\n    y_train, y_valid = y[train_index], y[test_index]\n    \n    # define regression model\n    regressor = TabNetRegressor(\n        n_d = 16, # default: 8\n        n_a = 16, # default: 8\n        n_steps = 4, # default: 3\n        n_independent = 2, # default: 2\n        n_shared = 2, # default: 2\n        lambda_sparse = 0, # default: 1e-3\n        optimizer_params = dict(lr = 1e-2, weight_decay=1e-5), # default: dict(lr=2e-2)\n        mask_type = 'entmax',\n        scheduler_params = dict(mode = 'min',\n                                patience = 5,\n                                min_lr = 1e-4,\n                                factor = 0.8),\n        scheduler_fn = ReduceLROnPlateau,\n        verbose = 1,\n        seed = rnd_seed_reg)\n    \n    # fit model\n    regressor.fit(X_train=X_train, y_train=y_train,\n              eval_set=[(X_valid, y_valid)],\n              max_epochs=100,\n              patience=15,\n              batch_size = 1024,\n              eval_metric=['rmse'])\n    \n    # update stats for cross validation performance, predictions and scoring history\n    CVs.append(regressor.best_cost)\n    preds_train.append(regressor.predict(X))\n    preds_test.append(regressor.predict(X_test))\n    hists.append(regressor.history)\nt2 = time.time()\n\nprint('\\nElapsed time [s]: ', np.round(t2-t1,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Details about model parameters etc. see [https://pypi.org/project/pytorch-tabnet/](https://pypi.org/project/pytorch-tabnet/)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot scoring history\nfor i in range(n_cv):\n    plt.plot(hists[i]['loss'], label=i)\nplt.title('CV loss')\nplt.ylim(0.4,0.6)\nplt.grid()\nplt.legend(loc='lower left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot scoring history\nfor i in range(n_cv):\n    plt.plot(hists[i]['val_0_rmse'], label=i)\nplt.title('CV RMSE')    \nplt.grid()\nplt.legend(loc='lower left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot learning rates\nfor i in range(n_cv):\n    plt.plot(hists[i]['lr'], label=i)\nplt.title('Learning Rates')\nplt.grid()\nplt.legend(loc='lower left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation performance\nprint(CVs)\nprint()\nprint('Mean CV performance [RMSE]:  ', np.round(np.mean(CVs, axis=0),8))\nprint('Stdev CV performance [RMSE]: ', np.round(np.std(CVs, axis=0),8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show volatility of predictions (on training data)\nn_show = 100 # select subset\nmy_alpha = 0.5\nplt.figure(figsize=(18,5))\nfor i in range(n_cv):\n    plt.scatter(range(0,n_show),preds_train[i][0:n_show], alpha=my_alpha)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show volatility of predictions (on test set)\nn_show = 100 # select subset\nmy_alpha = 0.5\nplt.figure(figsize=(18,5))\nfor i in range(n_cv):\n    plt.scatter(range(0,n_show),preds_test[i][0:n_show], alpha=my_alpha)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calc predictions on train and test set by averaging\npred_train = np.mean(preds_train, axis=0)\npred_test = np.mean(preds_test, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot distribution of predictions on training data / test set\nplt.figure(figsize=(10,4))\n\nplt.subplot(1, 2, 1)\nplt.hist(pred_train, bins=50)\nplt.title('Predictions on Training Data')\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.hist(pred_test, bins=50)\nplt.title('Predictions on Test Set')\nplt.grid()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add predictions to training data\ndf_train['prediction'] = pred_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot predictions vs actual on training data\nsns.jointplot(data=df_train, x='target', y='prediction',\n             joint_kws={'alpha' : 0.1})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare submission\ndf_sub = pd.read_csv('../input/tabular-playground-series-jan-2021/sample_submission.csv')\ndf_sub.target = pred_test\ndf_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save to file for submission\ndf_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}