{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport xgboost as xgb\nimport optuna\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading training data\ntrain_df = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')\n\n# Display the first line of training data, check the summary\nprint(train_df.head())\nprint(train_df.describe())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading test data\ntest_df  = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')\n\n# Display the first line of test data, check the summary\nprint(test_df.head())\nprint(test_df.describe())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 300,000 training data and 200,000 test data.  \nThere are 14 variables from cont1 to cont14, and there is no category data.  \n\nNext, check if there are any missing values.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.info())\nprint(test_df.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There seems to be no missing values.  \n\nCheck the correlation between cont1 to 14 and target.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a heat map of the correlation matrix of training data\ncor = train_df.corr()\n\nplt.figure(figsize=(10,8))\nsns.heatmap(cor, cmap= sns.color_palette('coolwarm', 10),\n            vmin = -1, vmax = 1);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no correlation between target and cont1-14.   \nCont2 and cont14 have a small correlation with other variables. Weak negative correlations are rarely seen between cont3-1 and cont3-9.\nOn the other hand, there are many positively correlated variables such as cont1-6,9,10,12, cont6-9,10,11,12,13, and cont11-12 has a particularly strong correlation.  \n\nCheck the distribution of each variable. First from target.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"column = train_df.columns[-1]\n\nfig, ax1 = plt.subplots(1,1)\n\nax1.hist(train_df[column], bins=50)\nax1.set_title(column);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is not a single distribution, but it seems that the shape is like two distributions overlapping.\n\nCheck the distribution of each cont for train and test."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw a histogram of training data\ntrain_cols = [col for col in list(train_df) if col != 'id']\ntrain_df[train_cols].hist(figsize=(20,20), bins=100, color='blue', alpha=0.5)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw a histogram of test data\ntest_cols = train_cols.copy()\ntest_cols.pop(-1)\n\ntest_df[test_cols].hist(figsize=(20,20), bins=100, color='orange', alpha = 0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the distribution by overlaying the training data and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20,20))\n\nfor i, col in enumerate(test_cols):\n    sns.distplot(train_df[col],bins=50, hist=True, color='blue', ax=axes[i//4, i%4])\n    sns.distplot(test_df[col],bins=50, hist=True, color='orange', ax=axes[i//4, i%4])\n    fig.subplots_adjust(wspace=0.2, hspace=0.2);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the distribution shape is the same, if the training data gives a good prediction, the test data is likely to give a good prediction.  \nLet's actually predict with a model.\n\n\nI refer to the following notebooks.\n+ https://www.kaggle.com/dwin183287/tps-jan-2021-eda-models\n"},{"metadata":{},"cell_type":"markdown","source":"## Modeling and Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store features in x_train and'target' in y_train\nfeatures = [feature for feature in train_df.columns if feature not in ['id', 'target']]\nX_train = train_df[features]\ny_train = train_df['target']\nX_test = test_df[features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  \nLet's try Random Forest first.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# Random forest\n\nforest_reg = RandomForestRegressor(random_state=121, n_jobs=-1)\n# Learn using training data and calculate score by cross-validation (CV = 4)\n# Random forest learning takes time, so I am running it with CV = 4.\nscores = cross_val_score(forest_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=4)\n\nforest_rmse_scores = np.sqrt(-scores)\nprint('Random Forest performance:', forest_rmse_scores)\nprint('Random Forest performance_mean:', forest_rmse_scores.mean())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Learning Random Forest takes time.  \nNext, let's predict with xgboost and lightGBM.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# xgboost\n\nxgb_reg = XGBRegressor(random_state=121, objective = 'reg:squarederror', n_jobs=-1)\n\nscores = cross_val_score(xgb_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\nxgb_rmse_scores = np.sqrt(-scores)\nprint('XGBoost performance:', xgb_rmse_scores)\nprint('XGBoost performance_mean:', xgb_rmse_scores.mean())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"xgboost is faster to learn and more predictive than Random Forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# lightGBM\nlgbm_reg = LGBMRegressor(random_state=121)\n\nscores = cross_val_score(lgbm_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\nlgbm_rmse_scores = np.sqrt(-scores)\nprint('LGBM performance:', lgbm_rmse_scores)\nprint('LGBM performance_mean:', lgbm_rmse_scores.mean())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lightGBM learns faster than xgboost.  \nI can't expect much, but let's take a look at Lasso and Ridge for linear regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"# LASSO regression model\n# The default regularization strength is alpha = 1.0.\n\nlasso_reg = Lasso()\n\nscores = cross_val_score(lasso_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\nlasso_rmse_scores = np.sqrt(-scores)\nprint('LASSO performance:', lasso_rmse_scores)\nprint('LASSO performance_mean:', lasso_rmse_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ridge regression model\n# The default regularization strength is alpha = 1.0.\n\nridge_reg = Ridge()\n\nscores = cross_val_score(ridge_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\nridge_rmse_scores = np.sqrt(-scores)\nprint('Ridge performance:', ridge_rmse_scores)\nprint('Ridge performance_mean:', ridge_rmse_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The performance of both LASSO and Ridge is not high.  \nTry to improve the prediction performance by tuning the parameters.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change the value of alpha and try to improve the model.\n\n# To try and compare multiple alpha conditions, \n# create a function that calculates rmse_scores and returns the mean.\ndef rmse_mean(model):\n    \"\"\"\n    RMSE averaging function\n    \n    \"\"\"\n    rmse_scores_mean = np.sqrt(\n        -cross_val_score(   # Calculate score by cross-validation\n            model, X_train, y_train, # Model, training data, correct value\n            scoring=\"neg_mean_squared_error\", \n            cv=5,          # Divide the data into 5 and use 80% for training\n            )).mean()       # Calculate the average of RMSE\n    return(rmse_scores_mean)\n\n# Prepare 6 patterns of L1 regularization intensity (alphas)\n# Larger alpha makes a simple model\nalphas = [1, 10**-1, 10**-2, 10**-3, 10**-4, 10**-5]\n\n# Perform lasso regression at each intensity of regularization\n# Calculate RMSE with CV = 5, get the average and assign it to the list\nlasso_regs = [rmse_mean(Lasso(alpha = alpha)) for alpha in alphas]\n\n# Convert lasso_regs to Pandas Series object\nlasso_regs = pd.Series(lasso_regs, index=alphas)\n\n# Output score\nprint(\"LASSO RMSE loss:\")\nprint(lasso_regs, \"\\n\")\n\n# Output the minimum score\nprint(\"LASSO RMSE best_alpha :\", lasso_regs.idxmin())\n# Outputs the regularization term parameter at the minimum score\nprint(\"LASSO RMSE best_score value :\", lasso_regs.min(), \"\\n\")\n\n# Graph the score for each intensity of regularization\nplt.figure(figsize=(10, 5))\nplt.plot(lasso_regs)\nplt.grid()\nplt.title(\"LASSO: Validation_score - by regularization strength\")\nplt.xlabel(\"Alpha\")\nplt.ylabel(\"RMSE\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The optimum point was not found in the searched range.  \nSimilarly, try increasing the strength of the regularization of the Ridge regression to improve the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare 9 patterns of L2 regularization intensity (alphas)\n# Larger alpha makes a simple model\nalphas = [ 1, 5, 8, 10, 11, 12, 13, 15, 20]\n\n# Perform Ridge regression at each intensity of regularization\n# Calculate RMSE with CV = 5, get the average and assign it to the list\nredge_regs = [rmse_mean(Ridge(alpha = alpha)) for alpha in alphas]\n\n# Convert redge_regs to Pandas Series object\nredge_regs = pd.Series(redge_regs, index=alphas)\n\n# Output score\nprint(\"Ridge RMSE loss:\")\nprint(redge_regs, \"\\n\")\n\n# Output the minimum score\nprint(\"Ridge RMSE best_alpha :\", redge_regs.idxmin())\n# Outputs the regularization term parameter at the minimum score\nprint(\"Ridge RMSE Loss best_score value :\", redge_regs.min(), \"\\n\")\n\n# Graph the score for each intensity of regularization\nplt.figure(figsize=(10, 5))\nplt.plot(redge_regs)\nplt.grid()\nplt.title(\"Ridge: Validation_score - by regularization strength\")\nplt.xlabel(\"Alpha\")\nplt.ylabel(\"RMSE\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Alpha = 11 was the best parameter in the searched range. Unfortunately, no major improvement can be expected."},{"metadata":{},"cell_type":"markdown","source":"For XGboost, try optimizing hyperparameters using Optuna.  \n\nThe code is taken from the notebook below.  \n\n+ https://www.kaggle.com/hamzaghanmi/xgboost-hyperparameter-tuning-using-optuna\n+ https://www.kaggle.com/sakuraandblackcat/leaning-validation-curve-and-optuna-for-gbdts\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Store training data in X and'target' in y\n\nX = train_df[features]\ny = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial,data=X,target=y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n    param = {\n        'tree_method':'gpu_hist',  # 'gpu_hist'this parameter means using the GPU \n        \n        'lambda': \n            trial.suggest_loguniform('lambda', 1e-3, 1),\n        'alpha': \n            trial.suggest_loguniform('alpha', 1e-3, 1),\n        'colsample_bytree': \n            trial.suggest_categorical('colsample_bytree', \n                                      [0.1, 0.2, 0.3,0.5,0.7,0.9]),\n        'subsample': \n            trial.suggest_categorical('subsample', \n                                      [0.1, 0.2,0.3,0.4,0.5,0.8,1.0]),\n        'learning_rate': \n            trial.suggest_categorical('learning_rate', \n                                      [0.0008, 0.01, 0.015, 0.02,0.03, 0.05,0.08,0.1]),\n        'n_estimators': 4000,\n        'max_depth': \n            trial.suggest_categorical('max_depth', \n                                      [5,7,9,11,13,15,17,20,23,25]),\n        'random_state': 48,\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 400),\n    }\n    \n    model = xgb.XGBRegressor(**param)\n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)], \n              early_stopping_rounds=100,verbose=False)\n    \n    preds = model.predict(test_x)\n    \n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a study object and record the learning content.\nstudy = optuna.create_study(direction='minimize') #、Minimize the objective function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This cell will take some time.\n# The search may be inadequate, but if it takes too long, reduce the number of attempts.\n# You can add the number of searches by executing this cell multiple times.\n\nstudy.optimize(objective, n_trials=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output the number of trials and best parameters\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can check the search results in the data frame.   \nIt is also possible to output and save as a csv file."},{"metadata":{"trusted":true},"cell_type":"code","source":"study_data_table = study.trials_dataframe()\nstudy_data_table.to_csv('study_xgboost.csv', index=False)\n\nstudy_data_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions with the parameters with the best score."},{"metadata":{},"cell_type":"markdown","source":"The best parameters when creating a notebook were as follows.  \nNumber of finished trials: 25  \n\n\nTrial 22 finished with value: 0.6936483703969993 and parameters: {'lambda': 0.03349655513592068, 'alpha': 0.12097952030992898, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 179}. Best is trial 22 with value: 0.6936483703969993.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_trial_paras = {'tree_method':'gpu_hist', 'lambda': 0.03349655513592068, \n                    'alpha': 0.12097952030992898, 'colsample_bytree': 0.5, \n                    'subsample': 0.4, 'learning_rate': 0.01, \n              'n_estimators': 4000, 'max_depth': 11, 'min_child_weight': 179, \n              'random_state': 2021 \n              }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# At CV = 5, add up each rmse and use the average value.\n\npreds = np.zeros(test_df.shape[0])\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nrmse=[]  # list contains rmse for each fold\nn=0\nfor trn_idx, test_idx in kf.split(train_df[features],train_df['target']):\n    X_tr,X_val=train_df[features].iloc[trn_idx],train_df[features].iloc[test_idx]\n    y_tr,y_val=train_df['target'].iloc[trn_idx],train_df['target'].iloc[test_idx]\n    model = xgb.XGBRegressor(**best_trial_paras)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100, verbose=False)\n    preds+=model.predict(test_df[features])/kf.n_splits\n    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n    print(n+1,rmse[n])\n    n+=1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading submission data\nsub = pd.read_csv('../input/tabular-playground-series-jan-2021/sample_submission.csv')\nprint(sub.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target']=preds\nprint(sub.head())\nsub.to_csv('xgboost_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you for reading my notebook.  \nI hope the content of the article will be useful to you."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}