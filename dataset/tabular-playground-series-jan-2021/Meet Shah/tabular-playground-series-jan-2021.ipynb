{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Try AutoMLJar (Notebook Window Should be Opened)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.0 Importing Essential Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.0 Data Exploration & Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/tabular-playground-series-jan-2021/'\n\ntrain_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\nsample_submission = pd.read_csv(path + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, test_df.shape, sample_submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df.drop(columns = ['target'])\n#X_test = test_df.drop('id', axis = 1)\n#y_train = cudf.DataFrame(train_df.target)\ny_train = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train.set_index('id', inplace = True)\n#X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_df.copy()\n#X_test.set_index('id', inplace = True)\n#X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#columns = [col for col in train_df.columns.to_list() if col not in ['id','target']]\n#X_train = train_df[columns]\n#y_train = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.0 Model Building in Pipelines"},{"metadata":{"trusted":true},"cell_type":"code","source":"#params1 = {\n#    'n_estimators' : [100, 200, 300, 400, 500, 600],\n#    'max_depth' : 10, #[4, 6, 8, 10, 12, 14],\n#    'max_leaves' : 2**4,\n#    'tree_method' : 'gpu_hist',\n#    'learning_rate' : 0.1,\n#    'objective' : 'reg:squaredlogerror',\n#    'eval_metric' : 'rmse'\n#}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from cuml.preprocessing.model_selection import train_test_split\nfrom xgboost import XGBRegressor\n#from cuml.metrics import roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial, X = X_train, y = y_train):\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, \n                                test_size = 0.2, random_state = 0)\n    params = {\n        'tree_method' : 'gpu_hist',\n        'learning_rate' : trial.suggest_categorical(\"learning_rate\",\n            [0.008, 0.009, 0.01, 0.012, 0.014, 0.016 ,0.018, 0.02]),\n        'n_estimators' : trial.suggest_int(\"n_estimators\", 100, 1500),\n        'max_depth' : trial.suggest_int(\"max_depth\", 2, 20),\n        #'max_features' : trial.suggest_uniform(\"max_features\", 0.01, 1.0),\n        'random_state' : 0,\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300)\n    }\n    \n    xgb = XGBRegressor(**params)\n    xgb.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False)\n    \n    pred = xgb.predict(X_val)\n    \n    rmse = mean_squared_error(y_val, pred, squared = False)\n    \n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import optuna\nstudy = optuna.create_study(direction = 'minimize')\nstudy.optimize(objective, n_trials = 100)\nprint ('Total Finished Trials:', len(study.trials))\nprint('Best Trial:', study.best_trial.params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total Finished Trials: 100\n#Best Trial1: {'learning_rate': 0.01, 'n_estimators': 1258, 'max_depth': 16, 'max_features': 0.4314231900564939, 'lambda': 0.06175177599003586, \n#                'alpha': 0.0301162104635596, 'colsample_bytree': 0.6, 'subsample': 0.8, 'min_child_weight': 282}\n\n\n# Best Trial No 72: {'learning_rate': 0.012, 'n_estimators': 1457, 'max_depth': 13, 'lambda': 3.470813989036924, 'alpha': 0.04682398849757302, \n#                'colsample_bytree': 0.7, 'subsample': 0.5, 'min_child_weight': 227}\n\n\n# Best Trail No 54 : {'learning_rate': 0.012, 'n_estimators': 1471, 'max_depth': 13, 'lambda': 5.054720822936409, 'alpha': 0.06441154220145467, \n#                      'colsample_bytree': 0.7, 'subsample': 0.5, 'min_child_weight': 237}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Best_trial = {'tree_method' : 'gpu_hist', 'eval_metric' : 'rmse', 'learning_rate': 0.01, 'n_estimators': 1258, 'max_depth': 16, 'lambda': 0.06175177599003586, \n                'alpha': 0.0301162104635596, 'colsample_bytree': 0.6, 'subsample': 0.8, 'min_child_weight': 282, \n              'importance_type' : 'total_gain', 'objective' : 'reg:tweedie', 'grow_policy' : 'depthwise', 'random_state' : 0} #'max_features': 0.4314231900564939,\n\nfrom xgboost import XGBRegressor\n\n\nxgb = XGBRegressor(**Best_trial) #, n_estimators = 500, max_depth = 10, eval_metric = 'rmse',\nxgb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1st Try\n\n#{'tree_method': 'gpu_hist',\n# 'n_estimators': 300,\n# 'min_child_weight': 5,\n# 'max_depth': 6,\n# 'learning_rate': 0.1,\n# 'gamma': 0.4}\n\n# Score = 0.70158\n\n\n#2nd Try\n\n#{'tree_method': 'gpu_hist',\n# 'n_estimators': 400,\n# 'min_child_weight': 3.5,\n# 'max_depth': 6,\n# 'learning_rate': 0.15,\n# 'gamma': 0.6}\n\n# Score = 0.70225\n\n\n#3rd Try\n\n#Best_trial = {'tree_method' : 'gpu_hist', 'learning_rate': 0.01, 'n_estimators': 1258, 'max_depth': 16, \n#'max_features': 0.4314231900564939, 'lambda': 0.06175177599003586, 'alpha': 0.0301162104635596, 'colsample_bytree': 0.6, \n#                'subsample': 0.8, 'min_child_weight': 282, 'random_state' : 0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the model\ny_pred = xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n\n\n#print('R2 Score : ', r2_score(y_val, y_pred_val))\n#print('ROC AUC SCORE : ', roc_auc_score(y_val, y_pred_val))\n#print('Mean Squared Error : ', mean_squared_error(y_val, y_pred_val))\n#print('Root Mean Squared Error : ', (mean_squared_error(y_val, y_pred_val, squared = False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a Submission File\nsample_submission['target'] = y_pred\nsample_submission.to_csv('submission26.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the submission file\nsubmission = pd.read_csv('submission26.csv')\nsubmission.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}