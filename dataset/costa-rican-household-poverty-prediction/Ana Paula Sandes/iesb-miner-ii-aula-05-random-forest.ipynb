{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IESB - Miner II - Aula 05 - Random Forest\nPor: Ana Souza Matricula: 1931133141","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Carregando os dados\ntrain = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando os dataframes\ndf_all = train.append(test)\ndf_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tipos dos dados\ndf_all.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Temos três tipos de dados na planilha","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5 colunas são do tipo object: \n> \n    Id: a unique identifier for each individual.\n    idhogar: a unique identifier for each household. Group individuals by household.\n    parentesco1: indicates if person is the head of the household or not. \n    Target: the label, which should be equal for all members in a household","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> \n    dependency: Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)\n    edjefe: years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n    edjefa: years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Substituindo valores yes e no por 1 e 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping = {\"yes\": 1, \"no\": 0}\n\n# Apply same operation to both train and test\nfor df in [train, test]:\n    # Fill in the values with the correct mapping\n    df['dependency'] = df['dependency'].replace(mapping).astype(np.float64)\n    df['edjefa'] = df['edjefa'].replace(mapping).astype(np.float64)\n    df['edjefe'] = df['edjefe'].replace(mapping).astype(np.float64)\n\ntrain[['dependency', 'edjefa', 'edjefe']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo int\ndf_all.select_dtypes('int').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"129 colunas são do tipo int","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.select_dtypes(np.int64).nunique().value_counts().sort_index().plot.bar(color = 'pink', \n                                                                             figsize = (8, 6),\n                                                                            edgecolor = 'k', linewidth = 2);\nplt.xlabel('Number of Unique Values'); plt.ylabel('Count');\nplt.title('Count of Unique Values in Integer Columns');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"É possível notar que grande parte das colunas int são binarias","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo float\ndf_all.select_dtypes('float').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\n\nplt.figure(figsize = (20, 16))\nplt.style.use('fivethirtyeight')\n\n# Color mapping\ncolors = OrderedDict({1: 'red', 2: 'orange', 3: 'blue', 4: 'green'})\npoverty_mapping = OrderedDict({1: 'extreme', 2: 'moderate', 3: 'vulnerable', 4: 'non vulnerable'})\n\n# Iterate through the float columns\nfor i, col in enumerate(train.select_dtypes('float')):\n    ax = plt.subplot(4, 2, i + 1)\n    # Iterate through the poverty levels\n    for poverty_level, color in colors.items():\n        # Plot each poverty level as a separate line\n        sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(), \n                    ax = ax, color = color, label = poverty_mapping[poverty_level])\n        \n    plt.title(f'{col.capitalize()} Distribution'); plt.xlabel(f'{col}'); plt.ylabel('Density')\n\nplt.subplots_adjust(top = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"meaneduc distribution (media de escolaridade) parece estar mais relacionada ao nivel de pobreza","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Precisamos adicionar a coluna de valores nulos para nossa target no dataset de teste","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adicionar coluna de nulo no test\ntest['Target'] = np.nan\ndata = train.append(test, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribuição dos dados","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\n\n# Color mapping\ncolors = OrderedDict({1: 'red', 2: 'orange', 3: 'blue', 4: 'green'})\n# Poverty Mapping\npoverty_mapping = OrderedDict({1: 'extreme', 2: 'moderate', 3: 'vulnerable', 4: 'non vulnerable'})\n\n# Heads of household\nheads = data.loc[data['parentesco1'] == 1].copy()\n\n# Labels for training\ntrain_labels = data.loc[(data['Target'].notnull()) & (data['parentesco1'] == 1), ['Target', 'idhogar']]\n\n# Value counts of target\nlabel_counts = train_labels['Target'].value_counts().sort_index()\n\n# Bar plot of occurrences of each label\nlabel_counts.plot.bar(figsize = (8, 6), \n                      color = colors.values(),\n                      edgecolor = 'k', linewidth = 2)\n\n# Formatting\nplt.xlabel('Poverty Level'); plt.ylabel('Count'); \nplt.xticks([x - 1 for x in poverty_mapping.keys()], \n           list(poverty_mapping.values()), rotation = 60)\nplt.title('Poverty Level Breakdown');\n\nlabel_counts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A maior parte dos nossos dados apresentam valores non-vulterable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nas colunas edjefe, edjefa e dependency, temos valores yes e no que gostariamos de substituir por valores int","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(float)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(float)\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all[['dependency', 'edjefa', 'edjefe']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para garantir que nossos dados de treino e teste estarao ok, vou separa-los somente apos o tratamento do df_all","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Existem alguns problemas de labels errados que podemos encontrar em datasets reais. Neste caso, devemos utilizar o head of household as true label. Dessa forma, pessoas com o mesmo head devem ter o mesmo label. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Groupby the household and figure out the number of unique values\nall_equal = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Households where targets are not all equal\nnot_equal = all_equal[all_equal != True]\nprint('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para corrigir o erro onde pessoas de uma mesma casa tem diferentes valores target, podemos reassing os valores de acordo com o valor onde parentesco1 == 1.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Outro erro que pode ocorrer é o caso de households sem uma head, o que nesse caso, dificultaria a chance de ter uma target. O caderno \"A complete introduction and walkthrough\" apresenta uma forma de resolver o problema.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"households_leader = train.groupby('idhogar')['parentesco1'].sum()\n\n# Find households without a head\nhouseholds_no_head = train.loc[train['idhogar'].isin(households_leader[households_leader == 0].index), :]\n\nprint('There are {} households without a head.'.format(households_no_head['idhogar'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No caso do código acima, a estratégia utilizada envolve somar os valores de parentesco1, sabendo que se a soma for 0, significa que não houve designação de head. Caso os labels fossem diferentes para casa sem head, não saberíamos como reassing a nova target.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Outra necessidade que temos que ainda trata do handle da limpeza de dados, é o tratamento de valores nulos. Primeiramente é necessaŕio verificar a quantidade de valores nulos, o que eu gosto de fazer pela porcentagem. Depois, é necessário esoclher um método de acordo com o problema que estamos resolvendo - e decidir se iremos substituir os valores missing ou retirá-los do dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = pd.DataFrame(data.isnull().sum()).rename(columns = {0: 'total'})\nmissing['percent'] = missing['total'] / len(data)\nmissing.sort_values('percent', ascending = False).head(10).drop('Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De acordo com o resultado, as principais colunas que devemos tratar sao as rez_esc, v18q1, v2a1, SQBmeaned e meaneduc. Como as duas ultimas tem uma porcentagem baixa de nulos, as que realmente precisam de tratamento seriam as tres primeiras.\n\n> v18q1: Numero de tablets por familia. \nv2a1: Pagamento de alguel mensal.\nrez_esc: anos atrasados na escolaridade.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_value_counts(df, col, heads_only = False):\n    \"\"\"Plot value counts of a column, optionally with only the heads of a household\"\"\"\n    # Select heads of household\n    if heads_only:\n        df = df.loc[df['parentesco1'] == 1].copy()\n        \n    plt.figure(figsize = (8, 6))\n    df[col].value_counts().sort_index().plot.bar(color = 'blue',\n                                                 edgecolor = 'k',\n                                                 linewidth = 2)\n    plt.xlabel(f'{col}'); plt.title(f'{col} Value Counts'); plt.ylabel('Count')\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_value_counts(heads, 'v18q1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A grande maioria das casas tem 1 tablet. Entretanto, talvez o esperado fosse que a maioria ou uma parte proxima disto, teria nenhum tablet. O que não é apresentado aqui. Isto pode indicar então, que a quantidade de valores missing são, na verdade, valores 0. Assim, irei substituir valores NaN por zeros.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['v18q1'] = data['v18q1'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para tratar da proxima coluna, referente ao aluguel, precisamos selecionar casas que sejam alugadas. A coluna para isso é a tipovivi_. Tambem podemos suspeitar de inicio, que valores NaN indiquem casas que nao precisam de alguel.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Variables indicating home ownership\nown_variables = [x for x in data if x.startswith('tipo')]\n\n\n# Plot of the home ownership variables for home missing rent payments\ndata.loc[data['v2a1'].isnull(), own_variables].sum().plot.bar(figsize = (10, 8),\n                                                                        color = 'green',\n                                                              edgecolor = 'k', linewidth = 2);\nplt.xticks([0, 1, 2, 3, 4],\n           ['Owns and Paid Off', 'Owns and Paying', 'Rented', 'Precarious', 'Other'],\n          rotation = 60)\nplt.title('Home Ownership Status for Households Missing Rent Payments', size = 18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> tipovivi1, =1 own and fully paid house\ntipovivi2, \"=1 own,  paying in installments\"\ntipovivi3, =1 rented\ntipovivi4, =1 precarious\ntipovivi5, \"=1 other(assigned,  borrowed)\"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Para casas que sao owned, podemos substituir o valor missing. Ja para casas que nao sao owned e tem valores missing, podemos adicionar uma indicacao de que ela nao tem valor.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill in households that own the house with 0 rent payment\ndata.loc[(data['tipovivi1'] == 1), 'v2a1'] = 0\n\n# Create missing rent payment column\ndata['v2a1-missing'] = data['v2a1'].isnull()\n\ndata['v2a1-missing'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Valores nulos em rez_esc podem indicar casas sem crianças.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['rez_esc'].notnull()]['age'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A idade mais velha que temos de nao missings é de 17, ou seja, até 17 anos temos nao missing e depois começamos a ter.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# If individual is over 19 or younger than 7 and missing years behind, set it to 0\ndata.loc[((data['age'] > 19) | (data['age'] < 7)) & (data['rez_esc'].isnull()), 'rez_esc'] = 0\n\n# Add a flag for those between 7 and 19 with a missing value\ndata['rez_esc-missing'] = data['rez_esc'].isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['rez_esc'] > 5, 'rez_esc'] = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos querer remover variavies que sao muito redundates para nosso modelo","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create correlation matrix\ncorr_matrix = heads.corr()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n\nto_drop\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix.loc[corr_matrix['tamhog'].abs() > 0.9, corr_matrix['tamhog'].abs() > 0.9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heads = heads.drop(columns = ['tamhog', 'hogar_total', 'r4t3'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para feature, podemos observar a diferença do tamanho da casa e da quantidade de pessoas dentro do household ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_categoricals(x, y, data, annotate = True):\n    \"\"\"Plot counts of two categoricals.\n    Size is raw count for each grouping.\n    Percentages are for a given value of y.\"\"\"\n    \n    # Raw counts \n    raw_counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = False))\n    raw_counts = raw_counts.rename(columns = {x: 'raw_count'})\n    \n    # Calculate counts for each group of x and y\n    counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = True))\n    \n    # Rename the column and reset the index\n    counts = counts.rename(columns = {x: 'normalized_count'}).reset_index()\n    counts['percent'] = 100 * counts['normalized_count']\n    \n    # Add the raw count\n    counts['raw_count'] = list(raw_counts['raw_count'])\n    \n    plt.figure(figsize = (14, 10))\n    # Scatter plot sized by percent\n    plt.scatter(counts[x], counts[y], edgecolor = 'k', color = 'lightgreen',\n                s = 100 * np.sqrt(counts['raw_count']), marker = 'o',\n                alpha = 0.6, linewidth = 1.5)\n    \n    if annotate:\n        # Annotate the plot with text\n        for i, row in counts.iterrows():\n            # Put text with appropriate offsets\n            plt.annotate(xy = (row[x] - (1 / counts[x].nunique()), \n                               row[y] - (0.15 / counts[y].nunique())),\n                         color = 'navy',\n                         s = f\"{round(row['percent'], 1)}%\")\n        \n    # Set tick marks\n    plt.yticks(counts[y].unique())\n    plt.xticks(counts[x].unique())\n    \n    # Transform min and max to evenly space in square root domain\n    sqr_min = int(np.sqrt(raw_counts['raw_count'].min()))\n    sqr_max = int(np.sqrt(raw_counts['raw_count'].max()))\n    \n    # 5 sizes for legend\n    msizes = list(range(sqr_min, sqr_max,\n                        int(( sqr_max - sqr_min) / 5)))\n    markers = []\n    \n    # Markers for legend\n    for size in msizes:\n        markers.append(plt.scatter([], [], s = 100 * size, \n                                   label = f'{int(round(np.square(size) / 100) * 100)}', \n                                   color = 'lightgreen',\n                                   alpha = 0.6, edgecolor = 'k', linewidth = 1.5))\n        \n    # Legend and formatting\n    plt.legend(handles = markers, title = 'Counts',\n               labelspacing = 3, handletextpad = 2,\n               fontsize = 16,\n               loc = (1.10, 0.19))\n    \n    plt.annotate(f'* Size represents raw count while % is for a given y value.',\n                 xy = (0, 1), xycoords = 'figure points', size = 10)\n    \n    # Adjust axes limits\n    plt.xlim((counts[x].min() - (6 / counts[x].nunique()), \n              counts[x].max() + (6 / counts[x].nunique())))\n    plt.ylim((counts[y].min() - (4 / counts[y].nunique()), \n              counts[y].max() + (4 / counts[y].nunique())))\n    plt.grid(None)\n    plt.xlabel(f\"{x}\"); plt.ylabel(f\"{y}\"); plt.title(f\"{y} vs {x}\");\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heads['hhsize-diff'] = heads['tamviv'] - heads['hhsize']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix.loc[corr_matrix['coopele'].abs() > 0.9, corr_matrix['coopele'].abs() > 0.9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\n\n# Custom scorer for cross validation\nscorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Labels for training\ntrain_labels = np.array(list(train[train['Target'].notnull()]['Target'].astype(np.uint8)))\n\n# Extract the training data\ntrain_set = train[train['Target'].notnull()].drop(columns = ['Id', 'idhogar', 'Target'])\ntest_set = test[test['Target'].isnull()].drop(columns = ['Id', 'idhogar', 'Target'])\n\n# Submission base which is used for making submissions to the competition\nsubmission_base = test[['Id', 'idhogar']].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(train_set.columns)\n\npipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n                      ('scaler', MinMaxScaler())])\n\n# Fit and transform training data\ntrain_set = pipeline.fit_transform(train_set)\ntest_set = pipeline.transform(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=100, random_state=10, \n                               n_jobs = -1)\n# 10 fold cross validation\ncv_score = cross_val_score(model, train_set, train_labels, cv = 10, scoring = scorer)\n\nprint(f'10 Fold Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}