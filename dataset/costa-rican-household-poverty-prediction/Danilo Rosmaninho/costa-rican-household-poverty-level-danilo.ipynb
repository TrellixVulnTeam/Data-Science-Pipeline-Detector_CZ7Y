{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Sources:\n# https://www.kaggle.com/shivamb/costa-rica-poverty-exploration-kernel\n# https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough\n# https://www.kaggle.com/willkoehrsen/featuretools-for-good\n\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\n%matplotlib inline\nimport seaborn as sns\nfrom scipy.stats import spearmanr\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom skopt import BayesSearchCV\nfrom skopt.space import Real, Categorical, Integer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nimport xgboost as xgb\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix, f1_score, make_scorer\nimport shap\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\ncodebook = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/codebook.csv')\nsubmission = test[['Id', 'idhogar']]\n\npd.options.display.max_columns = 150\npd.options.display.max_rows = 200\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", message=\"FixedFormatter should only be used together with FixedLocator\")\nwarnings.filterwarnings(\"ignore\", message=\"Pass the following variables as keyword args: x, y. From version 0.12, the only valid\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-24T03:15:56.132936Z","iopub.execute_input":"2021-08-24T03:15:56.133301Z","iopub.status.idle":"2021-08-24T03:15:56.55711Z","shell.execute_reply.started":"2021-08-24T03:15:56.133269Z","shell.execute_reply":"2021-08-24T03:15:56.556019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"codebook","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:56.558704Z","iopub.execute_input":"2021-08-24T03:15:56.559013Z","iopub.status.idle":"2021-08-24T03:15:56.588394Z","shell.execute_reply.started":"2021-08-24T03:15:56.558985Z","shell.execute_reply":"2021-08-24T03:15:56.586852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:56.591888Z","iopub.execute_input":"2021-08-24T03:15:56.592393Z","iopub.status.idle":"2021-08-24T03:15:56.685017Z","shell.execute_reply.started":"2021-08-24T03:15:56.592343Z","shell.execute_reply":"2021-08-24T03:15:56.683657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()\n\n# We're dealing with an 9557x143 dataframe, using 10.4MB of memory. A fairly large database to kaggle parameters\n# Most values are int, some are categorical and float","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:56.686733Z","iopub.execute_input":"2021-08-24T03:15:56.687081Z","iopub.status.idle":"2021-08-24T03:15:56.712164Z","shell.execute_reply.started":"2021-08-24T03:15:56.687051Z","shell.execute_reply":"2021-08-24T03:15:56.710647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()\n\n# There are many columns that are hot one encoded categorical features\n# Which is visible by their min, 75% and max values","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:56.713899Z","iopub.execute_input":"2021-08-24T03:15:56.71424Z","iopub.status.idle":"2021-08-24T03:15:57.170748Z","shell.execute_reply.started":"2021-08-24T03:15:56.71421Z","shell.execute_reply":"2021-08-24T03:15:57.169707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.duplicated().sum()\n\n# No duplicated values in the dataset","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:57.17237Z","iopub.execute_input":"2021-08-24T03:15:57.172781Z","iopub.status.idle":"2021-08-24T03:15:57.219695Z","shell.execute_reply.started":"2021-08-24T03:15:57.172747Z","shell.execute_reply":"2021-08-24T03:15:57.218686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_nan = train.isna().sum()\nprint(cols_nan.where(cols_nan > 0).dropna().astype('int32'))\n\n# Only a few columns with missing data. Since there are 9557 entries total, the columns with over 6000 missing entries will likely be dropped\n# The columns with 5 missing entries will be further investigated","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:57.220983Z","iopub.execute_input":"2021-08-24T03:15:57.221294Z","iopub.status.idle":"2021-08-24T03:15:57.240114Z","shell.execute_reply.started":"2021-08-24T03:15:57.221263Z","shell.execute_reply":"2021-08-24T03:15:57.238752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First, lets check v2a1\n# The column represents the amount of rent payed for the household\n# One possibility is that the values are null because the residents own the house, so have no rent to pay\n# The columns tipovivi 1 - tipovivi 5 shows if the house is owned by the residents or is paying for it monthly somehow\n\nown_series = train.columns.to_series().str.contains('tipo')\nown_var = own_series.where(own_series != False).dropna().index.to_list()\n\ntrain.loc[train['v2a1'].isnull(), own_var].sum().plot.bar(figsize = (7, 5))\nplt.xticks([0, 1, 2, 3, 4],\n           ['Owns and Paid Off', 'Owns and Paying', 'Rented', 'Precarious', 'Other'],\n          rotation = 60)\nplt.title('Home Ownership Status for Households Missing Rent Payments', size = 15);\n\n# So it seems that most houses that pays no rent are houses owned by the residents. This makes sense\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:57.244325Z","iopub.execute_input":"2021-08-24T03:15:57.244835Z","iopub.status.idle":"2021-08-24T03:15:57.449048Z","shell.execute_reply.started":"2021-08-24T03:15:57.244799Z","shell.execute_reply":"2021-08-24T03:15:57.447842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can fill the NaN values as 0 for tipovivi1\n# The other 2 columns will be imputed as 0 as well, since it is the most likely value\n# But since for them we're taking a guess, its good practice to create a impute flag column\n\ntrain.loc[(train['tipovivi1'] == 1), 'v2a1'] = 0\ntest.loc[(test['tipovivi1'] == 1), 'v2a1'] = 0\n\ntrain['v2a1-missing'] = train['v2a1'].isnull()\ntest['v2a1-missing'] = test['v2a1'].isnull()\n\ntrain['v2a1'].fillna(0, inplace=True)\ntest['v2a1'].fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:57.451096Z","iopub.execute_input":"2021-08-24T03:15:57.45142Z","iopub.status.idle":"2021-08-24T03:15:57.464981Z","shell.execute_reply.started":"2021-08-24T03:15:57.451389Z","shell.execute_reply":"2021-08-24T03:15:57.463742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now for the next missing value, v18q1\n# v18q1 refers to number of tablets in the household\n# Since its a household feature, it only makes sense to all residents in a household have the same value\n\ncheck_tablet = train.groupby('idhogar')['v18q1'].apply(lambda x: x.nunique() == 1)\ndif_tablet = check_tablet[check_tablet != True] \ndif_tablet.sum()\n\n# No distinct tablet count inside a same household, as expected\n# So we`ll use only the values for the heads of households\n\nheads = train.loc[train['parentesco1'] == 1]","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:57.466389Z","iopub.execute_input":"2021-08-24T03:15:57.466839Z","iopub.status.idle":"2021-08-24T03:15:58.147432Z","shell.execute_reply.started":"2021-08-24T03:15:57.466805Z","shell.execute_reply":"2021-08-24T03:15:58.146156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heads['v18q1'].value_counts().plot.bar()\nplt.xlabel('Number of tablets')\nplt.ylabel('Number of households')\n\n# So the most common value is 1 tablet per household, but its important to remember that the graph doesnt include NaNs\n# The most plausible idea is that the NaNs represents houses with no tablets\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:58.152519Z","iopub.execute_input":"2021-08-24T03:15:58.152888Z","iopub.status.idle":"2021-08-24T03:15:58.35934Z","shell.execute_reply.started":"2021-08-24T03:15:58.152856Z","shell.execute_reply":"2021-08-24T03:15:58.358161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The v18q column indicates whether the family owns a tablet or not\n# So comparing this column to the NaNs at v18q1, we must get to a conclusion\n\nheads.groupby('v18q')['v18q1'].apply(lambda x: x.isnull().sum())\n\n# This shows that all NaN values fall under the Dont Own a Tablet category\n# So we can simply fill the NaN values with 0\n\ntrain['v18q1'] = train['v18q1'].fillna(0)\ntest['v18q1'] = test['v18q1'].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:58.361099Z","iopub.execute_input":"2021-08-24T03:15:58.361529Z","iopub.status.idle":"2021-08-24T03:15:58.373185Z","shell.execute_reply.started":"2021-08-24T03:15:58.361487Z","shell.execute_reply":"2021-08-24T03:15:58.372176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The third feature with missing values is rez_esc\n# It represents the years behind in school the individual has\n# The most plausible hypothesis is that the NaN values represents individuals that are not behind in school\n\ntrain.loc[train['rez_esc'].notnull()]['age'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:58.375739Z","iopub.execute_input":"2021-08-24T03:15:58.376492Z","iopub.status.idle":"2021-08-24T03:15:58.394775Z","shell.execute_reply.started":"2021-08-24T03:15:58.376415Z","shell.execute_reply":"2021-08-24T03:15:58.393263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[train['rez_esc'].isnull()]['age'].describe()\n\n# The competition describes the rez_esc feature only taking in consideration people between the ages 7-19\n# Anything under 7 or over 19 will be assumed to have no years behind in school","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:58.396654Z","iopub.execute_input":"2021-08-24T03:15:58.397071Z","iopub.status.idle":"2021-08-24T03:15:58.414093Z","shell.execute_reply.started":"2021-08-24T03:15:58.397029Z","shell.execute_reply":"2021-08-24T03:15:58.413007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[((train['age'] > 19) | (train['age'] < 7)) & (train['rez_esc'].isnull()), 'rez_esc'] = 0\ntest.loc[((test['age'] > 19) | (test['age'] < 7)) & (test['rez_esc'].isnull()), 'rez_esc'] = 0\n\n# For those in the 7 to 19 range and still have missing value, it makes sense to imput with 0 as well\n# But its good practice to create the imputed flag column, to flag our assumption\n\ntrain['rez_esc-missing'] = train['rez_esc'].isnull()\ntest['rez_esc-missing'] = test['rez_esc'].isnull()\n\n# Now that the flag column has been created, we can finish filling all the missing values\n\ntrain['rez_esc'].fillna(0, inplace=True)\ntest['rez_esc'].fillna(0, inplace=True)\n\n# The competition also describes as the maximum years behind school is 5. So anything over it will be considered an outlier\n\ntrain.loc[train['rez_esc'] > 5, 'rez_esc'] = 5\ntest.loc[test['rez_esc'] > 5, 'rez_esc'] = 5","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:58.415412Z","iopub.execute_input":"2021-08-24T03:15:58.41607Z","iopub.status.idle":"2021-08-24T03:15:58.434657Z","shell.execute_reply.started":"2021-08-24T03:15:58.416024Z","shell.execute_reply":"2021-08-24T03:15:58.433741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_nan = train.isna().sum()\nprint(cols_nan.where(cols_nan > 0).dropna().astype('int32'))\n\n# Now all thats left is meaneduc and SQBmeaned\n# meaneduc shows the average years of education on adults (18+)\n# SQBmeaned shows the square of the mean years of education of adults (18+) in the household","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:58.436409Z","iopub.execute_input":"2021-08-24T03:15:58.436906Z","iopub.status.idle":"2021-08-24T03:15:58.458108Z","shell.execute_reply.started":"2021-08-24T03:15:58.436861Z","shell.execute_reply":"2021-08-24T03:15:58.457256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First lets check if the NaN values in both columns correspond to the same indexes\n\nnan_index = train[train['meaneduc'].isna()].index\nprint(nan_index)\nprint(train[train['SQBmeaned'].isna()].index)\n\n# Same indexes, so they refer to the same individuals\n\nhouse_with_nan = train.loc[train['meaneduc'].isnull(), 'idhogar'].value_counts()\n\nprint('-'*25)\nprint(house_with_nan)\n\nprint('-'*25)\nprint(train.loc[train['idhogar'].isin(house_with_nan.index), ['age']])\n\n# All individuals with null values are 18 or 19 years old\n# They are the only individuals in the household\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:58.459513Z","iopub.execute_input":"2021-08-24T03:15:58.460138Z","iopub.status.idle":"2021-08-24T03:15:58.480618Z","shell.execute_reply.started":"2021-08-24T03:15:58.460091Z","shell.execute_reply":"2021-08-24T03:15:58.479529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the level of education of these 5 individuals\n\nedu_series = train.columns.to_series().str.contains('instlevel')\nedu_var = edu_series.where(edu_series != False).dropna().index.to_list()\n\ntrain.loc[train['meaneduc'].isnull(), edu_var].sum().plot.bar(figsize = (7, 5))\nplt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8],\n           ['No Education', 'Incomplete Primary', 'Complete Primary', 'Incomplete Second Level', 'Complete Second Level', 'Incomplete Technical Level', 'Complete Technical Level', 'Undergraduated and Higher', 'Postgraduate and Higher'],\n          rotation = 60)\nplt.title('Level of education of individuals with NaN meaneduc value', size = 15);\n\n# So we have a variety of education levels to these 5 individuals","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:58.482027Z","iopub.execute_input":"2021-08-24T03:15:58.482678Z","iopub.status.idle":"2021-08-24T03:15:59.136548Z","shell.execute_reply.started":"2021-08-24T03:15:58.48263Z","shell.execute_reply":"2021-08-24T03:15:59.135177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For each of them, we'll impute the median value for that specific education level\n\ndef impute_median(index, df):\n    \n    df_t = (df.loc[df.index == index, edu_var]).transpose()\n    instlevel = df_t[df_t == 1].dropna().index.values\n    \n    \n    mdmed = df.loc[df[instlevel[0]] == 1, 'meaneduc'].median()\n    sqmed = df.loc[df[instlevel[0]] == 1, 'SQBmeaned'].median()\n        \n    df.loc[df.index == index, 'meaneduc'] = mdmed\n    df.loc[df.index == index, 'SQBmeaned'] = sqmed","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:59.138402Z","iopub.execute_input":"2021-08-24T03:15:59.138895Z","iopub.status.idle":"2021-08-24T03:15:59.1473Z","shell.execute_reply.started":"2021-08-24T03:15:59.138848Z","shell.execute_reply":"2021-08-24T03:15:59.145967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for df in [train, test]: \n    nan_index = df[df['meaneduc'].isna()].index\n    for j in nan_index:\n        impute_median(j, df)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:59.148535Z","iopub.execute_input":"2021-08-24T03:15:59.148859Z","iopub.status.idle":"2021-08-24T03:15:59.458596Z","shell.execute_reply.started":"2021-08-24T03:15:59.148828Z","shell.execute_reply":"2021-08-24T03:15:59.457712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_nan = train.isna().sum()\nprint(cols_nan.where(cols_nan > 0).dropna().astype('int32'))\n\n# All NaN values in the dataset has been dealt with","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:59.459739Z","iopub.execute_input":"2021-08-24T03:15:59.460171Z","iopub.status.idle":"2021-08-24T03:15:59.475738Z","shell.execute_reply.started":"2021-08-24T03:15:59.460141Z","shell.execute_reply":"2021-08-24T03:15:59.474828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In the dataframe, each column represents one individual. The predictions must be made based on households\n# Each individual has its household identified by the idhogar column, and the head of the household is identified as parentesco1 = 1\n# Every individual in a same household must share the same Target feature in the train database, since its household based\n\ncheck_target = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\nprint(check_target)\nprint('-'*25)\ndif_target = check_target[check_target != True] \nprint(len(dif_target))\nprint('-'*25)\nprint(train['parentesco1'].sum())\nprint('-'*25)\nprint(train.groupby('idhogar')['parentesco1'].apply(lambda x: x.sum() > 1).sum())\n# There are 2988 total households in the dataset\n# 85 of these households have more than 1 target value for the residents\n# There are 2988 different households and 2973 heads, so we have 15 households without a household head\n# There are no household with multiple heads","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:15:59.476836Z","iopub.execute_input":"2021-08-24T03:15:59.477265Z","iopub.status.idle":"2021-08-24T03:16:00.329988Z","shell.execute_reply.started":"2021-08-24T03:15:59.477236Z","shell.execute_reply":"2021-08-24T03:16:00.329142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One way to deal with the multiple targets per idhogar is to assign the household head value to all others\n# But in order to do that, we must make sure there aren't households with both multiple target values and no household head\n\nhouse_has_head = train.groupby('idhogar')['parentesco1'].apply(lambda x: x.sum() == 1)\nhouse_no_head = house_has_head[house_has_head == 0]\ntrain_no_head = train.loc[train['idhogar'].isin(house_no_head.index)]\ndif_no_head = train_no_head.groupby('idhogar')['Target'].apply(lambda x: x.nunique() > 1).sum()\nprint(dif_no_head)\n\n# This proves there are no households without head and with multiple targets\n# So we can apply the previous solution","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:00.334193Z","iopub.execute_input":"2021-08-24T03:16:00.334725Z","iopub.status.idle":"2021-08-24T03:16:00.591823Z","shell.execute_reply.started":"2021-08-24T03:16:00.33469Z","shell.execute_reply":"2021-08-24T03:16:00.5908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.loc[train['idhogar'] == '0172ab1d9']['Target'])\n\nfor household in dif_target.index:\n    true_target = int(train[(train['idhogar'] == household) & (train['parentesco1'] == 1)]['Target'])\n    train.loc[train['idhogar'] == household, 'Target'] = true_target\n\n    \ncheck_target = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\ndif_target = check_target[check_target != True]\n\nprint(train.loc[train['idhogar'] == '0172ab1d9']['Target'])\n\n# Correction has been made, now all residents of a same household has the same target value","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:00.594724Z","iopub.execute_input":"2021-08-24T03:16:00.595351Z","iopub.status.idle":"2021-08-24T03:16:01.676765Z","shell.execute_reply.started":"2021-08-24T03:16:00.595299Z","shell.execute_reply":"2021-08-24T03:16:01.675517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now that all the missing values have been dealt with, and some corrections made, lets further investigate our features\n# Lets try to group the overly correlated features, first by analysing their definition\n\n# tipovivi1 - tipovivi5 (own a house or not) and v2a1 (rent payed)\n# hacdor, hacapo, overcrowding, SQBovercrowding (whether the house is overcrowded or not)\n# rooms, v14a, tamhog, hhsize, pared^, piso^, techo^, cielorazo, sanitario1-6, energcocinar1-6, epared1-3, etecho1-3, eviv1-3, bedrooms, area1-2 are related to house characteristics\n# r4h1-3, r4m1-3, r4t1-3, tamviv, dis, male, female, hogar_nin, hogar_adul, hogar_mayor, hogar_total, dependency, SQBhogar_total, SQBhogar_nin, age, agesq, estadocivil1-7, parentesco1-12 are related to number of persons in the house\n# refrig, v18q, v18q1, sanitario1-6, computer, television, mobilephone, qmobilephone related to things that are in the house\n# abastagua^, public, planpri, noelec, coopele, elimbasu1-6, lugar1-6, related to structure outside the house\n# escolari, rez_esc, edjefe, edjefa, instlevel1-9, meaneduc, SQBescolari, SQBedjefe, SQBmeaned, related to education levels","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:01.678216Z","iopub.execute_input":"2021-08-24T03:16:01.678622Z","iopub.status.idle":"2021-08-24T03:16:01.683149Z","shell.execute_reply.started":"2021-08-24T03:16:01.67859Z","shell.execute_reply":"2021-08-24T03:16:01.681813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are a series of squared feature columns\n# These can be useful when using a simple linear model, but to more complex models, it tends to be prejudicial by making the model overfit\n# So these features will be dropped\n\nsqbcol = ['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq']\ntrain = train.drop(sqbcol, axis=1)\ntest = test.drop(sqbcol, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:01.684732Z","iopub.execute_input":"2021-08-24T03:16:01.685038Z","iopub.status.idle":"2021-08-24T03:16:01.719292Z","shell.execute_reply.started":"2021-08-24T03:16:01.685008Z","shell.execute_reply":"2021-08-24T03:16:01.718126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are many columns that are one hot encoded features, and others that are clearly correlated\n# For the hot one encoded, we'll try to create a single ordinal column, when we can define a clear order for the values\n# We'll also focus on features house related, since the resident related must be aggregated into house related as well\n\ndef mc(dic, colname):\n    for df in [train, test]:\n        for i in dic:\n            df.loc[df[i] == 1, colname] = dic[i]","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:01.720543Z","iopub.execute_input":"2021-08-24T03:16:01.721022Z","iopub.status.idle":"2021-08-24T03:16:01.725989Z","shell.execute_reply.started":"2021-08-24T03:16:01.720985Z","shell.execute_reply":"2021-08-24T03:16:01.724931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First lets join the wall type columns\n\ntrain['walltype'] = 0\ntest['walltype'] = 0\n\nwall_dt = {\n    'paredother': 1,\n    'pareddes': 1,\n    'paredfibras': 1,\n    'paredzinc': 2,\n    'paredzocalo': 3,\n    'paredmad': 4,\n    'paredpreb': 5,\n    'paredblolad': 6    \n}\n\nmc(wall_dt, 'walltype')\n\nfor i in wall_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)\n    \n# The number of entries that matches pareddes, paredfibras, paredzinc and other are too few\n# Since all of them represent low quality wall, to avoid overfitting they will be joined in a single category","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:01.727399Z","iopub.execute_input":"2021-08-24T03:16:01.727843Z","iopub.status.idle":"2021-08-24T03:16:01.87912Z","shell.execute_reply.started":"2021-08-24T03:16:01.727809Z","shell.execute_reply":"2021-08-24T03:16:01.878138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wall Quality\n\ntrain['wallquality'] = 0\ntest['wallquality'] = 0\n\nwallq_dt = {\n    'epared1': 1,\n    'epared2': 2,\n    'epared3': 3,  \n}\n\nmc(wallq_dt, 'wallquality')\n\nfor i in wallq_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:01.880517Z","iopub.execute_input":"2021-08-24T03:16:01.880825Z","iopub.status.idle":"2021-08-24T03:16:01.945667Z","shell.execute_reply.started":"2021-08-24T03:16:01.880797Z","shell.execute_reply":"2021-08-24T03:16:01.944766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now for the floor type columns\n\ntrain['floortype'] = 0\ntest['floortype'] = 0\n\nfloor_dt = {\n    'pisonotiene': 1,\n    'pisoother': 2,\n    'pisonatur': 2,\n    'pisocemento': 3,\n    'pisomadera': 4,\n    'pisomoscer': 5,  \n}\n\nmc(floor_dt, 'floortype')\n\nfor i in floor_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)\n    \n# The number of entries that matches pisoother, pisonatur and pisonotiene are too few\n# Since all of them represent low quality floor, to avoid overfitting they will be joined in a single category","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:01.947209Z","iopub.execute_input":"2021-08-24T03:16:01.947921Z","iopub.status.idle":"2021-08-24T03:16:02.053879Z","shell.execute_reply.started":"2021-08-24T03:16:01.947875Z","shell.execute_reply":"2021-08-24T03:16:02.052766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Floor Quality\n\ntrain['floorqual'] = 0\ntest['floorqual'] = 0\n\nfloorq_dt = {\n    'eviv1': 1,\n    'eviv2': 2,\n    'eviv3': 3 \n}\n\nmc(floorq_dt, 'floorqual')\n\nfor i in floorq_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.055512Z","iopub.execute_input":"2021-08-24T03:16:02.055941Z","iopub.status.idle":"2021-08-24T03:16:02.122102Z","shell.execute_reply.started":"2021-08-24T03:16:02.055896Z","shell.execute_reply":"2021-08-24T03:16:02.121028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now for the roof\n\n# cielorazo gives 1 if a house HAS a roof. We want a column that is True when it DOES NOT\n\ntrain['nothaveroof'] = 0\ntrain.loc[train['cielorazo'] == 0, 'nothaveroof'] = 1\ntrain = train.drop('cielorazo', axis=1)\n\ntest['nothaveroof'] = 0\ntest.loc[test['cielorazo'] == 0, 'nothaveroof'] = 1\ntest = test.drop('cielorazo', axis=1)\n\n\ntrain['rooftype'] = 0\ntest['rooftype'] = 0\n\nroof_dt = {\n    'nothaveroof': 1,\n    'techootro': 2,\n    'techocane': 2,\n    'techoentrepiso': 3,\n    'techozinc': 4\n}\n\nmc(roof_dt, 'rooftype')\n\nfor i in roof_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)\n\n# The number of entries that matches techootro and techocane are too few\n# Since all of them represent low quality ceiling, to avoid overfitting they will be joined in a single category","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.123817Z","iopub.execute_input":"2021-08-24T03:16:02.12424Z","iopub.status.idle":"2021-08-24T03:16:02.240681Z","shell.execute_reply.started":"2021-08-24T03:16:02.124195Z","shell.execute_reply":"2021-08-24T03:16:02.239632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Roof quality\n\ntrain['roofqual'] = 0\ntest['roofqual'] = 0\n\nroofq_dt = {\n    'etecho1': 1,\n    'etecho2': 2,\n    'etecho3': 3,\n}\n\nmc(roofq_dt, 'roofqual')\n\nfor i in roofq_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.24191Z","iopub.execute_input":"2021-08-24T03:16:02.24223Z","iopub.status.idle":"2021-08-24T03:16:02.30395Z","shell.execute_reply.started":"2021-08-24T03:16:02.242199Z","shell.execute_reply":"2021-08-24T03:16:02.302928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now for water provision\n\ntrain['waterprov'] = 0\ntest['waterprov'] = 0\n\nwater_dt = {\n    'abastaguano' : 1,\n    'abastaguafuera' : 2,\n    'abastaguadentro' : 3\n}\n  \nmc(water_dt, 'waterprov')\n\nfor i in water_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.307624Z","iopub.execute_input":"2021-08-24T03:16:02.307948Z","iopub.status.idle":"2021-08-24T03:16:02.368779Z","shell.execute_reply.started":"2021-08-24T03:16:02.30792Z","shell.execute_reply":"2021-08-24T03:16:02.367729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Electricity Source\n\ntrain['elecsource'] = 0\ntest['elecsource'] = 0\n\nelec_dt = {\n    'noelec' : 1,\n    'planpri' : 2,\n    'coopele' : 2,\n    'public' : 3,\n}\n  \nmc(elec_dt, 'elecsource')\n\nfor i in elec_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.370556Z","iopub.execute_input":"2021-08-24T03:16:02.370982Z","iopub.status.idle":"2021-08-24T03:16:02.44425Z","shell.execute_reply.started":"2021-08-24T03:16:02.370934Z","shell.execute_reply":"2021-08-24T03:16:02.443179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Toilet Dwelling\n\ntrain['toiletdwel'] = 0\ntest['toiletdwel'] = 0\n\ntoilet_dt = {\n    'sanitario1' : 1,\n    'sanitario5' : 2,\n    'sanitario6' : 3,\n    'sanitario3' : 3,\n    'sanitario2' : 4\n}\n  \nmc(toilet_dt, 'toiletdwel')\n\nfor i in toilet_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.445604Z","iopub.execute_input":"2021-08-24T03:16:02.445924Z","iopub.status.idle":"2021-08-24T03:16:02.525441Z","shell.execute_reply.started":"2021-08-24T03:16:02.445894Z","shell.execute_reply":"2021-08-24T03:16:02.524358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cooking Energy Source\n\ntrain['cookingsource'] = 0\ntest['cookingsource'] = 0\n\ncook_dt = {\n    'energcocinar1' : 1,\n    'energcocinar4' : 2,\n    'energcocinar3' : 3,\n    'energcocinar2' : 4,\n}\n  \nmc(cook_dt, 'cookingsource')\n\nfor i in cook_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.527072Z","iopub.execute_input":"2021-08-24T03:16:02.527377Z","iopub.status.idle":"2021-08-24T03:16:02.593531Z","shell.execute_reply.started":"2021-08-24T03:16:02.527348Z","shell.execute_reply":"2021-08-24T03:16:02.59258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rubbish Disposal\n\ntrain['rubbishdisp'] = 0\ntest['rubbishdisp'] = 0\n\nrubbish_dt = {\n    'elimbasu6' : 1,\n    'elimbasu5' : 2,\n    'elimbasu4' : 1,\n    'elimbasu3' : 3,\n    'elimbasu2' : 1,\n    'elimbasu1' : 4\n}\n  \nmc(rubbish_dt, 'rubbishdisp')\n\nfor i in rubbish_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.594869Z","iopub.execute_input":"2021-08-24T03:16:02.595154Z","iopub.status.idle":"2021-08-24T03:16:02.684055Z","shell.execute_reply.started":"2021-08-24T03:16:02.595128Z","shell.execute_reply":"2021-08-24T03:16:02.682914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Own House Status\n\n# This feature will be divided into owned or not, and the precarious feature will remain as a separated one\n\ntrain = train.rename(columns = {'tipovivi4': 'isprecarious'})\ntest = test.rename(columns = {'tipovivi4': 'isprecarious'})\n\n                     \ntrain['houseowned'] = 0\ntest['houseowned'] = 0\n\nhouseown_dt = {\n    'tipovivi5' : 0,\n    'tipovivi3' : 0,\n    'tipovivi2' : 1,\n    'tipovivi1' : 1,\n}\n  \nmc(houseown_dt, 'houseowned')\n\nfor i in houseown_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.685507Z","iopub.execute_input":"2021-08-24T03:16:02.685843Z","iopub.status.idle":"2021-08-24T03:16:02.759644Z","shell.execute_reply.started":"2021-08-24T03:16:02.685812Z","shell.execute_reply":"2021-08-24T03:16:02.758609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Location\n\ntrain['region'] = 0\ntest['region'] = 0\n\nregion_dt = {\n    'lugar1' : 1,\n    'lugar2' : 2,\n    'lugar3' : 3,\n    'lugar4' : 4,\n    'lugar5' : 5,\n    'lugar6' : 6\n}\n  \nmc(region_dt, 'region')\n\nfor i in region_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.762757Z","iopub.execute_input":"2021-08-24T03:16:02.763256Z","iopub.status.idle":"2021-08-24T03:16:02.849593Z","shell.execute_reply.started":"2021-08-24T03:16:02.763208Z","shell.execute_reply":"2021-08-24T03:16:02.848534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing reduntant area column\n\ntrain = train.rename(columns = {'area1': 'isurban'})\ntest = test.rename(columns = {'area1': 'isurban'})\n\ntrain = train.drop('area2', axis=1)\ntest = test.drop('area2', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.853194Z","iopub.execute_input":"2021-08-24T03:16:02.853539Z","iopub.status.idle":"2021-08-24T03:16:02.875752Z","shell.execute_reply.started":"2021-08-24T03:16:02.853501Z","shell.execute_reply":"2021-08-24T03:16:02.874655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.877036Z","iopub.execute_input":"2021-08-24T03:16:02.877315Z","iopub.status.idle":"2021-08-24T03:16:02.93371Z","shell.execute_reply.started":"2021-08-24T03:16:02.877288Z","shell.execute_reply":"2021-08-24T03:16:02.932649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['dependency', 'edjefe', 'edjefa']].head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.93534Z","iopub.execute_input":"2021-08-24T03:16:02.935728Z","iopub.status.idle":"2021-08-24T03:16:02.950845Z","shell.execute_reply.started":"2021-08-24T03:16:02.935695Z","shell.execute_reply":"2021-08-24T03:16:02.949874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain['dependency'].value_counts()\n\n# The dependency column seems really weird\n# The challenge describes dependency as (number of residents 19< y.o. or >64 y.o.) / (number of residents between 19 and 64 y.o\n# Therefore it doesnt make sense to be 'yes' or 'no' values in this column\n# Luckly we have the age of each resident in the database, so we can recalculate this column\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.952035Z","iopub.execute_input":"2021-08-24T03:16:02.952321Z","iopub.status.idle":"2021-08-24T03:16:02.963913Z","shell.execute_reply.started":"2021-08-24T03:16:02.952293Z","shell.execute_reply":"2021-08-24T03:16:02.962909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['n_depend'] = 0\ntrain['n_indep'] = 0\n\nn_dep = train[['age', 'idhogar']].loc[(train['age'] < 19) | (train['age'] > 64)].groupby('idhogar').count()\nn_ind = train[['age', 'idhogar']].loc[(train['age'] >= 19) & (train['age'] <= 64)].groupby('idhogar').count()\n\n\nfor i in n_dep.index:\n    train.loc[train['idhogar'] == i, 'n_depend'] = int(n_dep.loc[n_dep.index == i, 'age'].values)\n    \nfor i in n_ind.index:\n    train.loc[train['idhogar'] == i, 'n_indep'] = int(n_ind.loc[n_ind.index == i, 'age'].values)\n        \ntrain['dependencynew'] = train['n_depend']/train['n_indep']\ntrain.loc[train['dependencynew'] == np.inf, 'dependencynew'] = 10\n\ntrain[['idhogar', 'n_depend', 'n_indep', 'age']].head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:02.965292Z","iopub.execute_input":"2021-08-24T03:16:02.965673Z","iopub.status.idle":"2021-08-24T03:16:16.735404Z","shell.execute_reply.started":"2021-08-24T03:16:02.965625Z","shell.execute_reply":"2021-08-24T03:16:16.734217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(['n_depend', 'n_indep', 'dependency'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:16.736928Z","iopub.execute_input":"2021-08-24T03:16:16.737242Z","iopub.status.idle":"2021-08-24T03:16:16.745532Z","shell.execute_reply.started":"2021-08-24T03:16:16.737213Z","shell.execute_reply":"2021-08-24T03:16:16.744254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['n_depend'] = 0\ntest['n_indep'] = 0\n\nn_dep = test[['age', 'idhogar']].loc[(test['age'] < 19) | (test['age'] > 64)].groupby('idhogar').count()\nn_ind = test[['age', 'idhogar']].loc[(test['age'] >= 19) & (test['age'] <= 64)].groupby('idhogar').count()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:16.747069Z","iopub.execute_input":"2021-08-24T03:16:16.747524Z","iopub.status.idle":"2021-08-24T03:16:16.798046Z","shell.execute_reply.started":"2021-08-24T03:16:16.747476Z","shell.execute_reply":"2021-08-24T03:16:16.797018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in n_dep.index:\n    test.loc[test['idhogar'] == i, 'n_depend'] = int(n_dep.loc[n_dep.index == i, 'age'].values)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:16.799651Z","iopub.execute_input":"2021-08-24T03:16:16.800077Z","iopub.status.idle":"2021-08-24T03:16:47.767233Z","shell.execute_reply.started":"2021-08-24T03:16:16.800034Z","shell.execute_reply":"2021-08-24T03:16:47.766029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in n_ind.index:\n    test.loc[test['idhogar'] == i, 'n_indep'] = int(n_ind.loc[n_ind.index == i, 'age'].values)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:16:47.768725Z","iopub.execute_input":"2021-08-24T03:16:47.769031Z","iopub.status.idle":"2021-08-24T03:17:29.065359Z","shell.execute_reply.started":"2021-08-24T03:16:47.769002Z","shell.execute_reply":"2021-08-24T03:17:29.064218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['dependencynew'] = test['n_depend']/test['n_indep']\ntest.loc[test['dependencynew'] == np.inf, 'dependencynew'] = 10\n\ntest[['idhogar', 'n_depend', 'n_indep', 'age']].head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.067396Z","iopub.execute_input":"2021-08-24T03:17:29.067851Z","iopub.status.idle":"2021-08-24T03:17:29.088347Z","shell.execute_reply.started":"2021-08-24T03:17:29.067804Z","shell.execute_reply":"2021-08-24T03:17:29.087215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.drop(['n_depend', 'n_indep', 'dependency'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.089725Z","iopub.execute_input":"2021-08-24T03:17:29.090027Z","iopub.status.idle":"2021-08-24T03:17:29.102049Z","shell.execute_reply.started":"2021-08-24T03:17:29.089998Z","shell.execute_reply":"2021-08-24T03:17:29.101021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['edjefe', 'edjefa']].value_counts()\n\n# edjefe and edjefa seem to have the same weird problem, with both columns\n# We'll remake these two columns as well\n# They will be converted into one","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.10352Z","iopub.execute_input":"2021-08-24T03:17:29.103908Z","iopub.status.idle":"2021-08-24T03:17:29.127722Z","shell.execute_reply.started":"2021-08-24T03:17:29.103875Z","shell.execute_reply":"2021-08-24T03:17:29.126642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['headescolari'] = 0\ntest['headescolari'] = 0\n\ntrain.loc[train['parentesco1'] == 1, 'headescolari'] = train['escolari']\ntest.loc[test['parentesco1'] == 1, 'headescolari'] = test['escolari']\n\ntrain = train.drop(['edjefe', 'edjefa'], axis=1)\ntest = test.drop(['edjefe', 'edjefa'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.128917Z","iopub.execute_input":"2021-08-24T03:17:29.129192Z","iopub.status.idle":"2021-08-24T03:17:29.161988Z","shell.execute_reply.started":"2021-08-24T03:17:29.129165Z","shell.execute_reply":"2021-08-24T03:17:29.160753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.163571Z","iopub.execute_input":"2021-08-24T03:17:29.163879Z","iopub.status.idle":"2021-08-24T03:17:29.174852Z","shell.execute_reply.started":"2021-08-24T03:17:29.163851Z","shell.execute_reply":"2021-08-24T03:17:29.173742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We converted into ordinal all columns household related where the trend was clear\n# Now lets do the same for columns in individual level\n\n# The variables r4 shows a clear correlation and redundancy others\n# Sex and Age are already given by different columns\n# A column showing whether someone is under or over 12 could be useful though\n# So all columns will be dropped except r4t1 and r4t3\n\ndrop_cols = ['r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t2']\ntrain = train.drop(drop_cols, axis=1)\ntest = test.drop(drop_cols, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.176432Z","iopub.execute_input":"2021-08-24T03:17:29.176905Z","iopub.status.idle":"2021-08-24T03:17:29.197014Z","shell.execute_reply.started":"2021-08-24T03:17:29.176869Z","shell.execute_reply":"2021-08-24T03:17:29.195875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Civil State\n\ntrain['civilstate'] = 0\ntest['civilstate'] = 0\n\ncivil_dt = {\n    'estadocivil1' : 1,\n    'estadocivil2' : 3,\n    'estadocivil3' : 4,\n    'estadocivil4' : 5,\n    'estadocivil5' : 5,\n    'estadocivil6' : 6,\n    'estadocivil7' : 2\n}\n  \nmc(civil_dt, 'civilstate')\n\nfor i in civil_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.198544Z","iopub.execute_input":"2021-08-24T03:17:29.198843Z","iopub.status.idle":"2021-08-24T03:17:29.283023Z","shell.execute_reply.started":"2021-08-24T03:17:29.198815Z","shell.execute_reply":"2021-08-24T03:17:29.282022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['civilstate'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.284333Z","iopub.execute_input":"2021-08-24T03:17:29.284671Z","iopub.status.idle":"2021-08-24T03:17:29.294738Z","shell.execute_reply.started":"2021-08-24T03:17:29.284639Z","shell.execute_reply":"2021-08-24T03:17:29.293594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We'll drop all the columns of kinship besides parentesco1, since they are individual features without huge relevance\n\ndrop_cols = ['parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12']\n\ntrain = train.drop(drop_cols, axis=1)\ntest = test.drop(drop_cols, axis=1)\n\ntrain = train.rename(columns = {'parentesco1': 'ishousehead'})\ntest = test.rename(columns = {'parentesco1': 'ishousehead'})","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.295917Z","iopub.execute_input":"2021-08-24T03:17:29.296244Z","iopub.status.idle":"2021-08-24T03:17:29.322626Z","shell.execute_reply.started":"2021-08-24T03:17:29.296207Z","shell.execute_reply":"2021-08-24T03:17:29.321388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Individual education\n\ntrain['education'] = 0\ntest['education'] = 0\n\neduc_dt = {\n    'instlevel1' : 1,\n    'instlevel2' : 2,\n    'instlevel3' : 3,\n    'instlevel4' : 4,\n    'instlevel5' : 5,\n    'instlevel6' : 6,\n    'instlevel7' : 7,\n    'instlevel8' : 8,\n    'instlevel9' : 9\n}\n  \nmc(educ_dt, 'education')\n\nfor i in educ_dt:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.324287Z","iopub.execute_input":"2021-08-24T03:17:29.324647Z","iopub.status.idle":"2021-08-24T03:17:29.420126Z","shell.execute_reply.started":"2021-08-24T03:17:29.324606Z","shell.execute_reply":"2021-08-24T03:17:29.419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['education'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.421265Z","iopub.execute_input":"2021-08-24T03:17:29.421593Z","iopub.status.idle":"2021-08-24T03:17:29.430599Z","shell.execute_reply.started":"2021-08-24T03:17:29.421565Z","shell.execute_reply":"2021-08-24T03:17:29.429349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[train['education'] == 0, 'education'] = 1","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.431992Z","iopub.execute_input":"2021-08-24T03:17:29.432307Z","iopub.status.idle":"2021-08-24T03:17:29.44769Z","shell.execute_reply.started":"2021-08-24T03:17:29.432279Z","shell.execute_reply":"2021-08-24T03:17:29.44636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.449091Z","iopub.execute_input":"2021-08-24T03:17:29.449404Z","iopub.status.idle":"2021-08-24T03:17:29.465111Z","shell.execute_reply.started":"2021-08-24T03:17:29.449374Z","shell.execute_reply":"2021-08-24T03:17:29.463947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are a few columns related to electronics the household has\n# Lets try to aggregate these columns in order to increase their correlation with target\n\n# refrig, v18q, v18q1, computer, television, mobilephone, qmobilephone\n# Its expected to be a linear correlation","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.466558Z","iopub.execute_input":"2021-08-24T03:17:29.467158Z","iopub.status.idle":"2021-08-24T03:17:29.483924Z","shell.execute_reply.started":"2021-08-24T03:17:29.467118Z","shell.execute_reply":"2021-08-24T03:17:29.482735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_frac(col_plot, x_vals, x_label, gtype):\n    \n    # Creates the dataframe that will be filled with values to be plotted\n    df_plot = pd.DataFrame()\n    \n    # Defines range used in the for loop\n    loop_range = x_vals\n    \n    # Loop that fills the df_plot\n    for i in loop_range:\n        temp_train = train[train[col_plot] == i]\n        temp_val = temp_train.groupby(['Target']).count()[col_plot]/temp_train[col_plot].count()\n        df_plot = df_plot.append(temp_val)\n    df_plot.set_index(np.array(range(len(loop_range))), inplace=True)\n    df_plot.fillna(0, inplace=True)\n    df_plot = df_plot.rename(columns = {1:'ExtermePoverty', 2:'ModeratePoverty', 3:'Vulnerable', 4:'NonVulnerable'})\n\n    # Creating aliases to reduce the length of code\n    ds1d, ds2d, ds3d, ds4d = df_plot['ExtermePoverty'], df_plot['ModeratePoverty'], df_plot['Vulnerable'], df_plot['NonVulnerable']\n    \n    fig, ax = plt.subplots()\n    # Creating each of the bars, passing the the bottom parameter as the sum of the bars under it\n    ax.bar(df_plot.index, ds1d, label='ExtermePoverty')\n    ax.bar(df_plot.index, ds2d, label='ModeratePoverty', bottom=ds1d)\n    ax.bar(df_plot.index, ds3d, label='Vulnerable', bottom=np.array(ds1d)+np.array(ds2d))\n    ax.bar(df_plot.index, ds4d, label='NonVulnerable', bottom=np.array(ds1d)+np.array(ds2d)+np.array(ds3d))\n    ax.legend()\n    # Set the x-axis to the animal gender\n    ax.set_xticklabels(x_label)\n    ax.xaxis.set_major_locator(matplotlib.ticker.FixedLocator(range(50)))\n    plt.xticks(rotation=30)\n    plt.yticks(np.linspace(0,1,11))\n    plt.title('Target Fraction based on ' + gtype)\n    plt.ylabel('Fraction of Target')\n    plt.show()\n    return None\n\ndef calc_corrs(x, y):\n    \"\"\"Plot data and show the spearman and pearson correlation.\"\"\"\n    \n    # Calculate correlations\n    spr = spearmanr(x, y).correlation\n    pcr = np.corrcoef(x, y)[0, 1]\n    \n    print(' '*14+'Spearman: '+str(round(spr, 2))+'; Pearson: '+str(round(pcr, 2)))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.485622Z","iopub.execute_input":"2021-08-24T03:17:29.485928Z","iopub.status.idle":"2021-08-24T03:17:29.501642Z","shell.execute_reply.started":"2021-08-24T03:17:29.4859Z","shell.execute_reply":"2021-08-24T03:17:29.500617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_frac('refrig', [0,1], ['Not Have', 'Have'], 'Having Refrigerators')\n\ncalc_corrs(train['v2a1'], train['Target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.503044Z","iopub.execute_input":"2021-08-24T03:17:29.503408Z","iopub.status.idle":"2021-08-24T03:17:29.818126Z","shell.execute_reply.started":"2021-08-24T03:17:29.503363Z","shell.execute_reply":"2021-08-24T03:17:29.816994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_frac('v18q', [0,1], ['Not Have', 'Have'], 'Having Tablets')\n\ncalc_corrs(train['v18q'], train['Target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:29.819693Z","iopub.execute_input":"2021-08-24T03:17:29.820083Z","iopub.status.idle":"2021-08-24T03:17:30.113324Z","shell.execute_reply.started":"2021-08-24T03:17:29.820043Z","shell.execute_reply":"2021-08-24T03:17:30.11244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_frac('v18q1', range(0,7), range(0,7), 'Number of Tablets')\n\ncalc_corrs(train['v18q1'], train['Target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:30.114598Z","iopub.execute_input":"2021-08-24T03:17:30.115087Z","iopub.status.idle":"2021-08-24T03:17:30.513888Z","shell.execute_reply.started":"2021-08-24T03:17:30.115038Z","shell.execute_reply":"2021-08-24T03:17:30.512543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_frac('computer', [0,1], ['Not Have', 'Have'], 'Having Computer')\n\ncalc_corrs(train['computer'], train['Target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:30.521507Z","iopub.execute_input":"2021-08-24T03:17:30.521872Z","iopub.status.idle":"2021-08-24T03:17:30.8232Z","shell.execute_reply.started":"2021-08-24T03:17:30.521843Z","shell.execute_reply":"2021-08-24T03:17:30.822034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_frac('television', [0,1], ['Not Have', 'Have'], 'Having Television')\n\ncalc_corrs(train['television'], train['Target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:30.825706Z","iopub.execute_input":"2021-08-24T03:17:30.826028Z","iopub.status.idle":"2021-08-24T03:17:31.132917Z","shell.execute_reply.started":"2021-08-24T03:17:30.825996Z","shell.execute_reply":"2021-08-24T03:17:31.131603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_frac('mobilephone', [0,1], ['Not Have', 'Have'], 'Having Mobile Phone')\n\ncalc_corrs(train['mobilephone'], train['Target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:31.134329Z","iopub.execute_input":"2021-08-24T03:17:31.134657Z","iopub.status.idle":"2021-08-24T03:17:31.43639Z","shell.execute_reply.started":"2021-08-24T03:17:31.134628Z","shell.execute_reply":"2021-08-24T03:17:31.435112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_frac('qmobilephone', range(0,11), range(0,11), 'Number of Mobile Phones')\n\ncalc_corrs(train['qmobilephone'], train['Target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:31.437952Z","iopub.execute_input":"2021-08-24T03:17:31.43832Z","iopub.status.idle":"2021-08-24T03:17:31.919882Z","shell.execute_reply.started":"2021-08-24T03:17:31.438287Z","shell.execute_reply":"2021-08-24T03:17:31.918814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It seems that Having a Tablet, a Computer, Number of Tablets and of Mobile Phones are the variables with higher correlation with Target\n# Lets try aggregating the number of computers, tablets and mobile phones into a new feature and see if it represents a higher correlation\n\ntrain['sumelectronics'] = train[['qmobilephone', 'v18q1', 'computer']].apply(np.sum, axis=1)\ntest['sumelectronics'] = test[['qmobilephone', 'v18q1', 'computer']].apply(np.sum, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:31.921297Z","iopub.execute_input":"2021-08-24T03:17:31.921787Z","iopub.status.idle":"2021-08-24T03:17:34.828169Z","shell.execute_reply.started":"2021-08-24T03:17:31.921752Z","shell.execute_reply":"2021-08-24T03:17:34.826989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_frac('sumelectronics', range(0,15), range(0,15), 'Number of Electronics')\n\ncalc_corrs(train['sumelectronics'], train['Target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:34.829875Z","iopub.execute_input":"2021-08-24T03:17:34.830186Z","iopub.status.idle":"2021-08-24T03:17:35.372773Z","shell.execute_reply.started":"2021-08-24T03:17:34.830158Z","shell.execute_reply":"2021-08-24T03:17:35.371447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We managed to create a feature with higher correlation than the others separately, so this feature will substitute the others\n\ndrop_cols = ['refrig', 'v18q', 'v18q1', 'computer', 'television', 'mobilephone', 'qmobilephone']\n\ntrain = train.drop(drop_cols, axis=1)\ntest = test.drop(drop_cols, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.374323Z","iopub.execute_input":"2021-08-24T03:17:35.374784Z","iopub.status.idle":"2021-08-24T03:17:35.389234Z","shell.execute_reply.started":"2021-08-24T03:17:35.374749Z","shell.execute_reply":"2021-08-24T03:17:35.387957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.390758Z","iopub.execute_input":"2021-08-24T03:17:35.39118Z","iopub.status.idle":"2021-08-24T03:17:35.399903Z","shell.execute_reply.started":"2021-08-24T03:17:35.391146Z","shell.execute_reply":"2021-08-24T03:17:35.398904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['tamhog', 'hhsize']]\ntrain[['tamviv', 'hogar_total']]\n\ntrain = train.drop(['hhsize', 'hogar_total'], axis=1)\ntest = test.drop(['hhsize', 'hogar_total'], axis=1)\n\n\n# Duplicated Column","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.40187Z","iopub.execute_input":"2021-08-24T03:17:35.402447Z","iopub.status.idle":"2021-08-24T03:17:35.423656Z","shell.execute_reply.started":"2021-08-24T03:17:35.402399Z","shell.execute_reply":"2021-08-24T03:17:35.422417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dependency column already makes the relation between dependent and independent individuals in the household\n# The columns indicating the number of individuals of each age will be dropped\n\ndrop_cols = ['hogar_nin', 'hogar_adul', 'hogar_mayor']\n\ntrain = train.drop(drop_cols, axis=1)\ntest = test.drop(drop_cols, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.425448Z","iopub.execute_input":"2021-08-24T03:17:35.425793Z","iopub.status.idle":"2021-08-24T03:17:35.44161Z","shell.execute_reply.started":"2021-08-24T03:17:35.425763Z","shell.execute_reply":"2021-08-24T03:17:35.440238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['hacdor', 'rooms', 'hacapo', 'tamviv', 'bedrooms', 'overcrowding']].head(20)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.443174Z","iopub.execute_input":"2021-08-24T03:17:35.443539Z","iopub.status.idle":"2021-08-24T03:17:35.469643Z","shell.execute_reply.started":"2021-08-24T03:17:35.443449Z","shell.execute_reply":"2021-08-24T03:17:35.468485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['hacapo'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.4733Z","iopub.execute_input":"2021-08-24T03:17:35.473649Z","iopub.status.idle":"2021-08-24T03:17:35.484036Z","shell.execute_reply.started":"2021-08-24T03:17:35.473619Z","shell.execute_reply":"2021-08-24T03:17:35.482674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[train['hacapo'] == 1]","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.485437Z","iopub.execute_input":"2021-08-24T03:17:35.486081Z","iopub.status.idle":"2021-08-24T03:17:35.542941Z","shell.execute_reply.started":"2021-08-24T03:17:35.486034Z","shell.execute_reply":"2021-08-24T03:17:35.541692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['overcrowding', 'hacapo', 'hacdor', 'tamviv', 'rooms', 'tamhog']]","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.54562Z","iopub.execute_input":"2021-08-24T03:17:35.546065Z","iopub.status.idle":"2021-08-24T03:17:35.568443Z","shell.execute_reply.started":"2021-08-24T03:17:35.546019Z","shell.execute_reply":"2021-08-24T03:17:35.567306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['rooms'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.571169Z","iopub.execute_input":"2021-08-24T03:17:35.571548Z","iopub.status.idle":"2021-08-24T03:17:35.580588Z","shell.execute_reply.started":"2021-08-24T03:17:35.571514Z","shell.execute_reply":"2021-08-24T03:17:35.579642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['tamhog'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.582093Z","iopub.execute_input":"2021-08-24T03:17:35.58247Z","iopub.status.idle":"2021-08-24T03:17:35.598185Z","shell.execute_reply.started":"2021-08-24T03:17:35.582425Z","shell.execute_reply":"2021-08-24T03:17:35.597189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are some columns related to the size of the house and the number of persons in the house\n# We'll aggregate all these columns in a new feature that represents the number of people/size of the house\n\novercrowd_df = train[['bedrooms', 'hacdor', 'rooms', 'hacapo', 'tamviv', 'tamhog', 'overcrowding', 'Target']]\n\ncorr_matrix = overcrowd_df.corr()\n\nfig, ax = plt.subplots(figsize=(10,8))\nsns.heatmap(corr_matrix, annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:35.599427Z","iopub.execute_input":"2021-08-24T03:17:35.59978Z","iopub.status.idle":"2021-08-24T03:17:36.257205Z","shell.execute_reply.started":"2021-08-24T03:17:35.599749Z","shell.execute_reply":"2021-08-24T03:17:36.255899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# No combination were able to create a feature with higher correlation than overcrowding\n# So it will be preserved\n# The others will be dropped\n\ncol_drops = ['bedrooms', 'hacdor', 'rooms', 'hacapo', 'tamviv', 'tamhog']\n\ntrain['overcrowding'] = train['overcrowding'].apply(lambda x: round(x, 1))\ntest['overcrowding'] = test['overcrowding'].apply(lambda x: round(x, 1))\n\ntrain = train.drop(col_drops, axis=1)\ntest = test.drop(col_drops, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:36.258584Z","iopub.execute_input":"2021-08-24T03:17:36.258992Z","iopub.status.idle":"2021-08-24T03:17:36.310547Z","shell.execute_reply.started":"2021-08-24T03:17:36.258949Z","shell.execute_reply":"2021-08-24T03:17:36.309655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:36.311905Z","iopub.execute_input":"2021-08-24T03:17:36.312569Z","iopub.status.idle":"2021-08-24T03:17:36.345721Z","shell.execute_reply.started":"2021-08-24T03:17:36.312521Z","shell.execute_reply":"2021-08-24T03:17:36.344655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will rebuild the dis column into a feature that sums the total of disable people in the house\n\ntrain['totaldisabled'] = 0\n\ntot_dis = train.groupby('idhogar')['dis'].apply(np.sum, axis=0)\n\nfor i in tot_dis.index:\n    train.loc[train['idhogar'] == i, 'totaldisabled'] = int(tot_dis.loc[tot_dis.index == i].values)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:36.347188Z","iopub.execute_input":"2021-08-24T03:17:36.34779Z","iopub.status.idle":"2021-08-24T03:17:45.276303Z","shell.execute_reply.started":"2021-08-24T03:17:36.347743Z","shell.execute_reply":"2021-08-24T03:17:45.275442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['totaldisabled', 'Target']].corr()\n\ntrain = train.drop('totaldisabled', axis=1)\n\n# The correlation is still to low to be worth keeping the columns","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:45.277599Z","iopub.execute_input":"2021-08-24T03:17:45.278209Z","iopub.status.idle":"2021-08-24T03:17:45.287732Z","shell.execute_reply.started":"2021-08-24T03:17:45.278164Z","shell.execute_reply":"2021-08-24T03:17:45.28678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We'll do the same to rez_esc\n\ntrain['totalrezesc'] = 0\n\ntot_dis = train.groupby('idhogar')['rez_esc'].apply(np.sum, axis=0)\n\nfor i in tot_dis.index:\n    train.loc[train['idhogar'] == i, 'totalrezesc'] = int(tot_dis.loc[tot_dis.index == i].values)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:45.289221Z","iopub.execute_input":"2021-08-24T03:17:45.289694Z","iopub.status.idle":"2021-08-24T03:17:54.226673Z","shell.execute_reply.started":"2021-08-24T03:17:45.289649Z","shell.execute_reply":"2021-08-24T03:17:54.225612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['totalrezesc', 'Target']].corr()\n\ntrain = train.drop('totalrezesc', axis=1)\n\n# The correlation is still to low to be worth keeping the columns","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.227886Z","iopub.execute_input":"2021-08-24T03:17:54.228161Z","iopub.status.idle":"2021-08-24T03:17:54.237727Z","shell.execute_reply.started":"2021-08-24T03:17:54.228133Z","shell.execute_reply":"2021-08-24T03:17:54.236598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.238955Z","iopub.execute_input":"2021-08-24T03:17:54.239248Z","iopub.status.idle":"2021-08-24T03:17:54.273869Z","shell.execute_reply.started":"2021-08-24T03:17:54.239221Z","shell.execute_reply":"2021-08-24T03:17:54.272574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We now will drop the last of the features individual related\n\ndrop_cols = ['escolari', 'rez_esc', 'rez_esc-missing', 'dis', 'male', 'female', 'age', 'civilstate', 'education']\n\ntrain = train.drop(drop_cols, axis=1)\ntest = test.drop(drop_cols, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.275337Z","iopub.execute_input":"2021-08-24T03:17:54.275767Z","iopub.status.idle":"2021-08-24T03:17:54.292322Z","shell.execute_reply.started":"2021-08-24T03:17:54.275717Z","shell.execute_reply":"2021-08-24T03:17:54.291278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now that all features are household related, we can drop all rows that aren't the household head row\n\ntrain = train.loc[train['ishousehead']  == 1]\ntest = test.loc[test['ishousehead'] == 1]\n\ntrain = train.drop('ishousehead', axis=1)\ntest = test.drop('ishousehead', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.293784Z","iopub.execute_input":"2021-08-24T03:17:54.294097Z","iopub.status.idle":"2021-08-24T03:17:54.312196Z","shell.execute_reply.started":"2021-08-24T03:17:54.294064Z","shell.execute_reply":"2021-08-24T03:17:54.311303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.313941Z","iopub.execute_input":"2021-08-24T03:17:54.314703Z","iopub.status.idle":"2021-08-24T03:17:54.322449Z","shell.execute_reply.started":"2021-08-24T03:17:54.314656Z","shell.execute_reply":"2021-08-24T03:17:54.321387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.323878Z","iopub.execute_input":"2021-08-24T03:17:54.324375Z","iopub.status.idle":"2021-08-24T03:17:54.338224Z","shell.execute_reply.started":"2021-08-24T03:17:54.324341Z","shell.execute_reply":"2021-08-24T03:17:54.337233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We already built enough features, now lets analyse the correlation of each one to target and keep dropping redundant features\n\ncorr_matrix = train.corr()\nprint(corr_matrix['Target'].sort_values(ascending=False))\n\n# We will drop most of the features that is between 0.2 and -0.2, unless we have a good reason to keep it\n\n\ndrop_cols = ['cookingsource', 'v2a1', 'toiletdwel', 'rubbishdisp', 'isurban', 'waterprov', 'v14a', 'houseowned', 'rooftype', 'elecsource', 'r4t3', 'v2a1-missing', 'Id','idhogar']\n\ntrain = train.drop(drop_cols, axis=1)\ntest = test.drop(drop_cols, axis=1)\n\ntrain = train.rename(columns = {'r4t1': 'numchilds', 'dependencynew' : 'dependency'})\ntest = test.rename(columns = {'r4t1': 'numchilds', 'dependencynew' : 'dependency'})","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.33974Z","iopub.execute_input":"2021-08-24T03:17:54.340243Z","iopub.status.idle":"2021-08-24T03:17:54.365016Z","shell.execute_reply.started":"2021-08-24T03:17:54.340209Z","shell.execute_reply":"2021-08-24T03:17:54.364058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.366129Z","iopub.execute_input":"2021-08-24T03:17:54.36639Z","iopub.status.idle":"2021-08-24T03:17:54.386699Z","shell.execute_reply.started":"2021-08-24T03:17:54.366365Z","shell.execute_reply":"2021-08-24T03:17:54.385548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.388248Z","iopub.execute_input":"2021-08-24T03:17:54.388691Z","iopub.status.idle":"2021-08-24T03:17:54.410417Z","shell.execute_reply.started":"2021-08-24T03:17:54.388648Z","shell.execute_reply":"2021-08-24T03:17:54.409145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"y = train['Target']\nX = train.drop('Target', axis=1)\nprint(y)\nprint(X)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.411794Z","iopub.execute_input":"2021-08-24T03:17:54.412115Z","iopub.status.idle":"2021-08-24T03:17:54.436193Z","shell.execute_reply.started":"2021-08-24T03:17:54.412085Z","shell.execute_reply":"2021-08-24T03:17:54.435111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we initialize all the modeling methods we'll test\nscorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')\nscaler = MinMaxScaler()\n\nkneigh = KNeighborsClassifier()\ndectree = DecisionTreeClassifier(random_state=42)\nforest = RandomForestClassifier(random_state=42)\nadab = AdaBoostClassifier(random_state=42)\ngb = xgb.XGBClassifier(eval_metric=scorer, random_state=42)\n\n\n# Create the train_test_split for model evaluation\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle=True, stratify=y , random_state=42)\ny_test = y_test.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.437746Z","iopub.execute_input":"2021-08-24T03:17:54.438216Z","iopub.status.idle":"2021-08-24T03:17:54.45382Z","shell.execute_reply.started":"2021-08-24T03:17:54.438181Z","shell.execute_reply":"2021-08-24T03:17:54.452663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bayes_search(model, param_grid):\n\n    # Initialize the cross validation method\n    n_iter = 5\n    cv = StratifiedKFold(n_splits=n_iter, shuffle=True, random_state=42)\n\n    # Execute the bayes search\n    bsearch = BayesSearchCV(model, param_grid, n_iter=n_iter, scoring=scorer, cv=cv, verbose=True).fit(X,y)\n    # Print the values to be used in each parameter for best result in the final fitting\n    print(' ',bsearch.best_score_)\n    print(' ',bsearch.best_params_)\n    \n    return None","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.455767Z","iopub.execute_input":"2021-08-24T03:17:54.456504Z","iopub.status.idle":"2021-08-24T03:17:54.46597Z","shell.execute_reply.started":"2021-08-24T03:17:54.456469Z","shell.execute_reply":"2021-08-24T03:17:54.464951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Searching for KNeighbors\n\n'''\n# Define the parameters to be tested in the bayes search\nparam_grid = {'n_neighbors': Integer(2, 20),\n              'weights': Categorical(['uniform','distance']),\n              'leaf_size': Integer(10, 100)}\n\nbayes_search(kneigh, param_grid)\n'''\n\n# Results: \n# ('leaf_size', 69), ('n_neighbors', 18), ('weights', 'distance')\n\n\nkneigh = KNeighborsClassifier(leaf_size=69, n_neighbors=18, weights='distance')\nkneigh.fit(X_train, y_train)\ny_pred = kneigh.predict(X_test)\nresult = f1_score(y_pred, y_test, average='macro')\nprint(result)\n\n# Result:\n# macro F1: 0.2989191209747389","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.467399Z","iopub.execute_input":"2021-08-24T03:17:54.467851Z","iopub.status.idle":"2021-08-24T03:17:54.508487Z","shell.execute_reply.started":"2021-08-24T03:17:54.467768Z","shell.execute_reply":"2021-08-24T03:17:54.507707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Searching for DecisionTreeClassifier\n\n'''\n# Define the parameters to be tested in the bayes search\nparam_grid = {'criterion': Categorical(['gini','entropy']),\n              'splitter': Categorical(['best','random']),\n              'max_depth': Integer(10, 200),\n              'min_samples_split': Integer(5, 50),\n              'max_leaf_nodes': Integer(10, 200),\n              }\n\nbayes_search(dectree, param_grid)\n'''\n\n# Results:\n# ('criterion', 'gini'), ('max_depth', 69), ('min_samples_split', 43), ('splitter', 'random')\n\ndectree = DecisionTreeClassifier(criterion='gini', max_depth=69, min_samples_split=43, splitter='random', random_state=42)\ndectree.fit(X_train, y_train)\ny_pred = dectree.predict(X_test)\nresult = f1_score(y_pred, y_test, average='macro')\nprint(result)\n\n# Result:\n# macro F1 0.31521827047080664","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.509664Z","iopub.execute_input":"2021-08-24T03:17:54.510127Z","iopub.status.idle":"2021-08-24T03:17:54.526175Z","shell.execute_reply.started":"2021-08-24T03:17:54.510085Z","shell.execute_reply":"2021-08-24T03:17:54.524972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Searching for RandomForestRegressor\n\n'''\n# Define the parameters to be tested in the bayes search\nparam_grid = {'n_estimators': Integer(100, 2000),\n              'criterion': Categorical(['gini','entropy']),\n              'max_leaf_nodes': Integer(20, 500),\n              'min_samples_split': Integer(5, 50),\n              'max_leaf_nodes': Integer(10, 200),\n              }\n\nbayes_search(forest, param_grid)\n'''\n\n# Results:\n# ('criterion', 'entropy'), ('max_leaf_nodes', 154), ('min_samples_split', 15), ('n_estimators', 682)\n\nforest = RandomForestClassifier(criterion='entropy', max_leaf_nodes=154, min_samples_split=15, n_estimators=682, random_state=42)\nforest.fit(X_train, y_train)\ny_pred = forest.predict(X_test)\nresult = f1_score(y_pred, y_test, average='macro')\nprint(result)\n\n# Result\n# macro F1 0.2880104516588272\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:54.52782Z","iopub.execute_input":"2021-08-24T03:17:54.528259Z","iopub.status.idle":"2021-08-24T03:17:57.414092Z","shell.execute_reply.started":"2021-08-24T03:17:54.528217Z","shell.execute_reply":"2021-08-24T03:17:57.412871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Searching for AdaBoostClassifier\n\n'''\n# Define the parameters to be tested in the bayes search\nparam_grid = {'n_estimators': Integer(50, 1000),\n              'learning_rate': Real(0.01, 1, prior='log-uniform')\n              }\n\nbayes_search(adab, param_grid)\n'''\n\n# Results:\n# ('learning_rate', 0.3935549480126014), ('n_estimators', 336)\n\nadab = AdaBoostClassifier(learning_rate=0.394, n_estimators=336 ,random_state=42)\nadab.fit(X_train, y_train)\ny_pred = adab.predict(X_test)\nresult = f1_score(y_pred, y_test, average='macro')\nprint(result)\n\n# Result\n# macro F1 0.327066295591346\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:57.415606Z","iopub.execute_input":"2021-08-24T03:17:57.416019Z","iopub.status.idle":"2021-08-24T03:17:58.658335Z","shell.execute_reply.started":"2021-08-24T03:17:57.415976Z","shell.execute_reply":"2021-08-24T03:17:58.657135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Searching for XGBoost\n\n'''\n# Define the parameters to be tested in the bayes search\nparam_grid = {'max_depth': Integer(1, 90),\n              'learning_rate': Real(0.01, 1, prior='log-uniform'),\n              'reg_alpha': Real(0.01, 100),\n              'colsample_bytree': Real(0.2e0, 0.8e0),\n              'subsample': Real(0.2e0, 0.8e0),\n              'n_estimators': Integer(50, 200)}\n\nbayes_search(gb, param_grid)\n'''\n\n# Results:\n# ('colsample_bytree', 0.3641610047267118), ('learning_rate', 0.8433396554938758), ('max_depth', 3), ('n_estimators', 94), ('reg_alpha', 7.175005707630737), ('subsample', 0.681950796538646)\n\n\ngb = xgb.XGBClassifier(colsample_bytree=0.36, learning_rate=0.84, max_depth=3, n_estimators=94, reg_alpha=7.18, subsample=0.68, random_state=42)\ngb.fit(X_train, y_train)\ny_pred = gb.predict(X_test)\nresult = f1_score(y_pred, y_test, average='macro')\nprint(result)\n\n# Result:\n# macro F1 0.36306483376974086","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:58.659989Z","iopub.execute_input":"2021-08-24T03:17:58.660342Z","iopub.status.idle":"2021-08-24T03:17:58.884856Z","shell.execute_reply.started":"2021-08-24T03:17:58.660309Z","shell.execute_reply":"2021-08-24T03:17:58.884019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Out of all models tried, XGBClassifier got the better result\n\ngb = xgb.XGBClassifier(colsample_bytree=0.36, learning_rate=0.84, max_depth=3, n_estimators=94, reg_alpha=7.18, subsample=0.68, random_state=42)\ngb.fit(X, y)\ny_pred = gb.predict(test)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:58.88879Z","iopub.execute_input":"2021-08-24T03:17:58.890811Z","iopub.status.idle":"2021-08-24T03:17:59.148156Z","shell.execute_reply.started":"2021-08-24T03:17:58.890764Z","shell.execute_reply":"2021-08-24T03:17:59.147247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets analyse the results of the xgboost model\n\ny_pred_conf = gb.predict(X_test)\nlabels_cm = ['ExtermePoverty','ModeratePoverty','Vulnerable','NonVulnerable'] \ncm = confusion_matrix(y_test, y_pred_conf)\n\ndf_cm = pd.DataFrame(cm, index = [i for i in labels_cm], columns = [i for i in labels_cm])\nplt.figure(figsize = (8,6))\nsns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='YlGnBu')\n\n# The model manages to predict fairly well people on the ExtremePoverty and NonVulnerable targets\n# It doesn't work so well on ModeratePoverty","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:59.152756Z","iopub.execute_input":"2021-08-24T03:17:59.155128Z","iopub.status.idle":"2021-08-24T03:17:59.470146Z","shell.execute_reply.started":"2021-08-24T03:17:59.155071Z","shell.execute_reply":"2021-08-24T03:17:59.46937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets see the relevancy the model gave to each feature\n\n# print the JS visualization code to the notebook\nshap.initjs()\n\n# use Kernel SHAP to explain test set predictions\nexplainer = shap.TreeExplainer(gb)\nshap_values = explainer.shap_values(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:59.471281Z","iopub.execute_input":"2021-08-24T03:17:59.471724Z","iopub.status.idle":"2021-08-24T03:17:59.901483Z","shell.execute_reply.started":"2021-08-24T03:17:59.471692Z","shell.execute_reply":"2021-08-24T03:17:59.900621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize the effects of all the features\nprint('---------------------------------ExtermePoverty----------------------------------')\nshap.summary_plot(shap_values[0], X_train)\nprint('---------------------------------ModeratePoverty---------------------------------')\nshap.summary_plot(shap_values[1], X_train)\nprint('-----------------------------------Vulnerable------------------------------------')\nshap.summary_plot(shap_values[2], X_train)\nprint('---------------------------------NonVulnerable-----------------------------------')\nshap.summary_plot(shap_values[3], X_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:17:59.902921Z","iopub.execute_input":"2021-08-24T03:17:59.903523Z","iopub.status.idle":"2021-08-24T03:18:03.616942Z","shell.execute_reply.started":"2021-08-24T03:17:59.903484Z","shell.execute_reply":"2021-08-24T03:18:03.616049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,18):\n    y_pred = np.append(y_pred, 4)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:18:03.617988Z","iopub.execute_input":"2021-08-24T03:18:03.618415Z","iopub.status.idle":"2021-08-24T03:18:03.622647Z","shell.execute_reply.started":"2021-08-24T03:18:03.618385Z","shell.execute_reply":"2021-08-24T03:18:03.621831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('mode.chained_assignment', None)\n\nsubmission['Target'] = 0\n\nn_idho = submission['idhogar'].unique()\nvi = 0\n\nfor i in n_idho:\n    submission.loc[submission['idhogar'] == i, 'Target'] = y_pred[vi]\n    vi += 1\n\nsubmission = submission.drop('idhogar', axis=1)\n\nsubmission.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T03:20:33.111975Z","iopub.execute_input":"2021-08-24T03:20:33.112521Z","iopub.status.idle":"2021-08-24T03:21:07.836886Z","shell.execute_reply.started":"2021-08-24T03:20:33.11248Z","shell.execute_reply":"2021-08-24T03:21:07.835809Z"},"trusted":true},"execution_count":null,"outputs":[]}]}