{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set a few plotting defaults\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.size'] = 18\nplt.rcParams['patch.edgecolor'] = 'k'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Read in Data and look at summary information"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = 150\n\n#Read in data\ntrain = pd.read_csv('../input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('../input/costa-rican-household-poverty-prediction/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()\n\n#130 개의 정수 열, 8 개의 부동 (숫자) 열 및 5 개의 개체 열이 있음\n#정수 열은 부울 변수 (0 또는 1을 사용), 불연속 순서 값을 가진 서수 변수를 나타낸다.\n#객체 열은 머신 러닝 모델로 직접 공급 될 수 없기 때문에 문제가 될 수도 있다\n\n#열보다 행이 더 많은 test를 살펴보자.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()\n# 타겟이 없기 때문에 열은 하나가 적음 (train int130개 test int129개)\n\n#정수 열\n#정수 열에서 고유 한 값의 분포를 살펴보고\n#각 열에 대해 고유 값의 수를 세고 결과를 막대 그래프로 확인","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.select_dtypes(np.int64).nunique().value_counts().sort_index().plot.bar(color = 'blue',\n                                                                                 figsize = (8, 6),                                                                          \n                                                                                 edgecolor = 'k', linewidth = 2);\n\nplt.xlabel('Number of Unique Values');plt.ylabel('Count');\nplt.title('Count of Unique Values in Integer Columns');\n\n#정수열의 고유한 값의 분포를 살펴본 결과","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\n\nplt.figure(figsize = (20, 16))\nplt.style.use('fivethirtyeight')\n\n#Color mapping\ncolors = OrderedDict({1: 'red', 2:'orange', 3:'blue', 4:'green'})\npoverty_mapping = OrderedDict({1:'extreme', 2:'moderate', 3:'vulnerable', 4:'non vulnerable'})\n\n#Interate through the float columns\nfor i, col in enumerate(train.select_dtypes('float')):\n    ax = plt.subplot(4, 2, i+1)\n    #Interate throught the poverty levels\n    for poverty_level, color in colors.items():\n        #plot each poverty level as a separate line\n        sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(),\n                   ax = ax,color = color, label = poverty_mapping[poverty_level])\n        \n        plt.title(f'{col.capitalize()} Distribution'); plt.xlabel(f'{col}');plt.ylabel('Desity')\n        \n        plt.subplots_adjust(top = 2)\n        \n        #v2al = mothly rent payment 월세 지불\n        #b18q1 = number of tablets household owns 세대가 소유한 태블릿 수\n        #rez_esc, Years behind in school 학교 몇년뒤에 가냐\n        \n        #overcrowding = persons per room  방 당 사람\n        #SQBovercrowding = overcrowding squared \n      \n        \n        #dependency = dependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/\n                                                #(number of member of household between 19 and 64)\n            \n            #의존성, 의존성 비율, 계산 된 = (19 세 이하 또는 64 세 이상 가구 구성원 수) / (19-64 세 가구 구성원 수)\n        #SQBdependency = dependency squared\n        #SQBmeaned = square of the mean years of education of adults (>=18) in the household\n        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위의 도표를 통해 모델과 가장 관련이있는 변수를 파악 할 수 있다.\n그래프 중 하나를 설명하자면, \n성인평균 교육수준이 높을 수록 빈곤이 덜하다는 것을 알 수 있다\n\n또한 피처 간의 관계를 측정하기 위해 변수와 대상 간의 상관 관계를 계산할 것 이다."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Object Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dependency 오류남 왜인지는 모름\n\nmapping = {\"yes\" : 1, \"no\" : 0}\n\n#Apply the same operation to both train and test\nfor df in [train, test]:\n    #Fill in the values with the correct mapping\n    df['dependency'] = df['dependency'].replace(mapping).astype(np.float64)\n    df['edjefa'] = df['edjefa'].replace(mapping).astype(np.float64)\n    df['edjefe'] = df['edjefe'].replace(mapping).astype(np.float64)\n    \n    train[['dependency', 'edjefa', 'edjefe']].describe()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 12))\n\n# Iterate through the float columns\nfor i, col in enumerate(['dependency', 'edjefa', 'edjefe']):\n    ax = plt.subplot(3, 1, i + 1)\n    # Iterate through the poverty levels\n    for poverty_level, color in colors.items():\n        # Plot each poverty level as a separate line\n        sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(), \n                    ax = ax, color = color, label = poverty_mapping[poverty_level])\n        \n    plt.title(f'{col.capitalize()} Distribution'); plt.xlabel(f'{col}'); plt.ylabel('Density')\n\nplt.subplots_adjust(top = 2)\n\n#dependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)\n#edjefe, years of education of male head of household,based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n#edjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n\n\n#이런 단계를 거치면 변수는 이제 숫자로 올바르게 표시되며 기계 학습 모델에 제공 될 수 있음\n\n#위와 같은 작업을 좀 더 쉽게하기 위해 교육 및 테스트 데이터 프레임을 결합한다.\n#기능 엔지니어링을 시작한 후에는 두 데이터 프레임에 동일한 작업을 적용하여\n#동일한 기능을 사용하기 때문에 중요하다. 나중에 Target을 기준으로 세트를 분리 할 수 있다.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add null Target column to test\ntest['Target'] = np.nan\ndata = train.append(test, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n> 라벨 배포 탐색\n\n라벨의 분포를 보면 문제가 얼마나 불균형한지 알 수 있음\n4 가지 가능한 정수 수준이 있는데, 이는 4 가지 빈곤 수준을 나타냅니다.\n(extreme, moderate vulnerable non vulnerable)\n\n올바른 레이블을 확인하기 위해 parentesco1 == 1 인 열만 하위 세트합니다.\n각 세대의 올바른 라벨 인 세대주이기 때문입니다. parentesco1, = 1 if 세대주\n\n아래 막대 그림은  test 레이블이 없기 때문에 교육 레이블의 분포를 보여준다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heads of household\nheads = data.loc[data['parentesco1'] == 1].copy()\n\n# Labels for training\ntrain_labels = data.loc[(data['Target'].notnull()) & (data['parentesco1'] == 1), ['Target', 'idhogar']]\n\n# Value counts of target\nlabel_counts = train_labels['Target'].value_counts().sort_index()\n\n# Bar plot of occurrences of each label\nlabel_counts.plot.bar(figsize = (8, 6), \n                      color = colors.values(),\n                      edgecolor = 'k', linewidth = 2)\n\n# Formatting\nplt.xlabel('Poverty Level'); plt.ylabel('Count'); \nplt.xticks([x - 1 for x in poverty_mapping.keys()], \n           list(poverty_mapping.values()), rotation = 60)\nplt.title('Poverty Level Breakdown');\n\nlabel_counts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"지금 우리는 불균형 class문제를 다루고 정리하는 중임\n\n이때까지 정리하여 바차트로 확인해본 결과\nnon vulnerable이 가장 많고 extreme이 가장 낮은 것으로 나온다.\n\n우리가 관심있는것은 빈곤층!\n\n\n불균형 분류 문제의 한 가지 문제점은 머신 러닝 모델이 소수 클래스 예측도가 낮다.\n우리가 빈곤을 분류하였는데 extreme보다 non vulnerable한 경우를 더 많이 본다면,\n노출이 적기 때문에 빈곤 가정을 파악하기가 더 어려워진다.\n\n클래스 불균형을 해결하는 한 가지 가능한 방법은 오버 샘플링을 이용하는 것."},{"metadata":{},"cell_type":"markdown","source":"잘못된 레이블 해결\n\n실제 데이터 세트와 마찬가지로 Costa Rican Poverty 데이터에는 몇 가지 문제가 있다.\n\n일반적으로 데이터 과학 프로젝트의 80 %는 cleaning data and fixing erros 하는데 사용한다.\n사람 입력 오류, 측정 오류 또는 때로는 정확하지만 눈에 띄는 극단적 인 값일 수 있습니다.\n\n\n이 데이터 문제의 경우, 같은 가구에 속한 개인의 빈곤 수준이 다르기 때문에 일부 레이블이 올바르지 않다.\n\n이것이 왜 그런지에 대해서는 알려지지 않았지만 데이터제공처(The organizers)에서 세대주를\ntrue label로 하는것을 추천했다.\n\n이러한 정보를 통해 업무를 훨씬 쉽게 수행 할 수 있지만\n실제 문제에서는 레이블이 왜 틀린지, 문제를 직접 해결하는 방법을 찾아야한다.\n\n이 섹션에서는 레이블이 반드시 필요한 것은 아니지만 레이블 관련 문제를 해결할것이다.\n\n\n-오류 식별\n먼저 오류를 찾아 수정해야한다.\n가족 구성원에 대해 다른 레이블이있는 세대를 찾으려면 세대별로 데이터를 그룹화 한 다음\n대상의 고유 한 값이 하나만 있는지 확인해야한다.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Groupby the household and figure out the number of unique values\nall_equal = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Households where targets are not all equal\nnot_equal = all_equal[all_equal != True]\nprint('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"가족구성원중 같지않은 타겟을 가지고 있는 세대주가 85개 있다.\n\n예시.\n\nidhogar = 세대 수준 식별자\nparentesco1, = 1 if 세대주"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['idhogar'] == not_equal.index[0]][['idhogar', 'parentesco1', 'Target']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The organizers는 올바른 레이블이 parentesco1 == 1 인 세대주라고 한다.\n\n이 세대의 모든 구성원에 대해 올바른 레이블은 3입니다.\n우리는 이 가구의 모든 개인을 올바른 빈곤 수준으로 재 할당함으로써\n(나중에 보여지는 바와 같이)이를 수정한다.\n\n또한 세대주가없는 가정은 동일한 세대의 개인에게\n세대주 레이블을 할당하여 모든 상표 불일치를 수정할 계획 "},{"metadata":{"trusted":true},"cell_type":"code","source":"households_leader = train.groupby('idhogar')['parentesco1'].sum()\n\n# Find households without a head\nhouseholds_no_head = train.loc[train['idhogar'].isin(households_leader[households_leader == 0].index), :]\n\nprint('There are {} households without a head.'.format(households_no_head['idhogar'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find households without a head and where labels are different\n#head가 없는 세대주를 찾고 어느 라벨이 다른지 찾기\nhouseholds_no_head_equal = households_no_head.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\nprint('{} Households with no head have different labels.'.format(sum(households_no_head_equal == False)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 0 Households with no head have different labels.\n\nhead가없고 구성원의 레이블 값이 다른 세대주에 대해 걱정할 필요가 없음을 의미함.\n이 문제에 대해 the organizers에 따르면 세대에 head가 없으면 true label이 없다.\n따라서 head가 없는 세대주는 트레이닝 하지 않는다.\n\nCorrect Errors\n이제, head가있는 가구와 빈곤층이 다른 세대에 대한 레이블을 수정한다.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterate through each household\nfor household in not_equal.index:\n    # Find the correct label (for the head of household)\n    true_target = int(train[(train['idhogar'] == household) & (train['parentesco1'] == 1.0)]['Target'])\n    \n    # Set the correct label for all members in the household\n    train.loc[train['idhogar'] == household, 'Target'] = true_target\n    \n    \n# Groupby the household and figure out the number of unique values\nall_equal = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Households where targets are not all equal\nnot_equal = all_equal[all_equal != True]\nprint('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"레이블에는 세대주만 사용하기 때문에 이 단계는 완전히 필요한 것은 아니지만\n실제 상황에서 발생할 수있는 데이터 오류를 수정하기위한 workflow를 보여주는 것이다.\n\n경력을 위해 연습하기 !"},{"metadata":{},"cell_type":"markdown","source":"누락 된 변수\n탐색적 데이터 분석의 가장 중요한 단계 중 하나는 데이터에서 누락 된 값을 찾아서 처리 방법을 결정하는 것.\n기계 학습 모델을 사용하기 전에 누락 된 값을 채워야하며,\n기능을 기반으로 값을 채우는 가장 좋은 전략을 고려해야한다.\n\n먼저 각 열에서 결 측값의 백분율을 확인한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of missing in each column\nmissing = pd.DataFrame(data.isnull().sum()).rename(columns = {0: 'total'})\n\n# Create a percentage missing\nmissing['percent'] = missing['total'] / len(data)\n\nmissing.sort_values('percent', ascending = False).head(10).drop('Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"결측값이 높은 다른 3 개의 열을 처리해야함\n\nv18q1 : 정제 수\n\n<밑에는 뭔말인지 모름용>\n가족이 소유 한 태블릿 수를 나타내는 v18q1부터 시작해보면.이 변수의 값 카운트를 볼 수 있다.\n이것은 가계 변수이기 때문에 가계 수준에서만 살펴 보는 것이 합리적이므로 세대주를위한 행만 선택합니다.\n\n값 카운트를 플롯하는 기능\n다른 열에 대한 값 수를 플로팅하고 싶을 수도 있으므로 간단한 함수를 작성하면됩니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_value_counts(df, col, heads_only = False):\n    \"\"\"Plot value counts of a column, optionally with only the heads of a household\"\"\"\n    # Select heads of household\n    if heads_only:\n        df = df.loc[df['parentesco1'] == 1].copy()\n        \n    plt.figure(figsize = (8, 6))\n    df[col].value_counts().sort_index().plot.bar(color = 'blue',\n                                                 edgecolor = 'k',\n                                                 linewidth = 2)\n    plt.xlabel(f'{col}'); plt.title(f'{col} Value Counts'); plt.ylabel('Count')\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\"\" \"선택적으로 세대주 만 포함하는 열의 값 개수를 표시.\" \"\""},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_value_counts(heads, 'v18q1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n존재하는 데이터 만 사용하는 경우 가장 일반적인 태블릿 수는 1\n\nv18q의 값을 그룹화하여 (태블릿의 경우 1, 그렇지 않은 경우 0) v18q1의 null 값 수를 계산할 수 있다.\n\nv18q = 가족이 태블릿을 소유하고 있는지 여부\n이 칼럼을 여러 태블릿과 결합하여 가설이 유지되는지 확인해야함.\n\n(null 값이 가족이 태블릿을 소유하지 않음을 나타내는 지 알려준다.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"heads.groupby('v18q')['v18q1'].apply(lambda x: x.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"v18q1에 대해 nan이있는 모든 가족은 태블릿을 소유하지 않는 것을 확인됨\n따라서 이 결 측값을 0으로 채울 수 있다."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['v18q1'] = data['v18q1'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Variables indicating home ownership\nown_variables = [x for x in data if x.startswith('tipo')]\n\n\n# Plot of the home ownership variables for home missing rent payments\ndata.loc[data['v2a1'].isnull(), own_variables].sum().plot.bar(figsize = (10, 8),\n                                                                        color = 'green',\n                                                              edgecolor = 'k', linewidth = 2);\nplt.xticks([0, 1, 2, 3, 4],\n           ['Owns and Paid Off', 'Owns and Paying', 'Rented', 'Precarious', 'Other'],\n          rotation = 60)\nplt.title('Home Ownership Status for Households Missing Rent Payments', size = 18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"V2a1 : 월 임대료 지불\n다음으로 누락 된 열은 월 임대료 지불을 나타내는 v2a1\n\n이 바차트는 월 임대료 지불에 대해 주택의 소유권 상태를 보여줍니다.\n\n\n\n주택 소유 변수의 의미는 다음과 같다.\n\ntipovivi1, = 1 소유 및 완전 지불 주택\ntipovivi2, \"= 1 소유, 할부 지불\"\ntipovivi3, = 1 임대\ntipovivi4, = 1 불안정한 상태\ntipovivi5, \"= 1 기타 (지정, 차용)\"\n\n주로 : 월세를 지불하지 않는 가구는 일반적으로 자신의 집을 소유한다. \n\n소유하고 월 임대료가 누락 된 주택의 경우 임대료 지불액을 0으로 설정할 수 있다.\n다른 주택의 경우 결측값을 대치 할 수 있지만 해당 가정에 결측값이 있음을 나타내는 플래그(부울)열을 추가한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill in households that own the house with 0 rent payment\ndata.loc[(data['tipovivi1'] == 1), 'v2a1'] = 0\n\n# Create missing rent payment column\ndata['v2a1-missing'] = data['v2a1'].isnull()\n\ndata['v2a1-missing'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"rez_esc \n\n결측값 비율이 높은 마지막 열은 rez_esc이며 학교에서 몇 년이 지났음을 나타낸다.\nnull 값을 가진 가정의 경우 현재 학교에 자녀가 없을 가능성이 있기때문에 이 열에서 결측값이없는 사람의 연령과\n결측값이없는 사람의 연령을 찾아서 이것을 테스트 해본다."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['rez_esc'].notnull()]['age'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"가장 가치가없는 나이: 17 세\n이보다 나이가 많은 사람은 아마도 학교에 있지 않다고 가정 할 수 도 있다.\n\n이 변수는 7과 19 사이의 개인에 대해서만 정의\n이 범위보다 젊거나 더 오래된 사람은 아마도 몇 년 뒤 학교에 없기 때문에 그 값은 0으로 설정해야함.\n이 변수는 개인이 19 세 이상이고 결측값이 있거나 7보다 작고 결측값이있는 경우 0으로 설정할 수 있습니다.\n다른 사람에게는 값을 대치하고 부울 플래그를 추가합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# If individual is over 19 or younger than 7 and missing years behind, set it to 0\ndata.loc[((data['age'] > 19) | (data['age'] < 7)) & (data['rez_esc'].isnull()), 'rez_esc'] = 0\n\n# Add a flag for those between 7 and 19 with a missing value\ndata['rez_esc-missing'] = data['rez_esc'].isnull()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"rez_esc 열에는 이상치가 하나있다.\n변수의 최대 값이 5임. 따라서 5보다 큰 값은 5로 설정해야한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['rez_esc'] > 5, 'rez_esc'] = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" 점의 크기가 각 x- 값으로 표시되는 주어진 y- 값의 백분율을 나타내는 두 범주 형의 산점도."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_categoricals(x, y, data, annotate = True):\n    \"\"\"Plot counts of two categoricals.\n    Size is raw count for each grouping.\n    Percentages are for a given value of y.\"\"\"\n    \n    # Raw counts \n    raw_counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = False))\n    raw_counts = raw_counts.rename(columns = {x: 'raw_count'})\n    \n    # Calculate counts for each group of x and y\n    counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = True))\n    \n    # Rename the column and reset the index\n    counts = counts.rename(columns = {x: 'normalized_count'}).reset_index()\n    counts['percent'] = 100 * counts['normalized_count']\n    \n    # Add the raw count\n    counts['raw_count'] = list(raw_counts['raw_count'])\n    \n    plt.figure(figsize = (14, 10))\n    # Scatter plot sized by percent\n    plt.scatter(counts[x], counts[y], edgecolor = 'k', color = 'lightgreen',\n                s = 100 * np.sqrt(counts['raw_count']), marker = 'o',\n                alpha = 0.6, linewidth = 1.5)\n    \n    if annotate:\n        # Annotate the plot with text\n        for i, row in counts.iterrows():\n            # Put text with appropriate offsets\n            plt.annotate(xy = (row[x] - (1 / counts[x].nunique()), \n                               row[y] - (0.15 / counts[y].nunique())),\n                         color = 'navy',\n                         s = f\"{round(row['percent'], 1)}%\")\n        \n    # Set tick marks\n    plt.yticks(counts[y].unique())\n    plt.xticks(counts[x].unique())\n    \n    # Transform min and max to evenly space in square root domain\n    sqr_min = int(np.sqrt(raw_counts['raw_count'].min()))\n    sqr_max = int(np.sqrt(raw_counts['raw_count'].max()))\n    \n    # 5 sizes for legend\n    msizes = list(range(sqr_min, sqr_max,\n                        int(( sqr_max - sqr_min) / 5)))\n    markers = []\n    \n    # Markers for legend\n    for size in msizes:\n        markers.append(plt.scatter([], [], s = 100 * size, \n                                   label = f'{int(round(np.square(size) / 100) * 100)}', \n                                   color = 'lightgreen',\n                                   alpha = 0.6, edgecolor = 'k', linewidth = 1.5))\n        \n    # Legend and formatting\n    plt.legend(handles = markers, title = 'Counts',\n               labelspacing = 3, handletextpad = 2,\n               fontsize = 16,\n               loc = (1.10, 0.19))\n    \n    plt.annotate(f'* Size represents raw count while % is for a given y value.',\n                 xy = (0, 1), xycoords = 'figure points', size = 10)\n    \n    # Adjust axes limits\n    plt.xlim((counts[x].min() - (6 / counts[x].nunique()), \n              counts[x].max() + (6 / counts[x].nunique())))\n    plt.ylim((counts[y].min() - (4 / counts[y].nunique()), \n              counts[y].max() + (4 / counts[y].nunique())))\n    plt.grid(None)\n    plt.xlabel(f\"{x}\"); plt.ylabel(f\"{y}\"); plt.title(f\"{y} vs {x}\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoricals('rez_esc', 'Target', data);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"마커의 크기는 원시 수를 나타낸다.\n그림을 읽으려면 주어진 y 값을 선택한 다음 행을 읽는다.\n\n예를 들어, 빈곤 수준이 1 인 경우, 개인의 93 %가 약 800 명으로 총 수에 뒤쳐지지 않으며,\n약 0.4 %의 개인이 5 년 뒤에이 범주에서 약 50 명의 전체 개인을 갖는다.\n이 플롯은 전체 개수와 범주 내 비율을 모두 표시하려고 시도합니다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categoricals('escolari', 'Target', data, annotate = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_value_counts(data[(data['rez_esc-missing'] == 1)], \n                  'Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n여기서 분포는 모든 데이터의 분포와 일치하는 것으로 보인다.\n\n(poverty level breakdown 그래프 (빨노파초))"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_value_counts(data[(data['v2a1-missing'] == 1)], \n                  'Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<뭔말인지 이해하지 못함>\n이것은 빈곤율이 보통 인 빈곤율이 높을수록 빈곤의 지표가 될 수있는 것처럼 보인다.\n\n이것은 중요한 요점을 나타냅니다. 때로는 누락 된 정보가 귀하가 제공 한 정보만큼 중요합니다."},{"metadata":{},"cell_type":"markdown","source":"*뛰어넘기*\n\nModel Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model imports\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegressionCV, RidgeClassifierCV\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Optimization\n\n\n모델 최적화는 교차 검증을 통해 하이퍼 파라미터를 조정하여 기계 학습 모델에서 최상의 성능을 추출하는 프로세스이다.\n최상의 모델 하이퍼 파라미터는 모든 데이터 세트마다 다르기 때문에이 작업이 필요하다.\n\n\n1.설명서\n2.그리드 검색\n3.무작위 검색\n4.자동화 된 최적화\n\n이 방법은 일반적으로 가장 효율적인 방법이며 Tree Parzen Estimator와 함께 수정 된 Bayesian Optimization 버전을 사용하는 Hyperopt를 포함한 여러 라이브러리에서 쉽게 구현할 수 있기 때문에 4가지를 고수 할 것이다."},{"metadata":{},"cell_type":"markdown","source":"Hyperopt를 사용한 모델 튜닝\n베이지안 최적화에는 4 가지 부분이 필요함.\n\n목표 함수 : 우리가 최대화하고 싶은 것\n도메인 공간 : 검색 할 지역\n다음 하이퍼 파라미터 선택 알고리즘 : 과거 결과를 사용하여 다음 값 제안\n결과 기록 : 과거 결과를 저장\n이전에 Hyperopt 사용에 대해 작성 했으므로 여기서는 구현을 한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import hp, tpe, Trials, fmin, STATUS_OK\nfrom hyperopt.pyll.stochastic import sample\nimport csv\nimport ast\nfrom timeit import default_timer as timer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. 목적 함수\n모델 하이퍼 파라미터를 가져와 관련 유효성 검사 점수를 반환합니다 Hyperopt는 최소화하기 위해 점수가 필요하므로 1-Macro F1 점수를 반환합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(hyperparameters, nfolds=5):\n    \"\"\"Return validation score from hyperparameters for LightGBM\"\"\"\n    \n    # Keep track of evals\n    global ITERATION\n    ITERATION += 1\n    \n    # Retrieve the subsample\n    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n    subsample_freq = hyperparameters['boosting_type'].get('subsample_freq', 0)\n    \n    boosting_type = hyperparameters['boosting_type']['boosting_type']\n    \n    if boosting_type == 'dart':\n        hyperparameters['drop_rate'] = hyperparameters['boosting_type']['drop_rate']\n    \n    # Subsample and subsample frequency to top level keys\n    hyperparameters['subsample'] = subsample\n    hyperparameters['subsample_freq'] = subsample_freq\n    hyperparameters['boosting_type'] = boosting_type\n    \n    # Whether or not to use limit maximum depth\n    if not hyperparameters['limit_max_depth']:\n        hyperparameters['max_depth'] = -1\n    \n    # Make sure parameters that need to be integers are integers\n    for parameter_name in ['max_depth', 'num_leaves', 'subsample_for_bin', \n                           'min_child_samples', 'subsample_freq']:\n        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n\n    if 'n_estimators' in hyperparameters:\n        del hyperparameters['n_estimators']\n    \n    # Using stratified kfold cross validation\n    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True)\n    \n    # Convert to arrays for indexing\n    features = np.array(train_selected)\n    labels = np.array(train_labels).reshape((-1 ))\n    \n    valid_scores = []\n    best_estimators = []\n    run_times = []\n    \n    model = lgb.LGBMClassifier(**hyperparameters, class_weight = 'balanced',\n                               n_jobs=-1, metric = 'None',\n                               n_estimators=10000)\n    \n    # Iterate through the folds\n    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n        \n        # Training and validation data\n        X_train = features[train_indices]\n        X_valid = features[valid_indices]\n        y_train = labels[train_indices]\n        y_valid = labels[valid_indices]\n        \n        start = timer()\n        # Train with early stopping\n        model.fit(X_train, y_train, early_stopping_rounds = 100, \n                  eval_metric = macro_f1_score, \n                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n                  eval_names = ['train', 'valid'],\n                  verbose = 400)\n        end = timer()\n        # Record the validation fold score\n        valid_scores.append(model.best_score_['valid']['macro_f1'])\n        best_estimators.append(model.best_iteration_)\n        \n        run_times.append(end - start)\n    \n    score = np.mean(valid_scores)\n    score_std = np.std(valid_scores)\n    loss = 1 - score\n    \n    run_time = np.mean(run_times)\n    run_time_std = np.std(run_times)\n    \n    estimators = int(np.mean(best_estimators))\n    hyperparameters['n_estimators'] = estimators\n    \n    # Write to the csv file ('a' means append)\n    of_connection = open(OUT_FILE, 'a')\n    writer = csv.writer(of_connection)\n    writer.writerow([loss, hyperparameters, ITERATION, run_time, score, score_std])\n    of_connection.close()\n    \n    # Display progress\n    if ITERATION % PROGRESS == 0:\n        display(f'Iteration: {ITERATION}, Current Score: {round(score, 4)}.')\n    \n    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n            'time': run_time, 'time_std': run_time_std, 'status': STATUS_OK, \n            'score': score, 'score_std': score_std}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. 검색 공간\n도메인은 검색하려는 전체 값 범위이다.\n유일하게 어려운 부분은 boosting_type = \"goss\"인 경우 1.0으로 설정해야하는 서브 샘플 비율이다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the search space\nspace = {\n    'boosting_type': hp.choice('boosting_type', \n                              [{'boosting_type': 'gbdt', \n                                'subsample': hp.uniform('gdbt_subsample', 0.5, 1),\n                                'subsample_freq': hp.quniform('gbdt_subsample_freq', 1, 10, 1)}, \n                               {'boosting_type': 'dart', \n                                 'subsample': hp.uniform('dart_subsample', 0.5, 1),\n                                 'subsample_freq': hp.quniform('dart_subsample_freq', 1, 10, 1),\n                                 'drop_rate': hp.uniform('dart_drop_rate', 0.1, 0.5)},\n                                {'boosting_type': 'goss',\n                                 'subsample': 1.0,\n                                 'subsample_freq': 0}]),\n    'limit_max_depth': hp.choice('limit_max_depth', [True, False]),\n    'max_depth': hp.quniform('max_depth', 1, 40, 1),\n    'num_leaves': hp.quniform('num_leaves', 3, 50, 1),\n    'learning_rate': hp.loguniform('learning_rate', \n                                   np.log(0.025), \n                                   np.log(0.25)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 2000, 100000, 2000),\n    'min_child_samples': hp.quniform('min_child_samples', 5, 80, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.5, 1.0)\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample(space)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. 알고리즘\n다음 값을 선택하는 알고리즘은 목적 함수의 대리 모델을 구성하기 위해 베이즈 규칙을 사용하는 Tree Parzen Estimator이다.\n알고리즘은 목적 함수를 최대화하는 대신 대리 모델의 EI (Expected Improvement)를 최대화이다."},{"metadata":{"trusted":true},"cell_type":"code","source":"algo = tpe.suggest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. 결과 기록\n결과를 기록하기 위해 두 가지 방법을 사용\n\n평가판 개체 : 목적 함수에서 반환 된 모든 내용을 저장한다.\n반복 할 때마다 CSV 파일에 쓰기\n중복을 의미하기 때문에 진행 상황을 추적하기 위해 여러 가지 방법을 사용하는 것이 좋다.\n한 가지 방법은 실패 할 수 있지만 두 가지 방법 모두 그렇지 않습니다! csv 파일을 사용하여 메서드가 실행되는 동안 메서드를 모니터링하고 Trials 개체를 저장 한 다음 다시로드하여 최적화를 다시 시작할 수 있다."},{"metadata":{"trusted":true},"cell_type":"code","source":"#여기부터 내가 뛰어넘어서 오류 및 제대로 결과값이 나오지 않음. 본문 보면서 설명하기\n# Record results\ntrials = Trials()\n\n# Create a file and open a connection\nOUT_FILE = 'optimization.csv'\nof_connection = open(OUT_FILE, 'w')\nwriter = csv.writer(of_connection)\n\nMAX_EVALS = 100\nPROGRESS = 10\nN_FOLDS = 5\nITERATION = 0\n\n# Write column names\nheaders = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score', 'std']\nwriter.writerow(headers)\nof_connection.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture --no-display\ndisplay(\"Running Optimization for {} Trials.\".format(MAX_EVALS))\n\n# Run optimization\nbest = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n            max_evals = MAX_EVALS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"o 훈련을 다시 시작하면 동일한 평가판 개체를 전달하고 최대 반복 횟수를 늘릴 수 있다.\n나중에 사용하기 위해 평가판을 json으로 저장할 수 있다."},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\n# Save the trial results\nwith open('trials.json', 'w') as f:\n    f.write(json.dumps(str(trials)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Optimized Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.read_csv(OUT_FILE).sort_values('loss', ascending = True).reset_index()\nresults.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8, 6))\nsns.regplot('iteration', 'score', data = results);\nplt.title(\"Optimization Scores\");\nplt.xticks(list(range(1, results['iteration'].max() + 1, 3)));\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}