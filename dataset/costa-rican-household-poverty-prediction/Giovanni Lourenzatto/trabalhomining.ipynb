{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"##bibliotecas \nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve, classification_report, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nimport scikitplot as skplt\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.utils import resample\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n## visualização\npd.set_option('max_columns', 140)\npd.set_option('max_colwidth', 5000)\npd.set_option('display.max_rows', 140)\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (12,8)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## carregando e juntando datasets\ntrain = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\ncodebook = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/codebook.csv')\n\ndf = train.append(test)\n\ntrain.shape,test.shape, df.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# > > Explorando dados e realizando o pré-processamento","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## procurando valores com grande quantidade de nulos\ndf.isna().sum().sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## verificando variáveis que apresentaram muitos nulos e não são a Target\nprint(codebook[codebook['Variable name']=='rez_esc'])\nprint('----------------------------------')\nprint(codebook[codebook['Variable name']=='v18q1'])\nprint('----------------------------------')\nprint(codebook[codebook['Variable name']=='v2a1'])\nprint('----------------------------------')\nprint(codebook[codebook['Variable name']=='meaneduc'])\nprint('----------------------------------')\nprint(codebook[codebook['Variable name']=='SQBmeaned'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.v18q1.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rez_esc.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.v2a1.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.meaneduc.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.SQBmeaned.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* A variável v18q1 (number of tablets household owns) não possui em seus valores distintos o 0, o que leva a crer que os valores missings presentes são de casas que não possuem tabletes - Candidata a imputação de dados\n* A variável rez_esc  (Years behind in school) Possui 0 em seus valores distintos, o que leva a crer que são realmente dados faltantes. - Por representar mais de 50% da base de valores nulos, utilizaremos o número -1 nos valores nulos.\n* A variável v2a1  (Monthly rent payment) só é preenchida em caso de casas alugadas, para isso utilizaremos o número -1 nos valores nulos\n* A variável meaneduc (average years of education for adults (18+)) é candidata a ter seus valores nulos substituidos pela mediana","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#realizando a imputação e dropando coluna\ndf['v2a1'].fillna(-1, inplace=True)\ndf['v18q1'].fillna(0, inplace=True)\ndf['SQBmeaned'].fillna(-1, inplace=True)\ndf['rez_esc'].fillna(-1, inplace=True)\ndf.meaneduc.fillna(df.meaneduc.median(), inplace=True)\n## realizando o drop de outras colunas que assim como SQBmeaned são provenientes de outras\n# df.drop(['SQBescolari'], axis=1, inplace=True)\n# df.drop(['SQBage'], axis=1, inplace=True)\n# df.drop(['SQBhogar_total'], axis=1, inplace=True)\n# df.drop(['SQBedjefe'], axis=1, inplace=True)\n# df.drop(['SQBhogar_nin'], axis=1, inplace=True)\n# df.drop(['SQBovercrowding'], axis=1, inplace=True)\n# df.drop(['SQBdependency'], axis=1, inplace=True)\n# df.drop(['agesq'], axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum().sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##verificando se existem colunas do tipo objeto\ndf.select_dtypes('object').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dependency.value_counts().head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.edjefe.value_counts().head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.edjefa.value_counts().head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#realizando um replace\nvalores_replace = {'yes': 1, 'no': 0}\n#df.drop(['Id'], axis=1, inplace=True)\n#df.drop(['idhogar'], axis=1, inplace=True)\ndf['dependency'] = df['dependency'].replace(valores_replace).astype(float)\ndf['edjefe'] = df['edjefe'].replace(valores_replace).astype(int)\ndf['edjefa'] = df['edjefa'].replace(valores_replace).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## verificando a correlação entre as variáveis e a Target\n\ndf[df['Target'].notnull()].corr()['Target'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As variáveis que obtiveram as maiores correlações positivas foram meaneduc, cielorazo, escolari. meaneduc e escolari são variáveis voltadas ao tempo de educação dos moradores, já cielorazo se a casa possui teto. \n* Já as variáveis que obtiveram as maiores correlações negativas foram hogar_nin, r4t1, overcrowding. hogar_nin informa a quantidade de crianças presentes na casa, ou seja, se você deseja possuir uma boa casa, não tenha filhos. r4t1 são pessoas mais jovens de 12 anos e overcrowding são quantidade de pessoas por quarto.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# > Feature engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## após a criação das colunas ocorreu uma leve melhoria no score, as colunas comentadas foram testadas e diminuiram o score geral.\n\n#df[\"telperpessoa\"]=df[\"qmobilephone\"]/df[\"tamviv\"]\ndf[\"m2perpessoa\"]=df[\"tamhog\"]/df[\"tamviv\"]\n# df['tabletsperpessoa'] = df['v18q1'] / df['tamviv']\n# df['roomsperpessoa'] = df['rooms'] / df['tamviv']\ndf['rentperpessoa'] = df['v2a1'] / df['tamviv']\n# df['hsizeperpessoa'] = df['hhsize'] / df['tamviv']\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. # > Análisando os dados","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## média de aluguel paga por quantidade de quartos \ndf[df['tipovivi3']==1].groupby(['rooms'])['v2a1'].mean().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df['v2a1'].value_counts.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## quantidade de moradias com teto (1) e sem teto (0)\ndf.groupby(['cielorazo'])['idhogar'].nunique().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## porcentagem de moradias sem teto\nprint(round(df[df['cielorazo']==0]['idhogar'].nunique()/df[df['cielorazo']==1]['idhogar'].nunique()*100,2),'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#abastaguano\nplt.figure(figsize=(15,9))\nfig, axes = plt.subplots(nrows=2, ncols=2)\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.3)\nfig.suptitle('0 (possuem) 1 (não possuem)')\n\nax=axes[0,0].title.set_text('Distribuição água.')\nax=axes[0,1].title.set_text('Distribuição energia.')\nax=axes[1,0].title.set_text('Possui Sanitario.')\nax=axes[1,1].title.set_text('Possui piso.')\n\ndf.groupby(['abastaguano'])['idhogar'].nunique().plot(kind='bar',ax=axes[0,0])\ndf.groupby(['noelec'])['idhogar'].nunique().plot(kind='bar',ax=axes[0,1])\ndf.groupby(['pisonotiene'])['idhogar'].nunique().plot(kind='bar',ax=axes[1,0])\ndf.groupby(['sanitario1'])['idhogar'].nunique().plot(kind='bar',ax=axes[1,1])\n\nquantidade = mpatches.Patch(label='Quantidade')\nplt.legend(fancybox=True, framealpha=1,handles=[quantidade] ,shadow=True, borderpad=1 )\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint('** Métodos de se jogar lixo fora **')\nprint('Tanker truck:',df[df['elimbasu1']==1].groupby(['elimbasu1'])['idhogar'].nunique().iloc[0])\nprint('Botan hollow or buried:',df[df['elimbasu2']==1].groupby(['elimbasu2'])['idhogar'].nunique().iloc[0])\nprint('Burning:',df[df['elimbasu3']==1].groupby(['elimbasu3'])['idhogar'].nunique().iloc[0])\nprint('Throwing in an unoccupied space:',df[df['elimbasu4']==1].groupby(['elimbasu4'])['idhogar'].nunique().iloc[0])\nprint('Throwing in river,  creek or sea:',df[df['elimbasu5']==1].groupby(['elimbasu5'])['idhogar'].nunique().iloc[0])\nprint('Other:',df[df['elimbasu6']==1].groupby(['elimbasu6'])['idhogar'].nunique().iloc[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## zonas de moradia\nrural = round(df[df['area2']==1].groupby(['area2'])['idhogar'].nunique().iloc[0]/df[df['area1']==1].groupby(['area1'])['idhogar'].nunique().iloc[0],2)\nurbana = 1-rural\nplt.figure(figsize=(15,9))\nlabels = [r'Urbana('+str(urbana)+')', r'Rural ('+str(rural)+')']\nsizes = [88.4, 10.6, 0.7, 0.3]\ncolors = ['orange', 'blue']\npatches, texts = plt.pie(sizes, colors=colors, startangle=90)\nplt.legend(patches, labels, loc=\"best\")\nplt.pie(df.groupby('area1')['idhogar'].nunique())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## contando a quantidade de lideres de familia masculinos e femininos\nprint('quantidade de lideres de família homens:',df[(df['parentesco1']==1) & (df['male']==1)].shape[0])\nprint('quantidade de lideres de família mulheres:',df[(df['parentesco1']==1) & (df['female']==1)].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## verificando a distribuição da classe a ser predita\ndf[df['Target'].notnull()].groupby(['Target'])['idhogar'].nunique().plot(kind='bar', title='1 = extreme poverty 2 = moderate poverty 3 = vulnerable households 4 = non vulnerable households')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. # > Treinando modelo 0.36746 (Submissão Kaggle)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## separando datasets em treino e teste para aplicação no modelo\nfeats = [c for c in df.columns if c not in ['Id', 'idhogar', 'Target']]\ntrain, test = df[~df['Target'].isnull()], df[df['Target'].isnull()]\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Criando vários parâmetros  afim de buscar o melhor caso\nparam_grid = {\n    'criterion' : ['gini', 'entropy'],\n    'class_weight' : ['balanced','balanced_subsample'],\n     'n_estimators': [100, 200, 300, 400]\n }\nrf = RandomForestClassifier()\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                         cv = 3, n_jobs = -1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## comentado para não rodar toda vez já que demora mais de 10 minutos\n# grid_search.fit(train[feats], train['Target'])\n# grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## mesmo após aplicar o grid_search, o resultado ainda não ficou melhor que apenas com o n_estimators 200, por isso foi mantido ele.\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200 ,random_state=42)\nrf.fit(train[feats], train['Target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## realizando a predição de valores\ntest['Target'] = rf.predict(test[feats]).astype(int)\n## Demonstrando a importância das variáveis e seus nomes \nprint(rf.feature_importances_)\nprint(train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribuição da variável \ntest['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(rf.feature_importances_, index=feats).sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skplt.metrics.plot_confusion_matrix(train['Target'], rf.predict(train[feats])) ## Matriz de confusão\naccuracy_score(train['Target'], rf.predict(train[feats])) ## score do modelo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O modelo acertou 100% dos dados colocados de treinamento, demonstrando claramente um overfit","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o arquivo para submissão\ntest[['Id', 'Target']].to_csv('submission1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# > Treinamento apenas com chefe de família RandomForest alcançou 0.43912 (Submissão Kaggle)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## pegando chefe de família\nheads2 = train[train['parentesco1'] == 1]\n## treinando modelo\n# max_depth : profundidade de árvore, utilizando none para ir expandido até todas estarem puras\n# n_jobs : quantidade de tarefas rodando em paralelo\n# n_estimators : quantidade de árvores na floresta, 700 foi o melhor valor entre os testados\n# min_impurity_decrease : o nó vai se dividir se a impureza da divisão for maior ou igual ao valor utilizado\n# min_samples_leaf : quantidade minima de amostras para ser considerado um nó folha\n# verbose : demonstrar menos informações na hora de rodar o modelo\n# class_weight : Foi utilizado balanced, balanceando o peso das classes\n#\n#\nrf4 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\nrf4.fit(heads2[feats], heads2['Target'])\n## predizendo\ntest['Target'] = rf4.predict(test[feats]).astype(int)\n# criando arquivo\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skplt.metrics.plot_confusion_matrix(heads2['Target'], rf4.predict(heads2[feats])) ## Matriz de confusão\naccuracy_score(heads2['Target'], rf4.predict(heads2[feats])) ## Score do modelo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Diferentemente do primeiro modelo, esse modelo que foi o que alcançou o melhor resultado dentre todos do trabalho, não acertou 100% das predições do modelo de treino, demonstrando que a escolha de pegar apenas chefe de familia, e o tratamento dos parâmetros, realmente melhoraram o modelo","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# > Treinamento Chefe de família com XGBoost utilizando os mesmos parâmetros do RandomForest alcançou 0.40326 (Submissão Kaggle)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\nxgb.fit(heads2[feats], heads2['Target'])\ntest['Target'] = xgb.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission2.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skplt.metrics.plot_confusion_matrix(heads2['Target'], xgb.predict(heads2[feats])) ## Matriz de confusão\naccuracy_score(heads2['Target'], xgb.predict(heads2[feats])) ## Score do modelo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Utilizando os mesmos parâmetros do melhor modelo, o XGBoost também alcançou 100% de acerto nos scores, demonstrando comportamento de um modelo com overfit","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# > Treinamento Chefe de família com ADABoost alcançou 0.37155 (Submissão Kaggle)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## learning_rate : controla quanto vai ser a contribuição para o novo modelo, utilizando o atual\nabc = AdaBoostClassifier(random_state=42, n_estimators=700,learning_rate=1.0)\nabc.fit(heads2[feats], heads2['Target'])\ntest['Target'] = abc.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skplt.metrics.plot_confusion_matrix(heads2['Target'], abc.predict(heads2[feats])) ## Matriz de confusão\naccuracy_score(heads2['Target'], abc.predict(heads2[feats])) ## Score do modelo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O ADABoost alcançou aproximadamente 65% de score, é importante observar que existe uma grande dispersão na matriz de confusão, com os acertos 4 representando a maior parte dentro o score obtido. Isso mostra que esse modelo tem facilida apenas para acertar resultados 4.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# > Cross Validation avaliando modelo, utilizando o melhor resultado que foi RandomForest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando um modelo de RF Classifier e usando o Cross Validation\nrfc = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\nscores = cross_val_score(rfc, heads2[feats], heads2['Target'], cv=5, n_jobs=-1)\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# a média do Cross Validation deu 0.59, bem acima do melhor score após submeter o código ao Kaggle que foi de 0.43912. De todos os modelos aplicados, o RandomForest com os parâmetros escolhidos foi o que alcançou o maior score. XGBoost vem logo atrás com 0.40326, e o ADABoost na última posição com 0.37155.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# > Balanceamento Over-Sampling 0.43312 (Submissão Kaggle melhor modelo) 0.40099 (Submissão Kaggle primeiro modelo do trabalho)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Target'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = train[train['Target'] == 1]\ndf_2 = train[train['Target'] == 2]\ndf_3 = train[train['Target'] == 3]\ndf_4 = train[train['Target'] == 4]\ndf_1.shape,df_2.shape,df_3.shape,df_4.shape,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## aumentando as classes menores até igualar a quantidade com df_4\n\ndf_1 = resample(df_1, \n                       replace=True,\n                       n_samples=len(df_4),\n                       random_state=42)\n\ndf_2 = resample(df_2, \n                       replace=True,\n                       n_samples=len(df_4),\n                       random_state=42)\n\ndf_3 = resample(df_3, \n                       replace=True,\n                       n_samples=len(df_4),\n                       random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1.shape,df_2.shape,df_3.shape,df_4.shape,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## juntando as 4 tabelas\ntrain = pd.concat([df_1, df_2, df_3, df_4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## aplicando o mesmo treinamento que alcançou o maior score\nheads2 = train[train['parentesco1'] == 1]\nrf4 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\nrf4.fit(heads2[feats], heads2['Target'])\n## predizendo\ntest['Target'] = rf4.predict(test[feats]).astype(int)\n# criando arquivo\ntest[['Id', 'Target']].to_csv('submission4.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skplt.metrics.plot_confusion_matrix(heads2['Target'], rf4.predict(heads2[feats])) ## Matriz de confusão\naccuracy_score(heads2['Target'], rf4.predict(heads2[feats])) ## Score do modelo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Após o balanceamento, e a aplicação dos mesmos parâmetros utilizados no melhor modelo, a matriz de confusão demonstra um resultado de 86% de acerto. Esse resultado se encontra um pouco acima dos 84% de acerto do melhor modelo.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## verificando a melhoria do primeiro modelo do testo, após aplicação de balanceamento \nrf4 = RandomForestClassifier(n_jobs=-1, n_estimators=200 ,random_state=42)\nrf4.fit(heads2[feats], heads2['Target'])\n## predizendo\ntest['Target'] = rf4.predict(test[feats]).astype(int)\n# criando arquivo\ntest[['Id', 'Target']].to_csv('submission5.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skplt.metrics.plot_confusion_matrix(heads2['Target'], rf4.predict(heads2[feats])) ## Matriz de confusão\naccuracy_score(heads2['Target'], rf4.predict(heads2[feats])) ## Score do modelo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O balanceamento da classe target não alterou os 100% de acerto do primeiro modelo, ainda apresentando características de um modelo com overfit. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# O balancemento da classe Target embora tenha melhorado o resultado do primeiro modelo realizando no trabalho, acabou diminuindo em  aproximadamente 0.006 o modelo que obteve o melhore score. Isso demonstra uma certa importância do balanceamento no modelo inicial e que uma possível alteraçao nos parâmetros passados na hora do treinamento do modelo com maior score, pode elevar mais ainda o score obtido.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Conclusão:\n\n* Logo no início do trabalho foi realizado a limpeza e visualizações de determinadas variáveis existentes, a fim de ter uma melhor compreensão do dataset como um todo. Também foi realizada a criação de diversas colunas novas, e testadas 1 a 1, buscando a combinação que mais contribuia para um score positivo.\n\n* Após essa etapa, foi realizado o treinamento dos modelo, assim observando a importância de se aplicar diversos modelos e parâmetros diferentes. Durante o treinamento e predição dos modelos de treino, diversos modelos alcançaram 100% de acertos, causando overfit desses modelos, já o modelo que se saiu melhor na submissão do kaggle, foi o modelo que alcançou 84% de acerto, nesse modelo foi utilizado diversos parâmetros presentes no RandomForest que ao longo do trabalho foram modificados diversas vezes a fim de escontrar melhores combinações.\n\n* O estudo de diferentes modelos e suas infinidades de parâmetros, é de extrema importância, e considero essa a parte de maior dificuldade do trabalho. Entender quais os melhores modelos e parâmetros para determinado treinamento exige muito estudo e experiência. Por isso durante o trabalho o ambiente do Kaggle foi de grande ajuda, proporcionando a visualização de código de outras pessoas, facilitando assim o entendimento de passos, modelos e parâmetros utilizados.\n\n* A etapa de tratamento também foi um desafio, diversos testes foram realizados, desde o drop de colunas, até a imputação por média,mediana ou valores bem distintos, como -1. Ao fim a imputação de -1 nos modelos foi a que obteve melhores resultados durante o modelo, por isso parte do trabalho foi comentada ou apagada, utilizando apenas o tratamento com melhores resultados.\n\nEsse trabalho demonstrou a importância de se realizar diversos testes e mudanças ao longo de todo o processo, e só reforçou a afirmação da não existência de um tipo especifico de pré-processamento e treinamento que sirva para todos os casos\n\nobs : o melhor modelo é o único que gera o arquivo submission.csv, que é o único que pode ser rodado pelo Kaggle","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}