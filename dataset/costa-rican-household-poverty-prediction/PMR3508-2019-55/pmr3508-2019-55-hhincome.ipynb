{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = \"../input/costa-rican-household-poverty-prediction/train.csv\"\ntest_data = \"../input/costa-rican-household-poverty-prediction/test.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Intro\nSince it should be an analysis by household: grouping by the household id"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.groupby('idhogar').first()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So much smaller, let's start exploring the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attributes = list(train_df)\nattributes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ntrain_df = train_df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above info, we see that applying dropna() directly to the raw data it is left with few rows, since the amount of data is not great we need to analyze and see which collumns have missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"na_per_column = train_df.isna().sum()\nna_per_column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the output above we can filter the collumns with missing data and see which one have too many, therefore should be discarded\n\nGetting the indexes of the columns with missing data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"nan_indexes = na_per_column.nonzero()\nnan_indexes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the collumn names and the respectives amount of missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"na_per_column[nan_indexes[0]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the data field description:\n\nv2a1, Monthly rent payment\n\nv18q1, number of tablets household owns\n\nrez_esc, Years behind in school\n\nmeaneduc,average years of education for adults (18+)\n\nSQBmeaned, square of the mean years of education of adults (>=18) in the household"},{"metadata":{},"cell_type":"markdown","source":"### Dealing with missing data\nAnalizying the missing data variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['v2a1','v18q1','rez_esc','meaneduc','SQBmeaned']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the analysis above, for 'v18q1' we can infer that the missing data are household with 0 tablets, and for 'meaneduc' and 'SQB meaned' we can use the standard value."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['v18q1'] = train_df['v18q1'].fillna(0)\ntrain_df['meaneduc'] = train_df['meaneduc'].fillna(4)\ntrain_df['SQBmeaned'] = train_df['SQBmeaned'].fillna(97)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['v18q1','meaneduc','SQBmeaned']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_per_column = train_df.isna().sum()\nnan_indexes = na_per_column.nonzero()\nna_per_column[nan_indexes[0]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"cleared the nan values"},{"metadata":{},"cell_type":"markdown","source":"### Dealing with binary columns\nIn this database we have many columns with binary data, only to express whether an attribute is present or not in the household, therefore let's combine those columns into a single one according to its characteristic, taking the walls attribute as an example"},{"metadata":{"trusted":true},"cell_type":"code","source":"wall_col = ['paredblolad','paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc','paredfibras', 'paredother']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def join_binary_columns(df, cols, new_column_label):\n    df[new_column_label] = df[cols[0]]\n    for i in range(1,len(cols)):\n        df[new_column_label] = df[new_column_label] + df[cols[i]]*(2**i)\n    return df.drop(columns = cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = join_binary_columns(train_df, wall_col, 'wall')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['wall'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['wall'].value_counts().plot(kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying this transformation to the other many binary decomposed variables:\n- Floor\n- Roof\n- Water provision\n- Electricity\n- Toilet\n- Energy cooking\n- Rubbish disposal\n- quality of walls\n- quality of roof\n- quality of floor\n- State of house\n- location of house"},{"metadata":{"trusted":true},"cell_type":"code","source":"floor_col = ['pisonotiene', 'pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisomadera']\nroof_col = ['techozinc', 'techoentrepiso', 'techocane', 'techootro']\nwater_col = ['abastaguadentro', 'abastaguafuera', 'abastaguano']\nelectricity_col = ['public', 'planpri', 'noelec', 'coopele']\ntoilet_col = ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']\nenergy_col = ['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']\nrubbish_col = ['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']\nqua_wall_col = ['epared1', 'epared2', 'epared3']\nqua_roof_col = ['etecho1', 'etecho2', 'etecho3']\nqua_floor_col = ['eviv1', 'eviv2', 'eviv3']\nhouse_state_col = ['tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5']\nlocation_col = ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']\narea_col = ['area1', 'area2']\n# some social variables aggregation that maybe useful to refine training (not used in this notebook)\n# males_col = ['r4h1', 'r4h2', 'r4h3']\n# females_col = ['r4m1', 'r4m2', 'r4m3']\n# person_col = ['r4t1', 'r4t2', 'r4t3']\n# civil_state_col = ['estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7']\n# family_col = ['parentesco1', 'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = join_binary_columns(train_df, floor_col, 'floor')\ntrain_df = join_binary_columns(train_df, roof_col, 'roof')\ntrain_df = join_binary_columns(train_df, water_col, 'water')\ntrain_df = join_binary_columns(train_df, electricity_col, 'electricity')\ntrain_df = join_binary_columns(train_df, toilet_col, 'toilet')\ntrain_df = join_binary_columns(train_df, energy_col, 'energy')\ntrain_df = join_binary_columns(train_df, rubbish_col, 'rubbish')\ntrain_df = join_binary_columns(train_df, qua_wall_col, 'qua_wall')\ntrain_df = join_binary_columns(train_df, qua_roof_col, 'qua_roof')\ntrain_df = join_binary_columns(train_df, qua_floor_col, 'qua_roof')\ntrain_df = join_binary_columns(train_df, house_state_col, 'house_state')\ntrain_df = join_binary_columns(train_df, location_col, 'location')\ntrain_df = join_binary_columns(train_df, area_col, 'area')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data analysis\nAfter filtering and managing the data, we can start doing some analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Target\"].value_counts().plot(kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attributes = list(train_df)\nattributes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_columns = ['v2a1', 'rez_esc']\ntrain_df = train_df.drop(columns = ['v2a1', 'rez_esc'])\nattributes.remove('Target')\nattributes.remove('Id')\nfor e in drop_columns:\n    attributes.remove(e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still, many variables, let's just see the correlation between the variables and output"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_df[attributes].apply(preprocessing.LabelEncoder().fit_transform).apply(lambda x: x.corr(train_df.Target))\ncorr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filtering with the best correlation we can find"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_thresh = 0.2\ncorr.where(abs(corr) > corr_thresh).dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_attr = corr.where(abs(corr) > corr_thresh).dropna().index.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_attr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_x = train_df[train_attr].apply(preprocessing.LabelEncoder().fit_transform)\ntrain_df_y = train_df.Target","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying the same data preparation to test dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(test_data)\ntest_df['v18q1'] = test_df['v18q1'].fillna(0)\ntest_df['meaneduc'] = test_df['meaneduc'].fillna(4)\ntest_df['SQBmeaned'] = test_df['SQBmeaned'].fillna(97)\ntest_df = join_binary_columns(test_df, wall_col, 'wall')\ntest_df = join_binary_columns(test_df, floor_col, 'floor')\ntest_df = join_binary_columns(test_df, roof_col, 'roof')\ntest_df = join_binary_columns(test_df, water_col, 'water')\ntest_df = join_binary_columns(test_df, electricity_col, 'electricity')\ntest_df = join_binary_columns(test_df, toilet_col, 'toilet')\ntest_df = join_binary_columns(test_df, energy_col, 'energy')\ntest_df = join_binary_columns(test_df, rubbish_col, 'rubbish')\ntest_df = join_binary_columns(test_df, qua_wall_col, 'qua_wall')\ntest_df = join_binary_columns(test_df, qua_roof_col, 'qua_roof')\ntest_df = join_binary_columns(test_df, qua_floor_col, 'qua_roof')\ntest_df = join_binary_columns(test_df, house_state_col, 'house_state')\ntest_df = join_binary_columns(test_df, location_col, 'location')\ntest_df = join_binary_columns(test_df, area_col, 'area')\ntest_df_x = test_df[train_attr].apply(preprocessing.LabelEncoder().fit_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['neighbors', 'scores']\nresults = [columns]\nfor n in range (5, 40):\n    neighbors = n\n    cross = 5\n    knn = KNeighborsClassifier(n_neighbors = neighbors)\n    scores = cross_val_score(knn, train_df_x, train_df_y, cv = cross)\n    results.append([neighbors, scores])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics as st\n\nanalysis = [['neighbors', 'mean', 'max', 'min']]\nfor i in range(1, len(results)):\n    analysis.append([results[i][0], st.mean(results[i][1]), max(results[i][1]), min(results[i][1])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbors = 32\ncross = 5\nKNeighborsClassifier(n_neighbors = neighbors)\ncross_val_score(knn, train_df_x, train_df_y, cv = cross)\nknn.fit(train_df_x, train_df_y)\ntest_pred_y = knn.predict(test_df_x)\ntest_pred_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame({'Id':test_df.Id.values, 'Target':test_pred_y})\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}