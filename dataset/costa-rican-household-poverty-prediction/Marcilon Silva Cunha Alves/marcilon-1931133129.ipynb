{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IESB - Trabalho final - Data Mining e Machine Learning II\n## Marcilon Silva Cunha Alves \n## Matricula: 1931133129\n\n# Previsão da situação de pobreza Costa-Riquenha\n\nO Banco Interamericano de Desenvolvimento está pedindo à comunidade Kaggle ajuda com a qualificação de renda para algumas das famílias mais pobres do mundo. \n\nNa América Latina, um método popular usa um algoritmo para verificar a qualificação de renda. É chamado de Teste de Média de Proxy (ou PMT). Com a PMT, as agências usam um modelo que considera os atributos domésticos observáveis de uma família, como o material das paredes e do teto, ou os ativos encontrados na casa para classificá-los e prever seu nível de necessidade.\n\nPara melhorar a PMT, o BID (a maior fonte de financiamento para o desenvolvimento da América Latina e do Caribe) recorreu à comunidade Kaggle. Eles acreditam que novos métodos além da econometria tradicional, com base em um conjunto de dados de características domésticas da Costa Rica, podem ajudar a melhorar o desempenho do PMT.\n\nAlém da Costa Rica, muitos países enfrentam o mesmo problema de avaliar incorretamente as necessidades sociais. Se Kagglers puder gerar uma melhoria, o novo algoritmo pode ser implementado em outros países ao redor do mundo.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Carregar e ler dados\n\n* Importanto das bibliotecas necessárias\n* Listando os arquivos de banco de dados disponível no diretório input","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Carregando os dados de treino e de teste","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\n\ndf.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Juntando os dataframes df (treino) e test (teste)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = df.append(test)\n\ndf_all.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análise exploratória e tratamento de dados\n\n* Estatísticas básicas\n* Verificar mínimos e máximos para garantir se estão dentro dos limites esperados\n* Verificar intervalo de variação da medida\n* Verificar possíveis outliers","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Analisando a variável TARGET com a base de dados Train.\n\nOs valores Target representam os níveis de pobreza da seguinte forma:\n\n1 = pobreza extrema;\n\n2 = pobreza moderada;\n\n3 = famílias vulneráveis;\n\n4 = famílias não vulneráveis;\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Target'].hist(grid = False, bins = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Target.value_counts()/100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Verificar os principais indicadores descritivos","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Verificando quais colunas do dataframe são do tipo object","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Observando os dados da coluna edjefa\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['edjefa'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Transformando 'yes' em 1 e 'no' em 0\n* Para as colunas edjefa e edjefe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Observando as colunas do dataframe que são do tipo object","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Obserando a coluna dependency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Transformando 'yes' em 1 e 'no' em 0\n* Para a coluna dependency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Observando quais colunas do dataframe são do tipo object","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Analisando os valores nulos de cada variável","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_na = df_all.isnull().sum().values / df_all.shape[0] *100\ndf_na = pd.DataFrame(data_na, index=df_all.columns, columns=['Count'])\ndf_na = df_na.sort_values(by=['Count'], ascending=False)\n\nmissing_value_count = df_na[df_na['Count']>0].shape[0]\n\nprint(f'We got {missing_value_count} rows which have missing value in train set ')\ndf_na.head(6)\n\n# rez_esc represents \"years behind in school\", missing value could be filled as 0\n# meaneduc represents \"average years of education for adults (18+)\", missing value could be filled as 0\n# v18q1 really depends on v18q\n# v2a1 depends on tipovivi3\n# We do not really need SQBxxxx features for polynomial in our case, and i will use fillna as 0 after at the last step of feature engineering\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Analisando os valores de aluguel (v2a1) para os chefes/as de familia (parentesco1 = 1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Analizando os dados de variável v18q","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['v18q'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Prenchendo com \"0\" os valores nulos de: v2a1, v18q1 e rez_esc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['v2a1'].fillna(0, inplace=True)\ndf_all['v18q1'].fillna(0, inplace=True)\ndf_all['rez_esc'].fillna(0, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Plotanto v2a1 e analisando distribuição","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['v2a1'].hist(grid = False, bins = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Plotanto v18q1 e analisando distribuição","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['v18q1'].hist(grid = False, bins = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Analizando os principais indicadores para meaneduc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.meaneduc.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Analizando os principais indicadores para SQBmeaned","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.SQBmeaned.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Prenchendo com a Mediana os valores nulos de: meaneduc e SQBmeaned","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_all.loc[df_all.meaneduc.isnull(), \"meaneduc\"] = 0\n#df_all.loc[df_all.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n\ndf_all['meaneduc'].fillna(df_all['meaneduc'].median(), inplace=True) \ndf_all['SQBmeaned'].fillna(df_all['SQBmeaned'].median(), inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Plotanto meaneduc e analisando distribuição","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['meaneduc'].hist(grid = False, bins = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Plotanto SQBmeaned e analisando distribuição","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['SQBmeaned'].hist(grid = False, bins = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Verificando quais variáveis ainda possuem nulos","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Prenchendo com \"-1\" os valores nulos ainda existentes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.fillna(-1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Feature Engineering\n\n* Criando novas colunas para valores percapita","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['hsize-pc'] = df_all['hhsize'] / df_all['tamviv']\ndf_all['phone-pc'] = df_all['qmobilephone'] / df_all['tamviv']\ndf_all['tablets-pc'] = df_all['v18q1'] / df_all['tamviv']\ndf_all['rooms-pc'] = df_all['rooms'] / df_all['tamviv']\ndf_all['rent-pc'] = df_all['v2a1'] / df_all['tamviv']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Plotando a Matrix de correlação","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport seaborn as sns\n\nvariables = ['Target', 'dependency', 'v2a1', 'v18q1', 'rez_esc', 'meaneduc' ,'SQBmeaned']\n\n# Calculate the correlations\ncorr_mat = df_all[variables].corr().round(2)\n\n# Draw a correlation heatmap\nplt.rcParams['font.size'] = 12\nplt.figure(figsize = (12, 12))\nsns.heatmap(corr_mat, vmin = -0.5, vmax = 0.8, center = 0, \n            cmap = plt.cm.RdYlBu, annot = True);\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Separando as colunas para treinamento","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Separando os dataframes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = df_all[df_all['Target'] != -1], df_all[df_all['Target'] == -1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embora todos os membros de uma família devam ter o mesmo rótulo nos dados de treinamento, existem erros onde os indivíduos na mesma casa têm rótulos diferentes. Nestes casos, somos orientados a usar o rótulo do chefe de cada família, que pode ser identificado pelas linhas onde parentesco1 == 1.0. \n\n* Limitando o treinamento ao chefe da familia\n* Criando um novo dataframe para treinar","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"heads = train[train['parentesco1'] == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODELOS\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## LightGBM\n\n* Instanciando o LightGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n#parameter value is copied from \nclf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n                             random_state=None, silent=True, metric='None', \n                             n_jobs=4, n_estimators=700, class_weight='balanced',\n                             colsample_bytree =  0.93, min_child_samples = 95, num_leaves = 14, subsample = 0.96)\n\n\nclf.fit(heads[feats], heads['Target'])\n\naccuracy_score(heads['Target'], clf.predict(heads[feats]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Target'] = clf.predict(test[feats]).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#test[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CatBoostClassifier\n\n* Instanciando o CBC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com CatBoost\nfrom catboost import CatBoostClassifier\ncbc = CatBoostClassifier(random_state=42)\ncbc.fit(heads[feats], heads['Target'])\naccuracy_score(test['Target'], cbc.predict(test[feats]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Target'] = cbc.predict(test[feats]).astype(int)\ntest['Target'].value_counts(normalize=True)\n#test[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(15, 20))\n\npd.Series(cbc.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RandomForestClassifier\n\n* Instanciando o random forest classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nrf = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Treinando o modelo RandomForestClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(heads[feats], heads['Target'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Prevendo o Target de teste usando o modelo treinado","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Target'] = rf.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Analisando as previsões para o Target","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Target'].value_counts(normalize=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(heads['Target'], rf.predict(heads[feats]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Criando o arquivo para submissão","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['Id', 'Target']].to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Plotando e avalisando a importância de cada coluna (cada variável de entrada)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(15, 20))\n\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.figure(figsize = (10, 10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, size = 18)\n    plt.colorbar(aspect=4)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45, size = 12)\n    plt.yticks(tick_marks, classes, size = 12)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    \n    # Labeling the plot\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), fontsize = 16,\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.grid(None)\n    plt.tight_layout()\n    plt.ylabel('True label', size = 12)\n    plt.xlabel('Predicted label', size = 12)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    cm = confusion_matrix(heads['Target'], rf.predict(heads[feats]))\n\n    plot_confusion_matrix(cm, classes = ['Extreme', 'Moderate', 'Vulnerable', 'Non-Vulnerable'],\n                      title = 'Poverty Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusão\n\nEsse desafio foi de grande proveito para a prática dos conhecimentos adquiridos, pois foi possível aplicar uma solução completa de ciência de dados para um problema do mundo real. \n\nCaminho percorrido para chegar nessa solução:\n* Entendimento do desafio;\n* Análise Exploratória de Dados;\n* Análise dos dados com problemas e pesquisa de soluções propostas nos fóruns de discussões;\n* Preenchimento dos valores ausentes utilizando técnicas de input;\n* Criação de novas feactures;\n* Experimento de modelos diferentes para verificar qual apresentava melhor score;\n\nApós aplicação dos modelos foi possível analisar os resultados, principalmente quais variáveis mais influenciavam nos resultados. \n\nCom isso foi possível efetuar novas tentativas com inputs diferenciados para essas variáveis em questão, ação essa que melhorou significativamente os resultados obtidos.\n\n### RESULTADOS\n\nModelo LightGBM\n* Score: 0.37500\n\nModelo CatBoostClassifier\n* Score: 0.37500\n\nModelo RandomForestClassifier\n* Score: 0.44117\n\nA parte mais valiosa do trabalho proposto foi o conhecimento prático adquirido com a utilização e participação efetiva nas competições do Kaggle. Foi ótimo desenvolver soluções realistas como um cientista de dados. \n\n\nMarcilon Cunha.\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}