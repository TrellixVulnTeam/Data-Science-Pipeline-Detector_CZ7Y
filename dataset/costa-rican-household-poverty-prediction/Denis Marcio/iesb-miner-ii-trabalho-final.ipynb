{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IESB - Miner II - Trabalho Final\n* Objetivo: elaborar modelo preditivo em Python para prever o nível de pobreza de chefes de família da Costa Rica, a partir de base de dados disponibilizada no Kaggle\n* Conteúdo:\n* * Análise exploratória dos dados\n* * Pré-processamento dos dados\n* * Aplicação de técnicas de tratamento de classes desbalanceadas \n* * Avaliação dos melhores algoritmos de classificação, usando base de validação\n* * Aplicação dos melhores algoritmos na base de teste\n* * Submissão dos resultados ao Kaggle"},{"metadata":{},"cell_type":"markdown","source":"# Bibliotecas"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils import resample\n\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Carregando os dados"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ndf_test = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando dados de treino e teste\ndf_all = df_train.append(df_test)\ndf_all.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Considerações iniciais\n- Cada linha representa uma pessoa\n- Múltiplas pessoas podem fazer parte de uma única residência\n- Mais de uma família pode viver na mesma casa\n- A previsão deve se dar apenas para os chefes de família "},{"metadata":{},"cell_type":"markdown","source":"# Análise Exploratória / Pré-processamento dos dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tamanhos das bases de treino e teste\n# O número de dados de treino é menor que os dados de teste\n# Em tese, essa característica torna o trabalho de classificação mais difícil\ndf_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Informações do dataset \n# 9 variáveis float, 129 inteiras e 5 object\ndf_all.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tratamento das Variáveis Object"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Variáveis do tipo 'object': Id, idhogar, dependency, edjefe, edjefa\n# Id e idhogar são identificadores de pessoa e casa - ok\n# dependency, edjefe, edjefa requerem tratamento\ndf_all.select_dtypes('object').head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variáveis edjefe e edjefa\n* Anos de escolaridade do chefe / da chefe de família \n* Do dicionário de dados, yes=1 e no=0 => basta fazer a substituição"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Substituindo 'yes' e 'no'\nyes_no_map = {'no': 0, 'yes': 1}\n\ndf_all['edjefe'] = df_all['edjefe'].replace(yes_no_map).astype(np.float32)\ndf_all['edjefa'] = df_all['edjefa'].replace(yes_no_map).astype(np.float32)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variável dependency\n* Taxa de dependência: (membros da família  potencialmente dependentes) / (número de trabalahadores potencialmente ativos)\n* Fórmula: (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Os valores 0 e 1 não estão na lista acima, confirmando que a regra 'yes'=1 e 'no'=0 se aplica\n# É feita a substituição:\ndf_all['dependency'] = df_all['dependency'].replace(yes_no_map).astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confirmando os resultados\n# => não existem outras variáveis do tipo object após os tratamentos, às exceções dos identificadores de pessoa (Id) e casa (idhogar)\ndf_all.select_dtypes('object').head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tratamento dos Valores Ausentes "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do resultado, as variáveis com valores nulos são: rez_esc, v18q1, v2a1, SQBmeaned, meaneduc\n# os valores nulos da variável Target se referem aos dados de teste => comportamento esperado\ndf_all.isnull().sum().sort_values(ascending=False).head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Uma visualização mais sofisticada....\n\ndf_all_null = df_all.isnull().sum()\n\n# filtra apenas as variáveis que contêm valores nulos, representadas com relação ao total\ndf_all_null_non_zero = (df_all_null[df_all_null>0] / df_all.shape[0]).sort_values(ascending=False)\n\nsns.barplot(x=df_all_null_non_zero, y=df_all_null_non_zero.index)\n_ = plt.title('Percentual de Valores Nulos')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variável rez_esc\n* Anos atrasados na escola"},{"metadata":{"trusted":true},"cell_type":"code","source":"# O valor zero (0) é presente no dados => não é possível aplicar uma regra de negócio específica\ndf_all['rez_esc'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Investigação do outlier 99 (valor máximo verificado no describe)\ndf_all['rez_esc'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apenas uma ocorrência deste outlier, provavelmente um erro de alimentação de dados\n# este será substituído pelo pior valor de anos atrasados presente na base (5)\ndf_all['rez_esc'].replace(to_replace=99, value=5, inplace=True)\ndf_all['rez_esc'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# solução: atribuir o valor -1 para os valores nulos de rez_esc\n# isso é uma estratégia válida para algoritmos baseados em árvore\ndf_all['rez_esc'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variável v2a1\n* Valor do aluguel"},{"metadata":{"trusted":true},"cell_type":"code","source":"# O valor zero (0) é presente no dados => não é possível aplicar uma regra de negócio específica\ndf_train['v2a1'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# solução: atribuir um valor -1 para os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variável v18q1\n* Número de tablets que a família possui"},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlacionada com  a variável 'v18q', que identifica se a família possui um tablet\n# => valores nulos correspondem a zero tablet\ndf_all['v18q1'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variável meaneduc\n* Média de anos de educação para adultos (+18)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# se referem a uma fração muito pequena do dataset (0,1%)\ndf_all['meaneduc'].isnull().sum() / df_all['meaneduc'].count() * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputação de 'meaneduc' pela mediana\ndf_all['meaneduc'].fillna(df_all['meaneduc'].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## SQBmeaned: derivado de 'meaneduc'\n# imputação pela mediana\ndf_all['SQBmeaned'].fillna(df_all['SQBmeaned'].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Verificação do dataset após os tratamentos dos missing values\n# pelo resultado, percebe-se que as variáveis com valores ausentes foram devidamente tratadas\ndf_all.isnull().sum().sort_values(ascending=False).head(7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribuição da variável 'Target'"},{"metadata":{},"cell_type":"markdown","source":"Valores possíveis:\n* 1: pobreza extrema\n* 2: pobreza moderada\n* 3: famílias vulneráveis\n* 4: famílias não vulneráveis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confirmação que não existem  valores nulos em 'Target'\ndf_train['Target'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Contagem dos valores 'Target'\ndf_train['Target'].value_counts().sort_index(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribuição dos valores 'Target'\nax = sns.countplot(x='Target', data=df_train)\n_ = plt.title('Distribuição dos valores Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Os resultados acima indicam um problema de classificação com classes desbalanceadas. A quantidade de famílias em situação não vulnerável é muito superior ao número das demais famílias"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Chefes de família\n* Somente os chefes de família são usados na pontuação. \n* Todos os membros da família são incluídos no teste + o envio da amostra, mas apenas os chefes de família são pontuados.\n* Variável parentesco1=1 indica se é chefe de família \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Número e percentual de chefes de família na base de treino\nn_chefes_familia = df_train[df_train['parentesco1']==1]['parentesco1'].sum()\nn_chefes_familia, n_chefes_familia / df_train.shape[0] * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Número e percentual de chefes de família na base de teste\nn_chefes_familia = df_test[df_test['parentesco1']==1]['parentesco1'].sum()\nn_chefes_familia, n_chefes_familia / df_test.shape[0] * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 31.1% da base de treino é composta de chefes de família\n* 30.7% da base de treino é composta de chefes de família\n* Nota-se o balanceamento da distribuição entre as quantidades de chefes de família nas bases de treino e teste\n"},{"metadata":{},"cell_type":"markdown","source":"# Exclusão de Variáveis\n* Para redução da dimensionalidade, as variáveis que representam o quadrado de outras variáveis (SQBxxx) são descartadas\n* Eles seriam úteis para um modelo linear, mas são inúteis para um modelo baseado em árvore e podem confundi-lo\n* Fonte: https://www.kaggle.com/mlisovyi/feature-engineering-lighgbm-with-f1-macro"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exclusão variáveis SQBxxx\ncol_excluir = ['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned']\ndf_all.drop(col_excluir, axis=1, inplace=True)\ndf_train.drop(col_excluir, axis=1, inplace=True)\ndf_test.drop(col_excluir, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Conferência final do dataframe\n# sem valores ausentes; sem variáveis object\ndf_all.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Análise de Correlação"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlacao = df_train.corr()\ncorrelacao = correlacao['Target'].sort_values(ascending=False)\n\nprint(f'10 features positivas mais relevantes: \\n{correlacao.head(10)}')\nprint('\\n', '=' * 50, '\\n')\nprint(f'10 features negativas mais relevantes:: \\n{correlacao.tail(10)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considerações:\n* As variáveis mais correlacionadas com taxa de pobreza estão relacionadas com a educação dos adultos (meaneduc, escolari), número de criancas na casa (hogar_nin, r4t1), se a casa tem teto (cielorazo). \n* Isso coincide com o senso comum"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Observação: do resultado acima, chamou atenção o valor NaN da variável 'elimbasu5'\n# Investigando-se a mesma nota, nota-se que ela possui apenas um valor para toda a base de treinamento, portanto sem nenhuma função explicativa\ndf_train['elimbasu5'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decisão: eliminar essa variável\ndf_all.drop('elimbasu5', axis=1, inplace=True)\ndf_train.drop('elimbasu5', axis=1, inplace=True)\ndf_test.drop('elimbasu5', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Separação das bases de treino e teste"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separa as bases de treino e teste\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]\n\ntrain = df_all[~df_all['Target'].isnull()]\ntest = df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Balanceamento das Classes"},{"metadata":{},"cell_type":"markdown","source":"### Técnica SMOTE\n* Não obteve resultados satisfatórios\n* F1-Score: 0.8288343045151485\n* Acurácia: 0.830938292476754"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aplica over-sampling SMOTE\n# sm = SMOTE()\n# X_train, y_train = sm.fit_resample(X_train,y_train)\n# X_valid, y_valid = sm.fit_resample(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Técnica de over-sampling tradicional (sklearn)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separa os dados de treino de acordo com a classificação de pobreza (valor de Target)\ntrain_1 = train[train['Target'] == 1]\ntrain_2 = train[train['Target'] == 2]\ntrain_3 = train[train['Target'] == 3]\ntrain_4 = train[train['Target'] == 4]\n\ntrain_1.shape, train_2.shape,train_3.shape,train_4.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aplica over-sampling na base de treino\ntrain_1_over = resample(train_1,                 # aumenta a classe menor\n                       replace=True,             # sample com replacement\n                       n_samples=len(train_4),   # iguala à maior classe (4)\n                       random_state=42)\n\ntrain_2_over = resample(train_2,               \n                       replace=True,             \n                       n_samples=len(train_4),  \n                       random_state=42)\n\ntrain_3_over = resample(train_3,               \n                       replace=True,             \n                       n_samples=len(train_4),  \n                       random_state=42)\n\n\ntrain_1_over.shape,train_2_over.shape,train_3_over.shape,train_4.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Junta os dados\ntrain = pd.concat([train_1_over, train_2_over, train_3_over, train_4])\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Treinamento Inicial - com dados de validação\n* Utiliza base de validação para a escolha do melhor algoritmo\n* Os dois melhores algoritmos selecionados nesta fase serão utilizado para treinar com a base completa de treino\n* O melhos dos dois resultados será submetido à competição "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separa a base de treino em treino e validação\ntrain, valid = train_test_split(train, test_size=0.20, random_state=42)\n\nX_train = train[feats]\ny_train = train['Target'].astype(int)\n\nX_valid = valid[feats]\ny_valid = valid['Target'].astype(int)\n\nX_test = test[feats]\n\ntrain.shape, valid.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Função que avalia F1-score e acurácia do modelo\ndef avalia_modelo (val_true, val_pred):\n    acuracia = accuracy_score(y_true=val_true, y_pred=val_pred)\n    f1score = f1_score(y_true=val_true, y_pred=val_pred, average='macro')\n    return f1score, acuracia","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Random Forest \nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)\nrf.fit(X_train, y_train)\n\n# Avalia modelo\nf1score, acuracia = avalia_modelo(y_valid, rf.predict(X_valid))\n\n# Apresentação dos resultados\nprint (\"Random Forest\")\nprint(\"F1-Score:\", f1score)\nprint(\"Acurácia:\", acuracia)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\ngbm.fit(X_train, y_train)\n\n# Avalia modelo\nf1score, acuracia = avalia_modelo(y_valid, gbm.predict(X_valid))\n\n# Apresentação dos resultados\nprint (\"Gradient Boosting\")\nprint(\"F1-Score:\", f1score)\nprint(\"Acurácia:\", acuracia)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## XGBoost\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(n_estimators=200, learning_rate=0.09, random_state=42)\nxgb.fit(X_train, y_train)\n\n# Avalia modelo\nf1score, acuracia = avalia_modelo(y_valid, xgb.predict(X_valid))\n\n# Apresentação dos resultados\nprint (\"XGBoost\")\nprint(\"F1-Score:\", f1score)\nprint(\"Acurácia:\", acuracia)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## AdaBoost\nfrom sklearn.ensemble import AdaBoostClassifier\n\nabc = AdaBoostClassifier(n_estimators=200, learning_rate=1.0, random_state=42)\nabc.fit(X_train, y_train)\n\n# Avalia modelo\nf1score, acuracia = avalia_modelo(y_valid, abc.predict(X_valid))\n\n# Apresentação dos resultados\nprint (\"AdaBoost\")\nprint(\"F1-Score:\", f1score)\nprint(\"Acurácia:\", acuracia)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## CatBoost\nfrom catboost import CatBoostClassifier\n\ncbc = CatBoostClassifier(random_state=42)\ncbc.fit(X_train, y_train)\n\n# Avalia modelo\nf1score, acuracia = avalia_modelo(y_valid, cbc.predict(X_valid))\n\n\n# Apresentação dos resultados\nprint (\"CatBoost\")\nprint(\"F1-Score:\", f1score)\nprint(\"Acurácia:\", acuracia)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## LightGBM\n# parâmetros derivados de https://www.kaggle.com/denismarcio/improve-vision-with-lightgbm/\nimport lightgbm as lgb\n\nclf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n                                 random_state=None, silent=True, metric='None', \n                                 n_jobs=4, n_estimators=5500, class_weight='balanced',\n                                 colsample_bytree =  0.89, min_child_samples = 90, num_leaves = 56, subsample = 0.96)\nclf.fit(X_train, y_train)\n\n# Avalia modelo\nf1score, acuracia = avalia_modelo(y_valid, clf.predict(X_valid))\n\n# Apresentação dos resultados\nprint (\"LightGBM\")\nprint(\"F1-Score:\", f1score)\nprint(\"Acurácia:\", acuracia)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análise dos resultados - com base de validação\n#### Random Forest:\n    F1-Score: 0.9939934343153598\n    Acurácia: 0.9940072954663888\n\n#### LightGBM\n    F1-Score: 0.9932042106373568\n    Acurácia: 0.993225638353309\n\n### CatBoost\n    F1-Score: 0.976593475869052\n    Acurácia: 0.9768108389786347\n\n### Gradient Boosting\n    F1-Score: 0.6199833610920772\n    Acurácia: 0.6206357477853048\n\n### XGBoost\n    F1-Score: 0.939220952973292\n    Acurácia: 0.9395518499218343\n\n### AdaBoost\n    F1-Score: 0.5263839922419775\n    Acurácia: 0.52892131318395\n* Dos resultados acima, os algoritmos com melhor desempenho foram o Random Forest e o LightGBM\n* Estes dois algoritmos serão utilizados para o treino com toda a base de treino (sem validação) e depois aplicados na base de teste, para submissão ao Kaggle"},{"metadata":{},"cell_type":"markdown","source":"# Treino dos melhores algorimos - toda a base de treino"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recupera as bases de treino e teste\n\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]\n\n# Recupera a base de treino com oversampling \ntrain_full = pd.concat([train_1_over, train_2_over, train_3_over, train_4])\ntest = df_all[df_all['Target'].isnull()]\n\nX_train_full = train_full[feats]\ny_train_full = train_full['Target'].astype(int)\n\nX_test = test[feats]\n\ntrain_full.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Random Forest \nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)\nrf.fit(X_train_full, y_train_full)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## LightGBM\nclf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n                                 random_state=None, silent=True, metric='None', \n                                 n_jobs=4, n_estimators=5500, class_weight='balanced',\n                                 colsample_bytree =  0.89, min_child_samples = 90, num_leaves = 56, subsample = 0.96)\nclf.fit(X_train_full, y_train_full)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submissão para Competição"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Realiza previsão do valor de Target na base de teste \n\n# Random Forest\n#test['Target'] = rf.predict(X_test).astype(int)\n\n# LightGBM\ntest['Target'] = clf.predict(X_test).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cria o arquivo para submissão\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Resultados Finais\n\n* LightGBM: 0.40331  \n* Random Forest: 0.37312 \n* Embora o Random Forest tenha obtido um resultado ligeiramente melhor na base de validação, o algoritmo LightGBM obteve melhor desempenho na base de teste, ou seja, soube generalizar melhor\n"},{"metadata":{},"cell_type":"markdown","source":"# Sugestões de Trabalhos Futuros\n* Melhorar a etapa de feature engineering, fazendo consolidação de variáveis \n* Aprimorar a análise relacionada aos chefes de família, dado que somente estes que são avaliados pelo Kaggle. Avaliar a possibilidade de criar mais colunas, trazendo informações gerais dos membros de família para o chefe de família"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}