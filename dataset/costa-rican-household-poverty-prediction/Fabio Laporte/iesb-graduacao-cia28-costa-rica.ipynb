{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IESB - Graduacao - CIA028 - Costa Rica"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Carregando os dados\ndf = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\n\ndf.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I - Análise Exploratória e tratamento dos dados\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Target'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando tamanhos e tipos\ndf_all.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.select_dtypes(include='object')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# na coluna dependency\nmapeamento = {'yes': 1, 'no': 0}\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando do comando info\ndf_all.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos\ndf_all.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # Verificando os valores de aluguel (v2a1) para os chefes/as de familia (parentesco1 = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Qual a cara dos dados de v18q\ndf_all['v18q'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de SQBmeaned, meaneduc e rez_esc\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualização da distribuição das variáveis\ndf_all.hist(figsize=(20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# II - Aplicando o Modelo Random Forest\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciando o random forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos verificar as previsões\ntest['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o arquivo para submissão\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig=plt.figure(figsize=(15, 20))\n\n# Avaliando a importancia de cada coluna (cada variável de entrada)\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando a classe target nos dados de treino\ntrain['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Limitando o treinamento as/aos chefas/es de familia\n\n# Coluna parentesco1\nheads = train[train['parentesco1'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando, treinando, fazendo previsões e gerando o arquivo de submissão com RF2\n# Dados de treinao apenas dos chefes/chefas de familia\n\nrf2 = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)\n\nrf2.fit(heads[feats], heads['Target'])\n\ntest['Target'] = rf2.predict(test[feats]).astype(int)\n\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Qual o tamanho da base de treino heads?\nheads.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores da coluna hhsize\ntrain['hhsize'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os dados da coluna tamviv\ntrain['tamviv'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os dados da coluna tamhog\ntrain['tamhog'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering / Criação de novas colunas\n\n# Relação tamanho da casa / moradores\ndf_all['hhsize-pc'] = df_all['hhsize'] / df_all['tamviv']\n\n# Relação qtde celulares / moradores\ndf_all['mobile-pc'] = df_all['qmobilephone'] / df_all['tamviv']\n\n# Relaçao qtde de tablets / moradores\ndf_all['tablet-pc'] = df_all['v18q1'] / df_all['tamviv']\n\n# Relação qtde de quartos / moradores\ndf_all['rooms-pc'] = df_all['rooms'] / df_all['tamviv']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando, treinando, fazendo previsões e gerando o arquivo de submissão com RF3\n# Dados de treino com 4 colunas a mais\n\nrf3 = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)\n\nrf3.fit(train[feats], train['Target'])\n\ntest['Target'] = rf3.predict(test[feats]).astype(int)\n\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(15, 20))\n\n# Avaliando a importancia de cada coluna (cada variável de entrada)\npd.Series(rf3.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando as abordagens\n\n# Selecionando para treio só parentesco1 == 1\nheads2 = train[train['parentesco1'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando, treinando, fazendo previsões e gerando o arquivo de submissão com RF4\n# Dados de treino apenas dos chefes/chefas de familia e 4 colunas a mais\n\nrf4 = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)\n\nrf4.fit(heads2[feats], heads2['Target'])\n\ntest['Target'] = rf4.predict(test[feats]).astype(int)\n\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os dados de treino e teste\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Usando o Out-Of-Bag (oob_score)\n\n# Criando, treinando, fazendo previsões e gerando o arquivo de submissão com RF3\n# Dados de treino com 4 colunas a mais + oob_score\n\nrf5 = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42, oob_score=True, class_weight='balanced')\n\nrf5.fit(train[feats], train['Target'])\n\ntest['Target'] = rf5.predict(test[feats]).astype(int)\n\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Voltando as origens\n\n# Carregando os dados\ndf = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\n\ndf.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos transformar 'yes' em 1 e 'no' em 0\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preenchendo os valores nulos\ndf_all['v2a1'].fillna(-1, inplace=True)\ndf_all['v18q1'].fillna(0, inplace=True)\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'edjefe', 'edjefa','Target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Usando o Out-Of-Bag (oob_score)\n\n# Criando, treinando, fazendo previsões e gerando o arquivo de submissão com RF6\n# oob_score + class_weight\n\nrf6 = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42, oob_score=True, class_weight='balanced')\n\nrf6.fit(train[feats], train['Target'])\n\ntest['Target'] = rf6.predict(test[feats]).astype(int)\n\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copiando do campeão\nrf7 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\n\nrf7.fit(train[feats], train['Target'])\n\ntest['Target'] = rf7.predict(test[feats]).astype(int)\n\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# III - Modificações no Modelo (Prova 1)"},{"metadata":{},"cell_type":"markdown","source":"Existe uma diferença entre propriedades de cada uma das árvores, e as propriedades da floresta (sacola de árvores).\nOs principais parâmetros são n_estimators (número de árvores na floresta) e max_features (o tamanho do subconjunto de variáveis que serão consideradas quando o modelo faz a divisão do nó).\nA documentação do scikit-learn recomenda utilizar max_features=\"sqrt\" para tarefas de classificação. Uma possibilidade seria não utilizar um subconjunto, e sim todas as variáveis, como é recomendado por Geurts, Erns e Wehenkel (2006) para o modelo the RandomForestRegressor\n\nhttps://orbi.uliege.be/bitstream/2268/9357/1/geurts-mlj-advance.pdf\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mudança 1 - max_features=n_features\nrf8 = RandomForestClassifier(max_depth=None, max_features=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\n\nrf8.fit(train[feats], train['Target'])\n\ntest['Target'] = rf8.predict(test[feats]).astype(int)\n\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O modelo RandomForestClassifier pode utilizar dois métodos de avaliação da qualidade da divisão: gini e entropia.\nGini - Mede o quanto um elemento aleatoriamente escolhido do conjunto seria incorretamente classificado. Quanto maior o valor gini, mais \"impuro\", ou seja, mais o elemento aleatório seria incorretamente classificado.\nEntropia - mede a \"desordem\" geral de uma segmentação da árvore. É um método mais pesado computacionalmente do que o gini, por usar logbase2 das probabilidades\n\nLaura Elena Raileanu e Kilian Stoffel estimam que só há diferença entre as duas medidas em 2% dos casos.\n\nhttps://www.unine.ch/files/live/sites/imi/files/shared/documents/papers/Gini_index_fulltext.pdf\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mudança 2 - criterion=\"entropy\"\nrf9 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2, criterion=\"entropy\",\n                            verbose=0, class_weight='balanced')\n\nrf9.fit(train[feats], train['Target'])\n\ntest['Target'] = rf9.predict(test[feats]).astype(int)\n\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Número máximo de folhas é utilizado para limitar a quantidade de folhas, escolhendo apenas as melhores folhas. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mudança 3 - max_leaf_nodes=10\nrf10 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700, max_leaf_nodes=10,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\n\nrf10.fit(train[feats], train['Target'])\n\ntest['Target'] = rf10.predict(test[feats]).astype(int)\n\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# IV - Balanceamento das Classes\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando a biblioteca\nfrom sklearn.utils import resample\nimport scikitplot as skplt\n\n# Separando os dados de acordo com a classificação\ndf_1 = df_all[df_all['Target'] == 1]\ndf_2 = df_all[df_all['Target'] == 2]\ndf_3 = df_all[df_all['Target'] == 3]\ndf_4 = df_all[df_all['Target'] == 4]\n\ndf_1.shape, df_2.shape, df_3.shape, df_4.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Over-Sampling\nAumentando a classe minoritária"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Over-Sampling\ndf_1_over = resample(df_1, # vamos aumentar a classe menor\n                       replace=True, # sample com replacement\n                       n_samples=len(df_4), # igualando a maior classe\n                       random_state=42)\n\n# Over-Sampling\ndf_2_over = resample(df_2, # vamos aumentar a classe menor\n                       replace=True, # sample com replacement\n                       n_samples=len(df_4), # igualando a maior classe\n                       random_state=42)\n\n# Over-Sampling\ndf_3_over = resample(df_3, # vamos aumentar a classe menor\n                       replace=True, # sample com replacement\n                       n_samples=len(df_4), # igualando a maior classe\n                       random_state=42)\n\n\n\n# juntando os dados\ndf_over= pd.concat([df_1_over, df_2_over, df_3_over, df_4])\n\n# check new class counts\ndf_over['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_over.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n# Executando o modelo com df_over\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_over, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['Target'])\n\n# Previsões na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acurácia\naccuracy_score(test['Target'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['Target'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Under-Sampling\nDiminuindo a classe majoritária"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Under-Sampling\ndf_2_under = resample(df_2, # vamos diminuir as classes maiores\n                       replace=False, # sample sem replacement\n                       n_samples=len(df_1), # igualando a menor classe\n                       random_state=42)\n\n# Under-Sampling\ndf_3_under = resample(df_3, # vamos aumentar a classe menor\n                       replace=False, # sample se replacement\n                       n_samples=len(df_1), # igualando a menor classe\n                       random_state=42)\n# Under-Sampling\ndf_4_under = resample(df_4, # vamos aumentar a classe menor\n                       replace=False, # sample se replacement\n                       n_samples=len(df_1), # igualando a menor classe\n                       random_state=42)\n\n\n\n# juntando os dados\ndf_under= pd.concat([df_1, df_2_under, df_3_under, df_4_under])\n\n# check new class counts\ndf_under['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Executando o modelo com df_under\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_under, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['Target'])\n\n# Previsões na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acurácia\naccuracy_score(test['Target'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['Target'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Usando a bilioteca imbalanced-learn\nEssa biblioteca implementa diversos modelos diferentes para tratar classes desabalanceadas"},{"metadata":{},"cell_type":"markdown","source":"Tive problemas com essa biblioteca:\nModuleNotFoundError: No module named 'sklearn.neighbors._base'"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando a biblioteca\nimport imblearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando os dados de entrada e o target\nX, y = df_all[feats], df_all[['Target']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imblearn Random Over-Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando a biblioteca\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Fazendo o over-sampling\nros = RandomOverSampler(random_state=42)\nX_ros,y_ros= ros.fit_resample(X,y)\n\n# Verificando os dados\ny_ros['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Executando o modelo com imblearn over-sampling\n\n# Juntando os dados\ndf_over = pd.concat([X_ros, y_ros], axis=1)\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_over, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['Target'])\n\n# Previsões na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acurácia\naccuracy_score(test['Target'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['Target'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imblearn Tomek-links (under-sampling)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando a biblioteca\nfrom imblearn.under_sampling import TomekLinks\n\n# Fazendo o under-sampling\ntl = TomekLinks()\nX_tl, y_tl = tl.fit_resample(X,y)\n\n# Verificando os dados\ny_tl['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Executando o modelo com Tomek-links\n\n# Juntando os dados\ndf_under = pd.concat([X_tl, y_tl], axis=1)\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_under, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['Target'])\n\n# Previsões na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acurácia\naccuracy_score(test['Target'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['Target'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imblearn SMOTE (over-sampling)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando a biblioteca\nfrom imblearn.over_sampling import SMOTE\n\n# Fazendo o under-sampling\nsm = SMOTE()\nX_sm, y_sm = sm.fit_resample(X,y)\n\n# Verificando os dados\ny_sm['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Executando o modelo com SMOTE\n\n# Juntando os dados\ndf_over = pd.concat([X_sm, y_sm], axis=1)\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_over, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['Target'])\n\n# Previsões na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acurácia\naccuracy_score(test['Target'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando a matriz de confusao para os dados de teste\nskplt.metrics.plot_confusion_matrix(test['Target'], preds_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}