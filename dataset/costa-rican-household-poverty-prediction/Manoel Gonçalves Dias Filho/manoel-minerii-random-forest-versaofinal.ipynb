{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Trabalho Final - Data Mining II - IESB\n\nEsse projeto foi realizado como entrega final da matéria de Data Mining II da Pós Graduação de Ciência de Dados no IESB.\nPara execução do projeto foi realizada a competição Costa Rican Household Poverty Level Prediction - https://www.kaggle.com/c/costa-rican-household-poverty-prediction\n    \nComo base do projeto foi utilizado o notebook disponibilizado pelo professor Marcos https://www.kaggle.com/marcosvafg/iesb-miner-ii-aula-05-random-forest e o objetivo era ter uma submissão maior do que 0.43719.\n\nFoi obtido um valor de 0.44109 na competição, atigindo o objetivo primário da matéria.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importações iniciais\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Carregando os dados do desafio\ntrain = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\n\nprint('Tamanho dos datasets Train e Test:')\nprint(' - Train - Linhas:', train.shape[0],'Colunas:', train.shape[1],'\\n - Test - Linhas:', test.shape[0],'Colunas:', test.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando os dataframes - train e test\ndf_all = train.append(test)\n\nprint('Informações do novo dataset:\\n df_all - Linhas:', df_all.shape[0],'Colunas:', df_all.shape[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tratamento dos dados","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Passo 1. Verificação do dataset para validar se os dados inseridos são os dados esperados pelo dataset. Caso seja esperado dado númerico e o campo for object, esses registros precisam ser tratados.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\n# Importante passo para saber se alguma coluna tem dados (linhas) \n#    com tipo diferente\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nComo pode ser visualizado na saída acima, as colunas dependency, edjefa e edjefe são do tipo object. Nas instruções do desafio informava o seguinte:\n\n* dependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)\n* edjefe, years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n* edjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n\nOu seja, valores númericos, então nesse caso precisam ser tratados.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna dependency\ndf_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Após análise dos dados das colunas edjefa, edjefe e dependency, temos:\n\nPara a coluna edjefa, temos 214: yes e 22075: no\n\nPara a coluna edjefe, temos 416: yes e 12818: no\n\nPara a coluna dependecy, temos 7580: yes e 6036: no\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Para alteração dos registros, será utilizada a função abaixo, onde:\n* yes será 1\n* no será 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Função para excecutar troca dos valores yes e no, para 1 e 0, respectivamente\nmapeamento = {'yes': 1, 'no': 0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transformação dos dados das colunas edjefa e edjefe\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Após execução, espera que apenas a coluna dependency ainda seja object","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Com a execução anterior podemos verificar que as variáveis edjefa e edjefe não são mais do tipo object, agora apenas coluna dependecy possui dados desse tipo yes/no e precisam ser tratados.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Como a variável dependecy possui uma variável SQBdependency com os dados 'Ao Quadrado', iremos tratá-la com os dados da raiz quadrada de SQBdependency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando as colunas dependency e SQBdependency, pois uma é baseada na outra.\ndf_all[['dependency','SQBdependency']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preenchimento dos valores de dependency \n#  com os valores da raiz quadrada de SQBdependency\ndf_all['dependency'] = np.sqrt(df_all['SQBdependency'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora não é esperado mais colunas do tipo object.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Após tratamento dos registros das colunas objects, vamos verificar se temos valores nulos no dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Temos algumas colunas como dados nulos, vamos tratar primeiramente as que mais tem dados, pois saída acima está ordenada. São elas: v2a1, v18q1 e rez_esc.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tratamento dos valores nulos nas variáveis: v2a1, v18q1 e rez_esc\n#df_all['v2a1'].fillna(0, inplace=True)\n#df_all['v18q1'].fillna(0, inplace=True)\n#df_all['rez_esc'].fillna(0, inplace=True)\ndf_all['v2a1'] = df_all['v2a1'].fillna(value=df_all['tipovivi3'])\ndf_all['v18q1'] = df_all['v18q1'].fillna(value=df_all['v18q'])\ndf_all['rez_esc'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Registros tratados, vamos tratar os outros dados que ainda possuem nulo","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos restantes\ndf_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como temos poucos dados e iremos atribuir 0 para as colunas meaneduc e SQBmeaned","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com 0 todos os valores nulos\ndf_all['meaneduc'].fillna(0, inplace=True)\ndf_all['SQBmeaned'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Os valores da variável Target serão tratados com -1 para realizar o split do dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['Target'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bibliotecas","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Carregando as bibliotecas utilizadas para os modelos\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, f1_score, make_scorer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelo 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[df_all['Target'] != -1], df_all[df_all['Target'] == -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciando RadomForestClassifier\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, oob_score=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos verificar as previsões\ntest['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o arquivo para submissão\n#test[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelo 2","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n\nApós primeira submissão após limpeza da base. Tivemos um resultado de 0.43777. Agora iremos fazer novas limpezas para verificar se o valor pode ser melhorado.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering\n\n# Vamos criar novas colunas para valores percapita\ndf_all['hsize-pc'] = df_all['hhsize'] / df_all['tamviv']\ndf_all['phone-pc'] = df_all['qmobilephone'] / df_all['tamviv']\ndf_all['tablets-pc'] = df_all['v18q1'] / df_all['tamviv']\ndf_all['rooms-pc'] = df_all['rooms'] / df_all['tamviv']\ndf_all['rent-pc'] = df_all['v2a1'] / df_all['tamviv']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[df_all['Target'] != -1], df_all[df_all['Target'] == -1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nPara isso utilizaremos matrix de correlação e também verificação no dataset para variáveis que sejam basicamente a mesma coisa. O código abaixo foi retirado do kaggle https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough para verificar a correlação das variáveis. Alguns ajustes foram realizados.\n\nPara realizar a correlação foram utilizados:\n\nnp.triu: Upper triangle of an array. Return a copy of a matrix with the elements below the k-th diagonal zeroed.\n\nnp.ones: Return a new array of given shape and type, filled with ones.\n\nPara que a colune fosse considerada correlacionada e pudesse ser retirada, foi utlizado o parâmetro de 0.975, fazendo o usu do valor absoluto da coluna (abs).\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizando matriz de correspondência para verificar se algumas variáveis podem ser retiradas do modelo\n\n# Create correlation matrix\ncorr = df_all.corr()\n\n# Select upper triangle of correlation matrix\nupper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.975\nto_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.975)]\n\nprint(f'There are {len(to_drop)} correlated columns to remove.')\nprint(to_drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removendo algumas colunas que tem basicamente o mesmo valor para o modelo e/ou tenha alta correlação\n# r4t3, tamviv, tamhog, hhsize = hogar_total\n# v18q, mobilephone = v18q1, qmobilephone\n# v14a = saniatrio1\n# male oposto do female. Retirando female.\n# area1 oposto da area2\n\nretira_cols = ['agesq', 'area2', 'hogar_total', 'male', 'public', 'r4t3', 'tamhog', 'tamviv', \n               'hhsize', 'v18q', 'v14a', 'mobilephone', 'female']\n\n\nparentesco_cols = [colunas for colunas in train.columns.tolist() if 'parentesco' in colunas and 'parentesco1' not in colunas]\n\nretira_cols.extend(parentesco_cols)\n\ntrain = train.drop(retira_cols, axis=1)\ntest = test.drop(retira_cols, axis=1)\ndf_all = df_all.drop(retira_cols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Limitando o treinamento ao chefe da familia\n\n# Criando um novo dataframe para treinar\nheads = train[train['parentesco1'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando um novo modelo\nrf2 = RandomForestClassifier(n_jobs=-1, n_estimators=200, oob_score=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando o modelo\nrf2.fit(train[feats], train['Target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf2.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o arquivo para submissão\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelo 3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando as abordagens\nheads2 = train[train['parentesco1'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando um novo modelo\nrf3 = RandomForestClassifier(n_jobs=-1, n_estimators=200, oob_score=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando o modelo\nrf3.fit(heads2[feats], heads2['Target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prevendo usando o modelo treinado\ntest['Target'] = rf3.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o arquivo para submissão\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Importance\npd.Series(rf3.feature_importances_, index=feats).sort_values().plot.barh(figsize = (20, 40));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelo 4 - Melhor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copiando do campeão\nrf4 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando o modelo\nrf4.fit(heads2[feats], heads2['Target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prevendo usando o modelo treinado\ntest['Target'] = rf4.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Importance\npd.Series(rf4.feature_importances_, index=feats).sort_values().plot.barh(figsize = (20, 40));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o arquivo para submissão\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Passos para criação da Matriz de Confusão. Código foi verificado no kaggle https://www.kaggle.com/kuriyaman1002/reduce-features-140-85-keeping-f1-score/execution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divisão dos datasets para poder fazer a matriz de confusão.\n# Obtensão do f1_score também\n\nimport lightgbm as lgb\n\ntrain_y = train['Target']\n\nX_train, X_test, y_train, y_test = train_test_split(train[feats], train_y, test_size=0.2, random_state=42)\n\nF1_scorer = make_scorer(f1_score, greater_is_better=True, average='macro')\n\ngbm = lgb.LGBMClassifier(boosting_type='dart', objective='multiclassova', class_weight='balanced', random_state=0)\n\ngbm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\ntrain_y = train.Target\n\nX_train, X_test, y_train, y_test = train_test_split(train[feats], train_y, test_size=0.2, random_state=42)\n\nF1_scorer = make_scorer(f1_score, greater_is_better=True, average='macro')\n\ngbm = lgb.LGBMClassifier(boosting_type='dart', objective='multiclassova', class_weight='balanced', random_state=0)\n\ngbm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matriz de confusão\ny_test_pred = gbm.predict(X_test)\ncm = confusion_matrix(y_test, y_test_pred)\nf1 = f1_score(y_test, y_test_pred, average='macro')\nprint(\"confusion matrix: \\n\", cm)\nprint(\"macro F1 score: \\n\", f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusão:\n\nEsse notebook é resultado da matéria de Data Mining da pós graduação em Ciência de Dados do IESB - Brasília.\n\nO notebook do professor Marcos https://www.kaggle.com/marcosvafg/iesb-miner-ii-aula-05-random-forest?scriptVersionId=29607563 foi utilizado como base para esse trabalho.\n\nNo decorer da execução do modelo também foram utilizados notebooks submetidos na competição que utilizei aqui também.\n\nO trabalho foi concluído com um valor de 0.44109 para o melhor modelo, o modelo 4. Utilizando RandomForestClassifier com os parâmetros utilizados pelo campeão da competição. Sendo necessário um grande trabalho de verificação das variáveis e de qual modelo seria melhor. Outras validações também foram utilizadas de alguns códigos no kaggle, e estão documentados nesse arquivo.\n\n# Desafios e problemas encontrados\n\nA cada teste realizado o valor diminuia consideravelmente mesmo tomando ações que achava que seria melhor. Enfim, em alguns momentos parece que nada fluiria.\n\nTentei utilizar o plot_confusion_matrix para melhorar a visualização mas não foi possível. Acredito que a versão no kaggle estava diferente da necessária.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}