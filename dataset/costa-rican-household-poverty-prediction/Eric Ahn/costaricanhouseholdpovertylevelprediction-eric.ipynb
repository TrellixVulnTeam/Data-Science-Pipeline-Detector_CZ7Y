{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Inter-American Development Bank \n* Financing for Latin America / Caribbean\n* the right people are not given enough aid\n* To verify income qualification => PMT ( Proxy Means Test )\n* family's observable household attributes : the material of their walls and ceiling, assets ) \n* ref : YouhanLee ( https://www.kaggle.com/youhanlee/3250feats-532-feats-using-shap-lb-0-436/output#1.-Check-datasets )"},{"metadata":{},"cell_type":"markdown","source":"### Problem and Data Explanation\n* The data for this competition is provided in two files: train.csv and test.csv. \n* The training set has 9557 rows and 143 columns while the testing set has 23856 rows and 142 columns. \n* Each row represents one individual and each column is a feature, either unique to the individual, or for the household of the individual. \n* The training set has one additional column, Target, which represents the poverty level on a 1-4 scale and is the label for the competition. \n* A value of 1 is the most extreme poverty.\n\n**This is a supervised multi-class classification machine learning problem:**\n\n* **Supervised**: provided with the labels for the training data\n* **Multi-class classification**: Labels are discrete values with 4 classes"},{"metadata":{},"cell_type":"markdown","source":"### Objective\n\n* \"ONLY the heads of household are used in scoring\" which means we want to predict poverty on a household basis.\n* (\"parentesco1\",\" =1 if household head\"), => to use the label for the head of each household\n* Target : 1/2/3/4\n* 1 = extreme poverty 극심한 빈곤\n* 2 = moderate poverty 빈곤\n* 3 = vulnerable households 취약한 가구\n* 4 = non vulnerable households 비 취약한 가구"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set(font_scale=2.2)\nplt.style.use('seaborn')\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, ShuffleSplit\nfrom sklearn.metrics import f1_score\nimport itertools\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier\nimport shap \nfrom tqdm import tqdm\nimport featuretools as ft\nimport warnings\nwarnings.filterwarnings('ignore')\nimport time\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Check datasets"},{"metadata":{},"cell_type":"markdown","source":"**1.1 Read dataset **"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ndf_test = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('df_train shape:', df_train.shape, '  ', 'df_test shape: ', df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Make description df"},{"metadata":{"trusted":true},"cell_type":"code","source":"description = [\n(\"v2a1\",\" Monthly rent payment\"),\n(\"hacdor\",\" =1 Overcrowding by bedrooms\"),\n(\"rooms\",\"  number of all rooms in the house\"),\n(\"hacapo\",\" =1 Overcrowding by rooms\"),\n(\"v14a\",\" =1 has toilet in the household\"),\n(\"refrig\",\" =1 if the household has refrigerator\"),\n(\"v18q\",\" owns a tablet\"),\n(\"v18q1\",\" number of tablets household owns\"),\n(\"r4h1\",\" Males younger than 12 years of age\"),\n(\"r4h2\",\" Males 12 years of age and older\"),\n(\"r4h3\",\" Total males in the household\"),\n(\"r4m1\",\" Females younger than 12 years of age\"),\n(\"r4m2\",\" Females 12 years of age and older\"),\n(\"r4m3\",\" Total females in the household\"),\n(\"r4t1\",\" persons younger than 12 years of age\"),\n(\"r4t2\",\" persons 12 years of age and older\"),\n(\"r4t3\",\" Total persons in the household\"),\n(\"tamhog\",\" size of the household\"),\n(\"tamviv\",\" number of persons living in the household\"),\n(\"escolari\",\" years of schooling\"),\n(\"rez_esc\",\" Years behind in school\"),\n(\"hhsize\",\" household size\"),\n(\"paredblolad\",\" =1 if predominant material on the outside wall is block or brick\"),\n(\"paredzocalo\",\" =1 if predominant material on the outside wall is socket (wood, zinc or absbesto\"),\n(\"paredpreb\",\" =1 if predominant material on the outside wall is prefabricated or cement\"),\n(\"pareddes\",\" =1 if predominant material on the outside wall is waste material\"),\n(\"paredmad\",\" =1 if predominant material on the outside wall is wood\"),\n(\"paredzinc\",\" =1 if predominant material on the outside wall is zink\"),\n(\"paredfibras\",\" =1 if predominant material on the outside wall is natural fibers\"),\n(\"paredother\",\" =1 if predominant material on the outside wall is other\"),\n(\"pisomoscer\",\" =1 if predominant material on the floor is mosaic ceramic   terrazo\"),\n(\"pisocemento\",\" =1 if predominant material on the floor is cement\"),\n(\"pisoother\",\" =1 if predominant material on the floor is other\"),\n(\"pisonatur\",\" =1 if predominant material on the floor is  natural material\"),\n(\"pisonotiene\",\" =1 if no floor at the household\"),\n(\"pisomadera\",\" =1 if predominant material on the floor is wood\"),\n(\"techozinc\",\" =1 if predominant material on the roof is metal foil or zink\"),\n(\"techoentrepiso\",\" =1 if predominant material on the roof is fiber cement,   mezzanine \"),\n(\"techocane\",\" =1 if predominant material on the roof is natural fibers\"),\n(\"techootro\",\" =1 if predominant material on the roof is other\"),\n(\"cielorazo\",\" =1 if the house has ceiling\"),\n(\"abastaguadentro\",\" =1 if water provision inside the dwelling\"),\n(\"abastaguafuera\",\" =1 if water provision outside the dwelling\"),\n(\"abastaguano\",\" =1 if no water provision\"),\n(\"public\",\" =1 electricity from CNFL,  ICE, ESPH/JASEC\"),\n(\"planpri\",\" =1 electricity from private plant\"),\n(\"noelec\",\" =1 no electricity in the dwelling\"),\n(\"coopele\",\" =1 electricity from cooperative\"),\n(\"sanitario1\",\" =1 no toilet in the dwelling\"),\n(\"sanitario2\",\" =1 toilet connected to sewer or cesspool\"),\n(\"sanitario3\",\" =1 toilet connected to  septic tank\"),\n(\"sanitario5\",\" =1 toilet connected to black hole or letrine\"),\n(\"sanitario6\",\" =1 toilet connected to other system\"),\n(\"energcocinar1\",\" =1 no main source of energy used for cooking (no kitchen)\"),\n(\"energcocinar2\",\" =1 main source of energy used for cooking electricity\"),\n(\"energcocinar3\",\" =1 main source of energy used for cooking gas\"),\n(\"energcocinar4\",\" =1 main source of energy used for cooking wood charcoal\"),\n(\"elimbasu1\",\" =1 if rubbish disposal mainly by tanker truck\"),\n(\"elimbasu2\",\" =1 if rubbish disposal mainly by botan hollow or buried\"),\n(\"elimbasu3\",\" =1 if rubbish disposal mainly by burning\"),\n(\"elimbasu4\",\" =1 if rubbish disposal mainly by throwing in an unoccupied space\"),\n(\"elimbasu5\",\" =1 if rubbish disposal mainly by throwing in river,   creek or sea\"),\n(\"elimbasu6\",\" =1 if rubbish disposal mainly other\"),\n(\"epared1\",\" =1 if walls are bad\"),\n(\"epared2\",\" =1 if walls are regular\"),\n(\"epared3\",\" =1 if walls are good\"),\n(\"etecho1\",\" =1 if roof are bad\"),\n(\"etecho2\",\" =1 if roof are regular\"),\n(\"etecho3\",\" =1 if roof are good\"),\n(\"eviv1\",\" =1 if floor are bad\"),\n(\"eviv2\",\" =1 if floor are regular\"),\n(\"eviv3\",\" =1 if floor are good\"),\n(\"dis\",\" =1 if disable person\"),\n(\"male\",\" =1 if male\"),\n(\"female\",\" =1 if female\"),\n(\"estadocivil1\",\" =1 if less than 10 years old\"),\n(\"estadocivil2\",\" =1 if free or coupled uunion\"),\n(\"estadocivil3\",\" =1 if married\"),\n(\"estadocivil4\",\" =1 if divorced\"),\n(\"estadocivil5\",\" =1 if separated\"),\n(\"estadocivil6\",\" =1 if widow/er\"),\n(\"estadocivil7\",\" =1 if single\"),\n(\"parentesco1\",\" =1 if household head\"),\n(\"parentesco2\",\" =1 if spouse/partner\"),\n(\"parentesco3\",\" =1 if son/doughter\"),\n(\"parentesco4\",\" =1 if stepson/doughter\"),\n(\"parentesco5\",\" =1 if son/doughter in law\"),\n(\"parentesco6\",\" =1 if grandson/doughter\"),\n(\"parentesco7\",\" =1 if mother/father\"),\n(\"parentesco8\",\" =1 if father/mother in law\"),\n(\"parentesco9\",\" =1 if brother/sister\"),\n(\"parentesco10\",\" =1 if brother/sister in law\"),\n(\"parentesco11\",\" =1 if other family member\"),\n(\"parentesco12\",\" =1 if other non family member\"),\n(\"idhogar\",\" Household level identifier\"),\n(\"hogar_nin\",\" Number of children 0 to 19 in household\"),\n(\"hogar_adul\",\" Number of adults in household\"),\n(\"hogar_mayor\",\" # of individuals 65+ in the household\"),\n(\"hogar_total\",\" # of total individuals in the household\"),\n(\"dependency\",\" Dependency rate\"),\n(\"edjefe\",\" years of education of male head of household\"),\n(\"edjefa\",\" years of education of female head of household\"),\n(\"meaneduc\",\"average years of education for adults (18+)\"),\n(\"instlevel1\",\" =1 no level of education\"),\n(\"instlevel2\",\" =1 incomplete primary\"),\n(\"instlevel3\",\" =1 complete primary\"),\n(\"instlevel4\",\" =1 incomplete academic secondary level\"),\n(\"instlevel5\",\" =1 complete academic secondary level\"),\n(\"instlevel6\",\" =1 incomplete technical secondary level\"),\n(\"instlevel7\",\" =1 complete technical secondary level\"),\n(\"instlevel8\",\" =1 undergraduate and higher education\"),\n(\"instlevel9\",\" =1 postgraduate higher education\"),\n(\"bedrooms\",\" number of bedrooms\"),\n(\"overcrowding\",\" # persons per room\"),\n(\"tipovivi1\",\" =1 own and fully paid house\"),\n(\"tipovivi2\",\" =1 own,   paying in installments\"),\n(\"tipovivi3\",\" =1 rented\"),\n(\"tipovivi4\",\" =1 precarious\"),\n(\"tipovivi5\",\" =1 other(assigned\"),\n(\"computer\",\" =1 if the household has notebook or desktop computer,   borrowed)\"),\n(\"television\",\" =1 if the household has TV\"),\n(\"mobilephone\",\" =1 if mobile phone\"),\n(\"qmobilephone\",\" # of mobile phones\"),\n(\"lugar1\",\" =1 region Central\"),\n(\"lugar2\",\" =1 region Chorotega\"),\n(\"lugar3\",\" =1 region PacÃƒÂ­fico central\"),\n(\"lugar4\",\" =1 region Brunca\"),\n(\"lugar5\",\" =1 region Huetar AtlÃƒÂ¡ntica\"),\n(\"lugar6\",\" =1 region Huetar Norte\"),\n(\"area1\",\" =1 zona urbana\"),\n(\"area2\",\" =2 zona rural\"),\n(\"age\",\" Age in years\"),\n(\"SQBescolari\",\" escolari squared\"),\n(\"SQBage\",\" age squared\"),\n(\"SQBhogar_total\",\" hogar_total squared\"),\n(\"SQBedjefe\",\" edjefe squared\"),\n(\"SQBhogar_nin\",\" hogar_nin squared\"),\n(\"SQBovercrowding\",\" overcrowding squared\"),\n(\"SQBdependency\",\" dependency squared\"),\n(\"SQBmeaned\",\" meaned squared\"),\n(\"agesq\",\" Age squared\"),]\n\ndescription = pd.DataFrame(description, columns=['varname', 'description'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"description","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 Check null data"},{"metadata":{"trusted":true},"cell_type":"code","source":"total = df_train.isnull().sum().sort_values(ascending=False)\nprint(total)\npercent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending=False)\nmissing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n\nmissing_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"=> rez_esc, v18q1, v2a1 ..."},{"metadata":{},"cell_type":"markdown","source":"## 1.4 Fill missing values"},{"metadata":{},"cell_type":"markdown","source":"* edjefe : years of education of male head of household\n* edjefa : years of education of female head of household\n* parentesco1 : 1 if household head\n* escolari : years of schooling "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['edjefa'].head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* => yes/no/num? \n* => So, Using https://www.kaggle.com/skooch/lgbm-w-random-split-2 -> Fill proper values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_train.drop(['edjef'], axis=1)\n#df_test.drop(['edjef'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# edjefa if education is \"yes\" and person is head of household <== fill with escolari\n# \ndf_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefa\"] = df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\ndf_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefe\"] = df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n\ndf_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefa\"] = df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\ndf_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefe\"] = df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n\n# this field is supposed to be interaction between gender and escolari, \n# but it isn't clear what \"yes\" means, let's fill it with 4\ndf_train.loc[df_train['edjefa'] == \"yes\", \"edjefa\"] = 4\ndf_train.loc[df_train['edjefe'] == \"yes\", \"edjefe\"] = 4\n\ndf_test.loc[df_test['edjefa'] == \"yes\", \"edjefa\"] = 4\ndf_test.loc[df_test['edjefe'] == \"yes\", \"edjefe\"] = 4\n\n# create feature with max education of either head of household\n#(\"edjefe\",\" years of education of male head of household\"),\n#(\"edjefa\",\" years of education of female head of household\"),\ndf_train['edjef'] = df_train[['edjefa','edjefe']].max(axis=1) # axis=1, max of every row\ndf_test['edjef'] = df_test[['edjefa','edjefe']].max(axis=1)\n\n# \"v14a\",\" =1 has toilet in the household\"),\n# \"sanitario1\",\" =1 no toilet in the dwelling\"), sanitario=위생적인\n# \"abastaguano\",\" =1 if no water provision\"),\n# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet, \n# if there is no water we'll assume they do not\ndf_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"v14a\"] = 0\ndf_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"sanitario1\"] = 0\n\ndf_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"v14a\"] = 0\ndf_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"sanitario1\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[['edjefa','edjefe']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* rez_esc, SQBmeaned"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['rez_esc']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* => rez_esc : \"Years behind in school\"\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['rez_esc'].fillna(0, inplace=True)\ndf_test['rez_esc'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* => inplace=True, drop NaN field and replace new data(0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['rez_esc'].head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* => \"agesq\",\" Age squared\"\n* => SQBmeaned : \" square of the mean\" years of education of adults ( >= 18 ) in the household agesq, Age squared -> same with rez_esc -> filled with 0 ????"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SQBmeaned : Found 5 NaN, and fill 0\ndf_train['SQBmeaned'].fillna(0, inplace=True)\ndf_test['SQBmeaned'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* v18q1"},{"metadata":{},"cell_type":"markdown","source":"> * => 'v18q1' : \"number of tablets household owns\"\n* => \"v18q\" : \" owns a tablet\"),"},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of count the every value\n#\ndf_train['v18q'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* => 0/1 count\n* => 1 means : 1 or some values\n* => 0 means : only NaN values in v18q1 "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[df_train['v18q'] == 1, 'v18q1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[df_train['v18q'] == 0, 'v18q1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['v18q1'].fillna(0, inplace=True)\ndf_test['v18q1'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['v18q1'].head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* \"v2a1\",\" Monthly rent payment\" => tipovivi3(rented?) == 1, there are some values. if not, there are also some values\n* => NaN value => replace 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"tipovivi3\",\" =1 rented\"),\ndf_train['tipovivi3'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 1, 'v2a1'], label = 'Monthly rent payment of household(rented=1)')\nsns.kdeplot(df_train.loc[df_train['tipovivi3'] == 0, 'v2a1'], label = 'Monthly rent payment of household(rented=0)')\nplt.xscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['v2a1'].fillna(0, inplace=True)\ndf_test['v2a1'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 1, 'v2a1'], label = 'Monthly rent payment of household(rented=1)')\nsns.kdeplot(df_train.loc[df_train['tipovivi3'] == 0, 'v2a1'], label = 'Monthly rent payment of household(rented=0)')\nplt.xscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = df_train.isnull().sum().sort_values(ascending=False)\npercent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending=False)\nmissing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n\nmissing_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = df_test.isnull().sum().sort_values(ascending=False)\npercent = 100 * (df_test.isnull().sum() / df_test.isnull().count()).sort_values(ascending=False)\nmissing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n\nmissing_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Feature engineering"},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Object features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# object type check ( mixed types )\n#\nfeatures_object = [col for col in df_train.columns if df_train[col].dtype == 'object']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_object","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1) 'dependency' object"},{"metadata":{},"cell_type":"markdown","source":"* (\"dependency\",\" Dependency rate\"),\n* (\"SQBdependency\",\" dependency squared\"),"},{"metadata":{"trusted":true},"cell_type":"code","source":"# some dependencies are Na, fill those with \"the square root\" of the square ( Na = NaN = Null 모두 같은 의미 )\ndf_train['dependency'] = np.sqrt(df_train['SQBdependency'])\ndf_test['dependency'] = np.sqrt(df_test['SQBdependency'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['dependency']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* => Fill 'dependency' as below : "},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train['dependency'] = df_train['dependency'].replace({np.inf: 0})\n# df_test['dependency'] = df_test['dependency'].replace({np.inf: 0})\n\n# def replace_dependency(x):\n#     if x == 'yes':\n#         return 10\n#     elif x == 'no':\n#         return 0\n#     else:\n#         return x\n\n# df_train['dependency'] = df_train['dependency'].apply(replace_dependency).astype(float)\n# df_test['dependency'] = df_test['dependency'].apply(replace_dependency).astype(float)\n\n# - As you can see, setting yes -> 10 and no -> 0 is good choice.\n# - At first, fill inf value with 0.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2) 'edjefe' object"},{"metadata":{},"cell_type":"markdown","source":"* (\"edjefe\",\" years of education of male head of household\"), <= based on the interaction of escolari ( years of education ), head of household and gender, yes=1 and no=0, replace yes->1, no -> 0\n* (\"SQBedjefe\",\" edjefe squared\"),"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['edjefe'].head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_edjefe(x):\n    if x == 'yes':\n        return 1\n    elif x == 'no':\n        return 0\n    else:\n        return x\n    \ndf_train['edjefe'] = df_train['edjefe'].apply(replace_edjefe).astype(float)\ndf_test['edjefe'] = df_test['edjefe'].apply(replace_edjefe).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['edjefe'].head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2) 'edjefa' object"},{"metadata":{},"cell_type":"markdown","source":"* 'edjefa' : years of education of female head of household, based on the interaction of escolari ( years of education ), head of household and gender, yes=1 and no=0\n* replace yes -> 1, no -> 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_edjefa(x):\n    if x == 'yes':\n        return 1\n    elif x == 'no':\n        return 0\n    else:\n        return x\n    \ndf_train['edjefa'] = df_train['edjefa'].apply(replace_edjefa).astype(float)\ndf_test['edjefa'] = df_test['edjefa'].apply(replace_edjefa).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create feature with max education of either head of household\ndf_train['edjef'] = np.max(df_train[['edjefa', 'edjefe']], axis=1)\ndf_test['edjef'] = np.max(df_test[['edjefa', 'edjefe']], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['edjef']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3) 'roof' and 'electricity' object"},{"metadata":{},"cell_type":"markdown","source":"* => refer to https://www.kaggle.com/mineshjethva/exploratory-data-analysis-lightgbm"},{"metadata":{},"cell_type":"markdown","source":"* (\"techozinc\",\" =1 if predominant material on the roof is metal foil or zink\"), 금속 포일, 아연\n* (\"techoentrepiso\",\" =1 if predominant material on the roof is fiber cement,   mezzanine \"), 섬유 시멘트 ( 메자닌)\n* (\"techocane\",\" =1 if predominant material on the roof is natural fibers\"), 천연 섬유\n* (\"techootro\",\" =1 if predominant material on the roof is other\"), 기타\n"},{"metadata":{},"cell_type":"markdown","source":"* (\"public\",\" =1 electricity from CNFL,  ICE, ESPH/JASEC\"),\n* (\"planpri\",\" =1 electricity from private plant\"),\n* (\"noelec\",\" =1 no electricity in the dwelling\"),\n* (\"coopele\",\" =1 electricity from cooperative\"),"},{"metadata":{"trusted":true},"cell_type":"code","source":"# new feature\ndf_train['roof_waste_material'] = np.nan\ndf_test['roof_waste_material'] = np.nan\ndf_train['electricity_other'] = np.nan\ndf_test['electricity_other'] = np.nan\n\ndef fill_roof_exception(x):\n    if ( x['techozinc'] == 0 ) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n        return 1\n    else:\n        return 0\n    \ndef fill_no_electricity(x):\n    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n        return 1\n    else:\n        return 0\n    \ndf_train['roof_waste_material'] = df_train.apply(lambda x : fill_roof_exception(x), axis=1)\ndf_test['roof_waste_material'] = df_test.apply(lambda x : fill_roof_exception(x), axis=1)\ndf_train['electricity_other'] = df_train.apply(lambda x : fill_no_electricity(x), axis=1)\ndf_test['electricity_other'] = df_test.apply(lambda x : fill_no_electricity(x), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Extract cat features"},{"metadata":{},"cell_type":"markdown","source":"* According to data scription, there are many binary category features"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_cat_features = [col for col in df_train.columns if df_train[col].value_counts().shape[0] == 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_cat_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Make new features using continuos feature"},{"metadata":{},"cell_type":"markdown","source":"* continuous feature ? 연속적인 기능? 속성? 숫자가 의미있는 연속..?"},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_features = [col for col in df_train.columns if col not in binary_cat_features]\ncontinuous_features = [col for col in continuous_features if col not in features_object]\ncontinuous_features = [col for col in continuous_features if col not in ['Id', 'Target', 'idhogar']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} continuous features'.format(len(continuous_features)))\nfor col in continuous_features:\n    print('{}: {}'.format(col, description.loc[description['varname'] == col, 'description'].values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* => hhsize : household size\n* => tamhog : size of the household \n* => What is different? hm, just drop 'tamhog' feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['tamhog'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop('tamhog', axis=1, inplace=True)\ndf_test.drop('tamhog', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Squared features"},{"metadata":{},"cell_type":"markdown","source":"* For this data, have many squared features.\n* LightGBM ( Tree model ) don't need these features.\n* => set entity-embedding as classifier ? "},{"metadata":{},"cell_type":"markdown","source":"### Family features"},{"metadata":{},"cell_type":"markdown","source":"* hogar_nin, hogar_adul, hogar_mayor, hogar_total, r4h1, r4h2, r4h3, r4m1, r4m2, r4m3, r4t1, r4t2, r4t3, tmbhog, tamvid, rez_esc, escolari\n* Family size features : substract, ratio\n* make new features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"hogar_adul\",\" Number of adults in household\"),\n# (\"hogar_mayor\",\" # of individuals 65+ in the household\"),\ndf_train['adult'] = df_train['hogar_adul'] - df_train['hogar_mayor']\n\n# (\"hogar_nin\",\" Number of children 0 to 19 in household\"),\n# (\"hogar_mayor\",\" # of individuals 65+ in the household\"),\ndf_train['dependency_count'] = df_train['hogar_nin'] + df_train['hogar_mayor']\n\n# (\"dependency\",\" Dependency rate\"),\ndf_train['dependency'] = df_train['dependency_count'] / df_train['adult']\n\n# (\"hogar_nin\",\" Number of children 0 to 19 in household\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['child_percent'] = df_train['hogar_nin'] / df_train['hogar_total']\n\n# (\"hogar_mayor\",\" # of individuals 65+ in the household\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['elder_percent'] = df_train['hogar_mayor'] / df_train['hogar_total']\n\n# (\"hogar_adul\",\" Number of adults in household\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['adult_percent'] = df_train['hogar_adul'] / df_train['hogar_total']\n\n# (\"r4h2\",\" Males 12 years of age and older\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['males_older_12_years_percent'] = df_train['r4h2'] / df_train['hogar_total']\n\n# (\"r4h3\",\" Total males in the household\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['males_percent'] = df_train['r4h3'] / df_train['hogar_total']\n\n# (\"r4m1\",\" Females younger than 12 years of age\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['females_older_12_years_percent'] = df_train['r4m2'] / df_train['hogar_total']\n\n# (\"r4m3\",\" Total females in the household\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['females_percent'] = df_train['r4m3'] / df_train['hogar_total']\n\n# (\"r4t1\",\" persons younger than 12 years of age\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['persons_younger_12_years_percent'] = df_train['r4t1'] / df_train['hogar_total']\n\n# (\"r4t2\",\" persons 12 years of age and older\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['persons_older_12_years_percent'] = df_train['r4t2'] / df_train['hogar_total']\n\n# (\"r4t3\",\" Total persons in the household\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['persons_percent'] = df_train['r4t3'] / df_train['hogar_total']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['adult'] = df_test['hogar_adul'] - df_test['hogar_mayor']\ndf_test['dependency_count'] = df_test['hogar_nin'] + df_test['hogar_mayor']\ndf_test['dependency'] = df_test['dependency_count'] / df_test['adult']\ndf_test['child_percent'] = df_test['hogar_nin'] / df_test['hogar_total']\ndf_test['elder_percent'] = df_test['hogar_mayor'] / df_test['hogar_total']\ndf_test['adult_percent'] = df_test['hogar_adul'] / df_test['hogar_total']\ndf_test['males_younger_12_years_percent'] = df_test['r4h1'] / df_test['hogar_total']\ndf_test['males_older_12_years_percent'] = df_test['r4h2'] / df_test['hogar_total']\ndf_test['males_percent'] = df_test['r4h3'] / df_test['hogar_total']\ndf_test['females_younger_12_years_percent'] = df_test['r4m1'] / df_test['hogar_total']\ndf_test['females_older_12_years_percent'] = df_test['r4m2'] / df_test['hogar_total']\ndf_test['females_percent'] = df_test['r4m3'] / df_test['hogar_total']\ndf_test['persons_younger_12_years_percent'] = df_test['r4t1'] / df_test['hogar_total']\ndf_test['persons_older_12_years_percent'] = df_test['r4t2'] / df_test['hogar_total']\ndf_test['persons_percent'] = df_test['r4t3'] / df_test['hogar_total']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"r4h1\",\" Males younger than 12 years of age\"),\n# (\"hhsize\",\" household size\"),\ndf_train['males_younger_12_years_in_household_size'] = df_train['r4h1'] / df_train['hhsize']\n\n# (\"r4h2\",\" Males 12 years of age and older\"),\n# (\"hhsize\",\" household size\"),\ndf_train['males_older_12_years_in_household_size'] = df_train['r4h2'] / df_train['hhsize']\n\n# (\"r4h3\",\" Total males in the household\"),\n# (\"hhsize\",\" household size\"),\ndf_train['males_in_household_size'] = df_train['r4h3'] / df_train['hhsize']\n\n# (\"r4m1\",\" Females younger than 12 years of age\"),\n# (\"hhsize\",\" household size\"),\ndf_train['females_younger_12_years_in_household_size'] = df_train['r4m1'] / df_train['hhsize']\n\n# (\"r4m2\",\" Females 12 years of age and older\"),\n# (\"hhsize\",\" household size\"),\ndf_train['females_older_12_years_in_household_size'] = df_train['r4m2'] / df_train['hhsize']\n\n# (\"r4m3\",\" Total females in the household\"),\n# (\"hogar_total\",\" # of total individuals in the household\"),\ndf_train['females_in_household_size'] = df_train['r4m3'] / df_train['hogar_total']\n\n# (\"r4t1\",\" persons younger than 12 years of age\"),\n# (\"hhsize\",\" household size\"),\ndf_train['persons_younger_12_years_in_household_size'] = df_train['r4t1'] / df_train['hhsize']\n\n# (\"r4t2\",\" persons 12 years of age and older\"),\n# (\"hhsize\",\" household size\"),\ndf_train['persons_older_12_years_in_household_size'] = df_train['r4t2'] / df_train['hhsize']\n\n# (\"r4t3\",\" Total persons in the household\"),\n# (\"hhsize\",\" household size\"),\ndf_train['persons_in_household_size'] = df_train['r4t3'] / df_train['hhsize']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['males_younger_12_years_in_household_size'] = df_test['r4h1'] / df_test['hhsize']\ndf_test['males_older_12_years_in_household_size'] = df_test['r4h2'] / df_test['hhsize']\ndf_test['males_in_household_size'] = df_test['r4h3'] / df_test['hhsize']\ndf_test['females_younger_12_years_in_household_size'] = df_test['r4m1'] / df_test['hhsize']\ndf_test['females_older_12_years_in_household_size'] = df_test['r4m2'] / df_test['hhsize']\ndf_test['females_in_household_size'] = df_test['r4m3'] / df_test['hogar_total']\ndf_test['persons_younger_12_years_in_household_size'] = df_test['r4t1'] / df_test['hhsize']\ndf_test['persons_older_12_years_in_household_size'] = df_test['r4t2'] / df_test['hhsize']\ndf_test['persons_in_household_size'] = df_test['r4t3'] / df_test['hhsize']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"hacdor\",\" =1 Overcrowding by bedrooms\"),\n# (\"hacapo\",\" =1 Overcrowding by rooms\"),\ndf_train['overcrowding_room_and_bedroom'] = ( df_train['hacdor'] + df_train['hacapo'] ) / 2\ndf_test['overcrowding_room_and_bedroom'] = ( df_test['hacdor'] + df_test['hacapo'] ) / 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"escolari\",\" years of schooling\"),\n# (\"age\",\" Age in years\"),\ndf_train['escolari_age'] = df_train['escolari'] / df_train['age']\ndf_test['escolari_age'] = df_test['escolari'] / df_test['age']\n\n# (\"hogar_nin\",\" Number of children 0 to 19 in household\"),\n# (\"r4t1\",\" persons younger than 12 years of age\"),\ndf_train['age_12_19'] = df_train['hogar_nin'] - df_train['r4t1']\ndf_test['age_12_19'] = df_test['hogar_nin'] - df_test['r4t1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"qmobilephone\",\" # of mobile phones\"),\n# (\"tamviv\",\" number of persons living in the household\"),\ndf_train['phones-per-capita'] = df_train['qmobilephone'] / df_train['tamviv']\n\n# (\"v18q1\",\" number of tablets household owns\"),\n# (\"tamviv\",\" number of persons living in the household\"),\ndf_train['tablets-per-capita'] = df_train['v18q1'] / df_train['tamviv']\n\n# (\"rooms\",\"  number of all rooms in the house\"),\n# (\"tamviv\",\" number of persons living in the household\"),\ndf_train['rooms-per-capita'] = df_train['rooms'] / df_train['tamviv']\n\n# (\"v2a1\",\" Monthly rent payment\"),\n# (\"tamviv\",\" number of persons living in the household\"),\ndf_train['rent-per-capita'] = df_train['v2a1'] / df_train['tamviv']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['phones-per-capita'] = df_test['qmobilephone'] / df_test['tamviv']\ndf_test['tablets-per-capita'] = df_test['v18q1'] / df_test['tamviv']\ndf_test['rooms-per-capita'] = df_test['rooms'] / df_test['tamviv']\ndf_test['rent-per-capita'] = df_test['v2a1'] / df_test['tamviv']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* (\"hogar_total\",\" # of total individuals in the household\"),\n* (\"r4t3\",\" Total persons in the household\"),\n* => not equal "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"( df_train['hogar_total'] == df_train['r4t3'] ).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* => 뭔가 합산하는 과정에서 오류가 있어서 차이가 남. 두 features를 유지하는 것도 이상함... \n* => 그럼에도 불구하고, 유지..."},{"metadata":{},"cell_type":"markdown","source":"### Rent per family features"},{"metadata":{},"cell_type":"markdown","source":"* Reduce the number of features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"v2a1\",\" Monthly rent payment\"),\n\nfamily_size_features = ['adult', 'hogar_adul', 'hogar_mayor', 'hogar_nin', 'hogar_total', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'hhsize']\nnew_feats = []\nfor col in family_size_features:\n    new_col_name = 'new_{}_per_{}'.format('v2a1', col)\n    new_feats.append(new_col_name)\n    df_train[new_col_name] = df_train['v2a1'] / df_train[col]\n    df_test[new_col_name] = df_test['v2a1'] / df_train[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_feats","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Ratio feature can have infinite values. So let them be filled with 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in new_feats:\n    df_train[col].replace([np.inf], np.nan, inplace=True)\n    df_train[col].fillna(0, inplace=True)\n    \n    df_test[col].replace([np.inf], np.nan, inplace=True)\n    df_test[col].fillna(0, inplace=True)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Room per family features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"rooms\",\"  number of all rooms in the house\"),\nnew_feats = []\nfor col in family_size_features:\n    new_col_name = 'new_{}_{}'.format('rooms', col)\n    new_feats.append(new_col_name)\n    df_train[new_col_name] = df_train['rooms'] / df_train[col]\n    df_test[new_col_name] = df_test['rooms'] / df_test[col]\n    \nfor col in new_feats:\n    df_train[col].replace([np.inf], np.nan, inplace=True)\n    df_train[col].fillna(0, inplace=True)\n    \n    df_test[col].replace([np.inf], np.nan, inplace=True)\n    df_test[col].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### BedRoom per family features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"bedrooms\",\" number of bedrooms\"),\nnew_feats = []\nfor col in family_size_features:\n    new_col_name = 'new_{}_per_{}'.format('bedrooms', col)\n    new_feats.append(new_col_name)\n    df_train[new_col_name] = df_train['bedrooms'] / df_train[col]\n    df_test[new_col_name] = df_test['bedrooms'] / df_test[col]\n    \nfor col in new_feats:\n    df_train[col].replace([np.inf], np.nan, inplace=True)\n    df_train[col].fillna(0, inplace=True)\n    \n    df_test[col].replace([np.inf], np.nan, inplace=True)\n    df_test[col].fillna(0, inplace=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of features, target is in train\nprint(df_train.shape, df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tabulet per family features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"v18q1\",\" number of tablets household owns\"),\n\nnew_feats = []\nfor col in family_size_features:\n    new_col_name = 'new_{}_per_{}'.format('v18q1', col)\n    new_feats.append(new_col_name)\n    df_train[new_col_name] = df_train['v18q1'] / df_train[col]\n    df_test[new_col_name] = df_test['v18q1'] / df_test[col]\n    \nfor col in new_feats:\n    df_train[col].replace([np.inf], np.nan, inplace=True)\n    df_train[col].fillna(0, inplace=True)\n    \n    df_test[col].replace([np.inf], np.nan, inplace=True)\n    df_test[col].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### phone per family features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"qmobilephone\",\" # of mobile phones\"),\nnew_feats = []\nfor col in family_size_features:\n    new_col_name = 'new_{}_per_{}'.format('qmobilephone', col)\n    new_feats.append(new_col_name)\n    df_train[new_col_name] = df_train['qmobilephone'] / df_train[col]\n    df_test[new_col_name] = df_test['qmobilephone'] / df_test[col]\n\nfor col in new_feats:\n    df_train[col].replace([np.inf], np.nan, inplace=True)\n    df_train[col].fillna(0, inplace=True)\n    \n    df_test[col].replace([np.inf], np.nan, inplace=True)\n    df_test[col].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### rez_esc per family feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"rez_esc\",\" Years behind in school\"),\nnew_feats = []\nfor col in family_size_features:\n    new_col_name = 'new_{}_per_{}'.format('rez_esc', col)\n    new_feats.append(new_col_name)\n    df_train[new_col_name] = df_train['rez_esc'] / df_train[col]\n    df_test[new_col_name] = df_test['rez_esc'] / df_test[col]\n\nfor col in new_feats:\n    df_train[col].replace([np.inf], np.nan, inplace=True)\n    df_train[col].fillna(0, inplace=True)\n    \n    df_test[col].replace([np.inf], np.nan, inplace=True)\n    df_test[col].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"age\",\" Age in years\"),\n# (\"escolari\",\" years of schooling\"),\ndf_train['rez_esc_age'] = df_train['rez_esc'] / df_train['age']\ndf_train['rez_esc_escolari'] = df_train['rez_esc'] / df_train['escolari']\n\ndf_test['rez_esc_age'] = df_test['rez_esc'] / df_test['age']\ndf_test['rez_esc_escolari'] = df_test['rez_esc'] / df_test['escolari']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rich features"},{"metadata":{},"cell_type":"markdown","source":"* => higer income "},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"v18q1\",\" number of tablets household owns\"),\n# (\"qmobilephone\",\" # of mobile phones\"),\ndf_train['tabulet_x_qmobilephone'] = df_train['v18q1'] * df_train['qmobilephone']\ndf_test['tabulet_x_qmobilephone'] = df_test['v18q1'] * df_test['qmobilephone']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* wall, roof, floor may be key features\n* => binary category features  -> multification of each features generate new categori features"},{"metadata":{"trusted":true},"cell_type":"code","source":"(\"epared1\",\" =1 if walls are bad\"),\n(\"epared2\",\" =1 if walls are regular\"),\n(\"epared3\",\" =1 if walls are good\"),\n\n(\"etecho1\",\" =1 if roof are bad\"),\n(\"etecho2\",\" =1 if roof are regular\"),\n(\"etecho3\",\" =1 if roof are good\"),\n\n# wall and roof\nfor col1 in ['epared1', 'epared2', 'epared3']:\n    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]\n\n# (\"eviv1\",\" =1 if floor are bad\"),\n# (\"eviv2\",\" =1 if floor are regular\"),\n# (\"eviv3\",\" =1 if floor are good\"),\n\n# wall and floor\nfor col1 in ['epared1', 'epared2', 'epared3']:\n    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]\n\n\n# roof and floor\nfor col1 in ['etecho1', 'etecho2', 'etecho3']:\n    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* combine using above 3 features"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col1 in ['epared1', 'epared2', 'epared3']:\n    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n        for col3 in ['eviv1', 'eviv2', 'eviv3']:\n            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape, df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Mixing electricity and energy features => energy features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"public\",\" =1 electricity from CNFL,  ICE, ESPH/JASEC\"),\n# (\"planpri\",\" =1 electricity from private plant\"),\n# (\"noelec\",\" =1 no electricity in the dwelling\"),\n# (\"coopele\",\" =1 electricity from cooperative\"),\n\n# (\"energcocinar1\",\" =1 no main source of energy used for cooking (no kitchen)\"),\n# (\"energcocinar2\",\" =1 main source of energy used for cooking electricity\"),\n# (\"energcocinar3\",\" =1 main source of energy used for cooking gas\"),\n# (\"energcocinar4\",\" =1 main source of energy used for cooking wood charcoal\"),\n\nfor col1 in ['public', 'planpri', 'noelec', 'coopele']:\n    for col2 in ['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* * Mixing toilet and rubbish disposal(쓰레기 처분) features => other_infra features\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"sanitario1\",\" =1 no toilet in the dwelling\"),\n# (\"sanitario2\",\" =1 toilet connected to sewer or cesspool\"),\n# (\"sanitario3\",\" =1 toilet connected to  septic tank\"),\n# (\"sanitario5\",\" =1 toilet connected to black hole or letrine\"),\n# (\"sanitario6\",\" =1 toilet connected to other system\"),\n\n# (\"elimbasu1\",\" =1 if rubbish disposal mainly by tanker truck\"),\n# (\"elimbasu2\",\" =1 if rubbish disposal mainly by botan hollow or buried\"),\n# (\"elimbasu3\",\" =1 if rubbish disposal mainly by burning\"),\n# (\"elimbasu4\",\" =1 if rubbish disposal mainly by throwing in an unoccupied space\"),\n# (\"elimbasu5\",\" =1 if rubbish disposal mainly by throwing in river,   creek or sea\"),\n# (\"elimbasu6\",\" =1 if rubbish disposal mainly other\"),\n\nfor col1 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n    for col2 in ['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Mixing toilet and water provision features => water features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"abastaguadentro\",\" =1 if water provision inside the dwelling\"),\n# (\"abastaguafuera\",\" =1 if water provision outside the dwelling\"),\n# (\"abastaguano\",\" =1 if no water provision\"),\n\n# (\"sanitario1\",\" =1 no toilet in the dwelling\"),\n# (\"sanitario2\",\" =1 toilet connected to sewer or cesspool\"), 하수구\n# (\"sanitario3\",\" =1 toilet connected to  septic tank\"), 정화조\n# (\"sanitario5\",\" =1 toilet connected to black hole or letrine\"), 변소\n# (\"sanitario6\",\" =1 toilet connected to other system\"),\n\n\nfor col1 in ['abastaguadentro', 'abastaguafuera', 'abastaguano']:\n    for col2 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape, df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Mixing education and area features => educaiton_zone_features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"area1\",\" =1 zona urbana\"),\n# (\"area2\",\" =2 zona rural\"),\n\n# (\"instlevel1\",\" =1 no level of education\"),\n# (\"instlevel2\",\" =1 incomplete primary\"),\n# (\"instlevel3\",\" =1 complete primary\"),\n# (\"instlevel4\",\" =1 incomplete academic secondary level\"),\n# (\"instlevel5\",\" =1 complete academic secondary level\"),\n# (\"instlevel6\",\" =1 incomplete technical secondary level\"),\n# (\"instlevel7\",\" =1 complete technical secondary level\"),\n# (\"instlevel8\",\" =1 undergraduate and higher education\"),\n# (\"instlevel9\",\" =1 postgraduate higher education\"),\n\nfor col1 in ['area1', 'area2']:\n    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Mixing region and education"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"lugar1\",\" =1 region Central\"),\n# (\"lugar2\",\" =1 region Chorotega\"),\n# (\"lugar3\",\" =1 region PacÃƒÂ­fico central\"),\n# (\"lugar4\",\" =1 region Brunca\"),\n# (\"lugar5\",\" =1 region Huetar AtlÃƒÂ¡ntica\"),\n# (\"lugar6\",\" =1 region Huetar Norte\"),\n\nfor col1 in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape, df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Multiply television, mobilephone, computer, tabulet and refrigerator => electronics feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"computer\",\" =1 if the household has notebook or desktop computer,   borrowed)\"),\n# (\"television\",\" =1 if the household has TV\"),\n# (\"mobilephone\",\" =1 if mobile phone\"),\n# (\"v18q\",\" owns a tablet\"),\n# (\"refrig\",\" =1 if the household has refrigerator\"),\n\ndf_train['electronics'] = df_train['computer'] * df_train['mobilephone'] * df_train['television'] * df_train['v18q'] * df_train['refrig']\ndf_test['electronics'] = df_test['computer'] * df_test['mobilephone'] * df_test['television'] * df_test['v18q'] * df_test['refrig']\n\ndf_train['no_appliances'] = df_train['refrig'] + df_train['computer'] + df_train['television'] + df_train['mobilephone']\ndf_test['no_appliances'] = df_test['refrig'] + df_test['computer'] + df_test['television'] + df_test['mobilephone']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Mixing wall material of roof, floor, and wall"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"paredblolad\",\" =1 if predominant material(주 재료) on the outside wall is block or brick\"), 블록/벽돌\n# (\"paredzocalo\",\" =1 if predominant material on the outside wall is socket (wood, zinc or absbesto\"), 나무, 아연, \n# (\"paredpreb\",\" =1 if predominant material on the outside wall is prefabricated or cement\"), 조립식(?) 시멘트\n# (\"pareddes\",\" =1 if predominant material on the outside wall is waste material\"), 폐기물\n# (\"paredmad\",\" =1 if predominant material on the outside wall is wood\"),\n# (\"paredzinc\",\" =1 if predominant material on the outside wall is zink\"),\n# (\"paredfibras\",\" =1 if predominant material on the outside wall is natural fibers\"), 천연 섬유\n# (\"paredother\",\" =1 if predominant material on the outside wall is other\"),\n\n# (\"pisomoscer\",\" =1 if predominant material on the floor is mosaic ceramic   terrazo\"),\n# (\"pisocemento\",\" =1 if predominant material on the floor is cement\"),\n# (\"pisoother\",\" =1 if predominant material on the floor is other\"),\n# (\"pisonatur\",\" =1 if predominant material on the floor is  natural material\"),\n# (\"pisonotiene\",\" =1 if no floor at the household\"),\n# (\"pisomadera\",\" =1 if predominant material on the floor is wood\"),\n\n\nfor col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]\n\n# (\"techozinc\",\" =1 if predominant material on the roof is metal foil or zink\"), 금속 호일, 나무\n# (\"techoentrepiso\",\" =1 if predominant material on the roof is fiber cement,   mezzanine \"), 섬유 시멘트(?),  메자닌(?)\n# (\"techocane\",\" =1 if predominant material on the roof is natural fibers\"),\n# (\"techootro\",\" =1 if predominant material on the roof is other\"),\n\nfor col1 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n    for col1 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]\n        \nfor col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n    for col2 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n        df_train[new_col_name] = df_train[col1] * df_train[col2]\n        df_test[new_col_name] = df_test[col1] * df_test[col2]        \n        \nfor col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n        for col3 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape, df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now, let's remove features with only one attribute\n* => 여태 만들었는데, 지운다고? "},{"metadata":{},"cell_type":"markdown","source":"### Remove feature with only one value"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_with_only_one_value = []\nfor col in df_train.columns:\n    if col == 'Target':\n        continue\n    if df_train[col].value_counts().shape[0] == 1 or df_test[col].value_counts().shape[0] == 1:\n        print(col)\n        cols_with_only_one_value.append(col)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(cols_with_only_one_value, axis=1, inplace=True)\ndf_test.drop(cols_with_only_one_value, axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check whether both train and test have same features"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_train = np.array(sorted([col for col in df_train.columns if col != 'Target']))\ncols_test = np.array(sorted(df_test.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(cols_train == cols_test).sum() == len(cols_train)\n\n# ??? ValueError: shape mismatch: objects cannot be broadcast to a single shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4 aggregation features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def max_min(x):\n    return x.max() - x.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (\"idhogar\",\" Household level identifier\"),\n# tqdm : for 문의 상태바를 나타내줌.\n# family_size_features = ['adult', 'hogar_adul', 'hogar_mayor', 'hogar_nin', 'hogar_total', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'hhsize']\n\nagg_train = pd.DataFrame()\nagg_test = pd.DataFrame()\n\nfor item in tqdm(family_size_features):\n    for i, function in enumerate(['mean','std','min','max','sum', 'count', max_min]):\n        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n        if i == 6:\n            new_col = item + '_new_' + 'max_min'\n        else:\n            new_col = item + '_new_' + function\n        agg_train[new_col] = group_train\n        agg_test[new_col] = group_test\n\nprint('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\nprint('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aggr_list = ['rez_esc', 'dis', 'male', 'female', \n                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n                  'parentesco11', 'parentesco12',\n                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n            'area1', 'area2', 'v18q', 'edjef']\n\n\n\nfor item in tqdm(aggr_list):\n    for function in ['count', 'sum']:\n        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n        new_col = item + '_new1_' + function\n        agg_train[new_col] = group_train\n        agg_test[new_col] = group_test\nprint('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\nprint('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aggr_list = ['escolari', 'age', 'escolari_age', 'dependency', 'bedrooms', 'overcrowding', 'rooms', 'qmobilephone', 'v18q1']\n\nfor item in tqdm(aggr_list):\n    for function in ['mean','std','min','max','sum', 'count', max_min]:\n        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n        if i == 6:\n            new_col = item + '_new2_' + 'max_min'\n        else:\n            new_col = item + '_new2_' + function\n        agg_train[new_col] = group_train\n        agg_test[new_col] = group_test\n\nprint('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\nprint('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_test = agg_test.reset_index()\nagg_train = agg_train.reset_index()\n\ntrain_agg = pd.merge(df_train, agg_train, on='idhogar')\ntest = pd.merge(df_test, agg_test, on='idhogar')\n\n#fill all na as 0\ntrain_agg.fillna(value=0, inplace=True)\ntest.fillna(value=0, inplace=True)\n\nprint('train shape:', train_agg.shape, 'test shape:', test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aggr_list = ['rez_esc', 'dis', 'male', 'female', \n                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n                  'parentesco11', 'parentesco12',\n                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n            'area1', 'area2', 'v18q', 'edjef']\n    \nfor lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n    group_train.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n\n    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n    group_test.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n\n    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n    \nprint('train shape:', train_agg.shape, 'test shape:', test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aggr_list = ['rez_esc', 'dis', 'male', 'female', \n                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n                  'parentesco11', 'parentesco12',\n                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n            'area1', 'area2', 'v18q', 'edjef']\n    \nfor lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n    group_train.columns = [lugar, 'idhogar'] + ['new4_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n\n    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n    group_test.columns = [lugar, 'idhogar'] + ['new4_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n\n    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n    \nprint('train shape:', train_agg.shape, 'test shape:', test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이 로직은 시간이 많이 소요..  over 10min...\ncols_nums = ['age', 'meaneduc', 'dependency', \n             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n             'bedrooms', 'overcrowding']\n\nfor function in tqdm(['mean','std','min','max','sum', 'count', max_min]):\n    for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n        group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n        group_train.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_train][2:]\n\n        group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n        group_test.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_test][2:]\n\n        train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n        test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n        \nprint('train shape:', train_agg.shape, 'test shape:', test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* According to data descriptions,ONLY the heads of household are used in scoring. /\n* All household members are included in test + the sample submission, but only heads of households are scored."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train_agg.query('parentesco1==1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['dependency'].replace(np.inf, 0, inplace=True)\ntest['dependency'].replace(np.inf, 0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test[['Id']]\n\n#Remove useless feature to reduce dimension\ntrain.drop(columns=['idhogar','Id', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\ntest.drop(columns=['idhogar','Id',  'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n\ncorrelation = train.corr()\ncorrelation = correlation['Target'].sort_values(ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('final_data size', train.shape, test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'The most 20 positive feature: \\n{correlation.head(40)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'The most 20 negative feature: \\n{correlation.tail(20)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Feature selection using shap"},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape[0] == 2, 두 가지 값을 가진 feature는 binary category\n#\nbinary_cat_features = [col for col in train.columns if train[col].value_counts().shape[0] == 2]\nobject_features = ['edjefe', 'edjefa']\n\n# category 는 binary와 object를 합침.\ncategorical_feats = binary_cat_features + object_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_feats","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* https://www.youtube.com/watch?v=3llmZMHHL_8 \n* True Positive Rate / False Positive Rate ..."},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_macroF1_lgb(truth, predictions):  \n    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n    f1 = f1_score(truth, pred_labels, average='macro')\n    return ('macroF1', f1, True) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['Target']\ntrain.drop(columns=['Target'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_execution_time(start):\n    end = time.time()\n    hours, rem = divmod(end-start, 3600)\n    minutes, seconds = divmod(rem, 60)\n    print('*'*20, \"Execution ended in {:0>2}h {:0>2}m {:05.2f}s\".format(int(hours),int(minutes),seconds), '*'*20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_good_features_using_shap_LGB(params, SEED):\n    clf = lgb.LGBMClassifier(objective='multiclass',\n                             random_state=1989,\n                             max_depth=params['max_depth'], \n                             learning_rate=params['learning_rate'],  \n                             silent=True, \n                             metric='multi_logloss',\n                             n_jobs=-1, n_estimators=10000, \n                             class_weight='balanced',\n                             colsample_bytree = params['colsample_bytree'], \n                             min_split_gain= params['min_split_gain'], \n                             bagging_freq = params['bagging_freq'],\n                             min_child_weight=params['min_child_weight'],\n                             num_leaves = params['num_leaves'], \n                             subsample = params['subsample'],\n                             reg_alpha= params['reg_alpha'],\n                             reg_lambda= params['reg_lambda'],\n                             num_class=len(np.unique(y)),\n                             bagging_seed=SEED,\n                             seed=SEED,\n                            )\n\n    kfold = 5\n    kf = StratifiedKFold(n_splits=kfold, shuffle=True) \n           # shuffle before divide data\n           # n_splits : 5 divide\n            \n    feat_importance_df  = pd.DataFrame()\n\n    for i, (train_index, test_index) in enumerate(kf.split(train, y)):\n        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n        start = time.time()\n        X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb, \n                categorical_feature=categorical_feats,\n                early_stopping_rounds=500, verbose=500)\n        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n        fold_importance_df  = pd.DataFrame()\n        fold_importance_df['feature'] = X_train.columns\n        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n        fold_importance_df['feat_imp'] = clf.feature_importances_\n        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n        print_execution_time(start)\n\n    feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n#     feat_importance_df_shap['shap_cumsum'] = feat_importance_df_shap['shap_values'].cumsum() / feat_importance_df_shap['shap_values'].sum()\n#     good_features = feat_importance_df_shap.loc[feat_importance_df_shap['shap_cumsum'] < 0.999].feature\n    return feat_importance_df_shap\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* SHAP ( SHapley Additive exPlanations ) ; https://shap.readthedocs.io/en/latest/\n* => https://github.com/OpenXAIProject/PyConKorea2019-Tutorials/blob/master/SHAP/PyConKorea2019-SHAP-tutorial-presentation.pdf \n* => Model-Agnostic Methods (모델 불가지론적 방법)??"},{"metadata":{"trusted":true},"cell_type":"code","source":"# run time : 10???min\ntotal_shap_df  = pd.DataFrame()\nNUM_ITERATIONS = 3\nfor SEED in range(NUM_ITERATIONS):\n    print('#'*40, '{} of {} iterations'.format(SEED+1, NUM_ITERATIONS), '#' * 40)\n    params = {'max_depth': np.random.choice([5, 6, 7, 8, 10, 12, -1]),\n             'learning_rate': np.random.rand() * 0.02,\n              'colsample_bytree': np.random.rand() * (1 - 0.5) + 0.5,\n              'subsample': np.random.rand() * (1 - 0.5) + 0.5,\n              'min_split_gain': np.random.rand() * 0.2,\n              'num_leaves': np.random.choice([32, 48, 64]),\n              'reg_alpha': np.random.rand() * 2,\n              'reg_lambda': np.random.rand() *2,\n              'bagging_freq': np.random.randint(4) +1,\n              'min_child_weight': np.random.randint(100) + 20\n             }\n    temp_shap_df = extract_good_features_using_shap_LGB(params, SEED)\n    total_shap_df = pd.concat([total_shap_df, temp_shap_df])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1) SHAP value 높은 순으로 정렬해서 shap_sorted_df 에 저장.\nshap_sorted_df = total_shap_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n\n# 2) LGBM feature importances feature를 feat_imp_sorted_df에 저장\n\n# LGBMClassifier : 각 독립 변수의 중요도(feature importance)를 계산할 수 있다는 점이다.\n# 모든 노드에 대해 어떤 독립 변수를 사용하였고 그 노드에서 얻은 information gain을 구할 수 있으므로 \n# 각각의 독립 변수들이 얻어낸 information gain의 평균을 비교하면 어떤 독립 변수가 중요한지를 비교할 수 있다.\n# feat_imp은 LGBMClassifier.feature_importances_ feature임.\nfeat_imp_sorted_df = total_shap_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n\n# 3) 상위 500개만 가져옴.\nfeatures_top_shap = shap_sorted_df['feature'][:500]\nfeatures_top_feat_imp = feat_imp_sorted_df['feature'][:500]\n\n# 4) 위 두 feature를 합쳐서 top_features를 만듬.\ntop_features = pd.Series(features_top_shap.tolist() + features_top_feat_imp.tolist())\ntop_features = top_features.unique()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Model development"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = train[top_features].copy()\nnew_test = test[top_features].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('new_train shape:', new_train.shape, 'new_test shape:', new_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# top_features 중에서, categorical_feats 만 뽑아냄.\nnew_categorical_feats = [col for col in top_features if col in categorical_feats]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LGB_OOF(params, categorical_feats, N_FOLDs, SEED=1989):\n    clf = lgb.LGBMClassifier(objective='multiclass',\n                             random_state=1989,\n                             max_depth=params['max_depth'], \n                             learning_rate=params['learning_rate'],  \n                             silent=True, \n                             metric='multi_logloss',\n                             n_jobs=-1, n_estimators=10000, \n                             class_weight='balanced',\n                             colsample_bytree = params['colsample_bytree'], \n                             min_split_gain= params['min_split_gain'], \n                             bagging_freq = params['bagging_freq'],\n                             min_child_weight=params['min_child_weight'],\n                             num_leaves = params['num_leaves'], \n                             subsample = params['subsample'],\n                             reg_alpha= params['reg_alpha'],\n                             reg_lambda= params['reg_lambda'],\n                             num_class=len(np.unique(y)),\n                             bagging_seed=SEED,\n                             seed=SEED,\n                            )\n\n    kfold = N_FOLDs\n    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n    feat_importance_df  = pd.DataFrame()\n    predicts_result = []\n\n    for i, (train_index, test_index) in enumerate(kf.split(new_train, y)):\n        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n        start = time.time()\n        X_train, X_val = new_train.iloc[train_index], new_train.iloc[test_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb,categorical_feature=new_categorical_feats,\n                early_stopping_rounds=500, verbose=500)\n        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n        fold_importance_df  = pd.DataFrame()\n        fold_importance_df['feature'] = X_train.columns\n        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n        fold_importance_df['feat_imp'] = clf.feature_importances_\n        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n        predicts_result.append(clf.predict(new_test))\n        print_execution_time(start)\n    return predicts_result, feat_importance_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'max_depth': 6,\n         'learning_rate': 0.002,\n          'colsample_bytree': 0.8,\n          'subsample': 0.8,\n          'min_split_gain': 0.02,\n          'num_leaves': 48,\n          'reg_alpha': 0.04,\n          'reg_lambda': 0.073,\n          'bagging_freq': 2,\n          'min_child_weight': 40\n         }\n\nN_Folds = 20\nSEED = 1989\n\n# predit결과와 모델(SHAP value포함) 에서 중요한 feat \npredicts_result, feat_importance_df = LGB_OOF(params, new_categorical_feats, N_Folds, SEED=1989)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(20, 20))\nfeat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n\nnum_features = 50\nsns.barplot(x=feat_importance_df_shap.shap_values[:num_features], y=feat_importance_df_shap.feature[:num_features], ax=ax[0])\nax[0].set_title('Feature importance based on shap values')\n\nfeat_importance_df = feat_importance_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n\nnum_features = 50\nsns.barplot(x=feat_importance_df.shap_values[:num_features], y=feat_importance_df.feature[:num_features], ax=ax[1])\nax[1].set_title('Feaure importance based on feature importance from lgbm')\nplt.show()\n\n# shap value 기준으로 중요한 feature\n#     => phones-per-capital, new5_lugar1_idhogar_instlevel8_mean..\n# LGBM에서 중요한 feature\n#     => measureduc, escolari_age ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\nsubmission.to_csv('submission_with_new_feature_set.csv', index = False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Randomized Search"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimized_param = None\nlowest_cv = 1000\ntotal_iteration = 100\nfor i in range(total_iteration):\n    print('-'*20, 'For {} of {} iterations'.format(i+1, total_iteration), '-'*20)\n    learning_rate = np.random.rand() * 0.02\n    n_folds = 3\n\n    num_class = len(np.unique(y))\n\n    params = {}\n    params['application'] = 'multiclass'\n    params['metric'] = 'multi_logloss'\n    params['num_class'] = num_class\n    params['class_weight'] = 'balanced'\n    params['num_leaves'] = np.random.randint(24, 48)\n    params['max_depth'] = np.random.randint(5, 8)\n    params['min_child_weight'] = np.random.randint(5, 50)\n    params['min_split_gain'] = np.random.rand() * 0.09\n    params['colsample_bytree'] = np.random.rand() * (0.9 - 0.1) + 0.1\n    params['subsample'] = np.random.rand() * (1 - 0.8) + 0.8\n    params['bagging_freq'] = np.random.randint(1, 5)\n    params['bagging_seed'] = np.random.randint(1, 5)\n    params['reg_alpha'] = np.random.rand() * 2\n    params['reg_lambda'] = np.random.rand() * 2\n    params['learning_rate'] = np.random.rand() * 0.02\n    params['seed']  =1989\n\n    d_train = lgb.Dataset(data=new_train, label=y.values-1, categorical_feature=new_categorical_feats, free_raw_data=False)\n    cv_results = lgb.cv(params=params, train_set=d_train, num_boost_round=10000, categorical_feature=new_categorical_feats,\n                        nfold=n_folds, stratified=True, shuffle=True, early_stopping_rounds=1, verbose_eval=1000)\n\n    min_cv_results = min(cv_results['multi_logloss-mean'])\n\n    if min_cv_results < lowest_cv:\n        lowest_cv = min_cv_results\n        optimized_param = params\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_Folds = 20\nSEED = 1989\npredicts_result, feat_importance_df = LGB_OOF(optimized_param, new_categorical_feats, N_Folds, SEED=1989)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\nsubmission.to_csv('submission_shap_randomized_search.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}