{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf =pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44b1ad2c049cd0f2866f59275ff181752ef14134"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acf6e261930526180240f1e5708a12e953ec6c68"},"cell_type":"code","source":"df_h = df.loc[df[\"parentesco1\"]==1]\ndf_h = df_h.fillna(0)\n\ndf_y =pd.DataFrame(df_h[\"Target\"])\ndf_y.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5da9441519888f46974f69bc145f9f5328b66a33"},"cell_type":"code","source":"df_x1 = df_h.drop([\"Target\"],1)\n#세대주성별 교육년수 (논의필요)\ndf_x1 = df_x1.drop([\"edjefa\", \"edjefe\"],1) \n#중복정보 제거\ndf_x1 = df_x1.drop([\"dependency\",\"female\",\"area2\",\"hacdor\",\"hacapo\",\"bedrooms\",\"r4h3\",\"r4m3\"],1) \n#수학적으로 의미가 없는 값 제거\ndf_x1 = df_x1.drop([\"Id\",\"SQBescolari\", \"SQBage\", \"SQBhogar_total\", \"SQBedjefe\", \"SQBhogar_nin\", \"SQBovercrowding\",\"idhogar\"],1) \n#세대주와의 관계열 제거\ndf_x1 = df_x1.drop([\"parentesco1\",\"parentesco2\",\"parentesco3\",\"parentesco4\",\"parentesco5\",\"parentesco6\",\"parentesco7\",\"parentesco8\",\n                   \"parentesco9\",\"parentesco10\",\"parentesco11\",\"parentesco12\"],1)\ndf_x1 = df_x1.drop([\"etecho1\"],[\"etecho2\"],[\"etecho3\"],[\"eviv1\"],[\"eviv2\"],[\"eviv3\"],1)\n#집세 임시제거!!!!!!!!!!!!!!!!!!!!!!!!!!\ndf_x1 = df_x1.drop([\"v2a1\"],1)\ndf_x1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"773ce7e5dbe7bb6aaf60dd35bde817c8339f8381"},"cell_type":"code","source":"df_x1['lent'] = df_x1['tamviv']-df_x1['tamhog']\n\n#열 생성 이후 불필요한 열 제거 \ndf_x1 = df_x1.drop([\"r4t1\",\"r4t2\",\"r4t3\",\"tamhog\",\"tamviv\"],1) \ndf_x1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"924b73ddae05327b184608d0c83235eedd967eaa"},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b6b13d03b64585d1ebc52a773352e1cb0e82198"},"cell_type":"code","source":"def xavier_init(n_inputs, n_outputs, uniform=True):\n    if uniform:\n        # 6 was used in the paper.\n        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n        return tf.random_uniform_initializer(-init_range, init_range)\n    else:\n        # 3 gives us approximately the same limints as above since this repicks\n        # values greater than 2 standard deviations from the mean.\n        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n        return tf.truncated_normal_initializer(stddev=stddev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22836476e6d217f0b98958e6f9a5276327439593"},"cell_type":"code","source":"df_y[\"Target\"]=df_y[\"Target\"]-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59516e912a41c833c253d34f728d3830dfef3ee9"},"cell_type":"code","source":"import tensorflow as tf\nimport random\nimport matplotlib.pyplot as plt\n\nx_data = x_data = df_x1\nsess = tf.Session()\ny_data = tf.one_hot(df_y, depth = 4).eval(session=sess)\ny_data = tf.reshape(y_data, shape=[-1,4]).eval(session=sess)\nprint(y_data)\ntf.set_random_seed(999)  # reproducibility\n\n\n# parameters\nlearning_rate = 0.001\n\n\n\nX = tf.placeholder(tf.float32, [None, 101])\nY = tf.placeholder(tf.float32, [None, 4])\nkeep_prob = tf.placeholder(tf.float32)\n\n\n\nW1 = tf.get_variable(\"W1\", shape=[101, 64], initializer=tf.contrib.layers.xavier_initializer())\nb1 = tf.Variable(tf.random_normal([64]))\nL1 = tf.nn.relu(tf.matmul(X, W1) + b1)\nL1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n\n\nW2 = tf.get_variable(\"W2\", shape=[64, 64], initializer=tf.contrib.layers.xavier_initializer())\nb2 = tf.Variable(tf.random_normal([64]))\nL2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\nL2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n\nW3 = tf.get_variable(\"W3\", shape=[64, 64], initializer=tf.contrib.layers.xavier_initializer())\nb3 = tf.Variable(tf.random_normal([64]))\nL3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\nL3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n\n\nW4 = tf.get_variable(\"W4\", shape=[64, 64], initializer=tf.contrib.layers.xavier_initializer())\nb4 = tf.Variable(tf.random_normal([64]))\nL4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\nL4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n\n\nW5 = tf.get_variable(\"W5\", shape=[64, 4], initializer=tf.contrib.layers.xavier_initializer())\nb5 = tf.Variable(tf.random_normal([4]))\nL5 = tf.nn.relu(tf.matmul(L4, W5) + b5)\n\nhypothesis = tf.matmul(L4, W5) + b5\n\n\n\nhypothesis = tf.matmul(L2, W3) + b3\n\n# define cost/loss & optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=hypothesis, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\ncorrect_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0056e36abb3c16d7afbfa694c55974ba6e2a5ea"},"cell_type":"code","source":"sess = tf.Session()\n\n# Initializes global variables in the graph.\nsess.run(tf.global_variables_initializer())\n\nfor step in range(10001):\n    sess.run(optimizer, feed_dict={X: x_data, Y: y_data,keep_prob:0.7})\n    if step % 1000 == 0 or step < 100:\n        loss, acc = sess.run([cost, accuracy], feed_dict={\n                             X: x_data, Y: y_data,keep_prob:0.7})\n        print(\"Step: {:5}, \\t Loss: {:.3f}, \\t Acc: {:.2%}\".format(\n            step, loss, acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f68af7c2fb63f0a2e083df01be409bd2a62fe9cc"},"cell_type":"code","source":"df2 =pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5958f9689079cde956f90184ac67695b6294491a"},"cell_type":"code","source":"df2_h = df2.fillna(0)\ndf2_x1 = df2_h\n#세대주성별 교육년수 (논의필요)\ndf2_x1 = df2_x1.drop([\"edjefa\", \"edjefe\"],1) \n#중복정보 제거\ndf2_x1 = df2_x1.drop([\"dependency\",\"female\",\"area2\",\"hacdor\",\"hacapo\",\"bedrooms\",\"r4h3\",\"r4m3\"],1) \n#수학적으로 의미가 없는 값 제거\ndf2_x1 = df2_x1.drop([\"Id\",\"SQBescolari\", \"SQBage\", \"SQBhogar_total\", \"SQBedjefe\", \"SQBhogar_nin\", \"SQBovercrowding\",\"idhogar\"],1) \n#세대주와의 관계열 제거\ndf2_x1 = df2_x1.drop([\"parentesco1\",\"parentesco2\",\"parentesco3\",\"parentesco4\",\"parentesco5\",\"parentesco6\",\"parentesco7\",\"parentesco8\",\n                   \"parentesco9\",\"parentesco10\",\"parentesco11\",\"parentesco12\"],1)\ndf2_x1['lent'] = df2_x1['tamviv']-df2_x1['tamhog']\n#집세 임시제거!!!!!!!!!!!!!!!!!!!!!!!!!!\ndf2_x1 = df2_x1.drop([\"v2a1\"],1)\ndf2_x1 = df2_x1.drop([\"r4t1\",\"r4t2\",\"r4t3\",\"tamhog\",\"tamviv\"],1) \ndf2_x1 = df_x1.drop([\"etecho1\"],[\"etecho2\"],[\"etecho3\"],[\"eviv1\"],[\"eviv2\"],[\"eviv3\"],1)\ndf2_x1 =  df2_x1.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9873846113e66d78c54d60012160b3ff26e645d"},"cell_type":"code","source":"test_data = df2_x1\n\n\npred_val = sess.run(hypothesis, feed_dict={X: test_data,keep_prob:1})\npred_idx = sess.run(tf.argmax(pred_val, 1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a289cc59cd4d8b1995bf2ee0498a6abf48f7c39"},"cell_type":"code","source":"pred_idx = pred_idx +1\nsubmission = pd.DataFrame({'Id' : df2.Id, 'Target' : pred_idx})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e16f0723c6b68b8ed4b715c25297c6ee1572b686"},"cell_type":"code","source":"submission.to_csv(\"submissions.csv\", index =False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a3399be8f4ebbc59b68f7c29c6a5eff13e9f780"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}