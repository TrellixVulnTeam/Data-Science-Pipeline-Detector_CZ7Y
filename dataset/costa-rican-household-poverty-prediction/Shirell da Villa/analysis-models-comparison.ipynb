{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom colorama import Fore\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nimport scikitplot as skplt \n\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split as split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nimport xgboost as xgb\n\nfrom IPython.display import Image\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def report(y_true, y_pred, labels):\n    f1 = f1_score(y_true=y_true, y_pred=y_pred, labels=labels, average='macro', pos_label=1)\n    \n    acc = accuracy_score(y_true=y_true, y_pred=y_pred)\n    \n    cm = pd.DataFrame(confusion_matrix(y_true=y_true, \n                                       y_pred=y_pred), \n                      index=labels, \n                      columns=labels)\n    rep = classification_report(y_true=y_true, \n                                y_pred=y_pred)\n    \n    return (f'F1 Macro = {f1:.4f}\\n\\nAccuracy = {acc:.4f}\\n\\nConfusion Matrix:\\n{cm}\\n\\nClassification Report:\\n{rep}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Poverty Level Prediction of Costa Rican Households"},{"metadata":{},"cell_type":"markdown","source":"# Outline:"},{"metadata":{},"cell_type":"markdown","source":"1. Introduction\n2. Data Cleaning\n3. Base Model\n4. Adding Features\n5. Visualization\n6. Feature Selection\n7. Models"},{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction:"},{"metadata":{},"cell_type":"markdown","source":"* \"Many social programs have a hard time making sure the right people are given enough aid. It’s especially tricky when a program focuses on the poorest segment of the population. The world’s poorest typically can’t provide the necessary income and expense records to prove that they qualify.\n* In Latin America, one popular method uses an algorithm to verify income qualification. It’s called the Proxy Means Test (or PMT). With PMT, agencies use a model that considers a family’s observable household attributes like the material of their walls and ceiling, or the assets found in the home to classify them and predict their level of need.\n\n* While this is an improvement, accuracy remains a problem as the region’s population grows and poverty declines\". \n* Source: https://www.kaggle.com/c/costa-rican-household-poverty-prediction/data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/train.csv', index_col='idhogar')\ndata = data.rename(columns = {'v2a1':'rent','hacdor':'crowd_bedroom', 'hacapo': 'crowd_room', 'v14a': 'bathroom' })\nprint(data.shape)\ndata.tail(7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Each row represents one family member.\n* Each row contains individual features and household features.\n* According to kaggles file description, only predictions for heads of household are scored."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info(verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target Variable: Poverty level\n1. <u>extreme poverty</u> \n2. moderate poverty \n3. vulnerable households \n4. non vulnerable households\n\nThe main class I would like to identify and predict is the extreme poverty households - class 1. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.reset_index()\ndata.Target.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The data is imbalanced"},{"metadata":{},"cell_type":"markdown","source":"The evaluation is based on the <b> F1 macro score</b>, which is the <b>harmonic mean of precision and recall</b>."},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"### Dropping duplicated features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print((data['agesq'] == data['SQBage']).all())\nprint((data['tamhog'] == data['hhsize']).all())\nprint((data['hhsize'] == data['hogar_total']).all())\ndata.drop(columns=['agesq', 'tamhog','hhsize'], inplace=True)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating Ordinal Features from dummies:"},{"metadata":{"trusted":true},"cell_type":"code","source":"issues_list = ['epared', 'etecho', 'elimbasu', 'eviv', 'tipovivi', 'area'] #good, normal, bad etc.\n\nfor issue in issues_list:\n\n    col_list = list(data.columns[data.columns.str.startswith(issue)])\n    df = data[col_list]\n    \n    s = pd.Series(df.columns[np.where(df!=0)[1]])\n    s = s.apply(lambda x: x[-1]).astype('int64')\n    s = s.rename(issue+'_cat', copy=True)\n    \n    data = pd.concat([data, s], axis=1)\n    data = data.drop(columns=col_list)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#educational level\n\ndef instlevel_cat(row):\n    col_list = list(data.columns[data.columns.str.startswith('instlevel')])\n    \n    for i in col_list:\n        if row[i] == 1:\n            return (int(i[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# water provision\n\ndef water_cat(row):\n    if row.abastaguadentro == 1:\n        return 1\n    if row.abastaguafuera == 1:\n        return 2\n    if row.abastaguano == 1:\n        return 3\n\n# source of energy used for cooking\ndef energcocinar_cat(row):\n    if row.energcocinar1 == 1:\n        return 1\n    if row.energcocinar4 == 1:\n        return 2\n    if row.energcocinar3 == 1:\n        return 3\n    if row.energcocinar2 == 1:\n        return 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['water_cat'] = data.apply(water_cat, axis=1)\ndata['energcocinar_cat'] = data.apply(energcocinar_cat, axis=1)\ndata['instlevel_cat'] = data.apply(instlevel_cat, axis=1)\n\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before dropping these categorical features, I found that there are null values in instlevel_cat:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('nulls: ', data['instlevel_cat'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['instlevel_cat'].isnull()]['escolari']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.instlevel_cat.fillna(1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dropping these dummies:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ncolumns_list = list(data.columns)\ncol_drop = []\n\nfor i in columns_list:\n    if re.match(\"instlevel\\d\", i) or re.match(\"abastagua\", i) or re.match(\"energcocinar\\d\", i):\n        col_drop.append(i)\nprint(col_drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Before:',data.shape)\ndata.drop(columns=col_drop, inplace=True)\nprint('After:',data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['female', 'male']].head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.rename(columns={'female': 'sex'}).drop(columns='male')\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fixing mixed Scales:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['dependency','edjefe','edjefa']].head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['dependency','edjefe','edjefa']:\n    print(col.capitalize(),':\\n', data[col].unique(),'\\n')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['dependency','edjefe','edjefa']:\n    data[col].replace({'yes': 1, 'no': 0 }, inplace=True)\n    data[col] = data[col].astype('float64')\n    if data[col].dtype == 'float64':\n        print(col,': fixed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_list = list(data.columns)\nprint(len(columns_list))\nprint(columns_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping all squared parameters:\n* I will create new ones without null values or calculation mistakes"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Before:',data.shape)\n\ncol_drop = []\n\nfor i in columns_list:\n    if re.match(\"SQB\", i):\n        col_drop.append(i)\nprint(col_drop)\n\ndata.drop(columns=col_drop, inplace=True)\n\nprint('After:',data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Filling Null Values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum().sort_values(ascending=False).head(7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### rez_esc - Years behind in school"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.rez_esc.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ages = list(data[data['rez_esc'].isnull()]['age'].unique())\nprint(sorted(ages))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This feature is available between the ages of 11-17"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['rez_esc', 'age']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['rez_esc'] = data['rez_esc'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum().sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### v18q1 - Number of tablets in the household"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.v18q1.describe(np.arange(0,1.1,0.2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.v18q1.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The category 0 doesn't exist, so I checked it with the boolean feature v18q:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['v18q1', 'v18q']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[data['v18q1'].isnull()]['v18q'].sum())\ndata['v18q1'] = data['v18q1'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum().sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### rent - house rental fees "},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['rent', 'tipovivi_cat']].head() #own the house or no house to pay rent for","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['rent'].isnull()]['tipovivi_cat'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are families who own the house or does't have one, so there are no rental fees."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['rent'] = data['rent'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum().sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### meaneduc - Average years of education for adults (18+)"},{"metadata":{"trusted":true},"cell_type":"code","source":"meaneduc_df = data.groupby(['idhogar', 'Id'])['age', 'escolari'].sum()\nmeaneduc_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_meaneduc(df): \n    counter=0\n    escolari=0\n    \n    list_age = list(df.age) \n    list_escolari = list(df.escolari) \n    \n    for i in range(len(list_age)):\n        if (list_age[i] >= 18):\n            counter +=1\n            escolari += list_escolari[i]\n    if counter==0:\n        return 0\n    return (escolari/counter)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meaneduc_new = data.groupby('idhogar').apply(fix_meaneduc)\nmeaneduc_new.isnull().any()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meaneduc_new.head() #series, each row is for idhogar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(meaneduc_new.shape) \nprint((data.parentesco1==1).sum()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['meaneduc'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since I would like to create a new table where each row represents a household, I will drop meaneduc and replace it with meaneduc_new later on."},{"metadata":{},"cell_type":"markdown","source":"# 3. Houseowners Model"},{"metadata":{},"cell_type":"markdown","source":"### Creating a dataset of houseowners (where parentesco1==1)\n* This dataset includes houseowners individual features and house features."},{"metadata":{"trusted":true},"cell_type":"code","source":"# family example:\nprint(data.shape)\ndata[data['idhogar'] == '2b58d945f']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dropping meaneduc - family feature\n* Dropping columns that repeat themselves in a boolean and ordinal manner ('mobilephone', 'v18q')."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(columns=['meaneduc','mobilephone', 'v18q'])\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Houseowners Example:\nowners_data = data[data['parentesco1']==1]\nprint(owners_data.shape)\nowners_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### First Model: Houseowners' features only"},{"metadata":{},"cell_type":"markdown","source":"I will compare the next models to this model, in order to understand if we actually need the features of the family or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = split(owners_data, test_size=0.3, random_state=44, stratify=owners_data.Target)\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Target.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imbalances data - I will use the balanced class_weight"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(class_weight='balanced', n_estimators=300, \n                            max_depth=30, min_samples_leaf=10, max_features=30, random_state=111)\n\nX = train.drop(columns=['Target','Id','idhogar'])\ny = train.Target\n\nparams = {'max_depth': range(25,30),\n          'min_samples_leaf': range(7,10)}\n\ngs = GridSearchCV(rf, params, cv=5, scoring='f1_macro')\ngs.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = gs.best_estimator_\ngs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test.drop(columns=['Target','Id','idhogar'])\ny_test = test.Target\n\nprint(Fore.BLUE+report(y_test, model1.predict(X_test), model1.classes_))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_list = list(zip(model1.feature_importances_ ,X.columns))\nmy_list.sort(key=lambda tup: tup[0],reverse=True)\n# for item in my_list:\n#     if item[0]> 0.01:\n#         print(item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.DataFrame(data=None,columns=['importance', 'feature'])\n\nimportance_l = []\nfeature_l = []\n\nfor t in my_list:\n    importance_l.append(t[0])\n    feature_l.append(t[1])\n    \nimportances['importance'] = importance_l\nimportances['feature'] = feature_l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.xticks(rotation=90)\nplt.title('Feature Importances')\nsns.barplot(x=\"feature\", y=\"importance\", data=importances)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"owners_data_only = owners_data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Adding Features\n"},{"metadata":{},"cell_type":"markdown","source":"### Adding meaneduc_new:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding meaneduc_new\nowners_data = owners_data.merge(meaneduc_new.to_frame(), left_on='idhogar', right_index=True)\\\n                        .rename(index=str, columns={0: \"meaneduc_new\"})\n\nowners_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(data.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a dataframe of individual features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Individual Features:\n\nfamily_data = data[['idhogar', 'Id','escolari', 'rez_esc','dis','instlevel_cat','age',\n                           'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', \n                           'estadocivil5', 'estadocivil6', 'estadocivil7', \n                           'parentesco1', 'parentesco2', 'parentesco3', 'parentesco4', \n                           'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', \n                           'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12']]\nprint(owners_data.shape, family_data.shape)\nfamily_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"family_data[family_data.idhogar == '2b58d945f']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping  family members without a houseowner:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'There are {(len(family_data.idhogar.unique()))-(len(owners_data.idhogar.unique()))} family members with no related homeowner')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrong_idhogars = []\nfor id_ in list(family_data.idhogar.unique()):\n    if id_ not in owners_data.idhogar.unique():\n        wrong_idhogars.append(id_)\nprint(wrong_idhogars)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will drop them since the score is given to the homeowners."},{"metadata":{},"cell_type":"markdown","source":"### Creating family features:\n* Aggregating individual features of each family member to one family feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(family_data.shape)\nfor id_ in wrong_idhogars:\n    family_data = family_data[family_data['idhogar'] != id_]\nprint('Number of family members in the dataset (rows): ',family_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of families in the dataset: ',owners_data.shape)\n\nowners_data = owners_data.sort_values(by='idhogar')\nfamily_data = family_data.sort_values(by='idhogar')\n\ndf = family_data.groupby('idhogar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#school min, max and mean per family\n\nowners_data['escolari_max_fam'] = np.array(df.escolari.max())\nowners_data['escolari_min_fam'] = np.array(df.escolari.min())\nowners_data['escolari_mean_fam'] = np.array(df.escolari.mean())\n\nowners_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#age min, max and mean per family\n\nowners_data['age_max_fam'] = np.array(df.age.max())\nowners_data['age_min_fam'] = np.array(df.age.min())\nowners_data['age_mean_fam'] = np.array(df.age.mean())\nowners_data['age_median_fam'] = np.array(df.age.median())\n\nowners_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rez_esc max and mean per family\n\nowners_data['rez_esc_max'] = np.array(df.rez_esc.max())\nowners_data['rez_esc_mean'] = np.array(df.rez_esc.mean())\n\nowners_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sum of disabled in the family\nowners_data['dis_fam'] = np.array(df.rez_esc.sum())\nowners_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mean of family members that studied in each education level:\nowners_data['instlevel_mean_fam'] = np.array(df.instlevel_cat.mean())\nowners_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = pd.Series(owners_data.columns)\nprint(list(col_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sum of family members that are married, divorced etc.:\n\ncol_list = owners_data.columns[col_names.str.startswith('estadocivil')]\n\nfor col in col_list:\n    owners_data[col+'_fam'] = np.array(df[col].sum())\n\nprint(owners_data.shape)\nowners_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sum of family members in each family category (spouse/partner, son/doughter, mother/father etc.):\n\ncol_names = pd.Series(owners_data.columns)\n#col_names\ncol_list = owners_data.columns[col_names.str.startswith('parentesco')]\nfor col in col_list:\n    owners_data[col+'_fam'] = np.array(df[col].sum())\n\nprint(owners_data.shape)\nowners_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(owners_data.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping part of the individual features of houseowners:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Before:',owners_data.shape)\n\nowners_data.drop(columns=['Id','rez_esc',\n                   'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', \n                   'estadocivil5', 'estadocivil6', 'estadocivil7', \n                   'parentesco1','parentesco1_fam','parentesco2', 'parentesco3', 'parentesco4', 'parentesco5',\n                   'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10',\n                   'parentesco11', 'parentesco12' ], inplace=True)\n\nprint('After:',owners_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"owners_data = owners_data.set_index('idhogar')\nprint(owners_data.shape)\nowners_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding Features and Interactions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"owners_data_all_features = owners_data.copy()\nowners_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"owners_data['instlevel_cat*age_mean_fam'] = owners_data['instlevel_cat']*owners_data['age_mean_fam']\nowners_data['instlevel_cat*escolari_mean_fam'] = owners_data['instlevel_cat']*owners_data['escolari_mean_fam']\nowners_data['v18q1/r4t2'] = owners_data['v18q1']/owners_data['r4t2'] #tablets/people\nowners_data['qmobilephone/r4t2'] = owners_data['qmobilephone'] /  owners_data['r4t2'] #phones/people\n\nowners_data['SQescolari_mean_fam'] = np.square(owners_data['escolari_mean_fam'])\nowners_data['SQdependency'] = np.square(owners_data['dependency'])\nowners_data['SQmeaneduc_new'] =  np.square(owners_data['meaneduc_new'])\nowners_data['SQescolari_mean_fam'] = np.square(owners_data.escolari_mean_fam)\nowners_data['SQescolari'] = np.square(owners_data['escolari'])\nowners_data['SQage'] = np.square(owners_data.age)\nowners_data['SQhogar_total'] = np.square(owners_data['hogar_total'])\nowners_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,7))\nowners_data.nunique().sort_values(ascending=False).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* most of the features are binary, the rest are ordinal or continuous"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = owners_data.corr()\ncols = corrmat.nlargest(30, 'Target')['Target'].index\ncm = np.corrcoef(owners_data[cols].values.T)\nsns.set(font_scale=1.5)\nplt.figure(figsize=(20, 20))\n\nhm = sns.heatmap(cm, cbar=False, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.yticks(rotation=0)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* No feature is highly correlated with the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\nplt.title('Mean Years of Education per Family by Poverty Level')\nax = sns.boxplot(x=\"Target\", y=\"escolari_mean_fam\", data=owners_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\nplt.title('Median age per Family by Poverty Level')\nax = sns.boxplot(x=\"Target\", y=\"age_median_fam\", data=owners_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = {1: 'b', 2:'orange', 3: 'g', 4:'r'}\nplt.figure(figsize = (12, 3))\n\n# overcrowding - persons per room\n# meaneduc_new - mean years of education of adults (>=18)\n\nfor i, col in enumerate(['overcrowding', 'meaneduc_new']):\n    ax = plt.subplot(2, 1, i + 1)\n    \n    for poverty_level, color in colors.items():\n        sns.kdeplot(owners_data.loc[owners_data['Target'] == poverty_level, col], \n                     ax = ax, color = color, label = poverty_level)\n        \n    plt.title(f'{col.capitalize()} Distribution'); plt.xlabel(f'{col}'); plt.ylabel('Density')\nplt.subplots_adjust(top = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from target, how many appeared in each instlevel\n\nmap_df = pd.crosstab(columns=owners_data.Target, \n                          index=owners_data.instlevel_cat, \n                          normalize='columns')\n\nfig, ax = plt.subplots(figsize=(10, 5))\nsns.heatmap(ax=ax, data=map_df, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA For Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = owners_data.drop(columns='Target')\ny = owners_data.Target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = split(X,y, random_state=555, test_size=0.3, stratify = y)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores = []\n# test_scores = []\nfor k in range(1, X.shape[1]):\n    scaled_pca_transformer = PCA(n_components=k).fit(X_train_scaled)\n        \n    X_train_scaled_pca = scaled_pca_transformer.transform(X_train_scaled)\n        \n    clf = KNeighborsClassifier().fit(X_train_scaled_pca, y_train)\n    \n    X_test_scaled_pca = scaled_pca_transformer.transform(X_test_scaled)\n    \n    train_scores.append(clf.score(X_train_scaled_pca, y_train))\n#    test_scores.append(clf.score(X_test_scaled_pca, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,7))\n# plt.plot(list(zip(train_scores, test_scores)), linewidth=5)\nplt.plot(train_scores, linewidth=5)\nplt.xticks(ticks=np.arange(0, len(X.columns)+1, 2.0))\nplt.title('Model score vs. number of components')\nplt.xlabel('n_components')\nplt.ylabel('Score (accuracy)')\nplt.legend(['train score', 'test score'], loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_transformer = PCA(n_components=2).fit(X_train_scaled)\nX_train_scaled_pca = pca_transformer.transform(X_train_scaled)\nX_test_scaled_pca = pca_transformer.transform(X_test_scaled)\nX_train_scaled_pca[:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.scatterplot(x=X_train_scaled_pca[:, 0], \n                y=X_train_scaled_pca[:, 1], \n                hue=y_train, \n                sizes=100,\n                palette=\"Accent\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Feature Selection"},{"metadata":{},"cell_type":"markdown","source":"### Variance Threshold:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = owners_data.drop(columns='Target')\ny = owners_data.Target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = split(X, y, random_state=555, test_size=0.3, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train:')\nprint(y_train.value_counts(normalize=True))\nprint('test:')\nprint(y_test.value_counts(normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test) \n\nX_train_scaled = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\nX_test_scaled = pd.DataFrame(X_test_scaled,index=X_test.index, columns=X_test.columns)\nX_train_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selector = VarianceThreshold(0.008)\nselector.fit(X_train_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'There are {len(X_train_scaled.columns[selector.get_support()])} columns left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropped_features = X_train_scaled.columns[~selector.get_support()]\ndropped_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_data_train = selector.transform(X_train_scaled)\nselected_data_test = selector.transform(X_test_scaled)\n\n\nselected_data_train = pd.DataFrame(selected_data_train, \n                             columns=X_train_scaled.columns[selector.get_support()])\nselected_data_test = pd.DataFrame(selected_data_test, \n                             columns=X_test_scaled.columns[selector.get_support()])\n\nselected_data_train.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Models"},{"metadata":{},"cell_type":"markdown","source":"### Models using PCA"},{"metadata":{},"cell_type":"markdown","source":"* according to the PCA graph above - I chose to use 50 conponents."},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_transformer = PCA(n_components=50).fit(selected_data_train)\nX_train_scaled_pca = pca_transformer.transform(selected_data_train)\nX_test_scaled_pca = pca_transformer.transform(selected_data_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VotingClassifier (LogisticRegression and KNeighborsClassifier)"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [('LR', LogisticRegression(solver='lbfgs', multi_class='auto', \n                            max_iter=1000, class_weight='balanced',\n                            random_state=555)), \n               ('KNC', KNeighborsClassifier(n_neighbors=5, metric='manhattan'))] #no class_weights\n\n\nmodel2 = VotingClassifier(estimators=classifiers, voting='soft')\nmodel2.fit(X_train_scaled_pca, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.BLUE+report(y_test, model2.predict(X_test_scaled_pca), model2.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models without using PCA"},{"metadata":{},"cell_type":"markdown","source":"### VotingClassifier (LogisticRegression and KNeighborsClassifier)"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [('LR', LogisticRegression(solver='lbfgs', multi_class='auto', \n                            max_iter=1000, class_weight='balanced',\n                            random_state=555)), \n               ('KNC', KNeighborsClassifier(n_neighbors=5, metric='manhattan'))] #no class_weights\n\n\nmodel4 = VotingClassifier(estimators=classifiers, voting='soft')\nmodel4.fit(selected_data_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.BLUE+report(y_test, model4.predict(selected_data_test), model4.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AdaBoostClassifier (DecisionTreeClassifier)"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=555 )\n\nmodel8 = AdaBoostClassifier(base_estimator=dt, learning_rate=0.01, n_estimators=100, random_state=222)\nmodel8.fit(selected_data_train ,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.BLUE+report(y_test, model8.predict(selected_data_test), model8.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### BaggingClassifier (SVC):"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(class_weight='balanced',random_state=222, kernel='rbf', C= 1.0, gamma='auto')\n\nparams = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n          'C': [0.1, 1.0, 10]}\n\ngs = GridSearchCV(svc, params, cv=3, return_train_score=False, scoring='f1_macro')\ngs.fit(selected_data_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_params_)\nsvc_best = gs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model10 = BaggingClassifier(base_estimator=svc_best, n_estimators=100, n_jobs=4, max_features=30, random_state=555)\n\nmodel10.fit(selected_data_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.BLUE+report(y_test, model10.predict(selected_data_test), model10.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(solver='lbfgs', multi_class='auto', \n                            max_iter=10000, class_weight='balanced',\n                            random_state=555)\nparams = {'C': [0.1, 1.0, 10]}\n\ngs = GridSearchCV(lr, params, scoring='f1_macro', cv=5, return_train_score=False)\ngs.fit(selected_data_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model5 = gs.best_estimator_\nprint(Fore.BLUE+report(y_test, model5.predict(selected_data_test), model5.classes_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(class_weight='balanced', n_estimators=50000, #max_depth=30, \n                            min_samples_leaf=5, max_features=30, n_jobs=4, random_state=222)\n\nparams = {#'max_depth': range(25,30),\n          'min_samples_leaf': range(5,7)}\n\ngs = GridSearchCV(rf, params, cv=5, return_train_score=False, scoring='f1_macro')\ngs.fit(selected_data_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_params_)\nmodel6 = gs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.RED+report(y_train, model6.predict(selected_data_train), model6.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.BLUE+report(y_test, model6.predict(selected_data_test), model6.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This is the best model so far, which I chose to work with."},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_results = pd.DataFrame(gs.cv_results_)\ngrid_results.sort_values(by='rank_test_score').head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scores = grid_results.sort_values(by='rank_test_score')[['params', 'mean_test_score', 'std_test_score' ]]\n\ndf_scores[['mean_test_score',  'std_test_score']].plot(kind='scatter', x='mean_test_score', y='std_test_score', \n                                                       color='lightblue', figsize=(10,5))\n\nP = [df_scores.iloc[0,1] , df_scores.iloc[0,2]]\nplt.plot(P[0], P[1], marker='o', markersize=5, color=\"darkblue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_list = list(zip(model6.feature_importances_ ,selected_data_test.columns))\nmy_list.sort(key=lambda tup: tup[0],reverse=True)\n# for item in my_list:\n#     if item[0]> 0.009:\n#         print(item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.DataFrame(data=None,columns=['importance', 'feature'])\n\nimportance_l = []\nfeature_l = []\n\nfor t in my_list:\n    importance_l.append(t[0])\n    feature_l.append(t[1])\n    \nimportances['importance'] = importance_l\nimportances['feature'] = feature_l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.xticks(rotation=90)\nplt.title('Feature Importances')\nsns.barplot(x=\"feature\", y=\"importance\", data=importances)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clustering as a model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model13 = KMeans(n_clusters=4).fit(selected_data_train)\ny_pred = model13.predict(selected_data_train)\nprint(f1_score(y_true=y_train, y_pred=y_pred, average='macro',labels=np.unique(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f1_score(y_true=y_test, \n               y_pred=model13.predict(selected_data_test), \n               average='macro', \n               labels=np.unique(model13.predict(selected_data_test))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RandomForestClassifier with clustering as a parameter:"},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_data_train1 = selected_data_train.copy()\nselected_data_test1= selected_data_test.copy()\n\nmodel13 = KMeans(n_clusters=4).fit(selected_data_train1)\n\nselected_data_train1['clustering'] = model13.predict(selected_data_train1)\nselected_data_test1['clustering'] = model13.predict(selected_data_test1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(class_weight='balanced', n_estimators=50000, \n                            min_samples_leaf=5, max_features=30, n_jobs=4, random_state=222)\n\nparams = {#'max_depth': range(25,30),\n          'min_samples_leaf': range(5,7)}\n\ngs = GridSearchCV(rf, params, cv=5, return_train_score=False, scoring='f1_macro')\ngs.fit(selected_data_train1,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_params_)\nmodel14 = gs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.BLUE+report(y_test, model14.predict(selected_data_test1), model14.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Clustering doesn't improve the f1 macro score. The previous model was better.\n"},{"metadata":{},"cell_type":"markdown","source":"recommendations for future research:\n* Improve feature selection\n* Compare models by other score methods except f1 score"},{"metadata":{},"cell_type":"markdown","source":"# Thank you!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}