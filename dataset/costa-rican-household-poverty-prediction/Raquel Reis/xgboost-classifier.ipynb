{"cells":[{"metadata":{},"cell_type":"markdown","source":"# XGBoost \n\nNesse notebook será feito:\n\n* Análise Exploratória dos Dados\n* Tratamento de Classes Desbalanceadas\n* XGBoost\n"},{"metadata":{},"cell_type":"markdown","source":"## Problema de Gestão\n\nQueremos montar um modelo que seja capaz de identifcar qual casa precisa de mais assistência social da Costa Rica.\n\nEstamos diante de um problema de **classificação multiclasse**."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Carregando os dados\ndf = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\n\ndf.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos visualizar os dados\ndf_all.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos aumentar o número de colunas para o info mostrar\ndf_all.info(max_cols=145)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Features dtype object"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dependency\n\nDe acordo com o dicionário de dados, \n\n> dependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percebemos a grande quantidade de valores armazenados como \"yes\" e \"no\" (strings).\n\nVisto no dicionário de dados que o 'yes' pode ser substituído por 1 e que o 'no' pode ser substituído por 0.\n\nVamos calcular e verificar se isso pode ser feito."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Vamos criar uma coluna com a fórmula descrita no dicionário de dados\ndf_all['dependency_calculated'] = (df_all['hogar_nin'] + df_all['hogar_mayor']) / (df_all['hogar_adul'])\ndf_all['dependency_calculated'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Vamos criar uma coluna cópia de dependency, mas substituindo as strings por inteiros\ndf_all['dependency_test'] = df_all['dependency'].replace('yes',1).replace('no',0)\ndf_all['dependency_test'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Vamos comparar os valores\ndf_all[['dependency','dependency_calculated','dependency_test','hogar_nin','hogar_mayor','hogar_adul','hogar_total']].head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analisando esses valores, percebemos que os valores que estão na coluna \"dependency\" não correspondem a fórmula na descrição do dicionário de dados.\nA decisão nesse caso será dropar a coluna dependency que estava no dataset original (com erros de cálculo) e manter a coluna calculada."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropando as colunas com erro de cálculo\ndf_all.drop(['dependency','dependency_test'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vamos analisar se temos NA ou inf na coluna\ndf_all.dependency_calculated.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setar pandas para deixar os valores inf como na\npd.set_option('mode.use_inf_as_na', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# localizar os 36 valores infinitos\ndf_all.dependency_calculated.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# substituir os valores por -1\ndf_all['dependency_calculated'].fillna(-1, inplace=True)\ndf_all.dependency_calculated.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### edjefa e edjefe\n\nDe acordo com o dicionário de dados,\n\n> years of education of **female** head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n\n> years of education of **male** head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando do comando info\ndf_all.info(max_cols=145)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tratamento de Valores Ausentes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos\ndf_all.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Features que possuem missing values\n\n1. v2a1 = valor aluguel mensal\n2. v18q1 = quantidade de tablets que os proprietários da casa possuem\n3. rez_esc = anos antes da escola\n4. meaneduc = média ded anos de educação nos adultos\n5. SQBmeaned = quadrado da média dos anos de educação dos adultos"},{"metadata":{"trusted":true},"cell_type":"code","source":" # 1. Verificando os valores de aluguel (v2a1) para os chefes/as de familia (parentesco1 = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A escolha para preenchimento dos valores nulos por -1 foi intencional. A ideia é não tentar excluir essa coluna e também de não perder nenhum dado. Como o algoritmo usado será Random Forest, o uso de -1 (outlier) será para \"forçar\" a árvore a dispensar os valores -1."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Análise de v18q (relacao com v18q1)\ndf_all['v18q'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A quantidade de valores nulos na feature v18q (possui tablet), que é binária, bate com o valor de missing values da feature quantidade de tablets. Basta substituir valores nulos por 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3. Verificando valores nulos de rez_esc\nprint('Porcentagem de Valores Nulos:',(df_all['rez_esc'].isnull().sum() / len(df_all))*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de rez_esc (estratégia do outlier)\ndf_all['rez_esc'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4. Verificando valores nulos de meaneduc\nprint('Porcentagem de Valores Nulos:',(df_all['meaneduc'].isnull().sum() / len(df_all))*100)\nprint('Quantidade de Valores Nulos:',df_all['meaneduc'].isnull().sum() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Média e mediana de meaneduc\ndf_all.meaneduc.mean(), df_all.meaneduc.median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Preenchendo os valores nulos de meaneduc com o valor de 9 anos de estudos (entre média e mediana), ou seja, uma tendência geral dos dados\ndf_all['meaneduc'].fillna(9, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5. Verificando valores nulos de SQBmeaned\nprint('Porcentagem de Valores Nulos:',(df_all['SQBmeaned'].isnull().sum() / len(df_all))*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de SQBmeaned (estratégia do outlier)\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Verificação dos dados pós tratamento"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualização dados\ndf_all.info(max_cols=145)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualização da Variável Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histograma da Variável Target\nsns.histplot(data=train, x=\"Target\", bins = 4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando valores absolutos\ntrain['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando as porcentagens\ntrain['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estamos diante de um caso de classificação multiclasse em que as classes estão desbalanceadas (a categoria 4.0 ocupa 63% do dataset). Vamos usar **Over Sampling** para aumentar as classes minoritárias."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividindo dataset treino em X,y\n\nX, y = train[feats], train[['Target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando a biblioteca\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Fazendo o over-sampling\nros = RandomOverSampler(random_state=42)\nX_ros,y_ros= ros.fit_resample(X,y)\n\n# Verificando os dados\ny_ros['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost após Over Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com XGBoost\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier(n_estimators=250, learning_rate=0.09, random_state=42)\n\n# Treinando o modelo\nxgb.fit(X_ros, y_ros)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = xgb.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos verificar as previsões\ntest['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o arquivo para submissão\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(15, 20))\n\n# Avaliando a importancia de cada coluna (cada variável de entrada)\npd.Series(xgb.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}