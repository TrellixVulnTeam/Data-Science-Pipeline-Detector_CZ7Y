{"cells":[{"metadata":{},"cell_type":"markdown","source":"Explicação do problema e dos dados: \nOs dados para esta competição são fornecidos em dois arquivos: train.csve test.csv. O conjunto de treinamento tem 9557 linhas e 143 colunas, enquanto o conjunto de teste tem 23856 linhas e 142 colunas. Cada linha representa um indivíduo e cada coluna é um recurso, exclusivo para o indivíduo ou para a família do indivíduo . O conjunto de treinamento tem uma coluna adicional Target, que representa o nível de pobreza em uma escala de 1 a 4 e é o rótulo da competição. Um valor de 1 é a pobreza mais extrema.\n\nEste é um problema de aprendizado de máquina de classificação multi-classe supervisionado :\n\nSupervisionado : fornecido com os rótulos dos dados de treinamento\nClassificação multiclasse: os rótulos são valores discretos com 4 classes\nObjetivo\nO objetivo é prever a pobreza ao nível do agregado familiar . Recebemos dados em nível individual com cada indivíduo tendo características únicas, mas também informações sobre sua família. Para criar um conjunto de dados para a tarefa, teremos que realizar algumas agregações dos dados individuais para cada família. Além disso, temos que fazer uma previsão para cada indivíduo no conjunto de teste, mas \"SOMENTE os chefes de família são usados ​​na pontuação\", o que significa que queremos prever a pobreza em uma base familiar.\n\nObservação importante: embora todos os membros de uma família devam ter o mesmo rótulo nos dados de treinamento, existem erros onde os indivíduos na mesma casa têm rótulos diferentes. Nestes casos, somos orientados a usar a etiqueta do chefe de cada família, que pode ser identificada pelas linhas onde parentesco1 == 1.0. Abordaremos como corrigir isso no caderno (para mais informações, dê uma olhada na discussão principal da competição ).\n\nOs Targetvalores representam os níveis de pobreza da seguinte forma:\n\n1 = Extrema pobreza \n2 = Pobreza moderada\n3 = Famílias vulneráveis \n4 = Famílias não vulneráveis","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set a few plotting defaults\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.size'] = 18\nplt.rcParams['patch.edgecolor'] = 'k'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotar(variaveis,eixoX,titulo):\n    eixoY = []\n    for v in variaveis: \n        eixoY.append(df[v].value_counts()[1])\n    \n    plt.figure(figsize=(20,5))\n    sns.barplot(x = eixoX,y = eixoY).set_title(titulo)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Célula padrão da criação de um novo notebook - importando o numpy e o pandas e processa o diretório para mostrar quais arquivos possui.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Carregar os dados dos datasets\ndf = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\n\ndf.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A base de treino possui 9557 linhas e 143 colunas e a de teste 23856 linhas e 142 colunas. O treino será realizado com 9557 linhas e a previsão será com as 23856 linhas. As linhas que não possuirem a informação de chefe de família serão desconsideradas pelo Kaggle no resultado final.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chefes de família\nheads = df.loc[df['parentesco1'] == 1].copy()\n\n\n\n# Variáveis para treinamento\ntrain_campos = df.loc[(df['Target'].notnull()) & (df['parentesco1'] == 1), ['Target', 'idhogar']]\n\n# Quantidade de chefes conforme a calissificação\nl_counts = train_campos['Target'].value_counts().sort_index()\n\nl_counts\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Parentes = 'Parentesco'\nvariaveis = 'parentesco1','parentesco2','parentesco3','parentesco4','parentesco5','parentesco6','parentesco7','parentesco8','parentesco9','parentesco10','parentesco11','parentesco12'\neixoX = ['Chefe de família','Cônjugue','Filho','Divorciado','Genro/Nora','Neto','Pai','Sogro','Irmão','Cunhada','Outro Familiar','Outro Não Familiar']\nplotar(variaveis,eixoX,Parentes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gráfico para verificação da quantidade de individuos e parentesco","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificação de famílias onde os indivíduos no mesmo domicílio têm um nível de pobreza diferente na base de treino\n# Agrupa as famílias para verificar os valores únicos\nall_equal = df.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Famílias onde as metas não são todas iguais\nnot_equal = all_equal[all_equal != True]\nprint('Encontramos {} Individuos na mesma familia no mesmo domícilio que possuem um nível de probreza diferente e precisamos corrigir.'.format(len(not_equal)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iteração com cada familia\nfor household in not_equal.index:\n    # Localizar a classificação correta do chefe para cada familia\n    true_target = int(df[(df['idhogar'] == household) & (df['parentesco1'] == 1.0)]['Target'])\n    \n    # Definindo a target correta para todos os membros da família\n    df.loc[df['idhogar'] == household, 'Target'] = true_target\n    \n    \n# Agrupando a famíliapara decobrir o número de valores únicos\nall_equal = df.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Famílias onde as metas não são todas iguais\nnot_equal = all_equal[all_equal != True]\nprint('Encontramos {} familias no mesmo domícilio que possuem um nível de probreza diferente.'.format(len(not_equal)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"households_leader = df.groupby('idhogar')['parentesco1'].sum()\n\n# verificação de familias sem chefe\nhouseholds_no_head = df.loc[df['idhogar'].isin(households_leader[households_leader == 0].index), :]\n\nprint('There are {} households without a head.'.format(households_no_head['idhogar'].nunique()))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verificação das familias que não possuiam chefes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificação das famílias sem chefe e com classificação diferente\nhouseholds_no_head_equal = households_no_head.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\nprint('{} Households with no head have different labels.'.format(sum(households_no_head_equal == False)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_all = df.append(test)\n\ndf_all.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unindo os data sets de treino e de teste para verificação das características dos dados. Na sequencia dos tratamentos dos dados , as bases de treino e de teste serão separados novamente. Na união temos 33413 linhas e 143 colunas. Foi criada uma coluna target no data ser de teste.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.drop('area2', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando a variável com as caracteristicas das paredes da casa\ndf_all['walls'] = np.argmax(np.array(df_all[['epared1', 'epared2', 'epared3']]),\n                           axis = 1)\ndf_all = df_all.drop(columns = ['epared1', 'epared2', 'epared3'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['walls'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Versão 10 - verificamos que houve melhoria na pontuação após a entrega da versão e da utilização da variáve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Roof ordinal variable\n#df_all['roof'] = np.argmax(np.array(df_all[['etecho1', 'etecho2', 'etecho3']]),\n#                           axis = 1)\n#df_all = df_all.drop(columns = ['etecho1', 'etecho2', 'etecho3'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_all['roof'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Versão 11","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Floor ordinal variable\n#df_all['floor'] = np.argmax(np.array(df_all[['eviv1', 'eviv2', 'eviv3']]),\n #                          axis = 1)\n#df_all = df_all.drop(columns = ['eviv1', 'eviv2', 'eviv3'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_all['floor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Varsão 12","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create new feature\n#df_all['walls+roof+floor'] = df_all['walls'] + df_all['roof'] + df_all['floor']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_all['walls+roof+floor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Varsão 13","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verificando as colunas que são do tipo object (que contém texto), pois o modelo trabalha somente com colunas numericas.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verificando os registros da chefe de família (feminino), conforme a quantidade de anos de escolaridade. Nesse resultado verificamos a quantidade de 22075 mulheres sem escolaridade, o dado está como \"no\" e \"yes\" que é igual a 1 a quantidade de 214, vamos tratar os dados adiante., vamos tratar os dados adiante.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verificando os registros do chefe de família (masculino), conforme a quantidade de anos de escolaridade. Nesse resultado verificamos a quantidade de 12818 homens sem escolaridade, o dado está como \"no\" e \"yes\" que é igual a 1 a quantidade de 416, vamos tratar os dados adiante.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sobrescrevendo os dados que estão como yes e no para 1 e 0 para as variáveis edjefa e edjfe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando a sobreposição dos dados para o masculino\ndf_all['edjefe'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando a sobreposição dos dados para o Feminino\ndf_all['edjefa'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COntinuação da verificação das variaveis que são do tipo Object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pelo resultado e após sobrescrever como yes e no para 1 e 0 para as variáveis edjefa e edjfe, verificamos que essas variáveis não retornaram como object, logo se tornaram numericas. A coluna dependency restou para ser tratada.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando a coluna dependence\ndf_all['dependency'].value_counts().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mediante o resultado, vemos que temos a seguinte quantidade de dados: yes = 7580 e no = 6036. Vamos tratar esses dados para que se tornem como ponto flutuante, assim como os demais da coluna.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sobrepondo os dados da coluna dependency conforme o mapeamento e tranformando em tipo float\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['dependency'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COntinuação da verificação das variaveis que são do tipo Object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos verificar no resultado acima que não temos mais nenhuma variável que utilizaremos como object. as variáveis ID e idhogar não serão utilizadas.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# verificando as informações do data set\ndf_all.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O resultado gerado mostra 143 variáveis (considerado muitas variáveis).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores de aluguel (v2a1) para os chefes de familia (parentesco = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os dados de  v2a1 - pagamento do valor de aluguel\ndf_all['v2a1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['v2a1'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os dados de v18q\ndf_all['v18q'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['v18q'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os dados de v18q1 \ndf_all['v18q1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['v18q1'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de SQBmeaned, meaneduc e rez_esc\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering\n\n# Vamos criar novas colunas para valores percapita\ndf_all['phone-pc'] = df_all['qmobilephone'] / df_all['tamviv']\ndf_all['tablets-pc'] = df_all['v18q1'] / df_all['tamviv']\ndf_all['rooms-pc'] = df_all['rooms'] / df_all['tamviv']\ndf_all['rent-pc'] = df_all['v2a1'] / df_all['tamviv']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciando o random forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all['Target'].value_counts().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos verificar as previsões\ntest['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com AdaBoost\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nabc = AdaBoostClassifier(n_estimators=200, learning_rate=1.0, random_state=42)\nabc.fit(train[feats], train['Target'])\naccuracy_score(test['Target'], abc.predict(test[feats]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com GBM\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\ngbm.fit(train[feats], train['Target'])\naccuracy_score(test['Target'], gbm.predict(test[feats]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o arquivo para submissão\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Avaliando a importancia de cada coluna\nimport matplotlib.pyplot as plt\nfig=plt.figure(figsize=(25,30))\n    \npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Demonstração das variáveis mais importantes para o modelo","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Limitando o treinamento ao chefe da familia\n\n# Criando um novo dataframe para treinar\nheads = train[train['parentesco1'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering\n\n# Vamos criar novas colunas para valores percapita\nheads['hsize-pc'] = heads['hhsize'] / heads['tamviv']\nheads['phone-pc'] = heads['qmobilephone'] / heads['tamviv']\nheads['tablets-pc'] = heads['v18q1'] / heads['tamviv']\nheads['rooms-pc'] = heads['rooms'] / heads['tamviv']\nheads['rent-pc'] = heads['v2a1'] / heads['tamviv']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Versão 15","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando um novo modelo\nrf2 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando o modelo\nrf2.fit(heads[feats], heads['Target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf2.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos verificar as previsões\ntest['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com AdaBoost\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nabc = AdaBoostClassifier(n_estimators=200, learning_rate=1.0, random_state=42)\nabc.fit(heads[feats], heads['Target'])\naccuracy_score(test['Target'], abc.predict(test[feats]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com GBM\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\ngbm.fit(heads[feats], heads['Target'])\naccuracy_score(test['Target'], gbm.predict(test[feats]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando o arquivo para submissão\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Avaliando a importancia de cada coluna\nimport matplotlib.pyplot as plt\nfig=plt.figure(figsize=(25,30))\n    \npd.Series(rf2.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Demonstração das variáveis mais importantes para o modelo 2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\n\n# Imprimir a matriz de confusão no modelo de test\nprint(classification_report(Id, Target))\n\n\ncmat = confusion_matrix(Id, Target)\n\n\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4) # for label size\nsns.heatmap(cmat, annot=True, fmt=\"d\") # font size\n\n\nprint('Verdade Negativo {}'.format(cmat[0,0]))\nprint('Falso Positivo {}'.format(cmat[0,1]))\nprint('Falso Negativo {}'.format(cmat[1,0]))\nprint('Verdadeiro Positivo {}'.format(cmat[1,1]))\nprint('Acurácia: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\nprint('Classificação: {}'.format(np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))))\n\nerror_rate = []\nacc = []\n\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(Id, Target)\n\n    acc.append(knn.score(Id, Target))\n\n    # Plotando o erro\n\nplt.figure(figsize=(10,4))\nplt.plot(range(1,40), acc, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.title('Accuracia vs. K-Valores')\nplt.xlabel('K-Valores')\nplt.ylabel('Accuracia')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix('Target', test['prediction'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Este trabaho teve como objetivo submeter ao Kaggle um valor melhor para a competição, mas somente os chefes de família são usados na pontuação, o que significa que queremos prever a pobreza em uma base familiar. O valor como parametro foi 0.43719. Após várias tentativas de melhorar o modelo, conseguimos atingir o melhor valor de 0.43768, atingindo o objetivo de melhoria da pontuação.\n\nAs análises foram iniciadas a partir do dicionario de dados para o entendimento das caracteristicas das variaveis. O foco inicial foi verificar as famílias onde os indivíduos no mesmo domicílio tinham um nível de pobreza diferente na base de treino, constamos 85 individuos da mesma familia que estão em situaçã de probreza diferente. Ao identificar ajustamos os dados para normalizar a classificação dos individuos da mesma familia com a mesma situação de pobreza.\n\nCom foco no chefe de familia, foi realizada  a verificação das familias que não possuiam chefes. Encontramos 15 familias sem chefes e ajustamos.\n\n\n\n\n\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}