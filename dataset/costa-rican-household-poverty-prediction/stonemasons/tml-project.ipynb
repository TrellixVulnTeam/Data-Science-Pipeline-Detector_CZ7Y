{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install lime\n!pip install lightgbm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nfrom sklearn import preprocessing, model_selection\nimport random, os, torch\nimport numpy as np\nimport lightgbm as lgb\nfrom pandas.api.types import is_numeric_dtype\nfrom sklearn.metrics import f1_score\nimport sklearn\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom lightgbm import LGBMClassifier\n\nseed = 1234\n\ndef lgb_f1_score(y_hat, data):\n    y_true = data.get_label()\n    print(y_hat.shape)\n    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n    return 'f1', f1_score(y_true, y_hat), True\n\ndef seed_everything(seed=seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sklearn.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"codebook = pd.read_csv('../input/costa-rican-household-poverty-prediction/codebook.csv')\ncodebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/costa-rican-household-poverty-prediction/train.csv')\ntrain_size = train.shape[0]\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/costa-rican-household-poverty-prediction/test.csv')\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alldata = pd.concat([train, test], 0)\nalldata\ny = np.array(alldata.Target[:train_size], dtype=np.int) - 1\nalldata = alldata.drop('Target', axis=1)\nalldata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"too_much_na = []\ncategorical_feat = []\nid_encoder = preprocessing.LabelEncoder()\nalldata.Id = id_encoder.fit_transform(alldata.Id)\nfor feat in alldata.columns:\n    if not is_numeric_dtype(alldata[feat]):\n        categorical_feat.append(feat)\n    if alldata[feat].isna().sum() / alldata.shape[0] > 0:\n        too_much_na.append(feat)\n    \n\nalldata = alldata.drop(too_much_na, axis=1)\nalldata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoders = dict()\nfor feat in categorical_feat:\n    encoders[feat] = preprocessing.LabelEncoder()\n    alldata[feat] = encoders[feat].fit_transform(alldata[feat])\n\ncategorical_feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = alldata.iloc[:train_size]\ntest = alldata.iloc[train_size:]\ntrain, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all = pd.DataFrame(train, copy=True)\ntrain_all['Target'] = y\ntrain_all","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"地区之间的发展是不平衡的，rural 地区的平困比例稍微高一些","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all.groupby(['area1', 'Target']).count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"在性别上则没有较大的差异","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all.groupby(['male', 'Target']).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tX, vX, ty, vy = model_selection.train_test_split(train, y, test_size=0.1, random_state=seed, stratify=y)\ntrain_data = lgb.Dataset(tX, label=ty)\neval_data = lgb.Dataset(vX, label=vy)\ntX.shape, vX.shape, ty.shape, vy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LGB:\n    def __init__(self, param, lgb_config, n_round):\n        self.param = param\n        self.lgb_config = lgb_config\n        self.n_round = n_round\n        \n    def fit(self, X, y):\n        data = lgb.Dataset(X, y)\n        self.gbm = lgb.train(self.param, data, **lgb_config)\n        \n    def predict(self, X):\n        return self.gbm.predict(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_macroF1_lgb(predictions, truth):  \n    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n    pred_labels = predictions.argmax(axis=1)\n    truth = truth.get_label()\n    f1 = f1_score(truth, pred_labels, average='macro')\n    return ('macroF1', 1-f1) \n\ndef learning_rate_power_0997(current_iter):\n    base_learning_rate = 0.1\n    min_learning_rate = 0.02\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return max(lr, min_learning_rate)\n\nopt_parameters = {'max_depth':35, \n                  'eta':0.15, \n                  'silent':1, \n                  'objective':'multi:softmax', \n                  'min_child_weight': 2, \n                  'num_class': 4, \n                  'gamma': 2.5, \n                  'colsample_bylevel': 1, \n                  'subsample': 0.95, \n                  'colsample_bytree': 0.85, \n                  'reg_lambda': 0.35 }\nfit_params={\"early_stopping_rounds\":500,\n            \"eval_metric\" : evaluate_macroF1_lgb, \n            \"eval_set\" : [(tX, ty), (vX, vy)],\n#             'verbose': 50,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf =  xgb.XGBClassifier(random_state=seed, n_estimators=300, learning_rate=0.15, n_jobs=4, **opt_parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(tX, ty, **fit_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1 = f1_score(clf.predict(vX), vy, average='macro')\nf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_y = clf.predict(test)\nfinal_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv('../input/costa-rican-household-poverty-prediction/sample_submission.csv')\nsample_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(test, copy=True).loc[:, ['Id', 'hacdor']]\nsub['Target'] = final_y + 1\nsub = sub.drop('hacdor', 1)\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.Id = id_encoder.inverse_transform(sub.Id)\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}