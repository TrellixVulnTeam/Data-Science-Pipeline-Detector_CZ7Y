{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IESB - Graduacao - CIA028 - Costa Rica"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importando Bibliotecas\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.ensemble import RandomForestClassifier\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Carregando os dados\ndf = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\n\ndf.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando tamanhos e tipos\ndf_all.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# na coluna dependency\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando do comando info\ndf_all.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos\ndf_all.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # Verificando os valores de aluguel (v2a1) para os chefes/as de familia (parentesco1 = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Qual a cara dos dados de v18q\ndf_all['v18q'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de SQBmeaned, meaneduc e rez_esc\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Copiando do campeão\n\n# Pontuação - 0.43687\n\n\nrf = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\n\nrf.fit(train[feats], train['Target'])\n\ntest['Target'] = rf.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modificação 01\n\n#Realizei um ajuste mais fino no número de árvores e consegui subir um pouco a pontuação.\n\n#Pontuação - 43746  \n\n\n\nrf1 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=701,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\n\nrf1.fit(train[feats], train['Target'])\n\ntest['Target'] = rf1.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Modificação 02\n\n#Adcionei o parâmetro min_samples_split, que seta um número de amostras mínimas para divisão de um nó, e consegui subir a pontuação.\n\n#Pontuação - 0.43821  \n\n\n\nrf2 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=701,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2, min_samples_split=5,\n                            verbose=0, class_weight='balanced')\n\nrf2.fit(train[feats], train['Target'])\n\ntest['Target'] = rf2.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Modificação 03\n\n#Ajustei o valor do parâmetro min_impurity_decrease, que divide um nó, caso essa divisão reduza a impureza, baseado no valor setado. Com isso consegui subir a pontuação\n\n#Pontuação - 0.44049\n\n\n\nrf3 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=701,\n                            min_impurity_decrease=0.0007, min_samples_leaf=2, min_samples_split=5,\n                            verbose=0, class_weight='balanced')\n\nrf3.fit(train[feats], train['Target'])\n\ntest['Target'] = rf3.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}