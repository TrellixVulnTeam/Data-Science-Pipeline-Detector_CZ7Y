{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Modelagem"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import TomekLinks\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report\n\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\npd.set_option('display.max_rows', 200)\npd.set_option('display.max_columns', 200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lendo os Dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/new-trainnew-test/new_train.csv')\ntest = pd.read_csv('/kaggle/input/new-trainnew-test/new_test.csv')\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removendo Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 5, figsize=(12, 4))\nax = ax.reshape(1, 5)[0]\nfig.suptitle('Boxplot para Visualização de Outliers', fontsize=16)\n\ncols_float = []\nfor col in train.columns:\n    if train[col].dtype == float and not col.startswith('SQB'):\n        cols_float.append(col)\n\nfor i, col in enumerate(cols_float):\n    ax[i].boxplot(train[col])\n    ax[i].set_title(col, fontsize=16)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = IsolationForest(max_samples=300, random_state=42)\nclf.fit(train[cols_float])\ntrain['outliers'] = clf.predict(train[cols_float])\nprint('Outliers:', len(train.query('outliers < 0')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.query('outliers > 0') # Filtrando somente dados que não são outliers\ntrain.drop(columns=['outliers'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Fazendo a remoção de outliers com IsolationForest.\n\n- O modelo IsolatioForest funciona da seguinte maneira: São definidos grupos de dados aleatoriamente dentro do conjunto de dados utilizado no treinamento. Cada conjunto de dados será representado por uma árvore isolada (IsolationTree ou iTree). Cada iTree pontua os dados com uma pontuação de anomalia, e ao final é tirado a média destas pontuações de anomalia. O valor da média da pontuação de anomalia é utilizado pelo modelo para encontar os pontos mais distantes da base de dados, esses pontos distantes são os outliers."},{"metadata":{},"cell_type":"markdown","source":"## Preparando os Dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_dependency_yes(row):\n    if row.dependency == 'yes':\n        return (row.hogar_nin + row.hogar_mayor) / row.hogar_adul\n    return row.dependency","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['edjefe'] = train['edjefe'].replace({'yes': '1', 'no': '0'}).astype(int)\ntrain['edjefa'] = train['edjefe'].replace({'yes': '1', 'no': '0'}).astype(int)\ntrain['dependency'] = train.apply(change_dependency_yes, axis=1)\ntrain['dependency'] = train['dependency'].replace({'no': '0'}).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['edjefe'] = test['edjefe'].replace({'yes': '1', 'no': '0'}).astype(int)\ntest['edjefa'] = test['edjefe'].replace({'yes': '1', 'no': '0'}).astype(int)\ntest['dependency'] = test.apply(change_dependency_yes, axis=1)\ntest['dependency'] = test['dependency'].replace({'no': '0'}).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_all = train.drop(columns=['Target', 'Id', 'idhogar'])\ny_train_all = train['Target']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_all, y_train_all, test_size=0.15, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tratando Classes Desbalanceadas"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_all.shape, y_train_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Oversampling\nsm = SMOTE()\nX_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\ny_train_sm.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Fazendo oversampling com método SMOTE. Este método criará novas observações baseado no padrão de comportamento dos dados. Ao final serão criados novos registros até que todas as classes estejam balanceadas."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sm.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Undesampling\ntl = TomekLinks()\nX_train_tl, y_train_tl = tl.fit_resample(X_train_sm, y_train_sm)\nX_train_tl.shape, y_train_tl.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Após o oversampling com o método SMOTE foi utilizado o método TomekLinks para que seja removido as observações semelhantes (Undersampling). Um dos motivos de utilizar o TomekLinks após o uso do SMOTE é para refinar as observações, retirando os registros semelhantes que possam \"enviesar\" o modelo."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_tl.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Treinando e Avalidando os Modelos\n\n### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'n_estimators': [200, 400],\n    'oob_score': [True],\n    'min_samples_leaf': [1, 2],\n    'random_state': [42]\n}\nrfg = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=10, n_jobs=-1, return_train_score=True, scoring='accuracy')\nrfg.fit(X_train_tl, y_train_tl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df = pd.DataFrame(rfg.cv_results_)\nrank = grid_df[['mean_train_score','mean_test_score','rank_test_score']].sort_values('rank_test_score').head(3)\nBEST_PARAMS = grid_df.sort_values('rank_test_score').params.to_list()[0]\nrank","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(grid_df['mean_train_score'],label='train')\nplt.plot(grid_df['mean_test_score'],label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- O gráfico acima apresenta o comportamento do desemepenho de treino e teste realizado no CrossValidation do GridSearch. Podemos notar um alto desempenho no treino e um desempenho inferior nos testes, devido a diferença de valores não ser tão distante (1,00 - treino e 0,935 - teste), este gráfico mostra que o modelo não está \"overfittado\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_valid.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(\n   rfg, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, rfg.predict(X_valid)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Analisando gráfico acima e a matriz de confusão podemos notar que o modelo de RandomForest obteve uma acurácia de 92%. Outro ponto importante a ser observado é o *precision* e *recall*:\n- Para a classe 4 foi obtido uma precisão de 94%.\n- Já o recall da classe 4 foi igual a 98%.\n- O f1-score para classe 4 = 96%.\n\n\n- Foram citados as medidas da classe 4 pelo fato desta classe possuir a maior ocorrência na base de dados.\n\n\n- **Precision**: De todos os valores previstos pelo modelo como classe X , quantos valores o modelo preveu como classe X?\n- **Recall**: De todos os valores que realmente são da classe X quantos valores o modelo preveu sendo da classe X?\n- **f1-Score**: Média Harmônica - Medida única para repersentar o recall e precision juntos."},{"metadata":{},"cell_type":"markdown","source":"### GBM\n\n- Observação: Devido ao tempo de execução, não será utilizado o GridSearch para os modelos de boost."},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm = GradientBoostingClassifier(n_estimators=400)\ngbm.fit(X_train_tl, y_train_tl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(\n   gbm, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, gbm.predict(X_valid)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analisando gráfico acima e a matriz de confusão podemos notar que o modelo de GradientBoost obteve uma acurácia geral de 80%.\n- Para a classe 4 foi obtido uma precisão de 84%.\n- Já o recall da classe 4 foi igual a 94%.\n- O f1-score para classe 4 foi igual 89%."},{"metadata":{},"cell_type":"markdown","source":"### AdaBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"ada = AdaBoostClassifier(n_estimators=400)\nada.fit(X_train_tl, y_train_tl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(\n   ada, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, ada.predict(X_valid)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analisando gráfico acima e a matriz de confusão podemos notar que o modelo de AdaBoost obteve uma acurácia de 66%.\n- Para a classe 4 foi obtido uma precisão de 78%.\n- O recall da classe 4 foi igual a 86%.\n- O f1-score para classe 4 igual a 82%."},{"metadata":{},"cell_type":"markdown","source":"### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(n_estimators=400, eval_metric='mlogloss')\nxgb.fit(X_train_tl, y_train_tl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(\n   xgb, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, xgb.predict(X_valid)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analisando gráfico acima e a matriz de confusão podemos notar que o modelo de XGBoost obteve uma acurácia de 90%.\n- Para a classe 4 foi obtido uma precisão de 92%.\n- O recall da classe 4 foi igual a 97%.\n- O f1-score para classe 4 foi igual a 95%."},{"metadata":{},"cell_type":"markdown","source":"### CatBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"cbc = CatBoostClassifier(random_state=42, n_estimators=400, verbose=False)\ncbc.fit(X_train_tl, y_train_tl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(\n   cbc, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, cbc.predict(X_valid)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analisando gráfico acima e a matriz de confusão podemos notar que o modelo de CatBoost obteve uma acurácia de 86%.\n- Para a classe 4 foi obtido uma precisão de 89%.\n- O recall da classe 4 foi igual a 97%.\n- O f1-score para classe 4 foi igual a 92%."},{"metadata":{},"cell_type":"markdown","source":"### LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMClassifier(random_state=42, n_estimators=400)\nlgbm.fit(X_train_tl, y_train_tl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(\n   lgbm, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, lgbm.predict(X_valid)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analisando gráfico acima e a matriz de confusão podemos notar que o modelo de LightGBM obteve uma acurácia de 90%.\n- Para a classe 4 foi obtido uma precisão de 92%.\n- O recall da classe 4 foi igual a 98%.\n- O f1-score para classe 4 foi igual a 95%."},{"metadata":{},"cell_type":"markdown","source":"### Resumo\n- Dentre os Modelos Treinados o melhor modelo foi o RandomForest. Os fatores de escolha foram: Acurárcia, Precision e F1-Score (em especial da classe 4).\n        Acc, Prec (classe 4), F1 (Classe 4)\n- **RF**: 92%, 94%, 96%\n- **Light**: 90%, 92%, 95%\n- **XGB**: 90%, 92%, 95%\n- **CAT**: 86%, 89%, 92%\n- **GBM**: 79%, 84%, 89%\n- **ADA**: 66%, 78%, 82%\n\n\n\n- A Explicação sobre **Precision**, **Recall** e **F1-Score** estão na célula de explicação do RandomForest.\n\n\n- Existe a possibilidade do LightGBM ou XGBoost performarem ainda melhor caso sejam utilizados sob o GridSearch com diferentes configurações de parâmetros, porém, o GridSearch não foi utilizado devido a demora no tempo e treinamento.\n\n\n## Aplicando O RandomForest Melhorado na Base de Teste\n\n\n### Ajustando os Dados Finais"},{"metadata":{"trusted":true},"cell_type":"code","source":"tl = TomekLinks()\nsm = SMOTE()\n\nX_train_sm_all, y_train_sm_all = sm.fit_resample(X_train_all, y_train_all) # Oversampling\nX_train_tl_all, y_train_tl_all = tl.fit_resample(X_train_sm_all, y_train_sm_all) # Undersampling","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Treinando o Melhor Modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(**BEST_PARAMS)\nmodel.fit(X_train_tl_all, y_train_tl_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predições"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test[['Id']].copy()\ny_pred = model.predict(test.drop(columns=['Id', 'idhogar']))\nsubmission['Target'] = y_pred\n\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}