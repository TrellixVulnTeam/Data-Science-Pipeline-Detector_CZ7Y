{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/costa-rican-household-poverty-prediction/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at different dtypes in the dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmmm, looks like there are 5 objects, 130 integers, and 8 floats.\n\nLet's take a look at our categorical features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for label, content in data.items():\n    if pd.api.types.is_string_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 5 categorical features, including `Id`, which we will set as index later.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now this is a very important step, always make a copy of your original dataframe, so that if something goes wrong, we still have a back-up data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the distribution of our target variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Target'].value_counts())\ndf['Target'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, look's like our target variable is unbalanced.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"One of the main characteristic a data scientist must have is to write a clean, readable block of code.\n\nWe can do that by defining functions, like this:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(df):    \n    # Fill numeric rows with the median\n    df.drop('Id', axis=1)\n    df.set_index('Id', inplace=True)\n    for label, content in df.items():\n        if pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum():\n                #df[label+\"_is_missing\"] = pd.isnull(content)\n                df[label] = content.fillna(content.median())\n                \n        # Turn categorical variables into numbers\n        if not pd.api.types.is_numeric_dtype(content):\n            #df[label+\"_is_missing\"] = pd.isnull(content)\n            # We add the +1 because pandas encodes missing categories as -1\n            df[label] = pd.Categorical(content).codes+1        \n    \n    return df\npreprocess_data(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This looks clean enough, now there are different approaches to any given problem, always try with different approaches before finalizing an approach.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering\n\nLet's split our data into X & Y, so that we can later split it into train and validation sets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('Target', axis=1)\ny = df['Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After trying with different ML algorithms, I feel that these two work like a charm on this dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier().fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nprint('R2 score is : {:.2f}'.format(accuracy_score(y_test, rf_pred)))\nprint('\\n')\nprint(\"Classification Report : \")\nprint(classification_report(y_test,rf_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmmm, this looks good. The model seems to be learning well as you can look at the f1-scores for each classes.\n\nLet's take a look at other algorithms before jumping to conclusions.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## ExtraTreesClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\netc = ExtraTreesClassifier().fit(X_train, y_train)\netc_pred = etc.predict(X_test)\nprint('R2 score is : {:.2f}'.format(accuracy_score(y_test, etc_pred)))\nprint('\\n')\nprint(\"Classification Report : \")\nprint(classification_report(y_test,etc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"WOWW ! There's an improvement. I mean just look at the f1-scores.\n\nI've tried with different models but, this seems to work really good. So I'll keep this model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Wait a minute, our work isn't done yet.\n\nA good data scientist should be able to build a model, which can produce amazing results even with lesser data.\nAs we can see `ExtraTreesClassifier` did really good let's see the what are top 10 important features, and see if we can achieve the same results as compared to using all the features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"etc.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I know this is not readable, so let's visualize it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\n# Helper function for plotting feature importance\ndef plot_features(columns, importances, n=10):\n    df = (pd.DataFrame({\"features\": columns,\n                        \"feature_importance\": importances})\n          .sort_values(\"feature_importance\", ascending=False)\n          .reset_index(drop=True))\n    \n    sns.barplot(x=\"feature_importance\",\n                y=\"features\",\n                data=df[:n],\n                orient=\"h\")\nplot_features(X_train.columns, etc.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmmm, top 10 features according to our model are : \n                                                    \n`'meaneduc',\n'SQBmeaned',\n'hogar_nin',\n'SQBhogar_nin',\n'cielorazo',\n'qmobilephone',\n'idhogar',\n'overcrowding',\n'r4t1',\n'SQBdependency'`.\n                                                    \nSo let's just use these 10 features and see if the model still works good.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data = df[['meaneduc','SQBmeaned','hogar_nin','SQBhogar_nin','cielorazo',\n               'qmobilephone','idhogar','overcrowding','r4t1','SQBdependency']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(new_data,y, test_size=0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"etc = ExtraTreesClassifier().fit(X_train, y_train)\netc_pred = etc.predict(X_test)\nprint('R2 score is : {:.2f}'.format(accuracy_score(y_test, etc_pred)))\nprint('\\n')\nprint(\"Classification Report : \")\nprint(classification_report(y_test,etc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nice, still works like a charm.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now It's time to predict on the test data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/costa-rican-household-poverty-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, making a copy of test set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = test.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the information of test data...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's similar to our training data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Looking at categorical features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for label, content in test_df.items():\n    if pd.api.types.is_string_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, we have 5 categorical features, let's set `Id` as index and drop it.\n\nBetter yet, since we've already done this while training our model using `preprocess_data`, let's use the same function here.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_data(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Beautiful, everything looks good.\n\nNow let's predict it on our test set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = rf.predict(test_df)\npred = pd.DataFrame(pred)\npred.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Id = test['Id']\nId = pd.DataFrame(Id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs = pd.concat([id, pred], ignore_index=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs.rename(columns={'0':'ID','1':'Target'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs.columns = ['Id','Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs.drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = subs.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s.set_index('Id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs = s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}