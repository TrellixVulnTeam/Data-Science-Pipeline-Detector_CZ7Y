{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Carregando os dados\ndf = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\nentrega = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/sample_submission.csv')\n\ndf.shape, test.shape, entrega.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Fiz o mesmo que foi realizado em aula com o dataset de treino","metadata":{}},{"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# na coluna dependency\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quais colunas do dataframe são do tipo object\ndf_all.select_dtypes('object').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Verificando os valores de aluguel (v2a1) para os chefes/as de familia (parentesco1 = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['v2a1'].fillna(-1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### A maioria das variáveis com missing values foram substituídas por -1, pois não podemos assumir que os valores ausentes são 0. Eles vão interferir nos dados. Já a variável 'v18q1' é a quantidade de tablets dentro de uma residência. Comparando ela com a variável v18q, podemos concluir que os valores ausentes são as residências que não possuem tablets. Logo, esses valores ausentes podem ser substituídos por 0.","metadata":{}},{"cell_type":"code","source":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prenchendo com -1 os valores nulos de SQBmeaned, meaneduc e rez_esc\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Análise Exploratória de algumas variáveis","metadata":{}},{"cell_type":"markdown","source":"##### Para as variáveis binárias, eu realizei um agrupamento delas com o total de entradas de cada variável, vendo a distribuição delas em histogramas","metadata":{}},{"cell_type":"code","source":"pared = df_all.filter(regex='^pared',axis=1)\n\npared_sum = pared.sum()\n\nparede = pared_sum.to_frame()\n\nnomes_paredes = ['Concreto ou tijolo', 'Parede revestida', 'Pré-fabricada ou cimento', \n                 'Material reciclado', 'Madeira', 'Zinco', 'Fibras naturais', 'Outros']\n\npared_sum.index = nomes_paredes\n\nplt.figure(figsize=(15,10))\n\nplt.bar(pared_sum.index.values, pared_sum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ec = df_all.filter(regex='^estadocivil',axis=1)\n\nec = ec.sum()\n\nnomes_ec = ['Menos de 10 anos de idade', 'União estável', 'Casado', \n            'Divorciado', 'Separado', 'Viúvo(a)', 'Solteiro']\n\nec.index = nomes_ec\n\nplt.figure(figsize=(15,10))\n\nplt.bar(ec.index.values, ec)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lixo = df_all.filter(regex='^elimbasu',axis=1)\n\nlixo = lixo.sum()\n\nnomes_lixo = ['Caminhão de lixo', 'Buraco ou enterrado', 'Cremado', \n              'Espaço não ocupado', 'Jogado em rio, lagoa ou mar', 'Outro']\nlixo.index = nomes_lixo\n\nplt.figure(figsize=(15,10))\n\nplt.bar(lixo.index.values, lixo)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sanitario = df_all.filter(regex='^sanitario',axis=1)\n\nsanitario = sanitario.sum()\n\nnomes_sanitario = ['Sem sistema sanitário', 'Esgoto', 'Tanque séptico', 'Latrina', 'Outro sistema']\nsanitario.index = nomes_sanitario\n\nplt.figure(figsize=(15,10))\n\nplt.bar(sanitario.index.values, sanitario)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agua = df_all.filter(regex='^abastagua',axis=1)\n\nagua = agua.sum()\n\nnomes_agua = ['Abastecimento interno', 'Abastecimento externo', 'Sem água']\nagua.index = nomes_agua\n\nplt.figure(figsize=(10,10))\n\nplt.bar(agua.index.values, agua)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"teto = df_all.filter(regex='^techo',axis=1)\n\nteto = teto.sum()\n\nnomes_teto = ['Folha laminada ou zinco', 'Fibra de cimento, mezanino', 'Fibras naturais', 'Outros']\n\nteto.index = nomes_teto\n\nplt.figure(figsize=(15,10))\n\nplt.bar(teto.index.values, teto)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"piso = df_all.filter(regex='^piso',axis=1)\n\npiso = piso.sum()\n\nnomes_piso = ['Mosaico, cerâmica ou porcelanato', 'Cimento', 'Outro', 'Material Natural', 'Sem piso', 'Madeira']\n\npiso.index = nomes_piso\n\nplt.figure(figsize=(15,10))\n\nplt.bar(piso.index.values, piso)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parentesco = df_all.filter(regex='^parentesco',axis=1)\n\nparentesco = parentesco.sum()\n\nnomes_parentesco = ['Chefe da casa', 'Esposo/parceiro', 'Filho(a)',\n                    'Enteado(a)', 'Noro(a)', 'Neto(a)', 'Mãe/pai', \n                    'Sogro(a)', 'Irmã(o)', 'Cunhado(a)', \n                    'Outro parente', 'Outra pessoa']\n\nparentesco.index = nomes_parentesco\n\nplt.figure(figsize=(20,10))\n\nplt.bar(parentesco.index.values, parentesco)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"escol = df_all.filter(regex='^instlevel',axis=1)\n\nescol = escol.sum()\n\nnomes_escol = ['Sem educação', 'Primário incompleto', 'Primário completo', \n               'Secundário incompleto', 'Secundário completo', 'Técnico incompleto',\n               'Técnico completo', 'Ensino superior', 'Pós-graduação']\n               \nescol.index = nomes_escol\n\nplt.figure(figsize=(20,10))\n\nplt.bar(escol.index.values, escol)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"casa = df_all.filter(regex='^tipovivi',axis=1)\n\ncasa = casa.sum()\n\nnomes_casa = ['Casa própria', 'Casa própria, mas pagando', 'Alugada', 'Precária', 'Outro']\n\ncasa.index = nomes_casa\n\nplt.figure(figsize=(15,10))\n\nplt.bar(casa.index.values, casa)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lugar = df_all.filter(regex='^lugar',axis=1)\n\nlugar = lugar.sum()\n\nnomes_lugar = ['Central', 'Chorotega', 'Pacífico Central', 'Brunca',\n              'Huetar Atlántica', 'Huetar Norte']\n\nlugar.index = nomes_lugar\n\nplt.figure(figsize=(15,10))\n\nplt.bar(lugar.index.values, lugar)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"area = df_all.filter(regex='^area',axis=1)\n\narea = area.sum()\n\nnomes_area = ['Área urbana', 'Área Rural']\n\narea.index = nomes_area\n\nplt.figure(figsize=(5,10))\n\nplt.bar(area.index.values, area)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all['Idade'] = df_all['age']\n\nplt.figure(figsize=(20,12))\nsns.histplot(data=df_all, x='Idade')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tratando os dados desbalanceados e utilizando Random Forest para a variável Target ","metadata":{}},{"cell_type":"markdown","source":"##### As primeiras células foram retiradas do notebook criado na aula. As células seguintes foram baseadas nesse notebook e em outras submissões da competição.","metadata":{}},{"cell_type":"code","source":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\nX_train, Y_train = train[feats], train[['Target']]\nX_test, Y_test = test[feats], test[['Target']]\n\ntrain.shape, test.shape, X_test.shape, Y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(['Id', 'idhogar'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As células abaixo estão como comentário para rodar apenas o último resultado","metadata":{}},{"cell_type":"code","source":"# Instanciando o random forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Treinando o modelo\n\n#rf.fit(train[feats], train['Target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prever o Target de teste usando o modelo treinado\n\n#test['Target'] = rf.predict(test[feats]).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Criando o arquivo para submissão\n# test[['Id', 'Target']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### A partir daqui, tentamos utilizar Over Sampling para poder tratar o desbalanceamento dos dados.","metadata":{}},{"cell_type":"code","source":"ros = RandomOverSampler(random_state = 42)\nX_ros, y_ros = ros.fit_resample(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=1, n_estimators=200, random_state=42)\nrf.fit(X_ros,y_ros)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test['Target'] = rf.predict(test[feats]).astype(int)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test[['Id', 'Target']].to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Over Sampling não é a melhor maneira de lidar com os dados. Vamos tentar regressão .","metadata":{}},{"cell_type":"code","source":"# from sklearn.feature_selection import SelectKBest, f_regression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## a variável ID tem que ser dropada, pois causa erro na próxima tentativa\n\n## x = train.drop(['Target', 'Id', 'idhogar'], axis=1)\n## y = train.Target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### seleciona as melhores K variáveis para o modelo\n\n## variaveis = SelectKBest(score_func = f_regression, k = 80)\n## novas_variaveis = variaveis.fit_transform(x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## var_selec = variaveis.get_support()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## len(var_selec)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## var_teste = train.columns\n## var_teste","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### A próxima célula é repetiva, mas ela foi feita da seguinte maneira, pois o length da variável var_teste tem que ter o mesmo lenght da variável var_selec.","metadata":{}},{"cell_type":"code","source":"# var_teste = list(var_teste)\n\n# del var_teste[len(var_teste)-1]\n\n# var_teste = list(var_teste)\n\n# del var_teste[len(var_teste)-1]\n\n# var_teste = list(var_teste)\n\n# del var_teste[len(var_teste)-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(var_teste)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# var = []\n# for i in range (len(var_teste)):\n  #  if var_selec[i] == True:\n   #     var.append(var_teste[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# teste = train[var]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# var.append('Target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# treino = train[var]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Aqui eu realizei o mesmo drop que foi realizado acima para poder rodar as bases de teste e treino durante o predict.","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train, X_val, y_train, y_val = train_test_split (test, test.Target, test_size = 0.3, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Vamos tentar utilizar regressão para conseguir as variáveis Target.","metadata":{}},{"cell_type":"code","source":"# from sklearn.ensemble import RandomForestRegressor \n\n# florestarandomica = RandomForestRegressor(n_estimators = 200, criterion='mse', random_state=42, max_depth = 15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# florestarandomica.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred = florestarandomica.predict(X_val)\n\n# from sklearn.metrics import mean_squared_error\n\n# mean_squared_error(y_pred,y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tentativa1 = florestarandomica.predict(teste)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# entrega['Target'].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# entrega.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### O score obtido através dessa tentativa é menor que 0.20. Vamos tentar mudar a maneira como geramos os dados da variável Target. Vamos tentar Under Sampling.","metadata":{}},{"cell_type":"code","source":"rus = RandomUnderSampler(random_state = 42)\nX_under, y_under = rus.fit_resample(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=1, n_estimators=200, random_state=42)\nrf.fit(X_under,y_under)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Target'] = rf.predict(test[feats]).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['Id', 'Target']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Aparentemente, o Under Sample é melhor do que regressão e que Over Sample para o problema.","metadata":{}}]}