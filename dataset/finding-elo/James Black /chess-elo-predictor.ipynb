{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#chess analysis object oriented \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport statistics as st\nimport pickle\nfrom sklearn.preprocessing import RobustScaler\n\nRS = RobustScaler()\n\n\n\ndata1 = pd.read_pickle('chess_data.pkl')\n\n#removing errors \ndata1.loc[13683, 'result'] = 0.5\ndata1.loc[15846, 'result'] = 0\ndata1.loc[33094,'result'] = 1\nwhite= []\nfor i in data1.white:\n    white.append(float(i))\nblack = []\nfor i in data1.black:\n    black.append(float(i))\n\ndata1.white = white \ndata1.black = black    \nmeanElo = []\nfor i, j in zip(data1.white, data1.black):\n    meanElo.append((i+j)/2)\neloDiff = []\nfor i, j in zip(data1.white, data1.black):\n    eloDiff.append(i-j)\ndata1 = pd.concat([data1,pd.Series(meanElo), pd.Series(eloDiff)], axis = 1)\ndata1.rename(columns = {0: 'meanElo', 1: 'diffElo'}, inplace = True)\nlenmoves = []\nfor i in data1.moves:\n    lenmoves.append(len(i) -1)\nlenmoves = pd.Series(lenmoves)\ndata1 = pd.concat([data1,lenmoves], axis = 1)\ndata1.rename(columns = {0:'lengths'}, inplace = True)\n\n\nclippedElo = []\nfor i in data1.evals:\n    clippedElo.append((pd.Series(i)).clip(-400,400))\n\ndata1.evals = clippedElo\n\n\n\nmean_data = pd.DataFrame(data1.lengths)\n\n\nclass Features:\n    def __init__(self, name, data):\n        self.name = name\n        self.data =  data\n    def addtodata(self):\n            matrix.data = pd.concat([matrix.data, pd.Series(self.data)], axis = 1)\n            matrix.data.rename(columns = {0:self.name}, inplace = True)\n        \n    def removefromdata(self):\n        matrix.drop(self.name, axis = 1, inplace = True)\n    \n\nclass EvalFeatures(Features):\n    def __init__(self, name, data):\n        super().__init__(name, data)\n        self.std = []\n        for i in self.data:\n            if i != []:\n                self.std.append(np.std(i))\n            else:\n                self.std.append(None)\n        self.std = pd.Series(self.std) \n        self.std.fillna(np.median(self.std.dropna()), inplace = True)\n        self.median = []\n        for i in self.data:\n            if i != []:\n                self.median.append(np.median(i))\n            else:\n                self.median.append(None)\n        self.median = pd.Series(self.median) \n        self.median.fillna(np.median(self.median.dropna()), inplace = True)\n        self.maximum = []\n        for i in self.data:\n             if i != []:\n                self.maximum.append(np.max(i))\n             else:\n                self.maximum.append(None)\n        self.maximum = pd.Series(self.maximum) \n        self.maximum.fillna(np.median(self.maximum.dropna()), inplace = True)\n        self.minimum = []\n        for i in self.data:\n             if i != []:\n                self.minimum.append(np.min(i))\n             else:\n                self.minimum.append(None)\n        self.minimum = pd.Series(self.minimum) \n        self.minimum.fillna(np.median(self.minimum.dropna()), inplace = True)    \n    def addtodata(self):\n            matrix.data = pd.concat([matrix.data, pd.Series(self.std),pd.Series(self.median),pd.Series(self.maximum),pd.Series(self.minimum)], axis = 1)\n            matrix.data.rename(columns = {0 : self.name + '_std',1 : self.name +'_med', 2 : self.name + '_max', 3 : self.name +'_min'}, inplace = True)\n    def addtodataMean(self):\n            means.data = pd.concat([means.data, pd.Series(self.std),pd.Series(self.median),pd.Series(self.maximum),pd.Series(self.minimum)], axis = 1)\n            means.data.rename(columns = {0 : self.name + '_std',1 : self.name +'_med', 2 : self.name + '_max', 3 : self.name +'_min'}, inplace = True)\n    \n    @staticmethod\n    def partitiondiffs(pieces, eval_cutoff = 10000, first_move = 0, last_move = 1000):\n        minuses = []\n        if pieces == 'white':\n            for i in matrix.data.evals:\n                avg = []\n                if len(i) > first_move:\n                    for j in range(first_move, (min(len(i), last_move))):\n                        if (j%2 == 0) & (j !=0):\n                            if (-(eval_cutoff) < i[j] < eval_cutoff):\n                                avg.append(i[j] - i[j-1])\n            \n                minuses.append(avg)\n            minuses = pd.Series(minuses)                \n            return minuses\n            #return minuses.fillna(np.median(minuses).dropna()) \n        \n        elif pieces == 'black':\n            for i in matrix.data.evals:\n                avg = []\n                if len(i) > first_move:\n                    for j in range(first_move, (min(len(i), last_move))):\n                        if (j%2 != 0):\n                            if (-(eval_cutoff) < i[j] < eval_cutoff):\n                                avg.append(-1*(i[j] - i[j-1]))\n                minuses.append(avg)\n            minuses = pd.Series(minuses)                \n            return minuses\n        \nclass MoveFeatures(Features):\n    def __init__(self, name, data):\n        super().__init__(name, data)\n        self.queenw, self.queenb = MoveFeatures.firstmove('Q')\n        self.kingw, self.kingb = MoveFeatures.firstmove('K')\n        self.checkw, self.checkb = MoveFeatures.firstmove('+')  \n    def addtodata1(self):\n            matrix.data = pd.concat([matrix.data, pd.Series(self.queenw),pd.Series(self.queenb),pd.Series(self.kingw),pd.Series(self.kingb), pd.Series(self.checkw),pd.Series(self.checkb)], axis = 1)\n            matrix.data.rename(columns = {0 : 'queenw',1 : 'queenb', \n                                          2 : 'kingw', 3 : 'kingb',4 : 'checkw', \n                                          5 : 'checkb'}, inplace = True)\n    @staticmethod\n    def firstmove(piece):\n        white = []\n        black = []\n        for i in matrix.data.moves:\n            for j in range(len(i)):\n                if j == (len(i) -1):\n                    white.append(j)\n                if (piece in i[j]) & (j%2 == 0):\n                    white.append(j)\n                    break\n        \n    \n        for i in matrix.data.moves:\n            for j in range(len(i)):\n                if j == (len(i) -1):\n                    black.append(j)\n                if (piece in i[j]) & (j%2 != 0):\n                    black.append(j)\n                    break  \n        return white,black\n    @staticmethod\n    def goodmovecounts(colour, threshold, result, move):\n        count = []\n        if colour == 'white':\n            for i in matrix.data.evals:\n                moves = 0\n                if len(i) >0: \n                    for j in range(len(i)):                   \n                        if (j%2 == 0) & (j !=0):\n                            if move == 'good':\n                                if i[j] - i[j-1] > threshold:\n                                    moves+=1\n                            elif move == 'bad':\n                                if i[j] - i[j-1] < threshold:\n                                    moves+=1\n                    if result == 'count':\n                        count.append(moves)\n                    else:\n                        count.append(moves/(len(i)/2))\n                else: \n                    count.append(None)                \n        if colour == 'black':\n            for i in matrix.data.evals:\n                moves = 0\n                if len(i) >0: \n                    for j in range(len(i)):\n                        if (j%2 != 0):\n                            if move == 'good':\n                                if i[j] - i[j-1] < threshold:\n                                    moves+=1\n                            elif move == 'bad':\n                                if i[j] - i[j-1] > threshold:\n                                    moves+=1\n                    if result == 'count':\n                        count.append(moves)\n                    else:\n                        count.append(moves/(len(i)/2))\n                else: \n                    count.append(None)\n        return pd.Series(count)\n    \n    \nmatrix = Features('matrix', data1)\n\n\n\ndiffs = []\nfor i in matrix.data.evals:\n    each_diff = []\n    for j in range(len(i)):\n        if j !=0:\n            each_diff.append(i[j] - i[j-1])\n    diffs.append(each_diff)\n\nabsdiffs = []\nfor i in diffs:\n    eachabsdiff = []\n    for j in range(len(i)):\n        eachabsdiff.append(abs(i[j]))\n    absdiffs.append(eachabsdiff)\n\n\n\ndiffsw = []\nfor i in matrix.data.evals:\n    each_diff = []\n    for j in range(len(i)):\n        if j !=0 and j%2 == 0:\n            each_diff.append(i[j] - i[j-1])\n    diffsw.append(each_diff)\n\ndiffsb = []\nfor i in matrix.data.evals:\n    each_diff = []\n    for j in range(len(i)):\n        if j%2 !=0:\n            each_diff.append(i[j] - i[j-1])\n    diffsb.append(each_diff)\n\nmeans = Features('means', mean_data)\ndeltas = EvalFeatures('delta', diffs)\nabsdeltas = EvalFeatures('absdeltas', absdiffs)\ndeltas.addtodata()\nabsdeltas.addtodataMean()\n\ndeltasw= EvalFeatures('deltasw', diffsw)\ndeltasw.addtodata()\ndeltasb = EvalFeatures('deltasb', diffsb)\ndeltasb.addtodata()\n\n\ndeltaw1 = EvalFeatures('deltaw1',EvalFeatures.partitiondiffs('white', first_move = 0, last_move = 20))\ndeltaw1.addtodata()\ndeltaw2 = EvalFeatures('deltaw2',EvalFeatures.partitiondiffs('white', first_move = 21, last_move = 40))\ndeltaw2.addtodata()\ndeltaw3 = EvalFeatures('deltaw3',EvalFeatures.partitiondiffs('white', first_move = 41, last_move = 60))\ndeltaw3.addtodata()\ndeltaw4 = EvalFeatures('deltaw4',EvalFeatures.partitiondiffs('white', first_move = 61, last_move = 90))\ndeltaw4.addtodata()\ndeltaw5 = EvalFeatures('deltaw5',EvalFeatures.partitiondiffs('white', first_move = 91))\ndeltaw5.addtodata()\n\ndeltab1 = EvalFeatures('deltab1',EvalFeatures.partitiondiffs('black', first_move = 0, last_move = 20))\ndeltab1.addtodata()\ndeltab2 = EvalFeatures('deltab2',EvalFeatures.partitiondiffs('black', first_move = 21, last_move = 40))\ndeltab2.addtodata()\ndeltab3 = EvalFeatures('deltab3',EvalFeatures.partitiondiffs('black', first_move = 41, last_move = 60))\ndeltab3.addtodata()\ndeltab4 = EvalFeatures('deltab4',EvalFeatures.partitiondiffs('black', first_move = 61, last_move = 90))\ndeltab4.addtodata()\ndeltab5 = EvalFeatures('deltab5',EvalFeatures.partitiondiffs('black', first_move = 91))\ndeltab5.addtodata()\n\nmoves = MoveFeatures('moves', matrix.data.moves)\nmoves.addtodata1()\n\ngoodmovesw = Features('goodmovesw',MoveFeatures.goodmovecounts('white', -10, 'share','good'))\ngoodmovesb = Features('goodmovesb',MoveFeatures.goodmovecounts('white', 10, 'share','good'))\ngoodmovescw = Features('goodmovescw',MoveFeatures.goodmovecounts('white', -10, 'count','good'))\ngoodmovescb = Features('goodmovescb',MoveFeatures.goodmovecounts('white', 10, 'count','good'))\n\ngoodmovesw.addtodata()\ngoodmovesb.addtodata()\ngoodmovescw.addtodata()\ngoodmovescb.addtodata()\n\n\n\n\nblundersw = Features('blundersw',MoveFeatures.goodmovecounts('white', -100, 'share','bad'))\nblundersb = Features('blundersb',MoveFeatures.goodmovecounts('white', 100, 'share','bad'))\nblunderscw = Features('blunderscw',MoveFeatures.goodmovecounts('white', -100, 'count','bad'))\nblunderscb = Features('blunderscb',MoveFeatures.goodmovecounts('white', 100, 'count','bad'))\n\nblundersw.addtodata()\nblundersb.addtodata()\nblunderscw.addtodata()\nblunderscb.addtodata()\n\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nle = LabelEncoder()\nohe = OneHotEncoder(sparse = False)\n\nlabelencodedv = le.fit_transform(data1.variation)\nonehotencodedv = ohe.fit_transform(labelencodedv.reshape(-1,1))\n\nlabelencodedo = le.fit_transform(data1.opening)\nonehotencodedo = ohe.fit_transform(labelencodedo.reshape(-1,1))\n\nopenings = pd.concat([pd.DataFrame(onehotencodedo), pd.DataFrame(onehotencodedv)], axis = 1)\n\n'''x1_mean = pd.concat([means.data, openings], axis = 1)\nx1_mean.columns = list(range(1123))\ny1_mean = data1.meanElo\n\nx1_diff = matrix.data.drop(['white', 'black', 'meanElo', 'diffElo','result', 'evals', 'opening', 'variation', 'moves','lengths'], axis = 1) \ny1_diff = data1.diffElo\n\nx_trainm = x1_mean.loc[:20000, :]\nx_testm = x1_mean.loc[20000:,:]\ny_trainm = y1_mean.loc[:20000]\ny_testm = y1_mean.loc[20000:]\n\n\nx_traind = x1_diff.loc[:20000, :]\nx_testd = x1_diff.loc[20000:,:]\ny_traind = y1_diff.loc[:20000]\ny_testd = y1_diff.loc[20000:]\n\n\n\n\nfrom xgboost import XGBRegressor\n\nxgb = XGBRegressor(max_depth = 4, n_estimators = 250, learning_rate = 0.05, lamda= .1, alpha = .1 )\n\nxgb.fit(x_trainm,y_trainm)\nxgbpredsm = xgb.predict(x_testm)\n\nnp.sqrt(mse(xgbpreds,y_testm))\n\nxgb.fit(x_traind, y_traind)\nxgbpredsd = xgb.predict(x_testd)\nfinalpredsw = []\nfinalpredsb = []\nfor i,j in zip(xgbpredsm, xgbpredsd):\n    finalpredsw.append(i + (j/2))\n    finalpredsb.append(i - (j/2))\n\nnp.sqrt(mse(finalpredsw,y_test.white))'''\n\n\ntrain = matrix.data.loc[:24999,:]\ntrain = pd.concat([train, openings.loc[:24999]], axis = 1)\n\n\n#test data \nX2  = matrix.data.drop(['white', 'black', 'meanElo', 'diffElo','result', 'evals', 'opening', 'variation', 'moves'], axis = 1).loc[25000:,:]\nX2 = pd.concat([X2, openings.loc[25000:]], axis = 1)\n\n#outliers \ntrain.drop(labels = [14854,23781],inplace = True)\ntrain.reset_index(inplace = True, drop = True)\n\n\n\n\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.metrics import mean_squared_error\nmse  = mean_squared_error\n\n\n\n\nX1= train.drop(labels = train.lengths.loc[(train.lengths<20)].index)\nX1= X1.drop(labels = train.lengths.loc[(train.lengths>300)].index)\nX1.reset_index(inplace = True, drop = True)\n\n\n\n\ny = X1[['white','black']]\nX = X1.drop(['white', 'black', 'meanElo', 'diffElo','result', 'evals', 'opening', 'variation', 'moves'], axis = 1)\n\nX.columns = list(range(1306))\n\n\n\nx_train = X.loc[ :20000,:]\nx_test = X.loc[20000:,:]\ny_train = y.loc[:20000,:]\ny_test = y.loc[20000:,:]\n\n\n\n\n\nx_train = pd.DataFrame(RS.fit_transform(x_train))\nx_test = pd.DataFrame(RS.fit_transform(x_test))\n\n\n\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import AdaBoostRegressor\nxgb = XGBRegressor(max_depth = 4, n_estimators = 250, learning_rate = 0.05)\n#en = ElasticNet(alpha = 0,l1_ratio = .1, max_iter = 500)\n#ada = AdaBoostRegressor(n_estimators = 25, learning_rate = .05)\n\n#en.fit(x_train,y_train.white)\n#enpreds = en.predict(x_test)\n\n#ada.fit(x_train,y_train.white)\n#adapreds = ada.predict(x_test)\n\nxgb.fit(x_train,y_train.white)\nxgbpreds = xgb.predict(x_test)\n\nprint('xgb error is ' + str(np.sqrt(mse(xgbpreds,y_test.white))))\n#print('en error is ' + str(np.sqrt(mse(enpreds,y_test.white))))\n#print('ada error is ' + str(np.sqrt(mse(adapreds,y_test.white))))\n\nmisses =[]\nfor i,j in zip(xgbpreds,y_test.white):\n    misses.append(i-j)\n\n'''missesada =[]\nfor i,j in zip(adapreds,y_test.white):\n    missesada.append(i-j)'''\n\n\n\n#final preds\nxgbw = XGBRegressor(max_depth = 4, n_estimators = 250, learning_rate = 0.05)\nxgbb = XGBRegressor(max_depth = 4, n_estimators = 250, learning_rate = 0.05)\nX2.columns = list(range(1306))\n\n\nX = pd.DataFrame(RS.fit_transform(X))\nX2 = pd.DataFrame(RS.fit_transform(X2))\n\n\n\n\nxgbw.fit(X,y.white)\nxgbb.fit(X,y.black)\nwhite_preds = xgbw.predict(X2)\nblack_preds = xgbb.predict(X2)\n\nevents = list(range(25001,50001))\nintev= []\nfor i in events:\n    intev.append(int(i))\n\npreds = pd.concat([pd.Series(events), pd.Series(white_preds), pd.Series(black_preds)], axis = 1 )\npreds.columns = ['Event', 'WhiteElo','BlackElo']\npreds.Event = intev\n\npreds.to_csv('first_preds.csv', index = False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}