{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><h2>Kaggle Survey 2019 Story</h2></center>\n<p style='text-align: justify;'>Machine learning (ML) algorithms and statistical models of data science has become so popular in industries and enterprises in past few years. Data science is a multi-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data. These algorithms have revolutionized and change the structure of organizations. There is a lot of data collected by organizations on daily basis. Before these algorithms and techniques, a lot of hard work is required to extract useful information from bulky data (a.k.a big data).This is where machine learning algorithms come into power. The machine learning algorithms are a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task Thus saving a lot of time and man power for employers and employees in the organization. In order to know what’s happening in organizations, what ML algorithms they use and what frameworks and materials they use, a small survey has been conducted. This survey is composed of 34 multiple choice questions and survey got 19717 responses. Table below shows the questions asked within they survey, after that, we see what survey got response. </p>"},{"metadata":{},"cell_type":"markdown","source":"<table width=\"100%\" border=\"1\" cellpadding=\"0\" cellspacing=\"0\" bordercolor=\"#000000\">\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p><strong>SR#</strong></p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p><strong>Questions</strong></p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">1</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>What is your age?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">2</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>What is your gender?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">3</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>In which country do    you currently reside?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">4</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>What is the highest    level of formal education that you have attained or plan to attain within the    next 2 years?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">5</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Select the title    most similar to your current role (or most recent title if retired)</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">6</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>What is the size of    the company where you are employed?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">7</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Approximately how    many individuals are responsible for data science workloads at your place of    business?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">8</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Does your current    employer incorporate machine learning methods into their business?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">9</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Select any    activities that make up an important part of your role at work</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">10</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>What is your current    yearly compensation (approximate $USD)?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">11</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Approximately how    much money have you spent on machine learning and/or cloud computing products    at your work in the past 5 years?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">12</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Who/what are your    favorite media sources that report on data science topics?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">13</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>On which platforms    have you begun or completed data science courses?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">14</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>What is the primary    tool that you use at work or school to analyze data?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">15</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>How long have you    been writing code to analyze data (at work or at school)?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">16</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which of the following    integrated development environments (IDE's) do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">17</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which of the    following hosted notebook products do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">18</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>What programming    languages do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">19</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>What programming    language would you recommend an aspiring data scientist to learn first?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">20</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>What data    visualization libraries or tools do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">21</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which types of    specialized hardware do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">22</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Have you ever used a    TPU (tensor processing unit)?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">23</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>For how many years    have you used machine learning methods?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">24</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which of the    following ML algorithms do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">25</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which categories of    ML tools do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">26</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which categories of    computer vision methods do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">27</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which of the    following natural language processing (NLP) methods do you use on a regular    basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">28</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which of the    following machine learning frameworks do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">29</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which of the    following cloud computing platforms do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">30</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which specific cloud    computing products do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">31</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which specific big    data / analytics products do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">32</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which of the    following machine learning products do you use on a regular basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">33</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which automated    machine learning tools (or partial AutoML tools) do you use on a regular    basis?</p></td>\n  </tr>\n  <tr>\n    <td width=\"37\" nowrap valign=\"top\"><p align=\"right\">34</p></td>\n    <td width=\"587\" nowrap valign=\"top\"><p>Which of the    following relational database products do you use on a regular basis?</p></td>\n  </tr>\n</table>\n"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The first column of data contains information about time taken by participants to fill out survey. The minimum time taken was 23 seconds and the maximum time taken by participant was 843612 seconds. There are some instances where people leave the site open and went to do other stuff and then came back to fill forms. Some participants type text which takes time to fill the form as some are slow types, some are fast typists. That is why there is a lot of time difference. The minimum time is 23 seconds is the case where may be did not added his on other text but only choses the choices already available.  The average time taken by participants is 14341 seconds.\n</p>"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>In 1st question was about the age of participants. The age from 18 to 70 above. From 19717 participants, 2502 participants marked their age as 18-21. 3610 participants marked their age as 22-24. 4458 participants marked their age as 25-29. 3120 participants marked their age as 30-24. 2087 participants marked their age as 35-39. 1439 participants marked their age as 40-44. 949 marked their age as 45-49. 692 participants marked their age as 50-54. 422 participants marked their age as 55-59. 339 marked their age as 60-69. 100 participants marked their age as 70+. The graph below shows the representations of all participants age groups. The Results showed that the most participants were aged with between 25 – 29 (4458) while the least ones are 70+ (100). The statistics are shown below.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-n-EazbGP7Ws/XeUG3Lmm2UI/AAAAAAAAEgo/KN2Mz8RXtAcdrVzVv2J60h8EPhkq9hUtQCKgBGAsYHg/s1600/ap.png\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 2nd question was about the gender with 4 possible options. The 16138 participants said that they are males (Male). 3212 participants said that they are females (Female). 318 said that they prefer not to describe (PNTS).  Those want to self-describe themselves were provided with text box to explain themselves whose data is available in other responses file (PTSD).  The Graph of gender statistics is shown below.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-qrbxqcwnBtQ/XeUG3Af6mTI/AAAAAAAAEgo/gnVA0HnapzkFLsvorB1dF_MLuAGIeuPGACKgBGAsYHg/s1600/gp.png**\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>During survey, survey takers leave one choice optional for participants to enter their own information if other hard coded choices do not apply. Same in this survey, “Prefer to self-describe (PTSD)” left open for participants. Some of the results in other options were hilarious. It is very painful to see that when option of male or female is provided then why people put it in self -description. Some responses were “I am funky potato”, “Heli copter”, “I am robot” etc. We are curious to know if really potatoes or helicopters give birth to children or they really belong to living organisms or genders. Well anyhow, we applied text mining, duplicate removal, trimming, word frequency, string matching and correction, stopword removal (like in “I am transgender” the word “I” and “am” are stopwords, the real word we need is “transgender”) algorithms to remove less frequent, useless words and keep only useful, frequent and expected words. After all this corrections, we got 5 trans (transgenders), 7 binary, 9 male , 2 female, 2 genderfluid and 2 half words in gender other responses. Statistics are shown below.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-O81VIQK9Urk/XeUG3IWsIwI/AAAAAAAAEgo/LYi1QxP3FfIG_NVWNptMB2yWq4mrSOd8ACKgBGAsYHg/s1600/gpo.png\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p align='justify'>The 3rd question was about the countries the participants belong too. Table below shows the countries and participants from each country.</p>"},{"metadata":{},"cell_type":"markdown","source":"<table cellspacing=\"0\" cellpadding=\"0\">\n  <col width=\"233\">\n  <col width=\"64\">\n  <tr height=\"20\">\n      <td height=\"20\" width=\"291\"><div align=\"left\"><strong>Countries</strong></div></td>\n    <td width=\"146\"><strong>Participant Count </strong></td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">France</div></td>\n    <td align=\"right\">387</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">India</div></td>\n    <td align=\"right\">4786</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Germany</div></td>\n    <td align=\"right\">531</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Australia</div></td>\n    <td align=\"right\">269</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">United States of America</div></td>\n    <td align=\"right\">3085</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Netherlands</div></td>\n    <td align=\"right\">161</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Ireland</div></td>\n    <td align=\"right\">89</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Russia</div></td>\n    <td align=\"right\">626</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Greece</div></td>\n    <td align=\"right\">108</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Ukraine</div></td>\n    <td align=\"right\">191</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Pakistan</div></td>\n    <td align=\"right\">210</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Japan</div></td>\n    <td align=\"right\">673</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Other</div></td>\n    <td align=\"right\">1054</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Brazil</div></td>\n    <td align=\"right\">728</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">South Korea</div></td>\n    <td align=\"right\">182</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Belarus</div></td>\n    <td align=\"right\">68</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Nigeria</div></td>\n    <td align=\"right\">395</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">United Kingdom of Great    Britain and Northern Ireland</div></td>\n    <td align=\"right\">482</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Sweden</div></td>\n    <td align=\"right\">92</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Mexico</div></td>\n    <td align=\"right\">195</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Canada</div></td>\n    <td align=\"right\">450</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Portugal</div></td>\n    <td align=\"right\">114</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Poland</div></td>\n    <td align=\"right\">212</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Indonesia</div></td>\n    <td align=\"right\">167</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Italy</div></td>\n    <td align=\"right\">271</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Czech Republic</div></td>\n    <td align=\"right\">58</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Spain</div></td>\n    <td align=\"right\">399</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Morocco</div></td>\n    <td align=\"right\">123</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Chile</div></td>\n    <td align=\"right\">91</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Hong Kong (S.A.R.)</div></td>\n    <td align=\"right\">64</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">South Africa</div></td>\n    <td align=\"right\">120</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Hungary</div></td>\n    <td align=\"right\">56</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Argentina</div></td>\n    <td align=\"right\">123</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Turkey</div></td>\n    <td align=\"right\">288</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Singapore</div></td>\n    <td align=\"right\">156</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">!sreal</div></td>\n    <td align=\"right\">104</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Taiwan</div></td>\n    <td align=\"right\">301</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Egypt</div></td>\n    <td align=\"right\">122</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Bangladesh</div></td>\n    <td align=\"right\">136</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Colombia</div></td>\n    <td align=\"right\">168</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Norway</div></td>\n    <td align=\"right\">51</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Thailand</div></td>\n    <td align=\"right\">67</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">China</div></td>\n    <td align=\"right\">574</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Switzerland</div></td>\n    <td align=\"right\">97</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Viet Nam</div></td>\n    <td align=\"right\">128</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Denmark</div></td>\n    <td align=\"right\">55</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Tunisia</div></td>\n    <td align=\"right\">68</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Republic of Korea</div></td>\n    <td align=\"right\">73</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">New Zealand</div></td>\n    <td align=\"right\">51</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Iran</div></td>\n    <td align=\"right\">96</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Peru</div></td>\n    <td align=\"right\">74</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Kenya</div></td>\n    <td align=\"right\">114</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Romania</div></td>\n    <td align=\"right\">58</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Malaysia</div></td>\n    <td align=\"right\">80</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Belgium</div></td>\n    <td align=\"right\">70</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Algeria</div></td>\n    <td align=\"right\">58</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Austria</div></td>\n    <td align=\"right\">53</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Philippines</div></td>\n    <td align=\"right\">65</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Saudi Arabia</div></td>\n    <td align=\"right\">50</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\"></div></td>\n    <td></td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">Total</div></td>\n    <td align=\"right\">19717</td>\n  </tr>\n</table>\n"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The most least particpants were from Saudi Arabia (50) and the most highest ones were from India (4786)</p>"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 4th question was about the education of participants.  5993 participants said that they have bachelor’s degree. 8549 participants said that they have Master’s degree. 2767 said that they have PHD degree. 611 participants said that they have professional degrees. 837 participants said that they studied but don’t have degrees or still studying. 233 participants that they have no education past high school. 333 participants said that they have no answer. Visualized information is shown below. The most of the participants of survey hold Master’s degree (8549). Least have no education past high school. </p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-mMX-pJi5Hu4/XeUG3A_l7XI/AAAAAAAAEgo/otWUS-yHPb4gp6NUTVMBelDJw8iWrIqIgCKgBGAsYHg/s1600/edu.png\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 5th question was about the role of participants during job or last role if they were retired. 2705 participants said that they are Software Engineers. 1690 participants said that they have other jobs than mentioned here. 4085 participants said that they are Data Scientists. 4014 participants said that they are Students. 322 participants said that they are Statisticians. 723 participants said that they are Product/Project Managers. 1598 participants said that they are Data Analysts. 1470 participants said that they are Research Scientists. 778 participants said that they are Business Analysts. 624 participants said that they are Data Engineers. 942 participants said that they are Not employed. 156 participants said that they are DBA/Database Engineers. Below is the representation of all participants’ roles.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-7l7OPauHvg8/XeUG3BCQ6iI/AAAAAAAAEgo/I3ITRbuBOQMeJxybnhXrYzrBBFAornShgCKgBGAsYHg/s1600/prole.png\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>In other section of question 5, we applied frequent techniques to merge different words, like professor, teacher, teach into one. After corrections, counting and using different text mining algorithms we got four core professions from other responses: teacher, researcher, technologist and engineer and their number of occurrences after data processing are 638, 273, 434 and 345 respectively. The visualization of this information is shown below.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-wq9A-FhhAls/XeUG3LK6E6I/AAAAAAAAEgo/198JFuAVhpEGZvcLSx2TIAR_vL7UMjTwQCKgBGAsYHg/s1600/q5o.png\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 6th question was about the size of company. It was about the number of employees currently working in organization. 2641 participants said that there are 1000-9999 employees working in an organization. 3160 participants said that there are more than 10000 employees working in an organization. 4025 participants said that there are 0-49 employees working in an organization. 2329 participants said that there are 50-249 employees working in an organization. 1847 participants said that there are 250-999 employees working in an organization. The visualization of this information is shown below.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-DFzSH9Zc5og/XeUG3P6dRYI/AAAAAAAAEgo/3JXrtIjQqhkw64gZ1RtJBuDM1C4HJ4oJQCKgBGAsYHg/s1600/pemp.png**\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 7th question was about Individuals Responsible For Data Science Workloads. It is about how many individuals within the organization work on data science. 1880 participants said that there are no employees working on data science workloads. 3178 participants said that there are between 1 to 2 employees working on data science workloads. 2319 participants said that there are between 3 to 4 employees working on data science workloads. 3005 participants said that there are between 5 to 9 employees working on data science workloads. 1847 participants said that there are between 10 to 14 employees working on data science workloads. 967 participants said that there are between 15 to 19 employees working on data science workloads. 427 participants said that there are more than 20 employees working on data science workloads. The visualization of this information is shown below.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-UFhxh2nzboY/XeUG3GzNBPI/AAAAAAAAEgo/ZiZn-oAv8i0QYfcegsdAkaFLyBIONIB6gCKgBGAsYHg/s1600/pwl.png\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 8th question was about that does employer incorporate machine learning methods into their business or not. 1191 participants said that they Don't Know about this. 2528 participants said that they have well established machine learning models, methods and they are working on it for more than 2 years. 2415 participants said that they don’t incorporate machine learning methods. 2812 participants said that they are exploring machine learning methods and models and soon they will use or run in organization. 2731 participants said that they have recently established machine learning methods. 1550 participants said that yes they are using machine learning methods for generating insights. The visualization of this information is shown below.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-3ZtvX6dbiDc/XeUG3ET3glI/AAAAAAAAEgo/ofeB888sL2gscjdqQTPIpYph8-oCUQJlACKgBGAsYHg/s1600/ceulm.png\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 9th question was about selection of activities that make up an important part of participants' role at work. 6091 participants said that they analyze and understand data to influence product or business decisions.  3566 participants said that they build and/or run the data infrastructure that my business uses for storing. 4981 participants said that they build prototypes to explore applying machine learning to new areas. 3348 participants said that they build and/or run a machine learning service that operationally improves my product or workflows. 3705 participants said that they do experimentation and iteration to improve existing ML models. 2359 participants said that they do research that advances the state of the art of machine learning. 531 participants said that they do none of these activities are an important part of my role at work. 249 participants said that they do other kind of activities the we will see in next paragraph. The visualization of this inforamtion is shown below.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-CMPtvSG-EnI/XeUG3EwG4OI/AAAAAAAAEgo/jV-FLxJWUcIzxAPB_u9ISQy0sE4MF0UQQCKgBGAsYHg/s1600/q9.png\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>After cleaning other responses of question 9, we got its 6 categories: consultation, management, research, develop, learn and training. The word frequency was 45,49,55,50,43 and 7 respectively. The visualization of this information is shown below.</p>"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://1.bp.blogspot.com/-5BMVZJldRvc/XeUG3EmU99I/AAAAAAAAEgo/m8VDbjfhi2g8ZRBbQpkCXjEylLqXMJ0UQCKgBGAsYHg/s1600/q9o.png\" width=\"100%\">"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 10th question was about the approximate yearly compensation of participants in US dollors (\\$). 1513 participants said that they have approximate yearly compensation in between \\$0 and \\$999. 599 participants said that they have approximate yearly compensation in between \\$1000 and \\$1999. 390 participants said that they have approximate yearly compensation in between \\$2000 and \\$2999. 305 participants said that they have approximate yearly compensation in between \\$3000 and \\$3999. 289 participants said that they have approximate yearly compensation in between \\$4000 and \\$4999. 536 participants said that they have approximate yearly compensation in between \\$5000 and \\$7499. 408 participants said that they have approximate yearly compensation in between \\$7500 and \\$9999. 833 participants said that they have approximate yearly compensation in between \\$10000 and \\$14999. 529 participants said that they have approximate yearly compensation in between \\$15000 and \\$19999. 526 participants said that they have approximate yearly compensation in between \\$20000 and \\$24999. 482 participants said that they have approximate yearly compensation in between \\$25000 and \\$29999. 728 participants said that they have approximate yearly compensation in between \\$30000 and \\$39999. 719 participants said that they have approximate yearly compensation in between \\$40000 and \\$49999. 704 participants said that they have approximate yearly compensation in between \\$50000 and \\$59999. 576 participants said that they have approximate yearly compensation in between \\$60000 and \\$69999. 524 participants said that they have approximate yearly compensation in between \\$70000 and \\$79999. 405 participants said that they have approximate yearly compensation in between \\$80000 and \\$89999. 377 participants said that they have approximate yearly compensation in between \\$90000 and \\$99999. 750 participants said that they have approximate yearly compensation in between \\$100000 and \\$124999. 483 participants said that they have approximate yearly compensation in between \\$125000 and \\$149999. 434 participants said that they have approximate yearly compensation in between \\$150000 and \\$199999. 165 participants said that they have approximate yearly compensation in between \\$200000 and \\$249999. 65 participants said that they have approximate yearly compensation in between \\$250000 and \\$299999. 74 participants said that they have approximate yearly compensation in between \\$300000 and \\$500000. 83 participants said that they have approximate yearly compensation in between More than \\$500000. Table below shows all above said information.</p>"},{"metadata":{},"cell_type":"markdown","source":"<table cellspacing=\"0\" cellpadding=\"0\">\n  <col width=\"754\">\n  <col width=\"64\">\n  <tr height=\"20\">\n    <td height=\"20\" width=\"754\"><div align=\"left\"><strong>Money    Compensation</strong></div></td>\n    <td width=\"64\"><strong>Responses</strong></td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\" align=\"right\"><div align=\"left\">0</div></td>\n    <td align=\"right\">0</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">0-500</div></td>\n    <td align=\"right\">0</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">$0-999</div></td>\n    <td align=\"right\">1513</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">1,000-1,999</div></td>\n    <td align=\"right\">599</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">2,000-2,999</div></td>\n    <td align=\"right\">390</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">3,000-3,999</div></td>\n    <td align=\"right\">305</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">4,000-4,999</div></td>\n    <td align=\"right\">289</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">5,000-7,499</div></td>\n    <td align=\"right\">536</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">7,500-9,999</div></td>\n    <td align=\"right\">408</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">10,000-14,999</div></td>\n    <td align=\"right\">833</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">15,000-19,999</div></td>\n    <td align=\"right\">529</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">20,000-24,999</div></td>\n    <td align=\"right\">526</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">25,000-29,999</div></td>\n    <td align=\"right\">482</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">30,000-39,999</div></td>\n    <td align=\"right\">728</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">40,000-49,999</div></td>\n    <td align=\"right\">719</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">50,000-59,999</div></td>\n    <td align=\"right\">704</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">60,000-69,999</div></td>\n    <td align=\"right\">576</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">70,000-79,999</div></td>\n    <td align=\"right\">524</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">80,000-89,999</div></td>\n    <td align=\"right\">405</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">90,000-99,999</div></td>\n    <td align=\"right\">377</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">100,000-124,999</div></td>\n    <td align=\"right\">750</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">125,000-149,999</div></td>\n    <td align=\"right\">483</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">150,000-199,999</div></td>\n    <td align=\"right\">434</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">200,000-249,999</div></td>\n    <td align=\"right\">165</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">250,000-299,999</div></td>\n    <td align=\"right\">65</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">300,000-500,000</div></td>\n    <td align=\"right\">74</td>\n  </tr>\n  <tr height=\"20\">\n    <td height=\"20\"><div align=\"left\">&gt;500,000</div></td>\n    <td align=\"right\">83</td>\n  </tr>\n</table>\n"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 11th question was about the approximate participant's expenses on machine learning and cloud computing products in last 5 years. 4038 participants said that they didn't spent anything on ML and cloud computing products. 1485 participants said that they spent \\$1-\\$99 on ML and cloud computing products. 2335 participants said that they spent \\$100-\\$999 on ML and cloud computing products. 2123 participants said that they spent \\$1000-\\$9999 on ML and cloud computing products. 1268 participants said that they spent \\$10000-\\$99999 on ML and cloud computing products. 1001 participants said that they spent \\$100000 on ML and cloud computing products. The visualization of this information is shown below.</p>\n\n<img src='https://1.bp.blogspot.com/-S6UqjluQ1RE/XeUG3OvPAhI/AAAAAAAAEgo/BAXwzJH7C2sSSZ4QZo3Jrp0I6jua-syiQCKgBGAsYHg/s1600/q11.png' width='100%'>"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 12th question was about media sources that report on data science and participants use. 3740 participants considered Twitter (data science influencers) as media source that reports on data science. 1804 participants considered Hacker News (https://news.ycombinator.com/) as media source that reports on data science. 3419 participants considered Reddit (r/machinelearning: r/datascience: etc) as media source that reports on data science. 10751 participants considered Kaggle (forums: blog: social media: etc) as media source that reports on data science. 3755 participants considered Course Forums (forums.fast.ai: etc) as media source that reports on data science.  Siraj Raval: etc) participants considered YouTube (Cloud AI Adventures as media source that reports on data science. 2075 participants considered Podcasts (Chai Time Data Science: Linear Digressions: etc) as media source that reports on data science. 9907 participants considered Blogs (Towards Data Science: Medium: Analytics Vidhya: KDnuggets etc) as media source that reports on data science. 4472 participants considered Journal Publications (traditional publications: preprint journals: etc) as media source that reports on data science. 2412 participants considered Slack Communities (ods.ai: kagglenoobs: etc) as media source that reports on data science. 575 participants considered None as media source that reports on data science. 1184 participants considered Other as media source that reports on data science. The visualization of this information is shown below.</p>\n\n<img src=\"https://1.bp.blogspot.com/-gPWovpGfB8Q/XeUG3LETNiI/AAAAAAAAEgo/rpYHg9Fxl8QnPOUGIVQ4fHcTCTrEFSzlACKgBGAsYHg/s1600/q12.png\" width=\"100%\">\n"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>Following are the frequent terms extracted from question 12 other answers; Analytics Vidhya, github, google, Applied AI, linkedin, blogs, Arxiv org, deep learning, academics, courses conferences, publications, books, webinar, seminar, towardsdatascience, meetup, kdnuggets, telegram, telegram, paperswithcode, udemy, pluralsight, stackoverflow, data science, facebook, courseera, Andrew NG, whatsapp, newsletters, ods, data camp, zhihu, medium, instagram, o reilly, online course, wechat, quora, udacity and edx.</p>\n"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 13th question was about the platforms where participants have begun or completed data science courses. 2953 participants marked Udacity as a platform. 8685 participants marked Coursera as a platform. 3150 participants marked edX as a platform. 3843 participants marked DataCamp as a platform. 743 participants marked DataQuest as a platform. 5119 participants marked Kaggle Courses (i.e. Kaggle Learn) as a platform. 1520 participants marked Fast.ai as a platform. 4804 participants marked Udemy as a platform. 1283 participants marked LinkedIn Learning as a platform. 4478 participants marked University Courses (resulting in a university degree) as a platform. 1491 participants marked None as a platform as if they don’t use any. The visualization of this information is shown below.</p>\n\n<img src=\"https://1.bp.blogspot.com/-vsHXhT8vjsc/XeUG3Lo5Z-I/AAAAAAAAEgo/AWUvfyhB_WYNT4BlFQ9n5qO1DCq8RR1TACKgBGAsYHg/s1600/q13.png\" width=\"100%\">\n"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>Following are the most frequent and few unique choices of question 13th other choice filled by participants. aaic, alura, analytics vidhya, applied ai, aws, bilibili, book, bootcamp, caltech, class, codeacademy, coding ninja, congintiveclass, digital, DQLAB, DSA, eduonix, edureka, edvancer, edwisor, general assembly, google, great learning, IBD intel, intellipart, internshala, jigsaw, khan, lambda, mlcourse, nptel, onefourthlabs, opensap, platzi, plural sight, seminar, seminar, simplelearn, springboard, standford, stepik, upgrad, upx academy, webinar, worldquant and youtube.</p>\n\n<p style='text-align: justify;'>The 14th question was about the primary tool that participants use in work or in school to analyze data. 3061 participants said that they use Basic statistical software (Microsoft Excel, Google Sheets, etc.) to analyze data. 1188 participants said that they use Cloud-based data software & APIs (AWS, GCP, Azure, etc.) to analyze data. 8475 participants said that they use Local development environments (RStudio, JupyterLab, etc.) to analyze data. 895 participants said that they use Advanced statistical software (SPSS, SAS, etc.) to analyze data. 1190 participants said that they use Other tools to analyze data. 881 participants said that they use Business intelligence software (Salesforce, Tableau, Spotfire, etc.) to analyze data. The visualization of this information is shown below.</p>\n\n<img src=\"https://1.bp.blogspot.com/-nm1HZqkaTMY/XeUG3OJGgII/AAAAAAAAEgo/KqCKqP6oEA8ytzVucJ5D3JaP6Ir4jSYugCKgBGAsYHg/s1600/q14.png\" width=\"100%\">\n\n\n<p style='text-align: justify;'>Following are the most frequent responses of question 14th other options; Datarobot, Jupyter, Weka, Pytorch, python, RapidMiner, Pandas, R, Power BI, Spyder, MATLAB, IBM Cloud Pak for Data, Tableau, SQL, Excel, Google colab, Teradata, Inhouse software, DataRobot, Spss, No, Anaconda, spark, Visual Studio, Databricks, Alteryx, excel, Tensorflow, Knime, Microsoft Excel, spark, ROOT, anaconda, Pycharm, tensorflow, Proprietary, Watson, sage maker, Azure, Amazos Services, Redshift and salesforce.</p>\n\n<p style='text-align: justify;'>The 15th question was about participants’ duration of writing code analyze data. 4061 participants said that they are writing code in between of 1 and 2 years to analyze data. 865 participants said that they had never written code to analyze data. 3828 participants said that they are writing code less than 1 years to analyze data. 576 participants said that they are writing code more than 20 years to analyze data. 3365 participants said that they are writing code in between of 3 and 5 years to analyze data. 1887 participants said that they are writing code in between of 5 and 10 years to analyze data. 1045 participants said that they are writing code in between of 10 and 20 years to analyze data. The visualization of this information is shown below.</p>\n\n<img src=\"https://1.bp.blogspot.com/-tjHmuGeXryU/XeUG3F2Qo_I/AAAAAAAAEgo/nVP9LsJeJ_Qt3UUgdx6g4Y3yleInI2_RACKgBGAsYHg/s1600/q15.png\" width=\"100%\">\n\n\n<p style='text-align: justify;'>The 16th question was about IDEs that participants use on regular basis. 10804 participants said that they use Jupyter (JupyterLab: Jupyter Notebooks: etc) on regular basis. 4455 participants said that they use RStudio on regular basis. 4224 participants said that they use PyCharm on regular basis. 1487 participants said that they use Atom on regular basis. 1768 participants said that they use MATLAB on regular basis. 4534 participants said that they use Visual Studio / Visual Studio Code on regular basis. 3085 participants said that they use Spyder on regular basis. 1782 participants said that they use Vim / Emacs on regular basis. 3281 participants said that they use Notepad++ on regular basis. 2655 participants said that they use Sublime Text on regular basis. 238 participants said that they none of the mentioned IDE’s. 691 participants said that they use Other IDE’s than mentioned here. The visualization of this information is shown below.</p>\n\n<img src=\"https://1.bp.blogspot.com/-f4S8986rymk/XeUG3F2LARI/AAAAAAAAEgo/P0rm57BOokI7StaqQRpSO6q7ov-brE2OgCKgBGAsYHg/s1600/q16.png\" width=\"100%\">\n\n\n\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 16th mined by frequency and text mining are; CLion, Eclipse, Gedit, google colab, IDLE, Intellij, Knime, Nano, netbeans, SAS, Sql, Textmate and vscode.</p>\n\n<p style='text-align: justify;'>The 17th question was about the hosted notebooks that participants used on regular basis. 4845 participants said that they use Kaggle Notebooks (Kernels) on regular basis. 4551 participants said that they use Google Colab on regular basis. 855 participants said that they use Microsoft Azure Notebooks on regular basis. 1121 participants said that they use Google Cloud Notebook Products (AI Platform, Datalab, etc) on regular basis. 142 participants said that they use Paperspace / Gradient on regular basis. 101 participants said that they use FloydHub on regular basis. 1681 participants said that they use Binder / JupyterHub on regular basis. 669 participants said that they use IBM Watson Studio on regular basis. 76 participants said that they use Code Ocean on regular basis. 757 participants said that they use AWS Notebook Products (EMR Notebooks, Sagemaker Notebooks, etc) on regular basis. 5177 participants said that they use None on regular basis. 460 participants said that they use Other on regular basis. The visualization of this information is shown below.</p>\n\n<img src=\"https://1.bp.blogspot.com/-YMq5JAjoF5w/XeUG3OQehnI/AAAAAAAAEgo/u10z-upUYtgSklC_hxokEvUKGfvZDn1cwCKgBGAsYHg/s1600/q17.png\" width=\"100%\">\n\n\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 17th are Anaconda, CoCalc, Databricks, Domino Data Labs, Evernote, Github, IBM Cloud, Internal, jupyter, MATLAB, Qubole, Repl, it, RPUBS, RStudio, SAS, sublime and Zeppelin.</p>\n"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 18th question was about the programming languages participants use on regular basis. 12841 participants said that they use Python programming language on regular basis. 4588 participants said that they use R programming language on regular basis. 6532 participants said that they use SQL programming language on regular basis. 1672 participants said that they use C programming language on regular basis. 2256 participants said that they use C++ programming language on regular basis. 2267 participants said that they use Java programming language on regular basis. 2174 participants said that they use Javascript programming language on regular basis. 389 participants said that they use TypeScript programming language on regular basis. 2037 participants said that they use Bash programming language on regular basis. 1516 participants said that they use MATLAB programming language on regular basis. 83 participants said that they use None of mentioned programming languages on regular basis. 1148 participants said that they use Other programming languages other than mentioned.The visualization of this information is shown below.</p>\n\n<img src=\"https://1.bp.blogspot.com/-rC9hsJyiVS0/XeUG3MGsZSI/AAAAAAAAEgo/VwrhKBB_jZI-F4TTTV7USmEm4ujK70bAACKgBGAsYHg/s1600/q18.png\" width=\"100%\">\n"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The other most frequent options filled by participants of question 18th are .NET, C#, Clojure, COBOL, Common Lisp, CYPHER, Dart, DAX, Delphi, Elixir, Excel VBA, F#, Fortran, Fortran, Go, Golang, Groovy, Haskell, html, Java, Julia, Kotlin, LabVIEW, Lisp, Mathematica, ocaml, octave, Pascal, Perl, PHP, PL, SQL, PowerBASIC, Powershell, PySpark, Ruby, rust, SAS, Scala, scilab, Shell, spark, STATA, Stata,  SAS, Swift and  yaml.</p>\n\n<p style='text-align: justify;'>The 19th question was about the recommendation of programming language. It was asked from participants that which language do they recommend to any newbie data scientist to learn first. 11316 participants recommended that newbies data scientists must learn Python programming language first. 104 participants recommended that newbies data scientist must learn Java programming language first. 1343 participants recommended that newbies data scientist must learn R programming language first. 817 participants recommended that newbies data scientist must learn SQL programming language first. 199 participants recommended that newbies data scientist must learn C++ programming language first. 69 participants recommended that newbies data scientist must learn None of the mentioned programming languages. 127 participants recommended that newbies data scientist must learn Other mentioned programming language. 162 participants recommended that newbies data scientist must learn MATLAB programming language first. 25 participants recommended that newbies data scientist must learn TypeScript programming language first. 17 participants recommended that newbies data scientist must learn JavaScript programming language first. 35 participants recommended that newbies data scientist must learn Bash programming language first. The visualization of this information is shown below.</p>\n\n<img src=\"https://1.bp.blogspot.com/-vMWLLsMXlCE/XeUG3PEZH6I/AAAAAAAAEgo/BZPKTnaVkjE0oIgwWtaa6iCH2zALkUrpwCKgBGAsYHg/s1600/q19.png\" width=\"100%\">\n\n"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The other most frequent options filled by participants of question 19th are C#, Julia, mathematica, Octave, Rust, Sas, Scala, SQL, Swift and VBA.</p>\n\n<p style='text-align: justify;'>The 20th question was about the data visualization libraries that participants use on regular basis. 4182 participants said that they use Ggplot / ggplot2 visualization library on regular basis. 10516 participants said that they use Matplotlib visualization library on regular basis. 167 participants said that they use Altair visualization library on regular basis. 1244 participants said that they use Shiny visualization library on regular basis. 1078 participants said that they use D3.js visualization library on regular basis. 3217 participants said that they use Plotly / Plotly Express visualization library on regular basis. 1043 participants said that they use Bokeh visualization library on regular basis. 6905 participants said that they use Seaborn visualization library on regular basis. 644 participants said that they use Geoplotlib visualization library on regular basis. 550 participants said that they use Leaflet / Folium visualization library on regular basis. 1240 participants said that they use None of mentioned libraries. 465 participants said that they use Other visualization libraries than mentioned here. The visualization of this information is shown below.</p>\n\n<img src=\"https://1.bp.blogspot.com/-SbYyJM9I3fI/XeUG3CQ9_TI/AAAAAAAAEgo/7J_OXwfgJEoLC5irNk05yXqrtboTkdrCgCKgBGAsYHg/s1600/q20.png\" width=\"100%\">\n\n\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 20th are Dash, Data Studio, DataRobot, dplyr, Echarts, Excel, ggplot, GNUPlot, google charts, Google Data Studio, Highcharts, Holoviews, JMP, Keras, Kibana, lattice, Looker, mathematica, MATLAB, Matplotlib, Metabase, networkx, NumPy, opencv, Orange, Pandas, Plotly, Plotnine, Power BI, PyPlot, pyviz, QlikSense, QlikView, Qt, R, ROOT, SAS, scikit, learn, Spotfire, Tableau and Tensorboard.</p>"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'>The 21st question was about hardware participants use on regular basis. 10472 participants said that they use CPUs hardware on regular basis. 6638 participants said that they use GPUs hardware on regular basis. 496 participants said that they use TPUs hardware on regular basis. 2449 participants said that they don’t know if they use any hardware or use any hardware at all on regular basis. 108 participants said that they use other hardware on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-t9LAyN6e7Qo/XeUG3BoFmKI/AAAAAAAAEgo/ZtwMsjT4adI62opSj9Ife-fQSHiUhJS7wCKgBGAsYHg/s1600/q21.png\" width=\"100%\">\n\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 21st are Cloud, cluster, Colab, computing, Fpga, GPU, Intel, park, ras berry pi and laptop.</p>\n\n<p style='text-align: justify;'>The 22nd question was about was about if participants ever heard or used Tensor Processing Units. 11495 participants said that they had never used tensor processing units. 1320 participants said that they had used tensor processing units once. 1037 participants said that they had used 2 to 5 Times tensor processing units. 193 participants said that they had used 6 to 24 Times tensor processing units. 158 participants said that they had used more than 25 Times tensor processing units. 5514 participants said that they had used other than tensor processing units. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-JfH2f80G46U/XeUG3EQ5j9I/AAAAAAAAEgo/tEEa5pue_V05aXxH6Jw-PGV_XZinxnyPQCKgBGAsYHg/s1600/q22.png\" width=\"100%\">\n<p style='text-align: justify;'>The 23rd question was about was about how long participants were using machine learning methods. 5149 participants said that they are using machine learning methods for less than past 1 years. 3798 participants said that they are using machine learning methods for past 1 to 2 years. 1840 participants said that they are using machine learning methods for past 2 to 3 years. 1080 participants said that they are using machine learning methods for past 3 to 4 years. 927 participants said that they are using machine learning methods for past 4 to 5 years. 869 participants said that they are using machine learning methods for past 5 to 10 years. 326 participants said that they are using machine learning methods for past 10 to 15 years. 183 participants said that they are using machine learning methods for More than past 20 years. 5545 didn’t answered the question. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-1mfDhoXmO9M/XeUG3FtZHdI/AAAAAAAAEgo/UsBOA7dbDvcLcOSyf_AgOUt_hoFJHeEnwCKgBGAsYHg/s1600/q23.png\" width=\"100%\">\n<p style='text-align: justify;'>The 24th question was about what machine learning algorithms the participants were using on regular basis. 10223 participants said that they use Linear or Logistic Regression algorithms on regular basis. 8490 participants said that they use Decision Trees or Random Forests algorithms on regular basis. 5539 participants said that they use Gradient Boosting Machines (xgboost, lightgbm, etc) algorithms on regular basis. 3725 participants said that they use Bayesian Approaches algorithms on regular basis. 866 participants said that they use Evolutionary Approaches algorithms on regular basis. 3323 participants said that they use Dense Neural Networks (MLPs, etc) algorithms on regular basis. 5450 participants said that they use Convolutional Neural Networks algorithms on regular basis. 977 participants said that they use Generative Adversarial Networks algorithms on regular basis. 3389 participants said that they use Recurrent Neural Networks algorithms on regular basis. 907 participants said that they use Transformer Networks (BERT, gpt-2, etc) algorithms on regular basis. 1186 participants said that they use none of mentioned algorithms on regular basis. 421 participants said that they use other algorithms on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-E0fGck6h_oo/XeUG3JHtt4I/AAAAAAAAEgo/WM1slgijdUAvDXHaFCPICOd2mRsEvYNJACKgBGAsYHg/s1600/q24.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 24th are  ANN, Classification, Clustering, Collaborative Filtering, Factor Analysis, Fuzzy Logic, KMeans, KNN, LSTM, NLP, Reinforcement Learning and Support Vector Machines (SVM).</p>\n<p style='text-align: justify;'>The 25th question was about the categories of machine learning tools the participants were using on regular basis. 1800 participants said that they use Automated data augmentation (e.g. imgaug: albumentations) on regular basis. 1505 participants said that they use Automated feature engineering/selection (e.g. tpot, boruta_py) on regular basis. 3200 participants said that they use Automated model selection (e.g. auto-sklearn, xcessiv) on regular basis. 450 participants said that they use Automated model architecture searches (e.g. darts, enas) on regular basis. 1778 participants said that they use Automated hyperparameter tuning (e.g. hyperopt, ray.tune) on regular basis. 1178 participants said that they use Automation of full ML pipelines (e.g. Google AutoML, H20 Driverless AI) on regular basis. 7822 participants said that they use none of mentioned on regular basis. 229 participants said that they use other than mentioned on regular basis. Visualized information is shown below.</p>\n<p style='text-align: justify;'><img src=\"https://1.bp.blogspot.com/-g2h3Z-FpRr4/XeUG3E0zCLI/AAAAAAAAEgo/24IroRWi6tkye0xkD8M2sZnRmxobsLI4gCKgBGAsYHg/s1600/q25.png\" width=\"100%\">\nThe other most frequent options filled by participants of question 25th are sklearn, SAS, Microsoft ML, fastai, DataRobot, Catalyst, Weka and Rapid Miner.</p>\n\n<p style='text-align: justify;'>The 26th question was about categories of computer vision methods the participants were using on regular basis. 2207 participants said that they use General purpose image/video tools (PIL, cv2, skimage, etc) on regular basis. 2061 participants said that they use Image segmentation methods (U-Net, Mask R-CNN, etc) on regular basis. 1872 participants said that they use Object detection methods (YOLOv3, RetinaNet, etc) on regular basis. 3187 participants said that they use Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc) on regular basis. 1081 participants said that they use Generative Networks (GAN, VAE, etc) on regular basis. 1203 participants said that they use none of mentioned categories of computer vision methods on regular basis. 51 participants said that they use other than mentioned categories of computer vision methods on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-LL6OFxAWZ9Q/XeUG3GIzN8I/AAAAAAAAEgo/oM1N5AP0X6wNNq7SMyRYu29DPZyIWrF_gCKgBGAsYHg/s1600/q26.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 26th are OpenCV, Azure Computer, Fast.ai, CNN, wavenet, text processing and classification.</p>\n<p style='text-align: justify;'>The 27th question was about the Natural Language Processing (NLP) methods that participants used on regular basis. 2115 participants said that they use Word embeddings/vectors (GLoVe, fastText, word2vec) on regular basis. 1368 participants said that they use Encoder-decorder models (seq2seq, vanilla transformers) on regular basis. 562 participants said that they use Contextualized embeddings (ELMo, CoVe) on regular basis. 1031 participants said that they use Transformer language models (GPT-2, BERT, XLnet, etc) on regular basis. 1027 participants said that they use none of mentioned NLP methods on regular basis. 49 participants said that they use other than mentioned NLP methods on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-KipHwCarkRI/XeUG3J5ri8I/AAAAAAAAEgo/3re8l7lvCokSdvFKCZzy4JLPi7BpSGGigCKgBGAsYHg/s1600/q27.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 27th are FastAI, LSTM, OCR, OWL, Python libraries, SpaCy, SPSS, svm, Tfidf and R.</p>\n<p style='text-align: justify;'>The 28th question was about machine learning frameworks that participants used on regular basis. 9390 participants said that they use Scikit-learn framework on regular basis. 5822 participants said that they use TensorFlow framework on regular basis. 5756 participants said that they use Keras framework on regular basis. 4524 participants said that they use RandomForest framework on regular basis. 4243 participants said that they use Xgboost framework on regular basis. 3412 participants said that they use PyTorch framework on regular basis. 1139 participants said that they use Caret framework on regular basis. 2166 participants said that they use LightGBM framework on regular basis. 910 participants said that they use Spark MLib framework on regular basis. 949 participants said that they use Fast.ai framework on regular basis. 1720 participants said that they use none of mentioned frameworks on regular basis. 342 participants said that they use other mentioned frameworks on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-nxDHG-veTzE/XeUG3MlrdJI/AAAAAAAAEgo/_6Fkx2uLvC0JSCMB4xZsVW3njAYV-OCbQCKgBGAsYHg/s1600/q28.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 28th are Caffe, caffe, Catalyst, CatBoost, Chainer, DataRobot, Gensim, H2O.ai, matlab, Mlr, MXNet, R packages, RapidMiner, SAS, Spacy, Stan and Weka.</p>\n<p style='text-align: justify;'>The 29th question was about cloud computing platforms that participants used on regular basis. 2134 participants said that they use Google Cloud Platform (GCP) on regular basis. 2758 participants said that they use Amazon Web Services (AWS) on regular basis. 1356 participants said that they use Microsoft Azure on regular basis. 373 participants said that they use IBM Cloud on regular basis. 110 participants said that they use Alibaba Cloud on regular basis. 115 participants said that they use Salesforce Cloud on regular basis. 162 participants said that they use Oracle Cloud on regular basis. 90 participants said that they use SAP Cloud on regular basis. 171 participants said that they use VMware Cloud on regular basis. 78 participants said that they use Red Hat Cloud on regular basis. 2229 participants said that they use none of mentioned platforms on regular basis. 170 participants said that they use other platforms on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-Hf6zZ_NYkiE/XeUG3F-5xjI/AAAAAAAAEgo/IwwfgxORpisPvJWze_uDK-wYRjtynNdrgCKgBGAsYHg/s1600/q29.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 29th are Cloudera, Databricks, DataRobot, Digital Ocean, DigitalOcean, Google Colab, kaggle, Linode, OVH, paperspace, RStudio cloud, SAS Cloud, Tencent Cloud, Private Cloud, Openstack, Huawei, Cloudra and Adobe Creative.</p>\n<p style='text-align: justify;'>The 30th question was about specific cloud computing products participants use on regular basis. 1810 participants said that they use AWS Elastic Compute Cloud (EC2) on regular basis. 1138 participants said that they use Google Compute Engine (GCE) on regular basis. 876 participants said that they use AWS Lambda on regular basis. 838 participants said that they use Azure Virtual Machines on regular basis. 597 participants said that they use Google App Engine on regular basis. 702 participants said that they use Google Cloud Functions on regular basis. 311 participants said that they use AWS Elastic Beanstalk on regular basis. 526 participants said that they use Google Kubernetes Engine on regular basis. 284 participants said that they use AWS Batch on regular basis. 395 participants said that they use Azure Container Service on regular basis. 3155 participants said that they use none of mentioned cloud computing products on regular basis. 239 participants said that they use other than mentioned cloud computing products on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-mJ9Kk2Ya4WY/XeUG3Pho5nI/AAAAAAAAEgo/hla3d86OBsIyFw7Ei89CYmSXgt4Z3drWwCKgBGAsYHg/s1600/q30.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 30th are Azuer, SAS, Sagemaker, Oracle, OpenShift, Own, Kaggle, IBM, Google Colab, Databricks, Digital Ocean, Bigquery, Google AI Platform,Google BigQuery, Google Colab, IBM Cloud, IBM Watson, Inhouse and OpenShift.</p>\n<p style='text-align: justify;'>The 31st question was about specific big data products participants use on regular basis. 958 participants said that they use Google BigQuery big data product on regular basis. 562 participants said that they use AWS Redshift big data product on regular basis. 604 participants said that they use Databricks big data product on regular basis. 429 participants said that they use AWS Elastic MapReduce big data product on regular basis. 322 participants said that they use Teradata big data product on regular basis. 426 participants said that they use Microsoft Analysis Services big data product on regular basis. 525 participants said that they use Google Cloud Dataflow big data product on regular basis. 369 participants said that they use AWS Athena big data product on regular basis. 281 participants said that they use AWS Kinesis big data product on regular basis. 398 participants said that they use Google Cloud Pub/Sub big data product on regular basis. 4133 participants said that they use none of mentioned big data products on regular basis. 266 participants said that they use other than mentioned big data products on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-893IN7px7NI/XeUG3ODhowI/AAAAAAAAEgo/stx8bbCUfJIEXxb32eMUx0PPR1y5WWmEgCKgBGAsYHg/s1600/q31.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 31st are Apache Spark, Azure Data Factory, Cloudera, DataRobot, Elastic Stack, Hadoop, IBM, IBM Watson, KNIME, SAS, Snowflake, Spark, Splunk, Vertica, Watson, Weka, Tableu, R Studio, Rapid Miner and Oracle.</p>\n<p style='text-align: justify;'>The 32nd question was about machine learning products participants used on regular basis. 450 participants said that they use SAS machine learning product on regular basis. 418 participants said that they use Cloudera machine learning product on regular basis. 581 participants said that they use Azure Machine Learning Studio machine learning product on regular basis. 586 participants said that they use Google Cloud Machine Learning Engine machine learning product on regular basis. 372 participants said that they use Google Cloud Vision machine learning product on regular basis. 438 participants said that they use Google Cloud Speech-to-Text machine learning product on regular basis. 400 participants said that they use Google Cloud Natural Language machine learning product on regular basis. 265 participants said that they use RapidMiner machine learning product on regular basis. 315 participants said that they use Google Cloud Translation machine learning product on regular basis. 569 participants said that they use Amazon SageMaker machine learning product on regular basis. 4313 participants said that they use none of mentioned machine learning products on regular basis. 225 participants said that they use other than mentioned machine learning products on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-vvnoOsmJwVs/XeUG3PlYLEI/AAAAAAAAEgo/lDGcLoGRA8QlpLw88kfhtG330nFPYs3WACKgBGAsYHg/s1600/q32.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 32nd are Alteryx, Amazon Transcribe, Dataiku, DataRobot, Driverless AI, IBM Cloud, IBM Watson, KNIME, MATLAB, R Studio, Spss, Weka, SPSS, SPARK and Azure.</p>\n<p style='text-align: justify;'>The 33rd question was about automated machine learning tools participants use on regular basis. 498 participants said that they use Google AutoML tool on regular basis. 277 participants said that they use H20 Driverless AI tool on regular basis. 191 participants said that they use Databricks AutoML tool on regular basis. 171 participants said that they use DataRobot AutoML tool on regular basis. 176 participants said that they use Tpot tool on regular basis. 465 participants said that they use Auto-Keras tool on regular basis. 756 participants said that they use Auto-Sklearn tool on regular basis. 279 participants said that they use Auto_ml tool on regular basis. 28 participants said that they use Xcessiv tool on regular basis. 133 participants said that they use MLbox tool on regular basis. 5175 participants said that they use none of mentioned tools on regular basis. 132 participants said that they use other than mentioned tools on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-NR5vB4s6K7Q/XeUG3B8fWKI/AAAAAAAAEgo/Y_n2ySW9s0gDkHON5OQ5EKlDOs6NuneaQCKgBGAsYHg/s1600/q33.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 33rd are Auto AI, Customized Auto. Arima and others, H,  AutoML, Hyperas, Hyperopt, IBM Auto AI, IBM SPSS Modeler, IBM Watson Auto AI, MATLAB, Microsoft Bot Framework, ML. NET Auto ML, prevision, io, private automl, RapidMiner, Sagemaker, Salford Predictive Modeler, SAP Predictive Analysis, SAS, SPSS, SVM, tensorflow, Visual Studio and Watson ML.</p>\n<p style='text-align: justify;'>The 34th question was about automated relational databases that participants used on regular basis. 3122 participants said that they use MySQL on regular basis. 2160 participants said that they use PostgresSQL on regular basis. 1527 participants said that they use SQLite on regular basis. 1852 participants said that they use Microsoft SQL Server on regular basis. 1192 participants said that they use Oracle Database on regular basis. 547 participants said that they use Microsoft Access on regular basis. 588 participants said that they use AWS Relational Database Service on regular basis. 415 participants said that they use AWS DynamoDB on regular basis. 479 participants said that they use Azure SQL Database on regular basis. 526 participants said that they use Google Cloud SQL on regular basis. 1245 participants said that they use none of mentioned automated relational databases on regular basis. 287 participants said that they use other than mentioned automated relational databases on regular basis. Visualized information is shown below.</p>\n<img src=\"https://1.bp.blogspot.com/-rA9_xgnpCXo/XeUG3I0N2BI/AAAAAAAAEgo/eXjAE6T3ajELcgKq2_xMtFyiQIwF3yOkwCKgBGAsYHg/s1600/q34.png\" width=\"100%\">\n<p style='text-align: justify;'>The other most frequent options filled by participants of question 34th are Cassandra, DB, IBM DB, MongoDB, Snowflake, Teradata, Apache, AWS Red Shift, Excel, Firebird, GreenPlum, Hadoop, Hana, Hive, MariaDB, Neo, j, NetZa and Vertica.</p>"},{"metadata":{},"cell_type":"markdown","source":"<center><h2>Summary</h2></center>\n<p style='text-align: justify;'>There are 34 questions asked from people all over the globe to get information about data science and machine learning. 19717 people all over the world participated in this survey. The time take by participants was also measured the least time taken to complete the survey was '' and maximum time taken to complete the survey was ''. The average time take by participants was ''. The first questions were about the age of participants. most of the participants were aged between 25-29 and the least were ones age 70 above. The second question was about gender in which male participants were more than females. The third question was about country of participants, the most participants were from India and the least participants were from Saudi Arab. The fourth question was about education of participants in which most of the participants were masters’ degree holders and least have no education past high school. The question fifth was about roles of participants in which most of the participants were data scientists and least were DBA, database engineers. In question sixth, the number of employees worked in the organization were asked where most results range between 0 to 49 and least results were ranged 250-999. The seventh question was about individuals responsible for data science work load were asked where most of the participants said that there are 1-2 participants while least said that they have 20+ individuals responsible for work load. The question 8 was about the whether current employers cooperating ML methods are not where majority says that they are exploring and minorities said that they are using for 1550. The ninth question was about selection of activities that make up an important part of participants' role at work in which majority of participants said that their role is to understand data and least said that they do research. The tenth question was about the approximate yearly compensation of participants in US dollors where most of the participants said that it is between US Dollar 0 and 999 and least ones said that it is between US Dollar 300,000 and 500,000. The eleventh question was about the approximate participant's expenses on machine learning and cloud computing products in last 5 years in which most of participants said that they didn't spend a penny and least of them said that they are using more than US Dollar 100,000 on ML. The question 12 was about media sources that report on data science and participants use where most of the participant said that they are using reddit and least of them said that they are using Hacker News. The thirteenth question was about the platforms where participants have begun or completed data science course where most of them said that they are using Coursera and least of them said that they were using data quest. The fourteenth question was about the primary tool that participants use in work or in school to analyze data where most of them said that they are using local development environments and least of them said that they are using advanced statistical software. The fifteenth question was about participants’ duration of writing code analyze data in which most of the participants most of participants said that they have 1 - 2 years duration while many less participants said that they have 20+ duration. The sixteenth question was about IDEs that participants use on regular basis in which most of them said that they are using Jupyter while many less of them said that they are using MATLAB. The seventeenth question was about the hosted notebooks that participants used on regular basis in which most of the participants said that they use Kaggle notebooks while least said that they are using code ocean.\nThe eighteenth question was about the programming languages participants use on regular basis in which most of the participants choose pythone where least ones choose typescript. The nineteenth question was about the recommendation of programming language where most of the participants recommended Python and least ones recommend javascript. The question 20 was about the data visualization libraries that participants use in which most of participants voted matplotlib and least ones voted Altair. The question 21 was about hardware participants use in which most of the participants use VPU's and least ones use TPU's. The question 22 was about was about if participants ever heard or used Tensor Processing Units in which most of the participants said that they didn't use TPU's and least ones said that they use it more than 25 times. The question 23 was about was about how long participants were using machine learning methods in which most of the participants said that they using for less than one years and least of them said that they are using for past 20 plus years. The question 24 was about what machine learning algorithms the participants were using on regular basis in which most of the participants said that they are using Linear or Logisitc Regression and least of them said that they using Evolutionary approaches. The question 25 was about the machine learning tools the participants were using in which most of them said that they use automated model selection and least of them said they use automated model architecture searches. The question 26 was about categories of computer vision methods the participants were using in which most of the participants said that they use Image classification/GPL networks and least of them said that they are using generative networks. The question 27 was about the Natural Language Processing (NLP) methods that participants used and most of the participants said that they use word embeddings/ vectors and least of them said they use contextualized embeddings. The 28th question was about machine learning frameworks that participants used where most of the participants said that they use Scikit-learn and least of them use Spark MLib. The question 29 was about cloud computing platforms that participants used in which most of the participants said they use Amazon Web Services and least of them said they use Red Hat Cloud. The question 30 was about specific cloud computing products participants use in which most of the participants said they use AWS Elastic Compute while least of them said they use AWS Batch. The question 31 was about specific big data products participants use in which most of the participants said that they use Google BigQuery and least of them said they use AES Kinesis. The question 32 was about machine learning products participants use in which most of the participants said that they use Amazone SageMaker and least of them use RapidMiner.The question 33 was about automated machine learning tools participants use in which most of them said they use Auto-Sklearn and least of them said that they use Xcessiv. The question 34 was about automated relational databases that participants use and most of the participants said that they sue MySQl while least of them said that they use AWS DynamoDB.</p>"},{"metadata":{},"cell_type":"markdown","source":"<center><h2>Conclusion</h2></center>\n<p style='text-align: justify;'>This is the great take about machine learning and data science. It covers all aspects and questions that must be asked aboud machine learning and data scince. It provides the average age ranges of data scientists, their educations and also which gender dominates the datascience wolrd the most. It also tells the diversity of datascientists in the world.The roles of datascientists, their organization structure, hardware used within the organization, several ML products and services used, several algorithms used mean every thing. This will allow newbie datascientists to know what is happening in Machine Learning and Datascience era, what are people workingm, what are differnt algorithms and what new algorithms that are used by people mentioned in other section. This will make up to date the datascientists about lates sites, repositories, technologies and frameworks etc.</p>"},{"metadata":{},"cell_type":"markdown","source":"<center><h2>Programming Visualizations</h2></center>\n<p style='text-align: justify;'> The visualization was tried within Jupyter notebook, but our Jupyter was installed on 64 bit operating system and doesn't allow to install matplotlib on 64 bit operating systems. Matplotlib is library that visualize information. As matplot lib doesn't work on anaconda 64 bit, that doesn't mean we didn't visualized data. We isntalled Python 3.8 (32) bit and then installed matplotlib by pip. The above visualization of images are taken from matplotlib. The python code for these visualizations is available in 'kagglevisualizationscripts' folder available with this notebook, other wise you can download these 'kagglevisualizationscripts' folder from <a href=\"https://mediafire.com/file/00mswvvogtf5ng7/kagglevisualizationscripts.zip/file\" target=\"_blank\">here</a></p>"},{"metadata":{},"cell_type":"markdown","source":"<center><h2>How we Collect And Extract Data?</h2></center>"},{"metadata":{},"cell_type":"markdown","source":"<p style='text-align: justify;'> We Use C# programming language desktop forms and datagrid view to read dataset csv files available within Kaggle2019Survey Datasets. We then extract features one by one using loops (like gender has male, female, prefer not to say, prefer to self describe) of every column then we count (like for male we got 16318 via loops etc) them as shown in image below.</p>\n<img src=\"https://1.bp.blogspot.com/-zTrrJkTH8VA/XeUG3CT4WwI/AAAAAAAAEgo/Cgm45Jx0qxoBX987SzPyqnO2zrExTpl8gCKgBGAsYHg/s1600/Form1.JPG\">\n<p style='text-align: justify;'> One of the cool features of C# datagridview is that you call click on datagrid view column header, it arranges your data, in this way we arrange all other responses we got from participants like in question 5 , 9 and so on etc. as shown in image below. We clicked on question 12 other column header and it arranges all other responses in Ascending order. Later we use string correction and string normalization (toUpper or ToLower) to count response frequency.</p>\n<img src=\"https://1.bp.blogspot.com/-HgSWLJ1sCSQ/XeUG3PpGOrI/AAAAAAAAEgo/Dw0DyfyeZoAzJMjMkqW4r2zBIrB0E-2aQCKgBGAsYHg/s1600/Form2.JPG\">\n<p style='text-align: justify;'> After getting all data in some order, every word count is required. So we remove all special characters and make word count. In image below we counted the other responses of question 2. This question was about gender</p>\n<img src=\"https://1.bp.blogspot.com/-55nd4Fex0Es/XeUG3IRgrcI/AAAAAAAAEgo/qePH0tB8zn8WldiUMBpSUOr_Qe_86Z4QgCKgBGAsYHg/s1600/Form3.JPG\">\n<p style='text-align: justify;'> The laziness didn't end here. We don't have enough time to explain how many participants choose what, so we also made a mini tool called \"story Generator\" that automatically makes story for a particulare question. It takes question number, question about, how to start the sentence, how to end the sentence and dataset of question options and responses. In output it gives us a story for a particular question. Image below shows the story generated for question 34. </p>\n<img src=\"https://1.bp.blogspot.com/-VbG1i3z1ahg/XeUG3EfeV1I/AAAAAAAAEgo/MgzCh_nRHHQKjUcA08kVP69ZWxqiyAInACKgBGAsYHg/s1600/Form4.JPG\">\n<p style='text-align: justify;'>These Four Data Collection Software Can Be Provided Upon Request Free Charge.</p>"},{"metadata":{},"cell_type":"markdown","source":"<center><h2>References</h2>\n<a href=\"http://google.com\" target=\"_blank\">Google</a><br>\n<a href=\"http://wikipedia.org\" target=\"_blank\">Wiki Pedia.</a></center>"},{"metadata":{},"cell_type":"markdown","source":"<center><h2>Kind Information</h2></center>\n<p style='text-align: justify;'>This submission is not intended for prize. This is Quaid - E - Azam Univeristy Assignment of Subject Datamining. We fullfilled our requirement. It would be a pleausre for us if above information helps you in some means.\nThis notebook, software for data extraction used and kagglevisualizationscripts are available at University Intranet.\nLast but not the least, apologies for bad English.</p>"},{"metadata":{},"cell_type":"markdown","source":"<hr>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}