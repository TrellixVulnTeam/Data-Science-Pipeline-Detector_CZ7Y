{"cells":[{"metadata":{},"cell_type":"markdown","source":"# How to earn as a Data Scientist"},{"metadata":{},"cell_type":"markdown","source":"### Introduction<br>\n\nThese days, Data Scientist is a popular job around the world.<br>\nTherefore, I investigated the occupation of Data Scientist from the following two perspectives.<br>\n① Is a Data Scientist a profitable occupation ?<br>\n② What do earning Data Scientists have skills ?<br>\n\nAnd, I defined Data Scientists who can earn and can't.<br>\n・Data Scientists who can earn : 50,000 dollars and over<br>\n・Data Scientists who can't earn : 50,000 dollars fewer than<br>\nIn this analysis, Data Scientists who can earn is called \"Earn\" and Data Scientists who can't earn is called \"Not earn\"."},{"metadata":{},"cell_type":"markdown","source":"### Summary<br>\n\n① Is a Data Scientist a profitable occupation ?\n\n> Data Scientist is a profitable occupation.\n\n② What do earning Data Scientists have skills ?\n\n**Play an important part of your role at work in ML**<br>\n> Analyze data to influence business decisions.(Must)<br>\n> Build ML service that operationally improves our products.(Desirable)<br>\n> Build the data infrastructure.(Desirable)<br>\n> The person who can play an important part of your role at ML work in various situations can earn.<br>\n\n**Favorite media sources that report on data science topics**<br>\n> Blogs(Must)<br>\n> Kaggle(Desirable)<br>\n> Journal Publications(Desirable)<br>\n> It doesn't matter how many sources you are reading.<br>\n\n**IDE or text editor**<br>\n> Jupyter(Must)<br>\n> Rstudio(Desirable)<br>\n> Vim or Emacs(Desirable)<br>\n> The person who can use many IDE or text editor can earn.<br>\n\n**Programming languages**<br>\n> Python(Must)<br>\n> SQL(Must)<br>\n> Bash(Desirable)<br>\n> R(Desirable)<br>\n> The person who can use many programming languages can earn.<br>\n\n**Data visualization libraries or tools**<br>\n> Seaborn(Desirable)<br>\n> Matplotlib(Desirable)<br>\n> ggplot or ggplot2(Desirable)<br>\n> The person who can use many data visualization libraries or tools can earn.<br>\n\n**ML algorithms**<br>\n> Linear or Logistic Regression(Must)<br>\n> GBM(Must)<br>\n> Decision Trees or Random Forests(Must)<br>\n> Bayesian(Desirable)<br>\n> While, deep learning methods is used by \"Not earn\" compared to \"Earn\".<br>\n> The person who can use many ML algorithms can earn.<br>\n\n**ML frameworks**<br>\n> Scikit-learn(Must)<br>\n> Xgboost(Desirable)<br>\n> The person who can use many ML frameworks can earn.<br>\n\n**Cloud computing platforms**<br>\n> AWS(Desirable)<br>\n> The person who can use many cloud computing platforms can earn.<br>\n\n**Big data analytics products**<br>\n> AWS Redshift(Desirable)<br>\n> The person who can use many big data analytics products can earn.<br>\n\n**RDB products**<br>\n> PostgresSQL(Desirable)<br>\n> Microsoft SQL server(Desirable)<br>\n> The person who can use many RDB products can earn.<br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#Import library\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n#Set dataframe view options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', 1000)\n\n#Data cleansing function\ndef arrange_onehot_var_df(multi_choise_df, onehot_var_list):\n    for var in onehot_var_list:\n        qestion_no = var[:3]\n        rename_df = pd.DataFrame(multi_choise_df[var].value_counts()).reset_index()['index']            \n        rename_col = rename_df.values[0]\n        multi_choise_df = multi_choise_df.rename(columns={var : qestion_no + rename_col})\n        multi_choise_df[qestion_no + rename_col] = multi_choise_df[qestion_no + rename_col].fillna(0)\n        multi_choise_df[qestion_no + rename_col] = multi_choise_df[qestion_no + rename_col].apply(lambda x: 0 if x == 0 else 1)\n    return multi_choise_df\n\ndef question_no_sum(multi_choise_df, quetion_no_list):\n    for question_no in quetion_no_list:\n        extract_list = [item for item in multi_choise.columns if item.find(question_no) != -1]\n        i = 0\n        for var in extract_list:\n            if i == 0:\n                multi_choise_df[question_no + '_sum'] = multi_choise_df[var]\n            else:\n                multi_choise_df[question_no + '_sum'] = multi_choise_df[question_no + '_sum'] + multi_choise_df[var]\n            i = i + 1\n    return multi_choise_df\n\n#Make dataframe\nmulti_choise = pd.read_csv('../input/kaggle-survey-2019/multiple_choice_responses.csv')[1:]\n\n#Drop useless variable\ndrop_col = [item for item in multi_choise.columns if item.find('_TEXT') != -1]\nmulti_choise.drop(drop_col, axis=1, inplace=True)\n\n#Data cleansing\nonehot_var_list = [item for item in multi_choise.columns if item.find('Part') != -1]\nmulti_choise = arrange_onehot_var_df(multi_choise_df=multi_choise, onehot_var_list=onehot_var_list)\n\nquetion_no_list = ['Q9','Q12','Q13','Q16','Q17','Q18','Q20','Q21','Q24','Q25',\n                   'Q26','Q27','Q28','Q29','Q30','Q31','Q32','Q33','Q34']\nmulti_choise = question_no_sum(multi_choise_df=multi_choise, quetion_no_list=quetion_no_list)\n\ndef Q10_cond(x):\n    if  x == '$0-999':\n        return '01. $0-999'\n    elif x == '1,000-1,999':\n        return '02. $1,000-1,999'\n    elif x == '2,000-2,999':\n        return '03. $2,000-2,999'\n    elif x == '3,000-3,999':\n        return '04. $3,000-3,999'\n    elif x == '4,000-4,999':\n        return '05. $4,000-4,999'\n    elif x == '5,000-7,499':\n        return '06. $5,000-7,499'\n    elif x == '7,500-9,999':\n        return '07. $7,500-9,999'\n    elif x == '10,000-14,999':\n        return '08. $10,000-14,999'\n    elif x == '15,000-19,999':\n        return '09. $15,000-19,999'\n    elif x == '20,000-24,999':\n        return '10. $20,000-24,999'\n    elif x == '25,000-29,999':\n        return '11. $25,000-29,999'\n    elif x == '30,000-39,999':\n        return '12. $30,000-39,999'\n    elif x == '40,000-49,999':\n        return '13. $40,000-49,999'\n    elif x == '50,000-59,999':\n        return '14. $50,000-59,999'\n    elif x == '60,000-69,999':\n        return '15. $60,000-69,999'\n    elif x == '70,000-79,999':\n        return '16. $70,000-79,999'\n    elif x == '80,000-89,999':\n        return '17. $80,000-89,999'\n    elif x == '90,000-99,999':\n        return '18. $90,000-99,999'\n    elif x == '100,000-124,999':\n        return '19. $100,000-124,999'\n    elif x == '125,000-149,999':\n        return '20. $125,000-149,999'\n    elif x == '150,000-199,999':\n        return '21. $150,000-199,999'\n    elif x == '200,000-249,999':\n        return '22. $200,000-249,999'\n    elif x == '250,000-299,999':\n        return '23. $250,000-299,999'\n    elif x == '300,000-500,000':\n        return '24. $300,000-500,000'\n    elif x == '> $500,000':\n        return '25. $500,000 and over'\n\nmulti_choise['Q10'] = multi_choise['Q10'].apply(Q10_cond)\n\ndef Q10_earn_cond(x):\n    if x == '01. $0-999':\n        return 'Not earn'\n    elif x == '02. $1,000-1,999':\n        return 'Not earn'\n    elif x == '03. $2,000-2,999':\n        return 'Not earn'\n    elif x == '04. $3,000-3,999':\n        return 'Not earn'\n    elif x == '05. $4,000-4,999':\n        return 'Not earn'\n    elif x == '06. $5,000-7,499':\n        return 'Not earn'\n    elif x == '07. $7,500-9,999':\n        return 'Not earn'\n    elif x == '08. $10,000-14,999':\n        return 'Not earn'\n    elif x == '09. $15,000-19,999':\n        return 'Not earn'\n    elif x == '10. $20,000-24,999':\n        return 'Not earn'\n    elif x == '11. $25,000-29,999':\n        return 'Not earn'\n    elif x == '12. $30,000-39,999':\n        return 'Not earn'\n    elif x == '13. $40,000-49,999':\n        return 'Not earn'\n    elif x == '14. $50,000-59,999':\n        return 'Earn'\n    elif x == '15. $60,000-69,999':\n        return 'Earn'\n    elif x == '16. $70,000-79,999':\n        return 'Earn'\n    elif x == '17. $80,000-89,999':\n        return 'Earn'\n    elif x == '18. $90,000-99,999':\n        return 'Earn'\n    elif x == '19. $100,000-124,999':\n        return 'Earn'\n    elif x == '20. $125,000-149,999':\n        return 'Earn'\n    elif x == '21. $150,000-199,999':\n        return 'Earn'\n    elif x == '22. $200,000-249,999':\n        return 'Earn'\n    elif x == '23. $250,000-299,999':\n        return 'Earn'\n    elif x == '24. $300,000-500,000':\n        return 'Earn'\n    elif x == '25. $500,000 and over':\n        return 'Earn'\n\nmulti_choise['Q10_earn_flg'] = multi_choise['Q10'].apply(Q10_earn_cond)\n\n#Fill Nan\nmulti_choise = multi_choise.fillna('No Answer')\n\n#Extract Earn or not\nmulti_choise = multi_choise[multi_choise['Q10_earn_flg'] != 'No Answer']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ① Is a Data Scientist a profitable occupation ?"},{"metadata":{},"cell_type":"markdown","source":"Firstly, I comfirmed whether Data Scientist is profitable occupation or not.<br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Calc Earn Rate in occupations\ndef calc_earn_rate(df, occupation_list):\n    i = 0\n    for occupation in occupation_list:\n        gb_df = df[(df['Q5'] == occupation)]\n        gb_df = pd.DataFrame(gb_df.groupby('Q10_earn_flg').count()['Q5']).reset_index()\n        rate = round(gb_df['Q5'][0] / gb_df['Q5'].sum() * 100, 1)\n        if i == 0:\n            rate_df = pd.DataFrame([[rate]], columns=['rate'])\n            rate_df['Earn'] = gb_df['Q5'][0]\n            rate_df['Not Earn'] = gb_df['Q5'][1]\n            rate_df['sum'] = gb_df['Q5'].sum()\n            rate_df['occupation'] = occupation\n            i = i + 1\n        else:\n            tmp_rate_df = pd.DataFrame([[rate]], columns=['rate'])\n            tmp_rate_df['Earn'] = gb_df['Q5'][0]\n            tmp_rate_df['Not Earn'] = gb_df['Q5'][1]\n            tmp_rate_df['sum'] = gb_df['Q5'].sum()\n            tmp_rate_df['occupation'] = occupation\n            rate_df = rate_df.append(tmp_rate_df)\n    return rate_df\n\noccupation_list = ['Data Scientist', 'Software Engineer', 'Data Analyst', 'Research Scientist', 'Business Analyst', \n                   'Product/Project Manager', 'Data Engineer', 'Statistician', 'DBA/Database Engineer']\n\noccupation_rate_df = calc_earn_rate(df=multi_choise, occupation_list=occupation_list)\n\n#Add occupation All\nrate = round(occupation_rate_df['Earn'].sum() / occupation_rate_df['sum'].sum() * 100, 1)\ntmp_rate_df = pd.DataFrame([[rate]], columns=['rate'])\ntmp_rate_df['Earn'] = occupation_rate_df['Earn'].sum()\ntmp_rate_df['Not Earn'] = occupation_rate_df['Not Earn'].sum()\ntmp_rate_df['sum'] = occupation_rate_df['sum'].sum()\ntmp_rate_df['occupation'] = 'ALL'\noccupation_rate_df = occupation_rate_df.append(tmp_rate_df)\n\n#Sort\noccupation_rate_df = occupation_rate_df.sort_values('rate')\n\n#Make graph\ncolors=['blue',] * 10\ncolors[8]='crimson'\n\nx=occupation_rate_df['rate'].values\ny=occupation_rate_df['occupation'].values\n\nfig = go.Figure(data=[go.Bar(x=x,y=y,text=x,textposition='auto',orientation='h',marker_color=colors)])\nfig.update_layout(title='\"Earn\" rate by occupation')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fact**<br>\n・Data Scientists of \"Earn\" rate is 44.0%.<br>\n・It was second after the Product/Project Manager and 7.3% better than compared to ALL occupations.<br>\n\n**Conclusion**<br>\n・Data Scientist is a profitable occupation.<br>"},{"metadata":{},"cell_type":"markdown","source":"# ② What do earning Data Scientists have skills ?"},{"metadata":{},"cell_type":"markdown","source":"Next, I comfirmed the difference between Data Scientists who can earn and can't.<br>\nHowever, the difference of attribute information(age, gender, country and so on) is not excluded.\nBecause it can't be changed."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#Make graph function\ndef make_onehot_var_graph(df, var, drop_list, title, height):\n    qvar_list = [item for item in df.columns if item.find(var) != -1]\n    qvar_list.append('Q10_earn_flg')\n\n    gb_df = ds[qvar_list]\n    gb_df = gb_df.groupby('Q10_earn_flg').sum()\n\n    df_col = []\n    for i in range(len(qvar_list)-1):\n        tmp_df_col = qvar_list[i][3:]\n        df_col.append(tmp_df_col)\n\n    gb_df.columns = df_col\n    gb_df.drop(drop_list, axis=1, inplace=True)\n    gb_df = gb_df.T.reset_index()\n    gb_df['Earn_rate'] = round(gb_df['Earn'] / earn * 100, 1)\n    gb_df['Not earn_rate'] = round(gb_df['Not earn'] / notearn * 100, 1)\n\n    if var == 'Q9':\n        def Q9_cond(x):\n            if  x == 'Do research that advances the state of the art of machine learning':\n                return 'Research that advances the cutting-edge ML'\n            elif x == 'Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data':\n                return 'Build the data infrastructure'\n            elif x == 'None of these activities are an important part of my role at work':\n                return 'I do not play an important role in data science'\n            elif x == 'Build prototypes to explore applying machine learning to new area':\n                return 'Build prototypes to explore applying ML to new area'\n            elif x == 'Analyze and understand data to influence product or business decisions':\n                return 'Analyze data to influence business decisions'\n            elif x == 'Build and/or run a machine learning service that operationally improves my product or workflows':\n                return 'Build ML service that operationally improves our products'\n            elif x == 'Other':\n                return 'Other'\n\n        gb_df['index'] = gb_df['index'].apply(Q9_cond)\n\n    if var == 'Q12':\n        def Q12_cond(x):\n            if  x == 'None':\n                return 'None'\n            elif x == 'Other':\n                return 'Other'\n            elif x == 'Twitter (data science influencers)':\n                return 'Twitter'\n            elif x == 'Hacker News (https://news.ycombinator.com/)':\n                return 'Hacker News'\n            elif x == 'Reddit (r/machinelearning, r/datascience, etc)':\n                return 'Reddit'\n            elif x == 'Kaggle (forums, blog, social media, etc)':\n                return 'Kaggle'\n            elif x == 'Course Forums (forums.fast.ai, etc)':\n                return 'Course Forums'\n            elif x == 'YouTube (Cloud AI Adventures, Siraj Raval, etc)':\n                return 'YouTube'\n            elif x == 'Podcasts (Chai Time Data Science, Linear Digressions, etc)':\n                return 'Podcasts'\n            elif x == 'Blogs (Towards Data Science, Medium, Analytics Vidhya, KDnuggets etc)':\n                return 'Blogs'\n            elif x == 'Journal Publications (traditional publications, preprint journals, etc)':\n                return 'Journal Publications'\n            elif x == 'Slack Communities (ods.ai, kagglenoobs, etc)':\n                return 'Slack Communities'\n        \n        gb_df['index'] = gb_df['index'].apply(Q12_cond)\n\n    if var == 'Q26':\n        def Q26_cond(x):\n            if  x == 'None':\n                return 'None'\n            elif x == 'Object detection methods (YOLOv3, RetinaNet, etc)':\n                return 'Object detection methods (YOLOv3, RetinaNet, etc)'\n            elif x == 'Other':\n                return 'Other'\n            elif x == 'General purpose image/video tools (PIL, cv2, skimage, etc)':\n                return 'General purpose image/video tools (PIL, cv2, etc)'\n            elif x == 'Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)':\n                return 'Image classification and other general purpose networks (VGG, ResNet, etc)'\n            elif x == 'Build and/or run a machine learning service that operationally improves my product or workflows':\n                return 'Build ML service that operationally improves our products'\n            elif x == 'Image segmentation methods (U-Net, Mask R-CNN, etc)':\n                return 'Image segmentation methods (U-Net, Mask R-CNN, etc)'\n\n        gb_df['index'] = gb_df['index'].apply(Q26_cond)\n    \n    gb_df['dif_Earn_Notearn'] = gb_df['Earn_rate'] - gb_df['Not earn_rate']\n    gb_df = gb_df.sort_values('dif_Earn_Notearn', ascending=False)\n\n    X=list(gb_df['index'].values)\n    Y1=gb_df['Earn_rate'].values\n    Y2=gb_df['Not earn_rate'].values\n\n    fig = go.Figure(data=[\n        go.Bar(name='Earn', x=X, y=Y1, text=Y1, textposition='auto'),\n        go.Bar(name='Not Earn', x=X, y=Y2, text=Y2, textposition='auto')\n    ])\n\n    fig.update_layout(title=title, barmode='group', height=height, font_size=10, xaxis_tickangle=45)\n    fig.show()\n\ndef make_onehot_var_sum_avg_graph(df, var, avg_var, title):\n    qvar_list = [item for item in df.columns if item.find(var) != -1]\n    qvar_list.append('Q10_earn_flg')\n\n    gb_df = ds[qvar_list]\n    \n    x = gb_df['Q10_earn_flg'].values\n    y = gb_df[var+avg_var].values\n\n    earn_df = gb_df[gb_df['Q10_earn_flg'] == 'Earn']\n    nearn_df = gb_df[gb_df['Q10_earn_flg'] == 'Not earn']\n    \n    p_eran = earn_df[var+avg_var].values\n    p_nearn = nearn_df[var+avg_var].values\n    p_earn_nearn = stats.ttest_ind(p_eran, p_nearn, equal_var=False)\n    pvalue = round(p_earn_nearn[1],3)\n    name = title+'(p-value='+str(pvalue)+')'\n\n    earn_mean = round(earn_df[var+avg_var].mean(),2)\n    nearn_mean = round(nearn_df[var+avg_var].mean(),2)\n    \n    fig = go.Figure(data=[\n        go.Bar(name='Earn', x=[\"Earn or Not earn\"], y=[earn_mean], text=earn_mean, textposition='auto'),\n        go.Bar(name='Not earn', x=[\"Earn or Not earn\"], y=[nearn_mean], text=nearn_mean, textposition='auto')\n    ])\n    fig.update_layout(title=name, font_size=10, height=300, barmode='group')\n    fig.show()\n\n#Make Data Scientist data frame\nds = multi_choise[multi_choise['Q5'] == 'Data Scientist']\nnotearn = ds['Q10_earn_flg'].value_counts()[0]\nearn = ds['Q10_earn_flg'].value_counts()[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q9', drop_list='sum', title='Response rate', height=450)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q9', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Play an important part of your role at work in ML<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・77.5% of \"Earn\" work 「Analyze data to influence business decisions」.<br>\n&emsp;It is 15.1% better than compared to \"Not earn\".<br>\n・51.4% of \"Earn\" work 「Build ML service that operationally improves our products」.<br>\n&emsp;It is 10.0% better than compared to \"Not earn\".<br>\n・43.8% of \"Earn\" work 「Build the data infrastructure」.<br>\n&emsp;It is 10.9% better than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options</u><br>\n・There is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n・You should be able to analyze data to influence business decisions.<br>\n・It would be even better if you can build ML service that operationally improves our products and the data infrastructure.<br>\n・The person who can play an important part of your role at ML work in various situations can earn.<br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q12', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q12', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Favorite media sources that report on data science topics<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・Blogs are read 75.5% of \"Earn\".<br>\n&emsp;It is 10.1% better than compared to \"Not earn\".<br>\n・Journal Publications are read 36.9% of \"Earn\".<br>\n&emsp;It is 9.2% better than compared to \"Not earn\".<br>\n・Kaggle are read 55.8% of \"Earn\".<br>\n&emsp;It is 13.9% worse than compared to \"Not earn\".<br>\n・Youtube are read 29.8% of \"Earn\".<br>\n&emsp;It is 14.7% worse than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options</u><br>\n・There is no significant difference between \"Earn\" and \"Not earn\".\n\n**Conclusion**<br>\n・Blogs and Journal Publications may be for expert and Kaggle and Youtube may be for beginners.<br>\n・It doesn't matter how many sources you are reading."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q16', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q16', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### IDE or text editor<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・39.7% of \"Earn\" use Rstudio.<br>\n&emsp;It is 8.7% better than compared to \"Not earn\".<br>\n・17.3% of \"Earn\" use Vim or Emacs.<br>\n&emsp;It is 8.0% better than compared to \"Not earn\".<br>\n・16.2% of \"Earn\" use Spyder.<br>\n&emsp;It is 5.6% worse than compared to \"Not earn\".<br>\n・\"Earn\" and \"Not earn\" almost use Jupyter.<br>\n<u>Number of checks for questioning options</u><br>\n・There is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n・There are no programming language with a difference of more than 10% between \"Earn\" and \"Not earn\".<br>\n・You should be able to use Jupyter. It would be even better if you can use Rstudio and Vim or Emacs.<br>\n・The person who can use many IDE or text editor can earn.<br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q18', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q18', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Programming languages<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・61.3% of \"Earn\" use SQL.<br>\n&emsp;It is 15.0% better than compared to \"Not earn\".<br>\n・23.8% of \"Earn\" use Bash.<br>\n&emsp;It is 10.5% better than compared to \"Not earn\".<br>\n・43.3% of \"Earn\" use R.<br>\n&emsp;It is 9.9% better than compared to \"Not earn\".<br>\n・\"Earn\" and \"Not earn\" almost use Python.<br>\n<u>Number of checks for questioning options</u><br>\n・There is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n・You should be able to use Python and SQL. It would be even better if you can use Bash and R.<br>\n・The person who can use many programming languages can earn.<br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q20', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q20', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data visualization libraries or tools<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・38.9% of \"Earn\" use ggplot or ggplot2.<br>\n&emsp;It is 8.6% better than compared to \"Not earn\".<br>\n・18.5% of \"Earn\" use shiny.<br>\n&emsp;It is 7.5% better than compared to \"Not earn\".<br>\n・Seaborn and Matplotlib are often used by \"Earn\" and \"Not earn\".<br>\n&emsp;\"Earn\" are a little worse than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options</u><br>\n・There is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n・There are no programming language with a difference of more than 10% between \"Earn\" and \"Not earn\".<br>\n・If I must say, you should be able to use ggplot or ggplot2.<br>\n・You should be able to use other than Seaborn and Matplotlib.<br>\n・The person who can use many data visualization libraries or tools can earn.<br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q24', drop_list='_sum', title='Response rate', height=450)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q24', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ML algorithms<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・79.3% of \"Earn\" use Linear or Logistic Regression.<br>\n&emsp;It is 10.7% better than compared to \"Not earn\".<br>\n・62.8% of \"Earn\" use GBM.<br>\n&emsp;It is 9.7% better than compared to \"Not earn\".<br>\n・75.2% of \"Earn\" use Decision Trees or Random Forests.<br>\n&emsp;It is 9.4% better than compared to \"Not earn\".<br>\n・32.8% of \"Earn\" use Bayesian.<br>\n&emsp;It is 7.9% better than compared to \"Not earn\".<br>\n・26.9% of \"Earn\" use RNN.<br>\n&emsp;It is 1.5% worse than compared to \"Not earn\".<br>\n・37.1% of \"Earn\" use CNN.<br>\n&emsp;It is 2.8% worse than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options</u><br>\n・There is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n・You should be able to use classical ML algorithms(Linear or Logistic Regression, GBM, Decision Trees or Random Forests, Bayesian).<br>\n・While, deep learning methods is used by \"Not earn\" compared to \"Earn\".<br>\n・The person who can use many ML algorithms can earn.<br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q28', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q28', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ML frameworks<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・50.0% of \"Earn\" use Xgboost.<br>\n&emsp;It is 8.2% better than compared to \"Not earn\".<br>\n・\"Earn\" and \"Not earn\" almost use Scikit-learn.<br>\n<u>Number of checks for questioning options</u><br>\n・There is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n・You should be able to use Scikit-learn. It would be even better if you can use Xgboost.<br>\n・The person who can use many ML frameworks can earn.<br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q29', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q29', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cloud computing platforms<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・39.0% of \"Earn\" use AWS.<br>\n&emsp;It is 13.6% better than compared to \"Not earn\".<br>\n・16.7% of \"Earn\" use Microsoft Azure.<br>\n&emsp;It is 5.1% better than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options</u><br>\n・There is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n・You should be able to use AWS.<br>\n・The person who can use many cloud computing platforms can earn.<br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q31', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q31', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Big data analytics products<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・10.0% of \"Earn\" use AWS Redshift.<br>\n&emsp;It is 5.2% better than compared to \"Not earn\".<br>\n・Big data analytics products are rarely used \"Earn\" and \"Not earn\".<br>\n<u>Number of checks for questioning options</u><br>\n・There is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n・If I must say, You should be able to use AWS Redshift.<br>\n・The person who can use many big data analytics products can earn.<br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"make_onehot_var_graph(df=ds, var='Q34', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q34', avg_var='_sum', title='Number of checks for questioning options')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RDB products<br>\n\n**Fact**<br>\n<u>Response rate</u><br>\n・29.3% of \"Earn\" use PostgresSQL.<br>\n&emsp;It is 10.3% better than compared to \"Not earn\".<br>\n・21.9% of \"Earn\" use Microsoft SQL server.<br>\n&emsp;It is 7.1% better than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options</u><br>\n・There is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n・You should be able to use PostgresSQL and Microsoft SQL server.<br>\n・The person who can use many RDB products can earn.<br>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}