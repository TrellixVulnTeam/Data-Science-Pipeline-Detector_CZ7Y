{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install -q textgenrnn\n# from google.colab import files\nfrom textgenrnn import textgenrnn\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"model_cfg = {\n    'word_level': True,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n    'rnn_size': 64,   # number of LSTM cells of each layer (128/256 recommended)\n    'rnn_layers': 1,   # number of LSTM layers (>=2 recommended)\n    'rnn_bidirectional': True,   # consider text both forwards and backward, can give a training boost\n    'max_length': 5,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n}\n\ntrain_cfg = {\n    'line_delimited': False,   # set to True if each text has its own line in the source file\n    'num_epochs': 2,   # set higher to train the model for longer\n    'gen_epochs': 2,   # generates sample text from model after given number of epochs\n    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n    'dropout': 0.2,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n    'is_csv': True  # set to True if file is a CSV exported from Excel/BigQuery/pandas\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'colaboratory'\ntextgen = textgenrnn(name=model_name)\n\ntrain_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n\ntrain_function(\n    file_path=\"../input/interview-full/Inerv_full.txt\",\n    new_model=True,\n    num_epochs=train_cfg['num_epochs'],\n    gen_epochs=train_cfg['gen_epochs'],\n    batch_size=512,\n    train_size=train_cfg['train_size'],\n    dropout=train_cfg['dropout'],\n    validation=train_cfg['validation'],\n    is_csv=train_cfg['is_csv'],\n    rnn_layers=model_cfg['rnn_layers'],\n    rnn_size=model_cfg['rnn_size'],\n    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n    max_length=model_cfg['max_length'],\n    dim_embeddings=200,\n    word_level=model_cfg['word_level'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}