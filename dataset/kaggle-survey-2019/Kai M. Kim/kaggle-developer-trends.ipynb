{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle 2021 Survey Data Visualization\n\n<br>\n<br>\n\n\n## Let's find out trends in relevant ML-related tools and algorithms.\n### - This can be helpful for students and beginners who want to learn practical ML.\n### - We can also use data to see what \"the world\" is doing.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T04:28:25.706259Z","iopub.execute_input":"2021-11-28T04:28:25.706912Z","iopub.status.idle":"2021-11-28T04:28:25.727711Z","shell.execute_reply.started":"2021-11-28T04:28:25.706877Z","shell.execute_reply":"2021-11-28T04:28:25.72698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The first thing I want to know is \n####    - Group by expertise\n####       - Ex. Age, job title, ML experience, compensation.\n####    - Why? Qualify each responses by their expected expertise.\n   ","metadata":{}},{"cell_type":"code","source":"%matplotlib ipympl\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib.lines import Line2D\nfrom IPython.display import HTML\n\n# from matplotlib import animation, rc","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:28:33.558221Z","iopub.execute_input":"2021-11-28T04:28:33.558897Z","iopub.status.idle":"2021-11-28T04:28:33.56635Z","shell.execute_reply.started":"2021-11-28T04:28:33.558852Z","shell.execute_reply":"2021-11-28T04:28:33.565565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"survey_2021 = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv', dtype='string')\nsurvey_2020 = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv', dtype='string')\nsurvey_2019 = pd.read_csv('../input/kaggle-survey-2019/multiple_choice_responses.csv', dtype='string')\nsurvey_2018 = pd.read_csv('../input/kaggle-survey-2018/multipleChoiceResponses.csv', dtype='string')\n\nlist_surveys = [survey_2018, survey_2019, survey_2020, survey_2021]","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:49:48.018566Z","iopub.execute_input":"2021-11-28T04:49:48.018894Z","iopub.status.idle":"2021-11-28T04:49:54.30128Z","shell.execute_reply.started":"2021-11-28T04:49:48.018852Z","shell.execute_reply":"2021-11-28T04:49:54.300532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list in order of 2017 ~ 2021\ngroups = {\n    'Age': ['Q2', 'Q1', 'Q1', 'Q1'],\n    'Gender': ['Q1', 'Q2', 'Q2', 'Q2'],\n    'Job Title': ['Q6', 'Q5', 'Q5', 'Q5'],\n    'Programming Experience': [np.nan, np.nan, 'Q6', 'Q6'],\n    'ML Experience': ['Q25', 'Q23', 'Q15', 'Q15'],\n    'Compensation': ['Q9', 'Q10', 'Q25', 'Q25'],\n    'Industry': ['Q7', np.nan, 'Q4', 'Q4'],\n    \n    'Programming Language': ['Q16_', 'Q18_', 'Q7_', 'Q7_'],\n    'IDE': ['Q13_', 'Q16_', 'Q9_', 'Q9_'],\n    'Notebook': ['Q14_', 'Q17_', 'Q10_', 'Q10_'],\n    'Specialized Hardware': [np.nan, 'Q21_', 'Q12_', 'Q12_'],\n    'Visualization Libraries/Tools': ['Q21_', 'Q20_', 'Q14_', 'Q14_'],\n    'ML Frameworks': ['Q19_', 'Q28_', 'Q16_', 'Q16_'],\n    'ML Algorithms': [np.nan, 'Q24_', 'Q17_', 'Q17_'],\n    'CV Algorithms': [np.nan, 'Q26_', 'Q18_', 'Q18_'],\n    'NLP Methods': [np.nan, 'Q27_', 'Q19_', 'Q19_'],\n    'Important Part of Work': ['Q11_', 'Q24_', 'Q24_', 'Q24_'],\n    'Computing Platform': ['Q15_', 'Q29_', 'Q26_', 'Q27_'],\n    \n# Cloud platforms: GCP, AWS, Microsoft Azure, IBM\n#     'Daily Cloud Platforms': 'Q27_A_',\n#     'Cloud Products': 'Q27_A_'\n#     'Data Storage Products': 'Q30_A_',\n#     'Big Data Products': 'Q32_A_',\n#     'Data Analysis Tools': 'Q41'\n\n    'Language Recommendation': ['Q18', 'Q19', 'Q8', 'Q8'],\n    'Courses': ['Q36_', 'Q13_', 'Q40_', 'Q40_'],\n    'Favorite Media Source': ['Q38_', 'Q12_', 'Q42_', 'Q42_'],\n    'Tools to Share Projects': ['Q49_', np.nan, 'Q39_', 'Q39']\n}\n\nyear_df = {\n    0: '2018',\n    1: '2019',\n    2: '2020',\n    3: '2021'\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:29:58.204834Z","iopub.execute_input":"2021-11-28T05:29:58.20506Z","iopub.status.idle":"2021-11-28T05:29:58.217585Z","shell.execute_reply.started":"2021-11-28T05:29:58.205034Z","shell.execute_reply":"2021-11-28T05:29:58.216901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cleaning Functions\n\n# Get df for using and rec without questions by given Q: 'Q6_' or 'Q7'\ndef get_df(df, Q):\n    if pd.isna(Q):\n        return None\n    elif Q[-1] == '_':\n        result = df.loc[1:, df.columns.str.startswith(Q)]\n    else:\n        result = df.loc[1:, [Q]]\n    return result\n\n# 2018, 2019\n# change -1 to np.nan and others to 'Other'\ndef change_other(x):\n    if x != -1 and x != '-1':\n        return 'Other'\n    else:\n        return np.nan\n    \n# For Using df with multiple columns\ndef change_columns(df): \n    columns = []\n    for col in df.columns:\n        val = df[col].unique()\n        val = [x for x in val if not pd.isna(x)][0]\n        columns.append(val)\n    df.columns = columns\n    return df\n\n# For Rec df with single column\ndef format_values(df): \n    vals = df.values.flatten().tolist()\n    columns = np.unique([x for x in vals if not pd.isna(x)])\n    results = pd.DataFrame(index=df.index, columns=columns)\n\n    for col in columns:\n        idx = df[df.iloc[:, 0] == col].index\n        results.loc[idx, col] = col\n\n    return results\n\n# Groupby given group G: 'Age'\ndef group_by(survey, groups, i, group_name, df):\n    if groups[group_name] is None:\n        return None\n    col = groups[group_name][i]\n    group_col = survey.loc[1:, col]\n    group_col.name = group_name\n    grouped = (pd.concat([group_col, df], axis=1).groupby(group_name)).count()\n    return grouped\n\n\ndef get_df_by_group(group_name, variable_name):\n    # Combined responses of all surveys and groups.\n    combined = []\n    for i in range(len(list_surveys)):\n        df = get_df(list_surveys[i], groups[variable_name][i])\n        if df is None:\n            combined.append(None)\n        else:\n            if df.shape[1] == 1:\n                df = format_values(df)\n            else:\n                # if -1 exists in other (2018-2019), apply (change_other)\n                if i in [0, 1]:\n                    df.iloc[:, -1] = df.iloc[:, -1].apply(change_other)\n                df = change_columns(df)\n            grouped = group_by(list_surveys[i], groups, i, group_name, df)\n            combined.append(grouped)\n    return combined","metadata":{"execution":{"iopub.status.busy":"2021-11-28T04:51:05.784821Z","iopub.execute_input":"2021-11-28T04:51:05.78506Z","iopub.status.idle":"2021-11-28T04:51:05.803041Z","shell.execute_reply.started":"2021-11-28T04:51:05.785033Z","shell.execute_reply":"2021-11-28T04:51:05.801815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = get_df_by_group('Compensation', 'Computing Platform')\n\ntemp[3].empty","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:25:58.842638Z","iopub.execute_input":"2021-11-28T05:25:58.842845Z","iopub.status.idle":"2021-11-28T05:25:59.983086Z","shell.execute_reply.started":"2021-11-28T05:25:58.84282Z","shell.execute_reply":"2021-11-28T05:25:59.98229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def animate_X_by_Group(fig, axes, G, X):\n#     plt.close('all')\n    fig.suptitle(f'Trend of {X} Grouped by {G} for each Year')\n    datas = get_df_by_group(G, X)\n    \n    \n    max_values = []\n    # max_value\n    for df in datas:\n        if not df.empty:\n            max_values.append(max(df.values.flatten()) + 200)\n        else:\n            max_values.append(None)\n    \n    def animate(frame):\n        for i, ax in enumerate(axes.flatten()):\n            if max_values[i]:\n                data = datas[i].sort_values(by=datas[i].index[0], axis=1)\n\n                ax.clear()\n                ax.set_ylim([0, max_values[i]])\n\n                group = data.iloc[frame, :]\n\n                rects = ax.bar(group.index, group.values, color=None)\n                ax.bar_label(rects, labels=group.values)\n\n                title = ax.set_title(f'Year {str(year_df[i])}: {G} {group.name}')\n                plt.setp(ax.get_xticklabels(), rotation=-45, horizontalalignment='left')\n\n                top_5 = group.sort_values(ascending=False).iloc[:5]\n                top_5 = [i + ': ' + str(j) for i, j in zip(top_5.index, top_5.values)]\n                custom_lines = [Line2D([0], [0],  lw=4),\n                                Line2D([0], [0],  lw=4),\n                                Line2D([0], [0],  lw=4),\n                               Line2D([0], [0], lw=4),\n                                Line2D([0], [0], lw=4)]\n                legs = ax.legend(custom_lines, top_5, title=f'Top 5 {X}',\n                               title_fontsize='large', fontsize='medium',\n                               loc=2)\n            else:\n                pass\n        return axes, rects\n\n    ani = FuncAnimation(fig, animate, frames=len(datas), repeat=True, interval=2000, blit=False)\n        \n    return ani","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:26:09.684596Z","iopub.execute_input":"2021-11-28T05:26:09.684878Z","iopub.status.idle":"2021-11-28T05:26:09.700828Z","shell.execute_reply.started":"2021-11-28T05:26:09.684834Z","shell.execute_reply":"2021-11-28T05:26:09.699012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's See What We Got!","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'Compensation', 'Programming Language')\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1) Language Used Grouped by Compensation\n\n### Python came in first in all groups and all years.\n### SQL came in strong second.\n<br>\n<br>\n\n### And other languages such as Javascript, C++, R, and Bash appeared in the top 5 languages.\n\n#### My intuition is that Python is the primary language of data science and artificial intelligence\n#### And Javascript, SQL, C++, R, and Bash are used to create and manipulate website interactions, embedded systems, and operating systems.","metadata":{}},{"cell_type":"code","source":"HTML(result.to_jshtml())","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:06:17.047122Z","iopub.execute_input":"2021-11-28T05:06:17.047531Z","iopub.status.idle":"2021-11-28T05:06:20.477014Z","shell.execute_reply.started":"2021-11-28T05:06:17.047491Z","shell.execute_reply":"2021-11-28T05:06:20.47632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'ML Experience', 'Visualization Libraries/Tools')\nplt.close()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Visualization Libraries/Tools grouped by ML Experience\n\n### - Matplotlib seems to be the go-to choice for visualizations.\n### - Seaborn, which is built on top of Matplotlib, came in second.\n### - Ggplot2, Plotly, Shiny (for R), and Geoplotlib (geo-data) came in the top 5.\n\n\n<br>\n<br>\n\n\n#### I used Matplotlib to create data visualizations and animations.\n#### It allows flexibility and versatility, which, combined with other visualization tools, can help data scientists tremendously.","metadata":{}},{"cell_type":"code","source":"HTML(result.to_jshtml())","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:06:23.863297Z","iopub.execute_input":"2021-11-28T05:06:23.863593Z","iopub.status.idle":"2021-11-28T05:06:27.063848Z","shell.execute_reply.started":"2021-11-28T05:06:23.863555Z","shell.execute_reply":"2021-11-28T05:06:27.063265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML Frameworks Grouped by ML Experience\n\n## The plot reveals a popularity in\n### - Scikit-Learn,\n### - Then TensorFlow, Keras, and PyTorch,\n### - and Xgboost and RandomForest.\n\n<br/> \n\n### Similar to programming languages, machine learning frameworks and tools seem to be growing in users.\n### This may be due to rapid developments and advances in machine learning communities.\n### It's quiet awesome to see the numbers at the beginning of an exponential growth of the data science community!\n","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'ML Experience', 'ML Frameworks')\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HTML(result.to_jshtml())","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:06:42.093574Z","iopub.execute_input":"2021-11-28T05:06:42.093851Z","iopub.status.idle":"2021-11-28T05:06:45.736873Z","shell.execute_reply.started":"2021-11-28T05:06:42.093795Z","shell.execute_reply":"2021-11-28T05:06:45.736285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'Compensation', 'Computing Platform')\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Computing Platform Grouped by Compensation for each Year\n\n## The plot reveals a clear trend:\n### - Data scientists began ramping up Cloud Services usage.\n### - AWS, Google Cloud Platform, Microsoft Azure are same big names out there currently.\n\n<br/> \n\n### Like other categories, we expect the usage in the top 5 platforms to increase.\n### Cloud computing platforms allow data scientists to leverage the power of data centers to analyze data and train machine learning models.","metadata":{}},{"cell_type":"code","source":"HTML(result.to_jshtml())","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:30:07.625225Z","iopub.execute_input":"2021-11-28T05:30:07.625557Z","iopub.status.idle":"2021-11-28T05:30:11.002948Z","shell.execute_reply.started":"2021-11-28T05:30:07.625518Z","shell.execute_reply":"2021-11-28T05:30:11.002277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'Compensation', 'Courses')\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Courses Completed or Started Grouped by Compensation for each Year\n\n\n### - Data scientists have been using courses such as,\n### - Coursera, Kaggle, Universities, Udemy, DataCamp, and edX.\n\n<br/>\n** Kaggle did not ask this question in the year 2020\n<br/> \n\n### Most of these courses are free or sold at an affordable price, so it's a great idea to start studying them.\n### My intuition is that AI education and consulting will play as a huge catalyst to the AI revolution.","metadata":{}},{"cell_type":"code","source":"HTML(result.to_jshtml())","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:42:21.721495Z","iopub.execute_input":"2021-11-28T05:42:21.72222Z","iopub.status.idle":"2021-11-28T05:42:24.638673Z","shell.execute_reply.started":"2021-11-28T05:42:21.722176Z","shell.execute_reply":"2021-11-28T05:42:24.638056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wrapping Things Up...\n\n<br>\n<br />\n\n### What I am excited about:\n### - Expanding data science community. (Stack Overflow, Kaggle, Youtube...). I had so many people help me create these visualizations and I can't thank them enough.\n### - Improving documentations (Matplotlib, Seaborn, Tensorflow, PyTorch, Keras) that accelerate data science projects.\n### - Powerful technologies that are being developed by big companies that give immense computing powers to individuals like me.\n### - Learning more about data visualizations and artificial intelligence. There are lots of room for improvement (speed, accuracy, publications, revisions).\n\n<br />\n\n### Improvements I could have made: \n### - I could have cleaned the data a lot more to allow for more robust data analysis.\n### - I could have tried different kinds of plots such as scatter plot and 3d animations.\n### - I could have came up with more intereseting subsets.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}