{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport os\nimport time\nimport glob\nfrom PIL import *\nimport skimage\n\n\nWIDTH = 100\nHEIGHT = 100\nSEQUENCE = np.array([])\nBASIC_SEQUENCE = np.array([])\nNEXT_SEQUENCE = np.array([])\nNUMBER = 0\n\ndef image_initialize(image):\n    picture = Image.open(image)\n    picture = picture.resize((WIDTH, HEIGHT), Image.ANTIALIAS)\n    picture = picture.convert('L')\n    picture.save('./temp.png')  \n    data = np.array(picture.getdata()).reshape(WIDTH, HEIGHT, 1)\n    return data\n\nfor file in glob.glob(\"../input/draper-satellite-image-chronology/train_sm/train_sm/set107_*.jpeg\"):\n    image_array = (image_initialize(file))/255\n    SEQUENCE = np.append(SEQUENCE, image_array)\n    NUMBER += 1\n    print(SEQUENCE[0])\n    print(NUMBER)\n    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n\nSEQUENCE = SEQUENCE.reshape(NUMBER, WIDTH * HEIGHT)\n\nnp.savez('./sequence_array.npz', sequence_array=SEQUENCE)\nprint('Data saved.')\nprint(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T14:11:51.570786Z","iopub.execute_input":"2022-03-02T14:11:51.5711Z","iopub.status.idle":"2022-03-02T14:11:53.110756Z","shell.execute_reply.started":"2022-03-02T14:11:51.571022Z","shell.execute_reply":"2022-03-02T14:11:53.110006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ssim_loss(y_true, y_pred):\n    return tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T14:11:56.370262Z","iopub.execute_input":"2022-03-02T14:11:56.370514Z","iopub.status.idle":"2022-03-02T14:11:56.377749Z","shell.execute_reply.started":"2022-03-02T14:11:56.370486Z","shell.execute_reply":"2022-03-02T14:11:56.377018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def psnr(y_true,y_pred):\n    max_pixel = 1.0\n    return (10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true), axis=-1)))) / 2.303","metadata":{"execution":{"iopub.status.busy":"2022-03-02T14:11:57.406158Z","iopub.execute_input":"2022-03-02T14:11:57.406455Z","iopub.status.idle":"2022-03-02T14:11:57.412561Z","shell.execute_reply.started":"2022-03-02T14:11:57.406426Z","shell.execute_reply":"2022-03-02T14:11:57.409925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv3D,ConvLSTM2D,BatchNormalization,MaxPooling2D, Dense, Flatten,GRU,Conv2D,Reshape,Permute,Lambda,Input\nfrom tensorflow.keras.models import Sequential, load_model\nfrom keras import backend as K\nimport pylab as pl\nimport time\n# from tensorflow.keras.utils import multi_gpu_model\nfrom keras import optimizers\nimport imutils\nimport cv2\n# from google.colab.patches import cv2_imshow\n\ndef custom_layer(tensor):\n    tensor=tensor[:,None]\n    return tensor\n\n\n#Loading array\nSEQUENCE = np.load('./sequence_array.npz')['sequence_array']  # load array\nn_samples = len(SEQUENCE)\n\nWIDTH = 100\nHEIGHT = 100\nn_frames = 1\n\n# step =1\nSEQUENCE = SEQUENCE.reshape(n_samples, WIDTH, HEIGHT, 1)\nBASIC_SEQUENCE = np.zeros((n_samples-n_frames, n_frames, WIDTH, HEIGHT, 1))\nNEXT_SEQUENCE = np.zeros((n_samples-n_frames, n_frames, WIDTH, HEIGHT, 1))\n\nfor i in range(n_frames):\n    BASIC_SEQUENCE[:, i, :, :, :] = SEQUENCE[i:i+n_samples-n_frames]\n    NEXT_SEQUENCE[:, i, :, :, :] = SEQUENCE[i+1:i+n_samples-n_frames+1]\n\n\n\n\n\n# model=Sequential()\n# model.add(ConvLSTM2D(filters=256, kernel_size=(3, 3),input_shape=(None, WIDTH, HEIGHT, 1), padding=\"same\", return_sequences=True))\n# model.add(BatchNormalization())\n# model.add(ConvLSTM2D(filters=256, kernel_size=(3, 3), padding=\"same\", return_sequences=True))\n# model.add(BatchNormalization())\n# model.add(Conv3D(filters=1, kernel_size=(3, 3, 3), activation=\"relu\", padding='same', data_format=\"channels_last\"))\n# model.compile(loss=ssim_loss, optimizer=\"adadelta\",metrics=[tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.RootMeanSquaredError(),ssim_loss,psnr])\n\nmodel=Sequential()\nmodel.add(Conv2D(filters=256, kernel_size=(3, 3),input_shape=(None, WIDTH, HEIGHT, 1), padding=\"same\"))\nmodel.add(Reshape((10000,256)))\nmodel.add(GRU(256,return_sequences=True))\nmodel.add(BatchNormalization())\nmodel.add(Reshape((100,100,256)))\nmodel.add(Lambda(custom_layer))\nmodel.add(Conv3D(filters=1, kernel_size=(3, 3, 3), activation=\"relu\", padding='same', data_format=\"channels_last\"))\nmodel.compile(loss=ssim_loss, optimizer=\"adadelta\",metrics=[tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.RootMeanSquaredError(),ssim_loss,psnr])\n\n### Split data into training and test sets\n# trainingfraction = 0.95\ntrainingfraction = 1.0\ntrain_size = round(n_samples * trainingfraction)\n\n### Train the network\n# model.fit(BASIC_SEQUENCE[:train_size], NEXT_SEQUENCE[:train_size],  epochs=10, validation_split=0.05)\nt_start = time.time()\nH=model.fit(BASIC_SEQUENCE[:train_size], NEXT_SEQUENCE[:train_size], verbose=2, epochs=10)\nt_end = time.time()\n\nprint('Training Elapsed time:')\nprint(t_end - t_start)\n\n### Take an example from the test set and predict the next steps\nindex = 3\n\nnum_test_frames = 0 ### Number of frames to predict\n\n\ntrain_pred = BASIC_SEQUENCE[index][:n_frames-num_test_frames:, ::, ::, ::]  ##(track)\nfor j in range(n_frames):\n    t_start = time.time()\n    new_pos = model.predict(train_pred[np.newaxis, :, :, :, :])\n    t_end = time.time()\n    print('Testing Elapsed time:')\n    print(t_end - t_start)\n    new = new_pos[:, -1, :, :, :]\n    train_pred = np.concatenate((train_pred, new), axis=0)\n\n### Compare predictions to the truth\ntruth = BASIC_SEQUENCE[index][:, :, :, :]\n\nfor i in range(n_frames):\n    fig = plt.figure(figsize=(10, 5))\n    ax = fig.add_subplot(121)\n    ### In left panel show original then predicted frames\n    # ax.text(1, 3, 'Predictions', fontsize=20, color='w')\n    plt.text(1, 3, 'Predictions', fontsize=20)\n    toplot = train_pred[i, ::, ::, 0]\n    plt.imshow(toplot, cmap='binary')\n    plt.savefig('%i_Prediction.png' % (i + 1))\n\nfor i in range(n_frames):   \n    fig = plt.figure(figsize=(10, 5))\n    ax = fig.add_subplot(122)\n    plt.text(1, 3, 'Ground truth', fontsize=20)\n    toplot = truth[i, ::, ::, 0]\n    plt.imshow(toplot, cmap='binary')\n    plt.savefig('%i_GroundTruth.png' % (i + 1))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T14:14:45.139741Z","iopub.execute_input":"2022-03-02T14:14:45.14017Z","iopub.status.idle":"2022-03-02T14:14:53.765456Z","shell.execute_reply.started":"2022-03-02T14:14:45.140134Z","shell.execute_reply":"2022-03-02T14:14:53.764635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install imutils","metadata":{"execution":{"iopub.status.busy":"2022-03-02T14:12:07.898085Z","iopub.execute_input":"2022-03-02T14:12:07.89869Z","iopub.status.idle":"2022-03-02T14:12:18.295063Z","shell.execute_reply.started":"2022-03-02T14:12:07.898646Z","shell.execute_reply":"2022-03-02T14:12:18.294258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.metrics import structural_similarity as ssim\n#Load Data\nimageA = cv2.imread('./1_Prediction.png')\nimageB = cv2.imread('./1_GroundTruth.png')\n\n# convert the images to grayscale\ngrayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\ngrayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n\n# compute the Structural Similarity Index (SSIM) between the two\n# images, ensuring that the difference image is returned\n(score, diff) = ssim(grayA, grayB, full=True)\ndiff = (diff * 255).astype(\"uint8\")\nprint(\"SSIM: {}\".format(score))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-02T14:14:58.181642Z","iopub.execute_input":"2022-03-02T14:14:58.182132Z","iopub.status.idle":"2022-03-02T14:14:58.234195Z","shell.execute_reply.started":"2022-03-02T14:14:58.182096Z","shell.execute_reply":"2022-03-02T14:14:58.233382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}