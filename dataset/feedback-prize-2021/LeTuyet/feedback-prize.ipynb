{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Evaluating Student Writing","metadata":{}},{"cell_type":"markdown","source":"## Business Understanding","metadata":{}},{"cell_type":"markdown","source":"Writing is a critical skill for success.Â However, less than a third of high school seniors are proficient writers, according to the National Assessment of Educational Progress. One way to help students improve their writing is via automated feedback tools, which evaluate student writing and provide personalized feedback.\n\nIn this task, you need to identify elements in student writing. More specifically, you will automatically segment texts and classify argumentative and rhetorical elements in essays written by 6th-12th grade students.\n\nIf successful, you'll make it easier for students to receive feedback on their writing and increase opportunities to improve writing outcomes. Virtual writing tutors and automated writing systems can leverage these algorithms while teachers may use them to reduce grading time. The open-sourced algorithms you come up with will allow any educational organization to better help young writers develop.","metadata":{}},{"cell_type":"markdown","source":"## Analytic Approach","metadata":{}},{"cell_type":"markdown","source":"The task is not a normal classification problem. We can not just classify directly the essays. First, we need to segment essays into discrete rhetorical and argumentative elements, then classify those elements.\n\nWe can use NER approach to solve the problem. We will convert train dataset into a NER token array that we can use to train a NER transformer.","metadata":{}},{"cell_type":"markdown","source":"## Data Understanding","metadata":{}},{"cell_type":"markdown","source":"The data is provided in two formats:\n\n* A train.csv with annotation for essays\n* A train folder with invidual .txt files for each essay.","metadata":{}},{"cell_type":"code","source":"#import pakages\nimport numpy as np\nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\n#from nltk.corpus import stopwords\nimport tensorflow as tf\nfrom transformers import *\n###Insipred from CHRIS DEOTTE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-27T02:51:19.789662Z","iopub.execute_input":"2022-02-27T02:51:19.789974Z","iopub.status.idle":"2022-02-27T02:51:36.934751Z","shell.execute_reply.started":"2022-02-27T02:51:19.789893Z","shell.execute_reply":"2022-02-27T02:51:36.933884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data overview","metadata":{}},{"cell_type":"markdown","source":"Let look at the training data table.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T02:51:36.936849Z","iopub.execute_input":"2022-02-27T02:51:36.937067Z","iopub.status.idle":"2022-02-27T02:51:38.463332Z","shell.execute_reply.started":"2022-02-27T02:51:36.937036Z","shell.execute_reply":"2022-02-27T02:51:38.462534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 7 fields in the table:\n\n* id - ID code for essay response\n* discourse_id - ID code for discourse element\n* discourse_start - character position where discourse element begins in the essay response\n* discourse_end - character position where discourse element ends in the essay response\n* discourse_text - text of discourse element\n* discourse_type - classification of discourse element\n* discourse_type_num - enumerated class label of discourse element\n* predictionstring - the word indices of the training sample, as required for predictions","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:31:59.420844Z","iopub.execute_input":"2022-02-25T03:31:59.421106Z","iopub.status.idle":"2022-02-25T03:31:59.512771Z","shell.execute_reply.started":"2022-02-25T03:31:59.421071Z","shell.execute_reply":"2022-02-25T03:31:59.512088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:31:59.513998Z","iopub.execute_input":"2022-02-25T03:31:59.514265Z","iopub.status.idle":"2022-02-25T03:31:59.545066Z","shell.execute_reply.started":"2022-02-25T03:31:59.514209Z","shell.execute_reply":"2022-02-25T03:31:59.544301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:31:59.547Z","iopub.execute_input":"2022-02-25T03:31:59.547274Z","iopub.status.idle":"2022-02-25T03:31:59.626436Z","shell.execute_reply.started":"2022-02-25T03:31:59.547225Z","shell.execute_reply":"2022-02-25T03:31:59.625753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no missing values in the training set.","metadata":{}},{"cell_type":"markdown","source":"Let see how many raw text files and annotaions in the training set.","metadata":{}},{"cell_type":"code","source":"raw_text_files = os.listdir('/kaggle/input/feedback-prize-2021/train')\nprint(f'Training data consists of {len(raw_text_files)} texts')\nprint(f'Training data consists of {train.shape[0]} annotaions')\nprint(f'Each essay contains average {round(train.shape[0]/len(raw_text_files), 1)} annotaions.')","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:32:06.18659Z","iopub.execute_input":"2022-02-25T03:32:06.18707Z","iopub.status.idle":"2022-02-25T03:32:06.44212Z","shell.execute_reply.started":"2022-02-25T03:32:06.187032Z","shell.execute_reply":"2022-02-25T03:32:06.440804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let look at the first file in the data frame","metadata":{}},{"cell_type":"code","source":"with open('../input/feedback-prize-2021/train/423A1CA112E2.txt', 'r') as file:\n    first_txt = file.read()\nprint(first_txt)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:32:09.641305Z","iopub.execute_input":"2022-02-25T03:32:09.641884Z","iopub.status.idle":"2022-02-25T03:32:09.651099Z","shell.execute_reply.started":"2022-02-25T03:32:09.641845Z","shell.execute_reply":"2022-02-25T03:32:09.650295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train['id'] == \"423A1CA112E2\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:32:09.971673Z","iopub.execute_input":"2022-02-25T03:32:09.971912Z","iopub.status.idle":"2022-02-25T03:32:10.011811Z","shell.execute_reply.started":"2022-02-25T03:32:09.971886Z","shell.execute_reply":"2022-02-25T03:32:10.011151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Texts (essay) overview","metadata":{}},{"cell_type":"code","source":"text_df = pd.DataFrame(columns = ['id', 'text'])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:32:16.874297Z","iopub.execute_input":"2022-02-25T03:32:16.874846Z","iopub.status.idle":"2022-02-25T03:32:16.8818Z","shell.execute_reply.started":"2022-02-25T03:32:16.874797Z","shell.execute_reply":"2022-02-25T03:32:16.880894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntexts = []\nfor file in raw_text_files:\n    with open(f'/kaggle/input/feedback-prize-2021/train/{file}') as f:\n        texts.append({'id': file[:-4], 'text': f.read()})\n        #text_df.append(pd.Series({'id': file[:-4], 'text': f.read()}), ignore_index = True)\ntexts_df = pd.DataFrame(texts)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:32:17.092227Z","iopub.execute_input":"2022-02-25T03:32:17.092616Z","iopub.status.idle":"2022-02-25T03:33:03.59577Z","shell.execute_reply.started":"2022-02-25T03:32:17.09258Z","shell.execute_reply":"2022-02-25T03:33:03.594935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:33:03.597422Z","iopub.execute_input":"2022-02-25T03:33:03.597675Z","iopub.status.idle":"2022-02-25T03:33:03.607324Z","shell.execute_reply.started":"2022-02-25T03:33:03.597642Z","shell.execute_reply":"2022-02-25T03:33:03.605635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#count the number of character and number of word of each essay\ntexts_df['len'] = texts_df['text'].apply(len)\ntexts_df['word_num'] = texts_df['text'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:33:03.608466Z","iopub.execute_input":"2022-02-25T03:33:03.608715Z","iopub.status.idle":"2022-02-25T03:33:04.003919Z","shell.execute_reply.started":"2022-02-25T03:33:03.608681Z","shell.execute_reply":"2022-02-25T03:33:04.003275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts_df['len'].hist(bins = 50, figsize = (12, 8))\nplt.title('Number of characters of each essay', fontsize = 15)\nplt.xlabel('Number of characters')\nplt.ylabel('Frequency');","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:33:04.006008Z","iopub.execute_input":"2022-02-25T03:33:04.006285Z","iopub.status.idle":"2022-02-25T03:33:04.347116Z","shell.execute_reply.started":"2022-02-25T03:33:04.006237Z","shell.execute_reply":"2022-02-25T03:33:04.346445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the histogram, we can see that most of the texts have less than 5000 characters, with some outlier that length up to about 17500 characters.","metadata":{}},{"cell_type":"code","source":"texts_df['word_num'].hist(bins = 50, figsize = (12, 8))\nplt.title('Number of words of each essay', fontsize = 15)\nplt.xlabel('Number of words')\nplt.ylabel('Frequency');","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:33:04.348285Z","iopub.execute_input":"2022-02-25T03:33:04.349068Z","iopub.status.idle":"2022-02-25T03:33:04.646756Z","shell.execute_reply.started":"2022-02-25T03:33:04.34903Z","shell.execute_reply":"2022-02-25T03:33:04.646082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(texts_df['word_num'] <= 512).sum()/len(texts_df['word_num'])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:33:04.647809Z","iopub.execute_input":"2022-02-25T03:33:04.649401Z","iopub.status.idle":"2022-02-25T03:33:04.656551Z","shell.execute_reply.started":"2022-02-25T03:33:04.649359Z","shell.execute_reply":"2022-02-25T03:33:04.655628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(texts_df['word_num'] <= 1024).sum()/len(texts_df['word_num'])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:33:04.657878Z","iopub.execute_input":"2022-02-25T03:33:04.658218Z","iopub.status.idle":"2022-02-25T03:33:04.666826Z","shell.execute_reply.started":"2022-02-25T03:33:04.658173Z","shell.execute_reply":"2022-02-25T03:33:04.66596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the histogram, we can see that most of the texts have less than 1000 words. There are 73.9% texts have less than or equal to 512 words and 99% texts have less than or equal to 1024 words.","metadata":{}},{"cell_type":"markdown","source":"###  Length and frequency of each discourse type","metadata":{}},{"cell_type":"code","source":"train['discourse_type'].value_counts(ascending = True).plot(kind = 'barh')\nplt.title('Number of each Discourse Type', fontsize = 16, pad = 15)\nplt.ylabel('')\nplt.xlabel('Frequency');","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:33:04.667996Z","iopub.execute_input":"2022-02-25T03:33:04.668314Z","iopub.status.idle":"2022-02-25T03:33:04.877533Z","shell.execute_reply.started":"2022-02-25T03:33:04.668281Z","shell.execute_reply":"2022-02-25T03:33:04.876636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The most popular discourse type is Claim, and the least popular is Rebuttal.","metadata":{}},{"cell_type":"code","source":"#make a collumn to calculate the len of each discoure\ntrain[\"discourse_len\"] = train[\"discourse_text\"].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:33:29.435035Z","iopub.execute_input":"2022-02-25T03:33:29.435326Z","iopub.status.idle":"2022-02-25T03:33:29.888633Z","shell.execute_reply.started":"2022-02-25T03:33:29.435293Z","shell.execute_reply":"2022-02-25T03:33:29.887881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby('discourse_type')[\"discourse_len\"].mean().sort_values().plot(kind = 'barh')\nplt.title('Average length of each Discourse Type', fontsize = 16, pad = 15)\nplt.xlabel('Number of words')\nplt.ylabel('');","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:33:29.890133Z","iopub.execute_input":"2022-02-25T03:33:29.890396Z","iopub.status.idle":"2022-02-25T03:33:30.11051Z","shell.execute_reply.started":"2022-02-25T03:33:29.890364Z","shell.execute_reply":"2022-02-25T03:33:30.109862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Evidence type has the longest average number of words, and the sortest one is Claim. It seems resonable","metadata":{}},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Token file\nLOAD_TOKENS_FROM = '../input/longformerbase4096'\n\n# Pretrained model\nDOWNLOADED_MODEL_PATH = '../input/longformerbase4096'\n\n# Model name\n#MODEL_NAME = \"../input/huggingface-bert/bert-base-cased\"\n\n# NER target file\nTARGET = '../input/ner-target-for-feedback-prize-competition'","metadata":{"execution":{"iopub.status.busy":"2022-02-27T02:51:38.464768Z","iopub.execute_input":"2022-02-27T02:51:38.465042Z","iopub.status.idle":"2022-02-27T02:51:38.471975Z","shell.execute_reply.started":"2022-02-27T02:51:38.465002Z","shell.execute_reply":"2022-02-27T02:51:38.471252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First, I will make a baseline using BERT\n\nBERT can only process a max of 512 input tokens lenght.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenize Training set","metadata":{}},{"cell_type":"markdown","source":"First we need to converts training dataset into a NER token array that we can use to train a NER transformer.","metadata":{}},{"cell_type":"code","source":"# Make an array of training texts name\nIDS = train.id.unique()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T02:51:38.474807Z","iopub.execute_input":"2022-02-27T02:51:38.475567Z","iopub.status.idle":"2022-02-27T02:51:38.496112Z","shell.execute_reply.started":"2022-02-27T02:51:38.475527Z","shell.execute_reply":"2022-02-27T02:51:38.495347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 1024 # BERT limit\n\n# THE TOKENS AND ATTENTION ARRAYS\ntokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH)\ntrain_tokens = np.zeros((len(IDS),MAX_LEN), dtype='int32')\ntrain_attention = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n\n# THE 14 CLASSES FOR NER\nlead_b = np.zeros((len(IDS),MAX_LEN))\nlead_i = np.zeros((len(IDS),MAX_LEN))\n\nposition_b = np.zeros((len(IDS),MAX_LEN))\nposition_i = np.zeros((len(IDS),MAX_LEN))\n\nevidence_b = np.zeros((len(IDS),MAX_LEN))\nevidence_i = np.zeros((len(IDS),MAX_LEN))\n\nclaim_b = np.zeros((len(IDS),MAX_LEN))\nclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nconclusion_b = np.zeros((len(IDS),MAX_LEN))\nconclusion_i = np.zeros((len(IDS),MAX_LEN))\n\ncounterclaim_b = np.zeros((len(IDS),MAX_LEN))\ncounterclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nrebuttal_b = np.zeros((len(IDS),MAX_LEN))\nrebuttal_i = np.zeros((len(IDS),MAX_LEN))\n\n# HELPER VARIABLES\ntrain_lens = []\ntargets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\ntargets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}","metadata":{"execution":{"iopub.status.busy":"2022-02-27T02:51:38.497893Z","iopub.execute_input":"2022-02-27T02:51:38.498451Z","iopub.status.idle":"2022-02-27T02:51:38.663782Z","shell.execute_reply.started":"2022-02-27T02:51:38.498412Z","shell.execute_reply":"2022-02-27T02:51:38.663022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"txt = open('../input/feedback-prize-2021/train/423A1CA112E2.txt', 'r').read()\ntxt","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:25:50.640458Z","iopub.execute_input":"2022-02-23T08:25:50.641067Z","iopub.status.idle":"2022-02-23T08:25:50.661906Z","shell.execute_reply.started":"2022-02-23T08:25:50.641021Z","shell.execute_reply":"2022-02-23T08:25:50.661197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens = tokenizer(txt, max_length = MAX_LEN, padding = 'max_length',\n                        truncation = True, return_offsets_mapping = True)\noffsets = tokens['offset_mapping']\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:25:53.188504Z","iopub.execute_input":"2022-02-23T08:25:53.188943Z","iopub.status.idle":"2022-02-23T08:25:53.231057Z","shell.execute_reply.started":"2022-02-23T08:25:53.188907Z","shell.execute_reply":"2022-02-23T08:25:53.230318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = 0\nfor i in offsets:\n    if i != (0,0):\n        s += 1\ns","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:25:56.006137Z","iopub.execute_input":"2022-02-23T08:25:56.006803Z","iopub.status.idle":"2022-02-23T08:25:56.013261Z","shell.execute_reply.started":"2022-02-23T08:25:56.006766Z","shell.execute_reply":"2022-02-23T08:25:56.012316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets_b[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:29:20.760822Z","iopub.execute_input":"2022-02-23T08:29:20.761159Z","iopub.status.idle":"2022-02-23T08:29:20.766811Z","shell.execute_reply.started":"2022-02-23T08:29:20.761108Z","shell.execute_reply":"2022-02-23T08:29:20.765971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FOR LOOP THROUGH EACH TRAIN TEXT\nfor id_num in range(len(IDS)):\n    \n    # Run and save the target for the first time\n    if TARGET:\n        break\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    \n    # loop through each text, store its length to the train_lens\n    n = IDS[id_num]\n    name = f'../input/feedback-prize-2021/train/{n}.txt'\n    txt = open(name, 'r').read()\n    #train_lens.append(len(txt.split()))\n    \n    #tokenize the text\n    tokens = tokenizer(txt, max_length = MAX_LEN, padding = 'max_length',\n                        truncation = True, return_offsets_mapping = True)\n    #save token of the text to the train_tokens array\n    train_tokens[id_num,] = tokens['input_ids']\n    #save attention mask to the train_attention array\n    train_attention[id_num,] = tokens['attention_mask']\n    \n    # FIND TARGETS IN TEXT AND SAVE IN TARGET ARRAYS\n    \n    #loop through offset_mapping to asign each token to a class\n    offsets = tokens['offset_mapping']\n    offset_index = 0\n    df = train.loc[train.id == n]\n    for index,row in df.iterrows():\n        a = row.discourse_start\n        b = row.discourse_end\n        if offset_index > MAX_LEN - 1:\n            break\n        c = offsets[offset_index][0] \n        d = offsets[offset_index][1]\n        beginning = True\n        while b > c:\n            if (c >= a) & (b >= d):\n                k = target_map[row.discourse_type]\n                if beginning:\n                    targets_b[k][id_num][offset_index] = 1\n                    beginning = False\n                else:\n                    targets_i[k][id_num][offset_index] = 1\n            offset_index += 1\n            if offset_index > MAX_LEN - 1:\n                break\n            c = offsets[offset_index][0]\n            d = offsets[offset_index][1]","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:35:17.213661Z","iopub.execute_input":"2022-02-25T03:35:17.214344Z","iopub.status.idle":"2022-02-25T03:35:17.225117Z","shell.execute_reply.started":"2022-02-25T03:35:17.214294Z","shell.execute_reply":"2022-02-25T03:35:17.224348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the NER target if it is created\nif TARGET is None:\n    targets = np.zeros((len(IDS),MAX_LEN,15), dtype='int32')\n    for k in range(7):\n        targets[:,:,2*k] = targets_b[k]\n        targets[:,:,2*k+1] = targets_i[k]\n    targets[:,:,14] = 1 - np.max(targets,axis = -1)\n    np.save(f'targets_{MAX_LEN}', targets)\n    np.save(f'tokens_{MAX_LEN}', train_tokens)\n    np.save(f'attention_{MAX_LEN}', train_attention)\n    print('Saved NER tokens')\nelse:\n    targets = np.load(f'{TARGET}/targets_{MAX_LEN}.npy')\n    train_tokens = np.load(f'{TARGET}/tokens_{MAX_LEN}.npy')\n    train_attention = np.load(f'{TARGET}/attention_{MAX_LEN}.npy')\n    print('Loaded NER tokens')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T02:51:38.666737Z","iopub.execute_input":"2022-02-27T02:51:38.666952Z","iopub.status.idle":"2022-02-27T02:51:45.278314Z","shell.execute_reply.started":"2022-02-27T02:51:38.666923Z","shell.execute_reply":"2022-02-27T02:51:45.276837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Model\nWe will use LongFormer backbone and add our own NER head using one hidden layer of size 256 and one final layer with softmax. We use 15 classes because we have a B class and I class for each of 7 labels. And we have an additional class (called O class) for tokens that do not belong to one of the 14 classes.","metadata":{}},{"cell_type":"code","source":"DOWNLOADED_MODEL_PATH","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:40:57.524228Z","iopub.execute_input":"2022-02-25T03:40:57.524824Z","iopub.status.idle":"2022-02-25T03:40:57.529768Z","shell.execute_reply.started":"2022-02-25T03:40:57.524788Z","shell.execute_reply":"2022-02-25T03:40:57.529127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\nattention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n\nconfig = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \nbackbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T02:53:52.629033Z","iopub.execute_input":"2022-02-27T02:53:52.629421Z","iopub.status.idle":"2022-02-27T02:54:02.098513Z","shell.execute_reply.started":"2022-02-27T02:53:52.629384Z","shell.execute_reply":"2022-02-27T02:54:02.097803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx = backbone(tokens, attention_mask=attention)\nx = tf.keras.layers.Dense(256, activation='relu')(x[0])\nx = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n\nmodel = tf.keras.Model(inputs=[tokens,attention], outputs=x)\nmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4),\n              loss = ['categorical_crossentropy'],\n              metrics = ['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-27T02:54:02.100125Z","iopub.execute_input":"2022-02-27T02:54:02.100859Z","iopub.status.idle":"2022-02-27T02:54:17.894399Z","shell.execute_reply.started":"2022-02-27T02:54:02.100817Z","shell.execute_reply":"2022-02-27T02:54:17.893626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model","metadata":{"execution":{"iopub.status.busy":"2022-02-27T03:02:01.349998Z","iopub.execute_input":"2022-02-27T03:02:01.350255Z","iopub.status.idle":"2022-02-27T03:02:01.355138Z","shell.execute_reply.started":"2022-02-27T03:02:01.350225Z","shell.execute_reply":"2022-02-27T03:02:01.354352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\nmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.5e-4),\n              loss = ['categorical_crossentropy'],\n              metrics = ['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-27T03:02:01.516774Z","iopub.execute_input":"2022-02-27T03:02:01.517367Z","iopub.status.idle":"2022-02-27T03:02:01.541772Z","shell.execute_reply.started":"2022-02-27T03:02:01.517324Z","shell.execute_reply":"2022-02-27T03:02:01.541115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    \n    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n    \n    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)\n    \n    x = backbone(tokens, attention_mask=attention)\n    x = tf.keras.layers.Dense(256, activation='relu')(x[0])\n    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n    \n    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4),\n                  loss = ['categorical_crossentropy'],\n                  metrics = ['categorical_accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:34:03.656432Z","iopub.execute_input":"2022-02-23T08:34:03.656993Z","iopub.status.idle":"2022-02-23T08:34:03.664703Z","shell.execute_reply.started":"2022-02-23T08:34:03.656956Z","shell.execute_reply":"2022-02-23T08:34:03.663765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:34:10.09128Z","iopub.execute_input":"2022-02-23T08:34:10.091551Z","iopub.status.idle":"2022-02-23T08:34:34.059007Z","shell.execute_reply.started":"2022-02-23T08:34:10.091504Z","shell.execute_reply":"2022-02-23T08:34:34.058225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\nEPOCHS = 4\nBATCH_SIZE = 4\nLRS = [0.25e-4, 0.1e-4, 0.75e-4, 0.5e-5] \ndef lrfn(epoch):\n    return LRS[epoch]\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:34:34.060403Z","iopub.execute_input":"2022-02-23T08:34:34.060655Z","iopub.status.idle":"2022-02-23T08:34:34.066855Z","shell.execute_reply.started":"2022-02-23T08:34:34.060621Z","shell.execute_reply":"2022-02-23T08:34:34.066075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN VALID SPLIT 90% 10%\nnp.random.seed(6)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)\nprint('Train size',len(train_idx),', Valid size',len(valid_idx))","metadata":{"execution":{"iopub.status.busy":"2022-02-27T02:54:17.896151Z","iopub.execute_input":"2022-02-27T02:54:17.896447Z","iopub.status.idle":"2022-02-27T02:54:17.907688Z","shell.execute_reply.started":"2022-02-27T02:54:17.896404Z","shell.execute_reply":"2022-02-27T02:54:17.906874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train['id'].isin(IDS[valid_idx])].shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-25T09:52:54.49559Z","iopub.execute_input":"2022-02-25T09:52:54.495847Z","iopub.status.idle":"2022-02-25T09:52:54.524417Z","shell.execute_reply.started":"2022-02-25T09:52:54.495819Z","shell.execute_reply":"2022-02-25T09:52:54.523694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train['id'].isin(IDS[valid_idx])]","metadata":{"execution":{"iopub.status.busy":"2022-02-25T09:53:21.103535Z","iopub.execute_input":"2022-02-25T09:53:21.10381Z","iopub.status.idle":"2022-02-25T09:53:21.14734Z","shell.execute_reply.started":"2022-02-25T09:53:21.103781Z","shell.execute_reply":"2022-02-25T09:53:21.146684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train['id'].isin(IDS[valid_idx])]['discourse_type'].value_counts(ascending = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T09:41:55.795139Z","iopub.execute_input":"2022-02-25T09:41:55.795811Z","iopub.status.idle":"2022-02-25T09:41:55.828235Z","shell.execute_reply.started":"2022-02-25T09:41:55.795777Z","shell.execute_reply":"2022-02-25T09:41:55.827487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[~train['id'].isin(IDS[train_idx])]['discourse_type'].value_counts(ascending = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T09:41:32.409161Z","iopub.execute_input":"2022-02-25T09:41:32.409648Z","iopub.status.idle":"2022-02-25T09:41:32.432747Z","shell.execute_reply.started":"2022-02-25T09:41:32.409613Z","shell.execute_reply":"2022-02-25T09:41:32.432025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train['id'].isin(IDS[train_idx])]['discourse_type'].value_counts(ascending = True).plot(kind = 'barh')\nplt.title('Number of each Discourse Type in Training Set', fontsize = 16, pad = 15)\nplt.ylabel('')\nplt.xlabel('Frequency');","metadata":{"execution":{"iopub.status.busy":"2022-02-25T09:58:40.997725Z","iopub.execute_input":"2022-02-25T09:58:40.998323Z","iopub.status.idle":"2022-02-25T09:58:41.226895Z","shell.execute_reply.started":"2022-02-25T09:58:40.998161Z","shell.execute_reply":"2022-02-25T09:58:41.22613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[~train['id'].isin(IDS[train_idx])]['discourse_type'].value_counts(ascending = True).plot(kind = 'barh')\nplt.title('Number of each Discourse Type in Validation Set', fontsize = 16, pad = 15)\nplt.ylabel('')\nplt.xlabel('Frequency');","metadata":{"execution":{"iopub.status.busy":"2022-02-25T09:58:38.699464Z","iopub.execute_input":"2022-02-25T09:58:38.699681Z","iopub.status.idle":"2022-02-25T09:58:38.906596Z","shell.execute_reply.started":"2022-02-25T09:58:38.699649Z","shell.execute_reply":"2022-02-25T09:58:38.905964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['discourse_type'].value_counts(ascending = True, normalize = True)/train[train['id'].isin(IDS[train_idx])]['discourse_type'].value_counts(ascending = True, normalize = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:37:10.885788Z","iopub.execute_input":"2022-02-25T03:37:10.886476Z","iopub.status.idle":"2022-02-25T03:37:10.951735Z","shell.execute_reply.started":"2022-02-25T03:37:10.886436Z","shell.execute_reply":"2022-02-25T03:37:10.950915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train['id'].isin(IDS[train_idx])]['discourse_type'].value_counts(ascending = True, normalize = True)/train[~train['id'].isin(IDS[train_idx])]['discourse_type'].value_counts(ascending = True, normalize = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T03:37:11.060625Z","iopub.execute_input":"2022-02-25T03:37:11.060833Z","iopub.status.idle":"2022-02-25T03:37:11.117872Z","shell.execute_reply.started":"2022-02-25T03:37:11.060809Z","shell.execute_reply":"2022-02-25T03:37:11.117073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.get_config()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T03:01:04.422925Z","iopub.execute_input":"2022-02-27T03:01:04.423209Z","iopub.status.idle":"2022-02-27T03:01:04.439708Z","shell.execute_reply.started":"2022-02-27T03:01:04.423177Z","shell.execute_reply":"2022-02-27T03:01:04.439022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T02:58:10.774036Z","iopub.execute_input":"2022-02-27T02:58:10.774354Z","iopub.status.idle":"2022-02-27T02:58:10.802227Z","shell.execute_reply.started":"2022-02-27T02:58:10.77431Z","shell.execute_reply":"2022-02-27T02:58:10.801254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n          y = targets[train_idx,],\n          validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n                         targets[valid_idx,]),\n          epochs = 5,\n          batch_size = 4,\n          verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T03:02:11.786104Z","iopub.execute_input":"2022-02-27T03:02:11.786378Z","iopub.status.idle":"2022-02-27T08:46:00.148424Z","shell.execute_reply.started":"2022-02-27T03:02:11.786344Z","shell.execute_reply":"2022-02-27T08:46:00.147609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(history.history)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T08:56:31.258075Z","iopub.execute_input":"2022-02-27T08:56:31.258491Z","iopub.status.idle":"2022-02-27T08:56:31.26451Z","shell.execute_reply.started":"2022-02-27T08:56:31.258454Z","shell.execute_reply":"2022-02-27T08:56:31.263766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('Accuracy 4th training')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T08:56:33.626877Z","iopub.execute_input":"2022-02-27T08:56:33.627376Z","iopub.status.idle":"2022-02-27T08:56:33.635812Z","shell.execute_reply.started":"2022-02-27T08:56:33.627336Z","shell.execute_reply":"2022-02-27T08:56:33.635017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot(y = ['categorical_accuracy', 'val_categorical_accuracy'], figsize = (12, 7))\nplt.xlabel(\"Epochs\")\nplt.ylabel('Accuracy')\nplt.title('Accuracy vs. epochs');","metadata":{"execution":{"iopub.status.busy":"2022-02-27T08:56:37.218779Z","iopub.execute_input":"2022-02-27T08:56:37.219507Z","iopub.status.idle":"2022-02-27T08:56:37.533848Z","shell.execute_reply.started":"2022-02-27T08:56:37.219466Z","shell.execute_reply":"2022-02-27T08:56:37.533153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot(y = ['loss', 'val_loss'], figsize = (12, 7))\nplt.xlabel(\"Epochs\")\nplt.ylabel('Loss')\nplt.title('Loss vs. epochs');","metadata":{"execution":{"iopub.status.busy":"2022-02-27T08:56:37.558214Z","iopub.execute_input":"2022-02-27T08:56:37.558717Z","iopub.status.idle":"2022-02-27T08:56:37.812723Z","shell.execute_reply.started":"2022-02-27T08:56:37.558682Z","shell.execute_reply":"2022-02-27T08:56:37.812029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('long_v4.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T08:57:00.8842Z","iopub.execute_input":"2022-02-27T08:57:00.884588Z","iopub.status.idle":"2022-02-27T08:57:02.288455Z","shell.execute_reply.started":"2022-02-27T08:57:00.884553Z","shell.execute_reply":"2022-02-27T08:57:02.287555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOAD_MODEL_FROM = '../input/trained-model-for-feedback-prize-competition'\nVER = 1","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:34:49.562134Z","iopub.execute_input":"2022-02-23T08:34:49.562966Z","iopub.status.idle":"2022-02-23T08:34:49.566724Z","shell.execute_reply.started":"2022-02-23T08:34:49.562903Z","shell.execute_reply":"2022-02-23T08:34:49.565517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_MODEL_FROM:\n    model.load_weights(f'{LOAD_MODEL_FROM}/long_v{VER}.h5')\n    \n# OR TRAIN MODEL\nelse:\n    history = model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n              y = targets[train_idx,],\n              validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n                             targets[valid_idx,]),\n              callbacks = [lr_callback],\n              epochs = EPOCHS,\n              batch_size = BATCH_SIZE,\n              verbose = 1)\n\n    # SAVE MODEL WEIGHTS\n    model.save_weights(f'long_v{VER}.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-23T08:34:57.578893Z","iopub.execute_input":"2022-02-23T08:34:57.579608Z","iopub.status.idle":"2022-02-23T13:10:25.67462Z","shell.execute_reply.started":"2022-02-23T08:34:57.579568Z","shell.execute_reply":"2022-02-23T13:10:25.673843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validate Model","metadata":{}},{"cell_type":"markdown","source":"We will now make predictions on the validation texts. Our model makes label predictions for each token, we need to convert this into a list of word indices for each label. Note that the tokens and words are not the same. A single word may be broken into multiple tokens. Therefore we need to first create a map to change token indices to word indices.","metadata":{}},{"cell_type":"code","source":"p = model.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n                  batch_size=16, verbose=1)\nprint('Validation predictions shape:',p.shape)\noof_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:10:25.676556Z","iopub.execute_input":"2022-02-23T13:10:25.67681Z","iopub.status.idle":"2022-02-23T13:14:03.072456Z","shell.execute_reply.started":"2022-02-23T13:10:25.676777Z","shell.execute_reply":"2022-02-23T13:14:03.071673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#turn from class number to class name\ntarget_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:14:03.073906Z","iopub.execute_input":"2022-02-23T13:14:03.074321Z","iopub.status.idle":"2022-02-23T13:14:03.080259Z","shell.execute_reply.started":"2022-02-23T13:14:03.074283Z","shell.execute_reply":"2022-02-23T13:14:03.079555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(dataset='train', verbose=True, text_ids = IDS[valid_idx], preds = oof_preds):\n    all_predictions = []\n\n    for id_num in range(len(preds)):\n\n        n = text_ids[id_num]\n    \n        # GET TOKEN POSITIONS IN CHARS\n        name = f'../input/feedback-prize-2021/{dataset}/{n}.txt'\n        txt = open(name, 'r').read()\n        tokens = tokenizer.encode_plus(txt, max_length = MAX_LEN, padding = 'max_length',\n                                   truncation = True, return_offsets_mapping = True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n                w.append(i)\n                blank = False\n            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n                blank = True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(MAX_LEN,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0:\n                continue\n            while off[i][0]>=w[w_i+1]:\n                w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        ### KEY: ###\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n        pred = preds[id_num,]/2.0\n    \n        i = 0\n        while i < MAX_LEN:\n            prediction = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                i += 1\n                if i >= MAX_LEN:\n                    break\n                while pred[i] == start + 0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    i += 1\n                    if i >= MAX_LEN:\n                        break\n            else:\n                i += 1\n            prediction = [x for x in prediction if x!=-1]\n            if len(prediction) > 4:\n                all_predictions.append((n, target_map_rev[int(start)], \n                                ' '.join([str(x) for x in prediction])))\n                \n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class','predictionstring']\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:16:47.678945Z","iopub.execute_input":"2022-02-23T13:16:47.679213Z","iopub.status.idle":"2022-02-23T13:16:47.69508Z","shell.execute_reply.started":"2022-02-23T13:16:47.679183Z","shell.execute_reply":"2022-02-23T13:16:47.694143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = get_preds(dataset = 'train', verbose = True, text_ids = IDS[valid_idx])\noof.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:16:51.348171Z","iopub.execute_input":"2022-02-23T13:16:51.348425Z","iopub.status.idle":"2022-02-23T13:17:13.099065Z","shell.execute_reply.started":"2022-02-23T13:16:51.348397Z","shell.execute_reply":"2022-02-23T13:17:13.098261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compute Validation Metric","metadata":{}},{"cell_type":"code","source":"# CODE FROM : Rob Mulla @robikscube\n# https://www.kaggle.com/robikscube/student-writing-competition-twitch\ndef calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(' '))\n    set_gt = set(row.predictionstring_gt.split(' '))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter/ len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df = pred_df[['id','class','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df['pred_id'] = pred_df.index\n    gt_df['gt_id'] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(gt_df,\n                           left_on=['id','class'],\n                           right_on=['id','discourse_type'],\n                           how='outer',\n                           suffixes=('_pred','_gt')\n                          )\n    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n\n    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n    tp_pred_ids = joined.query('potential_TP') \\\n        .sort_values('max_overlap', ascending=False) \\\n        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    #calc microf1\n    my_f1_score = TP / (TP + 0.5*(FP+FN))\n    return my_f1_score","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:17:13.117075Z","iopub.execute_input":"2022-02-23T13:17:13.117596Z","iopub.status.idle":"2022-02-23T13:17:13.134328Z","shell.execute_reply.started":"2022-02-23T13:17:13.117559Z","shell.execute_reply":"2022-02-23T13:17:13.133588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VALID DATAFRAME\nvalid = train.loc[train['id'].isin(IDS[valid_idx])]","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:17:13.137979Z","iopub.execute_input":"2022-02-23T13:17:13.138204Z","iopub.status.idle":"2022-02-23T13:17:13.172435Z","shell.execute_reply.started":"2022-02-23T13:17:13.138169Z","shell.execute_reply":"2022-02-23T13:17:13.171712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\n\nprint('Validation F1_score:')\nfor c in CLASSES:\n    pred_df = oof.loc[oof['class'] == c].copy()\n    gt_df = valid.loc[valid['discourse_type'] == c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c + ':', round(f1, 3))\n    f1s.append(f1)\nprint()\nprint('Overall',round(np.mean(f1s), 3))","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:17:15.20296Z","iopub.execute_input":"2022-02-23T13:17:15.203232Z","iopub.status.idle":"2022-02-23T13:17:17.24348Z","shell.execute_reply.started":"2022-02-23T13:17:15.203195Z","shell.execute_reply":"2022-02-23T13:17:17.242721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Infer Test Data\nWe will now infer the test data and create a submission.","metadata":{}},{"cell_type":"code","source":"# GET TEST TEXT IDS\nfiles = os.listdir('../input/feedback-prize-2021/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\nprint('There are',len(TEST_IDS),'test texts.')","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:17:17.244871Z","iopub.execute_input":"2022-02-23T13:17:17.245113Z","iopub.status.idle":"2022-02-23T13:17:17.254244Z","shell.execute_reply.started":"2022-02-23T13:17:17.245079Z","shell.execute_reply":"2022-02-23T13:17:17.25348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT TEST TEXT TO TOKENS\ntest_tokens = np.zeros((len(TEST_IDS), MAX_LEN), dtype='int32')\ntest_attention = np.zeros((len(TEST_IDS), MAX_LEN), dtype='int32')\n\nfor id_num in range(len(TEST_IDS)):\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = TEST_IDS[id_num]\n    name = f'../input/feedback-prize-2021/test/{n}.txt'\n    txt = open(name, 'r').read()\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    test_tokens[id_num,] = tokens['input_ids']\n    test_attention[id_num,] = tokens['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:17:30.26039Z","iopub.execute_input":"2022-02-23T13:17:30.260965Z","iopub.status.idle":"2022-02-23T13:17:30.303944Z","shell.execute_reply.started":"2022-02-23T13:17:30.26092Z","shell.execute_reply":"2022-02-23T13:17:30.303221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER TEST TEXTS\np = model.predict([test_tokens, test_attention], \n                  batch_size=16, verbose=2)\nprint('Test predictions shape:',p.shape)\ntest_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:17:32.174097Z","iopub.execute_input":"2022-02-23T13:17:32.174939Z","iopub.status.idle":"2022-02-23T13:17:32.813857Z","shell.execute_reply.started":"2022-02-23T13:17:32.174888Z","shell.execute_reply":"2022-02-23T13:17:32.81304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Write Submission CSV","metadata":{}},{"cell_type":"code","source":"# GET TEST PREDICIONS\nsub = get_preds( dataset='test', verbose=False, text_ids=TEST_IDS, preds=test_preds )\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:17:37.372621Z","iopub.execute_input":"2022-02-23T13:17:37.372899Z","iopub.status.idle":"2022-02-23T13:17:37.454546Z","shell.execute_reply.started":"2022-02-23T13:17:37.372869Z","shell.execute_reply":"2022-02-23T13:17:37.453846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:17:42.098128Z","iopub.execute_input":"2022-02-23T13:17:42.098392Z","iopub.status.idle":"2022-02-23T13:17:42.110424Z","shell.execute_reply.started":"2022-02-23T13:17:42.098363Z","shell.execute_reply":"2022-02-23T13:17:42.10974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WRITE SUBMISSION CSV\nsub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T13:18:38.83323Z","iopub.execute_input":"2022-02-23T13:18:38.833704Z","iopub.status.idle":"2022-02-23T13:18:38.842305Z","shell.execute_reply.started":"2022-02-23T13:18:38.833664Z","shell.execute_reply":"2022-02-23T13:18:38.841578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}