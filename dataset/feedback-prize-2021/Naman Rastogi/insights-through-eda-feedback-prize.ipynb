{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom collections import defaultdict\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n%matplotlib inline\n\nimport re\nimport string\nimport spacy\n\n# misc:\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tqdm as tqdm\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:04:07.162883Z","iopub.execute_input":"2022-01-31T08:04:07.163162Z","iopub.status.idle":"2022-01-31T08:04:07.171701Z","shell.execute_reply.started":"2022-01-31T08:04:07.163131Z","shell.execute_reply":"2022-01-31T08:04:07.17098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Path and configuration class","metadata":{}},{"cell_type":"code","source":"class Config:\n    \n    def __init__(self):\n        \n        # hyperparameters\n        \n        # paths\n        self.train_file_path = '../input/feedback-prize-2021/train.csv'\n        self.train_path = '../input/feedback-prize-2021/train'\n        self.test_path = '../input/feedback-prize-2021/test'\n        self.model_save_path = '.'\n        \n        # others\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:05:40.571939Z","iopub.execute_input":"2022-01-31T08:05:40.572244Z","iopub.status.idle":"2022-01-31T08:05:40.577664Z","shell.execute_reply.started":"2022-01-31T08:05:40.572212Z","shell.execute_reply":"2022-01-31T08:05:40.576446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf = Config()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:05:43.11738Z","iopub.execute_input":"2022-01-31T08:05:43.117801Z","iopub.status.idle":"2022-01-31T08:05:43.120858Z","shell.execute_reply.started":"2022-01-31T08:05:43.11777Z","shell.execute_reply":"2022-01-31T08:05:43.120225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: The terms 'discourse type(s)' and 'classe(s)' are used interchangeably.","metadata":{}},{"cell_type":"markdown","source":"# Exploration","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(conf.train_file_path)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:05:45.96627Z","iopub.execute_input":"2022-01-31T08:05:45.966706Z","iopub.status.idle":"2022-01-31T08:05:48.107176Z","shell.execute_reply.started":"2022-01-31T08:05:45.966675Z","shell.execute_reply":"2022-01-31T08:05:48.10645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pd.set_option('display.max_colwidth', -1)  # to make dataframe take up the whole width of the screen","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:05:50.828651Z","iopub.execute_input":"2022-01-31T08:05:50.829392Z","iopub.status.idle":"2022-01-31T08:05:50.852349Z","shell.execute_reply.started":"2022-01-31T08:05:50.829342Z","shell.execute_reply":"2022-01-31T08:05:50.851497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.predictionstring[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:05:54.822643Z","iopub.execute_input":"2022-01-31T08:05:54.822933Z","iopub.status.idle":"2022-01-31T08:05:54.831525Z","shell.execute_reply.started":"2022-01-31T08:05:54.822903Z","shell.execute_reply":"2022-01-31T08:05:54.83095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:05:56.363008Z","iopub.execute_input":"2022-01-31T08:05:56.363668Z","iopub.status.idle":"2022-01-31T08:05:56.432886Z","shell.execute_reply.started":"2022-01-31T08:05:56.363635Z","shell.execute_reply":"2022-01-31T08:05:56.431992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total number of unique text files\nlen(train_df['id'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:05:58.172575Z","iopub.execute_input":"2022-01-31T08:05:58.173013Z","iopub.status.idle":"2022-01-31T08:05:58.187079Z","shell.execute_reply.started":"2022-01-31T08:05:58.172966Z","shell.execute_reply":"2022-01-31T08:05:58.18645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample discourse text\ntrain_df['discourse_text'][0]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:05:59.578663Z","iopub.execute_input":"2022-01-31T08:05:59.57911Z","iopub.status.idle":"2022-01-31T08:05:59.58523Z","shell.execute_reply.started":"2022-01-31T08:05:59.579062Z","shell.execute_reply":"2022-01-31T08:05:59.584437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# utility for printing the text\ndef print_text(txt_id):\n    with open(f'{conf.train_path}/{txt_id}.txt', 'r') as fp:\n        text = fp.readlines()\n    print(''.join(text))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:00.96206Z","iopub.execute_input":"2022-01-31T08:06:00.962733Z","iopub.status.idle":"2022-01-31T08:06:00.966886Z","shell.execute_reply.started":"2022-01-31T08:06:00.962666Z","shell.execute_reply":"2022-01-31T08:06:00.966086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# corresponding text for above discourse text\nprint_text('423A1CA112E2')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:03.096033Z","iopub.execute_input":"2022-01-31T08:06:03.096315Z","iopub.status.idle":"2022-01-31T08:06:03.109657Z","shell.execute_reply.started":"2022-01-31T08:06:03.096285Z","shell.execute_reply":"2022-01-31T08:06:03.108961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classes\ntrain_df['discourse_type'].unique().tolist()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-31T08:06:05.246856Z","iopub.execute_input":"2022-01-31T08:06:05.247623Z","iopub.status.idle":"2022-01-31T08:06:05.261169Z","shell.execute_reply.started":"2022-01-31T08:06:05.247573Z","shell.execute_reply":"2022-01-31T08:06:05.260402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['Lead', 'Position', 'Evidence', 'Claim', 'Counterclaim', 'Rebuttal', 'Concluding Statement']","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:06.850004Z","iopub.execute_input":"2022-01-31T08:06:06.850631Z","iopub.status.idle":"2022-01-31T08:06:06.855826Z","shell.execute_reply.started":"2022-01-31T08:06:06.850582Z","shell.execute_reply":"2022-01-31T08:06:06.854734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discourse_type_num = train_df['discourse_type_num'].unique().tolist()\ndiscourse_type_num[0:5]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:08.253093Z","iopub.execute_input":"2022-01-31T08:06:08.253542Z","iopub.status.idle":"2022-01-31T08:06:08.26836Z","shell.execute_reply.started":"2022-01-31T08:06:08.253502Z","shell.execute_reply":"2022-01-31T08:06:08.267495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Let's see how many times a particular class appeared at maximum in some text(s) with maximum taken across all texts:</b>","metadata":{}},{"cell_type":"code","source":"# This function returns a list, where each index in the list correspond to a particular class (as in the list \n# classes declared above). Each entry in the returned list represents the maximum number of times a class has appeared in some\n# text(s).\n\ndef get_list_of_max(classes, discourse_type_num):\n    list_of_max = []\n\n    for _class in classes:\n        mx=0\n        for _type in discourse_type_num:\n            if _type[-1:].isdigit() and _type[-2:].isdigit():\n                if _class == _type[:-3]:\n                    curr = _type[-2:]\n                    mx = max(mx, int(curr))\n            else:\n                if _class == _type[:-2]:\n                    curr = _type[-1:]\n                    mx = max(mx, int(curr))\n            \n        list_of_max.append(mx)\n        \n    return list_of_max","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-31T08:06:10.724963Z","iopub.execute_input":"2022-01-31T08:06:10.725754Z","iopub.status.idle":"2022-01-31T08:06:10.731997Z","shell.execute_reply.started":"2022-01-31T08:06:10.725708Z","shell.execute_reply":"2022-01-31T08:06:10.731366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the maximum frequencies of all classes\nlist_of_max = get_list_of_max(classes, discourse_type_num)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:13.264226Z","iopub.execute_input":"2022-01-31T08:06:13.264847Z","iopub.status.idle":"2022-01-31T08:06:13.268724Z","shell.execute_reply.started":"2022-01-31T08:06:13.264803Z","shell.execute_reply":"2022-01-31T08:06:13.267905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7,5))\n\nax = sns.barplot(x=list_of_max, y=classes)\nax.set_xlabel('max frequency')\nax.set_ylabel('classes')\nax.set_title('Maximum number of times a class can be present in a text')\n\n# we can see from below graph that evidence and claim have appeared a maximum of 12 times in some text(s)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:15.182152Z","iopub.execute_input":"2022-01-31T08:06:15.18245Z","iopub.status.idle":"2022-01-31T08:06:15.444176Z","shell.execute_reply.started":"2022-01-31T08:06:15.182402Z","shell.execute_reply":"2022-01-31T08:06:15.443372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Distribution of classes across all rows of the dataframe:</b><br><br>\nNote that the train_df also contains multiple rows for the same text, and a particular discourse type, as we know, can occur multiple times (as shown in the column discourse_type_num) in any given text, therefore the count axis in the below plot takes into account all those multiple occurences of a discourse type of the same text.\n<br><br>\nWe see that the evidence and the claim are the dominant discourse types with rebuttal and concluding statement being the rare ones.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(9,7))\nsns.set_context('paper',font_scale=1.5)\nax = sns.countplot(x='discourse_type', data=train_df)\nax.set_xticklabels(classes, rotation=40, ha='right');","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:18.749624Z","iopub.execute_input":"2022-01-31T08:06:18.749921Z","iopub.status.idle":"2022-01-31T08:06:19.057503Z","shell.execute_reply.started":"2022-01-31T08:06:18.749889Z","shell.execute_reply":"2022-01-31T08:06:19.056634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Let's have a look at class distribution when considering only single instances of classes (discourse_type) in any given text.</b>","metadata":{}},{"cell_type":"code","source":"dframe = train_df.drop_duplicates(subset = ['id', 'discourse_type'], keep = 'first', inplace = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:21.952262Z","iopub.execute_input":"2022-01-31T08:06:21.952537Z","iopub.status.idle":"2022-01-31T08:06:21.995474Z","shell.execute_reply.started":"2022-01-31T08:06:21.952507Z","shell.execute_reply":"2022-01-31T08:06:21.994791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:23.762844Z","iopub.execute_input":"2022-01-31T08:06:23.763629Z","iopub.status.idle":"2022-01-31T08:06:23.777437Z","shell.execute_reply.started":"2022-01-31T08:06:23.763573Z","shell.execute_reply":"2022-01-31T08:06:23.776868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dframe)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:25.687647Z","iopub.execute_input":"2022-01-31T08:06:25.688095Z","iopub.status.idle":"2022-01-31T08:06:25.693717Z","shell.execute_reply.started":"2022-01-31T08:06:25.688049Z","shell.execute_reply":"2022-01-31T08:06:25.693107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9,7))\nsns.set_context('paper',font_scale=1.5)\nax = sns.countplot(x='discourse_type', data=dframe)\nax.set_xticklabels(classes, rotation=40, ha='right');","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:27.519006Z","iopub.execute_input":"2022-01-31T08:06:27.519263Z","iopub.status.idle":"2022-01-31T08:06:27.80056Z","shell.execute_reply.started":"2022-01-31T08:06:27.519235Z","shell.execute_reply":"2022-01-31T08:06:27.799669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Distribution of the length of complete texts:</b>","metadata":{}},{"cell_type":"code","source":"df = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:30.575923Z","iopub.execute_input":"2022-01-31T08:06:30.576189Z","iopub.status.idle":"2022-01-31T08:06:30.596424Z","shell.execute_reply.started":"2022-01-31T08:06:30.576161Z","shell.execute_reply":"2022-01-31T08:06:30.595555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['full_text'] = df['discourse_text'].groupby(df['id']).transform(lambda x: ' '.join(x))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:32.354763Z","iopub.execute_input":"2022-01-31T08:06:32.355032Z","iopub.status.idle":"2022-01-31T08:06:33.982882Z","shell.execute_reply.started":"2022-01-31T08:06:32.354994Z","shell.execute_reply":"2022-01-31T08:06:33.982088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_length = df['full_text'].drop_duplicates().apply(len)\n\nfig = plt.figure(figsize=(9,7))\n\nax = sns.distplot(text_length, kde=False, bins=100, color='r')\nax.set_title('Distribution of Text Length')\nax.set_xlabel(\"Text Length\")\nax.set_ylabel(\"Frequency\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:35.83737Z","iopub.execute_input":"2022-01-31T08:06:35.837656Z","iopub.status.idle":"2022-01-31T08:06:36.248828Z","shell.execute_reply.started":"2022-01-31T08:06:35.837628Z","shell.execute_reply":"2022-01-31T08:06:36.247879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Distribution for word count:</b>","metadata":{}},{"cell_type":"code","source":"word_count = df['full_text'].drop_duplicates().apply(lambda x: len(str(x).split()))\n\nfig = plt.figure(figsize=(9,7))\n\nax = sns.distplot(word_count, kde=False, bins=100, color='r')\nax.set_title('Distribution of Word Count')\nax.set_xlabel(\"Word Count\")\nax.set_ylabel(\"Frequency\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:38.637488Z","iopub.execute_input":"2022-01-31T08:06:38.638635Z","iopub.status.idle":"2022-01-31T08:06:39.353381Z","shell.execute_reply.started":"2022-01-31T08:06:38.638582Z","shell.execute_reply":"2022-01-31T08:06:39.352509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Relation between discourse types and discourse length:</b>","metadata":{}},{"cell_type":"code","source":"df = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:42.390837Z","iopub.execute_input":"2022-01-31T08:06:42.391122Z","iopub.status.idle":"2022-01-31T08:06:42.417625Z","shell.execute_reply.started":"2022-01-31T08:06:42.39109Z","shell.execute_reply":"2022-01-31T08:06:42.416912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['discourse_len'] = df['discourse_text'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:43.794226Z","iopub.execute_input":"2022-01-31T08:06:43.794987Z","iopub.status.idle":"2022-01-31T08:06:44.2529Z","shell.execute_reply.started":"2022-01-31T08:06:43.79493Z","shell.execute_reply":"2022-01-31T08:06:44.251817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(6,5))\n\nax = fig.add_axes([0,0,1,1])\nax = df.groupby('discourse_type')['discourse_len'].mean().sort_values().plot(kind=\"barh\", color='lightseagreen')\nax.set_title(\"Average number of words versus Discourse Type\", fontsize=14)\nax.set_xlabel(\"Average number of words\", fontsize = 12)\nax.set_ylabel(\"\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:45.322364Z","iopub.execute_input":"2022-01-31T08:06:45.323037Z","iopub.status.idle":"2022-01-31T08:06:45.594565Z","shell.execute_reply.started":"2022-01-31T08:06:45.322987Z","shell.execute_reply":"2022-01-31T08:06:45.593694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distribution of discourse types over discourse length:","metadata":{}},{"cell_type":"code","source":"labels = ['Evidence', 'Concluding Statement', 'Lead', 'Rebuttal', 'Counterclaim', 'Position', 'Claim']\nfeature = 'discourse_len'\n\ndata = []\nfor i in range(len(labels)):\n    _data = df.loc[df['discourse_type'] == labels[i]][feature]\n    data.append(_data)\n    \nrows, cols = 4, 2\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize = (15, 27))\nfor idx, axis in enumerate(axes.reshape(-1)):\n    if idx<len(labels):\n        ax = sns.distplot(data[idx], ax = axis, color = 'lightseagreen')\n        ax.set_title(labels[idx])\n    if idx == len(labels):\n        axis.axis('off')  # for turning off the axis of the very last plot","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:47.645021Z","iopub.execute_input":"2022-01-31T08:06:47.645313Z","iopub.status.idle":"2022-01-31T08:06:50.476474Z","shell.execute_reply.started":"2022-01-31T08:06:47.64528Z","shell.execute_reply":"2022-01-31T08:06:50.475453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualization in a single plot:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12, 5))\nax = sns.kdeplot(data[0])\nax = sns.kdeplot(data[1])\nax = sns.kdeplot(data[2])\nax = sns.kdeplot(data[3])\nax = sns.kdeplot(data[4])\nax = sns.kdeplot(data[5])\nax = sns.kdeplot(data[6])\nax.legend(labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:51.46026Z","iopub.execute_input":"2022-01-31T08:06:51.461151Z","iopub.status.idle":"2022-01-31T08:06:52.512693Z","shell.execute_reply.started":"2022-01-31T08:06:51.461107Z","shell.execute_reply":"2022-01-31T08:06:52.511777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Relation between discourse types and frequency of unique words in each discourse text:</b> ","metadata":{}},{"cell_type":"code","source":"df['unique_words_count'] = train_df['discourse_text'].apply(lambda x: len(set(str(x).split())))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:56.047356Z","iopub.execute_input":"2022-01-31T08:06:56.047756Z","iopub.status.idle":"2022-01-31T08:06:57.073453Z","shell.execute_reply.started":"2022-01-31T08:06:56.047726Z","shell.execute_reply":"2022-01-31T08:06:57.072773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(6,5))\n\nax = fig.add_axes([0,0,1,1])\nax = df.groupby('discourse_type')['unique_words_count'].mean().sort_values().plot(kind=\"barh\", color='mediumturquoise')\nax.set_title(\"Unique number of words versus Discourse Type\", fontsize=14)\nax.set_xlabel(\"Unique number of words\", fontsize = 12)\nax.set_ylabel(\"\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:06:59.804272Z","iopub.execute_input":"2022-01-31T08:06:59.804542Z","iopub.status.idle":"2022-01-31T08:06:59.994043Z","shell.execute_reply.started":"2022-01-31T08:06:59.804513Z","shell.execute_reply":"2022-01-31T08:06:59.993148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distribution of discourse types over count of unique words in discourse texts:","metadata":{}},{"cell_type":"code","source":"labels = ['Evidence', 'Concluding Statement', 'Lead', 'Rebuttal', 'Counterclaim', 'Position', 'Claim']\nfeature = 'unique_words_count'\n\ndata = []\nfor i in range(len(labels)):\n    _data = df.loc[df['discourse_type'] == labels[i]][feature]\n    data.append(_data)\n    \nrows, cols = 4, 2\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize = (15, 27))\nfor idx, axis in enumerate(axes.reshape(-1)):\n    if idx<len(labels):\n        ax = sns.distplot(data[idx], ax = axis, color = 'teal')\n        ax.set_title(labels[idx])\n    if idx == len(labels):  \n        axis.axis('off')  # for turning off the axis of the very last plot","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:01.843726Z","iopub.execute_input":"2022-01-31T08:07:01.844011Z","iopub.status.idle":"2022-01-31T08:07:04.606644Z","shell.execute_reply.started":"2022-01-31T08:07:01.843983Z","shell.execute_reply":"2022-01-31T08:07:04.60548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualization in a single plot:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12, 5))\nax = sns.kdeplot(data[0])\nax = sns.kdeplot(data[1])\nax = sns.kdeplot(data[2])\nax = sns.kdeplot(data[3])\nax = sns.kdeplot(data[4])\nax = sns.kdeplot(data[5])\nax = sns.kdeplot(data[6])\nax.legend(labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:08.415216Z","iopub.execute_input":"2022-01-31T08:07:08.415776Z","iopub.status.idle":"2022-01-31T08:07:09.502971Z","shell.execute_reply.started":"2022-01-31T08:07:08.415734Z","shell.execute_reply":"2022-01-31T08:07:09.50216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Relation between discourse types and average word length of discourse texts:</b>","metadata":{}},{"cell_type":"code","source":"df['avg_word_length'] = train_df['discourse_text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:12.888309Z","iopub.execute_input":"2022-01-31T08:07:12.888611Z","iopub.status.idle":"2022-01-31T08:07:16.191478Z","shell.execute_reply.started":"2022-01-31T08:07:12.888577Z","shell.execute_reply":"2022-01-31T08:07:16.190216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(6,5))\n\nax = fig.add_axes([0,0,1,1])\nax = df.groupby('discourse_type')['avg_word_length'].mean().sort_values().plot(kind=\"barh\", color='steelblue')\nax.set_title(\"Average word length versus Discourse Type\", fontsize=14)\nax.set_xlabel(\"Average word length\", fontsize = 12)\nax.set_ylabel(\"\")","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:16.193383Z","iopub.execute_input":"2022-01-31T08:07:16.193709Z","iopub.status.idle":"2022-01-31T08:07:16.455015Z","shell.execute_reply.started":"2022-01-31T08:07:16.193669Z","shell.execute_reply":"2022-01-31T08:07:16.454094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distribution of discourse types over the average word lengths of discourse texts:","metadata":{}},{"cell_type":"code","source":"labels = ['Evidence', 'Concluding Statement', 'Lead', 'Rebuttal', 'Counterclaim', 'Position', 'Claim']\nfeature = 'avg_word_length'\n\ndata = []\nfor i in range(len(labels)):\n    _data = df.loc[df['discourse_type'] == labels[i]][feature]\n    data.append(_data)\n    \nrows, cols = 4, 2\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize = (15, 27))\nfor idx, axis in enumerate(axes.reshape(-1)):\n    if idx<len(labels):\n        ax = sns.distplot(data[idx], ax = axis, color = 'steelblue')\n        ax.set_title(labels[idx])\n    if idx == len(labels):  \n        axis.axis('off')  # for turning off the axis of the very last plot","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:18.690099Z","iopub.execute_input":"2022-01-31T08:07:18.690392Z","iopub.status.idle":"2022-01-31T08:07:21.574012Z","shell.execute_reply.started":"2022-01-31T08:07:18.690358Z","shell.execute_reply":"2022-01-31T08:07:21.573278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visulization in a single plot:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12, 5))\nax = sns.kdeplot(data[0])\nax = sns.kdeplot(data[1])\nax = sns.kdeplot(data[2])\nax = sns.kdeplot(data[3])\nax = sns.kdeplot(data[4])\nax = sns.kdeplot(data[5])\nax = sns.kdeplot(data[6])\nax.legend(labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:24.438811Z","iopub.execute_input":"2022-01-31T08:07:24.439078Z","iopub.status.idle":"2022-01-31T08:07:25.503631Z","shell.execute_reply.started":"2022-01-31T08:07:24.439049Z","shell.execute_reply":"2022-01-31T08:07:25.502709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Visualizing the start and end positions of discourse texts:</b>","metadata":{}},{"cell_type":"code","source":"data_df = train_df.groupby(\"discourse_type\")[['discourse_end', 'discourse_start']].mean().reset_index().sort_values(\n    by = 'discourse_start', \n    ascending = False)\n\ndata_df.plot(x='discourse_type',\n        kind='barh',\n        stacked=False,\n        title='Average start and end position absolute',\n        figsize=(12,4))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:27.6985Z","iopub.execute_input":"2022-01-31T08:07:27.698775Z","iopub.status.idle":"2022-01-31T08:07:27.954826Z","shell.execute_reply.started":"2022-01-31T08:07:27.69874Z","shell.execute_reply":"2022-01-31T08:07:27.953779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Punctuations:</b>","metadata":{}},{"cell_type":"code","source":"# creating temporary corpus for analysing punctuations and stopwords:\ndef temporary_corpus(target = None):\n    corpus=[]\n    \n    if target == None:\n        text_data = train_df['discourse_text'].str.split()\n    else:\n        text_data = train_df[train_df['discourse_type']==target]['discourse_text'].str.split()\n        \n    for text in text_data:\n        for char in text:\n            corpus.append(char)\n    return corpus","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:29.792515Z","iopub.execute_input":"2022-01-31T08:07:29.792806Z","iopub.status.idle":"2022-01-31T08:07:29.798991Z","shell.execute_reply.started":"2022-01-31T08:07:29.79277Z","shell.execute_reply":"2022-01-31T08:07:29.797787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\ncorpus=temporary_corpus()\n\ndic=defaultdict(int)\nspecial = string.punctuation\nfor token in corpus:\n    for character in token:\n        if character in special:\n            dic[character]+=1\n        \nx,y=zip(*dic.items())\nplt.bar(x,y, color='cadetblue')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:31.469298Z","iopub.execute_input":"2022-01-31T08:07:31.46993Z","iopub.status.idle":"2022-01-31T08:07:36.249916Z","shell.execute_reply.started":"2022-01-31T08:07:31.46988Z","shell.execute_reply":"2022-01-31T08:07:36.249061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Stopwords (with reference to spacy's stopwords list):</b>","metadata":{}},{"cell_type":"code","source":"import en_core_web_lg\nnlp=en_core_web_lg.load()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:36.251291Z","iopub.execute_input":"2022-01-31T08:07:36.251734Z","iopub.status.idle":"2022-01-31T08:07:41.152427Z","shell.execute_reply.started":"2022-01-31T08:07:36.251698Z","shell.execute_reply":"2022-01-31T08:07:41.151698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus = temporary_corpus()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:47.274927Z","iopub.execute_input":"2022-01-31T08:07:47.275614Z","iopub.status.idle":"2022-01-31T08:07:49.101395Z","shell.execute_reply.started":"2022-01-31T08:07:47.275576Z","shell.execute_reply":"2022-01-31T08:07:49.100682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_frequent_stopwords(corpus):\n    \n    dic=defaultdict(int)\n    for word in corpus:\n        if word in nlp.Defaults.stop_words:\n            dic[word]+=1\n\n    # getting the top 20 most frequent stop words        \n    top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:20]\n    \n    return top, dic","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:54.11744Z","iopub.execute_input":"2022-01-31T08:07:54.117877Z","iopub.status.idle":"2022-01-31T08:07:54.124363Z","shell.execute_reply.started":"2022-01-31T08:07:54.117845Z","shell.execute_reply":"2022-01-31T08:07:54.123497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top, dic = get_frequent_stopwords(corpus)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:56.848237Z","iopub.execute_input":"2022-01-31T08:07:56.848554Z","iopub.status.idle":"2022-01-31T08:07:58.039338Z","shell.execute_reply.started":"2022-01-31T08:07:56.848516Z","shell.execute_reply":"2022-01-31T08:07:58.038453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Total number of stop words in spacy: {len(nlp.Defaults.stop_words)}')\nprint(f'Total number of stop words in the given text data which are part of the spacy\\'s stop words list: {len(dic)}')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:07:59.153918Z","iopub.execute_input":"2022-01-31T08:07:59.154207Z","iopub.status.idle":"2022-01-31T08:07:59.159703Z","shell.execute_reply.started":"2022-01-31T08:07:59.154173Z","shell.execute_reply":"2022-01-31T08:07:59.158746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top 20 most frequent stop words in our corpus:\nplt.figure(figsize = (15,4))\nx,y=zip(*top)\nplt.bar(x,y, color='goldenrod')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:00.813627Z","iopub.execute_input":"2022-01-31T08:08:00.814577Z","iopub.status.idle":"2022-01-31T08:08:01.118751Z","shell.execute_reply.started":"2022-01-31T08:08:00.814529Z","shell.execute_reply":"2022-01-31T08:08:01.117649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distribution of discourse types over stopword counts:","metadata":{}},{"cell_type":"code","source":"def get_count(text):\n    count=0\n    for ch in text:\n        if ch in nlp.Defaults.stop_words:\n            count+=1\n    return count","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:02.78346Z","iopub.execute_input":"2022-01-31T08:08:02.784051Z","iopub.status.idle":"2022-01-31T08:08:02.788956Z","shell.execute_reply.started":"2022-01-31T08:08:02.784002Z","shell.execute_reply":"2022-01-31T08:08:02.788102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = train_df.copy()\ndf['stop_words_count'] = train_df['discourse_text'].apply(lambda x: get_count(x))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:04.603011Z","iopub.execute_input":"2022-01-31T08:08:04.603542Z","iopub.status.idle":"2022-01-31T08:08:07.903876Z","shell.execute_reply.started":"2022-01-31T08:08:04.603506Z","shell.execute_reply":"2022-01-31T08:08:07.90306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Evidence', 'Concluding Statement', 'Lead', 'Rebuttal', 'Counterclaim', 'Position', 'Claim']\n\ndata = []\nfor i in range(len(labels)):\n    _data = df.loc[df['discourse_type'] == labels[i]]['stop_words_count']\n    data.append(_data)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:07.905463Z","iopub.execute_input":"2022-01-31T08:08:07.905711Z","iopub.status.idle":"2022-01-31T08:08:08.010288Z","shell.execute_reply.started":"2022-01-31T08:08:07.905681Z","shell.execute_reply":"2022-01-31T08:08:08.009529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 5))\nax = sns.kdeplot(data[0])\nax = sns.kdeplot(data[1])\nax = sns.kdeplot(data[2])\nax = sns.kdeplot(data[3])\nax = sns.kdeplot(data[4])\nax = sns.kdeplot(data[5])\nax = sns.kdeplot(data[6])\nax.legend(labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:09.896112Z","iopub.execute_input":"2022-01-31T08:08:09.896591Z","iopub.status.idle":"2022-01-31T08:08:11.006686Z","shell.execute_reply.started":"2022-01-31T08:08:09.896555Z","shell.execute_reply":"2022-01-31T08:08:11.005204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>n-grams analysis:</b>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:14.030755Z","iopub.execute_input":"2022-01-31T08:08:14.031059Z","iopub.status.idle":"2022-01-31T08:08:14.079805Z","shell.execute_reply.started":"2022-01-31T08:08:14.031027Z","shell.execute_reply":"2022-01-31T08:08:14.078882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_n_grams(n_grams, top_n = 10):\n    \n    df_words = pd.DataFrame()\n    \n    for dt in train_df['discourse_type'].unique():\n        \n        df = train_df.query('discourse_type == @dt')\n        texts = df['discourse_text'].tolist()\n        vec = CountVectorizer(lowercase = True, stop_words = 'english',\\\n                              ngram_range=(n_grams, n_grams)).fit(texts)\n        bag_of_words = vec.transform(texts)\n        sum_words = bag_of_words.sum(axis=0)\n        words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n        cvec_df = pd.DataFrame.from_records(words_freq,\\\n                                            columns= ['words', 'counts']).sort_values(by=\"counts\", ascending=False)\n        cvec_df.insert(0, \"Discourse_type\", dt)\n        cvec_df = cvec_df.iloc[:top_n,:]\n        df_words = df_words.append(cvec_df)\n        \n    return df_words","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:15.794019Z","iopub.execute_input":"2022-01-31T08:08:15.794275Z","iopub.status.idle":"2022-01-31T08:08:15.80273Z","shell.execute_reply.started":"2022-01-31T08:08:15.794246Z","shell.execute_reply":"2022-01-31T08:08:15.801612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unigrams = get_n_grams(n_grams = 1, top_n=10)\nunigrams.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-31T08:08:18.717441Z","iopub.execute_input":"2022-01-31T08:08:18.717729Z","iopub.status.idle":"2022-01-31T08:08:27.572307Z","shell.execute_reply.started":"2022-01-31T08:08:18.717694Z","shell.execute_reply":"2022-01-31T08:08:27.571398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_ngram(df, type = \"unigrams\"):\n    \n    plt.figure(figsize=(15, 12))\n    plt.subplots_adjust(hspace=0.5)\n\n    for n, dt in enumerate(df.Discourse_type.unique()):\n        ax = plt.subplot(4, 2, n + 1)\n        ax.set_title(f\"Most used {type} in {dt}\")\n        data = df.query('Discourse_type == @dt')[['words', 'counts']].set_index(\"words\").sort_values(by = \"counts\", ascending = True)\n        data.plot(ax=ax, kind = 'barh', color = 'steelblue')\n        plt.ylabel(\"\")\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:29.537884Z","iopub.execute_input":"2022-01-31T08:08:29.538326Z","iopub.status.idle":"2022-01-31T08:08:29.544925Z","shell.execute_reply.started":"2022-01-31T08:08:29.538279Z","shell.execute_reply":"2022-01-31T08:08:29.543868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unigrams\nplot_ngram(unigrams)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:33.709576Z","iopub.execute_input":"2022-01-31T08:08:33.709883Z","iopub.status.idle":"2022-01-31T08:08:35.152654Z","shell.execute_reply.started":"2022-01-31T08:08:33.709847Z","shell.execute_reply":"2022-01-31T08:08:35.151641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bigrams\nbigrams = get_n_grams(n_grams = 2, top_n=10)\nplot_ngram(bigrams, 'bigrams')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:37.770639Z","iopub.execute_input":"2022-01-31T08:08:37.770957Z","iopub.status.idle":"2022-01-31T08:08:56.011119Z","shell.execute_reply.started":"2022-01-31T08:08:37.770921Z","shell.execute_reply":"2022-01-31T08:08:56.009897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trigrams\ntrigrams = get_n_grams(n_grams = 3, top_n=10)\nplot_ngram(trigrams, 'trigrams')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:08:58.913264Z","iopub.execute_input":"2022-01-31T08:08:58.913559Z","iopub.status.idle":"2022-01-31T08:09:21.7849Z","shell.execute_reply.started":"2022-01-31T08:08:58.913528Z","shell.execute_reply":"2022-01-31T08:09:21.783914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Text Visualization","metadata":{}},{"cell_type":"code","source":"train_files = os.listdir(conf.train_path)\ntest_files = os.listdir(conf.test_path)\n\nfor file in range(len(train_files)):\n    train_files[file] = str(conf.train_path) + \"/\" +  str(train_files[file])\nfor file in range(len(test_files)):\n    test_files[file] = str(conf.test_path) + \"/\" +  str(test_files[file])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:09:27.048685Z","iopub.execute_input":"2022-01-31T08:09:27.048968Z","iopub.status.idle":"2022-01-31T08:09:27.327637Z","shell.execute_reply.started":"2022-01-31T08:09:27.048938Z","shell.execute_reply":"2022-01-31T08:09:27.32666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files[40]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:09:28.801323Z","iopub.execute_input":"2022-01-31T08:09:28.801953Z","iopub.status.idle":"2022-01-31T08:09:28.808595Z","shell.execute_reply.started":"2022-01-31T08:09:28.801886Z","shell.execute_reply":"2022-01-31T08:09:28.807478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files[40][35:-4]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:09:56.69351Z","iopub.execute_input":"2022-01-31T08:09:56.694063Z","iopub.status.idle":"2022-01-31T08:09:56.699953Z","shell.execute_reply.started":"2022-01-31T08:09:56.694013Z","shell.execute_reply":"2022-01-31T08:09:56.699275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = 20\nents = []\n \nfor i, row in train_df[train_df['id'] == train_files[r][35:-4]].iterrows():\n    ents.append({\n                    'start': int(row['discourse_start']),   \n                     'end': int(row['discourse_end']), \n                     'label': row['discourse_type']\n                })\n\nwith open(train_files[r], 'r') as file: \n    data = file.read()\n\ndoc2 = {\n    \"text\": data,\n    \"ents\": ents,\n}\n\ncolors = {'Lead': 'turquoise',\n          'Position': '#f9d5de',\n          'Claim': '#adcfad',\n          'Evidence': 'wheat',\n          'Counterclaim': '#bdf2fa',\n          'Concluding Statement': '#eea69e',\n          'Rebuttal': '#d1f8f4'}\n\noptions = {\"ents\": train_df.discourse_type.unique().tolist(), \"colors\": colors}\nspacy.displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T08:10:03.387388Z","iopub.execute_input":"2022-01-31T08:10:03.387668Z","iopub.status.idle":"2022-01-31T08:10:03.428147Z","shell.execute_reply.started":"2022-01-31T08:10:03.387638Z","shell.execute_reply":"2022-01-31T08:10:03.42724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### To be continued..","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}