{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport spacy\nimport string\nimport re\nfrom wordcloud import WordCloud\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-21T02:36:14.642938Z","iopub.execute_input":"2021-12-21T02:36:14.643632Z","iopub.status.idle":"2021-12-21T02:36:25.616731Z","shell.execute_reply.started":"2021-12-21T02:36:14.643525Z","shell.execute_reply":"2021-12-21T02:36:25.615784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Look at the train.csv Data Frame","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')\ndf = df[['discourse_start','discourse_end','discourse_text','discourse_type']]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:25.618583Z","iopub.execute_input":"2021-12-21T02:36:25.618884Z","iopub.status.idle":"2021-12-21T02:36:27.530109Z","shell.execute_reply.started":"2021-12-21T02:36:25.618852Z","shell.execute_reply":"2021-12-21T02:36:27.529288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Shape of the Data Frame:","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:27.531307Z","iopub.execute_input":"2021-12-21T02:36:27.531543Z","iopub.status.idle":"2021-12-21T02:36:27.536732Z","shell.execute_reply.started":"2021-12-21T02:36:27.531514Z","shell.execute_reply":"2021-12-21T02:36:27.536197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unique target values:","metadata":{}},{"cell_type":"code","source":"df.discourse_type.unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:27.538193Z","iopub.execute_input":"2021-12-21T02:36:27.538794Z","iopub.status.idle":"2021-12-21T02:36:27.560853Z","shell.execute_reply.started":"2021-12-21T02:36:27.538757Z","shell.execute_reply":"2021-12-21T02:36:27.559914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## What does the Target Variables Mean?\nBasically, there are 7 types of discourse:\n- **Lead**: intro part to hook readers' attention; \n- **Position**: demonstrate you understand the other side's viewpoint, but you explain your own stance; \n- **Evidence**: provide the readers with facts/data to prove the argument is strong;\n- **Claim**: explain the overall thesis on the subject. The main argument is made in this part;\n- **Concluding Statement**: draw conclusion;\n- **Counterclaim**: the opposite perspective;\n- **Rebuttal**: evidence that disagrees with the counterclaim.\n\nAccording to [Purdue owl writing lab](https://owl.purdue.edu/owl/general_writing/academic_writing/establishing_arguments/organizing_your_argument.html).","metadata":{}},{"cell_type":"markdown","source":"## Target Variables Distribution","metadata":{}},{"cell_type":"code","source":"sns.set_theme(style=\"whitegrid\")\nplt.figure(figsize=(8,6))\nsns.barplot(y=df['discourse_type'].unique(),\n            x=df['discourse_type'].value_counts())\nplt.xlabel('Count of Discourse Type')\nplt.title('Discourse Type Distribution')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:27.562529Z","iopub.execute_input":"2021-12-21T02:36:27.563189Z","iopub.status.idle":"2021-12-21T02:36:27.863641Z","shell.execute_reply.started":"2021-12-21T02:36:27.563153Z","shell.execute_reply":"2021-12-21T02:36:27.862735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Position of Each Target Variables\n\nWhere does each element target start at the student's article? Where do they end? In this section, we will plot each element's position in an article.","metadata":{}},{"cell_type":"code","source":"fig = px.box(df, y='discourse_type', x='discourse_start',\n            title='Where Each Type Element Starts')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:27.864779Z","iopub.execute_input":"2021-12-21T02:36:27.865012Z","iopub.status.idle":"2021-12-21T02:36:29.739764Z","shell.execute_reply.started":"2021-12-21T02:36:27.864983Z","shell.execute_reply":"2021-12-21T02:36:29.737132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.box(df, y='discourse_type', x='discourse_end',\n            title='Where Each Type Element Ends')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:29.741059Z","iopub.execute_input":"2021-12-21T02:36:29.741352Z","iopub.status.idle":"2021-12-21T02:36:30.735461Z","shell.execute_reply.started":"2021-12-21T02:36:29.741318Z","shell.execute_reply":"2021-12-21T02:36:30.734323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter(df.sample(frac=0.01, random_state=20), x='discourse_start', y='discourse_end',\n            title='Correlation between Discourse Start and End',\n            opacity = 0.3,\n            color = 'discourse_type')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:30.736694Z","iopub.execute_input":"2021-12-21T02:36:30.736928Z","iopub.status.idle":"2021-12-21T02:36:30.848831Z","shell.execute_reply.started":"2021-12-21T02:36:30.736901Z","shell.execute_reply":"2021-12-21T02:36:30.847959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In conclusion, we can all agree that lead statement start usually at the beginning of an article, where as concluding statement usually is at the very end of an article.\n\nUsually, when a sentence start early, it will end early. So I am not suprised that there is an obvious linear correlation between start and end point for each types. However, there \"Evidence\" seems scattered more and 'Lead' usually is very short.","metadata":{}},{"cell_type":"markdown","source":"## How Long Are Each Type of Elements?","metadata":{}},{"cell_type":"code","source":"df['txt_len'] = df['discourse_text'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:30.84997Z","iopub.execute_input":"2021-12-21T02:36:30.850276Z","iopub.status.idle":"2021-12-21T02:36:31.280791Z","shell.execute_reply.started":"2021-12-21T02:36:30.850246Z","shell.execute_reply":"2021-12-21T02:36:31.280151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.box(df, y='discourse_type', x='txt_len',\n            title='Length of Each Type of Element')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:31.28286Z","iopub.execute_input":"2021-12-21T02:36:31.283653Z","iopub.status.idle":"2021-12-21T02:36:32.243905Z","shell.execute_reply.started":"2021-12-21T02:36:31.283605Z","shell.execute_reply":"2021-12-21T02:36:32.242867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove Stopwords, Tokenization and Lemmatization\n\nFirst, add a few customized stopwords:","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')\nstopwords = nlp.Defaults.stop_words\nprint(f'There are {len(stopwords)} default stop-words before customization.')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:32.245175Z","iopub.execute_input":"2021-12-21T02:36:32.24553Z","iopub.status.idle":"2021-12-21T02:36:32.851013Z","shell.execute_reply.started":"2021-12-21T02:36:32.245491Z","shell.execute_reply":"2021-12-21T02:36:32.850402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customized_stopwords = ['student', 'people', 'make', 'school', 'teacher', 'be', 'electoral', 'college', 'think']\n\nfor token in customized_stopwords:\n    stopwords.add(token)\n    nlp.vocab[token].is_stop = True\n    \nprint(f'There are {len(stopwords)} stop-words after customization.')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:32.851941Z","iopub.execute_input":"2021-12-21T02:36:32.852312Z","iopub.status.idle":"2021-12-21T02:36:32.858641Z","shell.execute_reply.started":"2021-12-21T02:36:32.852278Z","shell.execute_reply":"2021-12-21T02:36:32.857778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create tokenzer function from a given sentence\ndef clean_text(sentence):\n    # Remove nan, @username, punctuation, URL, or any non alpanumeric characters and seperate word using a single space.\n    sentence = sentence.lower()\n    sentence = ' '.join(re.sub(\"(nan)|(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \", sentence).split())\n    # Removing stop words and obtain the lemma\n    text = [ word.lemma_ for word in nlp(sentence) if not word.text in stopwords]\n    return ' '.join(text).strip()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:32.859837Z","iopub.execute_input":"2021-12-21T02:36:32.860576Z","iopub.status.idle":"2021-12-21T02:36:32.870411Z","shell.execute_reply.started":"2021-12-21T02:36:32.860543Z","shell.execute_reply":"2021-12-21T02:36:32.869698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply clean_text function to the column.\ndf['text_cleaned'] = df['discourse_text'].map(clean_text)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T02:36:32.871623Z","iopub.execute_input":"2021-12-21T02:36:32.872006Z","iopub.status.idle":"2021-12-21T03:00:28.882188Z","shell.execute_reply.started":"2021-12-21T02:36:32.871976Z","shell.execute_reply":"2021-12-21T03:00:28.881162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top 10 Uni-grams of the tf-idf of the Text","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Define a function returning the top words\ndef get_top_tf_idf_words(df = df, col = \"text\", use_idf = True, ngram_range =(1, 1), top_n= 10):\n    \n    tf_idf = TfidfVectorizer(#stop_words='english',\n        ngram_range = ngram_range, use_idf = use_idf)\n    \n    # Fit and transform the corpus\n    X_sparse_matrix = tf_idf.fit_transform(df[col])\n    feature_names = np.array(tf_idf.get_feature_names())\n    \n    # Generate the tf-idf matrix\n    tf_idf_sparse_matrix = tf_idf.transform(df[col])\n    \n    # Rank the matrix by tf-idf values and return the indices of the top_n values\n    sorted_idx = np.argsort(tf_idf_sparse_matrix.data)[:-(top_n+1):-1]\n    \n    # Return the feature names and corresponding tf_idf values in a df\n    return pd.DataFrame(\n    {'feature': feature_names[tf_idf_sparse_matrix.indices[sorted_idx]],\n     'tf_idf': tf_idf_sparse_matrix.data[sorted_idx],\n    })\n\nTOP_N = 10\ndf_text_lead = get_top_tf_idf_words(df = df[df['discourse_type']=='Lead'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_posi = get_top_tf_idf_words(df = df[df['discourse_type']=='Position'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_evid = get_top_tf_idf_words(df = df[df['discourse_type']=='Evidence'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_clai = get_top_tf_idf_words(df = df[df['discourse_type']=='Claim'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_cclu = get_top_tf_idf_words(df = df[df['discourse_type']=='Concluding Statement'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_cntr = get_top_tf_idf_words(df = df[df['discourse_type']=='Counterclaim'], col = \"discourse_text\", top_n= TOP_N)\ndf_text_rebt = get_top_tf_idf_words(df = df[df['discourse_type']=='Rebuttal'], col = \"discourse_text\", top_n= TOP_N)\n\nx=range(0, TOP_N)\n\nfig, ax = plt.subplots(7, 1, figsize = (10, 25))\nfig.suptitle('Top 10 Bigrams of the TF-IDF', fontsize= 18)\n\nax[0].plot(x, df_text_lead.tf_idf, 'bo')\nax[0].set_title('Lead', fontsize= 14)\nax[0].set_xticks(x)\nax[0].set_xticklabels(df_text_lead.feature, rotation='vertical', fontsize=10)\n\nax[1].plot(x, df_text_posi.tf_idf, 'bo')\nax[1].set_title('Position', fontsize= 14)\nax[1].set_xticks(x)\nax[1].set_xticklabels(df_text_posi.feature, rotation='vertical', fontsize=10)\n\nax[2].plot(x, df_text_evid.tf_idf, 'bo')\nax[2].set_title('Evidence', fontsize= 14)\nax[2].set_xticks(x)\nax[2].set_xticklabels(df_text_evid.feature, rotation='vertical', fontsize=10)\n\nax[3].plot(x, df_text_clai.tf_idf, 'bo')\nax[3].set_title('Claim', fontsize= 14)\nax[3].set_xticks(x)\nax[3].set_xticklabels(df_text_clai.feature, rotation='vertical', fontsize=10)\n\nax[4].plot(x, df_text_cclu.tf_idf, 'bo')\nax[4].set_title('Concluding Statement', fontsize= 14)\nax[4].set_xticks(x)\nax[4].set_xticklabels(df_text_cclu.feature, rotation='vertical', fontsize=10)\n\nax[5].plot(x, df_text_cntr.tf_idf, 'bo')\nax[5].set_title('Counterclaim', fontsize= 14)\nax[5].set_xticks(x)\nax[5].set_xticklabels(df_text_cntr.feature, rotation='vertical', fontsize=10)\n\nax[6].plot(x, df_text_rebt.tf_idf, 'bo')\nax[6].set_title('Rebuttal', fontsize= 14)\nax[6].set_xticks(x)\nax[6].set_xticklabels(df_text_rebt.feature, rotation='vertical', fontsize=10)\n\nfig.subplots_adjust(hspace=1.5)\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-12-21T03:00:28.884162Z","iopub.execute_input":"2021-12-21T03:00:28.884908Z","iopub.status.idle":"2021-12-21T03:00:41.158407Z","shell.execute_reply.started":"2021-12-21T03:00:28.884828Z","shell.execute_reply":"2021-12-21T03:00:41.157485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Word Clouds for each Type\nWordcloud before clean the text:","metadata":{}},{"cell_type":"code","source":"elem = df.discourse_type.unique().tolist()\n\nplt.figure(figsize=(15,10))\nfor i in range(1,8):\n    plt.subplot(4, 2, i)\n    plt.imshow(WordCloud().generate(' '.join(df[df.discourse_type == elem[i-1]].discourse_text.apply(lambda x: x.lower()))),\n               interpolation='bilinear')\n    plt.title(elem[i-1])\n    plt.axis('off')\nplt.suptitle('Wordcloud for Each Category before Clean')\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T03:00:41.159533Z","iopub.execute_input":"2021-12-21T03:00:41.159769Z","iopub.status.idle":"2021-12-21T03:01:01.15365Z","shell.execute_reply.started":"2021-12-21T03:00:41.15974Z","shell.execute_reply":"2021-12-21T03:01:01.152524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wordcloud after clean the text:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nfor i in range(1,8):\n    plt.subplot(4, 2, i)\n    plt.imshow(WordCloud().generate(' '.join(df[df.discourse_type == elem[i-1]].text_cleaned)),\n               interpolation='bilinear')\n    plt.title(elem[i-1])\n    plt.axis('off')\nplt.suptitle('Wordcloud for Each Category After Clean')\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T03:01:01.155361Z","iopub.execute_input":"2021-12-21T03:01:01.155709Z","iopub.status.idle":"2021-12-21T03:01:21.419471Z","shell.execute_reply.started":"2021-12-21T03:01:01.155666Z","shell.execute_reply":"2021-12-21T03:01:21.418559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}