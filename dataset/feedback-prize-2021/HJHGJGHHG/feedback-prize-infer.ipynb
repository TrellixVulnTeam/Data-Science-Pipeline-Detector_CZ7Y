{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## A Pytorch version NER Baseline [LB: 0.545]\n### Part of this kernel is from zzy's [Pytorch NER infer](https://www.kaggle.com/zzy990106/pytorch-ner-infer)\n\n### Training: [Feedback Prize Train](https://www.kaggle.com/hjhgjghhg/feedback-prize-train/edit/run/82681035)\n\n### Infer: This kernel\n\n### Upvote if you find this kernel useful!ðŸ¤—","metadata":{}},{"cell_type":"code","source":"import random\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, AdamW, get_scheduler","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:05:50.642061Z","iopub.execute_input":"2021-12-22T11:05:50.642642Z","iopub.status.idle":"2021-12-22T11:05:57.193217Z","shell.execute_reply.started":"2021-12-22T11:05:50.642512Z","shell.execute_reply":"2021-12-22T11:05:57.192402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"config = {\n    'fold_num': 5,\n    'seed': 1234,\n    #'model': 'roberta-base',\n    #'model': '../input/robertalarge',\n    'model': 'allenai/longformer-base-4096',\n    #'model': 'allenai/longformer-large-4096',\n    'max_len': 1024,\n    'epochs': 5,\n    'train_bs': 6,\n    'valid_bs': 6,\n    'lr': 3e-5,\n    'num_workers': 0,\n    'weight_decay': 1e-2,\n    'num_warmup_steps': 1000,\n    'lr_scheduler_type': 'linear',\n    'gradient_accumulation_steps': 1,\n}","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-12-22T11:05:57.19491Z","iopub.execute_input":"2021-12-22T11:05:57.195175Z","iopub.status.idle":"2021-12-22T11:05:57.202612Z","shell.execute_reply.started":"2021-12-22T11:05:57.195142Z","shell.execute_reply":"2021-12-22T11:05:57.20182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim',\n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\nlabels2index = {\n    'Lead': 1, 'Position': 3, 'Claim': 5, 'Counterclaim': 7, 'Rebuttal': 9, 'Evidence': 11, 'Concluding Statement': 13\n}\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:05:57.206711Z","iopub.execute_input":"2021-12-22T11:05:57.207101Z","iopub.status.idle":"2021-12-22T11:05:57.217428Z","shell.execute_reply.started":"2021-12-22T11:05:57.207065Z","shell.execute_reply":"2021-12-22T11:05:57.216593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nset_seed(config['seed'])\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-12-22T11:05:57.218561Z","iopub.execute_input":"2021-12-22T11:05:57.219191Z","iopub.status.idle":"2021-12-22T11:05:57.275809Z","shell.execute_reply.started":"2021-12-22T11:05:57.219152Z","shell.execute_reply":"2021-12-22T11:05:57.275111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tokenizer = AutoTokenizer.from_pretrained(config['model'], add_prefix_space=True)\ntokenizer = AutoTokenizer.from_pretrained('../input/test-notebook/roberta_trained', add_prefix_space=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:05:57.278353Z","iopub.execute_input":"2021-12-22T11:05:57.278577Z","iopub.status.idle":"2021-12-22T11:05:57.455755Z","shell.execute_reply.started":"2021-12-22T11:05:57.278545Z","shell.execute_reply":"2021-12-22T11:05:57.455076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, phase='Train'):\n        self.df = df\n        self.phase = phase\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        text = self.df.text.values[idx]\n        if self.phase == 'Train':\n            label = self.df.tagging.values[idx]\n            return {'text': text, 'label': label}\n        else:\n            return {'text': text}\n\n\ndef collate_fn(data):\n    input_ids, attention_mask = [], []\n    text = [item['text'] for item in data]\n    tokenized_inputs = tokenizer(\n        text,\n        max_length=config['max_len'],\n        padding='max_length',\n        truncation=True,\n        is_split_into_words=True,\n        return_tensors='pt'\n    )\n\n    if 'label' in data[0].keys():\n        label = [item['label'] for item in data]\n        tokenized_inputs['labels'] = torch.LongTensor(label)\n\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:05:57.457039Z","iopub.execute_input":"2021-12-22T11:05:57.45729Z","iopub.status.idle":"2021-12-22T11:05:57.466049Z","shell.execute_reply.started":"2021-12-22T11:05:57.457258Z","shell.execute_reply":"2021-12-22T11:05:57.465351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Model","metadata":{}},{"cell_type":"code","source":"#model = AutoModelForTokenClassification.from_pretrained(config['model'], num_labels=15).to(device)\n#model.load_state_dict(torch.load('../input/feedback-prize-train/roberta_trained/pytorch_model.bin'))\nmodel = AutoModelForTokenClassification.from_pretrained('../input/feedback-prize-train/roberta_trained/', num_labels=15).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:05:57.467336Z","iopub.execute_input":"2021-12-22T11:05:57.467782Z","iopub.status.idle":"2021-12-22T11:06:12.567768Z","shell.execute_reply.started":"2021-12-22T11:05:57.467748Z","shell.execute_reply":"2021-12-22T11:06:12.567033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Test Data","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\ntest_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:12.569728Z","iopub.execute_input":"2021-12-22T11:06:12.57024Z","iopub.status.idle":"2021-12-22T11:06:12.599613Z","shell.execute_reply.started":"2021-12-22T11:06:12.570202Z","shell.execute_reply":"2021-12-22T11:06:12.598963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/test'))):\n    test_names.append(f.replace('.txt', ''))\n    with open('../input/feedback-prize-2021/test/' + f, 'r', encoding='utf-8') as f:\n        text = ''\n        for line in f.readlines():\n            #text += line.replace('\\n', '').replace('\\xa0', '')\n            text += line.replace('\\n', ' ')\n        test_texts.append(text)\ntest_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\ntest_texts['text'] = test_texts['text'].apply(lambda x: x.split())\ntest_texts","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:12.600838Z","iopub.execute_input":"2021-12-22T11:06:12.601099Z","iopub.status.idle":"2021-12-22T11:06:12.648811Z","shell.execute_reply.started":"2021-12-22T11:06:12.60105Z","shell.execute_reply":"2021-12-22T11:06:12.648131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = MyDataset(test_texts, phase='Test')\ntest_iter = DataLoader(test_dataset, batch_size=config['valid_bs'], collate_fn=collate_fn, shuffle=False,\n                        num_workers=config['num_workers'])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:12.650042Z","iopub.execute_input":"2021-12-22T11:06:12.650453Z","iopub.status.idle":"2021-12-22T11:06:12.655554Z","shell.execute_reply.started":"2021-12-22T11:06:12.650417Z","shell.execute_reply":"2021-12-22T11:06:12.654523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"y_pred = []\n\nwith torch.no_grad():\n    model.eval()\n    tk = tqdm(test_iter, total=len(test_iter), position=0, leave=True)\n    for step, batch in enumerate(tk):\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        output = model(input_ids=batch['input_ids'],\n                       attention_mask=batch['attention_mask']).logits\n\n        y_pred.extend(output.argmax(-1).cpu().numpy())\n        \ny_pred = np.array(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:12.656797Z","iopub.execute_input":"2021-12-22T11:06:12.657204Z","iopub.status.idle":"2021-12-22T11:06:13.817731Z","shell.execute_reply.started":"2021-12-22T11:06:12.657169Z","shell.execute_reply":"2021-12-22T11:06:13.817048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred[0][:200]","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:13.818961Z","iopub.execute_input":"2021-12-22T11:06:13.819644Z","iopub.status.idle":"2021-12-22T11:06:13.826659Z","shell.execute_reply.started":"2021-12-22T11:06:13.819606Z","shell.execute_reply":"2021-12-22T11:06:13.825909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds = []\n\nfor i in tqdm(range(len(test_texts))):\n    idx = test_texts.id.values[i]\n    pred = ['']*(len(y_pred[i])-2)\n\n    for j in range(1, len(y_pred[i])-1):\n        pred[j-1] = labels[y_pred[i][j]]\n\n    pred = [x.replace('B-','').replace('I-','') for x in pred]\n    \n    j = 0\n    while j < len(pred):\n        cls = pred[j]\n        if cls == 'O':\n            j += 1\n        end = j + 1\n        while end < len(pred) and pred[end] == cls:\n            end += 1\n            \n        if cls != 'O' and cls != '' and end - j > 10:\n            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n        \n        j = end\n        \nfinal_preds[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:08:43.034563Z","iopub.execute_input":"2021-12-22T11:08:43.034957Z","iopub.status.idle":"2021-12-22T11:08:43.061822Z","shell.execute_reply.started":"2021-12-22T11:08:43.034919Z","shell.execute_reply":"2021-12-22T11:08:43.061026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(final_preds)\nsub.columns = test_df.columns\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:08:45.14944Z","iopub.execute_input":"2021-12-22T11:08:45.14969Z","iopub.status.idle":"2021-12-22T11:08:45.158528Z","shell.execute_reply.started":"2021-12-22T11:08:45.149662Z","shell.execute_reply":"2021-12-22T11:08:45.157593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:08:47.022913Z","iopub.execute_input":"2021-12-22T11:08:47.023192Z","iopub.status.idle":"2021-12-22T11:08:47.035615Z","shell.execute_reply.started":"2021-12-22T11:08:47.023162Z","shell.execute_reply":"2021-12-22T11:08:47.034826Z"},"trusted":true},"execution_count":null,"outputs":[]}]}