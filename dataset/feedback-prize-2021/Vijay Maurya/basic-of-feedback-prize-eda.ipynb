{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## [Kaggel Link](https://www.kaggle.com/c/feedback-prize-2021) ","metadata":{"id":"0-AVqEPmZPEH"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","metadata":{"id":"nDrw46t8zJSx","execution":{"iopub.status.busy":"2022-03-07T04:33:50.907804Z","iopub.execute_input":"2022-03-07T04:33:50.908676Z","iopub.status.idle":"2022-03-07T04:33:50.91345Z","shell.execute_reply.started":"2022-03-07T04:33:50.908623Z","shell.execute_reply":"2022-03-07T04:33:50.912242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df =pd.read_csv(\"../input/feedback-prize-2021/train.csv\")\ndf.head()","metadata":{"id":"kPHmYmBO0UW7","outputId":"d7b9e603-718c-4f9f-f0c8-490db6740c23","execution":{"iopub.status.busy":"2022-03-07T04:33:50.917951Z","iopub.execute_input":"2022-03-07T04:33:50.918224Z","iopub.status.idle":"2022-03-07T04:33:51.834498Z","shell.execute_reply.started":"2022-03-07T04:33:50.918186Z","shell.execute_reply":"2022-03-07T04:33:51.833533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 About Data\nThe dataset contains argumentative essays written by U.S students in grades 6-12. The essays were annotated by expert raters for elements commonly found in argumentative writing.\n\nOur task is to predict the human annotations. You will first need to segment each essay into discrete rhetorical and argumentative elements (i.e., discourse elements like Lead,Claim,Evidence etc) and then classify each element as one of the following:\n\n* **Lead** - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the readerâ€™s attention and point toward the thesis\n* **Position** - an opinion or conclusion on the main question\n* **Claim** - a claim that supports the position\n* **Counterclaim** - a claim that refutes another claim or gives an opposing reason to the position\n* **Rebuttal**  - a claim that refutes a counterclaim\n* **Evidence**  - ideas or examples that support claims, counterclaims, or rebuttals.\n* **Concluding Statement**  - a concluding statement that restates the claims\n\n\n.csv file containing the annotated version of all essays in the training set\n\n* **id** - ID code for essay response\n* **discourse_id** - ID code for discourse element\n* **discourse_start** - character position where discourse element begins in the essay response\n* **discourse_end** - character position where discourse element ends in the essay response\n* **discourse_text** - text of discourse element\n* **discourse_type** - classification of discourse element\n* **discourse_type_num** - enumerated class label of discourse element\n* **predictionstring** - the word indices of the training sample, as required for predictions","metadata":{"id":"t1q0BJqC9XML"}},{"cell_type":"code","source":"train_dir =\"../input/feedback-prize-2021/train\"\ntest_dir = \"../input/feedback-prize-2021/test\"","metadata":{"id":"fPnOhddiEAgz","execution":{"iopub.status.busy":"2022-03-07T04:33:51.836296Z","iopub.execute_input":"2022-03-07T04:33:51.836526Z","iopub.status.idle":"2022-03-07T04:33:51.843289Z","shell.execute_reply.started":"2022-03-07T04:33:51.8365Z","shell.execute_reply":"2022-03-07T04:33:51.842404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total number of Rows/Records : {len(df.id)} \")\nprint(f\"Total number of Files data in CSV : {len(df.groupby('id'))} \")\nprint(f\"=\"*50)\nprint(f\"Total Number of files in Train Folder : { len(os.listdir(train_dir))}\")\nprint(f\"Total Number of files in Test Folder : { len(os.listdir(test_dir))}\")","metadata":{"id":"88z3YYwn0vIS","outputId":"ef6abbdc-9e36-4dd9-aa81-578b894841f1","execution":{"iopub.status.busy":"2022-03-07T04:33:51.845337Z","iopub.execute_input":"2022-03-07T04:33:51.846467Z","iopub.status.idle":"2022-03-07T04:33:52.492698Z","shell.execute_reply.started":"2022-03-07T04:33:51.846417Z","shell.execute_reply":"2022-03-07T04:33:52.49181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 EDA","metadata":{"id":"X5uEcEgnEzBl"}},{"cell_type":"markdown","source":"According to above explantion in About Data we required to classify in above category","metadata":{"id":"lYPrekVKFQrU"}},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.title(\"Discourse_type Distribution in train Dataset\",fontsize=20)\nplt.xlabel(\"Classes\")\n# plt.xticks(rotation=60)\nplt.ylabel(\"Records Count\")\nplt.bar(df.discourse_type.value_counts().index,df.discourse_type.value_counts(),color=plt.rcParams['axes.prop_cycle'].by_key()['color'])\n# Adding count bar plot \nfor index,data in enumerate(list(df.discourse_type.value_counts())):\n  plt.text(x=index , y =data+1 , s=f\"{data}\" , fontdict=dict(fontsize=15), ha=\"center\",bbox=dict(facecolor='wheat',boxstyle='square',edgecolor='black',pad=0.1))\nplt.tight_layout()\nplt.show()","metadata":{"id":"rj3MHwZT0vOU","outputId":"40df639a-a80d-4043-e63a-0f19f3a43b33","execution":{"iopub.status.busy":"2022-03-07T04:33:52.494167Z","iopub.execute_input":"2022-03-07T04:33:52.494833Z","iopub.status.idle":"2022-03-07T04:33:52.851494Z","shell.execute_reply.started":"2022-03-07T04:33:52.494784Z","shell.execute_reply":"2022-03-07T04:33:52.850655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# discourse_type_num\nplt.rcParams[\"figure.figsize\"] = (15,8)\nplt.title(\"discourse_type_num Distribution in train Dataset\",fontsize=20)\nplt.xlabel(\"Classes\")\nplt.xticks(rotation=90)\nplt.ylabel(\"Records Count\")\nplt.bar(df.discourse_type_num.value_counts().index,df.discourse_type_num.value_counts(),color=plt.rcParams['axes.prop_cycle'].by_key()['color'])\n# Adding count bar plot \nfor index,data in enumerate(list(df.discourse_type_num.value_counts())):\n  plt.text(x=index , y =data+1 , s=f\"{data}\" , fontdict=dict(fontsize=8),rotation=90,ha=\"center\",bbox=dict(facecolor='wheat',boxstyle='square',edgecolor='black',pad=0.5))\nplt.tight_layout()\nplt.show()","metadata":{"id":"fOe3UFjk0vRG","outputId":"c0e8f80a-fee5-47b8-9a48-cd49527affd1","execution":{"iopub.status.busy":"2022-03-07T04:33:52.854647Z","iopub.execute_input":"2022-03-07T04:33:52.855262Z","iopub.status.idle":"2022-03-07T04:33:53.600228Z","shell.execute_reply.started":"2022-03-07T04:33:52.855211Z","shell.execute_reply":"2022-03-07T04:33:53.599492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read Text of File","metadata":{"id":"XObVPMBsavhJ"}},{"cell_type":"code","source":"# Reading files and checking how text is store in File\nimport os\nfrom IPython.display import display\nfor i in os.listdir(train_dir)[:2]:\n  print(f\"\\033[1m File Name is : {i} \\033[0m \")\n  with open(train_dir+'/'+i, 'r') as file: \n    data = file.read()\n    print(data,end=\"\\n\")\n  print(\"=\"*200)","metadata":{"id":"gIxU-w77auo0","outputId":"4fcecdd0-7caa-4609-9467-ae5b07d88300","execution":{"iopub.status.busy":"2022-03-07T04:33:53.601376Z","iopub.execute_input":"2022-03-07T04:33:53.601778Z","iopub.status.idle":"2022-03-07T04:33:53.627258Z","shell.execute_reply.started":"2022-03-07T04:33:53.601737Z","shell.execute_reply":"2022-03-07T04:33:53.626648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking Length of Every Document ","metadata":{"id":"1c68AZP7Ir21"}},{"cell_type":"code","source":"file_data =[]\nfor i in os.listdir(train_dir):\n  data={}\n  with open(train_dir+'/'+i,'r') as file:\n    text_data=file.read()\n    data['file_name']=i\n    data['text_data']=text_data\n  file_data.append(data)  \n\n## Converting Dict to Data Fram\nfile_df = pd.DataFrame(file_data)\nfile_df['text_len'] =file_df['text_data'].apply(len)\nfile_df.head()","metadata":{"id":"futg-JYgIvMb","outputId":"4b35844b-2d91-44b7-aea1-4b2c47b4bcb9","execution":{"iopub.status.busy":"2022-03-07T04:33:53.628433Z","iopub.execute_input":"2022-03-07T04:33:53.628977Z","iopub.status.idle":"2022-03-07T04:35:14.038421Z","shell.execute_reply.started":"2022-03-07T04:33:53.628941Z","shell.execute_reply":"2022-03-07T04:35:14.037556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title(\"Text len frequency in File\")\nplt.xlabel(\"Length of Text \")\nfile_df['text_len'].plot(kind='hist',bins=100)\nplt.show()","metadata":{"id":"j31N39ugSydh","outputId":"d9ea17a4-065e-4241-d5e4-f1d3fa7ae294","execution":{"iopub.status.busy":"2022-03-07T04:35:14.040016Z","iopub.execute_input":"2022-03-07T04:35:14.040763Z","iopub.status.idle":"2022-03-07T04:35:14.399193Z","shell.execute_reply.started":"2022-03-07T04:35:14.040716Z","shell.execute_reply":"2022-03-07T04:35:14.398237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see we are getting Documents text of more then average words let's check manually ","metadata":{"id":"UKTLresyWzms"}},{"cell_type":"code","source":"file_df[file_df['text_len']>8000]","metadata":{"id":"fgNTgWnOSygf","outputId":"8501b9dd-6b3e-4494-b12d-5481e1a7702c","execution":{"iopub.status.busy":"2022-03-07T04:35:14.400778Z","iopub.execute_input":"2022-03-07T04:35:14.401468Z","iopub.status.idle":"2022-03-07T04:35:14.416155Z","shell.execute_reply.started":"2022-03-07T04:35:14.40143Z","shell.execute_reply":"2022-03-07T04:35:14.414671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have checked few Files like 8895,5866 extra space with special HTML character like \\xa0  which should be removed you can see in below row\n\n---\n\n","metadata":{"id":"FpBRamdaXph-"}},{"cell_type":"code","source":"file_df[file_df['text_len']>6000].text_data.loc[11236]","metadata":{"id":"vq2e4j29XGRw","outputId":"172b9468-8567-49f5-c001-014765258109","execution":{"iopub.status.busy":"2022-03-07T04:35:49.732715Z","iopub.execute_input":"2022-03-07T04:35:49.733767Z","iopub.status.idle":"2022-03-07T04:35:49.740377Z","shell.execute_reply.started":"2022-03-07T04:35:49.733727Z","shell.execute_reply":"2022-03-07T04:35:49.7398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import unicodedata\nfile_data =[]\nfor i in os.listdir(train_dir):\n  data={}\n  with open(train_dir+'/'+i,'r') as file:\n    text_data=file.read()\n    data['file_name']=i\n    data['text_data']=unicodedata.normalize(\"NFKD\",text_data).strip() # Using this we are removing \\xa0  and Strip help to remove extra space\n  file_data.append(data)  \n\n## Converting Dict to Data Fram\nfile_df = pd.DataFrame(file_data)\nfile_df['text_len'] =file_df['text_data'].apply(len)\nfile_df.head()","metadata":{"id":"421hJvKOSyjE","outputId":"6843707a-1c06-4df4-b2a8-ec71e284feab","execution":{"iopub.status.busy":"2022-03-07T04:35:56.72071Z","iopub.execute_input":"2022-03-07T04:35:56.721014Z","iopub.status.idle":"2022-03-07T04:36:04.805146Z","shell.execute_reply.started":"2022-03-07T04:35:56.720981Z","shell.execute_reply":"2022-03-07T04:36:04.80434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title(\"Text len frequency in File\")\nplt.xlabel(\"Length of Text \")\nfile_df['text_len'].plot(kind='hist',bins=100)\nplt.show()","metadata":{"id":"2PRmjhBCSymI","outputId":"0be9919a-ca96-42a5-ac3b-ecef60330b75","execution":{"iopub.status.busy":"2022-03-07T04:36:07.614536Z","iopub.execute_input":"2022-03-07T04:36:07.615946Z","iopub.status.idle":"2022-03-07T04:36:08.184976Z","shell.execute_reply.started":"2022-03-07T04:36:07.615874Z","shell.execute_reply":"2022-03-07T04:36:08.183996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_df[file_df['text_len']>6000]","metadata":{"id":"3koN2TD5Ycon","outputId":"19d2101e-570f-4c44-9905-605b9a58e962","execution":{"iopub.status.busy":"2022-03-07T04:36:12.143302Z","iopub.execute_input":"2022-03-07T04:36:12.143593Z","iopub.status.idle":"2022-03-07T04:36:12.160604Z","shell.execute_reply.started":"2022-03-07T04:36:12.143563Z","shell.execute_reply":"2022-03-07T04:36:12.159355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Length and Label comparison","metadata":{"id":"1NP2eaC7agit"}},{"cell_type":"code","source":"df['discourse_len']=df['discourse_text'].apply(len)","metadata":{"id":"RvyD7GE0a-UI","execution":{"iopub.status.busy":"2022-03-07T04:36:15.692982Z","iopub.execute_input":"2022-03-07T04:36:15.693262Z","iopub.status.idle":"2022-03-07T04:36:15.760878Z","shell.execute_reply.started":"2022-03-07T04:36:15.693235Z","shell.execute_reply":"2022-03-07T04:36:15.759554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/erikbruin/nlp-on-student-writing-eda\nfrom matplotlib.ticker import FuncFormatter\n\nfig = plt.figure(figsize=(12,8))\n\nax1 = fig.add_subplot(211)\nax1 = df.groupby('discourse_type')['discourse_len'].mean().sort_values().plot(kind=\"barh\")\nax1.set_title(\"Average number of words versus Discourse Type\", fontsize=14, fontweight = 'bold')\nax1.set_xlabel(\"Average number of words\", fontsize = 10)\nax1.set_ylabel(\"\")\n\nax2 = fig.add_subplot(212)\nax2 = df.groupby('discourse_type')['discourse_type'].count().sort_values().plot(kind=\"barh\")\nax2.get_xaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ','))) #add thousands separator\nax2.set_title(\"Frequency of Discourse Type in all essays\", fontsize=14, fontweight = 'bold')\nax2.set_xlabel(\"Frequency\", fontsize = 10)\nax2.set_ylabel(\"\")\n\nplt.tight_layout(pad=2)\nplt.show()","metadata":{"id":"ux4dZdebZEW3","outputId":"5e8c89d7-26a1-4ad3-973f-2d837705f56c","execution":{"iopub.status.busy":"2022-03-07T04:36:17.565308Z","iopub.execute_input":"2022-03-07T04:36:17.566037Z","iopub.status.idle":"2022-03-07T04:36:18.022879Z","shell.execute_reply.started":"2022-03-07T04:36:17.565986Z","shell.execute_reply":"2022-03-07T04:36:18.021977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## visualize using Spacy","metadata":{"id":"ZPe3x48sitI0"}},{"cell_type":"markdown","source":"We are not able visualize data in color lower cases of labels so we did into upper case ","metadata":{"id":"RfizFrI1fxZY"}},{"cell_type":"code","source":"labels = df.discourse_type.unique().tolist()\nlabels = list(map(str.upper,labels))\nprint(labels)","metadata":{"id":"zXchuxTRmVA7","outputId":"305ba4fd-1c19-4f32-925a-ea684ac934ac","execution":{"iopub.status.busy":"2022-03-07T04:36:21.246405Z","iopub.execute_input":"2022-03-07T04:36:21.247161Z","iopub.status.idle":"2022-03-07T04:36:21.262838Z","shell.execute_reply.started":"2022-03-07T04:36:21.247115Z","shell.execute_reply":"2022-03-07T04:36:21.261818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/thedrcat/feedback-prize-eda-with-displacy\nimport spacy\nfrom spacy import displacy\n\n\ndef visualize(example):\n  colors = {\n\t\t\"LEAD\": \"#8000FF\",\n\t\t\"POSITION\": \"#2B7FF6\",\n\t\t\"EVIDENCE\": \"#2ADDDD\",\n\t\t'CLAIM': '#80FFB4',\n\t\t'CONCLUDING STATEMENT': 'D4DD80',\n\t\t'COUNTERCLAIM': '#FF8042',\n\t\t'REBUTTAL': '#FF0000'\n\t}\n  ents = []\n  for i, row in df[df['id'] == example].iterrows():\n      ents.append({\n                      'start': int(row['discourse_start']), \n                        'end': int(row['discourse_end']), \n                        'label': row['discourse_type'].upper() #upper case\n                  })\n  with open(train_dir+\"/\"+example+'.txt', 'r') as file: \n    data = file.read()\n  doc = {\n      \"text\": data,\n      \"ents\": ents,\n      \"title\": example\n  }\n  options = {\"ents\": labels, \"colors\": colors}\n  displacy.render(doc, style=\"ent\", options=options, manual=True, jupyter=True)","metadata":{"id":"dhDfoMiRZEZl","execution":{"iopub.status.busy":"2022-03-07T04:36:23.185477Z","iopub.execute_input":"2022-03-07T04:36:23.185827Z","iopub.status.idle":"2022-03-07T04:36:33.842539Z","shell.execute_reply.started":"2022-03-07T04:36:23.185793Z","shell.execute_reply":"2022-03-07T04:36:33.841384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df['id'].sample(n=5,random_state=10).values.tolist():\n  visualize(i)\n  print(\"\\n\\n\")\n  print(\"=\"*120)\n","metadata":{"id":"dyRD1R-OgOJW","outputId":"947c063d-7120-4694-ff54-c0ae0657c8b3","execution":{"iopub.status.busy":"2022-03-07T04:36:57.246407Z","iopub.execute_input":"2022-03-07T04:36:57.246747Z","iopub.status.idle":"2022-03-07T04:36:57.337822Z","shell.execute_reply.started":"2022-03-07T04:36:57.246715Z","shell.execute_reply":"2022-03-07T04:36:57.337023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From above visulization**\n\n* Specially in CLAIM tag we can see sequently same tag and some time its droping few words and sentence which makes prediction complex or complicated.\n* Most of Eassy Concluding Tag are at the end \n* In starting of EDA section we found most used tags are claim,evidence,position,concluding Statement\n* In CSV we have also given  claim1, claim2 etc like means if any tag getting repeate then it will increase number of tag but we have predict Tags only","metadata":{"id":"O6oByY4fhjiq"}},{"cell_type":"code","source":"","metadata":{"id":"SQR04dUdhgsJ"},"execution_count":null,"outputs":[]}]}