{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A Pytorch version NER Baseline\n\n#### This notebook based on from Liu's notebook [Feedback Prize Infer](https://www.kaggle.com/hjhgjghhg/feedback-prize-infer) , I modified some variable with my model\n\n#### Part of this kernel is from zzy's [Pytorch NER infer](https://www.kaggle.com/zzy990106/pytorch-ner-infer)\n\n#### If you liked this, please **UPVOTE**. Thank You.","metadata":{}},{"cell_type":"code","source":"import random\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, AdamW, get_scheduler","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:36:10.044278Z","iopub.execute_input":"2021-12-22T09:36:10.045014Z","iopub.status.idle":"2021-12-22T09:36:16.680403Z","shell.execute_reply.started":"2021-12-22T09:36:10.04491Z","shell.execute_reply":"2021-12-22T09:36:16.67967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"config = {\n    'fold_num': 5,\n    'seed': 1234,\n    #'model': 'roberta-base',\n    #'model': '../input/robertalarge',\n    'model': 'allenai/longformer-base-4096',\n    #'model': 'allenai/longformer-large-4096',\n    'max_len': 1024,\n    'epochs': 5,\n    'train_bs': 6,\n    'valid_bs': 6,\n    'lr': 1e-5,\n    'num_workers': 0,\n    'weight_decay': 1e-2,\n    'num_warmup_steps': 1000,\n    'lr_scheduler_type': 'linear',\n    'gradient_accumulation_steps': 1,\n}","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-12-22T09:36:18.858896Z","iopub.execute_input":"2021-12-22T09:36:18.859268Z","iopub.status.idle":"2021-12-22T09:36:18.872467Z","shell.execute_reply.started":"2021-12-22T09:36:18.859225Z","shell.execute_reply":"2021-12-22T09:36:18.868823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim',\n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\nlabels2index = {\n    'Lead': 1, 'Position': 3, 'Claim': 5, 'Counterclaim': 7, 'Rebuttal': 9, 'Evidence': 11, 'Concluding Statement': 13\n}\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:36:23.978522Z","iopub.execute_input":"2021-12-22T09:36:23.979208Z","iopub.status.idle":"2021-12-22T09:36:23.984211Z","shell.execute_reply.started":"2021-12-22T09:36:23.979169Z","shell.execute_reply":"2021-12-22T09:36:23.983337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nset_seed(config['seed'])\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2021-12-22T09:36:25.856637Z","iopub.execute_input":"2021-12-22T09:36:25.857339Z","iopub.status.idle":"2021-12-22T09:36:25.906044Z","shell.execute_reply.started":"2021-12-22T09:36:25.857298Z","shell.execute_reply":"2021-12-22T09:36:25.905366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tokenizer = AutoTokenizer.from_pretrained(config['model'], add_prefix_space=True)\ntokenizer = AutoTokenizer.from_pretrained('../input/test-notebook/roberta_trained', add_prefix_space=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:36:27.019217Z","iopub.execute_input":"2021-12-22T09:36:27.019756Z","iopub.status.idle":"2021-12-22T09:36:27.231452Z","shell.execute_reply.started":"2021-12-22T09:36:27.019717Z","shell.execute_reply":"2021-12-22T09:36:27.230687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, phase='Train'):\n        self.df = df\n        self.phase = phase\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        text = self.df.text.values[idx]\n        if self.phase == 'Train':\n            label = self.df.tagging.values[idx]\n            return {'text': text, 'label': label}\n        else:\n            return {'text': text}\n\n\ndef collate_fn(data):\n    input_ids, attention_mask = [], []\n    text = [item['text'] for item in data]\n    tokenized_inputs = tokenizer(\n        text,\n        max_length=config['max_len'],\n        padding='max_length',\n        truncation=True,\n        is_split_into_words=True,\n        return_tensors='pt'\n    )\n\n    words = []\n    for i in range(len(data)):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        words.append(word_ids)\n\n    tokenized_inputs[\"word_ids\"] = words\n    if 'label' in data[0].keys():\n        label = [item['label'] for item in data]\n        tokenized_inputs['labels'] = torch.LongTensor(label)\n\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:36:28.646381Z","iopub.execute_input":"2021-12-22T09:36:28.64694Z","iopub.status.idle":"2021-12-22T09:36:28.656768Z","shell.execute_reply.started":"2021-12-22T09:36:28.6469Z","shell.execute_reply":"2021-12-22T09:36:28.655899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Model","metadata":{}},{"cell_type":"code","source":"#model = AutoModelForTokenClassification.from_pretrained(config['model'], num_labels=15).to(device)\n#model.load_state_dict(torch.load('../input/feedback-prize-train/roberta_trained/pytorch_model.bin'))\nmodel = AutoModelForTokenClassification.from_pretrained('../input/feedback-prize-roberta-model/roberta_trained/', num_labels=15).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:38:03.997067Z","iopub.execute_input":"2021-12-22T09:38:03.997391Z","iopub.status.idle":"2021-12-22T09:38:05.90258Z","shell.execute_reply.started":"2021-12-22T09:38:03.997349Z","shell.execute_reply":"2021-12-22T09:38:05.901745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Test Data","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\ntest_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:38:08.736722Z","iopub.execute_input":"2021-12-22T09:38:08.737003Z","iopub.status.idle":"2021-12-22T09:38:08.772018Z","shell.execute_reply.started":"2021-12-22T09:38:08.73697Z","shell.execute_reply":"2021-12-22T09:38:08.77121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/test'))):\n    test_names.append(f.replace('.txt', ''))\n    with open('../input/feedback-prize-2021/test/' + f, 'r', encoding='utf-8') as f:\n        text = ''\n        for line in f.readlines():\n            #text += line.replace('\\n', '').replace('\\xa0', '')\n            text += line.replace('\\n', ' ')\n        test_texts.append(text)\ntest_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\ntest_texts['text'] = test_texts['text'].apply(lambda x: x.split())\ntest_texts","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:38:10.537216Z","iopub.execute_input":"2021-12-22T09:38:10.53786Z","iopub.status.idle":"2021-12-22T09:38:10.593766Z","shell.execute_reply.started":"2021-12-22T09:38:10.53782Z","shell.execute_reply":"2021-12-22T09:38:10.593001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = MyDataset(test_texts, phase='Test')\ntest_iter = DataLoader(test_dataset, batch_size=config['valid_bs'], collate_fn=collate_fn, shuffle=False,\n                        num_workers=config['num_workers'])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:38:12.178605Z","iopub.execute_input":"2021-12-22T09:38:12.179314Z","iopub.status.idle":"2021-12-22T09:38:12.184107Z","shell.execute_reply.started":"2021-12-22T09:38:12.179273Z","shell.execute_reply":"2021-12-22T09:38:12.183013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"y_pred = []\nwords = []\n\nwith torch.no_grad():\n    model.eval()\n    tk = tqdm(test_iter, total=len(test_iter), position=0, leave=True)\n    for step, batch in enumerate(tk):\n        word_ids = batch['word_ids']\n        words.extend(word_ids)\n        batch = {k: v.to(device) for k, v in batch.items() if k != 'word_ids'}\n\n        output = model(input_ids=batch['input_ids'],\n                       attention_mask=batch['attention_mask']).logits\n\n        y_pred.extend(output.argmax(-1).cpu().numpy())\n        \ny_pred = np.array(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:38:16.297279Z","iopub.execute_input":"2021-12-22T09:38:16.298101Z","iopub.status.idle":"2021-12-22T09:38:17.560641Z","shell.execute_reply.started":"2021-12-22T09:38:16.298061Z","shell.execute_reply":"2021-12-22T09:38:17.559947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred[0][:200]","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:38:20.638586Z","iopub.execute_input":"2021-12-22T09:38:20.638864Z","iopub.status.idle":"2021-12-22T09:38:20.645047Z","shell.execute_reply.started":"2021-12-22T09:38:20.638835Z","shell.execute_reply":"2021-12-22T09:38:20.643913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds = []\n\nfor i in tqdm(range(len(test_texts))):\n    idx = test_texts.id.values[i]\n    pred = ['']*len(y_pred[i]-2)\n\n    for j in range(1, len(y_pred[i])):\n        pred[j-1] = labels[y_pred[i][j]]\n\n    pred = [x.replace('B-','').replace('I-','') for x in pred]\n    \n    j = 0\n    while j < len(pred):\n        cls = pred[j]\n        if cls == 'O':\n            j += 1\n        end = j + 1\n        while end < len(pred) and pred[end] == cls:\n            end += 1\n            \n        if cls != 'O' and cls != '' and end - j > 10:\n            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n        \n        j = end\n        \nfinal_preds[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:38:24.459604Z","iopub.execute_input":"2021-12-22T09:38:24.460205Z","iopub.status.idle":"2021-12-22T09:38:24.487786Z","shell.execute_reply.started":"2021-12-22T09:38:24.460167Z","shell.execute_reply":"2021-12-22T09:38:24.487056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(final_preds)\nsub.columns = test_df.columns\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:38:26.77686Z","iopub.execute_input":"2021-12-22T09:38:26.77757Z","iopub.status.idle":"2021-12-22T09:38:26.787096Z","shell.execute_reply.started":"2021-12-22T09:38:26.777459Z","shell.execute_reply":"2021-12-22T09:38:26.786383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:38:43.539211Z","iopub.execute_input":"2021-12-22T09:38:43.540047Z","iopub.status.idle":"2021-12-22T09:38:43.558963Z","shell.execute_reply.started":"2021-12-22T09:38:43.539991Z","shell.execute_reply":"2021-12-22T09:38:43.558169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}