{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\ngc.enable()\n\nimport sys\nsys.path.append(\"../input/tez-lib/\")\n\nimport os\nimport random\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import softmax\nimport pickle\n\n#import tez\nimport torch\nimport torch.nn as nn\nfrom joblib import Parallel, delayed\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-14T19:50:55.382977Z","iopub.execute_input":"2022-03-14T19:50:55.383341Z","iopub.status.idle":"2022-03-14T19:50:57.41165Z","shell.execute_reply.started":"2022-03-14T19:50:55.383256Z","shell.execute_reply":"2022-03-14T19:50:57.410463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    input_dir = '../input/feedback-prize-2021'\n    \n    model_longformer = '../input/longformerlarge4096/longformer-large-4096'\n    model_led = '../input/led-large'\n    model_deberta = '../input/deberta-large-download/deberta-large'\n    \n    max_len_test_longformer = 1600\n    max_len_test_led = 1024\n    \n    tokenizer = '../input/deberta-large-download/deberta-large' #'../input/longformerlarge4096/longformer-large-4096'\n    num_jobs = 4\n    seed = 1\n    \n    model_ckp_path = [\n        #  (kind, num_labels, model_path, weight)\n        # exp lf-large, lf-base, led-large, bb-large, ...\n        \n        #('lf-large', 22, '../input/2022021410-lf-bie-bin/model_0.bin', 1.0),\n        #('lf-large', 22, '../input/2022021410-lf-bie-bin/model_1.bin', 1.0),\n        #('lf-large', 22, '../input/2022021410-lf-bie-bin/model_2.bin', 1.0),\n        #('lf-large', 22, '../input/2022021410-lf-bie-bin/model_3.bin', 1.0),\n        #('lf-large', 22, '../input/2022021410-lf-bie-bin/model_4.bin', 1.0),\n        \n        #('lf-large', 15, '../input/2022020906-aug-bin/model_0.bin', 1.0),\n        #('lf-large', 15, '../input/2022020906-aug-bin/model_1.bin', 1.0),\n        #('lf-large', 15, '../input/2022020906-aug-bin/model_2.bin', 1.0),\n        #('lf-large', 15, '../input/2022020906-aug-bin/model_3.bin', 1.0),\n        #('lf-large', 15, '../input/2022020906-aug-bin/model_4.bin', 1.0),\n\n        #('led-large', 24, '../input/fb-exp037-led/model_0.bin', 1.0),\n        #('led-large', 24, '../input/fb-exp037-led/model_1.bin', 1.0),\n        #('led-large', 24, '../input/fb-exp037-led/model_2.bin', 1.0),\n        #('led-large', 24, '../input/fb-exp037-led/model_3.bin', 1.0),\n        #('led-large', 24, '../input/fb-exp037-led/model_4.bin', 1.0),\n\n        #('led-large', 24, '../input/fb-exp017-led/model_0.bin', 1.0),\n        #('led-large', 24, '../input/fb-exp017-led/model_1.bin', 1.0),\n        #('led-large', 24, '../input/fb-exp017-led/model_2.bin', 1.0),\n        #('led-large', 24, '../input/fb-exp017-led/model_3.bin', 1.0),\n        #('deberta-large', 22, '../input/fb-exp045-deberta/model_0.bin', 1.0),\n        ('deberta-large', 15, '../input/2022022709-deberta-large-boe-bin/model_0.bin', 1.0),\n    ]\n\n    proba_thresh = {\n        \"Lead\": 0.6, # 0.7\n        \"Position\": 0.4, # 0.55\n        \"Evidence\": 0.65,\n        \"Claim\": 0.55,\n        \"Concluding Statement\": 0.6, # 0.7\n        \"Counterclaim\": 0.5,\n        \"Rebuttal\": 0.55,\n    }\n    min_token_thresh = {\n        \"Lead\": 5, # 9\n        \"Position\": 4, # 5\n        \"Evidence\": 14,\n        \"Claim\": 2,\n        \"Concluding Statement\": 7, # 11\n        \"Counterclaim\": 6,\n        \"Rebuttal\": 4,\n    }\n    link = {\n        'Evidence': 40,\n        'Counterclaim': 200,\n        'Rebuttal': 200,\n    }\n    \n    \n\n\ncfg = Config()    \ntarget_id_map = {\n    \"B-Lead\": 0,\n    \"I-Lead\": 1,\n    \"B-Position\": 2,\n    \"I-Position\": 3,\n    \"B-Evidence\": 4,\n    \"I-Evidence\": 5,\n    \"B-Claim\": 6,\n    \"I-Claim\": 7,\n    \"B-Concluding Statement\": 8,\n    \"I-Concluding Statement\": 9,\n    \"B-Counterclaim\": 10,\n    \"I-Counterclaim\": 11,\n    \"B-Rebuttal\": 12,\n    \"I-Rebuttal\": 13,\n    \"O\": 14,\n    \"PAD\": -100,\n}\nid_target_map = {v: k for k, v in target_id_map.items()}","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:50:57.413816Z","iopub.execute_input":"2022-03-14T19:50:57.4142Z","iopub.status.idle":"2022-03-14T19:50:57.431986Z","shell.execute_reply.started":"2022-03-14T19:50:57.414156Z","shell.execute_reply":"2022-03-14T19:50:57.431108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Postprocess","metadata":{}},{"cell_type":"code","source":"def post_process(samples):\n    sub = create_submission(samples)\n    sub = thresh_prob(sub, cfg)\n    sub = thresh_min_token(sub, cfg)\n    sub = get_max_prob(sub)\n    sub = link_class(sub, 'Evidence', cfg.link['Evidence'])\n    sub = link_class(sub, 'Counterclaim', cfg.link['Counterclaim'])\n    sub = link_class(sub, 'Rebuttal', cfg.link['Rebuttal'])\n    sub = sub.reset_index(drop=True)\n    sub = sub[['id', 'class', 'predictionstring']]\n    return sub\n\n\ndef create_submission(samples):\n    sub = []\n    for _, sample in enumerate(samples):\n        pred_class = sample['pred_class']\n        offset_mapping = sample['offset_mapping']\n        sample_id = sample['id']\n        sample_text = sample['text']\n        pred_prob = sample['pred_prob']\n        \n        second_class = sample['second_class']\n        second_prob = sample['second_prob']\n        \n        third_class = sample['third_class']\n        third_prob = sample['third_prob']\n        \n\n        pred_class = fix_list_(pred_class)\n\n        sample_preds = []\n        # テキストが4096より長い場合\n        if len(pred_class) < len(offset_mapping)-1:\n            pred_class += ['O'] * (len(offset_mapping) - len(pred_class))\n            second_class += ['O'] * (len(offset_mapping) - len(second_class))\n            third_class += ['O'] * (len(offset_mapping) - len(third_class))\n            \n            pred_prob += [0] * (len(offset_mapping) - len(pred_prob))\n            second_prob += [0] * (len(offset_mapping) - len(second_prob))\n            third_prob += [0] * (len(offset_mapping) - len(third_prob))\n\n        idx = 0\n        phrase_preds = []\n        while idx < len(offset_mapping)-1:\n            start, _ = offset_mapping[idx]\n            if pred_class[idx] != 'O':\n                label = pred_class[idx][2:]\n            else:\n                label = 'O'\n                \n            if second_class[idx] != 'O':\n                second_label = second_class[idx][2:]\n            else:\n                second_label = 'O'\n                \n            if pred_class[idx] != 'O':\n                third_label = third_class[idx][2:]\n            else:\n                third_label = 'O'\n            \n            \n            phrase_probs = []\n            phrase_probs.append(pred_prob[idx])\n            \n            phrase_second_probs = []\n            phrase_second_probs.append(second_prob[idx])\n            \n            phrase_third_probs = []\n            phrase_third_probs.append(third_prob[idx])\n            \n            idx += 1\n            \n            while idx < len(offset_mapping)-1:\n                if label != 'O':\n                    matching_label = f'I-{label}'\n                else:\n                    matching_label = 'O'\n                if pred_class[idx] == matching_label:\n                    _, end = offset_mapping[idx]\n                    phrase_probs.append(pred_prob[idx])\n                    phrase_second_probs.append(second_prob[idx])\n                    phrase_third_probs.append(third_prob[idx])\n                    \n                    idx += 1\n                else:\n                    break\n            if 'end' in locals():\n                phrase = sample_text[start:end]\n                phrase_preds.append((phrase, start, end, label, second_label, third_label, phrase_probs, phrase_second_probs, phrase_third_probs))\n\n        temp_df = []\n        for phrase_idx, (phrase, start, end, label, second_label, third_label, phrase_probs, phrase_second_probs, phrase_third_probs) in enumerate(phrase_preds):\n            word_start = len(sample_text[:start].split())\n            word_end = word_start + len(sample_text[start:end].split())\n            word_end = min(word_end, len(sample_text.split()))\n            ps = \" \".join([str(x) for x in range(word_start, word_end)])\n            if label != 'O':\n                phrase_probs_mean = sum(phrase_probs) / len(phrase_probs)\n                phrase_second_probs_mean = sum(phrase_second_probs) / len(phrase_probs)\n                phrase_third_probs_mean = sum(phrase_third_probs) / len(phrase_probs)\n                \n                temp_df.append((sample_id, label, second_label, third_label, ps, phrase_probs_mean, phrase_second_probs_mean, phrase_third_probs_mean))\n        temp_df = pd.DataFrame(temp_df, columns=['id', 'class', 'second_class', 'third_class', 'predictionstring', 'prob', 'second_prob', 'third_prob'])\n        sub.append(temp_df)\n    \n    sub = pd.concat(sub).reset_index(drop=True)\n    sub['len'] = sub['predictionstring'].apply(lambda x: len(x.split()))\n    sub = sub[sub['len'] > 0]\n    return sub\n\ndef fix_list(pred_list):\n\n    class_list = [\"I-Lead\", \"I-Position\", \"I-Evidence\", \"I-Claim\", \n                  \"I-Concluding Statement\", \"I-Counterclaim\", \"I-Rebuttal\", \"O\"]\n    \n    fix_threholds = {\n        \"I-Lead\":2, \n        \"I-Concluding Statement\":2, \n        \"I-Evidence\":1,\n        \"I-Position\":2,\n        \"I-Claim\":1,\n        \"I-Counterclaim\":5, \n        \"I-Rebuttal\":7,\n        \"O\":1\n    }\n    \n    for class_ in class_list:\n\n        flg_index = []\n        out_class = [col for col in class_list if col not in class_]\n        counter = 0\n\n        for token_id, token in enumerate(pred_list):\n            \n            # 連続2回以上続いた後の別classにはflgを立てる\n            if counter > 2 and token in out_class:\n                flg_index.append(token_id)\n                counter = 0\n\n            if token == class_:\n                counter += 1\n            else:\n                counter = 0\n                \n        for ind in flg_index:\n            if ind + fix_threholds[class_] + 1 < len(pred_list):\n                counter_2 = fix_threholds[class_]\n                while counter_2 != 0:\n                    if pred_list[ind + counter_2] == class_ and pred_list[ind + counter_2 + 1] == class_:\n                        for i in range(counter_2):\n                            pred_list[ind + i] = class_\n                        counter_2 = 0\n                    else:\n                        counter_2 -= 1\n                        \n    return pred_list\n\ndef fix_list_(pred_list):\n    class_list = [\"I-Lead\", \"I-Position\", \"I-Evidence\", \"I-Claim\", \n                  \"I-Concluding Statement\", \"I-Counterclaim\", \"I-Rebuttal\"]\n\n    for class_ in class_list:\n        flg_index = []\n        out_class = set(class_list) - {class_}\n        counter = 0\n\n        for token_id, token in enumerate(pred_list):\n            if counter > 2 and token in out_class:\n                flg_index.append(token_id)\n                counter = 0\n\n            if token == class_:\n                counter += 1\n            else:\n                counter = 0\n\n        for ind in flg_index:\n            if ind + 2 < len(pred_list):\n                if pred_list[ind + 1] == class_ and pred_list[ind + 2] == class_:\n                    pred_list[ind] = class_\n\n    return pred_list\n\n\ndef jn(pst, start, end):\n    return \" \".join([str(x) for x in pst[start:end] if x != -1])\n\n\ndef link_class(oof, discourse_type, thresh2):\n    id_list = oof['id'].unique().tolist()\n    if not len(oof):\n        return oof\n    thresh = 1\n    idu = oof['id'].unique()\n    eoof = oof[oof['class'] == f\"{discourse_type}\"]\n    neoof = oof[oof['class'] != f\"{discourse_type}\"]\n    eoof.index = eoof[['id', 'class']]\n    \n    retval = []\n    for idv in idu:\n        q = eoof[eoof['id'] == idv]\n        if not len(q):\n            continue\n        pst = []\n        for r in q.itertuples():\n            pst = [*pst, -1,  *[int(x) for x in r.predictionstring.split()]]\n        start, end = 1, 1\n        for i in range(2, len(pst)):\n            cur = pst[i]\n            end = i\n            if  (\n                (cur == -1) and\n                ((pst[i + 1] > pst[end - 1] + thresh) or (pst[i + 1] - pst[start] > thresh2))\n            ):\n                retval.append((idv, discourse_type, jn(pst, start, end)))\n                start = i + 1\n        v = (idv, discourse_type, jn(pst, start, end + 1))\n        retval.append(v)\n\n    roof = pd.DataFrame(retval, columns=['id', 'class', 'predictionstring'])\n    roof = roof.merge(neoof, how='outer')\n    \n    dfs = []\n    for doc_id in id_list:\n        r_df_tmp = roof.query(f'id == \"{doc_id}\"')\n        r_df_tmp['start'] = r_df_tmp['predictionstring'].apply(lambda x: int(x.split(' ')[0]))\n        r_df_tmp = r_df_tmp.sort_values('start').drop('start', axis=1)\n        dfs.append(r_df_tmp)\n    return pd.concat(dfs, axis=0)\n\n\ndef thresh_prob(df, cfg):\n    df_other = df[(df['class'] != 'Claim') | (df['len'] != 2)]\n    df_target = df[(df['class'] == 'Claim') & (df['len'] == 2)]\n    df_target['prob'] -= 0.1\n    df = pd.concat([df_other, df_target])\n    df = df.sort_index()\n    for k, v in cfg.proba_thresh.items():\n        idx = df.loc[df['class'] == k].query(f'prob < {v}').index\n        df = df.drop(idx)\n    return df\n\n# add\ndef thresh_second_prob(df, cfg):\n    df = df.sort_index()\n    for k, v in cfg.second_proba_thresh.items():\n        idx = df.loc[df['class'] == k].query(f'second_prob > {v}').index\n        df = df.drop(idx)\n    return df\n\n# add\ndef thresh_third_prob(df, cfg):\n    df = df.sort_index()\n    for k, v in cfg.second_proba_thresh.items():\n        idx = df.loc[df['class'] == k].query(f'third_prob > {v}').index\n        df = df.drop(idx)\n    return df\n\n\ndef thresh_min_token(df, cfg):\n    df['len'] = df['predictionstring'].apply(lambda x: len(x.split(' ')))\n    for k, v in cfg.min_token_thresh.items():\n        idx = df.loc[df['class'] == k].query(f'len < {v}').index\n        df = df.drop(idx)\n    return df\n\n\ndef get_max_prob(sub):\n    sub['prob'] = sub['prob'].astype(float)\n    id_list = sub['id'].unique().tolist()\n    unique_class = ['Lead', 'Position', 'Concluding Statement']\n    sub_in_unique = sub[sub['class'].isin(unique_class) == True]\n    sub_not_in_unique = sub[sub['class'].isin(unique_class) == False]\n    sub_in_unique = sub_in_unique.loc[sub_in_unique.groupby(['id', 'class'])['prob'].idxmax(), :]\n    sub = pd.concat([sub_in_unique, sub_not_in_unique])\n    return sub\n\ndef post_process_sub(sub):\n    sub = thresh_prob(sub, cfg)\n    sub = thresh_min_token(sub, cfg)\n    sub = get_max_prob(sub)\n    sub = link_class(sub, 'Evidence', cfg.link['Evidence'])\n    sub = link_class(sub, 'Counterclaim', cfg.link['Counterclaim'])\n    sub = link_class(sub, 'Rebuttal', cfg.link['Rebuttal'])\n    sub = sub.reset_index(drop=True)\n    sub = sub[['id', 'class', 'predictionstring', 'prob', 'len']]\n    return sub","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:50:57.434112Z","iopub.execute_input":"2022-03-14T19:50:57.434729Z","iopub.status.idle":"2022-03-14T19:50:57.504819Z","shell.execute_reply.started":"2022-03-14T19:50:57.43468Z","shell.execute_reply":"2022-03-14T19:50:57.503642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scoring and add label","metadata":{}},{"cell_type":"code","source":"def calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(\" \"))\n    set_gt = set(row.predictionstring_gt.split(\" \"))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter / len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp_micro(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n\n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    This code is from Rob Mulla's Kaggle kernel.\n    \"\"\"\n    gt_df = gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]\n                  ].reset_index(drop=True).copy()\n    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]\n                      ].reset_index(drop=True).copy()\n    pred_df[\"pred_id\"] = pred_df.index\n    gt_df[\"gt_id\"] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(\n        gt_df,\n        left_on=[\"id\", \"class\"],\n        right_on=[\"id\", \"discourse_type\"],\n        how=\"outer\",\n        suffixes=(\"_pred\", \"_gt\"),\n    )\n    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\n        \" \")\n\n    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n\n    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (\n        joined[\"overlap2\"] >= 0.5)\n    \n    #print(joined)\n    \n    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n    tp_pred_ids = (\n        joined.query(\"potential_TP\")\n        .sort_values(\"max_overlap\", ascending=False)\n        .groupby([\"id\", \"predictionstring_gt\"])\n        .first()[\"pred_id\"]\n        .values\n    )\n    \n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined[\"pred_id\"].unique()\n                   if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique()\n                        if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    # calc microf1\n    my_f1_score = TP / (TP + 0.5 * (FP + FN))\n    return my_f1_score, tp_pred_ids\n\ndef score_feedback_comp(pred_df, gt_df, return_class_scores=False):\n    class_scores = {}\n    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]\n                      ].reset_index(drop=True).copy()\n    \n    tp_id_list = []\n    pred_subset_list = []\n    for discourse_type, gt_subset in gt_df.groupby(\"discourse_type\"):\n        pred_subset = pred_df.loc[pred_df[\"class\"] ==\n                                  discourse_type].reset_index(drop=True).copy()\n        \n        #print(pred_subset)\n        class_score, tp_pred_ids = score_feedback_comp_micro(pred_subset, gt_subset)\n        pred_subset['is_tp'] = pred_subset.index.isin(tp_pred_ids)\n        print(class_score)\n        pred_subset_list.append(pred_subset)\n        \n        \n        tp_id_list += list(tp_pred_ids)\n        class_scores[discourse_type] = class_score\n    f1 = np.mean([v for v in class_scores.values()])\n    if return_class_scores:\n        return f1, class_scores, pd.concat(pred_subset_list)\n    return f1, pd.concat(pred_subset_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:50:57.507229Z","iopub.execute_input":"2022-03-14T19:50:57.507796Z","iopub.status.idle":"2022-03-14T19:50:57.531065Z","shell.execute_reply.started":"2022-03-14T19:50:57.507747Z","shell.execute_reply":"2022-03-14T19:50:57.530199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths_ = [\n    #'../input/oof-pred-108/deberta-large-108.pkl',\n    '../input/fb-oof-dict/oof_dict_yyama_exp045.pickle',\n #'../input/fb-oof-dict/oof_dict_makotu_021410-lf-bie-bin.pickle',\n '../input/fb-oof-dict/oof_dict_makabe_feedback-101_LSTM_2head.pickle',\n #'../input/fb-oof-dict/oof_dict_makotu_030209-deberta-large-mnli-boe-bin.pickle',\n '../input/fb-oof-dict/oof_dict_022709-deberta-large-boe-bin.pickle',\n '../input/fb-oof-dict/oof_dict_makabe_feedback-096.pickle',\n '../input/convert-fp64-to-fp16-inference98/oof_dict_makabe_feedback-098_LSTM.pickle',\n '../input/fb-oof-dict/oof_dict_yyama_exp058-wo-mlm.pickle',\n'../input/fb-oof-dict/oof_dict_yyama_fb-exp037-led.pickle',\n'../input/fb-oof-dict-exp062-xlarge-f24/oof_dict_yyama_fb_exp06x_xlarge_fold2-4.pickle']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:50:57.533142Z","iopub.execute_input":"2022-03-14T19:50:57.533723Z","iopub.status.idle":"2022-03-14T19:50:57.556463Z","shell.execute_reply.started":"2022-03-14T19:50:57.533673Z","shell.execute_reply":"2022-03-14T19:50:57.555303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/feedback-prize-2021/train.csv')\n\n#test_df = pd.read_csv('../input/fb-train-folds/train_folds.csv')\n#test_df = test_df[test_df['kfold']==fold_num].reset_index(drop=True)\ntest_ids = test_df['id'].unique()\ntest_ids = test_ids[~(test_ids=='AD005493F9BF')]\n# for debug\n# test_ids = test_ids[:100]\ntest_df = test_df[test_df['id'].isin(test_ids)]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:50:57.557921Z","iopub.execute_input":"2022-03-14T19:50:57.558949Z","iopub.status.idle":"2022-03-14T19:50:59.42517Z","shell.execute_reply.started":"2022-03-14T19:50:57.558821Z","shell.execute_reply":"2022-03-14T19:50:59.423997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_df = pd.read_csv('../input/makabe-fold-csv/makabe_fold.csv', encoding='utf-8-sig')\n#fold_df = fold_df[['id', 'kfold']].drop_duplicates()\nfold_dict = dict(zip(fold_df['id'], fold_df['fold']))\n\n#fold_dict = dict(zip(test_ids, np.random.permutation(np.arange(len(test_ids))) % 5))","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:50:59.426821Z","iopub.execute_input":"2022-03-14T19:50:59.427087Z","iopub.status.idle":"2022-03-14T19:50:59.463132Z","shell.execute_reply.started":"2022-03-14T19:50:59.427056Z","shell.execute_reply":"2022-03-14T19:50:59.462192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_df = pd.read_csv('../input/train-folds/train_folds.csv')\nfold_df = fold_df[['id', 'kfold']].drop_duplicates()\nfold_dict_2 = dict(zip(fold_df['id'], fold_df['kfold']))\ntest_df['fold'] = test_df['id'].map(fold_dict_2)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:50:59.465304Z","iopub.execute_input":"2022-03-14T19:50:59.465691Z","iopub.status.idle":"2022-03-14T19:51:01.3135Z","shell.execute_reply.started":"2022-03-14T19:50:59.465643Z","shell.execute_reply":"2022-03-14T19:51:01.312456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_sub = pd.DataFrame()\nfor i, path in tqdm(enumerate(paths_)):\n    # 1,2は作成に失敗したため\n    #if i in [0,3,4,5]:\n    model_name = path.split('/')[-1].replace(\".pickle\", \"\").replace(\"oof_dict_\", \"\")\n    sub = pd.read_pickle(f'../input/feats-0315/feats_{model_name}.pkl')\n\n    #if sub.isna().mean().mean() < 0.05:\n    #new_cols = list(sub.columns[:12]) + ['model_' + str(i // 75) + '_' + '_'.join(sub.columns[i+12].split('_')[-2:]) for i in list(range(450))] + ['model_name']\n    #sub.columns = new_cols\n\n    for col in sub.columns:\n        if sub.dtypes[col] == np.int64:\n            sub[col] = sub[col].astype(np.int32)\n        if sub.dtypes[col] == np.float64:\n            sub[col] = sub[col].astype(np.float16)\n\n    _, true_sub = score_feedback_comp(sub[['id', 'class', 'predictionstring']], test_df, return_class_scores=False)\n    sub['is_tp'] = sub.set_index(['id', 'class', 'predictionstring']).index.map(true_sub.set_index(['id', 'class', 'predictionstring'])['is_tp'].to_dict()).astype(int)\n    sub['new_fold'] = sub['id'].map(fold_dict)\n    all_sub = all_sub.append(sub.reset_index(drop=True))\n    del sub","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:51:01.314712Z","iopub.execute_input":"2022-03-14T19:51:01.314935Z","iopub.status.idle":"2022-03-14T19:56:18.547329Z","shell.execute_reply.started":"2022-03-14T19:51:01.314907Z","shell.execute_reply":"2022-03-14T19:56:18.546071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'ensemble_0314'\nensemble_sub = pd.read_pickle(f'../input/feats-0315/feats_{model_name}.pkl')\n\n# columnsの修正が終わったら消す\n#new_cols = list(ensemble_sub.columns[:12]) + ['model_' + str(i // 75) + '_' + '_'.join(ensemble_sub.columns[i+12].split('_')[-2:]) for i in list(range(450))]\n#ensemble_sub.columns = new_cols\n\nfor col in ensemble_sub.columns:\n    if ensemble_sub.dtypes[col] == np.int64:\n        ensemble_sub[col] = ensemble_sub[col].astype(np.int32)\n    if ensemble_sub.dtypes[col] == np.float64:\n        ensemble_sub[col] = ensemble_sub[col].astype(np.float16)\n\n_, true_sub = score_feedback_comp(ensemble_sub[['id', 'class', 'predictionstring']], test_df[test_df.fold.isin([2,3,4])], return_class_scores=False)\nensemble_sub['is_tp'] = ensemble_sub.set_index(['id', 'class', 'predictionstring']).index.map(true_sub.set_index(['id', 'class', 'predictionstring'])['is_tp'].to_dict()).astype(int)\nensemble_sub['new_fold'] = ensemble_sub['id'].map(fold_dict)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:56:18.55066Z","iopub.execute_input":"2022-03-14T19:56:18.550925Z","iopub.status.idle":"2022-03-14T19:56:41.1614Z","shell.execute_reply.started":"2022-03-14T19:56:18.550891Z","shell.execute_reply":"2022-03-14T19:56:41.160108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(set(ensemble_sub.columns))","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:56:41.162877Z","iopub.execute_input":"2022-03-14T19:56:41.163118Z","iopub.status.idle":"2022-03-14T19:56:41.172712Z","shell.execute_reply.started":"2022-03-14T19:56:41.163076Z","shell.execute_reply":"2022-03-14T19:56:41.171466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['predictionstring', 'start', 'end']:\n    dic = (all_sub.groupby(['id', 'class', col])['model_name'].nunique() / all_sub['model_name'].nunique()).to_dict()\n    all_sub[f'dupli_{col}'] = all_sub.set_index(['id', 'class', col]).index.map(dic)\n    ensemble_sub[f'dupli_{col}'] = ensemble_sub.set_index(['id', 'class', col]).index.map(dic)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:56:41.173877Z","iopub.execute_input":"2022-03-14T19:56:41.174131Z","iopub.status.idle":"2022-03-14T19:57:23.711852Z","shell.execute_reply.started":"2022-03-14T19:56:41.174078Z","shell.execute_reply":"2022-03-14T19:57:23.710789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['predictionstring', 'start', 'end']:\n    ensemble_sub[f'dupli_{col}'] = ensemble_sub[f'dupli_{col}'].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:23.713206Z","iopub.execute_input":"2022-03-14T19:57:23.713519Z","iopub.status.idle":"2022-03-14T19:57:23.722497Z","shell.execute_reply.started":"2022-03-14T19:57:23.713475Z","shell.execute_reply":"2022-03-14T19:57:23.721331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_sub = all_sub.drop_duplicates(subset=['id', 'class', 'predictionstring'])\nall_sub = all_sub.dropna(subset=all_sub.columns[25:30])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:23.724348Z","iopub.execute_input":"2022-03-14T19:57:23.724655Z","iopub.status.idle":"2022-03-14T19:57:31.549336Z","shell.execute_reply.started":"2022-03-14T19:57:23.724616Z","shell.execute_reply":"2022-03-14T19:57:31.548297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_sub = all_sub.reset_index(drop=True)\nensemble_sub = ensemble_sub.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:31.551667Z","iopub.execute_input":"2022-03-14T19:57:31.552023Z","iopub.status.idle":"2022-03-14T19:57:31.955534Z","shell.execute_reply.started":"2022-03-14T19:57:31.551978Z","shell.execute_reply":"2022-03-14T19:57:31.954668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats = [col for col in all_sub.columns if not col in ['id', 'predictionstring', 'text', 'offset', 'fold', 'new_fold', 'is_tp', 'discourse_key', 'model_name']]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:31.957244Z","iopub.execute_input":"2022-03-14T19:57:31.957598Z","iopub.status.idle":"2022-03-14T19:57:31.963287Z","shell.execute_reply.started":"2022-03-14T19:57:31.957529Z","shell.execute_reply":"2022-03-14T19:57:31.962049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_sub_df = all_sub[['id', 'class', 'second_class', 'third_class', 'predictionstring', 'prob', 'second_prob', 'third_prob', 'len', 'start', 'end']]\nall_sub_folds = all_sub['fold']\nall_sub_new_folds = all_sub['new_fold']\nall_sub_targets = all_sub['is_tp']\nall_sub = all_sub[feats]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:31.965009Z","iopub.execute_input":"2022-03-14T19:57:31.965448Z","iopub.status.idle":"2022-03-14T19:57:32.980243Z","shell.execute_reply.started":"2022-03-14T19:57:31.965405Z","shell.execute_reply":"2022-03-14T19:57:32.979447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_sub_df = ensemble_sub[['id', 'class', 'second_class', 'third_class', 'predictionstring', 'prob', 'second_prob', 'third_prob', 'len', 'start', 'end']]\nensemble_sub_folds = ensemble_sub['fold']\nensemble_sub_new_folds = ensemble_sub['new_fold']\nensemble_sub_targets = ensemble_sub['is_tp']\nensemble_sub = ensemble_sub[feats]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:32.982529Z","iopub.execute_input":"2022-03-14T19:57:32.982938Z","iopub.status.idle":"2022-03-14T19:57:33.221652Z","shell.execute_reply.started":"2022-03-14T19:57:32.982888Z","shell.execute_reply":"2022-03-14T19:57:33.220692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_dict","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:33.22324Z","iopub.execute_input":"2022-03-14T19:57:33.223493Z","iopub.status.idle":"2022-03-14T19:57:33.264123Z","shell.execute_reply.started":"2022-03-14T19:57:33.223461Z","shell.execute_reply":"2022-03-14T19:57:33.263289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_dict = dict(zip(['Claim', 'Concluding Statement', 'Counterclaim', 'Evidence',\n       'Lead', 'Position', 'Rebuttal'], range(7)))\n\nclass_dict_inv = {v: k for k, v in class_dict.items()}","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:33.265305Z","iopub.execute_input":"2022-03-14T19:57:33.265533Z","iopub.status.idle":"2022-03-14T19:57:33.271041Z","shell.execute_reply.started":"2022-03-14T19:57:33.265505Z","shell.execute_reply":"2022-03-14T19:57:33.270419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef plotImp(model, X , num = 28, fig_size = (40, 20)):\n    feature_imp = pd.DataFrame({'Value':model.booster_.feature_importance(importance_type='gain'),'Feature':X.columns})\n    plt.figure(figsize=fig_size)\n    sns.set(font_scale = 5)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n                                                        ascending=False)[0:num])\n    plt.title('LightGBM Features')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:33.27212Z","iopub.execute_input":"2022-03-14T19:57:33.272463Z","iopub.status.idle":"2022-03-14T19:57:34.079302Z","shell.execute_reply.started":"2022-03-14T19:57:33.272424Z","shell.execute_reply":"2022-03-14T19:57:34.078421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\nfrom sklearn.metrics import log_loss\n\n\ndef train_and_evaluate(all_sub_df, all_sub, all_sub_folds, all_sub_new_folds, all_sub_targets, ensemble_sub_df, ensemble_sub, ensemble_sub_folds, ensemble_sub_new_folds, ensemble_sub_targets):\n    #kf = GroupKFold(n_splits=5)\n    \n\n    # 目的変数を除いて学習\n    #X = all_sub.copy()\n    all_sub['class'] = all_sub_df['class'].map(class_dict).fillna(7).astype(int)\n    all_sub['second_class'] = all_sub_df['second_class'].map(class_dict).fillna(7).astype(int)\n    all_sub['third_class'] = all_sub_df['third_class'].map(class_dict).fillna(7).astype(int)\n    \n    y = np.array(all_sub_targets).astype(int)\n    \n    weight = 1 + (all_sub_folds.isin([2, 3,4])) * 0\n    \n    #X_ens = ensemble_sub.copy()\n    ensemble_sub['class'] = ensemble_sub_df['class'].map(class_dict).fillna(7).astype(int)\n    ensemble_sub['second_class'] = ensemble_sub_df['second_class'].map(class_dict).fillna(7).astype(int)\n    ensemble_sub['third_class'] = ensemble_sub_df['third_class'].map(class_dict).fillna(7).astype(int)\n    y_ens = np.array(ensemble_sub_targets).astype(int)    \n\n    # oof: out of foldの略。trainの学習モデルをクロスバリデーションの各foldのモデルで予測した結果で評価する。\n    #oof = np.zeros(len(all_sub))\n    oof_ens = np.zeros(len(ensemble_sub))\n    cv_score = 0\n        \n    # クロスバリデーションで評価を行う\n    for fold in range(5):\n        train_index = all_sub_new_folds[all_sub_new_folds != fold].index\n        val_index = all_sub_new_folds[all_sub_new_folds == fold].index\n        val_index_ens = ensemble_sub_new_folds[ensemble_sub_new_folds == fold].index\n        \n        X_train, y_train,w_train  = all_sub.loc[train_index, :], y[train_index], weight[train_index]\n        #X_val, y_val = all_sub.loc[val_index, :], y[val_index]\n        X_val_ens, y_val_ens = ensemble_sub.loc[val_index_ens, :], y_ens[val_index_ens]\n\n        # ハイパーパラメータはとりあえずで決めただけ\n        model = LGBMClassifier(learning_rate=0.03, num_leaves=260, n_estimators=5000, colsample_bytree=0.6, subsample=0.8, subsample_freq=2,\n                              min_child_samples=70,max_depth=-1, metrics=['binary_logloss', 'auc'])\n        \n        # 100エポック回してバリデーションセットの精度が改善しなかったら訓練終了\n        model.fit(X_train, y_train,early_stopping_rounds=75,eval_set=[(X_train, y_train), (X_val_ens, y_val_ens)], verbose=25, sample_weight = w_train, categorical_feature=['class', 'second_class', 'third_class'])\n\n        # LightGBMにおける特徴量の重要度\n        plotImp(model, X_train)\n        \n        #y_pred = model.predict_proba(X_val)[:, 1]\n        y_pred_ens = model.predict_proba(X_val_ens)[:, 1]\n        fold_cv = log_loss(y_val_ens, y_pred_ens)\n        #oof[val_index] = y_pred\n        oof_ens[val_index_ens] = y_pred_ens\n        print(f'fold {fold} BCE: {fold_cv}')\n        #pred += model.predict(X_test) / 5\n        cv_score += fold_cv / 5\n        \n        pickle.dump(model, open(f'lgb_fold{fold}.pkl', 'wb'))\n\n    print(f'CV: {cv_score}')\n    \n    return oof_ens","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:34.080647Z","iopub.execute_input":"2022-03-14T19:57:34.080892Z","iopub.status.idle":"2022-03-14T19:57:35.267264Z","shell.execute_reply.started":"2022-03-14T19:57:34.080862Z","shell.execute_reply":"2022-03-14T19:57:35.266173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_ens = train_and_evaluate(all_sub_df, all_sub, all_sub_folds, all_sub_new_folds, all_sub_targets, ensemble_sub_df, ensemble_sub, ensemble_sub_folds, ensemble_sub_new_folds, ensemble_sub_targets)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T19:57:35.268714Z","iopub.execute_input":"2022-03-14T19:57:35.2692Z","iopub.status.idle":"2022-03-14T20:29:14.383642Z","shell.execute_reply.started":"2022-03-14T19:57:35.269164Z","shell.execute_reply":"2022-03-14T20:29:14.382272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature selection\n\n\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\n\ndic_list = []\nfor fold in range(5):\n    model = pickle.load(open(f'lgb_fold{fold}.pkl', 'rb'))\n    train_index = all_sub_new_folds[all_sub_new_folds != fold].index\n    val_index = all_sub_new_folds[all_sub_new_folds == fold].index\n    val_index_ens = ensemble_sub_new_folds[ensemble_sub_new_folds == fold].index\n\n    y_ens = np.array(ensemble_sub_targets).astype(int)\n    X_val_ens, y_val_ens = ensemble_sub.loc[val_index_ens, :], y_ens[val_index_ens]\n\n    dic = {}\n    base_score = roc_auc_score(y_val_ens, model.predict_proba(X_val_ens)[:, 1])\n    cols = [col.replace('Concluding Statement', 'Concluding_Statement') for col in X_val_ens.columns]\n    for col in tqdm(model.feature_name_):\n        val2 = X_val_ens.copy()\n        val2.columns = cols\n        val2[col] = np.random.permutation(val2[col].values)\n        val2['pred'] = model.predict_proba(val2[model.feature_name_])[:, 1]\n        perm_score = roc_auc_score(y_val_ens, val2['pred'])\n        diff_score = base_score - perm_score\n        dic[col] = diff_score\n\n    dic_list.append(dic)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T20:29:14.386256Z","iopub.execute_input":"2022-03-14T20:29:14.386599Z","iopub.status.idle":"2022-03-14T21:05:28.887194Z","shell.execute_reply.started":"2022-03-14T20:29:14.386554Z","shell.execute_reply":"2022-03-14T21:05:28.885992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_dic = {}\nfor col in model.feature_name_:\n    score_dic[col] = 0\n    for dic in dic_list:\n        score_dic[col] += dic[col] / 5","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:05:28.889143Z","iopub.execute_input":"2022-03-14T21:05:28.889417Z","iopub.status.idle":"2022-03-14T21:05:28.899914Z","shell.execute_reply.started":"2022-03-14T21:05:28.889385Z","shell.execute_reply":"2022-03-14T21:05:28.898571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len([score_dic[key] for key in score_dic.keys() if score_dic[key] <= 2e-5])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:05:28.902247Z","iopub.execute_input":"2022-03-14T21:05:28.902578Z","iopub.status.idle":"2022-03-14T21:05:28.917766Z","shell.execute_reply.started":"2022-03-14T21:05:28.902533Z","shell.execute_reply":"2022-03-14T21:05:28.916684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_dic","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:05:28.919078Z","iopub.execute_input":"2022-03-14T21:05:28.919328Z","iopub.status.idle":"2022-03-14T21:05:28.955928Z","shell.execute_reply.started":"2022-03-14T21:05:28.9193Z","shell.execute_reply":"2022-03-14T21:05:28.955291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate(all_sub_df, all_sub, all_sub_folds, all_sub_new_folds, all_sub_targets, ensemble_sub_df, ensemble_sub, ensemble_sub_folds, ensemble_sub_new_folds, ensemble_sub_targets):\n    #kf = GroupKFold(n_splits=5)\n    \n\n    # 目的変数を除いて学習\n    #X = all_sub.copy()\n    all_sub['class'] = all_sub_df['class'].map(class_dict).fillna(7).astype(int)\n    all_sub['second_class'] = all_sub_df['second_class'].map(class_dict).fillna(7).astype(int)\n    all_sub['third_class'] = all_sub_df['third_class'].map(class_dict).fillna(7).astype(int)\n    \n    y = np.array(all_sub_targets).astype(int)\n    weight = 1 + (all_sub_folds.isin([2, 3,4])) * 0\n    \n    #X_ens = ensemble_sub.copy()\n    ensemble_sub['class'] = ensemble_sub_df['class'].map(class_dict).fillna(7).astype(int)\n    ensemble_sub['second_class'] = ensemble_sub_df['second_class'].map(class_dict).fillna(7).astype(int)\n    ensemble_sub['third_class'] = ensemble_sub_df['third_class'].map(class_dict).fillna(7).astype(int)\n    y_ens = np.array(ensemble_sub_targets).astype(int)    \n\n    # oof: out of foldの略。trainの学習モデルをクロスバリデーションの各foldのモデルで予測した結果で評価する。\n    #oof = np.zeros(len(all_sub))\n    oof_ens = np.zeros(len(ensemble_sub))\n    cv_score = 0\n    \n    selected_feats = [key for key in score_dic.keys() if score_dic[key] > 2e-5]\n    cols = [col.replace('Concluding Statement', 'Concluding_Statement') for col in ensemble_sub.columns]\n    ensemble_sub.columns = cols\n    all_sub.columns = cols\n        \n    # クロスバリデーションで評価を行う\n    for fold in range(5):\n        train_index = all_sub_new_folds[all_sub_new_folds != fold].index\n        val_index = all_sub_new_folds[all_sub_new_folds == fold].index\n        val_index_ens = ensemble_sub_new_folds[ensemble_sub_new_folds == fold].index\n        \n        X_train, y_train,w_train  = all_sub.loc[train_index, selected_feats], y[train_index], weight[train_index]\n        #X_val, y_val = all_sub.loc[val_index, :], y[val_index]\n        X_val_ens, y_val_ens = ensemble_sub.loc[val_index_ens, selected_feats], y_ens[val_index_ens]\n\n        # ハイパーパラメータはとりあえずで決めただけ\n        model = LGBMClassifier(learning_rate=0.01, num_leaves=170, n_estimators=5000, colsample_bytree=0.6, subsample=0.8, subsample_freq=1,\n                              min_child_samples=70, max_depth=-1, metrics=['binary_logloss', 'auc'])\n        \n        # 100エポック回してバリデーションセットの精度が改善しなかったら訓練終了\n        model.fit(X_train, y_train,early_stopping_rounds=75,eval_set=[(X_train, y_train), (X_val_ens, y_val_ens)], sample_weight = w_train, verbose=25, categorical_feature=[col for col in ['class', 'second_class', 'third_class'] if col in selected_feats])\n\n        # LightGBMにおける特徴量の重要度\n        plotImp(model, X_train)\n        \n        #y_pred = model.predict_proba(X_val)[:, 1]\n        y_pred_ens = model.predict_proba(X_val_ens)[:, 1]\n        fold_cv = log_loss(y_val_ens, y_pred_ens)\n        #oof[val_index] = y_pred\n        oof_ens[val_index_ens] = y_pred_ens\n        print(f'fold {fold} BCE: {fold_cv}')\n        #pred += model.predict(X_test) / 5\n        cv_score += fold_cv / 5\n        \n        pickle.dump(model, open(f'lgb_fold{fold}.pkl', 'wb'))\n\n    print(f'CV: {cv_score}')\n    \n    return oof_ens","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:05:28.960528Z","iopub.execute_input":"2022-03-14T21:05:28.960813Z","iopub.status.idle":"2022-03-14T21:05:28.981266Z","shell.execute_reply.started":"2022-03-14T21:05:28.960782Z","shell.execute_reply":"2022-03-14T21:05:28.980347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_ens_2 = train_and_evaluate(all_sub_df, all_sub, all_sub_folds, all_sub_new_folds, all_sub_targets, ensemble_sub_df, ensemble_sub, ensemble_sub_folds, ensemble_sub_new_folds, ensemble_sub_targets)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T21:05:28.982527Z","iopub.execute_input":"2022-03-14T21:05:28.982759Z","iopub.status.idle":"2022-03-14T21:30:02.785064Z","shell.execute_reply.started":"2022-03-14T21:05:28.98273Z","shell.execute_reply":"2022-03-14T21:30:02.784198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred3 = ensemble_sub_df.copy()\npred3['disc_prob'] = oof_ens_2\n\ncfg.proba_thresh = {\n        \"Lead\": 0.49, # 0.49\n        \"Position\": 0.32, # 0.29\n        \"Evidence\": 0.54, # 0.54\n        \"Claim\": 0.44, # 0.44\n        \"Concluding Statement\": 0.49, # 0.49\n        \"Counterclaim\": 0.48, # 0.48\n        \"Rebuttal\": 0.44, # 0.44\n    }\ncfg.min_token_thresh = {\n        \"Lead\": 4, # 4\n        \"Position\": 3, # 3\n        \"Evidence\": 11, # 11\n        \"Claim\": 1, # 1\n        \"Concluding Statement\": 7, # 7\n        \"Counterclaim\": 4, # 4\n        \"Rebuttal\": 3, # 3\n    }\ncfg.link = {\n        'Evidence': 40,\n        'Counterclaim': 200,\n        'Rebuttal': 200,\n    }\n\npred3['proba_thresh'] = pred3['class'].map(target_id_map)\npred3 = pred3[((pred3['disc_prob'] > 0.17) & ((pred3['prob'] - pred3['proba_thresh'] > 0.1) | (pred3['disc_prob'] > 0.26) | ((pred3['class'].isin(['Counterclaim']) & (pred3['prob'] - pred3['second_prob'] > 0.25)) | (pred3['class'].isin(['Rebuttal']))\n                                             )))][['id', 'class', 'predictionstring', 'prob', 'len']]\n\npred3 = post_process_sub(pred3[['id', 'class', 'predictionstring', 'prob', 'len']])\n\nf1, pred3 = score_feedback_comp(pred3[['id', 'class', 'predictionstring']], test_df[test_df.fold.isin([2,3,4])], return_class_scores=False)\nprint(f1)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T22:07:16.850344Z","iopub.execute_input":"2022-03-14T22:07:16.851577Z","iopub.status.idle":"2022-03-14T22:12:35.08039Z","shell.execute_reply.started":"2022-03-14T22:07:16.851497Z","shell.execute_reply":"2022-03-14T22:12:35.079322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 0.19 1 0.28 counterclaim 0.25\n0.6933596454784656\n0.874198322644302\n0.5936626281453867\n0.7840398625948435\n0.8470567153480871\n0.7459136512230865\n0.5047579644187009\n0.7204269699789817\n\n#\n0.692765370354402\n0.8741607637819526\n0.5951492537313433\n0.7838453858760148\n0.8472545161867286\n0.7457284172661871\n0.5045155993431856\n0.7204884723628304\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 0.19 0.1 0.28\n\n0.6898861768445864\n0.8738632162661738\n0.5830446672743846\n0.7806852452325345\n0.8475780409041981\n0.741726327164663\n0.5096870342771982\n0.7180672439948198\n\n\n# 0.17 0.1 0.26 add counterclaim\n\n0.6901163568276046\n0.8740357999630928\n0.5869024592428848\n0.7805071225715935\n0.8472408790500242\n0.7415359763074645\n0.5097701855720782\n0.7185869685049633\n\n\n# 0.16 0.1 0.27 add counterclaim 0.45\n\n0.6901163568276046\n0.8740357999630928\n0.5869024592428848\n0.7805071225715935\n0.8472408790500242\n0.7415359763074645\n0.5097701855720782\n0.7185869685049633\n\n# 0.18 0.1 0.27 feature selection and lr=0.01\n0.6900359501024939\n0.8744000590711068\n0.5874163804013741\n0.7809275723427148\n0.8477326456049861\n0.7418387629282754\n0.5109578921447919\n0.7190441803708205","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0.686601218261361\n0.8728387764149549\n0.5840014577259475\n0.781573323382747\n0.8487255165012074\n0.7412634635513388\n0.5087546239210851\n0.7176797685369489","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(0.7149, {'Claim': 0.6824, 'Concluding Statement': 0.8737, 'Counterclaim': 0.5845, 'Evidence': 0.7774, 'Lead': 0.8445, 'Position': 0.739, 'Rebuttal': 0.5025})","metadata":{},"execution_count":null,"outputs":[]}]}