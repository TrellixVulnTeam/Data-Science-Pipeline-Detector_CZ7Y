{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. 학습, 평가에 사용할 raw datas (train dir, test dir)\n# 2. 학습시 참고할 raw datas 에 대한 메타 정보 (train.csv)\n# 3. 최종 제출 파일 (sample_submission.csv)\n","metadata":{}},{"cell_type":"markdown","source":"* (Lead) 리드 - 독자의 관심을 끌고 논문을 가리키도록 하기 위해 통계, 인용문, 설명 또는 기타 장치로 시작하는 소개 \n* (Position) 입장 - 주요 질문에 대한 의견 또는 결론\n* (Claim) 주장 - 입장을 뒷받침하는 주장\n* (Counterclaim) 반대 주장 - 다른 주장을 반박하거나 반대 이유를 제시하는 주장\n* (Rebuttal) 반박 - 반대 주장을 반박하는 주장\n* (Evidence) 증거 - 주장, 반대 주장 또는 반박을 뒷받침하는 아이디어 또는 예.\n* (Concluding Statement) 결론 진술 - 주장을 다시 설명하는 결론 진술","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nfrom matplotlib.ticker import FuncFormatter\nfrom nltk.corpus import stopwords\nfrom tqdm.notebook import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nimport spacy\nfrom sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:06:53.251069Z","iopub.execute_input":"2022-01-07T08:06:53.251763Z","iopub.status.idle":"2022-01-07T08:07:05.862954Z","shell.execute_reply.started":"2022-01-07T08:06:53.25164Z","shell.execute_reply":"2022-01-07T08:07:05.861591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain[['discourse_id', 'discourse_start', 'discourse_end']] = train[['discourse_id', 'discourse_start', 'discourse_end']].astype(int)\n\nsample_submission = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\n\n#The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell\ntrain_txt = glob('../input/feedback-prize-2021/train/*.txt') \ntest_txt = glob('../input/feedback-prize-2021/test/*.txt')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:07:21.841943Z","iopub.execute_input":"2022-01-07T08:07:21.842327Z","iopub.status.idle":"2022-01-07T08:07:23.020716Z","shell.execute_reply.started":"2022-01-07T08:07:21.842284Z","shell.execute_reply":"2022-01-07T08:07:23.019713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 학습시 참고할 raw datas 에 대한 메타 정보 (train.csv)","metadata":{}},{"cell_type":"code","source":"!cat ../input/feedback-prize-2021/train/423A1CA112E2.txt","metadata":{"execution":{"iopub.status.busy":"2022-01-07T07:56:31.068442Z","iopub.execute_input":"2022-01-07T07:56:31.069511Z","iopub.status.idle":"2022-01-07T07:56:31.89098Z","shell.execute_reply.started":"2022-01-07T07:56:31.069473Z","shell.execute_reply":"2022-01-07T07:56:31.889907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 학습 데이터, 정답 데이터와 관련된 정보","metadata":{}},{"cell_type":"markdown","source":"* id\n* discourse_id\n* discourse_start, discourse_end\n* discourse_text\n* discourse_type, discourse_type_num\n* predictionstring","metadata":{}},{"cell_type":"code","source":"train.head(15)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T07:56:31.894403Z","iopub.execute_input":"2022-01-07T07:56:31.894728Z","iopub.status.idle":"2022-01-07T07:56:31.91758Z","shell.execute_reply.started":"2022-01-07T07:56:31.894696Z","shell.execute_reply":"2022-01-07T07:56:31.917001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_display = ['discourse_text', 'predictionstring']\n\ntext = train[cols_to_display].values[0][0].split(' ')\npredict_string = train[cols_to_display].values[0][1].split(' ')\nprint(text, len(text))\nprint()\nprint(predict_string, len(predict_string))","metadata":{"execution":{"iopub.status.busy":"2022-01-07T07:56:31.918481Z","iopub.execute_input":"2022-01-07T07:56:31.919027Z","iopub.status.idle":"2022-01-07T07:56:31.969233Z","shell.execute_reply.started":"2022-01-07T07:56:31.918996Z","shell.execute_reply":"2022-01-07T07:56:31.968303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this code chunk is copied from Rob Mulla\nlen_dict = {}\nword_dict = {}\nfor t in tqdm(train_txt):\n    with open(t, \"r\") as txt_file:\n        myid = t.split(\"/\")[-1].replace(\".txt\", \"\")\n        data = txt_file.read()\n        mylen = len(data.strip())\n        myword = len(data.split())\n        len_dict[myid] = mylen\n        word_dict[myid] = myword\ntrain[\"essay_len\"] = train[\"id\"].map(len_dict)\ntrain[\"essay_words\"] = train[\"id\"].map(word_dict)\n\n#add columns\ntrain[\"discourse_len\"] = train[\"discourse_text\"].apply(lambda x: len(x.split()))\ntrain[\"pred_len\"] = train[\"predictionstring\"].apply(lambda x: len(x.split()))\n\n#initialize column\ntrain['gap_length'] = np.nan\n\n#set the first one\ntrain.loc[0, 'gap_length'] = 7 #discourse start - 1 (previous end is always -1)\n\n#loop over rest\nfor i in tqdm(range(1, len(train))):\n    #gap if difference is not 1 within an essay\n    if ((train.loc[i, \"id\"] == train.loc[i-1, \"id\"])\\\n        and (train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] > 1)):\n        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] - 2\n        #minus 2 as the previous end is always -1 and the previous start always +1\n    #gap if the first discourse of an new essay does not start at 0\n    elif ((train.loc[i, \"id\"] != train.loc[i-1, \"id\"])\\\n        and (train.loc[i, \"discourse_start\"] != 0)):\n        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] -1\n\n\n #is there any text after the last discourse of an essay?\nlast_ones = train.drop_duplicates(subset=\"id\", keep='last')\nlast_ones['gap_end_length'] = np.where((last_ones.discourse_end < last_ones.essay_len),\\\n                                       (last_ones.essay_len - last_ones.discourse_end),\\\n                                       np.nan)\n\ncols_to_merge = ['id', 'discourse_id', 'gap_end_length']\ntrain = train.merge(last_ones[cols_to_merge], on = [\"id\", \"discourse_id\"], how = \"left\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:08:04.495066Z","iopub.execute_input":"2022-01-07T08:08:04.495464Z","iopub.status.idle":"2022-01-07T08:09:38.005901Z","shell.execute_reply.started":"2022-01-07T08:08:04.495426Z","shell.execute_reply":"2022-01-07T08:09:38.0052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualization","metadata":{}},{"cell_type":"code","source":"def add_gap_rows(essay):\n    cols_to_keep = ['discourse_start', 'discourse_end', 'discourse_type', 'gap_length', 'gap_end_length']\n    df_essay = train.query('id == @essay')[cols_to_keep].reset_index(drop = True)\n\n    #index new row\n    insert_row = len(df_essay)\n   \n    for i in range(1, len(df_essay)):          \n        if df_essay.loc[i,\"gap_length\"] >0:\n            if i == 0:\n                start = 0 #as there is no i-1 for first row\n                end = df_essay.loc[0, 'discourse_start'] -1\n                disc_type = \"Nothing\"\n                gap_end = np.nan\n                gap = np.nan\n                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n                insert_row += 1\n            else:\n                start = df_essay.loc[i-1, \"discourse_end\"] + 1\n                end = df_essay.loc[i, 'discourse_start'] -1\n                disc_type = \"Nothing\"\n                gap_end = np.nan\n                gap = np.nan\n                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n                insert_row += 1\n\n    df_essay = df_essay.sort_values(by = \"discourse_start\").reset_index(drop=True)\n\n    #add gap at end\n    if df_essay.loc[(len(df_essay)-1),'gap_end_length'] > 0:\n        start = df_essay.loc[(len(df_essay)-1), \"discourse_end\"] + 1\n        end = start + df_essay.loc[(len(df_essay)-1), 'gap_end_length']\n        disc_type = \"Nothing\"\n        gap_end = np.nan\n        gap = np.nan\n        df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n        \n    return(df_essay)\n\n\ndef print_colored_essay(essay):\n    df_essay = add_gap_rows(essay)\n    #code from https://www.kaggle.com/odins0n/feedback-prize-eda, but adjusted to df_essay\n    essay_file = \"../input/feedback-prize-2021/train/\" + essay + \".txt\"\n\n    ents = []\n    for i, row in df_essay.iterrows():\n        ents.append({\n                        'start': int(row['discourse_start']), \n                         'end': int(row['discourse_end']), \n                         'label': row['discourse_type']\n                    })\n\n    with open(essay_file, 'r') as file: data = file.read()\n\n    doc2 = {\n        \"text\": data,\n        \"ents\": ents,\n    }\n\n    colors = {'Lead': '#EE11D0','Position': '#AB4DE1','Claim': '#1EDE71','Evidence': '#33FAFA','Counterclaim': '#4253C1','Concluding Statement': 'yellow','Rebuttal': 'red'}\n    options = {\"ents\": df_essay.discourse_type.unique().tolist(), \"colors\": colors}\n    spacy.displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);\n    \nprint_colored_essay(\"423A1CA112E2\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:09:45.626374Z","iopub.execute_input":"2022-01-07T08:09:45.62748Z","iopub.status.idle":"2022-01-07T08:09:45.669009Z","shell.execute_reply.started":"2022-01-07T08:09:45.627408Z","shell.execute_reply":"2022-01-07T08:09:45.66826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터 이슈 점검","metadata":{}},{"cell_type":"code","source":"print(f\"The total number of discourses is {len(train)}\")\n\nprint(len(train.query('discourse_len != pred_len')[cols_to_display]))\ntrain.query('discourse_len != pred_len')[cols_to_display].head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:09:49.419972Z","iopub.execute_input":"2022-01-07T08:09:49.420973Z","iopub.status.idle":"2022-01-07T08:09:49.450709Z","shell.execute_reply.started":"2022-01-07T08:09:49.42092Z","shell.execute_reply":"2022-01-07T08:09:49.449794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# discourse type 종류 별 데이터 개수","metadata":{}},{"cell_type":"code","source":"train.groupby('discourse_type')['discourse_type'].count()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:09:51.800974Z","iopub.execute_input":"2022-01-07T08:09:51.801584Z","iopub.status.idle":"2022-01-07T08:09:51.840904Z","shell.execute_reply.started":"2022-01-07T08:09:51.801542Z","shell.execute_reply":"2022-01-07T08:09:51.840262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# discourse type 종류 별 평균 길이","metadata":{}},{"cell_type":"code","source":"train.groupby('discourse_type')['discourse_len'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:09:52.260087Z","iopub.execute_input":"2022-01-07T08:09:52.260872Z","iopub.status.idle":"2022-01-07T08:09:52.286898Z","shell.execute_reply.started":"2022-01-07T08:09:52.260826Z","shell.execute_reply":"2022-01-07T08:09:52.286261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\n\nax1 = fig.add_subplot(211)\nax1 = train.groupby('discourse_type')['discourse_len'].mean().sort_values().plot(kind=\"barh\")\nax1.set_title(\"Average number of words versus Discourse Type\", fontsize=14, fontweight = 'bold')\nax1.set_xlabel(\"Average number of words\", fontsize = 10)\nax1.set_ylabel(\"\")\n\nax2 = fig.add_subplot(212)\nax2 = train.groupby('discourse_type')['discourse_type'].count().sort_values().plot(kind=\"barh\")\nax2.get_xaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ','))) #add thousands separator\nax2.set_title(\"Frequency of Discourse Type in all essays\", fontsize=14, fontweight = 'bold')\nax2.set_xlabel(\"Frequency\", fontsize = 10)\nax2.set_ylabel(\"\")\n\nplt.tight_layout(pad=2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:09:52.761058Z","iopub.execute_input":"2022-01-07T08:09:52.761765Z","iopub.status.idle":"2022-01-07T08:09:53.341672Z","shell.execute_reply.started":"2022-01-07T08:09:52.761703Z","shell.execute_reply":"2022-01-07T08:09:53.340636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 각 discourse_type_num이 Essay에 포함되어 있는 비율","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nav_per_essay = train['discourse_type_num'].value_counts(ascending = True).rename_axis('discourse_type_num').reset_index(name='count')\nav_per_essay['perc'] = round((av_per_essay['count'] / train.id.nunique()),3) * 100\nav_per_essay = av_per_essay.set_index('discourse_type_num')\nax = av_per_essay.query('perc > 3')['perc'].plot(kind=\"barh\")\nax.set_title(\"discourse_type_num: Percent present in essays\", fontsize=20, fontweight = 'bold')\nax.bar_label(ax.containers[0], label_type=\"edge\")\nax.set_xlabel(\"Percent\")\nax.set_ylabel(\"\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:09:54.621352Z","iopub.execute_input":"2022-01-07T08:09:54.621724Z","iopub.status.idle":"2022-01-07T08:09:55.084932Z","shell.execute_reply.started":"2022-01-07T08:09:54.621684Z","shell.execute_reply":"2022-01-07T08:09:55.08387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 이슈 점검 2","metadata":{}},{"cell_type":"markdown","source":"# 분류 하고자 하는 Discourse_type이 마킹 되어 있지 않는 Gap 분석","metadata":{}},{"cell_type":"code","source":"#display an example\n#how many pieces of tekst are not used as discourses?\nprint(f\"Besides the {len(train)} discourse texts, there are {len(train.query('gap_length.notna()', engine='python'))+ len(train.query('gap_end_length.notna()', engine='python'))} pieces of text not classified.\")\n\ncols_to_display = ['id', 'discourse_start', 'discourse_end', 'discourse_type', 'essay_len', 'gap_length', 'gap_end_length']\ntrain[cols_to_display].query('id == \"AFEC37C2D43F\"')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:10:50.889899Z","iopub.execute_input":"2022-01-07T08:10:50.890661Z","iopub.status.idle":"2022-01-07T08:10:50.950605Z","shell.execute_reply.started":"2022-01-07T08:10:50.890602Z","shell.execute_reply":"2022-01-07T08:10:50.949541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_gaps = train.groupby('id').agg({'essay_len': 'first',\\\n                                               'gap_length': 'sum',\\\n                                               'gap_end_length': 'sum'})\ntotal_gaps['perc_not_classified'] = round(((total_gaps.gap_length + total_gaps.gap_end_length)/total_gaps.essay_len),2)\n\ntotal_gaps.sort_values(by = 'perc_not_classified', ascending = False).head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:09:59.260367Z","iopub.execute_input":"2022-01-07T08:09:59.261512Z","iopub.status.idle":"2022-01-07T08:09:59.335764Z","shell.execute_reply.started":"2022-01-07T08:09:59.261453Z","shell.execute_reply":"2022-01-07T08:09:59.334719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.sort_values(by = \"gap_length\", ascending = False)[cols_to_display].head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:10:12.42909Z","iopub.execute_input":"2022-01-07T08:10:12.429467Z","iopub.status.idle":"2022-01-07T08:10:12.488075Z","shell.execute_reply.started":"2022-01-07T08:10:12.429427Z","shell.execute_reply":"2022-01-07T08:10:12.487126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_gaps = (train.gap_length[~train.gap_length.isna()]).append((train.gap_end_length[~train.gap_end_length.isna()]), ignore_index= True)\n#filter outliers\nall_gaps = all_gaps[all_gaps<300]\nfig = plt.figure(figsize=(12,6))\nall_gaps.plot.hist(bins=100)\nplt.title(\"Histogram of gap length (gaps up to 300 characters only)\")\nplt.xticks(rotation=0)\nplt.xlabel(\"Length of gaps in characters\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T07:41:05.524627Z","iopub.execute_input":"2022-01-07T07:41:05.52521Z","iopub.status.idle":"2022-01-07T07:41:05.925763Z","shell.execute_reply.started":"2022-01-07T07:41:05.525167Z","shell.execute_reply":"2022-01-07T07:41:05.925134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_gap_rows(\"7330313ED3F0\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:14:43.271913Z","iopub.execute_input":"2022-01-07T08:14:43.2723Z","iopub.status.idle":"2022-01-07T08:14:43.302016Z","shell.execute_reply.started":"2022-01-07T08:14:43.272261Z","shell.execute_reply":"2022-01-07T08:14:43.301025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_colored_essay(\"7330313ED3F0\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T07:47:11.71753Z","iopub.execute_input":"2022-01-07T07:47:11.717867Z","iopub.status.idle":"2022-01-07T07:47:11.741843Z","shell.execute_reply.started":"2022-01-07T07:47:11.717832Z","shell.execute_reply":"2022-01-07T07:47:11.740965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}