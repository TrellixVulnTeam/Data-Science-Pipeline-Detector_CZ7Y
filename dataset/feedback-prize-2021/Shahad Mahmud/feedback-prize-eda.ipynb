{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd\n\nfrom spacy import displacy\n\n# settings\npd.set_option('display.max_colwidth', 200)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/feedback-prize-2021/train'\ntrain_csv_path = '../input/feedback-prize-2021/train.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# total number of files\ntrain_files = os.listdir(train_dir)\nlen(train_files)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read the CSV file\ntrain_df = pd.read_csv(train_csv_path)\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label names\ntrain_df.discourse_type.unique().tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CSV total number of rows\nlen(train_df.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are total *15,594* text files in the training dir. But *1,44,293* rows in the CSV file. That meas one file may contain multiple lebels/segments. Thus this can be a **multi-label classification problem** like NER.","metadata":{}},{"cell_type":"code","source":"# Check if there is any null\ntrain_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Column names\ncols = [*train_df]\ncols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Type of data in each column\ntrain_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Discourse type distribution\ntrain_df.discourse_type.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.discourse_type.value_counts().plot(kind='pie', figsize=(8,8), ylabel='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly the dataset is not balanced. Examples of *Evidence* and *Claim* contains many examples where other labels have very few examples. ","metadata":{}},{"cell_type":"code","source":"# number of chars frequency in discourse text\ntrain_df['discourse_text'].apply(len).value_counts().hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization ","metadata":{}},{"cell_type":"code","source":"# View a text file\nindex = 1\nfile_path = os.path.join(train_dir, train_files[index])\nfile_content = open(file_path).read()\nfile_content","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View discourses\nfile_id = train_files[index].split('.')[0]\ntrain_df[train_df['id'] == file_id]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the segments. \ncolors = {\n    'Lead': '#F5B7B1',\n    'Position': '#D7BDE2',\n    'Evidence': '#AED6F1',\n    'Claim': '#A3E4D7',\n    'Concluding Statement': '#F9E79F',\n    'Counterclaim': '#E5E7E9',\n    'Rebuttal': '#FEF9E7'\n}\n\ndef visualize_segments(df, text, file_id):\n    segments = []\n    seg_df = df[df['id'] == file_id]\n    lable_names = df.discourse_type.unique().tolist()\n    \n    for _, row in seg_df.iterrows():\n        seg_info = {\n            'start': int(row['discourse_start']),\n            'end': int(row['discourse_end']),\n            'label': row['discourse_type'],\n        }\n        segments.append(seg_info)\n\n    text_info = {\n        'text': text,\n        'ents': segments,\n        'title': f'{file_id}.txt'\n    }\n    \n    configs = {\n        'colors': colors\n    }\n    \n    displacy.render(\n        text_info, \n        style='ent',\n        options=configs,\n        manual=True,\n        jupyter=True\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_segments(train_df, file_content, file_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}