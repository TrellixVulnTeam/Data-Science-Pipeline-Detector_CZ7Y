{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"ls -l ../input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-29T22:04:29.742536Z","iopub.execute_input":"2022-03-29T22:04:29.742882Z","iopub.status.idle":"2022-03-29T22:04:30.547031Z","shell.execute_reply.started":"2022-03-29T22:04:29.742803Z","shell.execute_reply":"2022-03-29T22:04:30.546243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/pipwheels/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n!pip install ../input/pipwheels/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install ../input/pipwheels/transformers-4.16.0.dev0-py3-none-any.whl\n!pip install ../input/pipwheels/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:04:30.549735Z","iopub.execute_input":"2022-03-29T22:04:30.549994Z","iopub.status.idle":"2022-03-29T22:06:26.260368Z","shell.execute_reply.started":"2022-03-29T22:04:30.549967Z","shell.execute_reply":"2022-03-29T22:06:26.259536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r ../input/feedbackrepo/kaggle-feedback-clean/* ./","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:26.261791Z","iopub.execute_input":"2022-03-29T22:06:26.262041Z","iopub.status.idle":"2022-03-29T22:06:27.059092Z","shell.execute_reply.started":"2022-03-29T22:06:26.262008Z","shell.execute_reply":"2022-03-29T22:06:27.058227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy as sp\nimport os\nimport json\nimport sys\nimport importlib\nimport multiprocessing as mp\nimport gc\nfrom tqdm.auto import tqdm\nimport glob\nimport torch\nfrom copy import copy\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import DataLoader\nimport torch_scatter\nimport pickle\nimport collections","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:27.063553Z","iopub.execute_input":"2022-03-29T22:06:27.06379Z","iopub.status.idle":"2022-03-29T22:06:28.608906Z","shell.execute_reply.started":"2022-03-29T22:06:27.063764Z","shell.execute_reply":"2022-03-29T22:06:28.608172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True\n\nsys.path.append('./configs')\nsys.path.append('./data')\nsys.path.append('./models')\nsys.path.append('./scripts')\nsys.path.append('./blend')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:28.611164Z","iopub.execute_input":"2022-03-29T22:06:28.611582Z","iopub.status.idle":"2022-03-29T22:06:28.616856Z","shell.execute_reply.started":"2022-03-29T22:06:28.611543Z","shell.execute_reply":"2022-03-29T22:06:28.616233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLD = 0\n\ncache_allowed = False\nTHRESHOLD = True\nnposn = 3000\nNMODELS = 1","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:28.618172Z","iopub.execute_input":"2022-03-29T22:06:28.618419Z","iopub.status.idle":"2022-03-29T22:06:28.625971Z","shell.execute_reply.started":"2022-03-29T22:06:28.618384Z","shell.execute_reply":"2022-03-29T22:06:28.625252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ppcfg = importlib.import_module('cfg_dh_12G').cfg\nmap_clip = ppcfg.map_clip_init\nload_configs = ppcfg.load_configs.split()\nmodel_weights = [ppcfg.baseline_weights[c] for c in load_configs]\nstart_threshold = ppcfg.baseline_start_threshold\nposition_proba_threshold = ppcfg.baseline_position_proba_threshold\nname_map = ppcfg.name_map\nproba_thresh = ppcfg.proba_thresh\nprint(f'load order \\n{load_configs}\\n')\nprint(f'map clip \\n{json.dumps(map_clip, indent = 4)}\\n')\nprint(f'model weights \\n{json.dumps(ppcfg.baseline_weights, indent = 4)}\\n')\nprint(f'model weights order \\n{json.dumps(model_weights, indent = 4)}\\n')\nprint(f'name map \\n{json.dumps(name_map, indent = 4)}\\n')\nprint(f'proba thresh \\n{json.dumps(proba_thresh, indent = 4)}\\n')\nprint(f'start threshold \\n{start_threshold}\\n')\nprint(f'position_proba_threshold \\n{position_proba_threshold}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:28.629175Z","iopub.execute_input":"2022-03-29T22:06:28.629399Z","iopub.status.idle":"2022-03-29T22:06:28.641686Z","shell.execute_reply.started":"2022-03-29T22:06:28.62937Z","shell.execute_reply":"2022-03-29T22:06:28.640821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMP_FOLDER = '../input/feedback-prize-2021/'\n\ntrain = pd.read_csv(COMP_FOLDER + 'train.csv')\nSAMPLE_SUBMISSION = pd.read_csv(COMP_FOLDER + 'sample_submission.csv')\nN_CORES = mp.cpu_count()\n\nRAM_CHECK = False\nOOF_CHECK = False\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nPUBLIC_RUN = len(SAMPLE_SUBMISSION) == 5\nTEST_FOLDER = COMP_FOLDER + 'test/'\n\nids = SAMPLE_SUBMISSION[\"id\"].unique()\n\nprint(SAMPLE_SUBMISSION.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:28.642953Z","iopub.execute_input":"2022-03-29T22:06:28.643619Z","iopub.status.idle":"2022-03-29T22:06:30.073897Z","shell.execute_reply.started":"2022-03-29T22:06:28.643583Z","shell.execute_reply":"2022-03-29T22:06:30.073138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cfg(CFG):\n    cfg = importlib.import_module('default_config')\n    importlib.reload(cfg)\n    cfg = importlib.import_module(CFG)\n    importlib.reload(cfg)\n    cfg = copy(cfg.cfg)\n    print(CFG, cfg.model, cfg.dataset, cfg.backbone, cfg.tokenizer, cfg.pretrained_weights)\n\n    cfg.data_dir = COMP_FOLDER\n    cfg.tokenizer = '../input/feedback-huggingface-models/' + cfg.tokenizer\n    cfg.backbone = '../input/feedback-huggingface-models/' + cfg.backbone\n    cfg.data_folder = TEST_FOLDER\n    cfg.pretrained = False\n    cfg.pretrained_weights = False\n    cfg.batch_size = 1\n    cfg.offline_inference = True\n    return cfg\n    \ndef get_dl(cfg):\n    ds = importlib.import_module(cfg.dataset)\n    importlib.reload(ds)\n\n    CustomDataset = ds.CustomDataset\n    batch_to_device = ds.batch_to_device\n    val_collate_fn = ds.val_collate_fn\n\n    test_ds = CustomDataset(SAMPLE_SUBMISSION, cfg, cfg.val_aug, mode=\"test\")\n    test_dl = DataLoader(\n        test_ds,\n        shuffle=False,\n        batch_size=cfg.batch_size,\n        num_workers=N_CORES,\n        pin_memory=True,\n        collate_fn=val_collate_fn\n    )\n\n    return test_dl, batch_to_device\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")#['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\n\ndef get_nets(cfg,state_dicts,test_ds, regenerate_pos_embeddings=False):\n    model = importlib.import_module(cfg.model)\n    importlib.reload(model)\n    Net = model.Net\n\n    nets = []\n\n    for i,state_dict in enumerate(state_dicts):\n        net = Net(cfg).eval().to(DEVICE)\n        print(\"loading dict\")\n        sd = get_state_dict(state_dict)\n        if \"model\" in sd.keys():\n            sd = sd[\"model\"]\n        if regenerate_pos_embeddings:\n            sd.update({'backbone.embeddings.position_ids':torch.arange(cfg.max_length).unsqueeze(0)})\n        net.load_state_dict(sd, strict=True)\n        net.return_preds = True\n        nets += [net.half()]\n        del sd\n        gc.collect()\n    return nets","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:30.075103Z","iopub.execute_input":"2022-03-29T22:06:30.075539Z","iopub.status.idle":"2022-03-29T22:06:30.092392Z","shell.execute_reply.started":"2022-03-29T22:06:30.075501Z","shell.execute_reply":"2022-03-29T22:06:30.091629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=False, regenerate_pos_embeddings=False):\n    cache_dir = \"./cache/\"\n    os.makedirs(cache_dir, exist_ok=True)\n    \n    if os.path.isfile(f'{cache_dir}class_preds_word_{name}_fold{FOLD}.data') and os.path.isfile(f'{cache_dir}sep_preds_word_{name}_fold{FOLD}.data') and cache_allowed:\n        print(f\"{name} cached preds exist, loading from cache ...\")\n\n        with open(f\"{cache_dir}class_preds_word_{name}_fold{FOLD}.data\", \"rb\") as filehandle:\n            # read the data as binary data stream\n            class_preds_word = pickle.load(filehandle)\n\n        with open(f\"{cache_dir}sep_preds_word_{name}_fold{FOLD}.data\", \"rb\") as filehandle:\n            # read the data as binary data stream\n            sep_preds_word = pickle.load(filehandle)\n    else:\n        print(f\"{name} cached preds do not exist, running inference ...\")\n        \n        test_dl, batch_to_device = get_dl(cfg)\n\n        if OOF_CHECK:\n            nets = get_nets(cfg, [state_dict_fps[FOLD]], test_dl.dataset, regenerate_pos_embeddings=regenerate_pos_embeddings)\n        else:\n            nets = get_nets(cfg, state_dict_fps, test_dl.dataset, regenerate_pos_embeddings=regenerate_pos_embeddings)\n\n        class_preds_word = []\n        sep_preds_word = []\n\n        with torch.inference_mode():\n            for batch in tqdm(test_dl):\n                batch = batch_to_device(batch,DEVICE)\n\n                outs = [net(batch) for net in nets] \n                class_preds = torch.stack([out['class_preds'] for out in outs]).mean(0)\n                sep_preds = torch.stack([out['sep_preds'] for out in outs]).mean(0).sigmoid()\n                wordposition = outs[0]['wordposition']\n                attention_mask = outs[0][\"attention_mask\"]\n                class_preds[:, :, 8][attention_mask == 0] = 5000\n\n                for i in range(class_preds.shape[0]):\n\n                    class_pred = class_preds[i]\n                    sep_pred = sep_preds[i]\n\n                    word_pos = wordposition[i].contiguous()\n                    word_pos[word_pos==-1] = word_pos.max() + 1\n                    class_pred_word = torch_scatter.scatter_mean(class_pred.permute(1,0),word_pos).permute(1,0)[:-1]\n                    sep_pred_word, _ = torch_scatter.scatter_max(sep_pred.permute(1,0),word_pos)\n                    sep_pred_word = sep_pred_word.permute(1,0)[:-1]\n                    class_preds_word += [class_pred_word.cpu()]\n                    sep_preds_word += [sep_pred_word.cpu()]\n\n\n        del nets, test_dl\n        gc.collect()\n        torch.cuda.empty_cache()\n\n        with open(f'{cache_dir}class_preds_word_{name}_fold{FOLD}.data', 'wb') as filehandle:\n            # store the data as binary data stream\n            pickle.dump(class_preds_word, filehandle)\n\n        with open(f'{cache_dir}sep_preds_word_{name}_fold{FOLD}.data', 'wb') as filehandle:\n            # store the data as binary data stream\n            pickle.dump(sep_preds_word, filehandle)\n\n    return class_preds_word, sep_preds_word","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:30.095756Z","iopub.execute_input":"2022-03-29T22:06:30.096152Z","iopub.status.idle":"2022-03-29T22:06:30.112692Z","shell.execute_reply.started":"2022-03-29T22:06:30.096116Z","shell.execute_reply":"2022-03-29T22:06:30.111796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_preds_word_blend = []\nsep_preds_word_blend = []\nnamecheck = []","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:30.113867Z","iopub.execute_input":"2022-03-29T22:06:30.114644Z","iopub.status.idle":"2022-03-29T22:06:30.124515Z","shell.execute_reply.started":"2022-03-29T22:06:30.114605Z","shell.execute_reply":"2022-03-29T22:06:30.123711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_ch_10c'\nnamecheck.append(name)\nseeds = [245426]  # , 369687 946118\ncfg = get_cfg(name)\ncfg.dataset = \"ds_ch_4_var_tok_fix\"\ncfg.model = \"mdl_ch_2d\"\ncfg.max_length = 4096\ncfg.max_length_test = 4096\n\nstate_dict_fps = [f'../input/feedback/cfg_ch_10c/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:06:30.125623Z","iopub.execute_input":"2022-03-29T22:06:30.125961Z","iopub.status.idle":"2022-03-29T22:07:25.941148Z","shell.execute_reply.started":"2022-03-29T22:06:30.125924Z","shell.execute_reply":"2022-03-29T22:07:25.940324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_ch_11'\n\nnamecheck.append(name)\nseeds = [295209]  # , 634549 447068\ncfg = get_cfg(name)\ncfg.dataset = 'ds_ch_4_var_tok_fix'\ncfg.model = \"mdl_ch_4\"\ncfg.max_length = 1024\ncfg.max_length_test = 1024\n\nstate_dict_fps = [f'../input/feedback/cfg_ch_11/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:07:25.942428Z","iopub.execute_input":"2022-03-29T22:07:25.94268Z","iopub.status.idle":"2022-03-29T22:08:27.136774Z","shell.execute_reply.started":"2022-03-29T22:07:25.942643Z","shell.execute_reply":"2022-03-29T22:08:27.135884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_pp_12b'\nnamecheck.append(name)\n\nseeds = [743507] # , 830398\ncfg = get_cfg(name)\ncfg.dataset = 'ds_pp_6d'\ncfg.model = \"mdl_pp_7e\"\ncfg.max_length = 4096\ncfg.max_length_test = 4096\n\nstate_dict_fps = [f'../input/feedback/cfg_pp_12b/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:08:27.138509Z","iopub.execute_input":"2022-03-29T22:08:27.138803Z","iopub.status.idle":"2022-03-29T22:09:00.883515Z","shell.execute_reply.started":"2022-03-29T22:08:27.138765Z","shell.execute_reply":"2022-03-29T22:09:00.882719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_ch_33d'\nnamecheck.append(name)\n\nseeds = [313148] \ncfg = get_cfg(name)\ncfg.model = 'mdl_ch_8_deberta_varlen'\ncfg.dataset = 'ds_ch_6_varlen'\ncfg.max_length = 4096\ncfg.tokenizer = '../input/feedback-huggingface-models/transformers/deberta-v2-xlarge'\n\nstate_dict_fps = [f'../input/feedback/cfg_ch_33d/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed, regenerate_pos_embeddings=True)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:09:00.884803Z","iopub.execute_input":"2022-03-29T22:09:00.885082Z","iopub.status.idle":"2022-03-29T22:09:57.853782Z","shell.execute_reply.started":"2022-03-29T22:09:00.88503Z","shell.execute_reply":"2022-03-29T22:09:57.852864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_ch_34d'\nnamecheck.append(name)\n\nseeds = [520521] # , 827251\ncfg = get_cfg(name)\ncfg.model = 'mdl_ch_8_deberta_varlen'\ncfg.dataset = 'ds_ch_6_varlen'\ncfg.max_length = 1250\ncfg.tokenizer = '../input/feedback-huggingface-models/transformers/deberta-v2-xxlarge'\n\nstate_dict_fps = [f'../input/feedback/cfg_ch_34d/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed, regenerate_pos_embeddings=True)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:09:57.855342Z","iopub.execute_input":"2022-03-29T22:09:57.855629Z","iopub.status.idle":"2022-03-29T22:11:24.538965Z","shell.execute_reply.started":"2022-03-29T22:09:57.855578Z","shell.execute_reply":"2022-03-29T22:11:24.538131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_dh_02C'\nnamecheck.append(name)\n\nseeds = [892929] \ncfg = get_cfg(name)\ncfg.model = \"mdl_dh_1A_bigbird\"\ncfg.tokenizer = '../input/bigbird-roberta-large/'\ncfg.max_length = 4096\ncfg.max_length_test = 4096\ncfg.verify_sample = False\ncfg.config_path = \"./configs/cfg_dh_02_bigbird_config.json\"\nstate_dict_fps = [f'../input/feedback/cfg_dh_02C/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:11:24.5405Z","iopub.execute_input":"2022-03-29T22:11:24.540754Z","iopub.status.idle":"2022-03-29T22:11:56.178968Z","shell.execute_reply.started":"2022-03-29T22:11:24.540717Z","shell.execute_reply":"2022-03-29T22:11:56.178127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_dh_03E'\nnamecheck.append(name)\n\nseeds = [461966] # , 860867\ncfg = get_cfg(name)\ncfg.model = \"mdl_dh_2_bart_pp\"\ncfg.max_length = 1024\ncfg.max_length_test = 1024\ncfg.verify_sample = False\ncfg.config_path = \"./configs/cfg_dh_03_bart_conifg.json\"\nstate_dict_fps = [f'../input/feedback/cfg_dh_03E/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:11:56.180385Z","iopub.execute_input":"2022-03-29T22:11:56.181447Z","iopub.status.idle":"2022-03-29T22:12:30.619726Z","shell.execute_reply.started":"2022-03-29T22:11:56.181404Z","shell.execute_reply":"2022-03-29T22:12:30.618925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_ch_32c'\nnamecheck.append(name)\n\nseeds = [453209]  # ,529051 ,863515\ncfg = get_cfg(name)\ncfg.model = 'mdl_ch_8_deberta_varlen'\ncfg.dataset = 'ds_ch_6_varlen'\ncfg.max_length = 4096\ncfg.tokenizer = '../input/feedback-huggingface-models/transformers/deberta-v3-large'\n\nstate_dict_fps = [f'../input/feedback/cfg_ch_32c/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed, regenerate_pos_embeddings=True)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:12:30.621387Z","iopub.execute_input":"2022-03-29T22:12:30.621647Z","iopub.status.idle":"2022-03-29T22:13:02.985376Z","shell.execute_reply.started":"2022-03-29T22:12:30.621612Z","shell.execute_reply":"2022-03-29T22:13:02.984557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_dh_04C'\nnamecheck.append(name)\n\nseeds = [430400] # , 860867\ncfg = get_cfg(name)\ncfg.model = \"mdl_dh_3_deberta\"\ncfg.tokenizer = '../input/feedback-huggingface-models/transformers/deberta-large'\ncfg.max_length = 2000\ncfg.max_length_test = 2000\ncfg.verify_sample = False\ncfg.config_path = \"./configs/cfg_dh_03_deberta_config.json\"\nstate_dict_fps = [f'../input/feedback/cfg_dh_04C/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:13:02.986818Z","iopub.execute_input":"2022-03-29T22:13:02.987078Z","iopub.status.idle":"2022-03-29T22:13:35.916761Z","shell.execute_reply.started":"2022-03-29T22:13:02.987026Z","shell.execute_reply":"2022-03-29T22:13:35.915965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_dh_05D'\nnamecheck.append(name)\n\nseeds = [181857] \ncfg = get_cfg(name)\ncfg.model = \"mdl_dh_3_deberta\"\ncfg.tokenizer = '../input/deberta-xlarge'\ncfg.dataset = 'ds_dh_2A'\ncfg.max_length = 2000\ncfg.max_length_test = 2000\ncfg.verify_sample = False\ncfg.verify_sample = False\ncfg.config_path = \"./configs/cfg_dh_03_debertaxl_config.json\"\nstate_dict_fps = [f'../input/feedback/cfg_dh_05D/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:13:35.918209Z","iopub.execute_input":"2022-03-29T22:13:35.918494Z","iopub.status.idle":"2022-03-29T22:14:28.64191Z","shell.execute_reply.started":"2022-03-29T22:13:35.918455Z","shell.execute_reply":"2022-03-29T22:14:28.641123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_dh_14A'\nnamecheck.append(name)\n\nseeds = [840631] \ncfg = get_cfg(name)\ncfg.model = \"mdl_dh_8_deberta\"\ncfg.tokenizer = '../input/feedback-huggingface-models/transformers/deberta-large'\ncfg.max_length = 1536\ncfg.max_length_test = 1536\ncfg.verify_sample = False\ncfg.offline_inference = True\ncfg.config_path = \"./configs/cfg_dh_03_deberta_config.json\"\nstate_dict_fps = [f'../input/feedback/cfg_dh_14A/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:14:28.643185Z","iopub.execute_input":"2022-03-29T22:14:28.643692Z","iopub.status.idle":"2022-03-29T22:15:01.431696Z","shell.execute_reply.started":"2022-03-29T22:14:28.643652Z","shell.execute_reply":"2022-03-29T22:15:01.430916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'cfg_dh_14F'\nnamecheck.append(name)\n\nseeds = [310279] \ncfg = get_cfg(name)\ncfg.model = \"mdl_dh_8C_deberta\"\ncfg.tokenizer = '../input/deberta-xlarge'\ncfg.dataset = 'ds_dh_1A'\ncfg.max_length = 1536\ncfg.max_length_test = 1536\ncfg.verify_sample = False\ncfg.offline_inference = True\ncfg.config_path = \"./configs/cfg_dh_03_debertaxl_config.json\"\nstate_dict_fps = [f'../input/feedback/cfg_dh_14F/fold-1/checkpoint_last_seed{seed}.pth' for seed in seeds]\n\nclass_preds_word, sep_preds_word = get_preds(name, FOLD, cfg, state_dict_fps, cache_allowed=cache_allowed)\n\nclass_preds_word_blend += [class_preds_word]\nsep_preds_word_blend += [sep_preds_word]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:01.433187Z","iopub.execute_input":"2022-03-29T22:15:01.433433Z","iopub.status.idle":"2022-03-29T22:15:54.535556Z","shell.execute_reply.started":"2022-03-29T22:15:01.433397Z","shell.execute_reply":"2022-03-29T22:15:54.534746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the load order is the same\nassert namecheck == load_configs","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:54.536933Z","iopub.execute_input":"2022-03-29T22:15:54.537225Z","iopub.status.idle":"2022-03-29T22:15:54.542113Z","shell.execute_reply.started":"2022-03-29T22:15:54.537186Z","shell.execute_reply":"2022-03-29T22:15:54.541269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def blendfn(preds_word_blend, \n            predidls, \n            start_threshold = 0.55, \n            position_proba_thresh = 0.5,\n            map_clip_curr = {},\n            nposn = 3000):\n    \n    preds = torch.zeros(10, *preds_word_blend.shape[1:])\n    preds[:9] = preds_word_blend.clone()\n    nposn  = preds.shape[-1]\n    name_map1 = copy(name_map)\n    name_map1[8] = 'Other'\n    \n    # Start here\n    filemat = np.expand_dims(predidls, 1).repeat(nposn, 1)\n    posnmat = np.expand_dims(np.arange(nposn), 0).repeat(len(predidls), 0)\n    logitmat = preds.view(10, -1)\n    \n    idx = logitmat.sum(0)!=0\n    predfnm  = filemat.flatten()[idx]\n    predpos = torch.from_numpy(posnmat.flatten()[idx])\n    logitall = logitmat[:, idx].transpose(1,0)\n    \n    probscls = logitall[:,:8].numpy() #* proba_weight\n    probsbrk = logitall[:,8:].numpy()\n    \n    classidx = pd.Series(probscls.argmax(1))#.map(name_map)\n    \n    preddfls = []\n    for cidx in tqdm(range(7)):\n        aggdf = pd.DataFrame(probsbrk.copy(), columns=['start', 'end'])\n        aggdf['discourse_prob'] = pd.Series(probscls.max(1))\n        aggdf['discourse_type'] = pd.Series(probscls.argmax(1))#.map(name_map)\n        aggdf['discourse_type'][(classidx != cidx)] = 8\n        aggdf['predictionstring'] = predpos.numpy()\n        \n        \n        aggdf['grp8'] = range(len(aggdf))\n        aggdf['grp8'][aggdf['discourse_type']==8] += 9999999 - np.arange(len(aggdf['grp8'][aggdf['discourse_type']==8]))\n        aggdf['grp8'][aggdf['discourse_type']!=8] -= np.arange(len(aggdf['grp8'][aggdf['discourse_type']!=8]))\n        aggdf['grp8len'] = aggdf.groupby('grp8')['end'].transform(lambda x: len(x))\n        aggdf['grp8avg'] = aggdf.groupby('grp8')['discourse_prob'].transform(np.mean)\n\n        aggdf['start'][((aggdf['discourse_type'] == 8) & \\\n                (aggdf['grp8avg'] > 0.6)) & \\\n                (aggdf['grp8len'] > 4)] = 1.\n\n        aggdf = aggdf.groupby(predfnm)['start', 'end', 'discourse_type', 'predictionstring', 'discourse_prob'].agg(lambda x: list(x))\n        aggdf['startcut'] = aggdf['start'].apply(lambda x: (np.array(x)>start_threshold).astype(np.int32))\n    \n        u, ind = np.unique(predfnm, return_index=True)\n        aggdf = aggdf.loc[u[np.argsort(ind)]]\n        aggdf = pd.DataFrame({'discourse_type':  flatten(aggdf.discourse_type.tolist()), \n                              'discourse_prob':  flatten(aggdf.discourse_prob.apply(list).tolist()), \n                                  'predictionstring':  flatten(aggdf.predictionstring.tolist()),\n                                  'start': flatten(aggdf.start.apply(list).tolist()),\n                                  'startcut': flatten(aggdf.startcut.apply(list).tolist()),\n                                  'end': flatten(aggdf.end.apply(list).tolist())})\n        aggdf['id'] = predfnm\n        aggdf['seq'] = (aggdf['startcut']).cumsum()\n        aggdf['seq'][aggdf['discourse_type']==8] -= -999999999 + (aggdf['startcut'][aggdf['discourse_type']==8]).cumsum()\n        \n        aggdf['discourse_type'] = aggdf['discourse_type'].map(name_map1)\n        preddf = aggdf.groupby(['id', 'discourse_type', 'seq'])['predictionstring']\\\n                    .apply(list).reset_index()\\\n                        .query('discourse_type != \"None\"')\n        preddfprob = aggdf.groupby(['id', 'discourse_type', 'seq'])['discourse_prob'].mean()\\\n                            .reset_index().query('discourse_type != \"None\"')\n        preddf = pd.merge(preddf, preddfprob, on=['id', 'discourse_type', 'seq'])#.drop('seq', 1)\n        preddf = preddf.drop('seq', 1)\n        preddfls .append(preddf.query('discourse_type != \"Other\"'))\n    \n    def threshold(df, map_clip_curr):\n        df = df.copy().reset_index(drop= True)\n        df['len'] = df['predictionstring'].apply(len)\n        #for key, value in cfg.map_clip.items():\n        for key, value in map_clip_curr.items():\n            index = df.loc[df['discourse_type']==key].query(f'len<{value}').index\n            df.drop(index, inplace = True)\n        return df\n    preddf = pd.concat(preddfls)\n    preddf = threshold(preddf, map_clip_curr)\n    preddf.predictionstring = preddf.predictionstring.apply(lambda x: ' '.join(map(str, x)))\n    preddf['class'] = preddf['discourse_type']\n    preddf = preddf[preddf.discourse_prob > position_proba_thresh]\n    \n    return preddf\n\ndef link_class_meta(preddf):\n    preddf = link_class(preddf, class_name=\"Evidence\", min_gap=1, min_span_dist=38, min_len=8)\n    preddf = link_class(preddf, class_name=\"Position\", min_gap=3, min_span_dist=100, min_len=2)\n    preddf = link_class(preddf, class_name=\"Concluding Statement\", min_gap=25, min_span_dist=80, max_spans=1, direction=\"backward\", min_len=3)\n    preddf = link_class(preddf, class_name=\"Lead\", min_gap=10, min_span_dist=50, max_spans=1, min_len=3)\n    return preddf","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:54.543614Z","iopub.execute_input":"2022-03-29T22:15:54.543866Z","iopub.status.idle":"2022-03-29T22:15:54.574372Z","shell.execute_reply.started":"2022-03-29T22:15:54.54383Z","shell.execute_reply":"2022-03-29T22:15:54.573463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from blend_dh_01 import class_thresh_2_proba_fn, flatten, get_cfg, get_dl, val_data_2_ls, link_class\nfrom torch.utils.data import DataLoader, Dataset\nnmodels = len(load_configs)\n\nname_map_rev = dict((v,k) for k,v in name_map.items())\nproba_thresh_weights = class_thresh_2_proba_fn(ppcfg.proba_thresh, ppcfg.name_map)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:54.57557Z","iopub.execute_input":"2022-03-29T22:15:54.575973Z","iopub.status.idle":"2022-03-29T22:15:54.587493Z","shell.execute_reply.started":"2022-03-29T22:15:54.575934Z","shell.execute_reply":"2022-03-29T22:15:54.586596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_weights = np.array(model_weights)\nproba_thresh_wts = torch.tensor(proba_thresh_weights).permute(1,0)\nclip_index = [load_configs.index(c) for c in ['cfg_ch_33d', 'cfg_ch_34d','cfg_ch_32c']]\nnon_clip_index = [i for i in range(nmodels) if i not in clip_index]\nrawpreds = torch.zeros(9, \n                   1, \n                   len(class_preds_word_blend[0]), \n                   nposn)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:54.589315Z","iopub.execute_input":"2022-03-29T22:15:54.589492Z","iopub.status.idle":"2022-03-29T22:15:54.5973Z","shell.execute_reply.started":"2022-03-29T22:15:54.58947Z","shell.execute_reply":"2022-03-29T22:15:54.595506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clip_posn = []\nfor step in range(len(class_preds_word_blend[0])):\n    step_class_preds = torch.zeros(8, nmodels, nposn)\n    for i in range(nmodels):\n        step_class_pred = class_preds_word_blend[i][step][:nposn,:8].permute(1,0)\n        step_class_preds[:,i,:step_class_pred.shape[-1]] = step_class_pred\n    # Clip where deberta extended on past the labels\n    max_len_deb = torch.where(step_class_preds[:,clip_index].sum((0,1))!=0)[0][-1]\n    max_len_other = torch.where(step_class_preds[:,non_clip_index].sum((0,1))!=0)[0][-1]\n    if max_len_other == (max_len_deb-1):\n        step_class_preds[:,:,max_len_other+1:] = 0.\n        clip_posn.append(max_len_other)\n    else:\n        clip_posn.append(max(max_len_other, max_len_deb))\n    step_class_preds  = step_class_preds * model_weights[None,:,None]\n    msk = (step_class_preds!=0).float() * model_weights[None,:,None]\n    msk = msk.sum(1)\n    step_class_preds = step_class_preds.sum(1) / msk\n    step_class_preds = torch.nan_to_num(step_class_preds, 0)\n    step_class_preds = torch.softmax(step_class_preds, 0)\n    step_class_preds = step_class_preds * proba_thresh_wts\n    step_class_preds[msk==0] = 0\n    rawpreds[:8,0,step] = step_class_preds\nclip_posn = torch.tensor(clip_posn)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:54.602224Z","iopub.execute_input":"2022-03-29T22:15:54.602404Z","iopub.status.idle":"2022-03-29T22:15:54.661512Z","shell.execute_reply.started":"2022-03-29T22:15:54.602382Z","shell.execute_reply":"2022-03-29T22:15:54.660825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for step in range(len(sep_preds_word_blend[0])):\n    step_sep_preds = torch.zeros(nmodels, nposn)\n    for i in range(nmodels):\n        step_sep_pred = sep_preds_word_blend[i][step][:clip_posn[step]].squeeze(1)\n        step_sep_preds[i,:len(step_sep_pred)] = step_sep_pred\n    step_sep_preds = step_sep_preds * model_weights[:,None]\n    msk = (step_sep_preds!=0).float() * model_weights[:,None]\n    step_sep_preds = step_sep_preds.sum(0)/ msk.sum(0)\n    step_sep_preds = torch.nan_to_num(step_sep_preds, 0)\n    rawpreds[8,0,step] = step_sep_preds","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:54.662772Z","iopub.execute_input":"2022-03-29T22:15:54.663009Z","iopub.status.idle":"2022-03-29T22:15:54.674269Z","shell.execute_reply.started":"2022-03-29T22:15:54.662977Z","shell.execute_reply":"2022-03-29T22:15:54.673479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preddf = blendfn(rawpreds,ids, start_threshold, position_proba_threshold, map_clip)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:54.675978Z","iopub.execute_input":"2022-03-29T22:15:54.676256Z","iopub.status.idle":"2022-03-29T22:15:55.154685Z","shell.execute_reply.started":"2022-03-29T22:15:54.676222Z","shell.execute_reply":"2022-03-29T22:15:55.15399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preddf = link_class_meta(preddf)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:55.155812Z","iopub.execute_input":"2022-03-29T22:15:55.156352Z","iopub.status.idle":"2022-03-29T22:15:55.189445Z","shell.execute_reply.started":"2022-03-29T22:15:55.156312Z","shell.execute_reply":"2022-03-29T22:15:55.188774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = preddf[[\"id\",\"class\",\"predictionstring\"]].copy()\nsub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:55.190829Z","iopub.execute_input":"2022-03-29T22:15:55.191112Z","iopub.status.idle":"2022-03-29T22:15:55.200494Z","shell.execute_reply.started":"2022-03-29T22:15:55.191054Z","shell.execute_reply":"2022-03-29T22:15:55.199588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2022-03-29T22:15:55.20216Z","iopub.execute_input":"2022-03-29T22:15:55.202604Z","iopub.status.idle":"2022-03-29T22:15:55.224524Z","shell.execute_reply.started":"2022-03-29T22:15:55.202562Z","shell.execute_reply":"2022-03-29T22:15:55.223841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}