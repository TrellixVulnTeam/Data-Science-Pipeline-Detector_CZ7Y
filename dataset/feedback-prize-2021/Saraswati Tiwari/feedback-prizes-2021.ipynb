{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### What are you trying to do in this notebook?\nThis notebook is a TensorFlow starter notebook for Kaggle's \"Feedback Prize - Evaluating Student Writing\" Competition. Currently this notebook uses\n\n- backbone LongFormer\n- NER formulation\n- one fold\n\n#### What we learned while making this notebook?\nWith simple changes, we can convert this notebook into Question Answer formulation and we can try different backbones. Furthermore this notebook is one fold. It trains with 90% data and validates on 10% data. We can convert this notebook to K-fold or train with 100% data for boost in LB.\n\n#### Why are you trying it?\nThis notebook can either train a new model or load a previously trained model. Furthermore, this notebook can either create new NER tokens or load existing tokens. In this notebook version, we will load model and load NER tokens.\nAlso this notebook can load huggingface stuff (like tokenizers) from a Kaggle dataset.\nIn this notebook, the improvement comes from set threshold for each class individually to remove Fasle Negative prediction.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:08.906505Z","iopub.execute_input":"2022-01-07T08:32:08.906784Z","iopub.status.idle":"2022-01-07T08:32:30.460827Z","shell.execute_reply.started":"2022-01-07T08:32:08.906751Z","shell.execute_reply":"2022-01-07T08:32:30.459704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n# DECLARE HOW MANY GPUS YOU WISH TO USE. \n# KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu\n\n# VERSION FOR SAVING/LOADING MODEL WEIGHTS\n# THIS SHOULD MATCH THE MODEL IN LOAD_MODEL_FROM\nVER=14 \n\n# IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n# OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\nLOAD_TOKENS_FROM = '../input/tf-longformer-v12'\n\n# IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n# OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\nLOAD_MODEL_FROM = \"../input/bathsize1\" #'../input/tflongformerv14'\n\n# IF FOLLOWING IS NONE, THEN NOTEBOOK \n# USES INTERNET AND DOWNLOADS HUGGINGFACE \n# CONFIG, TOKENIZER, AND MODEL\nDOWNLOADED_MODEL_PATH = '../input/tf-longformer-v12'\n\nif DOWNLOADED_MODEL_PATH is None:\n    DOWNLOADED_MODEL_PATH = 'model'    \nMODEL_NAME = 'allenai/longformer-base-4096'","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:30.4634Z","iopub.execute_input":"2022-01-07T08:32:30.463788Z","iopub.status.idle":"2022-01-07T08:32:30.472825Z","shell.execute_reply.started":"2022-01-07T08:32:30.463713Z","shell.execute_reply":"2022-01-07T08:32:30.469308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DOWNLOADED_MODEL_PATH == 'model':\n    os.mkdir('model')\n    \n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    tokenizer.save_pretrained('model')\n\n    config = AutoConfig.from_pretrained(MODEL_NAME) \n    config.save_pretrained('model')\n\n    backbone = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n    backbone.save_pretrained('model')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:30.47469Z","iopub.execute_input":"2022-01-07T08:32:30.475068Z","iopub.status.idle":"2022-01-07T08:32:30.484388Z","shell.execute_reply.started":"2022-01-07T08:32:30.475023Z","shell.execute_reply":"2022-01-07T08:32:30.483204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom transformers import *\nprint('TF version',tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:30.486371Z","iopub.execute_input":"2022-01-07T08:32:30.486787Z","iopub.status.idle":"2022-01-07T08:32:30.504962Z","shell.execute_reply.started":"2022-01-07T08:32:30.486678Z","shell.execute_reply":"2022-01-07T08:32:30.503747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE MULTIPLE GPUS\nif os.environ[\"CUDA_VISIBLE_DEVICES\"].count(',') == 0:\n    strategy = tf.distribute.get_strategy()\n    print('single strategy')\nelse:\n    strategy = tf.distribute.MirroredStrategy()\n    print('multiple strategy')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:30.508708Z","iopub.execute_input":"2022-01-07T08:32:30.509179Z","iopub.status.idle":"2022-01-07T08:32:30.520127Z","shell.execute_reply.started":"2022-01-07T08:32:30.509134Z","shell.execute_reply":"2022-01-07T08:32:30.518883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nprint('Mixed precision enabled')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:30.521795Z","iopub.execute_input":"2022-01-07T08:32:30.522252Z","iopub.status.idle":"2022-01-07T08:32:30.53254Z","shell.execute_reply.started":"2022-01-07T08:32:30.522184Z","shell.execute_reply":"2022-01-07T08:32:30.531422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/feedback-prize-2021/train.csv')\nprint( train.shape )\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:30.534557Z","iopub.execute_input":"2022-01-07T08:32:30.534933Z","iopub.status.idle":"2022-01-07T08:32:31.36133Z","shell.execute_reply.started":"2022-01-07T08:32:30.534878Z","shell.execute_reply":"2022-01-07T08:32:31.359341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The train labels are:')\ntrain.discourse_type.unique()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:31.36274Z","iopub.execute_input":"2022-01-07T08:32:31.364096Z","iopub.status.idle":"2022-01-07T08:32:31.387179Z","shell.execute_reply.started":"2022-01-07T08:32:31.364034Z","shell.execute_reply":"2022-01-07T08:32:31.386221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDS = train.id.unique()\nprint('There are',len(IDS),'train texts.')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:31.388829Z","iopub.execute_input":"2022-01-07T08:32:31.389159Z","iopub.status.idle":"2022-01-07T08:32:31.412014Z","shell.execute_reply.started":"2022-01-07T08:32:31.389114Z","shell.execute_reply":"2022-01-07T08:32:31.410981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 1024\n\n# THE TOKENS AND ATTENTION ARRAYS\ntokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH)\ntrain_tokens = np.zeros((len(IDS),MAX_LEN), dtype='int32')\ntrain_attention = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n\n# THE 14 CLASSES FOR NER\nlead_b = np.zeros((len(IDS),MAX_LEN))\nlead_i = np.zeros((len(IDS),MAX_LEN))\n\nposition_b = np.zeros((len(IDS),MAX_LEN))\nposition_i = np.zeros((len(IDS),MAX_LEN))\n\nevidence_b = np.zeros((len(IDS),MAX_LEN))\nevidence_i = np.zeros((len(IDS),MAX_LEN))\n\nclaim_b = np.zeros((len(IDS),MAX_LEN))\nclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nconclusion_b = np.zeros((len(IDS),MAX_LEN))\nconclusion_i = np.zeros((len(IDS),MAX_LEN))\n\ncounterclaim_b = np.zeros((len(IDS),MAX_LEN))\ncounterclaim_i = np.zeros((len(IDS),MAX_LEN))\n\nrebuttal_b = np.zeros((len(IDS),MAX_LEN))\nrebuttal_i = np.zeros((len(IDS),MAX_LEN))\n\n# HELPER VARIABLES\ntrain_lens = []\ntargets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\ntargets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\ntarget_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n             'Counterclaim':5, 'Rebuttal':6}","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:31.413656Z","iopub.execute_input":"2022-01-07T08:32:31.415394Z","iopub.status.idle":"2022-01-07T08:32:31.565743Z","shell.execute_reply.started":"2022-01-07T08:32:31.415347Z","shell.execute_reply":"2022-01-07T08:32:31.564682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WE ASSUME DATAFRAME IS ASCENDING WHICH IT IS\nassert( np.sum(train.groupby('id')['discourse_start'].diff()<=0)==0 )\n\n# FOR LOOP THROUGH EACH TRAIN TEXT\nfor id_num in range(len(IDS)):\n    if LOAD_TOKENS_FROM: break\n    if id_num%100==0: print(id_num,', ',end='')\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = IDS[id_num]\n    name = f'../input/feedback-prize-2021/train/{n}.txt'\n    txt = open(name, 'r').read()\n    train_lens.append( len(txt.split()))\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    train_tokens[id_num,] = tokens['input_ids']\n    train_attention[id_num,] = tokens['attention_mask']\n    \n    # FIND TARGETS IN TEXT AND SAVE IN TARGET ARRAYS\n    offsets = tokens['offset_mapping']\n    offset_index = 0\n    df = train.loc[train.id==n]\n    for index,row in df.iterrows():\n        a = row.discourse_start\n        b = row.discourse_end\n        if offset_index>len(offsets)-1:\n            break\n        c = offsets[offset_index][0]\n        d = offsets[offset_index][1]\n        beginning = True\n        while b>c:\n            if (c>=a)&(b>=d):\n                k = target_map[row.discourse_type]\n                if beginning:\n                    targets_b[k][id_num][offset_index] = 1\n                    beginning = False\n                else:\n                    targets_i[k][id_num][offset_index] = 1\n            offset_index += 1\n            if offset_index>len(offsets)-1:\n                break\n            c = offsets[offset_index][0]\n            d = offsets[offset_index][1]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:31.567337Z","iopub.execute_input":"2022-01-07T08:32:31.567693Z","iopub.status.idle":"2022-01-07T08:32:35.598299Z","shell.execute_reply.started":"2022-01-07T08:32:31.56763Z","shell.execute_reply":"2022-01-07T08:32:35.597296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    plt.hist(train_lens,bins=100)\n    plt.title('Histogram of Train Word Counts',size=16)\n    plt.xlabel('Train Word Count',size=14)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:35.600119Z","iopub.execute_input":"2022-01-07T08:32:35.600409Z","iopub.status.idle":"2022-01-07T08:32:35.607293Z","shell.execute_reply.started":"2022-01-07T08:32:35.600367Z","shell.execute_reply":"2022-01-07T08:32:35.606303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    targets = np.zeros((len(IDS),MAX_LEN,15), dtype='int32')\n    for k in range(7):\n        targets[:,:,2*k] = targets_b[k]\n        targets[:,:,2*k+1] = targets_i[k]\n    targets[:,:,14] = 1-np.max(targets,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:35.608657Z","iopub.execute_input":"2022-01-07T08:32:35.611537Z","iopub.status.idle":"2022-01-07T08:32:35.62049Z","shell.execute_reply.started":"2022-01-07T08:32:35.61149Z","shell.execute_reply":"2022-01-07T08:32:35.619358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_TOKENS_FROM is None:\n    np.save(f'targets_{MAX_LEN}', targets)\n    np.save(f'tokens_{MAX_LEN}', train_tokens)\n    np.save(f'attention_{MAX_LEN}', train_attention)\n    print('Saved NER tokens')\nelse:\n    targets = np.load(f'{LOAD_TOKENS_FROM}/targets_{MAX_LEN}.npy')\n    train_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{MAX_LEN}.npy')\n    train_attention = np.load(f'{LOAD_TOKENS_FROM}/attention_{MAX_LEN}.npy')\n    print('Loaded NER tokens')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:35.62572Z","iopub.execute_input":"2022-01-07T08:32:35.626004Z","iopub.status.idle":"2022-01-07T08:32:36.130825Z","shell.execute_reply.started":"2022-01-07T08:32:35.62592Z","shell.execute_reply":"2022-01-07T08:32:36.128738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    \n    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n    \n    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)\n    \n    x = backbone(tokens, attention_mask=attention)\n    x = tf.keras.layers.Dense(256, activation='relu')(x[0])\n    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n    \n    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n    model.compile(optimizer = tf.keras.optimizers.Adam(lr = 1e-4),\n                  loss = [tf.keras.losses.CategoricalCrossentropy()],\n                  metrics = [tf.keras.metrics.CategoricalAccuracy()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:36.132219Z","iopub.execute_input":"2022-01-07T08:32:36.132552Z","iopub.status.idle":"2022-01-07T08:32:36.144484Z","shell.execute_reply.started":"2022-01-07T08:32:36.132487Z","shell.execute_reply":"2022-01-07T08:32:36.143113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = build_model()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:36.146934Z","iopub.execute_input":"2022-01-07T08:32:36.14734Z","iopub.status.idle":"2022-01-07T08:32:59.172031Z","shell.execute_reply.started":"2022-01-07T08:32:36.147292Z","shell.execute_reply":"2022-01-07T08:32:59.171111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\nEPOCHS = 5\nBATCH_SIZE = 1\nLRS = [0.25e-4, 0.25e-4, 0.25e-4, 0.25e-4, 0.25e-5] \ndef lrfn(epoch):\n    return LRS[epoch]\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:59.173435Z","iopub.execute_input":"2022-01-07T08:32:59.174448Z","iopub.status.idle":"2022-01-07T08:32:59.182443Z","shell.execute_reply.started":"2022-01-07T08:32:59.174402Z","shell.execute_reply":"2022-01-07T08:32:59.181015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\nEPOCHS = 5\nBATCH_SIZE = 1\nLRS = [0.25e-4, 0.25e-4, 0.25e-4, 0.25e-4, 0.25e-5] \ndef lrfn(epoch):\n    return LRS[epoch]\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:59.184111Z","iopub.execute_input":"2022-01-07T08:32:59.184472Z","iopub.status.idle":"2022-01-07T08:32:59.195796Z","shell.execute_reply.started":"2022-01-07T08:32:59.184403Z","shell.execute_reply":"2022-01-07T08:32:59.194782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN VALID SPLIT 90% 10%\nnp.random.seed(42)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)\nprint('Train size',len(train_idx),', Valid size',len(valid_idx))","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:59.197085Z","iopub.execute_input":"2022-01-07T08:32:59.198045Z","iopub.status.idle":"2022-01-07T08:32:59.21843Z","shell.execute_reply.started":"2022-01-07T08:32:59.197984Z","shell.execute_reply":"2022-01-07T08:32:59.217296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOAD MODEL\nif LOAD_MODEL_FROM:\n    model.load_weights('../input/tflongformerv14/long_v14.h5')\n    \n# OR TRAIN MODEL\nelse:\n    model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n          y = targets[train_idx,],\n          validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n                             targets[valid_idx,]),\n          callbacks = [lr_callback,\n                   #   tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n                      ],\n          epochs = EPOCHS,\n          batch_size = BATCH_SIZE,\n          verbose = 1)\n\n    # SAVE MODEL WEIGHTS\n    model.save_weights(f'long_v{VER}.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:32:59.21995Z","iopub.execute_input":"2022-01-07T08:32:59.220862Z","iopub.status.idle":"2022-01-07T08:33:06.531818Z","shell.execute_reply.started":"2022-01-07T08:32:59.220811Z","shell.execute_reply":"2022-01-07T08:33:06.530775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = model.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n                  batch_size=16, verbose=2)\nprint('OOF predictions shape:',p.shape)\noof_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:33:06.533323Z","iopub.execute_input":"2022-01-07T08:33:06.534678Z","iopub.status.idle":"2022-01-07T08:36:49.852686Z","shell.execute_reply.started":"2022-01-07T08:33:06.534629Z","shell.execute_reply":"2022-01-07T08:36:49.851631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:36:49.854201Z","iopub.execute_input":"2022-01-07T08:36:49.855201Z","iopub.status.idle":"2022-01-07T08:36:49.861694Z","shell.execute_reply.started":"2022-01-07T08:36:49.855151Z","shell.execute_reply":"2022-01-07T08:36:49.860616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef jn(pst, start, end):\n    return \" \".join([str(x) for x in pst[start:end]])\n\ndef link_evidence(oof):\n    thresh = 1\n    idu = oof['id'].unique()\n    idc = idu[1]\n    eoof = oof[oof['class'] == \"Evidence\"]\n    neoof = oof[oof['class'] != \"Evidence\"]\n    print(len(eoof))\n    for thresh2 in range(26,27, 1):\n        retval = []\n        for idv in tqdm(idu): #\n            for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n                   'Counterclaim', 'Rebuttal']:\n                q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n                if len(q) == 0:\n                    continue\n                pst = []\n                for i,r in q.iterrows():\n                    pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n                start = 1\n                end = 1\n                for i in range(2,len(pst)):\n                    cur = pst[i]\n                    end = i\n                    #if pst[start] == 205:\n                    #   print(cur, pst[start], cur - pst[start])\n                    if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n                        retval.append((idv, c, jn(pst, start, end)))\n                        start = i + 1\n                v = (idv, c, jn(pst, start, end+1))\n                #print(v)\n                retval.append(v)\n        roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n        roof = roof.merge(neoof, how='outer')\n        return roof\n    \ndef get_preds(dataset='train', verbose=True, text_ids=IDS[valid_idx], preds=oof_preds):\n    all_predictions = []\n\n    for id_num in range(len(preds)):\n    \n        # GET ID\n        if (id_num%100==0)&(verbose): \n            print(id_num,', ',end='')\n        n = text_ids[id_num]\n    \n        # GET TOKEN POSITIONS IN CHARS\n        name = f'../input/feedback-prize-2021/{dataset}/{n}.txt'\n        txt = open(name, 'r').read()\n        tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n        off = tokens['offset_mapping']\n    \n        # GET WORD POSITIONS IN CHARS\n        w = []\n        blank = True\n        for i in range(len(txt)):\n            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n                w.append(i)\n                blank=False\n            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n                blank=True\n        w.append(1e6)\n            \n        # MAPPING FROM TOKENS TO WORDS\n        word_map = -1 * np.ones(MAX_LEN,dtype='int32')\n        w_i = 0\n        for i in range(len(off)):\n            if off[i][1]==0: continue\n            while off[i][0]>=w[w_i+1]: w_i += 1\n            word_map[i] = int(w_i)\n        \n        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n        ### KEY: ###\n        # 0: LEAD_B, 1: LEAD_I\n        # 2: POSITION_B, 3: POSITION_I\n        # 4: EVIDENCE_B, 5: EVIDENCE_I\n        # 6: CLAIM_B, 7: CLAIM_I\n        # 8: CONCLUSION_B, 9: CONCLUSION_I\n        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n        # 12: REBUTTAL_B, 13: REBUTTAL_I\n        # 14: NOTHING i.e. O\n        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n        pred = preds[id_num,]/2.0\n    \n        i = 0\n        while i<MAX_LEN:\n            prediction = []\n            start = pred[i]\n            if start in [0,1,2,3,4,5,6,7]:\n                prediction.append(word_map[i])\n                i += 1\n                if i>=MAX_LEN: break\n                while pred[i]==start+0.5:\n                    if not word_map[i] in prediction:\n                        prediction.append(word_map[i])\n                    i += 1\n                    if i>=MAX_LEN: break\n            else:\n                i += 1\n            prediction = [x for x in prediction if x!=-1]\n            if len(prediction)>3:\n                all_predictions.append( (n, target_map_rev[int(start)], w[prediction[0]], w[prediction[-1]+1]-1,\n                                ' '.join([str(x) for x in prediction]) ) )\n                \n    # MAKE DATAFRAME\n    df = pd.DataFrame(all_predictions)\n    df.columns = ['id','class', 'discourse_start', 'discourse_end', 'predictionstring']\n    df = link_evidence(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:36:49.863868Z","iopub.execute_input":"2022-01-07T08:36:49.864201Z","iopub.status.idle":"2022-01-07T08:36:49.897119Z","shell.execute_reply.started":"2022-01-07T08:36:49.864155Z","shell.execute_reply":"2022-01-07T08:36:49.89572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = get_preds( dataset='train', verbose=True, text_ids=IDS[valid_idx] )\noof.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:36:49.898853Z","iopub.execute_input":"2022-01-07T08:36:49.899369Z","iopub.status.idle":"2022-01-07T08:37:39.409428Z","shell.execute_reply.started":"2022-01-07T08:36:49.899323Z","shell.execute_reply":"2022-01-07T08:37:39.408303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The following classes are present in oof preds:')\noof['class'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:37:39.411117Z","iopub.execute_input":"2022-01-07T08:37:39.411534Z","iopub.status.idle":"2022-01-07T08:37:39.423573Z","shell.execute_reply.started":"2022-01-07T08:37:39.411485Z","shell.execute_reply":"2022-01-07T08:37:39.42241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CODE FROM : Rob Mulla @robikscube\n# https://www.kaggle.com/robikscube/student-writing-competition-twitch\ndef calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(' '))\n    set_gt = set(row.predictionstring_gt.split(' '))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter/ len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n        \n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df = pred_df[['id','class','predictionstring']] \\\n        .reset_index(drop=True).copy()\n    pred_df['pred_id'] = pred_df.index\n    gt_df['gt_id'] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(gt_df,\n                           left_on=['id','class'],\n                           right_on=['id','discourse_type'],\n                           how='outer',\n                           suffixes=('_pred','_gt')\n                          )\n    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n\n    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n\n\n    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n    tp_pred_ids = joined.query('potential_TP') \\\n        .sort_values('max_overlap', ascending=False) \\\n        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    #calc microf1\n    my_f1_score = TP / (TP + 0.5*(FP+FN))\n    return my_f1_score","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:38:02.437405Z","iopub.execute_input":"2022-01-07T08:38:02.43774Z","iopub.status.idle":"2022-01-07T08:38:02.457275Z","shell.execute_reply.started":"2022-01-07T08:38:02.437696Z","shell.execute_reply":"2022-01-07T08:38:02.456167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VALID DATAFRAME\nvalid = train.loc[train['id'].isin(IDS[valid_idx])]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:38:06.699667Z","iopub.execute_input":"2022-01-07T08:38:06.700003Z","iopub.status.idle":"2022-01-07T08:38:06.73028Z","shell.execute_reply.started":"2022-01-07T08:38:06.699972Z","shell.execute_reply":"2022-01-07T08:38:06.728387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof['len'] = oof['predictionstring'].apply(lambda x:len(x.split()))\ntrain['len'] = train['predictionstring'].apply(lambda x:len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:38:11.429622Z","iopub.execute_input":"2022-01-07T08:38:11.430052Z","iopub.status.idle":"2022-01-07T08:38:12.072445Z","shell.execute_reply.started":"2022-01-07T08:38:11.430011Z","shell.execute_reply":"2022-01-07T08:38:12.071407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby('discourse_type')['len'].describe(percentiles = [0.02, 0.25, 0.50, 0.75, 0.98])","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:38:14.658742Z","iopub.execute_input":"2022-01-07T08:38:14.659062Z","iopub.status.idle":"2022-01-07T08:38:14.72629Z","shell.execute_reply.started":"2022-01-07T08:38:14.659026Z","shell.execute_reply":"2022-01-07T08:38:14.725149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map_clip = {'Lead':9, 'Position':5, 'Evidence':14, 'Claim':3, 'Concluding Statement':11,\n             'Counterclaim':6, 'Rebuttal':4}\n\ndef threshold(df):\n    df = df.copy()\n    for key, value in map_clip.items():\n    # if df.loc[df['class']==key,'len'] < value \n        index = df.loc[df['class']==key].query(f'len<{value}').index\n        df.drop(index, inplace = True)\n    return df\n\noof_2 = threshold(oof)\noof_2.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:38:17.516415Z","iopub.execute_input":"2022-01-07T08:38:17.516724Z","iopub.status.idle":"2022-01-07T08:38:17.591728Z","shell.execute_reply.started":"2022-01-07T08:38:17.516682Z","shell.execute_reply":"2022-01-07T08:38:17.590733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\nfor c in CLASSES:\n    pred_df = oof.loc[oof['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall_before',np.mean(f1s))","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:38:20.293121Z","iopub.execute_input":"2022-01-07T08:38:20.293957Z","iopub.status.idle":"2022-01-07T08:38:23.814643Z","shell.execute_reply.started":"2022-01-07T08:38:20.29392Z","shell.execute_reply":"2022-01-07T08:38:23.813712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1s = []\nCLASSES = oof['class'].unique()\nfor c in CLASSES:\n    pred_df = oof_2.loc[oof_2['class']==c].copy()\n    gt_df = valid.loc[valid['discourse_type']==c].copy()\n    f1 = score_feedback_comp(pred_df, gt_df)\n    print(c,f1)\n    f1s.append(f1)\nprint()\nprint('Overall_after',np.mean(f1s))","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:38:27.328468Z","iopub.execute_input":"2022-01-07T08:38:27.328766Z","iopub.status.idle":"2022-01-07T08:38:30.149856Z","shell.execute_reply.started":"2022-01-07T08:38:27.328733Z","shell.execute_reply":"2022-01-07T08:38:30.148898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GET TEST TEXT IDS\nfiles = os.listdir('../input/feedback-prize-2021/test')\nTEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\nprint('There are',len(TEST_IDS),'test texts.')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:38:46.603116Z","iopub.execute_input":"2022-01-07T08:38:46.604008Z","iopub.status.idle":"2022-01-07T08:38:46.616057Z","shell.execute_reply.started":"2022-01-07T08:38:46.603953Z","shell.execute_reply":"2022-01-07T08:38:46.614906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT TEST TEXT TO TOKENS\ntest_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\ntest_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n\nfor id_num in range(len(TEST_IDS)):\n        \n    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n    n = TEST_IDS[id_num]\n    name = f'../input/feedback-prize-2021/test/{n}.txt'\n    txt = open(name, 'r').read()\n    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n                                   truncation=True, return_offsets_mapping=True)\n    test_tokens[id_num,] = tokens['input_ids']\n    test_attention[id_num,] = tokens['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:39:20.345212Z","iopub.execute_input":"2022-01-07T08:39:20.345592Z","iopub.status.idle":"2022-01-07T08:39:20.40174Z","shell.execute_reply.started":"2022-01-07T08:39:20.345542Z","shell.execute_reply":"2022-01-07T08:39:20.400603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER TEST TEXTS\np = model.predict([test_tokens, test_attention], \n                  batch_size=16, verbose=2)\nprint('Test predictions shape:',p.shape)\ntest_preds = np.argmax(p,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:39:41.851368Z","iopub.execute_input":"2022-01-07T08:39:41.851694Z","iopub.status.idle":"2022-01-07T08:39:42.529328Z","shell.execute_reply.started":"2022-01-07T08:39:41.85166Z","shell.execute_reply":"2022-01-07T08:39:42.527569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GET TEST PREDICIONS\nsub = get_preds( dataset='test', verbose=False, text_ids=TEST_IDS, preds=test_preds )\nsub['len'] = sub['predictionstring'].apply(lambda x:len(x.split()))\nsub = threshold(sub)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:40:14.70474Z","iopub.execute_input":"2022-01-07T08:40:14.705069Z","iopub.status.idle":"2022-01-07T08:40:14.90107Z","shell.execute_reply.started":"2022-01-07T08:40:14.705037Z","shell.execute_reply":"2022-01-07T08:40:14.899806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WRITE SUBMISSION CSV\nsub[['id','class','predictionstring']].to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:40:38.803584Z","iopub.execute_input":"2022-01-07T08:40:38.803916Z","iopub.status.idle":"2022-01-07T08:40:38.816225Z","shell.execute_reply.started":"2022-01-07T08:40:38.803882Z","shell.execute_reply":"2022-01-07T08:40:38.815183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Did it work?\nI'll make it easier for students to receive feedback on their writing and increase opportunities to improve writing outcomes. Virtual writing tutors and automated writing systems can leverage these algorithms while teachers may use them to reduce grading time. The open-sourced algorithms you come up with will allow any educational organization to better help young writers develop.\n\n#### What did you not understand about this process?\nWell, everything provides in the competition data page. I've no problem while working on it. If you guys don't understand the thing that I'll do in this notebook then please comment on this notebook.\n\n#### What else do you think you can try as part of this approach?\nWriting is a critical skill for success. However, less than a third of high school seniors are proficient writers, according to the National Assessment of Educational Progress. Unfortunately, low-income, Black, and Hispanic students fare even worse, with less than 15 percent demonstrating writing proficiency. One way to help students improve their writing is via automated feedback tools, which evaluate student writing and provide personalized feedback.","metadata":{}}]}