{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pickle\nimport gc\ngc.enable()\n\nimport sys\nsys.path.append(\"../input/pythonbox\")\n\nfrom box import Box\nfrom tqdm import tqdm\nimport copy\n\nimport random\nimport math\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import (\n    Dataset, DataLoader,\n)\nfrom joblib import Parallel, delayed\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom string import punctuation\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:31:55.50444Z","iopub.execute_input":"2022-03-09T02:31:55.504906Z","iopub.status.idle":"2022-03-09T02:32:03.340814Z","shell.execute_reply.started":"2022-03-09T02:31:55.504817Z","shell.execute_reply":"2022-03-09T02:32:03.340095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seeD\ndef seed_everything(seed: int):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(2022)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.342317Z","iopub.execute_input":"2022-03-09T02:32:03.342563Z","iopub.status.idle":"2022-03-09T02:32:03.353875Z","shell.execute_reply.started":"2022-03-09T02:32:03.342528Z","shell.execute_reply":"2022-03-09T02:32:03.353225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_id_map = {\n    \"B-Lead\": 0,\n    \"I-Lead\": 1,\n    \"B-Position\": 2,\n    \"I-Position\": 3,\n    \"B-Evidence\": 4,\n    \"I-Evidence\": 5,\n    \"B-Claim\": 6,\n    \"I-Claim\": 7,\n    \"B-Concluding Statement\": 8,\n    \"I-Concluding Statement\": 9,\n    \"B-Counterclaim\": 10,\n    \"I-Counterclaim\": 11,\n    \"B-Rebuttal\": 12,\n    \"I-Rebuttal\": 13,\n    \"O\": 14,\n    \"PAD\": -100,\n}\n\n\nid_target_map = {v: k for k, v in target_id_map.items()}\n\nclass args1:\n    input_path = \"../input/feedback-prize-2021/\"\n    model = \"../input/longformerlarge\"\n    model_weight= '../input/exp001'\n    output = \".\"\n    batch_size = 8\n    max_len = 4096\n    use_folds=[1,2,3]\n\nclass args2:\n    input_path = \"../input/feedback-prize-2021/\"\n    model = '../input/funneltransformers/large'\n    model_weight= '../input/exp051'\n    output = \".\"\n    batch_size = 8\n    max_len = 4096\n    use_folds=[1,2,3]\n\nclass args3:\n    input_path = \"../input/feedback-prize-2021/\"\n    model = \"../input/deberta/large\"\n    model_weight= '../input/exp056'\n    output = \".\"\n    batch_size = 2\n    max_len = 4096\n    use_folds= [1,2,3]\n\nclass args4:\n    input_path = \"../input/feedback-prize-2021/\"\n    model = \"../input/deberta/large\"\n    model_weight= '../input/exp063'\n    output = \".\"\n    batch_size = 2\n    max_len = 4096\n    use_folds= [1,2]\n    \nclass args5:\n    input_path = \"../input/feedback-prize-2021/\"\n    model = \"../input/deberta-xlarge\"\n    model_weight= '../input/exp066'\n    output = \".\"\n    batch_size = 2\n    max_len = 4096\n    use_folds= [1,2,3,4,5]\n\nconfigs={\n    args1: 0.175,\n    args2: 0.175,\n    args3: 0.15,\n    args4: 0.15,\n    args5: 0.35\n}\n\nNUM_LABELS=len(target_id_map) - 1","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.355022Z","iopub.execute_input":"2022-03-09T02:32:03.355955Z","iopub.status.idle":"2022-03-09T02:32:03.369764Z","shell.execute_reply.started":"2022-03-09T02:32:03.355913Z","shell.execute_reply":"2022-03-09T02:32:03.369053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeedbackDataset(Dataset):\n    def __init__(self, samples, max_len, tokenizer):\n        self.samples = samples\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.length = len(samples)\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, idx):\n        input_ids = self.samples[idx][\"input_ids\"]\n        # print(input_ids)\n        # print(input_labels)\n\n        # add start token id to the input_ids\n        input_ids = [self.tokenizer.cls_token_id] + input_ids\n\n        if len(input_ids) > self.max_len - 1:\n            input_ids = input_ids[: self.max_len - 1]\n\n        # add end token id to the input_ids\n        input_ids = input_ids + [self.tokenizer.sep_token_id]\n        attention_mask = [1] * len(input_ids)\n\n        return {\n            \"ids\": input_ids,\n            \"mask\": attention_mask,\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.373128Z","iopub.execute_input":"2022-03-09T02:32:03.373334Z","iopub.status.idle":"2022-03-09T02:32:03.380654Z","shell.execute_reply.started":"2022-03-09T02:32:03.373305Z","shell.execute_reply":"2022-03-09T02:32:03.37995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Collate:\n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n\n    def __call__(self, batch):\n        output = dict()\n        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n\n        # calculate max token length of this batch\n        batch_max = max([len(ids) for ids in output[\"ids\"]])\n\n        # add padding\n        if self.tokenizer.padding_side == \"right\":\n            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n        else:\n            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n\n        # convert to tensors\n        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.382277Z","iopub.execute_input":"2022-03-09T02:32:03.382683Z","iopub.status.idle":"2022-03-09T02:32:03.394884Z","shell.execute_reply.started":"2022-03-09T02:32:03.382647Z","shell.execute_reply":"2022-03-09T02:32:03.394076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeedbackModel(nn.Module):\n    def __init__(self, model_name, num_labels):\n        super().__init__()\n        self.model_name = model_name\n        self.num_labels = num_labels\n        config = AutoConfig.from_pretrained(model_name)\n\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": hidden_dropout_prob,\n                \"layer_norm_eps\": layer_norm_eps,\n                \"add_pooling_layer\": False,\n            }\n        )\n        self.transformer = AutoModel.from_config(config)\n        self.output = nn.Linear(config.hidden_size, self.num_labels)\n\n    def forward(self, ids, mask):\n        transformer_out = self.transformer(ids, mask)\n        sequence_output = transformer_out.last_hidden_state\n        logits = self.output(sequence_output)\n        logits = torch.softmax(logits, dim=-1)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.396742Z","iopub.execute_input":"2022-03-09T02:32:03.399414Z","iopub.status.idle":"2022-03-09T02:32:03.406047Z","shell.execute_reply.started":"2022-03-09T02:32:03.399381Z","shell.execute_reply":"2022-03-09T02:32:03.405313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_sample(sample, max_len, stride = 128):\n\n    split_features=[]\n\n    length=len(sample['input_ids'])\n    #special token分を除いた最大span\n    max_span = max_len-2\n    \n    if length <= max_span:\n        split_features.append(sample)\n    \n    else:\n        #ループは最低2回以上なので、ceil + 1。\n        loop_num = math.ceil((length - max_span) / stride) + 1\n\n        for i in range(loop_num):\n            split_feature={}\n            start=i*stride\n\n            split_feature['id'] = sample['id']\n            split_feature['input_ids']  = sample['input_ids'][start:  start + max_span]\n            split_feature['text']  = sample['text']\n            split_feature['offset_mapping']  = sample['offset_mapping'][start:  start + max_span]\n\n            split_features.append(split_feature)\n\n    return split_features\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.407426Z","iopub.execute_input":"2022-03-09T02:32:03.407658Z","iopub.status.idle":"2022-03-09T02:32:03.41637Z","shell.execute_reply.started":"2022-03-09T02:32:03.407624Z","shell.execute_reply":"2022-03-09T02:32:03.415544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_samples(all_test_samples, raw_preds):\n\n    preds_list=[j for i in raw_preds for j in i]\n\n    for j in range(len(all_test_samples)):\n        offset__len=len(all_test_samples[j]['offset_mapping'])\n        \n        if len(preds_list[j])<offset__len:\n            #cls,sepを除く\n            pred_len=len(preds_list[j])-2\n            diff = offset__len - pred_len\n            \n            raw_pred = preds_list[j][1: 1+pred_len]\n            #もしも、offset__lenの方が長い場合、Oが大きい値を取るようにする。\n            pad=np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 100.])\n            pad = np.repeat(pad[None, :], diff, axis=0)\n            raw_pred = np.vstack([raw_pred, pad])\n            all_test_samples[j][\"raw_pred\"] = raw_pred\n\n        else:\n            #1はずらした分。\n            raw_pred = preds_list[j][1:1+offset__len]\n            all_test_samples[j][\"raw_pred\"] = raw_pred\n\n    #collate\n    sample_dict={}\n    for i in all_test_samples:\n        if i['id'] not in sample_dict.keys():\n            sample_dict[i['id']]=i\n        else:\n            sample_dict[i['id']]['input_ids'] += i['input_ids']\n            sample_dict[i['id']]['offset_mapping'] += i['offset_mapping']\n            sample_dict[i['id']]['raw_pred'] = np.vstack([sample_dict[i['id']]['raw_pred'],  i['raw_pred']])\n\n    all_test_samples=list(sample_dict.values())\n    all_test_samples=sorted(all_test_samples, key=lambda x: x['id'])\n\n    return all_test_samples\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.417544Z","iopub.execute_input":"2022-03-09T02:32:03.417946Z","iopub.status.idle":"2022-03-09T02:32:03.429805Z","shell.execute_reply.started":"2022-03-09T02:32:03.417913Z","shell.execute_reply":"2022-03-09T02:32:03.429176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _prepare_test_data_helper(args, tokenizer, ids):\n    test_samples = []\n    for idx in ids:\n        filename = os.path.join(args.input_path, \"test\", idx + \".txt\")\n        with open(filename, \"r\") as f:\n            text = f.read()\n\n        encoded_text = tokenizer.encode_plus(\n            text,\n            add_special_tokens=False,\n            return_offsets_mapping=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        offset_mapping = encoded_text[\"offset_mapping\"]\n\n        sample = {\n            \"id\": idx,\n            \"input_ids\": input_ids,\n            \"text\": text,\n            \"offset_mapping\": offset_mapping,\n        }\n\n        test_samples.append(sample)\n    return test_samples\n\n\ndef prepare_test_data(df, tokenizer, args):\n    test_samples = []\n    ids = df[\"id\"].unique()\n    ids_splits = np.array_split(ids, 4)\n\n    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n        delayed(_prepare_test_data_helper)(args, tokenizer, idx) for idx in ids_splits\n    )\n    for result in results:\n        test_samples.extend(result)\n\n    return test_samples","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.432381Z","iopub.execute_input":"2022-03-09T02:32:03.433218Z","iopub.status.idle":"2022-03-09T02:32:03.441974Z","shell.execute_reply.started":"2022-03-09T02:32:03.433189Z","shell.execute_reply":"2022-03-09T02:32:03.441332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_pred(df, args, perfome_split=False):\n\n    tokenizer = AutoTokenizer.from_pretrained(args.model)\n    collate = Collate(tokenizer=tokenizer)\n    \n    raw_preds=[]\n    all_test_samples=[]\n    test_samples=prepare_test_data(df, tokenizer, args)\n\n    #split_sampleを行い、max_lenを超えていた場合にも対処\n    if perfome_split==False:\n        all_test_samples += test_samples\n        test_dataset = FeedbackDataset(test_samples, args.max_len, tokenizer)\n        del test_samples\n        gc.collect()\n        \n    else:\n        split_test_samples = []\n        for i in test_samples:\n            split_test_samples += split_sample(i, max_len = args.max_len, stride = args.max_len-2) \n        \n        del test_samples\n        gc.collect()\n\n        all_test_samples += split_test_samples\n        test_dataset = FeedbackDataset(split_test_samples, args.max_len, tokenizer)\n\n        del split_test_samples\n        gc.collect()\n\n\n    test_dataloader = DataLoader(\n        dataset=test_dataset,\n        batch_size = args.batch_size,\n        shuffle = False,\n        num_workers = 4,\n        pin_memory = True,\n        drop_last = False,\n        collate_fn = collate\n    )\n    del test_dataset\n    gc.collect()\n\n    for idx in range(len(args.use_folds)):\n        print(f'{args.use_folds[idx]}fold')\n\n        model = FeedbackModel(model_name=args.model, num_labels=len(target_id_map) - 1)\n        model.to('cuda')\n        \n        model_weight=f'{args.model_weight}/{args.use_folds[idx]}fold_best_metrics.ckpt'\n        print(model_weight)\n        model.load_state_dict(torch.load(model_weight))\n        \n        model.eval()\n        \n        #半精度\n\n        with torch.no_grad():\n            with torch.cuda.amp.autocast(enabled=True):\n                for i, output in enumerate(test_dataloader):\n                    input_ids=output['ids'].to('cuda')\n                    attention_mask=output['mask'].to('cuda')\n                    out=model(input_ids, attention_mask)\n                    out=out.to('cpu').detach().numpy()\n                    \n                    out = out / len(args.use_folds)\n                    if idx == 0:\n                        raw_preds.append(out)\n                    else:\n                        raw_preds[i] += out\n\n        del model\n        gc.collect()\n\n    all_test_samples=collate_samples(all_test_samples, raw_preds)\n    del test_dataloader\n    gc.collect()\n    \n    return all_test_samples, raw_preds\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.445245Z","iopub.execute_input":"2022-03-09T02:32:03.445881Z","iopub.status.idle":"2022-03-09T02:32:03.460929Z","shell.execute_reply.started":"2022-03-09T02:32:03.445837Z","shell.execute_reply":"2022-03-09T02:32:03.460237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(os.path.join(\"../input/feedback-prize-2021/\", \"sample_submission.csv\"))\n\nfor i, (args, weight) in enumerate(configs.items()):\n    #from IPython.core.debugger import Pdb; Pdb().set_trace()\n    if i==0:\n        all_test_samples, raw_preds = make_pred(df, args, perfome_split=False)\n        #アンサンブル用サンプルを作成。1個目がベース。\n        ens_samples=copy.deepcopy(all_test_samples)\n        #アンサンブルサンプルのraw_predを初期化\n        for t in range(len(ens_samples)):\n            ens_samples[t]['raw_pred']=np.zeros((len(ens_samples[t]['input_ids']), NUM_LABELS))\n    elif i>=1:\n        all_test_samples, raw_preds = make_pred(df, args, perfome_split=False)\n\n\n    for j in tqdm(range(len(all_test_samples))):\n        #諸々、１個目のモデルをbaseにする。\n        #最初にtextをキャッチキャッチし、prob配列を作成したりしている。ここで文字レベルアンサンブルを実施\n        text = ens_samples[j]['text']\n        base_input_ids = ens_samples[j]['input_ids']\n        base_offset_mapping= ens_samples[j]['offset_mapping']\n\n        token_to_text_probability = np.full((len(text),NUM_LABELS),0, np.float32)\n        text_to_token_probability = np.full((len(base_input_ids),NUM_LABELS),0, np.float32)\n\n        p = all_test_samples[j]['raw_pred']\n        #token to text\n        for t,(start,end) in enumerate(all_test_samples[j]['offset_mapping']):\n            token_to_text_probability[start:end]+=p[t] #**0.5\n        token_to_text_probability = token_to_text_probability \n\n        #text to token\n        for t,(start,end) in enumerate(base_offset_mapping):\n            text_to_token_probability[t]=token_to_text_probability[start:end].mean(0)\n\n        ens_samples[j]['raw_pred'] += text_to_token_probability * weight\n\n    del all_test_samples, raw_preds\n    gc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:32:03.462229Z","iopub.execute_input":"2022-03-09T02:32:03.462987Z","iopub.status.idle":"2022-03-09T02:33:55.910313Z","shell.execute_reply.started":"2022-03-09T02:32:03.462951Z","shell.execute_reply":"2022-03-09T02:33:55.908814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#あとは下を使って、アンサンブル結果を格納\nfor i in range(len(ens_samples)):\n    pred_class = np.argmax(ens_samples[i]['raw_pred'], axis=1)\n    pred_scrs = np.max(ens_samples[i]['raw_pred'], axis=1)\n    ens_samples[i][\"preds\"] = [id_target_map[p] for p in pred_class]\n    ens_samples[i][\"pred_scores\"] = pred_scrs","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:39:44.89261Z","iopub.execute_input":"2022-03-07T15:39:44.892961Z","iopub.status.idle":"2022-03-07T15:39:44.90541Z","shell.execute_reply.started":"2022-03-07T15:39:44.892914Z","shell.execute_reply":"2022-03-07T15:39:44.904297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"../input/longformerlarge\")\nremove_words=[\n                  'I',\n                  'You'\n                  'She',\n                  'she',\n                  'He',\n                  'he',\n                  'the',\n                  'The',\n                  'This',\n                  'That'\n                  'however',\n                  'However',\n                  'Although',\n                  'although',\n                  'Because',\n                  'Some',\n                  'Not',\n                  'There',\n                  'To',\n                  '(',\n                  '[',\n                  'A',\n                  'In',\n                  'On',\n                  'At',\n                  'With',\n                  'Electoral'\n                'If',\n                'It',\n                'They',\n                'Venus',\n                'When',\n                'You',\n                'College',\n                'Students',\n                'So',\n                'A',\n                'We',\n                'Many',\n                'As',\n                'With',\n                'People',\n                'These',\n                'That',\n                'Another',\n                'And',\n                'Also',\n                'Action',\n 'Facial',\n 'President',\n 'After',\n 'Online',\n 'Teachers',\n 'Why',\n 'Being',\n 'Cars',\n 'Asking',\n 'Just',\n 'According',\n 'Its',\n 'System',\n 'Since',\n 'Sometimes',\n 'Cowboys',\n 'Summer',\n 'Do',\n 'No',\n 'How',\n 'Do',\n 'No',\n 'How',\n 'Paris',\n 'Have',\n 'Well',\n 'Which',\n 'Like',\n 'Without',\n 'American',\n 'Mars.',\n 'Earth.',\n 'America',\n 'School',\n 'She',\n 'Everyone',\n 'Maybe',\n 'Therefore,',\n 'Distance',\n 'Mona',\n 'An',\n \"That's\",\n 'So',\n 'Those',\n 'Imagine',\n 'Or',\n 'Venus,',\n 'College.',\n '2000',\n 'Seeking',\n 'Using',\n 'Is',\n 'Your',\n 'Getting',\n 'Google',\n 'Every',\n 'Viking',\n 'Cell',\n 'Cowboy',\n 'First',\n 'Schools',\n 'Our',\n 'From',\n 'Making',\n 'Lastly',\n 'During',\n 'Each',\n 'Exploring',\n 'Finally',\n 'Other',\n 'Source',\n 'Instead',\n 'Their',\n 'Technology',\n 'Policy',\n 'Kids',\n 'Driving',\n 'Are',\n 'But,',\n 'Texting',\n 'Furthermore,',\n 'Community',\n 'Once',\n 'Would',\n 'Car',\n 'More',\n 'Overall,',\n 'Challenge',\n 'Thats',\n 'College,',\n 'Taking',\n 'Who',\n 'New',\n 'Of',\n 'Yes',\n 'Though',\n 'Extracurricular',\n 'Limiting',\n 'War',\n 'Learning',\n 'Global',\n 'Think',\n 'First',\n 'Drivers',\n 'Doing',\n 'House',\n 'Whether',\n 'Due',\n '-',\n 'Over',\n 'Well',\n 'Therefore',\n 'Student',\n 'Secondly',\n 'Although',\n 'Congress',\n 'Say',\n 'Advice',\n 'Phones',\n 'Others',\n 'Going',\n 'Yes',\n 'Indefensible',\n 'Life',\n 'Surveyor',\n 'Scientists',\n 'Should',\n 'Bush',\n 'Democratic',\n 'Voters',\n 'Giving',\n 'National',\n 'Allowing',\n 'Paragraph',\n 'Talking',\n 'Middle',\n 'Knowing',\n 'Sports',\n 'Venus\"',\n 'Last',\n 'Snake',\n 'Attending',\n 'Additionally,',\n 'River',\n 'Despite',\n 'Someone',\n 'Studies',\n 'Humans',\n 'Such',\n 'Plain',\n 'Vice',\n 'Safety',\n 'Plus',\n 'English',\n 'Second',\n 'Overall',\n 'Can',\n 'Working',\n 'Only',\n 'Monday',\n 'Did',\n 'Under',\n 'Here',\n 'Multiple',\n 'Before',\n 'Five',\n 'Popular',\n 'Through',\n 'Defense',\n 'Almost',\n 'Parents',\n 'Both',\n 'Especially',\n 'Will',\n 'Driveless',\n 'Different',\n 'Goes',\n 'Helping',\n 'Along',\n 'Let',\n 'Today',\n 'Everybody',\n 'Next',\n 'Throughout',\n 'Second',\n 'His',\n 'Today',\n 'High',\n 'Red',\n 'Sometimes',\n 'Take',\n 'Office',\n 'Lastly',\n 'Scientist',\n 'Something',\n 'Teacher',\n 'Nobody',\n 'Moreover',\n 'Representatives',\n 'Traffic',\n 'Please',\n 'Education',\n 'Day',\n 'Teens',\n 'Either',\n 'Electors',\n 'Less',\n 'Hearing',\n 'Island',\n 'Any',\n 'Public',\n 'Things',\n 'Often',\n 'District',\n 'Thus',\n 'Keeping',\n 'Teenagers',\n 'Projects',\n 'Citizens',\n 'Yet',\n 'Based',\n 'Changing',\n 'Perhaps',\n 'Studying',\n 'Everyday',\n 'Besides',\n 'Her',\n 'Back',\n 'State',\n 'Children',\n 'Make',\n 'Where',\n 'Science',\n 'Human',\n 'Seeing',\n 'Unfortunately,',\n 'End',\n 'Camera',\n 'Firstly,',\n 'Whenever',\n 'See',\n 'Looking',\n 'Swing',\n 'Instead,',\n 'Distracted',\n 'Does',\n 'Colleges',\n 'Thank',\n 'Transportation',\n 'Representatives,',\n 'Letting',\n 'Smog',\n 'Home',\n 'Personally',\n 'Wyoming',\n 'Video',\n 'Depending',\n 'Meaning',\n 'Presidential',\n 'Finding',\n 'Theres',\n 'Us',\n 'System',\n 'Social',\n 'Smart',\n 'Thousands',\n 'Coming\"',\n 'System.',\n 'Dear',\n 'Personally',\n 'Lots',\n 'Space',\n 'Two',\n 'Later',\n 'Nations',\n 'Smile\"',\n 'Relief',\n 'Pacific',\n 'Candidates',\n 'Always',\n 'Reasons',\n 'Computers',\n 'Everything',\n 'Participating',\n 'Joining',\n 'Forcing',\n 'About',\n 'Ever',\n 'Duffer',\n 'Whatever',\n 'Could',\n 'Time',\n 'Third',\n 'Adding',\n 'Bill',\n 'Usually',\n 'Anyone',\n 'Me',\n 'Nothing',\n 'Stress',\n 'Remember',\n 'Be',\n 'Voting',\n 'Unlike',\n 'Majority',\n 'Good',\n 'Ultimately',\n 'Ask',\n 'Agency',\n 'Consider',\n 'Putting',\n 'Opinions',\n 'Protection',\n 'Hopefully',\n 'Bullying',\n 'Classes',\n 'Out',\n 'Pollution',\n 'Listening',\n 'Activities',\n 'Face,',\n 'May',\n 'Anything',\n 'Reading',\n 'Recently,',\n 'Companies',\n 'Considering',\n 'Receiving',\n 'Rather',\n 'Walking',\n 'Given',\n 'Certain',\n 'Playing',\n 'Clearly',\n 'Help',\n 'Unless',\n 'Sure,',\n 'Congestion',\n 'Staying',\n 'Statistics',\n 'Trying',\n 'Wyoming,',\n 'Until',\n 'Service',\n 'Keep',\n 'Within',\n 'Free',\n 'Evening',\n 'Three',\n 'Author',\n 'Theory',\n 'Nearly',\n 'Avoid',\n 'Trust',\n 'Mostly',\n 'Coming',\n 'Advanced',\n 'Never',\n 'Honestly',\n 'Millions',\n 'Constitution.',\n 'Conclusion',\n 'Last',\n 'Reason',\n 'Emotions',\n 'Accidents',\n 'Feedback',\n 'Exploration',\n 'Creating',\n 'Soon',\n 'Too',\n 'Use',\n 'Maine',\n 'Look',\n 'Program',\n 'Congressional',\n\n \n 'West',\n  'Constitution',\n \n  'Elections',\n 'Also,',\n \n 'People',\n 'Well', \n 'Driverless',\n 'All',\n 'Even',\n 'Program',\n 'One',\n 'Having',\n 'Congress',\n 'Which',\n 'My',\n 'By',\n 'Most',\n 'On',\n 'Why',\n 'Planet',\n 'Outcome',\n 'Driving',\n 'Like',\n 'Online',\n 'Do',\n 'Phones',\n 'Distance',\n 'Asking',\n 'Cell',\n 'Just',\n 'Service',\n 'Voting',\n 'Ocean',\n 'Since',\n 'Learning',\n 'Etc',\n 'Everyone',\n 'Limiting',\n 'Every',\n 'Bush',\n 'Getting',\n 'House',\n 'Without',\n 'Times',\n 'Due',\n 'Are',\n 'Multiple',\n 'Looking',\n 'Seagoing',\n 'Giving',\n 'Taking',\n 'Coming\"',\n 'Problems',\n 'Imagine',\n 'Exploring',\n 'Bullying',\n 'Texting',\n 'Avoid',\n 'Studying',\n 'Knowing',\n 'Perhaps',\n 'Idea',\n 'Road',\n 'Finding',\n 'Constisution',\n 'Viking',\n 'Studies',\n 'Sounds',\n 'Nation',\n 'Making',\n 'Process',\n \"Let's\",\n 'Respect',\n 'Statistics',\n 'Day',\n 'Kids',\n \"Would\",\n 'Education',\n 'Help',\n 'Ravines',\n 'Tragic',\n 'Fun',\n 'Works',\n 'Band',\n 'Bad',\n 'Money',\n 'Surveyor',\n 'Illions.\"',\n 'Quizizz',\n 'Minimizing',\n 'Humanity',\n 'Nearly',\n 'Hardly',\n '--',\n 'Market',\n 'Orbiters',\n 'Trouble',\n 'Healthy',\n 'Unfair,',\n 'Fast',\n 'Threes',\n  'Passing',\n 'Baseball',\n 'Unfortunatley,',\n 'Smile',\n 'Life',\n 'Polish',\n 'Clothes,',\n 'Mean',\n]\n\n\n\nremove_words_ids=[tokenizer(i, add_special_tokens=False)['input_ids'][0] for i in remove_words]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(range(len(ens_samples))):\n    preds=ens_samples[i]['preds']\n    input_ids=ens_samples[i]['input_ids']\n    idx=0\n    while idx<len(preds):\n        if preds[idx] != \"O\":\n            label = preds[idx][2:]\n            matching_label = f\"I-{label}\"\n        else:\n            idx+=1\n            continue\n        idx+=1\n        while idx<len(preds):\n            if preds[idx] == matching_label:\n                idx+=1\n                #print(idx)\n                continue\n            else:\n                #from IPython.core.debugger import Pdb; Pdb().set_trace()\n                if input_ids[idx-1] in remove_words_ids:\n                    ens_samples[i]['preds'][idx-1]='O'\n                    ens_samples[i]['pred_scores']==1.\n                    break\n                else:\n                    break\n\n                    \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def link_evidence(oof):\n    if not len(oof):\n        return oof\n  \n    def jn(pst, start, end):\n        return \" \".join([str(x) for x in pst[start:end] if x !=-1])\n  \n    thresh = 1\n    idu = oof['id'].unique()\n    eoof = oof[oof['class'] == \"Evidence\"]\n    neoof = oof[oof['class'] != \"Evidence\"]\n    eoof.index = eoof[['id', 'class']]\n    for thresh2 in range(30, 31, 1):\n        retval = []\n        for idv in tqdm(idu, desc='link_evidence', leave=False):\n            for c in ['Evidence']:\n                q = eoof[(eoof['id'] == idv)]\n\n                if len(q) == 0:\n                    continue\n                pst = []\n\n                for r in q.itertuples():\n                    pst = [*pst, -1,  *[int(x) for x in r.predictionstring.split()]]\n                start = 1\n                end = 1\n                for i in range(2, len(pst)):\n                    cur = pst[i]\n                    end = i\n                    if  ((cur == -1) and ((pst[i + 1] > pst[end - 1] + thresh) or (pst[i + 1] - pst[start] > thresh2))):\n                        retval.append((idv, c, jn(pst, start, end)))\n                        start = i + 1\n                v = (idv, c, jn(pst, start, end + 1))\n                retval.append(v)\n    roof = pd.DataFrame(retval, columns=['id', 'class', 'predictionstring'])\n    roof = roof.merge(neoof, how='outer')\n    return roof","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:39:45.050433Z","iopub.execute_input":"2022-03-07T15:39:45.050986Z","iopub.status.idle":"2022-03-07T15:39:45.06647Z","shell.execute_reply.started":"2022-03-07T15:39:45.050941Z","shell.execute_reply":"2022-03-07T15:39:45.065283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def link_lead(oof):\n    if not len(oof):\n        return oof\n  \n    def jn(pst, start, end):\n        return \" \".join([str(x) for x in pst[start:end] if x !=-1])\n  \n    thresh = 200\n    idu = oof['id'].unique()\n    eoof = oof[oof['class'] == \"Lead\"]\n    neoof = oof[oof['class'] != \"Lead\"]\n    eoof.index = eoof[['id', 'class']]\n    for thresh2 in range(1000, 1001, 1):\n        retval = []\n        for idv in tqdm(idu, desc='link_lead', leave=False):\n            for c in ['Lead']:\n                q = eoof[(eoof['id'] == idv)]\n                if len(q) == 0:\n                    continue\n                pst = []\n                for r in q.itertuples():\n                    pst = [*pst, -1,  *[int(x) for x in r.predictionstring.split()]]\n                start = 1\n                end = 1\n                for i in range(2, len(pst)):\n                    cur = pst[i]\n                    end = i\n                    if  ((cur == -1) and ((pst[i + 1] > pst[end - 1] + thresh) or (pst[i + 1] - pst[start] > thresh2))):\n                        retval.append((idv, c, jn(pst, start, end)))\n                        start = i + 1\n                v = (idv, c, jn(pst, start, end + 1))\n                retval.append(v)\n    roof = pd.DataFrame(retval, columns=['id', 'class', 'predictionstring'])\n    roof = roof.merge(neoof, how='outer')\n    return roof","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:39:45.069975Z","iopub.execute_input":"2022-03-07T15:39:45.070208Z","iopub.status.idle":"2022-03-07T15:39:45.0869Z","shell.execute_reply.started":"2022-03-07T15:39:45.070179Z","shell.execute_reply":"2022-03-07T15:39:45.085744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def link_conclude(oof):\n    if not len(oof):\n        return oof\n  \n    def jn(pst, start, end):\n        return \" \".join([str(x) for x in pst[start:end] if x !=-1])\n  \n    thresh = 100\n    idu = oof['id'].unique()\n    eoof = oof[oof['class'] == \"Concluding Statement\"]\n    neoof = oof[oof['class'] != \"Concluding Statement\"]\n    eoof.index = eoof[['id', 'class']]\n    for thresh2 in range(500, 501, 1):\n        retval = []\n        for idv in tqdm(idu, desc='link_conclude', leave=False):\n            for c in [\"Concluding Statement\"]:\n                q = eoof[(eoof['id'] == idv)]\n                if len(q) == 0:\n                    continue\n                pst = []\n                for r in q.itertuples():\n                    pst = [*pst, -1,  *[int(x) for x in r.predictionstring.split()]]\n                start = 1\n                end = 1\n                for i in range(2, len(pst)):\n                    cur = pst[i]\n                    end = i\n                    if  ((cur == -1) and ((pst[i + 1] > pst[end - 1] + thresh) or (pst[i + 1] - pst[start] > thresh2))):\n                        retval.append((idv, c, jn(pst, start, end)))\n                        start = i + 1\n                v = (idv, c, jn(pst, start, end + 1))\n                retval.append(v)\n    roof = pd.DataFrame(retval, columns=['id', 'class', 'predictionstring'])\n    roof = roof.merge(neoof, how='outer')\n    return roof","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:39:45.088831Z","iopub.execute_input":"2022-03-07T15:39:45.089168Z","iopub.status.idle":"2022-03-07T15:39:45.106472Z","shell.execute_reply.started":"2022-03-07T15:39:45.089132Z","shell.execute_reply":"2022-03-07T15:39:45.105246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def link_position(oof):\n    if not len(oof):\n        return oof\n  \n    def jn(pst, start, end):\n        return \" \".join([str(x) for x in pst[start:end] if x !=-1])\n  \n    thresh = 15\n    idu = oof['id'].unique()\n    eoof = oof[oof['class'] == \"Position\"]\n    neoof = oof[oof['class'] != \"Position\"]\n    eoof.index = eoof[['id', 'class']]\n    for thresh2 in range(200, 201, 1):\n        retval = []\n        for idv in tqdm(idu, desc='link_position', leave=False):\n            for c in ['Position']:\n                q = eoof[(eoof['id'] == idv)]\n                if len(q) == 0:\n                    continue\n                pst = []\n                for r in q.itertuples():\n                    pst = [*pst, -1,  *[int(x) for x in r.predictionstring.split()]]\n                start = 1\n                end = 1\n                for i in range(2, len(pst)):\n                    cur = pst[i]\n                    end = i\n                    if  ((cur == -1) and ((pst[i + 1] > pst[end - 1] + thresh) or (pst[i + 1] - pst[start] > thresh2))):\n                        retval.append((idv, c, jn(pst, start, end)))\n                        start = i + 1\n                v = (idv, c, jn(pst, start, end + 1))\n                retval.append(v)\n    roof = pd.DataFrame(retval, columns=['id', 'class', 'predictionstring'])\n    roof = roof.merge(neoof, how='outer')\n    return roof","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:39:45.108599Z","iopub.execute_input":"2022-03-07T15:39:45.109636Z","iopub.status.idle":"2022-03-07T15:39:45.126194Z","shell.execute_reply.started":"2022-03-07T15:39:45.109589Z","shell.execute_reply":"2022-03-07T15:39:45.125156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def link_counterclaim(oof):\n    if not len(oof):\n        return oof\n  \n    def jn(pst, start, end):\n        return \" \".join([str(x) for x in pst[start:end] if x !=-1])\n  \n    thresh = 8\n    idu = oof['id'].unique()\n    eoof = oof[oof['class'] == \"Counterclaim\"]\n    neoof = oof[oof['class'] != \"Counterclaim\"]\n    eoof.index = eoof[['id', 'class']]\n    for thresh2 in range(50, 51, 1):\n        retval = []\n        for idv in tqdm(idu, desc='link_counterclaim', leave=False):\n            for c in [\"Counterclaim\"]:\n                q = eoof[(eoof['id'] == idv)]\n                if len(q) == 0:\n                    continue\n                pst = []\n                for r in q.itertuples():\n                    pst = [*pst, -1,  *[int(x) for x in r.predictionstring.split()]]\n                start = 1\n                end = 1\n                for i in range(2, len(pst)):\n                    cur = pst[i]\n                    end = i\n                    if  ((cur == -1) and ((pst[i + 1] > pst[end - 1] + thresh) or (pst[i + 1] - pst[start] > thresh2))):\n                        retval.append((idv, c, jn(pst, start, end)))\n                        start = i + 1\n                v = (idv, c, jn(pst, start, end + 1))\n                retval.append(v)\n    roof = pd.DataFrame(retval, columns=['id', 'class', 'predictionstring'])\n    roof = roof.merge(neoof, how='outer')\n    return roof","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:39:45.129157Z","iopub.execute_input":"2022-03-07T15:39:45.129434Z","iopub.status.idle":"2022-03-07T15:39:45.14737Z","shell.execute_reply.started":"2022-03-07T15:39:45.129404Z","shell.execute_reply":"2022-03-07T15:39:45.146121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def link_rebuttal(oof):\n    if not len(oof):\n        return oof\n    \n    def jn(pst, start, end):\n        return \" \".join([str(x) for x in pst[start:end] if x !=-1])\n  \n    thresh = 1\n    idu = oof['id'].unique()\n    eoof = oof[oof['class'] == \"Rebuttal\"]\n    neoof = oof[oof['class'] != \"Rebuttal\"]\n    eoof.index = eoof[['id', 'class']]\n    for thresh2 in range(40, 41, 1):\n        retval = []\n        for idv in tqdm(idu, desc='link_rebuttal', leave=False):\n            for c in [\"Rebuttal\"]:\n                q = eoof[(eoof['id'] == idv)]\n                if len(q) == 0:\n                    continue\n                pst = []\n                for r in q.itertuples():\n                    pst = [*pst, -1,  *[int(x) for x in r.predictionstring.split()]]\n                start = 1\n                end = 1\n                for i in range(2, len(pst)):\n                    cur = pst[i]\n                    end = i\n\n                    if  ((cur == -1) and ((pst[i + 1] > pst[end - 1] + thresh) or (pst[i + 1] - pst[start] > thresh2))):\n                        retval.append((idv, c, jn(pst, start, end)))\n                        start = i + 1\n                v = (idv, c, jn(pst, start, end + 1))\n                retval.append(v)\n    roof = pd.DataFrame(retval, columns=['id', 'class', 'predictionstring'])\n    roof = roof.merge(neoof, how='outer')\n    return roof","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:39:45.151541Z","iopub.execute_input":"2022-03-07T15:39:45.151975Z","iopub.status.idle":"2022-03-07T15:39:45.17028Z","shell.execute_reply.started":"2022-03-07T15:39:45.151926Z","shell.execute_reply":"2022-03-07T15:39:45.169234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_token_v4(row, discourse_type, thresh_list: list):\n\n    #昇順sort\n    thresh_list=sorted(thresh_list, key=lambda x: x['start'])\n\n    #thresh_listのspanに重なりがないか確認。\n    count_array=np.zeros(10000)\n    for d in thresh_list:\n        count_array[d['start']: d['end']+1]+=1\n    if (count_array>1).sum()>=1:\n        raise Exception(\"spans are overlapping\")\n    \n    pred_len=len(row['predictionstring'].split())\n    for d in thresh_list:\n        if (row['class']==discourse_type) and (pred_len>=d['start']) and (pred_len<=d['end']):\n            max_idx=int(row['predictionstring'].split()[-1])\n            min_idx=int(row['predictionstring'].split()[0])\n            fix_pred=' '.join([str(i) for i in range(min_idx, max_idx+d['add_num']+1)])\n            return fix_pred\n    #もし、どのspanにも含まれなければ、そのまま返す。\n    return row['predictionstring']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"claim_thresh_list=[\n                {\n    'start':1,\n    'end':5,\n    'add_num':1\n},\n             {\n    'start':6,\n    'end':10,\n    'add_num':2\n},\n\n{\n    'start':11,\n    'end': 20,\n    'add_num':4\n    \n},\n]\n\nlead_thresh_list=[\n                {\n    'start':7,\n    'end':13,\n    'add_num':6\n},\n             {\n    'start':14,\n    'end':19,\n    'add_num':12\n},\n\n             {\n    'start':20,\n    'end':30,\n    'add_num':14\n},\n\n]\n\nposition_thresh_list=[\n             {\n    'start':5,\n    'end':15,\n    'add_num':3\n},\n{\n    'start':16,\n    'end': 20,\n    'add_num':2\n},\n\n]\n\nrebuttal_thresh_list=[\n\n             {\n    'start':2,\n    'end':4,\n    'add_num':1\n},\n                      \n             {\n    'start':5,\n    'end':13,\n    'add_num':5\n},\n\n             {\n    'start':14,\n    'end':21,\n    'add_num':7\n},\n\n             {\n    'start':22,\n    'end':27,\n    'add_num':8\n},\n\n]\n\ncounterclaim_thresh_list=[\n             {\n    'start':5,\n    'end':24,\n    'add_num':4\n},\n{\n    'start':25,\n    'end': 37,\n    'add_num':5\n},\n\n]\n\n# conclude_thresh_list=[\n#              {\n#     'start':9,\n#     'end':15,\n#     'add_num':2\n# },\n# ]\n\n\n\nevidence_thresh_list=[\n             {\n    'start':17,\n    'end':20,\n    'add_num':11\n},\n\n             {\n    'start':21,\n    'end':23,\n    'add_num':14\n},\n\n             {\n    'start':24,\n    'end':29,\n    'add_num':17\n},\n\n             {\n    'start':30,\n    'end':36,\n    'add_num':20\n},\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"proba_thresh = {\n    \"Lead\": 0.604,\n    \"Position\": 0.55,\n    \"Evidence\": 0.6,\n    \"Claim\": 0.525,\n    \"Concluding Statement\": 0.62,\n    \"Counterclaim\": 0.52,\n    \"Rebuttal\": 0.535,\n}\n\nmin_thresh = {\n    \"Lead\": 7,\n    \"Position\": 5,\n    \"Evidence\": 17,\n    \"Claim\": 1,\n    \"Concluding Statement\": 9,\n    \"Counterclaim\": 5,\n    \"Rebuttal\": 4,\n}\n\nmax_thresh = {\n    \"Lead\": 300,\n    \"Position\": 100,\n    \"Evidence\": 1000,\n    \"Claim\": 200,\n    \"Concluding Statement\": 500,\n    \"Counterclaim\": 1000,\n    \"Rebuttal\": 1000,\n}\n\nsubmission = []\nfor sample_idx, sample in enumerate(ens_samples):\n    preds = sample[\"preds\"]\n    offset_mapping = sample[\"offset_mapping\"]\n    sample_id = sample[\"id\"]\n    sample_text = sample[\"text\"]\n    sample_input_ids = sample[\"input_ids\"]\n    sample_pred_scores = sample[\"pred_scores\"]\n    sample_preds = []\n\n    idx = 0\n    phrase_preds = []\n    while idx < len(offset_mapping):\n        #はじめ\n        start, _ = offset_mapping[idx]\n        # if preds[idx] != \"O\":\n        #     label = preds[idx][2:]\n        if preds[idx] != \"O\":\n            label = preds[idx][2:]\n        else:\n            label = \"O\"\n        phrase_scores = []\n        phrase_scores.append(sample_pred_scores[idx])\n\n        idx += 1\n        while idx < len(offset_mapping):\n            if label == \"O\":\n                matching_label = \"O\"\n            else:\n                matching_label = f\"I-{label}\"\n            if preds[idx] == matching_label:\n                _, end = offset_mapping[idx]\n                phrase_scores.append(sample_pred_scores[idx])\n                idx += 1\n            else:\n                break\n        if \"end\" in locals():\n            phrase = sample_text[start:end]\n            phrase_preds.append((phrase, start, end, label, phrase_scores))\n\n    temp_df = []\n    for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n        word_start = len(sample_text[:start].split())\n        word_end = word_start + len(sample_text[start:end].split())\n        word_end = min(word_end, len(sample_text.split()))\n        ps = \" \".join([str(x) for x in range(word_start, word_end)])\n        if label != \"O\":\n            # if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n            #     if len(ps.split()) >= min_thresh[label]:\n            #         temp_df.append((sample_id, label, ps))\n            if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n                if (len(ps.split()) >= min_thresh[label]) and (len(ps.split()) <= max_thresh[label]):\n                    temp_df.append((sample_id, label, ps))\n    \n    temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n    submission.append(temp_df)\n\nsubmission = pd.concat(submission).reset_index(drop=True)\nsubmission = link_evidence(submission)\nsubmission = link_lead(submission)\nsubmission = link_conclude(submission)\nsubmission = link_position(submission)\nsubmission = link_counterclaim(submission)\nsubmission = link_rebuttal(submission)\n#submission = link_claim(submission)\n\n# submission['predictionstring']=submission.apply(lambda x: add_token_v4(x, 'Concluding Statement', conclude_thresh_list), axis=1)\nsubmission['predictionstring']=submission.apply(lambda x: add_token_v4(x, 'Evidence', evidence_thresh_list), axis=1)\nsubmission['predictionstring']=submission.apply(lambda x: add_token_v4(x, 'Claim', claim_thresh_list), axis=1)#best params\nsubmission['predictionstring']=submission.apply(lambda x: add_token_v4(x, 'Lead', lead_thresh_list), axis=1)#best params\nsubmission['predictionstring']=submission.apply(lambda x: add_token_v4(x, 'Position', position_thresh_list), axis=1) #best params\nsubmission['predictionstring']=submission.apply(lambda x: add_token_v4(x, 'Counterclaim', counterclaim_thresh_list), axis=1) #best params\nsubmission['predictionstring']=submission.apply(lambda x: add_token_v4(x, 'Rebuttal', rebuttal_thresh_list), axis=1) #best params\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:39:45.172403Z","iopub.execute_input":"2022-03-07T15:39:45.172768Z","iopub.status.idle":"2022-03-07T15:39:45.347645Z","shell.execute_reply.started":"2022-03-07T15:39:45.172719Z","shell.execute_reply":"2022-03-07T15:39:45.346594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:44:22.743667Z","iopub.execute_input":"2022-03-07T15:44:22.74468Z","iopub.status.idle":"2022-03-07T15:44:22.763049Z","shell.execute_reply.started":"2022-03-07T15:44:22.744645Z","shell.execute_reply":"2022-03-07T15:44:22.762197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}